{
    "TRAINING_DATA": [
        [
            "Artificial Intelligence 184–185 (2012) 1–16Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA complete solution to the Maximum Density Still Life Problem ✩Geoffrey Chu, Peter J. Stuckey∗NICTA Victoria Laboratory, Department of Computing and Information Systems, University of Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 17 August 2011Received in revised form 8 November 2011Accepted 8 February 2012Available online 10 February 2012Keywords:Combinatorial optimizationSearchConstraint programmingDynamic programming1. IntroductionThe Maximum Density Still Life Problem (CSPLib prob032) is to find the maximum numberof live cells that can fit in an n × n region of an infinite board, so that the board is stableunder the rules of Conway’s Game of Life. It is considered a very difficult problem andhas a raw search space of O (2n2). Previous state of the art methods could only solveup to n = 20. We give a powerful reformulation of the problem into one of minimizing“wastage” instead of maximizing the number of live cells. This reformulation allows usto compute very strong upper bounds on the number of live cells, which dramaticallyreduces the search space. It also gives us significant insights into the nature of the problem.By combining these insights with several powerful techniques: remodeling, lazy clausegeneration, bounded dynamic programming, relaxations, and custom search, we are ableto solve the Maximum Density Still Life Problem for all n. This is possible because theMaximum Density Still Life Problem is in fact well behaved mathematically for sufficientlylarge n (around n > 200) and if such very large instances can be solved, then there existways to construct provably optimal solutions for all n from a finite set of base solutions.Thus we show that the Maximum Density Still Life Problem has a closed form solution anddoes not require exponential time to solve.© 2012 Elsevier B.V. All rights reserved.The Game of Life was invented by John Horton Conway and is played on an infinite board made up of square cells. Thegame takes place through discrete time steps. Each cell c in the board is either alive or dead during each time period. Thelive/dead state of cell c at time t + 1, denoted as state(c, t + 1), can be obtained from the number l of live neighbors of c attime t and from state(c, t) as follows:state(c, t + 1) =⎧⎪⎪⎪⎨⎪⎪⎪⎩l < 2 dead [Death by isolation]l = 2 state(c, t) [Stable condition]l = 3 alive [Birth condition]l > 3 dead [Death by overcrowding]The board is said to be a still life at time t if it is stable under these rules, i.e., it is identical at t + 1. For example, anempty board is a still life. Given a finite n × n region where all cells outside must be dead, the Maximum Density Still LifeProblem is to compute the maximum density of live cells that can appear in the n × n region in a still life, or equivalently,the maximum number of live cells that can appear in the n × n region.✩This paper includes and significantly extends the earlier work (Chu et al., 2009) [1].* Corresponding author.E-mail address: peter.stuckey@nicta.com.au (P.J. Stuckey).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.02.001\f2G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16The raw search space of the Still Life Problem has size O (2n2) and it is extremely difficult even for small values of n.Previous search methods using integer programming (IP) [2] and constraint programming (CP) [3] could only solve upto n = 9, while a CP/IP hybrid method with symmetry breaking [3] could solve up to n = 15. An attempt using bucketelimination [4] reduced the time complexity to O (n223n) but increased the space complexity to O (n22n). This methodcould solve up to n = 14 before it ran out of memory. A subsequent improvement that combined bucket elimination withsearch [5] used less memory and was able to solve up to n = 20.In this paper, we combine some mathematical insights into the Still Life Problem with several powerful search techniquesto completely solve the problem for all n. This is possible because the Still Life Problem becomes well behaved mathemat-ically for sufficiently large n (around n > 200). The overall solution plan has four parts: (1) use complete search with amodel that propagates strongly to solve the problem for all “small” n (n (cid:2) 50), (2) use bounded dynamic programming ona relaxation of the problem to prove a closed form upper bound on live cells for all medium and large n (n > 50), (3) use acustom search to look for special form solutions to prove lower bounds on live cells for medium n (around 50 < n (cid:2) 200),(4) look for special form periodic solutions that can be tiled to construct arbitrarily large solutions to prove lower boundson live cells for large n (around n > 200). The lower and upper bounds proved in parts 2, 3 and 4 coincide, thus they are theoptimums for those n. Each of these parts require some mathematical insights into the problem as well as the appropriateapplication of search techniques. We give a brief overview of them here.Part 1. In Section 2 we give a new insightful proof that the maximum density of live cells in the infinite case (n = ∞)2 . The proof is based on counting “wastage”. Wastage is calculated by looking at each 3 × 3 pattern and seeing howis 1much space we have “wasted” by not fitting in enough live cells into the local area. This proof allows us to reformulatethe Maximum Density Still Life Problem into one of minimizing wastage rather than maximizing the number of live cells.The new model gives very tight lower bounds on wastage that dramatically increases the pruning strength of the model. InSection 3 we show how this model, coupled with a simple lookahead, allows a Lazy Clause Generation [6] solver to solvethe problem up to around n = 50 using complete search.Part 2. In Section 4, we conjecture that for sufficiently large n, all wastage which is forced to occur by the still life con-straints are forced by only the constraints near the edge of the n × n region. That is, only the boundary conditions causesuboptimality compared to the optimal density of 12 in the infinite case. If this conjecture holds, then it is possible to geta very good or optimal lower bound on the wastage (and thus upper bound on live cells) simply by relaxing the Still LifeProblem onto its boundary and solving it, i.e., ignore all constraints other than then those within the first k rows of theedge of the n × n region for some small k. This relaxed problem has the interesting property that the pathwidth of itsconstraint graph is O (k) instead of the O (n) of the original. There exist various techniques for solving such low pathwidthproblems which can reduce the complexity from O (2nk) to only O (n22k), e.g., caching [7], nogood learning [6,8], dynamicprogramming [9], variable elimination [4]. In Section 5 we show how to use bounded dynamic programming [10] to solvethe boundary relaxation. For fixed and small k, these relaxed problems can be solved in O (n) time. Furthermore, due to thetranslational symmetry in the problem, we can solve the boundary relaxation for all n using induction by examining a finitenumber of base cases. Thus we can derive a closed form expression which gives a very tight upper bound on the numberof live cells.Part 3. In Section 6, we conjecture that for sufficiently large n, there always exist optimal solutions of the following form:wastage only exists at the four 4 × 4 corners of the board, or in the one row beyond the edge of the board. Based on thisconjecture, we search for these special form solutions using a variant of limited discrepancy search with dynamic relaxationsas a lookahead. Such a search can find optimal solutions for up to n = 200 or so. We know that the solution is optimal ifthe number of live cells in the solution coincides with the upper bound on live cells proved in part 2.Part 4. The Still Life Problem becomes mathematically well behaved for sufficiently large n. This raises the possibility thatoptimal solutions can be constructed in a systematic way. In Section 7 we find optimal solutions for n ∼ 200 which areperiodic, and which satisfy certain other constraints. If such solutions are found, then they can be tiled indefinitely toproduce arbitrarily large, provably optimal solutions.We conclude the paper in Section 8.2. Wastage reformulationThe maximum density of live cells in a still life on an infinite board is known to be 12 [11]. However, this proof is quitecomplex and only applies to the infinite case. In this section we provide a much simpler proof that can easily be extendedto the finite case and gives much better insight into the possible sub-patterns that can occur in an optimal solution.Theorem 1. The maximum density of live cells in a still life on an infinite board is 12 .Proof. Consider any configuration of the board which is a still life. We show that the density of live cells in this configura-tion is (cid:2) 12 . We initially assign 2 tokens to each cell in the board. We will show below that there exists a way to redistribute\fG. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–163Table 1Possible patterns around dead cells, showing where they donate their tokens and anywastage.Table 2Contributions to the tokens of a live cell from its Southneighbor.these tokens such that: (1) each live cell ends up with (cid:3) 4 tokens, and (2) each token either remains at the original cell towhich it was assigned, or is redistributed to one of the 4 orthogonal neighbors. If such a redistribution exists, then in anyn × n region of the infinite board, if L is the number of live cells, then: 2(n2 + 4n) (cid:3) 4L. This is because at most 2(n2 + 4n)tokens could have ended up in the n × n region after redistribution, and each live cell must have (cid:3) 4 of them. Rearranging,we get L/n2 (cid:2) 12 and t",
            {
                "entities": [
                    [
                        3268,
                        3296,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 322 (2023) 103951Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintSpectral complexity-scaled generalisation bound of complex-valued neural networksHaowen Chen a,b,c, Fengxiang He d,b,∗a Department of Mathematics, ETH Zürich, 8092 Zürich, Switzerlandb JD Explore Academy, JD.com, Inc., Beijing, 100176, Chinac Department of Mathematics, Faculty of Science, The University of Hong Kong, Hong Kong Special Administrative Regiond Artificial Intelligence and its Applications Institute, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdome School of Computer Science, Faculty of Engineering, The University of Sydney, Darlington NSW 2008, Australia, Shiye Lei e, Dacheng Tao e,ba r t i c l e i n f oa b s t r a c tArticle history:Received 12 November 2021Received in revised form 22 May 2023Accepted 27 May 2023Available online 5 June 2023Keywords:Complex-valued neural networksGeneralisationSpectral complexityComplex-valued neural networks (CVNNs) have been widely applied in various fields, primarily in signal processing and image recognition. Few studies have focused on the generalisation of CVNNs, although it is vital to ensure the performance of CVNNs on unseen data. This study is the first to prove a generalisation bound for complex-valued neural networks. The bounds increase as the spectral complexity increases, with the dominant factor being the product of the spectral norms of the weight matrices. Furthermore, this work provides a generalisation bound for CVNNs trained on sequential data, which is also affected by the spectral complexity. Theoretically, these bounds are derived using the Maurey Sparsification Lemma and Dudley entropy integral. We conducted empirical experiments on various datasets including MNIST, ashionMNIST, CIFAR-10, CIFAR-100, Tiny ImageNet, and IMDB by training complex-valued convolutional neural networks. The Spearman rank-order correlation coefficient and the corresponding p-values on these datasets provide strong proof of the statistically significant correlation between the spectral complexity of a network and its generalisation ability, as measured by the spectral norm product of the weight matrices. The code is available at https://github .com /LeavesLei /cvnn _generalization.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons .org /licenses /by-nc -nd /4 .0/).1. IntroductionComplex-valued neural networks (CVNNs) have garnered significant attention in various fields, such as signal processing [1,2], voice processing [3], and image reconstruction [4]. To reduce complex operations, it is natural to link CVNNs to two-dimensional real-valued neural networks with fewer degrees of freedom [5,6]. A complex number consists of a real part and imaginary part, which can alternatively be expressed as amplitude and phase. When performing computations using complex numbers, distinct arithmetic operations are applied separately to the real and imaginary parts.Several recent studies endeavoured to investigate the different properties of CVNNs and built basic algorithms for their implementation. For example, Nitta [7,8,9,10] proved the orthogonality of the decision boundary of complex-valued neu-* Corresponding author at: Artificial Intelligence and its Applications Institute, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdom.E-mail address: F.He@ed.ac.uk (F. He).https://doi.org/10.1016/j.artint.2023.1039510004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons .org /licenses /by-nc -nd /4 .0/).\fH. Chen, F. He, S. Lei et al.Artificial Intelligence 322 (2023) 103951rones, addressed the redundancy problem of the parameters of CVNNs, extended the backpropagation algorithm to complex numbers, and Trabelsi et al. [11] organised the essential components of complex-valued deep neural networks, such as complex convolutions, complex batch normalisation, and complex weight initialisation. Empirical studies were conducted to examine the experimental performance of CVNNs. Hirose and Yoshida [5] used different neural networks, including CVNNs, to process signals of different coherence and Nitta [7] found that for the same computational cost, CVNNs display a higher learning speed than real-valued neural networks.Previous studies have shown satisfactory experimental performance for CVNNs. However, there is still a lack of theoretical analysis of their generalisation ability. This gap in understanding has motivated us to derive a generalisation bound for CVNNs.This is the first study to provide theoretical evidence for the generalisation performance of CVNNs. We propose novel upper bounds which positively correlate with the spectral complexity of CVNNs trained on both independent identically distributed (i.i.d.) and sequential data. The spectral complexity-scaled upper bounds suggest a direct correlation between the generalisation ability of CVNNs and the spectral norm product of their complex-valued weight matrices.From an empirical perspective, the experiments were conducted to investigate the influence of spectral complexity on the generalisation ability. Specifically, we trained CVNNs using stochastic gradient descent (SGD) on six standard datasets: CIFAR-10, CIFAR-100, MNIST, FashionMNIST, Tiny ImageNet, and IMDB. Excess risks were collected for analysis. When the training error is almost zero across all datasets, the excess risk equals the test accuracy and is informative in expressing gen-eralisation ability. In addition, because the change in the spectral norm product of the weight matrices primarily contributes to the change in spectral complexity, it is used to simulate spectral complexity. Our experimental results demonstrate a strong correlation between the spectral-norm product and excess risk, which is consistent with our theoretical analysis. The code is available at https://github .com /LeavesLei /cvnn _generalization.The remainder of this paper is organised as follows. Section 2 presents the motivation behind the research and pro-vides a review of related work. Section 3 provides an introduction to the preliminaries of complex-valued neural networks. Section 4 presents the theoretical results, while Section 5 presents the experimental results. In Section 6, a comparison is made between CVNNs and real-valued neural networks to explore the novelties and advantages of the proposed bound. In Section 7, the practical applications of the proposed theorems in spectral normalisation algorithms are discussed in detail.2. Motivation and related worksComplex values are widely adopted in different neural networks for their biological [12], computational [7,13], and representational advantages [14,15].From a biological perspective, Reichert and Serre [12] proposed that the complex-valued neuronal unit is a more ap-propriate abstraction in modelling the activity of neurones in the brain than a real-valued unit. To better process cortical information, the modelling mechanism must consider both firing rate and spike timing. In incorporating these two elements into deep neural networks, the amplitude of a complex-valued neuron represents the firing rate and the phase represents the spike timing. When two inputs of an excitatory complex-valued neuron have similar or dissimilar phase information, the magnitude of the net input may increase or decrease depending on whether the phases are similar, which correspond to synchronous and asynchronous situations, respectively. The incorporation of complex values into deep neural networks helps construct richer and more versatile representations.Regarding the computational aspect, Danihelka et al. [13] combined long short-term memory (LSTM) with the concept of holographic reduced representations and used complex values to increase the efficiency of information retrieval. Experiments showed that this method achieves a faster learning speed on multiple memorisation tasks. Nitta [7] extended the back-propagation algorithm to complex values, preserving the basic idea of real-valued back-propagation, with updates conducted on both real and imaginary parts. Through experiments, it was demonstrated that under the same time complexity, the learning speed of complex backpropagation is definitely faster than the real speed when the learning rate is low, that is, less than 0.5.Complex-valued neural networks also provide advantages over real-valued neural networks in terms of representational ability. Arjovsky et al. [14] proposed a unitary recurrent neural network (RNN) with unitary matrices as the weight matrix, to circumvent the well-studied gradient vanishing and gradient exploding issues. The unitary matrix is the generalised form of the orthogonal matrices in the complex field, and the absolute value of its eigenvalue is 1. Compared to an orthogonal matrix, a complex-valued matrix has a richer representation, particularly in applications of the discrete Fourier Transform. Wisdom et al. [15] further proposed full-capacity unitary RNNs, thereby improving the performance over unitary evolution RNN (uRNN).Given these advantages and applications of CVNNs, an increasing number of researchers have been investigating the properties of complex-valued neural networks to provide a basic framework for the implementation of CVNNs. Nitta [8]demonstrated that the decision boundary of a two-layered complex-valued network is orthogonal, and for a three-layered network, the decision boundary is nearly orthogonal. This reflects the computational power and versatility of complex values. In their work, Trabelsi et al. [11] provided the building blocks for complex-valued deep neural networks, including complex batch normalisation and complex weight initialisation strategies. They also compared the p",
            {
                "entities": [
                    [
                        3572,
                        3600,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1174–1182www.elsevier.com/locate/artintFrom here to human-level AIJohn McCarthyComputer Science Department, Stanford University, Stanford, CA 94305, USAAvailable online 10 October 2007AbstractHuman-level AI will be achieved, but new ideas are almost certainly needed, so a date cannot be reliably predicted—maybe fiveyears, maybe five hundred years. I’d be inclined to bet on this 21st century.It is not surprising that human-level AI has proved difficult and progress has been slow—though there has been importantprogress. The slowness and the demand to exploit what has been discovered has led many to mistakenly redefine AI, sometimes inways that preclude human-level AI—by relegating to humans parts of the task that human-level computer programs would have todo. In the terminology of this paper, it amounts to settling for a bounded informatic situation instead of the more general commonsense informatic situation.Overcoming the “brittleness” of present AI systems and reaching human-level AI requires programs that deal with the commonsense informatic situation—in which the phenomena to be taken into account in achieving a goal are not fixed in advance.We discuss reaching human-level AI, emphasizing logical AI and especially emphasizing representation problems of informationand of reasoning. Ideas for reasoning in the common sense informatic situation include nonmonotonic reasoning, approximateconcepts, formalized contexts and introspection.© 2007 Published by Elsevier B.V.Keywords: Human-level AI; Elaboration tolerance1. What is human-level AI?The first scientific discussion of human level machine intelligence was apparently by Alan Turing in the lec-ture [35]. The notion was amplified as a goal in [34], but at least the latter paper did not say what would have to bedone to achieve the goal.Allen Newell and Herbert Simon in 1954 were the first people to make a start on programming computers forgeneral intelligence. They were over-optimistic, because their idea of what has to be done to achieve human-levelintelligence was inadequate. The General Problem Solver (GPS) took general problem solving to be the task oftransforming one expression into another using an allowed set of transformations.Many tasks that humans can do, humans cannot yet make computers do. There are two approaches to human-level AI, but each presents difficulties. It isn’t a question of deciding between them, because each should eventuallysucceed; it is more a race.E-mail address: jmc@cs.stanford.edu.URL: http://www-formal.stanford.edu/jmc/.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.10.009\fJ. McCarthy / Artificial Intelligence 171 (2007) 1174–118211751. If we understood enough about how the human intellect works, we could simulate it. However, we don’t havesufficient ability to observe ourselves or others to understand directly how our intellects work. Understanding thehuman brain well enough to imitate its function therefore requires theoretical and experimental success in psy-chology and neurophysiology.1 See [28] for the beginning of the information processing approach to psychology.2. To the extent that we understand the problems achieving goals in the world presents to intelligence we can writeintelligent programs. That’s what this article is about.Much of the public recognition of AI has been for programs with a little bit of AI and a lot of computing. Thissucceeded for chess and checkers and has so far failed for the game of go. Go requires the identification ofsubpositions that are analyzed separately first and then in interaction with each other. Human chess players alsodo this, but the chess programs don’t. The price of the much greater computation this makes necessary has beenaffordable in chess but not in go. Computer speed bypasses many other heuristics that save humans enormouscomputation.What problems does the world present to intelligence? More narrowly, we consider the problems it would presentto a human scale robot faced with the problems humans might be inclined to relegate to sufficiently intelligent ro-bots. The physical world of a robot contains middle sized objects about which its sensory apparatus can obtain onlypartial information quite inadequate to fully determine the effects of its future actions. Its mental world includes itsinteractions with people and also meta-information about the information it has or can obtain.Our approach is based on what we call the common sense informatic situation, which we contrast with the boundedinformatic situation that characterizes both formal scientific theories and almost all (maybe all) experimental work inAI done so far.A formal theory in the physical sciences deals with a bounded informatic situation. Scientists decide informally inadvance what phenomena to take into account. For example, much celestial mechanics is done within the Newtoniangravitational theory and does not take into account possible additional effects such as outgassing from a comet orelectromagnetic forces exerted by the solar wind. If more phenomena are to be considered, a person must make a newtheory. Probabilistic and fuzzy uncertainties can still fit into a bounded informatic system; it is only necessary that theset of possibilities (sample space) be bounded.Most AI formalisms also work only in a bounded informatic situation. What phenomena to take into account isdecided by a person before the formal theory is constructed. With such restrictions, much of the reasoning can bemonotonic, but such systems cannot reach human level ability. For that, the machine will have to decide for itselfwhat information is relevant. When a bounded informatic system is appropriate, the system must construct or choosea limited context containing a suitable theory whose predicates and functions connect to the machine’s inputs andoutputs in an appropriate way.2 The logical tool for bounding the informatic situation is nonmonotonic reasoning.2. The common sense informatic situationContention: The key to reaching human-level AI is making systems that operate successfully in the common senseinformatic situation.In general a thinking human is in what we call the common sense informatic situation [13]. It is more general thanany bounded informatic situation. The known facts are incomplete, and there is no a priori limitation on what facts arerelevant. It may not even be decided in advance what phenomena are to be taken into account. The consequences ofactions cannot be fully determined. The common sense informatic situation necessitates the use of approximate con-cepts that cannot be fully defined and the use of approximate theories involving them. It also requires nonmonotonicreasoning in reaching conclusions.The common sense informatic situation also includes some knowledge about the system’s mental state.1 Recent work with positron emission tomography has identified areas of the brain that consume more glucose when a person is doing mentalarithmetic. This knowledge will help build AI systems only when it becomes possible to observe what is going on in these areas during mentalarithmetic.2 The textbook [4] puts it this way. “To get human-level computational intelligence it must be the agent itself that decides how to divide up theworld, and which relationships to reason about”.\f1176J. McCarthy / Artificial Intelligence 171 (2007) 1174–1182A nice example of the common sense informatic situation is illustrated by an article in the American Journal ofPhysics some years ago. It discussed grading answers to a physics problem. The exam problem is to find the height ofa building using a barometer. The intended solution is to measure the air pressure at the top and bottom of the buildingand multiply the difference by the ratio of the density of mercury to the density of air.However, other answers may be offered. (1) Drop the barometer from the top of the building and measure the timebefore it hits the ground. (2) Measure the height and length of the shadow of the barometer and measure the lengthof the shadow of the building. (3) Rappel down the building using the barometer as a measuring rod. (4) Lower thebarometer on a string till it reaches the ground and measure the string. (5) Offer the barometer to the janitor of thebuilding in exchange for information about the height. (6) Ignore the barometer, count the stories of the building andmultiply by ten feet.Clearly it is not possible to bound in advance the common sense knowledge of the world that may be relevant tograding the problem. Grading some of the solutions requires knowledge of the formalisms of physics and the physicalfacts about the earth, e.g. the law of falling bodies or the variation of air pressure with altitude. However, in every case,the physics knowledge is embedded in common sense knowledge. Thus before one can use Galileo’s law of fallingbodies s = 12 gt 2, one needs common sense information about buildings, their shapes and their roofs.Bounded informatic situations are obtained by nonmonotonically inferring that only the phenomena that somehowappear to be relevant are relevant. In the barometer example, the student was expected to infer that the barometer wasonly to be used in the conventional way for measuring air pressure. For example, a reasoning system might do this byapplying circumscription to a predicate relevant in a formalism containing also metalinguistic information, e.g. thatthis was a problem assigned in a physics course. Formalizing relevance in a useful way promises to be more difficultthan just using existing relevance logics.Common sense facts and common sense reasoning are necessarily imprecise. The imprecision necessitated by thecommon sense informatic situation applies to computer programs as well as to people.Some kinds of imprecision can be represented numerically and have been explored with the aid of Bayesian net-works, fuzzy logic and similar formalisms. This is in a",
            {
                "entities": [
                    [
                        2649,
                        2677,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 25–38Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstraint propagation as information maximization ✩A. Nait Abdallah a,b, M.H. van Emden c,∗a Department of Computer Science, University of Western Ontario, Canadab INRIA Rocquencourt, Francec Department of Computer Science, University of Victoria, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 January 2012Received in revised form 11 February 2013Accepted 14 February 2013Available online 16 February 2013Keywords:Constraint-satisfaction problemsInformation partial orderIntervalsPropagationThis paper draws on diverse areas of computer science to develop a unified view ofcomputation:• Optimization in operations research, where a numerical objective function is maximizedunder constraints, is generalized from the numerical total order to a non-numericalpartial order that can be interpreted in terms of information.• Relations are generalized so that there are relations of which the constituent tuplesindexes, whereas in other relations these indexes are variables.have numericalThe distinction is essential in our definition of constraint-satisfaction problems.• Constraint-satisfaction problems are formulated in terms of semantics of conjunctions ofatomic formulas of predicate logic.• Approximation structures, which are available for severalapplied to solutions of constraint-satisfaction problems.important domains, areAs application we treat constraint-satisfaction problems over reals. These cover a large partof numerical analysis, most significantly nonlinear equations and inequalities. The chaoticalgorithm analyzed in the paper combines the efficiency of floating-point computation withthe correctness guarantees of arising from our logico-mathematical model of constraint-satisfaction problems.© 2013 Elsevier B.V. All rights reserved.1. Computation as maximization in information spaceThe early history of constraint processing is written in three MIT theses: Sutherland’s, Waltz’s, and Steele’s [16,20,14].Already in this small selection one can discern two radically different approaches. Sutherland and Steele use relaxation:starting form a guessed assignment of values to variables, constraints are successively used to adjust variables in such away as to satisfy better the constraint under consideration. These authors followed an old idea brought into prominenceunder the name of relaxation by Southwell [15].Waltz adopted a radically different approach (and was, to our knowledge, the first to do so). He associated with each ofthe problem’s variables a domain; that is, the set of all values that are not a priori impossible. Each constraint is then usedto eliminate values from the domains of one or more variables affected by the constraint that are incompatible with thatconstraint. In this paper we are concerned with the latter method, which we call the domain reduction method.✩Research Report 746, Dept. of Computer Science, University of Western Ontario, Canada.* Corresponding author.E-mail address: vanemden@cs.uvic.ca (M.H. van Emden).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.002\f26A. Nait Abdallah, M.H. van Emden / Artificial Intelligence 197 (2013) 25–38The attraction of domain reduction is its completeness for finite domains: if a solution exists, then it will be found. Thisin contrast with relaxation, which can flounder forever.1In this paper we present domain reduction as an example of the view of computation as monotonic gain of information. Thisview was pioneered by Dana Scott, who was the first to make mathematical sense [12] of a recursively defined function f .f a sequence a of partial functions. If x is such that f (x) requires aHe did this by associating with the definition ofrecursion depth is at most n, then an(x) is defined and equal to f (x); otherwise an(x) is undefined. Thus a is a sequence ofpartial functions in which each function agrees with the previous one, but is “more defined”.In general, if two partial functions g and h of the same type are such that h is defined wherever g is and such thatthey have the same value when both are defined, then Scott proposed to regard g as an approximation to h and noted thatthis notion of approximation is a partial order in the set of partial functions of the same type. Moreover Scott proposedto transfer the information concept from random variables, as it was in Shannon’s information theory, to partial functions,noting that a partial function can be regarded as containing more information than partial functions approximating it.The approach to the semantics of recursive definitions can be summarized by saying that every such definition can beregarded as the limit of a sequence of approximations each containing more information about the limit of the sequencethan the previous one.Scott was aware that it might seem somewhat far-fetched to give such an interpretation to the notion of “information”.As a justification Scott [13] gave another example of a set partially ordered by information: that of numerical intervals.Although this certainly strengthened the case, this suggestion has not, as far as we know, been followed up. In this paperwe do so, motivated by the opportunities for deeper understanding of constraint solving.In numerical applications the view of computation as monotonic gain of information is more than a theoretically in-teresting insight: it is adds an essential capability. Suppose a conventional numerical computation is stopped after 1000iterations and yields 1.912837465 and that it yields 1.912877134 when allowed to run for 10,000 iterations, what do weknow about the improvement obtained, if any? If results, intermediate and final, were expressed as intervals we would, say,have [1.911, 1.938]2 after 1000 iterations and perhaps [1.9126, 1.9283]3 after 10,000 iterations. Here we see that we knowmore about the unknown solution as a result of the additional computational work. Rephrasing “knowing more” as “gain ininformation” suggests that the effect of iteration in interval arithmetic can be described as “monotonic gain of information”.The important qualification “monotonic” is there because in interval arithmetic we never need to settle for less informationas a result of additional computational work, though we may fail to make a gain. Moreover, such a stalling of progress is auseful criterion for halting the iteration.Because of the special importance of solving constraint-satisfaction problems over the reals by means of floating-pointarithmetic, we choose our example problem from this area. Section 3 gives the needed review of interval methods; Section 4describes the example. The new view of domain reduction as monotonic information gain is used in Section 6 to developthe method from first principles. This suggests regarding the set of constraints in a constraint-satisfaction problem as aformula in predicate logic with a fixed interpretation of predicate symbols. The standard semantics only assigns meaningsto closed formulas, whereas here we have a formula with free variables. Accordingly, in Section 5 we develop the requiredextension of the semantics of predicate logic. This needs a novel treatment of relations, also in this section.2. Related workFollowing Mackworth’s AC-3 algorithm [9] there are many other papers concerned with converging fair itera-tions [1,3,17,18,11].For historical references we refer to the textbooks [7,2].We address the connections with the work of Saraswat et al. [11] in Section 7.3. Interval arithmetic and interval constraintsTo facilitate the use of information in computation we do not use interval arithmetic directly, but indirectly via aconstraint-satisfaction problem (CSP). Such problems are solved by associating with each unknown a set of possible val-ues instead of the usual single value. This is especially appropriate for real-valued unknowns. In combination with the useof floating-point arithmetic, the sets of possible values take the form of intervals with floating-point numbers as bounds.This special case of CSP solving is called interval constraints [6,1].We introduce interval constraints by means of an example. In interval arithmetic the rule for adding intervals is[a, b] + [c, d] =(cid:2)(cid:3)x + y: x ∈ [a, b] ∧ y ∈ [c, d]1 But, as one may expect, domain reduction is no cure-all. For some problems, relaxation quickly finds a solution, and domain reduction requires aninfeasible amount of time. The n-queens problem for large n is an example. Van Hentenryck and Michel [19], page 89, mention n = 10,000 as a routineexample for relaxation in combination with their search technique.2 Note the smaller number of decimals: with intervals it becomes clear that additional decimals would be meaningless.3 The smaller interval warrants another decimal.\fA. Nait Abdallah, M.H. van Emden / Artificial Intelligence 197 (2013) 25–3827so that, e.g., [0, 2] + [0, 2] = [0, 4]. The analogous operation in interval constraints starts by defining the constraintsum(x, y, z) which holds between the reals x, y, and z iff x + y = z. In other words, the formula sum(x, y, z) is true wheneverx + y = z. This leads to the following inferencesum(x, y, z)x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [−∞, +∞]x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [0, 4]We use here the conventional format for inference: the premises above the horizontal line; the conclusion below. The aboveinference coincides, in this special case, with interval arithmetic. Only the interval for z is narrowed.In interval constraints we may have a priori constraints on all variables, as insum(x, y, z)x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [3, 5]x ∈ [1, 2] ∧ y ∈ [1, 2] ∧ z ∈ [3, 4]Here the intervals for all three variables are narrowed. As a result, the effect of the operation can no longer be exclusivelycharacterized as an addition or as its inverse: the effect is a mixture of seve",
            {
                "entities": [
                    [
                        3231,
                        3259,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 1–39www.elsevier.com/locate/artintA framework for linguistic modellingJonathan LawryDepartment of Engineering Mathematics, University of Bristol, Bristol BS8 1TR, UKReceived 13 November 2001; received in revised form 7 November 2003AbstractA new framework for linguistic reasoning is proposed based on a random set model of the degree ofappropriateness of a label. Labels are assumed to be chosen from a finite predefined set of labels andthe set of appropriate labels for a value is defined as a random set-valued function from a populationof individuals into the set of subsets of labels. Appropriateness degrees are then evaluated relativeto the distribution on this random set where the appropriateness degree of a label corresponds to theprobability that it is contained in the set of appropriate labels. This interpretation is referred to as labelsemantics. A natural calculus for appropriateness degrees is described which is weakly functionalwhile taking into account the logical structure of expressions. Given this framework it is shown that abayesian approach can be adopted in order to infer probability distributions on the underlying variablegiven constraints both in the form of linguistic expressions and mass assignments. In addition, twoconditional measures are introduced for evaluating the appropriateness of a linguistic expressiongiven other linguistic information. 2003 Elsevier B.V. All rights reserved.Keywords: Random sets; Linguistic constraints; Fuzzy labels; Label semantics; Bayesian inference1. IntroductionThe limitations of classical modelling techniques to effectively capture the behaviourof complex systems has become increasingly clear over recent years. This has motivatedresearch into new, alternative modelling paradigms by the artificial intelligence community(e.g., fuzzy reasoning, possibility theory, Bayesian modelling, default reasoning: see [4,8,11,28,30]). All of these approaches share an emphasis on high level qualitative descriptionsas opposed to a more traditional low level framework. The advantage of such higher-levelknowledge representation is that it allows for the fusion of expert or background knowl-E-mail address: j.lawry@bris.ac.uk (J. Lawry).0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2003.10.001\f2J. Lawry / Artificial Intelligence 155 (2004) 1–39edge and knowledge derived from data. Furthermore, it tends to provide a clearer insightinto the underlying nature of the system than can be obtained from less transparent lower-level models. Another feature shared by many of the new approaches is that they providea methodology for reasoning in the presence of uncertainty. This is no coincidence, butrather is due to the fact that uncertainty and imprecision are often inherent in complexmodelling problems. This uncertainty is not only due to lack of precision or errors in mea-sured features but is often present in the model itself since the available features may notbe sufficient to provide a complete model of the system. To illustrate this point, considerthe important area of river basin modelling for flood forecasting. For this problem it isoften necessary to model river levels at a particular time point, purely in terms of rainfalland river levels at earlier times. However, in reality so many complex features influencerunoff that it is both difficult to identify the most important and practically impossible tomeasure any but a few of them. For instance, the likelihood that a given rainfall event willproduce a flood is dramatically affected by such factors as the size of the drainage basin,the topography of the basin, the amount of urban use within the basin and so on.While the development of analytical models may be impractical for many complex sys-tems, there is often data available implicitly describing the behaviour of the system. Forexample, large companies such as supermarkets, high street stores and banks collect astream of data relating to the behaviour of their customers. Such data must be analysedto provide flexible models of customer behaviour that can be used to aid a wide varietyof decision-making processes. Hence, if a higher level modelling approach is to be trulyeffective it must provide a natural knowledge representation framework for inductive learn-ing. As such it is important that it allows for the modelling of uncertainty, imprecision andvagueness in a semantically clear manner. Indeed, we should emphasise the necessity of aclear underlying semantics for any higher-level modelling paradigm since one of the fun-damental reasons for a high level approach is to provide transparent models that can beunderstood and used by practitioners in the relevant fields. This cannot be achieved if thevalidity of the underlying concepts and inference processes are either obscured or in doubt.In the sequel we will outline a new methodology for linguistic modelling and show how itcan be applied in an inductive learning context. The approach will centre on the modellingof linguistic constraints on variables as proposed by Zadeh [37] although the underlyingsemantics will be quite different.The phrase computing with words was introduced by Zadeh [42] to capture the idea ofcomputation based not on numerical values, but on natural language terms and expressions.As a general idea this is clearly of relevance to the type of modelling described above,however, we shall propose a quite different interpretation to that given in [38–40]. Thegeneral methodology for computing with words proposed by Zadeh is that of fuzzy settheory or fuzzy logic and in particular is based on the idea of linguistic variables (see [38–40]). A linguistic variable is defined as a variable that takes natural language terms such aslarge, small, tall, medium etc. as values and where the meaning of these words is given byfuzzy sets on some underlying domain of discourse. Hence, a particular expression of theform Bill is tall can be taken as expressing the fact that the linguistic variable describingBill’s height has the value tall, and such a statement has a partial truth-value correspondingto the membership degree of Bill’s actual height in the fuzzy set representing the meaningof tall. The truth-value of compound expressions such as Bill is tall or medium is then\fJ. Lawry / Artificial Intelligence 155 (2004) 1–393evaluated according to a fuzzy set calculus based on some choice of t-norm or t-conorm(see [18] for an exposition).In our view the principal problem with the above approach is that the semanticsunderlying standard fuzzy logic or indeed the notion of membership function itself is ratherobscure. The difficulty is revealed by consideration of a fundamental question that shouldbe asked of all models of linguistic constraints. What information is conveyed regardingthe underlying variable? For instance, if someone asserts that Bill is tall exactly whatinformation about Bill’s height is conveyed by that assertion? In the case of fuzzy settheory, according to Zadeh [41], the latter provides a flexible constraint on the variablerepresenting Bill’s height. More specifically, it tells us that the possibility distribution onBill’s height corresponds to the membership function of the fuzzy set tall. However, thisassociation with possibility distributions does not, in itself, support the assumption of afully truth-functional calculus for membership degrees, as in fuzzy set theory (see [26]).Indeed, it does not really provide any insight into the behaviour of compound fuzzy sets.One possible solution to this difficulty is to accept that neither possibility distributions orfuzzy memberships are sufficiently intuitive to be treated as primitive notions and attemptto provide a lower-level model. If we are going to adopt the fuzzy logic methodology thenany such semantics should not only be intuitive but should also be consistent with a fullytruth-functional calculus based on a particular choice of t-norm and t-conorm. A numberof different models have been investigated and these are reviewed in [6,27].One of the most promising ideas is to view fuzzy memberships as being fixed pointcoverage functions of random sets, themselves representing uncertainty or variation in theunderlying crisp definition of a concept [12]. For instance, we might have a populationof different individuals each proposing their own set of heights that would qualify for thedescription tall. The associated random set would be a function from the set of individ-uals into the set of subsets of heights and the membership of a particular height, h, inthe fuzzy set tall would correspond to the probability of encountering an individual whoincluded h in their crisp set definition. This is the essence of the voting model for fuzzysets proposed originally by Black [3] and later by Gaines [10]. Clearly this interpretationis implicitly probabilistic in its nature and hence, it is not perhaps surprising that it doesnot fit well within the inference framework of fuzzy logic. One problem is that there isnot a one-to-one correspondence between fuzzy sets and random sets. The same fuzzy setcould be generated by a potentially infinite family of random sets (see Goodman [12]). Inpossibility theory this problem is overcome by making the assumption that the random setis consonant (i.e., the set of sets with non-zero mass constitutes a nested hierarchy). Lawry[20] justifies this by introducing the idea of an optimism parameter according to which themore optimistic a voter the more likely they are to include h in the extension of the concepttall. It is difficult to consolidate such an assumption with a fully truth-functional calculussince, in that case, a voter with a high optimism parameter would be required to be opti-mistic regarding both the concept and its negation. Lawry [20] suggests a weaker notionof negation to overcome this difficulty but nonetheless t",
            {
                "entities": [
                    [
                        2361,
                        2389,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 156 (2004) 139–176www.elsevier.com/locate/artintTheory revision with queries:Horn, read-once, and parity formulasJudy Goldsmith a,1, Robert H. Sloan b,∗,2, Balázs Szörényi c,György Turán c,d,3a Computer Science Department, University of Kentucky, Lexington, KY 40506-0046, USAb Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60607-7053, USAc Hungarian Academy of Sciences and University of Szeged, Research Group on Artificial Intelligence,Aradi vértanúk tere 1, H-6720 Szeged, Hungaryd Department of Mathematics, Statistics, and Computer Science, University of Illinois at Chicago,Chicago, IL 60607-7045, USAReceived 6 March 2003; received in revised form 11 November 2003; accepted 15 January 2004AbstractA theory, in this context, is a Boolean formula; it is used to classify instances, or truth assignments.Theories can model real-world phenomena, and can do so more or less correctly. The theoryrevision, or concept revision, problem is to correct a given, roughly correct concept. This problemis considered here in the model of learning with equivalence and membership queries. A revisionalgorithm is considered efficient if the number of queries it makes is polynomial in the revisiondistance between the initial theory and the target theory, and polylogarithmic in the number ofvariables and the size of the initial theory. The revision distance is the minimal number of syntacticrevision operations, such as the deletion or addition of literals, needed to obtain the target theory fromthe initial theory. Efficient revision algorithms are given for Horn formulas and read-once formulas,where revision operators are restricted to deletions of variables or clauses, and for parity formulas,where revision operators include both deletions and additions of variables. We also show that thequery complexity of the read-once revision algorithm is near-optimal. 2004 Published by Elsevier B.V.Keywords: Theory revision; Knowledge revision; Horn formulas; Query learning; Computational learningtheory; Boolean function learning* Corresponding author.E-mail addresses: goldsmit@cs.uky.edu (J. Goldsmith), sloan@uic.edu (R.H. Sloan), szorenyi@rgai.hu(B. Szörényi), gyt@uic.edu (G. Turán).1 Partially supported by NSF grant CCR-0100040.2 Partially supported by NSF grants CCR-9800070 and CCR-0100336.3 Partially supported by NSF grants CCR-0100336 and CCR-9800070.0004-3702/$ – see front matter  2004 Published by Elsevier B.V.doi:10.1016/j.artint.2004.01.002\f140J. Goldsmith et al. / Artificial Intelligence 156 (2004) 139–1761. IntroductionSometimes our model isn’t quite right. As computer scientists, we build models of real-world phenomena, based on limited data or on the opinions of sometimes-fallible experts.We verify or begin to use the models and discover that they are not quite correct. Ratherthan beginning the model-building phase again, we would prefer to quickly and simplyrevise the current model, and continue our project. If the initial model is nearly correct,this should be more efficient.The revision of an initial theory, represented by a formula, consists of applying syntacticrevision operators, such as the deletion or the addition of a literal. For instance, the CUPtheory,1 presented in Fig. 1, might be revised to become more accurate by deleting theliteral white. The revision distance of the target theory from the initial theory is definedto be the minimal number of revision operations from a specified fixed set needed toproduce a theory equivalent to the target, starting from the initial theory. As in our previouswork [30] we consider two sets of revision operators: deletions-only operators, which allowthe deletion of literals and of clauses and/or terms, and general operators, which also allowthe addition of literals. Others have also implicitly or explicitly considered both of thosemodels [32,40].If the target theory is close to the initial theory, then an efficient revision algorithmshould find it quickly. Thus, revision distance is one of the relevant parameters for definingthe efficiency of theory revision.One way of formalizing the problem of theory revision as a concept learning problemis: learn the class of concepts that are within a given revision distance of the initial theory.A novel feature of this definition is that it associates a concept class with each concept, andthus, in a sense, assigns a learning complexity to every individual concept (more precisely,to every concept representation, and every revision distance bound). This may perhapshelp formalize the intuitive, yet elusive, notion that in general, there are hard and easytarget concepts in learning theory. For instance, intuitively, there are hard and easy DNFs,but it does not make sense to talk about the difficulty of learning a particular DNF. On theother hand, it does make sense to talk about the difficulty of revising a particular DNF. Sotheory revision gives a way to quantify the learning complexity of each DNF.This article and its companion article [30] consider revision in query-based learningmodels, in particular, in the standard model of learning with membership and equivalencequeries, denoted by MQ and EQ [5]. This is a very well-studied model (e.g., [2,4–8,11,13–15]), nearly as much so as PAC-learning. In an equivalence query, the learning algorithmproposes a hypothesis, that is, a theory h, and the answer depends on whether h = c,CUP ≡ has-concavity ∧ white ∧ upward-pointing-concavity ∧ has-bottom∧ flat-bottom ∧ lightweight ∧ (has-handle ∨ (width-small ∧ styrofoam))Fig. 1. Cup theory/concept, inspired by Winston et al. [57]. Note that there may be many additional variables thatare not used in the current cup theory.1 Cups are for theory revision what elephants are for computational learning theory and perhaps for AI ingeneral, and what penguins are for nonmonotonic reasoning: the canonical toy example.\fJ. Goldsmith et al. / Artificial Intelligence 156 (2004) 139–176141where c is the target theory. If so, the answer is “correct”, and the learning algorithmhas succeeded in its goal of exact identification of the target theory. Otherwise, the answeris a counterexample: any instance x such that c(x) (cid:5)= h(x). In a membership query, thelearning algorithm gives an instance x, and the answer is either 1 or 0, depending on c(x).The query complexity of a learning algorithm is the number of queries it asks. Note thatthe query complexity is a lower bound on the running time. For running time, we do notcount the time required to answer the queries. From a formal, theoretical point of view,we assume that there are two oracles, one each to answer membership and equivalencequeries. In practice, membership queries would need to be answered by a domain expert,and equivalence queries could either be answered by a domain expert, or by using thehypothesis and waiting for evidence of an error in classification.It is typical in practical applications that one starts with an initial theory and a setof (counter)examples, for which the initial theory gives an incorrect classification. Thegoal then is to find a small modification of the initial theory that is consistent with theexamples. (In fact, many theory revision methods, including the algorithms presented here,would work even if a large number of changes were needed, but in that case it might bemore efficient to learn from scratch rather than revising.) In this setup, one can simulatean equivalence query by running through the examples. If we find a counterexample tothe current hypothesis, then we continue the simulation of the algorithm. Otherwise, weterminate the learning process with the current hypothesis serving as our final revisedtheory. In this way, an efficient equivalence and membership query algorithm can be turnedinto an efficient practical revision algorithm.Besides this motivation, there are other reasons, specific to theory revision, that justifythe use of equivalence and membership queries. In practical applications, it is often thecase that the goal of theory revision is to fix an initial theory that is provided by anexpert. It is reasonable to hope that the expert is able to answer further queries aboutthe classification of new instances. For instance, natural language applications make thispossibility apparent, as here everybody can serve as an expert, answering queries aboutthe correctness of sentences. This means that in all these cases learning algorithms may beassumed to use membership queries.Another important reason to study the query model is that it turns out to be the “right”model for many important learning problems. That is, for several basic problems, suchas learning finite automata and Horn formulas, there are nontrivial efficient learningalgorithms in this model, while in weaker models one can prove superpolynomial lowerbounds.In this paper we study two very important tractable classes of formulas: conjunctions ofHorn clauses and read-once formulas.Horn sentences are the tractable heart of several branches of computer science. Thesatisfiability of Horn sentences can be decided in polynomial—indeed linear—time(e.g., [23]). There is a combinatorial characterization of functions that can be expressedby Horn sentences [21,34,44,54].Horn sentences have many applications. For instance, Horn sentences occur as specialcases in logic, logic programming, and databases. Real-world reasoning and causality canbe described by Horn theories: If the world is like so, then these are the consequences,\f142J. Goldsmith et al. / Artificial Intelligence 156 (2004) 139–176separately and jointly. Horn sentences model safe queries in relational database theory[43].Given the plethora of Horn sentences out there, it is imperative that we be able to mendthose that are broken. The work presented in this paper is a first step in that direction.Similarly to Horn formulas, read-once formulas form a nontrivial class that is tractablefrom several different aspects,",
            {
                "entities": [
                    [
                        2487,
                        2515,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 215 (2014) 79–119Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn influence, stable behavior, and the most influential individuals in networks: A game-theoretic approachMohammad T. Irfan a,1, Luis E. Ortiz b,∗a Department of Computer Science, Bowdoin College, Brunswick, ME 04011, United Statesb Department of Computer Science, Stony Brook University, Stony Brook, NY 11794, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 13 September 2012Received in revised form 31 May 2014Accepted 17 June 2014Available online 25 June 2014Keywords:Computational game theorySocial network analysisInfluence in social networksNash equilibriumComputational complexityWe introduce a new approach to the study of influence in strategic settings where the action of an individual depends on that of others in a network-structured way. We propose network influence games as a game-theoretic model of the behavior of a large but finite networked population. In particular, we study an instance we call linear-influence gamesthat allows both positive and negative influence factors, permitting reversals in behavioral choices. We embrace pure-strategy Nash equilibrium, an important solution concept in non-cooperative game theory, to formally define the stable outcomes of a network influence game and to predict potential outcomes without explicitly considering intricate dynamics. We address an important problem in network influence, the identification of the most influential individuals, and approach it algorithmically using pure-strategy Nash-equilibria computation. Computationally, we provide (a) complexity characterizations of various problems on linear-influence games; (b) efficient algorithms for several special cases and heuristics for hard cases; and (c) approximation algorithms, with provable guarantees, for the problem of identifying the most influential individuals. Experimentally, we evaluate our approach using both synthetic network influence games and real-world settings of general interest, each corresponding to a separate branch of the U.S. Government. Mathematically,we connect linear-influence games to important models in game theory: potential and polymatrix games.© 2014 Published by Elsevier B.V.1. IntroductionThe influence of an entity on its peers is a commonly noted phenomenon in both online and real-life social networks. In fact, there is growing scientific evidence that suggests that influence can induce behavioral changes among the entities in a network. For example, recent work in medical social sciences posits the intriguing hypothesis that much of our behavior such as smoking [16], obesity [15], and even happiness [24] is contagious within a social network.Regardless of the specific problem addressed, the underlying system studied by Christakis and Fowler exhibits several core features. First, it is often very large and complex, with the entities exhibiting different behaviors and interactions. Second, the network structure of complex interactions is central to the emergence of collective (global) behavior from individual (local) behavior. For example, in their work on obesity, individuals locally interact with their friends and relatives within their * Corresponding author. Tel.: +1 631 632 1805; fax: +1 631 632 8334.E-mail addresses: mirfan@bowdoin.edu (M.T. Irfan), leortiz@cs.stonybrook.edu (L.E. Ortiz).1 Parts of this work were done while the author was a PhD student at Stony Brook University.http://dx.doi.org/10.1016/j.artint.2014.06.0040004-3702/© 2014 Published by Elsevier B.V.\f80M.T. Irfan, L.E. Ortiz / Artificial Intelligence 215 (2014) 79–119social network. These local interactions appear to give rise to a global phenomenon, namely, the clustering of medically obese individuals [15]. Third, the directions and strengths of local influences are highlighted as very relevant to the global behavior of the system as a whole. Fourth, given that one’s behavioral choice depends on others, the individuals potentially act in a strategic way.The prevalence of systems and problems like the ones just described, combined with the obvious issue of often-limited control over individuals, raises immediate, broad, difficult, and longstanding policy questions: e.g., Can we achieve a desired goal, such as reducing the level of smoking or controlling obesity via targeted, minimal interventions in a system? How do we optimally allocate our often limited resources to achieve the largest impact in such systems?Clearly, these issues are not exclusive to obesity, smoking or happiness; similar issues arise in a large variety of settings: drug use, vaccination, crime networks, security, marketing, markets, the economy, public policy-making and regulations, and even congressional voting!2 The work reported in this paper is in large part motivated by such questions/settings and their broader implication.We begin by providing a brief and informal description of our approach to influence in networks. In the next section, we place our approach within the context of the existing literature.1.1. Overview of our model of influenceConsider a social network where each individual has a binary choice of action or behavior, denoted by −1 and 1. Let us represent this network as a directed graph, where each node represents an individual. Each node of this graph has a threshold level, which can be positive, negative, or zero; and the threshold levels of all the nodes are not required to be the same. Each arc of this graph is weighted by an influence factor, which signifies the level of direct influence the tail node of that arc has on the head node. Again, the influence factors can be positive, negative, or zero and are not required to be the same (i.e., symmetric) between two nodes.Given such a network, our model specifies the best response of a node (i.e., what action it should choose) with respect to the actions chosen by the other nodes. The best response of a node is to adopt the action 1 if the total influence on it exceeds its threshold and −1 if the opposite happens. In case of a tie, the node is indifferent between choosing 1 and −1; i.e., either would be its best response. Here, we calculate the total influence on a node as follows. First, sum up the incoming influence factors on the node from the ones who have adopted the action 1. Second, sum up those influence factors that are coming in from the ones who have adopted −1. Finally, subtract the second sum from the first to get the total influence on that node.Clearly, in a network with n nodes, there are 2n possible joint actions, resulting from the action choice of each individual node. Among all these joint actions, we call the ones where every node has chosen its best response to everyone else a pure-strategy Nash equilibria (PSNE). We use PSNE to mathematically model the stable outcomes that such a networked system could support.1.2. Overview of the most-influential-nodes problemWe formulate the most-influential-nodes problem with respect to a goal of interest. The goal of interest indirectly de-termines what we call the desired stable outcome(s). Unlike the mainstream literature on the most-influential-nodes prob-lem [49], maximizing the spread of a particular behavior is not our objective. Rather, the desired stable outcome(s) resulting from the goal of interest is what determines our computational objective. In addition, our solution concept abstracts away the dynamics and does not rely on the “diffusion” process by which such a “spread of behavior” happens.Roughly speaking, in our approach, we consider a set of individuals S in a network to be a most influential set, with respect to a particular goal of interest, if S is the most preferred subset among all those that satisfy the following condition: were the individuals in S to choose the behavior xS prescribed to them by a desired stable outcome x ≡ (xS , x−S ) which achieves the goal of interest, then the only stable outcome of the system that remains consistent with their choices xS is xitself.Said more intuitively, once the nodes in the most influential set S follow the behavior xS prescribed to them by a desired stable outcome x achieving the goal of interest, they become collectively “so influential” that their behavior “forces” every other individual to a unique choice of behavior! Our proposed concept of the most influential individuals is illustrated in Fig. 1 with a very simple example.Now, there could be many different sets S that satisfy the above condition. For example, S could consist of all the individuals, which might not be what we want. To account for this, we also specify a preference function over all subsets of individuals. While this preference function could in principle be arbitrary, a natural example would be the one that prefers a set S of minimum cardinality.2 The headline-grabbing U.S. “debt-ceiling crisis” in 2011, especially the last-minute deal to increase the debt ceiling, is evidence of influence among senators in a strategic setting. We can also view the bipartisan “gang-of-six” senators, specifically chosen to work out a solution, as an intervention as such a group would not naturally arise otherwise.\fM.T. Irfan, L.E. Ortiz / Artificial Intelligence 215 (2014) 79–11981Fig. 1. Illustration of our approach to influence in networks. Each node has a binary choice of behavior, {−1, +1}, and, in this instance, wants to behave like the majority of its neighbors (and is indifferent if there is a tie). We adopt pure-strategy Nash equilibrium (formally defined later), abbreviated as PSNE, as the notion of stable outcome. Here, (a) shows the network, and (b) shows all the PSNE, one in each row, where black denotes behavior 1, gray −1. The goal of interest or the desired outcome is to have everyone choose 1. Selecting the set of nodes {1, 2, 3} and assigning these nodes the behavior prescribed by the desired outcome (i.",
            {
                "entities": [
                    [
                        3562,
                        3590,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 163 (2005) 233–263www.elsevier.com/locate/artintBayesian network modelling throughqualitative patternsPeter J.F. LucasInstitute for Computing and Information Sciences, Radboud University Nijmegen, Toernooiveld 1,6525 ED Nijmegen, The NetherlandsReceived 10 July 2004; accepted 31 October 2004Available online 15 December 2004AbstractIn designing a Bayesian network for an actual problem, developers need to bridge the gap betweenthe mathematical abstractions offered by the Bayesian-network formalism and the features of theproblem to be modelled. Qualitative probabilistic networks (QPNs) have been put forward as quali-tative analogues to Bayesian networks, and allow modelling interactions in terms of qualitative signs.They thus have the advantage that developers can abstract from the numerical detail, and thereforethe gap may not be as wide as for their quantitative counterparts. A notion that has been suggested inthe literature to facilitate Bayesian-network development is causal independence. It allows exploitingcompact representations of probabilistic interactions among variables in a network. In the paper, wedeploy both causal independence and QPNs in developing and analysing a collection of qualitative,causal interaction patterns, called QC patterns. These are endowed with a fixed qualitative semantics,and are intended to offer developers a high-level starting point when developing Bayesian networks. 2004 Elsevier B.V. All rights reserved.Keywords: Bayesian networks; Knowledge representation; Qualitative reasoning1. IntroductionReasoning with uncertainty is a significant area of research in Artificial Intelligence atleast since the early 1970s. Many different methods for representing and reasoning withE-mail address: peterl@cs.kun.nl (P.J.F. Lucas).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.10.011\f234P.J.F. Lucas / Artificial Intelligence 163 (2005) 233–263uncertain knowledge have been developed during the last three decades, including thecertainty-factor calculus [2,22], Dempster-Shafer theory [21], possibilistic logic [8], fuzzylogic [29], and Bayesian networks, also called belief networks and causal probabilistic net-works [3,18,19]. During the last decade a gradual shift towards the use of probability theoryas the foundation of almost all of the work in this area could be observed, mainly due tothe impact, both theoretically and practically, of the introduction of Bayesian networks andrelated graphical probabilistic models into the field.Bayesian networks offer a powerful framework for the modelling of uncertain interac-tions among variables in a given domain. Such interactions are represented in two differentmanners: firstly, in a qualitative manner, by means of a directed acyclic graph, and sec-ondly, in a quantitative manner, by specifying a conditional probability distribution forevery variable represented in the network. These conditional probability distributions allowfor expressing various logical, functional and probabilistic relationships among variables.Much of the appeal of the Bayesian network formalism derives from this feature (cf. [3]for a modern, technical overview).It is well known that ensuring that the graph topology of a Bayesian network is sparseeases the assessment of its underlying joint probability distribution, as the required prob-ability tables will then be relatively small. Unfortunately, designing a network with atopology that is sparse is neither easy nor always possible. Researchers have thereforeidentified special types of independence relationships in order to facilitate the process ofprobability assessment. In particular the theory of causal independence fulfils this pur-pose [15]. The theory allows for the specification of the interactions among variables interms of cause-effect relationships, adopting particular statistical independence assump-tions. Causal independence is frequently used in the construction of practical networks forsituations where the underlying probability distributions are complex. The theory has alsobeen exploited to increase the efficiency of probabilistic inference in Bayesian networks[30,31]. A limitation of the theory of causal independence is that it is usually unclear withwhat sort of qualitative behaviour a network will be endowed when choosing for a particu-lar interaction type. As a consequence, only two types of interaction are in frequent use: thenoisy-OR and the noisy-MAX; in both cases, interactions among variables are modelledas being disjunctive [4,16,19].Qualitative probabilistic networks offer a qualitative analogue to the formalism ofBayesian networks. They allow describing the dynamics of the interaction among variablesin a purely qualitative fashion by means of the specification and propagation of qualitativesigns [6,7,20,28]. Hence, qualitative probabilistic networks abstract from the numericaldetail, yet retain the qualitative semantics underlying Bayesian networks. The theory ofqualitative probabilistic networks, therefore, seems to offer potentially useful tools for thequalitative analysis of Bayesian networks.The aim of the present work was to develop a theory of qualitative, causal interactionpatterns, QC patterns for short, in the context of Bayesian networks. Such a theory couldassist developers of systems based on Bayesian networks in designing such networks, ex-ploiting the qualitative information that is available in the domain concerned as much aspossible. In the paper, various interaction types are defined using Boolean algebra; qual-itative probabilistic networks are then used to provide a qualitative semantic foundationfor these interactions. The Bayesian-network developer is supposed to utilise the theory\fP.J.F. Lucas / Artificial Intelligence 163 (2005) 233–263235by selecting appropriate interaction patterns based on domain properties, which thus canguide Bayesian-network development.The remainder of this paper is organised as follows. In the following section, the basicproperties of Bayesian networks are introduced, as are Boolean functions, and the no-tions of causal independence and qualitative probabilistic networks. We start the analysisby considering various causal-independence models, unravelling the qualitative behaviourof these causal models using qualitative probabilistic networks in Section 3. Section 4summarises the various patterns that have been obtained, and discusses these results inthe context of all possible patterns. Finally, in Section 5, it is summarised what has beenachieved by this research.2. PreliminariesTo start, the basic theory of Bayesian networks, causal independence and qualitativeprobabilistic networks are reviewed.2.1. Bayesian networksA Bayesian network is a concise representation of a joint probability distribution on aset of statistical variables [19]. It consists of a qualitative part and an associated quan-titative part. The qualitative part is a graphical representation of the interdependencesbetween the variables in the encoded distribution. It takes the form of an acyclic directedgraph (digraph) G = (V (G), A(G)), where each node V ∈ V (G) corresponds to a sta-tistical variable that takes one of a finite set of values, and A(G) ⊆ V (G) × V (G) is aset of arcs. In this paper, we assume all variables to be binary; for abbreviation, we willoften use v to denote V = (cid:3) (true) and ¯v to denote V = ⊥ (false). Sometimes, we pre-fer to leave the specific value of a variable open (i.e., it is taken as a free variable), andthen we simply state V . In other cases, we use this notation when a variable is actuallybound. The context will make clear which interpretation is intended. Furthermore, for ab-breviation, we use the notation V1, . . . , Vn\\Vi, . . . , Vj which stands for the set of variables{V1, V2, . . . , Vi−1, Vi+1, . . . , Vj −1, Vj +1, . . . , Vn}. Furthermore, an expression such as(cid:1)g(I1, . . . , In)ψ(I1,...,In)=estands for summing over g(I1, . . . , In) for all possible values of the variables Ik for whichthe constraint ψ(I1, . . . , In) = e holds. However, if we refer to variables separate fromsuch constraints, such as in(cid:1)g(I1, . . . , In)I1,I2ψ(I1,...,In)=ethen we only sum over the separately mentioned variables, here the variables I1, I2, andthe equality only acts as a constraint.The arcs A(G) in the digraph G model possible dependences between the representedvariables. Informally speaking, we take an arc V → V (cid:6) between the nodes V and V (cid:6) to\f236P.J.F. Lucas / Artificial Intelligence 163 (2005) 233–263represent an influential relationship between the associated variables V and V (cid:6). If this arcis given a causal reading, then the arc’s direction marks V (cid:6) as the effect of the cause V .Absence of an arc between two nodes means that the corresponding variables do not in-fluence each other directly and, hence, are (conditionally) independent. In the following,causes will often be denoted by Ci and their associated effect variable by E.Associated with the qualitative part of a Bayesian network are numerical quantities fromthe encoded probability distribution. With each variable V in the digraph is associated aset of conditional probabilities Pr(V | π(V )), describing the joint influence of values forthe parents π(V ) of V on the probabilities of the variable V ’s values. These sets of prob-abilities constitute the quantitative part of the network. A Bayesian network represents ajoint probability distribution on its variables and thus provides for computing any proba-bility of interest. Various algorithms for probabilistic inference with a Bayesian networkare available [19,23,30].Bayesian networks are successfully applied in a growing number of fields; biomed-ical applications in particular have attracted a great deal of research activity (cf. [1,5,11,12,24,25]). This may be due to the fact that biological mechanisms can often be de-scribed quite naturally",
            {
                "entities": [
                    [
                        1880,
                        1908,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 332–360www.elsevier.com/locate/artintInductive situation calculusMarc Denecker a,∗, Eugenia Ternovska ba Department of Computer Science, KU Leuven, Belgiumb School of Computing Science, Simon Fraser University, CanadaReceived 15 November 2006; received in revised form 7 February 2007; accepted 8 February 2007Available online 20 February 2007AbstractTemporal reasoning has always been a major test case for knowledge representation formalisms. In this paper, we develop aninductive variant of the situation calculus in ID-logic, classical logic extended with inductive definitions. This logic has beenproposed recently and is an extension of classical logic. It allows for a uniform representation of various forms of definitions,including monotone inductive definitions and non-monotone forms of inductive definitions such as iterated induction and inductionover well-founded posets. We show that the role of such complex forms of definitions is not limited to mathematics but extends tocommonsense knowledge representation. In the ID-logic axiomatization of the situation calculus, fluents and causality predicatesare defined by simultaneous induction on the well-founded poset of situations. The inductive approach allows us to solve theramification problem for the situation calculus in a uniform and modular way. Our solution is among the most general solutionsfor the ramification problem in the situation calculus. Using previously developed modularity techniques, we show that the basicvariant of the inductive situation calculus without ramification rules is equivalent to Reiter-style situation calculus.© 2007 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Inductive definitions; Situation calculus1. IntroductionID-logic1 [5,8,10] is an extension of classical logic with inductive definitions (ID). In mathematical texts, inductivedefinitions are usually represented as collections of rules, which represent the base case and inductive cases. Inductiverules may be monotone or non-monotone. An example of the latter is the following rule in the definition of the truthrelation |=:I |= ¬ψ ifI (cid:3)|= ψ,which states that I satisfies ¬ψ if I does not satisfy ψ. It is well known that in general, inductive definitions cannotbe represented in first-order logic (FO). ID-logic extends classical logic with a construction that allows for a uniform* Corresponding author.E-mail address: Marc.Denecker@cs.kuleuven.be (M. Denecker).1 The term ID-logic was introduced by the first author in [5] to denote a logic of sets of classical first-order logic sentences and definitions.This logic was extended to its current definition in [8] and in [7], where it was called NMID-logic in order to emphasize that the logic deals withnon-monotone inductive definitions (NMIDs).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.002\fM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360333representation of different sorts of inductive definitions; moreover, this representation preserves the rule-based natureof definitions in mathematical texts. The semantics of this new construct is based on the well-founded semantics oflogic programming [41]. This semantics correctly formalizes the semantics of different types of definitions that canbe found in mathematics, e.g. recursion-free definitions, monotone inductive definitions, and non-monotone inductivedefinitions such as inductive definitions over well-founded orders and iterated inductive definitions [4,6].ID-logic occupies an interesting place in the spectrum of logics used in mathematics, computer science and knowl-edge representation. As an extension of classical logic with a fixpoint semantics for inductive definitions, it can beviewed as a new element in the family of fixpoint logics. Monotone fixpoint logics have their origin in the logicalstudy of monotone inductive definitions [1,28]. The contribution of ID-logic is that it formalizes two non-monotoneinductive principles (i.e., inductive definition over a well-founded order and iterated inductive definition), which differfrom the non-monotone principle based on the inflationary fixpoint studied in the inflationary fixpoint logic IFP [16].ID-logic is similar to description logics [2] in its separation of definitional and assertional knowledge, but it allowsdefinitions for n-nary predicates and non-monotone inductive definitions. In addition, ID-logic is formally an exten-sion of Logic Programming and its variants such as Abductive Logic Programming and Datalog. In this way, ID-logicinduces an alternative informal semantics for logic programming, solidly based on the mathematical principle of in-ductive definitions. As such, the study of semantical and computational aspects of ID-logic can lead to synergy andintegration of all these different areas.On the computational level, ID-logic has recently been proposed as the underlying language for a constraint pro-gramming framework [27]. This framework is based on ideas from descriptive complexity theory and is similar insome respects to Answer Set Programming [20,29]. A problem instance is a finite structure, and a problem specifica-tion is an ID-logic formula defining the relationship between an instance and its solutions. Solving a problem amountsto expanding the structure with new relations to satisfy the formula. Depending on the expressiveness allowed, theframework captures various complexity classes, including P and NP. Several ID-logic solvers have been developed[21,30].The focus of this paper is on knowledge representation and modeling in ID-logic. Although diverse forms ofinductive definitions occur frequently in mathematics, there is little awareness in the logic and KR community ofnon-monotone forms of inductive definitions and of the potential role of inductive definitions for knowledge repre-sentation. Thus, a central aim of this paper is to clarify and illustrate these types of definitions. We provide examplesof monotone definitions, definitions by induction over well-founded order and iterated inductive definitions and relatethese to other knowledge representation principles such as completion and circumscription. Moreover, we show thatthe role of these complex forms of definitions is not limited to mathematics but extends to commonsense knowledgerepresentation.A second major purpose of the paper is to illustrate the use of a “tool set” from [8,42] for analyzing definitions,consisting of different modularity theorems, totality theorems and translation theorems. Our experiment demonstratesthe effectivity of the tool set for breaking up large complex definitions into conjunctions of smaller and simplerones, for translating definitions into classical logic, and for proving consistency and correctness of ID-logic theo-ries.The domain of application selected for our study is temporal reasoning. Since the early days of AI, temporal rea-soning, in particular the situation calculus, has been a major test case for knowledge representation languages. In [25],McCarthy and Hayes exposed the famous frame problem, showing the difficulty of axiomatizing actions and causa-tion in classical logic. This problem has (partly) motivated the development of the area of non-monotonic reasoning,leading to non-monotone logics such as default logic [32] and non-monotone reasoning techniques in classical logicsuch as circumscription [23] and completion [3]. Many different temporal reasoning formalisms were developed. Cur-rently, the most widely adopted formalization of situation calculus is the one in classical logic developed by Reiter andhis collaborators in the nineties [18,31,34]. Other well-known solutions are Event calculus [35], Fluent calculus [39],non-monotonic logic approaches such as the (many extensions of) the language A [14] and non-monotonic causaltheories [15,22].We present here a formalization of situation calculus in ID-logic, which we call the inductive situation calculus.Temporal reasoning is a natural application for using inductive definitions on the set of situations. In Reiter’s situ-ation calculus for example, the description of the initial state may be viewed as the base case, and successor stateaxioms may be seen the inductive case. By axiomatizing situation calculus in ID-logic, we explicitate the definitionalstructure underlying situation calculus. The main component of the inductive situation calculus will be a definition\f334M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360of fluent and causality predicates by simultaneous, non-monotone, iterated induction in the well-founded set of situ-ations. This definition and its components are natural illustrations of each of the above mentioned types of inductivedefinitions.A first benefit in explicitating the definitional structure of situation calculus, is that we considerably gain on therepresentational level. In particular, the inductive situation calculus is more expressive and modular than Reiter’sclassical logic version. On the level of modularity, in the inductive situation calculus it is possible to represent ef-fects of specific actions on specific fluents in specific circumstances by individual effect rules. It is well-known thatincreased modularity may improve elaboration tolerance [24]. On the level of expressivity, the inductive situationcalculus can handle recursive ramifications, where an effect to one fluent may cause an effect to another fluent andvice versa. The challenge in handling such recursive ramifications is to avoid erroneous models in which the re-lated fluents “cause” each other and become true simultaneously without external cause. By interpreting effect rulesas definitional rules, such spontaneous generation of effects is avoided. As a consequence, the inductive situationcalculus currently provides the most general solution of the ramification problem. It also provides the most genera",
            {
                "entities": [
                    [
                        2908,
                        2936,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 51–71Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGrounded fixpoints and their applications in knowledge representation ✩Bart Bogaerts a,∗a Department of Computer Science, KU Leuven, 3001 Heverlee, Belgiumb Department of Computer Science, Campus De Nayer, KU Leuven, 2860 Sint-Katelijne-Waver, Belgium, Joost Vennekens a,b, Marc Denecker aa r t i c l e i n f oa b s t r a c tArticle history:Received 21 December 2014Received in revised form 19 March 2015Accepted 21 March 2015Available online 25 March 2015Keywords:Approximation fixpoint theoryLattice operatorStable semanticsWell-founded semanticsGroundednessLogic programmingAutoepistemic logicAbstract argumentationAbstract dialectical frameworks1. IntroductionIn various domains of logic, researchers have made use of a similar intuition: that facts (or models) can be derived from the ground up. They typically phrase this intuition by saying, e.g., that the facts should be grounded, or that they should not be unfounded, or that they should be supported by cycle-free arguments, et cetera. In this paper, we formalise this intuition in the context of algebraical fixpoint theory. We define when a lattice element x ∈ L is grounded for lattice operator O : L → L. On the algebraical level, we investigate the relationship between grounded fixpoints and the various classes of fixpoints of approximation fixpoint theory, including supported, minimal, Kripke–Kleene, stable and well-founded fixpoints. On the logical level, we investigate groundedness in the context of logic programming, autoepistemic logic, default logic and argumentation frameworks. We explain what grounded points and fixpoints mean in these logics and show that this concept indeed formalises intuitions that existed in these fields. We investigate which existing semantics are grounded. We study the novel semantics for these logics that is induced by grounded fixpoints, which has some very appealing properties, not in the least its mathematical simplicity and generality. Our results unveil a remarkable uniformity in intuitions and mathematics in these fields.© 2015 Elsevier B.V. All rights reserved.Motivated by structural analogies in the semantics of several non-monotonic logics, Denecker, Marek and Truszczy ´nski (from now on abbreviated as DMT) [10] developed an algebraic fixpoint theory that defines different types of fixpoints for a so-called approximating bilattice operator, called supported, Kripke–Kleene, stable and well-founded fixpoints. In the context of logic programming, they found that Fitting’s (three- or four-valued) immediate consequence operator is an approximating operator of the two-valued immediate consequence operator and that its four different types of fixpoints correspond exactly to the four major, equally named semantics of logic programs. They also identified approximating operators for default logic (DL) and autoepistemic logic (AEL) and showed that the fixpoint theory induces all main and some new semantics in these fields [11]. Moreover, by showing that Konolige’s mapping from DL to AEL [26] preserves the approximating operator, they A short version of this paper is accepted for publication in the proceedings of the AAAI’15 conference [5]. This paper extends the previous work with ✩proofs of all propositions and applications of the theory to abstract dialectical frameworks, autoepistemic logic and default logic.* Corresponding author.E-mail addresses: bart.bogaerts@cs.kuleuven.be (B. Bogaerts), joost.vennekens@cs.kuleuven.be (J. Vennekens), marc.denecker@cs.kuleuven.be(M. Denecker).http://dx.doi.org/10.1016/j.artint.2015.03.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\f52B. Bogaerts et al. / Artificial Intelligence 224 (2015) 51–71resolved an old research question regarding the nature of these two logics: AEL and DL were essentially unified in the sense that for each semantics covered by AFT, a DL theory is equivalent with its Konolige mapping in AEL. However, the original DL and AEL semantics occupy different positions in this family and do not correspond. As such AEL and DL under their original semantics, are “just” two different dialects of autoepistemic reasoning [11,13].The study of these approximating operators called approximation fixpoint theory (AFT) was later used to define semantics of extensions of logic programs, such as logic programs with aggregates [35] and HEX logic programs [2]. Vennekens et al. [42] used AFT in an algebraical modularity study for logic programming, AEL and DL. Recently, Strass [38] showed that many semantics from Dung’s argumentation frameworks (AFs) and abstract dialectical frameworks (ADFs) can be obtained by direct applications of AFT. Bi et al. [4] extended AFT with approximators allowing for inconsistencies and used it to integrate description logics with logic programs. Bogaerts et al. [6] defined the causal logic FO(C) as an instantiation of AFT. This suggests that fixpoint theory, in ways that are difficult to explain due to its high level of abstraction, captures certain fundamental intuitions in a range of logics and sorts of human knowledge. It is this observation that provides the basic motivation for the present study.In this paper, we formally use fixpoint theory to investigate an intuition that is found in all aforementioned logic do-mains. There, researchers have made use of a similar intuition: that facts (or models) can be derived from the ground up. They typically phrase this intuition by saying that, e.g., the facts should be grounded, or that they should not be unfounded, or that they should be supported by cycle-free arguments, or by arguments that contain no vicious circles, et cetera. In several cases, great efforts were done to refine semantics which did allow ungrounded models or facts. For example, it is well-known that the completion semantics of logic programs allows ungrounded models, e.g., for the transitive closure program. The efforts to avoid these led to the development of perfect, stable and well-founded semantics. Also for AEL, it was known that Moore’s expansion semantics accepted ungrounded models, e.g., for the theory {KP ⇒ P } which has the ungrounded model in which P is known but this knowledge is self-supported. Examples like this motivated several attempts to refine Moore’s semantics, among others by Halpern and Moses [24] and Konolige [26].We formalise the intuition of groundedness in the context of algebraical fixpoint theory. We call a lattice element x ∈ Lgrounded for lattice operator O : L → L if for all v ∈ L such that O (x ∧ v) ≤ v, it holds that x ≤ v. We investigate this notion on the algebraical level in AFT and on the logical level in the context of logic programming, autoepistemic logic, default logic and abstract argumentation frameworks. We explain what grounded points and fixpoints mean in these logics and show that this concept indeed formalises intuitions that existed in these fields. We investigate which existing semantics are grounded, where we call a semantics grounded if all its models are grounded, and investigate a novel semantics for these logics that is based on grounded fixpoints. Our results unveil a remarkable uniformity in intuition and mathematics in these fields and lead to a new candidate semantics with some very appealing properties, not in the least the mathematical simplicity and generality to define it in the context of operator-based logics and logic constructs.We can summarise the main contributions of this paper as follows. We extend AFT with the notion of a grounded fixpoint, a fixpoint closely related to stable and well-founded fixpoints. We show that if the Kripke–Kleene fixpoint is exact, then it is grounded. If the well-founded fixpoint is exact, then it is the unique grounded and the unique stable fixpoint. Otherwise, stable fixpoints are grounded but not necessarily the other way around. A useful feature of grounded fixpoints that distinguishes them from stable and well-founded fixpoints is that they are determined by O and do not require the choice of an approximator. We then apply this theory to different logical research domains. In all domains, we explain the meaning of grounded fixpoints, relate them to attempts to formalise groundedness, study which semantics are grounded and finally, we explore the semantics induced by grounded fixpoints. More specifically, (i) in the context of logic programming, our theory yields an intuitive, purely two-valued, semantics that is easily extensible and that formalises well-known intuitions related to unfounded sets. (ii) We show that two of the main semantics of AFs can be characterised as grounded fixpoints of previously defined operators and discuss grounded fixpoints in the context of ADFs. (iii) Applied to autoepistemic logic and default logic, groundedness turns out to provide an alternative and improved formalisation of intuitions described by Konolige [26].2. Preliminaries2.1. Lattices and operatorsA partially ordered set (poset) (cid:8)L, ≤(cid:9) is a set L equipped with a partial order ≤, i.e., a reflexive, antisymmetric, transitive relation. As usual, we write x < y as abbreviation for x ≤ y ∧ x (cid:10)= y. If S is a subset of L, then x is an upper bound, respectively a lower bound of S if for every s ∈ S, it holds that s ≤ x respectively x ≤ s. An element x is a least upper bound, respectively greatest lower bound of S if it is an upper bound that is smaller than every other upper bound, respectively a lower bound that is greater than every other lower bound. If S has a least upper bound, respectively a greatest lower bound, we denote it lub(S), respectively glb(S). As is custom, we sometimes call a greatest lower bound a meet, and a least upper bound a S = lub(S) and x ∨ y = lub({x, y}). We call (cid:8)L, ≤(cid:9) a join and use the related notations complete lattice if every subset of L has a least upper bound a",
            {
                "entities": [
                    [
                        3676,
                        3704,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1223–1250Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the ERA ranking representability of pairwise bipartite rankingfunctionsWillem Waegeman∗, Bernard De BaetsKERMIT, Department of Applied Mathematics, Biometrics and Process Control, Ghent University, Coupure links 653, B-9000 Ghent, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 January 2009Received in revised form 19 June 2010Accepted 19 June 2010Available online 2 December 2010Keywords:Pairwise bipartite rankingReciprocal preference relationCycle transitivityReceiver operating characteristics (ROC)analysisGraph theoryMulti-class classificationDecision theoryMachine learning1. IntroductionIn domains like decision theory and social choice theory it is known for a long timethat stochastic transitivity properties yield necessary and sufficient conditions for theranking or utility representability of reciprocal preference relations. In this article weextend these results for reciprocal preference relations originating from the pairwisecomparison of random vectors in a machine learning context. More specifically, theexpected ranking accuracy (ERA) is such a reciprocal relation that occurs in multi-classclassification problems, when ranking or utility functions are fitted to the data in apairwise manner. We establish necessary and sufficient conditions for which these pairwisebipartite ranking functions can be simplified to a single ranking function such that thepairwise expected ranking accuracies of both models coincide. Similarly as for morecommon reciprocal preference relations, cycle transitivity plays a crucial role in this newsetting. We first consider the finite sample case, for which expected ranking accuracy canbe estimated by means of the area under the ROC curve (AUC), and subsequently, wefurther generalize these results to the underlying distributions. It turns out that the rankingrepresentability of pairwisely compared random vectors can be expressed elegantly in adistribution-independent way by means of a specific type of cycle transitivity, defined by aconjunctor that is closely related to the algebraic product.© 2010 Elsevier B.V. All rights reserved.Multi-class classification and ordinal regression can be seen as two closely related machine learning settings that sharemany properties. Multi-class classification refers to the supervised learning problem of inferring a predictive model capableof classifying data into a finite number of classes. This simply means that the model predicts for new data instances anoutput (also called label or response variable) that takes values in a finite unordered set (for example, class labels red,green, blue). Ordinal regression considers a slightly different setting. Labels here come from a finite ordered set, in whichthe order naturally follows from the semantics of the classes (for example, class labels bad, moderate, good). As a specificcase of preference learning, ordinal regression problems typically arise in situations where humans are involved in the datageneration process, like human experts or internet users expressing preferences on objects w.r.t. characteristics such asquality, beauty, appropriateness, etc.So, the different semantics of the data respectively result in the absence or presence of an order relation on the classesin multi-class classification or ordinal regression. Owing to this important interpretation of the classes, substantially differ-ent methods have been proposed in the past for the two types of learning problems. Briefly summarized, the absence orpresence of an order relation leads to two main differences in assumptions:* Corresponding author. Tel.: +329 264 6018, fax: +329 264 6220.E-mail address: Willem.Waegeman@UGent.be (W. Waegeman).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.006\f1224W. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–1250(1) Firstly, both models typically differ in the type of performance measure they optimize. If an order relation on theclasses can be assumed, then a performance measure that takes this order into account must be utilized, both foroptimization and evaluation. For example, in ordinal regression, misclassifying an object of class “bad” into class “good”must typically lead to a higher loss than misclassifying the same object into class “moderate”.(2) Secondly, the absence or presence of an order relation on the classes gives rise to a different model structure for thetwo types of problems. The model structure of multi-class classification methods typically consists of an ensemble ofbinary classifiers, such as one-versus-one [26,30] and one-versus-all [41] ensembles, while typically only one globalmodel is considered in ordinal regression. Moreover, this global model always consists of an underlying latent variablethat reflects the order on the classes. Let X denote the set of data objects, then this latent variable serves as a rankingfunction f : X → R that defines a total order on the data objects. The final decision rule is then in the end obtainedby placing a number of thresholds on the ranking function. This is for example the case in traditional statistical ordinalregression algorithms [2,38] and kernel-based methods [6,42].Several authors [27,35,44] empirically analyzed in recent work the relationship between multi-class classification and ordinalregression, in which they primarily aim to improve ordinal regression algorithms by using ideas from multi-class classifica-tion, without considering an underlying ranking function. Conversely, the motivation of this article is to improve multi-classclassification algorithms by using techniques from ordinal regression. Moreover, we will mainly focus on the theoreticalconnections between both problem settings, and to establish such a connection, we will take the ranking function that char-acterizes ordinal regression models as starting point. In this context, expected ranking accuracy (ERA) is a ranking-basedperformance measure that has recently been introduced for bipartite ranking [1] and further extended to ordinal regression[47]. Expected ranking accuracy can be easily considered too in multi-class classification, especially for one-versus-one en-sembles, where the ensemble contains a set of pairwise bipartite ranking functions (i.e. one bipartite ranking function foreach pair of classes). By using concepts from receiver operator characteristics (ROC) analysis, graph theory, decision theoryand preference modeling, we will show that transitivity properties of the reciprocal relation generated by expected rankingaccuracy result in a connection between multi-class classification and ordinal regression models.Roughly speaking, we will investigate the conditions for which a one-versus-one ensemble, containing a set of bipartiteranking functions, can be reduced to an ordinal regression model with only one underlying ranking function, such that bothmodels obtain an identical performance in terms of expected ranking accuracy. We will further refer to this property asERA ranking representability of a one-versus-one ensemble. ERA ranking representability can be interpreted as a naturalextension to the infinite sample case of AUC ranking representability, as previously introduced in [46]. It is well known thatthe area under the ROC curve (AUC) forms an unbiased estimator of the expected ranking accuracy on a finite dataset. Letus as an introductory example in a multi-class classification setting consider the following hypothetical three-class datasetthat contains six objects of each class:21i10 11 12 13 14 15 16 17 189yi C1 C1 C1 C1 C1 C1 C2 C2 C2 C2 C2 C2 C3 C3 C3 C3 C3 C3836754We have for simplicity assigned the indices in such a way that pairwise AUCs can be computed easily for a given ranking.Remark that the AUC simply computes the fraction of (lower class, higher class) couples that are correctly ranked by theclassifier. Let us suppose that the following triplet of bipartite ranking functions is statistically inferred by a one-versus-oneensemble for this small toy problem:iranking for f 12 72 9ranking for f 23 13 7 14 8 9ranking for f 13 13 1 28 14310 11 12610 11 12 15 16 17 1853 14 15 16 17 18 456So, from left to right, the numbers represent the ranking of the indices of the data objects, respectively obtained with theranking functions f 12, f 23 and f 13. For the pairwise AUCs we find:(cid:2)A12( f 12, D) = 20/36,(cid:2)A23( f 23, D) = 25/36,(cid:2)A13( f 13, D) = 15/36.(1)In other words, one finds for instance that 20 of the 36 couples are correctly ranked by the ranking function f 12: objectnumber 1 is ranked before four objects of class C2, as well as object number 2, object number 3 is ranked before threeobjects of class C2, and so on. A more formal definition of the AUC will be given in Section 2.In this example, the triplet of bipartite rankings can still be replaced in different ways by a single ranking of the wholedata set such that the same pairwise AUCs are measured, for exampleranking for global f13 1 2 3 7 8 9 10 11 14 15 16 17 18 4 5 12 6iis such a ranking that results in the same pairwise AUCs. Verification of AUC ranking representability is much more difficultfor larger datasets, since enumerating all global rankings is then computationally infeasible. However, in [46] we have shown\fW. Waegeman, B. De Baets / Artificial Intelligence 175 (2011) 1223–12501225that AUC ranking representability is strongly linked with a specific type of transitivity that has been called AUC transitivityfor this reason. In Section 4 we will first recapitulate necessary transitivity conditions for AUC ranking representability byexplaining the link between bipartite rankings and collections of dice. The reciprocal relations observed in both problemsexhibit a specific type of transitivity that has been called dice transitivity [15",
            {
                "entities": [
                    [
                        3920,
                        3948,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 231 (2016) 17–38Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomated conjecturing I: Fajtlowicz’s Dalmatian heuristic revisitedC.E. Larson a,∗,1, N. Van Cleemput b,ca Department of Mathematics and Applied Mathematics, Virginia Commonwealth University, Richmond, VA 23284, United Statesb Department of Mathematics, European Centre of Excellence NTIS (New Technologies for the Information Society), University of West Bohemia, Univerzitní 8, 306 14 Plze ˇn, Czech Republicc Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Krijgslaan 281 – S9 – WE02, 9000 Ghent, Belgiuma r t i c l e i n f oa b s t r a c tWe discuss a new implementation of, and new experiments with, Fajtlowicz’s Dalmatian conjecture-making heuristic. Our program makes conjectures about relations of real number invariants of mathematical objects. Conjectures in matrix theory, number theory, and graph theory are reported, together with an experiment in using conjectures to automate game play. The program can be used in a way that, by design, advances mathematical research. These experiments suggest that automated conjecture-making can be a useful ability in the design of machines that can perform a variety of tasks that require intelligence.© 2015 Elsevier B.V. All rights reserved.Article history:Received 22 December 2013Received in revised form 9 October 2015Accepted 12 October 2015Available online 2 November 2015Keywords:Automated conjecturingAutomated conjecture-makingMathematical discoveryAutomated scientific discoveryDalmatian heuristic1. IntroductionWe have reimplemented Fajtlowicz’s useful but little-known Dalmatian heuristic for the automation of mathematical conjecture-making (this heuristic, for instance, has never been referenced in the pages of this journal). The heuristic is gen-eral and can be used to conjecture relations between real number invariants of any objects, mathematical or otherwise. We include examples of conjectures in number theory, matrix theory, graph theory and the characterization of game positions. One of the number theory conjectures implies, and is stronger than, Goldbach’s Conjecture. Some of the number theory conjectures seem to imply the Riemann Hypothesis. And some of the graph theory conjectures would advance the lower bound theory of the independence number of a graph, a widely-studied NP-hard graph invariant. We have also implemented an idea, suggested to us by Barry Mazur, to include existing theorems in the program; when used in this way the program is guaranteed to produce statements that are not implied by existing mathematical knowledge.Our program often makes interesting and useful conjectures on the basis of only a few examples. Humans, ordinarily and of necessity, make decisions based on very limited data. A general automated conjecture-making module that can make plausible and useful guesses based on limited data may be a central architectural feature in the design of machines that are intelligent. Guesses can be used, for instance, to constrain a search of possible actions. Fajtlowicz introduced his Dalmatian heuristic for the automation of mathematical conjecture-making more than 20 years ago [1]. Simply put, the heuristic is to produce a considered mathematical statement if it is both true—with respect to some given examples (matrices, integers, * Corresponding author. Tel.: +1 804 828 5576; fax: +1 804 828 8785.E-mail addresses: clarson@vcu.edu (C.E. Larson), nico.vancleemput@gmail.com (N. Van Cleemput).1 The authors dedicate this article to Prof. Justin Leiber, teacher, mentor, friend and inspiration.http://dx.doi.org/10.1016/j.artint.2015.10.0020004-3702/© 2015 Elsevier B.V. All rights reserved.\f18C.E. Larson, N. Van Cleemput / Artificial Intelligence 231 (2016) 17–38graphs, etc.)—and if the statement gives new information about those objects, in particular, if it says something about at least one of the objects which is not implied by any other stored statement or conjecture.It was very successful—both in limiting the number of conjectures produced by earlier versions of his Graffiti program and in producing conjectures of interest to research mathematicians. His student DeLaVina reimplemented the heuristic in a program that produces conjectures that have led to research and publications by mathematicians [2]; otherwise the heuristic has not been used. Fajtlowicz made some experiments to demonstrate the domain independence of the Dalmatian heuristic; nevertheless, the predominant and best-known uses of the heuristic—in the programs of Fajtlowicz and DeLaVina—has been in the production of graph theory conjectures. But the heuristic is not specific to the production of graph theory conjectures.Our program is open-source, written in Python and C, and implemented as a Sage package. Details about the acquisition and use of our program, the Sage open-source mathematical computing environment, and how to reproduce our results are relegated to Appendix A.Our experiments in implementing and applying this heuristic, including in domains where the authors have no more knowledge than anyone who has browsed a textbook or reference book, lead us to make several conclusions, which we will elaborate and discuss.1. Successful mathematical discovery heuristics can be applicable in a variety of mathematical domains.2. Good conjectures can be based on very limited data.3. Mathematical discovery programs should aim to produce conjectures that address and advance pre-existing mathemat-ical questions.4. Intelligent conjecture-making programs for a domain do not require developer expertise in that domain.Some of these conclusions should be surprising and, we hope, inspire new research in automated scientific discovery.We see conjecture-making—and conjecture-revision in the face of contradictory data (counterexamples)—as a central feature of intelligence. We make guesses, based on our previous experience in relevantly similar situations, learn that our guesses are wrong, revise them, and test them against our experience.2. Background & related workTuring, famously, proposed the idea of designing intelligent machines as an engineering problem, and proposed a test for evaluating the success of such machines. In 1948 he suggested designing machines to do mathematical research as a starting point: mathematical research certainly requires intelligence and, it would be a good starting point as mathematical research would “require little contact with the outside world” [3]. In the 1950s Newell and Simon developed the Logic Theorist program that could prove (some) theorems in first-order logic, and went on to predict that a computer would discover and prove an important mathematical theorem within another decade [4]. Success did not come quite that quickly—but there has been significant progress in many areas of automating mathematical discovery, and there is no theoretical impediment to continued improvement. There is every reason to believe that Newell and Simon’s prediction will be achieved—and likely sooner rather than later.The automation of theorem proving is by far the largest and best-developed area of automated mathematical discovery research. A highlight in this area was the 1996 computer proof of the Robbins Conjecture [5]. More recently Timothy Gowers, a Fields Medalist, and likely the most accomplished mathematician to do research in automated mathematical discovery has, together with Mohan Ganesalingam, developed a theorem-proving program.2Research on automated conjecture-making was initiated by Wang in the late-1950s [6]. His Program II produced thou-sands of statements in propositional logic that could be considered as conjectures or potential theorems. His program included heuristics for deciding which statements to output. Evaluated as a tool for advancing mathematical research, Wang’s program was a failure. He wrote:It was at first thought that these crude principles are sufficient to cut down the number of theorems to a degree that only a reasonably small number of theorems remain. It turns out that there are still too many theorems. The number of theorems printed out after running the machine for a few hours is so formidable that the writer has not even attempted to analyze the mass of data obtained [6].What Wang really wanted was for his program to produce a limited number of statements of interest to logicians. Wang selected a few statements to include in publication—but what was really needed was a way for the program itself to identify the interesting, useful or important statements.The first program to make conjectures leading to published mathematical research was Fajtlowicz’s Graffiti program [7–10,1]. An early version of Graffiti was called the “Sorcerer’s Apprentice” [11] because the program, like Wang’s, produced a large number of statements. In the Goethe poem (and the Disney Fantasia version with Mickey Mouse) a sorcerer’s apprentice intends to use his master’s spells to animate a broom to help him carry a bucket of water but he ends up with 2 A preprint of their paper is available at: arxiv.org/abs/1309.4501.\fC.E. Larson, N. Van Cleemput / Artificial Intelligence 231 (2016) 17–3819so many brooms and buckets of water that the “help” is no help at all—the flood of water is a bigger mess than he had to clean up in the first place. The Sorcerer’s Apprentice Problem is how to reduce the flood of potential conjectures to a useable or scannable number—how to design a program to produce just the most “significant”, “interesting” or useful statements? It is not difficult to program a computer to produce an endless stream of mathematical statements. And given a stream of mathematical statements, there is a chance that some of these statements will be of mathematical interest. The problem is to produce just these ones.This problem was remedied by Fajtlowicz’s invention of his Dalmatian heuristic,",
            {
                "entities": [
                    [
                        3707,
                        3735,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 181–219Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLakatos-style collaborative mathematics through dialectical, structured and abstract argumentationAlison Pease a,∗Chris Reed aa Centre for Argument Technology, University of Dundee, UKb Institute of Philosophy and Sociology, Polish Academy of Sciences, Polandc Department of Computing, Goldsmiths, University of London, UKd University of Edinburgh, UK, John Lawrence a, Katarzyna Budzynska b,a, Joseph Corneli c,d, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 October 2015Received in revised form 17 February 2017Accepted 20 February 2017Available online 1 March 2017Keywords:Automated theorem provingAutomated reasoningAbstract argumentationArgumentationCollaborative intelligenceDialogue gamesLakatosMathematical argumentStructured argumentationSocial creativityPhilosophy of mathematical practiceThe simulation of mathematical reasoning has been a driving force throughout the history of Artificial Intelligence research. However, despite significant successes in computer mathematics, computers are not widely used by mathematicians apart from their quotidian applications. An oft-cited reason for this is that current computational systems cannot do mathematics in the way that humans do. We draw on two areas in which Automated Theorem Proving (ATP) is currently unlike human mathematics: firstly in a focus on soundness, rather than understandability of proof, and secondly in social aspects.Employing techniques and tools from argumentation to build a framework for mixed-initiative collaboration, we develop three complementary arcs. In the first arc – our theoretical model – we interpret the informal logic of mathematical discovery proposed by Lakatos, a philosopher of mathematics, through the lens of dialogue game theory and in particular as a dialogue game ranging over structures of argumentation. In our second arc – our abstraction level – we develop structured arguments, from which we induce abstract argumentation systems and compute the argumentation semantics to provide labelings of the acceptability status of each argument. The output from this stage corresponds to a final, or currently accepted proof artefact, which can be viewed alongside its historical development. Finally, in the third arc – our computational model – we show how each of these formal steps is available in implementation. In an appendix, we demonstrate our approach with a formal, implemented example of real-world mathematical collaboration. We conclude the paper with reflections on our mixed-initiative collaborative approach.© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionThe simulation of mathematical reasoning has been a driving force throughout the history of Artificial Intelligence re-search [58,86,87,98]. However, despite significant successes in ‘computer mathematics’ (e.g., [18,40,42,45]) computers are not widely used by mathematicians apart from their quotidian applications like running word processing tools, email pro-grams, web servers and web browsers, and (sometimes) computer algebra systems. An oft-cited reason for this is that current computational systems cannot do mathematics in the way that humans do. Despite – or perhaps because of [69] – * Corresponding author.E-mail address: a.pease@dundee.ac.uk (A. Pease).http://dx.doi.org/10.1016/j.artint.2017.02.0060004-3702/© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f182A. Pease et al. / Artificial Intelligence 246 (2017) 181–219their profound rigour, machine proofs are often thought to be unclear, uninspiring and untrustworthy, as opposed to human proofs which can be deep, elegant and explanatory [21,41]. In order to help to close the gap between machine-constructed proofs and human-constructed ones, we consider two key areas of focus: informal and social aspects of proof discovery in the human context. We propose that theories and tools from the field of argumentation can be used to more closely align AI systems with the human context in these two areas.1.1. Informal aspects of proofEvaluation metrics in the Automated Theorem Proving (ATP) community are focused on soundness, and the power of a solver to prove a wide selection of difficult problems with specific resource limits.1 Qualities of the resulting proof other than soundness are rarely considered. This stands at variance with the practices of the mathematical community, in which a lack of soundness might be forgiven if a proof is interesting or complex. Indeed, an error in a proof may be neither “perturb-ing,” nor “surprising,” if it is judged to be the right sort of error (one which is not critical to the integrity of the proof) [20].2Instead, one of the main criteria by which a proof is judged in the human context is its understandability. A well-written proof can provide insight as to why a theorem may be true, point to new conjectures, form connections between different fields and suggest solutions to open problems [44,75,106]. Fields medal winners Gowers and Thurston, respectively, have said: “We like our proofs to be explanations rather than just formal guarantees of truth” [41, p. 3], and “reliability does not primarily come from mathematicians formally checking formal arguments; it comes from mathematicians thinking carefully and critically about mathematical ideas” [94, p. 10]. Thurston emphasises that informal conversations between mathemati-cians can often convey ideas more quickly and comprehensibly than a written proof [94, p. 6]. Hersch has suggested that “The standard style of expounding mathematics purges it of the personal, the controversial, and the tentative, producing a work that acknowledges little trace of humanity, either in the creators or the consumers” [47, p. 131].Lakatos offered similar insight into proof-understanding [55]. Building on Pólya’s distinction between informal, unfinished mathematics-in-the-making and formal, finished mathematics [76], he argued that a theorem and proof which are presented in isolation from their development are “artificial and mystifyingly complicated”, analogous to a “conjuring act” [55, p. 142]. In order to make results understandable, they should be presented alongside the “struggle” and “adventure” involved in the story of their development. This insight is echoed by Ernest, who criticises the practice of presenting mathematics learners with the “sanitized outcomes of mathematical enquiry”: “The outcome may be elegant texts meant for public consumption, but they also generate learning obstacles through this reformulation and inversion” [67, p. 67]. Bundy points out that this practice also obscures understandability for research mathematicians: “Mathematicians find informal proofs more accessible and understandable [than formal proofs]” [21, p. 2].In contrast to the concerns about understandability voiced by mathematicians and philosophers of mathematics, under-standability is not traditionally a concern for ATP. A handful of exceptions have focused on making an existing machine proof more comprehensible [29,30,36]. MacKenzie [60] has argued that rather than treating machines as oracles and giving them responsibility for verifying the reliability of hardware and software, there needs to be a continued interaction between computer systems and our collective human judgement: “The finished product of formal verification – the ‘proof object’ – may thus be less important than the process of constructing it.” [61, p. 2348]. Constructing or verifying proofs which are written in a classical logical formalism does not align with mainstream mathematical activity, since proofs are typically neither constructed nor presented in this way.Accordingly, our objective to model mathematical dialogues connects closely with the theory of defeasible argument (reasoning that is rationally compelling but not deductively valid [52]). The structure of classical proof theoretic systems and formal theorisations of defeasible argument differ [99]. Defeasible argument is used during the initial construction of a proof, and as the proof is refined or changed over time to reflect conceptual changes in the underlying theory, or to rectify deductive errors discovered after a proof is commonly accepted – all themes that Lakatos emphasised [55]. In practice, we may have an argument whose conclusion states that for all x, P (x) → Q (x), whose logical validity rests on a particular interpretation of P and Q . In some cases P or Q might not be clearly defined, and can be subsequently defined in different ways by different people, sometimes rendering the initial argument invalid. Whether a consensus ever occurs and whether we could be sure that the consensus is final, is an open and somewhat contentious question.We propose that applied argumentation theory can improve the understandability of output from, and input to, ATP systems, and other computer-mediated, -moderated, or -motivated proof systems. Doing this will help to close the cultural gap between human and machine mathematics. One way to go about this is to keep track of informal proof development, presenting the errors, conflicts and deadends involved, alongside a finished or current proof artefact.1.2. The social dimension of human mathematicsThe social dimension is typically neglected in automated reasoning, which usually consists of two approaches: au-tonomous theorem proving, in which a single system proves theorems, or interactive theorem proving, in which there is one 1 “Wide”, “difficult” and “resources” are all defined appropriately: see, for instance [92].2 Indeed, Aschbacher – one of the main mathematicians involved in the development of the proof of the Classification of Fin",
            {
                "entities": [
                    [
                        3532,
                        3560,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 184–185 (2012) 78–123Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPatrolling security games: Definition and algorithms for solving largeinstances with single patroller and single intruderNicola Basilico, Nicola Gatti∗, Francesco AmigoniArtificial Intelligence and Robotics Laboratory, Dipartimento di Elettronica e Informazione, Politecnico di Milano, Piazza Leonardo da Vinci 32, 20133 Milano, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 29 July 2010Received in revised form 22 February 2012Accepted 8 March 2012Available online 12 March 2012Keywords:Security gamesAdversarial patrollingAlgorithmic game theorySecurity games are gaining significant interest in artificial intelligence. They are characteri-zed by two players (a defender and an attacker) and by a set of targets the defendertries to protect from the attacker’s intrusions by committing to a strategy. To reach theirgoals, players use resources such as patrollers and intruders. Security games are Stackelberggames where the appropriate solution concept is the leader–follower equilibrium. Currentalgorithms for solving these games are applicable when the underlying game is in normalform (i.e., each player has a single decision node). In this paper, we define and studysecurity games with an extensive-form infinite-horizon underlying game, where decisionnodes are potentially infinite. We introduce a novel scenario where the attacker canundertake actions during the execution of the defender’s strategy. We call this new gameclass patrolling security games (PSGs), since its most prominent application is patrollingenvironments against intruders. We show that PSGs cannot be reduced to security gamesstudied so far and we highlight their generality in tackling adversarial patrolling onarbitrary graphs. We then design algorithms to solve large instances with single patrollerand single intruder.© 2012 Elsevier B.V. All rights reserved.1. IntroductionSecurity applications for transportation, shipping, airports, ports, and other infrastructures have recently received anincreasing interest in the artificial intelligence literature [39,40,52,62]. The mainstream approach models a security problemas a two-player non-cooperative game [27] between a defender and an attacker with the aim to find effective strategies for thedefender [51]. The basic ingredients are a number of targets, each with a value (possibly different for the two players), and anumber of resources available to the defender to protect the targets and to the attacker to intrude them. In most situations ofinterest, the resources available to the defender are not enough to protect all the targets at once. This induces the defenderto randomize over the possible assignments of resources to targets to maximize her expected utility. Furthermore, whilethe defender continuously and repeatedly protects the targets, the attacker is assumed to be in the position to observe thedefender and derive a correct belief over her strategy. This last assumption pushes the defender to commit to a strategyand places security games in the more general class of leader–follower (also said Stackelberg) games where the leader is thedefender and the follower is the attacker [64].A leader–follower game is characterized by an underlying game and by the property that the leader can commit to astrategy. Von Stengel and Zamir studied this class of games in [64]. They show that, by committing to a particular strategyin a two-player normal-form underlying game, the leader cannot receive a utility worse than that she would receive when* Corresponding author. Tel.: +39 02 2399 3658; fax: +39 02 2399 3411.E-mail address: ngatti@elet.polimi.it (N. Gatti).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.03.003\fN. Basilico et al. / Artificial Intelligence 184–185 (2012) 78–12379playing a Nash equilibrium. The leader–follower equilibrium is thus proposed as the appropriate solution concept. Letchfordand Conitzer recently showed that the same result holds also when the underlying game is in extensive form [45].In the last few years, several works have addressed the field of security games. For example, one of the most influentialworks is [51], where the problem of placing checkpoints to protect some targets from intrusions is studied (the approachhas been practically applied at the Los Angeles International Airport [52]). The works proposed in this field are based onan underlying game in normal form (both players have a single decision node) and focus on the equilibrium computationproblem, i.e., on the development of efficient algorithms to compute a leader–follower equilibrium.The currently available models are not applicable when the attacker has the option to exploit the observation of theexecution of the defender’s actions to decide when to attack during the realization of the defender’s plan without beingsubject to any temporal deadline (namely, with the possibility of waiting indefinitely for attacking). In [29], the authorshows that by exploiting this option an attacker can drastically improve her expected utility.In this paper, we propose a variant of security games that accounts for such an option. To do so, we consider a securitygame with an underlying game in extensive form with infinite horizon, players having multiple (potentially infinite) decisionnodes. This contribution constitutes, to the best of our knowledge, an extension to the state of the art in security games.The main theoretical motivation behind our work is that the currently available techniques are not efficient with thisvariant of security games. Indeed, their resolution requires techniques, largely unexplored in the security games literature, toreduce the size of the game instances. The main practical motivation behind our work is that the above option is available tothe attacker in many scenarios, among which the most studied is probably adversarial patrolling, where one or more patrollers(the resources controlled by the defender, usually consisting in autonomous mobile robots) move within an environmentto protect it and one or more intruders (the resources controlled by the attacker) wait outside the environment for thebest time to attack. We focus on patrolling as reference scenario for our game models and we call them patrolling securitygames (PSGs). Formulating the adversarial patrolling problem as a PSG allows us to deal with environments represented asarbitrary graphs with targets. The drawback is that the needed computational effort is much larger than that required tosolve settings with special topologies without targets (e.g., with closed perimeters [3]).Our main original contributions, aiming at addressing the equilibrium computation problem for PSGs, follow.(i) We model a PSG as a two-player multi-stage game with infinite horizon, where the defender moves a single resourceon the vertices of an arbitrary graph environment to protect the targets while the attacker intrudes the environment byplacing, for some time, a resource on a selected target vertex. We show that the equilibrium computation problem isa multi-quadratic mathematical programming problem that does not scale to realistically large settings. To tackle theselimitations, we propose the following techniques.(ii) We study the problem to find, when it exists, an equilibrium in pure strategies (namely, deterministic patrolling strate-gies). We show that this problem is a currently unexplored variant of the travel salesman problem (TSP) and that,although NP-complete, it can be efficiently solved by a constraint satisfaction programming algorithm, that solves withhigh success rate ((cid:2) 90%) significantly large instances ((cid:2) 500 targets) in short time ((cid:3) 10 s).(iii) We develop reduction techniques to find a mixed strategy equilibrium (namely, non-deterministic patrolling strategies) inlarge game instances when no pure strategy equilibrium exists. We provide some reduction algorithms based on thecombination of removal of dominated actions and abstractions and we show that no further general reductions ex antethe actual resolution can be provided. We show that with first-order Markovian strategies (that depend only on thevertex visited last by the patroller) our algorithm optimally solves medium-size game instances (up to 75 vertices and15 targets) and sub-optimally solves large-size game instances (up to 166 vertices and 30 targets). We show that thequality of optimal and sub-optimal first-order Markovian solutions is at least 99% and 86%, respectively, of the qualityof the optimal high-order Markovian solutions.The structure of the paper follows. In Section 2, we survey the related works on security games and on robotic patrolling.In Section 3, we describe our game model and we extend the known techniques to solve it, showing their limitations. InSection 4, we discuss how a pure strategy equilibrium can be found when it exists. In Section 5, we provide techniques toreduce game instances and speed up the (mixed strategy) equilibrium computation. Our algorithm is summarized in Sec-tion 6 and experimentally evaluated in Section 7. Section 8 concludes the paper. Appendices A, B, and C report extensions,proofs, and complete experimental data, respectively.2. Related worksWe review security games and leader–follower equilibrium computation in Section 2.1. Next, we survey the main workson robotic patrolling in Section 2.2 and on other related fields in Section 2.3.2.1. Security games and leader–follower equilibrium computationThe seminal work on security games is probably the von Neumann’s hide-and-seek game [24]. It is a strategic-form zero-sum game played in grid environments where the hider chooses a location wherein to hide and the seeker chooses a set oflocations wherein to seek. Starting from this work, several significant variations have been prop",
            {
                "entities": [
                    [
                        3860,
                        3888,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1498–1507Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQualitative reasoning with directional relations ✩D. Wolter∗, J.H. LeeSFB/TR 8 Spatial Cognition, P.O. Box 330440, Universität Bremen, 28334 Bremen, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 1 September 2009Received in revised form 6 September 2010Accepted 7 September 2010Available online 25 September 2010Keywords:Qualitative spatial reasoningQualitative spatial reasoning (QSR) pursues a symbolic approach to reasoning about aspatial domain. Qualitative calculi are defined to capture domain properties in relationoperations, granting a relation algebraic approach to reasoning. QSR has two primary goals:providing a symbolic model for human common-sense level of reasoning and providingefficient means for reasoning. In this paper, we dismantle the hope for efficient reasoningabout directional information in infinite spatial domains by showing that it is inherentlyhard to decide consistency of a set of constraints that represents positions in the planeby specifying directions from reference objects. We assume that these reference objectsare not fixed but only constrained through directional relations themselves. Known QSRreasoning methods fail to handle this information.© 2010 Elsevier B.V. All rights reserved.1. IntroductionQualitative spatial reasoning (QSR) [1] is the subfield of knowledge representation and symbolic reasoning that representsknowledge about spatial domains by finite sets of named qualitative relations. One particular aim of qualitative approaches isto model human common-sense understanding of space. This makes qualitative approaches useful, for instance, in human–machine interaction. Qualitative reasoning is considered to provide efficient means for reasoning about continuous, infinitebut structured domains such as space or time.Qualitative relations state relationships of variables ranging over a spatial domain. Thus, consistency problems in qual-itative spatial reasoning are closely related to constraint-based reasoning over mostly infinite domains and so QSR sharesmuch of the terminology of constraint-based reasoning. One central task in QSR is to decide consistency of qualitative con-straint networks, i.e., constraint networks in which only qualitative relations are used as constraints. In the following werefer to this problem as the consistency problem. Deciding consistency of qualitative constraint networks differs from classi-cal constraint satisfaction problems (CSP) in that the infinite domain prevents exhaustive search. QSR techniques rely on therelation algebraic structure of qualitative calculi [2] that is captured in converse and composition tables. While reasoning infull qualitative calculi is mostly NP-complete, tractable sub-algebras have been identified for some calculi [3,4].Directional calculi consist of a set of qualitative directional relations that coarsely specify the direction in which an objectis positioned. Positions are considered to be points in the Euclidean plane and directions are given with respect to a frameof reference. Qualitative representations of directional information may involve a single, global frame of reference or theymay employ different frames of reference that are determined by reference objects. In this paper we are concerned withdirectional relations that involve different reference objects, i.e., we are not concerned with cardinal directions that usea single frame of reference and for which reasoning is known to be tractable [5]. Two important examples for reference✩This work was carried out in the framework of the Transregional Collaborative Research Center “Spatial Cognition”, financial support by the DeutscheForschungsgemeinschaft is gratefully acknowledged.* Corresponding author.E-mail addresses: dwolter@sfbtr8.uni-bremen.de (D. Wolter), jay@sfbtr8.uni-bremen.de (J.H. Lee).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.09.004\fD. Wolter, J.H. Lee / Artificial Intelligence 174 (2010) 1498–15071499objects are directed lines (establishing directions “left of” or “right of” the line, for instance) or pairs of points to determinetriangle orientations (see for example [6]). Directional calculi are important for handling knowledge that makes use ofrelative or egocentric frames of references. In particular, directional calculi draw their motivation from tasks in high-levelagent control [7] or from interpreting natural language for robot instruction [8]. In this article we show that reasoning aboutdirectional relations is inherently intractable. By reducing the problem of matroid realizability to the consistency problem weshow that reasoning with directional relations is NP-hard, NP membership being an open question. Our result has impacton reasoning with any qualitative calculus that is expressive enough to distinguish “left of” from “right of” which includesflip-flop [6,9], double cross [10,11], dipole [12], OPRA [13], TPCC [14]. For all such calculi, the existing relation algebraicapproach is too weak for deciding consistency problems and all reasonable sub-algebras remain NP-hard.This paper is organized as follows. First we give basis definitions of qualitative reasoning and discuss related work. InSection 3 we explain the principle steps of our proof. After formally introducing oriented matroids (Section 4) we givein Section 5 new intractability results for several directional calculi. In Section 6 we sketch a new approach to decidingconsistency in directional calculi. We conclude by discussion and outlook.2. Qualitative constraint-based reasoningThe basic concept of qualitative spatial reasoning is the qualitative calculus [2] which comprises a set of qualitative relationsand relation algebraic operations that for many calculi meet conditions for a relation algebra in the sense of Tarski. For thecontext of this paper, only the relations are important.Definition 1 (Qualitative relation). Let D be a non-empty set called domain and let B = {r1, r2, . . . , rn} be a set of k-aryrelations over D. B is called the set of base relations and the set of all unions of base relations R = {| b ∈ 2B } is calledthe set of qualitative relations. Commonly, a qualitative relation ri ∪ r j is denoted {ri, r j}.r∈b(cid:2)Qualitative relations express the relationship of variables ranging over the domain by base relations or disjunctionsthereof.Definition 2 (QCSP). Let R = {r1, r2, . . . , rn} be a set of k-ary qualitative relations over domain D and let X be a set ofvariables ranging over D. A qualitative constraint is a formula X1 . . . Xk−1ri Xk with variables X j ∈ X . For a valuation φ : X →D we say that a qualitative constraint X1 . . . Xk−1 r Xk is satisfied if (φ( X1), φ( X2), . . . , φ( Xk)) ∈ r holds.A qualitative constraint network is a set of variables and constraints such that for any k-tuple of variables exactly oneconstraint is defined. If constraints only involve base relations, it is called a scenario for short.The problem of deciding whether there exists a valuation satisfying all qualitative constraints over a set of qualitativerelations R is called QCSP(R).Qualitative spatial reasoning exploits the algebraic structure of qualitative relations. The consistency problem is tackledusing the algebraic closure algorithm [15], an adaption of Mackworth’s AC-3 algorithm [16] for enforcing path-consistencyin finite domain CSPs. Algebraic closure exploits the composition operation to rule out local inconsistencies in a constraintnetwork. For some calculi algebraic closure implies path-consistency and can already be a sufficient condition for consis-tency [17]. In order to apply decision procedures for the consistency problem it is commonly required that algebraic closureis applicable to decide consistency of scenarios [15,18]. For example, this is the case in the RCC calculus [19] or Allen’sinterval algebra [20]. Given that algebraic closure decides consistency for scenarios, networks involving disjunctions canthen be refined to base relations by means of a backtracking search and consistency can be decided [15]. This approachgains efficiency from exploiting maximal tractable subsets, i.e., maximal sets of relations for which algebraic closure decidesconsistency [21].To put it in a nutshell, qualitative spatial reasoning pursues a relation algebraic approach which relies on the existenceof efficient decision algorithms for consistency of scenarios such that reasoning in the full algebra (i.e., including disjunctiverelations) can still be tackled in NP.Previous research investigating the tractability of directional calculi identified intractable sub-algebras that involve dis-junctions of base relations [11,14,12]. Particularly ternary point calculi are so expressive that encoding NOT-ALL-EQUAL-3-SAT or BETWEENNESS instances is straightforward (cf. [11,22]) when using disjunctions of base relations. In this paperwe significantly refine these results by showing that directional information is inherently intractable, i.e., even decidingconsistency of scenarios is intractable.3. Proof sketchIn the following we describe the general idea of how to show NP-hardness of consistency problems that constrain apoint position to be either left of or right of a line. Essentially, we develop a reduction from a realizability problem incombinatorial geometry to a consistency problem of qualitative constraints. This is captured by the central Theorem 8 thatdirectly applies to all calculi that contain relations “left of” and “right of”. As our reductions are reversible we are also able\f1500D. Wolter, J.H. Lee / Artificial Intelligence 174 (2010) 1498–1507Fig. 1. (a) Steps in the reduction of decision problems about directional information to NP-hard matroid realizability. (b) Projective plane z = 1.to show that if the geometric realizability problem turns out to be in ",
            {
                "entities": [
                    [
                        4049,
                        4077,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Journal Pre-proofEntropy Estimation via UniformizationZiqiao Ao and Jinglai LiPII:DOI:S0004-3702(23)00100-5https://doi.org/10.1016/j.artint.2023.103954Reference:ARTINT 103954To appear in:Artificial IntelligenceReceived date:4 June 2022Revised date:1 June 2023Accepted date:3 June 2023Please cite this article as: Z. Ao and J. Li, Entropy Estimation via Uniformization, Artificial Intelligence, 103954,doi: https://doi.org/10.1016/j.artint.2023.103954.This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, andformatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting andreview before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that,during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journalpertain.© 2023 Published by Elsevier.\fEntropy Estimation via UniformizationSchool of Mathematics, University of Birmingham, Birmingham B15 2TT, UKZiqiao Ao, Jinglai LiAbstractEntropy estimation is of practical importance in information theory and statis-tical science. Many existing entropy estimators suffer from fast growing esti-mation bias with respect to dimensionality, rendering them unsuitable for high-dimensional problems. In this work we propose a transform-based method forhigh-dimensional entropy estimation, which consists of the following two mainingredients. Firstly, we provide a modified k-nearest neighbors (k-NN) entropyestimator that can reduce estimation bias for samples closely resembling a uni-form distribution. Second we design a normalizing flow based mapping thatpushes samples toward the uniform distribution, and the relation between theentropy of the original samples and the transformed ones is also derived. As aresult the entropy of a given set of samples is estimated by first transformingthem toward the uniform distribution and then applying the proposed estima-tor to the transformed samples. The performance of the proposed method iscompared against several existing entropy estimators, with both mathematicalexamples and real-world applications.Keywords: entropy estimation, k nearest neighbor estimator, normalizing flow,uniformization2010 MSC: 00-01, 99-001. Introduction5Entropy, a fundamental concept in information theory, has found applica-tions in various fields such as physics, statistics, signal processing, and machinelearning. For example, in the statistics and data science contexts, various ap-plications rely critically on the estimation of entropy, including goodness-of-fittesting [1, 2], sensitivity analysis [3], parameter estimation [4, 5], and Bayesianexperimental design [6, 7].In this work we focus on the continuous version of entropy that takes theform,(cid:2)H(X) = −log[px(x)]px(x)dx,(1)Email addresses: zxa029@bham.ac.uk (Ziqiao Ao), j.li.10@bham.ac.uk (Jinglai Li)Preprint submitted to Journal of LATEX TemplatesJune 7, 2023\f101520253035404550where px(x) is the probability density function (PDF) of random variable X.Despite the rather simple definition, entropy only admits an analytical expres-sion for a limited family of distributions and needs to be evaluated numericallyin general. When the distribution of interest is analytically available, in princi-ple its entropy can be estimated by numerical integration schemes such as theMonte Carlo method. However, in many real-world applications, the distribu-tion of interest is not analytically available, and one has to estimate the entropyfrom the realizations drawn from the target distribution, which makes it difficultor even impossible to directly compute the entropy via numerical integration.Entropy estimation has attracted considerable attention from various com-munities in the last a few decades, and numerous methods have been developedto directly estimate entropy from realizations. In this work we only considernon-parametric approaches which do not assume any parametric model of thetarget distribution, and those methods can be broadly classified into two cate-gories. The first class of methods, are known as the plug-in estimators, whichfirst estimate the underlying probability density, and then compute the integralin Eq. (1) using numerical integration or Monte Carlo (see [8] for a detaileddescription). Some examples of density estimation approaches that have beenstudied for plug-in methods are kernel density estimator [9, 10, 11, 12], his-togram estimator [13, 10] and field-theoretic approach [14]. A major limitationof this type of methods is that they rely on an effective density estimation, whichis a difficult problem in its own right, especially when the dimensionality of theproblem is high. A different strategy is to directly estimate the entropy from theindependent samples of the random variable. Popular methods falling in thiscategory include the sample-spacing [15] and the k-nearest neighbors (k-NN)[16, 17] based estimators. The latter is particularly appealing among the exist-ing estimation methods thanks to its theoretical and computational advantagesand has been widely used in practical problems. Efforts have been constantly de-voted to extending and improving the k-NN methods, and some recent variantsand extensions of the methods are [18, 19, 20]. It is also worth mentioning thatthere are many other types of direct entropy estimators available. For example,Ariel and Louzoun [21] decoupled the target entropy to a sum of the entropy ofmarginals, which is estimated using one-dimensional methods, and the entropyof copula, which is estimated recursively by splitting the data along statisticallydependent dimensions. Kandasamy et al.[22] suggested a leave-one-out tech-nique for the von Mises expansion based estimator [23]. We also note that incertain applications the main purpose is to minimize or maximize the quantityof entropy, and in this case entropy gradient estimation strategies [24, 25] havebeen explored to avoid direct entropy estimation.It is well known that, entropy estimation becomes increasingly more diffi-cult as the dimensionality grows, and such difficulty is mainly due to the es-timation bias, which decays very slowly with respect to sample size for high-dimensional problems. For example in many popular approaches including thek-NN method [16], the estimation bias decays at the rate of O(N −γ/d) whereN is the sample size, d is the dimensionality, and γ is a positive constant[26, 22, 27, 28]. As a result, very few, if not none, of the existing entropy2\f5560657075808590estimation methods can effectively handle high-dimensional problems withoutmaking strong assumptions about the smoothness of the underlying distribu-tion [22]. Indeed, the well-known minimax bias results (e.g., [29, 30]) indicatethat without the strong smoothness assumption [22], the curse of dimensional-ity is unavoidable. However, efforts can still be made to reduce the differencebetween the actual estimation bias and the theoretical bound.The main goal of this work is to provide an effective entropy estimationapproach which can achieve faster bias decaying rate under mild smoothnessassumption, and thus can effectively deal with high-dimensional problems. Themethod presented here consists of two main ingredients. First propose two trun-cated k-NN estimators based on those by [16] and [17] respectively, and alsoprovide the bounds of the estimation bias in these estimators. Interestingly ourtheoretical results suggest that the estimators achieve zero bias for uniform dis-tributions, while there is no such a result for any existing k-NN based estimators,according to the bias analysis available to date [27, 31, 32]. This property offersthe possibility to significantly improve the performance of entropy estimationby mapping the data points toward a uniform distribution, a procedure that werefer to as uniformization. Therefore the second main ingredient of the methodis to conduct the uniformization of the data points, with the normalizing flow(NF) technique [33, 34]. Simply speaking, NF constructs a sequence of invertibleand differentiable mappings that transform a simple base distribution such asstandard Gaussian into a more complicated distribution whose density functionmay not be available. Specifically we use the Masked Autoregressive Flow [35],a NF algorithm originally developed for density estimation, combined with theprobability integral transform, to push the original data points towards the uni-form distribution. We then estimate the entropy of the resulting near-uniformdata points with the proposed truncated k-NN estimators, and derive that ofthe original ones accordingly (by adding an entropic correction term due to thetransformation). Therefore, by combining the truncated k-NN estimators andthe normalizing flow model, we are able to decode a complex high-dimensionaldistribution represented by the realizations, and obtain an accurate estimationof its entropy.The rest of the paper is organized as follows. In Section 2, we describe thetraditional k-NN based methods of entropy estimation and their convergenceproperties. In Section 3, we introduce the truncated k-NN estimators for dis-tributions with compact support, and then show how to combine these newestimators with the NF-based uniformization procedure to estimate the entropyof general distributions. Numerical examples and applications are presented inSections 4 and Section 5 respectively to demonstrate the effectiveness of theproposed methods. Finally, in Section 6, we summarize our findings and discusssome future research directions.952. k-NN Based Entropy EstimationWe provide a brief introduction to two commonly used k-NN based entropyestimators in this section. We start with the original k-NN entropy estimator3\f100proposed in [16], where the k-th nearest neighbor is contained in the sma",
            {
                "entities": [
                    [
                        123,
                        151,
                        "DOI"
                    ],
                    [
                        422,
                        450,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 160 (2004) 145–172www.elsevier.com/locate/artintA formal theory for reasoning about parthood,connection, and locationMaureen DonnellyInstitute for Formal Ontology and Medical Information Science, Saarland University,D-66041 Saarbrücken, GermanyReceived 5 February 2004; accepted 27 June 2004AbstractIn fields such as medicine, geography, and mechanics, spatial reasoning involves reasoning aboutentities that may coincide without overlapping. Some examples are: cavities and invading particles,passageways and valves, geographic regions and tropical storms. The purpose of this paper is todevelop a formal theory of spatial relations for domains that include coincident entities. The core ofthe theory is a clear distinction between mereotopological relations, such as parthood and connection,and relative location relations, such as coincidence. To guide the development of the formal theory,I construct mathematical models in which nontrivial relative location relations are defined. 2004 Elsevier B.V. All rights reserved.Keywords: Spatial reasoning; Mereotopology; Formal ontology; Physical objects; Holes1. IntroductionTwo entities overlap when they share a common part. Two entities coincide when theyoccupy overlapping regions of space.1 The Mississippi River and Minnesota overlap—thefirst ten kilometers of the Mississippi River are part of both the river and the state. Theriver and the state also coincide—the region occupied by the first ten kilometers of theE-mail address: maureen.donnelly@ifomis.uni-saarland.de (M. Donnelly).1 Note that with this usage coincident objects need only occupy overlapping spatial regions. I will use the term“complete coincidence” for the stronger relation that holds between objects that occupy identical spatial regions.0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.06.003\f146M. Donnelly / Artificial Intelligence 160 (2004) 145–172Mississippi River is part of both the region occupied by the entire river and the regionoccupied by the state. Similarly, my hand and my body both overlap and coincide. It iseasy to see that any overlapping spatial entities must also coincide. Their locations willoverlap at their common parts.But the relation of coincidence is broader than that of overlap. In other words, thereare pairs of coincident objects which do not share parts. The food that is currently beingdigested in my stomach cavity coincides with, but does not overlap, my stomach cavity.A tropical storm covering Acapulco coincides with, but does not overlap, Mexico. Anyobject coincides with, but does not overlap, the spatial region at which it is located at agiven point of time.A mereotopology is a formal theory of parthood and connection relations. It has longbeen recognized that mereotopology forms an essential part of formal ontology. Severaldifferent mereotopologies have been proposed in recent literature, including [1,4,11,17].These theories are ultimately intended for reasoning about relations among a variety ofspatial entities including material objects (amoebas, mechanical devices, etc.) and geo-graphical entities (islands, bays, etc.). However, it is assumed in nearly all of this work thatthe immediate domains of application are restricted to spatial regions. When material ob-jects are introduced, as in [8], mereotopological relations are still restricted to regions. Thematerial objects have only a second-hand mereotopological structure that is inherited fromthe regions at which they are located. Thus, a distinct coincidence relation is not usuallyintroduced in the mereotopology: on domains of regions, coincidence is just overlap.Likewise, mathematical models for these theories typically use simple domains consist-ing just of subsets of a topological space. See, for example, [1,3,9]. On these domains, thereis no natural way of giving the coincidence relation a broader interpretation than that ofthe overlap relation. Here, overlap is generally interpreted as non-empty intersection.2 Thecoincidence relation could have a broader interpretation only if it were artificially extendedto pairs of subsets with an empty intersection.The goal of this paper is to construct a mereotopology for domains that include coinci-dent but non-overlapping entities. I present a primary theory, called Layered Mereotopol-ogy, and two variants of it. Domains for Layered Mereotopology may include both materialobjects and the regions at which they are located, in addition to other types of entities,such as holes or geopolitical entities, which may coincide with material objects. LayeredMereotopology allows spatial relations to apply directly to all entities within the domain,be they regions, material objects, holes, or what have you. It extends mereotopology byadding relative location relations—relations such as coincidence that depend only on theobjects’ locations—and by making explicit the relation between a spatial entity and theregion at which it is located. To guide the development of the formal theory, I construct aclass of mathematical structures, called Layered Models, in which a coincidence relationdistinct from overlap is defined.Layered Mereotopology borrows much from the theory of location of [7]. It differs inthat it divides the domain into different layers, each of which is mereologically independentof the others. Also, no models are provided for the Casati and Varzi theory other than2 The interpretation in [1] is slightly different but in the same spirit.\fM. Donnelly / Artificial Intelligence 160 (2004) 145–172147the standard topological models that conflate coincidence and overlap. Additional workon combining either relative location relations or a location function with other spatialrelations can be found in [2,5,8,15].The outline for this paper is as follows. In Section 2, I construct the Layered Models.These structures include both mereotopological relations and relative location relations.Layered Models are the target models of the formal theory, Layered Mereotopology, whichis presented in Sections 3–5. The mereological subtheory, Layered Mereology, is developedin Section 3. In Section 4, a function that maps each member of the domain to its regionis added and the first group of relative location relations are defined. Topological relationsand more relative location relations are added in Section 5. In the last part of the paper,I present two variations of Layered Mereotopology, both of which make weaker assump-tions about the composition of the spatial domain. Section 6 proposes a version of LayeredMereotopology with weakened requirements on the formation of sums. Section 7 developsa version of Layered Mereotopology that does not assume that the spatial domain includesa special sub-domain of regions.Layered Mereotopology and its two variants are presented here as time-independenttheories. They can be used in this form either to describe instantaneous time-slices ofa three-dimensional domain or to describe space-time relations among changeless four-dimensional entities such as processes. The theory can also be naturally extended to includetime-dependent relations which can be used to describe change in spatial domains.2. Layered ModelsIn this section, I introduce a class of mathematical structures in which both mereotopo-logical and relative location relations are defined. I call these structures Layered Models be-cause their domains are partitioned into non-overlapping layers. Members of the same layercoincide only when they overlap. Members of different layers never stand in mereotopo-logical relations, but they may coincide or stand in other relative location relations.Layered Models are intended to represent the actual spatial world in such a way that spa-tial entities of distinct types—regions, material objects, holes, geographic objects, etc.—are assigned to distinct layers. In particular, a special layer, covering the entire spatialdomain, represents the collection of all regions. For other types of spatial entities (materialobjects, holes, geographical objects, etc.), I leave open the question of whether all tokensof that type reside on one layer or whether they are distributed to different layers. For ex-ample, at one extreme, all material objects may be assigned to the same layer and, at theother extreme, each independent material object (my desk, your car, etc.) may be assignedto its own layer.Layered Models are defined as follows. Let T = (cid:1)X, cl(cid:2) be a topological space, whereX is the set of points and cl is the closure operator. Let I be any index set that includes 0.The domain, D, of a Layered Model is a nonempty set of ordered pairs, xi = (cid:1)x, i(cid:2) where∅ (cid:4)= x ⊆ X and i ∈ I . (I will generally use the abbreviation xi for (cid:1)x, i(cid:2). All variables referringto objects in Layered Models appear in Arial font to distinguish them from the variables ofthe formal theory.) The first component of each ordered pair determines its location. The\f148M. Donnelly / Artificial Intelligence 160 (2004) 145–172second component determines the layer to which it belongs. All pairs of the form (cid:1)x, 0(cid:2)(i.e., x0) belong to a special layer, called the region layer.I require that the domain, D, of any Layered Model satisfy the following conditions:1. For any i ∈ I , if xi ∈ D, then x0 ∈ D.2. For any i ∈ I and any Y ⊆ ℘ (X), if yi ∈ D for all y ∈ Y, then (3. For any i ∈ I and any xi, yi ∈ D, if x (cid:1) y, then there is a zi ∈ D such that z ⊆ x andy∈Y(y))i ∈ D.(cid:1)z ∩ y = ∅.4. If xi, yi ∈ D and x ∩ y (cid:4)= ∅, then (x ∩ y)i ∈ D.Note that conditions 1–4 are not very restrictive. Even once the topological space andindex set are fixed, domains with very different compositions are possible. As a tokenexample, suppose T is the usual topological space based on the real numbers, (cid:8), andI = {0, 1}. Then {xi: ∅ (cid:4)= x ⊆ (cid:8) and i = 0, 1} satisfies conditions 1–4. In this case, the do-main",
            {
                "entities": [
                    [
                        1868,
                        1896,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 479–499Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRepresenting uncertainty on set-valued variables using belief functionsThierry Denœux∗, Zoulficar Younes, Fahed AbdallahHEUDIASYC, UTC, CNRS, Centre de Recherche de Royallieu, BP 20529, F-60205 Compiègne, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 April 2009Received in revised form 2 February 2010Accepted 3 February 2010Available online 6 February 2010Keywords:Dempster–Shafer theoryEvidence theoryConjunctive knowledgeLatticeUncertain reasoningMulti-label classification1. IntroductionA formalism is proposed for representing uncertain information on set-valued variablesusing the formalism of belief functions. A set-valued variable X on a domain Ω is a variabletaking zero, one or several values in Ω. While defining mass functions on the frame 22Ωis usually not feasible because of the double-exponential complexity involved, we proposean approach based on a definition of a restricted family of subsets of 2Ω that is closedunder intersection and has a lattice structure. Using recent results about belief functionson lattices, we show that most notions from Dempster–Shafer theory can be transposedto that particular lattice, making it possible to express rich knowledge about X with onlylimited additional complexity as compared to the single-valued case. An application tomulti-label classification (in which each learning instance can belong to several classessimultaneously) is demonstrated.© 2010 Elsevier B.V. All rights reserved.An important concept in knowledge representation is that of variable. Usually, we associate to each variable X a domain(or frame of discernment) Ω , and we assume that X takes one and only one value in Ω . For instance, in conventionalclassification problems, X denotes the class of an object, and each object is assumed to belong to one and only one classamong a set Ω of classes.There are cases, however, where it is convenient to consider a variable X taking zero, one or several values in a domainΩ . In such cases, X may be called a set-valued, or conjunctive variable [8,33]. For instance, in diagnosis problems, Ω maydenote the set of faults that can possibly occur in a system, and X the faults actually occurring at a given time. In textclassification, Ω may denote a set of topics, and X the list of topics dealt with in a given text, etc.A straightforward approach to the above problem is, of course, to consider a set-valued variable X on Ω as a single-valued variable on the power set Θ = 2Ω . However, this approach often implies working in a space of very high cardinality.If, as done in this paper, we assume Ω to be finite with size K , then the size of Θ is 2K . If we want to express impreciseinformation about X , we will have to manipulate subsets of Θ . As there are 22Kof these subsets, this approach rapidlybecomes intractable as K increases.In this paper, we consider the problem of representing partial knowledge about a set-valued variable X with domain Ωusing the Dempster–Shafer theory of belief functions [26,30]. Our approach will be based on a simple representation of aclass C(Ω) of subsets of Θ = 2Ω which, endowed with set inclusion, has a lattice structure. Using recent results about belieffunctions on lattices [14], we will be able to generalize most concepts of Dempster–Shafer theory (including the canonicaldecompositions and the cautious rule [5]) in this setting. This formalism will be shown to allow the expression of a widerange of knowledge about set-valued variables, with only a moderate increase of complexity (from 2K to 3K ) as comparedto the usual single-valued case.* Corresponding author. Fax: +33 03 44 23 44 77.E-mail address: tdenoeux@hds.utc.fr (T. Denœux).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.002\f480T. Denœux et al. / Artificial Intelligence 174 (2010) 479–499The rest of this paper is organized as follows. Background notions on belief functions in the classical setting and ingeneral lattices will first be recalled in Sections 2 and 3, respectively. Our approach will then be introduced in Section 4,and some relationships with previous work will be outlined in Section 5. An application to multi-label classification will bepresented in Section 6, and Section 7 will conclude the paper.2. Belief functionsThe basic concepts of the Dempster–Shafer theory of belief functions, as introduced in [26], will first be summarized inSection 2.1. The canonical decomposition and the cautious rule will then be recalled in Section 2.2.2.1. Basic definitionsLet Ω be a finite set. A mass function on Ω is a function m : 2Ω → [0, 1] such that(cid:2)m( A) = 1.A⊆ΩThe subsets A of Ω such that m( A) > 0 are called the focal elements of m. The set of focal elements of m will be denotedF (m). m is said to be normal if ∅ is not a focal element, and dogmatic if Ω is not a focal element.A mass function m is often used to model an agent’s beliefs about a variable X taking a single but ill-known value ω0in Ω [30]. The quantity m( A) is then interpreted as the measure of the belief that is committed exactly to the hypothesisω0 ∈ A. Full certainty corresponds to the case where m({ωk}) = 1 for some ωk ∈ Ω , while total ignorance is modeled by thevacuous mass function verifying m(Ω) = 1. Probabilistic uncertainty corresponds to the case where all focal elements aresingletons, in which case m is equivalent to a probability distribution on Ω .To each mass function m can be associated an implicability function b and a belief function bel defined as follows:(cid:2)b( A) =B⊆ Abel( A) =m(B),(cid:2)m(B) = b( A) − m(∅).(1)(2)B⊆ A,B(cid:2) AThese two functions are equal when m is normal. However, they need to be distinguished when considering non-normalmass functions. Function bel has easier interpretation, as bel( A) corresponds to a degree of belief in the proposition “The truevalue ω0 of X belongs to A”. However, function b has simpler mathematical properties. For instance, m can be recoveredfrom b asm( A) =(−1)| A\\B|b(B),(3)(cid:2)B⊆ Awhere | · | denotes cardinality. Function m is said to be the Möbius transform of b. For every function fsuch that f (Ω) = 1, the following conditions are known to be equivalent [26]:from 2Ω to [0, 1]1. The Möbius transform m of fis positive and verifies(cid:3)A⊆Ω m( A) = 1.2.fis totally monotone, i.e., for any k (cid:2) 2 and for any family A1, . . . , Ak in 2Ω ,(cid:6)(cid:2)Ai(cid:4)fk(cid:5)i=1(cid:2)(−1)|I|+1 f∅(cid:7)=I⊆{1,...,k}(cid:7) (cid:8)(cid:9)Ai.i∈IHence, b (and bel) are totally monotone.Other functions related to m are the plausibility function, defined as(cid:2)pl( A) =m(B)B∩ A(cid:7)=∅= 1 − b( A)and the commonality function (or co-Möbius transform of b) defined asq( A) =(cid:2)m(B).B⊇ Am can be recovered from q using the following relation:m( A) =(−1)|B\\ A|q(B).(cid:2)B⊇ A(4)(5)(6)(7)\fT. Denœux et al. / Artificial Intelligence 174 (2010) 479–499481Functions m, bel, b, pl and q are thus in one-to-one correspondence and can be regarded as different facets of the sameinformation.A special case of interest is that where the focal elements of m are nested: m is then said to be consonant. In this case,we havepl( A ∪ B) = max(cid:10)(cid:11)pl( A), pl(B), ∀ A, B ⊆ Ω.The plausibility function is thus a possibility measure, with corresponding possibility distribution defined by π (x) = pl({x})for all x ∈ Ω . Conversely, to each possibility distribution corresponds a unique consonant mass function [26].Let us now assume that we receive two mass functions m1 and m2 from two distinct sources of information assumed tobe reliable. Then m1 and m2 can be combined using the conjunctive sum (or unnormalized Dempster’s rule of combination)defined as follows:(m1 ∩(cid:12) m2)( A) =(cid:2)m1(B)m2(C).B∩C= A(8)This rule is commutative, associative, and admits the vacuous mass function as neutral element. It is conjunctive as theproduct of m1(B) and m2(C) is transferred to the intersection of B and C . The quantity (m1 ∩(cid:12) m2)(∅) is referred to as thedegree of conflict between m1 and m2.Let q1 ∩(cid:12) 2 denote the commonality function corresponding to m1 ∩(cid:12) m2. It can be computed from q1 and q2, the common-The normalized Dempster’s rule ⊕ [26] is defined as the conjunctive sum followed by a normalization step:ality functions associated to m1 and m2, as follows:q1 ∩(cid:12) 2( A) = q1( A) · q2( A), ∀ A ⊆ Ω.(cid:12)0(m1 ⊕ m2)( A) =(m1 ∩(cid:12) m2)( A)1−(m1 ∩(cid:12) m2)(∅)It is clear that m1 ⊕ m2 is defined as long as (m1 ∩(cid:12) m2)(∅) < 1.if A = ∅,otherwise.the choice of the union operator results in the disjunctive sum [28]:(m1 ∪(cid:12) m2)( A) =It can be shown that(cid:2)m1(B)m2(C).B∪C= Ab1 ∪(cid:12) 2( A) = b1( A) · b2( A), ∀ A ⊆ Ω,Alternatives to the conjunctive sum can be constructed by replacing ∩ by any binary set operation in (8). For instance,(9)(10)(11)(12)which is the counterpart of (9). Dubois and Prade [10] have also proposed a “hybrid” rule intermediate between the con-junctive and disjunctive sums, in which the product m1(B)m2(C) is assigned to B ∩ C whenever B ∩ C (cid:7)= ∅, and to B ∪ Cotherwise. This rule is not associative, but it usually provides a good summary of partially conflicting items of evidence.In [30], Smets proposed a two-level model in which items of evidence are quantified by mass functions and combinedat the credal level, while decisions are made at the pignistic level (from the Latin pignus meaning a bet). Once a decisionhas to be made, a mass function m is thus transformed into a pignistic probability distribution p. The pignistic transformationconsists in normalizing m (assuming that m(∅) < 1), and then distributing each normalized mass m( A)/(1 − m(∅)) equallybetween the atoms ωk ∈ A:(cid:2)p(ωk) ={ A⊆Ω,ωk∈ A}m( A)(1 − m(∅))| A|, ∀ωk ∈ Ω.(13)Other authors have suggested the so-called plausibility transformation fo",
            {
                "entities": [
                    [
                        3898,
                        3926,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 875–896www.elsevier.com/locate/artintThe Carneades model of argument and burden of proofThomas F. Gordon a,∗, Henry Prakken b, Douglas Walton ca Fraunhofer FOKUS, Berlin, Germanyb Department of Information and Computing Sciences, Utrecht University,and Faculty of Law, University of Groningen, Utrecht and Groningen, The Netherlandsc Department of Philosophy, University of Winnipeg, Winnipeg, Manitoba, CanadaReceived 8 November 2006; received in revised form 3 April 2007; accepted 16 April 2007Available online 29 April 2007AbstractWe present a formal, mathematical model of argument structure and evaluation, taking seriously the procedural and dialogicalaspects of argumentation. The model applies proof standards to determine the acceptability of statements on an issue-by-issue basis.The model uses different types of premises (ordinary premises, assumptions and exceptions) and information about the dialecticalstatus of statements (stated, questioned, accepted or rejected) to allow the burden of proof to be allocated to the proponent or therespondent, as appropriate, for each premise separately. Our approach allows the burden of proof for a premise to be assigned to adifferent party than the one who has the burden of proving the conclusion of the argument, and also to change the burden of proofor applicable proof standard as the dialogue progresses from stage to stage. Useful for modeling legal dialogues, the burden ofproduction and burden of persuasion can be handled separately, with a different responsible party and applicable proof standard foreach. Carneades enables critical questions of argumentation schemes to be modeled as additional premises, using premise types tocapture the varying effect on the burden of proof of different kinds of questions.© 2007 Elsevier B.V. All rights reserved.Keywords: Argument structure; Argument graphs; Argument evaluation; Argumentation schemes; Burden of proof; Proof standards; Legalargument1. IntroductionThis article presents a functional model of the evaluation of commonsense arguments, taking seriously the proce-dural and dialogical aspects of argumentation. The model, called Carneades in honor of the Greek skeptic philosopherwho emphasized the importance of plausible reasoning [9, vol. 1, p. 33–34], applies proof standards [10] to determinethe acceptability of statements on an issue-by-issue basis. The model has been implemented using a functional pro-gramming language. This system, also called Carneades, supports a range of argumentation tasks, including argumentreconstruction, evaluation and visualization.Carneades is meant to overcome several limitations of current ‘mainstream’ AI work on argumentation. The main-stream approach essentially regards the problem of argument evaluation to be a question of defining the appropriate* Corresponding author.E-mail addresses: thomas.gordon@fokus.fraunhofer.de (T.F. Gordon), henry@cs.uu.nl (H. Prakken), d.walton@uwinnipeg.ca (D. Walton).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.010\f876T.F. Gordon et al. / Artificial Intelligence 171 (2007) 875–896(non-monotonic) relation between sets of statements: a statement ‘follows’ from a set of statements if an argumentfor it can be constructed that survives all attacks by counterarguments that can be constructed from the same set ofstatements. (This idea can be refined in various ways but that is not the issue here.) This ‘relational’ approach ignoresthat arguments are embedded in a procedural context, in that they can be seen as having been put forward on oneside or the other of an issue during a dialogue between (human and/or artificial) agents. This dialogical context mustbe taken into account when evaluating arguments. The information provided by a dialogue for constructing and eval-uating arguments is richer than just a set of sentences. The context can tell us whether some party has questionedor conceded a statement, or whether a decision has been taken, perhaps by a third party, to accept or reject a claim,taking into consideration the arguments which have been made. Such decisions may be taken at intermediate states ofthe dialogue, for example when some alternatives are eliminated after brainstorming during a deliberation. Moreover,the dialogue context may provide information about the allocation of the burden of proof for each statement. Legalapplications may require the burden of production and burden of persuasion to be handled separately, with a differentresponsible party and applicable proof standard for each [35]. This allocation may well change over the course of thedialogue. In the law of civil procedure, for example, the burden of proof may be allocated to the party who has thebetter access to the evidence. Finally, the proof standard may depend on the phase of the dialogue. For example, aweak proof standard may be appropriate during the brainstorming phase of a deliberation or during the pleading phaseof a legal conflict.The Carneades model has been designed to be applied in such rich dialogical contexts. The evaluation of argumentsin Carneades depends on whether statements have been questioned or decided; the allocation of the burden of proof;and the proof standard applicable to questioned statements. All these elements depend on the stage and context of thedialogue in which the arguments have been put forward.An influential classification of dialogue types is that of Walton and Krabbe [51]. For present purposes their dis-tinction between persuasion and deliberation dialogue is especially relevant. The goal of a deliberation dialogue is tosolve a problem while the goal of a persuasion dialogue is to test whether a claim is acceptable. The present versionof Carneades is meant to support persuasion dialogues. In such dialogues, two or more participants try to resolve adifference of opinion by arguing about the tenability of a claim, each trying to persuade the other participants to adopttheir point of view. Dialogue systems regulate such things as the preconditions and effects of speech acts, includingtheir effects on the commitments of the participants, as well as criteria for terminating the dialogue and determiningits outcome. Good dialogue systems regulate all this in such a way that conflicting viewpoints can be resolved in away that is both fair and effective [24].It is important to note that although Carneades has been designed to be embedded in a procedural context, itdoes not itself define a dialogue protocol. No roles, speech acts, termination criteria, or procedural rules are defined.Instead Carneades is intended to be a reusable component providing services generally needed when specifying suchargumentation protocols.In line with prior AI research, arguments in Carneades are defeasible, i.e., arguments can be defeated by counterar-guments. The Carneades model of defeasible argument is founded on Walton’s theory of argumentation schemes [48].Argumentation schemes express reasoning policies, i.e. conventional patterns of reasoning, and thus are dependent onthe norms of the community. Arguments in Carneades are designed to model instantiations of argumentation schemes.Besides being defeasible, argumentation schemes have a dialogical aspect in that they come with a set of critical ques-tions [20], which enumerate ways of challenging arguments created using the scheme. Critical questions differ withregard to their impact on the burden of proof [3,43]. For some critical questions, merely asking the question is enoughto shift the burden of proof back to the party who put forward the argument to answer the question. For other criticalquestions, the party who raised the question also has the burden of answering it. Carneades models critical questionsas additional premises of an argument, with a different type of premise, called assumptions and exceptions, for eachkind of question.1The Carneades model is the latest result of a research effort that started with the Pleadings Game [14], a com-putational model of civil pleading in Anglo-American Law. Besides a dialogue protocol, the Pleadings Game also1 In an earlier version of Carneades, as reported in [17], assumptions were called ‘presumptions’. This usage however conflicted with the meaningof ‘presumption’ in our main intended application field, the legal domain. In the law, merely questioning a legal presumption is not enough to shiftthe burden of proof to the other party; the burden of proof is on the party interested in rebutting the presumption. For example, the presumption ofinnocence in criminal cases places the burden on the prosecution to prove guilt.\fT.F. Gordon et al. / Artificial Intelligence 171 (2007) 875–896877included a component for evaluating arguments in states of a dialogue. Like Carneades, the status of statements in thedialogue state was taken into account by this evaluation. (Burden of proof and proof standards were not modeled in thePleadings Game.) Whereas statements and arguments were modeled in the Pleadings Game using a specific logicalcalculus, Geffner’s logic of Conditional Entailment [12], Carneades is designed to be an open integration frameworkfor various kinds of argumentation schemes, using whatever kind of knowledge representation is appropriate for eachkind of scheme. Thus, like Dung’s abstract model of argument [8], Carneades does not depend on a particular logicallanguage for expressing statements, inference rules or argumentation schemes.Another ancestor of Carneades is Zeno [15], an argumentation model based on Horst Rittel’s idea of an Issue-BasedInformation System (IBIS) [38]. In IBIS, issues can be raised, ideas to resolve them can be proposed and arguments proand con the various ideas can be put forward. Zeno was intended to be simple enough for use in web-based mediationsystems and targeted to support practical decisions in deliberation dialogues, about what action to take. Later versi",
            {
                "entities": [
                    [
                        3079,
                        3107,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 154 (2004) 1–42www.elsevier.com/locate/artintOptimizing the mutual intelligibility oflinguistic agents in a shared worldNatalia Komarova a,b, Partha Niyogi c,∗a Institute for Advanced Study, Einstein Drive, Princeton, NJ 08540, USAb Department of Applied Mathematics, University of Leeds, Leeds LS2 9JT, UKc Department of Computer Science, University of Chicago, Chicago, IL 60637, USAReceived 4 October 2001; received in revised form 11 May 2003Abstract(cid:2)We consider the problem of linguistic agents that communicate with each other about a sharedworld. We develop a formal notion of a language as a set of probabilistic associations between form(lexical or syntactic) and meaning (semantic) that has general applicability. Using this notion, wedefine a natural measure of the mutual intelligibility, F (L, L(cid:2)), between two agents, one using thelanguage L and the other using L. We then proceed to investigate three important questions withinthis framework: (1) Given a language L, what language L(cid:2)maximizes mutual intelligibility with L?We find surprisingly that L(cid:2)need not be the same as L and we present algorithms for approximatingL(cid:2)arbitrarily well. (2) How can one learn to optimally communicate with a user of language Lwhen L is unknown at the outset and the learner is allowed a finite number of linguistic interactionswith the user of L? We describe possible algorithms and calculate explicit bounds on the numberof interactions needed. (3) Consider a population of linguistic agents that learn from each other andevolve over time. Will the community converge to a shared language and what is the nature of sucha language? We characterize the evolutionarily stable states of a population of linguistic agents in agame-theoretic setting. Our analysis has significance for a number of areas in natural and artificialcommunication where one studies the design, learning, and evolution of linguistic communicationsystems. 2003 Published by Elsevier B.V.Keywords: Linguistic agents; Optimal communication; Language learning; Language evolution; Game theory;Multi-agent systems* Corresponding author.E-mail address: niyogi@cs.uchicago.edu (P. Niyogi).0004-3702/$ – see front matter  2003 Published by Elsevier B.V.doi:10.1016/j.artint.2003.08.005\f2N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–421. IntroductionConsider two linguistic agents in a shared world. The agents desire to communicatedifferent messages (meanings) to each other. Such a situation arises in a number of differentcontexts in natural and artificial communication systems and it is important in such casesto be able to quantify the rate of success in information transfer, in other words, themutual intelligibility of the agents. Each agent possesses a communicative device or alanguage that allows it to relate code (signal) and message, form and meaning, syntax andsemantics, depending upon the context in which the communication arises. If they sharethe same language and this language is expressive enough and unambiguous, then mutualintelligibility will be very high. If on the other hand, they do not share the same language,or the languages are inexpressive or ambiguous, the mutual intelligibility will be muchlower. This is often the case in the real world and in this paper, we present an analysis ofthis situation. We view languages as probabilistic associations between form and meaningand develop a natural measure of intelligibility, F (L1, L2), between two languages, L1 andL2, which is a generalization of a similar function introduced in [10]. We ask the followingquestion: if there is a biological/cultural/technological advantage for an agent to increaseits intelligibility with the rest of the population, what are the ways to do this?The task of increasing intelligibility reduces ultimately to three related sub-problems:• Given a language L, what language L(cid:2) maximizes the mutual intelligibility F (L, L(cid:2))for two way communication about the shared world?• What are some acquisition mechanisms/learning algorithms that can serve the task ofimproving intelligibility?• What are the consequences of individual language acquisition behavior on thepopulation dynamics and the communicative efficiency of an interacting populationof linguistic agents?In this paper, we create a mathematical framework to address these questions analytically.We find, surprisingly, that the optimal language L(cid:2) need not be the same as L, andwe present an algorithm for approximating L(cid:2) arbitrarily well (Section 3). The optimallanguage, L(cid:2), can be either learned or inherited by each individual from its “parents”. In theformer case, we find some bounds on the performance of appropriate learning algorithms(Section 4). In the latter case, we study the resulting population dynamics in the context ofan evolutionary language game (Section 5).1.1. Communicability in animal, human and machine communicationThe simplest situation where communicability is readily defined corresponds to the casewhere the “language” may be viewed as an association matrix, A. Such a matrix simplylinks referents to signals. If there are M referents and N signals, then A is an N × Mmatrix. The entries, aij , define the relative strength of the association between signal iand meaning j . The matrix A thus characterizes the behavior of the linguistic agent in(i) production mode where it may produce any of the signals corresponding to a particularmeaning in proportion to the strength of the association, and in (ii) comprehension mode\fN. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–423where it may interpret a particular signal as any of the meanings in proportion to theassociation strengths.The specific settings in which such a scheme is a useful description include animalcommunication, human languages and artificial languages. For instance, it often makessense to talk about a lexical matrix as a formal description of human mental vocabular-ies. It is introduced to describe the arbitrary relations between discrete words and discreteconcepts of human languages ([10,14,19,26]; also see [36] for a more Bayesian perspec-tive). Each column of the lexical matrix corresponds to a particular word meaning (orconcept), each row corresponds to a particular word form (or word image). In the Saus-surean terminology of arbitrary sign, the lexical matrix provides the link between signifiéand signifiant [28].An equivalent of a lexical matrix is also at the basis of any animal communicationsystem, where it defines the relation between animal signals and their specific meanings [4,8,15,31,32]. A classic example of this is alarm calls in primates. There are a finite numberof referents that are coded using acoustic signals and decoded appropriately by recipients.Infinite association matrices can be used as a description of human languages [13,25].Human grammars mediate a complex mapping between form and meaning. There, thespace of possible signals is the set of all strings (sentences) over a finite syntactic alphabetand the set of possible meanings is the set of all strings over some semantic alphabet. Mostcrucially, the sets of possible sentences and meanings are infinite. This accounts for theinfinite expressibility of human grammars.In artificial intelligence, the problem arises in many different settings. A number ofstudies have emerged where linguistic agents interact with each other in simulated worldsand one studies whether coherent or coordinated communication ultimately emerges (see,for example, [2,12,21–23,33–35]). Much of this kind of research employs the simulationmethodology of Artificial Life. In this paper, we create a mathematical framework forthese kinds of problems and derive a number of analytic results. We also study languagecoordination in a game-theoretic setting and our results have consequences for the Nashequilibria for such problems (for related research on multi-agent systems and game-theoretic foundations, see [1,37] among others).In the design of natural language understanding systems, the goal is to develop acomputer system that is able to communicate with a human. The statistical approachto this problem assumes an underlying probabilistic model for the human source. Thisprobabilistic model is then recovered or learned from data either by randomly drawnsamples as in the case of corpus linguistics or statistical language modeling (see [3] and[16] for overviews of this point of view) or via some interactive exchanges and semanticreinforcement [7,11]. The primary implication of this paper is that optimal communicationwith a language user might require one to learn a language that is different from the targetsource.1.2. Main results in the context of previous workHere we outline the three main sets of results presented, respectively, in Sections 3, 4and 5.\f4N. Komarova, P. Niyogi / Artificial Intelligence 154 (2004) 1–421.2.1. How to maximize the mutual intelligibility?Let us consider a population of agents and assume that each of them has a language. Anevolutionary process can then be described where individuals reproduce and the offspringdo not have an innate language, but acquire a language on the basis of interaction with thepopulation. This process was first explicitly modeled in [10] and later in [23] and [21]. Inthe approach of the latter two works, at each (discrete) moment of time, a randomly chosenindividual is replaced by a new one, which then learns the language of the population; in[10], the generations do not overlap. It is clear that the choice of a learning procedure usedby the offspring will influence the evolutionary dynamics that ensues and, in particular,whether or not the population will converge to (and maintain) a reasonably coherentlanguage.Several basic learning mechanisms have been considered. The “imitator” simply learnsthe averaged language of the population, both in the production and in the comprehensionmo",
            {
                "entities": [
                    [
                        2278,
                        2306,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 619–641www.elsevier.com/locate/artintArgumentation in artificial intelligenceT.J.M. Bench-Capon, Paul E. Dunne ∗Department of Computer Science, University of Liverpool, Liverpool, United KingdomReceived 27 April 2007; received in revised form 27 April 2007; accepted 1 May 2007Available online 10 May 2007AbstractOver the last ten years, argumentation has come to be increasingly central as a core study within Artificial Intelligence (AI). Thearticles forming this volume reflect a variety of important trends, developments, and applications covering a range of current topicsrelating to the theory and applications of argumentation. Our aims in this introduction are, firstly, to place these contributions in thecontext of the historical foundations of argumentation in AI and, subsequently, to discuss a number of themes that have emergedin recent years resulting in a significant broadening of the areas in which argumentation based methods are used. We begin bypresenting a brief overview of the issues of interest within the classical study of argumentation: in particular, its relationship—in terms of both similarities and important differences—to traditional concepts of logical reasoning and mathematical proof. Wecontinue by outlining how a number of foundational contributions provided the basis for the formulation of argumentation modelsand their promotion in AI related settings and then consider a number of new themes that have emerged in recent years, many ofwhich provide the principal topics of the research presented in this volume.© 2007 Elsevier B.V. All rights reserved.Keywords: Argumentation models; Dialogue processes; Argument diagrams and schemes; Agent-based negotiation; Practical reasoning1. IntroductionIn its classical treatment within philosophy, the study of argumentation may, informally, be considered as concernedwith how assertions are proposed, discussed, and resolved in the context of issues upon which several divergingopinions may be held. Thus philosophical investigations of argumentation, from Aristotle to the present day, haveaddressed such themes as: the mechanisms by which “legitimate” argumentation in support of a claim may be dis-tinguished from “flawed” argumentation; analyses of the typical structures that constitute argument components andargumentation development; the processes by which participants engaging in debate may advance their respectivepositions and undermine contrary stances and arguments, etc; and the contexts in which these questions are decided.The importance of such philosophical theories to so-called everyday reasoning has a long and distinguished historyin AI, and contributions from contemporary philosophical analyses continue to play a major role in the evolution ofeffective computational exploitation of argumentation technology.Within the simplified overview of argumentation outlined in the preceding paragraph, one can, already, identify anumber of themes whose elements embody issues of a computational nature in the following:* Corresponding author.E-mail address: ped@csc.liv.ac.uk (P.E. Dunne).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.001\f620T.J.M. Bench-Capon, P.E. Dunne / Artificial Intelligence 171 (2007) 619–641• Defining the component parts of an argument and their interaction.• Identifying rules and protocols describing argumentation processes.• Distinguishing legitimate from invalid arguments.• Determining conditions under which further discussion is redundant.It is, of course, the case that similar issues underpin one well-established and highly-developed theory: that of formallogic and mathematical proof. It is no coincidence that much of the formal computational treatment of argumentationhas its roots in ideas developed from AI inspired contributions to logic and deductive reasoning. So one finds inmathematical proof theory core concepts such as: precisely defined means for expressing assertions (e.g. formulaein a given logical language); accepted bases on which to build theorems (e.g. collections of axioms); proceduresprescribing the means by which further theorems may be derived from existing theorems and axioms (e.g. templatesfor inference rules); and precise concepts of termination (e.g. a sentential form is derivable as a theorem, “true”; or islogically invalid, “false”).While the structural elements presented in this view of mathematical reasoning have proven to be a useful basis inthe development of argumentation-based models in AI, the formal apparatus and methods of mathematical reasoningare, ultimately, radically different in nature to those of importance when considering the concept of argumentationas it is familiar from everyday contexts, e.g. as it might occur in political debate, the discussion of ethical principles,deliberation in judicial settings, etc. While there are, of course, parallels that can be made,—e.g. that those engagedin debate have some collection of accepted premises on which there is agreement, possibly, even, some recognition ofwhen contributions to a discussion are “unreasonable” or flawed, etc.—there are, however, a number of fundamentaldistinctions between the concepts “P is a formal proof that T holds” and “P is a persuasive argument for accepting T ”.Thus, in mathematical reasoning,(a) The premises can, ultimately, be explicitly defined in terms of closed concepts, e.g. the axioms of Euclideangeometry, the Zermelo–Frankel basis for set theory (ZF). Furthermore classical mathematical reasoning is basedon an assumption that such premises are, collectively, consistent.1(b) Reasoning and analysis takes place within a closed, tightly defined context, i.e. there is no notion of “incomplete”or “uncertain” information.(c) Conclusions are final and definite: if P is a correct proof that T , then T is, ipso facto valid and this status doesnot admit subsequent qualification or amendment, let alone retraction.(d) Reasoning and conclusions are entirely objective, not susceptible to rational dispute on the basis of subjectiveviews and prejudices.2 Proof is demonstration whereas argument is persuasion.In argument and discussion as encountered in everyday contexts, it is rare that any, let alone all, of these apply:the premises upon which debates may build are often presupposed as forming part of the background assumptionscommon to all parties involved; the information and knowledge brought to bear in the course of discussion willoften be incomplete, vague, or uncertain. The remaining two aspects, in many ways, highlight the most significantdifferences between “logical proof” and “persuasive argument”. Arguments are defeasible: the reasoning that formeda persuasive case for T , in the light of changes in viewpoint or awareness of information not previously available, maysubsequently fail to convince. This defeasibility is never removed: an argument may cease to be challenged and soaccepted, but the possibility of challenge remains. Finally, the extent to which an argued case is accepted is subjective,dependent on the views, attitudes, and prejudices of the audiences to which it is directed. The same case may convincesome people but, equally, fail to convince others.1 We note that in a number of systems, consistency cannot be formally proven, cf. [95] and so, in such cases, consistency is, indeed, an assumption.2 Some clarification of this claim may be in order. Suppose (cid:2) is a derivation of ϕ within a theory (cid:3)A, R(cid:4) (with axioms A and inference rules R).Within the same theory, the proof (cid:2) admits no rational, objective basis for dispute: criticisms that “ϕ is ‘inconvenient’ or ‘counter-intuitive’ ” aresubjective, and entirely irrelevant to the status of ϕ within the theory (cid:3)A, R(cid:4). In order to give rational grounds for not accepting ϕ it is necessary toendorse an alternative theory within which ϕ cannot be derived. As a concrete example, consider the axiomatic basis ZF extended by the so-called“Axiom of Choice” (ZF + AC): although widely adopted in modern theory this conflicts with Intuitionist principles which disqualify AC as an axiomso that theorems dependent on AC are (rationally) not accepted by Intuitionists.\fT.J.M. Bench-Capon, P.E. Dunne / Artificial Intelligence 171 (2007) 619–641621One can summarise the distinction between argumentation and proof by the observation that the object of argu-mentation is to persuade (to acceptance of a given claim; to performance of a desired action, and so on). Unlike theconcept of “proof”—at the level of deriving a sentential representation of an assertion—whether an argument is “cor-rect” is not a factor, and, indeed, “correctness” may not even be sensibly defined. In contrast, mathematical reasoning,in order to have any value, must be correct where “correctness” has a strict, formal definition: beyond this requirement,however, notions of “persuasiveness” are unimportant.In summary, the importation of elements from logic and formal deductive reasoning has provided a powerful basisfor modelling and analysing argumentation in computational settings of AI. As we shall discuss later, these continueto form an important strand of contemporary work. It is also the case, however, that a number of significant direc-tions pursued in recent years, have broadened the scope and concerns of argumentation in AI beyond this earlierlogic driven motivation. As a consequence, one has a shift of emphasis within the developed treatment of argumen-tation in AI progressing from formalisms rooted in classical deductive reasoning through models handling conceptsof incomplete information and uncertainty, to precise semantics for capturing defeasibility, and, within recent work,propounding computational bases to account for subjective aspects of argumentation, often using the notion of “au-dience” introduced by Perelman [145]. One consequence of such analyses has been the growth of work dealing w",
            {
                "entities": [
                    [
                        3202,
                        3230,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 240–257Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA comparative runtime analysis of heuristic algorithms forsatisfiability problemsYuren Zhou a,c,∗, Jun He b, Qing Nie ca School of Computer Science and Engineering, South China University of Technology, Guangzhou 510640, Chinab Department of Computer Science, University of Wales, Aberystwyth, Ceredigion, SY23 3DB, UKc Department of Mathematics, University of California, Irvine, CA 92697-3875, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 18 March 2008Received in revised form 23 July 2008Accepted 1 November 2008Available online 7 November 2008Keywords:Boolean satisfiabilityHeuristic algorithmsRandom walk(1 + 1) EAHybrid algorithmExpected first hitting timeRuntime analysis1. IntroductionThe satisfiability problem is a basic core NP-complete problem. In recent years, a lot ofheuristic algorithms have been developed to solve this problem, and many experimentshave evaluated and compared the performance of different heuristic algorithms. However,rigorous theoretical analysis and comparison are rare. This paper analyzes and comparesthe expected runtime of three basic heuristic algorithms: RandomWalk, (1 + 1) EA,and hybrid algorithm. The runtime analysis of these heuristic algorithms on two 2-SATinstances shows that the expected runtime of these heuristic algorithms can be exponentialtime or polynomial time. Furthermore, these heuristic algorithms have their own advan-tages and disadvantages in solving different SAT instances. It also demonstrates that theexpected runtime upper bound of RandomWalk on arbitrary k-SAT (k (cid:2) 3) is O ((k − 1)n),and presents a k-SAT instance that has (cid:2)((k − 1)n) expected runtime bound.© 2008 Elsevier B.V. All rights reserved.The satisfiability problem (SAT) of a propositional formula plays a central role in computer science and artificial intelli-gence. It is the first proposed NP-complete problem [5,21] and one of the basic core NP-complete problems [10]. In additionto its theoretical importance, the SAT problem is also directly applied in VLSI formal verification, software automation, andso on.Researchers have been trying to look for an effective algorithm for the SAT problem. Since the SAT problem is an NP-complete problem in nature, a polynomial algorithm is not currently available to solve it, although we cannot prove thatsuch an algorithm does not exist. In fact, a basic conjecture of modern computer science and mathematics is that nopolynomial algorithm exists for NP-complete problems. At present, the main methods for solving the SAT problems arecomplete algorithms [3,6,34] and incomplete algorithms [7,12,13,15,20,25,27,29,31,32]. There are several very successfulcomplete algorithms (e.g., SATO [34]). A complete algorithm often explores the whole search space and can always de-termine whether a given propositional formula is satisfiable or not; however, its time complexity is usually exponential.An incomplete algorithm does not carry out a complete search on the search space; instead, it often explores some partof the search space using heuristic information within a limited time; however it does not give the correct answer withcertainty.Since the 1990s, the use of incomplete algorithm for solving the SAT problem has grown quickly. The basic incom-plete heuristic methods are RandomWalk algorithm [25], GSAT algorithm [13,31], WalkSat algorithm [32], UnitWalk [15],* Corresponding author at: School of Computer Science and Engineering, South China University of Technology, Guangzhou 510640, China.E-mail addresses: yrzhou@scut.edu.cn (Y. Zhou), jun.he@ieee.org (J. He), qnie@math.uci.edu (Q. Nie).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.002\fY. Zhou et al. / Artificial Intelligence 173 (2009) 240–257241population-search-based evolutionary algorithms [7,12,20] and so on. In recent years, some powerful concepts and tech-niques of statistical physics have been applied to the SAT problem. One of these incomplete algorithms, known as “surveypropagation” [4,22], which is based on statistical physics methods, shows good performance on some difficult randomlygenerated SAT instances. It is well known that one of the earliest applications of statistical physics in the optimization prob-lem is the simulated annealing algorithm [19]. WalkSat [32] used a probability selection mechanism similar to that of thesimulated annealing algorithm.For some heuristic algorithms for the SAT problem, theoretical results about computational complexities have been ob-tained to some extent. Papadimitiou [25] was the first to prove that the average time upper bound of RandomWalk for2-SAT is O (n2). Schöning [29] presented a restarting local-search algorithm to show that, for any satisfiable k-CNF formulawith n variables, the algorithm has to repeat O ((2(1 − 1k ))n) times, on average, to find a satisfying assignment. Specially ifk = 3, the average time is O (1.334n) (the upper bound of an exhaustive search is O (2n)). There have been several improve-ments on the upper bound by hybrid algorithms based on randomized algorithms by Paturi et al. [27] and Schöning [29],e.g. O (1.324n) [18] and O (1.322n) [28]. Alekhnovich et al. [2] proved that, when the clause density is less than 1.63, theaverage time complexity of RandomWalk for 3-SAT is linear.Since there are many incomplete heuristic algorithms for SAT problems, comparing and understanding the workingprincipals of these heuristic algorithms is useful. The first thing we have to accept is that no one algorithm beats all otheralgorithms on all problems. There have been many numerical experiments that compared various heuristic algorithms onSAT problems, but theoretical study has been rare. This paper analyzes and compares the expected running time of threebasic heuristic algorithms: RandomWalk, (1 + 1) EA, and hybrid algorithm. We use absorbing Markov chains to model searchprocesses of these heuristic algorithms, and use explicit expressions of the first hitting time of a Markov chain to analyzeand estimate their expected runtime. Through runtime analysis of three SAT instances, we show that the expected runtimeof these heuristic algorithms can be exponential or polynomial. We also find that these heuristic algorithms have their owncomparative advantage under different circumstances.The rest of this paper is organized as follows. Section 2 introduces the concepts of the SAT problem, some heuristicalgorithms for the SAT problem, and the first hitting time of an absorbing Markov chain. Section 3 discusses the worst-case bound and the worst-case example on RandomWalk. Section 4 analyzes and compares the expected runtime boundsof three heuristic algorithms on two 2-SAT instances. Section 5 presents our conclusions and suggestions for further re-search.2. Heuristic algorithms for satisfiability and the first hitting time of the Markov chain2.1. The SAT problemWe begin by stating some definitions and notations that will be used throughout the paper.In Boolean logic, a literal is a variable or its negation, and a clause is a disjunction of literals. The formula f = c1 ∧ c2 ∧· · · ∧ cm is in k conjunctive normal form (k-CNF) if it is a conjunction of clauses with each clause as a disjunction of at mostk literals. We view a CNF Boolean formula as both a Boolean function and a set of clauses. Satisfiability is the problem ofdetermining whether the variables of a given Boolean formula can be assigned truth values in such a way as to make theformula evaluate to true.SAT is originally stated as a decision problem. In this paper we consider the more general MaxSAT, so, our goal is to lookfor an assignment that satisfies the maximum number of clauses.Evolutionary algorithms (EAs) are the heuristic algorithms that have been applied to SAT and to many other NP-completeproblems. EAs usually use a fitness value to guide the search process. In the MaxSAT formulation, the fitness value is definedas the number of satisfied clauses, i.e.fit(x) = c1(x) + c2(x) + · · · + cm(x)(1)where ci(x) (1 (cid:2) i (cid:2) m) represents the true value of the ith clause. This fitness function is used in most EAs for SATproblems.Throughout this paper, for x = (x1 · · · xn), y = ( y1 · · · yn) ∈ {0, 1}n, we denote by H(x, y) the Hamming distance between|xi − yi|. We also denote |x| = x1 + · · · + xn, and let S i = {x | x ∈ S = {0, 1}n, |x| = i}(cid:2)ni=1two points x and y, i.e. H(x, y) =(i = 0, 1, . . . , n) be a partition of search space S = {0, 1}n.2.2. Heuristic algorithms for the SAT problemRandomWalk, first introduced by Papadimitiou [25], is one of the most basic incomplete algorithms, and many otherheuristics have been developed based on the improvement of this algorithm, e.g. the Walk-SAT [32], combines RandomWalkwith a greed bias towards assignments that satisfy more clauses. RandomWalk algorithm first randomly selects a clause thatis not satisfied with the CNF, then randomly selects a flip in the clause (see Algorithm 1).\f242Y. Zhou et al. / Artificial Intelligence 173 (2009) 240–257Algorithm 1 (The RandomWalk algorithm).begininitialization: Select an initial bit string x at random;while (termination-condition does not hold) doSelect c := an unsatisfied clause chosen at random;Select xi := a variable in c chosen at random;Flip the value of xi ;odendEvolutionary algorithms are inspired from modeling the processes of natural selection and genetic evolution. Here weconsider a simple EA using mutation and selection approaches with population size of 1 denoted as (1 + 1) EA [9]. (1 + 1)EA is a simple but effective random hill-climbing EA. Its general description is:Algorithm 2 ((1 + 1) EA).begininitialization: Choose randomly an initial bit string x;while (termination-condition does not hold) doMutation: y := mutate(x);Selection: If fitness( y) >fitness(x), x := y;odend(1 + 1) EA gene",
            {
                "entities": [
                    [
                        3824,
                        3852,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 6–29Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMiningZinc: A declarative framework for constraint-based miningTias Guns a,∗a Department of Computer Science, KU Leuven, Belgiumb LIACS, Universiteit Leiden, Netherlandsc Faculty of IT, Monash University, National ICT Australia (NICTA), Australia, Anton Dries a, Siegfried Nijssen a,b, Guido Tack c, Luc De Raedt aa r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 17 September 2015Accepted 20 September 2015Available online 26 September 2015Keywords:Constraint-based miningItemset miningConstraint programmingDeclarative modelingPattern miningWe introduce MiningZinc, a declarative framework for constraint-based data mining. MiningZinc consists of two key components: a language component and an execution mechanism.First, the MiningZinc language allows for high-level and natural modeling of mining problems, so that MiningZinc models are similar to the mathematical definitions used in the literature. It is inspired by the Zinc family of languages and systems and supports user-defined constraints and functions.Secondly, the MiningZinc execution mechanism specifies how to compute solutions for the models. It is solver independent and supports both standard constraint solvers and specialized data mining systems. The high-level problem specification is first translated into a normalized constraint language (FlatZinc). Rewrite rules are then used to add redundant constraints or solve subproblems using specialized data mining algorithms or generic constraint programming solvers. Given a model, different execution strategies are automatically extracted that correspond to different sequences of algorithms to run. Optimized data mining algorithms, specialized processing routines and generic solvers can all be automatically combined.Thus, the MiningZinc language allows one to model constraint-based itemset mining problems in a solver independent way, and its execution mechanism can automatically chain different algorithms and solvers. This leads to a unique combination of declarative modeling with high-performance solving.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe fields of data mining and constraint programming are amongst the most successful subfields of artificial intelligence. Significant progress in the past few years has resulted in important theoretical insights as well as the development of effec-tive algorithms, techniques, and systems that have enabled numerous applications in science, society, as well as industry. In recent years, there has been an increased interest in approaches that combine or integrate principles of these two fields [1]. This paper intends to contribute towards bridging this gap.* Corresponding author.(S. Nijssen), guido.tack@monash.edu (G. Tack), luc.deraedt@cs.kuleuven.be (L. De Raedt).E-mail addresses: tias.guns@cs.kuleuven.be (T. Guns), anton.dries@cs.kuleuven.be (A. Dries), siegfried.nijssen@cs.kuleuven.be, s.nijssen@liacs.leidenuniv.nlhttp://dx.doi.org/10.1016/j.artint.2015.09.0070004-3702/© 2015 Elsevier B.V. All rights reserved.\fT. Guns et al. / Artificial Intelligence 244 (2017) 6–297It is motivated by the observation that the methodologies of constraint programming and data mining are quite dif-ferent. Constraint programming has focused on a declarative modeling and solving approach of constraint satisfaction and optimization problems. Here, a problem is specified through a so-called model consisting of the variables of interest and the possible values they can take, the constraints that need to be satisfied, and possibly an optimization function. Solutions are then computed using a general purpose solver on the model. Thus the user specifies what the problem is and the constraint programming system determines how to solve the problem. This can be summarized by the slogan constraint programming = model + solver(s).The declarative constraint programming approach contrasts with the typical procedural approach to data mining. The latter has focused on handling large and complex datasets that arise in particular applications, often focusing on special-purpose algorithms to specific problems. This typically yields complex code that is not only hard to develop but also to reuse in other applications. Data mining has devoted less attention than constraint programming to the issue of general and generic solution strategies. Today, there is only little support for formalizing a mining task and capturing a problem specification in a declarative way. Developing and implementing the algorithms is labor intensive with only limited re-use of software. The typical iterative nature of the knowledge-discovery cycle [2] further complicates this process, as the problem specification may change between iterations, which may in turn require changes to the algorithms.The aim of this paper is to contribute to bridging the methodological gap between the fields of data mining and con-straint programming by applying the model + solver approach to data mining.In constraint programming, high-level languages such as Zinc [3], Essence [4] and OPL [5] are used to model the problem while general purpose solvers are used to compute the solutions. Motivated in particular by solver-independent modeling languages, we devise a modeling language for data mining problems that can be expressed as constraint satisfaction or optimization problems. Furthermore, we contribute an accompanying framework that can infer efficient execution strategies involving both specialized mining systems, and generic constraint solvers. This should contribute to making data mining approaches more flexible and declarative, as it becomes easy to change the model and to reuse existing algorithms and solvers.As the field of data mining is diverse, we focus in this paper on one of the most popular tasks, namely, constraint-based pattern mining. Even for the restricted data type of sets and binary databases, many settings (supervised and unsuper-vised) and corresponding systems have been proposed in the literature; this makes itemset mining an ideal showcase for a declarative approach to data mining.The key contribution of this paper is the introduction of a general-purpose, declarative mining framework called Min-ingZinc. The design criteria for MiningZinc are:• to support the high-level and natural modeling of pattern mining tasks; that is, MiningZinc models should closely corre-spond to the definitions of data mining problems found in the literature;• to support user-defined constraints and criteria such that common elements and building blocks can be abstracted away, easing the formulation of existing problems and variations thereof;• to be solver-independent, such that the best execution strategy can be selected for the problem and data at hand. Supported methods should include both general purpose solvers, specialized efficient mining algorithms and combinations thereof;• to build on and extend existing constraint programming and data mining techniques, capitalizing on and extending the state-of-the-art in these fields.In data mining, to date there is no other framework that supports these four design criteria. Especially the combination of user-defined constraints and solver-independence is uncommon (we defer a detailed discussion of related work to Section 6). In the constraint programming community, however, the design of the Zinc [3,6] family of languages and frameworks is in line with the above criteria. The main question that we answer in this paper is hence how to extend this framework to support constraint-based pattern mining.We contribute:1. a novel library of functions and constraints in the MiniZinc language, to support modeling itemset mining tasks in terms of set operations and constraints;2. the ability to define the capabilities of generic solvers and specialized algorithms in terms of constraints, where the latter can solve a predefined combination of constraints over input and output variables;3. a rewrite mechanism that can be used to add redundant constraints and determine the applicability of the defined algorithms and solvers;4. and automatic composition of execution strategies involving multiple such specialized or generic solving methods.The language used is MiniZinc [7] version 2.0, extended with a library of functions and constraints tailored for pattern mining. The execution mechanism, however, is much more elaborate than that of standard MiniZinc. For a specific constraint solver, it will translate each constraint individually to a constraint supported by said solver. Our method can automatically compose execution strategies with multiple solvers.\f8T. Guns et al. / Artificial Intelligence 244 (2017) 6–29The MiningZinc framework builds on our earlier CP4IM framework [8], which showed the feasibility of constraint pro-gramming for pattern mining. This work started from the modeling experience obtained with CP4IM, but the latter contained none of the above contributions as it was tied to the Gecode solver and consisted of a low-level encoding of the constraints.The present paper extends our earlier publication on MiningZinc [9] in many respects. It considers the modeling and solving of a wider range of data mining tasks including numeric and probabilistic data, multiple databases and pattern sets. The biggest change is in the execution mechanism, which is no longer restricted to using a single algorithm or generic solver. Instead, it uses rewrite rules to automatically construct execution plans consisting of multiple solver/algorithm components. We also perform a more elaborate evaluation, including a comparison of automatically composed execution strategies on a novel combination of tasks.Structure of the text Section 2 introduces modeling in MiningZinc using the basic problem of frequent itemset mining. Section 3 illustrates how a wide range of c",
            {
                "entities": [
                    [
                        3101,
                        3129,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1093–1141Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLogic-based ontology comparison and module extraction,with an application to DL-LiteRoman Kontchakov a,∗, Frank Wolter b, Michael Zakharyaschev aa Department of Computer Science and Information Systems, Birkbeck College London, UKb Department of Computer Science, University of Liverpool, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 31 July 2009Received in revised form 30 April 2010Accepted 17 June 2010Available online 23 June 2010Keywords:Description logicOntologyModule extractionEntailmentComputational complexityUniform interpolationForgettingWe develop a formalframework for comparing different versions of ontologies, andapply it to ontologies formulated in terms of DL-Lite, a family of ‘lightweight’ descriptionlogics designed for data-intensive applications. The main feature of our approach is thatwe take into account the vocabulary (= signature) with respect to which one wantsto compare ontologies. Five variants of difference and inseparability relations betweenontologies are introduced and their respective applications for ontology developmentand maintenance discussed. These variants are obtained by generalising the notion ofconservative extension from mathematical logic and by distinguishing between differencesthat can be observed among concept inclusions, answers to queries over ABoxes, by takinginto account additional context ontologies, and by considering a model-theoretic, language-independent notion of difference. We compare these variants, study their meta-properties,determine the computational complexity of the corresponding reasoning tasks, and presentdecision algorithms. Moreover, we show that checking inseparability can be automatedby means of encoding into QBF satisfiability and using off-the-shelf general purpose QBFsolvers.Inseparability relations between ontologies are then used to develop a formal frameworkfor (minimal) module extraction. We demonstrate that different types of minimal modulesinduced by these inseparability relations can be automatically extracted from real-worldmedium-size DL-Lite ontologies by composing the known tractable syntactic locality-basedmodule extraction algorithm with our non-tractable extraction algorithms and using themulti-engine QBF solver aqme. Finally, we explore the relationship between uniforminterpolation (or forgetting) and inseparability.© 2010 Elsevier B.V. All rights reserved.1. IntroductionIn computer science, ontologies are used to provide a common vocabulary (or, in logic parlance, signature) for a domainof interest, together with a description of certain relationships between terms built from the vocabulary. Ontology languagesbased on description logics represent ontologies as ‘TBoxes’ (terminological boxes) containing inclusions between complexconcepts over the vocabulary [2]. An increasingly important application of ontologies is management of large amounts ofdata, where ontologies are used to provide flexible and efficient access to repositories consisting of data sets of instances ofconcepts and relations. In description logics, such repositories are typically modelled as ‘ABoxes’ (assertion boxes) [2].* Corresponding author.E-mail addresses: roman@dcs.bbk.ac.uk (R. Kontchakov), frank@csc.liv.ac.uk (F. Wolter), michael@dcs.bbk.ac.uk (M. Zakharyaschev).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.06.003\f1094R. Kontchakov et al. / Artificial Intelligence 174 (2010) 1093–1141Developing and maintaining ontologies for this and other purposes is a rather difficult task. When using description logics(including the description logic based dialects of the Web Ontology Language OWL1), the ontology designer is supported byefficient reasoning tools for classification, instance checking and a variety of other reasoning tasks. However, this support isgenerally recognised to be insufficient when ontologies are developed not as ‘monolithic entities’ but by means of importing,merging, combining, refining and extending already existing ontologies. In all those cases, reasoning support for analysingthe impact of the respective operation on the ontology would be extremely useful. Typical examples of such ‘unorthodox’reasoning services include the following:Comparing versions of ontologies. The standard syntactic diff utility is an indispensable tool for comparing differentversions of text files, and it would be very helpful to have a similar versioning tool for ontologies. However,a purely syntactic operation of computing the difference between ontologies is of little value [3] because ourconcern now is not the syntactic form of the ontologies, but their differing logical consequences. Moreover, insteadof comparing arbitrary logical consequences, it is more useful and informative to compare logical consequencesover the common vocabulary Σ of the versions, or even such consequences regarding a certain subject mattercorresponding to some subvocabulary of Σ . Thus, the reasoning service we need in this case should be able tocompare the logical consequences of different versions of ontologies over some vocabulary Σ .Ontology refinement. When refining an ontology by adding new axioms, one usually wants to preserve the relationshipsbetween terms of a certain part Σ of its vocabulary. The reasoning service required in such a case is to checkwhether the refined ontology has precisely the same logical consequences over Σ as the original one.Ontology re-use. When importing an ontology, one wants to use its vocabulary Σ as originally defined. However, relation-ships between terms over Σ may change due to interaction with some axioms in the importing ontology. So againwe need a reasoning service capable of checking whether new logical consequences over Σ are derivable (thisservice has been termed safety checking in [4]).In all these and many other cases, we are interested in comparing logical consequences over some vocabulary Σ that canbe drawn from two different ontologies. This gives rise to the three main notions we investigate in this paper: Σ -difference,Σ -entailment, and Σ -inseparability. Roughly, the Σ -difference between two ontologies is the set of ‘formulas’ over Σ thatare derivable from one ontology but not from the other; one ontology Σ -entails another one if all Σ -formulas derivablefrom the latter are also derivable from the former; and two ontologies are Σ -inseparable if they Σ -entail each other.In the discussion so far, we have not specified the language from which the logical consequences over Σ are drawn. Thislanguage depends on the application. For example, if one is mainly interested in terminological reasoning and differencesvisible in applications that use relationships between concepts, then an appropriate language is the set of all conceptinclusions. The Σ -difference then consists of all concept inclusions over Σ derivable from one ontology but not from theother. And one ontology Σ -entails another ontology if every concept inclusion over Σ derivable from the latter is derivablefrom the former. If, however, one is mainly interested in using ontologies to query instance data, then it is more appropriateto consider a language for consequences over Σ that reflects, in some way, answers to queries in the signature Σ (or Σ -queries) over instance data in Σ . In this case, two ontologies should be Σ -inseparable if, and only if, they give the sameanswers to every Σ -query in the chosen language for any instance data over Σ . Even this language may be insufficientfor applications where different versions of ontologies are imported into a context ontology, in which case two ontologiesshould be deemed Σ -inseparable only if after importing them into another ontology over Σ , the resulting extensions stillgive the same answers to Σ -queries.The first aim of this paper is to give precise formalisations of five variants of Σ -difference, Σ -entailment and Σ -insepa-NNhorn. These variants of Σ -difference and Σ -entailmentbool and DL-Literability for ontologies given in the DL-Lite logics DL-Liteare obtained by distinguishing between differences visible among concept inclusions, answers to queries over ABoxes, bytaking additional context ontologies into account, and by considering model-theoretic, language-independent notions ofΣ -difference and Σ -entailment.The DL-Lite family of description logics [5–8] has been originally designed with the aim of providing query access to largeamounts of data via a high-level conceptual (ontological) interface. Thus, the DL-Lite logics result from various compromisesbetween (i) the necessity of retaining the data complexity of query answering as close as possible to the complexity ofstandard database query evaluation and (ii) the desire of having the expressive means for representing various constraintsNbool [10]of data modelling formalisms such as the ER model and UML class diagrams [9]. For example, the logic DL-Lite(containing many other DL-Lite logics) can express is-a hierarchies of concepts, disjointness and covering constraints forNbool is in AC0 forconcepts, and domain, range and cardinality constraints for binary relations. Instance checking in DL-Litedata complexity (i.e., of the same complexity as database query evaluation); however, answering conjunctive queries isNhorn cannot express covering constraints, but boasts AC0 query answering (undercoNP-complete. On the other hand, DL-Litethe unique name assumption) [11]. To simplify presentation, in this paper we do not consider DL-Lite logics with roleinclusions, focusing mainly on the impact of the Boolean constructs in concept inclusions as well as number restrictions.1 http://www.w3.org/2007/OWL/.\fR. Kontchakov et al. / Artificial Intelligence 174 (2010) 1093–11411095We also note that the DL-Lite family forms the basis of OWL 2 QL, one of the three profi",
            {
                "entities": [
                    [
                        3511,
                        3539,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1307–1322Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic-based axiomatic model of bargainingDongmo ZhangIntelligent Systems Laboratory, School of Computing and Mathematics, University of Western Sydney, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 4 October 2009Received in revised form 4 August 2010Accepted 5 August 2010Available online 12 August 2010Keywords:Bargaining solutionAxiomatic model of bargainingLogical model of negotiationOrdinal bargainingGame theory1. IntroductionThis paper introduces an axiomatic model for bargaining analysis. We describe a bargainingsituation in propositional logic and represent bargainers’ preferences in total pre-orders.Based on the concept of minimal simultaneous concessions, we propose a solution ton-person bargaining problems and prove that the solution is uniquely characterizedby five logical axioms: Consistency, Comprehensiveness, Collective rationality, Disagreement,and Contraction independence. This framework provides a naive solution to multi-person,multi-issue bargaining problems in discrete domains. Although the solution is purelyqualitative, it can also be applied to continuous bargaining problems through a procedureof discretization, in which case the solution coincides with the Kalai–Smorodinsky solution.© 2010 Elsevier B.V. All rights reserved.As one of the most fundamental models in modern economic theory, the Nash bargaining solution [23] has been de-veloped into a highly sophisticated theory with extensive applications in economics, social science, political science andmanagement science [1,13,23,24,26,40,42]. Computer scientists, especially researchers in the area of artificial intelligence(AI), have found it useful in modeling interactions among distributed computer systems and autonomous software agentssince the early 90s [12,17,30,38]. Many applications have been developed for the design and evaluation of high-level inter-action protocols among autonomous agents for task assignment, resource allocation, conflict resolution, electronic tradingand web services [16,27,30,41,48].Traditionally, a bargaining situation is modeled as a numerical game, using the language of utility. In his seminal paper,Nash [23] defined a bargaining situation as a pair (S, d), where S ⊆ (cid:3)2 represents the set of utility pairs that can be derivedfrom possible agreements and d ∈ S is the utility pair that follows disagreement.1 A solution is a rule that associates toeach bargaining situation (S, d) a feasible utility pair of S. Nash proposed a set of axioms that he thought a solution shouldsatisfy and established the existence of a unique solution satisfying all the axioms [23]. Numerous extensions and alternativesolutions have been proposed in the past sixty years after this first axiomatic model of bargaining [42]. The subsequentwork has diverged in two different directions: the cooperative models and the non-cooperative models. The former, followingNash’s approach and thus also called axiomatic models, provide an axiomatic characterization of bargaining solutions [23,42].A bargaining problem is modelled as a one-shot game and solutions are characterized by a set of axioms, such as Paretooptimality, Symmetry, and so on. The non-cooperative models, also called strategic models, establish explicit constructions ofnegotiation procedures and identify the bargaining outcome as an equilibrium [1]. The attempt to establish the relationshipbetween the two models is known as the Nash program [1,24].The Nash bargaining model provides simple and mathematically elegant solutions to bargaining problems and facilitatesquantitative analysis of bargaining situations. However, in many real-world bargaining situations, the utility of a bargainerE-mail address: d.zhang@uws.edu.au.1 (cid:3)2 represents 2-dimensional real Euclidean space.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.08.003\f1308D. Zhang / Artificial Intelligence 174 (2010) 1307–1322cannot be measured using a numeric scale, therefore the solutions that are built on the Nash model become inapplicable.2Examples of such bargaining situations can be easily found in political/legal negotiations, household bargaining, labor dis-putes and so on. For instance, it is difficult to imagine an analysis of the Six-Party Talks on North Korea’s Nuclear Programthat is based on a numerical measure of each party’s utility gains or losses from the negotiations.3An alternative method of bargaining analysis, initially suggested by Shapley and Shubik, is modeling a bargaining situa-tion in terms of bargainers’ preference orderings over possible agreements [40, p. 91]. Formally, a bargaining situation canbe represented as a tuple ( A, D, (cid:2)1, (cid:2)2), where A is a set of possible agreements (described in physical terms), D is thedisagreement, and (cid:2)1 and (cid:2)2 are preference orderings over A ∪ {D}. The interpretation is that a (cid:2)i b if and only if player ieither prefers a to b or is indifferent [26, p. 9]. This allows us to assess a bargainer’s utility through pairwise comparisonsamong the possible agreements instead of quantitative measurement. Such a model of bargaining problems is called anordinal bargaining model. A bargaining solution is ordinal if it can be built on an ordinal bargaining model. We would liketo remark that a bargaining solution built on the Nash bargaining model can also be ordinal as long as it is invariant un-der any order-preserving transformations of utilities (ordinal invariance) because such a solution can be expressed in anordinal model [31]. Therefore the judgement of whether a solution is ordinal or cardinal is not by the use of numbers butits structure. In fact, most of the existing work on ordinal bargaining solutions in the literature was built on numericalmodels [3,25,35,37].The ordinal bargaining models are of interest because ordinal information is relatively easier to obtain than cardinal util-ities [36]. Asked if they prefer coffee or tea, anyone can provide a preference. However, if asked to value their preference incardinal scale, they would find it difficult [8]. Nevertheless, Shapley observed that there is no non-trivial ordinal bargainingsolution to two-player bargaining problems [39].4 The reason is, as pointed out by many researchers, that the informationabout bargainers’ attitudes towards risk, which in fact determines the negotiation power of a bargainer, is not describable byordinal preferences [26,31,40].5 With the Nash bargaining model, bargainers’ risk attitudes, combined with the preferenceson the possible agreements, are represented by utility scales, i.e., cardinal utility, through the non-linearity or curvature ofutility functions (for an intuitive example see [44]). However, such information is lost when the model is converted to anordinal model through an order-preserving transformation. Therefore the information about bargainers’ risk attitudes is lost.This suggests that additional components have to be introduced to the ordinal bargaining models to express bargainers’ riskattitudes.Rubinstein et al. introduced a variation of the ordinal bargaining model in which the preference ordering of each playeris extended to the space of lotteries over the possible agreements and the disagreement [33]. A player can express herattitudes towards risk through her preference on the lotteries. However, an ordinal preference on the lotteries is by nomeans easier to elicit than the utility scales on the possible agreements because the space of lotteries is also a continuum.More recently, O’Neill et al. introduced an ordinal bargaining solution based on the idea of gradual bargaining [25]. Instead ofmodeling a bargaining problem as a one-shot game, they look at bargaining as a family of bargaining games, parameterizedby time. The bargaining outcome can then be viewed as the limit of a step-by-step bargaining in which the agreementof the last negotiation becomes the disagreement point for the next. Players’ risk attitudes can then be observed throughthe variations of their utilities over time. However, there is no explicit representation of players’ attitudes towards risk.Zhang and Zhang proposed a purely qualitative model of bargaining based on bargainers’ ordinal preferences [44]. Similarto but different from Rubinstein et al.’s framework, the preference ordering of each player is defined on the player’s demanditems (instead of the lotteries of possible agreements). More precisely, the physical demands of each player are expressedby logical statements. A possible agreement is a logically consistent set of demands from each player. The risk attitudes ofa player are represented based on a relative ranking of the player’s demands: a risk-lover tends to insist on conflicting demandsmore firmly than a risk-averse player and therefore may rank these conflicting demands higher, and vice versa. Bargaining then isviewed as a procedure of conflict resolution over two sets of ranked demands (for two-player bargaining). A solution conceptwas proposed based on minimal changes but no axiomatic characterization was provided [44].This paper will develop an axiomatic model of bargaining based on the ordinal preference structure proposed in [44]. Wedescribe a bargaining situation in propositional logic and represent bargainers’ preferences in total pre-orders. Following thetradition of cooperative bargaining theory, we assume that any negotiation is conducted through an impartial arbitrator whohas complete information about the negotiation [22, Chapter 8].6 The agreement of a negotiation is the outcome of a se-quence of concessions simultaneously made by all players. We assume that whenever a player has to make a concession, shealways tries to make the concession as small as possible provided it is enough to break even. Based on the assumptions, w",
            {
                "entities": [
                    [
                        4012,
                        4040,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 300 (2021) 103546Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintKandinsky Patterns ✩Heimo Müller∗, Andreas HolzingerMedical University Graz, Austriaa r t i c l e i n f oa b s t r a c tArticle history:Received 16 September 2019Received in revised form 23 May 2021Accepted 3 June 2021Available online 9 June 2021Keywords:Explainable AIExplainabilitySynthetic test dataGround truthKandinsky Figures and Kandinsky Patterns are mathematically describable, simple, self-contained hence controllable synthetic test data sets for the development, validation and training of visual tasks and explainability in artificial intelligence (AI). Whilst Kandinsky Patterns have these computationally manageable properties, they are at the same time easily distinguishable by human observers. Consequently, controlled patterns can be described by both humans and computers. We define a Kandinsky Pattern as a set of Kandinsky Figures, where for each figure an “infallible authority” defines that the figure belongs to the Kandinsky Pattern. With this simple principle we build training and validation data sets for testing explainability, interpretability and context learning. In this paper we describe the basic idea and some underlying principles of Kandinsky Patterns. We provide a Github repository and invite the international AI research community to a challenge to experiment with our Kandinsky Patterns. The goal is to help expand and advance the field of AI, and in particular to contribute to the increasingly important field of explainable AI.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionAI is currently very successful, due to (i) advances in statistical machine learning (“deep learning”), (ii) the availability of large amounts of training data, and (iii) the available computing power [1], [2]. The high complexity, nonlinearity, and high dimensionality of such approaches make them difficult for a human to interpret, and therefore such approaches are considered “black box” models [3].Boosted by DARPA’s Explainable Artificial Intelligence Program [4], the field of explainable AI (xAI) has experienced a tremendous renaissance. Due to the imoprtance of legal and ethical considerations, explainability became enormously rel-evant and has established itself as an important concept. In roughly simplified terms, explainability technically highlights decision relevant parts of machine representations and/or parts which contributed to model accuracy in training and the xAI community has already developed a variety of successful methods. However, explainability does not refer to a human model. In certain application domains, e.g. in the medical domain, there is a need for going beyond explainability, i.e. there is a need for causability. Causability [5] is neither a typo nor a synonym for Causality [6]. The term Causa-bil-ity was intro-duced in reference to the well-known term Usa-bil-ity [7]. Causability has been defined as the measurable extent to which an explanation (resulting from an explainable AI method) to a human achieves a specified level of causal understanding ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail address: heimo.mueller@medunigraz.at (H. Müller).URL: http://human-centered.ai (H. Müller).https://doi.org/10.1016/j.artint.2021.1035460004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fH. Müller and A. HolzingerArtificial Intelligence 300 (2021) 103546measured with effectiveness, efficiency and satisfaction in a specified context of use - similar to usability. This can be mea-sured with the System Causability Scale (SCS) [8]. Consequently, causability refers to a human model and the understanding can be ensured when mapping explainability with causability. A successful mapping between the two would require new human-AI interfaces which allow domain experts to interactively ask questions and counterfactual questions to gain insight into the underlying independent explanatory factors of a result [9]. In an ideal world both human and AI statements would be identical and congruent with the ground truth, which is defined for both humans and AI equally [8]. Compared to the map metaphor, the explainability–causability mapping is about establishing connections and relations - not drawing a new map. It is about identifying the same areas in two completely different maps. For example, when explaining predictions of deep learning models we apply an explanation method, e.g. simple sensitivity analysis, to understand the prediction in terms of the input variables. The result of such an explainability method can be a heatmap. This heatmap visualization indicates which pixels need to be changed to make the image look (from the AI-systems perspective!) more or less like the predicted class [10]. On the other hand there are the corresponding human concepts, and “contextual understanding” needs effective mapping of them both [11], and is among the future grand goal of human-centered AI [12].The central motivation for this work was the lack of ground truth when testing with real data sets. Image classifiers operate on low-level features (e.g. lines, circles, etc.) rather than high-level concepts, and with domain concepts (e.g. imageswith a storefront). With our Kandinsky exploration environment we can produce Kandinsky Figures and Kandinsky Patterns along with the ground truth. With these mathematically describable, simple, and controllable synthetic test data sets we enhance the development, validation and training of visual tasks and explainability. Very important is that they are at the same time easily distinguishable by human observers.2. Kandinsky patternsWassily Kandinsky (1866–1944) was an influential Russian painter [13]. As his career progressed, Kandinsky produced increasingly abstract images. For a period from 1922 to 1933 he taught at the famous Bauhaus school in Germany, which celebrated simple colors and forms. Kandinsky was a theorist as well as an artist, and he derived profound meaning from aesthetic experiences. One of Kandinsky’s ideas was that there are certain fundamental associations between colors and shapes [14], e.g. he proposed Yellow-Triangle, Blue-Circle, and Red-Square. These associations were formulated introspec-tively, however, he did conduct his own survey at the Bauhaus in 1923 and postulated a correspondence between color and form. Subsequent empirical studies used preference judgments to test Kandinsky’s original color-form combinations, usually yielding inconsistent results. Recent findings suggest that there is no implicit association between the original color-form combinations and hence cannot be considered as a universal property of the visual system [15]. In our work we do not pursue this hypothesis any further, but take only the visual principles of Kandinsky as starting point and eponym for the following definitions.A Kandinsky Figure is a square image containing 1 to n geometric objects. Each object is characterized by its shape, color, size and position within this square. Objects do not overlap and are not cropped at the border. All objects must be easily recognizable and clearly distinguishable by a human observer.The set of all possible Kandinsky Figures k is defined by the general definition together with a specific set of values for shape, color, size, position and the number of geometric objects. In the following examples we use for shape the values circle, square and triangle; for color we use the values red, blue, yellow, and we allow arbitrary positions and size with the restriction that it is still recognizable. Furthermore, we require each Kandinsky Figure to contain exactly 4 objects in the following illustrative examples. In the demo implementation this fact is embedded in the base class “Kandinsky Universe”, and in the generator functions,1 see Fig. 1.A Statement s(k) about a Kandinsky Figure k is either a mathematical function, s(k) → B; with B(0, 1) or a natural language statement, which is either true or false.Remark: The evaluation of a natural language statement is always done in a specific context. In the followings examples we use well known concepts from human perception and linguistic theory. If s(k) is given as an algorithm, it is essential that the function is a pure function, which is a computational analogue of a mathematical function.A Kandinsky Pattern K is defined as the subset of all possible Kandinsky Figures k with s(k) → 1 or the natural language statement is true. s(k) and a natural language statement are equivalent, if and only if the resulting Kandinsky Patterns con-tains the same Kandinsky Figures. s(k) and the natural language statement are defined as the Ground Truth of a Kandinsky Pattern.In a deep learning solution classification algorithm for a visual pattern is usually represented as a highly non-linear, high-dimensional network. One aim of explainable AI is to identify areas of activation within the network structure, which correspond to concepts in the natural language statement.Problem 1: How can we explain a Kandinsky Pattern, if we do not know the Ground Truth and the membership of Kandinsky Figures to a Kandinsky Pattern is only known for a limited number of Kandinsky Figures.Problem 2: Generate a natural language statement, which is easily understandable and equivalent to the machine expla-nation (classification algorithm).1 https://github .com /human -centered -ai -lab /app -kandinsky-pattern -generator.2\fH. Müller and A. HolzingerArtificial Intelligence 300 (2021) 103546Fig. 1. A Kandinsky Figure with 4 objects. (For interpretation of the colors in the figure(s), the reader is referred to the web versi",
            {
                "entities": [
                    [
                        3482,
                        3510,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1731–1751Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe combination of multiple classifiers using an evidential reasoningapproachYaxin Bi a,∗, Jiwen Guan b, David Bell ba School of Computing and Mathematics, University of Ulster at Jordanstown, Co Antrim, BT37 0QB, UKb School of Computer Science, The Queen’s University of Belfast, Belfast, BT7 1NN, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 4 June 2007Received in revised form 12 June 2008Accepted 12 June 2008Available online 19 June 2008Keywords:Ensemble methodsDempster’s rule of combinationEvidential reasoningEvidential structuresCombination functions1. IntroductionIn many domains when we have several competing classifiers available we want tosynthesize them or some of them to get a more accurate classifier by a combinationfunction. In this paper we propose a ‘class-indifferent’ method for combining classifierdecisions represented by evidential structures called triplet and quartet, using Dempster’srule of combination. This method is unique in that it distinguishes important elementsfrom the trivial ones in representing classifier decisions, makes use of more informationthan others in calculating the support for class labels and provides a practical way toapply the theoretically appealing Dempster–Shafer theory of evidence to the problem ofensemble learning. We present a formalism for modelling classifier decisions as tripletmass functions and we establish a range of formulae for combining these mass functionsin order to arrive at a consensus decision.In addition we carry out a comparativesimplet and dichotomous structure and also compare twostudy with the alternatives ofcombination methods, Dempster’s rule and majority voting, over the UCI benchmark data,to demonstrate the advantage our approach offers.© 2008 Elsevier B.V. All rights reserved.The idea characterizing ensemble learning is to learn and retain multiple classifiers and combine their decisions in someway in order to classify new instances [36]. The attraction of this approach in supervised machine learning is based onthe premise that a combination of classifiers is often more accurate than an individual classifier. A theoretical explanationof its success is that different classifiers offer complementary information about instances to be classified which could beharnessed to improve the performance of the individual classifiers [27].Generally speaking a successful ensemble method depends on two components: a set of appropriate classifiers and acombination method, function or scheme [30]. Classifiers assign single classes or sets of classes to a new instance alongwith respective numeric values as decisions, and a combination function merges these decisions in some way to determinea final decision—usually by voting among the decisions.Ensemble classifiers can be generated in different ways. A typical approach is to use a single learning algorithm tooperate on different subsets of attributes or instances of the training data, as done in bagging [9] and boosting [11,21],and in derivatives such as random forests [10] or the random subspace method for constructing decision tree forests [26].Another approach is to use different learning algorithms to operate on a single data set [4,8,32]. Among any set of individualclassifiers, some are more accurate for a given task and others are less accurate. However there is often not a dominant* Corresponding author.E-mail addresses: y.bi@ulster.ac.uk (Y. Bi), j.guan@qub.ac.uk (J. Guan), da.bell@qub.ac.uk (D. Bell).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.002\f1732Y. Bi et al. / Artificial Intelligence 172 (2008) 1731–1751one for the complete data distribution. By taking account of the strengths of classifiers through combination functions, theperformance of the best individual classifier can be improved [12].Kuncheva [28] roughly characterizes combination methods, based on the forms of classifier outputs, into two categories.In the first category, the combination of decisions is performed on single class labels, including majority voting and Bayesianprobability, which have been extensively examined in the ensemble literature [18,27,40,49]. The second category is con-cerned with the utilization of continuous values corresponding to class labels. One set of methods, often called class-alignedmethods, is based on using the same class labels from different classifiers in calculating the support for class labels, regard-less of what the support for the other classes is. This method includes linear sum and order statistics, to which considerableeffort has been devoted [25,27,47,48,51]. Another method, called stacked generalization or meta-learning, is to use continu-ous values of class labels as a set of features to learn a combination function in addition to a set of classifiers [19,46,54]. Analternative group of methods, which are called class-indifferent methods, is to make use of as much information as possibleobtained from both single classes and sets of classes in calculating the support for each class [28].Class-aligned methods and class-indifferent methods are both based on continuous values of class labels in calculatingthe support for class labels. A distinction between them is, however, that the latter takes impacts from different classesinto account in determining the support for a class that permits the presence of uncertainty information—as happens whenan instance is classified into different classes by different classifiers. Several related studies are presented in the literature,where class-indifferent methods utilize single classes and sets of classes [16,39,49]. Class-indifferent methods for combiningdecisions in the form of a list of ordered decisions have not been intensively studied and are poorly understood. In particular,little is known about the value of evidential reasoning methods for combining truncated lists of ordered decisions [5,8].In this study we consider a class-indifferent approach to combining classifiers using Dempster’s rule of combination. Ourfocus is on generating classifiers using different learning methods to manipulate a single data set, and the combinationof classifiers is modeled as a process of reasoning under uncertainty. We model each output given by classifiers on newinstances as a list of contender decisions and reduce it to subsets of 2 and 3 decisions, respectively, which are then repre-sented by the evidential structures oftriplet and quartet [5–8]. We first establish a formalism for combining triplets andquartets using Dempster’s rule of combination to constrain the final decision, and then we empirically and analytically ex-amine the effect of different sizes of decision lists on the combination of classifiers. Furthermore we justify the assumptionwe make that modelling classifier results as independent bodies of evidence is sensible.The advantages of our approach are summarized as follows. The first advantage is that our method makes use of a widerange of evidence items in classification to make the final decision. The idea is inspired by the observation that if onlythe ‘best’ single class labels are selected on the basis of their corresponding values, valuable information contained in thediscarded labels may be lost. Arguably, the potential loss of support from the other classes should be avoided by utilizingthis support information in the decision making process. The evidence structures, such as the triplet, are able to distinguishthe important classes from the trivial ones and incorporate the best-supported class, the second best-supported class, andthe rest of the classes which are treated in terms of ignorance within the process of decision making. The second advantageis that these evidence structures provide an efficient way for combining many pieces of evidence since they break downa large list of contender decisions into smaller, more tractable subsets. Like the simplet and dichotomous structures [2,44],our method deals well with a long-standing criticism saying that the evidence theory does not translate easily into practicalapplications due to the computational complexity of combining multiple pieces of evidence.To validate our method and illustrate its power, we have carried out numerous comparative experiments over the UCIdata sets [3]. We experimentally compare the triplet and quartet with the alternatives of simplet, dichotomous structureand the full list of decisions. We also make a comparison between Dempster’s rule and majority voting in combiningclassifiers. During the course of classifier combination, another important issue, namely the extent of agreement reachedon classification decisions among classifiers, is assessed by means of κ statistics, and the associative property of combiningtriplets is also experimentally examined. Finally to explain our empirical findings, we present an investigation into thecalculation process of Dempster’s rule which provides an insight into the reason for superiority of our method.The rest of the paper is organized as follows. Section 2 presents the representation of classifier outputs and the ideaof class-independent methods. Section 3 reviews the Dempster–Shafer theory of evidence. Section 4 presents a review ofseveral related studies with a focus on the alternative structures of simplet and dichotomous structure previously used incombining classifiers. The rationale of the evidential structure of the triplet, and the associated formulae, are presentedin Section 5. The combination functions of Dempster’s rule with different evidential structures and majority voting forcombining classifiers are evaluated and the experimental settings and results are detailed in Section 6. Section 7 presentsa discussion about the advantage of the triplet and the quartet over the alternatives. Section 8 gives a justific",
            {
                "entities": [
                    [
                        3705,
                        3733,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 188–216Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelational linear programmingKristian Kersting a,∗a CS Department, TU Dortmund University, Germanyb LEAR-INRIA Rhone-Alpes, Montbonnot, France, Martin Mladenov a, Pavel Tokmakov ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 25 June 2015Accepted 28 June 2015Available online 2 July 2015Keywords:Machine learningOptimizationRelational logicStatistical relational learningLinear programmingSymmetry(Fractional) automorphismColor-refinementLifted probabilistic inferenceLifted linear programmingEquitable partitionsOrbit partitions1. IntroductionWe propose relational linear programming, a simple framework for combining linear programs (LPs) and logic programs. A relational linear program (RLP) is a declarative LP template defining the objective and the constraints through the logical concepts of objects, relations, and quantified variables. This allows one to express the LP objective and constraints relationally for a varying number of individuals and relations among them without enumerating them. Together with a logical knowledge base, effectively a logic program consisting of logical facts and rules, it induces a ground LP. This ground LP is solved using lifted linear programming. That is, symmetries within the ground LP are employed to reduce its dimensionality, if possible, and the reduced program is solved using any off-the-shelf LP solver. In contrast to mainstream LP template languages such as AMPL, which features a mixture of declarative and imperative programming styles, RLP’s relational nature allows a more intuitive representation of optimization problems, in particular over relational domains. We illustrate this empirically by experiments on approximate inference in Markov logic networks using LP relaxations, on solving Markov decision processes, and on collective inference using LP support vector machines.© 2015 Elsevier B.V. All rights reserved.Modern social and technological trends result in an enormous increase in the amount of accessible data, with a sig-nificant portion of the resources being interrelated in a complex way and having inherent uncertainty. Such data, which we may refer to as relational data, arises for instance in social network and media mining, natural language processing, open information extraction, the web, bioinformatics, and robotics, among others. Making this data amenable to computing machinery typically yields substantial social and/or business value. Therefore, it is not surprising that probabilistic logical languages1 are currently provoking much new AI research with tremendous theoretical and practical implications. By com-bining aspects of logic and probabilities—a dream of AI dating back to at least the late 1980’s when Nils Nilsson introduced the term probabilistic logics [5]—they help to effectively manage both complex interactions and uncertainty in the data.However, instead of looking at AI through the glasses of probabilities over possible worlds, we may also approach it using optimization. That is, we have a preference relation, i.e., some objective function over possible worlds, and we want a best possible world according to the preference. Consider for example a typical data analyst solving a machine learning problem for a given dataset. She selects a model for the underlying phenomenon to be learned (choosing a learning bias), formats * Corresponding author.E-mail addresses: kristian.kersting@cs.tu-dortmund.de (K. Kersting), martin.mladenov@cs.tu-dortmund.de (M. Mladenov), pavel.tokmakov@inria.fr(P. Tokmakov).1 We refer to e.g. [1–4] and references therein for overviews.http://dx.doi.org/10.1016/j.artint.2015.06.0090004-3702/© 2015 Elsevier B.V. All rights reserved.\fK. Kersting et al. / Artificial Intelligence 244 (2017) 188–216189the raw data according to the chosen model, tunes the model parameters by minimizing some objective function induced by the data and the model assumptions, and may iterate the last step as part of model selection and validation. This is an instance of the declarative “Model + Solver” paradigm that was and is prevalent in AI [6], natural language processing [7], machine learning [8], and data mining [9]: instead of outlining how a solution should be computed, we specify what the problem is in terms some high-level modeling language and solve it using general solvers.Unfortunately, however, today’s solvers for mathematical programs typically require that the program is presented in solver-readable form and/or offer only some very restricted modeling environment. For example, a solver may require that a set of linear constraints be presented as a system of linear inequalities Ax ≤ b. This can create severe difficulties for the user. First of all, the process of turning the intuition that defines the model “on paper” into a solver-readable form could be quite cumbersome. Consider the following example from graph isomorphism [10]. Given two graphs G and H , the LP formulation introduces a variable for every possible partial function mapping k vertices of G to k vertices in H . It is not a trivial task to come up with a convenient linear indexing of the variables, let alone expressing the resulting inequalities Ax ≤ b. It requires the user to produce and maintain complicated matrix generation code, which can be tedious and error-prone. Moreover, the reusability of such specialized code is limited, as relatively minor modifications of the equations could require large modifications of the code (for example, the user decides to switch from having variables over sets of vertices to variables over tuples of vertices). Ideally, one would like to separate the rules that generate the problem from the problem instance itself. Finally, solver-readable forms are inherently propositional. By design they cannot model domains with a variable number of individuals and relations among them without enumerating all of them. As already mentioned, however, many AI tasks and domains are best modeled in terms of individuals and relations. Agents must deal with heterogeneous information of all types. Even more important, they must often build models before they know what individuals are in the domain and, therefore, before they know what variables exist. Hence modeling should facilitate the formulation of abstract, general knowledge.To overcome these downsides and triggered by the success of probabilistic logical languages, we show that optimization is liftable to the relational level too. Specifically, we lift linear programs—the most tractable, best understood, and widely used in practice fragment of mathematical programs—by introducing relational linear programs (RLPs). They are declarative LP templates defined through the logical concepts of individuals, relations, and quantified variables, and allow the user to express LP objectives and constraints for a varying number of individuals without enumerating them. For instance, the following codesubject to {vertex(X),not source(X),not target(X)}: outflow(X)-inflow(X)=0;encodes the conservation of flows for all vertices of a graph that are not source or target. Together with a logical knowledge base (LogKB) referring to the individuals and relations (effectively a logical program consisting of logical facts and rules), it induces a ground LP that can be solved using any LP solver. However, since RLPs consist of templates that are instantiated several times to construct a ground linear model, they are also likely to induce ground models that exhibit symmetries, and we will demonstrate how to detect and exploit them. As our main technical contribution, we introduce lifted linear programming (LLP). It detects symmetries in a linear program in quasilinear time and eliminates them by reparametrizing the original linear program into a smaller one sharing optimal solutions that can be computed using any LP solver.Both contributions together result in relational linear programming, best summarized as(cid:2)(cid:3)(LP + Logic) − Symmetry+ Solver.The user describes a relational problem in a high-level, relational LP modeling language and—given a logical knowledge base (LogKB) encoding some individuals or rather data—the system automatically compiles a symmetry-reduced LP that in turn can be solved using any off-the-shelf LP solver.Our empirical illustrations on several AI tasks such as computing optimal value-functions of Markov decision pro-cesses [11], approximate inference within Markov logic networks [12] using LP relaxations, and collective classification [13]demonstrate that relational linear programming can• ease the process of turning the “modeler’s form”, i.e., the form in which the modeler understands a problem or actually a class of problems (since we can now deal with a varying number of individuals and relations among them), into a solver-readable form, and• considerably reduce the time spent to compute solutions.The present paper is a significant extension of a previously published conference paper [14]. It provides a much more concise development of LLP and the first coherent view on relational linear programming as a novel and promising way for scaling AI by developing and showcasing the first modeling language for LPs based on logic programming. One of the advantages of the language is the closeness of its syntax to the mathematical notation of LP problems while supporting language elements from logic programming such as individuals, relations, and quantified variables. This allows for a very concise and readable relational definition of linear optimization problems in a general, declarative fashion; the (relational) algebraic formulation of a model does not contain any hints how to process it.We proceed as follows. We start off by reviewing linear programming and existing LP template languages in Section 2. Then, in Section 3, we introduce re",
            {
                "entities": [
                    [
                        3768,
                        3796,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1877–1910Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the complexity of core, kernel, and bargaining set ✩Gianluigi Greco a, Enrico Malizia b, Luigi Palopoli b, Francesco Scarcello b,∗a Dipartimento di Matematica, Università della Calabria, I-87036 Rende (CS), Italyb DEIS, Università della Calabria, I-87036 Rende (CS), Italya r t i c l ei n f oa b s t r a c tArticle history:Received 4 November 2010Received in revised form 10 June 2011Accepted 13 June 2011Available online 16 June 2011Keywords:Coalitional gamesCompact representationsComputational complexitySolution conceptsBounded treewidthCoalitional games model scenarios where players can collaborate by forming coalitions inorder to obtain higher worths than by acting in isolation. A fundamental issue of coalitionalgames is to single out the most desirable outcomes in terms of worth distributions,usually called solution concepts. Since decisions taken by realistic players cannot involveunbounded resources, recent computer science literature advocated the importance ofassessing the complexity of computing with solution concepts. In this context, the paperprovides a complete picture of the complexity issues arising with three prominent solutionconcepts for coalitional games with transferable utility, namely, the core, the kernel, andthe bargaining set, whenever the game worth-function is represented in some reasonablycompact form. The starting points of the investigation are the settings of graph gamesand of marginal contribution nets, where the worth of any coalition can be computedin polynomial time in the size of the game encoding and for which various openquestions were stated in the literature. The paper answers these questions and, in addition,provides new insights on succinctly specified games, by characterizing the computationalcomplexity of the core, the kernel, and the bargaining set in relevant generalizationsand specializations of the two settings. Concerning the generalizations, the paper showsthat dealing with arbitrary polynomial-time computable worth functions—no matter ofthe specific game encoding being considered—does not provide any additional source ofcomplexity compared to graph games and marginal contribution nets. Instead, only forthe core, a slight increase in complexity is exhibited for classes of games whose worthfunctions encode NP-hard optimization problems, as in the case of certain combinatorialgames. As for specializations, the paper illustrates various tractability results on classes ofbounded treewidth graph games and marginal contribution networks.© 2011 Elsevier B.V. All rights reserved.1. IntroductionCoalitional games were introduced by von Neumann and Morgenstern [59] in order to reason about scenarios where play-ers can collaborate by forming coalitions with the aim of obtaining higher worths than by acting in isolation. In the Trans-ferable Utility (TU) setting, coalition worths can be freely distributed amongst agents, while in the Non-Transferable Utility(NTU) setting coalitions are allowed to distribute worths only in some specified configurations, called consequences [62].✩Preliminary versions of parts of this paper appeared in the Proceedings of the 20th and of the 21st International Joint Conferences on ArtificialIntelligence (Malizia et al., 2007 [53]; Greco et al., 2009 [38]).* Corresponding author.E-mail addresses: ggreco@mat.unical.it (G. Greco), emalizia@deis.unical.it (E. Malizia), palopoli@deis.unical.it (L. Palopoli), scarcello@deis.unical.it(F. Scarcello).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.06.002\f1878G. Greco et al. / Artificial Intelligence 175 (2011) 1877–1910In this paper, we consider only the classical TU setting, and thus by saying game we always mean hereafter coalitionalgame with transferable utility. Such a game can abstractly be modeled as a pair G = (cid:3)N, v(cid:4), where N is a finite set of players,and v is a function associating with each coalition S ⊆ N a certain worth v(S) ∈ R that players in S obtain by collaboratingwith each other. The outcome of G is an imputation, i.e., a vector of payoffs (xi)i∈N meant to specify the distribution of thei∈N xi = v(N), and individuallytotal worth v(N) granted to each player in N. Imputations are required to be efficient, i.e.,rational, i.e., xi (cid:2) v({i}), for each i ∈ N. In the following, the set of all imputations of G is denoted by X(G).It is easily seen that, for any given coalitional game G, the set X(G) may even contain infinitely many payoff vectors.Therefore, a fundamental problem is to single out the most desirable ones in terms of appropriate notions of worth distribu-tions, which are usually called solution concepts. Traditionally, this question was studied in economics and game theory withthe aim of providing arguments and counterarguments about why such proposals are reasonable mathematical renderingsof the intuitive concepts of fairness and stability. Well-known and widely-accepted solution concepts are the Shapley value,the core, the kernel, the bargaining set, and the nucleolus (see, e.g., [62]). Each solution concept defines a set of outcomes thatare referred to with the name of the underlying concept. For instance, the “core of a game” is the set of those outcomessatisfying the conditions associated with the concept of core.(cid:2)1.1. Coalitional games from the AI perspective: Complexity and representation issuesSolution concepts for coalitional games have been brought to the attention of the computer science community, byconsidering them from a computational point of view, in a seminal study by Megiddo [57]. There, it has been observed thatthe naïve approach of explicitly listing all associations of coalitions with their worths in the specification of coalitional gamesmakes the “game theory approach” hardly applicable in practice, due to the exponential blow-up of the input representationw.r.t. the number of involved players. In fact, Megiddo [57] showed the importance of conceiving succinct representations ofcoalitional games, and taking into consideration computational complexity issues when analyzing classical solution concepts,with the aim of exhibiting efficient algorithms for their calculation. In particular, Megiddo [57] exhibited polynomial-timealgorithms for computing the nucleolus and the Shapley value of cost allocation games over trees.Another influential study on complexity issues related to coalitional games is due to Kalai and Zemel [48], who showedpolynomial-time algorithms for computing an imputation in the core of flow games.Deng and Papadimitriou [26] took a step further to use computational complexity in the analysis of coalitional games, byarguing that decisions taken by realistic agents cannot involve unbounded resources to support reasoning, and suggesting toformally capture the bounded rationality principle [76] by assessing the amount of resources needed to compute solutionconcepts in terms of their computational complexity [26,47]. In this context, Deng and Papadimitriou [26] were interestednot only in exhibiting efficient algorithms, but also in characterizing those scenarios where such algorithms are unlikely toexist due to the inherent complexity of the solution concepts. In particular, they again noticed that computational questionsare of interest whenever worth functions are encoded in some succinct way, e.g., when they are given in terms of polyno-mially computable functions over some combinatorial structure. However, to the end of assessing the intrinsic complexityof solution concepts, calling for succinct specifications is not only motivated by the practical difficulty of explicitly listingall associations of coalitions with their worths, but also because with an explicit encoding the input sizes are so large thatcomplexity problems are trivially—and in fact artificially—easy. Coalitional games whose worth functions are encoded bymeans of some succinct representation mechanism are hereinafter called compact games.Coalitional games gained popularity in the context of multi-agent systems and artificial intelligence research since thenineties, when they had been recognized by these research communities as very natural models to understand and reasonabout cooperative action. In particular, inspired by the approach of Deng and Papadimitriou [26], the questions of findingrepresentation schemes to compactly encode worth functions and assessing over them the complexity of various solutionconcepts have motivated most of the research on coalitional games in the AI field. In fact, research works facing thesequestions can be classified into two main groups, depending on the kinds of representation schemes being adopted (cf. [1])1:1. Representation schemes that are succinct, but not complete (i.e., such that there are coalitional games that cannotbe captured by such representations). Complexity analysis have been conducted on several prominent schemes of thiskind, including graph games [26], traveling salesman games [31], flow games [24], matching games [49], facility locationgames [37], skill games [9], threshold games [5,28,30], minimum cost spanning tree games [33], combinatorial optimizationgames (see [25] and the references therein), games on combinatorial structures [12], voting games [68], games in multi-issuedomains [17], linear production games [63], bin packing games [32], permutation games [77], path disruption games [8], and(vertex) connectivity games [10].2. Representation schemes that are complete, but not succinct (i.e., such that there are coalitional games requiring ex-ponential space—in the worst case—to be encoded in such representations). Influential proposals thereof are marginalcontribution nets [44], read-once (and general) marginal contribution nets [29], games with synergies among coalitions [18],and multi-attribute games [45].1 Details o",
            {
                "entities": [
                    [
                        3684,
                        3712,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 264–277Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom answer set logic programming to circumscription via logic of GKFangzhen Lin a,∗, Yi Zhou ba Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kongb School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Logic programmingAnswer set programmingLogic of GKCircumscriptionNonmonotonic reasoningKnowledge representation and reasoningWe first embed Pearce’s equilibrium logic and Ferraris’s propositional generallogicprograms in Lin and Shoham’s logic of GK, a nonmonotonic modal logic that has beenshown to include as special cases both Reiter’s default logic in the propositional case andMoore’s autoepistemic logic. From this embedding, we obtain a mapping from Ferraris’spropositional general logic programs to circumscription, and show that this mapping canbe used to check the strong equivalence between two propositional logic programs inclassical logic. We also show that Ferraris’s propositional general logic programs can beextended to the first-order case, and our mapping from Ferraris’s propositional generallogic programs to circumscription can be extended to the first-order case as well to providea semantics for these first-order general logic programs.© 2010 Elsevier B.V. All rights reserved.PrologueIt gives us great pleasure to be able to contribute this work to this special issue of Artificial Intelligence in honor of JohnMcCarthy. Like so many others, we have been influenced greatly by McCarthy and his work for as long as we have known AI.This particular work relates McCarthy’s circumscription to several other nonmonotonic logics, and obviously could not havebeen done without McCarthy’s pioneering work on nonmonotonic reasoning in general and circumscription in particular.1. IntroductionAnswer Set Programming (ASP) is a new paradigm of constraint-based programming based on logic programming withanswer set semantics [9,13,17]. It started out with normal logic programs, which are programs that can have negation butnot disjunction. Driven by the need of applications, various extensions have been proposed. These include disjunctive logicprograms [5,6], nested expressions [7], cardinality and weight constraints [16], and others. Recently, Ferraris [2] proposedto view formulas in propositional logic as logic programs and showed that they include as special cases all the abovementioned classes of logic programs. In particular, Ferraris [2] provided a stable model semantics for these formulas usinga transformation similar to the original Gelfond–Lifschitz transformation, and showed that this semantics coincides withPearce’s equilibrium logic [19].In this paper, we show that this general stable model semantics can be embedded in Lin and Shoham’s logic of GK(Grounded Knowledge) [11]. Besides showing the generality of Lin and Shoham’s logic, which was proposed as a generallogic for nonmonotonic reasoning, this embedding allows us to obtain a way to check in classical propositional logic whetherany given two logic programs are strongly equivalent in almost the same way as in [12]. It also allows us to obtain a* Corresponding author.E-mail address: flin@cs.ust.hk (F. Lin).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.001\fF. Lin, Y. Zhou / Artificial Intelligence 175 (2011) 264–277265mapping from general logic programs to propositional circumscription in the same way as Lin and Shoham [11] did formapping normal logic programs to circumscription. As it turned out, this mapping, when extended to first-order case, yieldsa semantics to first-order general logic programs that is similar to the one proposed recently by Ferraris et al. [4].We first briefly review Lin and Shoham’s logic of GK, Ferraris’s general logic programs, and Pearce’s equilibrium logic.2. Logic of GKThe language of the logic of GK is a modal propositional language with two modal operators, K , for knowledge, and A,for assumption. Given a set Atom of atoms (also called variables or primitive propositions), formulas in the logic of GK aredefined inductively below in BNF notation:F ::= ⊥ | p | K (F ) | A(F ) | ¬F | F ∧ F | F ∨ F | F → F ,where p ∈ Atom, and ⊥ is a constant standing for falsity. Formulas without modal operators are called base formulas.The semantics of the logic of GK is defined through Kripke interpretations. A Kripke interpretation M is a tuple(cid:8)W , π , R K , R A, s(cid:9), where W is a nonempty set whose elements are called possible worlds, π is a function that maps apossible world to a truth assignment on Atom, R K and R A are binary relations over W representing the accessibility re-lations for K and A, respectively, and s ∈ W , called the actual world of M. The satisfaction relation |(cid:10) between a Kripkeinterpretation M = (cid:8)W , π , R K , R A, s(cid:9) and a formula F is defined inductively as follows:• M (cid:11)|(cid:10) ⊥;• M |(cid:10) p if π (s)(p) = 1, where p ∈ Atom;• M |(cid:10) ¬F iff M (cid:11)|(cid:10) F ;• M |(cid:10) F ∧ G iff M |(cid:10) F and M |(cid:10) G;• M |(cid:10) F ∨ G iff M |(cid:10) F or M |(cid:10) G;• M |(cid:10) F → G iff M (cid:11)|(cid:10) F or M |(cid:10) G;• M |(cid:10) K (F ) iff (cid:8)W , π , R K , R A, w(cid:9) |(cid:10) F for any w ∈ W , such that (s, w) ∈ R K ;• M |(cid:10) A(F ) iff (cid:8)W , π , R K , R A, w(cid:9) |(cid:10) F for any w ∈ W , such that (s, w) ∈ R A .We say that a Kripke interpretation M is a model of a formula F if M satisfies F . In the following, given a Kripke interpre-tation M, we let(cid:2)K (M) =A(M) =(cid:2)FF(cid:3)(cid:4)(cid:3) F is a base formula and M |(cid:10) K (F )(cid:3)(cid:4)(cid:3) F is a base formula and M |(cid:10) A(F ).,Notice that K (M) and A(M) are always closed under classical logical entailment. In the following, for any set X of formulas,we let Th( X) be the logical closure of X under classical logic.Informally in GK, one assumes A(M) and minimizes K (M). When the assumed A(M) turns out to be the same as theminimal K (M), an equilibrium is reached, and the assumption is said to be “justified” or the knowledge is said to be“grounded”. Formally, GK models are defined as follows.Definition 2.1 (GK models). Given a formula F , a Kripke interpretation M is a minimal model of F if M is a model of F andthere does not exist another model M1 of F such that A(M1) = A(M) and K (M1) ⊂ K (M). We say that M is a GK model1 ifM is a minimal model of F and K (M) = A(M).Lin and Shoham showed that the logic of GK can be used to capture Reiter’s default logic [20] and Moore’s auto-epistemiclogic [15]. As a consequence, normal logic programs under stable model semantics can be captured in the logic of GK aswell. Specifically, they showed that a normal ruler ← p1, . . . , pn, not q1, . . . , not qmcan be translated into the following sentence in the logic of GK:Kp1∧ · · · ∧ Kpn∧ ¬Aq1∧ · · · ∧ ¬Aqm→ Kr.(1)They also showed that this translation extends to disjunctive logic programs.In this paper, we shall show that general logic programs proposed by Ferraris [2] can be captured in the logic of GK aswell.1 In [11], GK models are called preferred models.\f266F. Lin, Y. Zhou / Artificial Intelligence 175 (2011) 264–2773. General logic programsGiven a set Atom of atoms, general logic programs [3] are formulas defined inductively below in BNF notation:F ::= ⊥ | p | F ∧ F | F ∨ F | F → F ,where p ∈ Atom. Notice that there is no negation in the language. Instead, for any formula F , ¬F is considered to be ashorthand for F → ⊥.A set X ⊆ Atom of atoms can be considered as a truth assignment in the straightforward way:X (cid:11)|(cid:10) ⊥,X |(cid:10) p iff p ∈ X,and the usual definition for the logical connectives.The stable models of a formula (general logic program) are defined by a modified extended Gelfond–Lifschitz transforma-tion. Given a general logic program F , and a set X of atoms, the reduct of F under X [2], written F X , is the formula obtainedfrom F by replacing each maximal subformula that is not classically satisfied by X with ⊥. Thus for example,(¬F ) X =(cid:5)(cid:15), X |(cid:10) ¬F ,⊥, otherwise.Now a set X of atoms is a stable model of a general logic program F if:(i) X |(cid:10) F X ;(ii) there is no proper subset X1 of X , such that X1 |(cid:10) F X .Example 3.1. Consider the following three general logic programs.P = ¬p → q,Q = ¬p ∨ p,R = p → ¬¬p,is ¬⊥ → q, which is satisfiedwhere p, q are atoms. The maximal subformula in P that is false under {q} is p, thus Pby {q}, but not by ∅. Therefore, {q} is a stable model of P . On the other hand, Pis ⊥ → ⊥, which is satisfied by {p} aswell as its subset ∅. Therefore, {p} is not a stable model of P . It can be seen that {q} is the only stable model of P . Similarly,it can be shown that Q has two stable models, {p} and ∅, and R has exactly one stable model ∅.{p}{q}4. Pearce’s equilibrium logicPearce’s equilibrium logic [19] is based on the logic of here-and-there, a non-classical logic. Given a set Atom of atoms,formulas of Atom are exactly the same as in the case of general logic programs. Thus, negation in equilibrium logic isconsidered a shorthand as well.The semantics of the logic of here-and-there is defined in terms of HT-interpretations, which are pairs (cid:8) X, Y (cid:9) of setsof atoms such that X ⊆ Y . The HT satisfaction relation2 |(cid:10) between an HT-interpretation (cid:8) X, Y (cid:9) and a formula F is definedrecursively as follows:• For p ∈ Atom, (cid:8) X, Y (cid:9) |(cid:10) p if p ∈ X ;• (cid:8) X, Y (cid:9) (cid:11)|(cid:10) ⊥;• (cid:8) X, Y (cid:9) |(cid:10) F ∧ G if (cid:8) X, Y (cid:9) |(cid:10) F and (cid:8) X, Y (cid:9) |(cid:10) G;• (cid:8) X, Y (cid:9) |(cid:10) F ∨ G if (cid:8) X, Y (cid:9) |(cid",
            {
                "entities": [
                    [
                        3529,
                        3557,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 240 (2016) 36–64Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintNasari: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entitiesJosé Camacho-Collados a,∗a Department of Computer Science, Sapienza University of Rome, Italyb Language Technology Lab, Department of Theoretical and Applied Linguistics, University of Cambridge, United Kingdom, Mohammad Taher Pilehvar b,1, Roberto Navigli aa r t i c l e i n f oa b s t r a c tArticle history:Received 23 December 2015Received in revised form 14 July 2016Accepted 25 July 2016Available online 16 August 2016Keywords:Semantic representationLexical semanticsWord Sense DisambiguationSemantic similaritySense clusteringDomain labelingOwing to the need for a deep understanding of linguistic items, semantic representation is considered to be one of the fundamental components of several applications in Natural Language Processing and Artificial Intelligence. As a result, semantic representation has been one of the prominent research areas in lexical semantics over the past decades. However, due mainly to the lack of large sense-annotated corpora, most existing representation techniques are limited to the lexical level and thus cannot be effectively applied to individual word senses. In this paper we put forward a novel multilingual vector representation, called Nasari, which not only enables accurate representation of word senses in different languages, but it also provides two main advantages over existing approaches: (1) high coverage, including both concepts and named entities, (2) comparability across languages and linguistic levels (i.e., words, senses and concepts), thanks to the representation of linguistic items in a single unified semantic space and in a joint embedded space, respectively. Moreover, our representations are flexible, can be applied to multiple applications and are freely available at http :/ /lcl .uniroma1.it /nasari/. As evaluation benchmark, we opted for four different tasks, namely, word similarity, sense clustering, domain labeling, and Word Sense Disambiguation, for each of which we report state-of-the-art performance on several standard datasets across different languages.© 2016 Elsevier B.V. All rights reserved.1. IntroductionSemantic representation, i.e., modeling the semantics of a linguistic item2 in a mathematical or machine interpretable form, is a fundamental problem in Natural Language Processing (NLP) and Artificial Intelligence (AI). Because they represent the lowest linguistic level, word senses play a vital role in natural language understanding. Effective representations of word senses can be directly useful to Word Sense Disambiguation [93], semantic similarity [13,129,106], coarsening sense inven-tories [92,124], alignment of lexical resources [101,98,108], lexical substitution [75], and semantic priming [100]. Moreover, sense-level representation can be directly extended to applications requiring word representations, with the added bene-fit that it provides extra semantic information. Turney and Pantel [129] provide a review of some of the applications of * Corresponding author.E-mail address: collados@di.uniroma1.it (J. Camacho-Collados).1 Work mainly done at the Sapienza University of Rome.2 Throughout this article by a linguistic item we mean any kind of linguistic unit that can bear a meaning, i.e., a word sense, a word, a phrase, a sentence or a larger piece of text.http://dx.doi.org/10.1016/j.artint.2016.07.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\fJ. Camacho-Collados et al. / Artificial Intelligence 240 (2016) 36–6437word representation, including: automatic thesaurus generation [21,22], word similarity [25,128,113] and clustering [103], query expansion [140], information extraction [61], semantic role labeling [29,104], spelling correction [53], and Word Sense Disambiguation [93].The Vector Space Model (VSM) is a prominent approach for semantic representation. The model represents a linguistic item as a vector (or a point) in an n-dimensional semantic space, i.e., a mathematical space wherein each of the n dimen-sions (hence, axes of the space) denotes a single linguistic entity, such as a word. The popularity of the VSM representation is due to two main reasons. Firstly, it is straightforward to view vectors as sets of features and directly apply various ma-chine learning techniques on them. Secondly, the model enjoys support from the field of Cognitive Science wherein several studies have empirically or theoretically suggested that various aspects of human cognition accord with VSMs [36,64].However, most VSM-based techniques, whether in their conventional co-occurrence based form [119,129,63], or in their newer predictive branch [20,81,8], usually base their computation on the distributional statistics derived from text corpora. Hence, in order to be able to represent individual meanings of words (i.e., word senses), these techniques require large amounts of disambiguated text prior to modeling. Additionally, Word Sense Induction techniques [103,11,58,27] require sense-annotated data, if their induced sense clusters are to be mapped to an existing sense inventory. However, providing sense-annotated data on a large scale is a time-consuming process which has to be carried out separately for each word sense and repeated for each new language of interest, i.e., the so-called knowledge acquisition bottleneck. Importantly, the largest manual effort for providing a wide-coverage sense-annotated dataset dates back to 1993, in the case of the SemCor corpus [85]. In fact, although cheap and fast annotations could be obtained by means of Amazon Mechanical Turk [123,55], games with a purpose [133,131,56], or voluntary collaborative editing such as in Wikipedia [77], producing annotated resources manually is still an onerous task. On the other hand, the performance of Word Sense Disambiguation (WSD) techniques is still far from ideal [93], which in its turn prevents a reliable automatic sense-annotation of large text corpora that can be used for modeling individual word senses. This hinders the functionality of this group of vector space models in tasks such as WSD that require the representation of individual word senses.There have been several efforts to adapt and apply distributional approaches to the representation of word senses [103,12,114,47,68]. However, most of these techniques cannot provide representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data [48]. Recently, there have been attempts to address this issue and to obtain vectors for individual word senses by exploiting the WordNet semantic network [74,106,108,116] and its glosses [19]. These approaches, however, are either restricted to the representation of concepts defined in WordNet and to the English language only, or are designed for specific tasks.In our recent work [16], we proposed a method that exploits the structural knowledge derived from semantic networks, together with distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our approach provides two main advantages in comparison to previous VSM techniques. Firstly, it is multilingual, as it can be directly applied for the representation of concepts in dozens of languages. Secondly, each vector represents a concept, irrespective of its language, in a unified semantic space having concepts as its dimensions, permitting direct comparison of different representations across languages and hence enabling cross-lingual applications.In this article, we improve our approach, referred to as Nasari (Novel Approach to a Semantically-Aware Representation of Items) henceforth, and extend their application to a wider range of tasks in lexical semantics. Specifically, the novel contributions are as follow:1. We propose a new formulation for fast computation of lexical specificity (Section 3.1.1).2. We propose a new flexible way to get continuous embedded vector representations, with the added benefit of obtaining a semantic space shared by BabelNet synsets, words and texts (Section 3.3).3. We put forward a technique for improved computation of weights in the unified vectors and show how it can improve the accuracy and efficiency of the representations (Section 3.4).4. We compute and assign weights to individual edges in our semantic network (Section 4.1) and show by means of different experiments the advantage we gain when using this new weighted graph (Section 10).5. We release the lexical and unified vector representations for five different languages (English, French, German, Italian and Spanish) and the embedded vector representations for the English language at http :/ /lcl .uniroma1.it /nasari/.In addition to these contributions, we also devised robust frameworks that enable direct application of our representa-tions to four different tasks: Semantic Similarity (Section 6), Sense Clustering (Section 7), Domain Labeling (Section 8) and Word Sense Disambiguation (Section 9). For each of the tasks, we carried out a comprehensive set of evaluations on several datasets in order to verify the reliability and flexibility of Nasari different datasets and tasks. We provide a summary of the experiments in Section 5.The rest of this article is structured as follows. We first provide an introduction of some of the most widely used knowl-edge resources in lexical semantics, in Section 2. After which, in Section 3 we describe our methodology to convert text into lexical, embedded and unified vectors. The process to obtain vector representations for synset vectors by leveraging the knowledge resources described in Section 2, and the methodology to obtain vectors from text described in Section 3, is presented in S",
            {
                "entities": [
                    [
                        3554,
                        3582,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 914–927Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the phase transitions of random k-constraint satisfaction problemsYun Fan a, Jing Shen a,b,∗a Department of Mathematics, Central China Normal University, Wuhan, 430079, Chinab School of Science, Naval University of Engineering, Wuhan, 430033, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 29 July 2010Received in revised form 11 November 2010Accepted 11 November 2010Available online 13 November 2010Keywords:Constraint satisfaction problemPhase transitionConstraint satisfaction has received increasing attention over the years. Intense researchhas focused on solving all kinds of constraint satisfaction problems (CSPs). In this paper,first we propose a random CSP model, named k-CSP, that guarantees the existence ofphase transitions under certain circumstances. The exact location of the phase transitionis quantified and experimental results are provided to illustrate the performance ofthe proposed model. Second, we revise the model k-CSP to a random linear CSP byincorporating certain linear structure to constraint relations. We also prove the existenceof the phase transition and exhibit its exact location for this random linear CSP model.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConstraint satisfaction problem, or CSP in short, is represented by a finite set of variables, each one of which is associatedwith a domain, and a finite set of constraints, each of which consists of a subset of the variables, called a constraint scope, anda constraint relation that restricts the values of the variables in the constraint scope can simultaneously take. The objectiveis to assign a value to each variable satisfying all the constraint relations. CSP is an important topic in the area of computerscience, especially in artificial intelligence, since the regularity in their formulation provides a common base to analyze andsolve the problems of many unrelated families. In recent years, the random CSP and the corresponding phase transitionshave attracted more and more attention since Cheeseman et al. proposed in [7] that many hard instances should be foundat the phase transition points.There have been various models for investigating the phase transitions of random CSP proposed by various academiccommunities, e.g. [2,10–12,17–19,27–29]. The initial standard models, named A, B, C and D [23,28], were proposed togenerate random binary CSP instances. Experiments showed that the standard models [23,28] all exhibit a “threshold-like”behavior. On the other hand, it has been proved theoretically by Achlioptas et al. in [1] that the random instances generatedby the standard models do not have an asymptotic threshold when the length of constraint scopes and the size of domainsare fixed.Improvement of the performance of standard models was addressed from various perspectives in numerous efforts[1,21–23,26,31]. Some new models incorporated special combinatorial structures on the constraints. In other words, theconstraints are subject to certain combinatorial restrictions and the restrictions ensure that the generated instances arearc consistent [23], path consistent [21], strongly 3-consistent [22] or weakly 4-consistent [22]. It has been proved that allthese revised models have non-trivial asymptotic behaviors. While the combinatorial structures provide the capability forproducing phase transitions, this achievement typically comes at the price of more restrictions on the constraint relationsof instances.Based on the model B [28] mentioned previously, Xu and Li [31] proposed a random CSP model, named model RB.Instead of fixing the size of domains associated with each instance as in the model B, the size of domains of the model RB* Corresponding author at: Department of Mathematics, Central China Normal University, Wuhan, 430079, China.E-mail addresses: yunfan02@yahoo.com.cn (Y. Fan), shendina@hotmail.com (J. Shen).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.004\fY. Fan, J. Shen / Artificial Intelligence 175 (2011) 914–927915is uniform for each instance and the value of the size is variant as a power function of the cardinality of the set of variables,i.e. the number of variables. On the other hand, the length of constraint scopes and the tightness of constraint relationsfor each instance of the model RB are fixed. It has been proved theoretically in [1] that model B does not have the phasetransition point over most of the parameter space. Due to incorporating uniformly variant domain size, the revised modelRB does have phase transitions and the exact phase transition points have been quantified by Xu and Li [31]. Moreover,it has been demonstrated that the model RB has a lot of hard instances existing [32] and all the instances at the phasetransition points have exponential tree-resolution complexity [30]. Compared with revised models in [21–23], the capabilityof generating instances is dramatically enhanced for the model RB due to the fact that there is no combinatorial restrictionenforced on the constraint relations of model RB. Generally speaking, it is natural and relatively easier for the model RB togenerate asymptotically non-trivial CSP instances with relatively large domain size.Another area of active research in the field of CSP is the development of k-SAT, where k denotes the length of theconstraint scopes. It is proved by Friedgut in [17] that a phase transition exists for k-SAT if k is fixed. However, for fixed kwith k (cid:2) 3, there is still no effective method to obtain the exact location of the phase transition. For example, it is alreadyderived theoretically in [24] and [14] that the best lower bound and upper bound of the phase transition for 3-SAT are3.53 and 4.506 respectively; but the exact location is still under investigation. When compared with the results for k-SATwith fixed k, it has been demonstrated that it is possible for k-SAT to ascertain the exact location of phase transitions if theparameter k is growing moderately, as detailed in [16,20].Motivated by k-SAT with growing k in [20], in this paper first we revise the model RB in [31] to propose a new randomCSP model, named model k-CSP. When comparing with the model RB in [20], instead of fixing the parameters of constraints,including both the length of constraint scopes and the tightness of constraint relations, and varying the size of domains asa power function, for the new model k-CSP we assume that the size of domains and the tightness of constraint relations arefixed and the length of constraint scopes, which is denoted by k, is variant as a function of n, where n denotes the cardinalityof the set of variables. Although similar to k-SAT, the new proposed model k-CSP has growing length of constraint scopes,the two models are essentially different from each other, more specifically, the tightness of constraint relations is variant fork-SAT while is fixed for the model k-CSP. For the new model k-CSP we theoretically prove the existence of a phase transitionwhen the parameter k grows up to a logarithm function of n, and determine the exact location of the phase transition point.Further, we experimentally demonstrate the performance of the proposed model k-CSP. The experiments we conducted onthe k-CSP not only verify the theoretical results we established, but also illustrate that the computational complexity of thek-CSP grows exponentially with n (the number of variables) and the worse-cases happen around the phase transition point.We note that, the model k-CSP can generate instances as easily as the model RB since there is no other restrictions on theconstraint relations except the fixed tightness; on the other hand, the parameter k of the model k-CSP is growing up veryslowly as a logarithm function rather than the power function appearing in the model RB. In summary, the model k-CSPcan easily and naturally generate asymptotically non-trivial CSP instances within a reasonably small range of domain sizeand constraint scope length, thus it is very suitable for testing the capability of CSP algorithms.The algebraic CSP, which employs algebraic structures to the domains and the constraint relations of CSP model, isanother popular approach to construct a CSP model. We note that the algebraic CSP approach has received considerableattention in recent years [4]. One classical example of algebraic CSPs is the linear CSP, which domains are finite fields andconstraint relations are affine subspaces of the vector spaces over the finite fields. One of the major advantages of variouslinear CSP models [3,5,6,8,9,13,15] is that they all exhibit satisfiability thresholds. This motivates our other research inconstructing a random CSP model that combines the model k-CSP mentioned above with the linear CSP model.To combine the advantages of linear CSP and the model k-CSP, we incorporate certain algebraic structure to the domainsand constraint relations of k-CSP and then introduce another type of random linear CSP model, named k-hyper-F-linearCSP. For each instance of the new proposed model, we assume that the domain could be any finite field, which is denotedby F; the constraint relations are randomly chosen from the hyperplanes of the vector space Fk, where k is the lengthof constraint scopes. Similar to the model k-CSP, the length of constraint scopes k is uniformly variant as a function of n,where n denotes the number of variables. We exhibit theoretically the exact phase transition of the model k-hyper-F-linear CSP. When comparing with the linear CSP models from [3,5,6,8,9,13], we provide a more general formulation anda new proof based on a more general argument, which make the k-hyper-F-linear CSP model more widely applicable inpractice.This paper is organized as follows. Section 2 states some preliminary definitions, introduces the random model k-CSPand ",
            {
                "entities": [
                    [
                        4098,
                        4126,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 210 (2014) 78–122Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe dropout learning algorithmPierre Baldi∗, Peter SadowskiDepartment of Computer Science, University of California, Irvine, CA 92697-3435, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 11 June 2013Received in revised form 18 February 2014Accepted 18 February 2014Available online 24 February 2014Keywords:Machine learningNeural networksEnsembleRegularizationStochastic neuronsStochastic gradient descentBackpropagationGeometric meanVariance minimizationSparse representationsDropout is a recently introduced algorithm for training neural networks by randomlydropping units during training to prevent their co-adaptation. A mathematical analysisof some of the static and dynamic properties of dropout is provided using Bernoulligating variables, general enough to accommodate dropout on units or connections, andwith variable rates. The framework allows a complete analysis of the ensemble averagingproperties of dropout in linear networks, which is useful to understand the non-linearcase. The ensemble averaging properties of dropout in non-linear logistic networks resultfrom three fundamental equations: (1) the approximation of the expectations of logisticfunctions by normalized geometric means, for which bounds and estimates are derived;(2) the algebraic equality between normalized geometric means of logistic functions withthe logistic of the means, which mathematically characterizes logistic functions; and (3) thelinearity of the means with respect to sums, as well as products of independent variables.The results are also extended to other classes of transfer functions, including rectifiedlinear functions. Approximation errors tend to cancel each other and do not accumulate.Dropout can also be connected to stochastic neurons and used to predict firing rates,and to backpropagation by viewing the backward propagation as ensemble averagingin a dropout linear network. Moreover, the convergence properties of dropout can beunderstood in terms of stochastic gradient descent. Finally, for the regularization propertiesof dropout, the expectation of the dropout gradient is the gradient of the correspondingapproximation ensemble, regularized by an adaptive weight decay term with a propensityfor self-consistent variance minimization and sparse representations.© 2014 The Authors. Published by Elsevier B.V.Open access under CC BY-NC-ND license.1. IntroductionDropout is a recently introduced algorithm for training neural networks [27]. In its simplest form, on each presentationof each training example, each feature detector unit is deleted randomly with probability q = 1 − p = 0.5. The remainingweights are trained by backpropagation [40]. The procedure is repeated for each example and each training epoch, shar-ing the weights at each iteration (Fig. 1.1). After the training phase is completed, predictions are produced by halving allthe weights (Fig. 1.2). The dropout procedure can also be applied to the input layer by randomly deleting some of theinput-vector components—typically an input component is deleted with a smaller probability (i.e. q = 0.2).The motivation and intuition behind the algorithm is to prevent overfitting associated with the co-adaptation of featuredetectors. By randomly dropping out neurons, the procedure prevents any neuron from relying excessively on the output ofany other neuron, forcing it instead to rely on the population behavior of its inputs. It can be viewed as an extreme form of* Corresponding author.E-mail address: pfbaldici@uci.edu (P. Baldi).http://dx.doi.org/10.1016/j.artint.2014.02.0040004-3702 © 2014 The Authors. Published by Elsevier B.V.Open access under CC BY-NC-ND license.\fP. Baldi, P. Sadowski / Artificial Intelligence 210 (2014) 78–12279Fig. 1.1. Dropout training in a simple network. For each training example, feature detector units are dropped with probability 0.5. The weights are trainedby backpropagation (BP) and shared with all the other examples.Fig. 1.2. Dropout prediction in a simple network. At prediction time, all the weights from the feature detectors to the output units are halved.bagging [17], or as a generalization of naive Bayes [23], as well as denoising autoencoders [42]. Dropout has been reportedto yield remarkable improvements on several difficult problems, for instance in speech and image recognition, using wellknown benchmark datasets, such as MNIST, TIMIT, CIFAR-10, and ImageNet [27].In [27], it is noted that for a single unit dropout performs a kind of “geometric” ensemble averaging and this propertyis conjectured to extend somehow to deep multilayer neural networks. Thus dropout is an intriguing new algorithm forshallow and deep learning, which seems to be effective, but comes with little formal understanding and raises severalinteresting questions. For instance:1. What kind of model averaging is dropout implementing, exactly or in approximation, when applied to multiple layers?2. How crucial are its parameters? For instance, is q = 0.5 necessary and what happens when other values are used? Whathappens when other transfer functions are used?3. What are the effects of different deletion randomization procedures, or different values of q for different layers? Whathappens if dropout is applied to connections rather than units?4. What are precisely the regularization and averaging properties of dropout?5. What are the convergence properties of dropout?To answer these questions, it is useful to distinguish the static and dynamic aspects of dropout. By static we refer toproperties of the network for a fixed set of weights, and by dynamic to properties related to the temporal learning process.We begin by focusing on static properties, in particular on understanding what kind of model averaging is implementedby rules like “halving all the weights”. To some extent this question can be asked for any set of weights, regardless of thelearning stage or procedure. Furthermore, it is useful to first study the effects of droupout in simple networks, in particularin linear networks. As is often the case [8,9], understanding dropout in linear networks is essential for understandingdropout in non-linear networks.Related work. Here we point out a few connections between dropout and previous literature, without any attempt at beingexhaustive, since this would require a review paper by itself. First of all, dropout is a randomization algorithm and as suchit is connected to the vast literature in computer science and mathematics, sometimes a few centuries old, on the useof randomness to derive new algorithms, improve existing ones, or prove interesting mathematical results (e.g. [22,3,33]).\f80P. Baldi, P. Sadowski / Artificial Intelligence 210 (2014) 78–122Second, and more specifically, the idea of injecting randomness into a neural network is hardly new. A simple Google searchyields dozen of references, many dating back to the 1980s (e.g. [24,25,30,34,12,6,37]). In these references, noise is typicallyinjected either in the input data or in the synaptic weights to increase robustness or regularize the network in an empiricalway. Injecting noise into the data is precisely the idea behind denoising autoencoders [42], perhaps the closest predecessorto dropout, as well as more recent variations, such as the marginalized-corrupted-features learning approach described in[29]. Finally, since the posting of [27], three articles with dropout in their title were presented at the NIPS 2013 conference:a training method based on overlaying a dropout binary belief network on top of a neural network [7]; an analysis of theadaptive regularizing properties of dropout in the shallow linear case suggesting some possible improvements [43]; and asubset of the averaging and regularization properties of dropout described primarily in Sections 8 and 11 of this article [10].2. Dropout for shallow linear networksIn order to compute expectations, we must associate well defined random variables with unit activities or connectionweights when these are dropped. Here and everywhere else we will consider that a unit activity or connection is set to 0when the unit or connection is dropped.2.1. Dropout for a single linear unit (combinatorial approach)We begin by considering a single linear unit computing a weighted sum of n inputs of the formS = S(I) =n(cid:2)i=1w i Ii(1)where I = (I1, . . . , In) is the input vector. If we delete inputs with a uniform distribution over all possible subsets of inputs,or equivalently with a probability q = 0.5 of deletion, then there are 2n possible networks, including the empty network.For a fixed I , the average output over all these networks can be written as:E(S) = 12n(cid:2)NS(N , I)(2)where N is used to index all possible sub-networks, i.e. all possible edge deletions. Note that in this simple case, deletionof input units or of edges are the same thing. The sum above can be expanded using networks of size 0, 1, 2, . . . , n in theform(cid:3)(cid:4)(cid:5)(cid:6) (cid:2)(cid:7)w i Ii + w j I j+ · · ·(cid:8)w i Ii+E(S) = 12n0 +n(cid:2)i=11(cid:2)i< j(cid:2)n(cid:7)(cid:6)n − 1n − 1= 2n−1In this expansion, the term w i Ii occurs(cid:7)(cid:7)(cid:6)(cid:6)1 +n − 11n − 12+ · · · +times. So finally the average output isE(S) = 2n−12n(cid:5)w i Ii=n(cid:2)i=1n(cid:2)i=1w i2Ii+(cid:4)(3)(4)(5)Thus in the case of a single linear unit, for any fixed input I the output obtained by halving all the weights is equal to thearithmetic mean of the outputs produced by all the possible sub-networks. This combinatorial approach can be applied toother cases (e.g. p (cid:3)= 0.5) but it is much easier to work directly with a probabilistic approach.2.2. Dropout for a single linear unit (probabilistic approach)Here we simply consider that the output is a random variable of the formS =n(cid:2)i=1w iδi Ii(6)where δi is a Bernoulli selector random variabl",
            {
                "entities": [
                    [
                        3694,
                        3722,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 278–298Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantics and complexity of recursive aggregates in answer setprogramming ✩Wolfgang Faber∗, Gerald Pfeifer, Nicola LeoneDepartment of Mathematics, University of Calabria, 87030 Rende (CS), Italya r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Nonmonotonic reasoningAnswer set programmingAggregatesComputational complexityThe addition of aggregates has been one of the most relevant enhancements to thelanguage of answer set programming (ASP). They strengthen the modelling power of ASPin terms of natural and concise problem representations. Previous semantic definitionstypically agree in the case of non-recursive aggregates, but the picture is less clear foraggregates involved in recursion. Some proposals explicitly avoid recursive aggregates, mostothers differ, and many of them do not satisfy desirable criteria, such as minimality orcoincidence with answer sets in the aggregate-free case.In this paper we define a semantics for programs with arbitrary aggregates (includingmonotone, antimonotone, and nonmonotone aggregates) in the full ASP language allowingalso for disjunction in the head (disjunctive logic programming — DLP). This semantics isa genuine generalization of the answer set semantics for DLP, it is defined by a naturalvariant of the Gelfond–Lifschitz transformation, and treats aggregate and non-aggregateliterals in a uniform way. This novel transformation is interesting per se also in theaggregate-free case, since it is simpler than the original transformation and does notneed to differentiate between positive and negative literals. We prove that our semanticsguarantees the minimality (and therefore the incomparability) of answer sets, and wedemonstrate that it coincides with the standard answer set semantics on aggregate-freeprograms.Moreover, we carry out an in-depth study of the computational complexity of the language.The analysis pays particular attention to the impact of syntactical restrictions on programsin the form of limited use of aggregates, disjunction, and negation. While the addition ofaggregates does not affect the complexity of the full DLP language, it turns out that theirpresence does increase the complexity of normal (i.e., non-disjunctive) ASP programs up tothe second level of the polynomial hierarchy. However, we show that there are large classesof aggregates the addition of which does not cause any complexity gap even for normalprograms, including the fragment allowing for arbitrary monotone, arbitrary antimonotone,and stratified (i.e., non-recursive) nonmonotone aggregates. The analysis provides someuseful indications on the possibility to implement aggregates in existing reasoning engines.© 2010 Elsevier B.V. All rights reserved.✩Parts of this work have been published in preliminary form in the proceedings of the conferences JELIA’04 (Faber et al. (2004) [1]) and IJCAI’05 (Calimeriet al. (2005) [2]).* Corresponding author.E-mail addresses: faber@mat.unical.it (W. Faber), gerald@pfeifer.com (G. Pfeifer), leone@mat.unical.it (N. Leone).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.002\fW. Faber et al. / Artificial Intelligence 175 (2011) 278–2982791. IntroductionAround 1960, McCarthy proposed the use of logical formulas as a basis for a knowledge representation language [3,4]. Itwas soon realized, however, that classical logic is not always adequate to model commonsense reasoning [5]. As an alterna-tive, it has been suggested to represent commonsense reasoning using logical languages with nonmonotonic consequencerelations, which allow new knowledge to invalidate some of the previous conclusions. This observation has led to the de-velopment and investigation of new logical formalisms, nonmonotonic logics. The most famous of these are circumscription[6,7], default logic [8], and nonmonotonic modal logics [9–11]. More recently, from cross fertilizations between the field ofnonmonotonic logics and that of logic programming, another nonmonotonic language, called Answer Set Programming (ASP)[12,13], has emerged.Answer Set Programs [12,13], also called Disjunctive Logic Programs (DLP) [14], are logic programs where (nonmonotonic)negation may occur in the bodies, and disjunction may occur in the heads of rules. This language is very expressive in aprecise mathematical sense: it allows to express every property of finite structures that is decidable in the complexity class2 (NPNP) [15]. The high expressive power of the language, along with its simplicity, and the availability of a numberΣ Pof efficient ASP systems [16–23], has encouraged the usage of ASP and the investigation of new constructs enhancing itscapabilities. One of the most relevant improvements to the language of answer set programming has been the addition ofaggregates [24–37].Aggregates significantly enhance the language of answer set programming (ASP), allowing for natural and concise mod-elling of many problems. Non-recursive (also called stratified) aggregates have clear semantics and capture a large classof meaningful problem specifications. However, there are relevant problems for which recursive (unstratified) aggregateformulations are natural; the Company Control problem, illustrated next, is a typical example, cf. [24–26,29].Example 1.1. We are given a set of facts for predicate company( X), denoting the companies involved, and a set of facts forpredicate ownsStk(C 1, C 2, Perc), denoting the percentage of shares of company C 2, which is owned by company C 1. Then,company C 1 controls company C 2 if the sum of the shares of C 2 owned either directly by C 1 or by companies, which arecontrolled by C 1, is more than 50%. This problem has been encoded as the following program Pctrl by many authors in theliterature [24–26,29].1controlsStk(C 1, C 1, C 2, P ):-ownsStk(C 1, C 2, P ).controlsStk(C 1, C 2, C 3, P ):-company(C 1), controls(C 1, C 2), ownsStk(C 2, C 3, P ).controls(C 1, C 3):-company(C 1), company(C 3),(cid:2)#sum(cid:3)P , C 2 : controlsStk(C 1, C 2, C 3, P )> 50.Intuitively, controlsStk(C 1, C 2, C 3, P ) denotes that company C 1 controls P percent of C 3 shares “through” company C 2(as C 1 controls C 2, and C 2 owns P percent of C 3 shares). Predicate controls(C 1, C 2) encodes that company C 1 controlscompany C 2. For two companies, say, c1 and c3, controls(c1, c3) is derived if the sum of the elements in the multiset{{P | ∃C 2 : controlsStk(c1, C 2, c3, P )}} is greater than 50. Note that in the adopted DLV syntax this multiset is expressed by{P , C 2 : controlsStk(c1, C 2, c3, P )} where the variable C 2 avoids that duplicate occurrences of P are eliminated.The encoding of Company Control contains a recursive aggregate (since predicate controlsStk in the aggregate depends onthe head predicate controls). Unfortunately, however, recursive aggregates are not easy to handle, and their semantics is notalways straightforward.Example 1.2. Consider the following two programs:(cid:2)(cid:2)p(a):-#count(cid:3)X : p(X)(cid:3)> 0.P 1 :(cid:2)(cid:2)p(a):-#count(cid:3)X : p(X)(cid:3)< 1.P 2 :In both cases p(a) is the only atom for p which might be true, so, intuitively, following the closed-world assumption, onemay expect that #count{ X : p( X)} > 0 is true iff p(a) is true; while #count{ X : p( X)} < 1 should be true iff p(a) is false.Thus, the above programs should, respectively, behave like the following standard programs:(cid:2)(cid:3)p(a):-p(a).(cid:4)1P:(cid:2)(cid:3)p(a):-not p(a).(cid:4)2P:This is not always the case in the literature, and there is a debate on the best semantics for recursive aggregates.There have been several attempts for defining a suitable semantics for recursive aggregates [25,27–30,34–37]. However,while previous semantic definitions typically agree in the non-recursive case, the picture is not so clear for recursion. Some1 Throughout this paper, we adopt the concrete syntax of the DLV language [38] to express aggregates in the examples.\f280W. Faber et al. / Artificial Intelligence 175 (2011) 278–298proposals explicitly avoid recursive aggregates, many others differ, and several of them do not satisfy desirable criteria, suchas minimality.2 For a more detailed analysis we refer to Section 5.In this paper, we make a step forward and provide a fully declarative semantics which works for disjunctive programsand arbitrary aggregates. Moreover, we carry out an in-depth analysis of the computational complexity of ASP with aggre-gates, which pays particular attention to the impact of syntactical restrictions on programs in the form of limited use ofaggregates, disjunction, and negation.The main contributions of the paper are the following:• We provide a definition of the answer set semantics for disjunctive programs with arbitrary aggregates (includingmonotone aggregates, antimonotone aggregates, and aggregates which are neither monotone nor antimonotone). Thissemantics is fully declarative and is given in the standard way for answer sets, by a generalization of the well-knownGelfond–Lifschitz transformation, which treats aggregate and non-aggregate literals in a uniform way. This novel trans-formation is interesting per se also in the aggregate-free case, since it is simpler than the original transformation anddoes not differentiate between the types of literals (positive and negative) in the program. Interestingly, the generalityof this transformation allows for defining the semantics of arbitrary linguistic extensions of ASP, and has already beenapplied also in other contexts (see Section 5).• We study the properties of the proposed semantics, and show the following results:◦ Our answer sets are subset-minimal models, and therefore they are incomparable to each other, which is generallyseen as an important property of nonmonotonic semantics [32,29].◦ For aggregate-free",
            {
                "entities": [
                    [
                        3271,
                        3299,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 656–684www.elsevier.com/locate/artintProof planning with multiple strategiesErica Melis, Andreas Meier, Jörg Siekmann ∗Universität des Saarlandes and German Research Center for Artificial Intelligence (DFKI), Saarbrücken, GermanyReceived 2 May 2006; received in revised form 13 November 2007; accepted 16 November 2007Available online 22 November 2007AbstractProof planning is a technique for theorem proving which replaces the ultra-efficient but blind search of classical theorem provingsystems by an informed knowledge-based planning process that employs mathematical knowledge at a human-oriented level ofabstraction. Standard proof planning uses methods as operators and control rules to find an abstract proof plan which can beexpanded (using tactics) down to the level of the underlying logic calculus.In this paper, we propose more flexible refinements and a modification of the proof planner with an additional strategic level ofcontrol above the previous proof planning control. This strategic control guides the cooperation of the problem solving strategiesby meta-reasoning.We present a general framework for proof planning with multiple strategies and describe its implementation in the MULTIsystem. The benefits are illustrated by several large case studies, which significantly push the limits of what can be achieved by amachine today.© 2007 Elsevier B.V. All rights reserved.Keywords: Theorem proving; Proof planning; Blackboard architecture; Planning; Meta-reasoning1. IntroductionThe control problem, i.e. how to choose one of the many potential actions an intelligent agent—man or machinealike—has at its disposal, is fundamental to all problem solving processes. It stimulated the development of manysoftware architectures in artificial intelligence, including blackboard architectures [18,19,24] and multi agent sys-tems [54].In spite of their increasing sophistication, however, many systems are still rather inflexible and employ a pre-determined and fixed control schema. In particular, this is true for most classical automated theorem proving systemswhich expand and efficiently search through very large search spaces guided by pre-fixed general-purpose filters andheuristics. A modification on the fly or a flexible combination of different heuristics to tackle sub-problems is ingeneral not possible. As a result, these systems can not recognize mathematically promising search paths as they go,and they make up for this deficiency by their sophisticated representational techniques (see Chapter VIII in [45]) and* Corresponding author.E-mail addresses: melis@dfki.de (E. Melis), meier@dacos.com (A. Meier), siekmann@dfki.de (J. Siekmann).URLs: http://www.ags.uni-sb.de/~melis (E. Melis), http://www-ags.dfki.uni-sb.de/JS/index.html (J. Siekmann).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.004\fE. Melis et al. / Artificial Intelligence 172 (2008) 656–684657general search heuristics to blindly examine a space of up to several billion nodes. The final performance of a system,however, depends on whether the pre-selected search heuristic is appropriate for the particular problem at hand.1As a reaction to these problems several remedies have been tried:(1) Different systems are competitively combined such that machine resources are allocated to the most promisingsystem at a time [2,47,51,59]. Typical meta-heuristics for system selection and resource allocation evaluate char-acteristics of the problem at hand and compare it to past experience. For instance: “in the past, the system S withheuristics H was best suited for problems with the following number and type of clauses and/or equations”.(2) Cooperation of different systems, which exchange intermediate results [15], where meta-heuristics are used todecide which results to exchange. For example: “The derived clause C is a unit clause, which could be useful inanother system and hence, should be exported”.Proof planning [7] is a technique for theorem proving in which proofs are planned at a higher level of abstraction,where individual choices can be mathematically motivated by the semantics of the domain. Thus, proof planningswings the pendulum from the desert of the blind but ultra-efficient search-based paradigm of classical automatedtheorem proving to the green grass of knowledge based systems. In particular, proof planning tackles theorems notonly using general logic based methods but also by using domain-specific and general mathematical knowledge,encoded explicitly into methods and control [39,41]. Essentially, however, proof planners like CLAM or (cid:2)MEGA, aremonolithic, in the sense that the planning algorithm is pre-defined and cannot take full advantage of the runtimeknowledge that is available during the problem solving process.Our experiments with proof planning in the past decade indicate that the search process would benefit substantiallyfrom more flexibility of choice and more usage of runtime knowledge instead of a mere competitive application ofseveral systems or the simple exchange of intermediate results. This situation has been recognized in other real-worldapplications of planning as well, see, e.g., [56].In the following, we report our results for proof planning with multiple strategies, which is built upon three generalprinciples: (1) decomposition of the monolithic search process into independent processes; (2) structuring the setof methods and the corresponding control knowledge into strategies; (3) meta-reasoning with explicitly representedcontrol knowledge at a strategic level.After more than a decade of development and experimentation this article presents our current ‘final’ stable solu-tion, introducing conceptually clean notions and notation and finally backs it all up with several large case studies.Most case studies had been published before at conferences and workshops on automated theorem proving, but step-ping back now from the presentation at the time of those particular achievements we like to present and summarizeour current more general view in this journal paper.The remainder of this paper is organized as follows. After a brief introduction to proof planning and some motivat-ing examples, we show how the three principles above are implemented in the MULTI system [32,35]. The results arethen discussed and evaluated with several case studies, which illustrate the potential of explicitly represented strategicknowledge and control and demonstrate what can be achieved with this automated reasoning system today.2. Preliminaries(cid:2)MEGA is a theorem proving environment developed at the University of Saarbrücken based on proof planning andother techniques and MULTI is now the proof planner of the current system. The (cid:2)MEGA project [48] represents one ofthe major attempts to build an all encompassing assistant tool for the working mathematician or the software engineer,which combines interactive and automated proof construction for domains with rich and well-structured mathematicalknowledge. The inference mechanism at the lowest level of abstraction is based on a higher order natural deduction(ND) variant of a soft-sorted version of Church’s simply typed λ-calculus [10]. While this represents the “machinecode” of the system the user will seldom want to see, the search for a proof is conducted at a higher level of abstractionby the proof planning process.1 The general wisdom is: no single theorem prover or heuristic is best for all problems, see contest http://www.cs.miami.edu/~tptp/CASC/.\f658E. Melis et al. / Artificial Intelligence 172 (2008) 656–684Proof planning differs from traditional search-based techniques in automated theorem proving as the proof of atheorem is planned at an abstract level, where an outline of the proof is constructed first. This outline, that is theabstract proof plan, can be recursively expanded with methods and tactics eventually down to a logical calculusproof. Most plan operators, called methods for this reason, represent mathematical techniques familiar to a workingmathematician.Knowledge-based proof planning [41] employs even more techniques from artificial intelligence such as hierar-chical planning, constraint solving and control rules, which encode the “how to solve it” knowledge for guiding thesearch at an abstract level. While the knowledge of a mathematical domain represented by operators and controlrules can be specific to the mathematical field at hand, the representational techniques and reasoning procedures aregeneral-purpose.The plan operators in mathematical proof planning are called methods. They (partially) describe changes of proofstates by pre- and postconditions which are called premises and conclusions in the following. The premises andconclusions of a method are formulae (more precisely: sequents) in a higher-order language and the conclusions areconsidered as logically inferable from the premises.Hence, a mathematical theorem proving problem is expressed as a planning problem whose initial state consistsof the proof assumptions and the goal description which is the conjecture to be shown. Proof planning searches for asequence (or a hierarchy) of instantiated methods, a solution plan, which transforms the initial state with assumptionsinto a state containing the conjecture.A proof planner can be realized by the following search procedure:• As long as there are goals, select a goal and try to apply a method to it.• If there is a goal for which no method is applicable, then backtrack to the method application, which introducedthis goal.• When all goals are closed, employ a constraint solver to instantiate the variables within the methods.The reason for the late variable instantiation is to first collect as many individual constraints as possible (as long asthere are goals) and instantiate all variables to satisfy the collected constraints only at the end.As opposed to precondition achievement planning [5",
            {
                "entities": [
                    [
                        2888,
                        2916,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 256 (2018) 105–129Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artint, Ewen Maclean d, Roberto Confalonieri e,c, Oliver Kutz e, A computational framework for conceptual blendingManfred Eppe a,b,∗Marco Schorlemmer c, Enric Plaza c, Kai-Uwe Kühnberger fa University of Hamburg, Germanyb International Computer Science Institute, Berkeley, USAc IIIA-CSIC, Barcelona, Catalonia, Spaind University of Edinburgh, UKe Free University of Bozen-Bolzano, Italyf University of Osnabrück, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 1 September 2016Received in revised form 3 November 2017Accepted 23 November 2017Available online 2 December 2017Keywords:Computational creativityConceptual blendingCognitive scienceAnswer set programmingWe present a computational framework for conceptual blending, a concept invention method that is advocated in cognitive science as a fundamental and uniquely human engine for creative thinking. Our framework treats a crucial part of the blending process, namely the generalisation of input concepts, as a search problem that is solved by means of modern answer set programming methods to find commonalities among input concepts. We also address the problem of pruning the space of possible blends by introducing metrics that capture most of the so-called optimality principles, described in the cognitive science literature as guidelines to produce meaningful and serendipitous blends. As a proof of concept, we demonstrate how our system invents novel concepts and theories in domains where creativity is crucial, namely mathematics and music.© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionCreativity is an inherent human capability that is crucial for the development and invention of new ideas and concepts [3]. This paper addresses a kind of creativity which Boden [3] calls combinational, and which has been studied by Fauconnier and Turner [27] in their framework of conceptual blending. In brief, conceptual blending is a process where one invents a novel concept, called the blend, by combining two familiar input concepts. For illustration, consider the classical example of blending the concepts house and boat (e.g. [34,27]). A possible result is the invention of a house-boat concept, where the medium on which a house is situated (land) becomes the medium on which boat is situated (water), and the inhabitant of the house becomes the passenger of the boat. Another possible blend is the boat-house, where the boat ‘inhabits’ the house.An inherent computational problem of conceptual blending is to find a common ground, called generic space, between the two input concepts [27]. For example, the house-boat blend has the generic space of a person being inside an object that is not situated on any medium (or that is situated on a more general medium). Once the generic space has been identified, one can develop possible blends by specialising the generic space with elements from the input concepts in a meaningful way. However, this is not trivial because the naive union of input spaces can lead to inconsistencies. For example, the medium on which an object is situated can not be land and water at the same time. Hence, before combining the input * Corresponding author at: University of Hamburg, Germany.E-mail addresses: eppe@informatik.uni-hamburg.de (M. Eppe), emaclea2@inf.ed.ac.uk (E. Maclean), roberto.confalonieri@unibz.it (R. Confalonieri).https://doi.org/10.1016/j.artint.2017.11.0050004-3702/© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\f106M. Eppe et al. / Artificial Intelligence 256 (2018) 105–129concepts, it is necessary to generalise at least one medium assignment. Another problem is the huge number of possible blends, which are often not meaningful. For example, blending house and boat such that the house becomes the passenger of the boat – imagine a house-transporting cargo vessel – is not very convincing. Consequently, one has to prune the search space by ruling out such low-quality blends.Conceptual blending is perceived as a milestone in human cultural development [27]. The main motivation behind blend-ing from an AI perspective is to find a computational interpretation of the human blending process, which could be an equally important milestone in the development of intelligent agents and autonomous systems. The value of conceptual blending for the development of creative systems has been witnessed by several works in the field of Artificial Intelligence and cognitive science, where particular implementations of this cognitive theory have been proposed [83,63,64,33,36].As we show in our survey in Sec. 5, existing approaches propose computational characterisations of conceptual blending by using different formal representations for the input spaces and different techniques for performing the blending oper-ation, and for the evaluation of the blends. For instance, Goguen and Harrell [33] logically formalise conceptual blending in terms of algebraic theories, Pereira [64] uses concept maps and frames, and rules and constraints to implement blend evaluation, while Veale and Donoghue [83] focus on the use semantic networks. The survey shows that providing a full computational account for conceptual blending is very challenging, in particular for the following two reasons:• When combining two input spaces, the generic space is of particular importance to steer possible variations of blends. However, computing the generic space is a challenging issue (e.g., [76]), especially for expressive representation lan-guages. Most existing blending frameworks are therefore not capable of computing a generic space automatically.• Having identified a generic space, there typically remains a huge number of possible combinations to generate blends. To prune this result space, blends need to be evaluated. One way to do this is to check their consistency and to apply certain quality metrics.In this paper, we address these issues and ask the following question:How can we orchestrate the blending of input concepts in a computationally efficient and feasible way, that is faithful to the cognitive theory of conceptual blending and can therefore be considered as computationally creative?To answer this question, we build a general creative computational framework for conceptual blending that allows the creation and evaluation of new blended concepts. The main contributions of this paper are as follows:• We provide a blending framework that accepts input concepts in form of semiotic systems (see Sec. 2.2). Herein, we use algebraic specifications similar to those proposed by Goguen [34, Def. 1], with the difference that we assign priorities not only to constructors, i.e., operators, but also to sorts, predicates, and axioms. This extra level of knowledge allows us to guide the generalisation search process and create meaningful generalisations of the input spaces more efficiently, and we also use it for the evaluation of blends.• We automate the discovery of generic spaces by applying amalgams, a notion known from case-based reasoning [61] (see Sec. 2.3). This process coordinates the interleaved generalisation and combination of input concepts as a non-monotonic search problem. We solve this search problem by using the declarative framework of Answer Set Programming (ASP) (e.g., [2]), as described in Sec. 3.• We evaluate blends by re-interpreting the optimality principles of Fauconnier and Turner [27] and give them a full computational account (see Sec. 2.1 and 3.6). This helps to prune the search space.• As a proof of concept, we implement our framework as an exploratory creative tool that can create interesting blends in the domain of mathematics and music. We also reproduce several blends that can be found in the literature. Finally, we show how our framework finds blends that belong to different domains (see Sec. 4).• We provide a survey to characterise existing computational blending systems (see Sec. 5) and position our own work within the state of the art.2. PreliminariesOur framework is inspired by the cognitive theory of conceptual blending as presented in Fauconnier and Turner [27], whose underlying principles are described in detail in Sec. 2.1. To realise these principles computationally, we follow the work by Goguen [34], who provides a category theoretical account of blending (see Sec. 2.2). Moreover, to make Goguen’s work computationally feasible, we implement blending as an amalgam-based workflow [61], a notion that was developed in case-based reasoning (see Sec. 2.3). The implementation framework for the amalgam-based workflow is Answer Set Program-ming (ASP), for which we provide a brief background in Sec. 2.4.2.1. Cognitive principles of blendingCreativity, understood as an unfamiliar combinations of familiar ideas, goes back to the notion of bisociation, the idea that creativity is often a result of an intersection and selective combination of rather distinct frames of reference, presented \fM. Eppe et al. / Artificial Intelligence 256 (2018) 105–129107Fig. 1. The ‘houseboat’ blend, adapted from [33].by Arthur Koestler in his book The Act of Creation in 1964 [46]. Based on these basic intuitions, within the cognitive sciences these ideas have been further developed into more concrete approaches of how to produce novel ideas (which may be concepts, theories, solutions to problems, works of art, etc.). One particular such approach, known as the theory of conceptual blending or conceptual integration has been proposed by Fauconnier and Turner [26] as a kind of primitive or fundamental cognitive operation underlying much of everyday thought and language. The process by which two concepts are ble",
            {
                "entities": [
                    [
                        3629,
                        3657,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 195 (2013) 291–315Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal identifiability via Chain Event GraphsPeter ThwaitesSchool of Mathematics, University of Leeds, LS2 9JT, United Kingdoma r t i c l ei n f oa b s t r a c tWe present the Chain Event Graph (CEG) as a complementary graphical model to theCausal Bayesian Network for the representation and analysis of causally manipulatedasymmetric problems. Our focus is on causal identifiability — finding conditions for whenthe effects of a manipulation can be estimated from a subset of events observable in theunmanipulated system. CEG analogues of Pearl’s Back Door and Front Door theorems arepresented, applicable to the class of singular manipulations, which includes both Pearl’sbasic Do intervention and the class of functional manipulations possible on BayesianNetworks. These theorems are shown to be more flexible than their Bayesian Networkcounterparts, both in the types of manipulation to which they can be applied, and in thenature of the conditioning sets which can be used.© 2012 Elsevier B.V. All rights reserved.Article history:Received 15 April 2011Received in revised form 6 September 2012Accepted 12 September 2012Available online 13 September 2012Keywords:Back Door theoremBayesian NetworkCausal identifiabilityCausal manipulationChain Event GraphConditional independenceFront Door theorem1. IntroductionIn this paper we consider cause and effect through the analysis of controlled models. The standard apparatus for suchan approach is the Causal Bayesian Network (CBN) [8,14,15,24]. The CBN is a version of a Bayesian Network (BN) where thedirectionality of the edges of the graph is interpreted as causal and the BN as representing a causal model.BNs are specifically designed to work with problems which have a natural product space structure, but many problemswhich we might wish to model do not have such a structure, and are asymmetric in that problem variables can have differentsets of possible outcomes given different outcomes of their parental variables, or even no possible outcomes given someoutcomes of their parents. The future development at any specific point depends on the particular history of the problemup to that point (i.e. on the outcomes of ancestral variables), and the values of a particular set of covariates at that point. Itis these types of problem that we are primarily concerned with here.So for instance, consider an infectious disease which is serious for people who have blood type O. Following a firsttreatment, patients with this blood type either die or need a second treatment; patients with other blood types either needa second treatment or make a full recovery. At the next stage of the process, patients who have died or fully recovered arenot offered a second treatment, but all other patients are given one of three possible second treatments, the choice of whichis dependent on factors such as hospital policy, consultant preference etc. Similar examples occur in many other areas (seefor example [1,3,7,12]).Context-specific variants of BNs have been developed for tackling asymmetric problems [2,13,18,20]. They can be usedfor the representation and analysis of problems whose future development at any specific point depends on the particularhistory of the problem up to that point, but their use is more circumscribed in problems where there may be no possibleoutcomes of some variables given certain histories or values of covariates. In both cases however the problems being anal-ysed are no longer fully represented by the topology of the graph — context-specific BNs require supplementary informationE-mail address: P.A.Thwaites@leeds.ac.uk.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.09.003\f292P. Thwaites / Artificial Intelligence 195 (2013) 291–315in the form of trees, or tree-like conditional probability tables attached to vertices to depict the asymmetries in the prob-lem. The Chain Event Graph (CEG) introduced in [22,25] is specifically designed for the representation and analysis of suchproblems. It is a function of an event tree [21], whose topology expresses the full collection of independence properties as-sociated with a problem. It is particularly useful when problems do not exhibit a product space structure, or when there isa lot of context-specific information present. All aspects of the model structure, including any context-specific dependenciesare represented in the topology of the graph — these are not bolted on.There have been many recent advances in CBN theory (see for example [5,6,9,16,27,28]), but little of this has madethe causal analysis of such asymmetric problems simpler. In particular, techniques such as Pearl’s Back and Front Doortheorems [14,15] have conditions which are expressed in terms of the topology of the CBN — if the structure of the problemcan no longer be expressed fully in terms of the topology of the graph, then this benefit is lost.CBNs can be used for the basic Do intervention of Pearl [15], which sets a particular variable to a particular value;and their use has been extended to functional manipulations (Do X = g(W ) for some set of variables W ), and stochasticmanipulations which assign a new probability distribution over the outcomes of the manipulated variable. The ease withwhich necessary conditions can be checked on the unmanipulated graph however vanishes very rapidly as we move awayfrom basic interventions.It can be argued [4,21,26] that causes are more naturally expressed as events rather than the values of some randomvariable. The CEG provides an ideal graphical representation given this argument. It is also a sensible representation forthe analysis of manipulations to events. By making additional assumptions concerning a CEG model we can give it a causalinterpretation, and extend its use to causal analysis in an analogous manner to that in which CBNs extend the use of BNs.Unlike analysis using CBNs, the analysis of functional and stochastic manipulations using CEGs is no more complex than theanalysis of the basic Do manipulation. In using the CEG for causal analysis we are building on the ideas of researchers whohave attempted to use trees for this purpose [19,21,24].Note also that in CBN analysis the standard methods for reducing the complexity of a manipulated probability expression(for example Pearl’s Back and Front Door theorems) rely on the use of blocking sets consisting of problem variables. WithCEG-based analysis our blocking sets are composed of events, allowing us more flexibility in their construction; so insteadof conditioning on a set of variables Z = {Z1, Z2} say, we might only need to condition on the events {patient is male, patientis female and aged below 40}.A crude version of a Back Door theorem for CEGs was introduced in [26]. Here we present a much more general BackDoor theorem as well as two alternative versions of a Front Door theorem. No knowledge of the content of [26] is assumedin this paper. The earlier paper touched briefly on some topics covered here, such as the use of CEGs for more sophisticatedmanipulations, but here we offer a comprehensive overview of causal analysis on CEGs, and look more carefully at causalidentifiability — finding conditions for when the effects of a manipulation can be estimated from a subset of events ob-servable in the idle system. Pearl’s Back and Front Door theorems give sufficient conditions for causal identifiability in BNs,and their arrival prompted a search for a complete set of conditions, using which an analyst could gauge whether or not anexpression could be estimated from a subset of observable variables [6,27,28]. This paper provides several sets of sufficientconditions for causal identifiability in CEGs. We anticipate that future work will allow us to find necessary and sufficientconditions for identifiability, expressed in terms of subsets of observable events as opposed to observable variables.As the CEG is a comparatively new structure, there have been minor modifications since [22] and [26]. In particular wehave removed the undirected edges from previous definitions so that the CEG is now a DAG. This has led to a less clutteredrepresentation and made the CEG easier to read.In Section 2 we define the CEG and manipulated CEG. Section 3 develops the Back Door theorem and the idea ofsingular manipulations. A Front Door theorem is then introduced in Section 4, and Section 5 provides a discussion of possibledirections for future research.2. Definitions and notationIn this section we define the CEG. We also provide some notation that will be used throughout the paper. We then turnour attention to what it means when we manipulate a CEG to an event, and present a definition of a manipulated CEG.The CEG is a function of an event tree [21], retaining those features of the tree which allow for the transparent repre-sentation of asymmetric problems. They are a significant extension to trees since they express within their topology a morecomplete description of the conditional independence structure of a problem.An event tree T is a directed tree with vertex set V (T ) and edge set E(T ). It has a single root vertex v 0, and a collectionof leaf vertices (see for example Fig. 1, where there are 7 leaf vertices). The root-to-leaf paths {λ} of T form the atoms ofthe event space. Events measurable with respect to this space are unions of these atoms.Let V 0(T ) denote the set of non-leaf vertices of T . Then each vertex v ∈ V 0(T ) labels a random variable X(v) whosestate space X(v) can be identified with the set of directed edges e(v, v(cid:4)(cid:3)(cid:4)(cid:3)(cid:3)) ∈ E(T ) emanating from v. For each X(v) we let(cid:5)∈ X(v)(cid:3))) are called the primitive probabilities of the tree; andΠ(v) ≡where πe(vΠ(T ) ≡(cid:2)πe(cid:3)v| e(cid:3) | vv, v(cid:3) | v) ≡ P ( X(v) = e(v, v(cid:5)Π(v)",
            {
                "entities": [
                    [
                        3843,
                        3871,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 193 (2012) 1–17Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA general model and thresholds for random constraintsatisfaction problemsYun Fan a, Jing Shen b,∗, Ke Xu ca Department of Mathematics, Central China Normal University, Wuhan, 430079, Chinab School of Science, Naval University of Engineering, Wuhan, 430033, Chinac State Key Lab of Software Development Environment, Beihang University, Beijing, 100191, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 February 2012Received in revised form 23 July 2012Accepted 17 August 2012Available online 21 August 2012Keywords:Constraint satisfaction problemPhase transitionIn this paper, we study the relation among the parameters in their most general settingthat define a large class of random CSP models d-k-CSP where d is the domain size andk is the length of the constraint scopes. The model d-k-CSP unifies several related modelssuch as the model RB and the model k-CSP. We prove that the model d-k-CSP exhibitsexact phase transitions if k ln d increases no slower than the logarithm of the number ofvariables. A series of experimental studies with interesting observations are carried outto illustrate the solubility phase transition and the hardness of instances around phasetransitions.Crown Copyright © 2012 Published by Elsevier B.V. All rights reserved.1. IntroductionThe constraint satisfaction problem (CSP in short) is a central topic in the artificial intelligence community. It is inter-esting that many random CSPs exhibit phase transitions. Since the seminal work of Cheesman et al. [3], the link betweenthe threshold phenomenon of CSPs and the computational hardness of CSPs has attracted a great interest of mathemati-cians, physicists and theoretical computer scientists. For the investigation of the threshold phenomenon of CSPs, numerousexperimental studies [26,28,30] have been carried out, which results show strong evidences that the instances in the phasetransition region are hard to solve. Therefore these CSPs with hard instances play an important role as they are used asbenchmarks to test different CSP algorithms.Random k-SAT is a special case of random CSPs, where each formula has precisely k literals per clause. In the pasttwo decades, random k-SAT has been widely studied. The satisfiability threshold for random 2-SAT is obtained in [4,15].Friedgut made tremendous progress in [13] towards establishing the existence of a sharp threshold for random k-SAT. Itis theoretically attained in [21] and [9] that the updated lower bound and upper bound of the threshold point of random3-SAT are 3.53 and 4.4898, respectively. However, the exact location of the phase transition of random k-SAT for k (cid:2) 3 isstill under investigation.Much research has gone into the study of random models of CSPs with constant domain size at least 2, e.g. [1,6–8,17–19,24,28]. The initial standard models, named A, B, C and D [19,28], turn out to be flawed as they do not exhibit non-trivialsatisfiability threshold when the length of constraint scopes and the size of domains are all fixed, see [1]. To get non-trivialphase transitions, researchers have been going on three directions. Some CSP models [17–19] restrict particular “structures”on constraint relations, so that the phase transitions are attained at a cost of more expenditure on generating randominstances.* Corresponding author.E-mail addresses: yunfan02@yahoo.com.cn (Y. Fan), shendina@hotmail.com (J. Shen), kexu@nlsde.buaa.edu.cn (K. Xu).0004-3702/$ – see front matter Crown Copyright © 2012 Published by Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.08.003\f2Y. Fan et al. / Artificial Intelligence 193 (2012) 1–17Instead of incorporating more structures in the relations, some researchers left the constraint relations without anyrestrictions and focused on allowing the domain size to grow up with the number of variables, e.g. [10,27,31]. In 2000, Xuand Li [31] constructed the well-known model RB, where the length of constraint scopes is fixed but the domain size of theinstances is growing up about a power function of the number of variables. A few years later, Frieze and Molloy proposedtwo natural models of random binary CSPs with non-constant domain size, and determined how fast the domain size mustgrow with the number of variables to guarantee that the two models exhibit coarse threshold [14]. To ensure that thesemodels can generate hard instances, the complexity of CSPs had been extensively investigated, e.g. [2,5,18,20,22,25,29,30,32].For the practical side, benchmarks based on the model RB had been widely used in various kinds of algorithm competitionsand in many research papers on algorithms.From another point of view, inspired by the work of Frieze and Wormald [16], some CSP models, e.g. [11,12], allowthe length of constraint scopes to grow moderately and the exact locations of phase transitions are gained. In [11] theauthors proposed the so-called model k-CSP; differently from the model RB, the domain size of the model k-CSP is fixedwhile the length, denoted by k, of constrain scopes of the model k-CSP is growing up to a logarithm function of n (thenumber of variables); they located mathematically the exact phase transition point and demonstrated experimentally theperformance of the model k-CSP in [11]. Because no restriction is put on constraint relations and the length k is growingvery slowly while the domain size d is fixed, it is convenient to generate the instances of the model k-CSP; this is suitablefor algorithmic practice.In this paper we study a new random CSP model, d-k-CSP, where both the domain size d and the length of constrainscopes k are allowed to vary with the number of variables n. We show that the new model has a phase transition and theexact threshold point can be quantified precisely if k ln d (cid:2) (1 + ε) ln n for an arbitrarily small positive real number ε. Thatis the major result of this paper.The new model d-k-CSP covers obviously both the model RB and the model k-CSP as two specially extreme cases; andin the two extreme cases, i.e. either k is fixed or d is fixed, the above major result covers the well-known results in [31]and [11]. Moreover, the effective range of the model d-k-CSP is much more extensive than those of the model RB and themodel k-CSP, it works well whenever k ln d increases no slower than ln n. Thus it provides us a lot of various choices to dealwith phase transitions of random CSPs; the various choices could meet various theoretical and practical requirements. Forexample, we can deduce at once from our major result that the model d-k-CSP with d growing up to ln n and k growingup to ln nln ln n has a phase transition and the exact threshold point can be located precisely; further, a series of experimentalstudies are carried out for that case and the results are reported in this paper.The rest of the paper is organized as follows. In Section 2, we formulate the random model d-k-CSP precisely, and stateour major result on the phase transition of the model d-k-CSP. Section 3 is contributed to a complete proof of our majorresult. The previous methods for the similar questions, e.g. the arguments in [11], are far from enough for the new extensivemodel; a new key idea to prove our major result is to divide the variant area of parameters, which we consider to estimatethe satisfiability probability in the “second moment method” stage, by suitable curves into several subareas, so that in eachsubarea we can estimate the probability in different ways. In Section 4, we compare precisely the model d-k-CSP with someprevious models and deduce the corresponding corollaries, and illustrate the vast effective range of the model d-k-CSP. InSection 5, we present the results of a series of experiments about the model d-k-CSP for the case d = ln n. Finally we drawour conclusions in Section 6.2. Random model d-k-CSPIn this paper, ln x = loge x denotes the natural logarithm function, and exp x = ex denotes the natural exponential func-tion. Denote by |T | the cardinality of the set T .Any instance of a constraint satisfaction problem is a triple I = ( X, D, C), where X = (x1, . . . , xn) is a sequence of n vari-ables, D = (D1, . . . , Dn) is a sequence of finite sets which are called the domains, and C = (C1, . . . , Ct ) with Ci = ( Xi, R i)) are subsequences of X of length ki for i = 1, . . . , t,which are called the constraints; more precisely, Xi = (xi1 , . . . , xikicalled the constraint scopes, and correspondingly, R i are subsets of D i1, called the constraint relations. LetA = D1 × · · · × Dn. Any element (a1, . . . , an) ∈ A is viewed as an assignment to the variables X = (x1, . . . , xn) with val-ues in the domains D, i.e. an evaluation f ( X) = ( f (x1), . . . , f (xn)) = (a1, . . . , an). If an assignment (a1, . . . , an) ∈ A satisfies) ∈ R i for all i = 1, . . . , t, then we say that (a1, . . . , an) is a solution of the instance I ; and at that case wethat (ai1 , . . . , aikisay that the instance I is satisfiable.× · · · × D ikiDefinition 2.1. Let n be the number of variables and t be the number of constraints; let d = d(n) and k = k(n) be two integerfunctions of the natural number n such that d(n) > 1 and k(n) > 1; let p be a positive constant with 0 < p < 1. A randomCSP model is said to be d-k-CSP if the instances are generated as follows:• every cardinality |D i| = d for i = 1, . . . , n;• for i = 1, . . . , t, the constraints are generated as follows:– the constraint scopes Xi = (xi1 , . . . , xik ) are randomly selected with repetition allowed from the subsequences oflength k of the variable sequence (x1, . . . , xn);\fY. Fan et al. / Artificial Intelligence 193 (2012) 1–173– the constraint relations R i are randomly selected with repetition allowed from the subsets of D i1with cardinality |R i| = pdk.× D i2× · · · × D ikLet Pr(SAT) denote the probability of a random",
            {
                "entities": [
                    [
                        3694,
                        3722,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 147–182www.elsevier.com/locate/artintHierarchical model-based diagnosis based onstructural abstractionLuca Chittaro ∗, Roberto RanonDepartment of Mathematics and Computer Science, University of Udine, via delle Scienze 206,33100 Udine, ItalyReceived 9 December 2002; received in revised form 20 June 2003AbstractAbstraction has been advocated as one of the main remedies for the computational complexityof model-based diagnosis. However, after the seminal work published in the early nineties, littleresearch has been devoted to this topic. In this paper, we consider one of the types of abstractioncommonly used in diagnosis, i.e., structural abstraction, investigating it both from a theoreticaland practical point of view. First, we provide a new formalization for structural abstraction thatgeneralizes and extends previous ones. Then, we present two new different techniques for model-based diagnosis that automatically derive easier-to-diagnose versions of a (hierarchical) diagnosisproblem on the basis of the available observations. The two proposed techniques are formulatedas extensions of the well-known Mozetic’s algorithm [I. Mozetic, Hierarchical diagnosis, in:W.H.L. Console, J. de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, SanMateo, CA, 1992, pp. 354–372], and experimentally contrasted with it to evaluate the obtainedefficiency gains. 2003 Elsevier B.V. All rights reserved.Keywords: Model-based diagnosis; Abstraction; Hierarchical reasoning1. IntroductionIn the last decade, Model-Based Diagnosis (MBD) [4,6,9,18] has been a very active areaof research in Artificial Intelligence that has led also to significant industrial projects (e.g.,[16,20,22]).* Corresponding author.E-mail addresses: chittaro@dimi.uniud.it (L. Chittaro), ranon@dimi.uniud.it (R. Ranon).0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2003.06.003\f148L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182Computational complexity of multiple fault diagnosis is one of the well-knownproblems that needs to be tackled in order to deploy real-world applications of MBD.Since the late eighties, some researchers (e.g., [10,12,14,19]) advocated abstractionas one of the main remedies for this problem. The proposed approaches are typicallyhierarchical: they represent the problem at multiple levels of detail, and then isolate faultsone level at a time, starting at the most abstract possible level and using the results at onelevel to focus reasoning at more detailed levels, thus reducing the overall computationalcost of diagnosis.Two kind of abstractions are commonly employed in MBD: structural abstraction [5,10], which aggregates components to describe the system at different levels of structuraldetail, and behavioral abstraction [12,14,19], which applies simplification operators todescribe the system at different levels of behavioral detail (e.g., moving from quantitativeto qualitative values in describing the functioning of components).In this paper, we build on seminal work on abstraction in MBD, and investigatestructural abstraction both from a theoretical and practical point of view.First, we provide a new logical formalization for structural abstraction that generalizesand extends previous ones [1,14,19]. Our proposal builds on the well-known consistency-based theory of diagnosis [8] and on a general framework (the semantic theory ofabstraction [15]) for the representation of abstraction between first-order theories. Unlikeprevious formalizations of structural abstraction, our proposal allows one to representcomponents with multiple behavioral modes (e.g., valves). Thus, it can be employedwith a wider class of physical systems. Moreover, the proposed formalization allowsone to easily prove some properties of structural abstraction that are useful in diagnosticreasoning.Second, we present two new techniques for hierarchical model-based diagnosis that areable to automatically derive easier-to-diagnose versions of a given diagnosis problem onthe basis of the available observations. The goal of our research is to move from simplyusing abstraction in diagnosis to using a good abstraction for the situation at hand, i.e.,using context to choose it. Indeed, one limit to the effectiveness of current approachesto hierarchical diagnosis is the fact that a single, pre-set hierarchical representation isemployed, regardless of the currently available diagnostic information. In some cases, thisleads to suboptimal or even counterproductive results in terms of efficiency (some detailedexamples will be illustrated in the paper). Unfortunately, most abstractions are usuallymanually engineered, and thus building a suitable abstract system representation for eachdiagnostic scenario is not a viable solution. We tackle the problem by using the idea ofautomatically tailoring an existing multi-level abstraction hierarchy (that may come fromdesign) to the particular problem at hand. The two techniques (called REARRANGE andBOTTOM-UP) we developed for this purpose:• are based on different strategies, and can be easily combined together to sum up theirrespective advantages;• build on the seminal work on hierarchical diagnosis by Mozetic [14], and are presentedas extensions to that approach.\fL. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182149To evaluate the efficiency gains that can be obtained, we present a detailed experimentalevaluation using a set of different hydraulic systems, considering the original Mozetic’sapproach, the two techniques in isolation, and the two techniques in combination.The techniques presented in the paper are general, and can be easily adopted by anymodel-based approach that follows the widely adopted consistency-based paradigm. Thepaper illustrates in detail the algorithms that implement the proposed techniques to allowinterested readers to easily include them and experiment with them in their systems.Finally, this work builds also on previous approaches we proposed in the domain ofFlow-Based Functional Models [3,17] and, more generally, in the context of structuralabstraction [2]. This paper extends and improves the latter in several directions, inparticular:• it proposes a proper theoretical framework, i.e., the formalization for structuralabstraction mentioned above;• it discusses (using also detailed examples) why using the same hierarchical represen-tation regardless of the currently available diagnostic information can limit or eveneliminate the efficiency gains of abstraction;• it refines the REARRANGE technique and proposes a new technique for hierarchicaldiagnosis (i.e., the BOTTOM-UP technique);• it presents a detailed experimental comparison of the proposed techniques and thereference approach of Mozetic.The paper is structured as follows: Section 2 summarizes background work on which webuild; Section 3 defines a formalization of structural abstraction in diagnosis and illustratesits properties, discussing also related work; Section 4 considers the problem of diagnosticreasoning with structural abstraction by illustrating the state of the art, proposing methodsto improve it by automatically tailoring existing abstractions to the situation at hand, andfinally illustrating the experimental activity that has been carried out. Section 5 concludesthe paper by presenting some possibilities for further work.2. BackgroundIn this section, we briefly illustrate those aspects of the consistency-based theory ofdiagnosis [8] and the semantic theory of abstraction [15] that are relevant to illustrateour work, and add some minor extensions to them. Moreover, we clarify the conceptsby introducing detailed examples taken from the hydraulic domain that will be followedthroughout the paper.2.1. Representing diagnosis problemsFollowing [8], a diagnosis problem D in a language L is defined as a triple (SD, OBS,COMPS) where SD and OBS are first-order theories in language L, representing the systemdescription and observations, respectively, and COMPS is a subset of the object constantsof L, i.e., the names of the system components.\f150L. Chittaro, R. Ranon / Artificial Intelligence 155 (2004) 147–182In order to explicitly separate structural knowledge (i.e., how components are connectedtogether) from behavioral knowledge (i.e., how components behave), we divide SD in thefollowing way:SD = CD ∪ BD ∪ Γwhere BD (behavioral description) represents the behavior of the components in thesystem, CD (compositional description) represents the structure of the system, and Γrepresents general knowledge (e.g., hydraulic laws) that is not specific to the consideredsystem.1Definition 1 (behavioral description of a component). The behavioral description of acomponent c (denoted BDc) in a diagnosis problem D, is a set of sentences of the form(cid:1)m(c) ⊃ σc( (cid:5)zc)(cid:2)Tc(c, (cid:5)zc) ⊃where• Tc(c, (cid:5)zc) is the component type predicate for c, and (cid:5)zc lists the ports of the component,• m is a predicate identifying one of the behavioral modes of c,• σc( (cid:5)zc) is a first-order formula with free variables (cid:5)zc describing the behavioral mode mof c with respect to its ports.The behavior of a component is thus represented as a set of first-order sentences, eachone corresponding either to a normal or a faulty behavior, which is defined by a predicateover the component ports.Definition 2 (behavioral description). The behavioral description BD of a diagnosisproblem D is the union of the behavioral descriptions of the components in COMPS.Definition 3 (compositional description). The compositional description CD of a diagnosisproblem D = (SD, OBS, COMPS) is a first-order sentence of the form(cid:3) (cid:4)(cid:5)T (S, (cid:5)zS) ≡ ∃z1, z2, . . . , znTc(c, (cid:5)zc)wherec∈COMPS• S is the system’s name,• every variable in (cid:5)zS appears in one of the tuples (cid:5)zc, for any c ∈ COMPS, and o",
            {
                "entities": [
                    [
                        1959,
                        1987,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 179–203www.elsevier.com/locate/artintPhase transition in a random NK landscape model ✩Sung-Soon Choi a, Kyomin Jung b, Jeong Han Kim c,∗,1a School of Computer Science and Engineering, Seoul National University, Seoul, 151-742 Koreab Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA 02139, USAc Department of Mathematics, Yonsei University, Seoul, 120-749 KoreaReceived 31 March 2006; received in revised form 26 March 2007; accepted 13 June 2007Available online 27 June 2007AbstractAn analysis for the phase transition in a random NK landscape model, NK(n, k, z), is given. This model is motivated frompopulation genetics and the solubility problem for the model is equivalent to a random (k + 1)-SAT problem. Gao and Culberson[Y. Gao, J. Culberson, An analysis of phase transition in NK landscapes, Journal of Artificial Intelligence Research 17 (2002)√309–332] showed that a random instance generated by NK(n, 2, z) with z > z0 = 27−7is asymptotically insoluble. Based on4empirical results, they conjectured that the phase transition occurs around the value z = z0. We prove that an instance generatedby NK(n, 2, z) with z < z0 is soluble with positive probability by providing a polynomial time algorithm. Using branching processarguments, we prove again that an instance generated by NK(n, 2, z) with z > z0 is asymptotically insoluble. The results show thephase transition around z = z0 for NK(n, 2, z). In the course of the analysis, we introduce a generalized random 2-SAT formula,which is of self interest, and show its phase transition phenomenon.© 2007 Elsevier B.V. All rights reserved.5Keywords: NK landscape; Fitness function; Solubility; Phase transition; Satisfiability problem1. Introduction1.1. NK landscape modelsA fitness landscape is a function that assigns each genetic composition (genotype) with the fitness of the expression(phenotype) of the genetic composition in an environment. The fitness landscape sometimes refers to its graphicalrepresentation as the word “landscape” indicates. The notion of fitness landscape was first introduced by Wright [47]for the analysis of population genetics. Afterwards, mathematical models to study the evolution on fitness landscapehave been proposed by many researchers including Franklin and Lewontin [20], Lewontin [34], Ewens [17], Kauffmanand Weinberger [30], and Macken and Perelson [35]. Among them, the NK model proposed by Kauffman [28] hasattracted considerable attention. The NK model generates fitness landscapes with correlation structures in which we✩ This work was partially carried on in Microsoft Research and partially supported by a grant of Research Institute of Mathematics funded byMicrosoft Korea.* Corresponding author.E-mail addresses: sschoi@soar.snu.ac.kr (S.-S. Choi), kmjung@mit.edu (K. Jung), jehkim@yonsei.ac.kr (J.H. Kim).1 This work was partially supported by Yonsei University Research Funds 2006-1-0078 and 2007-1-0025, and by the second stage of the BrainKorea 21 Project in 2007, and by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2006-312-C00455).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.06.002\f180S.-S. Choi et al. / Artificial Intelligence 172 (2008) 179–203can control the degree of interactions between genes and so, indirectly, the ruggedness and correlation degrees of thelandscapes.An NK landscape is a real-valued function defined on the set of binary n-tuples, {0, 1}n, which is of the formf (x1, x2, . . . , xn) =(cid:3)(cid:4)xi, Π(xi).fin(cid:2)i=1It is a summation of local fitness functions fi ’s, where each fi depends on its main variable xi and the variables inthe neighborhood of xi . Here the neighborhood Π(xi) is a subset of the set {x1, x2, . . . , xn} \\ {xi} and its size |Π(xi)|is k. Two ways have been introduced to choose the variables in the neighborhood Π(xi); adjacent neighborhood andrandom neighborhood. In the NK models with adjacent neighborhood, Π(xi) consists of the closest k variables (witha certain tie-break) to the main variable xi with respect to the indices modulo n. In the NK models with randomneighborhood, Π(xi) is composed of the k variables chosen uniformly at random from {x1, x2, . . . , xn} \\ {xi}. Localfitness functions are constructed independently of each other. For each local fitness function, a random value from aprobability distribution is assigned for each input. In general, it is independently (or nearly independently) assignedfor each of 2k+1 inputs and its expectation has small absolute value. In the Kauffman’s original model, the uniformdistribution between zero and one was used as the underlying distribution for local fitness functions. Later, it has beenreplaced with various probability distributions in the contexts of analysis and applications, inducing variants of theNK model.The name, “NK landscape”, embodies two parameters n and k. In terms of biology, each variable xi is regarded asa gene. The parameter n represents the number of genes that an organism has. The local fitness function fi quantifiesthe fitness of a character that is determined (or expressed in a biological term) by the gene xi affected by k other genesin Π(xi). A genotype of an organism is the values of genes xi ’s. Strictly speaking, the phenotype corresponding toa genotype is the characters expressed by the genotype. In practice, especially in this paper, the phenotype may beregarded as an organism that has the characters.Generally, the parameter k plays a role in controlling the degree of interactions between genes. The larger the valueof k is, the more genes interact one another in constructing the fitness landscape. Consider the case that k is small.Given two genotypes (or assignments) with the identical values for most of the genes, most of fi ’s produce the samevalues for the genotypes. Since the values of fi ’s are small relatively to the overall fitness f in absolute value, the twogenotypes have similar fitnesses, which implies that the landscape has strong correlation structure. On the other hand,if k is n − 1, each fi has (nearly) independent values for the two genotypes, which induces the landscape consistingof 2n (nearly) independent random values. Through experiments in the original NK model, Kauffman suggested thatthe ruggedness of the landscape generally increases as k increases [28].Kauffman [28] further analyzed various features of adaptive walks in the original NK model. Weinberger [42] andFontana et al. [19] carried out more detailed analysis of such walks. The asymptotic properties of the global and localoptima in NK landscapes were analyzed in various random NK landscape models. The differences between models aremainly due to the underlying distributions for local fitness functions. Evans and Steinsaltz [16], Durrett and Limic [13],Skellet et al. [39], and Kaul and Jacobson [31,32] used the exponential, negative exponential, uniform, and both ofnormal and uniform distributions in their works, respectively. Weinberger [43] and, later, Wright et al. [46] studiedthe computational complexities of problems related to NK landscapes. Gao and Culberson [22] showed a treewidthresult for NK landscapes in a probabilistic way.NK models have been used in biology, physics, and so on. In biology, NK models explain evolutions of biologicalobjects including amino acid sequences [29,30,35], protein or RNA sequences [6,18,19,37,41], and molecular quasi-species [14]. NK models have been served as a reference point for understanding the properties of those biologicalobjects. In statistical physics, models of spin-glasses are investigated from the viewpoint of NK models in [42]. Theevolution of organizations in a business environment is modeled based on an NK model [33]. NK models have beenused as a benchmark for evaluating various encoding schemes and genetic operators on the evolutionary algorithmand comparing them in the evolutionary computation area [5,24,36]. They have been also served as a basis for thedesign of problem difficulty measures for evolutionary algorithms [26,40] and the design of epistasis measures [38].\fS.-S. Choi et al. / Artificial Intelligence 172 (2008) 179–2031811.2. Solubility problem and phase transition in a random NK modelOne of the most interesting questions regarding NK landscape is the solubility problem that asks whether thereexists a genotype, or an assignment of values xi ’s, that maximizes the values of all local fitness functions. In otherwords, the problem asks whether there exists an organism that perfectly fits to a given environment, which seems tobe the most natural question regarding the NK landscape. For the problem it is enough to consider binary local fitnessfunctions having only two values 0 and 1, since one may replace each local fitness function by an auxiliary binaryfitness function that is 1 if and only if the value of the local fitness function is its maximum. An NK landscape f iscalled soluble if there is such an assignment. Otherwise, it is insoluble.Weinberger [43] and Wright et al. [46] proved that the problem for the NK landscapes with arbitrary neighborhoodis NP-complete for k (cid:2) 2. To investigate the difficulties of the solubility problems for typical NK landscapes with ran-dom neighborhood, Gao and Culberson [21] proposed two random NK landscape models and provided results aboutthe phase transition in the models. A phase transition in probabilistic combinatorial theory refers to the phenomenonthat the probability of a property being satisfied in the random model rapidly changes as the order parameter changesaround a certain value. The two random models are the uniform probability model and the fixed ratio model inspiredby the two random graph models of Erd˝os-Rényi type, G(n, p) and G(n, m), respectively. In the uniform probabilitymodel, the fitness value of each input for a local fitness function is independently assigned to zero",
            {
                "entities": [
                    [
                        3227,
                        3255,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 300 (2021) 103555Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHard choices in artificial intelligence, Thomas Krendl Gilbert b,∗∗Roel Dobbe a,∗a Faculty of Technology, Policy and Management, Delft University of Technology, The Netherlandsb Center for Human-Compatible AI, UC Berkeley, United States of Americac University of Wisconsin-Madison, United States of America, Yonatan Mintz c,1a r t i c l e i n f oa b s t r a c tArticle history:Received 22 June 2020Received in revised form 31 May 2021Accepted 5 July 2021Available online 14 July 2021Keywords:AI ethicsAI safetyAI governanceAI regulationPhilosophy of artificial intelligenceSociotechnical systems1. IntroductionAs AI systems are integrated into high stakes social domains, researchers now examine how to design and operate them in a safe and ethical manner. However, the criteria for identifying and diagnosing safety risks in complex social contexts remain unclear and contested. In this paper, we examine the vagueness in debates about the safety and ethical behavior of AI systems. We show how this vagueness cannot be resolved through mathematical formalism alone, instead requiring deliberation about the politics of development as well as the context of deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness in terms of distinct design challenges at key stages in AI system development. The resulting framework of Hard Choices in Artificial Intelligence(HCAI) empowers developers by 1) identifying points of overlap between design decisions and major sociotechnical challenges; 2) motivating the creation of stakeholder feedback channels so that safety issues can be exhaustively addressed. As such, HCAI contributes to a timely debate about the status of AI development in democratic societies, arguing that deliberation should be the goal of AI Safety, not just the procedure by which it is ensured.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).The rapid adoption of AI systems is reshaping many public, professional, and personal domains, providing opportunities for innovation while also generating new forms of harm. These harms are diverse, ranging from physical dangers related to new robotic systems (e.g. autonomous vehicles [1]), to economic losses related to welfare systems [2], to forms of racism and discrimination in systems that engage with biometrical data in public spaces [3,4] or with personal data on social media platforms [5,6]. These cases reveal emerging gaps between the promised beneficial outcomes of AI applications and the actual consequences of deployed systems. Ongoing risks and harms are thus a product of the sociotechnical gap, “the great divide between what we know we must support socially and what we can support technically” [7].In response, a broad spectrum of civil society initiatives have emerged to safeguard human domains from the effects of AI systems. Debates about the sociotechnical gap have taken two forms. One is the proposal of normative principles to determine how the gap should be filled or who should do it. This has led to a plethora of reports and statements [8]about how AI should be governed to respect fundamental rights [9,10], alongside a growing need to operationalize these principles [11]. For example, the OECD Principles on Artificial Intelligence “promote artificial intelligence (AI) that is inno-* Corresponding author: TU Delft - Faculty of Technology, Policy and Management, Building 31, Jaffalaan 5, 2628BX Delft, The Netherlands.** Corresponding author: UC Berkeley Graduate Division, 424 Sproul Hall, Delft, CA, 94720-5900, United States.E-mail addresses: r.i.j.dobbe@tudelft.nl (R. Dobbe), tg340@berkeley.edu (T. Krendl Gilbert).1 All authors contributed equally to this work.https://doi.org/10.1016/j.artint.2021.1035550004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fR. Dobbe, T. Krendl Gilbert and Y. MintzArtificial Intelligence 300 (2021) 103555vative and trustworthy and that respects human rights and democratic values,” and are signed by governments [12]. The European Commission recently proposed a regulatory framework to translate higher-level principles into concrete technical and legal solutions through “harmonized standards” [13]. However, it is unclear how these standards could reconcile the diverse needs of users in the context of particular systems and domains. Second is the proposal of technical tools to better fill the gap. While these efforts have generated many technical approaches related to mathematical criteria for “safety” or “fairness”, their systematic organization and prioritization remains unclear and contested [14–17].Missing from both debates is a sustained interrogation of what it means to identify, diagnose, and ultimately fill the sociotechnical gaps generated by AI systems. This entails asking deeper questions about how a given system may restructure human values and social practices, whether technical and governance criteria may be reconciled in design choices, and when or where gaps emerge across the system’s development lifecycle. Put differently, we lack a presentation of AI development as a form of machine politics: interrogating and evaluating how the choices that structure a system’s design and implementation in turn reorganize human domains. In terms of machine politics, AI development is a deliberative practice comprising how human constituencies make basic organizational choices about their status as a political community.Concretely, every AI system requires a consensus definition of what it would mean for it to be safe. But present proposals for the technical safety and governance of AI systems tend to focus on safety either as a criterion of technical design, operational conditions, or the experience of end users. This means safety criteria are marred by an underlying vagueness, the absence of unifying categories to establish whether a system’s capabilities are safe or not.This paper makes two key claims. First, AI development must be reconceived in terms of the multiple points of encounter between system capabilities and sociotechnical gaps. This requires a new vocabulary and framework to make sense of salient gaps in the context of technical design decisions, constituting a reciprocal relationship between system development and governance. Second, developers must take on new roles that are sensitive to feedback about how to manage these gaps. This requires communicative channels so that stakeholders are empowered to help shape the criteria for design decisions.Our contributions flow from these two claims. In Section 2 we supply a lexicon of terms for the problems at stake in sociotechnical gaps. In Section 3 we analyze the present landscape of proposed technical and normative solutions to particular gaps in terms of piecemeal responses to vagueness. In Section 4 we present Hard Choices in Artificial Intelligence (HCAI) as a systematic framework that maps possible gaps to particular feedback channels for designers and stakeholders to use. In Section 5 we present this framework’s implications for designers and advocates when evaluating the technical performance and governance standards of actual systems. Section 6 concludes.We emphasize that our concerns, while responding to more recent iterations of AI and computer systems, are not new. The research agenda of situated design [18] and Agre’s call for a “critical technical practice” [19] comprise classic phe-nomenological critiques of “good old-fashioned” symbolic and expert systems, in particular the need to become critical about certain formal assumptions behind intelligence and to reassess problematic metaphors for perception and action [20]. Yet much technical research today has moved beyond these critiques. Reinforcement learning (RL), for example, reflects Dreyfus’ exposition of intelligence as a learned, situated, dynamic activity developed from coping with one’s surrounding environment and embodying different strategies for action. The question is no longer what computers can or cannot do, buthow to structure computation in ways that support human values and concerns. To support this aim, we propose AI prac-titioners will need new cybernetic practices that guide how feedback may be solicited from existing and emerging political orders.We thus apply an insight to AI development that scholars in Science and Technology Studies (STS) have appreciated for over four decades: any and every technological system is political, requiring collective agency and corresponding forms of deliberation to ensure its safety for everyone affected by it [21].2. Towards a sociotechnical lexicon for AIAt present, AI research lacks a robust sociotechnical lexicon. This would include the emerging problem space of AI Safety as well as newly-relevant questions of cybernetics in the context of present and future AI governance topics. In this section we present a preliminary lexicon to reveal areas of overlap and divergence between these domains, enabling comparison between contemporary assumptions of AI development and possible alternative paradigms.As was stated in the original Dartmouth summer project proposal, research on artificial intelligence is meant to pursue “the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it” [22]. Beneath specific efforts to simulate language, brain models, and intellectual creativity, AI theorists were most interested in precision: adequately specifying the mechanisms underpinning intelligence such that they would be possible to replicate via computation and symbolic reasoning. This quest for exactness has con-tinued to",
            {
                "entities": [
                    [
                        3936,
                        3964,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2099–2127Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA condensed semantics for qualitative spatial reasoning about orientedstraight line segmentsReinhard Moratz a,∗, Dominik Lücke b, Till Mossakowski b,ca University of Maine, National Center for Geographic Information and Analysis, Department of Spatial Information Science and Engineering,348 Boardman Hall, Orono, 04469 Maine, USAb University of Bremen, Collaborative Research Center on Spatial Cognition (SFB/TR 8), Department of Mathematics and Computer Science,Bibliothekstr. 1, 28359 Bremen, Germanyc DFKI GmbH Bremen, Safe and Secure Cognitive Systems, Enrique-Schmidt-Str. 5, 28359 Bremen, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 13 March 2010Received in revised form 22 July 2011Accepted 25 July 2011Available online 10 August 2011Keywords:Qualitative spatial reasoningRelation algebraAffine geometryMore than 15 years ago, a set of qualitative spatial relations between oriented straight linesegments (dipoles) was suggested by Schlieder. However, it turned out to be difficult toestablish a sound constraint calculus based on these relations. In this paper, we presentthe results of a new investigation into dipole constraint calculi which uses algebraicmethods to derive sound results on the composition of relations of dipole calculi. Thisnew method, which we call condensed semantics, is based on an abstract symbolic modelof a specific fragment of our domain. It is based on the fact that qualitative dipole relationsare invariant under orientation preserving affine transformations.The dipole calculi allow for a straightforward representation of prototypical reasoning tasksfor spatial agents. As an example, we show how to generate survey knowledge fromlocal observations in a street network. The example illustrates the fast constraint-basedreasoning capabilities of dipole calculi. We integrate our results into two reasoning toolswhich are publicly available.© 2011 Elsevier B.V. All rights reserved.1. IntroductionQualitative reasoning about space abstracts from the physical world and enables computers to make predictions aboutspatial relations, even when precise quantitative information is not available [4]. A qualitative representation provides mech-anisms which characterize the essential properties of objects or configurations. In contrast, a quantitative representationestablishes a measure in relation to a unit of measurement which must be generally available [12]. The constant and gen-eral availability of common measures is now self-evident. In history, however, there used to be a lot of measurement systemsthat were only standardized locally. If you said that a pole was six feet long, that pole would have been 150 cm long in thegrand duchy of Hesse, but 300 cm in the duchy of Nassau. Even today several quantitative systems of measurements areused in the world, with the SI-system, the Imperial system and the United States Customary Units being the predominantones. One need only recall the history of length measurement technologies to see that the more local relative measures,which are represented qualitatively,1 can be managed by biological/epigenetic cognitive systems much more easily thanabsolute quantitative representations.* Corresponding author.E-mail addresses: moratz@spatial.maine.edu (R. Moratz), luecke@informatik.uni-bremen.de (D. Lücke), till@informatik.uni-bremen.de,Till.Mossakowski@dfki.de (T. Mossakowski).1 Compare for example the qualitative expression “one piece of material is longer than another” with the quantitative expression “this thing is twometers long.”0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.07.004\f2100R. Moratz et al. / Artificial Intelligence 175 (2011) 2099–2127Fig. 1. Orientation between two dipoles.Qualitative spatial calculi usually deal with elementary objects (e.g., regions, points) and qualitative relations betweenthem (e.g., “included in,” “adjacent,” “to the left of”). This is the reason why qualitative descriptions are quite natural forpeople. The two main trends in qualitative spatial reasoning (QSR) are topological reasoning about regions [9,44,45,49,64]and positional (e.g., direction and distance) reasoning about point configurations.2 Positional relations can refer to absolute(e.g., cardinal) directions [10,28,48] or to relative directions [25]. Relative position calculi based on points as basic entitiesare [3,13,23,35,54,65]. Most relative position calculi use ternary relations. In contrast cardinal directions are expressed asbinary relations. Positional calculi can be related to the results of psycholinguistic research in the field of reference systems[25,37]. Human natural language spatial propositions often express relative spatial positions based on reference directionsderived from the shape (and function) of one of the objects involved [25] (e.g., “The hill is to the left of the train”). Thisleads to binary relations between objects in which at least one of the objects has the feature of orientedness. For thatreason, in our conception, orientedness is an important feature of natural objects. In a corresponding qualitative calculus itis necessary to use more complex basic entities than points. One option for building more complex basic entities is to useoriented line segments (see Fig. 1) as basic entities. In this abstraction we lose the specific shape of the object, but preservethe feature of orientedness. With this approach we can design relative position calculi in which directions are expressed asbinary relations. The corresponding calculus, Schlieder’s line segment calculus [53],3 is the main topic of this paper. Orientedstraight line segments (which were called dipoles by Moratz et al. [36]) may be specified by their start and end points.Using dipoles as basic building blocks, more complex objects can be constructed (e.g., polylines, polygons) in a straight-forward manner (see Fig. 11). Therefore, dipoles can be used as the basic units in numerous applications. To give an example,line segments are central to edge-based image segmentation and grouping in computer vision. In addition, GIS systems oftenhave line segments as basic entities [21]. Polylines are particularly interesting for representing paths in cognitive robotics[40] and can serve as the geometric basis of a mobile robot when autonomously mapping its working environment [61]. Tosum up, dipole calculi are qualitative calculi that abstract from metric information. They focus on directional relations, butcan also be used to express certain topological relations (see Section 2.7).In the previous paragraphs, we discussed the representation of spatial knowledge. The central topic of this paper isthe collection of reasoning mechanisms which are employed to make use of the represented initial knowledge to inferindirect knowledge. In qualitative spatial reasoning two main reasoning modes are used: conceptual neighborhood-basedreasoning, and constraint-based reasoning about (static) spatial configurations. Conceptual neighborhood-based reasoningdescribes whether two spatial configurations of objects can be transformed into each other by small changes [11,15]. Theconceptual neighborhood of a qualitative spatial relation is the set of relations into which a relation can be changed withminimal transformations, e.g., by continuous deformation. Such a transformation can be a movement of one object in theconfiguration in a short period of time. The movement of an agent can then be modeled qualitatively as a sequence ofneighboring spatial relations which hold for adjacent time intervals.4 Based on this qualitative representation of trajectories,neighborhood-based spatial reasoning can for example be used as a simple, abstract model of the navigation of a spatialagent.5In constraint-based reasoning about spatial configurations, typically a partial initial knowledge of a scene is representedin terms of qualitative constraints between spatial objects. Implicit knowledge about spatial relations is then derived byconstraint propagation.6 Previous research has found that the mathematical notion of a relation algebra and related notionsare well-suited for this kind of reasoning. In particular, in an arbitrary relation algebra, the well-known path consistencyalgorithm computes an algebraic closure of a given constraint network, and this approximates, and in some cases alsodecides, the consistency of the network in polynomial time. Intelligent backtracking techniques and the study of maximaltractable subclasses also allow of efficiently deciding networks involving disjunctions. Starting with Allen’s interval algebra,this approach has been successfully applied to several qualitative constraint calculi, and is now supported by freely available2 There is also some work about directions between regions [18,55].3 However, Schlieder’s first presentation of dipole relations [53] does not mention composition of dipole relations. Moreover, he focuses on DRAlr (withno more than two start or end points on the same straight line), which cannot be used for polylines, while his presentation of the finer calculi is sketchyand imprecise, leading to the wrong number, 63, of DRA f relations. See Section 2.1 for the definition of these calculi.4 This was the reasoning used in the first investigation of dipole relations by Schlieder [53].5 For an application of neighborhood based reasoning of spatial agents, we refer the reader to the simulation model SAILAWAY [7].6 For an application of constraint-based reasoning for spatial agents, we refer the reader to the example in Section 2.5.\fR. Moratz et al. / Artificial Intelligence 175 (2011) 2099–21272101toolboxes [16,59]. Moreover, people have started to develop benchmark problem libraries [42] and have shown that thismethod performs quite well also when compared to other constraint reaso",
            {
                "entities": [
                    [
                        3771,
                        3799,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 316 (2023) 103843Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintPeerNomination: A novel peer selection algorithm to handle strategic and noisy assessmentsOmer Lev a, Nicholas Mattei b, Paolo Turrini c, Stanislav Zhydkov d,∗a Department of Industrial Engineering and Management, Ben-Gurion University of the Negev, Israelb Department of Computer Science, Tulane University, USAc Department of Computer Science, University of Warwick, United Kingdomd Mathematics Institute, University of Warwick, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 30 November 2021Received in revised form 12 June 2022Accepted 21 December 2022Available online 29 December 2022Keywords:Peer selectionStrategyproofnessOptimalityNoisy opinionsReweightingIn peer selection a group of agents must choose a subset of themselves, as winners for, e.g., peer-reviewed grants or prizes. We take a Condorcet view of this aggregation problem, assuming that there is an objective ground-truth ordering over the agents. We study agents that have a noisy perception of this ground truth and give assessments that, even when truthful, can be inaccurate. Our goal is to select the best set of agents according to the underlying ground truth by looking at the potentially unreliable assessments of the peers. Besides being potentially unreliable, we also allow agents to be self-interested, attempting to influence the outcome of the decision in their favour. Hence, we are focused on tackling the problem of impartial (or strategyproof) peer selection – how do we prevent agents from manipulating their reviews while still selecting the most deserving individuals, all in the presence of noisy evaluations? We propose a novel impartial peer selection algorithm, PeerNomination, that aims to fulfil the above desiderata. We provide a comprehensive theoretical analysis of the recall of PeerNomination and prove various properties, including impartiality and monotonicity. We also provide empirical results based on computer simulations to show its effectiveness compared to the state-of-the-art impartial peer selection algorithms. We then investigate the robustness of PeerNominationto various levels of noise in the reviews. In order to maintain good performance under such conditions, we extend PeerNomination by using weights for reviewers which, informally, capture some notion of reliability of the reviewer. We show, theoretically, that the new algorithm preserves strategyproofness and, empirically, that the weights help identify the noisy reviewers and hence to increase selection performance.1© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).* Corresponding author.E-mail addresses: omerlev@bgu.ac.il (O. Lev), nsmattei@tulane.edu (N. Mattei), p.turrini@warwick.ac.uk (P. Turrini), s.zhydkov@warwick.ac.uk(S. Zhydkov).1 This paper is a significant extension of our IJCAI 2020 contribution [29], which was limited to the study of PeerNomination without noise. Besides exploring the role of weights in peer selection in the presence of noise, we also extend the unweighted version with novel theoretical and experimental results.https://doi.org/10.1016/j.artint.2022.1038430004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fO. Lev, N. Mattei, P. Turrini et al.1. IntroductionArtificial Intelligence 316 (2023) 103843Peer evaluation and selection, where agents rate others and then choose a subset of themselves for an award or a prize, is one of the pillars for quality assessment in scientific contexts and beyond. While many of the current methods rely on expert panels, ideally impartial to the selection process [7,42], there is increasing need for alternative mechanisms that keep the procedure both reliable and cheap. An important approach to achieve this goal is that of using the agents that have submitted proposals for review as the set of reviewers themselves. This is particularly relevant in open online courses [37], where hiring professional graders is prohibitively expensive. Indeed, even large AI venues such as IJCAI and NeurIPS have been implementing a portion of this system, requiring authors who submit papers to agree to be the reviewers of other papers.The importance of improving peer reviewing procedures has been brought to light by the 2014 NeurIPS experiment [24,43]: of all papers submitted to NeurIPS 2014, 10% were reviewed twice by two independent committees which, aston-ishingly, agreed on less than half of the accepted papers. Whether the outcome was due to bias, incompetence, or rather well-thought disagreement is still unclear. What had been made clear, however, is that the current solutions seem to suffer from undesirable features. The exploding number of papers at AI and general computer science venues has spurred interest in improving many aspects of the peer review process, including: assignment biases [32,25,19], review quality [48], reviewer training [46], and even the quality of reviewers’ discussions (see overview by Shah [42]). Other studies of bias in evalua-tive processes have also brought to the fore the extent and impact of inaccurate assessments in peer reviewing, for example [49,45]. Finding high quality mechanisms for peer review is a critical step in helping the review process in large conferences [4], grant reviewing [33], online courses [47], and other domains.Researchers in algorithmic game theory and computational social choice worked on the peer selection problem for at least the past decade, focusing on accurate and strategyproof algorithms, including Partition [1], Credible Subset [23] and ExactDollarPartition (EDP) [4]; we provide an overview of these algorithms and more in Section 3. All of these algorithms take a Condorcet view on this aggregation problem, i.e., that there exists an a-priori ground-truth ranking of the agents, and we wish to select as many of the top ranked agents as possible, though given only access to the agents’ own noisy reports [52]. While this raises obvious philosophical challenges – e.g., what does this ground truth represent if we cannot have direct access to it? – we follow this view as it allows for quantitative analysis of the performance of peer selection algorithms, and hence their objective comparison.Many of the existing algorithms we survey in Section 3 highlight the trade-offs forced by the pursuit of the dual goal of impartiality and optimality. Some require the set of reviewing agents to be partitioned into clusters that do not review each other [4]; while others sacrifice exactness – the ability to select a given number of agents consistently [23]. With PeerNomination, the algorithm presented in this paper, we also sacrifice exactness, but we are able to achieve a new state-of-the-art performance. Additionally, none of the existing algorithms seek to alleviate the problem of noisy inputs in a unified, strategyproof mechanism. When earlier work did engage with noisy reports, it was limited to empirical testing with relatively low noise, e.g., a Mallows model with ϕ = 0.5 [4], which yields fairly minor changes in agents’ reports (as will be shown in Section 2.3). We are instead concerned with algorithms that can handle a significant level of noise, while maintaining strategyproofness and high quality of selection, an important missing aspect in the literature.Ideally, we would like an algorithm that is capable of identifying inaccurate reviewers and reducing their influence on the final selection, using only the agents’ reports themselves as a guide. We could, for example, try and downgrade those reviewers that differ too much from others. However, there are two problems with this approach: first, the noise may be such that it is difficult to establish what the consensus actually is; and second, that this meta-level reweighting can be exploited strategically. Simple reweighting is not strategyproof: consider, for example, an agent a that is harshly reviewing agent b, with both a and b reviewing a third agent c. Agent b could benefit by reviewing agent c in a way that would present agent a as an unreliable agent, lowering the impact of the report of agent a for agent b if weights are computed based on correlations to the evaluations of others, e.g., as done by Merrifield and Saari [33]. On the other hand, if a mechanism is able to identify agent b as a source of noise, it can increase the overall quality of the selection. While one can reweight agents without maintaining strategyproofness [47,51], we wish to achieve increased selection quality and strategyproofness. The algorithm we present in this paper is able to achieve both of these tasks with state of the art performance.1.1. ContributionWe present PeerNomination, an impartial (or strategyproof) peer selection method for scenarios where n agents re-view and are each reviewed by m others, with the goal of selecting k of them. Each proposal,2 which we identify with the proposing agent, is considered independently and it is selected only if it falls in the top kn m of the majority of its reviewers’ (partial) rankings, using a probabilistic completion if such number is not an integer. Performing the selection in-dependently relaxes the exactness requirement, hence our algorithm is not guaranteed to select exactly k agents every time. However, under some mild assumptions, the algorithm does select exactly k agents in expectation. Unlike other well-known 2 For the sake of clarity, when an agent is referred to as a reviewer we will always mean in the context of reviewing others and we will use the word proposal when referring to an agent that is being reviewed.2\fO. Lev, N. Mattei, P. Turrini et al.Artificial Intelligence 316 (2023) 103843peer reviewing me",
            {
                "entities": [
                    [
                        3329,
                        3357,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 239 (2016) 143–167Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBuilding knowledge maps of Web graphsValeria Fionda a, Claudio Gutierrez b, Giuseppe Pirrò c,∗a DeMaCS, University of Calabria, Italyb DCC, University of Chile, Chilec ICAR-CNR, Rende, CS, Italya r t i c l e i n f oa b s t r a c tArticle history:Received 22 May 2014Received in revised form 3 July 2016Accepted 11 July 2016Available online 18 July 2016Keywords:Maps of the webNavigationWeb of dataLinked dataSemantic web1. IntroductionWe research the problem of building knowledge maps of graph-like information. There exist well-consolidated cartographic principles and techniques for mapping physical landscapes. However, we live in the digital era and similarly to the Earth, the Web is simply too large and its interrelations too complex for anyone to grasp much of it through direct observation. Thus, the problem of applying cartographic principles also to digital landscapes is intriguing. We introduce a mathematical formalism that captures the general notion of map of a graph and enables its development and manipulation in a semi-automated way. We present an implementation of our formalism on the Web of Linked Data graph and discuss algorithms that efficiently generate and combine (via an algebra) regions and maps. We present the MaGe tool, implementing the map framework, and discuss examples of knowledge maps.© 2016 Elsevier B.V. All rights reserved.The Web can be seen as a vast space of interconnected information that users commonly access via navigation enabled by browsers. However, the Web is simply too large and its interrelations too complex for anyone to grasp much only by direct observation. Consider the task of navigating a citation network by using, for instance, Google Scholar.1 One typically starts from a seed paper. By clicking on the cited by link, one navigates towards papers that have cited the seed paper, selects those of interest (e.g., by bookmarking them) and then continues. After a while it is very hard to reconstruct the network of citations in terms of papers of interest and connections between them. Moreover, the whole process is manual. Having an automatic way of identifying the portion of the citation network of interest (i.e., papers and their connections) and then some form of abstract representation, where only salient papers (e.g., papers with certain keywords in the title) and links between them are represented, is an extremely useful support to the navigation.To cope with the huge amount of interconnected information available on the Web, we take inspiration from cartography and introduce a framework to build maps of the Web. In the physical space, the process of map making can be summarized in two main steps, that is, selection and abstraction [1]. Selection enables one to focus only on the particular pieces of information that will serve the map’s purpose; specifically, in this phase the region to be mapped is chosen. In our previous example about navigating a citation network, the region would consist in nodes (i.e., papers) and cited by links visited during the navigation. Abstraction is the fundamental property of a map, which states that a map is always smaller than the region * Corresponding author.1 http :/ /scholar.google .com.E-mail addresses: fionda@mat.unical.it (V. Fionda), cgutierr@dcc.uchile.cl (C. Gutierrez), pirro@icar.cnr.it (G. Pirrò).http://dx.doi.org/10.1016/j.artint.2016.07.0030004-3702/© 2016 Elsevier B.V. All rights reserved.\f144V. Fionda et al. / Artificial Intelligence 239 (2016) 143–167it portrays. Abstracting the region visited while navigating our citation network could be done by considering only nodes with certain properties (e.g., papers published in some specific conference) and links between them.We see Web Maps as useful navigational cues and powerful ways of conveying complex information via abstract repre-sentations; in our context abstraction is used to remove unwanted details that are out of the scope of the map’s subject. This gives Web Maps the role of navigational charts that help cope with the size of the Web (cyber) space and elude the “lost in the cyberspace” syndrome [2]. Thanks to Web Maps, users can explore complex digital territories, find routes toward destinations and discover previously unknown connections between knowledge items. Web Maps are also useful for analyz-ing information. For instance, the availability of a series of chronologically sequential maps enables complex map analysis (e.g., longitudinal analysis) for the detection and forecasting of trends in specific domains. This is useful, for instance, in the analysis of knowledge flows in scientific literature to show how the interlinking between disciplines is changing [3]. Another example are maps of social networks that can be analyzed to forecast friendship [4].Recent progress in Web technologies and languages originating from the Semantic Web proposal as well as the availability at planetary scale of structured information in the Resource Description Framework (RDF) standard data format, open new opportunities toward automating the construction of Web Maps. On one hand, interlinks between data items, encoded in RDF predicates, carry a precise semantic meaning, thus allowing for precise characterization of the nature of reachability that is crucial in extracting regions of the Web. On the other hand, maps can be given an RDF representation and then be processed not only by humans, via visual interpretations, but also by machines, due to the machine-processable nature of RDF. This will foster the exchange, combination and reuse of maps. We believe that the availability of Web Maps can help human users cope with the complexity of Web Regions in the same way as geographic maps help users cope with the complexity of large physical regions.Notions of maps for digital landscapes have been around for some time. Doemel [5] introduced the idea of Web Map as a means to capture user navigational activities. This kind of map is not a map in the cartographic sense as it misses the abstraction phase, which is the raison d’être of a map [1]. There are also many tools (partially) touching upon the problem of building maps of the Web. The most traditional and popular are bookmarks: a list of URLs specified by a user when navigating the Web. This idea has been enhanced to incorporate, for instance, social features (share, rank, tag) and/or annotations of different types of data (e.g., not only pages but also documents). Delicious,2 Diigo,3 and Google Bookmarks4are among the most popular bookmarking systems. Some systems go beyond simple bookmarks by enabling one to organize URLs to also highlight connections between the two. Results are grouped and presented in the form of a graph, which simulates the idea of a region of the Web. Examples of such systems are search engines like Tag Galaxy,5 navigational history tools (e.g., [5,6]), visual HTML site maps (for users) and atlases of the Web (e.g., [2]). More recent approaches focus on providing visual representations of information in specific domains such as publications or news (e.g., [7,8]).Existing approaches, discussed in Sections 2.1 and 6, do not comply with the idea of a map that we envision. First, even if they partially simulate the idea of capturing regions of the Web, they do not consider the abstraction of Web Regions to build maps. Second, they are designed for human visualization; hence their automatic processing, composition and reuse are not considered, which hinders the exchange, automatic combination and interpretation of maps. Third, they do not enable the declarative specification of the region (e.g., portion of interest of the Web) to be mapped thus hindering the automation of the process of creating maps. Fourth, they lack a formal mathematical model. They do not guarantee formal/provable (reachability) relations between the points in the map; formal notions of granularity and scope; and formal provable rela-tions between the map and the region it represents. These limitations obstruct the generation of formal deductions from maps.1.1. ContributionsIn this paper we formally introduce the notion of Web Map and face several challenges toward this goal. First, given a user need or a conceptual notion, provide a way to specify a region of the Web that represents or encompasses it. Second, given a region of the Web, define what is a map of it and investigate its formal properties. Third, devise algorithms and compose the procedures efficiently. The contributions of this paper are:• We provide a mathematical formalization of the notions of region and map of a graph; we discuss several types of maps, present algorithms for constructing such maps and study their complexity.• We introduce an algebra for maps and study its formal properties.• We discuss the problem of obtaining regions of the Web via graph navigational languages; to this aim we introduce a general navigational language to specify Web Regions.• We showcase an implementation of the formal map framework and navigational language on the current Web of Linked Data via a tool called MaGe (Map Generator).6• We discuss some examples of Web Maps with real data.2 http :/ /delicious .com/.3 http :/ /www.diigo .com/.4 http :/ /www.google .com /bookmarks/.5 http :/ /taggalaxy.de/.6 The tool is available at the Website http :/ /mapsforweb .wordpress .com.\fV. Fionda et al. / Artificial Intelligence 239 (2016) 143–167145An overview of the idea of Web Maps was given in Fionda et al. [9,10]. The present paper significantly extends our previous work by providing: (i) all the formal definitions (ii) a new family of maps (i.e., k-maps); (iii) all the formal proofs; (iv) algorithms and complexity; and (v) further examples of maps.1.2. Organization of the paperThe paper starts with a general overview of the problem of building Web maps and continues",
            {
                "entities": [
                    [
                        3495,
                        3523,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 306 (2022) 103667Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelation between prognostics predictor evaluation metrics and local interpretability SHAP valuesMarcia L. Baptista a,∗a Delft University of Technology (TU Delft), Mekelweg 5, 2628 CD Delft, the Netherlandsb Luleå University of Technology, 971 87 Luleå, Swedenc Palo Alto Research Center (PARC), Palo Alto CA 94304, USAd University of Lisbon - Instituto Superior Tecnico (IST), Av. Rovisco Pais nº1, 1049-001 Lisbon, Portugal, Kai Goebel b,c, Elsa M.P. Henriques da r t i c l e i n f oa b s t r a c tArticle history:Received 6 October 2020Received in revised form 24 December 2021Accepted 20 January 2022Available online 15 February 2022Keywords:Local interpretabilityModel-agnostic interpretabilitySHAP valuesMonotonicityTrendabilityPrognosabilityMaintenance decisions in domains such as aeronautics are becoming increasingly depen-dent on being able to predict the failure of components and systems. When data-driven techniques are used for this prognostic task, they often face headwinds due to their per-ceived lack of interpretability. To address this issue, this paper examines how features used in a data-driven prognostic approach correlate with established metrics of monotonicity, trendability, and prognosability. In particular, we use the SHAP model (SHapley Additive exPlanations) from the field of eXplainable Artificial Intelligence (XAI) to analyze the out-come of three increasingly complex algorithms: Linear Regression, Multi-Layer Perceptron, and Echo State Network. Our goal is to test the hypothesis that the prognostics metrics correlate with the SHAP model’s explanations, i.e., the SHAP values. We use baseline data from a standard data set that contains several hundred run-to-failure trajectories for jet engines. The results indicate that SHAP values track very closely with these metrics with differences observed between the models that support the assertion that model complexity is a significant factor to consider when explainability is a consideration in prognostics.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionOver the last decades, developments in storage and acquisition technologies have permitted access to large volumes of data. The continual growth in computing power, followed by a corresponding decrease in costs, has also come to meet the requirements of more advanced decision-making systems. These systems have started to revolutionize the way we think about data and modeling, but have also brought additional challenges, especially at the interpretability level. Decision systems based on machine learning are well-known for their promising results [79] but also for their complexity and lack of transparency [142,76]. An accuracy-interpretability trade-off [42] is true for almost all machine learning methods. For example, deep learning networks, an advanced form of machine learning, typically combine the activities of several hundred or even thousands of neurons. Despite each neural unit’s relative simplicity, the network’s structure can be so intricate that it may not be fully understood, even by its designer. Mostly due to this reason, neural network systems tend to be seen as black-boxes, where the user is typically only aware of input-output relationships, but not the underlying reasoning.* Corresponding author.E-mail addresses: m.lbaptista@tudelft.nl (M.L. Baptista), kgoebel@parc.com (K. Goebel), elsa.h@ist.utl.pt (E.M.P. Henriques).https://doi.org/10.1016/j.artint.2022.1036670004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM.L. Baptista, K. Goebel and E.M.P. HenriquesArtificial Intelligence 306 (2022) 103667Machine learning algorithms have already revolutionized fields such as image recognition or natural language processing [103]. However, several obstacles hinder their adoption in other fields. In highly regulated environments, strict requirements on the audit and verifiability of decisions have limited their acceptance. For example, in aerospace, certification by regulatory bodies requires the applicant to demonstrate that the system meets minimal safety criteria. Accountability and trust are essential properties in many applications. As noted by Wilkinson et al. [135], from the Federal Aviation Administration (FAA) and National Aero Space Agency (NASA), “understanding the mechanisms used (...) is essential to understanding the impact on software assurance”. The General Data Protection Regulation (GDPR) approved by the European Parliament in 2016 has also imposed restrictions on automated decision-making by establishing the human right to obtain explanations about the logic involved in algorithmic decisions that influence their lives [47,132].Recognizing the importance of interpretability to accelerate machine learning progress, the Artificial Intelligence (AI) re-search community has started to pay increasing attention to the explainability topic. Researchers from different backgrounds and experiences have started to produce a significant body of research about explanations and intelligibility. A project of note is the eXplainable AI (XAI) initiative [52] led by the Defense Advanced Research Projects Agency (DARPA) of the United States. The XAI initiative aims at creating machines that can operate in their environments while also providing explanations for their behavior.Researchers from different fields have researched interpretability, and given the complexity of the subject, there is no agreement on a single definition or taxonomy. As noted by Lipton [84], the concept of interpretability is not a monolithic one, but it reflects several distinct ideas, such as trust or transparency. Given the lack of a “formal technical meaning” [84], it is important to establish a definition for interpretability. Here, we adopt the definition of Biran and Cotton [19], as the level that an observer can understand the cause of a decision. Following the work of Miller [92], and for simplicity, we equate interpretability with explainability.As described in the work of Arrieta et al. [8], there are many approaches to interpretability. One such approach is the SHAP model (SHapley Additive exPlanations) [85]. This kind of XAI model uses Shapley values from game theory to characterize the input variables’ relative importance. The approach is model-agnostic [107] as it only requires knowing the black-box model’s output for the neighbor instances of an input sample. When using SHAP, each observed value of a feature gets its SHAP value. The focus is on explaining what the model locally depends on, instead of learning the full mapping. In other words, the goal is to achieve local interpretability [43].The technique of local interpretability contrasts with global interpretability. Global interpretability consists of all the tech-niques that are able to explain the structure of a model using a macro perspective. This type of approach is most often used for simpler methods since as the complexity of the models increases it can become gradually more difficult to understand them [93]. Global interpretability methods typically examine the black-box model’s input-output relationships to infer an equivalent logical structure that can describe or simulate the black-box model’s behavior. In other words, the goal is to build a surrogate model that is more transparent [60]. Local interpretability concerns the provision of independent explanations for individual model responses. Models such as SHAP focus on calculating the importance of the different features for a specific prediction. The goal is to isolate a single instance and build a surrogate model in the neighborhood (locally) of that instance to explain how the model processes it. Because there is typically no explicit concern in maintaining the correlation between the diverse independent local models, this work aims to understand better how the SHAP local models relate to each other.In this work, we are interested in understanding how SHAP can benefit Remaining Useful Life (RUL) estimation in aero-nautics. To this end, we study three increasingly complex prognostics models: Linear Regression (LR), Multi-Layer Perceptron (MLP), and the more recent algorithm of Echo State Network (ESN) [64,37]. The ESN is a recurrent neural network where only the connections to the output are computed, and this is done with regression instead of gradient-based methods, which simplifies and accelerates the training process. These networks have the additional capability of learning multidimensional temporal patterns. As an ESN is fed with input signals, past signals can influence new ones due to the network’s feedback loops. This kind of memory enables an ESN to capture the temporal dimension of the data explicitly. There are other archi-tectures with memory, such as Long-Short Term Memory Network (LSTM) [59] or Gated Recurrent Unit (GRU) [29]. The ESN is, however, a simple and efficient alternative that has shown promising results in prognostics [101,95,110,114,109].This paper discusses the need for XAI in prognostics by providing a comprehensive literature review and investigating the SHAP model according to the classical metrics of PHM (monotonicity, trendability, and prognosability) proposed in [32]. It is advantageous that the trajectories of explanatory values produced by SHAP exhibit these properties. Monotonic SHAP values imply that the weight associated with a given feature is changing monotonically over the unit’s lifecycle. Monotonicity is desirable as it means that sensor features exhibit either increasing or decreasing importance over time. Having fluctuating SHAP values would most likely mean that the SHAP model is unstable a",
            {
                "entities": [
                    [
                        3672,
                        3700,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 260 (2018) 1–35Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLearning in the machine: Random backpropagation and the deep learning channelPierre Baldi a,∗, Peter Sadowski a, Zhiqin Lu ba Department of Computer Science, University of California, Irvine, United Statesb Department of Mathematics, University of California, Irvine, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 7 December 2016Received in revised form 21 December 2017Accepted 15 March 2018Available online 3 April 2018Keywords:Deep learningNeural networksBackpropagationLocal learningRandom backpropagation (RBP) is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and learning channels. Through this connection, we derive several alternatives to RBP, including skipped RBP (SRBP), adaptive RBP (ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR-10 benchmarkdatasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results for RBP and its variants including: (1) the convergence to optimal fixed points for linear chains of arbitrary length; (2) convergence to fixed points for linear autoencoders with decorrelated data; (3) long-term existence of solutions for linear systems with a single hidden layer, and their convergence in special cases; and (4) convergence to fixed points of non-linear chains, when the derivative of the activation functions is included.© 2018 Elsevier B.V. All rights reserved.1. IntroductionOver the years, the question of the biological plausibility of the backpropagation algorithm, which implements stochastic gradient descent in neural networks, has been raised several times. The question has gained further relevance due to the numerous successes achieved by backpropagation in a variety of problems ranging from computer vision [21,31,30,14] to speech recognition [12] in engineering, and from high energy physics [7,26] to biology [8,32,1] in the natural sciences, as well to recent results on the optimality of backpropagation [6]. There are however, several well known issues facing bio-logical neural networks in relation to backpropagation, these include: (1) the continuous real-valued nature of the gradient * Corresponding author.E-mail address: pfbaldi @uci .edu (P. Baldi).https://doi.org/10.1016/j.artint.2018.03.0030004-3702/© 2018 Elsevier B.V. All rights reserved.\f2P. Baldi et al. / Artificial Intelligence 260 (2018) 1–35information and its ability to change sign, violating Dale’s Law; (2) the need for some kind of teacher’s signal to provide tar-gets; (3) the need for implementing all the linear operations involved in backpropagation; (4) the need for multiplying the backpropagated signal by the derivatives of the forward activations each time a layer is traversed; (5) the need for precise alternation between forward and backward passes; and (6) the complicated geometry of biological neurons and the problem of transmitting error signals with precision down to individual synapses. However, perhaps the most formidable obstacle is that the standard backpropagation algorithm requires propagating error signals backwards using synaptic weights that are identical to the corresponding forward weights. Furthermore, a related problem that has not been sufficiently recognized, is that this weight symmetry must be maintained at all times during learning, and not just during early neural develop-ment. It is hard to imagine mechanisms by which biological neurons could both create and maintain such perfect symmetry. However, recent simulations [24] surprisingly indicate that such symmetry may not be required after all, and that in fact backpropagation works more or less as well when random weights are used to backpropagate the errors. Our general goal here is to investigate backpropagation with random weights and better understand why it works.The foundation for better understanding random backpropagation (RBP) is provided by the concepts of local learning and deep learning channels introduced in [6]. Thus we begin by introducing the notations and connecting RBP to these concepts. In turn, this leads to the derivation of several alternatives to RBP, which we study through simulations on well known benchmark datasets before proceeding with more formal analyses.2. Setting, notations, and the learning channelThroughout this paper, we consider layered feedforward neural networks and supervised learning tasks. We will denote such an architecture byA[N0, . . . , Nh, . . . , N L](1)where N0 is the size of the input layer, Nh is the size of hidden layer h, and N L is the size of the output layer. We assume i j denote the weight connecting neuron j in layer h − 1 to neuron i in layer h. that the layers are fully connected and let whThe output O hi of neuron i in layer h is computed by:=i (Shi j O h−1whi ) where(cid:2)ShijO hi= f h(2)jThe transfer functions f hi are usually the same for most neurons, with typical exceptions for the output layer, and usually are monotonic increasing functions. The most typical functions used in artificial neural networks are the: identity, logistic, hyperbolic tangent, rectified linear, and softmax.We assume that there is a training set of M examples consisting of input and output-target pairs (I(t), T (t)), with t = 1, . . . , M. Ii(t) refers to the i-th component of the t-th input training example, and similarly for the target T i(t). In addition, there is an error function E to be minimized by the learning process. In general we will assume standard error functions such as the squared error in the case of regression and identity transfer functions in the output layer, or relative entropy in the case of classification with logistic (single class) or softmax (multi-class) units in the output layer, although this is not an essential point.While we focus on supervised learning, it is worth noting that several “unsupervised” learning algorithms for neural net-works (e.g. autoencoders, neural autoregressive distribution estimators, generative adversarial networks) come with output targets and thus fall into the framework used here.2.1. Standard backpropagation (BP)Standard backpropagation implements gradient descent on E , and can be applied in a stochastic fashion on-line (or in mini batches) or in batch form, by summing or averaging over all training examples. For a single example, omitting the tindex for simplicity, the standard backpropagation learning rule is easily obtained by applying the chain rule and given by:(cid:2)whi j= −η∂E∂ whi j= ηBhi O h−1j(3)where η is the learning rate, O h−1easy to see that the backpropagated error satisfies the recurrence relation:is the presynaptic activity, and Bhijis the backpropagated error. Using the chain rule, it is Bhi= ∂E∂ Shi(cid:3)= ( f hi )(cid:2)kk wh+1Bh+1kiwith the boundary condition:B Li= ∂Ei∂ S Li= T i − O Li(4)(5)\fP. Baldi et al. / Artificial Intelligence 260 (2018) 1–353Thus in short the errors are propagated backwards in an essentially linear fashion using the transpose of the forward ma-trices, hence the symmetry of the weights, with a multiplication by the derivative of the corresponding forward activations every time a layer is traversed.2.2. Standard random backpropagation (RBP)Standard random backpropagation operates exactly like backpropagation except that the weights used in the backward pass are completely random and fixed. Thus the learning rule becomes:(cid:2)whi j= ηRhi O h−1jwhere the randomly backpropagated error satisfies the recurrence relation:(cid:2)Rhi(cid:3)= ( f hi )Rh+1kch+1kikand the weights ch+1kiare random and fixed. The boundary condition at the top remains the same:R Li= ∂Ei∂ S Li= T i − O LiThus in RBP the weights in the top layer of the architecture are updated by gradient descent, identically to the BP case.2.3. The critical equations(6)(7)(8)Within the supervised learning framework considered here, the goal is to find an optimal set of weights whi j . The equa-tions that the weights must satisfy at any critical point are simply:∂E∂ whi j(cid:2)=ti (t)O h−1Bhj(t) = 0(9)Thus in general the optimal weights must depend on both the input and the targets, as well as the other weights in the network. And learning can be viewed as a lossy storage procedure for transferring the information contained in the training set into the weights of the architecture.The critical Equation (9) shows that all the necessary forward information about the inputs and the lower weights leading up to layer h − 1 is subsumed by the term O h−1(t). Thus in this framework a separate channel for communicating information about the inputs to the deep weights is not necessary. Thus here we focus on the feedback information about the targets, contained in the term Bhi (t) which, in a physical neural system, must be transmitted through a dedicated channel.jNote that Bhi (t) depends on the output O L(t), the target T (t), as well as all the weights in the layers above h ",
            {
                "entities": [
                    [
                        3331,
                        3359,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1424–1440Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStonian p-ortholattices: A new approach to the mereotopology RT0Torsten Hahmann a, Michael Winter b,∗, Michael Gruninger c✩a Department of Computer Science, University of Toronto, Canadab Department of Computer Science, Brock University, St. Catharines, Canadac Department of Mechanical and Industrial Engineering, Department of Computer Science, University of Toronto, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 22 January 2009Received in revised form 7 July 2009Accepted 7 July 2009Available online 28 July 2009Keywords:Qualitative spatial reasoning (QSR)MereotopologyRegion-based spaceStonian p-ortholatticeNon-distributive pseudocomplementedlattice1. Introduction−, RT−This paper gives an algebraic representation of the subtheories RTEC , and RT of Asherand Vieu’s first-order ontology of mereotopology RT0. It corrects and extends previous workon the representation of these mereotopologies. We develop the theory of p-ortholattices– lattices that are both orthocomplemented and pseudocomplemented – and show thattogether with the Stone identity (x · y)∗ = xor equivalent definitions the naturalclass of Stonian p-ortholattices can be defined. The main contribution of the paper consistsas Stonian p-ortholattices. Moreover, it is shown thatof a representation theorem for RT−the class of models of RTEC is isomorphic to the non-distributive Stonian p-ortholatticesand a characterization of RT is given by a set of four algebras of which one need tobe a subalgebra of the present lattice model. As corollary we obtain that Axiom (A11)– existence of two externally connected regions – is in fact a theorem of the remainingaxioms of RT.∗ + y−∗© 2009 Elsevier B.V. All rights reserved.Within AI and in particular Knowledge Representation (KR), region-based theories of space have been a prominent areaof research in the recent years. Traditionally, space has been considered in mathematics as point-based theories such asgeometric (e.g. Euclidean geometry) or topological representations (point-set topology) of space. Points are somewhat trickyto define and are far from intuitive in real-world applications. Instead, point-free theories of space such as region-basedtheories can be used to represent space in the context of (qualitative) spatial reasoning. Using regions instead of pointsas smallest units accounts more naturally for how humans conceptualize our physical world. Such commonsense spatialreasoning reflects rigid bodies or spatial regions more naturally than conventional, point-based models [19,27]. Since theearliest work of de Laguna [12] and Whitehead [30], mereotopology has been considered for building point-free theoriesof space. In AI, these theories are of importance for qualitative spatial reasoning (QSR): they focus on simple propertiesthat abstract from quantitative measurements while still being powerful enough to reason about spatial configurations andextract useful spatial knowledge, e.g. about bordering regions, intersecting regions, or the composition of regions. For anoverview of mereotopology within QSR we refer to [10].Broadly speaking, mereotopology is a composition of topological (from Greek topos, “place”) notions of connectednesswith mereological (from Greek méros, “part”) notions of parthood. Neither topology nor mereology are by themselves pow-erful enough to express part-whole relations.✩The authors gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada.* Corresponding author.E-mail addresses: torsten@cs.toronto.edu (T. Hahmann), mwinter@brocku.ca (M. Winter), gruninger@mie.utoronto.ca (M. Gruninger).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.07.001\fT. Hahmann et al. / Artificial Intelligence 173 (2009) 1424–14401425Topology can also be seen as a theory of wholeness, but has no means of expressing parthood relations. Connection doesnot imply a parthood relation between two individuals, as well as disconnection does not prevent parthood. Just considerthe example of countries – there exist many countries, e.g. the United States, that are not self-connected. Alaska should beconsidered part of the United States but is by no intuitive means connected to the other states. The same applies for Hawaii,although the kind of separation is different here: Alaska is separated by Canada from the continental US, whereas Hawaiiis solely separated by the Pacific ocean. If we consider landmass only, then Alaska and the continental US are part of aself-connected individual, namely continental North America, whereas Hawaii is separated from this landmass. On the otherhand, mereology is not powerful enough to reason about connectedness. As the previous example shows, two individualsbeing part of a common individual does not imply that this sum is self-connected. Hence, parthood is not sufficient tomodel connectedness.Consequently, to be able to reason about self-connected individuals, ways to combine mereology with topology arenecessary. Previously, Casati and Varzi [6] classified mereotopologies by how the two independent theories are merged.Other systematic treatments of mereotopology can be found in [11,16].One of the ways of building mereotopology studied in [30] takes topology as basis and defines mereology on top ofit reusing the topological primitive, thereby assuming a greater generality of topology than mereology. Clarke choose thisapproach for his seminal work in [7,8], and many later works in AI used Clarke’s work as starting point, e.g. the system RT0of Asher and Vieu [1], the Region Connection Calculus (RCC) [2,9,19,25], Gotts theory [18], and Pratt and Schoop’s polygonalmereotopology [24]. Due to the same origin all of these theories use a single primitive of connectedness (or contact)and express parthood in terms of connection, thus limiting the mereotopology to the expressiveness of the connectionprimitive.Most mereotopologies are described in terms of first-order axioms. However, many of them lack soundness and com-pleteness proofs. But even soundness and completeness proofs are insufficient, instead we aim for representation theoremsup to isomorphism (“full duality” in the tradition of Stone’s representation theorem of Boolean algebras [28], see also e.g.[13,14,26,29]) that describe the models in a uniform, mathematically well-understood formalism. Among others, for theRCC [9,25] and the framework of Pratt and Schoop [24], which is limited to planar polygonal mereotopology, there existformal proofs that actually give insight into the possible models. But to better understand the relation between differentmereotopologies, we need to identify the models of each mereotopology and compare them to each other. Algebraic conceptsand relation algebras in particular provide a mathematical sound foundation for comparing various mereotopological theo-ries. Most previous work in this direction focused on the RCC, generalizations and algebraic and topological representationsthereof. Clarke’s theory has also been characterized in terms of algebras, see [3]. Another approach relates mereotopologieswith certain lattice structures. In particular, Stell shows in [27] that models of the RCC are isomorphic to so-called Booleanconnection algebras (or Boolean contact algebras), i.e. Boolean algebras together with a binary contact relation C satisfyingcertain axioms. Since lattices and Boolean algebras in particular are well-known mathematical structures, this approach ledto an intensive study of the properties of the RCC including several topological representation theorems [13–15,26,29]. Inthis paper we want to apply a similar method to the mereotopology RT0 of Asher and Vieu [1]. We will show that the sub-−EC andtheory RTRT in terms of algebraic properties. This relationship between models of RT0 and certain lattices is the main contribution ofthis paper. It can be seen as the start of a lattice-theoretic treatment of RT0 in a similar way as [27]. The next step in thisendeavor can be found in [31]. Another interesting result is Corollary 7.3 showing that the original axiom system in [1] isnot independent.can be expressed by a certain class of lattices. Subsequently, we investigate the additional axioms of RT−Compared to the RCC, the system of Asher and Vieu [1] focuses on a larger set of regions. The standard models of RCCare made of regular closed sets only whereas the standard models of RT0 contain regions with regular closed closures andregular open interiors. Therefore, the system RT0 can be seen as a more general approach in the following sense. The closedelements in Asher and Vieu’s theory correspond to the elements in RCC. It is, therefore, not very surprising that RT0 doesnot provide the same algebraic structure as RCC models, i.e. Boolean algebras. Even though we will consider distributivity inSection 6 this is a very particular case. By requiring this property one basically forces the more general elements of Asherand Vieu, i.e. open, closed and other sets, into the framework of regular closed regions. It turns out that in this – and justin this – case the contact relation collapses to overlap similar to Clarke’s original system. A more detailed study of therelationship between RCC models and the current framework via the skeleton can be found in [31].2. The mereotopology RT 0The mereotopology RT0 proposed by Asher and Vieu [1] evolved from Clarke’s theory, addressing some of its shortcom-ings. RT0 follows the strategy “Topology as Basis for Mereology” for defining mereotopology and hence does not contain anexplicit mereology. Consequently, the parthood relation P is sufficiently defined by the extension of the primitive relation C ,which limits the expressiveness of the whole theory to that of C . As a indirect consequence of our work, it will turn outthat we could",
            {
                "entities": [
                    [
                        3848,
                        3876,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 314 (2023) 103804Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintWhen move acceptance selection hyper-heuristics outperform Metropolis and elitist evolutionary algorithms and when not ✩Andrei Lissovoi a, Pietro S. Oliveto a, John Alasdair Warwicker ba Department of Computer Science, University of Sheffield, UKb Institute of Operations Research, Karlsruhe Institute of Technology, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 30 April 2021Received in revised form 6 September 2022Accepted 3 October 2022Available online 4 October 2022Keywords:Hyper-heuristicsRuntime analysisNon-elitismMetropolisMove acceptance operatorsTheorySelection hyper-heuristics (HHs) are automated algorithm selection methodologies that choose between different heuristics during the optimisation process. Recently, selection HHs choosing between a collection of elitist randomised local search heuristics with different neighbourhood sizes have been shown to optimise standard unimodal benchmark functions from evolutionary computation in the optimal expected runtime achievable with the available low-level heuristics. In this paper, we extend our understanding of the performance of HHs to the domain of multimodal optimisation by considering a Move Acceptance HH (MAHH) from the literature that can switch between elitist and non-elitist heuristics during the run. In essence, MAHH is a non-elitist search heuristic that differs from other search heuristics in the source of non-elitism.We first identify the range of parameters that allow MAHH to hillclimb efficiently and prove that it can optimise the standard hillclimbing benchmark function OneMax in the best expected asymptotic time achievable by unbiased mutation-based randomised search heuristics. Afterwards, we use standard multimodal benchmark functions to highlight function characteristics where MAHH outperforms elitist evolutionary algorithms and the well-known Metropolis non-elitist algorithm by quickly escaping local optima, and ones where it does not. Since MAHH is essentially a non-elitist random local search heuristic, the paper is of independent interest to researchers in the fields of artificial intelligence and randomised search heuristics.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionSelection hyper-heuristics (HHs) are automated algorithm selection methodologies designed to choose which of a set of low-level heuristics to apply in the next steps of the optimisation process [15]. Rather than deciding in advance which heuristic and related parameter settings to apply for a problem, either by manual trial and error in preliminary experiments or using automated algorithm configurators [32,64], the aim behind HHs is to automate the process at runtime. Originally shown to effectively optimise scheduling problems, such as the scheduling of a sales summit and university timetabling [15,16], they have since been successfully applied to a variety of hard combinatorial optimisation problems (see e.g., [7,6,27,40,58,64] for surveys of results).✩An extended abstract of this manuscript has appeared at the 2019 Association for the Advancement of Artificial Intelligence Conference (AAAI 2019) [46].E-mail address: p.oliveto@sheffield.ac.uk (P.S. Oliveto).https://doi.org/10.1016/j.artint.2022.1038040004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fA. Lissovoi, P.S. Oliveto and J.A. WarwickerArtificial Intelligence 314 (2023) 103804Selection HHs consist of two separate components: (1) a heuristic selection method, often referred to as the learning mechanism, to decide which heuristic to be applied in the next step of the optimisation process, and (2) a move acceptance operator to decide whether the newly produced search points should be accepted.The majority of heuristic selection methods in the literature apply machine learning techniques that generate scores for each heuristic based on their past performance. A commonly used method for the purpose is reinforcement learning [15,50,5]. Despite their numerous successful applications, very limited rigorous theoretical understanding of their behaviour and performance is available [43,1].Recently, it has been proved that a reinforcement learning HH and a simple selection HH called Random Descent [15,16], both choosing between elitist randomised local search (RLS) heuristics with different neighbourhood sizes, can respectively optimise the standard unimodal benchmark functions OneMax and LeadingOnes in the best possible runtimes achievable (up to lower order terms), with the available low-level heuristics [22,48]. Since the Random Descent HH does not store information on the past performance of the low-level heuristics, it is necessary to run the selected low-level heuristics for a sufficient amount of time, called the learning period, to allow the HH to accurately determine how useful the chosen heuristic is at the current stage of the optimisation process. However, the optimal duration of the learning period may change during the optimisation process. Doerr et al. recently introduced a self-adjusting mechanism and rigorously proved that it allows the HH to track the optimal learning period throughout the optimisation process for LeadingOnes [25]. The optimal asymptotic performance of the same self-adjusting Random Descent HH has recently been shown also for the OneMax and Ridgeunimodal benchmark functions [47]. For a survey of the available theoretical results regarding the performance of HHs, see [51].In this paper we aim to extend the understanding of the behaviour and performance of HHs to multimodal optimisation problems. In order to evaluate their capability at escaping local optima, we consider elitist and non-elitist selection operators (called move acceptance operators) that have been used in the HH literature. Move acceptance operators (also referred to as selection operators in the classic evolutionary computation literature) are classified as either deterministic, where the same decision is made independent of the stage of the optimisation process, or non-deterministic, where different decisions for the same solutions might be made at different stages [56].Cowling et al. introduced two variants of deterministic move acceptance operators: the elitist OnlyImproving (OI) op-erator, which only accepts moves that improve the current solution, and the non-elitist AllMoves (AM) operator, which accepts any new solution independent of its quality [15,16]. Another move acceptance operator that has been considered in the literature is the ImprovingandEqual (IE) operator which, in addition to accepting improving solutions, also accepts solutions of equal quality [2,4,55]. In the mentioned works, the acceptance operator remains fixed throughout the run, with the HH only switching between different mutation operators. However, it would be more desirable that HHs are allowed to decide to change the move acceptance operator and hence, the selection pressure at different stages of the optimisation process. For instance, they may use elitist move acceptance in exploitation phases of the search, such as hillclimbing, and non-elitism for exploration, for instance to escape from local optima.Indeed, Qian et al. analysed a HH that switches between move acceptance operators in the context of multi-objective optimisation [60]. They considered a HH that selects between the elitist (IE) and the strict elitist (OI) move acceptance operators and presented a function where it is necessary to mix the two acceptance operators. Lehre and Özcan presented the only available analysis of a HH which chooses between elitist and non-elitist low level heuristics [43]. In particular, the HH uses the above described OI (strict elitist) and AM (non-elitist) acceptance operators. The considered Move Acceptance HH (MAHH) uses 1-bit flips (i.e., local mutations) as the mutation operator and selects the AM acceptance operator with probability p and the OI acceptance operator with probability 1 − p. Essentially, the algorithm is a randomised local search (RLS) algorithm that switches between strict elitism, by only accepting improvements, and extreme non-elitism, by accepting any new found solution. For the standard RoyalRoadk benchmark function from evolutionary computation, which consists of several blocks of k ≥ 2 bits each that have to be set correctly to observe a fitness improvement, they proved that it is necessary to mix the acceptance operators for MAHH to be efficient, because by only accepting improvements (i.e., p = 0) the runtime is infinite due to MAHH not being able to cross the plateaus of equal fitness while by always accepting any move (i.e., p = 1), the algorithm simply performs a random search. By choosing the value of the parameter p appropriately they provide an upper bound on the expected runtime of the HH of O (n3 · k2k−3) versus the O (n log(n) · (2k/k)) expected time required by evolutionary algorithms with standard bit mutation (i.e., each bit is flipped with probability 1/n) and with the standard selection operator that accepts new solutions if their fitness is at least as good as that of their parent [26]. In particular, just using the IE acceptance operator throughout the run leads to a better performance. Hence, the advantages of switching between selection operators rather than just using one all the time were not evident.In this paper we present a systematic analysis of the same HH considered by Lehre and Özcan [43] for multimodal optimisation problems,1 where the considerable advantages of changing the move acceptance operator during the run may be highlighted. In particular, we will increase our understanding of the behaviour ",
            {
                "entities": [
                    [
                        3466,
                        3494,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1272–1289Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIncompleteness and incomparability in preference aggregation:Complexity resultsM.S. Pini a, F. Rossi a, K.B. Venable a,∗, T. Walsh ba Department of Pure and Applied Mathematics, University of Padova, Italyb NICTA and UNSW Sydney, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 1 July 2010Accepted 1 July 2010Available online 1 December 2010Keywords:Preference in multi-agent systemsPreference aggregationComputational complexityUncertaintyElicitationWe consider how to combine the preferences of multiple agents despite the presence ofincompleteness and incomparability in their preference relations over possible candidates.The set of preference relations of an agent may be incomplete because, for example,there is an ongoing preference elicitation process. There may also be incomparability asthis is useful, for example, in multi-criteria scenarios. We focus here on the problemof computing the possible and necessary winners, that is, those candidates which canbe, or always are, the most preferred for the agents. Possible and necessary winnersare useful in many scenarios including preference elicitation. First, we show that testingpossible and necessary winners is in general a computationally intractable problem forSTV with unweighted votes and the cup rule with weighted votes, as is providing agood approximation of such sets. Then, we identify general properties of the preferenceaggregation function, such as independence to irrelevant alternatives, which are sufficientfor such sets to be computed in polynomial time. Finally, we show how possible andnecessary winners can be used to focus preference elicitation. We show that it iscomputationally intractable for the cup rule with weighted votes in the worst-case todecide when to terminate elicitation. However, we identify a property of the preferenceaggregation function that allows us to decide when to terminate elicitation in polynomialtime, by focusing on possible and necessary winners.© 2011 Elsevier B.V. All rights reserved.1. IntroductionWe consider a multi-agent setting where each agent specifies their preferences by means of a set of preference relationsover the possible candidates. A pair of candidates can be ordered, incomparable, in a tie, or the relationship betweenthem may not yet be specified. Incomparability and incompleteness represent very different concepts. Candidates may beincomparable because the agent does not wish very dissimilar candidates to be compared. For example, we might not wantto compare a biography with a novel since the criteria along which we judge them are just too different. Candidates can alsobe incomparable because the agent has multiple criteria to optimize. For example, we might not wish to compare a fasterbut more expensive laptop with a slower and cheaper one. Incompleteness, on the other hand, represents simply an absenceof knowledge about the relationship between certain pairs of candidates. Incompleteness arises when we have not fullyelicited an agent’s preferences or when agents have privacy concerns which prevent them from revealing their preferences.* Corresponding author.E-mail addresses: mpini@math.unipd.it (M.S. Pini), frossi@math.unipd.it (F. Rossi), kvenable@math.unipd.it (K.B. Venable), Toby.Walsh@nicta.com.au(T. Walsh).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.009\fM.S. Pini et al. / Artificial Intelligence 175 (2011) 1272–12891273Since we wish to aggregate together the agents’ preferences into a single preference ordering, we must modify preferenceaggregation functions to deal with incompleteness. One possibility is to consider all possible ways in which the incompletepreference orders can be consistently completed. In each possible completion, preference aggregation may give differentoptimal elements (or winners). This leads to the idea of possible winners (those candidates which are winners in at least onepossible completion) and necessary winners (those candidates which are winners in all possible completions) [14].While voting theory has been mainly interested in the fairness of social choice or social welfare functions, there hasbeen recent interest in computational properties of preference aggregation [19,15,14,10]. It has already been noted that thecomputational complexity of manipulating an election is closely related to that of computing possible winners [14,9]. In thispaper we start by considering the computational complexity of testing if a given candidate is a necessary or a possible win-ner for STV and the cup rule. We consider two different dimensions: weighted/unweighted agents and bounded/unboundednumber of candidates. Weights are useful in multi-agent systems where we have different types of agents and some agentmay have more importance than some other agent in the process of taking a decision. We provide the computational com-plexity of computing the necessary and possible winners in all of the considered scenarios in the worst case. Moreover, weshow that it is intractable even to obtain a good approximation of such sets, except when we have unweighted agents anda bounded number of candidates. Then, we identify sufficient conditions that assure tractability. Such conditions concernproperties of the preference aggregation function, such as monotonicity and independence of irrelevant alternatives (IIA) [2].Notice that IIA is a strong assumption. However, it is useful to show that intractability is not always the case for computingpossible/necessary winners in the general case.We stress that worst-case complexity results like these are only the start to our understanding the complexity of com-puting possible and necessary winners. The complexity of these problems in practice may still be easy. For example, anumber of recent theoretical results suggest that the closely related problem of manipulating an election may be NP-hardin the worst case but computationally easy in practice [11].Possible and necessary winners are useful in many scenarios including preference elicitation [6]. In fact, elicitation canbe terminated when the set of possible winners coincides with that of the necessary winners [10]. We show that decidingwhen to terminate the elicitation process for the cup rule with weighted votes is a computationally intractable problem.However, if the preference aggregation function is IIA, preference elicitation can be stopped in polynomial time. This canbe done by focusing just on the incompleteness concerning those candidates which are possible and necessary winners,allowing us to ignore all other candidates.The paper is a revised and an extended version of [18,17,22].2. Basic notionsWe now introduce some basic notions on which our work is based. First, we give the definitions regarding preferencerelations and incomplete profiles. We, then, consider the notions of preference aggregation functions, possible and necessarywinners and describe how to represent compactly the set of the results of a preference aggregation function. We concludeby motivating the usefulness of weighted votes in terms of some real-world setting.2.1. Preferences and incomplete profilesWe assume that each agent’s preferences (that is, each agent’s vote) are specified via a partially specified pre-order over theset of possible candidates, that we will denote by Ω .1 A partially specified pre-order is a pre-order (PO) (that is, a reflexive,antisymmetric and transitive relation) plus an additional set of pairs that represent unspecified preferences. More precisely,given two candidates A and B, an agent can specify one of the following:• A < B, that is, B is preferred to A;• A > B, that is, A is preferred to B;• A ∼ B, that is, A and B are equally preferred;• A (cid:4)(cid:5) B, that is, A and B are incomparable (i.e., neither A > B nor B > A, nor A ∼ B);• A?B, that is, the relation between A and B is unknown; this means that it could be any element of {∼, >, <, (cid:4)(cid:5)}.Example 1. Given candidates A, B, and C , an agent may state preferences such as A > B, B (cid:4)(cid:5) C , and A > C , or also justA > B and B (cid:4)(cid:5) C , that corresponds to preferences A > B, B (cid:4)(cid:5) C and A?C . However, an agent cannot state preferences suchas A > B, B > C , C > A, or also A > B, B > C , A (cid:4)(cid:5) C since they don’t satisfy transitivity and thus they are not POs.Definition 1 (Profile). A profile is a sequence of n pre-orders p1, . . . , pn over the candidates, one for each agent i ∈ {1, . . . , n},describing the preferences of the agents. The pre-order of a single agent is also called a vote.1 We believe the assumption of agents expressing their preferences via pre-orders is reasonable in the context of this paper, although it is known thatsometimes preferences of human beings are not transitive.\f1274M.S. Pini et al. / Artificial Intelligence 175 (2011) 1272–1289When one or more of these pre-orders is partially specified, we have an incomplete profile.Definition 2 (Incomplete profile). An incomplete profile is a sequence of n partially specified pre-orders ip1, . . . , ipn overcandidates, one for each agent i ∈ {1, . . . , n}.Example 2. Given three agents and three candidates A, B, and C , a possible incomplete profile is (( A > B > C )2; ( A > C ,A > B, B?C ); (C > A, A?B, B?C )).Definition 3 (Completions of a profile). Given a profile p, a completion of p is a profile obtained from p by replacing every ?with an element in {>, <, ∼, (cid:4)(cid:5)}. Since completions are profiles, the replacement of every ? with an element in {>, <, ∼, (cid:4)(cid:5)}must be done in such a way as to respect transitivity.2.2. Social welfare and preference aggregationSocial welfare functions [2] are functions from profiles to pre-orders. Social choice functions (also known ",
            {
                "entities": [
                    [
                        3549,
                        3577,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 442–448Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA note on minimal d-separation trees for structural learningBinghui Liu a, Jianhua Guo a,∗, Bing-Yi Jing ba Key Laboratory for Applied Statistics of MOE and School of Mathematics and Statistics, Northeast Normal University, Changchun 130024, Jilin Province, Chinab Department of Mathematics, Hong Kong University of Science and Technology, Hong Konga r t i c l ei n f oa b s t r a c tStructural learning of a Bayesian network is often decomposed into problems related to itssubgraphs, although many approaches without decomposition were proposed. In 2006, Xie,Geng and Zhao proposed using a d-separation tree to improve the power of conditionalindependence tests and the efficiency of structural learning. In our research note, we studya minimal d-separation tree under a partial ordering, by which the maximal efficiency canbe obtained. Our results demonstrate that a minimal d-separation tree of a directed acyclicgraph (DAG) can be constructed by searching for the clique tree of a minimal triangulationof the moral graph for the DAG.© 2010 Elsevier B.V. All rights reserved.Article history:Received 2 April 2009Received in revised form 19 January 2010Accepted 23 January 2010Available online 2 February 2010Keywords:Bayesian networkClique treeMinimal d-separation treeMinimal triangulationSeparation treeStructural learning1. IntroductionBayesian networks (BNs), also known as directed acyclic graphical models, are useful probabilistic graphical modelsthat can be represented by DAGs. For a Bayesian network, two components are involved. First, the DAG is the qualitativecomponent which represents dependence and independence relationships: the absence of some directed edges representsthe existence of certain conditional independence relationships between variables, and the presence of edges may representthe existence of direct dependence relationships or causal relationships [10,17]. Second, the joint probability distribution isthe quantitative component that expresses the strength of association between variables. We have special interest in thestructure recovery of DAGs. Several methods for structural learning of DAGs were considered and there are mainly two basicapproaches of structural learning [23]: constraint-based approach and search-and-score approach. We will introduce somemore constraint-based algorithms. As mentioned in [23], in a constraint-based algorithm, search for d-separators of pairs ofvariables is a major problem for orientation of edges and for structure recovery of a DAG. Here a d-separator is a subsetof variables by which the variable pairs are d-separated. Verma and Pearl [21] presented the IC algorithm and searched fora d-separator S from all possible variable subsets such that two variables u and v are conditionally independent on S. Asthe search for d-separators is often time-consuming, many algorithms were proposed to speed up the search. For example,the PC algorithm, an iterative algorithm, searched only for the d-separators contained in the variables that are adjacentto u and v in each step [19], where two variables are said to be adjacent if there is an edge between the two variables.Decomposition approaches [7,22] are also useful approaches to speed up the search. Using these approaches, the originallearning question can be decomposed into some sub-questions with smaller dimensions.For many constraint-based algorithms, there are two steps to recover DAG structures [23]. First, learn the moral graphof the target DAG applying Markov blanket learning algorithms, where the Markov blanket for a variable u is defined to* Corresponding author.E-mail addresses: liubh024@yahoo.com.cn (B. Liu), jhguo@nenu.edu.cn (J. Guo), majing@ust.hk (B.-Y. Jing).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.01.002\fB. Liu et al. / Artificial Intelligence 174 (2010) 442–448443be the set of variables composed of u’s parents, its children, and its children’s other parents [16]. Second, perform furtherindependence tests for edge orientation based on the moral graph learned in the first step. To speed up the second step,Xie, Geng and Zhao [22] proposed algorithms adopting a decomposition approach, which were supported by a useful andimportant definition of d-separation tree. They introduced this definition to depict separations and conditional independen-cies between sets of random variables, and we will describe the definition again in detail in the following section. Given ad-separation tree T , the problem of searching for d-separators in a large network can be localized to smaller subnetworks,that is, d-separators are only searched for in each node of the tree separately (see Theorem 2 in [22]). Then the number ofthe further independence tests mentioned in the second step can certainly be reduced.Different d-separation trees often carry corresponding efficiencies. The efficiency can be defined from several differentangles for different purposes. For example, if the aim is to search for the tree where the largest node has the minimumsize, the efficiency may be defined inversely proportional to the number of vertices in the largest node of the tree. Ouraim is slightly different from that one and here the efficiency is defined inversely proportional to the maximum numberof possible tests, which will be described in detail in the following section. To describe an appropriate d-separation treewith high efficiency, we first introduce the definition of minimal d-separation trees for a DAG. Our paper focuses on thecharacterization and construction of a minimal d-separation tree. Xie, Geng and Zhao (2006) already proposed a sufficientcondition for d-separation trees. Based on their work, we show that any minimal d-separation tree of a DAG is equivalentto a minimal separation tree of the moral graph for the DAG, which is in turn equivalent to a clique tree of a minimaltriangulation of the moral graph. According to these equivalences, some useful algorithms of searching for minimal trian-gulations and clique trees are available for us to construct a minimal d-separation tree, which leads to a minimal numberof the further independence tests mentioned above required for orientation of edges. The definitions, such as moral graph,clique tree and triangulation [10,12,13], will be introduced in the next section in detail.In Section 2, we introduce the notation and definitions. As our paper is mainly inspired by Xie, Geng and Zhao, wemainly follow the terminology of [22]. Section 3 discusses the characterization and construction of a minimal d-separationtree of a DAG. In Section 4, we make a conclusion for our paper.2. Notation and definitionsWe follow the terminology from [13,22], unless noted otherwise.2.1. Undirected graphs and separation treesWe consider simple and connected graphs. Let G = (V , E) denote an undirected graph, where V is the vertex set andE is the set of undirected edges. An undirected edge between two vertices u and v is denoted by (u, v). A ⊆ V induces asubgraph G A = ( A, E A), where E A = E ∩ ( A × A). A subset of V is called complete if every pair of vertices in the subset isconnected by an edge. A complete subset that is maximal w.r.t. inclusion is called a clique. A path p between two verticesu and v is a sequence of vertices w 0 = u, w 1, . . . , wn = v with (w i−1, w i) ∈ E, for 1 (cid:2) i (cid:2) n (n (cid:3) 1) and w i (cid:6)= w j for1 (cid:2) i, j (cid:2) n. A cycle is a path with w 0 = wn. A chord of the cycle is a pair of vertices w i , w j such that (w i, w j) ∈ E butj (cid:6)= i − 1, i + 1. Two subsets A, B ⊆ V with A ∩ B = ∅ are said to be separated by C ⊆ V in G if all paths from A to Bpass through C , i.e., for each vertex u ∈ A and each vertex v ∈ B, all paths from u to v intersect C at some vertices. Thepartition ( A, B, S) of V is said to be a decomposition of the undirected graph G, if (1) S separates A and B in G, and (2) Sis complete in G. Then G can be decomposed into subgraphs G A∪S and G B∪S .Hh=1 Ch = V . T denotes a tree whose node set is C and edge set is E T . Inspired by thedefinition of d-separation tree, Definition 1 in [22], here we propose a similar definition of separation tree for undirectedgraphs.Let C = {C1, . . . , C H }, such that(cid:2)Definition 1. A tree T = (C, E T ) is said to be a separation tree of an undirected graph G = (V , E) if for each edge (Ci, C j) ∈C , k = 1, 2; C 1 and C 2 are node sets ofE T , V 1\\(Ci ∩ C j) and V 2\\(Ci ∩ C j) are separated by Ci ∩ C j in G, where V k =T 1 and T 2, which are obtained by removing edge (Ci, C j) from tree T .C∈Ck(cid:2)If for each edge (Ci, C j) ∈ E T , Ci ∩ C j is complete in G, we say that T is a decomposition tree of G.A tree T = (C, E T ) is reduced if each vertex set in C is not contained in another one, that is, red{C} = C, where ‘red’stands for the operation of deleting the smaller of any two sets C1, C2 with C1 ⊆ C2.2.2. Triangulated graphs and clique treesA triangulated graph, also known as a chordal graph, is an undirected graph that contains no cycles of length (cid:3) 4 withouta chord. For any undirected graph G = (V , E) edges can be added so that the resulting graph Gt = (V , E ∪ F ), called a(cid:9)) is nottriangulation of the given graph G, is triangulated. A triangulation Gt of G is said to be minimal if Gtriangulated for every proper subset F(cid:9) = (V , E ∪ Fof F .(cid:9)\f444B. Liu et al. / Artificial Intelligence 174 (2010) 442–448Fig. 1. An undirected graph G = (V , E) (left) and a minimal triangulation Gt (right) of G.Fig. 2. A DAG G.Example 1. We see that Gt in Fig. 1 is a triangulation of the undirected graph G, because it contains no cycles of length (cid:3) 4without a chord. And Gt is a minimal triangulation, as G 1 = (V , E ∪ {(1, 4)}) and G 2 = (V , E ∪ {(4, 5)}) are not triangulated.We continue to show a graph G 3 t",
            {
                "entities": [
                    [
                        3928,
                        3956,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 201 (2013) 1–31Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief functions on distributive lattices ✩Chunlai ZhouDepartment of Computer Science and Technology, School of Information, Renmin University, Beijing, 100872, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 18 August 2012Received in revised form 7 May 2013Accepted 10 May 2013Available online 15 May 2013Keywords:Dempster–Shafer theoryMöbius transformsDistributive latticesde Morgan latticesFirst degree entailments1. IntroductionThe Dempster–Shafer theory of belief functions is an important approach to deal withuncertainty in AI.In the theory, belief functions are defined on Boolean algebras ofevents. In many applications of belief functions in real world problems, however, theobjects that we manipulate is no more a Boolean algebra but a distributive lattice. Inthis paper, we employ Birkhoff’s representation theorem for finite distributive lattices toextend the Dempster–Shafer theory to the setting of distributive lattices, which has amathematical theory as attractive as in that of Boolean algebras. Moreover, we use thismore general theory to provide a framework for reasoning about belief functions in adeductive approach on non-classical formalisms which assume a setting of distributivelattices. As an illustration of this approach, we investigate the theory of belief functionsfor a simple epistemic logic the first-degree-entailment fragment of relevance logic R byproviding an axiomatization for reasoning about belief functions for this logic and byshowing that the complexity of the satisfiability problem of a belief formula with respectto the class of the corresponding Dempster–Shafer structures is NP-complete.© 2013 Elsevier B.V. All rights reserved.Dealing with uncertainty is a fundamental issue for Artificial Intelligence [31]. Numerous approaches have been pro-posed, including Dempster–Shafer theory of belief functions (also called Dempster–Shafer theory of evidence). Ever sincethe pioneering works by Dempster [10] and Shafer [52], belief functions were brought into a practically usable form bySmets [59] and have become a standard tool in Artificial Intelligence for knowledge representation and decision-making.Dempster–Shafer belief functions on a finite frame of discernment S are defined on the power set of S, which is aBoolean algebra. They have an attractive mathematical theory and many intuitively appealing properties. Belief functionssatisfy the three axioms which generalize the Kolmogorov axioms for probability functions. Interestingly enough, they canalso be characterized in terms of mass functions m. Intuitively, for a subset event A, m( A) measures the belief that an agentcommits exactly to A, not the total belief that an agent commits to A. Shafer [52] showed that an agent’s belief in A is thesum of the masses he has assigned to all the subsets of A. This characterization of belief functions through mass functionsis simply an example of the well-known Inclusion–Exclusion principle in Enumerative Combinatorics [61] and hence has astrong combinatorial flavor. In this theory, mass functions are recognized as Möbius transforms of belief functions.Dempster–Shafer theory of belief functions is closely related to other approaches dealing with uncertainty. It includesthe Bayesian theory [51] as a special case. The first three rules of the Bayesian theory are simply those three axioms forprobability functions. It is shown [52] that a belief function on S is Bayesian (also a probability function) if and only if✩This is an expanded and improved version of a preliminary paper with the same title that appears in Proceedings of the Twenty-Sixth AAAI Conferenceon Artificial Intelligence (AAAI-12), 1968–1975, Toronto, 2012. All the technical proofs here are not published in the AAAI paper. In some sense, the prooftechniques developed in this paper are as important as the main results. In addition, Sections 3 and 4in the conference paper are totally revised andreplaced by more comprehensive sections, and some main results there get strengthened in this paper.E-mail addresses: czhou@ruc.edu.cn, chunlai.zhou@gmail.com.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.05.003\f2C. Zhou / Artificial Intelligence 201 (2013) 1–31its corresponding mass function assigns positive weights only to singletons. So a Bayesian belief function μ is more like apoint function than a set function in its level of complexity in the sense that μ is determined by its values at singletonsrather by its values at all events (its values at other non-singletons are 0). This implies that generally Bayesian belieffunctions are simpler and easier to describe than belief functions. As Shafer pointed out in Chapter 9 of his book [52],this simplicity makes the Bayesian belief functions awkward for the representation of evidence. In practice, the Bayesianapproach is criticized for having difficulty in efficiently providing reasonable estimate of the probability of some eventsand for describing confidence by a single point rather than a range [18]. The main advantage of the Dempster–Shafertheory over the Bayesian theory is that it allows for a proper representation of ignorance under incomplete information andassigns a meaningful interval to an event as a representation of the uncertainty of the event. In this aspect, the theory ofbelief functions is equivalent to the approach adopted by Fagin and Halpern [18] dealing with uncertainty using inner andouter probability measures. In contrast with the Dempster–Shafer theory, probability theory does not assign a probabilityto every event [30] and probability measures are defined on a σ -algebra, which is a subclass of the power set of the spaceunder consideration. Non-measurable events, those without probabilities, are usually considered as meaningless in probabilitytheory. However, in modeling uncertainty in artificial intelligence, they are used to represent those events to which an agenthas insufficient information to assign probabilities. A non-measurable event E is provided with inner probability measure(outer probability measure) which is the probability of the largest measurable event contained in E (the smallest measurableone containing E). The inner (outer) measure gives a lower bound (upper bound) on the agent’s degree of beliefs in E. Soinner probability measure (together with outer probability measure) induced by probability measure assigns an intervalto every event as a representation of uncertainty of the event E, which is similar to belief/plausibility functions. Moreover,belief functions and inner probability measures are equivalent on formulas [18]. There is an immediate payoff to this view ofDempster–Shafer belief functions: a logic for reasoning about belief functions can be obtained from that for inner probabilitymeasures [19].The first investigation of mathematical properties of belief functions on more general lattices was initiated by Barthélemy[4] with the combinatorial theory on lattices by Rota [47], which was motivated by possible applications of belief functionsfor non-standard representation of knowledge. Grabisch [26] continued along this direction and showed that such propertiesas Dempster’s rule of combination and Smets’s canonical decomposition [57] in the case of Boolean algebras can be trans-posed in general lattice setting. This generalized theory has been applied to many objects in real world problems that maynot form a Boolean algebra. Let us give some examples: set-valued variables in multi-label classification [13,70], the set ofpartitions in ensemble clustering [39] and bi-capacities in cooperative game theory [29]. Because of its generality, however,Grabisch’s theory loses many intuitively appealing properties in the Dempster–Shafer theory. For example, since a latticedoes not necessarily admit a probability function [26], belief functions in general lattice settings fail to maintain a closeconnection with the Bayesian theory and therefore lack many of the desirable properties associated with this theory asin Dempster–Shafer theory [18]. Since pignistic probabilities are used for decision-making in the transferable belief modelby Smets [65,58], it would be impossible to develop decision theory for general lattice structures along a similar line. Inparticular, most non-classical formalisms1 in AI assume a setting of distributive lattices and hence it would be difficult toapply Grabisch’s theory directly to obtain a deductive approach for reasoning about belief functions over these formalismsas developed in Section 5 of this paper. Our deductive approach requires a setting of distributive lattices. Moreover, in manyreal-world problems such as evidential reasoning on fuzzy events [68,55,56,66] and bipolar belief pairs on vague proposi-tions [36] which do assume a setting of distributive lattices, belief functions are defined in totally different forms. It wouldbe desirable to establish a uniform theory for all these applications of belief functions.An optimal balance between utility and elegance of a theory of belief functions is achieved for distributive lattices, whichis the main contribution of this paper. Not only does our approach for distributive lattices yield a mathematical theoryas appealing as Dempster–Shafer theory, but also its applications extend to many non-classical formalisms of structures inArtificial Intelligence (quantum theory [67] is one of very few important exceptions). The main difficulty in the extension ishow to characterize the class of belief functions without reference to mass assignments. Birkhoff’s fundamental theorem forfinite distributive lattices solves this problem. Through this characterization, many fundamental properties of belief functionsin the Boolean case are also preserved in distributive lattices. Just as i",
            {
                "entities": [
                    [
                        4337,
                        4365,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 551–569Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal query complexity bounds for finding graphsSung-Soon Choi a,1, Jeong Han Kim a,b,∗,2a Department of Mathematics, Yonsei University, Seoul, 120-749, Republic of Koreab National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Koreaa r t i c l ei n f oa b s t r a c tWe consider the problem of finding an unknown graph by using queries with an additiveproperty. This problem was partially motivated by DNA shotgun sequencing and linkagediscovery problems of artificial intelligence.Given a graph, an additive query asks the number of edges in a set of vertices whilea cross-additive query asks the number of edges crossing between two disjoint sets ofvertices. The queries ask the sum of weights for weighted graphs.For a graph G with n vertices and at most m edges, we prove that there exists an algorithmto find the edges of G using O( m log n2log(m+1) ) queries of both types for all m. The bound is bestpossible up to a constant factor. For a weighted graph with a mild condition on weights, itlog m ) queries are enough provided m (cid:2) (log n)α for a sufficiently largeis shown that O( m log nconstant α, which is best possible up to a constant factor if m (cid:3) n2−ε for any constantε > 0.This settles, in particular, a conjecture of Grebinski [V. Grebinski, On the power of additivecombinatorial search model, in: Proceedings of the 4th Annual International Conferenceon Computing and Combinatorics (COCOON 1998), Taipei, Taiwan, 1998, pp. 194–203] forfinding an unweighted graph using additive queries. We also consider the problem offinding the Fourier coefficients of a certain class of pseudo-Boolean functions as well asa similar coin weighing problem.m© 2010 Elsevier B.V. All rights reserved.Article history:Received 6 August 2008Received in revised form 12 February 2010Accepted 13 February 2010Available online 21 February 2010Keywords:Combinatorial searchCombinatorial group testingGraph findingCoin weighingFourier coefficientPseudo-Boolean functionLittlewood–Offord theorem1. Introduction1.1. Graph finding problemThe problem of finding a graph is stated as follows. Suppose that a graph G has n vertices and at most m edges and thatthe edges of G are unknown. We may consider two types of queries, additive queries and cross-additive queries. An additivequery asks the number of edges in a set of vertices while a cross-additive query asks the number of edges crossing betweentwo disjoint sets of vertices. The problem is to find the edges of G by using as few queries as possible.Additive queries have been motivated by a main process in shotgun sequencing [6,20]. Shotgun sequencing is a methodto determine the whole genome sequence in an organism’s DNA. In shotgun sequencing, it is required to order decoded* Corresponding author at: National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Korea.E-mail addresses: ss.choi@yonsei.ac.kr (S.-S. Choi), jehkim@nims.re.kr (J.H. Kim).1 This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry ofEducation, Science and Technology (CRI, No. 2008-0054850).2 This work was partially supported by Yonsei University Research Funds 2006-1-0078 and 2007-1-0025, and by the second stage of the Brain Korea 21Project in 2007, and by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2006-312-C00455).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.003\f552S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569fragments (called contigs) of the genome sequence. Given a set of contigs, a method called the multiplex PCR method [39]tells how many pairs of the contigs are adjacent in the original sequence. Thus, the task of ordering contigs is reduced tothe problem of finding an unknown graph, which is a Hamiltonian cycle or path, by using additive queries. See e.g., [20].Cross-additive queries have been motivated by the problem of finding the Fourier coefficients for a certain class ofpseudo-Boolean functions. A pseudo-Boolean function is a real-valued function defined on the set of binary sequences. It isk-bounded if it can be expressed as a sum of subfunctions each of which depends on at most k input bits. For example,given a 2-SAT formula, the number of clauses an assignment satisfies is a 2-bounded pseudo-Boolean function. In molecularbiology and biophysics, k-bounded functions have been used to study the evolution of a population of organisms in anenvironment [25]. Specifically, k-bounded functions with small k have received attention in modeling living systems [26]and real biological objects [17]. In evolutionary computation, k-bounded functions have been also used as a benchmark forcomparing heuristic algorithms [18,32,33,38]. Cross-additive queries are used to find the Fourier coefficients of 2-boundedfunctions. More generally, cross-additive queries for k-bounded hypergraphs can be used to find the Fourier coefficients ofk-bounded functions, where k-bounded hypergraphs are hypergraphs whose hyperedges are of size at most k.An algorithm to find an unknown graph is called non-adaptive if each query in the algorithm is independent of theanswers for the previous queries. Otherwise, it is called adaptive. Non-adaptive algorithms are preferable to adaptive onesparticularly when the number of required queries is fairly large and parallel computation is available. There have beena number of papers addressing the problem of finding a graph using additive queries. When the (unknown) graph is aHamiltonian cycle on n vertices, Grebinski and Kucherov [20] presented an adaptive algorithm using O(n) additive queries,which is the best possible up to a constant factor. Later, Grebinski and Kucherov [21] provided an extensive work for severaltypes of graphs. In particular, for graphs with maximum degree bounded by d, they proved the existence of a non-adaptivealgorithm using O(dn) additive queries. When the graph is k-degenerate, the existence of a non-adaptive algorithm usingO(kn) additive queries was shown by Grebinski [19].The fully general case that the graph has n vertices and at most m edges has been a matter of primary concern. It hasbeen conjectured by Grebinski [19] that there exists an algorithm to find the unknown graph using O(m) additive queriesprovided that m = Ω(n). The conjecture has not been settled for a decade. For general m, an adaptive algorithm usingO(m log n) additive queries by Angluin and Chen [4] is the best known to date. In fact, their algorithm uses less powerfulqueries called membership queries, which ask the oracle only about the existence of an edge in a set of vertices. (There havealso been a number of papers addressing the problem of finding a graph using membership queries [2,3,5–7].) Recently,Reyzin and Srivastava [34] presented a simpler adaptive algorithm using O(m log n) additive queries. In this paper, we provethe conjecture of Grebinski in a stronger form, namely the existence of a non-adaptive algorithm using O( m log n2queries. This bound is best possible and better than O(m) if log n2m(cid:3) log m, in particular, m > n2log(m+1) ) additivelog n .mWe shall focus on bounds for the number of required cross-additive queries. Note that cross-additive queries are lessstrong than additive queries since a cross-additive query for the disjoint sets S, T of vertices can be answered by the threeadditive queries for S ∪ T , S, and T . It can be easily shown that the converse is not true: For example, for a graph withexactly one edge, Ω(log n) cross-additive queries are required to verify that it has only one edge while one additive queryis enough to verify the same. In the rest of this paper, we state results with respect to cross-additive queries. The samestatements hold for additive queries after simple modifications if necessary.In this paper, we consider two versions of the graph finding problem. The first one isProblem 1 (Unweighted graphs).Input:Output:an unweighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edgesthe edges of GFor the query complexity of the problem, we have the following.Theorem 1.1. There is a non-adaptive algorithm that solves Problem 1 using O( m log n2mlog(m+1) ) cross-additive queries.The second is a generalized one for weighted graphs with a moderate condition on weights of edges.Problem 2 (Weighted graphs).Input:Output:a weighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edges– the weights of edges of G are between nthe edges of G−a and nb in absolute value\fS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569553For weighted graphs, a cross-additive query asks the sum of weights of the edges crossing between two disjoint sets ofvertices. We obtain bounds for the number of cross-additive queries required to solve the problem.Theorem 1.2. For any fixed constants a, b > 0, there are a constant α > 0 and a non-adaptive algorithm that solves Problem 2 usingO( m log nlog m ) cross-additive queries provided m (cid:2) (log n)α .This extends the result of the conference version [13] that gives the bound when m is at least a constant power of n.3Concerning the condition on weights, a remark is provided in Section 7.Notice that we focused only on query complexity of algorithms. The presented algorithms are not computationally ef-ficient and we do not try to optimize them in time complexity. In terms of query complexity, the bounds in the abovetheorems are optimal up to a constant factor for all or almost all m by the information-theoretic lower bounds. For un-weighted graphs, the bound is optimal for all m. For weighted graphs, the bound is optimal if m (cid:3) n2−ε for any constantε > ",
            {
                "entities": [
                    [
                        3634,
                        3662,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 620–642www.elsevier.com/locate/artintIs real-valued minimax pathological?Mitja Luštrek a,∗, Matjaž Gams a, Ivan Bratko ba Department of Intelligent Systems, Jožef Stefan Institute, Jamova 39, 1000 Ljubljana, Sloveniab Faculty of Computer and Information Science, University of Ljubljana, Tržaška cesta 25, 1000 Ljubljana, SloveniaReceived 4 January 2005; received in revised form 9 January 2006; accepted 15 January 2006Available online 17 February 2006AbstractDeeper searches in game-playing programs relying on the minimax principle generally produce better results. Theoretical analy-ses, however, suggest that in many cases minimaxing amplifies the noise introduced by the heuristic function used to evaluate theleaves of the game tree, leading to what is known as pathological behavior, where deeper searches produce worse results. In mostminimax models analyzed in previous research, positions’ true values and sometimes also heuristic values were only losses andwins. In contrast to this, a model is proposed in this paper that uses real numbers for both true and heuristic values. This model didnot behave pathologically in the experiments performed. The mechanism that causes deeper searches to produce better evaluationsis explained. A comparison with chess is made, indicating that the model realistically reflects position evaluations in chess-playingprograms. Conditions under which the pathology might appear in a real-value model are also examined. The essential differencebetween our real-value model and the common two-value model, which causes the pathology in the two-value model, is identified.Most previous research reports that the pathology tends to disappear when there are dependences between the values of siblingnodes in a game tree. In this paper, another explanation is presented which indicates that in the two-value models the error of theheuristic evaluation was not modeled realistically. 2006 Elsevier B.V. All rights reserved.Keywords: Game playing; Minimax; Pathology; Game tree; Real value; Chess1. IntroductionThe minimax principle lies at the heart of almost every game-playing program. Programs typically choose the bestmove by searching the game tree, heuristically evaluating the leaves and then propagating their values to the root usingthe minimax principle. In practice, deeper searches generally produce better results. However, mathematical analysisindicates that under certain seemingly sensible conditions, the opposite is true: minimaxing amplifies the error ofthe heuristic evaluation [2,10]. This phenomenon is called the minimax pathology [10]. Nau [14] described this as“doing worse by working harder”. Evidently, game trees of real games must be different from game trees used in thetheoretical analyses in some way that eliminates the pathology. Several explanations of what property of game treesof real games might be responsible have been put forth: similarity of positions close to each other [3,11], presence ofstabilizing game-tree nodes with reliable estimates [4,16] etc. And while these properties can be shown to eliminate* Corresponding author.E-mail addresses: mitja.lustrek@ijs.si (M. Luštrek), matjaz.gams@ijs.si (M. Gams), bratko@fri.uni-lj.si (I. Bratko).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.006\fM. Luštrek et al. / Artificial Intelligence 170 (2006) 620–642621the pathology, the question to what extent they are actually present in game trees of real games remains. Also, themechanism by which they achieve its goal is sometimes inadequately explained.This paper attempts to address both of these problems: we model game trees in a way that we believe reflects wellthe properties of real games and we explain the mechanism that eliminates the pathology. In our game trees, positionsclose to each other are similar. But unlike most models used in previous research, in which positions’ true values, andsometimes also heuristic values, could only be losses or wins, we use real numbers for both true and heuristic values.This makes it possible to model the similarity between a position’s descendants in a more natural way, and enables amore direct comparison to game-playing programs, which typically use a sizable range of integer values. The modelcan be analyzed mathematically to explain the mechanism that makes minimax effective. Multiple types of error anddifferent experimental settings, among them the approximation of real values by a limited number of discrete values,are used to determine when exactly is the pathology present in a real-value model. Some light is also shed on thereasons for pathological behavior of the two-value models used in previous research.The paper is organized as follows. Section 2 is a short introduction to the minimax pathology with some historicaloverview. Section 3 presents our model of minimax. Section 4 gives a mathematical analysis of minimax with real-number values. Section 5 compares our model to a chess program. Section 6 explains when and how the pathologyappears in a real-value model and examines the differences between real-value and two-value models. Section 7concludes the paper and points out some areas where further research is needed.2. Related workThe minimax pathology was discovered independently by Nau [10] and Beal [2]. It was later more thoroughlyanalyzed by many authors, among them Bratko and Gams [4], whose notation we adopt. In this section, we present abasic minimax model like the one by Beal and others.A game tree consists of nodes representing game positions and edges representing moves. In the basic model,positions can be lost or won. Negamax notation is used in this section, i.e. nodes are marked as lost or won from theperspective of the side to move. Two situations are possible: a node has at least one lost descendant, in which casethe node itself is won because one can always choose the move leading to the descendant lost for the opponent; or anode has only won descendants, in which case the node itself is lost because all moves lead to positions won for theopponent. This is shown in Fig. 1; losses are marked with “−” and wins with “+”.Virtually all research on the minimax pathology assumed game trees to have a uniform branching factor b. In thebasic model, the value of each leaf is independent of other leaves’ values. Let d be the depth of search and ki theprobability of a loss at ith ply. Plies are numbered upwards: 0 for the lowest ply of search and d for the root.Since a node can only be lost if all of its descendants are won, the relation between the values of k at consecutiveplies is governed by Eq. (1).ki+1 = (1 − ki)b.(1)The goal is to calculate the probability of incorrectly evaluating the root given the probability of an incorrectevaluation at the lowest ply of search. Two types of evaluation error are possible: a loss can be mistaken for a win(false win) or a win for a loss (false loss). Let pi and qi be the probabilities of the respective types of error at ith ply.False wins occur in nodes where all descendants should be won, but at least one of them is a false loss. Therefore pi+1can be calculated according to Eq. (2).pi+1 = 1ki+1(1 − ki)b(cid:1)1 − (1 − qi)b(cid:2)= 1 − (1 − qi)b.(2)False losses occur in nodes where some descendants should be lost, but all of those are false wins instead, whileall won descendants retain their true values. Therefore qi+1 can be calculated according to Eq. (3).Fig. 1. Types of nodes.\f622M. Luštrek et al. / Artificial Intelligence 170 (2006) 620–642qi+1 =11 − ki+1b(cid:3)j =1(cid:4)(cid:5)bji (1 − ki)b−j pjkji (1 − qi)b−j= (kipi + (1 − ki)(1 − qi))b − ((1 − ki)(1 − qi))b1 − ki+1.(3)If only games where both sides have an equal chance of winning at the root of the game tree are considered, kdmust be 0.5 and Eq. (1) can be used to calculate k for other plies. Values for p0 and q0 have to be chosen and Eqs. (2)and (3) can be used to calculate pd and qd . If error at the root is defined as either pd kd + qd (1 − kd ) [4] or 1/2(pd + qd )[16], it turns out that with increasing d, the error converges towards 0.5, rendering minimax useless.First attempts to explain this phenomenon were made by Bratko and Gams [4] and Beal [3]. Both came to theconclusion that the reason minimax is effective in real games is that sibling nodes have similar values. Bratko andGams argued that this property causes the formation of subtrees with reliably evaluated roots, which have a stabilizingeffect. They did not verify whether this is indeed the case in real games. Beal showed that if a sufficient numberof nodes that have all the descendants either lost or won are present in a game tree, the pathology disappears. Hesuccessfully verified his claim on king and pawn versus king chess endgame, but his results are not conclusive becausesuch an endgame is not a typical chess situation. Nau [11,13] used a simple game designed for minimax analysis toshow that a strong dependence between a node and its descendants eliminates the pathology. Pearl [16] suspected thatreal games do not have such a strong dependence. He argued that early terminations (also called blunders), which carryreliable evaluations, are the main reason for the elimination of the pathology. Both early terminations and subtreeswith similar node values proposed by Bratko and Gams [4] result in relatively error-free nodes, so these two propertiesuse basically the same mechanism to eliminate the pathology. Pearl’s calculations show that the number of necessaryearly terminations in a game tree with b = 2 is 5%, but attempts by Luštrek and Gams [9] to verify this experimentallyindicate that 20% is needed with b = 2 and even more with larger branching factors. Schrüfer [19] showed that if theerror, particularly the probability of a false loss, is sufficiently low and certain additional conditions are satisfied, agame tree is not pathological. He did not investigate whether these condition",
            {
                "entities": [
                    [
                        3339,
                        3367,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 368–395Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAuction optimization using regression trees and linear models as integer programsSicco Verwer a, Yingqian Zhang b,∗a Intelligent Systems Department, Delft University of Technology, The Netherlandsb Department of Econometrics, Erasmus University Rotterdam, The Netherlands, Qing Chuan Ye ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 14 May 2015Accepted 21 May 2015Available online 29 May 2015Keywords:Auction designMachine learningOptimizationInteger linear programmingRegressionIn a sequential auction with multiple bidding agents, the problem of determining the ordering of the items to sell in order to maximize the expected revenue is highly challenging. The challenge is largely due to the fact that the autonomy and private information of the agents heavily influence the outcome of the auction.The main contribution of this paper is two-fold. First, we demonstrate how to apply machine learning techniques to solve the optimal ordering problem in sequential auctions. We learn regression models from historical auctions, which are subsequently used to predict the expected value of orderings for new auctions. Given the learned models, we propose two types of optimization methods: a black-box best-first search approach, and a novel white-box approach that maps learned regression models to integer linear programs (ILP), which can then be solved by any ILP-solver. Although the studied auction design problem is hard, our proposed optimization methods obtain good orderings with high revenues.Our second main contribution is the insight that the internal structure of regression models can be efficiently evaluated inside an ILP solver for optimization purposes. To this end, we provide efficient encodings of regression trees and linear regression models as ILP constraints. This new way of using learned models for optimization is promising. As the experimental results show, it significantly outperforms the black-box best-first search in nearly all settings.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOne of the main challenges of mathematical optimization is to construct a mathematical model describing the properties of a system. When the structure of a system cannot be fully determined from the knowledge at hand, machine learning and data mining techniques have been used in optimization instead of this knowledge. They have, for example, been used in order to obtain decision values [1], fitness functions [2], or model parameters [3]. Models that have been learned from data are frequently used in a black-box manner, e.g., using only the predictions of learned models but not their internal structure. It is also possible to use these models in a white-box manner, for instance in order to determine search space cuts and parameter bounds. Neural networks have in this way been used to model unknown relations in constraint programming [4]. In this paper, we develop such a white-box optimization method for regression models in integer linear programming, that is, we map these entire models to sets of variables and constraints and solve them using an off the shelf solver. * Corresponding author.E-mail addresses: S.E.Verwer@tudelft.nl (S. Verwer), yqzhang@ese.eur.nl (Y. Zhang), ye@ese.eur.nl (Q.C. Ye).http://dx.doi.org/10.1016/j.artint.2015.05.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\fS. Verwer et al. / Artificial Intelligence 244 (2017) 368–395369This white-box method together with a proposed black-box method provides a solution to an optimization problem of key interest to the artificial intelligence and operations research communities: auction design. We briefly introduce this problem domain before going into the details of our methods.1.1. Sequential auction designAuctions are becoming increasingly popular for allocating resources or items in business-to-business and business-to-customer markets. Often sequential auctions [5] are adopted in practice, where items are sold consecutively to bidders. Sequential auctions are in particular desirable when the number of items for sale is large (e.g., flower auctions [6]), or when the buyers enter and leave the auction dynamically (e.g., online auctions [7]). In a sequential auction, an auctioneer may tune several auction parameters to influence the outcome of an auction, such as reserve prices for items and in which order to sell them. In other words, (s)he can design auctions for the purpose of achieving some predefined goal. In this paper, we solve one specific auction design problem, namely, deciding the optimal ordering of items to sell in a sequential auction in order to maximize the expected revenue (OOSA in short). We assume bidders in such auctions are budget constrained. This is a highly relevant problem in today’s auctions since bidders almost always have limited budget, as seen for instance in industrial procurement [8]. Previous research has shown that with the presence of budget constraints, the revenue collected by the auctioneer is heavily dependent on the ordering of items to sell [9–11]. This holds already for a toy problem with 2 items. Let us use a simple example to illustrate the importance of ordering in such cases.Example 1. Two agents A1 and A2 take part in a sequential auction of items. For sale are items r1 and r2. Suppose the items are sold by means of first-price, English auction.1 Assume the reserve prices, which are the lowest prices at which the auctioneer is willing to sell the times, for both items are 1. The amount that agent A1 and agent A2 are willing to pay for two items are: ν1(r1) = 10, ν1(r2) = 15, ν2(r1) = 12, ν2(r2) = 10. Furthermore, the budgets of A1 and A2 are 15 and 25respectively.We assume a simple bidding strategy in this example. The agents bid myopically on each item, that is, their highest bid on one item is the lower value between the amount that they are willing to pay and their remaining budget. The auctioneer’s goal is to maximize the total sold price of the items. Consider one situation where the auctioneer sells first r2and then r1. A1 will get r2 when she just over-bids A2 with 11, and then when r1 is auctioned, A1 bids maximally 4 due to her budget limit, and A2 will win the item with the price of 5. The total revenue is 16. However, if the selling sequence is (r1, r2), A2 will win r1 with the bid 11, and then A2 will win r2 with price 11. The collected revenue is 22 in this case. (cid:2)Most of the current approaches to the ordering problem in sequential auctions assume a very restricted market environ-ment. They either study the problem of ordering two items, see [11,12], or a market with homogeneous bidders [13]. To the best of our knowledge, we are the first to consider how to order items for realistic auction settings with many hetero-geneous bidders competing for many different items. This problem is highly complex—a good design on ordering needs to take care of many uncertainties in the system. For instance, in order to evaluate the revenue given an ordering, the opti-mization algorithm needs to know the bidders’ budgets and preferences on items, which are usually private and unshared. Furthermore, the large variety of possible bidding strategies that bidders may use in auctions are unknown. This auction design problem is a typical example where the mathematical optimization model cannot be fully determined, and hence, machine learning and data mining techniques can come into play. This is exactly what our approach builds upon.1.2. Learning models for white-box and black-box optimizationNowadays more and more auctions utilize information technology, which makes it possible to automatically store de-tailed information about previous auctions along with their selling sequences and the selling price per auctioned item. Our approach to solving the problem of optimal ordering for sequential auctions starts with the historical auction data. We define and compute several relevant features and then use them to learn regression trees and linear regression models for the expected revenue. Given the models, we propose two approaches to find the optimal ordering for a new set of items: (1) a best-first search that uses the models as a black-box to evaluate different orderings of the items; and (2) a novel white-box optimization method that translates the models and the set of items into a mixed-integer program (MIP) and runs this in an ILP-solver (CPLEX). Fig. 1 displays the general framework of our approaches using these two optimization methods.Just like the traditional black-box optimization approach (see, e.g. [14,15]), our best-first search is ignorant of the internal structure of the models and only calls it to perform function evaluations, i.e., predicting the revenue of an ordering of the items. Optimization is possible by means of a search procedure that uses heuristics to produce new orderings depending on previously evaluated ones. Our best-first search makes use of dynamic programming cuts inspired by sequential decision making in order to reduce the search space.1 The English auction that we consider is the one where the starting price is the reserve price, and bidders bid openly against each other. Each subsequent bid should be higher than the previous bid, and the item is sold to the highest bidder at a price equal to her bid.\f370S. Verwer et al. / Artificial Intelligence 244 (2017) 368–395One of the main contributions of this paper is the realization that learned regression models can be evaluated efficiently inside modern mathematical optimization solvers. This evaluation includes the computation of feature values (the input to machine learning), the evaluation of these features using a learned model (the output from machine learning), and a possible feedback from such evaluations to new features. In this paper, we efficiently translat",
            {
                "entities": [
                    [
                        3428,
                        3456,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 52–89Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConflict-driven answer set solving: From theory to practice ✩Martin Gebser, Benjamin Kaufmann, Torsten Schaub∗Universität Potsdam, Institut für Informatik, August-Bebel-Str. 89, D-14482 Potsdam, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 19 March 2010Received in revised form 26 February 2012Accepted 5 April 2012Available online 10 April 2012Keywords:Answer set programmingLogic programmingNonmonotonic reasoningWe introduce an approach to computing answer sets of logic programs, based on conceptssuccessfully applied in Satisfiability (SAT) checking. The idea is to view inferences inAnswer Set Programming (ASP) as unit propagation on nogoods. This provides us witha uniform constraint-based framework capturing diverse inferences encountered in ASPsolving. Moreover, our approach allows us to apply advanced solving techniques from thearea of SAT. As a result, we present the first full-fledged algorithmic framework for nativeconflict-driven ASP solving. Our approach is implemented in the ASP solver clasp that hasdemonstrated its competitiveness and versatility by winning first places at various solvercontests.© 2012 Elsevier B.V. All rights reserved.1. IntroductionAnswer Set Programming (ASP; [67,94,102,66,87,6,65]) has become an attractive paradigm for knowledge representationand reasoning, due to its appealing combination of rich yet simple modeling languages1 with powerful solving engines.Albeit specialized ASP solvers have been highly optimized (cf. [119,83,15]), their performance has so far not matched theone of modern solvers for Satisfiability (SAT; [12]) checking. However, computational mechanisms of SAT and ASP solvers arenot far-off, as witnessed by the SAT-based ASP solvers assat [90] and cmodels [71]. Nonetheless, state-of-the-art look-backtechniques from SAT, or more generally, Constraint Programming (CP; [26,113]), such as backjumping and conflict-drivenlearning, were not yet established in native ASP solvers. In fact, previous approaches to adopt such techniques [126,112,91]are rather implementation-specific, i.e., they focus on describing modifications of existing ASP solving approaches, and thuslack generality.We address this deficiency by introducing a novel computational approach to ASP solving, building on Boolean con-straints. Apart from the fact that this allows us to easily integrate solving techniques from related areas like SAT, e.g.,backjumping, conflict-driven learning, restarts, etc., it also provides us with a uniform characterization of inferences fromlogic program rules, unfounded sets, and conflict conditions. As major results, we show that all inferences in ASP solv-ing can be reduced to unit propagation on nogoods, and we devise the first self-contained algorithmic framework fornative conflict-driven ASP solving. While the general outline of search is the same as in Conflict-Driven Clause Learning(CDCL; [97,127,23,96]), the state-of-the-art algorithm for industrial SAT solving, the integration of unfounded set checkingis particular to ASP and owed to its elevated expressiveness (cf. [117,76,88]). However, our approach favors “local” unitpropagation over unfounded set checks, i.e., tests whether inherent (loop) nogoods are unit or violated. We elaborate upon✩This paper combines and extends the work presented in Anger et al. (2005) [2], Gebser et al. (2007, 2007, 2009) [54,52,56].* Corresponding author. Tel.: +49 331 977 3080/3081; fax: +49 331 977 3122. Torsten Schaub is also affiliated with the School of Computing Science atSimon Fraser University, Burnaby, Canada, and the Institute for Integrated and Intelligent Systems at Griffith University, Brisbane, Australia.E-mail addresses: gebser@cs.uni-potsdam.de (M. Gebser), kaufmann@cs.uni-potsdam.de (B. Kaufmann), torsten@cs.uni-potsdam.de (T. Schaub).1 The interested reader is referred to [120,45,83] for detailed accounts of ASP’s modeling languages.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.001\fM. Gebser et al. / Artificial Intelligence 187–188 (2012) 52–8953the formal properties of our conflict-driven algorithmic framework, and we demonstrate its soundness and completenessfor ASP solving.Our approach has led to the implementation of the award-winning ASP solver clasp, taking first places at the ASP, CASC,MISC, PB, and SAT contests in 2011 (see [110] for more details). We discuss the major features of clasp and provide anempirical evaluation of its performance by comparing it to other state-of-the-art ASP solvers, using the class of NP decisionproblems from the second ASP competition [28]. Generally, clasp has become a powerful native ASP solver, offering variousreasoning modes that make it an attractive tool for knowledge representation and reasoning.2 This is witnessed by anincreasing number of applications relying on clasp (or derivatives) as reasoning engine, e.g., [99,13,80,122,75,64]. Along withthe grounder gringo [51], clasp constitutes a central component of Potassco [44], the Potsdam Answer Set Solving Collectionbundling tools for ASP developed at the University of Potsdam.The outline of this paper is as follows. After establishing the formal background, we provide in Section 3 a constraint-based specification of answer sets in terms of nogoods. Based on this uniform characterization, we develop in Section 4algorithms for ASP solving that incorporate advanced look-back techniques. In Section 5, we describe the award-winningASP solver clasp, implementing our approach. Section 6 provides a systematic empirical evaluation demonstrating the com-petitiveness of clasp. We conclude with related work and summary. Proofs for formal results are provided in Appendix A.2. BackgroundGiven an alphabet P , a (propositional normal) logic program is a finite set of rules of the formp0 ← p1, . . . , pm, not pm+1, . . . , not pn(1)where 0 (cid:2) m (cid:2) n and each pi ∈ P is an atom for 0 (cid:2) i (cid:2) n. A body literal is an atom p or its (default) negation not p. Fora rule r as in (1), let head(r) = p0 be the head of r and body(r) = {p1, . . . , pm, not pm+1, . . . , not pn} be the body of r. Theintuitive reading of r is that head(r) must be true if body(r) holds, i.e., if p1, . . . , pm are (provably) true and if pm+1, . . . , pnare (assumed to be) false. Given a set β of body literals, let β+ = {p ∈ P | p ∈ β} and β− = {p ∈ P | not p ∈ β}. For body(r),− = {pm+1, . . . , pn}. The set of atoms occurring in a logic program Πwe then have that body(r)is denoted by atom(Π), and body(Π) = {body(r) | r ∈ Π} is the set of bodies of rules in Π . For regrouping rule bodiessharing the same head p, we define bodyΠ (p) = {body(r) | r ∈ Π, head(r) = p}.A set X ⊆ P of atoms is a model of a logic program Π , if head(r) ∈ X , body(r)− ∩ X (cid:7)= ∅ holds forevery r ∈ Π . In ASP, the semantics of Π is given by its answer sets [67]. The reduct, Π X , of Π relative to X is defined by− ∩ X = ∅}. Note that Π X is a Horn program possessing a unique ⊆-minimalΠ X = {head(r) ← body(r)model (cf. [30]). Given this, X is an answer set of Π , if X itself is the ⊆-minimal model of Π X . Note that any answer setof Π is a model of Π as well, while the converse does not hold in general.+ = {p1, . . . , pm} and body(r)+ | r ∈ Π, body(r)+ (cid:2) X , or body(r)The positive dependency graph of a program Π is given by (atom(Π), (cid:2)+), where atom(Π) and (cid:2)+ = {(p, head(r)) |+} are the set of vertices and directed edges, respectively. This graph allows us to identify circularr ∈ Π, p ∈ body(r)positive dependencies among atoms. According to [90], a non-empty L ⊆ atom(Π) is a loop of Π , if for every pair p ∈ L,q ∈ L (including p = q), there is a path of non-zero length from p to q in (atom(Π), (cid:2)+) such that all vertices in thepath belong to L. We denote the set of all loops of Π by loop(Π); if loop(Π) = ∅ (or loop(Π) (cid:7)= ∅), Π is a tight (or non-tight) program. As shown in [40] and exploited in Section 3, the answer sets of a tight program Π coincide with modelsof the Clark completion of Π [21], also referred to as the supported models of Π [3]. A strongly connected component of(atom(Π), (cid:2)+) is a maximal subgraph such that any pair of vertices is connected by some path; it is non-trivial, if it containssome edge. Note that, for any loop L of Π , the atoms in L belong to the same non-trivial strongly connected component of(atom(Π), (cid:2)+). Moreover, we have that Π is tight iff (atom(Π), (cid:2)+) does not include any non-trivial strongly connectedcomponent.Example 2.1. Consider the following logic program3:(cid:3)(cid:2)Π2 =a ←b ← not a d ← not c, not ec ← a, not de ← be ← e.(2)This program has two answer sets: {a, c} and {a, d}. Note that Π2 is non-tight because its positive dependency graphcontains the non-trivial strongly connected component ({e}, {(e, e)}).In practice, propositional logic programs are usually obtained from inputs in some first-order language (cf. [120,45,83])via grounding. We do not detail grounding here, but only mention that off-the-shelf grounders, such as dlv’s groundingcomponent [105], gringo [51], and lparse [120], are available to accomplish this task. Moreover, particular classes of logic2 Beyond search for one answer set of a propositional normal logic program, detailed in this paper, clasp supports so-called extended rules [47], solutionenumeration [53,57], and optimization [48]. Due to its versatile core engine, clasp can be run as a solver for ASP, SAT, Maximum Satisfiability (MaxSAT;[85]), and Pseudo-Boolean (PB; [114]) constraint satisfaction/optimization, incorporating dedicated front-ends for diverse input formats.3 Our enumeration scheme for particular logic programs Π follows that of equations.\f54M. Gebser et al. / Artificial Intelligence 187–188 (2012) 52–89programs adm",
            {
                "entities": [
                    [
                        4156,
                        4184,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 221–239Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRanking gamesFelix Brandt a,∗, Felix Fischer a, Paul Harrenstein a, Yoav Shoham ba Institut für Informatik, Universität München, Oettingenstr. 67, 80538 München, Germanyb Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA 94305, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 3 January 2008Received in revised form 28 August 2008Accepted 20 October 2008Available online 29 October 2008Keywords:Multi-agent systemsGame theoryStrict competitivenessn-player gamesSolution conceptsComputational complexityThe outcomes of many strategic situations such as parlor games or competitive economicscenarios are rankings of the participants, with higher ranks generally at least as desirableas lower ranks. Here we define ranking games as a class of n-player normal-form gameswith a payoff structure reflecting the players’ von Neumann–Morgenstern preferencesover their individual ranks. We investigate the computational complexity of a variety ofcommon game-theoretic solution concepts in ranking games and deliver hardness resultsfor iterated weak dominance and mixed Nash equilibrium when there are more than twoplayers, and for pure Nash equilibrium when the number of players is unbounded but thegame is described succinctly. This dashes hope that multi-player ranking games can besolved efficiently, despite their profound structural restrictions. Based on these findings,we provide matching upper and lower bounds for three comparative ratios, each of whichrelates two different solution concepts: the price of cautiousness, the mediation value, and theenforcement value.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe situations studied by the theory of games may involve different levels of antagonism. On the one end of the spec-trum are games of pure coordination, on the other those in which the players’ interests are diametrically opposed. In thispaper, we put forward a new class of competitive multi-player games whose outcomes are rankings of the players, i.e.,orderings of the players representing how well they have done in the game relative to one another. We assume players toweakly prefer a higher rank over a lower one and to be indifferent as to the other players’ ranks. This type of situation iscommonly encountered in parlor games, competitions, patent races, competitive resource allocation domains, social choicesettings, or any other strategic situation where players are merely interested in performing optimal relative to their oppo-nents rather than in absolute measures. Formally, ranking games are defined as normal-form games in which the payofffunction represents the players’ von Neumann–Morgenstern preferences over lotteries over rankings. A noteworthy specialcase of particular relevance to game playing in AI are single-winner games where in any outcome one player wins and allothers lose.While two-player ranking games form a subclass of zero-sum games, no such relationship holds for ranking games withmore than two players. Moreover, whereas the notion of a ranking is most natural in multi-player settings, this seems tobe less so for the requirement that the sum of payoffs in all outcomes be constant, as any game can be transformed intoa constant-sum game by merely introducing an additional player (with only one action at his disposal) who absorbs thepayoffs of the other players [41].* Corresponding author. Tel.: +49 89 2180 9406; fax: +49 89 2180 9338.E-mail addresses: brandtf@tcs.ifi.lmu.de (F. Brandt), fischerf@tcs.ifi.lmu.de (F. Fischer), harrenst@tcs.ifi.lmu.de (P. Harrenstein), shoham@cs.stanford.edu(Y. Shoham).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.008\f222F. Brandt et al. / Artificial Intelligence 173 (2009) 221–239As with games in which both contrary and common interests prevail, it turns out that solving ranking games tends tobecome considerably more complicated as soon as more than two players are involved. The maximin solution does notunequivocally extend to general n-player games and numerous alternate solution concepts have been proposed to copewith this type of situation. None of them, however, seems to be as compelling as maximin is for two-player zero-sumgames. In this paper we study and compare the properties of a variety of solution concepts in ranking games. The resultsof this paper fall into two different categories. First, we investigate the complexity of a number of computational problemsrelated to common solution concepts in ranking games, particularly Nash equilibrium and iterated weak dominance. Second,we study a number of comparative ratios in ranking games, each of which relates two different solution concepts: the priceof cautiousness, the mediation value, and the enforcement value.The computational effort required to determine a solution is obviously a very important property of any solution concept.If computing a solution is intractable, the solution concept is rendered virtually useless for large problem instances that donot exhibit additional structure. The importance of this aspect has by no means escaped the attention of game theorists. Inan interview with Eric van Damme [39], Robert Aumann claimed: “My own viewpoint is that, inter alia, a solution conceptmust be calculable, otherwise you are not going to use it.” It has subsequently been argued that this still holds if onesubscribes to a purely descriptive view of solution concepts: “I believe that the complexity of equilibria is of fundamentalimportance in game theory, and not just a computer scientist’s afterthought. Intractability of an equilibrium concept wouldmake it implausible as a model of behavior” [28]. In computational complexity theory, the distinction between tractableand intractable problems is typically one between membership in the class P of problems that can be solved in timepolynomial in the size of the problem instance versus hardness for the class NP of problems a solution of which can beverified efficiently. A third class that will play an important role in the context of this paper is PPAD. Problems in PPAD areguaranteed to possess a solution, and emphasis is put on actually finding it. Given the current state of complexity theory,we cannot prove the actual intractability of most algorithmic problems, but merely give evidence for their intractability. NP-hardness of a problem is commonly regarded as very strong evidence against computational tractability because it relatesthe problem to a large class of problems for which no efficient algorithm is known, despite enormous efforts to find suchalgorithms. To some extent, the same reasoning can also be applied to PPAD-hardness.We study the computational complexity of common game-theoretic solution concepts in ranking games and deliver NP-hardness and PPAD-hardness results, respectively, for iterated weak dominance and (mixed) Nash equilibria when there aremore than two players, and an NP-hardness result for pure Nash equilibria in games with an unbounded number of players.This dashes hope that multi-player ranking games can be solved efficiently, despite their profound structural restrictions.Remarkably, all hardness results hold for arbitrary preferences over ranks, provided they meet the requirements listed above.Accordingly, even very restricted subclasses of ranking games such as single-winner games—in which players only care aboutwinning—or single-loser games—in which players merely wish not to be ranked last—are computationally hard to solve.By contrast, maximin strategies [40] as well as correlated equilibria [5] are known to be computationally easy via linearprogramming for any class of games. Against the potency of these concepts, however, other objections can be brought in.Playing a maximin strategy is extremely defensive and a player may have to forfeit a considerable amount of payoff in orderto guarantee his security level. Correlation, on the other hand, may not be feasible in all practical applications, and may failto provide an improvement of social welfare in restricted classes of games [23]. Thus, we come to consider the followingcomparative ratios in an effort to facilitate the quantitative analysis of solution concepts in ranking games:• the price of cautiousness, i.e., the ratio between an agent’s minimum payoff in a Nash equilibrium and his security level,• the mediation value, i.e., the ratio between the social welfare obtainable in the best correlated equilibrium vs. the bestNash equilibrium, and• the enforcement value, i.e., the ratio between the highest obtainable social welfare and that of the best correlated equi-librium.Each of these values obviously equals 1 in the case of two-player ranking games, as these form a subclass of constant-sumgames. Accordingly, the interesting question to ask concerns the bounds of these values for ranking games with more thantwo players.2. Introductory exampleTo illustrate the issues addressed in this paper, consider a situation in which Alice, Bob, and Charlie are to choose awinner from among themselves by means of the following protocol. Each of them is either to raise or not to raise theirhand; they are to do so simultaneously and independently of one another. Alice wins if the number of hands raised,including her own, is odd, whereas Bob is victorious if this number equals two. Should nobody raise their hand, Charliewins. The normal-form of this game is shown in Fig. 1. What course of action would you recommend to Alice? There is aNash equilibrium in which Alice raises her hand, another one in which she does not raise her hand, and still another onein which she randomizes uniformly between these two options. In the only pure, i.e., non-randomized, equilibrium of thegame, Alice does not raise her hand. If the latter were to occur, we must assume that Alice believes",
            {
                "entities": [
                    [
                        3831,
                        3859,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 392–412Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for the coalitional manipulation problem ✩Michael Zuckerman a,1, Ariel D. Procaccia b,∗,2, Jeffrey S. Rosenschein aa School of Engineering and Computer Science, The Hebrew University of Jerusalem, Jerusalem 91904, Israelb Microsoft Israel R&D Center, 13 Shenkar Street, Herzeliya 46725, Israela r t i c l ei n f oa b s t r a c tWe investigate the problem of coalitional manipulation in elections, which is known to behard in a variety of voting rules. We put forward efficient algorithms for the problem inBorda, Maximin and Plurality with Runoff, and analyze their windows of error. Specifically,given an instance on which an algorithm fails, we bound the additional power themanipulators need in order to succeed. We finally discuss the implications of our resultswith respect to the popular approach of employing computational hardness to precludemanipulation.© 2008 Elsevier B.V. All rights reserved.Article history:Received 15 December 2007Received in revised form 17 November 2008Accepted 20 November 2008Available online 24 November 2008Keywords:Computational social choiceVotingManipulationComputational complexity1. IntroductionSocial choice theory is an extremely well-studied subfield of economics. In recent years, interest in the computationalaspects of social choice, and in particular in the computational aspects of voting, has sharply increased.In an election, a set of voters submit their (linear) preferences (i.e., rankings) over a set of candidates. The winner ofthe election is designated by a voting rule, which is basically a mapping from the space of possible preference profiles intocandidates. A thorn in the side of social choice theory is formulated in the famous Gibbard–Satterthwaite Theorem [15,26].This theorem essentially states that for any voting rule that is not a dictatorship, there are elections in which at least oneof the voters would benefit by lying. A dictatorship is a voting rule where one of the voters—the dictator—single-handedlydecides the outcome of the election.Since the 1970s, when this impossibility result was established, an enormous amount of effort has been invested indiscovering ways to circumvent it. Two prominent and well-established ways are allowing payments [4,16,29], or restrictingthe voters’ preferences [20].In this paper, we wish to discuss a third path—the “path less taken”, if you will—which has been explored by computerscientists. The Gibbard–Satterthwaite Theorem implies that in theory, voters are able to manipulate elections, i.e., bend themto their advantage by lying. But in practice, deciding which lie to employ may prove to be a hard computational problem;after all, there are a superpolynomial number of possibilities of ranking the candidates.✩A significantly shorter version of this paper (with most of the proofs omitted) appeared in the Proceedings of the Nineteenth ACM–SIAM Symposiumon Discrete Algorithms (SODA-08). This work was also presented at the Dagstuhl Workshop on Computational Issues in Social Choice, October 2007.* Corresponding author.E-mail addresses: michez@cs.huji.ac.il (M. Zuckerman), arielpro@gmail.com (A.D. Procaccia), jeff@cs.huji.ac.il (J.S. Rosenschein).1 The author thanks Noam Nisan for a generous grant which supported this work.2 The author was supported in this work by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.005\fM. Zuckerman et al. / Artificial Intelligence 173 (2009) 392–412393Indeed, Bartholdi et al. [3] put forward a voting rule where manipulation is N P -hard. In another important paper,Bartholdi and Orlin [2] greatly strengthened the approach by proving that the important Single Transferable Vote (STV) ruleis hard to manipulate.This line of research has enjoyed new life in recent years thanks to the influential work of Conitzer, Sandholm, andLang [7].3 The foregoing paper studied the complexity of coalitional manipulation. In this setting, there is a coalition ofpotentially untruthful voters, attempting to coordinate their ballots so as to get their favorite candidate elected. The authorsfurther assume that the votes are weighted: some voters have more power than others. Conitzer et al. show that in avariety of prominent voting rules, coalitional manipulation is N P -hard, even if there are only a constant number of candidates(for more details, see Section 2). This work has been extended in numerous directions, by different authors [5,8,12,18,25];Elkind and Lipmaa [9], for example, strengthened the abovementioned results about coalitional manipulation by employingcryptographic techniques.In short, computational complexity is by now a well-established method of circumventing the Gibbard–SatterthwaiteTheorem. Unfortunately, a shortcoming of the results we mentioned above is that they are worst-case hardness results,and thus provide a poor obstacle against potential manipulators. Recent work regarding the frequency of manipulation hasargued that with many worst-case hard-to-manipulate voting rules, a potential manipulator may be able to compute amanipulation in typical settings [6,13]. In particular, Procaccia and Rosenschein [23,24] have established some theoreticalresults regarding the frequency of success of an algorithm for the coalitional manipulation problem. The matter was furtherdiscussed by Erdélyi et al. [11]. In spite of this, the question of the tractability of the manipulation problem, and in particularof the coalitional manipulation problem, in typical settings is still wide-open.Our approach and results We wish to convince the reader that, indeed, the coalitional manipulation problem can be effi-ciently solved in typical settings under some prominent voting rules, but our approach differs from all previous work. Wepresent efficient heuristic algorithms for the problem that provide theoretical guarantees. Indeed, we characterize smallwindows of instances on which our algorithms may fail; the algorithms are proven to succeed on all other instances.Specifically, we prove the following results regarding three of the most prominent voting rules (in which coalitionalmanipulation is known to be N P -hard even for a constant number of candidates):Theorem.1. In the Borda rule, if there exists a manipulation for an instance with certain weights, Algorithm 2 will succeed when given an extramanipulator with maximal weight.2. In the Plurality with Runoff rule, if there exists a manipulation for an instance with certain weights, Algorithm 3 will succeed whengiven an extra manipulator with maximal weight.3. In the Maximin rule, if there exists a manipulation for an instance with certain weights, Algorithm 1 will succeed when given twocopies of the set of manipulators.Significance in Artificial Intelligence The sharply increased interest in computational aspects of voting is motivated by numer-ous applications of voting techniques and paradigms to problems in Artificial Intelligence (AI). These applications includework in AI subfields as diverse as Planning [10], Automated Scheduling [17], Recommender Systems [14], Collaborative Fil-tering [22], Information Extraction [27], and Computational Linguistics [21].Unfortunately, in the application of voting to AI, some of the problems investigated in Social Choice Theory, and in par-ticular the issue of manipulation, become especially acute. Indeed, multiagent systems are often inhabited by heterogeneous,self-interested agents. Such agents, unlike human beings, can be designed to be rational, and constantly engaged in com-putations meant to increase their utility. In particular, a self-interested agent could seize the opportunity to manipulate anelection to its benefit if such an opportunity were computationally easy to recognize (unless specifically programmed notto).The agenda of circumventing the Gibbard–Satterthwaite Theorem via computational complexity is, once again, mostrelevant and compelling when the voters are software agents that populate a multiagent system, since the effective, boundedrationality of such agents is practically governed by the laws of computational complexity. This is why the agenda hasbecome a prominent one in AI, with numerous papers on the subject published in the major AI conferences over the lastfive years. As of yet, there are few papers on frequency of manipulation, rather than on its worst-case complexity. We feelthat this line of work on frequency of manipulation may influence the entire direction of the computational social choiceresearch agenda (see Section 5 for more details regarding work on frequency of manipulation).Structure of the articleIn Section 2 we describe the major voting rules and formulate the coalitional manipulation problem.In Section 3 we present and analyze our algorithms in three subsections: Borda, Plurality with Runoff, and Maximin. Weprovide some results regarding an unweighted setting in Section 4. In Section 5 we describe related work at length. Finally,we discuss our approach in Section 6.3 Historical note: although we cite the JACM 2007 paper, this work originated in a AAAI 2002 paper.\f394M. Zuckerman et al. / Artificial Intelligence 173 (2009) 392–4122. Voting rules and manipulation problemsAn election consists of a set C = {c1, . . . , cm} of candidates and a set S = {v 1, . . . , v|S|} of voters. Each voter provides atotal order on the candidates. To put it differently, each voter submits a ranking of the candidates. The voting setting alsoincludes a voting rule, which is a function from the set of all possible combinations of votes to C .We shall discuss the following voting rules (whenever the voting rule is based on scores, the candidate with the highestscore wins):• Scoring rules. Let (cid:3)α = (cid:4)α1, . . . , αm(cid:5) be a vector of non-nega",
            {
                "entities": [
                    [
                        3595,
                        3623,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 250 (2017) 58–79Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA progression semantics for first-order logic programsYi Zhou a,b,∗a School of Computing, Engineering and Mathematics, Western Sydney University, Sydney, Australiab School of Computer Science and Technology, TianJin University, TianJin, Chinac School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China, Yan Zhang a,ca r t i c l e i n f oa b s t r a c tArticle history:Received 21 August 2015Received in revised form 19 May 2017Accepted 6 June 2017Available online 9 June 2017Keywords:Logic programmingStable modelProgressionFirst-order1. IntroductionIn this paper, we propose a progression semantics for first-order normal logic programs, and show that it is equivalent to the well-known stable model (answer set) semantics. The progressional definition sheds new insights into Answer Set Programming (ASP), for instance, its relationships to Datalog, First-Order Logic (FOL) and Satisfiability Modulo Theories (SMT). As an example, we extend the notion of boundedness in Datalog for ASP, and show that it coincides with the notions of recursion-freeness and loop-freeness under program equivalence. In addition, we prove that boundedness precisely captures first-order definability for normal logic programs on arbitrary structures. Finally, we show that the progressional definition suggests an alternative translation from ASP to SMT, which yields a new way of implementing first-order ASP.© 2017 Elsevier B.V. All rights reserved.Answer Set Programming (ASP) has emerged as a predominant approach for nonmonotonic reasoning in the area of knowledge representation and reasoning due to its simplicity, expressive power and computational advantage [6,20,33,34]. At its beginning, the stable model (answer set) semantics for first-order logic programs is defined only on Herbrand Struc-tures by grounding into propositional programs [21,22]. In recent years, a number of approaches have been developed to release this restriction by directly defining the stable model semantics on arbitrary structures [4,5,7,10,15,18,24,26,28,31,36,38,40,42].A typical approach on this research line is to use a translation to another host language, e.g. second-order language [18] or circumscription [31]. For this purpose, second-order is inevitable as the class of the stable models of some logic programs, e.g. transitive closure, cannot be captured in first-order logic [16]. Under this backdrop, a first-order logic pro-gram (cid:2) is transformed to a corresponding second-order sentence S M((cid:2)), and the stable models of (cid:2) are defined as the models of S M((cid:2)) [18]. While this definition provides a precise mathematical representation and also generalizes the tradi-tional propositional ASP, it, however, does not reveal much information about the expressiveness of first-order answer set programming. For instance, it is unclear whether we can provide a complete characterization of first-order definability for first-order ASP.In this paper, we propose a progressional definition for first-order normal logic programs. Intuitively, this definition may be viewed as a generalization of the Gelfond–Lifschitz transformation [6] to the first-order case as well as a generalization of the progression semantics for Datalog [1,32]. Also, it shares some fundamental ideas with Reiter’s semantics for default * Corresponding author.E-mail address: yzhou@scm.uws.edu.au (Y. Zhou).http://dx.doi.org/10.1016/j.artint.2017.06.0010004-3702/© 2017 Elsevier B.V. All rights reserved.\fY. Zhou, Y. Zhang / Artificial Intelligence 250 (2017) 58–7959logic [37]. Simply enough, in the progressional definition, a first-order structure M is a stable model of a first-order normal logic program (cid:2) if and only if it is the fixed point of the progression of (cid:2) with respect to M. More precisely, M coincides with the structure obtained by recursively applying the rules in (cid:2), where the negative parts are fixed by M itself. We show that, for normal logic programs, this progressional definition is equivalent to the general stable model semantics defined by S M((cid:2)).The progressional definition sheds new insights into Answer Set Programming (ASP), for instance, its relationships to Datalog, First-Order Logic (FOL) and Satisfiability Modulo Theories (SMT). It can be further evident from the progressional definition that Datalog is exactly the monotonic counterpart of ASP, and many important Datalog techniques can be ap-plied to ASP as well. Based on the proposed progressional definition, we are able to define the notion of boundedness for first-order answer set programs, which is critical for understanding the relationship between first-order ASP and classical first-order logic.With the features of iterative and nonmonotonic reasoning, ASP is a representative rule-based formalism that is signifi-cantly different from classical logics. Nevertheless, ASP and classical logics are very closely related. Hence, the relationships between them have attracted a lot of attention in the literature [4,5,12–14,17,25,26,39]. Among them, a central topic is first-order definability, that is, what kind of answer set programs can be captured in classical first-order logic in the sense that their answer sets/stable models are exactly the classical models of a first-order sentence. Our notion of boundedness provides a complete answer for this. We prove that an answer set program is first-order definable if and only if it is bounded. Moreover, the notion of boundedness/first-order definability is also equivalent to two important syntactic notions of recursion-freeness and loop-freeness (tightness) under program equivalence. We believe that results in this aspect will establish a foundation for the further study of the expressiveness and related properties of first-order ASP.The progressional definition is not only of theoretical interest but also of practical relevance as it directly yields a new translation from first-order ASP to Satisfiability Modulo Theories (SMT). Comparing this translation to the one obtained from ordered completion [4,5], it is logically stronger as it has less models.This paper is organized as follows. Section 2 introduces necessary backgrounds. Section 3 proposes the progressional definition and shows that it is equivalent to the translational definition. Then, Section 4 extends the notion of boundedness in Datalog for ASP and shows that it is equivalent to the notions of recursion-freeness and loop-freeness under program equivalence. Section 5 further shows that boundedness exactly captures first-order definability of ASP. Section 6 reports a natural translation from first-order ASP to SMT based on the progressional definition. Finally, Section 7 discusses some related and ongoing works and Section 8 concludes the paper respectively.2. PreliminariesAiWe start with necessary logical notions and notations. We consider a second-order language without function symbols but with equality. A vocabulary τ is a set that consists of relation symbols (or predicates) including the equality symbol = and constant symbols (or constants). Each predicate is associated with a natural number, called its arity. Given a vocabulary, term, atom, substitution, (first-order and second-order) formula and (first-order and second-order) sentence are defined as usual. In particular, an atom is called an equality atom if it has the form t1 = t2, where t1 and t2 are terms. Otherwise, it is called a proper atom.A structure A of vocabulary τ (or a τ -structure) is a tuple A = ( A, ccalled the domain of A, cover A for every k-ary predicate P j in τ . Pa finite set. In this paper, we consider both finite and infinite structures.AA1 , · · · , Pn ), where A is a nonempty set A(1 ≤ j ≤ n) is a k-ary relation(1 ≤ i ≤ m) is an element in A for every constant ci in τ , and Pjis also called the interpretation of P j in A. A structure is finite if its domain is A1 , · · · , cAm , P−→x ) be an atom, η an assignment in structure A. For convenience, we also write P (Let A be a structure of τ . An assignment in A is a function η from the set of variables to A. An assignment can be , where c is an arbitrary constant. −→x )η ∈ A for the fact that . The satisfaction relation |= between a structure A and a formula φ associated with an assignment η, denoted −→x be the set of free variables occurring in a formula φ. Then, the satisfaction relation −→a ) for convenience, −→a is a tuple of elements in A. In particular, if φ is a sentence, then the satisfaction relation is independent of the −→a ), where P is a predicate −→a ), to denote extended to a corresponding function from the set of terms to A by mapping η(c) to cLet P (−→x ) ∈ Pη(by A |= φ[η], is defined as usual. Let is independent from the assignment of variables not in where assignment. In this case, we simply write A |= φ for short. A ground atom in A is of the form P (−→and a a tuple of elements that matches the arity of P . For convenience, we also use P (−→a ∈ P−→x . In this case, we also write A |= φ(−→a ) ∈ A, or A |= P (−→x /AjAAA.Given a structure A of τ , Q a predicate in τ and some ground atoms Q (−→an }.−→a1 , . . . , to denote a new structure of τ which is obtained from A by expanding the interpretation of predicate Q in A (i.e. QQA ∪ {Let A1 and A2 be two structures of τ sharing the same domain, and for each constant c in τ , cA2 . By A1 ⊆ A2, A2 . By A1 ⊂ A2, we mean that A1 ⊆ A2 but not A2 ⊆ A1. We we simply mean that for each predicate P ∈ τ , Pwrite A1 ∪ A2 to denote the structure of τ where the domain of A1 ∪ A2 is the same as A1 and A2’s domain, each constant c is interpreted in the same way as in A1 and A2, and for each predicate P in τ , PA1∪A2 = PA1 ⊆ PA1 ∪ PA1 = cA2 .−→a1 ) ,. . . , Q (−→a n), we use A ∪{Q (−→−→an )}a1 ), . . . , Q (A) to \f60Y. Zhou, Y. Zhang / Arti",
            {
                "entities": [
                    [
                        3580,
                        3608,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1285–1306Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintReducts of propositional theories, satisfiability relations, andgeneralizations of semantics of logic programs ✩Miroslaw Truszczy ´nskiDepartment of Computer Science, University of Kentucky, Lexington, KY 40506, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 24 November 2009Received in revised form 6 August 2010Accepted 8 August 2010Available online 12 August 2010Keywords:Logic programmingStable modelsSupported modelsReductsLogic HTOver the years, the stable-model semantics has gained a position of the correct (two-for programs withvalued) interpretation of default negation in programs. However,aggregates (constraints), the stable-model semantics, in its broadly accepted generalizationstemming from the work by Pearce, Ferraris and Lifschitz, has a competitor: the semanticsproposed by Faber, Leone and Pfeifer, which seems to be essentially different. Ourgoalis to explain the relationship between the two semantics. Pearce, Ferraris andLifschitz’s extension of the stable-model semantics is best viewed in the setting ofarbitrary propositional theories. We propose here an extension of the Faber–Leone–Pfeifersemantics, or FLP semantics, for short, to the full propositional language, which revealsboth common threads and differences between the FLP and stable-model semantics. Weuse our characterizations of FLP-stable models to derive corresponding results on strongequivalence and on normal forms of theories under the FLP semantics. We apply a similarapproach to define supported models for arbitrary propositional theories, and to studytheir properties.© 2010 Elsevier B.V. All rights reserved.1. IntroductionThe stable-model semantics introduced by Gelfond and Lifschitz [23] is the foundation of answer-set programming [37,41,22], a paradigm for modeling and solving search problems. Answer-set programming is broadly accepted as an effectiveknowledge representation tool for modeling intelligent agents and reasoning in complex domains [12,13,3]. In the lastdecade, it has been successfully applied in several areas of artificial intelligence such as product configuration [47], planning[50,48], reasoning about action [25], and diagnosis [43,2], with some of these applications concerning large-scale systemslike the space shuttle flight controller [43]. Answer-set programming has also been applied beyond artificial intelligence forproblems arising in bio-informatics [4,46], linguistics [7] and automated music generation [5].The success of answer-set programming as a knowledge representation formalism and its applications in artificial intelli-gence and beyond make it essential that theoretical underpinnings of its semantics be established. Consequently, right fromits inception, the stable-model semantics, has received much attention. The present paper contributes to this general line ofresearch by extending the theoretical framework for the stable-model semantics based of the results and ideas proposed anddeveloped by Pearce [44] and Ferraris [19] to two other closely related semantics that also play a major role in answer-setprogramming, the Faber–Leone–Pfeifer stable-model semantics [16] and the supported-model semantics [9,1,38].A far-reaching contribution by Pearce [44] explained the stable-model semantics in terms of models of theories in thelogic of here-and-there (HT, for short), introduced by Heyting [26]. It had two important consequences. First, it resulted in ageneralization of the stable-model semantics, originally limited to a restricted syntax of program rules, to arbitrary theories✩An extended abstract of this paper appeared in the proceedings of the 2009 International Conference on Logic Programming.E-mail address: mirek@cs.uky.edu.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.08.004\f1286M. Truszczy´nski / Artificial Intelligence 174 (2010) 1285–1306in the language of propositional logic (we discuss the role of this development in more detail later). Second, it brought aboutthe notion of strong equivalence of programs, fundamental to modular program development [32]. Strong equivalence hasbeen extensively studied in the past decade. That research resulted in extensions and refinements of the original concept,in characterizations, and in complexity results [32,35,51,14,52,49].The original definition of stable models [23] was based on the reduct of a program with respect to a set of atoms.The characterization in terms of the logic HT makes no reference to reducts but employs a form of model minimization.Ferraris [19] extended the notion of reduct to propositional theories, and developed the reduct-based definition of stablemodels equivalent to that provided by the logic HT (an exposition of the idea can also be found in the paper by Ferrarisand Lifschitz [21]).The papers by Pearce and Ferraris resulted in an elegant comprehensive treatment of the stable-model semantics. Theyalso raise the question whether there are other generalizations of the stable-model semantics to the case of arbitrarylogic theories. An indication that it might be so comes from the work by Faber et al. [16] on programs with aggregates.Aggregates, in the form of weight atoms, were introduced to answer-set programming by Niemelä and Simons [42], whoextended the stable-model semantics to that class of programs. Ferraris [19] cast that generalization in terms of stablemodels of propositional theories. Stable models of programs with aggregates are no longer guaranteed to be minimal models.From the perspective of the Ferraris’ result, it is not surprising. Stable models of propositional theories in general do nothave the minimal-model property.However, as minimization is an important knowledge-representation principle, Faber et al. [16] sought an alternativesemantics for programs with constraints, one that would have the minimal-model property. Naturally, they also wanted itto coincide with the original semantics on the class of programs without aggregates. They came up with a solution thatsatisfied both requirements by modifying the concept of the reduct! In the setting with aggregates, the Faber–Leone–Pfeiferstable-model semantics, or FLP semantics, is different than the extension of the original stable-model semantics based onthe logic HT (throughout the paper, whenever we speak about the stable-model semantics, we have the original semanticsin mind). Thus, the question of alternative generalizations is relevant. The FLP semantics is steadily gaining on importance.It is now not only used as the basis for interpreting aggregates in the dlv system [17], but also in approaches aiming tointegrate answer-set programming with other declarative programing paradigms [11].A related question concerns a possibility of generalizing other semantics relevant to answer-set programming to thefull propositional logic language. The one we consider here is the supported-model semantics. Its importance stems fromtwo properties. First, the supported-model semantics is the key component of a characterization of stable models in termsof loop formulas [36], which gave rise to fast algorithms for computing stable models of programs [36,31,30]. Second,for a class of modal theories of some restricted syntax, it is a precise counterpart to the semantics of expansions of theautoepistemic logic [40,38], an important nonmonotonic logic for modeling belief sets of an agent with perfect introspectioncapabilities.Given the applications of the Faber–Leone–Pfeifer stable-model semantics as an alternative to the standard Gelfond–Lifschitz one, and the role of the supported-model semantics in answer-set programming and nonmonotonic logics, ourobjective here is to investigate these semantics and show that they also can be studied by the means stemming from thosedeveloped by Pearce and Ferraris for the stable-model semantics. Specifically, we have the following goals:(1) To extend the semantics of Faber et al. [16] to the language of propositional logic. We do so in two equivalent ways: bymeans of a generalization of the reduct introduced by Faber et al., as well as in terms of a certain satisfiability relationsimilar to the one that defines the logic HT. We show that the FLP semantics generalizes several properties of the stable-model semantics of logic programs and so, it can be regarded as its legitimate extension, alongside with the extensionbased on the logic HT. We derive several additional properties of the FLP semantics, including a characterization ofstrong equivalence under that semantics, and a normal-form result.(2) To relate the FLP and stable-model semantics of propositional theories. We show that each can be expressed in eachother in the sense that there are modular translations that do not use any auxiliary atoms and such that FLP-stablemodels of a theory are stable models of its image under the translation (and vice versa).(3) To apply a similar two-pronged approach, exploiting both some notion of reduct and some satisfiability relation, to thesupported model semantics. We show that also supported models can be defined for arbitrary propositional theories. Wegeneralize to propositional language some well-known properties of supported models, as well as the results connectingstable and supported models of programs.While most implemented answer-set programming systems [10] used in applications support only theories consistingof rules (we formally define rules in the next section), a generalization of answer-set programming to the full language ofpropositional logic is important. From the theoretical standpoint, it eliminates possible artifacts of syntactic restrictions andallows us to identify key principles behind the semantics of answer-set programming. In particular, considering answer setprogramming in the full language pinpoints the basic role of implication as a",
            {
                "entities": [
                    [
                        3927,
                        3955,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1153–1179Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecision making with multiple objectives using GAI networksC. Gonzales, P. Perny∗, J.Ph. DubusLIP6 – Université Pierre et Marie Curie, case 169, 4 place jussieu, 75005 Paris, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 28 February 2009Received in revised form 20 July 2010Accepted 15 September 2010Available online 2 December 2010Keywords:Graphical modelsGAI decomposable utilityPreference representationMultiobjective optimizationMultiagent decision makingCompromise searchFairness1. IntroductionThis paper deals with preference representation on combinatorial domains and preference-based recommendation in the context of multicriteria or multiagent decision making. Thealternatives of the decision problem are seen as elements of a product set of attributesand preferences over solutions are represented by generalized additive decomposable (GAI)utility functions modeling individual preferences or criteria. Thanks to decomposability,utility vectors attached to solutions can be compiled into a graphical structure closelyrelated to junction trees, the so-called GAI network. Using this structure, we presentpreference-based search algorithms for multicriteria or multiagent decision making.Although such models are often non-decomposable over attributes, we actually showthat GAI networks are still useful to determine the most preferred alternatives providedpreferences are compatible with Pareto dominance. We first present two algorithms for thedetermination of Pareto-optimal elements. Then the second of these algorithms is adaptedso as to directly focus on the preferred solutions. We also provide results of numerical testsshowing the practical efficiency of our procedures in various contexts such as compromisesearch and fair optimization in multicriteria or multiagent problems.© 2010 Elsevier B.V. All rights reserved.The complexity of decision problems in organizations, the importance of the issues raised and the increasing need toexplain or justify any decision has led decision makers to seek a scientific support in the preparation of their decisions. Formany years, rational decision making was understood as solving a single-objective optimization problem, the optimal deci-sion being implicitly defined as a feasible solution minimizing a cost function under some technical constraints. However,the practice of decision making in organizations has shown the limits of such formulations. First, there is some diversityand subjectivity in human preferences that requires distinguishing between the objective description of the alternatives of achoice problem and their value as perceived by individuals. In decision theory, alternatives are often seen as multiattributeitems characterized by a tuple in a product set of attributes domains, the preferences of each individual being encoded by autility function defined on the multiattribute space measuring the relative attractiveness of each tuple. Hence the objectivesof individuals take the form of multiattribute utility functions to be maximized. Typically, in a multiagent decision problem,we have to deal with several such utility functions that must be optimized simultaneously. Since individual utilities are gen-erally not commensurate, constructing an overall utility function gathering all relevant aspects is not always possible. Hencethe problem does not reduce to a classical single-objective optimization task; we have to solve a multiobjective problem.Moreover, even when there is a single decision maker, several points of views may be considered in the preferenceanalysis, leading to the definition of several criteria. Rationality in decision making is generally not only a matter of costsreduction. In practice, other significant aspects that are not reducible to costs must be included in the analysis; the outcomes* Corresponding author.E-mail addresses: kaveh@river-valley.com (C. Gonzales), patrice.perny@lip6.fr (P. Perny), cvr@river-valley.com (J.Ph. Dubus).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.020\f1154C. Gonzales et al. / Artificial Intelligence 175 (2011) 1153–1179of alternatives must be thought in a multidimensional space. This is the case in the elaboration of public policies wheredifferent aspects such as ecology and environment, education, health, security, public acceptability are considered in theevaluation process. This is also the case for individual decision of consumers. For example, when choosing a new car for afamily, an individual will look at the cost, but will also consider several multiattribute utility functions concerning security inthe car (brake system, airbags, . . . ), velocity (speed, acceleration, . . . ), space (boot size, . . . ), environmental aspects (pollution)and aesthetics (color, shape, brand, . . . ). All these observations have motivated the emergence of multicriteria methodologiesfor preference modeling and human decision support [1–4], an entire stream of research that steadily developed for fortyyears.As for human decision making, automated decision making in complex environment requires optimization proceduresinvolving multiple objectives. This is the case when computers are used for planning actions of autonomous agents or for or-ganizing the workflow in production chains. Various other examples can be mentioned such as web search [5], e-commerceand resource allocation problems. In many of them, however, a decision is actually characterized by a combination of lo-cal decisions, thus providing the set of alternatives with a combinatorial structure. This explains the growing interest formultiobjective combinatorial optimization. Besides the explicit introduction of several possibly conflicting objectives in theevaluation process, the necessity of exploring large size solution spaces is an additional source of complexity. This hasmotivated the development in the AI community of preference representation languages aiming at simplifying preferencehandling and decision making on combinatorial domains.As far as utility functions are concerned, the works on compact representation aim at exploiting preference independenceamong some attributes so as to decompose the utility of a tuple into a sum of smaller utility factors. Different decompositionmodels of utilities have been developed to model preferences. The most widely used assumes a special kind of independenceamong attributes called “mutual preferential independence”. It ensures that preferences are representable by an additivelydecomposable utility [6,7]. Such decomposability makes both the elicitation process and the query optimizations very fastand simple. However, in practice, preferential independence may fail to hold as it rules out any interaction among attributes.Generalizations have thus been proposed in the literature to significantly increase the descriptive power of additive utilities.Among them, multilinear utilities [2] and GAI (generalized additive independence) decompositions [8,9] allow quite generalinteractions between attributes [7] while preserving some decomposability. The latter has been used to endow CP nets withutilities (UCP nets) both under uncertainty [10] and under certainty [11]. GAI decomposable utilities can be compiled intographical structures closely related to junction trees, the so-called GAI networks. They can be exploited to perform classicaloptimization tasks (e.g. find a tuple with maximal utility) using a simple collect/distribute scheme essentially similar tothat used in the Bayes net community or to variable elimination algorithms in CSP [12–15]. In order to extend the useof GAI nets to multiobjective optimization tasks, we investigate the potential of GAI models for representing and solvingmultiobjective optimization problems.As soon as multiple criteria or utility functions are considered in the evaluation of a solution, the notion of optimality isnot straightforward. Among the various optimality criteria, the concept of Pareto optimality or efficiency is the most widelyused. A solution is said to be Pareto-optimal or efficient if it cannot be improved on one criterion without being depreciatedon another one. Pareto optimality is natural because it does not require any information about the relative importance ofcriteria and can be used as a preliminary filter to circumscribe the set of reasonable solutions in multiobjective problems.However, in combinatorial optimization problems, the complete enumeration of Pareto-optimal solutions is often infeasiblein practice [16–18]. For this reason, in many real applications, people facing such complexity resort to artificial simplifica-tions of the problem, either by focusing on the most important criterion (as in route planning assistants), or by performinga prior linear aggregation of the criteria to get a single objective version of the problem, or by generating samples of goodsolutions using heuristics, which in any case does not provide formal guarantees on the quality of the solutions.In this paper, we assume that each objective is represented by a GAI decomposable utility function defined on themultiattribute space describing items. In Section 2, after recalling basic definitions related to GAI nets, we show how theymake it possible to represent vector-valued utility functions in a compact form, thus facilitating preference handling inmultiobjective decision-making problems. In Section 3, we present two exact algorithms exploiting the structure of theGAI net for the determination of Pareto-optimal elements. In Section 4 we propose a refinement of the second algorithmaiming at focusing the search on specific compromise solutions within the Pareto set. We provide exact algorithms forpreference-based search with various preference models. The potential of this approach is illustrated in the",
            {
                "entities": [
                    [
                        4193,
                        4221,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1183–1186www.elsevier.com/locate/artintLevel-headedDrew McDermottYale University, USAAvailable online 10 October 2007AbstractI don’t believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more aboutthinking and computation, the mileposts will keep changing in ways that we can’t predict, as will the esteem we assign to pastaccomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusingon such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understandhardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus,when we can talk to machines, will we understand each other?© 2007 Published by Elsevier B.V.Keywords: Speculation; Methodology; Natural languageThe question when and how we will attain human-level artificial intelligence is hard to answer because it is soill-posed. It’s like asking a biologist in 1820 how and when Frankenstein’s monster would become a reality, replacingFrankenstein with Turing.1 The history of biology is the history of attacking and solving small technical problemsone after another, with many blind alleys. At the end, the goal of knitting parts of dead people together to make a newperson just doesn’t seem as attractive as it once did.There’s no reason to suppose AI will be any different. Although some old-timers decry our loss of the vision thefield exhibited 50 years ago, this sort of loss is exactly what we would hope for. By contrast, phrenology never turnedinto a real science, and was cranking out the same kind of broadly scoped, superficial, and unverifiable observationsat the end as it had at its start.2The phrase “human-level” subtly presupposes that we are measuring skills along one dimension. Humans standat one altitude, far above fungi and cats, and we are pushing machines up the hill as though moving pianos. Butintelligence is the ability to imagine. There are as many different kinds of intelligence as there are kinds of imagination.A computer solving a complex resource-allocation task already surpasses humans in the ability to imagine ways toallocate the resources. Computer programs will eventually have many such skills, but there will never be a time wheretheir total “equals” those of the average human.I consider it likely that as we solve one technical problem after another—and waste time on several promisingideas that go nowhere—we will eventually get a picture of how computation and thought fit together that we simplycan’t envisage. When I say “we,” I don’t mean the AI community by itself, but the entire cognitive-science commu-E-mail address: drew.mcdermott@yale.edu.1 Turing was his own Mary Shelley.2 Just spend some time with a few issues of the American Phrenological Journal, published from 1838 to 1911.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.10.013\f1184D. McDermott / Artificial Intelligence 171 (2007) 1183–1186nity, defined as all disciplines based on the working hypothesis that the important processes going on in brains arecomputational. AI gets its ideas from computer science, psychology, linguistics, neuroscience, and occasionally evenphilosophy. It gives back algorithms and empirical evidence that they work (mathematical proofs of competence beingrare in this business).It seems to me that arguments such as Kurzweil’s [1] that exponential growth in computer science is bound toproduce superhuman intelligence, and breath-takingly fast as we near that apotheosis, are flawed by the fact that wedon’t know what we’re measuring. Grant that you can fit an exponential curve to scientific output to date in anydiscipline; will it be the same curve from century to century? Whenever there is a scientific revolution, much of whatpassed for important advances suddenly becomes distracting filler. One now sees the history of that field in terms of anobscure but luminous path leading up to the new insight, which now precedes the so-called “knee” of the exponentialthat we thought we had already seen.3 This is not a rare phenomenon. In our own lifetime4 we have seen a dramaticchange in our understanding of learning. In 1950 it seemed that behaviorism was on the verge of explaining the entirehuman psyche in terms of some simple learning mechanisms. Time magazine even adopted the title “Behavior” for itssection on human psychology. A graph of the progress of learning theory measured by papers published and number ofrats explained would have shown exponential growth. Now we use learning algorithms to sift through huge masses ofdata, but they work within sharp limits set by computational learning theory. In retrospect, behaviorism didn’t even askthe right questions, including most notably: How do the rats compute the relevant properties of the current situation?A revised graph of progress in the field would sharply discount all those rat runners and display quiet exponentialgrowth leading from mathematical logic and empirical linguistics through Chomsky, Valiant, and their successors intoa profusion of applications.When people demand human-level intelligence, they often think in terms of an example such as this one:In my office I have a device for showing the day of the month. It consists of two little wooden cubes, each of whichhas a digit inscribed on each face. So there are a total of 12 faces, 6 per cube. To display today’s date, you select onecube and face for the tens digit and one for the ones digit. The same cube need not always occupy the same position;sometimes one is in the tens position, sometimes the other. Single-digit days are displayed as 0d. (The month is shownon a separate set of wooden pieces, which need not concern us.)I would be very impressed if a computer could prove that such a date-display system was impossible, by thefollowing argument: We’re going to need a 0, 1, and 2 on each cube. That’s because not all the digits from 1 to 9 willfit on one cube, and 0, 1, and 2 must appear in the tens position opposite each of them. So 0, 1, and 2 must occupy6 faces. But that leaves just 6 faces for the 7 digits above 2. “QED”In spite of this proof, I really do have such a date-display system in my office. So there must be a trick. At thispoint a person might start trying to physically construct the cube, by laying out face arrangements on paper that couldbe folded into a cube. Actually, a person would almost certainly start trying to construct the cube before going off toprove that it was impossible. The lemma that there must be two each of the digits 0, 1, and 2 would be arrived in theprocess of trying to do the construction, and the constructor would quickly realize that this posed a serious problem.Presumably, during the construction process the constructor would realize that how the sides folded up was irrel-evant. Any assignment of digits to a cube would be as good as any other, so long as there’s a 0, 1, and 2 on eachcube. On the other hand, they might keep in the mind that they’re operating in a weird zone where they “know” theenterprise is doomed, so they might reserve the right to go back and consider the physical arrangement later.In the process of writing the digits down, the person might somehow realize (don’t ask me how) that a 6 and a9 look very similar, and then realize that we can use one cube face for both, provided we pick a font in which turningthe 6 over makes it into a presentable 9. So the seven digits will fit on six faces! After that insight, it will become clearthat any assignment of the digits 3–8 to the two cubes will work.What would it take for a computer to solve this problem? One might argue that the computer would have to beembodied as a robot so that it could write the digits out and see the similarity between 6 and 9. I really don’t see whythe process wouldn’t work just as well in the mind’s eye. The important ability the machine must have is to makesimplifying assumptions away from the full physical reality of characters stamped on wood, and yet to make goodguesses about which of those assumptions to revoke when trouble arises. Two such simplifications are to think of the3 Why “knee”? It looks more like an elbow to me. Anyway, it’s an optical illusion, of course; draw the curve at a different scale and the knee willappear wherever you want it to.4 “Our” here refers to us old-timers.\fD. McDermott / Artificial Intelligence 171 (2007) 1183–11861185digits as arbitrary tokens whose only property is to represent a number between 0 and 9, and to assume that one canneglect the orientation of the visible face of a cube. What strikes one as “intelligent” about the ability to solve thisproblem is the choice of what assumption to question; it wouldn’t help to think about the position of the digits on eachface, or the possibility of using different colors for different digits, or whether the cubes could be made of cedar orpine.I did not solve the calendar problem myself; my wife5 got the little wooden gadget at an office-party gift exchange,and we don’t know who created it. Obviously, at least one person figured out how to make it, but who knows whatpercentage of the human population could? My guess is very few.6People are seldom just presented with problems like this one in cold, precise paragraphs. Instead, they must engagein conversations about them, just to get clear on what the problem is. Even if they ask no other questions, after theireureka moment they would surely ask/shout, “Is it okay to use one face to represent both the 6 and the 9?!” I willreturn to this key point below.We might suppose that we have not reached human-level intelligence until we have a program that can solve thispuzzle, and the “mutilated checkerboard” [2], and some other brain teasers. But why stop there? We could perhapsalso demand that it compo",
            {
                "entities": [
                    [
                        3044,
                        3072,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1254–1276Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPractical performance models of algorithms in evolutionary programinduction and other domainsMario Graff∗, Riccardo PoliSchool of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 22 October 2008Received in revised form 18 July 2010Accepted 19 July 2010Available online 23 July 2010Keywords:Evolution algorithmsProgram inductionPerformance predictionAlgorithm taxonomiesAlgorithm selection problemEvolutionary computation techniques have seen a considerable popularity as problemsolving and optimisation tools in recent years. Theoreticians have developed a varietyof both exact and approximate models for evolutionary program induction algorithms.However, these models are often criticised for being only applicable to simplistic problemsor algorithms with unrealistic parameters. In this paper, we start rectifying this situation inrelation to what matters the most to practitioners and users of program induction systems:performance. That is, we introduce a simple and practical model for the performance ofprogram-induction algorithms. To test our approach, we consider two important classes ofproblems — symbolic regression and Boolean function induction — and we model differentversions of genetic programming, gene expression programming and stochastic iterated hillclimbing in program space. We illustrate the generality of our technique by also accuratelymodelling the performance of a training algorithm for artificial neural networks and twoheuristics for the off-line bin packing problem.We show that our models, besides performing accurate predictions, can help in the analysisand comparison of different algorithms and/or algorithms with different parameterssetting. We illustrate this via the automatic construction of a taxonomy for the stochasticprogram-induction algorithms considered in this study. The taxonomy reveals importantfeatures of these algorithms from the performance point of view, which are not detectedby ordinary experimentation.© 2010 Elsevier B.V. All rights reserved.1. IntroductionEvolutionary Algorithms (EAs) are popular forms of search and optimisation [1–6]. Their invention dates back manydecades (e.g., see [7]). So, one might imagine that, by now, we should have a full theoretical understanding of their opera-tions and a rich set of theoretically-sound guidelines for their parametrisation and customisation. However, this is not thecase.Despite the simplicity of EAs, sound theoretical models of EAs and precise mathematical results have been scarce andhard to obtain, often emerging many years after the proposal of the original algorithm (e.g., see [8–18]). A key reason for thisis that each algorithm, representation, set of genetic operators and, often, fitness function requires a different theoreticalmodel. In addition, the randomness, non-linearities and immense number of degrees of freedom present in a typical EAmake life very hard for theoreticians.This applies also to techniques for the automatic evolution of computer programs, or Evolutionary Program-inductionAlgorithms (EPAs), including Genetic Programming (GP) [6,15,19], Cartesian GP (CGP) [20], Grammatical Evolution (GE)* Corresponding author.E-mail addresses: mgraff@essex.ac.uk (M. Graff), rpoli@essex.ac.uk (R. Poli).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.07.005\fM. Graff, R. Poli / Artificial Intelligence 174 (2010) 1254–12761255[21] and Gene Expression Programming (GEP) [22] among others. Our theoretical understanding of EPAs has been evenslower to develop than for other EAs chiefly because of the objective difficulty of modelling stochastic searchers in infinitespaces (programs have unbounded size) where search operators can dynamically change the dimension and structure of thesolutions being explored, as it is the case for most EPAs. So, despite recent successes in developing solid theory for GP andrelated EPAs (e.g., see [15,17,23] and the review in [19]), there is a growing gap between EPA theory and practice.Often theoretical studies and models of EAs are criticised for not being easily applicable to realistic situations (e.g., see[24]). One reason for this is that producing a comprehensive theory for complex adaptive systems such as EAs is objectivelyhard and slow, as we mentioned earlier. Another reason is that, sometimes, theoreticians focus on approaches and problemsthat are too distant from practice. So, despite the proven effectiveness of EAs and EPAs (see for example [19]), there is anurgent need for a theory that can clarify the applicability of different types of algorithms to particular problems, providedesign guidelines and, thereby, avoid the current, very time-consuming, practice of hand-tuning algorithms, parameters andoperators.This paper attempts to rectify this situation by proposing a practical model of EPAs. The model, by design, does notcapture all the characteristics of an algorithm nor models it exactly (which is extremely difficult). Instead, it focuses onwhat matters the most to practitioners, the performance of EAs in realistic problems, accepting the fact that, in practice,modelling performance cannot be done exactly. This model will allow us to give answers to questions such as: How likely isit that a particular algorithm will solve a particular problem of interest? What fitness should we expect to find at the end ofa run? What’s the best algorithm to solve a problem or a class of problems? Since no alternative model of EPA performanceis available at present, the only alternative is to seek answers to these questions by direct empirical experimentation!Although our approach was initially aimed at modelling EPAs, it can easily be extended beyond program induction bystochastic search to capture the characteristics of other forms of search and problem solving. To illustrate this we will alsomodel the performance of two heuristics for the off-line bin packing problem and one learning algorithm for feed-forwardneural networks.Our models are related to techniques used to solve the algorithm selection problem [25] (i.e., the problem of decidingwhich tool to choose to solve a problem out of a set of available tools) and, in particular, to the modelling techniques usedin algorithm portfolios [26–35] (i.e., collections of algorithms that are run in parallel or in sequence to solve a problem).The methodology presented here is complementary to (but competitive with) such approaches, as we will illustrate throughin the creation of effective portfolios of program induction algorithms: an area where no algorithm selection technique hadbeen tested before.Our models can also be used beyond the pure prediction of performance. For example, they enable the analysis of thesimilarities and differences between algorithms in relation to performance. To illustrate this, from a collection of models ofdifferent algorithms (or the same algorithms but with different parameters) we will obtain a meaningful and informativetaxonomy of evolutionary and stochastic program-induction algorithms, with a completely automatic process.The paper is organised as follows. In Section 2 we review related theoretical work in the field of EAs. In Section 3 wedescribe our performance model, how we arrived at it and the methodology used to instantiate it. Section 4 presents theproblems used to test the approach, while Section 5 describes the systems and parameter settings used in the experimen-tation. Experimental results that corroborate the validity of the models’ predictions are presented in Section 6. Section 7looks at the algorithm selection problem surveying relevant literature and applying our models to the creation of two algo-rithm portfolios for program-induction problems. The similarities and differences with other approaches are also discussed.Applications of our models in the comparison and categorisation of algorithms are discussed in Section 8. Some conclusionsand possible directions for future work are given in Section 9.2. Related workOur work is related to the problem of understanding what makes a problem easy or hard for EAs. Problem-difficultystudies in EAs focused initially on the building-block hypothesis for Genetic Algorithms (GAs) [2] and the related notion ofdeception [36]. The approach consisted in constructing artificial fitness functions that, based on certain a priori assumptions,would be easy or hard for GAs. This produced useful results but also some puzzling counter examples [37].The notion of fitness landscape, originally proposed in [38], underlies many recent approaches to problem difficulty. It isclear, for example, that a smooth landscape with a single optimum will be relatively easy to search for many algorithms,while a very rugged landscape, with many local optima, may be more problematic [39,40]. However, the graphical visuali-sation of fitness landscapes is rarely possible given the size of typical search spaces. So, one really needs to condense usefulinformation on fitness landscapes into one or a few numeric descriptors.In [41], Jones introduced one such descriptor of problem difficulty for GAs: the fitness distance correlation (fdc). The studyof fdc has been extended to GP [42–45]. These studies show that fdc is often a reliable indicator of problem hardness.However, it has one big flaw: it requires the optimal solution(s) to be known beforehand. This prevents the use of fdcto estimate problem difficulty in practical applications. A measure that does not suffer from this problem, the negativeslope coefficient (nsc), has recently been proposed [46]. This is based in the concept of fitness cloud (a scatter plot ofparent/offspring fitness pairs). The nsc uses the idea of first dividing the cloud into a certain number of bins alon",
            {
                "entities": [
                    [
                        3553,
                        3581,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 191–192 (2012) 1–19Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintApplicability conditions for plans with loops: Computability resultsand algorithmsSiddharth Srivastava∗, Neil Immerman, Shlomo ZilbersteinDepartment of Computer Science, University of Massachusetts, Amherst, MA 01003, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 15 November 2010Received in revised form 18 July 2012Accepted 20 July 2012Available online 25 July 2012Keywords:Automated planningPlans with loopsPlan verificationReachability in abacus programsGeneralized planning1. IntroductionThe utility ofincluding loops in plans has been long recognized by the planningcommunity. Loops in a plan help increase both its applicability and the compactness ofits representation. However, progress in finding such plans has been limited largely dueto lack of methods for reasoning about the correctness and safety properties of loopsof actions. We present novel algorithms for determining the applicability and progressmade by a general class of loops of actions. These methods can be used for directing thesearch for plans with loops towards greater applicability while guaranteeing termination,as well as in post-processing of computed plans to precisely characterize their applicability.Experimental results demonstrate the efficiency of these algorithms. We also discuss thefactors which can make the problem of determining applicability conditions for plans withloops incomputable.© 2012 Elsevier B.V. All rights reserved.The problem of planning in AI is to compute a plan, or a procedure which can be executed by an agent to achieve acertain goal. This paper presents methods which can be used for the computation of compact plans that resemble computerprograms with branches and loops.In the classical formulation of AI planning, the agent’s state is assumed to be completely observable, and effects ofactions are assumed to be determined entirely by this state. Classical plans consist of linear sequences of actions whichlead to a goal state from a particular initial state. Even in this restricted, deterministic formulation, the planning problemis PSPACE-complete [2] when the input is specified in the STRIPS framework [8]. More general formulations which allowthe agent to possess only partial information about its current state, and its actions to be non-deterministic make theproblem significantly harder [18]. Consequently, numerous approaches have been proposed for reusing sequences of actionscomputed for related problems [7,10] and for computing generalized plans which can be used to solve large classes ofplanning problems [19,14,26,24].Approaches for generalized planning build extensively upon the power of including loops of actions for representingcyclic flows of control in plans. Not only are such constructs necessary when the input problem instances can be un-bounded in size, but they also allow significant reductions in plan sizes for larger problems—particularly when contingentsolutions are required in order to deal with partial observability [1,23]. Plans with loops therefore present two very appeal-ing advantages: they can be more compact, and thus easier to synthesize, and they often solve many problem instances,offering greater generality.* Corresponding author.E-mail addresses: siddharth@cs.umass.edu (S. Srivastava), immerman@cs.umass.edu (N. Immerman), shlomo@cs.umass.edu (S. Zilberstein).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.005\f2S. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–19Loops in plans, however, are inherently unsafe structures because it is hard (and even impossible, in general) to de-termine the general conditions under which they will terminate and achieve their intended goals. It is therefore crucial todetermine when a plan with loops will be able to solve a given problem instance. Unfortunately, there is currently very littleunderstanding of when the applicability conditions of plans with loops can even be computed, and if so, whether this canbe done efficiently. This limitation significantly impacts the development and usability of approaches for finding generalizedplans.In this paper, we present methods for computing the conditions under which a plan with a particular class of loops willterminate at a desired state. Our approach elaborates and builds upon the ideas presented in [22]. We further develop theseideas to identify more clearly the factors that make the problem of determining termination of plans with loops difficult.We also present new results for determining termination for a broader class of plans with loops and illustrate how ourmethods can be applied.We first formulate the notion of plans with loops using the concept of generalized planning problems introduced in priorwork [21,24]. Solutions to such problems are expressed as generalized plans. Generalized plans are rich control structuresthat include loops and parameterized or “lifted” actions whose arguments must be instantiated during execution. Thesenotions are described in Section 2.In spite of their expressiveness, a broad class of generalized plans can be easily translated into abacus programs—formalmodels of computation that use primitive actions, but are as powerful as Turing machines. Abacus programs have finitesets of non-negative registers, and actions that may increment or conditionally decrement these registers (Section 2.4).Abacus programs have been shown to have a close relationship with numerical planning problems. Helmert [11] showedthat abacus programs can be reduced to a class of planning domains over numerical variables where the goal conditions donot use numerical variables, but action preconditions include comparisons of these variables with zero and action effectsincrement or decrement these variables. This leads to a negative result that the plan existence problem is undecidable forsuch planning domains due to the undecidability of the halting problem for abacus programs. In this work however, wepresent some positive results capturing classes of abacus programs for which the halting problem is decidable.Our approach for computing applicability conditions for plans with loops is to first develop methods for computing theconditions under which a given abacus program will reach a desired state. This is referred to as the reachability problem ofabacus programs. Undecidability of the halting problem in abacus programs implies that the reachability problem for abacusprograms is also undecidable in general. However, we show that certain classes of abacus programs, categorized in terms ofthe graphical structure used to represent their control flow, do have solvable reachability problems. We develop methodsfor addressing the reachability problem of abacus programs in these classes.These methods can be used to compute applicability conditions for a broad class of generalized plans by translatingthem into abacus programs. Furthermore, the fact that this translation preserves the structure of the control flow makesthese methods applicable also in synthesis of “tractable” generalized plans: during synthesis, we can choose to permit onlythose control structures in generalized plans that would allow the computation of reachability conditions upon translationto abacus programs. Prior work describes one possible instantiation of this process in greater detail [25]. The fundamentalnature of abacus programs also makes our methods more generally applicable to plans with loops that may not be expressedas generalized plans in our representation, but which have suitable translations into abacus programs.The following section develops the formal framework for the rest of the paper and describes the connection betweengeneralized plans and abacus programs. We develop methods for solving the reachability problem for abacus programswhose control flow only uses simple loops in Section 3. We then introduce a class of nested loops in Section 4 and developmethods for addressing the reachability problem for deterministic and non-deterministic abacus programs with this class ofnested loops in Section 5. Finally, we conclude with a demonstration of the scope and efficiency of these methods.2. Formal foundationsIn this work we consider loops of actions whose every iteration, during any execution of the plan, will make measurableprogress towards a goal. We call such necessarily terminating loops, progressive. For example, in the blocks-world, a loopof actions which in every iteration unstacks a block that is clear but not on the table, makes incremental progress towardsthe goal of having all blocks on the table. In contrast, a loop could also be used with actions that need to be repeated untilthey succeed. For example, in order to pick up a block using a slippery gripper, we need a loop that executes the pickupaction until it succeeds. Plans with such loops are considered in strong cyclic planning [3] but are not the focus of thispaper. Our motivation for considering only progressive loops is to facilitate the computation of plans with strong guaranteesof termination and correctness in situations where the number of objects to be manipulated is unknown.To clarify these notions, we begin the formal description of our approach with a brief summary of a recently proposedframework for generalized planning in which progressive loops turn out to be very useful. This is followed by a descrip-tion of our representation for generalized plans (Section 2.2). The latter half of this section presents the formal definitionof abacus programs (Section 2.4) and some conditions under which we can view generalized plans as abacus programs(Section 2.3).\fS. Srivastava et al. / Artificial Intelligence 191–192 (2012) 1–1932.1. Generalized planning problemsFig. 1. A generalized plan for transporting objects from L1 t",
            {
                "entities": [
                    [
                        3600,
                        3628,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 472–506www.elsevier.com/locate/artintExperiment selection for the discrimination of semi-quantitativemodels of dynamical systemsIvayla Vatcheva a, Hidde de Jong b,∗, Olivier Bernard c, Nicolaas J.I. Mars da German Cancer Research Center (DKFZ), Im Neuenheimer Feld 280, 69120 Heidelberg, Germanyb Institut National de Recherche en Informatique et en Automatique (INRIA), Unité de recherche Rhône-Alpes, 655 avenue de l’Europe,Montbonnot, 38334 Saint Ismier Cedex, Francec Institut National de Recherche en Informatique et en Automatique (INRIA), Unité de recherche Sophia Antipolis, 2004 route des Lucioles,BP 93, 06902 Sophia Antipolis, Franced Materials Science Centre, Department of Mathematics and Natural Sciences, Rijksuniversiteit Groningen, Nijenborgh 4,9747 AG Groningen, the NetherlandsReceived 19 September 2005; received in revised form 13 November 2005; accepted 13 November 2005Available online 9 December 2005AbstractModeling an experimental system often results in a number of alternative models that are all justified by the available ex-perimental data. To discriminate among these models, additional experiments are needed. Existing methods for the selection ofdiscriminatory experiments in statistics and in artificial intelligence are often based on an entropy criterion, the so-called infor-mation increment. A limitation of these methods is that they are not well-adapted to discriminating models of dynamical systemsunder conditions of limited measurability. Moreover, there are no generic procedures for computing the information increment ofan experiment when the models are qualitative or semi-quantitative. This has motivated the development of a method for the selec-tion of experiments to discriminate among semi-quantitative models of dynamical systems. The method has been implemented ontop of existing implementations of the qualitative and semi-quantitative simulation techniques QSIM, Q2, and Q3. The applicabil-ity of the method to real-world problems is illustrated by means of an example in population biology: the discrimination of fourcompeting models of the growth of phytoplankton in a bioreactor. The models have traditionally been considered equivalent forall practical purposes. Using our model discrimination approach and experimental data we show, however, that two of them aresuperior for describing phytoplankton growth under a wide range of experimental conditions. 2005 Elsevier B.V. All rights reserved.Keywords: Qualitative and semi-quantitative modeling and simulation; Model discrimination; Information theory; Population biology;Computer-supported modeling* Corresponding author.E-mail addresses: I.Vacheva@dkfz-heidelberg.de (I. Vatcheva), Hidde.de-Jong@inrialpes.fr (H. de Jong), Olivier.Bernard@sophia.inria.fr(O. Bernard), N.J.I.Mars@fwn.rug.nl (N.J.I. Mars).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.11.001\fI. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–5064731. IntroductionFinding an adequate model of the functioning of a complex system—either natural or man-made—is a problemconfronting practitioners in many different domains. For instance, it arises when a population biologist studies anecosystem, an electrical engineer diagnoses a fault in an electronic circuit, or a medical doctor tries to infer the causesof the illness of a patient. Given the pre-eminence of modeling in human endeavor, it comes as no surprise thatmethods for computer-supported modeling have been subject to active research in artificial intelligence. For instance,machine learning techniques infer a model from observations of the system behavior [47], while automated modelingtechniques in qualitative reasoning are able to derive a model from a description of the system, a user question, and adomain theory [40,51,63].The complexity of the task of modeling is such that in many cases the available information does not allow oneto decide between alternative models of the system under study. In the above examples, several interactions betweenspecies in an ecosystem can be imagined, the fault in the electronic circuit may be due to the failure of differentcomponents, and the symptoms of the patient might have a variety of causes. The different assumptions on the structureand behavior of the system may result in a number of competing models, all justifiable by the available observations.The existence of this set of competing models gives rise to the problem of model discrimination.To discriminate between a number of competing models, and identify which of them most adequately describesthe actual situation, new observations are needed. These can be obtained by performing additional experiments onthe system. An experiment discriminates among the models, if the predictions of some of the models fit the newly-obtained data, whereas the predictions of others do not. Since in real-life applications a large number of experimentscan be performed, and the cost of each of them may be considerable, it is important that the experiments be selectedcarefully. In fact, it is desirable that experiments be selected in such a way that the set of competing models ismaximally reduced (systematic model discrimination) at minimal costs (efficient model discrimination). Notice thatthe efficiency requirement does not necessarily amount to minimizing the number of experiments, since several cheapexperiments may cost less than a single expensive experiment.The problem of model discrimination has received substantial attention in the statistical literature (see [28,29]for reviews). This has resulted in criteria for determining the experiment that optimally discriminates among differentmodels of the system. These criteria, based on concepts derived from information theory and optimization theory, havebeen applied to a variety of problems in biology and biotechnology (e.g., [15,37,55,57]), in physics (e.g., [16,45]),and in chemical engineering (e.g., [1,25]). Similar criteria have been developed in artificial intelligence, especially inthe field of model-based diagnosis (MBD) [31]. In this case, the criteria play a key role in reducing the number ofcandidate diagnoses generated, that is, the set of hypotheses accounting for the observed faulty behavior of a device.In order to discriminate among the candidate diagnoses, and thus find out what is actually wrong with the system,methods for selecting the optimal measurements or experimental conditions have been developed (e.g., [20,22,53]).All of the above methods share the same underlying intuition. To evaluate the discriminatory potential of an ex-periment, its outcome is predicted by each of the competing models. The experiment for which the model predictionsdiffer most will have the highest chance of discriminating among the models, and is therefore selected as the optimaldiscriminatory experiment. Often, this intuition is formalized by means of the optimal information increment, thatis, the maximal difference in entropy before and after the execution of an experiment. The expected value of thisinformation increment, for each of the available experiments, can be determined from the model predictions.A first problem with existing methods for model discrimination is that the information increment criteria beingused are not well-adapted to dynamical systems. The criteria take into account the possible states of the system, butnot their temporal ordering. It has been shown that under certain conditions, the temporal evolution of the state ofthe system is not necessary for model discrimination [53,54]. These conditions, however, are often not fulfilled inpractice. As a consequence, it becomes important to take into account the differences in temporal behavior.A second problem with existing methods is the difficulty of computing the expected value of the information incre-ment from the model predictions. This is especially true when qualitative or semi-quantitative models are used, likethose developed in the field of qualitative reasoning (QR) [26,56,62]. Qualitative models deal with incomplete or im-precise information by assigning symbolic values to its parameters and initial conditions [42]. In addition, qualitativemodels may contain incompletely specified functional relations between the variables, defined by their monotonicityproperties only. Qualitative models can be extended to semi-quantitative models by specifying numerical intervalsbounding parameter values as well as envelopes bounding monotonic functions [4,38]. The latter models are useful\f474I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506in many scientific and engineering domains, which often deal with parametric and functional tolerances described byintervals and bounding curves. However, existing methods for model discrimination either focus on numerical modelsor, if they allow qualitative or semi-quantitative models, do not provide a generic, domain-independent computationalframework for computing the expected information increment.The above limitations of methods for model discrimination in statistics and in model-based diagnosis have mo-tivated the work described in this paper. We present a method for the systematic and efficient discrimination ofsemi-quantitative models of dynamical systems [58,59]. The selection of the optimal discriminatory experiment isbased on an entropy criterion that exploits the model prediction for the temporal evolution of the system state. Inaddition, the method provides computational procedures to actually calculate the entropy criterion from the modelpredictions. Overall, model discrimination proceeds iteratively, similarly to a sequential diagnosis strategy [22,30].The algorithm starts with a set of competing models to which initial probabilities have been assigned. At every step,the experiment with the highest discriminatory potential is determined, this experiment is executed, and the experi-mental out",
            {
                "entities": [
                    [
                        2931,
                        2959,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 985–1010www.elsevier.com/locate/artintExploiting functional dependencies in declarative problemspecifications ✩Toni Mancini ∗, Marco CadoliDipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”,Via Salaria 113, I-00198 Roma, ItalyReceived 4 June 2006; received in revised form 15 March 2007; accepted 30 April 2007Available online 22 May 2007AbstractIn this paper we tackle the issue of the automatic recognition of functional dependencies among guessed predicates in constraintproblem specifications. Functional dependencies arise frequently in pure declarative specifications, because of the intermediateresults that need to be computed in order to express some of the constraints, or due to precise modeling choices, e.g., to providemultiple viewpoints of the search space in order to increase constraint propagation. In either way, the recognition of dependen-cies greatly helps solvers, allowing them to avoid spending search on unfruitful branches, while maintaining the highest degree ofdeclarativeness. By modeling constraint problem specifications as second-order formulae, we provide a characterization of func-tional dependencies in terms of semantic properties of first-order ones, and prove undecidability of the problem of their recognition.Despite such negative result, we advocate the (in many cases effective) possibility of using automated tools to mechanize this task.Additionally, we show how suitable search procedures can be automatically synthesized in order to exploit recognized dependen-cies. We present OPL examples of various problems, taken from bio-informatics, planning and resource allocation, and show howin many cases OPL greatly benefits from the addition of such search procedures. Moreover, we also give evidence that writingsophisticated ad-hoc search procedures that handle dependencies exploiting the peculiarities of the particular problem is a verydifficult and error-prone task which in many cases does not seem to pay-off.© 2007 Elsevier B.V. All rights reserved.Keywords: Modeling; Reformulation; Second-order logic; Constraint satisfaction problems1. IntroductionDeclarative programming, and more specifically constraint programming, is becoming very attractive to solvedifferent classes of problems, one of the main advantages of the approach being the fast prototyping and the highdeclarativeness exhibited by the problem models (also called “specifications”). Current systems for constraint solving(e.g., AMPL [19], OPL [43], DLV [31], SMODELS [36], and NP-SPEC [8]) allow the programmer to model her problem✩ This paper is an extended and revised version of [M. Cadoli, T. Mancini, Exploiting functional dependencies in declarative problemspecifications, in: Proceedings of the Ninth European Conference on Logics in Artificial Intelligence (JELIA 2004), Lecture Notes in ArtificialIntelligence, vol. 3229, Lisbon, Portugal, Springer, 2004, pp. 628–640].* Corresponding author.E-mail addresses: tmancini@dis.uniroma1.it (T. Mancini), cadoli@dis.uniroma1.it (M. Cadoli).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.017\f986T. Mancini, M. Cadoli / Artificial Intelligence 171 (2007) 985–10107 8 7 ∗7 9 7 =0 6 13 18 12 4 049 56 4963 72 63 −49 56 49 − −6 2 7 2 3 9c7c6z6c3c4c5x2y2x3y3x1 ∗y1 =c2c1x3y1 x2y1 x1y1x3y2 x2y2 x1y2 −x3y3 x2y3 x1y3 − −z1z3z4z5z2Fig. 1. Factoring instance 627239, n = 6, b = 10.in a highly declarative way, supporting a neat separation of the specification from its instances. Such possibility allowsthe programmer to focus on structural and combinatorial aspects of the problem at hand before committing to actualinput data, and hence permits problem modeling at a much higher level than that provided by the CSP framework.However, it is well-known that the problem model obtained in this way is often not efficient, and much reasoningis required in order to reformulate it to speed-up the solving process. To this end, different approaches have beenproposed in the literature, like symmetry detection and breaking (cf., e.g., [5,12]), the addition of implied constraints(cf., e.g., [41]), the deletion or abstraction of some of the constraints [3,16,20,23], and the use of redundant models,i.e., multiple viewpoints of the search space synchronized by channeling constraints, in order to increase constraintpropagation [11,18,25,44]. However, many of these approaches either are designed for a specific constraint problem,or act at the instance level, and very little work has been done at the level of problem specification. Indeed, manyof the properties of constraint problems amenable to optimizations strongly depend on the problem structure. Hence,their recognition naturally fits at the symbolic level of the specification, both from a methodological and an efficiencypoint of view.Our research explicitly focuses on specification-level reasoning, with the goal of reformulating the declarativeproblem model submitted by the programmer into an equivalent one, more efficiently evaluable by solvers. In partic-ular, in [6] we show how some of the constraints of a specification can be ignored in a first step, and then efficientlyreinforced (i.e., without performing additional search, the so-called “safe delay” constraints), and provide a sufficientsemantic criterion on the specification that can be used in order to recognize such constraints. Moreover, in [34] wetackle the issue of detecting structural (i.e., problem-dependent) symmetries, and breaking them by adding symmetry-breaking constraints to the problem specification.In this paper we focus on another interesting property of constraint problems that is expected to benefit fromreformulation, i.e., the functional dependencies that can hold among variables in declarative problem specifications.Informally, given a specification, a variable is said to be functional dependent on the others if, for every solution ofevery instance, its value is determined by those assigned to the others.Functional dependencies are very common in problem specifications for different reasons: as an example, to allowthe modeler to have multiple views of the search space, in order to be able to express the various constraints under themost convenient viewpoint, or to maintain aggregate or intermediate results needed by some of the constraints. Thefollowing two examples show the use of dependent variables under the two afore-mentioned circumstances.Example 1 (Factoring [30,40]). This problem is a simplified version of a well-known problem in public-key cryptog-raphy. Given a (large) positive integer Z, which is known to be the product of two different prime numbers (differentfrom 1), it aims at finding its factors X and Y .An intuitive formulation of factoring as a constraint problem, in order to deal with arbitrarily large numbers,amounts to encode the combinatorial circuit of integer multiplication. In particular, assuming the input integer Zhaving n digits (in base b) z1, . . . , zn, we consider 2n variables x1, . . . , xn and y1, . . . , yn one for each digit (in baseb) of the two factors, X and Y (with z1, x1, and y1 being the least significant digits for Z, X, and Y , respectively).The domain for all these variables is [0, b − 1]. In order to maintain information about the carries, n + 1 additionalvariables c1, . . . , cn+1 must be considered, with domain [0, (b − 1)2n/b].As for the constraints (cf. Fig. 1 for the intuition, where x4, x5, x6, y4, y5, y6 are equal to 0, and are omitted forreadability), they are the following:11 Since integer Z is assumed to be the product of two prime numbers, constraints ensuring that X and Y are prime are not needed.\fT. Mancini, M. Cadoli / Artificial Intelligence 171 (2007) 985–1010987Fig. 2. HP 2D-Protein folding problem: A possible conformation for protein “PHHPHPPHP” with two contacts, and overall energy −2.(1) Constraints on factors:(a) Factors must be different from 1, or, equivalently, X (cid:3)= Z and Y (cid:3)= Z;(b) For every digit i ∈ [1, n]: zi = (ci +j,k∈[1,n]: j +k=i+1 xj ∗ yk) mod b;(cid:2)(2) Constraints on carries:(a) Carry on the least significant digit is 0: c1 = 0;(b) Carries on other digits: ∀i ∈ [2, n + 1], ci = (ci−1 +(c) Carry on the most significant digit is 0: cn+1 = 0.(cid:2)j,k∈[1,n]: j +k=i xj ∗ yk)/b (integer division);It is worth noting that, when a guess on the two factors X and Y (i.e., on variables x1, . . . , xn and y1, . . . , yn) hasbeen made, values for variables c1, . . . , cn+1 are completely determined, since they follow from the semantics of themultiplication. We denote such situation saying that variables c1, . . . , cn+1 are functional dependent on x1, . . . , xn andy1, . . . , yn.Example 2 (HP 2D-Protein folding [29]). This specification models a simplified version of a well-known problemin computational biology. It consists in finding the spatial conformation of a protein (i.e., a sequence of amino-acids)with minimal energy. The simplifications with respect to the real problem are twofold: firstly, the 20-letter alphabet ofamino-acids is reduced to a two-letter alphabet, namely H and P. H represents hydrophobic amino-acids, whereas Prepresents polar or hydrophilic amino-acids. Secondly, the conformation of the protein is limited to a bi-dimensionaldiscrete space. Nonetheless, these limitations have been proven to be very useful for attacking the whole proteinconformation prediction problem. The simplified version is known to be NP-complete [13] and very hard to solve inpractice.Given the sequence of amino-acids of the protein, i.e., a string over {H, P} of length n, the problem aims to finda connected shape for it on a 2D grid (with coordinates in [−(n − 1), (n − 1)], starting at a pre-determined position,e.g., (0, 0)), which is non-crossing, and such that the number of “contacts”, i.e., the number of non-sequential pairsof H’s for which the Euclidean distance of the positions is 1 is maximized (the ove",
            {
                "entities": [
                    [
                        3152,
                        3180,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 437–465Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing the fault tolerance of multi-agent deployment ✩Yingqian Zhang a,∗, Efrat Manisterski b, Sarit Kraus b,c, V.S. Subrahmanian c, David Peleg da Faculty of Electrical Engineering, Mathematics, and Computer Science, Delft University of Technology, 2628 CD Delft, The Netherlandsb Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900 Israelc Department of Computer Science & UMIACS, University of Maryland, College Park, MD 20742, USAd Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 76100, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 11 June 2007Received in revised form 12 November 2008Accepted 14 November 2008Available online 25 November 2008Keywords:Multi-agent deploymentFault toleranceAlgorithmsReplicationA deployment of a multi-agent system on a network refers to the placement of oneor more copies of each agent on network hosts, in such a manner that the memoryconstraints of each node are satisfied. Finding the deployment that is most likely totolerate faults (i.e. have at least one copy of each agent functioning and in communicationwith other agents) is a challenge.In this paper, we address the problem of findingthe probability of survival of a deployment (i.e. the probability that a deployment willtolerate faults), under the assumption that node failures are independent. We show thatthe problem of computing the survival probability of a deployment is at least NP-hard.Moreover, it is hard to approximate. We produce two algorithms to accurately compute theprobability of survival of a deployment—these algorithms are expectedly exponential. Wealso produce five heuristic algorithms to estimate survival probabilities—these algorithmswork in acceptable time frames. We report on a detailed set of experiments to determinethe conditions under which some of these algorithms perform better than the others.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThere have been tremendous advances in the last decade in the theory and implementation of massive multi-agent sys-tems. However, one major obstacle to the wider deployment of multi-agent systems (MASs) is their capability of toleratingfailures. MASs that are deployed across a network can quickly “go down” due to external factors such as power failures,network outages, malicious attacks, and other system issues. Protection against such unexpected failures that disable a nodeis critical if agents are to be used as the backbone for real world applications.Clearly, ensuring that MASs are safe and protected involves a vast range of technologies that must authenticate users andagents, ensure secure communications, identify vulnerabilities, and identify and quarantine attacks. Our goal in this paperis far more modest, and concerns the way replication can form the basis of one tool (amongst many that are needed) toprevent a MAS from succumbing to failure. By replicating agents, we hope to improve the fault tolerance of a multi-agentsystem. The faults considered in this paper are those that cause disconnection (or crash) of the nodes in the network where✩This article is the extended version of the paper which appeared in the Second IEEE Symposium on Multi-Agent Security and Survivability [Y. Zhang,E. Manister, S. Kraus, V.S. Subrahmanian, Approximation results for probabilistic survivability, in: Second IEEE Symposium on Multi-Agent Security andSurvivability, Philadelphia, USA, 2005, pp. 1–10]. This research was supported in part by the Technology Foundation STW, applied science division of NWO,and the Ministry of Economic Affairs of the Netherlands, by grant N6133906C0149, in part by ARO grant DAAD190310202, AFOSR grants FA95500610405,FA95500510298, NSF grant 0540216, NSF grant 0705587, and ISF grant 1685/07.* Corresponding author.E-mail addresses: yingqian.zhang@tudelft.nl (Y. Zhang), manister@macs.biu.ac.il (E. Manisterski), sarit@macs.biu.ac.il (S. Kraus), vs@cs.umd.edu(V.S. Subrahmanian), david.peleg@weizmann.ac.il (D. Peleg).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.007\f438Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465the MAS application resides. The fault model that we consider is one where the failure of each node in the network isrepresented by a probability. Given such a fault model, agents that locate on the nodes have different probabilities to beunavailable, and therefore the multi-agent system as a whole has some probability of being out of function. The idea ofusing replication as a fault tolerance method in our work is thus that, when facing failures, at least one copy of each agentwill continue to reside on a connected, working host computer (node), so that the MAS as a whole can function as a unifiedapplication. Furthermore, in this paper, we focus on the problem of measuring the probability that a multi-agent system willtolerate the node failure. We call this probability the survivability1 of a MAS system.For example, consider the CoAX [2,35] Coalition Agent Experiment in which a large, multinational team2 of universities,companies and government labs pieced together an experimental multi-agent application in which a set of sensory agentsdeployed in an ocean tracked enemy submarines. These sensory agents fed data to prediction agents that predicted when,where, and with what probability the submarine would be in a given location. Thereafter a whole set of decision making andvisualization agents assisted a decision maker in determining how best to proceed. All these agents were supported, in turn,by other agents such as agents assessing trustworthiness of a source, database agents, resource discovery agents, and thelike. In applications such as CoAX, it is quite likely that some nodes will “go down” or “get disconnected” from the network.Any enemy sophisticated enough to use jamming technology would also make efforts to jam the network, effectively causingsome agents to have no connectivity. Thus, critical agents such as the prediction agents and the decision making agents needto be appropriately located and replicated so that the whole multi-agent system has a high probability of functioning. Ofcourse, it is assumed that the physical hardware (sensors) are already replicated to support sensor failures—this paper doesnot address how to replicate physical devices.Likewise, consider the exhaustive set of deployed multi-agent applications listed in [36]. According to their description,Skoda—a branch of Volkswagen—deployed an agent based production planning tool for manufacturing car engines. Theirmulti-agent solution looked both at low level planning and high level planning. High levels plans are examined by a set oflow level planning agents that try to achieve a part of the high level plan and flag conflicts and inconsistencies in the highlevel plan. A back and forth process ensures, once a consensus is achieved, the production plans are sent to higher levelagents who use resource allocation mechanisms to execute these plans on the production line. It is clear that in criticalapplications such as these, any node “going down” (for whatever reason) has the potential to cause the production line tocome to a grinding halt, leading to a loss of revenue for the company.Tichy et al. [42] describe a multi-agent system for the control of several components of a ship so as to reduce man-power requirements, while still ensuring highly reliable and survivable operation of the ship. They develop a hierarchicalmulti-agent architecture in which agents are embedded within hardware controllers and higher level agents coordinate andmonitor the activities of groups of agent-enhanced hardware controllers. The agents are continuously engaged within a plancreation, plan commitment, and plan execution cycle. Here too, it is clear that when agents are in control of a physicalenvironment (the ship in this case) there is high potential that the overall environment being controlled by the MAS canbe adversely affected whenever an agent “goes down”. In any situation where hardware components exist (and certainly onships), there is a possibility that hardware components will fail—for simple reasons or for more complex reasons such asthe actual physical movement of the ship and/or the oceanographic and climactic conditions with which the ship is forcedto contend. Thus, mechanisms are needed so that MASs can be deployed in a survivable manner even if some agents godown. Furthermore, it is important to calculate the guaranteed probability that the system will survive.Fault tolerance and replication techniques have been extensively studied in distributed computing systems [4,10,20,31,43],but much less so in the multi-agent systems domain [5,16,29,33]. Building a fault tolerant distributed system is notoriouslyhard. The autonomy of agents in multi-agent systems such as CoAX makes this task even more difficult. In this paper, webuild upon the framework of [27], which defined the probability that a given deployment of a MAS3 will survive, consideredthe basic problem of deployment survivability, and proposed methods for finding most survival deployments. Zhang et al. [45]also consider the complexity of the problem of finding the most survivable deployment. That is, the complexity of finding thedeployment with the highest survival probability, given a MAS deployment.The model of [27] assumes ignorance about the dependencies between node failures. However, this assumption is notalways valid. For example, an attack on Cornell’s web site is—in all likelihood—independent of the Israeli Defence Ministry’sweb site going down. The framework proposed in [27] cannot handle this. The algorithm developed in [27] for finding themost survivable deployment of agents on the network only works under the ignorance assu",
            {
                "entities": [
                    [
                        4243,
                        4271,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 382–391www.elsevier.com/locate/artintPerspectives on multiagent learning ✩Tuomas SandholmCarnegie Mellon University, Computer Science Department, Pittsburgh, PA 15213, USAReceived 18 May 2006; received in revised form 27 February 2007; accepted 27 February 2007Available online 30 March 2007AbstractI lay out a slight refinement of Shoham et al.’s taxonomy of agendas that I consider sensible for multiagent learning (MAL)research. It is not intended to be rigid: senseless work can be done within these agendas and additional sensible agendas mayarise. Within each agenda, I identify issues and suggest directions. In the computational agenda, direct algorithms are often moreefficient, but MAL plays a role especially when the rules of the game are unknown or direct algorithms are not known for theclass of games. In the descriptive agenda, more emphasis should be placed on establishing what classes of learning rules actuallymodel learning by multiple humans or animals. Also, the agenda is, in a way, circular. This has a positive side too: it can be usedto verify the learning models. In the prescriptive agendas, the desiderata need to be made clear and should guide the design ofMAL algorithms. The algorithms need not mimic humans’ or animals’ learning. I discuss some worthy desiderata; some from theliterature do not seem well motivated. The learning problem is interesting both in cooperative and noncooperative settings, but theconcerns are quite different. For many, if not most, noncooperative settings, future work should increasingly consider the learningitself strategically.Lower bounds cut across the agendas. They can be derived on the computational complexity and on the number of interactionsneeded.© 2007 Elsevier B.V. All rights reserved.Keywords: Multiagent learning; Learning in games; Reinforcement learning; Game theory1. IntroductionLearning from experience is a key capability because one may not be able to devise a good strategy (a plan forall possible contingencies) in advance—even with the help of computers. In multiagent settings, learning may beneeded because the opponents’ strategies are unknown, because the rules of the game are unknown, or because it iscomputationally too complex to solve for a good strategy with other means. Multiagent learning (MAL) is complicatedby the fact that the other agents may be learning as well (or changing their exploration behavior [61]), thus makingthe environment nonstationary for a learner. MAL has been studied with different objectives as well as with differentrestrictions on the game and on what the learners can observe.✩ This work was supported by the National Science Foundation under ITR grants IIS-0121678 and IIS-0427858, and a Sloan Fellowship.E-mail address: sandholm@cs.cmu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.004\fT. Sandholm / Artificial Intelligence 171 (2007) 382–391383Fig. 1. Taxonomy of agendas for multiagent learning research.2. On agendas for multiagent learningIn their paper “If multi-agent learning is the answer, then what is the question?”, Shoham et al. make an importantcontribution by laying out five agendas of (and for) MAL. I present a refinement of that taxonomy in Fig. 1. Itis consistent with their view, but adds hierarchy (and renames the “normative” agenda as “learning algorithms inequilibrium”). In the rest of this section, I will comment on the agendas using this taxonomy.2.1. Computational agendaWhile some MAL algorithms can, at least in principle, be used for equilibrium finding, they tend to be significantlyless efficient than the best direct equilibrium-finding algorithms. For example, MAL algorithms have been able tosolve only tiny poker games while direct techniques have been able to find the exact equilibrium of poker games upto, and including, the game of Rhode Island Hold’em, which has 3.1 billion nodes in the game tree [32].If one’s goal is equilibrium finding, there seems to be little reason to use MAL algorithms. There has been tremen-dous recent progress on faster algorithms for equilibrium finding in normal form games [58,62], graphical games [42,71], sequential games of perfect information [64], and sequential games of imperfect information [31,32]. Why wouldone not want to take advantage of these efficient, direct techniques?One would, but there are settings for which efficient direct techniques are not (yet) known. For example, the bestcomputer programs for Backgammon have been developed using MAL, specifically Q-learning [69]. Also, MALalgorithms are in many cases simpler to program than the direct techniques, and are thus arguably preferable if codefor the direct algorithm is not readily available and the scalability of MAL suffices for the setting. Finally, it isconceivable that for some equilibrium-finding problems, MAL-based algorithms will turn out to be the most efficient.For example, for finding a minimax solution to a two-player zero-sum game, MAL (specifically, no-regret learning)might be an efficient alternative to linear programming if the game has a huge number of (pure) strategies but thepayoffs are small [2, page 73].Most importantly, however, MAL algorithms are needed if the agents do not know the structure (e.g., payoffs) ofthe game, or if the goal is to exploit a weak opponent more than an equilibrium strategy would exploit that oppo-nent.2.2. Descriptive agendaThe descriptive agenda of MAL grew largely out of the concern that people might not have the required rationality(reasoning capability) to act according to game-theoretic equilibrium. This in turn calls into question the descriptive\f384T. Sandholm / Artificial Intelligence 171 (2007) 382–391power of game theory. To mitigate this, economists have studied whether MAL techniques lead to equilibrium play.1If so, that is a justification of equilibrium because it is reached with learning, and thus does not require sophisticatedgame-theoretic reasoning and direct equilibrium-finding algorithms. This simplicity argument can also be used forequilibrium selection (easy-to-learn equilibria being more likely and more reasonable) and for justifying/selectingsolution concepts (concepts that can be associated with convergent learning algorithms being more descriptive). Hu-mans’ and animals’ learning other than learning that yields equilibrium is also in the scope of the descriptive MALagenda.There are, however, critical shortcomings in the descriptive MAL agenda, at least in many of the ways in which ithas been pursued to date. The most important shortcoming is that it is ill-defined what counts as a MAL algorithmunder this agenda, and the descriptive conclusions depend completely on what algorithms count. For example, elabo-rate work has been done on MAL algorithms that converge to equilibrium. However, even a trivial algorithm achievesthis goal: the players first explore each cell of the payoff matrix in order, then each of them individually computes anequilibrium (each agent using the same algorithm so as to find the same equilibrium in case of multiple equilibria), andthey play that equilibrium forever from then on. Researchers pursuing the descriptive agenda would not consider thisstraw man a MAL algorithm. Why not? Unfortunately, clear definitions of what algorithms count are usually not ar-ticulated. Instead, a variety of algorithms have been proposed, and their “naturalness” is argued based on intuition andtaste on an algorithm-by-algorithm basis. Since the descriptive conclusions hinge on what algorithms count, I thinkthere should be clear definitions of what MAL algorithms count. The definitions should preferably admit and excludeclasses of algorithms—defined by some properties of the algorithmic steps—rather than individual algorithms.What algorithms are admitted versus excluded should be guided at least by experiments on humans (or animals ifthat is the population about which descriptive conclusions are to be drawn). Unfortunately, this gives rise to a potentialcircularity in the agenda: in order to make descriptive conclusions about how humans behave, we need to start out withan understanding of how humans behave. (The circularity could also be used constructively to try to verify that theapproach is working. One could observe behavior in one setting, select learning models accordingly, test the modelsin a different setting, and check whether the descriptive conclusions align with observed behavior in that setting.)Another downside is that experimental results are context dependent.One approach is to admit in the definition algorithms that are simple (as opposed to complex to execute). Whilethis is intuitively appealing, it suffers from difficulties. First, it is not clear what is simple because human reasoningmay not coincide with the Turing machine model for which clear complexity measures have been devised. Second,some of the MAL algorithms admitted in the descriptive approach today involve numerous sophisticated calculations.Another shortcoming in the descriptive agenda is that most of that work assumes that people use the learning ruleeven if they would do better for themselves by behaving differently during the learning process. In other words, peopleare reduced, by assumption, to following a certain learning algorithm which guarantees that, if each agent follows thealgorithm, (eventually) an equilibrium will be reached. A related shortcoming is that each person is assumed to followthe learning rule even if he could, by behaving differently, drive the population to converge to a different equilibriumthat is more beneficial for himself.2.3. Prescriptive agendasIn the prescriptive agendas we are interested in how multiple agents should learn. It is thus largely irrelevantwhether the learning algorithms mimic how humans (or other animals) learn. The goal is to develop learning algo-rithms that satisfy given desiderata, that is, do well against given ",
            {
                "entities": [
                    [
                        2885,
                        2913,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 428–439Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMcCarthy variations in a modal keyJohan van Benthem a,b,∗a University of Amsterdam, Institute for Logic, Language and Computation (ILLC), P.O. Box 94242, Amsterdam, GE, Netherlandsb Stanford, United Statesa r t i c l ei n f oa b s t r a c tWe take a fresh look at some major strands in John McCarthy’s work from a logician’sperspective. First, we re-analyze circumscription in dynamic logics of belief change underhard and soft information. Next, we re-analyze the regression method in the SituationCalculus in terms of update axioms for dynamic–epistemic temporal logics. Finally, wedraw some general methodological comparisons between ‘Logical AI’ and practices inmodal logic, pointing at some creative tensions.© 2010 Elsevier B.V. All rights reserved.Article history:Available online 3 April 2010Keywords:CircumscriptionFixed-point logicStructural rulesBelief changeSituation CalculusTemporal logicRegression methodDynamic epistemic logic1. IntroductionJohn McCarthy is a colleague whom I have long respected and admired. He is a truly free spirit who always commu-nicates about issues in an open-minded way, away from beaten academic tracks and entrenched academic ranks. Eachencounter has been a pleasure, from being involved with his creative Ph.D. students in Logical AI (each a remarkable char-acter) to his lively presence at our CSLI workshop series on Logic, Language and Computation – and most recently, hisparticipation in the Handbook of the Philosophy of Information [1]. Interacting with John makes me see my own work andmy field in new ways, even in places where I eventually disagree. This brief note presents three illustrations. As a logician,I find John’s work intriguing because it is clearly about logic, but not in the ‘internal’ professional mode that I am usedto. True, many ideas of his have provided grist to our technical mills, and that is good. But more importantly, John’s workreminds us of broader issues: what logic should be about, and also, what methodology best suits the resulting agenda. Allthese themes play in my illustrations. In doing so, I merely give new perspectives on what exists, pointing out some newdirections: there are no new formal results.2. Circumscription, logical consequence, and logical dynamicsMy first encounter with the classic [18] introducing circumscription was when my student Wilfried Meyer Viol rushedinto my office, and said he had just seen the first truly new logical idea in years, and that: not coming from a logician!We quickly read the paper, and I was struck at once by the liberating effect of other consequence relations that retain basicstructure that makes them ‘logical’, while breaking new ground in terms of new varieties of reasoning. Ever since, I have* Address for correspondence: University of Amsterdam,Netherlands.E-mail address: johan.vanbenthem@uva.nl.URL: http://staff.science.uva.nl/~johan.Institute for Logic, Language and Computation (ILLC), P.O. Box 94242, Amsterdam, GE,0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.014\fJ. van Benthem / Artificial Intelligence 175 (2011) 428–439429been intrigued by what circumscription means, and I will tell a bit of the story up to my current somewhat iconoclasticreinterpretation.2.1. Classical consequence, circumscription, and beyondMinimal models. Classical consequence from premises P to a conclusion C says that all models of P are models for C . Themodels for P are the current range of options, encoding what we know: a logical conclusion does not add to that knowledge,but elucidates it. McCarthy [18] taught us that problem solving and planning go beyond this format, getting more out of thestated premises in special models that are most congenial to the scenario at hand. A circumscriptive consequence from P toC says thatC is true in all minimal models for P .Here, minimality refers to some relevant comparison order for models: inclusion of object domains, inclusion of denotationsfor specified predicates, and so on. The general idea is minimizing over any reflexive–transitive order of ‘relative plausi-bility’ [28].1 This is not just a trick for problem solving: circumscription seems a natural phenomenon in common sensereasoning broadly construed.Circumscription and classical logics. Circumscription quickly caught the imagination of logicians, since it raises new ques-tions about familiar systems. An example is the fine structure of second-order logic (cf. [39]). Letting the comparison orderbe inclusion of predicates over the same domain, and switching to standard notation, truth of a circumscriptive sequentϕ ⇒P C with ϕ a conjunction of premises (where the predicate P may occur in both ϕ and C ) in a first-order model M istruth of a following second-order implication:(cid:6) ⊂ P : ϕϕ(P ) ∧ ¬∃P→ C(P ).(cid:3)(cid:3)P(cid:2)(cid:2)(cid:6)Here the antecedent defines the ‘predicate minimal’ models of ϕ(P ).Thus, circumscription involves second-order logic, and high complexity is lurking. Still, basic results in [15] found specialsyntactic forms of ϕ(P ) that reduce circumscription to first-order reasoning.2 This line of analysis can be extended. [34] an-alyzes just when there exists a unique minimal predicate MIN P • ϕ(P ) satisfying a given first-order description ϕ(P ) (ϕmay also contain predicates Q that are not minimized):Definition 1. A first-order formula ϕ(P , Q ) has the Intersection Property for a predicate letter P if, in every model M ,whenever M, P i |(cid:9) ϕ(P , Q ) holds for all predicates in some family { P i | i ∈ I} (here the predicate letter P gets interpretedas the predicate P i ), then it also holds for the intersection of all these predicates, that is: M, ∩ P i |(cid:9) ϕ(P , Q ).If the formula ϕ(P , Q ) is satisfied in a model M by any predicate P at all, this ensures there is a unique smallestpredicate in M that does: and that is the earlier MIN P • ϕ(P ). A simple formula with the Intersection Property is ∀x(Q x →P x): the minimal predicate for P is just Q . A more complex example is ∀x(Q x → P x) ∧ ∀xy((P x ∧ Rxy) → P y): the minimalpredicate is the reflexive–transitive R-closure of Q in the model. These two cases suggest a syntactic format matching thesemantic Intersection Property:Definition 2. A first-order formula is a PIA form (‘positive antecedent implies atom’) if it has the syntactic format (with x afinite tuple of variables)(cid:2)∀x(cid:3)ϕ(P , Q , x) → P xwith P occurring only positively in ϕ(P , Q , x).Here is a model-theoretic preservation result connecting the two notions:Theorem 1. (See van Benthem [34].) The following assertions are equivalent for all first-order formulas ψ(P , Q ):(a) ψ(P , Q ) has the Intersection Property w.r.t. predicate P ,(b) ψ(P , Q ) is definable by a conjunction of PIA formulas.This analysis relates circumscription to well-known languages in the study of computation, with operators for smallestand greatest fixed-points:Theorem 2. (See van Benthem [34].) First-order logic with added predicate minimization over PIA-conditions has the same expressivepower as LFP(FO): first-order logic with added least fixed-point operators.1 This is much as in the Lewis semantics for conditional logic since around 1970 – an analogy which has been often noted (cf. [30]). This analogy willreturn below.2 The latter are reminiscent of ‘correspondence theory’ in modal logic [39] where we ask when modal logics whose axioms express second-order condi-tions on binary relations are already completely captured by matching first-order properties.\f430J. van Benthem / Artificial Intelligence 175 (2011) 428–439The connection between circumscription and fixed-point logic seems worth developing, but this technical strand is notmy main theme in this paper.Further travels of the idea. The next noticeable phenomenon is that circumscription, like all good ideas, has crossed overto other areas, in maybe unintended ways. Non-monotonic default reasoning is important in philosophy. [30] notes howphilosophers of science in the 1950s were quite close to it in their accounts of scientific explanation as what follows froma theory ‘under normal circumstances’.3 A more detailed account is found in [35].Circumscription made its way into linguistics as well. [30] noted also how it accounts for ‘exhaustive readings’ of answersto questions. An answer “John and Mary” to a question “Who are walking?” is usually read minimally: only John and Maryare walking. Such predicate minimizations are elaborated in [43]: the art is then finding the right model order to minimizeover for concrete semantic purposes. There is also work on linguistic formulations for McCarthy’s common sense puzzles.The innovative [12] analyzed these as a source of cues directing reasoning toward a solution.The complete travels of circumscription and related ideas remain to be chronicled, and they would also include cognitivescience and mathematics. Instead, we turn to the more general impact of circumscription in views of logic itself.The Bolzano Program: logic as a study of the varieties of consequence. By now, many styles of non-classical consequence havebeen found, with their structural properties [6,8,24], and it has been suggested that logic itself should be viewed as a studyof a plurality of consequence relations. Indeed, there is a historical precedent, if we go back to the agenda before Fregeand Boole. Logic was defined as the study of different natural styles of reasoning in the work of the great pioneer BernardBolzano, who already provided a highly original theory of sub-structural properties [29,32].But this diversity of reasoning styles also raises quite a few problems of its own. What is the nature of this diversity: dowe really ‘infer’ in many different ways, and why? Can we safely combine different styles in useful ways? And if these stylesare to refle",
            {
                "entities": [
                    [
                        3181,
                        3209,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 749–766Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDesigning competitions between teams of individuals ✩Pingzhong Tang a,∗, Yoav Shoham b,c, Fangzhen Lin aa Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kongb Computer Science Department, Stanford University, CA 94305, United Statesc Microsoft Israel R&D Center, Herzliya, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 15 June 2009Received in revised form 26 April 2010Accepted 26 April 2010Available online 29 April 2010Keywords:Team competitionMechanism designTruthfulnessMoral hazardDominant strategy implementation1. IntroductionWe consider a setting with two teams, each with a number of players. There is an orderingof all players that determines outcome of matches between any two players from theopposing teams. Neither the teams nor the competition designer know this ordering, buteach team knows the derived ordering of strengths among its own players. Each teamannounces an ordering of its players, and the competition designer schedules matchesaccording to the announced orderings. This setting in general allows for two types ofmanipulations by a team: Misreporting the strength ordering (lack of truthfulness), anddeliberately losing a match (moral hazard). We prove necessary and sufficient conditionsfor a set of competition rules to have the properties that truthful reporting are dominantstrategies and maximum effort in matches are Nash equilibrium strategies, and certainfairness conditions are met. Extensions of the original setting are discussed.© 2010 Elsevier B.V. All rights reserved.Once upon a time in ancient China, the emperor Qi threw down the gauntlet to his minister Tian for a horse race.The rule was that each of them would announce a ranking of his three horses and each time the two horses with thesame rankings would race. As the story goes, Tian learnt that his best horse was not as good as the emperor’s bestbut better than his second best one, and his second best one was not as good as the emperor’s second best but betterthan the emperor’s worst one. Knowing that the emperor would be confident enough to announce the true ordering,the clever minister put forward his worst horse first and his best horse second followed by his second best. As a result,while Tian’s worst horse lost badly to the emperor’s best horse in the first match, he won the second and third matchesnevertheless by taking the advantage of mismatches. Tian explained afterwards his strategy to the emperor and itspotential application in military matters and as a result, he was promoted to be the general in chief.Similar examples abound.1 A somewhat more recent example is the international team competition of table tennis. Theschedule is a modification of the horse racing one by adding two matches between the first player and the second playerfrom each team. Smart coaches can also benefit from strategically reporting the orderings. We will return to these exampleslater after we formally define the problem, which is henceforth called team competition problem.Competition among teams, each consisting of several players, presents at least two types of challenge. The first regardsthe desirable outcomes. Typically, the basic information is the relative strength of pairs of players, one from each team.✩An earlier version entitled “Team Competition” appeared in Proceedings of AAMAS’09.* Corresponding author.E-mail addresses: kenshin@cse.ust.hk (P. Tang), shoham@stanford.edu (Y. Shoham), flin@cse.ust.hk (F. Lin).1 For a related example in game theory, the Colonel Blotto game, cf. Section 7.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.025\f750P. Tang et al. / Artificial Intelligence 174 (2010) 749–766But how does this information get aggregated to decide the relative merit of the two teams? For example, should a teamwith one strong player and the rest very weak players beat a team consisting entirely of mediocre players? This amounts todefining the appropriate social-choice functions in this domain. One contribution of this paper is to establish criteria for suchfunctions; specifically, we adapted the notions of player anonymity, team anonymity, monotonicity, and Pareto efficiency tothis setting.The second challenge is that relative strengths among players are typically not common knowledge. Each team hasprivate information about its players, and the only objective way of getting this information is to play a match and observethe outcome. Playing all pairwise matches is usually not feasible, and so typically a competition among teams proceedsas follows: The teams announce a ranking of their players, and the organizer schedules individual matches based on theserankings according to a formula announced in advance. The matches then take place, and each match adds a certain scoreto the team of the winner. The team with the highest aggregate score wins the competition. But this opens the door to twoways in which teams can manipulate the outcome: It can misreport the true ordering of their players, and it can throw amatch (that is, deliberately lose). This is the problem of implementing the social-choice function, or of mechanism design(see [10,14] for introductions).Another contribution of this paper is the identification of necessary and sufficient conditions for implementing in dom-inant strategies social choice functions which satisfy the specified axioms. That is, identifying conditions under which it isbest for a given team to truthfully reveal the ordering among its players – no matter what the other team does, as wellas the conditions under which it is best for a given team to play its best in each match – knowing the other team alsoplays its best. These results are extended to a more general setting where the outcome of a match between two players isprobabilistic – decided according to a winning probability matrix [6].The remainder of the paper is organized as follows: We next formulate the team competition problem as a mechanismdesign problem, identify the basic forms of mechanisms and state the desirable properties in this domain. In Sections 4and 5, we characterize the conditions under which the mechanisms satisfy these properties. We then generalize our resultsin two directions in Section 6 and discuss related work in Section 7. Finally in Section 8, we briefly discuss future researchtopics related to team competition.2. Basic modelsWe now give the mathematic models for analyzing team competition.2.1. Team competition environmentsTeam competition environment is the setting where the designer operates.Definition 2.1. A team competition environment C is a tuple ( A, B, Θ, O , R), where• A = {a1, . . . , an} is the set of players of team A.• B = {b1, . . . , bn} is the set of players of team B.• Θ is the set of possible states, where:– Each state θ ∈ Θ uniquely defines a linear order >θ on A ∪ B. If a >θ b, then a beats b in state θ .– We denote by θ A and θB the orderings on A and B that are derived from θ respectively. θ A and θB can be seen asthe private information of A and B. We denote by Θ A and ΘB the sets of all possible θ A and θB .• O = {(s A, sB ) | s A, sB ∈ R} is the set of outcomes of the competition. s A and sB are the scores for teams A and B,respectively.• R is a preference relation over O .We consider R to be the one that team A weakly prefers (s A, sB ) to (s(cid:5)A, s(cid:5)B ) iffs A (cid:2) s(cid:5)Aand sB (cid:3) s(cid:5)B ,and team A strictly prefers (s A, sB ) to (s(cid:2)s A > s(cid:5)A and sB (cid:3) s(cid:5)B(cid:3)(cid:2)ors A (cid:2) s(cid:5)B ) iff(cid:5)A, s(cid:5)A and sB < s(cid:3).(cid:5)BTeam B has the opposite preference. We note that when s A > sis not defined.2(cid:5)A and sB > s(cid:5)B , the preference between (s A, sB ) and (s(cid:5)A, s(cid:5)B )An easy way to complete the preference defined above is to restrict a mechanism on certain set of outcomes satisfying,for each state θ , s A + sB = c, for some constant c. Such a mechanism is called a constant-sum mechanism.2 We will get back to another type of preference where each team is not so sensitive about scores but only cares about winning or losing. In this case,2 : 3 is as desirable as 3 : 4.\fP. Tang et al. / Artificial Intelligence 174 (2010) 749–7667512.2. StrategiesTypically, each team communicates with a mechanism by sending it a message. In team competition context, such amessage is confined to the form of an ordering of players of that team. A strategy of each team then specifies how tochoose among its orderings of players, given its true ordering of strengths.Definition 2.2. S A : Θ A → L A , is the set of A’s pure strategies that map A’s private information to a linear order on A,where L A is the set of all linear orders on A. Similarly for S B .When there is no restriction on Θ , both Θ A and L A denote the set of all permutations on A. We use different notationshere to clarify that Θ A is the set of private information (types) based on which A chooses an ordering in L A to report.Similarly, we can define the set of A’s mixed strategies to be σ A : Θ A → Ω(L A), where Ω(L A) is the set of probabilitydistributions over L A . We assume both teams are risk neural. As a result, when they play a mixed strategy, the outcome isequivalent to the expected score profile.2.3. Generalized round-robin mechanismsDefinition 2.3. Given a team competition environment and a message profile (L A, L B ) reported by A and B, a generalizedround-robin mechanism specifies an outcome via a matrix C , where:• Each entry ci, j in C denotes the score assigned to the match between ai and b j , where ai is the i-th player of L A andb j the j-th player of L B .• The winner of the match gets ci, j and the loser gets 0.• The total score that team A can get in state θ is s A =• Such a pair (s A, sB ) creates an",
            {
                "entities": [
                    [
                        3805,
                        3833,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 165 (2005) 137–163www.elsevier.com/locate/artintDecision making on the sole basis ofstatistical likelihoodPhan H. Giang a,∗, Prakash P. Shenoy ba Computer Aided Diagnosis and Therapy Solutions (CAD), Siemens Medical Solutions,51 Valley Stream Pkwy, Malvern, PA 19355, USAb University of Kansas School of Business, 1300 Sunnyside Ave, Summerfield Hall,Lawrence, KS 66045-7585, USAReceived 10 May 2004; accepted 16 March 2005Available online 10 May 2005AbstractThis paper presents a new axiomatic decision theory for choice under uncertainty. Unlike Bayesiandecision theory where uncertainty is represented by a probability function, in our theory, uncertaintyis given in the form of a likelihood function extracted from statistical evidence. The likelihood prin-ciple in statistics stipulates that likelihood functions encode all relevant information obtainable fromexperimental data. In particular, we do not assume any knowledge of prior probabilities. Conse-quently, a Bayesian conversion of likelihoods to posterior probabilities is not possible in our setting.We make an assumption that defines the likelihood of a set of hypotheses as the maximum likelihoodover the elements of the set. We justify an axiomatic system similar to that used by von Neumannand Morgenstern for choice under risk. Our main result is a representation theorem using the newconcept of binary utility. We also discuss how ambiguity attitudes are handled. Applied to the sta-tistical inference problem, our theory suggests a novel solution. The results in this paper could beuseful for probabilistic model selection. 2005 Elsevier B.V. All rights reserved.Keywords: Decision theory; Likelihood; Statistical inference; Ambiguity attitude* Corresponding author.E-mail addresses: phan.giang@siemens.com (P.H. Giang), pshenoy@ku.edu (P.P. Shenoy).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.03.004\f138P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1631. IntroductionVarious formal decision theories for choice under risk and uncertainty have been studiedsince the seminal work by von Neumann and Morgenstern (vNM) [38] where the expectedutility maximization principle was formally established. With few exceptions, a commonfeature in these theories is the use of probability to express uncertainty in decision situ-ations. An axiomatic model is as good as its axioms, the debate on axioms of the vNMtheory started almost immediately with their publication [2]. As a result of this ongoingdebate, axiomatic systems that are weaker than vNM but still possess the expected utilityrepresentation have been investigated [17,32,33]. There is also a recognition that the uncer-tainty that one usually associates with the words “ambiguity”, “vagueness” and “fuzziness”are not the same kind as that associated with “risk”. The latter is captured by standard nu-merical probability.In this paper,1 we consider a class of choice problems where uncertainty is character-ized by likelihood functions. This class includes a typical statistical inference problem thatis formulated as follows. Suppose we are to analyze a statistical experiment on a randomvariable Y given (i) Y follows one of the distributions in F = {Pθ | θ ∈ Ω} parameter-ized by θ ; and (ii) the outcome of the experiment is Y = y. The question is: what can weconclude about the true value of parameter θ ?There is consensus among statisticians about what information sample y brings to theunknown parameter. According to the likelihood principle, one of the fundamental princi-ples of statistics [4,5,8], all relevant information of the sample is encoded in the likelihoodfunction on the parameter space. And the consensus also ends at this point. The statisticalinference problem is treated differently by different approaches [3].According to the decision-theoretic approach advocated by Wald [39], the inferenceproblem is viewed as a choice problem. For example, in the context of a hypothesis testingproblem, the choice is to either accept or reject a hypothesis. Within the decision-theoreticapproach there are several variations. Wald’s maximin decision rule selects an action thatdelivers the most favorable worst-case outcome. A Bayesian treatment of the problem sug-gests a calculation of posterior probability function on Ω via Bayes’s theorem from thelikelihood function by assuming a prior distribution. Given the posteriors, actions are com-pared on the basis of their expected utility. In this paper, we proposes a third alternative.We construct a decision theory that works directly with likelihood information. We chooseto treat likelihood as uncertainty in its own right for a simple reason: priors are not knownin many situations.The problem of probabilistic model selection in the areas of AI, machine learning, pat-tern recognition and data mining is an example of the statistical inference problem. Givena (training) data set y, researchers construct a probabilistic model P (e.g., a Bayesian net)that generates/fits the data and then use this model for inference with future observations.Because there are, almost always, more than one models that emerge as plausible candi-dates, model selection is an essential part of model construction.1 A preliminary version of this work has appeared in the Proceedings of 18th Conference on Uncertainty inArtificial Intelligence (UAI 2002) [21].\fP.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163139From a decision theoretic point of view, the prevailing practice to select a model usingsimple criteria such as maximum likelihood (ML) or maximum a posteriori probability(MAP) is equivalent to assuming equal utilities (costs) for all models under consideration.This assumption however does not explain the following example. Given two models ofapproximately the same likelihoods, most researchers would go for a simpler one (and jus-tify this choice by invoking Occam’s razor principle). In the statistics literature, modelsare selected by using Akaike Information Criterion (AIC) [1] or Schwarz’s criterion (a.k.a.Bayesian Information Criterion or BIC) [34]. The idea underlying both AIC and BIC is topenalize model’s likelihood by an amount depending on its number of parameters. Polandand Shachter [31] suggest the “effectiveness ratio” criterion where the penalty has an ex-plicit computational interpretation. Clearly, the concern on complexity can be viewed asa cost associated with a model. In broader terms, an implication from these works is thatdifferent models are associated with different costs that must be taken into account in amodel selection process.This paper is organized as follows. In the next section, we discuss extending a likelihoodfunction to a function on the set of subsets of possible worlds. In the main part (Section 3),we develop a decision theory for likelihood uncertainty. We begin by proposing a set of fiveaxioms that are justified by intuition as well as by the stochastic dominance principle. Next,we introduce the concept of binary utility and prove the representation theorem for likeli-hood lotteries. That is followed by comments on related works. In Section 4, our decisiontheory is applied for a statistical inference problem. Section 5 contains some concludingremarks.2. Likelihood as uncertainty measureLet us consider the statistical inference problem as described earlier. Although the phe-nomenon under study is described probabilistically (by a set of probability functions F ),the uncertainty pertaining to the choice problem is not. It is a likelihood function. The term‘likelihood’ used in modern statistics was coined by R.A. Fisher who mentioned it as earlyas 1922 [18]. Fisher used likelihoods to measure “mental confidence” in competing sci-entific hypotheses as a result of a statistical experiment (see [14] for a detailed account).Likelihood has a puzzling nature. For each θ ∈ Ω, there is a likelihood quantity that bymagnitude equals Pθ (y)—the probability (or probability density in case of infinite Ω)2 ofobserving y if θ is in fact the true value of the parameter. However, if we view the set oflikelihood quantities as a function on the parameter space, we have a likelihood function.A likelihood function is not a probability function. For a simple reason, the sum of alllikelihood values (over the parameter space) may not add to unity. Moreover, likelihoodfunctions are equivalent up to a proportional constant.To emphasize the fact that a likelihood function is tied to data y and has θ as the variable,the notation liky(θ ) is used instead of Pθ (y). Technically, probability and likelihood are2 One can write Pθ0 (y) in the form of a conditional probability: P (Y = y | θ = θ0). The latter notation impliesthat there is a probability measure on parameter space Ω. This is the case for the Bayesian approach. In this paper,we do not assume such a probability measure. So we will stick with the former notation.\f140P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163two kinds of animals, but they are as close as mule and donkey. This proximity is thereason for an intertwining relationship. Obviously, (posterior) probability is derived fromlikelihood and priors via Bayes theorem. Since such priors are supposed to summarize theinformation about the parameter before the experiment is conducted, the assumption of itsexistence is beyond the realm of science as many statisticians contend. Although in certainsituations prior probability comes naturally, there is no compelling argument why it mustalways be known to an experimenter in all situations.Another path from likelihood to probability, that bypasses the issue of priors, was startedby Fisher himself. He suggested to compute what he called fiducial probabilities by nor-malizing the likelihoods (dividing by the sum of likelihoods). Fisher’s idea has been shownto work for isolated examples and but it faces a serious difficulty when applied t",
            {
                "entities": [
                    [
                        1922,
                        1950,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 429–433www.elsevier.com/locate/artintThe possible and the impossible in multi-agent learningH. Peyton Young a,b,ca Johns Hopkins University, USAb University of Oxford, UKc The Brookings Institution, USAReceived 16 May 2006; received in revised form 20 October 2006; accepted 20 October 2006Available online 7 February 2007AbstractThis paper surveys recent work on learning in games and delineates the boundary between forms of learning that lead to Nashequilibrium, and forms that lead to weaker notions of equilibrium or to none at all.© 2007 Elsevier B.V. All rights reserved.Keywords: Equilibrium; Learning; DynamicsInteractive learning is inherently more complex than single-agent learning, because the act of learning changes thething to be learned. If agent A is trying to learn about agent B, A’s behavior will naturally depend on what she haslearned so far, and also on what she hopes to learn next. But A’s behavior can be observed by B, hence B’s behaviormay change as a result of A’s attempts to learn it. The same holds for B’s attempts to learn about A.This feedback loop is a central and inescapable feature of multi-agent learning situations. It suggests that methodswhich work for single-agent learning problems may fail in multi-agent settings. It even suggests that learning couldfail in general, that is, there may exist situations in which no rules allow players to learn one another’s behavior in acompletely satisfactory sense. This turns out to be the case: in the next section I formulate an uncertainty principlefor strategic interactions which states that if there is enough ex ante uncertainty about the other players’ payoffs (andtherefore their potential behaviors), there is no way that rational players can learn to predict one another’s behavior,even over an infinite number of repetitions of the game ([5]; for earlier results in the same spirit see [1] and [13,14]).Admittedly this and related impossibility theorems rest on very demanding assumptions about agents’ rationality,and what it means for them to “learn” their opponents’ behavior. Under less restrictive conditions more positive resultscan be attained, as we shall see in Section 3. Thus the purpose of this note is not to claim that multi-agent learningis impossibly difficult, but to try to identify the boundary—insofar as we now know it—between the possible and theimpossible in multi-agent learning situations. These issues are discussed in greater depth in [18].1. Model-based learningThe accompanying perspectives paper by Shoham, Powers and Grenager [17], hereafter referred to as SPG, formsmy jumping-off point. They too draw attention to the fact that multi-agent learning is inherently more complex thanE-mail address: pyoung@jhu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.10.015\f430H.P. Young / Artificial Intelligence 171 (2007) 429–433single-agent learning. They also make a useful distinction between model-based and model-free forms of learning,which I shall follow here. Using essentially their language, a model-based learning scheme has the following elements:1. Start with a model of the opponent’s strategy.2. Compute and play a best [or almost best] response.3. Observe the opponent’s play and update your model.4. Goto step 2.SPG leave the concept of “model” open, but here I shall suggest a general definition. Namely, a model-based learningmethod is a function that maps any history of play into a prediction about what one’s opponents will do next period,that is, to a probability distribution over the opponents’ actions conditional on the history so far. This definitionencompasses many forms of pattern recognition. The key feature of a model-based learning rule, however, is not whatpatterns it is able to identify in the data, but how it uses these patterns to forecast the opponents’ next moves.Many game-theoretic learning methods fall into this category. Fictitious play is a simple example: each agentpredicts that his opponent will use the distribution next period that he used cumulatively up until now. More gener-ally, Bayesian updating is a model-based learning procedure: each agent updates his beliefs about the repeated-gamestrategy of the opponents (conditional on the observed history), which leads to a prediction of their behavior nextperiod.What exactly do we mean by “learning” in this context? A natural definition is that players “learn” if they eventuallysucceed in predicting their opponents’ behavior with a high degree of accuracy [5]. This idea can be given greaterprecision as follows. Suppose that you are engaged in a two-player game. Given a history ht to time t, let pt beyour prediction of the opponent’s next-period behavior, conditional on ht . Let qt be your opponent’s actual intendedbehavior next period, conditional on ht . Notice that both pt and qt are probability distributions over the opponent’saction space (which we assume is finite). Thus pt and qt lie in an m-dimensional simplex for some nonnegative integerm. The predictive error in period t is (cid:2)pt − qt (cid:2). We could say that you learn to predict if (cid:2)pt − qt (cid:2) → 0 almost surely(cid:2)ps − qs(cid:2)2 → 0as t → ∞. A less demanding definition would be that the mean square error goes to zero: (1/t)almost surely as t → ∞. We shall say that the former is learning to predict in the strong sense and the latter is learningto predict in the weak sense.s(cid:2)t(cid:2)There is a well-known condition in statistics that guarantees that all players will learn to predict in the strong sense.Namely, it suffices that each player’s forecast of the others’ behavior, conditional on his own behavior, never excludeevents that have positive probability under their actual joint behavior. This is the absolute continuity condition [2,15].So far we have said nothing about what determines agents’ behavior, only what it means for them to learn. Ingame theory, a standard assumption is that behavior is rational: at each point in time, given what has happened todate, the players’ behavioral strategies are optimal given their forecasts of what is going to happen at all future dates.If we combine rationality with the absolute continuity condition (which guarantees good prediction), then we getconvergence to Nash equilibrium along the play path [15].Suppose, however, that each player is ignorant of his opponent’s payoff function. If the opponent is rational, hisstrategy will depend—perhaps quite intricately—on what his payoffs are. Hence the first player will have difficultyforecasting the second player’s strategy unless he can gather enough information along the play path to deduce whatthe latter is optimizing. The same holds for the second player trying to forecast the behavior of the first. This turns outto be impossible in principle when there is enough ex ante uncertainty about the payoffs.Theorem 1. (See [5].) Consider an n-person game on a finite joint action space A, where the n|A| possible payoffsdefining G are drawn i.i.d. via a continuous density f that is bounded away from zero on an open interval. G isdetermined once and for all before play begins. Assume the players are forward-looking and rational, with discountfactors less than unity, they know their own realized payoffs, and they use forecasting rules that do not depend on theopponents’ realized payoffs.There is a positive probability that: (i) at least one of the players will not learn to predict even in the weak sense;and (ii) the players’ period-by-period behaviors do not converge to any Nash equilibrium of the repeated game.Furthermore, if the support of f is a sufficiently small interval, then conclusions (i) and (ii) hold with probabilityone.\fH.P. Young / Artificial Intelligence 171 (2007) 429–433431A consequence of this result is that there exist no general, model-based procedures for multi-agent learning whenplayers are perfectly rational and they have sufficiently incomplete knowledge of their opponents’ payoff functions.A crucial condition for Theorem 1 to hold is that the unknown payoffs are distributed over some interval. If insteadthey were known to lie in a finite set, or even in a countable set, the result can fail. In this case one can tailor theforecasting rules to take account of the restricted set of payoffs that the opponent could be using, and thereby satisfyabsolute continuity. The second crucial condition for Theorem 1 is rationality: agents must optimize exactly. If insteadagents almost optimize, as in smoothed fictitious play [8], the result does not necessarily hold.In my view the first of these conditions (lack of knowledge) is more important than the second (perfect rationality).For one thing the second condition is merely an ideal statement about behavior, there is little or no empirical supportfor the notion that subjects optimize exactly. By contrast the first condition seems quite realistic: a player can hardlybe expected to know the von Neumann Morgenstern payoffs of his opponent with any precision; surely the most thatcan be hoped for is that he knows they lie within some range.I now sketch a model-based, multi-agent learning method that gets around the preceding impossibility result byrelaxing rationality a bit, while maintaining the assumption about complete lack of knowledge. The method is struc-tured along the lines of statistical hypothesis testing [6]. Assume, for the moment, that there are two players, 1 and2, with finite action spaces A1 and A2. Let Δi be the simplex of probability distributions on Ai . At time t, agent 1’smodel is that agent 2 is going to play a fixed distribution p2t ∈ Δ2 in all future periods. Given this model, agent 1chooses a smoothed best response q1t ∈ Δ1. Similarly, agent 2’s model at time t is some p1t ∈ Δ1 and her smoothedbest response is q2t ∈ Δ2. Hypothesis testing takes the following form for each player. Let s be a large positive integer(the sample size) and l",
            {
                "entities": [
                    [
                        2852,
                        2880,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1815–1855Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSolving conflicts in information merging by a flexible interpretationof atomic propositionsSteven Schockaert a,∗,1, Henri Prade ba Ghent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281, 9000 Gent, Belgiumb Toulouse University, Université Paul Sabatier, IRIT, CNRS, 118 Route de Narbonne, 31062 Toulouse Cedex 09, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 July 2010Received in revised form 21 April 2011Accepted 23 April 2011Available online 28 April 2011Keywords:Information fusionSimilarity-based reasoningPrioritized knowledge basesPossibilistic logicPenalty logic1. IntroductionAlthough many techniques for merging conflicting propositional knowledge bases havealready been proposed, most existing work is based on the idea that inconsistency resultsfrom the presence of incorrect pieces of information, which should be identified andremoved. In contrast, we take the view in this paper that conflicts are often causedby statements that are inaccurate rather than completely false, suggesting to restoreconsistency by interpreting certain statements in a flexible way, rather than ignoringthem completely. In accordance with this view, we propose a novel approach to mergingwhich exploits extra-logical background information about the semantic relatedness ofatomic propositions. Several merging operators are presented, which are based on differentformalizations of this background knowledge, ranging from purely qualitative approaches,related to possibilistic logic, to quantitative approaches with a probabilistic flavor. Bothsyntactic and semantic characterizations are provided for each merging operator, and thecomputational complexity is analyzed.© 2011 Elsevier B.V. All rights reserved.In applications where information from different sources needs to be combined, conflicts are often the rule rather thanthe exception. The presence of conflicts requires special attention, as it casts doubt on the reliability of available information.Even worse, if information is encoded in classical logic, the combined pieces of information become trivial, as anything canbe derived from contradiction. To accommodate the possibility of conflicts in a more useful way, a wide array of approacheshas been proposed in the literature, ranging from purely syntactic approaches to semantic operators that manipulate sets ofinterpretations. In general, the problem of information merging has been studied both in logical and in numerical settings.An example of the latter case are situations where different probability or possibility distributions need to be fused [1,2].This paper focuses exclusively on merging in a logical setting.A common idea underlying many approaches to logical information merging is to get rid of the least reliable pieces ofinformation. The exact mechanism being employed may, among others, be based on prior knowledge about the reliabilityof different pieces of information and of sources [3,4], on discriminating between pieces of information according to thenumber of supporting sources [5], or on the dialectical principles of argument and counter-argument [6]. The essentialpoint of view underlying such approaches is that conflicts are caused by errors that are in some sense arbitrary: any pieceof information has some chance of being wrong, and agreement between sources (or prior knowledge) is all that can helpus to decide which pieces are more likely to be correct. A closely related idea is to weaken the information that is provided* Corresponding author.E-mail addresses: steven.schockaert@ugent.be (S. Schockaert), prade@irit.fr (H. Prade).1 Postdoctoral fellow of the Research Foundation – Flanders (FWO).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.04.001\f1816S. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–1855by each of the sources [7–10]. For instance, if some source claims p ∧ q, we may change this, among others to p ∨ q. Thismay be motivated in several ways. If the sources express conflicting goals or preferences, for instance, we may consider thateach competing source needs to concede to arrive at a feasible global strategy. Alternatively, when sources express beliefs,we may consider that weaker information is more reliable, and that by progressively weakening these beliefs we ultimatelyend up with beliefs that are correct, and thus consistent. Without extra-logical information, however, approaches based onthis idea tend to be rather coarse, often depending on the assumption that all atoms in the language encode properties thatare approximately of equal importance in the domain being modeled.A quite different approach to dealing with conflicts is to relax the assumption that sources need to be combined con-junctively. Indeed, if individual sources are consistent, combining them disjunctively trivially restores consistency. Startingfrom this basic idea, more refined techniques have been developed, e.g. based on disjunctively combining conjunctions ofmaximal consistent subsets of knowledge bases [11,12]. Paraconsistent logics [13] offer yet another solution to the problemof conflict. Rather than trying to modify the knowledge bases, the logic itself is changed such that only non-trivial conclu-sions can be derived, even in the face of logical contradiction. The fact that both p and ¬p may be entailed by a non-trivialtheory may, in some paraconsistent logics (e.g. the logic of formal inconsistency [14]), be interpreted as evidence that theproperty modeled by p is controversial (or ill-defined, vague, etc.) in which case it is natural that different sources mayhave a different standpoint regarding p. A consequence of this methodology is that, contrarily to most other methods, thereis no real loss of information when conflicts arise. Indeed, when p is asserted by some source and ¬p by another source,we do not give up our belief in p but rather gain the insight that p is controversial.In this paper, we are exploring a new direction, which is motivated by the fact that in real-world applications, randomerrors occur side-by-side with conflicts that are due to the use of properties that may be understood differently by differentsources (e.g. vague properties such as ‘tall’). The method being used to deal with conflicts is then not only determined bythe nature of conflicts, but also — and perhaps even especially — by the nature of available background knowledge. Logics offormal inconsistency, for instance, require that some atoms are designated as uncontroversial, to ensure meaningful results.In general, most methods assume no, or very little prior knowledge, making them widely applicable, but at the sametime limiting their ability to correctly identify the real cause of conflicts, and thus, ultimately, their usefulness. A similarconsideration applies to the problem of belief revision, for which it is well known that extra-logical information about theepistemic state of an agent (e.g. in the form of an epistemic entrenchment ordering) is key to meaningful results [15]. Forthe task of merging the beliefs expressed by different sources, however, the use and importance of extra-logical informationis less well-understood. Nonetheless, there are many situations where appropriate background knowledge is paramount incorrectly dealing with conflicts.Example 1. Consider a situation where predictions are available about tomorrow’s weather from three well-reputed sources.Predictions from all sources are expressed in a propositional language over the set of atoms {overcast, partiallyCloudy,openSky}, subject to the integrity constraint that overcast, partially cloudy, and open sky are Jointly Exhaustive and PairwiseDisjoint atoms (a property called JEPD in the following):K1 = {partiallyCloudy ∨ overcast}K2 = {openSky}K3 = {overcast}(1)(2)(3)If all three sources are considered equally reliable, classical merging strategies would either yield the trivial result overcast ∨partiallyCloudy ∨ openSky, or conclude overcast, which is the only atom that is compatible with the majority of the sources.Since all three sources are well-reputed, however, the extreme conclusions openSky and overcast seem less plausible than theintermediate conclusion partiallyCloudy. However, without additional information, encoding this idea of being intermediate,there are no reasons to prefer partiallyCloudy over overcast or openSky.The core idea in this example is that atoms such as overcast should be understood in a flexible way. The need forflexibility regarding the meaning of atoms may stem from different causes, including all of the following:1. Sources are overconfident, and the assertions they make are too precise, given the knowledge they actually have. In theexample above, it is clear that people prefer more informative weather reports (e.g. it will be sunny tomorrow), withthe risk of being slightly wrong from time to time, over completely honest but less informative or uninformative reports(e.g. it may be sunny or cloudy).2. Atoms refer to properties for which precise, generally accepted definitions are lacking. Typically these are propertiesthat depend on threshold values in some continuous domain, or properties whose definition may slightly vary with thecontext. For instance, there may be situations that are described as an open sky by some people and partially cloudyby others.3. Atoms refer to terms with a well-understood meaning, which are nonetheless used in a more liberal, or more restrictiveway in certain contexts. It is not hard to imagine, for example, a person in a civil union answering affirmatively tothe question “Are you married (yes/no)?”, e.g. when filling in a web form. As another example, the term Asian is often\fS. Schockaert, H. Prade / Artificial Intelligence 175 (2011) 1815–18551817reserve",
            {
                "entities": [
                    [
                        3919,
                        3947,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1133–1149Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe learnability of voting rules ✩Ariel D. Procaccia a,∗,1, Aviv Zohar b,a, Yoni Peleg b, Jeffrey S. Rosenschein ba Microsoft Israel R&D Center, 13 Shenkar Street, Herzeliya 46725, Israelb School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 16 May 2008Received in revised form 25 March 2009Accepted 27 March 2009Available online 9 April 2009Keywords:Computational social choiceComputational learning theoryMultiagent systemsScoring rules and voting trees are two broad and concisely-representable classes ofvoting rules; scoring rules award points to alternatives according to their position inthe preferences of the voters, while voting trees are iterative procedures that selectan alternative based on pairwise comparisons. In this paper, we investigate the PAC-learnability of these classes of rules. We demonstrate that the class of scoring rules, asfunctions from preferences into alternatives, is efficiently learnable in the PAC model. Withrespect to voting trees, while in general a learning algorithm would require an exponentialnumber of samples, we show that if the number of leaves is polynomial in the size of theset of alternatives, then a polynomial training set suffices. We apply these results in anemerging theory: automated design of voting rules by learning.© 2009 Elsevier B.V. All rights reserved.1. IntroductionVoting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computa-tional aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].In an election, n voters express their preferences over a set of m alternatives. To be precise, each voter is assumed toreveal linear preferences—a ranking of the alternatives. The outcome of the election is determined according to a voting rule.In this paper we will consider two families of voting rules: scoring rules and voting trees.Scoring rules. The predominant—ubiquitous, even—voting rule in real-life elections is the Plurality rule. Under Plurality, eachvoter awards one point to the alternative it ranks first, i.e., its most preferred alternative. The alternative that accumulatedthe most points, summed over all voters, wins the election. Another example of a voting rule is the Veto rule: each voter“vetoes” a single alternative; the alternative that was vetoed by the fewest voters wins the election. Yet a third exampleis the Borda rule: every voter awards m − 1 points to its top-ranked alternative, m − 2 points to its second choice, and soforth—the least preferred alternative is not awarded any points. Once again, the alternative with the most points is elected.The above-mentioned three voting rules all belong to an important family of voting rules known as scoring rules. A scoringrule can be expressed by a vector of parameters (cid:3)α = (cid:4)α1, α2, . . . , αm(cid:5), where each αlis a real number and α1 (cid:2) α2 (cid:2)· · · (cid:2) αm. Each voter awards α1 points to its most-preferred alternative, α2 to its second-most-preferred alternative, etc.Predictably, the alternative with the most points wins. Under this unified framework, we can express our three rules as:✩This paper subsumes two earlier conference papers [A.D. Procaccia, A. Zohar, Y. Peleg, J.S. Rosenschein, Learning voting trees, in: Proceedings of the 22ndAAAI Conference on AI (AAAI), 2007, pp. 110–115; A.D. Procaccia, A. Zohar, J.S. Rosenschein, Automated design of scoring rules by learning from examples,in: Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2008, pp. 951–958].* Corresponding author.E-mail addresses: arielpro@gmail.com (A.D. Procaccia), avivz@cs.huji.ac.il (A. Zohar), jonip@cs.huji.ac.il (Y. Peleg), jeff@cs.huji.ac.il (J.S. Rosenschein).1 The author was supported in this work by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.003\f1134A.D. Procaccia et al. / Artificial Intelligence 173 (2009) 1133–1149Fig. 1. A binary voting tree.• Plurality: (cid:3)α = (cid:4)1, 0, . . . , 0(cid:5).• Borda: (cid:3)α = (cid:4)m − 1, m − 2, . . . , 0(cid:5).• Veto: (cid:3)α = (cid:4)1, . . . , 1, 0(cid:5).A good indication of the importance of scoring rules is given by the fact that they are exactly the family of voting rulesthat are anonymous (indifferent to the identities of the voters), neutral (indifferent to the identities of the alternatives), andconsistent (an alternative that is elected by two separate sets of voters is elected overall) [26].Voting trees. Some voting rules rely on the concept of pairwise elections: alternative a beats alternative b in the pairwiseelection between a and b if the majority2 of voters prefers a to b. Ideally, we would like to select an alternative that beatsevery other alternative in a pairwise election, but such an alternative (called a Condorcet winner) does not always exist.However, there are other prominent voting rules that rely on the concept of pairwise elections, which select an alterna-tive in a sense “close” to the Condorcet winner. In the Copeland rule, for example, the score of an alternative is the numberof alternatives it beats in a pairwise election; the alternative with the highest score wins. In the Maximin rule, the score ofan alternative is the number of votes it gets in its worst pairwise election (the least number of voters that prefer it to somealternative), and, predictably, the winner is the alternative that scores highest.When discussing such voting rules, it is possible to consider a more abstract setting. A tournament T over A is a com-plete binary asymmetric relation over A (that is, for any two alternatives a and b, aT b or bT a, but not both). Clearly, theaforementioned majority relation induces a tournament (a beats b in the pairwise election iff aT b). More generally, thisrelation can reflect a reality that goes beyond a strict voting scenario. For example, the tournament can represent a basket-ball league, where aT b if team a is expected to beat team b in a game. We denote the set of all tournaments over A byT = T ( A).So, for the moment let us look at (pairwise) voting rules as simply functions f : T → A. The most prominent class ofsuch functions is the class of binary voting trees. Each function in the class is represented by a binary tree, with the leaveslabeled by alternatives. At each node, the alternatives at the two children compete; the winner ascends to the node (soif a and b compete and aT b, a ascends). The winner-determination procedure starts at the leaves and proceeds upwardstowards the root; the alternative that survives to the root is the winner of the election.For example, assume that the alternatives are a, b, and c, and bT a, cT b, and aT c. In the tree given in Fig. 1, b beats aand is subsequently beaten by c in the right subtree, while a beats c in the left subtree. a and c ultimately compete at theroot, making a the winner of the election.Notice that we allow an alternative to appear in multiple leaves; further, some alternatives may not appear at all (so, forexample, a singleton tree is a constant function).Motivation and setting. We consider the following setting: an entity, which we refer to as the designer, has in mind a votingrule (which may reflect the ethics of a society). We assume that the designer is able, for each constellation of voters’preferences with which it is presented, to designate a winning alternative (perhaps with considerable computational effort).In particular, one can think of the designer’s representation of the voting rule as a black box that matches preference profilesto winning alternatives. This setting is relevant, for example, when a designer has in mind different properties it wants itsrule to satisfy; in this case, given a preference profile, the designer can specify a winning alternative that is compatible withthese properties.We would like to find a concise and easily understandable representation of the voting rule the designer has in mind. Werefer to this process as automated design of voting rules: given a specification of properties, or, indeed, of societal ethics, findan elegant voting rule that implements the specification. In this paper, we do so by learning from examples. The designer ispresented with different preference profiles, drawn according to a fixed distribution. For each profile, the designer answerswith the winning alternative. The number of queries presented to the designer must intuitively be as small as possible: thecomputations the designer has to carry out in order to handle each query might be complex, and communication might becostly.2 We will assume, for simplicity, an odd number of voters.\fA.D. Procaccia et al. / Artificial Intelligence 173 (2009) 1133–11491135Now, we further assume that the “target” voting rule the designer has in mind, i.e., the one given as a black box, isknown to belong to some family R of voting rules. We would like to produce a voting rule from R that is as “close” aspossible to the target rule.By “close,” we mean close with respect to the fixed distribution over preference profiles. More precisely, we would liketo construct an algorithm that receives pairs of the form (preferences, winner) drawn according to a fixed distribution Dover preferences, and outputs a rule from R, such that the probability according to D that our rule and the target rule agreeis as high as possible. We wish, in fact, to learn rules from R in the framework of the formal PAC (Probably ApproximatelyCorrect) learning model; a concise introduction to this model is given in Section 2.In this paper, we look at two options for the choic",
            {
                "entities": [
                    [
                        4224,
                        4252,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 302 (2022) 103602Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnalyzing Differentiable Fuzzy Logic OperatorsEmile van Krieken a,∗a Vrije Universiteit Amsterdam, Netherlandsb Civic AI Lab, Amsterdam, Netherlands, Erman Acar a,b, Frank van Harmelen aa r t i c l e i n f oa b s t r a c tArticle history:Received 10 June 2020Received in revised form 27 September 2021Accepted 28 September 2021Available online 7 October 2021Keywords:Fuzzy logicNeural-symbolic AILearning with constraintsThe AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature is weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning.We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionIn recent years, integrating symbolic and statistical approaches to Artificial Intelligence (AI) gained considerable attention [22,6]. This research line has gained further traction due to recent influential critiques on purely statistical deep learning [47,59], which has been the focus of the AI community in the last decade. While deep learning has brought many important breakthroughs in computer vision [8], natural language processing [61] and reinforcement learning [68], the concern is that progress will be halted if its shortcomings are not dealt with. Among these is the massive amounts of data that deep learning models need to learn even a simple concept. In contrast, symbolic AI can easily reuse concepts and can express domain knowledge using only a single logical statement. Finally, it is much easier to integrate background knowledge using symbolic AI.* Corresponding author.E-mail addresses: e.van.krieken@vu.nl (E. van Krieken), erman.acar@vu.nl (E. Acar), Frank.van.Harmelen@vu.nl (F. van Harmelen).https://doi.org/10.1016/j.artint.2021.1036020004-3702/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fE. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602However, symbolic AI has issues with scalability: dealing with large amounts of data while performing complex reasoning task, and is not able to deal with the noise and ambiguity of e.g. sensory data. The latter is related to the well-known symbol grounding problem which Harnad [30] defines as how “the semantic interpretation of a formal symbol system can be made intrinsic to the system, rather than just parasitic on the meanings in our heads”. In particular, symbols refer to concepts that have an intrinsic meaning to us humans, but computers manipulating these symbols cannot understand (or ground) this meaning. On the other hand, a properly trained deep learning model excels at modeling complex sensory data. These models could bridge the gap between symbolic systems and the real world. Therefore, several recent approaches [18,23,67,46,20]aim at interpreting symbols that are used in logic-based systems using deep learning models. These are among the first systems to implement “a hybrid nonsymbolic/symbolic system (...) in which the elementary symbols are grounded in (...) non-symbolic representations that pick out, from their proximal sensory projections, the distal object categories to which the elementary symbols refer.” Harnad [30].1.1. Reasoning and learning using gradient descentWe introduce Differentiable Fuzzy Logics (DFL) which aims to integrate reasoning and learning by using logical formulas expressing background knowledge. The symbols in these formulas are interpreted using a deep learning model of which the parameters are to be learned. DFL constructs differentiable loss functions based on these formulas that can be minimized using gradient descent. This ensures that the deep learning model acts in a manner that is consistent with the background knowledge as we can backpropagate towards the parameters of the deep learning model.To ensure loss functions are differentiable, DFL uses fuzzy logic semantics [41]. Predicates, functions and constants are interpreted using the deep learning model. By maximizing the degree of truth of the background knowledge using gradient descent, both learning and reasoning are performed in parallel. We can apply the loss functions constructed using DFL for more challenging machine learning tasks than purely supervised learning. These methods fall under the umbrella of weakly supervised learning [76]. For example, it can be used for semi-supervised learning [74,32] or to detect noisy or inaccurate supervision [19]. For such problems, DFL corrects the predictions of the deep learning model when it is logically inconsistent with the background knowledge.To further our understanding of such losses, we present in this paper an analysis of the choice of operators used to com-pute the logical connectives in DFL. For example, functions called t-norms are used to connect two fuzzy propositions [41]. Because they return the degree of truth of the event that both propositions are true, such t-norms generalize the classical conjunction. Similarly, a fuzzy implication generalizes the classical implication. Most of these operators are differentiable, which enable their use in DFL. Interestingly, the derivatives of these operators determine how DFL corrects the deep learn-ing model when its predictions are inconsistent with the background knowledge. We show that the qualitative properties of these derivatives are integral to both the theory and practice of DFL. We approach this problem both from the view of symbolic and of statistical approaches to AI, to bridge the conceptual gap between those views. This provides insights that otherwise would be overlooked.1.2. ContributionsThe main contribution of this article is to answer the following question: “What fuzzy logic operators for existential quan-tification, universal quantification, conjunction, disjunction and implication have convenient theoretical properties when using them in gradient descent?” We analyze both theoretically and empirically the effect of the choice of operators used to compute the logical connectives in Differentiable Fuzzy Logics on the learning behavior of a DFL system. To this end,• We introduce Differentiable Fuzzy Logics (Section 4) which combines fuzzy logic and gradient-based learning, and analyze its behavior over different choices of fuzzy logic operators (Section 3).• We analyze the theoretical properties of aggregation functions, which are used to compute the universal quantifier ∀and the existential quantifier ∃, t-norms and t-conorms which are used to compute the connectives ∧ and ∨, and fuzzy implications which are used to compute the connective →.• We introduce a new family of fuzzy implications called sigmoidal implications (Section 5) using the insights from these analyses.• We perform experiments to compare fuzzy logic operators in a semi-supervised experiment (Section 9).• We give several recommendations for choices of operators.2. Differentiable LogicsLoss functions are real-valued functions that represent a cost and must be minimized. Differentiable Logics (DL) are logics for which differentiable loss functions are constructed that compute the truth value of given formulas using the semantics of the logic. These logics use background knowledge to deduce the truth value of statements in unlabeled or poorly labeled data, allowing us to use such data during learning, possibly together with normal labeled data. This can be beneficial as unlabeled, poorly labeled and partially labeled data is cheaper and easier to come by. This approach differs from Inductive Logic Programming [54] which derives formulas from data. DL instead informs what the data could have been.2\fE. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 1. In this running example, we have an image with two objects on it, o1 and o2.We motivate the use of DL with the following classification scenario we consider throughout our analysis. Assume we have an agent A whose goal is to describe the scene on an image. It gets feedback from a supervisor S, who does not have an exact description of these images available. However, S does have a background knowledge base K about the concepts contained on the images. The intuition behind Differentiable Logics is that S can correct A’s descriptions of scenes when they are not consi",
            {
                "entities": [
                    [
                        3379,
                        3407,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1539–1558Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUncertainty modelling for vague concepts: A prototype theory approachJonathan Lawry a,∗, Yongchuan Tang ba Department of Engineering Mathematics, University of Bristol, Bristol BS8 1TR, UKb College of Computer Science, Zhejiang University, Hangzhou 310027, PR Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 April 2008Received in revised form 28 July 2009Accepted 29 July 2009Available online 5 August 2009Keywords:Epistemic vaguenessPrototype theoryLabel semanticsRandom sets1. IntroductionAn epistemic model of the uncertainty associated with vague concepts is introduced.Label semantics theory is proposed as a framework for quantifying an agent’s uncertaintyconcerning what labels are appropriate to describe a given example. An interpretationof label semantics is then proposed which incorporates prototype theory by introducinguncertain thresholds on the distance between elements and prototypes for descriptionlabels. This interpretation naturally generates a functional calculus for appropriatenessmeasures. A more general model with distinct threshold variables for different labels isdiscussed and we show how different kinds of semantic dependence can be captured inthis model.© 2009 Elsevier B.V. All rights reserved.Natural language is a powerful, flexible and robust mechanism for communicating ideas, concepts and information. Yetthe meaning conveyed by even simple words is often inherently uncertain. This uncertainty is reflected in the variation andinconsistency in the use of words by different individuals. For example, Parikh [30] reports an experiment where a sampleof people are shown a chart with different coloured squares and asked to count the number of red and the number ofblue squares. The results differ significantly across the group. Similar inconsistencies in the use of colour categories are alsodescribed in the work of Belin and Kay [1] and Kintz et al. [20]. We believe that this uncertainty about the appropriate useof words arises as a natural consequence of the distributed and case-based manner by which an understanding of languageis acquired.Language is, to a large degree, learnt through the experience of our interactions with other speakers from which wecan make inferences about the implicit rules and conventions of language use [29]. Exposure to formal grammar rules andexplicit dictionary definitions comes relatively late in our education and requires a priori a basic vocabulary on the part ofthe student. It is perhaps not surprising then that such a process results in significant semantic uncertainty. We cannot real-istically expect that the boundaries of linguistic concepts, as perhaps represented by their extensions in a multi-dimensionalconceptual space [11], should be precisely and unambiguously defined by a finite set of often conflicting examples. It isour view then, that the uncertainty about word meanings which naturally result from such an empirical learning process isthe underlying source of concept vagueness. Consequently we adopt an epistemic perspective on vagueness, to some extentin accordance with the views of Williamson [37], whereby crisp concept boundaries are assumed to exist but where theirprecise definition is uncertain. Furthermore, as pointed out by Parikh [29,30], empirical learning requires extrapolation frompreviously encountered examples of word use to other new but similar cases. Hence, the notion of similarity is also funda-mental to any model of vagueness. Prototype theory [32,33] provides a powerful tool to understand the role of typicalityin concept definitions, resulting in a natural ordering on possible exemplars of concepts e.g. Bill is taller than Mary, but* Corresponding author.E-mail addresses: j.lawry@bris.ac.uk (J. Lawry), tyongchuan@gmail.com (Y. Tang).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.07.006\f1540J. Lawry, Y. Tang / Artificial Intelligence 173 (2009) 1539–1558Mary is richer than Bill. In this paper we attempt to provide a formal framework for representing the epistemic uncertaintyassociated with vague concepts, which incorporates elements of prototype theory.The modelling of concept vagueness in Artificial Intelligence has been dominated by ideas from fuzzy set theory asoriginally proposed by Zadeh [38]. In that approach the extension of a concept is represented by a fuzzy set which has agraded characteristic or membership function with values ranging between 0 and 1. This allows for intermediate membership(values in (0, 1)) in vague concepts resulting in intermediate truth values for propositions involving vague concepts (fuzzylogic). The calculus for fuzzy set theory is truth-functional which means that the full complement of Boolean laws cannot allbe satisfied [4].1 Furthermore, fuzzy set theory and fuzzy logic do not in their narrowest manifestations adopt an epistemicview of vagueness. Hájek [14], for example, argues that membership values of fuzzy categories are primitives quantifyinggradedness of membership according to which it is meaningless to refer to unknown or uncertain crisp boundaries of vagueconcepts, since such boundaries are inherently fuzzy. On the other hand, many of the proposed interpretations of fuzzy setsimplicitly adopt an epistemic position. In particular, the random set model of fuzzy sets (see [12,13] and [27]) according towhich fuzzy set membership functions correspond to single point coverage functions of a random set, inherently assumesthe existence of an uncertain but crisp set representing the extension of a vague concept. The basis of the label semanticstheory [21] outlined in this paper is also a random set model of vagueness but where the intention is to quantify uncertaintyconcerning the applicability or appropriateness of labels to describe a given example. Such a theory cannot result in a truth-functional calculus but can be functional in a weaker sense in the presence of certain assumptions concerning the semanticdependence between labels.A principal motivation for this paper is to explore the relationship between prototype theory and label semantics. Hence,there will be a focus on mathematical results demonstrating a clear link between these two theories in the case whencategorization (labeling) involves thresholding of a measure of similarity to prototypes. Furthermore, we will argue froman Artificial Intelligence perspective, that the proposed framework could be a suitable model for rational intelligent agentswho use concept labels and label expressions to describe elements of their environment with the aim of communicatinginformation to their fellow agents.An outline of the paper is as follows: Section 2 describes a variant of the epistemic theory of vagueness which providesthe philosophical underpinnings for the formal models we propose [23]. Section 3 provides an overview of label semanticsas first proposed in [21] and [22]. Section 4 discusses the relationship between prototype theory, typicality, uncertainty andvagueness. Section 5 describes a new prototype theory interpretation of label semantics and finally Section 6 gives someconclusions and possible directions for future work.2. An epistemic theory of vaguenessIn our everyday use of language we are continually faced with decisions about the best way to describe objects andinstances in order to convey the information we intend. For example, suppose you are witness to a robbery, how shouldyou describe the robber so that police on patrol in the streets will have the best chance of spotting him? You will havecertain labels that can be applied, for example tall, short, medium, fat, thin, blonde, etc., some of which you may view asinappropriate for the robber, others perhaps you think are definitely appropriate while for some labels you are uncertainwhether they are appropriate or not. On the other hand, perhaps you have some ordered preferences between labels so thattall is more appropriate than medium which is in turn more appropriate than short. Your choice of words to describe therobber should surely then be based on these judgments about the appropriateness of labels. Yet where does this knowledgecome from and more fundamentally what does it actually mean to say that a label is or is not appropriate? In the sequelwe shall propose an interpretation of vague description labels based on a particular notion of appropriateness and suggesta measure of subjective uncertainty resulting from an agent’s partial knowledge about what labels are appropriate to assert.Furthermore, we will suggest that the vagueness of these description labels lies fundamentally in the uncertainty about ifand when they are appropriate as governed by the rules and conventions of language use.‘The robber is blonde’) or to agree to a classification (e.g.It seems undeniable that humans posses some kind of mechanism for deciding whether or not to make certain assertions(e.g.‘Yes he was tall’). Furthermore, although the underlyingconcepts are often vague the decisions about assertions are, at a certain level, bivalent. That is to say for a particularexample x and description θ , you are either willing to assert that ‘x is θ ’ or not. Of course in general this decision maydepend on many factors associated with the context in which the communication is taking place. For example, you arelikely to be much more cautious in your use of language when describing a robber to the police than in describing acolleague to a close friend. Also, your motives may be much more complex than purely to communicate information. Forexample, you may have recognized the robber as a family member so that your aim when describing him is to throw thepolice off the scent. Nonetheless, there seems to be an underlying assumption that some things can be correctly assertedwhile others cannot. Exactly where t",
            {
                "entities": [
                    [
                        4008,
                        4036,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 953–982www.elsevier.com/locate/artintBackward-chaining evolutionary algorithmsRiccardo Poli ∗, William B. LangdonDepartment of Computer Science, University of Essex, UKReceived 12 August 2005; received in revised form 11 April 2006; accepted 24 April 2006Available online 9 June 2006AbstractStarting from some simple observations on a popular selection method in Evolutionary Algorithms (EAs)—tournamentselection—we highlight a previously-unknown source of inefficiency. This leads us to rethink the order in which operations areperformed within EAs, and to suggest an algorithm—the EA with efficient macro-selection—that avoids the inefficiencies associ-ated with tournament selection. This algorithm has the same expected behaviour as the standard EA but yields considerable savingsin terms of fitness evaluations. Since fitness evaluation typically dominates the resources needed to solve any non-trivial problem,these savings translate into a reduction in computer time. Noting the connection between the algorithm and rule-based systems,we then further modify the order of operations in the EA, effectively turning the evolutionary search into an inference process op-erating in backward-chaining mode. The resulting backward-chaining EA creates and evaluates individuals recursively, backwardfrom the last generation to the first, using depth-first search and backtracking. It is even more powerful than the EA with efficientmacro-selection in that it shares all its benefits, but it also provably finds fitter solutions sooner, i.e., it is a faster algorithm. Thesealgorithms can be applied to any form of population based search, any representation, fitness function, crossover and mutation,provided they use tournament selection. We analyse their behaviour and benefits both theoretically, using Markov chain theory andspace/time complexity analysis, and empirically, by performing a variety of experiments with standard and back-ward chainingversions of genetic algorithms and genetic programming.© 2006 Elsevier B.V. All rights reserved.Keywords: Evolutionary computation; Genetic algorithm; Genetic programming; Efficient search; Backward chaining; Tournament selection1. IntroductionEvolutionary Algorithms (EAs) (see Algorithm 1) are a simple and, today, very popular form of search and opti-misation technique [1,2,6,13,21,22]. Their invention dates back many decades [11,14,18,34,40] (and see also [10]).EAs share several ingredients with mainstream AI search techniques. For example, EAs can be seen as special kindsof generate-and-test algorithms, as parallel forms of beam search, etc. (see [26] for a discussion on similarities anddifferences between EAs and other search algorithms). However, their development has been largely in parallel andindependent from AI search.Despite the simplicity of EAs, sound theoretical models of EAs and precise mathematical results have been scarceand hard to obtain, often emerging many years after the proposal of the original algorithm [7,15,16,19,24,25,28–31,* Corresponding author.E-mail addresses: rpoli@essex.ac.uk (R. Poli), wlangdon@essex.ac.uk (W.B. Langdon).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.04.003\f954R. Poli, W.B. Langdon / Artificial Intelligence 170 (2006) 953–982Select sub-population for reproductionRecombine the genes of selected parents1: Initialise population2: Evaluate population3: loop4:5:6: Mutate the offspring stochastically7:8:9: end loopEvaluate the fitness of the new populationIf stopping criterion is satisfied then exit loopAlgorithm 1. Generic evolutionary algorithm.36–39,42–44,47]. An important reason for this delay is that each algorithm, representation, set of genetic operatorsand, in some cases, fitness function requires a different theoretical model. In addition, the randomness, non-linearitiesand immense number of degrees of freedom present in a typical EA make life very hard for theoreticians.One line of theoretical research where differences in representations have not been an obstacle is the analysis ofselection algorithms (step 4 in Algorithm 1). This is because selection requires only knowledge of the fitness (orphenotype) of the individuals in the population, and so the same form of selection can be applied irrespective of therepresentation of an individual (or genotype).Different selection methods have been analysed mathematically in depth in the last decade or so. The main empha-sis of previous research has been the takeover time [12], i.e., the time required by selection to fill up the populationwith copies of the best individual in the initial generation, and the evaluation of the changes produced by selection onthe fitness distribution of the population [4,5,23]. In this second line of research, the behaviour of selection algorithmsis characterised using the loss of diversity, i.e., the proportion of individuals in a population that are not selected.These theoretical studies are very comprehensive and appeared to have completely characterised selection, funda-mentally making it a largely understood process. However, starting from some simple observations on the samplingbehaviour of perhaps the most popular selection method, tournament selection, in this paper we show that there is apossible source of inefficiency in EAs. This phenomenon, which had not been analysed in previous research, has verydeep implications, its analysis effectively leading to a completely new class of EAs which is more powerful and closerin spirit to classical AI techniques than traditional EAs.The paper is organised as follows. In Section 2 we describe tournament selection, we briefly review previousrelevant theoretical results, and then go on to describe, in Section 3, the sampling inefficiency in this form of selection.In order to remove the predicted sampling inefficiency of tournament selection, in Section 4, we rethink the orderin which operations are performed within EAs. This reveals that, embedded in EAs, is a graph-structure induced bytournament selection which connects individual samples of the search space across time. (See Fig. 1 in Section 4.)We are then able to suggest an algorithm, the EA with efficient macro-selection, that exploits this graph to remove theinefficiencies associated with tournament selection. The algorithm has the same expected behaviour as the standardEA, while providing considerable savings in terms of fitness evaluations. Furthermore, it is totally general, i.e., it canbe applied to any representation and fitness function, and can be used with any crossover and mutation.In Section 5, we note an unexpected connection between the operations of the EA with efficient macro-selectionand rule-based systems, which leads us to further modify the order of operations in the EA effectively turning theevolutionary search into an inference process operating in backward-chaining mode. The resulting algorithm, whichwe call a backward-chaining EA, creates and evaluates individuals recursively. It starts at the last generation and, usingdepth-first search and backtracking, works backwards to the first. This algorithm is even more powerful than the EAwith efficient macro-selection in that it shares all its benefits, but it provably finds fitter solutions sooner, i.e., it is afaster algorithm.We analyse theoretically the behaviour of the EA with efficient macro-selection and the backward chaining EAalgorithms in Section 6. In particular, in Section 6.1 we start analysing the sampling behaviour of tournament se-lection, focusing on its effects over one time step (a generation) of an EA. We do this by noting and exploiting thesimilarity between sampling and the coupon collection problem. We extend the one-generation analysis to full runs inSection 6.2 by inventing, and then modelling mathematically using Markov chain theory, a more complex version ofthe problem—the iterated coupon collection problem—which exactly mimics tournament selection over multiple gen-erations. This allows us to fully and exactly evaluate the effects of the sampling inefficiency of tournament selectionover entire runs and indicates that extent of the savings that could be achieved.\fR. Poli, W.B. Langdon / Artificial Intelligence 170 (2006) 953–982955We discuss the details of the practical implementation of a backward-chaining EA in Section 7 while we comparethe time and space complexity of our implementation with those for a standard EA in Section 8. In Section 9 weprovide experimental results with a Genetic Algorithm (GA) and a Genetic Programming (GP) implementation ofbackward chaining EA. We discuss our findings in Section 10 and provide our conclusions in Section 11.2. Tournament selectionTournament selection is one of the most popular forms of selection in EAs. In its simplest form, a group of nindividuals is chosen randomly uniformly from the current population, and the one with the best fitness is selected(e.g., see [2]). The parameter n is called the tournament size and can be used to vary the selection pressure exerted bythis method (the higher n the higher the pressure to select above average quality individuals).In a population of size M, the takeover time is defined as the number of generations required for selection (whenno other operator is present) to obtain a population containing M − 1 copies of the best individual in the initialgeneration [12]. In [12] the takeover time for tournament selection was estimated using the asymptotic expressiont∗ = 1ln n(cid:2)ln(M) + ln(cid:4)(cid:5)(cid:3)ln(M)where the approximation improves as the population size M → ∞.The loss of (fitness) diversity is the proportion of individuals of a population that is not selected during the selectionphase. Assuming every member of the population has a unique fitness, the loss of diversity pd for tournament selectionwas estimated in [4,5] aspd = n− 1n−1 − n− nn−1 ,and later calculated exactly in [23] as(cid:7)pd = 1MM(cid",
            {
                "entities": [
                    [
                        3235,
                        3263,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 191–192 (2012) 61–95Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGAMoN: Discovering M-of-Nlattice-based Genetic Algorithm{¬,∨}hypotheses for text classification by aVeronica L. Policicchio∗, Adriana Pietramala, Pasquale RulloDept. of Mathematics, University of Calabria, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 16 November 2011Received in revised form 4 July 2012Accepted 11 July 2012Available online 20 July 2012{¬,∨}While there has been a long history of rule-based text classifiers, to the best of ourknowledge no M-of-N-based approach for text categorization has so far been proposed.In this paper we argue that M-of-N hypotheses are particularly suitable to model the textclassification task because of the so-called “family resemblance” metaphor: “the members(i.e., documents) of a family (i.e., category) share some small number of features, yet thereis no common feature among all of them. Nevertheless, they resemble each other”. Startingfrom this conjecture, we provide a sound extension of the M-of-N approach with negation, which enables to best fit the true structure of the data.and disjunction, called M-of-Nhypothesis space hasBased on a thorough theoretical study, we show that the M-of-Ntwo partial orders that form complete lattices.GAMoN is the task-specific Genetic Algorithm (GA) which, by exploiting the lattice-basedstructure of the hypothesis space, efficiently induces accurate M-of-NBenchmarking was performed over 13 real-world text data sets, by using four ruleinduction algorithms: two GAs, namely, BioHEL and OlexGA, and two non-evolutionaryalgorithms, namely, C4.5 and Ripper. Further, we included in our study linear SVM, as itis reported to be among the best methods for text categorization. Experimental resultsdemonstrate that GAMoN delivers state-of-the-art classification performance, providinga good balance between accuracy and model complexity. Further, they show that GAMoNcan scale up to large and realistic real-world domains better than both C4.5 and Ripper.hypotheses.{¬,∨}{¬,∨}© 2012 Elsevier B.V. All rights reserved.1. IntroductionAn M-of-N hypothesis, also called Boolean threshold function, may be thought of intuitively as follows. Given a set of Nfeatures, whenever an example satisfies at least M of such features, it is a positive example; otherwise, it is a negative one.That is, an M-of-N hypothesis is a description that involves “counting properties”. There is quite a literature on methodsfor building M-of-N hypotheses. For instance, in [1] algorithms for extracting M-of-N hypotheses from neural networks arereported. M-of-N concepts are also constructed as tests for the induction of decision trees [2–5,7].However, to the best of our knowledge, no M-of-N-based approach for text classification has been so far proposed.Despite this, we conjecture that M-of-N hypotheses are well suited to model the text classification task.Text categorization (TC) is aimed at assigning natural language texts to one or more thematic categories on the basis oftheir contents. It is a difficult task essentially because of two main factors: on one hand, TC has to do with the complexityand richness of the natural language, which allows a concept to be expressed by a variety of constructs and words. Thisaspect is often amplified by the presence in a category of documents which are not about a single narrow subject with* Corresponding author.E-mail address: policicchio@mat.unical.it (V.L. Policicchio).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.003\f62V.L. Policicchio et al. / Artificial Intelligence 191–192 (2012) 61–95limited vocabulary. On the other hand, the TC task deals with highly dimensional data sets (i.e., with many features).Both such factors concur to make quite unlikely the existence of a set of features, or even a single feature, that occur inall documents of a given category. It may even happen that documents that belong to the same category do not shareany content words. However, as argued in [6], the relationship of “family resemblance” holds. That is, documents underthe same category share a (usually small) set of N features, yet this set is not present in every document. Instead, eachdocument contains (at least) M (cid:2) N of such features, and different documents may not share features at all. That is, the textclassification task deals with the kind of data that M-of-N hypotheses are able to explain.A shortcoming of the M-of-N approach, however, is that its propositions handle positive information only, whereasnegative evidence is deemed to play a crucial role in text categorization. This is mainly because natural languages areintrinsically ambiguous, and negation helps to disambiguate concepts – e.g., the word “ball” may ambiguously refer toeither the concept “sport” or “dance”, whereas the conjunction “ball and not ballroom” much likely refers to “sport”.To overcome this drawback, we extend classical M-of-N hypotheses by negation. In addition, to best fit the true structureof the data, we allow disjunctions of hypotheses. That is, we define a new hypothesis language for text classification, called, which generalizes the classical M-of-N language through negation and disjunction (a preliminary descriptionM-of-Nof the proposed approach can be found in [8]).{¬,∨}In our approach, a classifier is a propositional formula of the form Hc = H1c= pi-of-Pos ∧¬ni-of-Neg is an atom (note that all atoms forming Hc share the same sets Pos and Neg). Here, Pos is the set of positiveterms, Neg the set of negative terms, and pi (cid:3) 0 and ni > 0 are integers called thresholds. The meaning of an atom Hic is:classify document d under category c if at least pi positive terms occur in d and (strictly) less than ni negative terms occurprovides support for explicitly modeling the interactions between positive and negative features.in d. That is, M-of-NOf course, Hc classifies document d under c if any of H1c classifies d under c.c , where each Hic , . . . , Hr∨ · · · ∨ Hr{¬,∨}c{¬,∨}where a hypothesis is an atom with thresholds p = n = 1 is OlexGA [10].The special case of M-of-NThere is a natural ordering in the space of M-of-N{¬,∨}hypotheses determined by two kinds of subsumption relation-ships: the feature and the threshold relationships. The feature relationship is determined by the feature sets Pos and Negappearing in a classifier Hc . As an example, assume that Hc is the atomic classifier p-of-Pos ∧ ¬n-of-Neg, with p = 2 andn = 1. Clearly, the larger Pos, the higher the probability that the condition “at least two positive features occur in a docu-ment” is satisfied. Dually, the smaller Neg, the more likely a document will contain no negative feature in Neg. In summary,the larger Pos, the smaller Neg, the more general Hc . The threshold relationship, in turn, is determined by the thresh-olds appearing in Hc . For an instance, if in the above classifier we replace p = 2 by p = 1, we get a new classifier whichis more general than the previous one – intuitively, only one instead of two positive features is necessary for classifyinga document. These relationships define two hierarchies of hypotheses (more precisely, complete lattices) exploitable for aneffective exploration of the hypothesis space. To this end, we provide suitable refinement operators whereby “navigating”the hypothesis lattices.As argued in [7], the evolutionary approach seems to be particularly suited for the M-of-N learning task, as the globalsearch style of GAs (as opposed to the “one-attribute-at-a-time” of the greedy approach) makes them capable of catching thehidden interactions among attributes that strongly characterize the induction of M-of-N hypotheses. However, the purelynon-deterministic nature of conventional genetic operators does not enable the search strategy to benefit of the structure ofthe hypothesis space. To overcome this drawback, we define a task-specific Genetic Algorithm (GA), called GAMoN, relyingon specialized evolutionary operators representing a stochastic implementation of the refinement operators defined over thesubsumption lattices. At a glance, the following are the main characteristics of GAMoN:• It relies on a variable-length individual representation, where each individual encodes a candidate classifier (Pittsburghapproach [9]).• It combines the standard search strategy of GAs with ad hoc generalizing/specializing (GS) reproduction operators whichexploit the structure of the hypothesis space.• It dynamically adapts the probability of selecting the GS operators over the standard ones.• It maintains a number of competing subpopulations.• It uses the F -measure to assess the fitness of an individual.Unlike in the classical approach, where the feature space is simply a subset of terms from the vocabulary, the one on whichGAMoN builds its hypotheses consists of both a set of positive and a set of negative candidate features. One main issue thatin general arises when inducing a classifier is that of selecting the appropriate dimensionality of the feature space, i.e., howmany features the classifier can access during the learning process. This is a very important design choice, as the qualityof the selected features strongly determines the quality of the learned classifier, especially in text classification, where datasets are usually highly dimensional, noisy and ambiguous. For most systems, the size of the feature space is managed asa tuning parameter, that is, the learning process is rerun over feature spaces of different dimensions and the best resultsare eventually taken. Unfortunately, this may require very long training times, especially over large data sets. To get overthis inconvenience, GAMoN was provided with techniques to automatically detect convenient dimensionality of the featurespace. This way, no manual feature selection is preliminar",
            {
                "entities": [
                    [
                        3650,
                        3678,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 198 (2013) 1–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProbability and timeMarco Zaffalon a,∗, Enrique Miranda ba Istituto Dalle Molle di Studi sull’Intelligenza Artificiale (IDSIA), Galleria 2, 6928 Manno (Lugano), Switzerlandb University of Oviedo, Department of Statistics and Operations Research, C – Calvo Sotelo, s/n, 33007 Oviedo, Spaina r t i c l ei n f oa b s t r a c tArticle history:Received 18 November 2011Received in revised form 17 December 2012Accepted 23 February 2013Available online 26 February 2013Keywords:Temporal reasoningImprecise probabilitiesConditioningLower previsionsSets of desirable gamblesCoherenceConglomerabilityProbabilistic reasoning is often attributed a temporal meaning,in which conditioningis regarded as a normative rule to compute future beliefs out of current beliefs andobservations. However, the well-established ‘updating interpretation’ of conditioning is notconcerned with beliefs that evolve in time, and in particular with future beliefs. On theother hand, a temporal justification of conditioning was proposed already by De Moivre andBayes, by requiring that current and future beliefs be consistent. We reconsider the latterapproach while dealing with a generalised version of the problem, using a behaviouraltheory of imprecise probability in the form of coherent lower previsions as well as ofcoherent sets of desirable gambles, and letting the possibility space be finite or infinite. Weobtain that using conditioning is normative, in the imprecise case, only if one establishesfuture behavioural commitments at the same time of current beliefs. In this case it isalso normative that present beliefs be conglomerable, which is a result that touches on along-term controversy at the foundations of probability. In the remaining case, where onecommits to some future behaviour after establishing present beliefs, we characterise theseveral possibilities to define consistent future assessments; this shows in particular thattemporal consistency does not preclude changes of mind. And yet, our analysis does notsupport that rationality requires consistency in general, even though pursuing consistencymakes sense and is useful, at least as a way to guide and evaluate the assessment process.These considerations narrow down in the special case of precise probability, because thisformalism cannot distinguish the two different situations illustrated above: it turns out thatthe only consistent rule is conditioning and moreover that it is not rational to be willing tostick to precise probability while using a rule different from conditioning to compute futurebeliefs; rationality requires in addition the disintegrability of the present-time probability.© 2013 Elsevier B.V. All rights reserved.1. Introduction1.1. What has time to do with probability?We are interested in probability understood in the subjective tradition: as an uncertainty formalism that allows you1to express beliefs and do rational reasoning. Conditioning is an important component to reason with probability. In fact,the computation of conditional beliefs (i.e., expectations or probabilities) is taken by some researchers as ‘the’ procedureto obtain future rational beliefs out of current beliefs and observations, as if the Bayesian calculus—and Bayes’ rule inparticular—had captured the essence of the reasoning process itself through time.* Corresponding author.E-mail addresses: zaffalon@idsia.ch (M. Zaffalon), mirandaenrique@uniovi.es (E. Miranda).1 We follow Good, de Finetti and Walley in referring to ‘you’ as the subject that holds some probabilistic assessments.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.005\f2M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Is this view justified? To see whether this is the case, it is useful to go back at the foundations of probability. As ithas been well documented by Shafer [54,55], De Moivre and Bayes provided, already in the 18th century, an argument forthe temporal use of conditioning: it relies on constructing two bets, at present and future times, that jointly yield you asure loss if you do not use conditioning to compute your future beliefs. This is, in other words, a (Dutch) book argumentapplied through time. The approach is not uncontroversial2 and it may well clash with one’s intuition: in fact, from thetemporal-book argument it follows that once you have established your initial beliefs, your future rational behaviour willbe ‘mechanically’ determined. Should this be the case, should you not be allowed to change your mind?Nowadays, well-established approaches to probability seem to have taken a more cautious approach to defining the roleof conditioning; this caution de facto corresponds to eliminating time from the picture. The so-called updating interpretationof conditioning reads as follows: “your expectation of a gamble (i.e., a bounded random variable) f : Ω → R, conditional onevent B from a partition B of the possibility space Ω , represents yourcurrent beliefs about f under the assumption that Boccurs and that you obtain no other relevant information about Ω ”. The crucial word in the previous phrase is ‘current’: itmeans that under the updating interpretation, conditional beliefs are beliefs that you hold now; moreover, there is nothingin that phrase that relates your current conditional beliefs with the behaviour you will adopt once, and if, B occurs. Inthis view, Bayes’ rule loses its temporal flavor and reveals a simpler nature, that of a consistency requirement between yourcurrent conditional and unconditional beliefs: in fact, Bayes’ rule can be made to follow from the traditional book argument,the one that is applied to beliefs held at the same point in time.Yet, part of the literature has kept on exploring the relationship between probability and time, in the spirit of De Moivreand Bayes’ original intuition: this is the case, for instance, of the philosophical work on ‘dynamic coherence’ started inthe seventies with Teller (who credited David Lewis for having originated the argument, see [62, Note 1 to Section 1.3])and that continued in the eighties with a number of papers [2,3,58–60]; Shafer’s work, we have already mentioned, wasalso concerned to some degree with temporal considerations [54,55]. More recent work by Shafer et al. [56] stresses suchan aspect even more: among other things, it shows that Walley’s generalisation of Bayes’ rule to sets of probabilities [67,Section 6.4] is temporally consistent in a game-theoretic sense [57].Some other tightly connected approach is the statistical work on ‘temporal coherence’ by Goldstein [21–24], and therelated one in philosophy by van Fraassen [65,66]. In our view the aim here is different, however, as the focus does notappear to be on relating present and future behaviour, but rather on widening present beliefs so as to encompass also beliefsabout future beliefs. The field of ‘belief revision’, originated in the work of Gärdenfors and colleagues [1,18], attempts alsoto deal with temporal considerations in probability, besides logic. Its connection with the temporal-book idea is weaker,though.1.2. ContributionsWe aim at making a thorough analysis about the extent to which De Moivre and Bayes’ intuition can be made to providea firm foundation for a temporal interpretation of probabilistic reasoning. To this end, we consider a framework madeof two time points: now, and a future one determined by the occurrence of an event B ∈ B. Accordingly, we considertwo uncertainty models: one that you hold at present time, that is, your current beliefs (we also call them your currentcommitments3), and another one that you will hold after B occurs. We call the latter your future commitments.Our approach to the problem initially makes no assumptions on the relationship between current and future commit-ments. We do not even force the analysis to focus on conditional beliefs: present beliefs are allowed to be generically madeboth of conditional and unconditional information. Rather, we let the relationship between current and future assessmentsemerge by itself by characterising what it means that current and future commitments are consistent. This will also revealwhether and when it is actually rational (or normative) for you to be self-consistent in time.We shall pursue our aims within the framework of imprecise probability, and in particular start our work using Walley’sbehavioural theory of coherent lower previsions [67]: this is an extension of de Finetti’s theory [12] to sets of probabilitiesthat is close to robust Bayesianism. De Finetti’s theory is based on the concept of a (linear) prevision, which is anothername for an expectation functional; a coherent lower prevision is a lower envelope of linear previsions, which is in one-to-one correspondence with a closed and convex set of finitely additive probabilities. These tools enable us to deal uniformlywith precise and imprecise probability, as well as with any cardinality of the possibility space Ω —which is then allowed tobe infinite. Section 2 provides an introduction to the theory that is conceived to make the work as self-contained as it ispossible in a research paper. It also discusses the alternative representation of coherent lower previsions in terms of a setof desirable gambles: this is the set of gambles that you find desirable (i.e., that you would accept if they were offered toyou) as a logical consequence of your probabilistic assessments. This helps us to convey the intuition behind the conceptsand the results we present. Section 3 describes our temporal framework in detail, and introduces your uncertainty modelsin the form of two coherent lower previsions for your present and future commitments, respectively.The core of our work starts in Section 4. We define a number of consistency notions for your curren",
            {
                "entities": [
                    [
                        3778,
                        3806,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 316 (2023) 103840Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintOn the robustness of sparse counterfactual explanations to adverse perturbationsMarco Virgolin a,∗a Evolutionary Intelligence Group, Centrum Wiskunde & Informatica, Science Park 123, 1098 XG Amsterdam, the Netherlandsb Department of Mathematics and Geosciences, University of Trieste, via Weiss 2, 34128 Trieste, Italy, Saverio Fracaros ba r t i c l e i n f oa b s t r a c tArticle history:Received 8 April 2022Received in revised form 25 November 2022Accepted 12 December 2022Available online 16 December 2022Keywords:Counterfactual explanationExplainable machine learningExplainable artificial intelligenceRobustnessUncertaintyCounterfactual explanations (CEs) are a powerful means for understanding how decisions made by algorithms can be changed. Researchers have proposed a number of desiderata that CEs should meet to be practically useful, such as requiring minimal effort to enact, or complying with causal models. In this paper, we consider the interplay between the desiderata of robustness (i.e., that enacting CEs remains feasible and cost-effective even if adverse events take place) and sparsity (i.e., that CEs require only a subset of the features to be changed). In particular, we study the effect of addressing robustness separately for the features that are recommended to be changed and those that are not. We provide def-initions of robustness for sparse CEs that are workable in that they can be incorporated as penalty terms in the loss functions that are used for discovering CEs. To carry out our experiments, we create and release code where five data sets (commonly used in the field of fair and explainable machine learning) have been enriched with feature-specific anno-tations that can be used to sample meaningful perturbations. Our experiments show that CEs are often not robust and, if adverse perturbations take place (even if not worst-case), the intervention they prescribe may require a much larger cost than anticipated, or even become impossible. However, accounting for robustness in the search process, which can be done rather easily, allows discovering robust CEs systematically. Robust CEs make ad-ditional intervention to contrast perturbations much less costly than non-robust CEs. We also find that robustness is easier to achieve for the features to change, posing an impor-tant point of consideration for the choice of what counterfactual explanation is best for the user. Our code is available at: https://github .com /marcovirgolin /robust -counterfactuals.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionModern Artificial Intelligence (AI) systems often rely on machine learning models such as ensembles of decision trees and deep neural networks [1–3], which contain from thousands to billions of parameters. These large models are appealing because, under proper training and regularization regimes, they are often unmatched by smaller models [4,5]. However, as large models perform myriads of computations, it can be very difficult to interpret and predict their behavior. Because of this, large models are often called black-box models, and ensuring that their use in high-stakes applications (e.g., of medicine and finance) is fair and responsible can be challenging [6,7].* Corresponding author.E-mail address: marco.virgolin@cwi.nl (M. Virgolin).https://doi.org/10.1016/j.artint.2022.1038400004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM. Virgolin and S. FracarosArtificial Intelligence 316 (2023) 103840The field of eXplainable AI (XAI) studies methods to dissect and analyze black-box models [8,9] (as well as methods to generate interpretable models when possible [10]). Famous methods of XAI include feature relevance attribution [11,12], explanation by analogy with prototypes [13,14], and, of focus in this work, counterfactual explanations. Counterfactual explanations enable to reason by contrast rather than by analogy, as they show in what ways the input given to a black-box model needs to be changed for the model to make a different decision [15,16]. A classic example of counterfactual explanation is: “Your loan request has been rejected. If your salary was 60 000$ instead of 50 000$ and your debt was 2500$ instead of 5000$, your request would have been approved.” A user who obtains an unfavorable decision can attempt to overturn it by intervening according to the counterfactual explanation.Normally, the search of counterfactual explanations is formulated as an optimization problem (see Sec. 2.1 for a formal description). Given the feature values that describe the user as starting point, we seek the minimal changes to those feature values that result in a point for which the black-box model makes a different (and oftentimes, a specific favorable) deci-sion. We wish the changes to be minimal for two reasons: one, to learn about the behavior of the black-box model for a neighborhood of data points, e.g., to assess its fairness (although this is not guaranteed in general, see e.g., [17]); two, in the hope that putting the counterfactual explanation into practice by means of real-life intervention will require minimal effort too. For counterfactual explanations to be most useful, more desiderata than requiring minimal feature changes may need to be taken into account (see Sec. 9) [18].In this paper, we consider a desideratum that can be very important for the usability of counterfactual explanations: ro-bustness to adverse perturbations. By adverse perturbations we mean changes in feature values that happen due to unforeseen circumstances beyond the user’s control, making reaching the desired outcome no longer possible, or requiring the user to put more effort than originally anticipated. These unforeseen circumstances can have various origins, e.g., time delays, mea-surement corrections, biological processes, and so on. For example, if a counterfactual explanation for improving a patient’s heart condition prescribes lowering the patient’s blood pressure, the chosen treatment may need to be employed for longer, or even turn out to be futile, if the patient has a genetic predisposition to resist that treatment (for more examples, see Sec. 5.1 and choices made in the coding of our experiments, in robust_cfe/dataproc.py).We show that, if adverse perturbations might happen, one can and should seek counterfactual explanations that are ro-bust to such perturbations. A particular novelty of our work is that we distinguish between whether perturbations impact the features that counterfactual explanations prescribe to change or keep as they are (note that some features may be irrele-vant and can be changed differently than how prescribed by a counterfactual explanation, we address this in Sec. 2.3). This is because counterfactual explanations are normally required to be sparse in terms of the intervention they prescribe (i.e., only a subset of the features should be changed), for better usability (see Sec. 2.1). As it will be shown, making this discrim-ination allows to improve the effectiveness and efficiency with which robustness can be accounted for. Consequently, one might need to consider carefully which counterfactual explanation to pursue, based on whether they are robust to features to change or keep as they are.In summary, this paper makes the following contributions:1. We propose two workable definitions of robustness of counterfactual explanations that concern, respectively, the fea-tures prescribed to be changed and those to be kept as they are;2. We release code to support further investigations, where five existing data sets are annotated with perturbations and plausibility constraints that are tailored to the features and type of user seeking recourse;3. We provide experimental evidence that accounting for robustness is important to prevent adverse perturbations from making it very hard or impossible to achieve recourse through counterfactual explanations, when adverse perturbations are sampled from a distribution (i.e., they are not necessarily worst-case ones);4. We show that robustness for the features to change is far more reliable and computationally efficient to account for than robustness for the features to keep as they are;5. Additionally, we propose a simple but effective genetic algorithm that outperforms several existing gradient-free search algorithms for the discovery of counterfactual explanations. The algorithm supports plausibility constraints and imple-ments the proposed definitions of robustness.2. PreliminariesIn the following, we introduce preliminary concepts for reasoning about robustness of counterfactual explanations in a sparse sense. In particular, we (i) describe the problem statement of searching for counterfactual explanations, (ii) present the notions of perturbation and robustness in general terms, and (iii) introduce the definitions of C and K, which are sets that partition the features of a counterfactual explanation. The following Secs. 3 and 4 will then present the main contribution of this paper: notions of robustness that are tailored to sparse counterfactual explanations, i.e., specific to Cand K.2.1. Problem statementLet us assume we are given a point x = (x1, . . . , xd), where d is the number of features. Each feature takes values either in (a subset of) R, in which case we call it a numerical feature, or in (a subset of) N, in which case we call it a categorical2\fM. Virgolin and S. FracarosArtificial Intelligence 316 (2023) 103840feature. For categorical features, we use natural numbers as a convenient way to identify their categories, but disregard ordering. For example, for the categoric",
            {
                "entities": [
                    [
                        3591,
                        3619,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2270–2290Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlan recognition in exploratory domainsYa’akov Gal a,b,∗, Swapna Reddy b, Stuart M. Shieber b, Andee Rubin c, Barbara J. Grosz ba Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israelb School of Engineering and Applied Sciences, Harvard University, USAc TERC, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 1 March 2010Received in revised form 8 August 2011Accepted 11 September 2011Available online 3 October 2011Keywords:Plan recognitionUser modelingThis paper describes a challenging plan recognition problem that arises in environmentsin which agents engage widely in exploratory behavior, and presents new algorithmsfor effective plan recognition in such settings. In exploratory domains, agents’ actionsmap onto logs of behavior that include switching between activities, extraneous actions,and mistakes. Flexible pedagogical software, such as the application considered in thispaper for statistics education, is a paradigmatic example of such domains, but many othersettings exhibit similar characteristics. The paper establishes the task of plan recognitionin exploratory domains to be NP-hard and compares several approaches for recognizingplans in these domains, including new heuristic methods that vary the extent to whichthey employ backtracking, as well as a reduction to constraint-satisfaction problems. Thealgorithms were empirically evaluated on people’s interaction with flexible, open-endedstatistics education software used in schools. Data was collected from adults using thesoftware in a lab setting as well as middle school students using the software in theclassroom. The constraint satisfaction approaches were complete, but were an order ofmagnitude slower than the heuristic approaches. In addition, the heuristic approaches wereable to perform within 4% of the constraint satisfaction approaches on student data fromthe classroom, which reflects the intended user population of the software. These resultsdemonstrate that the heuristic approaches offer a good balance between performanceand computation time when recognizing people’s activities in the pedagogical domain ofinterest.© 2011 Published by Elsevier B.V.1. IntroductionIn this paper we report on the development and evaluation of algorithms for recognizing users’ plans in domains inwhich users engage in exploratory and error-prone behaviors. The challenges presented by these domains were madeevident by our work with students using open-ended computer software for learning statistics, but they arise in human–computer interaction more broadly.Indeed, developing technology is changing rote and monolithic interaction styles between computers and their users tomore flexible types of interactions that allow users to explore and interleave between different activities. Examples of theseflexible systems include interactive drawing tools [44], Integrated Development Environments (IDEs), collaborative writingassistants [4], computer games, and educational software [51].To be effective partners, these systems need to recognize the activities their users are carrying out and to use thatinformation to provide support in a way that guides users’ interactions effectively. For example, an intelligent drawing tool* Corresponding author at: School of Engineering and Applied Sciences, Harvard University, USA.E-mail address: gal@eecs.harvard.edu (Y. Gal).0004-3702/$ – see front matter © 2011 Published by Elsevier B.V.doi:10.1016/j.artint.2011.09.002\fY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902271may infer that several objects on the canvas are all representatives of the same class. When the user modifies an attributein one of the forms, the system will identify and duplicate this change in the other objects in the class. Another benefit ofrecognizing users’ activities in software is to provide assessments of user performance. Such capabilities in educational andpedagogical systems could increase teachers’ abilities to identify those students who are having difficulty.Classical approaches to plan recognition have assumed a goal-oriented agent whose activities are consistent with therecognizers’ knowledge base and who forms a single encompassing plan. In contrast, flexible systems allow users to followmultiple plans, interleave actions from different plans, and perform redundant actions; they also tolerate user mistakes.Thus, inferring users’ plans in these systems gives rise to a more complex sort of plan recognition problem.This paper presents several new algorithms for keyhole plan recognition in exploratory domains.1 The algorithms arepost-hoc, in that they infer plans from complete interaction sequences, rather than after each observed action, as in on-linerecognition [13]. The algorithms we present vary in completeness (that is, whether plans are guaranteed to be found) andcomputational complexity. We investigate the trade-off between completeness and complexity empirically, by comparingthe performance of different plan recognition algorithms on real-world data.Our empirical analysis uses an educational software system for statistics education. Educational software is increasinglydesigned to be open-ended and flexible in order to support the types of exploratory activities that facilitate students’learning experience. This gives students the resources to explore concepts in new ways, but their interactions may be erraticor unfocused, making it challenging to recognize plans. During the chaos of a lab session, it is impossible for teachers totrack each student’s progress. As a result it is difficult to adapt their teaching to their students’ work. Educational softwarethus provides an important domain for plan recognition. A well structured post-hoc representation of the plans behindstudents’ activities would enable teachers to make better pedagogical decisions in the classroom.The research we report used a commercial system called TinkerPlots, used world-wide to teach students in grades 4through 8 about statistics and mathematics [34]. Using TinkerPlots, students build stochastic models and generate pseudo-random samples to analyze the underlying probability distributions. Our study used four different problems for whichstudents interacted with TinkerPlots to model hypothetical situations and to determine the probability of events.Students’ interactions with TinkerPlots are complex. They may pursue multiple plans and interleave actions from differentplans. They may be confused about the appropriate plan to take, and they may make mistakes. These behaviors create achallenging domain for plan recognition algorithms. Any number of extraneous actions may be interleaved among thosethat are a part of a successful plan. In addition, actions that are crucial to successful plans may occur in almost any order.All of the algorithms presented in the paper compose (possibly non-contiguous) interaction sequences from users’ in-teractions into a series of interdependent tasks and sub-tasks. They infer students’ plans by comparing their interactionsequence to ideal solutions, or recipes, that were specified by domain experts. At the end of this process, the algorithmsoutput a hierarchical plan that explains the student’s strategy during the session. The algorithms separate those actions thatcontribute to solving the problem from extraneous actions and mistakes.This paper integrates and extends initial reports of past studies [23,43] and makes several contributions. First, it formallydefines the task of plan recognition in exploratory domains and provides a proof of its NP-completeness. Second, it presentsnew greedy and complete algorithms for solving the plan recognition problem in these domains, providing a formal com-plexity analysis of these algorithms and comparing them to existing methods. Third, it is the first work to evaluate planrecognition algorithms on real-world data in the domain of flexible pedagogical software.We compared two algorithmic approaches for recognizing users’ interactions. One of the approaches employed incom-plete greedy algorithms to attempt to build plans from the bottom-up. The complexity of one of these algorithms ispolynomial in the size of the interaction sequence, while the complexity of the other algorithm is exponential (in theworst case) in the size of this sequence. The second approach converts the recognition process to a Constraint SatisfactionProblem (CSP) using one of two methods. One of these methods builds a complete plan to recognize the entire interactionsequence. The other method works piecemeal in a way that uses subsets of the activity sequence to eliminate infeasibleplans before attempting to recognize the entire sequence. This second method was suggested by Quilici et al. [42] but firsttested empirically here. In contrast to the greedy approach, the constraint satisfaction approach is complete, in the sensethat if all of the recipes for solving a given TinkerPlots problem exist, and the student solved the problem, the algorithmis guaranteed to find the plan that explains the student’s interaction. The complexity of both of the complete methods isexponential in the size of both the interaction sequence and the data set containing ideal solutions.We conducted a number of empirical studies to evaluate the ability of these algorithms to recognize the plans used tosolve TinkerPlots problems. The studies involved two types of settings: adults using TinkerPlots in a lab setting, and middleschool students using TinkerPlots in a classroom setting. The results confirmed that the complete algorithms were able torecognize all plans when the relevant recipes for the TinkerPlots problems existed, and students were able to solve theproblems. However, there was a systematic difference between these two empirical settings and their effect on th",
            {
                "entities": [
                    [
                        3614,
                        3642,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 984–1006Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUnderstanding the scalability of Bayesian network inference using cliquetree growth curvesOle J. MengshoelCarnegie Mellon University, NASA Ames Research Center, Mail Stop 269-3, Moffett Field, CA 94035, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 16 January 2009Received in revised form 18 May 2010Accepted 18 May 2010Available online 25 May 2010Keywords:Probabilistic reasoningBayesian networksClique tree clusteringClique tree growthC/V -ratioContinuous approximationGompertz growth curvesControlled experimentsRegressionOne of the main approaches to performing computation in Bayesian networks (BNs) isclique tree clustering and propagation. The clique tree approach consists of propagationin a clique tree compiled from a BN, and while it was introduced in the 1980s, there isstill a lack of understanding of how clique tree computation time depends on variationsin BN size and structure. In this article, we improve this understanding by developingan approach to characterizing clique tree growth as a function of parameters that canbe computed in polynomial time from BNs, specifically: (i) the ratio of the number of aBN’s non-root nodes to the number of root nodes, and (ii) the expected number of moraledges in their moral graphs. Analytically, we partition the set of cliques in a clique treeinto different sets, and introduce a growth curve for the total size of each set. For thespecial case of bipartite BNs, there are two sets and two growth curves, a mixed cliquegrowth curve and a root clique growth curve. In experiments, where random bipartiteBNs generated using the BPART algorithm are studied, we systematically increase theout-degree of the root nodes in bipartite Bayesian networks, by increasing the numberof leaf nodes. Surprisingly, root clique growth is well-approximated by Gompertz growthcurves, an S-shaped family of curves that has previously been used to describe growthprocesses in biology, medicine, and neuroscience. We believe that this research improvesthe understanding of the scaling behavior of clique tree clustering for a certain class ofBayesian networks; presents an aid for trade-off studies of clique tree clustering usinggrowth curves; and ultimately provides a foundation for benchmarking and developingimproved BN inference and machine learning algorithms.© 2010 Elsevier B.V. All rights reserved.1. IntroductionBayesian networks (BNs) play a central role in a wide range of automated reasoning applications, including in diagnosis,sensor validation, probabilistic risk analysis, information fusion, and decoding of error-correcting codes [64,6,59,38,37,60,43,58]. A crucial issue in reasoning using BNs, as well as in other forms of model-based reasoning, is that of computationalscalability. Most BN inference problems are computationally hard in the general case [10,63,61,1], thus there may be rea-son to be concerned about scalability. One can make progress on the scalability question by studying classes of probleminstances analytically and experimentally. Such problem instances may come from applications or they may be randomlygenerated. In the area of application BNs, both encouraging and discouraging scalability results have been reported. Forexample, a prominent bipartite BN for medical diagnosis is known to be intractable using current technology [64]. Decodingof error-correcting codes, which can be understood as BN inference, is also not tractable but has empirically been found tobe solvable with high reliability using inexact BN inference [20,37]. On the other hand, it is well-known that BNs that areE-mail address: Ole.Mengshoel@sv.cmu.edu.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.007\fO.J. Mengshoel / Artificial Intelligence 174 (2010) 984–1006985tree-structured, including the so-called naive Bayes model, are solvable in polynomial time using exact inference algorithms.There are also encouraging empirical results for application BNs that are “close” to being tree-structured or more generallyfor application BNs that are not highly connected [26,43].Clique tree clustering, where inference takes the form of propagation in a clique tree compiled from a BN, is currentlyamong the most prominent BN inference algorithms [33,2,62]. The performance of tree clustering algorithms depends on aBN’s treewidth or the optimal maximal clique size of a BN’s induced clique tree [16,11,15]. The performance of other exactBN inference algorithms also depends on treewidth. A key research question is, then, how the size of a clique tree generatedfrom a BN (and consequently, inference time) depends on structural measures of BNs. One way to investigate this is throughthe use of random generation from distributions of problem instances [66,5,11,52,23]. Taking this approach, and increasingthe ratio C/V between the number of leaf nodes C and the number of root nodes V in bipartite BNs, an easy-hard-harderpattern along with approximately exponential growth have previously been observed for clique tree clustering for a certainclass of BNs, namely BPART BNs [45].In this article, we develop a more precise understanding of this easy-hard-harder pattern. This is done by formulatingmacroscopic and approximate models of clique tree growth by means of restricted growth curves, which we illustrate byusing bipartite BNs created by the BPARTalgorithm [45]. For the sake of this work, we assume that a clique tree propagationalgorithm, operating on a clique tree compiled from a BN, is executed in order to answer probabilistic queries of interest.We introduce a random variable for total clique tree size. This random variable is, for the case of bipartite BNs, the sum oftwo random variables, one for the size of root cliques and one for the size of mixed cliques. Reflecting the random variablefor total clique tree size, we introduce a continuous growth curve for total clique tree size which is the sum of growthcurves for the size of root cliques and mixed cliques. Of particular interest is the growth curve for root clique size, whereGompertz curves of the form g(∞)e, where g(∞), ζ , and γ are parameters, turn out to be useful. A key findingis that Gompertz growth curves are justified on theoretical grounds and also fit very well to experimental data generatedusing the BPART algorithm [45]. While we emphasize bipartite BNs in this article, we also discuss how to generalize toarbitrary BNs, by using multiple growth curves or translating arbitrary BNs to bipartite BNs via factor graphs [32,70].−ζ e−γ xFor experimentation, we sampled bipartite BNs using an implementation of the BPART algorithm. For the number ofroot nodes, V , we used V = 20 and V = 30. The number of leaf nodes was also varied, thereby creating BNs of varyinghardness; 100 BNs per C/V -level were randomly generated. A clique tree inference system, employing the minimum fill-inweight heuristic, was used to generate clique trees for the sampled BNs. Let W be a random variable representing thenumber of moral edges in moral graphs induced by random BNs. In addition to x = C/V , we consider x = E(W ) as anindependent variable. In experiments, we compared different growth curves and investigated x = C/V versus x = E(W ) asindependent variables for Gompertz growth curves. Linear regression was used to obtain values for the parameters ζ and γbased on a linear form of the Gompertz growth curve; values for g(∞) were obtained by analysis. Gompertz growth curvesare common in biological, medical, and neuroscience research [4,35,17], but have not previously been used to characterizeclique tree growth (except for in our earlier conference paper [41] which this article extends). We provide improved resultscompared to previous research, where an easy-hard-harder pattern and approximately exponential growth of upper boundson optimal maximal clique size as a function of C/V -ratio were established [45].We believe this research is significant for the following reasons. First, analytical growth curves improve the understand-ing of clique tree clustering’s performance for a certain class of BNs, namely BPART BNs. Consider Kepler’s three laws ofplanetary motion, developed using Brahe’s observational data of planetary movement. There is a need to develop similarlaws for clique tree clustering’s performance, and in this article we obtain such laws in the form of Gompertz growth curvesfor BPART BNs [45]. While they admittedly have a strong empirical basis, these Gompertz growth curves give significantlybetter fit to the raw data than alternative curves. Consequently, they provide better insight into the underlying mechanismsof the clique tree clustering algorithm and may be used to approximately predict the performance of the algorithm. Sincethe performance of other exact BN inference algorithms — including conditioning [55,11] and elimination algorithms [34,71,14] — also depends on optimal maximal clique size, our results may have significance for these algorithms as well. A sec-ond benefit of growth curves is that they can be used to summarize performance of different BN inference algorithms ordifferent implementations of the same algorithm on benchmark sets of problem instances, and thereby aid in evaluations.1Suppose that the growth curves g1(x) and g2(x) were obtained by benchmarking slightly different clique tree algorithms.Compared to looking at and evaluating potentially large amounts of raw data, it may be easier to understand the perfor-mance difference between the two algorithms by studying their curves g1(x) and g2(x) or by comparing their respectiveGompertz curve parameter values ζ1 and γ1 versus ζ2 and γ2. A third benefit is that growth curves provide estimates ofresource consumption in terms of clique tree size, estimates that can easily be translated into requirements on memo",
            {
                "entities": [
                    [
                        3856,
                        3884,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 180–181 (2012) 1–19Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintManipulating the quota in weighted voting games ✩Michael Zuckerman a, Piotr Faliszewski b, Yoram Bachrach c, Edith Elkind d,∗a School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israelb AGH University of Science and Technology, Krakow, Polandc Microsoft Research Ltd., Cambridge, United Kingdomd Division of Mathematical Sciences, School of Physical and Mathematical Sciences, Nanyang Technological University, Singaporea r t i c l ei n f oa b s t r a c tArticle history:Received 27 November 2010Received in revised form 28 December 2011Accepted 31 December 2011Available online 4 January 2012Keywords:Weighted voting gamesManipulationComplexityWeighted voting games provide a simple model of decision-making in human societiesand multi-agent systems. Such games are described by a set of players, a list of players’weights, and a quota; a coalition of the players is said to be winning if the total weight ofits members meets or exceeds the quota. The power of a player in a weighted voting gameis traditionally identified with her Shapley–Shubik index or her Banzhaf index, two classicpower measures that reflect the player’s marginal contribution under different coalitionformation scenarios. In this paper, we investigate by how much one can change a player’spower, as measured by these indices, by modifying the quota. We give tight bounds on thechanges in the individual player’s power that can result from a change in quota. We thendescribe an efficient algorithm for determining whether there is a value of the quota thatmakes a given player a dummy, i.e., reduces her power (as measured by both indices) to 0.We also study how the choice of quota can affect the relative power of the players. Finally,we investigate scenarios where one’s choice in setting the quota is constrained. We showthat optimally choosing between two values of the quota is complete for the complexityclass PP, which is believed to be significantly more powerful than NP. On the other hand,we empirically demonstrate that even small changes in quota can have a significant effecton a player’s power.© 2012 Elsevier B.V. All rights reserved.1. IntroductionCooperation and joint decision-making are key aspects of many interactions among self-interested agents. In such in-teractions, the collaborating agents may have different preferences, so they need a method to agree on a common courseof action. One possible solution to this problem is to use a voting procedure, and select a plan that is supported by amajority of voters. This approach to decision-making is very common in human societies and can be naturally extended tomulti-agent systems [12].Under majority voting, all agents have the same power. However, treating all voters as equals is not always appropriate:some of the agents may be more important for the task at hand than others, or contribute a larger amount of resources toit. Similarly, in parliamentary voting, some of the legislators may represent a larger constituency, and therefore should begiven more influence over the final outcome. This issue can be addressed by employing the machinery of weighted votinggames. In such games, each agent is associated with a nonnegative weight, and a subset (coalition) of agents is deemed to✩A preliminary version of this paper was presented at the Twenty Third AAAI Conference on Artificial Intelligence (AAAI-08).* Corresponding author.E-mail addresses: michez@cs.huji.ac.il (M. Zuckerman), faliszew@agh.edu.pl (P. Faliszewski), yorambac@gmail.com (Y. Bachrach), eelkind@ntu.edu.sg(E. Elkind).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.12.003\f2M. Zuckerman et al. / Artificial Intelligence 180–181 (2012) 1–19be winning if its weight meets or exceeds a given quota. The voter’s weight reflects her relative importance in the decision-making process: more important voters are assigned a higher weight. The quota is typically set to be slightly greater thanhalf of the total weight, but other values of quota (e.g., 2/3 of the total weight) are quite common as well.Even though weights are intended to model the agents’ relative importance, an agent’s ability to influence the groupdecision is not always directly proportional to her weight. For example, if the quota is so high that the only winningcoalition is the one that involves all agents, each agent can veto the decision, and hence all agents have equal power. Thus,to measure the power, instead of using agents’ weights, one typically employs one of the so-called power indices. Perhapsthe most prominent ones among them are the Shapley–Shubik index [41] and the Banzhaf index [11,6]. Intuitively, bothof these indices measure the probability that a given agent is critical to a forming coalition, i.e., that the coalition wouldbecome winning if the agent joined in; the difference between these two power indices comes from different coalitionformation models. Besides measuring the apriori voting power, the power indices can be used to share the payoff obtainedby executing the task: a natural approach is to pay each agent in proportion to their voting power, i.e., their Shapley–Shubikindex or their Banzhaf index. Also, in politics, power indices provide very useful information to lobbyists who need to decidehow to allocate their contributions.The importance of power indices makes them a natural target for manipulators, i.e., rogue parties that want to increaseor decrease the voting power of a certain agent.1 Now, accomplishing this goal by changing an agent’s weight may requirea substantial investment on the manipulator’s part, such as, e.g., recruiting additional supporters of a political party. Incontrast, it may be relatively easy to change the quota. Indeed, such changes are not unusual in political decision-making,and can be explained by the desire to build a consensus (if the quota is increased) or simplify the passage of bills (if thequota is decreased)—for instance, a recent move by Democratic members of the U.S. Senate to change the filibuster rules [22]can be viewed as an attempt to change the quota. Therefore, the entity that determines the format of the decision-makingprocedure (in what follows, we will refer to this entity as the central authority) might be able to change the quota withoutencountering substantial resistance. However, this seemingly innocent change may have very different effects on differentvoters, and therefore the central authority can use it to advance its own goals.In some settings, the quota may have to be updated in response to other changes in the voting system, such as expansionof the system to include new players (as was the case, for instance, when the European Union expanded from 15 to 27member states) or changes to players’ weights (it is plausible that in the future the countries’ weights in the EU Councilmay have to be updated to reflect the demographic changes). In such scenarios, the central authority would normally havesome freedom in setting the quota and may pursue a variety of objectives when doing so; for a discussion of this issue inthe context of European Union enlargement, see [28,30,32].In this paper, we study the effect of quota changes on the agents’ power, as measured by the Shapley–Shubik power indexand by the Banzhaf power index. We first provide tight bounds on the change in voter’s power that can be accomplishedby modifying the quota. It turns out that there are settings where all voters except for the one with the maximum weightcan have their voting power reduced to zero by an appropriate choice of the quota, i.e., the ratio between the voter’s powerbefore and after the change of quota can be unbounded; however, for both indices, we can obtain tight worst-case boundson the difference between the values of the index before and after the change.Having established that changing the quota may have a very significant effect on the agents’ power, we focus on thealgorithmic aspects of the manipulator’s problem. The manipulator may want to either minimize or maximize the targetplayer’s power. We limit our attention to the former problem. In this case, the best that the manipulator can hope for is tomake the target player a dummy, i.e., to ensure that this player’s power (as measured by both indices) is 0. We show thatthe center can easily determine whether there is a quota value that accomplishes this. This result is somewhat surprising,since checking if a given agent is a dummy for a fixed value of the quota is well-known to be coNP-complete [37,10,35].The ranking of the agents is sometimes more important than the exact power they possess: for instance, a party inparliament may have a better negotiating position if it is among the top three most powerful players. Therefore, we alsostudy the problem of setting the quota so as to guarantee a particular relation (equality or inequality) between two agents’power-index values. We demonstrate that as long as two agents have different weights, the quota can be selected so thatthey have different voting power. A related issue that we consider is that of selecting the quota so as to ensure that allagents with different weights have different power-index values. We exhibit a family of weight vectors for which essentiallyany value of the quota has this property. In contrast, we show that if agents’ weights grow fast enough, this goal cannot beachieved.In many real-life settings, the center will only be able to change the quota by a relatively small amount, or choose amonga few acceptable quota values. It is therefore interesting to ask if the manipulator can achieve his goals when his abilityto change the quota is constrained. We provide a twofold answer to this question. First, we show that choosing the quotaoptimally from a given set is likely to be hard. Specifically,",
            {
                "entities": [
                    [
                        3793,
                        3821,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 315 (2023) 103825Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintStrategyproof Allocation Mechanisms with Endowments and M-convex Distributional Constraints ✩Takamasa Suzuki a, Akihisa Tamura b, Kentaro Yahiro c, Makoto Yokoo c, Yuzhe Zhang d,∗a Gifu Shotoku Gakuen University, Gifu, Japanb Keio University, Yokohama, Japanc Kyushu University, Fukuoka, Japand University of Groningen, Groningen, the Netherlandsa r t i c l e i n f oa b s t r a c tArticle history:Received 25 September 2020Received in revised form 17 April 2022Accepted 10 November 2022Available online 15 November 2022Keywords:Controlled school choiceM-convex setStrategyproofnessTop trading cyclesDeferred acceptanceDistributional constraints1. IntroductionWe consider an allocation problem of multiple types of objects to agents, where each type of object has multiple copies (e.g., multiple seats in a school), each agent is endowed with an object, and some distributional constraints are imposed on the allocation (e.g., minimum/maximum quotas). We develop two mechanisms that are strategyproof, feasible (they always satisfy distributional constraints), and individually rational, assuming the distributional constraints are represented by an M-convex set. One mechanism, based on Top Trading Cycles, is Pareto efficient; the other, which belongs to the mechanism class specified by Kojima et al. [1], satisfies a relaxed fairness requirement. The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific quotas, and distance constraints. Finally, we experimentally evaluate the performance of these mechanisms by a computer simulation.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).The objective of this paper is to develop mechanisms for allocating indivisible objects to agents without monetary trans-fers, where each individual agent has a prior claim to some object, each type of an object has multiple copies, and some distributional constraints are imposed on the allocation. Our motivation is to apply these mechanisms to controlled school choice programs for public schools, i.e., deciding the allocation of students to schools (where each school has multiple iden-tical seats) when schools offer students the opportunity to attend their preferred public school other than the one closest to where they live, under distributional constraints (e.g., the capacity limits of schools).Our mechanisms are general enough to be applied to any reallocation problem of indivisible objects with multiple sup-plies. For example, in many Japanese universities, undergraduate engineering students must be assigned to a laboratory to This paper is based on our conference paper [2]. The following are the main differences: an extended study of TTC-M’s axiomatic properties (non-✩bossiness, group strategyproofness, weak core, and the characterization of TTC-M based on weak consistency), the introduction of a fair mechanism (DA-R), and an experimental comparison of the proposed mechanisms.* Corresponding author.yokoo@inf.kyushu-u.ac.jp (M. Yokoo), yoezy.zhang@rug.nl (Y. Zhang).E-mail addresses: t.suzuki@gifu.shotoku.ac.jp (T. Suzuki), aki-tamura@math.keio.ac.jp (A. Tamura), yahiro@agent.inf.kyushu-u.ac.jp (K. Yahiro), https://doi.org/10.1016/j.artint.2022.1038250004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fT. Suzuki, A. Tamura, K. Yahiro et al.Artificial Intelligence 315 (2023) 103825conduct projects. However, some students fail to choose the laboratory of greatest interest due to limited familiarity with them. A possible remedy is to apply the following three-step procedure: (i) students are assigned to laboratories using some mechanism, (ii) they experience a certain trial period, and (iii) each student has a chance to apply to another laboratory if she changes her mind or her current laboratory fails to meet her expectations. Our new mechanisms can be used in step (iii). Naturally, no student should be mandatorily reallocated to a laboratory that is worse than her current assignment.Following a seminal work by Abdulkadiro˘glu and Sönmez [3], which formalized a school choice problem in the context of the mechanism design approach, a wide range of theoretical analysis has been conducted on the existing mechanisms used in practice.1 As the theory has been developed and applied to diverse types of environments, mechanism designers have faced a variety of forms of distributional constraints unaddressed by the standard model. For example, Biró et al. [5]was motivated by the Hungarian education system where higher education institutions can declare minimum quotas for study areas that must be satisfied to open courses. Another example is the regional maximum quotas introduced by the Japanese government to control the geographical distribution of medical residents to the country’s hospitals [6].It is well-known that in the presence of distributional constraints, a stable matching may not exist. A matching’s stability was first defined for two-sided, one-to-one matching problems [7]. In the setting of a school choice problem, stability is de-fined as the combination of individual rationality (IR), fairness, and nonwastefulness (NW) [8]. IR is a basic requirement that guarantees that a student2 can obtain a seat in a school that is at least as good as her initial endowment. Fairness ensures that when student s is not accepted by school c (which she believes to be better than her assigned school), then s is ranked lower than any student accepted by c based on c’s preference. NW is an efficiency notion that rules out incidents where a student can move unilaterally to her more preferred school without violating the underlying distributional constraints. Given the incompatibility of stability under distributional constraints, mechanism designers encounter a trade-off between fairness and efficiency. In recent literature on distributional constraints [9–16], a common approach is to weaken stability while maintaining a balance between efficiency and fairness to some extent.In this paper, we examine whether efficiency/fairness is achievable under distributional constraints while guaranteeing IR. More specifically, for efficiency, we study Pareto Efficiency (PE), a stronger welfare notion than NW, which eliminates incidents where students’ welfare can be improved without detracting from the welfare of others while satisfying distribu-tional constraints. For fairness, we study a slightly relaxed requirement such that it is compatible with IR called fairness among Non-Initial Endowment students (NIE-fairness) and examine how it is achieved without sacrificing excessive effi-ciency. It has generally remained an open question whether a Pareto Efficient (PE) mechanism (i.e., a mechanism that is guaranteed to obtain a PE matching) can satisfy some fairness property under distributional constraints [6]. Kamada and Kojima [6], one of the few studies investigating efficiency under distributional constraints, argued that PE is achievable un-der regional maximum quotas. Another study by Hamada et al. [17] develops a PE mechanism and an NIE-fair mechanism when minimum (and standard maximum) quotas are imposed on each school. As described below, the class of distributional constraints studied in this work is a strict generalization of these classes.We restrict our attention to strategyproof (SP) mechanisms, in which no student has an incentive to misreport her preference over schools. In theory, we can restrict our attention to SP mechanisms without loss of generality due to the well-known revelation principle [18]: if a certain property is achieved by a mechanism (more specifically, that property is satisfied in a dominant strategy equilibrium when using the mechanism), it can be achieved by an SP mechanism. An SP mechanism is also useful in practice since a student does not need to speculate about the actions of other students to obtain a good outcome; she only needs to truthfully report her preference.In this paper, we consider a class of distributional constraints that can be represented by an M-convex set (M stands for Matroid), a concept introduced in the field of discrete mathematics, which is a discrete counterpart of the frame-work of convex analysis [19,20]. We show that the M-convexity of the underlying distributional constraints is sufficient to guarantee the existence of mechanisms that satisfy desirable properties. The class of distributional constraints that can be represented by an M-convex set contains many situations raised from realistic matching problems, including individual minimum/maximum quotas (Fragiadakis et al. [9], Hamada et al. [17]), regional maximum quotas (Goto et al. [11], Kamada and Kojima [6]), type-specific maximum quotas (Abdulkadiro˘glu [21], Fragiadakis and Troyan [10]), and distance constraints (Kojima et al. [1]).We require an additional assumption: if every student is assigned to her initial endowment school, the underlying dis-tributional constraints are satisfied. This is an innocent requirement in the context of school choice since every student would attend her local school if there is no school choice program; assuming this default allocation satisfies distributional constraints is reasonable.Our mechanism achieving PE is based on the Top Trading Cycles (TTC) mechanism [22] developed by David Gale. TTC improves students’ welfare by trading their initial endowments. Our mechanism achieving NIE-fairness belongs to a mecha-nism class specified by Kojima et al. [1], which is a generalization of the Deferred Acceptance (DA) mechanism [7]. Both ar",
            {
                "entities": [
                    [
                        3538,
                        3566,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 215 (2014) 1–23Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFractals and RavensKeith McGreggor∗, Maithilee Kunda, Ashok GoelDesign & Intelligence Laboratory, School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA 30332, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 4 June 2013Received in revised form 14 April 2014Accepted 13 May 2014Available online 20 May 2014Keywords:AnalogyVisual reasoningFractal representationsComputational psychometrics1. IntroductionWe report a novel approach to visual analogical reasoning, one afforded expressly by fractalrepresentations. We first describe the nature of visual analogies and fractal representations.Next, we exhibit the Fractal Ravens algorithm through a detailed example, describe itsperformance on all major variants of the Raven’s Progressive Matrices tests, and discussthe implications and next steps. In addition, we illustrate the importance of consideringthe confidence of the answers, and show how ambiguity may be used as a guide for theautomatic adjustment of the problem representation. To our knowledge, this is the firstpublished account of a computational model’s attempt at the entire Raven’s test suite.© 2014 Elsevier B.V. All rights reserved.Despite references to its role as core to cognition [33,35], analogy defies a singular definition [58]. In one way, analogymay be seen as a process of transference, a mapping of knowledge from one situation to another, based upon a judgmentof the similarity between the two situations [12,19,20,22–27,37,40,57,67]. Gentner [24], for example, proposed that analo-gies entail transfer of relations from a source case to a target problem and that judgment of similarity between the targetand the source depends on the correspondence between the structure of their representations. Holyoak and Thagard [37]proposed that judgments of similarity between a source case and a target problem depend on multiple criteria: structuralcorrespondence, semantic similarity, and pragmatic constraints. Keane [40] proposed incremental mapping between thesource case and the target problem. Dunbar [19] found a paradox in that humans appear to exhibit significant spontaneoususe of analogies in their natural workflow but less so in laboratory settings. Kokinov and Petrov [42] describe several con-straints to facilitate the integration of analogue retrieval from memory and analogical transfer. Holyoak and Hummel [36]similarly examine findings for recruiting memory, reasoning and learning in the service of analogy making. Clement [12] de-scribes several processes of analogy such as the use of intermediate representations (or bridging analogies). Nersessian [57]similarly describes the use of generic mechanisms in scientific analogies. Our own work on model-based analogy [6,28] hasfocused on the use of semantic similarity and pragmatics constraints for evaluating similarity between source cases and tar-get problems, and identification and abstraction of generic mechanisms for transfer from a source case to a target problemin creative design [6,28,29].In contrast, case-based reasoning [1,43,49,63] views within-domain analogical reasoning as a memory task in whichmemory supplies a source case containing an almost correct solution to the target problem. Hammond [32], for example,describes retrieval of plans based on semantic similarity to the target problem and modification of the retrieved plan tomeet the target goal. Ashley and Rissland [3] describe the use of case-based reasoning in law. Smyth, Cunningham and Keane[65] describe hierarchical case-based reasoning, and Aha, Breslow and Munoz-Avila [2] describe conversational case-based* Corresponding author.E-mail addresses: keith.mcgreggor@gatech.edu (K. McGreggor), mkunda@gatech.edu (M. Kunda), goel@cc.gatech.edu (A. Goel).http://dx.doi.org/10.1016/j.artint.2014.05.0050004-3702/© 2014 Elsevier B.V. All rights reserved.\f2K. McGreggor et al. / Artificial Intelligence 215 (2014) 1–23Fig. 1. Problem similar to those of the Raven’s Standard Progressive Matrices test.reasoning. Our own work on case-based reasoning has focused in integration of case-based and model-based reasoning foradaptive design [30].Another line of research views analogy as a mechanism of perception, where one situation is recognized in terms ofanother [10,34,56] or as a mechanism of learning, where one situation is interpreted in terms of another [39]. Yet anotherline of research on analogy pertains to visual analogy [13–17,69,70]. In visual analogy, the source case and the targetproblem contain only modal, visual knowledge, and causality is (at most) implicit. For example, Yaner and Goel [69] describea technique for retrieving design drawings from memory that are similar to a target drawing; Davies, Goel and Yaner [16]describe the technique of constructive analogy for incrementally transferred from the source drawing to the target drawing;and Yaner and Goel [70] describe the technique of compositional modeling that builds a causal model of the target drawingby analogy to the causal model of the source drawing.Each of these schools of thought emphasizes the importance of certain aspects of analogy making, and, in turn, estab-lishes certain criteria that must be achieved by any associated methodologies through some combination of mechanismand representation. Our work concerns visual analogy, the act of forming analogies based upon purely visual perceptions,or, more formally, upon a purely visual perceptual history. We propose a new representation – the fractal representation– and corresponding mechanism for addressing a class of visual analogies that occur in computational psychometrics, andin particular, on the Raven’s Progressive Matrices test of intelligence. Although we focus our remarks on representation,visual analogy, and psychometrics, we expressly make no claims as to whether our model may be extended to provide fora cognitive account.1.1. Computational psychometricsAI research on computational psychometrics dates at least as far back as Evans’ Analogy program [21], which addressedgeometric analogy problems on the Miller Geometric Analogies test of intelligence. Bringsjord and Schimanski [7] haveproposed computational psychometrics, i.e., AI that can pass psychometric tests of intelligence, as a possible mechanism formeasuring and comparing AI.Raven’s Progressive Matrices Test suite is a set of standard and common tests of intelligence [61]. The standard versionof the test consists of 60 geometric analogy problems. Fig. 1 illustrates a problem typical to those that appear on the test.1The task in the problem is to pick one of the eight choices in the bottom of the figure for insertion in that bottom-rightelement of the 3 × 3 matrix in the top of the figure. The chosen element should best match the patterns in the rows andcolumns of the matrix.The Raven’s Progressive Matrices (RPM) test paradigm is intended to measure eductive ability, the ability to extract andprocess information from a novel situation [61]. Eductive ability stands in contrast to reproductive ability, which is theability to recall and use previously learned information.The problems from Raven’s various tests are organized into five sets. Each successive set is generally interpreted to bemore difficult than the prior set. Some of the problem sets are 2 × 2 matrices of images with six possible answers; theremaining sets are 3 × 3 matrices of images with eight possible answers.1 Throughout this paper, we use example problems that are similar to those found on Raven’s tests, due to copyright concerns and to ensure the integrityof the tests themselves. The results we report, however, are from the actual test problems.\fK. McGreggor et al. / Artificial Intelligence 215 (2014) 1–233The tests are purely visual: no verbal information accompanies the tests. The test-taker is asked to select from theavailable possible answers the single answer that best completes the matrix [61].1.2. Prior approaches to RPMOver the years, different models have proposed various combinations of representations and mechanisms for solvingRPM problems. Hunt [38] gives a theoretical account of the information processing demands of certain problems fromthe Advanced Progressive Matrices (APM), in which he proposes two qualitatively different solution algorithms—“Gestalt,”which uses visual operations on analogical representations, and “Analytic,” which uses logical operations on conceptualrepresentations.Carpenter, Just, and Shell [9] describe a computational model that simulates solving RPM problems using propositionalrepresentations. Their model is based on the traditional production system architecture, with a long-term memory contain-ing a set of hand-authored productions and a working memory containing the current state of problem solving (e.g. currentgoals). Productions are based on the relations among the entities in an RPM problem, for example, the location of the darkcomponent in a row, which might be the top half in the top row of a problem, bottom-half in the bottom row, and so on.They did not test their system on the Standard Progressive Matrices (SPM), but two different versions of their system solved23 and 32 out of 34 attempted problems on the APM.Bringsjord and Schimanski [7] used a theorem-prover to solve selected RPM problems stated in first-order logic, thoughno results from this effort were reported.Lovett, Forbus and Usher [51] describe a model that extracts qualitative spatial representations from visually segmentedrepresentations of RPM problem inputs and then uses the analogy technique of structure mapping to find solutions and,where needed to achieve better analogies, to regroup or re-segment the initial inputs to form new problem representations.Again, while visual information from the RPM problems is implicit in the final representations, the structure-mapping engineis app",
            {
                "entities": [
                    [
                        3920,
                        3948,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1479–1497Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInstantiating abstract argumentation with classical logic arguments:Postulates and propertiesNikos Gorogiannis a, Anthony Hunter b,∗a Department of Computer Science, Queen Mary, University of London, London, E1 4NS, UKb Department of Computer Science, University College London, London, WC1E 6BT, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 17 February 2010Received in revised form 22 December 2010Accepted 26 December 2010Available online 28 December 2010Keywords:Computational models of argumentAbstract argumentationLogical argumentationIn this paper we investigate the use of classical logic as a basis for instantiating abstractargumentation frameworks. In the first part, we propose desirable properties of attackrelations in the form of postulates and classify several well-known attack relations fromthe literature with regards to the satisfaction of these postulates. Furthermore, we provideadditional postulates that help us prove characterisation results for these attack relations.In the second part of the paper, we present postulates regarding the logical content ofextensions of argument graphs that may be constructed with classical logic. We thenconduct a comprehensive study of the status of these postulates in the context of thevarious combinations of attack relations and extension semantics.© 2011 Elsevier B.V. All rights reserved.1. IntroductionArgumentation is an important cognitive process that involves the generation and evaluation of arguments. There havebeen a number of proposals for capturing this cognitive process in computational models of argumentation (for example[1–6] and for reviews [7–10]). Amongst these proposals, two significant, intersecting and non-exclusive streams can bedistinguished.Abstract argumentation which focuses on the attack relations between arguments and usually considers arguments them-selves to be atomic objects (for example [11,3,12,13]). This approach offers insight into how arguments interactand achieve acceptability solely in terms of the attacks that may exist between them. Furthermore, this approachallows for harnessing tools from graph theory.Logical argumentation which considers arguments as complex entities with an internal structure that is governed by acertain logical language (for example [1,14,4–6,15]). In general, using logic for formalising argumentation enablesthe harnessing of natural concepts for disagreement, or attack between arguments, such as inconsistency. In ad-dition, this approach allows using logical entailment for drawing conclusions that may serve as the claims ofarguments.A wealth of research has been conducted in the context of these two streams, prompting the question whether theirderived knowledge can be combined to deliver models of argumentation that are more expressive, more natural or morepowerful. Proposals of frameworks that are situated in the intersection of these two areas exist (for example [16,4,5,17–20]) but (apart from [16,19,20]), they tend to focus on specialised, defeasible logics as their language of choice. Defeasible* Corresponding author.E-mail addresses: n.gorogiannis@cs.ucl.ac.uk (N. Gorogiannis), a.hunter@cs.ucl.ac.uk (A. Hunter).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.12.003\f1480N. Gorogiannis, A. Hunter / Artificial Intelligence 175 (2011) 1479–1497logics are a useful tool for many application areas where the expressiveness requirements are not great, but cannot readilyencompass applications where for example disjunction or true negation are required.Therefore, it would seem that an argumentation system that uses classical logic as its language, while explicitly employ-ing abstract argumentation-style semantics, is attractive for several reasons. It would benefit directly from the large numberof results on abstract argumentation frameworks produced in the last decade and, in addition, it would offer expressivenessthat is moderate but still higher than currently used defeasible logics for argumentation.It is the exploration of this gap, then, that this paper is aimed at. Proposing such a framework is not particularly compli-cated as there is a natural, if not unproblematic, way to instantiate an abstract argumentation framework using a knowledgebase in classical logic. What is little known about such systems is the properties they ought to satisfy for them to be usefuland predictable. While attempts have been made along these lines (e.g., [18] on rule-based systems and [19] on classicallogic) such work is far from complete. Moreover, after such postulates have been proposed and perhaps gained acceptance,the more important question remains as to which argumentation systems will satisfy them. Compounding the difficulty ofthese questions is the fact that components of both logical and abstract argumentation, such as attack relations and exten-sion semantics respectively, can be instantiated to a multiplicity of definitions, thus considerably enlarging the number ofcombinations to check. So we see that given the interesting possibilities raised in [16,18,19], there is a need to undertakea systematic analysis of instantiating abstract argumentation with classical logic that considers a comprehensive range ofattack relations and semantics for extensions. Furthermore, it is desirable that this is undertaken in a modular way using aframework of intuitive postulates.Given these concerns, in this paper we consider an intuitive way to generate a set of arguments, starting from aknowledge base in classical logic (along with preliminaries, in Section 2). We then review the attack relations for logi-cal argumentation in the literature and set out postulates that delineate desirable properties (Section 3). In addition, weinvestigate the status of these properties for these attack relations and then go on to propose additional postulates thatallow us to prove characterisation results, i.e., to show that an arbitrary attack relation is one of the reviewed ones if andonly if it satisfies a particular combination of postulates. Following that, we outline a set of postulates which express gen-eral properties of the logical content of the extensions of logical argument graphs (Section 4). To achieve that, we employand generalise properties found in the literature as well as novel postulates that specifically address the issues arising fromthe potential extension multiplicity that many extension semantics allow. The status of these postulates is examined next(Section 5), over the several combinations of extension semantics and attack relations possible. Finally, we conclude anddiscuss existing work that relates to this paper (Section 6).2. Preliminaries(cid:2)We will use a propositional logic (cid:3)L, (cid:4)(cid:5) with a countable set of propositional letters and constants (cid:6), ⊥ for truth andfalsum respectively. We write Φ (cid:4) ψ to mean that the set of formulae Φ entails the formula ψ , and φ (cid:4) ψ as shorthand for{φ} (cid:4) ψ . The notationΦ where Φ is a set of formulae, will be used to denote the conjunction of all formulae in Φ. Wealso use φ ≡ ψ to denote logical equivalence of the formulae φ and ψ in the meta-language (i.e., φ (cid:4) ψ and ψ (cid:4) φ), andΦ ≡Φ ≡ Ψ mean logical equivalence of sets of formulae, i.e.,Ψ . From now on (cid:6), the knowledge base, will stand fora finite set of individually consistent propositional formulae. We will denote the set of minimal inconsistent subsets of (cid:6)with MI((cid:6)) (that is to say, MI((cid:6)) = {Φ ⊆ (cid:6) | Φ (cid:4) ⊥ and for all Ψ ⊂ Φ, Ψ (cid:2) ⊥}).(cid:2)(cid:2)In order to give meaning and structure to the arguments in an abstract argumentation framework, we adopt the mostcommon definition in logical argumentation that separates the evidence, or support, from the claim, or conclusion of anargument.Definition 1. An argument is a pair (cid:3)Φ, φ(cid:5) such that Φ ⊆ (cid:6) is a consistent, finite set of formulae, φ is a formula such thatΦ (cid:4) φ, and no proper subset of Φ entails φ.The (countably infinite) set of all arguments is denoted by A. If A = (cid:3)Φ, φ(cid:5) is an argument, we will use the functionsS( A) = Φ to denote the support of A and C( A) = φ to denote the claim of A. We say that two arguments A, B areequivalent if S( A) = S(B) and C( A) ≡ C(B), and denote this by A ≡ B. Notice that this notion of equivalence is semanticwith respect to the claim, but syntactic with respect to the support. This compromise aims at accommodating the fact thatusers of a logical argumentation system may view the formulae in the input knowledge base as resources, in the sense thathaving two ways to prove the same thing should give rise to two different arguments that are not conflated together. Also,we will say that A is a sub-argument of B if S( A) ⊆ S(B).Definition 2. An argument graph (or simply, graph) is a pair (cid:3)N, R(cid:5) where N ⊆ A is a finite set of arguments and R is anon-reflexive binary relation on N. For each ( A, B) ∈ R, we say that A attacks B.We will only consider non-reflexive attack relations in this paper. While attack relations with self-loops have beenof some interest in the abstract argumentation community, they do not normally feature in logical argumentation sincearguments are usually required to be consistent, as above, and the attack relation definition ordinarily relates attack toinconsistency.\fN. Gorogiannis, A. Hunter / Artificial Intelligence 175 (2011) 1479–14971481Fig. 1. Is-a relationships between concepts in Definition 3. An arrow from X to Y denotes that any X -extension is also a Y -extension, or equivalently,EX(Γ ) ⊆ EY(Γ ).We use the convenience functions Nodes((cid:3)N, R(cid:5)) = N (the nodes of the graph) and Arcs((cid:3)N, R(cid:5)) = R (the arcs of thegraph). Whenever we are concerned with an argument gra",
            {
                "entities": [
                    [
                        3408,
                        3436,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1400–1427www.elsevier.com/locate/artintImprecise probability trees:Bridging two theories of imprecise probabilityGert de Cooman ∗, Filip HermansGhent University, SYSTeMS Research Group, Technologiepark – Zwijnaarde 914, 9052 Zwijnaarde, BelgiumReceived 30 March 2007; received in revised form 12 February 2008; accepted 3 March 2008Available online 18 March 2008AbstractWe give an overview of two approaches to probability theory where lower and upper probabilities, rather than probabilities,are used: Walley’s behavioural theory of imprecise probabilities, and Shafer and Vovk’s game-theoretic account of probability.We show that the two theories are more closely related than would be suspected at first sight, and we establish a correspondencebetween them that (i) has an interesting interpretation, and (ii) allows us to freely import results from one theory into the other.Our approach leads to an account of probability trees and random processes in the framework of Walley’s theory. We indicate howour results can be used to reduce the computational complexity of dealing with imprecision in probability trees, and we prove aninteresting and quite general version of the weak law of large numbers.© 2008 Elsevier B.V. All rights reserved.Keywords: Game-theoretic probability; Imprecise probabilities; Coherence; Conglomerability; Event tree; Probability tree; Imprecise probabilitytree; Lower prevision; Immediate prediction; Prequential Principle; Law of large numbers; Hoeffding’s inequality; Markov chain; Randomprocess1. IntroductionIn recent years, we have witnessed the growth of a number of theories of uncertainty, where imprecise (lower andupper) probabilities and previsions, rather than precise (or point-valued) probabilities and previsions, have a centralpart. Here we consider two of them, Glenn Shafer and Vladimir Vovk’s game-theoretic account of probability [29],which is introduced in Section 2, and Peter Walley’s behavioural theory [33], outlined in Section 3. These seem to havea rather different interpretation, and they certainly have been influenced by different schools of thought: Walley followsthe tradition of Frank Ramsey [22], Bruno de Finetti [11] and Peter Williams [39] in trying to establish a rational modelfor a subject’s beliefs in terms of her behaviour. Shafer and Vovk follow an approach that has many other influencesas well, and is strongly coloured by ideas about gambling systems and martingales. They use Cournot’s Principleto interpret lower and upper probabilities (see [28]; and [29, Chapter 2] for a nice historical overview), whereas onWalley’s approach, lower and upper probabilities are defined in terms of a subject’s betting rates.* Corresponding author.E-mail addresses: gert.decooman@UGent.be (G. de Cooman), filip.hermans@UGent.be (F. Hermans).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.001\fG. de Cooman, F. Hermans / Artificial Intelligence 172 (2008) 1400–14271401What we set out to do here, 1 and in particular in Sections 4 and 5, is to show that in many practical situations, thetwo approaches are strongly connected.2 This implies that quite a few results, valid in one theory, can automatically beconverted and reinterpreted in terms of the other. Moreover, we shall see that we can develop an account of coherentimmediate prediction in the context of Walley’s behavioural theory, and prove, in Section 6, a weak law of largenumbers with an intuitively appealing interpretation. We use this weak law in Section 7 to suggest a way of scoring apredictive model that satisfies A. Philip Dawid’s Prequential Principle [5,6].Why do we believe these results to be important, or even relevant, to AI? Probabilistic models are intended torepresent an agent’s beliefs about the world he is operating in, and which describe and even determine the actionshe will take in a diversity of situations. Probability theory provides a normative system for reasoning and makingdecisions in the face of uncertainty. Bayesian, or precise, probability models have the property that they are completelydecisive: a Bayesian agent always has an optimal choice when faced with a number of alternatives, whatever his stateof information. While many may view this as an advantage, it is not always realistic. Imprecise probability models tryto deal with this problem by explicitly allowing for indecision, while retaining the normative, or coherentist stance ofthe Bayesian approach. We refer to [8,33,34] for discussions about how this can be done.Imprecise probability models appear in a number of AI-related fields. For instance in probabilistic logic: it wasalready known to George Boole [1] that the result of probabilistic inferences may be a set of probabilities (an impreciseprobability model), rather than a single probability. This is also important for dealing with missing or incomplete data,leading to so-called partial identification of probabilities, see for instance [9,19]. There is also a growing literature onso-called credal nets [3,4]: these are essentially Bayesian nets with imprecise conditional probabilities.We are convinced that it is mainly the mathematical and computational complexity often associated with impreciseprobability models that is keeping them from becoming a more widely used tool for modelling uncertainty. But webelieve that the results reported here can help make inroads in reducing this complexity. Indeed, the upshot of ourbeing able to connect Walley’s approach with Shafer and Vovk’s, is twofold. First of all, we can develop a theoryof imprecise probability trees: probability trees where the transition from a node to its children is described by animprecise probability model in Walley’s sense. Our results provide the necessary apparatus for making inferences insuch trees. And because probability trees are so closely related to random processes, this effectively brings us into aposition to start developing a theory of (event-driven) random processes where the uncertainty can be described usingimprecise probability models. We illustrate this in Examples 1 and 3, and in Section 8.Secondly, we are able to prove so-called Marginal Extension results (Theorems 3 and 7, Proposition 9), whichlead to backwards recursion, and dynamic programming-like methods that allow for an exponential reduction inthe computational complexity of making inferences in such imprecise probability trees. This is also illustrated inExamples 3 and Section 8. For (precise) probability trees, similar techniques were described in Shafer’s book oncausal reasoning [26]. They seem to go back to Christiaan Huygens, who drew the first probability tree, and showedhow to reason with it, in his solution to Pascal and Fermat’s Problem of Points.32. Shafer and Vovk’s game-theoretic approach to probabilityIn their game-theoretic approach to probability [29], Shafer and Vovk consider games with two typical players,Reality and Sceptic, who play according to certain protocols. They obtain the most interesting results for what theycall coherent probability protocols. This section is devoted to explaining what this means: what are the roles of Realityand Sceptic, how and by what rules do they play, and how can their game-play be related to probabilistic reasoning?2.1. Reality’s event treeWe begin with a first and basic assumption, dealing with how the first player, Reality, plays.1 An earlier and condensed version of this paper, with much less discussion and without proofs, was presented at the ISIPTA ’07 Conference [7].2 Our line of reasoning here should be contrasted with the one in [28], where Shafer et al. use the game-theoretic framework developed in [29] toconstruct a theory of predictive upper and lower previsions whose interpretation is based on Cournot’s Principle. See also the comments near theend of Section 5.3 See Section 8 for more details and precise references.\f1402G. de Cooman, F. Hermans / Artificial Intelligence 172 (2008) 1400–1427Fig. 1. A simple event tree for Reality, displaying the initial situation (cid:2), other non-terminal situations (such as t ) as grey circles, and paths, orterminal situations, (such as ω) as black circles. Also depicted is a cut U = {u1, u2, u3, u4} of (cid:2). Observe that t (strictly) precedes u1: t (cid:2) u1, andthat C(t) = {u1, u2} is the children cut of t .G1. Reality makes a number of moves, where the possible next moves may depend on the previous moves he hasmade, but do not in any way depend on the previous moves made by Sceptic.This means that we can represent his game-play by an event tree (see also [26,27] for more information about eventtrees). We restrict ourselves here to the discussion of bounded protocols, where Reality makes only a finite andbounded number of moves from the beginning to the end of the game, whatever happens. But we don’t exclude thepossibility that at some point in the tree, Reality has the choice between an infinite number of next moves. We shallcome back to these assumptions further on, once we have the appropriate notational tools to make them more explicit.4Let us establish some terminology related to Reality’s event tree.2.1.1. Paths, situations and eventsA path in the tree represents a possible sequence of moves for Reality from the beginning to the end of the game.We denote the set of all possible paths ω by Ω, the sample space of the game.A situation t is some connected segment of a path that is initial, i.e., starts at the root of the tree. It identifies themoves Reality has made up to a certain point, and it can be identified with a node in the tree. We denote the set of allsituations by Ω ♦. It includes the set Ω of terminal situations, which can be identified with paths. All other situationsare called non-terminal; among them is the initial situation (cid:2), which represents the empty initial segment. See Fig. 1for a simple graphical example explaining these notions.If for two situat",
            {
                "entities": [
                    [
                        2920,
                        2948,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1615–1638Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnalogical model formulation for transfer learning in AP PhysicsMatthew Klenk∗,1, Ken ForbusQualitative Reasoning Group, Northwestern University, 2133 Sheridan Road, Evanston, IL 60208, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 29 September 2008Received in revised form 4 September 2009Accepted 18 September 2009Available online 23 September 2009Keywords:Transfer learningAnalogical reasoningModel formulationCase-based reasoningTransfer learning is the ability to apply previously learned knowledge to new problemsor domains. In qualitative reasoning, model formulation is the process of moving fromthe unruly, broad set of concepts used in everyday life to a concise, formal vocabularyof abstractions, assumptions, causal relationships, and models that support problem-solving. Approaching transfer learning from a model formulation perspective, we found thatanalogy with examples can be used to learn how to solve AP Physics style problems. Wecall this process analogical model formulation and implement it in the Companion cognitivearchitecture. A Companion begins with some basic mathematical skills, a broad commonsense ontology, and some qualitative mechanics, but no equations. The Companion usesworked solutions, explanations of example problems at the level of detail appearing intextbooks, to learn what equations are relevant, how to use them, and the assumptionsnecessary to solve physics problems. We present an experiment, conducted by theEducational Testing Service, demonstrating that analogical model formulation enables aCompanion to learn to solve AP Physics style problems. Across six different variationsof relationships between base and target problems, or transfer levels, a Companionexhibited a 63% improvement in initial performance. While already a significant result,we describe an in-depth analysis of this experiment to pinpoint the causes of failures.Interestingly, the sources offailures were primarily due to errors in the externallygenerated problem and worked solution representations as well as some domain-specificproblem-solving strategies, not analogical model formulation. To verify this, we describea second experiment which was performed after fixing these problems. In this secondexperiment, a Companion achieved a 95.8% improvement in initial performance due totransfer, which is nearly perfect. We know of no other problem-solving experiments whichdemonstrate performance of analogical learning over systematic variations of relationshipsbetween problems at this scale.© 2009 Elsevier B.V. All rights reserved.1. IntroductionTransfer learning research is motivated by the observation that people improve in their ability to learn new domainsbased on their experiences in related tasks. We focus here on the task of model formulation [10]. Given a scenario description,a domain theory of model fragments, and a question, model formulation produces a scenario model, which consists of therelevant abstractions, processes, and causal relationships useful for answering the question. An important contribution ofthe qualitative reasoning community has been formalizing this process. For example, methods have been developed toefficiently identify what levels of detail should be included and which perspectives should be taken in a scenario model* Corresponding author.E-mail address: matthew.klenk.ctr@nrl.navy.mil (M. Klenk).1 Current address: Naval Research Laboratory, 4555 Overlook Ave SW, Washington, DC 20375, USA.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.09.003\f1616M. Klenk, K. Forbus / Artificial Intelligence 173 (2009) 1615–1638Fig. 1. Example AP Physics problems of the four types used in this work.[35,42]. However, these approaches have three limitations. First, they rely on having a complete and correct domain theory.Such domain theories are difficult to construct. A more incremental, learning-oriented approach would be valuable for manyapplications, so that a system’s competence could be improved over time as needed. Second, work in model formulationtends to start with fairly abstract scenario descriptions, e.g. circuit schematics or process diagrams. While this is fine forengineering applications, the ability to create qualitative and quantitative models of everyday situations (e.g., the scenariosfound in physics problems) is one of the hallmarks of human flexibility in problem-solving. Third, also due to an emphasison engineering domains, model formulation research has largely ignored learning. We propose instead a quite differentapproach: analogical model formulation. Analogical model formulation builds scenario models of everyday situations, basedon prior experience. We believe that analogical model formulation provides a way to create systems that can incrementallylearn a domain by making effective use of what knowledge they have, even when it is incomplete.Solving physics problems provides a good example of the need for this kind of flexibility. Fig. 1 provides four examples,illustrating types of problems that our system learns to solve. (These problems will be used as examples through the paper.)We factor out natural language understanding by using predicate-calculus versions of these problems, but, unlike previoussystems such as MECHO [3] or ISAAC [36], the translation process leaves everyday concepts in place. That is, balls, buildings,astronauts, boxes, baseball bats, flying, falling, and pulling all appear in the formal problem descriptions.2 Understanding therelevant abstractions and assumptions for a physics problem stated as an everyday scenario is a difficult problem. Modelingdecisions are contextual. For example, a coin falling off a building can be considered to be a point mass. But if we weremodeling the exact same coin spinning on a table, it cannot be considered a point mass since its shape and size must beconsidered. The generalizations in any common-sense ontology are unlikely to provide much help: cats, coins, and pianoscan all be considered as point masses in particular situations, but they are not closely related in any non-trivial ontologywe are aware of. Analogical model formulation addresses the three limitations in model formulation research outlinedabove. First, since it relies on examples, analogical model formulation does not require a complete domain theory. Second,it operates directly with representations of situations drawn from a broad vocabulary of concepts. Finally, by accumulatingexamples, a system using analogical model formulation learns to formulate new models of different situations.While complex, there is ample evidence that people are able to solve physics problems stated in everyday terms. Theproblems used throughout this work were generated by the Educational Testing Service, which administers the AP Physicsexamination in the United States. The AP Physics exam tests the ability of high school students to solve physics problems.Students’ performance on this exam indicates that they do learn to categorize everyday objects in terms of domain ab-stractions, determine what equations are relevant, infer parameter values from scenarios, and assume default circumstanceswhen necessary. The problems used in this work were generated automatically, from templates. The four problems, one fromeach problem type, shown in Fig. 1 represent roughly 20% of the typical Mechanics portion of the AP Physics examination.Solving physics problems via analogical model formulation begins by retrieving an example analogous to the currentscenario. Analogical model formulation uses the explanation of this example to formulate a model of the current scenario.Finally, the system uses traditional rule based reasoning over the model to arrive at a solution for the problem. Usingexample explanations, analogical model formulation enables the system to learn from examples how to make the followingmodeling decisions necessary for solving physics problems:• Which equations are relevant and how they should be instantiated (e.g., the force exerted on the box is equal to themass of the box multiplied by the acceleration of the box).• Which assumptions to make by default (e.g., assuming that events happen on Earth).2 We used a subset of the ResearchCyc ontology, containing over 30,000 concepts. See http://research.cyc.com for details.\fM. Klenk, K. Forbus / Artificial Intelligence 173 (2009) 1615–16381617• Which assumptions about the values of specific quantities to make based on the scenario (e.g., objects at rest have0 m/s).We implement analogical model formulation using the Companion cognitive architecture [18]. A central hypothesis ofthe Companion architecture is that the flexibility and breadth of human common sense reasoning arises from analogicalreasoning and learning from experience [17]. That is, people use their experience to enable them to solve new problems, andover time, extract generalizations and heuristics. For model formulation, this is consistent with Falkenhainer’s [8] observationthat engineers often use analogy with their experience to create new models. Klenk et al. [28] showed that a Companioncan formulate models by analogy to solve everyday physical reasoning problems, such as those on the Bennett MechanicalComprehension Test [2]. This article goes beyond that result by demonstrating that analogical model formulation can beused to solve variations of AP Physics style problems, through an external evaluation involving a substantial number ofproblems over systematic variations in relationships between problems.Characterizing how well learned knowledge transfers is complex. One way involves identifying different transfer levels,each representing a particular type of relationship between a known source problem and a novel target problem. We usean externally-developed set of six transfer ",
            {
                "entities": [
                    [
                        3697,
                        3725,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 889–909Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal analysis with Chain Event GraphsPeter Thwaites a,∗, Jim Q. Smith a, Eva Riccomagno ba Department of Statistics, University of Warwick, Coventry, CV4 7AL, United Kingdomb Department of Mathematics, Università degli Studi di Genova, Via Dodecaneso 35, 16146 Genova, Italya r t i c l ei n f oa b s t r a c tAs the Chain Event Graph (CEG) has a topology which represents sets of conditionalindependence statements,it becomes especially useful when problems lie naturallyin a discrete asymmetric non-product space domain, or when much context-specificinformation is present. In this paper we show that it can also be a powerful represen-tational tool for a wide variety of causal hypotheses in such domains. Furthermore, wedemonstrate that, as with Causal Bayesian Networks (CBNs), the identifiability of the effectsof causal manipulations when observations of the system are incomplete can be verifiedsimply by reference to the topology of the CEG. We close the paper with a proof of a BackDoor Theorem for CEGs, analogous to Pearl’s Back Door Theorem for CBNs.© 2010 Elsevier B.V. All rights reserved.Article history:Received 16 January 2009Received in revised form 13 May 2010Accepted 13 May 2010Available online 20 May 2010Keywords:Back Door TheoremBayesian NetworkCausal manipulationChain Event GraphConditional independenceEvent treeGraphical model1. IntroductionMuch recent work in the field of causality has focused on how cause relates to control, and the analysis of controlledmodels. Here, with the advocates of this approach we assume the existence of a background idle system which is thensubjected to some sort of intervention or manipulation.The Bayesian Network (BN) is the most commonly used graphical tool for representing complex dependency relation-ships. Interpreting the directionality of the edges of the BN as causal leads to the Causal Bayesian Network (CBN), whichuses a non-parametric representation based on structural equation models [12,19,21,30]. CBNs provide a framework forexpressing assertions about what might happen when the system under study is externally manipulated and some of itsvariables are assigned certain values.BNs and CBNs are ideal for problems which admit a natural product space structure. However many processes do nothave this — they are asymmetric in the sense that measurement variables may have different collections of possible out-comes given different vectors of values for sets of ancestral variables. For a variety of examples see [4,1,10,16,2,17,23].Context-specific variants of BNs exist [2,26,23,18], usually with tree-structured conditional probability tables annexed to thevertices of the BN to allow for the analysis of context-specific independence properties. Although these graphs allow theanalyst a greater flexibility than unmodified BNs, they are still inefficient representations of processes (such as treatmentregimes) whose unfolding depends on the state of the system at any particular point and the values of specific covariates atthat point. Similarly, they are not ideal representations of problems where no outcomes of certain variables could logicallyoccur given some vectors of values of ancestral variables.* Corresponding author.E-mail address: Peter.Thwaites@warwick.ac.uk (P. Thwaites).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.004\f890P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909There have been major advances in CBN theory in the last decade (see [6,14,20,7,35,34], and [21] for a good review ofthese). The basic Do intervention of Pearl [19] has been extended to functional manipulations (Do X = g(Z )), and stochasticmanipulations which assign a new probability distribution to the state space of the manipulated variable. Nonetheless, atthe most primitive level a manipulation of a BN still corresponds to the setting of certain measurement variables to specificvalues, possibly following some rule or policy. However, whereas the effects of a cause can be reasonably represented by arandom variable, at times the specification of a cause as the value of a random variable can be artificial. Causes are morenaturally represented as conditioning events, and such conditioning is not elegantly expressed in the BN. An analogous caseis made by Dawid [5] who argues that causes are decisions and not decision rules.Although topologically complex, event trees (the elicitation of which often provides the first stage in the developmentof a model) explicitly acknowledge structural asymmetries — context-specific and sample space information is embeddedin the topology of the tree. Their semantics are also often closer to many verbal descriptions of the world, especially whenthose descriptions revolve around how things happen rather than how the world appears. Event trees however, cannot bereadily interrogated for the conditional independence structure of a model.Trees also have their advocates in the study of causality [27,30,25]. In the related field of decision analysis, French andInsua [11] argue that the advantages of influence diagrams over decision trees are illusory, and point out that asymmetricproblems in which a particular choice of action at a decision node makes available different choices of action at subsequent decisionnodes than those available after an alternative choice are the rule rather than the exception. Using trees we can also choosethe level of detail we include in our representation, and this can be dependent on what we intend to do to the system.We can incorporate context specific information that is informative about various causal hypotheses (see for example [8]).This is particularly useful in models of biological regulatory mechanisms, which typically contain many noisy and and orgates [28].In [28] we introduced an alternative graphical model — the Chain Event Graph (CEG), constructed from an event treetogether with a set of exchangeability assumptions. It can be seen as a generalisation of a probability graph [3,27], andtypically has many fewer nodes than the original tree. The CEG retains those characteristics of the event tree which allowfor the representation of asymmetric problems; but they are also more flexible and useful, since their nodes representintrinsic events in the problem and their edges dependencies between them. They express topologically all the conditionalindependence structure associated with a problem (this is not bolted on as with context-specific BNs), and also any samplespace information generated by the asymmetry of the problem. So in a non-causal context, CEGs provide a more expressive(if somewhat more complicated) topological framework for expressing collections of conditional independence statementsthan the discrete BN.We present here an extension of CEG models which provides a framework for causal reasoning. We believe this extensionto be as transparent and compelling as the extension from BNs to CBNs. In Section 2 we give a brief definition of the CEGand a description of how to read conditional independence properties from it. This section also contains an example of howan asymmetric problem can be depicted using such a graph. Section 3 introduces the manipulation of these graphs, and thistheory is developed in Section 4 where we address the identification of the effects of manipulations. Section 5 introduces aBack Door Theorem for CEGs, a generalisation of Pearl’s Back Door Theorem for BNs [21].2. Chain Event Graphs2.1. DefinitionWe provide here a brief definition and description of the CEG. A more comprehensive definition can be found in [28].The CEG is a function of an event tree [27], and we begin this section with a brief description of this graph. An event treeT is a directed, rooted tree, with vertex set V (T ) and edge set E(T ). The non-leaf vertices are called situations and the setof situations S(T ). The root-to-leaf paths {λ} of T form the atoms of the event space (called the path σ -algebra of T ), andlabel the different possible unfoldings of the described process. Events measurable with respect to this space are unions ofthese atoms.Each situation v serves as an index of a random variable X(v) whose values describe the next stage of possible de-velopments of the unfolding process. The state space X(v) of X(v) can be identified both with the set of directed edges(cid:3) ∈ V (T ) of these edges. For each X(v) (v ∈ S(T ))e(v, vwe let(cid:3)) ∈ E(T ) emanating from v in T and the set of end-nodes vΠ(v) ≡(cid:3)(cid:3)(cid:2)π(cid:4)(cid:4) v(cid:5) (cid:4)(cid:4) vv(cid:3) | v) ≡ P ( X(v) = v(cid:6)(cid:3) ∈ X(v)(cid:3)) are called the primitive probabilities of the tree; andwhere π (vΠ(T ) ≡(cid:2)(cid:6)Π(v)v∈S(T )A full specification of the probability model is given by (T , Π(T )).We extend Shafer’s definition of an event tree by the introduction of three further properties — coloured edges, stagesand positions.\fP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909891Definition 1. The stages, colouring and positions of an event tree are defined as follows:1. Two situations v 1 and v 2 are in the same stage u if X(v 1) and X(v 2) have the same distribution under some bijectionψ between their sample spaces. We label the set of stages of the tree T by L(T ).2. For v 1, v 2 ∈ u (for some stage u), the edges e(v 1, v 1(cid:3)) and e(v 2, v 2(cid:3)) have the same colour if e(v 1, v 1(cid:3)) maps to e(v 2, v 2(cid:3))under this bijection ψ , and π (v 2(cid:3) | v 2) = π (v 1(cid:3) | v 1).3. Two situations v 1 and v 2 are in the same position w if for each subpath emanating from v 1, the ordered sequence ofcolours is the same as that for some subpath emanating from v 2. We label the set of positions of the tree T by K (T ).So two situations are in the same stage when the immediate future evolution from both situatio",
            {
                "entities": [
                    [
                        3488,
                        3516,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1094–1118www.elsevier.com/locate/artintDomain permutation reduction for constraint satisfaction problemsMartin J. Green ∗, David A. CohenComputer Science Department, Royal Holloway, University of London, Egham, Surrey, TW20 0EX, UKReceived 24 January 2007; received in revised form 28 November 2007; accepted 7 December 2007Available online 15 December 2007AbstractThis paper is concerned with the Constraint Satisfaction Problem (CSP). It is well-known that the general CSP is NP-hard.However, there has been significant success in discovering subproblems which are tractable (polynomial time solvable). One ofthe most effective ways to obtain a tractable subproblem has been to force all of the constraint relations to lie in some tractablelanguage.In this paper we define a new way of identifying tractable subproblems of the CSP. Let P be an arbitrary CSP instance and Γbe any tractable language. Suppose there exists, for each variable of P , a permutation of the domain such the resultant permutedconstraint relations of P all lie in Γ . The domain permuted instance is then an instance of a tractable class and can be solved bythe polynomial time algorithm for Γ . Solutions to P can be obtained by inverting the domain permutations.The question, for a given class of instances and language Γ , whether such a set of domain permutations can be found efficientlyis the key to this method’s tractability. One of the important contributions made in this paper is the notion of a “lifted constraintinstance” which is a powerful tool to study this question.• We consider the open problem of discovering domain permutations which make instances max-closed. We show that, forbounded arity instances over a Boolean domain this problem is tractable, while for domain size three it is intractable even forbinary instances.• We give a simple proof verifying the tractability of discovering domain permutations which make instances row convex.We refute a published result by giving a simple proof of the intractability of discovering domain permutations which makeinstances, even with domain size four, connected row convex.• We demonstrate that triangulated and stable marriage instances are reducible, via domain permutations, to max-closed in-stances. This provides a simple explanation for arc consistency deciding these instances.• We verify with a simple direct proof the tractability of identification of renamable Horn instances, and the intractability offinding the largest renamable Horn subset of clauses of an instance of SAT.• We describe natural tractable classes which properly extend the maximal relational classes arising from tractable constraintlanguages.We believe that domain permutation reductions have a significant chance of being useful in practical applications.© 2008 Elsevier B.V. All rights reserved.Keywords: Complexity; Constraint satisfaction problem; CSP; NP-completeness; Renamable Horn; Stable marriage; Tractability* Corresponding author.E-mail address: M.J.Green@cs.rhul.ac.uk (M.J. Green).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.12.001\fM.J. Green, D.A. Cohen / Artificial Intelligence 172 (2008) 1094–111810951. IntroductionThe constraint satisfaction paradigm involves modelling a real-world problem as a set of variables to which wecan assign values from some domain [44]. The values that can be assigned are limited by constraints. A constraintconsists of a list of variables (its scope), and a set of tuples which are the allowed assignments to this list of variables(its relation). A solution is the assignment of a value from the domain to every variable so that all of the constraintsare satisfied.Many real-world problems are naturally represented as instances of the general constraint satisfaction problem(CSP), including planning [40], scheduling [48], image processing [44], frequency assignment [21] and natural lan-guage understanding [1].The CSP is NP-hard [43]. This motivates the search for polynomial time solvable (tractable) subproblems.The structure of a CSP instance is the hypergraph whose hyperedges are the scopes (abstracted to be sets of distinctvariables) of the constraints. The set of CSP instances whose structure is acyclic form a tractable subproblem [4].This structural tractability result has been extended by identifying tractable decompositions of hypergraphs (cycle-cutset [17], hypertree decompositions [30], hinges [22,33], tree-clustering [18], etc.). These decompositions all jointhe original constraints in sets of size at most k and project each such join to form the constraints of a new, solutionequivalent, acyclic CSP instance [15]. The value k is called the width of the decomposition. A decomposition istractable if, for any k, the set of instances with width at most k can be tractably identified and reduced to the acycliccase.It is rare that a real-world example has an acyclic structure when modelled as a CSP instance. However the possibil-ity of using these widely applicable decompositions to reduce instances to the acyclic case makes structural tractabilityuseful in practice.A constraint language is a set of allowed (constraint) relations. A relational subproblem of the CSP consists ofthose instances whose relations lie in a specified language. A language which gives a tractable relational subproblemis called tractable [34,35]. Many tractable languages have been discovered [7,46].This paper introduces a new study: reductions by domain permutations. A domain permutation reduction of an in-stance to a given subproblem of the CSP is an independent permutation of the domain of each variable that transformsthe instance to lie in that subproblem. Some preliminary results appeared in a conference paper [32].We will show that determining whether a domain permutation reduction exists for a particular instance to a rela-tional subproblem corresponds exactly to the solving of an associated instance of another CSP subproblem. When this“lifted” problem for a tractable language is itself tractable then, under certain natural assumptions, we obtain a newlarge tractable subproblem.We consider the well-known max-closed tractable languages [36]. In their original paper Jeavons and Cooper leftas an open question whether there exists an efficient algorithm that can decide, for any given instance, if a domainpermutation exists that makes the instance max-closed [36]. We answer this question in Section 5.2 for the case wherethe domain has three or more elements (it is intractable) by analysing the appropriate lifted problem.However, by more careful analysis of the lifted problem for max-closed languages we are able to properly extendthe tractable subproblem of bounded arity Boolean max-closed instances. We can also extend the tractable subprob-lem of all binary max-closed instances, which has been shown [36] to be maximal as a tractable binary relationalsubproblem of the CSP.Our theory also explains why the constraint representation of the Stable Marriage Problem (SMP) [27] is tractablysolvable. We have shown that these instances have a natural domain permutation reduction to the max-closed sub-problem.Recently, a new tractable subproblem of binary instances for which arc consistency is a decision procedure, knownas triangulated CSP instances [12], has been described. It was left as an open question to discover if some unifyingreason exists that explains why arc consistency is a decision procedure for this class. In this paper we provide just suchan explanation by showing that these instances also have natural domain permutation reductions to the max-closedsubproblem.A row convex CSP instance [49] can be transformed by a domain permutation to make a particular combinatoricproperty hold for its constraint relations. A connected row convex CSP instance [20] satisfies a slightly more restrictivecombinatoric property (without first applying a domain permutation restriction). This stronger property is preservedby projection and join. It was left as an open question as to whether we can tractably identify the instances for\f1096M.J. Green, D.A. Cohen / Artificial Intelligence 172 (2008) 1094–1118which domain permutations exist transforming them into connected row convex instances. An incorrect answer tothis question has unfortunately appeared in the literature. In this paper we give a simple and correct answer to thisquestion.We also have a natural explanation for the tractability of renamable Horn theories [3,42], since the lifted problemscan easily be shown to be contained in the tractable majority-closed relational subclass [38]. It has been shown usingad-hoc methods that it is NP-hard to find the largest renamable Horn theory which is a subset of a given set ofclauses [19]. By analysing the lifted language this result becomes a simple consequence of a well-known result in thetheory of the MAX-SAT problem [16].1.1. Outline of the paperWe give the necessary basic definitions in Section 2 and then continue in Section 3 by discussing tractable constraintlanguages.We introduce our new work in Section 4 with the concept of a domain permutation reduction to a tractable relationalsubproblem and its associated lifted problem. We show the power of the new theory with an analysis of the domainpermutation reductions to the max-closed constraint language in Section 5.We use our new theory in Section 6 to:• develop some new tractable subproblems of the CSP;• unify several disparate known tractable subproblems;• show that the main results from renamable Horn theory may be obtained directly.We conclude the paper in Section 7 with final remarks and directions for future research.2. DefinitionsIn this section we will give a formal definition of a constraint satisfaction problem instance, and the associatednotions required for the paper.2.1. Constraint satisfaction problem instancesDefinition 1. An r-ary relation, ρ, over D is a subset of Dr .For any t ∈ ρ we den",
            {
                "entities": [
                    [
                        3133,
                        3161,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 162 (2005) 145–204www.elsevier.com/locate/artintTowards a practical theory of reformulationfor reasoning about physical systemsBerthe Y. Choueiry a,∗, Yumi Iwasaki b, Sheila McIlraith ca Constraint Systems Laboratory, Department of Computer Science and Engineering,University of Nebraska-Lincoln, Lincoln, NE 68588-0115, USAb Woodinville, WA, USAc Department of Computer Science, University of Toronto, Toronto, Ontario, Canada M55 3H5Received 20 November 2001; accepted 14 November 2002Available online 15 December 2004The authors would like to dedicate this article to the memory of Robert S. Engelmore. He was a long-time friendand senior colleague of the authors. He was also an important contributor to the initial discussion group at KSLthat eventually lead us to write this article. We dearly miss him and regret that he did not live to read this productof the many discussions we had with him.AbstractReformulation is ubiquitous in problem solving and is especially common in modeling physicalsystems. In this paper we examine reformulation techniques in the context of reasoning about phys-ical systems. This paper does not present a general theory of reformulation, but it studies a numberof known reformulation techniques to achieve a broad understanding of the space of available refor-mulations. In doing so, we present a practical framework for specifying, classifying, and evaluatingvarious reformulation techniques applicable to this class of problems. Our framework provides theterminology to specify the conditions under which a particular reformulation technique is applica-ble, the cost associated with performing the reformulation, and the effects of the reformulation withrespect to the problem encoding. 2004 Elsevier B.V. All rights reserved.Keywords: Abstraction; Reformulation; Approximation; Reasoning about physical systems* Corresponding author.E-mail addresses: choueiry@cse.unl.edu (B.Y. Choueiry), Yumi_iwasaki@hotmail.com (Y. Iwasaki),sheila@cs.toronto.edu (S. McIlraith).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.004\f146B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041. IntroductionReformulation plays an important role in various intellectual activities and is ubiqui-tous in reasoning about physical systems. Reformulation improves the effectiveness of aproblem-solving process by recasting a problem into a new one that is tailored to a giventask. There are a number of reformulation techniques and the selection of reformulationtechniques must be carried out in the context of a problem-solving task.In this paper we examine the role of reformulation in reasoning about physical systems.To achieve a broad understanding of the space of available reformulations, we study anddiscuss a number of known reformulation techniques. All the methods discussed in thispaper have been presented in the literature, and some are in common use in science andengineering.Our investigations yield two important contributions. First, they provide the first prac-tical framework for a comprehensive description of reformulation techniques. This frame-work, based on our analysis of the field, allows us to characterize reformulation techniquesincluding their applicability conditions and effects along with the assumptions and implicitevaluation criteria underlying them. Such a framework is necessary for the future develop-ment of an automatic mechanism to select a reformulation technique that is appropriate fora task. Second, our study produces a survey of reformulation techniques in reasoning aboutphysical systems. Our framework was essential for undertaking this comparative analysis.Indeed, without a uniform framework from which to characterize reformulation techniquesas diverse as we have considered, a meaningful comparison would have been impossible.Informally, we define reformulation to be a transformation from one encoding of aproblem to another, given a particular problem-solving task. A problem-solving task isaccomplished by the application of a select sequence of reformulations to an initial problemencoding to produce a final encoding that directly addresses the task. We use the termreformulation to subsume the notions of abstraction and approximation, while avoidingthe implication that such a transformation necessarily generalizes or simplifies the domaintheory.Given a reasoning problem, one may choose to reformulate for any of the followingreasons:1. Engine-driven problem re-encoding: There may not be a method to solve the givenproblem as is. In such a case, one may choose to reformulate the original problemby approximating it by another problem (or a set of problems) for which a solutionmethod is known. For example, if the original problem requires one to solve a set ofnonlinear differential equations, engineers often substitute the original problem with aset of linear differential equations that approximate the nonlinear equations.2. Performance-driven problem re-encoding: The given problem may be too expensive tosolve by an available method, forcing one to reformulate into a similar problem that iseasier to solve. For example, if a given set of linear differential equation is too large tosolve with available computational resources, one may choose to aggregate to producea less detailed but smaller model.3. Supporting cognitive insight: One may choose to reformulate in order to gain cognitiveinsight into the problem or solution space. Mapping from Cartesian coordinates to\fB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204147polar coordinates, mapping a time domain to a frequency domain, reformulating theequations of an electric circuit in terms of the voltage and current into ones in terms ofpower are all examples of reformulation that are sometimes performed to make certainaspects of the system behavior easier to detect and/or analyze.Note that a given reformulation can serve multiple purposes. A reformulation methodapplied to reduce the cost of solution may also improve one’s understanding of the overallbehavior of a complex problem.For the purposes of this paper, we have elected to focus on a specific class of prob-lems, in an effort to develop a framework for characterizing reformulation methods withsufficient detail to be useful to practitioners and researchers alike. In particular, we exam-ine reformulation techniques that can be exploited to reason about physical systems. Thelong-term goal of our research is to develop an automatic task-driven capability that se-lects and applies appropriate reformulation techniques in the course of problem solving.An essential tool towards this ultimate goal is a practical framework for characterizingand evaluating the merits and relevance of various reformulation techniques. This paperproposes such a framework with respect to the restricted class of problems we describedabove. The motivation for developing such a framework came from the observation thatmuch of the previous work on reformulation (including abstraction and approximation)was not sufficient for our purpose. It was either too specific to account for the large va-riety of reformulation methods commonly used in reasoning about physical systems, ortoo general for characterizing them in sufficient details to allow informed selection amongthem. The framework we present provides a significant step towards our long-term goalby defining general criteria for understanding the properties and assessing the merits ofvarious reformulation procedures. More specifically, the framework provides the means toidentify the conditions under which a reformulation is applicable, the cost associated withperforming the reformulation, and the effects of the reformulation both with respect to theproblem encoding and with respect to the accuracy and cost of reasoning.The paper is organized as follows. Section 2 discusses the motivations behind our en-deavor and its scope. Section 3 describes the processing stages of reasoning about physicalsystems to define the context for the types of reformulation we are interested in. The frame-work for characterizing reformulation techniques is introduced in Section 4, where weprovide a detailed description of the framework itself and present a set of evaluators forassessing the effects of reformulation. Section 5 uses the framework to actually analyzea number of known reformulation techniques. Section 6 discusses related work. Finally,Section 7 summarizes our contributions and outline directions for future research.2. Motivation and scopeIn this section, we first state the motivations of this paper, then we justify our reasons forusing the term reformulation in an effort to clear up the ambiguity of previous terminology.\f148B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2042.1. MotivationReformulation is ubiquitous in reasoning about complex systems. Analyzing the be-havior of a complex electro-mechanical device in full detail, taking into account all itselectrical, mechanical, and thermal aspects is too costly and unnecessary for most purposes.Engineers and scientists are accustomed to reformulating repeatedly the mathematicalmodel of a complex physical system in order to reduce the complexity of analysis, tofacilitate the explanation of the problem or a solution to others, or often, even to be able toanalyze the system at all. There are numerous known techniques for reformulation that areused by engineers and scientists. AI literature also abounds with such techniques. A libraryof reformulation techniques and an ability to select from it the most appropriate techniquefor a given problem would greatly enhance the power of a program for reasoning aboutphysical systems.To compile such a library or to enable informed selection from it, we need a systematicway to compare and evaluate reformulation techniques, which the field currently lacks.This lack may be due to the fact that many commonly ",
            {
                "entities": [
                    [
                        2106,
                        2134,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 31–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the approximability of Dodgson and Young elections ✩Ioannis Caragiannis a, Jason A. Covey b, Michal Feldman c,d, Christopher M. Homan b,Christos Kaklamanis a, Nikos Karanikolas a, Ariel D. Procaccia e,∗, Jeffrey S. Rosenschein fa Computer Technology Institute and Department of Computer Engineering and Informatics, University of Patras, 26504 Rio, Greeceb Department of Computer Science, Rochester Institute of Technology, 102 Lomb Memorial Drive, Rochester, NY 14623-5603, USAc School of Business Administration and Center for the Study of Rationality, The Hebrew University of Jerusalem, Jerusalem 91904, Israeld Microsoft Israel R&D Center, Israele School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USAf School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 18 January 2011Received in revised form 8 April 2012Accepted 10 April 2012Available online 16 April 2012Keywords:Computational social choiceApproximation algorithmsThe voting rules proposed by Dodgson and Young are both designed to find an alternativeclosest to being a Condorcet winner, according to two different notions of proximity; thescore of a given alternative is known to be hard to compute under either rule. In this paper,we put forward two algorithms for approximating the Dodgson score: a combinatorial,greedy algorithm and an LP-based algorithm, both of which yield an approximation ratio ofHm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number.We also prove that our algorithms are optimal within a factor of 2, unless problems inN P have quasi-polynomial-time algorithms. Despite the intuitive appeal of the greedyalgorithm, we argue that the LP-based algorithm has an advantage from a social choicepoint of view. Further, we demonstrate that computing any reasonable approximation ofthe ranking produced by Dodgson’s rule is N P-hard. This result provides a complexity-theoretic explanation of sharp discrepancies that have been observed in the social choicetheory literature when comparing Dodgson elections with simpler voting rules. Finally, weshow that the problem of calculating the Young score is N P-hard to approximate by anyfactor. This leads to an inapproximability result for the Young ranking.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe discipline of voting theory deals with the following setting: there is a group of n agents and each of them ranks aset of m alternatives; one alternative is to be elected. The big question is: which alternative best reflects the social good?This question is fundamental to the study of multiagent systems, because the agents of such a system often need tocombine their individual objectives into a single output or decision that best reflects the aggregate needs of all the agentsin the system. For instance, web meta-search engines [12] and recommender systems [21] have used methods based onvoting theory.Reflecting on this question, the French philosopher and mathematician Marie Jean Antoine Nicolas de Caritat, marquis deCondorcet, suggested the following intuitive criterion: the winner should be an alternative that beats every other alternative✩A preliminary version of the results in this paper appeared in the Proceedings of the 20th Annual ACM–SIAM Symposium on Discrete Algorithms (SODA’09).* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), jac8687@cs.rit.edu (J.A. Covey), mfeldman@huji.ac.il (M. Feldman), cmh@cs.rit.edu(C.M. Homan), kakl@ceid.upatras.gr (C. Kaklamanis), nkaranik@ceid.upatras.gr (N. Karanikolas), arielpro@seas.harvard.edu (A.D. Procaccia), jeff@cs.huji.ac.il(J.S. Rosenschein).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.004\f32I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51in a pairwise election, i.e., an alternative that a (strict) majority of the agents prefers over any other alternative. Sadly, it isfairly easy to see that the preferences of the majority may be cyclic, hence a Condorcet winner does not necessarily exist.This unfortunate phenomenon is known as the Condorcet paradox (see Black [5]).In order to circumvent this result, several researchers have proposed choosing an alternative that is “as close as pos-sible” to a Condorcet winner. Different notions of proximity can be considered, and yield different voting rules. One suchsuggestion was advocated by Charles Dodgson, better known by his pen name Lewis Carroll, author of “Alice’s Adventuresin Wonderland.” The Dodgson score [5] of an alternative, with respect to a given set of agents’ preferences, is the minimumnumber of exchanges between adjacent alternatives in the agents’ rankings one has to introduce in order to make the givenalternative a Condorcet winner. A Dodgson winner is any alternative with a minimum Dodgson score.Young [45] raised a second option: measuring the distance by agents. Specifically, the Young score of an alternative is thesize of the largest subset of agents such that, if only these ballots are taken into account, the given alternative becomesa Condorcet winner. A Young winner is any alternative with the maximum Young score. Alternatively, one can perceive aYoung winner as the alternative that becomes a Condorcet winner by removing the fewest agents.Though these two voting rules sound appealing and straightforward, they have been criticized because they fail to meetseveral well-studied classical fairness criteria [18,6]. However, impossibility results tell us that every voting rule likewisefails to satisfy some such criterion. Thus, there is no hope of finding a voting rule that is perfect for all situations. Instead,social choice theory has advanced our understanding of an ever-increasing body of voting rules, each of which has uniquefeatures, virtues, and vices. Practitioners can choose from this body whichever rules best apply to their particular situations.Dodgson and Young voting are two such rules, as are the two approximation algorithms introduced later in this article.A less ambiguous drawback of Dodgson and Young voting is that they are notoriously complicated to resolve. As early as1989, Bartholdi, Tovey and Trick [2] showed that the Dodgson score decision problem is N P -complete, and that pinpointinga Dodgson winner is N P -hard. This important paper was one of the first to introduce complexity-theoretic considerationsto social choice theory. Hemaspaandra et al. [23] refined the aforementioned result by showing that the Dodgson winnerdecision problem is complete for Θ p2 , the class of problems that can be solved by O(log n) queries to an N P set. Subse-quently, Rothe et al. [41] proved that the Young winner problem is also complete for Θ p2 .These complexity-theoretic results give rise to the agenda of approximately calculating an alternative’s score, under theDodgson and Young schemes. This is clearly an interesting computational problem, as an application area of algorithmictechniques.However, from the point of view of social choice theory, it is not immediately apparent that an approximation of avoting rule is satisfactory, since an “incorrect” alternative—in our case, one that is not closest to a Condorcet winner—mightbe elected. The key insight is that an approximation of a voting rule is a voting rule in its own right, and in some cases onecan argue that this new voting rule has desirable properties. We discuss this point at length, and justify our approach, inSection 7.1.1. Our resultsIn the context of approximating the Dodgson score, we devise a greedy algorithm for the Dodgson score which has anapproximation ratio of Hm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number. Wethen propose a second algorithm that is based on solving a linear programming relaxation of the Dodgson score and hasthe same approximation ratio. Although the former algorithm gives us a better intuition into the combinatorial structureof the problem, we show that the latter has the advantage of being score monotonic, which is a desirable property froma social choice point of view. We further observe that it follows from the work of McCabe-Dansted [30] that the Dodgsonscore cannot be approximated within sublogarithmic factors by polynomial-time algorithms unless P = N P . We prove amore explicit inapproximability result of (1/2 − (cid:3)) ln m, under the assumption that problems in N P do not have algorithmsrunning in quasi-polynomial time; this implies that the approximation ratio achieved by our algorithms is optimal up to afactor of 2.A number of recent papers [38,39,27–29] have established that there are sharp discrepancies between the Dodgsonranking and the rankings produced by other rank aggregation rules. Some of these rules (e.g., Borda and Copeland) arepolynomial-time computable, so the corresponding results can be viewed as negative results regarding the approximabilityof the Dodgson ranking by polynomial-time algorithms. We show that the problem of distinguishing between whether am) positions in any Dodgson ranking is N P -hard. Thisgiven alternative is the unique Dodgson winner or in the last O (theorem provides a complexity-theoretic explanation for some of the observed discrepancies, but in fact is much wider inscope as it applies to any efficiently computable rank aggregation rule.√At first glance, the problem of calculating the Young score seems simple compared with the Dodgson score (we discussin Section 6 why this seems so). Therefore, we found the following result quite surprising: it is N P -hard to approximate theYoung score within any factor. Specifically, we show that it is N P -hard to distinguish between the case where the ",
            {
                "entities": [
                    [
                        4004,
                        4032,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 189–221Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintReasoning about discrete and continuous noisy sensors and effectors in dynamical systemsVaishak Belle a,b,∗a University of Edinburgh, Edinburgh, United Kingdomb The Alan Turing Institute, London, United Kingdomc University of Toronto, Toronto, Canada, Hector J. Levesque ca r t i c l e i n f oa b s t r a c tAmong the many approaches for reasoning about degrees of belief in the presence of noisy sensing and acting, the logical account proposed by Bacchus, Halpern, and Levesque is perhaps the most expressive. While their formalism is quite general, it is restricted to fluents whose values are drawn from discrete finite domains, as opposed to the continuous domains seen in many robotic applications. In this work, we show how this limitation in that approach can be lifted. By dealing seamlessly with both discrete distributions and continuous densities within a rich theory of action, we provide a very general logical specification of how belief should change after acting and sensing in complex noisy domains.Crown Copyright © 2018 Published by Elsevier B.V. All rights reserved.Article history:Received 27 October 2016Received in revised form 26 March 2018Accepted 5 June 2018Available online 26 June 2018Keywords:Knowledge representationReasoning about actionReasoning about knowledgeReasoning about uncertaintyProbabilistic logical modelsCognitive robotics1. IntroductionOn numerous occasions it has been suggested that the formalism [the situation calculus] take uncertainty into account by attaching probabilities to its sentences. We agree that the formalism will eventually have to allow statements about the probabilities of events, but attaching probabilities to all statements has the following objections:1. It is not clear how to attach probabilities to statements containing quantifiers in a way that corresponds to the amount of conviction people have.2. The information necessary to assign numerical probabilities is not ordinarily available. Therefore, a formalism that required numerical probabilities would be epistemologically inadequate.− McCarthy and Hayes [1].Much of high-level AI research is concerned with the behavior of some putative agent, such as an autonomous robot, operating in an environment. Broadly speaking, an intelligent agent interacting with a dynamic and incompletely known world grapples with two special sorts of reasoning problems. First, because the world is dynamic, it will need to reason about change: how its actions affect the state of the world. Pushing an object on a table, for example, may cause it to fall on the floor, where it will remain unless picked up. Second, because the world is incompletely known, the agent will need to make do with partial specifications about what is true. As a result, the agent will often need to augment what it believes about the world by performing perceptual actions, using sensors of one form or another.* Corresponding author at: University of Edinburgh, Edinburgh, United Kingdom.E-mail addresses: vaishak@ed.ac.uk (V. Belle), hector@cs.toronto.edu (H.J. Levesque).https://doi.org/10.1016/j.artint.2018.06.0030004-3702/Crown Copyright © 2018 Published by Elsevier B.V. All rights reserved.\f190V. Belle, H.J. Levesque / Artificial Intelligence 262 (2018) 189–221Fig. 1. A simple robot.For many AI applications, and robotics in particular, these reasoning problems are more involved. Here, it is not enough to deal with incomplete knowledge, where some formula φ might be unknown. One must also know which of φ or ¬φ is the more likely, and by how much. In addition, both the sensors and the effectors that the agent uses to modify its world are often subject to uncertainty in that they are noisy.To see a very simple example, imagine a robot moving towards a wall as shown in Fig. 1, and a certain distance h from it. Suppose the robot can move towards and away from the wall, and it is equipped with a distance sensor aimed at the wall. Here, the robot may not know the true value of h but may believe that it takes values from some set, say {2, . . . , 11}. If the sensor is noisy, a reading of, say, 5 units, does not guarantee that the agent is actually 5 units from the wall, although it should serve to increase the agent’s degree of belief in that fact. Analogously, if the robot intends to move by 1 unit and the effector is noisy, it may end up moving by 0.9 units, which the agent does not get to observe. Be that as it may, the robot’s degree of belief that it is closer to the wall should increase.While many proposals have appeared in the literature to address such concerns (cf. penultimate section), very few are embedded in a general theory of action whilst supporting features like disjunction and quantification. For example, graph-ical models such as Bayesian networks can represent and reason about the probabilistic dependencies between random variables, and how that might change over time. However, it lacks first-order features and a rich account of actions. Re-lational graphical models, including Markov logic networks [2], borrow devices from first-order logic to allow the succinct modeling of relational dependencies, but ultimately they are purely syntactic extensions to graphical models, and do not attempt to address the deeper issues pertaining to the specification of probabilities in the presence of logical connectives and quantifiers. Building on first-order accounts of probabilistic reasoning [3,4], perhaps the most general formalism for dealing with degrees of beliefin formulas, and in particular, with how degrees of belief should evolve in the presence of noisy sensing and acting is the account proposed by Bacchus, Halpern, and Levesque [5], henceforth BHL. Among its many properties, the BHL model shows precisely how beliefs can be made less certain by acting with noisy effectors, but made more certain by sensing (even when the sensors themselves are noisy).The main advantage of a logical account like BHL is that it allows a specification of belief that can be partial or incom-plete, in keeping with whatever information is available about the application domain. It does not require specifying a prior distribution over some random variables from which posterior distributions are then calculated, as in Kalman filters, for example [6]. Nor does it require specifying the conditional independences among random variables and how these depen-dencies change as the result of actions, as in the temporal extensions to Bayesian networks [7]. In the BHL model, some logical constraints are imposed on the initial state of belief. These constraints may be compatible with one or very many initial distributions and sets of independence assumptions. All the properties of belief will then follow at a corresponding level of specificity.Subjective uncertainty is captured in the BHL account using a possible-world model of belief [8–10]. In classical possible-world semantics, a formula φ is believed to be true when φ holds in all possible worlds that are deemed accessible. In BHL, the degree of belief in φ is defined as a normalized sum over the possible worlds where φ is true of some nonnegative weights associated with those worlds. (Inaccessible worlds are assigned a weight of zero.) To reason about belief change, the BHL model is then embedded in a rich theory of action and sensing provided by the situation calculus [1,11,12]. The BHL account provides axioms in the situation calculus regarding how the weight associated with a possible world changes as the result of acting and sensing. The properties of belief and belief change then emerge as a direct logical consequence of the initial constraints and these changes in weights.For example, suppose h is a fluent representing the robot’s horizontal distance to the wall in Fig. 1. The fluent h would have different values in different possible worlds. In a BHL specification, each of these worlds might be given an initial weight. For example, a uniform distribution might give an equal weight of .1 to ten possible worlds where h ∈ {2, 3, . . . , 11}. The degree of belief in a formula like (h < 9) is then defined as a sum of the weights, and would lead here to a value of .7. The theory of action would then specify how these weights change as the result of acting (such as moving away or towards the wall) and sensing (such as obtaining a reading from a sonar aimed at the wall). Naturally, the logical language permits weaker specifications, involving disjunctions and quantifiers, and the appropriate behavior would still emerge.While this model of belief is widely applicable, it does have one serious drawback: it is ultimately based on the addition of weights and is therefore restricted to fluents having discrete finite values. This is in stark contrast to robotics and ma-chine learning applications [13–15], where event and observation variables are characterized by continuous distributions, or perhaps combinations of discrete and continuous ones. There is no way to say in BHL that the initial value of h is any real number drawn from a uniform distribution on the interval [2, 12]. One would again expect the belief in (h < 9) to be .7, \fV. Belle, H.J. Levesque / Artificial Intelligence 262 (2018) 189–221191but instead of being the result of summing weights, it must now be the result of integrating densities over a suitable space of values, something quite beyond the BHL approach.So, on the one hand, the BHL account and others like it can be seen as general formal theories that attempt to address important philosophical problems such as those raised by McCarthy and Hayes above. But on the other, a serious criticism leveled at this line of work, and indeed at much of the work in reasoning about action, is that the theory is far removed from the kind of probabilistic uncertainty and noise seen in typical robotic applicat",
            {
                "entities": [
                    [
                        3219,
                        3247,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 258–298Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpatial reasoning in a fuzzy region connection calculusSteven Schockaert∗,1, Martine De Cock, Etienne E. KerreGhent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281 – S9, 9000 Gent, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 March 2008Received in revised form 18 August 2008Accepted 29 October 2008Available online 6 November 2008Keywords:Spatial reasoningRegion connection calculusFuzzy set theoryAlthough the region connection calculus (RCC) offers an appealing framework for modellingtopological relations,its application in real-world scenarios is hampered when spatialphenomena are affected by vagueness. To cope with this, we present a generalization ofthe RCC based on fuzzy set theory, and discuss how reasoning tasks such as satisfiabilityand entailment checking can be cast into linear programming problems. We furthermorereveal that reasoning in our fuzzy RCC is NP-complete, thus preserving the computationalcomplexity of reasoning in the RCC, and we identify an important tractable subfragment.Moreover, we show how reasoning tasks in our fuzzy RCC can also be reduced to reasoningtasks in the original RCC. While this link with the RCC could be exploited in practicalreasoning algorithms, we mainly focus on the theoretical consequences. In particular, usingthis link we establish a close relationship with the Egg–Yolk calculus, and we demonstratethat satisfiable knowledge bases can be realized by fuzzy regions in any dimension.© 2008 Elsevier B.V. All rights reserved.1. IntroductionTopological relations constitute an important facet of how humans perceive spatial configurations. Consequently, a largeproportion of the spatial information conveyed in natural language discourse is related to topology: we may find, for in-stance, that a certain geographic region is adjacent to, contained in or overlapping with another. The region connectioncalculus (RCC; [39]) has been proposed as a means to model such topological relations, and to reason about available topo-logical information (e.g., if a is adjacent to b, and b is a part of c, then c cannot be a part of a, regardless of how the regionsa, b and c are defined). A core feature of this calculus, discriminating it from related approaches such as the 9-intersectionmodel [12], is its generality. Starting from an arbitrary universe U of regions, topological relations are defined in terms ofan arbitrary reflexive and symmetric relation C in U , called connection (see Table 1 in Section 2). The intuitive meaning ofsome of the RCC relations from Table 1 is illustrated in Fig. 1. In particular, note that EC (externally connected) models adja-cency, while containment is modelled by TPP (tangential proper part), NTPP (non-tangential proper part) and EQ (equality).In different applications, regions can be modelled in different ways, and connection can be defined accordingly. Typically,regions are regular closed subsets of R2 or R3 and two regions a and b are called connected iff a ∩ b (cid:4)= ∅, although, forinstance, Z2 and Z3 are often of interest as well [29]. Furthermore, due to its generality, the RCC can also be applied incontexts where space is used in a metaphorical way (e.g., [38]). Note that frequently, the RCC is restricted to eight baserelations, which have the property of being jointly exhaustive and pairwise disjoint: DC (disconnected), EC, PO (partially−1. The RCC restricted to (unions of) these eight relations is referred to as RCC-8.overlaps), EQ , TPP, NTPP, TPPWhen using the RCC in applications, it is usually assumed that regions are well-defined entities, e.g., characterizedby precise boundaries. On the other hand, many geographical regions, for instance, are inherently ill-defined. For example,−1 and NTPP* Corresponding author.E-mail addresses: Steven.Schockaert@UGent.be (S. Schockaert), Martine.DeCock@UGent.be (M. De Cock), Etienne.Kerre@UGent.be (E.E. Kerre).1 Postdoctoral Fellow of the Research Foundation – Flanders.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.009\fS. Schockaert et al. / Artificial Intelligence 173 (2009) 258–298259Fig. 1. Intuitive meaning of some RCC relations.Fig. 2. Are the regions B, C , and D contained in region A?although political regions, such as countries, states, and provinces, have officially defined—and therefore precise—boundaries,many of the places people refer to in everyday communication (i.e., vernacular places), do not (e.g., [1,2,13,15,33,57,58]).Even the names of political regions are often used in a way that is not in perfect accordance with their official definitions;a typical example are city neighborhoods, whose official boundaries, if they exist, are merely intended for administrativepurposes (e.g., electoral divisions). Vague regions occur at very different scales (Ghent’s city center, the Highlands, theMiddle East), and a variety of techniques can be used to capture their spatial semantics. Approaches based on supervaluationsemantics (e.g., [1,27,57]), for instance, associate a set of possible crisp precisifications with a vague language concept, andreason about assertions that are true in every precisification, in some precisification, etc., typically using first-order logic.They are mainly motivated by philosophical considerations about the nature of vagueness, and tend to be less suitableas workable, computational models. Particularly popular are techniques which represent a vague region as a pair of crispsets (e.g., [2,4,5]). Their main idea is that a vague region can be approximated by defining a set of locations a which aredefinitely in the vague region, as well as a set of locations a which are in the vague region to some extent (where a ⊆ a);the complement of a is then the set of locations which are definitely not in the vague region. The resulting models are veryefficient, and theoretical results (e.g., reasoning procedures) can usually be obtained relatively easily from existing resultsfor crisp regions. Note that vague regions are in this case formally equivalent to ensembles flous [18] of locations. Finally,fuzzy set theory is frequently employed to model vague regions (e.g., [15,19,22,30,31]). In this case, the spatial extent of avague region is modelled by a mapping A from locations (points) to the unit interval [0, 1], such that for any location l,A(l) reflects the degree to which l belongs to the vague region. Although the resulting models may be somewhat lessefficient than models based on pairs of crisp regions, their increased flexibility is often needed to accurately capture vagueboundaries. Moreover, a pair (a, a) of crisp regions with a ⊆ a can be seen as a special case of a fuzzy set, e.g., by assigningall points in a membership degree 1, all points in a \\ a membership degree 0.5, and all other points membership degree 0.The existence of vague regions does not, as such, present any difficulties, as the RCC makes no assumptions on therepresentation of regions. However, when some of the regions involved are vague, topological relations can be vague as well.For instance, it is not entirely clear whether the Alps are included in, overlapping with, or disjoint from Southern Europe,as each of these relations seems defensible to some extent. This observation stands in contrast with the assumption thattopological relations are defined in terms of first-order logic and a crisp relation C . Moreover, even if the regions involved arecrisp, it may be desirable to define topological relations as fuzzy relations. In particular, the traditional, strict interpretationof topological relations (e.g., using point-set topology) does not always correspond very well to the way topological relationsare used in natural language. For example, it is commonplace to say that a cabinet is located against a wall even if thereis a gap of a few millimeters between the cabinet and the wall. In traditional frameworks, the cabinet and the wall wouldbe considered disjoint, irrespective of the size of the gap. A more natural solution would be to define topological relationsas fuzzy relations in which the cabinet and the wall are considered adjacent if they are actually touching, or located veryclose to each other. Note that adjacency then becomes a vague concept because it relies on nearness. A similar observationcan be made for containment; consider, for instance, the regions depicted in Fig. 2. Clearly, B is contained in A and D isnot. However, while C is in principle not a part of A, we could intuitively think of C as being a part of A to a large extent,because C is almost contained in A.Our solution is to define C as a fuzzy relation, i.e., for each pair (u, v) of regions, C(u, v) is a degree in [0, 1] reflectingto what extent u and v are connected. Keeping the generality of the RCC, other topological relations are still defined interms of C , using fuzzy logic connectives, however, instead of classical first-order logic. Note that in this way, we make nocommitment at all of why topological relations are vague (e.g., to define relations between vague regions, to model tolerant\f260S. Schockaert et al. / Artificial Intelligence 173 (2009) 258–298natural language relations, etc.). The central aim of this paper is to investigate how this fuzzification of the RCC affectsspatial reasoning. First, Section 2 presents the relevant details of our fuzzification of the RCC. Among others, we illustratehow fuzzy RCC relations can be interpreted in terms of nearness between fuzzy sets. Next, in Section 3, we provide anumber of use cases to further motivate the need for a fuzzy RCC, as well as the need for spatial reasoning in this context.Subsequently, we review some related work in Section 4, discussing shortcomings of existing approaches to handle fuzzytopological information. In Section ",
            {
                "entities": [
                    [
                        4215,
                        4243,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 597–618Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPositive approximation: An accelerator for attribute reduction in roughset theoryYuhua Qian a,c, Jiye Liang a,∗, Witold Pedrycz b, Chuangyin Dang ca Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education, Taiyuan, 030006, Shanxi, Chinab Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canadac Department of Manufacturing Engineering and Engineering Management, City University of Hong Kong, Hong Konga r t i c l ei n f oa b s t r a c tArticle history:Received 15 July 2009Received in revised form 6 April 2010Accepted 7 April 2010Available online 9 April 2010Keywords:Rough set theoryAttribute reductionDecision tablePositive approximationGranular computing1. IntroductionFeature selection is a challenging problem in areas such as pattern recognition, machinelearning and data mining. Considering a consistency measure introduced in rough settheory, the problem of feature selection, also called attribute reduction, aims to retain thediscriminatory power of original features. Many heuristic attribute reduction algorithmshave been proposed however, quite often, these methods are computationally time-consuming. To overcome this shortcoming, we introduce a theoretic framework based onrough set theory, called positive approximation, which can be used to accelerate a heuristicprocess of attribute reduction. Based on the proposed accelerator, a general attributereduction algorithm is designed. Through the use of the accelerator, several representativeheuristic attribute reduction algorithms in rough set theory have been enhanced. Notethat each of the modified algorithms can choose the same attribute reduct as its originalversion, and hence possesses the same classification accuracy. Experiments show that thesemodified algorithms outperform their original counterparts. It is worth noting that theperformance of the modified algorithms becomes more visible when dealing with largerdata sets.© 2010 Elsevier B.V. All rights reserved.Feature selection, also called attribute reduction, is a common problem in pattern recognition, data mining and machinelearning. In recent years, we encounter databases in which both the number of objects becomes larger and their dimen-sionality (number of attributes) gets larger as well. Tens, hundreds, and even thousands of attributes are stored in manyreal-world application databases [6,12,37]. Attributes that are irrelevant to recognition tasks may deteriorate the perfor-mance of learning algorithms [44,45]. In other words, storing and processing all attributes (both relevant and irrelevant)could be computationally very expensive and impractical. To deal with this issue, as was pointed out in [20], some at-tributes can be omitted, which will not seriously impact the resulting classification (recognition) error, cf. [20]. Therefore,the omission of some attributes could not only be tolerable but even desirable relatively to the costs involved in suchcases [32].In feature selection, we encounter two general strategies, namely wrappers [16] and filters. The former employs alearning algorithm to evaluate the selected attribute subsets, and the latter selects attributes by being guided by some sig-nificance measures such as information gain [23,46], consistency [6,41], distance [15], dependency [30], and others. These* Corresponding author. Tel.: +86 0351 7018176; fax: +86 0351 7018176.E-mail addresses: jinchengqyh@sxu.edu.cn (Y.H. Qian), ljy@sxu.edu.cn (J.Y. Liang), pedrycz@ee.ualberta.ca (W. Pedrycz), mecdang@cityu.edu.hk(C.Y. Dang).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.018\f598Y.H. Qian et al. / Artificial Intelligence 174 (2010) 597–618measures can be divided into two main categories: distance-based measures and consistency-based measures [20]. Roughset theory by Pawlak [33–36] is a relatively new soft computing tool for the analysis of a vague description of an object,and has become a popular mathematical framework for pattern recognition, image processing, feature selection, neuro-computing, data mining and knowledge discovery from large data sets [7,11,31]. Attribute reduction in rough set theoryoffers a systematic theoretic framework for consistency-based feature selection, which does not attempt to maximize theclass separability but rather attempts to retain the discernible ability of original features for the objects from the universe[13,14,53].Generally speaking, one always needs to handle two types of data, viz. those that assume numerical values and symbolicvalues. For numerical values, there are two types of approaches. One relies on fuzzy rough set theory, and the other isconcerned with the discretization of numerical attributes. In order to deal with numerical attributes or hybrid attributes,several approaches have been developed in the literature. Pedrycz and Vukovich regarded features as granular rather thannumerical [37]. Shen and Jenshen generalized the dependency function in classical rough set framework to the fuzzy caseand proposed a fuzzy-rough QUICKREDUCT algorithm [13,14,48]. Bhatt and Gopal provided a concept of fuzzy-rough setsformed on compact computational domain, which is utilized to improve the computational efficiency [3,4]. Hu et al. pre-sented a new entropy to measure of the information quantity in fuzzy sets [21] and applied this particular measure toreduce hybrid data [22]. Data discretization is another important approach to deal with numerical values, in which we usu-ally discretize numerical values into several intervals and associate the intervals with a set of symbolic values, see [5,28]. Inthe “classical” rough set theory, the attribute reduction method takes all attributes as those which assume symbolic values.Through preprocessing of original data, one can use the classical rough set theory to select a subset of features that is themost suitable for a given recognition problem.In the last twenty years, many techniques of attribute reduction have been developed in rough set theory. The conceptof the β-reduct proposed by Ziarko provides a suite of reduction methods in the variable precision rough set model [60].An attribute reduction method was proposed for knowledge reduction in random information systems [57]. Five kinds ofattribute reducts and their relationships in inconsistent systems were investigated by Kryszkiewicz [18], Li et al. [24] andMi et al. [29], respectively. By eliminating some rigorous conditions required by the distribution reduct, a maximum distri-bution reduct was introduced by Mi et al. in [29]. In order to obtain all attribute reducts of a given data set, Skowron [49]proposed a discernibility matrix method, in which any two objects determine one feature subset that can distinguish them.According to the discernibility matrix viewpoint, Qian et al. [42,43] and Shao et al. [47] provided a technique of attributereduction for interval ordered information systems, set-valued ordered information systems and incomplete ordered infor-mation systems, respectively. Kryszkiewicz and Lasek [17] proposed an approach to discovery of minimal sets of attributesfunctionally determining a decision attribute. The above attribute reduction methods are usually computationally very ex-pensive, which are intolerable for dealing with large-scale data sets with high dimensions. To support efficient attributereduction, many heuristic attribute reduction methods have been developed in rough set theory, cf. [19,20,22,25,26,39,52,54–56]. Each of these attribute reduction methods can extract a single reduct from a given decision table.1 For convenience,from the viewpoint of heuristic functions, we classify these attribute reduction methods into four categories: positive-regionreduction, Shannon’s entropy reduction, Liang’s entropy reduction and combination entropy reduction. Hence, we reviewonly four representative heuristic attribute reduction methods.(1) Positive-region reductionThe concept of positive region was proposed by Pawlak in [33], which is used to measure the significance of a conditionattribute in a decision table. While the idea of attribute reduction using positive region was originated by J.W. Grzymala-Busse in [9] and [10], and the corresponding algorithm ignores the additional computation required for selecting significantattributes. Then, Hu and Cercone [19] proposed a heuristic attribute reduction method, called positive-region reduction,which remains the positive region of target decision unchanged. The literature [20] gave an extension of this positive-region reduction for hybrid attribute reduction in the framework of fuzzy rough set. Owing to the consistency of ideas andstrategies of these methods, we regard the method from [19] as their representative. These reduction methods are the firstattempt to heuristic attribute reduction algorithms in rough set theory.(2) Shannon’s entropy reductionThe entropy reducts have first been introduced in 1993/1994 by Skowron in his lectures at Warsaw University. Basedon the idea, Slezak introduced Shannon’s information entropy to search reducts in the classical rough set model [50–52].Wang et al. [54] used conditional entropy of Shannon’s entropy to calculate the relative attribute reduction of a decisioninformation system. In fact, several authors also have used variants of Shannon’s entropy or mutual information to measureuncertainty in rough set theory and construct heuristic algorithm of attribute reduction in rough set theory [22,55,56]. Here1 The attribute reduct obtained preserves a particular property of a given decision table. However, as Prof. Bazan said, from the viewpoint of stability ofattribute reduct, the selected reduct may be of bad quality [1,2]. To overcome this problem, Bazan developed a method for dynamic red",
            {
                "entities": [
                    [
                        3804,
                        3832,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1800–1808Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA note on the correctness of the causal ordering algorithmDenver Dash a,b,∗,1, Marek J. Druzdzel c,da Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USAb Department of Biomedical Informatics, School of Medicine, University of Pittsburgh, Pittsburgh, PA 15260, USAc Decision Systems Laboratory, School of Information Sciences and Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA 15260, USAd Faculty of Computer Science, Białystok Technical University, Wiejska 45A, 15-351 Białystok, Polanda r t i c l ei n f oa b s t r a c tArticle history:Received 28 October 2005Received in revised form 16 June 2008Accepted 19 June 2008Available online 28 June 2008Keywords:CausalityStructural equation modelsIn this paper we examine in detail the algorithm of Simon [H.A. Simon, Causal orderingand identifiability, in: W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method.Cowles Commission for Research in Economics, Monograph No. 14, John Wiley & Sons, Inc.,New York, 1953, pp. 49–74, Chapter III], called the causal ordering algorithm (COA), usedfor constructing the “causal ordering” of a system given a complete specification of thesystem in terms of a set of “structural” equations that govern the variables in the system.This algorithm constructs a graphical characterization of the model in a form that we calla partial causal graph. Simon argued in [H.A. Simon, Causal ordering and identifiability, in:W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method. Cowles Commission forResearch in Economics, Monograph No. 14, John Wiley & Sons, Inc., New York, 1953, pp. 49–74, Chapter III] and subsequent papers that a graph so generated explicates causal structureamong variables in the model. We formalize this claim further by proving that any causalmodel based on a one-to-one correspondence between equations and variables must beconsistent with the COA.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThis note is concerned with a technique owing to Simon known as the causal ordering algorithm (COA). Given a self-contained system of simultaneous structural equations, COA will explicate asymmetries among variables in the system andproduce a (possibly partial) matching between variables and equations. In a classic article [24], Simon showed that COAgenerates a directed graph which we call a partial causal graph (PCG). In [24] and in subsequent writings [11,12,25,26] Simonet al. argue that if a set of equations E is self-contained and composed of causal mechanisms, COA will produce causal graphsthat are consistent with experts’ “intuitive” causal orderings. We show in this note that the COA provides a summary ofthe necessary mappings from variables to equations. That is, any one-to-one mapping from variables to equations will beconsistent with the COA. As a special case, when all clusters found by the COA contain only a single variable, then thereexists only one mapping from equations to variables and only one (acyclic) directed causal graph, which is given by COA.1.1. PreliminariesFor the purposes of this note, a causal model is defined as a set of equations together with a one-to-one mapping fromequations to variables in the model (see Fig. 1). Matching a variable to an equation is an assertion that the other variables* Corresponding author at: Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USA.E-mail addresses: denver.h.dash@intel.com (D. Dash), marek@sis.pitt.edu (M.J. Druzdzel).1 This work was performed while Denver Dash was a graduate student at the Intelligent Systems Program, University of Pittsburgh.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.005\fD. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081801Fig. 1. A causal model is specified by a set of equations and a one-to-one correspondence between equations and variables and defines a directed graphover the variables.present in that equation are causal parents of the matched variable. Such a specification of a system defines a directed graph(DiG) which is interpreted as a causal graph. This representation of causality has its roots in structural equation models inthe econometrics literature [8,10,24,30,36,37] and has been developed further within AI over the past decade [6,21,29]).It is frequently the case that we know the equations that govern a given system but we are unsure about the correctmapping from variables to equations. For example, any physical system typically has an associated set of physics equationsthat govern the processes in the system. Many socio-economic models have “laws” that are represented by equations thatmust be satisfied for a given set of assumptions. Given such a set of equations, in order to produce a causal model (asdefined in this note), one must be able to generate a one-to-one correspondence between variables in the system andequations. To do this in general requires detailed background knowledge about causal interactions in the system. In practicefor even modest systems it can become an intractable task by hand. It would thus be desirable to possess an automatedmethod by which the matching between equations and variables can be generated. Such a method would be especiallyvaluable for very large models possessing hundreds or thousands of variables. A central practical problem with such anautomated method is to ensure that the mapping generated has causal meaning.Our contributions here are to formally define a Partial Causal Graph (PCG) and define a notion of consistency between aDiG and a PCG. We then show that the mapping of equations to variables produced by COA will be consistent with any othermapping, and thus the PCG generated by COA will be consistent with any DiG that is consistent with E. By “consistent” wemean in essence that any arc present in the PCG must be present in the DiG, and any arc in the DiG must not be ruledout by the PCG. Our proof requires neither linear equations nor equations which can be solved for unique values for thevariables.We feel that this work is significant because it serves to validate decades of research which has shown COA to be apowerful tool for operating on causal models. One of the primary uses for causal graphs in general is to support the abilityto reason about the effects of manipulation on a real-world system and predict the resulting probability distribution. The Dooperator of Pearl [21] is a well-known case of an operator for modeling manipulation of a variable when such a manipula-tion breaks the connection between the variable and its parents. However, the COA has served as a generating function forall sorts of operations on causal models. For example, COA can be used to model the restructuring that occurs in a dynamiccausal system when it passes through equilibrium [2,3,11]. Yet another operation might be the replacement of some compo-nents with others that depend on qualitatively different factors, such as replacing a spring with a compressible gas piston.COA is capable of modeling manipulation when reversible mechanisms are present in the model [7]. This technique wasused in a model for strategic business planning by the administration at Carnegie Mellon University [23]. Given a library offundamental laws describing an arbitrary system, COA also provides a method to automate the process of model buildingby constructing causal graphs on the fly, depending on which devices are added to the system [16]. The validity of usingCOA for these purposes, however, rests on the existence of a proof of the correctness of COA. Thus, the key significance ofthis paper is that it converts an entire thread of research from a set of useful heuristics to provably correct techniques.1.2. Previous workMuch work on causality has been performed in the past decades in statistics and artificial intelligence. This work hasbeen concerned with representation (e.g., [13,14,19,33,34]), inference (e.g., [15,19]), causal reasoning (e.g., [20,28]), learningfrom data (e.g., [1,18,27,28]), among other topics. Most of this work has dealt with causal models that are very similar tothe type constructed with the COA; however, in their formulations, a causal model is assumed as a given or it is derivedfrom data, and the process of converting a set of equations to a causal model is not considered.Nayak [17] comes the closest to addressing the question that we pose here. He shows that all mappings between struc-tural equations and variables produce the same set of ancestor-descendant pairs. Similarly, we will show that all mappingspossess common features, but these common features will be in terms of direct causal connections rather than indirectancestral relations, and we provide the proof that COA provides a condensed representation of those necessary direct con-nections. Dash [2,3] shows that the causal interpretation of equilibrium systems is not straightforward due to the factthat underlying dynamics can lead to equilibrium independence graphs that are not causal. He terms this reason for non-causality “violation of Equilibration–Manipulation commutability.” We emphasize that the work presented here does notimply that models retrieved by COA are assured to obey the Equilibration–Manipulation commutability property. There existmany other concepts of causality that do not involve a mapping from equations to variables. Granger causality [9] uses\f1802D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808correlations across time to identify causal relations. The work by de Kleer and Brown [4] and that of Williams [35] addressthe problem of determining causality from a set of constraints by propagating disturbances on variables in the model. Thereis a debate as to whether the formalisms of de Kleer and Brown and Williams are consistent wi",
            {
                "entities": [
                    [
                        3837,
                        3865,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 983–1016www.elsevier.com/locate/artintThe complexity of soft constraint satisfactionDavid A. Cohen a, Martin C. Cooper b, Peter G. Jeavons c,∗,Andrei A. Krokhin da Department of Computer Science, Royal Holloway, University of London, UKb IRIT, University of Toulouse III, Francec Computing Laboratory, University of Oxford, UKd Department of Computer Science, University of Durham, UKReceived 4 October 2005; received in revised form 13 February 2006; accepted 13 April 2006Available online 5 June 2006AbstractOver the past few years there has been considerable progress in methods to systematically analyse the complexity of constraintsatisfaction problems with specified constraint types. One very powerful theoretical development in this area links the complexityof a set of constraints to a corresponding set of algebraic operations, known as polymorphisms.In this paper we extend the analysis of complexity to the more general framework of combinatorial optimisation problemsexpressed using various forms of soft constraints. We launch a systematic investigation of the complexity of these problems byextending the notion of a polymorphism to a more general algebraic operation, which we call a multimorphism. We show that manytractable sets of soft constraints, both established and novel, can be characterised by the presence of particular multimorphisms. Wealso show that a simple set of NP-hard constraints has very restricted multimorphisms. Finally, we use the notion of multimorphismto give a complete classification of complexity for the Boolean case which extends several earlier classification results for particularspecial cases.© 2006 Elsevier B.V. All rights reserved.Keywords: Soft constraints; Valued constraint satisfaction; Combinatorial optimisation; Submodular functions; Tractability; Multimorphism1. IntroductionIn the standard constraint satisfaction framework [14,38] a constraint is understood to be a predicate, or relation,specifying the allowed combinations of values for some fixed subset of variables: we will refer to such constraintshere as crisp constraints. Problems with crisp constraints deal only with feasibility: no satisfying solution is consideredbetter than any other.A number of authors have suggested that the usefulness of the constraint satisfaction framework could be greatlyenhanced by extending the definition of a constraint to include also soft constraints, which allow different measuresof desirability to be associated with different combinations of values [1,2,43]. In this extended framework a constraint* Corresponding author.E-mail addresses: d.cohen@rhul.ac.uk (D.A. Cohen), cooper@irit.fr (M.C. Cooper), peter.jeavons@comlab.ox.ac.uk (P.G. Jeavons),andrei.krokhin@durham.ac.uk (A.A. Krokhin).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.04.002\f984D.A. Cohen et al. / Artificial Intelligence 170 (2006) 983–1016can be seen as a cost function defined on a fixed subset of the variables which maps each possible combination ofvalues for those variables to a measure of desirability or undesirability.Problems with soft constraints deal with optimisation as well as feasibility: the aim is to find an assignment ofvalues to all of the variables having the best possible overall combined measure of desirability. In this paper weexamine how limiting the choice of cost functions affects the complexity of this optimisation problem.Example 1.1. Consider an optimisation problem where we have to choose sites for n service stations along a motorwayof length L, subject to the following requirements:• There are r > n possible sites at distances d1, . . . , dr along the motorway.• Each pair of consecutive service stations must be separated by a distance which is no less than A and no morethan B.• The service stations should be as equally spaced as possible.One possible way to model this situation is as follows:• Introduce variables v1, v2, . . . , vn to represent the position of each service station, where each variable must be• Impose a binary constraint on each pair vi, vi+1, i = 1, . . . , n − 1, with cost function δ, where δ(x, y) = 0 ifassigned a value from the set {d1, . . . , dr }.A (cid:2) y − x (cid:2) B and ∞ otherwise.• Impose a binary constraint on each pair vi, vi+1, i = 1, . . . , n − 1, with cost function ζ , where ζ (x, y) = |x − y|2.Add a unary constraint on v1 with cost function ζ (0, x), and a unary constraint on vn, with cost function ζ (x, L).(Note that the sum of these functions is minimal when the values of these variables are equally spaced between 0and L.)We would then seek an assignment of values from the set D = {d1, . . . , dr }, to all of the variables, which minimisesthe sum of all these cost functions:n−1(cid:2)i=1δ(vi, vi+1) + ζ (0, v1) +n−1(cid:2)i=1ζ (vi, vi+1) + ζ (vn, L).The cost of allowing additional flexibility in the specification of constraints, in order to model optimisation criteriaas well as feasibility, is generally an increase in computational difficulty. For example, we establish below that theclass of problems containing only unary constraints and a soft version of the binary equality constraint is NP-hard(see Example 2.11).On the other hand, for certain types of soft constraint it is possible to solve the associated optimisation problemsefficiently. For example, we establish below that optimisation problems of the form described in Example 1.1 can besolved in polynomial time (see Example 6.13).In the case of crisp constraints there has been considerable progress in analysing the complexity of problemsinvolving different types of constraints. This work has led to the identification of a number of classes of constraintswhich are tractable, in the sense that there exists a polynomial time algorithm to determine whether or not anycollection of constraints from such a class can be simultaneously satisfied [15,26,33,40,42]. One powerful result inthis area establishes that any tractable class of constraints over a finite domain must have relations which are allpreserved by a non-trivial algebraic operation, known as a polymorphism [6,26].In the case of soft constraints there has been little detailed investigation of the tractable cases, except for certainspecial cases on a two-valued domain [10,30], and a special case involving simple temporal constraints [31]. In anearlier paper [7] we identified a particular tractable class of binary soft constraints, and showed that this class wasmaximal, in the sense that adding any other soft binary constraint which is not in the class gives rise to a class ofproblems which is NP-hard. This class has recently been used to study the complexity of the MINIMUM COST HO-MOMORPHISM problem [21], which has been used to model the “Level of Repair Analysis” problem from operationsresearch [22] (see Example 2.7).\fD.A. Cohen et al. / Artificial Intelligence 170 (2006) 983–1016985In this paper we take the first step towards a systematic analysis of the complexity of soft constraints of arbitraryarity over arbitrary finite domains. To do this we generalise the algebraic ideas used to study crisp constraints, andintroduce a new algebraic operation which we call a multimorphism. Every cost function has an associated set ofmultimorphisms, and every multimorphism has an associated set of cost functions. We show that, for several differenttypes of multimorphism, the associated collection of soft constraints is a maximal tractable class. In other words, weshow that several maximal tractable classes of soft constraints can be precisely characterised as the collection of allsoft constraints associated with a particular multimorphism. Furthermore, we show that a simple NP-hard class of softconstraints has very restricted multimorphisms.Finally, we apply the techniques developed in the paper to the two-valued domain, where we obtain a new di-chotomy theorem which classifies the complexity of any set of soft constraints over this domain (Theorem 7.1). Thisdichotomy theorem generalises several earlier results concerning the complexity of particular Boolean constraint prob-lems, including the SATISFIABILITY problem [42], the MAX-SAT problem [9], the weighted MIN-ONES problem [10,30], and the weighted MAX-ONES problem [10,30] (see Corollary 7.12).The examples given throughout the paper demonstrate that the framework we introduce here can be used to unifyisolated results about tractable problem classes from many different application areas, as well as prompting thediscovery of new tractable classes. For example, the notion of a multimorphism generalises the notion of a poly-morphism (see Proposition 4.10), and so can be used to express earlier results concerning the characterisation oftractable subproblems of many different decision problems: in the case of the SATISFIABILITY problem these includethe HORN-SAT and 2-SAT subproblems [19]; in the case of the standard crisp constraint satisfaction problem theseinclude generalisations of HORN-SAT (such as the so-called ‘max-closed’ constraints [26,29]), generalisations of 2-SAT (such as the so-called ‘0/1/all’ or ‘implicative’ constraints [8,25,32]) and systems of linear equations [26]. Thenotion of a multimorphism can also be used to characterise tractable subproblems of optimisation problems: in thecase of the optimisation problem MAX-SAT these include the ‘0-valid’, ‘1-valid’ and ‘2-monotone’ constraints [10];in the case of optimisation problems over sets these include the minimisation of submodular set functions [23,39] andbisubmodular set functions [18].2. DefinitionsSeveral alternative mathematical frameworks for soft constraints have been proposed in the literature, includingthe very general frameworks of ‘semi-ring based constraints’ and ‘valued constraints’ [1,2,43]. For simplicity, weshall adopt the valued constraint framework here (the relationship with the semi-ring framework is discussed brieflyin Section 8).In the valued c",
            {
                "entities": [
                    [
                        2866,
                        2894,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 182–183 (2012) 1–31Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInformation-geometric approach to inferring causal directionsDominik Janzing a,∗Povilas Daniušis e, Bastian Steudel f, Bernhard Schölkopf a, Joris Mooij b, Kun Zhang a, Jan Lemeire c,d, Jakob Zscheischler a,a Max Planck Institute for Intelligent Systems, Tübingen, Germanyb Radboud University, Nijmegen, Netherlandsc Vrije Universiteit Brussel, Brussels, Belgiumd Interdisciplinary Institute for Broadband Technology, Ghent, Belgiume Vilnius University, Lithuaniaf Max Planck Institute for Mathematics in the Sciences, Leipzig, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 21 December 2010Received in revised form 10 January 2012Accepted 10 January 2012Available online 12 January 2012Keywords:Deterministic causal relationsPythagorean tripleCause–effect pairsWhile conventional approaches to causalinference are mainly based on conditional(in)dependences, recent methods also account for the shape of (conditional) distributions.The idea is that the causal hypothesis “ X causes Y ” imposes that the marginal distributionP X and the conditional distribution P Y | X represent independent mechanisms of nature.Recently it has been postulated that the shortest description of the joint distribution P X,Yshould therefore be given by separate descriptions of P X and P Y | X . Since descriptionlength in the sense of Kolmogorov complexity is uncomputable, practical implementationsrely on other notions of independence. Here we define independence via orthogonalityin information space. This way, we can explicitly describe the kind of dependence thatoccurs between P Y and P X|Y making the causal hypothesis “Y causes X” implausible.Remarkably, this asymmetry between cause and effect becomes particularly simple if Xand Y are deterministically related. We present an inference method that works in thiscase. We also discuss some theoretical results for the non-deterministic case although it isnot clear how to employ them for a more general inference method.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe problem of inferring whether X causes Y (write X → Y ) or Y causes X from observations (x1, y1), . . . , (xm, ym)that are i.i.d. drawn from P X,Y is a particularly challenging task for causal inference [1]. Although this restricted problemignores other important problems of causal inference (i.e., unobserved common causes or bidirectional influence), it isuseful for studying statistical asymmetries between cause and effect. Conventional methods for causal inference [2,3] focuson conditional independences and thus require observations from at least three variables.Extending an idea in [4,5] postulates that X → Y is only acceptable as causal hypothesis if the shortest description ofP X,Y is given by separate descriptions of P Y | X and P X . Here description length is understood in the sense of algorithmicinformation (“Kolmogorov complexity”) [6–8]. Note that the postulate is equivalent to saying that P Y | X and P X are algorith-mically independent in the sense that knowing P X does not enable a shorter description of P Y | X and vice versa. To showthat this helps in distinguishing between cause and effect for just two observed variables, [5] constructed toy models ofcausal mechanisms where the causal structure X → Y yields algorithmic dependences between P X|Y and P Y . Even though* Corresponding author.E-mail address: dominik.janzing@tuebingen.mpg.de (D. Janzing).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.01.002\f2D. Janzing et al. / Artificial Intelligence 182–183 (2012) 1–31SectionContentsSection 3Section 4Postulating independence conditions (h1)–(h3) forP cause and P effect|causeJustifying the conditionsRephrasing (h1)–(h3) as orthogonalityImplications of (h3) for deterministic causalityGeneralizing (h3) via exponential familiesInference method for deterministic case based on thegeneralized condition (h3)Main referencePostulate 1 and Definition 1Lemmas 1, 2Theorem 1Theorem 2Postulate 2Sections 4.3 and 4.4Appendix AOutlook: employing orthogonality for inferring non-deterministic relations (toy examples, negative results)Lemmas 9 and 10Fig. 1. Structure of the main results.algorithmic independence between P cause and P effect|cause is an appealing formalization of independence, practical methodsmust be based on computable criteria.[9,10] described a potential asymmetry between cause and effect where independence is meant in terms of statisticalindependence between the cause and the noise term that occurs in the causal mechanism: If Y is a function of X up to anadditive noise term that is statistically independent of X , i.e.,Y = f (X) + E with E ⊥⊥ X,(1)then there is usually (up to some exceptions like the bivariate Gaussian) no such additive noise model from Y to X . In otherwords, writing X as X = g(Y ) + ˜E with some function g will not render the residual term ˜E statistically independent of Y .[11] generalizes the model class to(cid:2)Y = hf (X) + E(cid:3)with E ⊥⊥ X,(2)and show that such a “post-nonlinear (PNL) model” also exists in at most one direction, except for some special cases. IfP X,Y is consistent with (1) or (2), respectively, in one direction but not the other, one infers that direction to be the causalone that is implied by the corresponding model. For the model (1) it has been shown [12] that this kind of reasoning isjustified by the above algorithmic independence principle.Note that these inference methods do not assume that causal relations are always of the above form. They only decidefor one of the causal directions if one and only one direction admits such a model. The idea is the following: if X → Y isthe correct model, but not of the additive noise form, it is rather unlikely that it generates a joint distribution that admitsan additive noise model in the opposite direction. The reason is that this would require rather contrived adjustmentsbetween P X (the marginal distribution of the hypothetical cause) and P Y | X (the conditional distribution of the effect, giventhe cause) [12]. This article develops an information-geometric principle that does not require the restricted class of additivenoise or post-nonlinear models. To this end, we revisit additive noise models in Section 2 and show that entropies can playa key role in describing the kind of dependences between P X|Y and P Y that can occur if X causes Y . This motivates ourinformation-geometric perspective developed in Section 3, which results in an inference method for deterministic causalrelations in Section 4, with an outlook for the non-deterministic case in Appendix A. The table in Fig. 1 shows how themain results are structured.Readers who are only interested in our inference method may focus on Section 4, with Sections 4.3 and 4.4 as its mainparts. The other sections provide a general background and describe a large class of asymmetries between cause and effectthat could be helpful for developing other information-theoretic methods in the future.2. Information-theoretic view on additive noise modelsWe consider the additive noise model (1) in the low noise regime (see Fig. 2) and show how the relationship betweenthe input distribution and the conditional one is different for both directions. We use the following notational conventions.P Y |x is the distribution of Y , given a fixed value x while P Y | X denotes the entire conditional distribution. The range ofa random variable X will be denoted by D X . S(P Y |x) denotes the (differential) Shannon entropy of P Y |x for fixed x. Thefunction x (cid:5)→ S(P Y |x) will also be called the conditional entropy function. Throughout the paper we will assume that alldistributions have densities with respect to a fixed reference measure (e.g., the Lebesgue measure for real-valued variablesor the counting measure for discrete variables). This measure will never appear explicitly and should not be confused withreference probability distributions that occur all over the article. By slightly overloading notation, P X will stand for boththe distribution and the density x (cid:5)→ P X (x). We will also write P (x) instead of P X (x) whenever this causes no confusion.· · · P (x) dx will be understood as sums by interpreting dx as dμ(x) where μFor discrete variables X , integrals of the formdenotes the counting measure.Regarding (1) we observe that E ⊥⊥ X ensures that the conditional entropy function S(P Y |x) is constant in x and coincidesS(P Y |x)P (x) dx). In studying how P Y and P X|Y are then( y)|( y) is large for those y-values where | fwith the conditional entropy S(P Y | X ) (defined by the averagerelated we first assume that P X is uniform. Then, P ( y) ≈ P X ( f−1( y)) · f−1−1(cid:4)(cid:4)(cid:7)(cid:7)\fD. Janzing et al. / Artificial Intelligence 182–183 (2012) 1–313Fig. 2. Functional relation with small noise. The conditional entropy function S(P X| y ) is high at regions with high slope of fthis point.−1( y), i.e., small slope of f atis large. At the same time, the entropy S(P X| y) is large for y-values in regions with large | f( y)| (see Fig. 2). Hence, largeentropy S(P X| y) correlates with high density P ( y), assuming that P (x) is constant on the interval under consideration. If−1( y)) are high. WeP X is not the uniform distribution, high values of P ( y) occur at points where both | fargue later that if the peaks of P (x) do not correlate with the slope of f then the qualitative argument above still holdsand S(P X| y) again correlates with P ( y). This reasoning will be formalized in Section 3.( y)| and P X ( f−1(cid:7)(cid:7)−1The first information-geometric inference principle that we are going to state in the next section no longer assumes thatthe entropy S(P Y |x) is constant in x if X → Y is the true causal direction. Instead, it postulates that regions of large S(P",
            {
                "entities": [
                    [
                        3650,
                        3678,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 779–801www.elsevier.com/locate/artintAutomated reformulation of specifications bysafe delay of constraints ✩Marco Cadoli, Toni Mancini ∗Dipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Salaria 113, I-00198 Roma, ItalyReceived 14 September 2004; received in revised form 25 January 2006; accepted 25 January 2006AbstractIn this paper we propose a form of reasoning on specifications of combinatorial problems, with the goal of reformulating themso that they are more efficiently solvable. The reformulation technique highlights constraints that can be safely “delayed”, andsolved afterwards. Our main contribution is the characterization (with soundness proof) of safe-delay constraints with respectto a criterion on the specification, thus obtaining a mechanism for the automated reformulation of specifications applicable to agreat variety of problems, e.g., graph coloring, bin-packing, and job-shop scheduling. This is an advancement with respect to theforms of reasoning done by state-of-the-art-systems, which typically just detect linearity of specifications. Another contributionis an experimentation on the effectiveness of the proposed technique using six different solvers, which reveals promising timesavings.© 2006 Elsevier B.V. All rights reserved.Keywords: Modelling; Reformulation; Second-order logic; Propositional satisfiability; Constraint satisfaction problems1. IntroductionCurrent state-of-the-art languages and systems for constraint modelling and programming (e.g., AMPL [22],OPL [48], XPRESSMP,1 GAMS [9], DLV [31], SMODELS [39], ESRA [21], PS [18] and NP-SPEC [8]) exhibit a strongseparation between a problem specification (e.g., Graph 3-coloring) and its instance (e.g., a graph), usually adopting atwo-level architecture for finding solutions: the specification is firstly instantiated (or grounded) against the instance,and then an appropriate solver is invoked (cf. Fig. 1). Such a separation leads to several advantages: obviously declar-ativeness increases, and the solver is completely decoupled from the specification. Ideally, the programmer can focusonly on the combinatorial aspects of the problem specification, without committing a priori to a specific solver. In✩ This paper is an extended and revised version of [M. Cadoli, T. Mancini, Automated reformulation of specifications by safe delay of constraints,in: Proceedings of the Ninth International Conference on the Principles of Knowledge Representation and Reasoning (KR 2004), Whistler, BC,Canada, AAAI Press/The MIT Press 2004, pp. 388–398].* Corresponding author.E-mail addresses: cadoli@dis.uniroma1.it (M. Cadoli), tmancini@dis.uniroma1.it (T. Mancini).1 Cf. http://www.dashoptimization.com.0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.008\f780M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Fig. 1. Two-level architecture of current problem solving systems.fact, some systems, e.g., AMPL, are able to translate—at the request of the user—a specification in various formats,suitable for different solvers, e.g., among the others, CPLEX, MINOS,2 LANCELOT.3Nonetheless, many existing techniques proposed in the literature for optimizing the solution of constraint satisfac-tion problems apply after the commitment to the instance: notable examples are, e.g., symmetry detection and breaking(cf., e.g., [4,16,37]), the development of techniques for imposing various local consistency notions and of heuristicsduring search (cf., e.g., [17]), the development of algorithms that deal with dependent variables, e.g., those added toSAT instances during the clausification of non-CNF formulae [27], and with the so-called “equivalence clauses” [32].However, in many cases, properties that are amenable to be optimized derive from the problem structure, ratherthan the particular instance considered. Optimization techniques that act on the problem structure have been proposed.They include the addition of implied constraints (cf., e.g., [47]), the deletion or abstraction of some of the constraints(cf., e.g., [28]), the use of redundant models, i.e., multiple viewpoints synchronized by channelling constraints, inorder to increase constraint propagation [12,20,29].Our research follows the latter approach, with the aim of systematize the process of finding useful reformulationsby performing a symbolic reasoning on the specification. In general, for many properties, symbolic reasoning can bemore natural and effective than making such “structural” aspects emerge after instantiation, when the structure of theproblem has been hidden.An example of system that performs a sort of reasoning on the specification is OPL, which is able to automaticallychoose the most appropriate solver for a problem. However, the kind of reasoning offered is very primitive: OPL onlychecks (syntactically) whether a specification is linear, in this case invoking a linear—typically more efficient—solver,otherwise a general constraint programming one.Conversely, our research aims to the following long-term goal: the automated reformulation of a declarative con-straint problem specification, into a form that is more efficiently evaluable by the solver at hand. The ultimate goal is tohandle all properties suitable for optimization that derive from the problem structure at the specification level, leavingat the subsequent instance level the handling of the remaining ones, i.e., those that truly depend on the instance. Infact, it is worthwhile to note that focusing on the specification does not rule out the possibility of additionally applyingexisting optimization techniques at the instance level.The approach we follow is similar, in a sense, to the one used in the database research community for attackingthe query optimization problem in relational databases. A query planner, whose task is to reformulate the query posedby the user in order to improve the efficiency of the evaluation, takes into account the query and the database schemaonly, not its current content, i.e., the instance (cf., e.g., [1]).In general, reformulating a constraint problem specification is a difficult task: a specification is essentially a formulain second-order logic, and it is well known that the equivalence problem is undecidable already in the first-order case[3]. For this reason, research must focus on controlled and restricted forms of reformulation.Moreover, the effectiveness of a particular reformulation technique is expected to depend both on the problem andon the solver, even if it is possible, in principle, to find reformulations that are good for all solvers (or for solversof a certain class, e.g., linear, or SAT-based ones). To this end, in related work (cf. Section 6), we present differentreformulation strategies that have been proposed in order to speed-up the process of solving a constraint problem.2 Cf. http://www.sbsi-sol-optimize.com/.3 Cf. http://www.cse.clrc.ac.uk/nag/lancelot/lancelot.shtml.\fM. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801781Fig. 2. Delaying the disjointness constraint in 3-coloring. (a) 1st stage: covering and good coloring; (b) 2nd stage: disjointness.(a)(b)In this paper, we propose a technique that allows us to select constraints in a problem specification that can beignored in a first step (regardless of the instance), and efficiently reinforced once a solution of the simplified problemhas been found. We call such constraints safe-delay. Moreover, we experimentally show how reformulating problemspecifications by safe-delay improves performances of different (but not all) solvers. On one hand, this gives evidencethat problem reformulation can be effective in many cases, and on the other, it confirms the intuition that a singlereformulation technique may have positive effects for some classes of solvers, but negative ones for others, and thata portfolio of different and complementary reformulation strategies has to be considered, in general (cf. Section 6 forrelated work).The NP-complete graph k-coloring problem offers a simple example of a safe-delay constraint. The problemamounts to find an assignment of nodes to k colors such that:• Each node has at least one color (covering);• Each node has at most one color (disjointness);• Adjacent nodes have different colors (good coloring).For each instance of the problem, if we obtain a solution neglecting the disjointness constraint, we can alwayschoose for each node one of its colors in an arbitrary way at a later stage (cf. Fig. 2). It is interesting to note that thedeletion of the disjointness constraints in graph k-coloring has been already proposed as an ad-hoc technique in [46](cf. also [42]), and implemented in, e.g., the standard DIMACS formulation in SAT of k-coloring.Of course not all constraints are safe-delay: as an example, both the covering and the good coloring constraints arenot. Intuitively, identifying the set of constraints of a specification which are safe-delay may lead to several advantages:• The instantiation phase (cf. Fig. 1) will typically be faster, since safe-delay constraints are not taken into account.As an example, let’s assume we want to use (after instantiation) a SAT solver for the solution of k-coloring ona graph with n nodes and e edges. The SAT instance encoding the k-coloring instance—in the obvious way, cf.,e.g., [25]—has n · k propositional variables, and a number of clauses which is n, n · k · (k − 1)/2, and e · k forcovering, disjointness, and good coloring, respectively. If we delay disjointness, n · k · (k − 1)/2 clauses need notto be generated.• Solving the simplified problem, i.e., the one without disjointness, might be easier than the original formulation forsome classes of solvers, since removing constraints makes the set of solutions larger. For each instance it holdsthat:{solutions of original problem} ⊆ {solutions of simplified problem}.In our experiments, using ",
            {
                "entities": [
                    [
                        2835,
                        2863,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1367–1405Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVivid: A framework for heterogeneous problem solving ✩Konstantine Arkoudas, Selmer Bringsjord∗Rensselaer AI & Reasoning (RAIR) Lab, Department of Cognitive Science, Department of Computer Science, Rensselaer Polytechnic Institute (RPI), Troy, NY 12180, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 30 June 2008Received in revised form 1 June 2009Accepted 9 June 2009Available online 13 June 2009Keywords:VividHeterogeneous reasoningProblem solvingDiagramsDPLsAssumption basesNamed system statesWorlds3-valued logic1. IntroductionWe introduce Vivid, a domain-independent framework for mechanized heterogeneous rea-soning that combines diagrammatic and symbolic representation and inference. The frame-work is presented in the form of a family of denotational proof languages (DPLs). Wepresent novel formal structures, called named system states, that are specifically designedfor modeling potentially underdetermined diagrams. These structures allow us to deal withincomplete information, a pervasive feature of heterogeneous problem solving. We intro-duce a notion of attribute interpretations that enables us to interpret first-order relationalsignatures into named system states, and develop a formal semantic framework based on3-valued logic. We extend the assumption-base semantics of DPLs to accommodate dia-grammatic reasoning by introducing general inference mechanisms for the valid extractionof information from diagrams, and for the incorporation of sentential information into dia-grams. A rigorous big-step operational semantics is given, on the basis of which we provethat the framework is sound. We present examples of particular instances of Vivid in orderto solve a series of problems, and discuss related work.© 2009 Elsevier B.V. All rights reserved.Diagrams have been recognized as valuable representational and reasoning tools at least since the days of Euclid. They areused extensively in a very wide range of fields. To note just a few examples, witness: free-body, energy-level and Feynmandiagrams in physics [60]; arrow diagrams in algebra and category theory [44]; Euler and Venn diagrams in elementaryset theory and logic; function graphs in calculus and analysis; planar figures in geometry; bar, chart, and pie graphs ineconomics; circuit, state, and timing diagrams in hardware design [32]; UML diagrams in software design [47]; higraphsin specification [25]; visual programming languages [15] and visual logic and specification languages [1,27,42]; transitiongraphs in model checking [11]; ER-diagrams and hypergraphs in databases [21]; semantic (as well as neural and belief)networks in AI [50]; icons and other pictorial devices in graphical user interfaces (GUIs) and information visualization[12,39,59,63]; and so on. Given such a list, and the power of diagrams that it suggests, it seems reasonable to hold thatif the capability of computers to work with diagrams intelligently can be further increased, human reasoning and problemsolving will be facilitated. The framework presented here, Vivid, is intended to purchase some of that increase.The representational power of diagrams stems primarily from the fact that they can have structural correspondenceswith the objects or situations they represent—they are analogical representations in the terminology of Sloman [54], orhomomorphic representations in the terminology of Barwise and Etchemendy [7]; also see Hayes [26]. To put it more plainly,✩This work was made possible by grants received from DARPA and DTO. We are indebted to Ron Brachman, David Musser, Martin Rinard, and to threeanonymous referees for insightful comments, objections, and suggestions.* Corresponding author.E-mail addresses: arkouk@rpi.edu (K. Arkoudas), selmer@rpi.edu (S. Bringsjord).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.002\f1368K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405a diagram resembles—or at any rate should resemble—what the diagram depicts, in contrast to sentential descriptions.1 Thiswas noticed at least as far back as the 19th century, when Peirce observed that a diagram is “naturally analogous to thething represented” [43, p. 316].Consider, for instance, the task of describing a human face. We could perhaps describe the face with a collection ofEnglish sentences, or with a set of sentences in some formal language. But such a description is likely to be long andcomplicated, and not particularly illuminating.2 A drawing or a picture of the face, on the other hand, will be much moreperspicuous, as well as significantly more compact than most sentential representations. Of course, some diagrams arebetter than others. A talented artist will produce a drawing that is a much more accurate depiction than the scrawlings ofa child. A digital picture will be even more accurate.3 So, as Hammer [24] observes, being an analogical or homomorphicrepresentation is not a distinguishing feature of diagrams in general, but rather a distinguishing feature of good diagrams.The utility of (good) diagrams is often thought to derive from the fact that diagrams are two-dimensional objects, andtherefore spatial relationships on the plane can directly reflect analogous relationships in the underlying domain, an obser-vation made a while back by Russell [49]. A classic example are maps. We can represent the streets of a city graphically,with a map, or sententially, e.g., by a collection of assertions expressing the various intersections and so forth. The graphicalrepresentation is doubtless a more intuitive and effective description because its spatial structure is similar to the actuallayout of the city. This analogical correspondence is lost in the sentential representation. As another example, consider amap of a lake and try to imagine a sentential description of it. Stenning and Lemon [57] trace this discrepancy to the factthat sentential languages derive from acoustic signals, which are one-dimensional and must therefore rely on a complexsyntax for representation, something that is not necessary in the case of diagrams.However, two-dimensionality by itself is neither a necessary nor a sufficient condition for being a diagram. For instance,as Hammer [24] points out, a representation of a picture by a two-dimensional array of numbers encoded under someencryption scheme does not count as a diagram; there is no structural similarity between the representation and thatwhich is being represented. And, by making sufficiently clever conventions, we can construct analogical one-dimensionaldiagrams. For example, the following string asserts that the stretch of road between Main Street/35th Street and Main/36this two-way, whereas that between Main/36th and Main/37th is one-way and proceeds from right to left:Main|35th <==> Main|36th <== Main|37thIt bears stressing that diagrams are helpful only when their visual structure is analogical or homomorphic with thesemantic structure of the information which they represent. In an era of Powerpoint and multimedia presentations, it isoften taken for granted that graphical displays of information are automatically clearer and more intuitive than text, simplyby virtue of being “visual.” That is emphatically not the case. The reason why Euler circles are efficacious, for instance, isprecisely because spatial enclosure is naturally analogous to the subset relation, spatial overlap to set-theoretic intersection,and spatial separation to set-theoretic disjointness [53]. In the absence of such structural similarities, diagrams can quicklydegenerate into what Tufte [59, p. 34] calls “chartjunk”: cluttered displays of lines, curves, arrows, bars, charts, and the like,that end up obscuring rather than clarifying information.4 Conversely, a diagram does not have to be visually arresting orelaborate in order to be superior to a sentential representation. It does not even have to be two-dimensional, as we notedabove, a point that is borne out by our Main Street example, or by Hammer’s example of an one-dimensional diagrammeant to express the relative distances between the Earth, Moon, and Mars when the Moon is aligned to fall betweenEarth and Mars:Earth–Moon————MarsThis diagram is one-dimensional: its syntax can be adequately modeled by sequences of symbols [24, p. 2].Some might be inclined to criticize such diagrams as inordinately simple and purely structural, hence suffering from in-sufficient “diagrammaticity,” the implication being that only visually elaborate diagrams qualify as truly diagrammatic. Thecriticism is at odds with the brute reality of ingenious human diagrammatic reasoning and problem solving. For example,consider the well-known example of the seating puzzle of Barwise and Etchemendy [6], which we discuss extensively inSection 8. The diagrams in that puzzle are indeed very simple (one-dimensional, small, and purely ASCII); but they are noless powerful for human reasoners as a result. In fact, their structural nature and simplicity, far from being defects, arepositively conducive to their representational power. Structure and simplicity are usually advantages of analogical represen-tations, not disadvantages.1 The terms “sentential” and “symbolic” will be used synonymously throughout.2 Fractals [37] might be able to yield compact representations for some complex shapes such as coastlines, etc., but the equations generating the fractalswould be no more analogical to the corresponding shapes than other symbolic descriptions.3 In the limiting case, the ultimate representation of an object is the object itself.4 Peter Norvig provides an amusing but compelling illustration of this point in his Powerpoint version of the Gettysburg address, where he turns “fourscores and seven years” into a gratuitous graph: www.norvig.com/Gettysburg/sld005.htm. More inf",
            {
                "entities": [
                    [
                        3982,
                        4010,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 237 (2016) 204–227Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHierarchical conceptual spaces for concept combinationMartha Lewis a,∗a Department of Computer Science, University of Oxford, OX1 3QD, United Kingdomb Department of Engineering Mathematics, University of Bristol, BS8 1UB, United Kingdom, Jonathan Lawry ba r t i c l e i n f oa b s t r a c tArticle history:Received 12 December 2014Received in revised form 4 January 2016Accepted 30 April 2016Available online 6 May 2016Keywords:Conceptual spacesConcept compositionRandom setsWe introduce a hierarchical framework for conjunctive concept combination based on conceptual spaces and random set theory. The model has the flexibility to account for composition of concepts at various levels of complexity. We show that the conjunctive model includes linear combination as a special case, and that the more general model can account for non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence. We investigate two further aspects of human concept use, the conjunction fallacy and the ‘guppy effect’.© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionHumans undoubtedly have the ability to form new concepts by combining existing ones. The development of effective representational models of this phenomenon could potentially shed light on human cognition. Human-like reasoning has been argued to be important to artificial intelligence for its flexibility and robustness [6,29,44]. Further, a good representa-tion of human concept use will aid us in considering problems of categorization and typicality, as argued by Freund [18]. Applications of AI that must interact with humans via natural language arguably need to be able to understand and to form for themselves novel combinations of concepts. Examples of theories proposed to account for such concept combi-nation include prototype theory together with fuzzy set theory [51], conceptual spaces [19], and quantum probability [3,9] approaches. Well-known counterexamples have been identified which suggest that fuzzy sets may not provide an ap-propriate formalisation in this context [25,27,40]. It is argued in [25] that the failure of fuzzy set theory to adequately model human concept combination results from its failure to consider the intension of concepts, i.e., the attributes that the concept possesses. In contrast, the conceptual spaces and the quantum approaches take intension into account, either by considering concepts as being comprised of a combination of properties,1 which are themselves embedded in a space of quality dimensions, or by incorporating context into the model. Our proposed approach utilises a random set interpretation of membership so as to quantify an agent’s subjective uncertainty about the extent of application of a concept. We refer to this uncertainty as semantic uncertainty [33] in order to emphasise that it concerns the definition of concepts and cate-gories. Lawry and Tang [33] combine random set theory with conceptual spaces [19] and prototype theory [43], to give a formalisation of concepts as based on a prototype and an uncertain distance threshold, located in a conceptual space. We use this account of concepts to provide a framework for conjunctive concept combination which captures the effects seen * Corresponding author.E-mail address: martha.lewis@cs.ox.ac.uk (M. Lewis).1 In the current paper, we use the terms ‘attribute’ and ‘property’ interchangeably.http://dx.doi.org/10.1016/j.artint.2016.04.0080004-3702/© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM. Lewis, J. Lawry / Artificial Intelligence 237 (2016) 204–227205in [25], including non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence.An outline of the paper is as follows. Section 2 overviews a range of theoretical approaches to concept combination from the literature, and summarises the results from experimental studies that we aim to model. Section 3 describes a random set and prototype theory representational model for concepts within a conceptual space. This model provides the theoretical underpinning for our work. Section 4 introduces a framework for concept combination based on a hierarchy of conceptual spaces, and in which compound concepts are defined within Boolean spaces. We prove a number of results showing the properties of this framework and compare this approach to others in the literature. Section 5 provides a discussion of our results and indicates possible future directions.2. BackgroundIn this section, we describe a number of approaches to concept combination that have been proposed. We consider general set-theoretic approaches, supervaluation theory, prototype theory, fuzzy set theory, conceptual spaces theory, ap-proaches from computational linguistics and quantum cognition approaches. We further describe some results from experi-mental studies with which we compare the theory we develop.2.1. Set-theoretic approachesMontague semantics [39] takes a model-theoretic approach to concepts and sentences. Concepts are defined using no-tions from set theory, and natural language expressions are modelled as functions or relations on these sets. This gives a de-scription of how the semantics of a language interacts with the syntax, so that the meaning of a compound expression may be systematically derived from its parts. However, as discussed in [27,28], this is inadequate for modelling some types of ad-jectives. In [39], an adjective is viewed as a function from properties to properties. This allows sentences such as ‘every small elephant is small’ not to be branded as logically true, which is what we require. This enables various types of adjective to be modelled. Intersective adjectives are those where the application of that adjective may simply be viewed as an intersection of sets (such as ‘red car’). Adjectives that are not intersective may be subsective, when the adjective-noun combination is a sub-set of the noun, or non-subsective, for example privative adjectives like ‘fake’, or ‘former’. However, the theory of adjectives as a function of properties is inadequate, in particular because it doesn’t account for comparatives, i.e. the ability to say that x is A-er than y. To account for this, Kamp introduces a theory of vague models, which are viewed as a nested sequence of partial models. In a partial model, a predicate is explained as assigning a value 1 to those objects which fall under the pred-icate, 0 to those that do not fall under the predicate, and no value to those for whom the predicate is indeterminate. These partial models may be completed in various ways, and the degree of truth of a sentence is related to the probability of a par-ticular set of completions of a partial model of the sentence conditioned on all sets of completions of the model. This set of completed models forms the basis for Kamp’s supervaluation, where a sentence has truth value 1 if it is true in all comple-tions of the model, 0 if it is false in all completions of the model, and indeterminate if it is true in some and false in others.Kamp’s approach is similar to Fine’s [17], in which the questions of the correct logic for vagueness and the correct truth conditions for a vague language are considered. Fine calls the possibility that logical relations hold between indefinite sentences penumbral connection, and truths that arise from such a connection penumbral truths, and argues that no natural truth-value approach respects such truths. He argues that differences in truth-value within penumbral truths concerning two predicates are essentially a difference in the way that these predicates can be made more precise. He describes a theory of super-truth, in which a sentence is true iff it is true in all admissible and complete specifications of the sentence.Both these approaches use the idea that there are in fact precise ways of describing a concept, and that the truth value of a sentence using a vague concept is dependent on the different possible ways of making the sentence more precise. In what follows, we do not consider truth values of sentences but rather typicality of an item to a concept. However, consideration of logics using the fuzzy sets we develop would be an interesting line of future work.Interestingly, [1] argue that adjective-noun combinations can be represented purely as set intersection between the adjective and the head noun. This is achieved by the use of typed sets. These are sets in which members are assigned types. So the adjective ‘clever’ is represented in the following way:Clever = { j : human, f : pet, f : policedog} : cleverwhere the interpretation of j is ‘John’, and the interpretation of f is ‘Fido’. [1] argue that by using this type of representation the problems of privative adjectives can be circumvented. An example is as follows. From the two sentences ‘Maria is a former teacher’ and ‘Maria is a programmer’, we do not wish to infer ‘Maria is a former programmer’. The typed set representation is as follows:H uman = {m : human, ...} : humanT eacher = {m : teacher, ...} : teacherF ormer = {m : teacher, ...} : f ormerP rogrammer = {m : programmer, ...} : programmer\f206M. Lewis, J. Lawry / Artificial Intelligence 237 (2016) 204–227Then, we can infer that m ∈ F ormer ∩ T eacher, but not that m ∈ F ormer ∩ P rogrammer. This is further extended to describe differences in scope when applying multiple adjectives. The approach described is interesting, and could presumably be extended to include some ",
            {
                "entities": [
                    [
                        3753,
                        3781,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 857–875Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStrengths and synergies of evolved and designed controllers:A study within collective roboticsGianluca Baldassarre∗, Stefano NolfiLaboratory of Autonomous Robotics and Artificial Life, Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerche (LARAL-ISTC-CNR),Via San Martino della Battaglia 44, 00185 Roma, Italya r t i c l ei n f oa b s t r a c tThis paper analyses the strengths and weaknesses of self-organising approaches, such asevolutionary robotics, and direct design approaches, such as behaviour-based controllers,for the production of autonomous robots’ controllers, and shows how the two approachescan be usefully combined. In particular, the paper proposes a method for encoding evolvedneural-network based behaviours into motor schema-based controllers and then showshow these controllers can be modified and combined to produce robots capable of solvingnew tasks. The method has been validated in the context of a collective robotics scenarioin which a group of physically assembled simulated autonomous robots are requested toproduce different forms of coordinated behaviours (e.g., coordinated motion, walled-arenaexiting, and light pursuing).© 2009 Elsevier B.V. All rights reserved.Article history:Received 10 November 2006Received in revised form 19 December 2008Accepted 3 January 2009Available online 6 January 2009Keywords:Neural networksGenetic algorithmsSelf-organisationMotor schema-based controllersPotential fieldsModularityMulti-variable statistical regression1. IntroductionIn the field of autonomous robotics, approaches in which the controllers are designed by the experimenter, such asbehaviour-based robotics [2,3,10,13,18,22,27,28,31,32,51,52], and approaches in which some of the characteristics of the con-trollers are developed through automatic procedures, such as evolutionary robotics [8,39,41,42,44,47,48,53], are usually seenas two alternative methods based on partially contrasting principles. This paper proposes a method for combining thestrengths of automatic procedures and direct design methods. In particular it show how effective solutions discoveredthrough an evolutionary technique can be re-coded in motor schema-based controllers which can be later manipulated andcombined to produce new behaviours.To accomplish this goal, the research presented here compares evolved feed-forward neural-network controllers [16,36,39]with hand-coded motor schema-based controllers [1,2]. Artificial neural networks are a formalism widely used to encode robots’controllers in evolutionary robotics research [39]. Feed-forward neural networks are the simplest type of neural controllerin which the state of the motors is a function of only the current state of the sensors. Feed-forward neural controllershave been chosen because they were sufficient for the purposes of this study and because they could be easily comparedwith hand-coded motor schema-based controllers. Hand-coded motor-schema based controllers are a class of behaviour-based controllers [2,13] based on artificial potential fields which have been successfully used with both mobile robots [1] androbotic manipulators [30]. These types of controllers have been chosen because, as feed-forward neural controllers, theyinvolve a direct mapping between the activation of sensors and the commands issued to motors: this feature was expectedto ease the comparison of the two types of controllers. Here the mapping between the two classes of controllers will be* Corresponding author.E-mail addresses: gianluca.baldassarre@istc.cnr.it (G. Baldassarre), stefano.nolfi@istc.cnr.it (S. Nolfi).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.01.001\f858G. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875obtained with suitable mathematical multi-variable functions. The form of these functions will be directly designed, whereasits parameters, depending on the specific goal in hand, will be either hand-tuned, or obtained through suitable regressions,or searched with evolutionary/design hybrid techniques.The test of models were conducted in the context of a collective robotics scenario [15,19,21,25,33,34] in which a “swarm”of assembled robots [37] is requested to display a variety of coordinated cooperative behaviours and in which each robothas access to only local sensory information.Beside highlighting the general strengths and weaknesses of the two approaches, the paper also shows how: (a) thesolutions encoded in evolved neural controllers (Section 2 illustrates the methods used for this evolution and Section 3illustrates the functioning of the evolved controllers) can be implemented in motor schema-based controllers (Section 4);(b) the obtained motor schema-based controllers can be manually manipulated to identify the key functioning features ofthe evolved solution (Section 5); (c) the obtained motor schema-based controllers can be modified to obtain new controllersable to produce new behaviours (Section 6); (d) different schema-based controllers obtained from the evolved ones can becombined to develop robots able to produce more complex behaviours (Section 7).2. The experimental set-up2.1. The robotThe research presented here was carried out within a research project, SWARM-BOTS, funded by the European Union (IST-FET Program; [20,37]). The goal of this project was to develop swarm-bots, that is groups of fully autonomous robots able tophysically connect and disconnect to form larger robotic systems. These systems can assume different physical shapes andact to solve problems that cannot be solved by single robots. This paper focuses on how a group of robots that are alreadyassembled can accomplish common tasks such as to coordinate the motion direction in a distributed fashion (that is withouta leader, cf. [8]). Other researches carried out within the project studied how robots can self-assemble and disassemble toaccomplish collective tasks [26,49].Each robot (Fig. 1; cf. [37]) has a cylindrical body with a diameter of 11.6 cm and consists of a mobile base (“chassis”), anda main body (“turret”). The chassis is endowed with two motors each controlling a track and a teethed wheel. A third motorallows the turret and the chassis to actively rotate with respect to each other. The turret is provided with two grippers, onerigid and one flexible, that allow the robots to self-assemble and grasp objects. Each robot is provided with a numberof different sensors [37], but only the traction sensor described below has been simulated and used in the experimentsreported in this paper.In order to carry out the experiments reported in the paper we built a simulator of the robot based on the SDK VortexTMtoolkit (Critical Mass Labs, Canada) which allows programming realistic simulations of dynamics and collisions of rigidbodies in 3D. Given the high computational costs of simulations, only few relevant characteristics of the sensors, actuatorsand body of the robot were simulated; moreover the size of the robots and the gravitational acceleration coefficient werereduced to have the possibility of increasing the simulation time step without having instabilities.Fig. 1. The robot that has been reproduced in the simulator used to carry out the experiments reported in the paper.\fG. Baldassarre, S. Nolfi / Artificial Intelligence 173 (2009) 857–875859Fig. 2. Four simulated robots linked up to form a linear swarm-bot. Each robot is made up by a chassis (parallelepiped) to whom two motorised cylindricalwheels and two small spherical wheels are attached (the two passive wheels have different colours, dark and light grey, to allow distinguishing the twopossible chassis’ fronts). The chassis is connected to a cylindrical turret. The black segment between the turrets of two robots represents a physical linkbetween them. The white line above each robot’s turret, which goes from the turret’s centre to a point on its perimeter, indicates the direction of tractionand, with its size, the intensity of traction.Fig. 3. Traction force detected by the robot traction sensor. The parallelepiped represents the chassis. The turret has not been drawn for clarity. The largeand small grey circles represent respectively the right motorised wheel and the front passive wheel. The thin arrow indicates the orientation of the chassis,the bold arrow indicates the vector of the traction force that the turret exerts on the chassis, and the dotted arrow indicates the angle of traction measuredclockwise from the back of the robot.The motor system of a simulated robot was modelled by four wheels connected to the chassis: two lateral motorisedwheels that modelled the external wheels of the real robot and two spherical passive wheels placed at the front and atthe back to stabilise the robot. The chassis was connected to the turret, modelled as a cylinder, through a motorised joint(Fig. 2). The turret was endowed with a gripper which was modelled by creating a physical joint between the robot andother robots when needed (this joint was either rigid – in which case it will be called rigid link in the following sections –or possessed a free hinge with a vertical pivot – in which case it will be called flexible link). The active and passive wheelshad a diameter of respectively 2.30 and 1.15 cm. The turret had a diameter of 5.8 cm and a height of 4.6 cm.During evolution, spherical collision models were used for all the wheels and for the chassis, as these speeded upcomputations (results equivalent to those reported below were obtained by testing the evolved controllers with the collisionmodels shown in Fig. 2). The gravitational acceleration coefficient was set at 9.8 cm/s2. This low value, that caused a lowfriction of the wheels on the ground, was compensated for by setting the maximum torque of the motors at a low va",
            {
                "entities": [
                    [
                        3830,
                        3858,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1897–1916Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLabel ranking by learning pairwise preferencesEyke Hüllermeier a,∗, Johannes Fürnkranz b, Weiwei Cheng a, Klaus Brinker aa Department of Mathematics and Computer Science, Philipps-Universität Marburg, Germanyb Department of Computer Science, TU Darmstadt, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 21 January 2008Received in revised form 14 July 2008Accepted 8 August 2008Available online 15 August 2008Keywords:Preference learningRankingPairwise classificationConstraint classification1. IntroductionPreference learning is an emerging topic that appears in different guises in the recentliterature. This work focuses on a particular learning scenario called label ranking, wherethe problem is to learn a mapping from instances to rankings over a finite number oflabels. Our approach for learning such a mapping, called ranking by pairwise comparison(RPC), first induces a binary preference relation from suitable training data using a naturalextension of pairwise classification. A ranking is then derived from the preference relationthus obtained by means of a ranking procedure, whereby different ranking methods canbe used for minimizing different loss functions. In particular, we show that a simple(weighted) voting strategy minimizes risk with respect to the well-known Spearman rankcorrelation. We compare RPC to existing label ranking methods, which are based on scoringindividual labels instead of comparing pairs of labels. Both empirically and theoretically, itis shown that RPC is superior in terms of computational efficiency, and at least competitivein terms of accuracy.© 2008 Elsevier B.V. All rights reserved.The topic of preferences has recently attracted considerable attention in Artificial Intelligence (AI) research, notably infields such as agents, non-monotonic reasoning, constraint satisfaction, planning, and qualitative decision theory [19].1 Pref-erences provide a means for specifying desires in a declarative way, which is a point of critical importance for AI. In fact,consider AI’s paradigm of a rationally acting (decision-theoretic) agent: The behavior of such an agent has to be driven byan underlying preference model, and an agent recommending decisions or acting on behalf of a user should clearly reflectthat user’s preferences.It is hence hardly surprising that methods for learning and predicting preferences in an automatic way are amongthe very recent research topics in disciplines such as machine learning, knowledge discovery, and recommender systems.Many approaches have been subsumed under the terms of ranking and preference learning, even though some of themare quite different and are not sufficiently well discriminated by existing terminology. We will thus start our paper with aclarification of its contribution (Section 2). The learning scenario that we will consider in this paper assumes a collectionof training examples which are associated with a finite set of decision alternatives. Following the common notation ofsupervised learning, we shall refer to the latter as labels. However, contrary to standard classification, a training example isnot assigned a single label, but a set of pairwise preferences between labels (which neither has to be complete nor entirely* Corresponding author.E-mail addresses: eyke@informatik.uni-marburg.de (E. Hüllermeier), juffi@ke.informatik.tu-darmstadt.de (J. Fürnkranz), cheng@informatik.uni-marburg.de(W. Cheng), brinker@informatik.uni-marburg.de (K. Brinker).1 The increasing activity in this area is also witnessed by several workshops that have been devoted to preference learning and related topics, such asthose at the NIPS-02, KI-03, SIGIR-03, NIPS-04, GfKl-05, IJCAI-05 and ECAI-2006 conferences (the second and fifth organized by two of the authors).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.002\f1898E. Hüllermeier et al. / Artificial Intelligence 172 (2008) 1897–1916Table 1Four different approaches to learning from preference information together withrepresentative referencesmodeling utility functionsmodeling pairwise preferencesobject rankinglabel rankingcomparison training [58]constraint classification [28]learning to order things [13]this work [24]consistent), each one expressing that one label is preferred over another. The goal is to learn to predict a total order, aranking, of all possible labels for a new training example.The ranking by pairwise comparison (RPC) algorithm, which we introduce in Section 3 of this paper, has a modular struc-ture and works in two phases. First, pairwise preferences are learned from suitable training data, using a natural extensionof so-called pairwise classification. Then, a ranking is derived from a set of such preferences by means of a ranking procedure.In Section 4, we analyze the computational complexity of the RPC algorithm. Then, in Section 5, it will be shown that, byusing suitable ranking procedures, RPC can minimize the risk for certain loss functions on rankings. Section 6 is devoted toan experimental evaluation of RPC and a comparison with alternative approaches applicable to the same learning problem.The paper closes with a discussion of related work in Section 7 and concluding remarks in Section 8. Parts of this paper arebased on [24,25,33].2. Learning from preferencesIn this section, we will motivate preference learning2 as a theoretically interesting and practically relevant subfield ofmachine learning. One can distinguish two types of preference learning problems, namely learning from object preferencesand learning from label preferences, as well as two different approaches for modeling the preferences, namely by evaluatingindividual alternatives (by means of a utility function), or by comparing (pairs of) competing alternatives (by means of apreference relation). Table 1 shows the four possible combinations thus obtained. In this section, we shall discuss theseoptions and show that our approach, label ranking by pairwise comparison, is still missing in the literature and hence anovel contribution.2.1. Learning from object preferencesThe most frequently studied problem in learning from preferences is to induce a ranking function r(·) that is able to orderany subset O of an underlying class X of objects. That is, r(·) assumes as input a subset O = {x1 . . . xn} ⊆ X of objects andreturns as output a permutation τ of {1 . . . n}. The interpretation of this permutation is that object xi is preferred to x jwhenever τ (i) < τ ( j). The objects themselves (e.g. websites) are typically characterized by a finite set of features as inconventional attribute-value learning. The training data consists of a set of exemplary pairwise preferences. This scenario,summarized in Fig. 1, is also known as “learning to order things” [13].As an example consider the problem of learning to rank query results of a search engine [35,52]. The training informationis provided implicitly by the user who clicks on some of the links in the query result and not on others. This informationcan be turned into binary preferences by assuming that the selected pages are preferred over nearby pages that are notclicked on [36].2.2. Learning from label preferencesIn this learning scenario, the problem is to predict, for any instance x (e.g., a person) from an instance space X , apreference relation (cid:4)x ⊆ L × L among a finite set L = {λ1 . . . λm} of labels or alternatives, where λi (cid:4)x λ j means thatinstance x prefers the label λi to the label λ j . More specifically, we are especially interested in the case where (cid:4)x is a totalstrict order, that is, a ranking of L. Note that a ranking (cid:4)x can be identified with a permutation τx of {1 . . . m}, e.g., thepermutation τx such that τx(i) < τx( j) whenever λi (cid:4)x λ j (τ (i) is the position of λi in the ranking). We shall denote theclass of all permutations of {1 . . . m} by Sm. Moreover, by abuse of notation, we shall sometimes employ the terms “ranking”and “permutation” synonymously.The training information consists of a set of instances for which (partial) knowledge about the associated preferencerelation is available (cf. Fig. 2). More precisely, each training instance x is associated with a subset of all pairwise preferences.Thus, even though we assume the existence of an underlying (“true”) ranking, we do not expect the training data to providefull information about that ranking. Besides, in order to increase the practical usefulness of the approach, we even allow forinconsistencies, such as pairwise preferences which are conflicting due to observation errors.2 We interpret the term “preference” not literally but in a wide sense as a kind of order relation. Thus, a (cid:4) b can indeed mean that alternative a is moreliked by a person than b, but also that a is an algorithm that outperforms b on a certain problem, that a is an event that is more probable than b, that ais a student finishing her studies before b, etc.\fE. Hüllermeier et al. / Artificial Intelligence 172 (2008) 1897–19161899Given:• a (potentially infinite) reference set of objects X(each object typically represented by a feature vector)• a finite set of pairwise preferences xi (cid:4) x j , (xi , x j ) ∈ X × XFind:• a ranking function r(·) that assumes as input a set of objects O ⊆ X andreturns a permutation (ranking) of this setFig. 1. Learning from object preferences.Given:• a set of training instances {xk | k = 1 . . . n} ⊆ X(each instance typically represented by a feature vector)• a set of labels L = {λi | i = 1 . . . m}• for each training instance xk : a set of pairwise preferences of the formλi (cid:4)xk λ jFind:• a ranking function that maps any x ∈ X to a ranking (cid:4)x of L (permutationτx ∈ Sm)Fig. 2. Learning from label preferences.As in the case of object ranking, this learning scenario has ",
            {
                "entities": [
                    [
                        3998,
                        4026,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 180–195Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStrong mediated equilibrium ✩Dov Monderer, Moshe Tennenholtz∗Faculty of Industrial Engineering and Management, Technion – Israel Institute of Technology, Haifa 32000, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 22 November 2007Received in revised form 5 October 2008Accepted 7 October 2008Available online 14 October 2008Keywords:Multi-agent systemsGame theoryMediatorMediated equilibriumStrong equilibriumStability against potential deviations by sets of agents is a most desired property inthe design and analysis of multi-agent systems. However, unfortunately, this property istypically not satisfied. In game-theoretic terms, a strong equilibrium, which is a strategyprofile immune to deviations by coalition, rarely exists. This paper suggests the use ofmediators in order to enrich the set of situations where we can obtain stability againstdeviations by coalitions. A mediator is defined to be a reliable entity, which can askthe agents for the right to play on their behalf, and is guaranteed to behave in a pre-specified way based on messages received from the agents. However, a mediator cannotenforce behavior; that is, agents can play in the game directly, without the mediator’shelp. A mediator generates a new game for the players, the mediated game. We provesome general results about mediators, and mainly concentrate on the notion of strongmediated equilibrium, which is just a strong equilibrium at the mediated game. We showthat desired behaviors, which are stable against deviations by coalitions, can be obtainedusing mediators in several classes of settings.© 2008 Published by Elsevier B.V.1. IntroductionWhen considering a prescribed behavior in a multi-agent system, it makes little sense to assume that an agent willstick to its part of that behavior, if deviating from it can increase its payoff. This leads to much interest in the study ofNash equilibrium in games. When agents are allowed to use mixed strategies, Nash equilibrium always exists. However,Nash equilibrium does not take into account deviations by non-singleton sets of agents. While stability against deviationsby subsets of the agents, captured by the notion of strong equilibrium [4], is a most natural requirement, it is well knownthat obtaining such stability is possible only in rare situations.1In order to tackle this issue we consider in this paper the use of mediators. A mediator is a reliable entity that can interactwith the players and perform on their behalf actions in a given game. However, a mediator cannot enforce behavior. Indeed,an agent is free to participate in the game without the help of the mediator. This notion is highly natural in a setting inwhich there exists some form of reliable party or administrator that is ready to serve as a mediator. For example, whenEbay is offering proxy services, it actually acts as a mediator and not only as an organizer. Notice that we assume that themulti-agent interaction formalized as a game is given, and that all the mediator can do is to communicate with the agents✩An extended abstract of this paper appears in the proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06). Almost allproofs are missing from the extended abstract. This version of the paper contains all of these missing proofs, and provides additional discussion and results.Furthermore, some of the definitions that appear in the extended abstract have been slightly modified. This work has been partially supported by the IsraelScience Foundations (ISF).* Corresponding author.E-mail address: moshet@ie.technion.ac.il (M. Tennenholtz).1 For example, in the context of congestion games, Holzman and Law-Yone [13] characterized the networks where strong equilibrium always exist. Theyshowed that strong equilibrium is guaranteed only in a very restricted type of networks.0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.10.005\fD. Monderer, M. Tennenholtz / Artificial Intelligence 173 (2009) 180–195181and perform actions on behalf of the agents that allow it to do so. The mediator’s behavior is pre-specified and depends onthe messages received from all agents. This natural setting is different from the one discussed in the theory of mechanismdesign, where a designer designs a new game from scratch in order to yield some desired behavior.Indeed, many markets employ very powerful forms of mediators like brokers, or routers in communication networks.2 Wefind the notion of a mediator as central to the study of multi-agent systems. Indeed, while in economic theory, the dominanttheme is that rational agents are to behave independently without any interference of a mediator, the (either explicit orimplicit) existence of a party that provides suggestions, protocols, and rules of behavior has always been fundamental in theAI context of multi-agent systems (see [9,25] for some early introductions). As a result, in this paper we develop a rigorousstudy of mediators, aiming at the study of their use in establishing stability against deviations by coalitions.A mediator for a given game is defined by sets of messages, one set for each player, and by an action function definedon vectors of messages; when a player sends a message to the mediator she gives the right to play to the mediator whowill choose an action on her behalf (possibly by randomization) by applying the action function to the vector of messagessent to him. However, the mediator cannot enforce the players to use his services. The mediator generates a new gamefor the players, which we call the mediated game. In this game every player can either send a message to the mediator orplay without the mediator. The outcome generated in the given game by an equilibrium in the mediated game is calleda mediated equilibrium. An outcome generated by a strong equilibrium at the mediated game is called a strong mediatedequilibrium. In an extreme case the message space of each player is a singleton. That is, this mediator accepts only onepossible message: “I give you the right to play on my behalf”. Such a mediator is called a minimal mediator. An importantmediator is the one already developed in [32], where the set of messages of each player is the set of possible programsin a given programming language; in this case the action function is the one that executes the programs. Hence, programequilibrium is a particular type of mediated equilibrium. We further discuss the connections between mediators and thenotion of program equilibrium in Section 10. In this paper we concentrate on the notion of strong mediated equilibrium.In order to illustrate the power of a reliable mediators as discussed in this paper, consider the following simple example:In this classical Prisoners’ dilemma game we get that in the unique equilibrium both agents will defect, yielding both ofthem a payoff of 1. However, this equilibrium, which is also a dominant strategy equilibrium, is inefficient; indeed, if bothagents deviate from defection to cooperation then both of them will improve their payoffs. Formally, mutual defection isnot a strong equilibrium.Consider a reliable minimal mediator who offers the agents the following action function: if both agents give the media-tor the right to play, he will perform cooperate on behalf of both agents. However, if only one agent agrees to give the rightto play, the mediator he will perform defect on behalf of that agent. Hence, the mediator generates the following mediatedgame:2 One interesting type of such markets is that of lottery syndicates. A lottery syndicate coordinates agents’ activities in a lottery by trying to optimizethe participants’ joint actions. Such syndicates are known to be successful in the UK. It seems, however, that they are considered illegal at the US.\f182D. Monderer, M. Tennenholtz / Artificial Intelligence 173 (2009) 180–195The mediated game has a most desirable property: it possesses a strong equilibrium; that is, an equilibrium which isstable against deviations by coalitions. In this equilibrium both agents will give the mediator the right to play, which willlead them to a payoff of 4 each! Hence, cooperation in the Prisoners’ Dilemma game is a strong mediated equilibrium.In Sections 3 and 4 we explore general properties of mediators. Given the general concept of a mediator, we prove thatmediators can indeed significantly increase the set of multi-agent encounters in which desired outcomes, which are stableagainst deviations by coalitions, can be obtained. We first prove that every two-person game possesses a strong mediatedequilibrium, which also leads to optimal surplus. For general n-person games we prove that every balanced symmetric gamepossesses a strong mediated equilibrium, which also leads to optimal surplus. The precise definition of a balanced game isgiven in Section 7.1.3 On an intuitive level, a game is balanced if there exists a profile of strategies yielding a payoff vectorwith the property that for each coalition of players their aggregate payoffs in this vector is at least as high as the aggregatepayoff they can grantee themselves in the game by using a correlated strategy. For example, the Prisoner’s Dilemma gamediscussed above is a balanced game. The profile of strategies (c, c) yields the payoff vector (4, 4); No player can guaranteesherself more than 4, and the coalition of the two players cannot guarantee itself more than 8.In between equilibrium and strong equilibrium one can naturally define k-strong equilibrium as an outcome, which isimmune to deviations of coalitions of size at most k. Indeed, if one considers the distributed computing and cryptographyliterature, it typically requires stability against deviations by up to k (typically faulty or malicious) agents, which can beviewed as a particular form of game-theoretic",
            {
                "entities": [
                    [
                        4063,
                        4091,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1540–1578Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPouring liquids: A study in commonsense physical reasoningErnest Davis 1Department of Computer Science, New York University, USAa r t i c l ei n f oa b s t r a c tThis paper presents a theory that supports commonsense, qualitative reasoning about theflow of liquid around slowly moving solid objects; specifically, inferring that liquid can bepoured from one container to another, given only qualitative information about the shapesand motions of the containers. It shows how the theory and the problem specificationcan be expressed in a first-order language; and demonstrates that this inference andother similar inferences can be justified as deductive conclusions from the theory and theproblem specification.© 2008 Elsevier B.V. All rights reserved.Article history:Received 7 August 2007Received in revised form 20 April 2008Accepted 22 April 2008Available online 30 April 2008Keywords:LiquidsQualitative physical reasoningNaive physicsQualitative spatial reasoning1. IntroductionCarrying liquids in containers and pouring or ladling liquids from one container to another are among the most commonways in which people interact with liquids in daily life. People are very familiar with these phenomena and can reasonabout them easily. In particular, people understand how the physical behavior of the liquids is largely determined by thegeometrical characteristics of the liquid, the containers, and the motions involved; they can reason about physical behaviorusing only partial knowledge of the geometry, without full geometric specifications; and they can use the same knowledgein multiple inferential directions.For instance, people know that, if a cup has a small hole through the bottom, then liquid in the cup will leak outthrough the hole, but that a dent in the bottom will not cause the liquid to leak. They can use this knowledge in manyways: prediction—given that there is a hole, predict that the liquid will leak; explanation—given that the liquid is leakingfrom the bottom, deduce that there is a hole; design—if you want the liquid to drain (e.g. you are designing a colander), puta hole in the bottom; and so on. These various forms of reasoning can be carried out without knowing or positing a preciseshape description for the cup or the hole.It is very desirable that an automated reasoner likewise be able to deal with partial geometric information. Precisegeometric information may be unavailable for a number of different reasons. It may not be possible for the agent to perceiveor measure the features accurately. The features may be inferred rather than perceived. The object may be in a preliminarystate of design, and the precise geometry may not yet have been specified. The features may be a result of a future eventwhich is not yet fully known; for instance, a reasoner may be concerned that an object may spring a leak and worry aboutthe effect on the liquid inside, without knowing where exactly the leak will be or what its shape will be. A reasoner mayneed to reason generically about classes of similar objects and similar actions rather than about a single manipulation of asingle object.The theory of fluid dynamics, of course, contains a very large body of mathematics, mathematical physics, and scientificsoftware devoted to the question of predicting the flow of fluids; and these computations can now be done with very greatE-mail address: davise@cs.nyu.edu.1 I am grateful to the reviewers for many helpful suggestions. This research was supported in part by NSF grant IIS-0534809.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.04.003\fE. Davis / Artificial Intelligence 172 (2008) 1540–15781541Fig. 1. Pouring from pitcher to pail.accuracy and speed. However, these techniques all work, either by using a fine-grained division of space and time, and bycalculating the force and flow of each small piece of liquid at small step of time; or, if the PDE’s are solved or analyzedexactly, by calculating the force and flow at literally every point and instant. The techniques deliver extremely precisepredictions of fluid flow, but they require correspondingly precise specification of the boundary conditions (the shapes ofthe solid objects in contact the liquid).As the evolution of forces and flows may be extremely variable over a range of circumstances where the overall qual-itative behavior is quite stable, there is an inherent mismatch between these techniques and the objectives of qualitativereasoning. In AI applications, precise boundary conditions are generally not known and detailed predictions are not neces-sary. Different ways of pouring from a pitcher to a pail, or different shapes of the pitcher and the pail, may give rise to flowand force patterns that are completely different; but the commonsensically important inference, that the liquid pours fromthe pitcher to the pail, remains stable.For this reason, we are looking for a characterization of the behavior of liquids that does not require calculating ofvelocity, acceleration, momentum and forces. Not that these concepts lie outside a commonsense understanding of physics—on the contrary these, or something similar, are part of a commonsense understanding—but it must often be possible for aqualitative reasoner to reason about the large scale behavior of liquids without invoking these concepts.The objective of this paper is to characterize some cases of commonsense reasoning about liquids at the knowledgelevel [28]; that is, to demonstrate that, for some types of simple qualitative reasoning about liquids, one can develop arepresentation language and a theory such that the knowledge used in the reasoning and the specifications of particularproblems can be (approximately) expressed in the language and the reasoning itself can be carried out as inference from thegeneral theory and specifications. This paper is thus part of the general programme proposed by Hayes and by McCarthy [18,24,25] of developing automated commonsense reasoners by representing commonsense knowledge in logic-based languages.(We will discuss the goals of the representation in more detail in Section 1.1.)In this paper we develop a large part, though not all, of a commonsense theory of liquid flowing around slowly movingsolid objects. We illustrate the adequacy of the theory by showing that it suffices for correct prediction in a number ofscenarios, including carrying a liquid in a closed container or in an open container, pouring a liquid from one container toanother, or ladling liquid out of a container using a spoon.The primary example we will use here is pouring from one container to another. Specifically, we consider the followingscenario (Fig. 1): There is a pitcher, partly full of liquid, and an empty pail. Both of these “hold water”. The pail remainsin a fixed position throughout the scenario. The pitcher is lifted, keeping it sufficiently upright that the liquid inside doesnot reach its spout. Once it is in position, with the spout (though not necessarily all of the pitcher) centered over the pail,the pitcher is tilted until the capacity of the part of the inside of the pitcher lower than the spout is less than the volumeof the liquid. At this point, the liquid pours out of the pitcher, and falls downward into the pail, where it remains. At theend of the scenario, the liquid is divided into a section that remains in the pitcher and a section that is in the pail. Wedemonstrate that, given qualitative characterizations of the shapes of the pitcher and the pail and of the motion of thepitcher, our theory allows us to infer the behavior of the liquid.(Note: all of the figures in this paper are cross-sections in the x–z plane. Throughout this paper, solid objects are indi-cated with diagonal lines, and liquid is indicated in grey. The fact that the pictures show liquid flowing in polygonal patternsreflects my personal limitations in using the drawing software; it is not at all a requirement of the theory.)Many aspects of the commonsense understanding of liquids are omitted from our analysis here. Some of the mostimportant of these are:• Liquids in modes that are not “bulk”, in Hayes’ [19] terminology, such as mists, wettings of surfaces, liquids absorbed insponges, and so on.• Liquids in energetic modes, again in Hayes’ terminology, such as fountains or even splashes.• Mixtures or solutions of any kind.• Interactions of liquids with the atmosphere or other gasses.\f1542E. Davis / Artificial Intelligence 172 (2008) 1540–1578• The effect of liquids on the solids with which they are in contact. We assume that the motion of the solids is given byexternal constraints. Thus, our theory does not include waterwheels or other mechanisms controlled by hydraulics, solidobjects floating on liquids, swimming, and so on. (The theory may be capable in such cases of predicting the liquid flowgiven the motion of the solid objects, but it certainly cannot predict the motion of the solid objects.)• Pressure and any consequences of pressure differences. In particular, we assume that all parts of the top surface of aliquid meet the open atmosphere and are therefore at equal height.• Viscosity, surface tension, cohesion, adhesion, absorption, and so on. We deal only with “dry water”, in von Neumann’ssardonic phrase.• Any consideration of heat, temperature, and phase transitions, such as evaporation and freezing.• The feasibility of actions by an agent. The theory developed for physical feasibility of actions on solid objects in [11]can be extended to this domain, but we will not discuss this in this paper.• The theory yields incorrect predictions for liquids flowing down a channel (Section 6). This is probably the most impor-tant gap in the theory.The paper is organized as follows. Section 1.1 discusses the various goals of this representational work i",
            {
                "entities": [
                    [
                        3739,
                        3767,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1222–1246Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCompactly representing utility functions using weighted goals andthe max aggregator ✩Joel Uckelman∗,1, Ulle EndrissInstitute for Logic, Language and Computation, University of Amsterdam, Netherlandsa r t i c l ei n f oa b s t r a c tWeighted propositional formulas can be used to model preferences over combinatorialdomains: each formula represents a goal we would like to see satisfied, the weight of aformula represents the importance of the goal in question, and to assess the desirability ofa given alternative we aggregate the weights of the goals satisfied by that alternative. Oneof several options is to aggregate by using the maximum of the weights of the satisfiedgoals. This approach gives rise to a family of preference representation languages, one foreach of a range of possible restrictions we can impose on either formulas or weights. Weanalyze the properties of these languages and establish results regarding their expressivity,and absolute and relative succinctness. We also study the computational complexity of theproblem of finding the best and the worst alternative for a given set of weighted goals,and of finding an alternative that is optimal for a group of agents, for a range of differentnotions of collective optimality proposed in social choice theory and welfare economics.© 2010 Elsevier B.V. All rights reserved.Article history:Received 11 January 2010Received in revised form 8 July 2010Accepted 12 July 2010Available online 17 July 2010Keywords:Preference representationPreference aggregation1. Introduction1.1. Motivation and backgroundPreference handling is a problem of central importance in Artificial Intelligence [3]. For example, recommender systemsneed to elicit and maintain a representation of the user’s preferences and multiagent systems are often modeled as col-lections of decision-theoretic agents, each of which are guided by their own preferences. Possibly the most fundamentalquestion in this context is how to best represent the preferences of an artificial agent or a human user. Designing suitablelanguages for representing preferences is particularly challenging when the alternatives over which an agent expresses pref-erences have a combinatorial structure. For example, in the context of combinatorial auctions [4] or other resource allocationproblems [5], the number of bundles of goods an agent may obtain is exponential in the number of goods under discussion,so being able to express preferences over this exponentially large space of alternatives in a compact manner is crucial.In this paper we study a particular family of languages for representing cardinal preferences over combinatorial domainsthat are Cartesian products of several binary domains. Expressing a cardinal preference means specifying a (utility or valua-tion) function mapping each alternative to a number reflecting the degree of preference for that alternative. For comparison,ordinal preferences are relations over pairs of alternatives specifying whether one is preferable to the other. The use of utility✩This paper is based on and extends work presented at the 11th International Conference on Principles of Knowledge Representation and Reasoning(KR-2008) (Uckelman and Endriss (2008) [1]), and additionally presents material from Uckelman (2009) [2].* Corresponding author.E-mail addresses: j.d.uckelman@uva.nl (J. Uckelman), ulle.endriss@uva.nl (U. Endriss).1 The work of Joel Uckelman was supported by a GLoRiClass fellowship funded by the European Commission (Early Stage Research Training Mono-HostFellowship MEST-CT-2005-020841).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.07.003\fJ. Uckelman, U. Endriss / Artificial Intelligence 174 (2010) 1222–12461223functions to model preferences is appropriate in some circumstances, and inappropriate in others. In the context of com-binatorial auctions, for instance, modeling preferences as utility functions is appropriate: in such an auction each bidderneeds to express how much they would be prepared to pay for a given bundle of goods [4]. From the representational pointof view, this amounts to specifying a function from the space of bundles to numbers, i.e., to specifying a cardinal preferencestructure.The family of preference representation languages we study is based on weighted propositional formulas, or weightedgoals. For a given set of propositional variables, alternatives correspond to models for propositional formulas. A utilityfunction mapping such alternatives to the reals can then be represented as a set of weighted goals, as follows: To computethe utility of a given alternative X , we first collect all the weights of the goals satisfied by X and then we aggregate thoseweights to obtain a single number, the utility of X . One natural aggregation function is (cid:2); in this case, the utility of X isthe sum of the weights of the goals satisfied by X . An other option is to use the max operator; in this case the utility of Xis the maximum of the weights of the goals satisfied by X .Using weighted formulas for preference representation is an idea which originated in penalty logic [6]. Penalty logicaddresses the problem of how to make inferences from an inconsistent knowledge base by augmenting the formulas ina knowledge base with weights, which indicate the cost of falsifying the associated formula; then the inference problemreduces to considering what is valid over only the minimal-cost consistent subsets of a given knowledge base. Here, costs aresummed: That is, the cost of rejecting ϕ and ψ is the sum of their weights. Lafage and Lang [7] generalize penalty logic topermit aggregators other than sum, and also introduce a distance-based aggregator. Coste-Marquis et al. [8] take a differentapproach: Rather than using goalbases directly for representing cardinal preferences, they use goalbases to underpin variousordinal preference relations.Chevaleyre et al. [9] shifted from considering the weights of unsatisfied formulas as penalties to considering the weightsof satisfied formulas as utilities, and their work contains initial results on goalbases aggregated with sum; later work extendsthis to systematically cover most naturally-defined sum-aggregated goalbase languages [10]. Recently, this framework hasbeen further extended from propositional logic to description logic [11,12].1.2. Our contributionAs mentioned, most previous work has concentrated on the weights of unsatisfied goals or on sum languages, whereweights are aggregated via (cid:2). In this paper we explore in depth the properties of the next most important family oflanguages that can be constructed in this framework, namely the max languages, in which the aggregation function used ismax. The properties we study concern the expressivity, the succinctness, and the complexity of max languages.Expressivity. We establish correspondence results which show what classes of utility functions can be represented by themost natural representatives of the family of the max languages. For instance, if the only logical connective allowed isconjunction, then we can represent the monotone utility functions, and only those.Succinctness. We rank the most important max languages in terms of how compactly they can represent those utilityfunctions that they are able to represent. Informally, language L is at least as succinct as L(cid:3)if the increase in size whentranslating representations from L(cid:3)to L is polynomially bounded. For instance, conjunctions of literals induce a strictlymore succinct language than conjunctions of atoms if only positive weights are permitted, but an equally succinct languageif both positive and negative weights can be used. We also provide results concerning bounds on the absolute succinct-ness of some languages, and we study whether languages have unique or multiple representations for the same utilityfunction.Complexity. We first address two natural problems that arise in the context of reasoning about the preferences of a singleagent when these are represented using a max language. Here we study the computational complexity of (the decisionvariants of) the problem of finding the highest and the lowest utility that such an agent may experience. It turns outthat the complexity strongly depends on the language chosen; some problems can be solved in linear time while othersare coNP-complete. We also study the complexity of collective utility maximization, the problem of finding the “best”partitioning of the set of propositional variables amongst a group of agents (inducing a model for each of them). There area number of different ways of aggregating the utilities of the members of a group to define what is best for that group. Weanalyze the complexity of the problem for several of the standard notions of collective utility, familiar from the social choiceand welfare economics literature, such as utilitarian social welfare, egalitarian social welfare, and the Nash product [13].1.3. Related workSimilar questions have previously been addressed for other preference representation languages.CP-nets [14] are a tool for representing conditional ordinal preferences over combinatorial domains (rather than utilityfunctions, on which we focus in this paper). As with any individual preference representation formalism, we may wish toaggregate individual preferences into group preferences. Various methods for aggregating the CP-nets of multiple agentshave been tried by, e.g., Rossi et al. [15] and Lang and Xia [16]; the analogous problem for us, aggregating the goalbases of\f1224J. Uckelman, U. Endriss / Artificial Intelligence 174 (2010) 1222–1246multiple agents, we take up in Section 8. The complexity of answering ordering and dominance queries is also studied inthe CP-nets literature [17]; we do not study these questions for goalbases",
            {
                "entities": [
                    [
                        3789,
                        3817,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 440–447www.elsevier.com/locate/artintA hierarchy of prescriptive goals for multiagent learningMartin Zinkevich a,∗, Amy Greenwald b, Michael L. Littman ca University of Alberta, Edmonton, AB, Canadab Brown University, Providence, RI, USAc Rutgers University, New Brunswick, NJ, USAReceived 13 May 2006; received in revised form 15 February 2007; accepted 15 February 2007Available online 30 March 2007AbstractA great deal of theoretical effort in multiagent learning involves either embracing or avoiding the inherent symmetry between theproblem and the solution. Regret minimization is an approach to the prescriptive, non-cooperative goal that explicitly breaks thissymmetry, but, since it makes no assumptions about the adversary, it achieves only limited guarantees. In this paper, we consider ahierarchy of goals that begins with the basics of regret minimization and moves towards the utility guarantees achievable by agentsthat could also guarantee converging to a game-theoretic equilibrium.© 2007 Published by Elsevier B.V.1. IntroductionThe prescriptive, non-cooperative goal set forth in Shoham et al. is to design intelligent agents that perform wellin the presence of other intelligent agents. Much of the research and analysis in this domain involves either bypassingthe circularity of this objective (as in regret minimization) or embracing it (as in equilibrium or self-play analyses).In this paper, we will try to unravel this objective by consciously breaking the symmetry between the agent, whosebehavior we can prescribe, and the environment (other players1) over which we have no control. Much of the regretminimization literature also speaks from this perspective: in fact, concepts like calibration have origins in predictingthe weather, hardly a multiagent problem!Nonetheless, without making some assumptions about an agent’s environment, there are some guarantees thatsimply cannot be achieved, such as convergence to the set of Nash or correlated equilibria. This observation hasprompted others in the past to study self-play, where the environment is assumed to exhibit the same behavior as theagent. We believe that self-play is an example of a restriction upon the environment that limits the applicability ofmany results. The fact that an agent performs well in self-play says nothing about how that agent might interact withhumans or agents designed by others.Instead, we believe a more useful focus is on characterizations of environments that can be made in an agent-independent way, as described below.* Corresponding author.E-mail addresses: maz@cs.ualberta.ca (M. Zinkevich), amy@cs.brown.edu (A. Greenwald), mlittman@cs.rutgers.edu (M.L. Littman).1 We will use player to refer to the agent or the environment.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.02.005\fM. Zinkevich et al. / Artificial Intelligence 171 (2007) 440–447441Different learning agents can be considered to be trading off between the breadth of the set of environments theywork on and how well they work on that set. Or, to focus on the set of environments apart from an agent, three relevantattributes of an environment class come to mind:• Workability: What type of guarantees can be achieved against the class? By definition, agents care about utility(although how they should go about earning utility is a matter of some debate). In this paper, for concreteness, wefocus on a particular form of utility guarantees, and then discuss the environment sets in which it is possible toachieve those guarantees.• Breadth: How broad is the class? As MAL researchers, we wish to develop agents that can achieve guarantees foras broad an environment class as possible.Consider the result that no-internal regret2 agents [2,3] (we call this set ANIR) converge (in the empirical frequencyof joint actions) to the set of correlated equilibria when playing against any environment that is no-internal regret(we call this set ENIR). An interesting question arises: what if the environment is not no-internal regret? Moreover,what if we only cared about getting the utility of a stationary correlated equilibrium instead of converging to theequilibrium itself?For instance, we could add to ENIR (although not to ANIR) those environments that play stationary Nash equilibria,and the NIR agents would still get a high utility.3 Oddly, we could not add altruistic environments that play asif their opponent’s utilities were their own and have no-internal regret: for instance, if the environment has adominant strategy, it might lead to easy cooperation, whereas both players even with identical utilities might havea difficult time making a common choice. Thus, as we expand this environment set, not only do we get a strongerguarantee, but we also learn more about what makes the original result work in the first place.• Saliency: Are there agents in the class that perform well on the class? Are there agents that could be considered in-telligent? Throughout our description of environment sets, we avoid circularity by not addressing saliency directly.However, we hope to find the environments that are ultimately derived (using the principles of workability andbreadth) to be a superset of the environments we consider intelligent, or at least to overlap significantly. Whetherthis outcome prevails or not will be the primary measure of the success of our proposed agent/environment split.Normally, when researchers formulate an environment class, they either consider the set of all environments orthey begin with some concept of saliency (such as self-play).4 Between these two extremes in multiagent learning—guarantees that can be achieved in every environment and guarantees that can be achieved in self-play—there lies ahierarchy:Definition 1. A hierarchy of prescriptive goals is:(1) A hierarchy of environment sets {S1, . . . , Sk}, each one contained in its predecessor.(2) A hierarchy of guarantees {G1, . . . , Gk},such that there exists a single agent that, for every i, satisfies Gi with every environment in Si .In the large margin structural risk-minimization literature, there is a hierarchy of hypothesis spaces, with largemargin hypotheses nearer to the top of the hierarchy and smaller margin hypotheses nearer to the bottom. Assumethat the data agrees with some hypothesis, given a supervised-learning problem. If it agrees only with a small marginhypothesis, then a large amount of training data is required for good generalization performance. This guarantee2 They are referred to as no-regret agents by Foster and Vohra [2]. We use the terminology of Greenwald and Jafari [4] to distinguish no-internaland no-external regret.3 In particular, the agents in ANIR would still CEV work with the environments that play stationary Nash equilibria (see Section 3). However,the empirical joint action frequency might no longer converge to the set of correlated equilibria. Moreover, the agents that play stationary Nashequilibria do not work with ENIR, because that the ENIR algorithms will converge to a best response to a Nash equilibrium, not a Nash equilibriumitself.4 Another popular choice is the set of stationary environments. The advantage of this set is that the stationarity assumption is made in classificationtasks, and therefore supervised-learning techniques can carry over. However, there is no reason to believe that intelligent agents should exhibitstationary behavior. They, too, should learn.\f442M. Zinkevich et al. / Artificial Intelligence 171 (2007) 440–447near the bottom of the hierarchy is weak. On the other hand, if a large margin hypothesis agrees with the data, thenthe generalization performance is excellent with only a few training examples. A single algorithm—a support-vectormachine—can achieve all of these guarantees. If one such algorithm did not exist, then this hierarchy of generalizationguarantees and hypotheses spaces could only be viewed as a collection of goals, and could not be interpreted as asingle, overarching goal. Similarly, we view our proposed hierarchy of prescriptive goals as a single, overarching goalfor multiagent learning.Our perspective is similar to the objectives specified by Bowling [1], who suggests that agents should be designedto achieve two different guarantees (convergence to Nash equilibrium and best response) against two different classesof environments (self-play and stationary). Even more closely related to what we are proposing here are two resultsabout no-internal regret agents: namely, that they minimize internal regret in an arbitrary environment and that theirempirical joint action frequency converges to the set of correlated equilibria. In this work, we will focus on theimplications upon utility of these two guarantees, and we will analyze whether a broader class of environments canbe handled at each level.It is not only the theoretical elegance of structural risk minimization that has excited machine-learning researchers;what is most impressive is its practical implications. The advantage to an empiricist of using such a technique isthat it allows her to give a soft boundary on what she expects to happen. Thus, an algorithm can use the data todecide exactly how accurate the empiricist’s assumptions are and to relax them as necessary to deal with real-worldoccurrences. Whether through regret methods or the hierarchies described here, soft assumptions which, if true, resultin a performance guarantee, but, if false, do not preclude the algorithm from performing reasonably well,5 are usefulfor developing agents that perform well in practice.2. A model of interaction: Repeated bimatrix gamesIn this paper, we restrict our attention to repeated bimatrix games, as they are sufficient to model many of thefundamental issues in multiagent learning.6 Moreover, we assume that the game, including its utility functions, isknown to both players. Although this assumption will bias our discussion, we believe",
            {
                "entities": [
                    [
                        2850,
                        2878,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 581–606www.elsevier.com/locate/artintLinguistic quantifiers modeled by Sugeno integralsMingsheng Ying 1State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology,Tsinghua University, Beijing 100084, ChinaReceived 1 December 2004; received in revised form 3 February 2006; accepted 15 February 2006Available online 20 March 2006AbstractSince quantifiers have the ability of summarizing the properties of a class of objects without enumerating them, linguisticquantification is a very important topic in the field of high level knowledge representation and reasoning. This paper introducesa new framework for modeling quantifiers in natural languages in which each linguistic quantifier is represented by a family offuzzy measures, and the truth value of a quantified proposition is evaluated by using Sugeno’s integral. This framework allowsus to have some elegant logical properties of linguistic quantifiers. We compare carefully our new model of quantification andother approaches to linguistic quantifiers. A set of criteria for linguistic quantification was proposed in the previous literature.The relationship between these criteria and the results obtained in the present paper is clarified. Some simple applications of theSugeno’s integral semantics of quantifiers are presented. 2006 Elsevier B.V. All rights reserved.Keywords: High level knowledge representation and reasoning; Natural language understanding; Computing with words; Fuzzy logic; Quantifier;Fuzzy measure; Sugeno’s integral1. IntroductionFirst order logic increases the expressive power of propositional logic a lot through adding quantifiers. Classicalfirst order logic only possesses two quantifiers, the universal quantifier (∀) and the existential quantifier (∃). However,these quantifiers are often too limited to express some properties of certain mathematical structures and to modelcertain knowledge stated in natural languages. This leads logicians and linguists to introduce the notion of generalizedquantifiers.As early as in 1957, Mostowski [29] proposed a general notion of generalized quantifier and showed that first orderlogic with a class of generalized quantifiers are not axiomatizable. This work together with others initiated the subjectof model theoretic logics.Barwise and Cooper [2] started the studies of generalized quantifiers in natural languages. Since then, a rich varietyof generalized quantifiers in natural languages have been found, and their expressive power and logical propertieshave been thoroughly investigated from both semantic and syntactic aspects. In particular, van Benthem [36] viewedE-mail address: yingmsh@tsinghua.edu.cn (M. Ying).1 This work was partly supported by the National Foundation of Natural Sciences of China (Grant No: 60321002, 60496321) and the Key GrantProject of Chinese Ministry of Education (Grant No: 10403).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.02.001\f582M. Ying / Artificial Intelligence 170 (2006) 581–606a generalized quantifier as a relation on the subsets of a universe of discourse, and systematically examined variousrelational behaviors of generalized quantifiers such as reflexivity, symmetry, transitivity, linearity and monotonicityand their roles in realizing certain inference patterns. For a recent review on the theory of generalized quantifiers innatural languages, we refer to [24].It has been clearly realized in the artificial intelligence community that natural languages are suited to high levelknowledge representation [26,33]. This is indeed one of the main motivations of computing with words [25,50,57].However, classical logic is not adequate to face the essential uncertainty, vagueness and ambiguity of human reasoningexpressed in natural languages. Consequently, the logical treatments and mathematical models of the concepts ofuncertainty, vagueness and ambiguity is of increasing importance in artificial intelligence and related researches, andmany logicians have proposed different logic systems as a formalization of reasoning under uncertainty, vaguenessand ambiguity (see, for example, [3,44–47,49], [11, Chapter III.1], or [19, Chapter 7]).Since quantifiers have the ability of summarizing the properties of a class of objects without enumerating them,linguistic quantification is a very important topic in the field of knowledge representation and reasoning. Quantifiersin natural languages are usually vague in some sense. Some representative examples of linguistic quantifiers withvagueness are [56]: several, most, much, not many, very many, not very many, few, quite a few, large number, smallnumber, close to five, approximately ten, frequently. It is clear that two-valued logic is not suited to cope with vaguequantifiers. There has been, therefore, increasing interest about logical treatment of quantifiers in human languages infuzzy logic community. Indeed, sometimes fuzzy logic permits a more precise representation of the kind of quantifiersin various natural languages.The first fuzzy set theoretic approach to linguistic quantifiers was described by Zadeh [55,56]. In his approach,linguistic quantifiers are treated as fuzzy numbers and they may be manipulated through the use of arithmetic forfuzzy numbers. The truth evaluation of a linguistically quantified statement is performed by computing the cardinalityof the fuzzy set defined by the linguistic predicate in such a statement and then by finding the degree to which thiscardinality is compatible with the involved quantifier. Since then, a considerable amount of literature [1,4–7,9,10,12,15–18,30–32,42,43,51,52] has been devoted to the studies of linguistic quantifiers in the framework of fuzzy settheory. For example, in a series of papers [39–41], Yager proposed the substitution method for evaluating quantifiedpropositions and the method based on OWA operators. For a survey, see [27,28].On the other hand, fuzzy quantification models are employed in solving a great variety of problems from manydifferent fields such as database querying [7,23], data mining and knowledge discovering [7,25], information fusion[21,25], group decision making and multiple-objective decision making [20,40], inductive learning [21], and opti-mization and control [22].This paper introduces a new framework for modeling quantifiers in natural languages. In this framework, linguisticquantifiers are represented by Sugeno’s fuzzy measures [35]. More precisely, a quantifier Q is seen as a family of fuzzymeasures indexed by nonempty sets. For each nonempty set X, the quantifier Q limited to the discourse universe Xis defined to be a fuzzy measure QX on X, and for any subset E of X, the quantity QX(E) expresses the truth valueof the quantified statement “Q Xs are As” when A is a crisp predicate and the set of elements in X satisfying A is E.As is well known, predicates in linguistically quantified statements are often vague too. In this general case, the truthvalue of a quantified proposition is then evaluated by using Sugeno’s integral [35].The advantage of this framework is that it allows us to have some elegant logical properties of linguistic quanti-fiers. For example, we are able to establish a prenex normal form theorem for linguistic quantifiers (see Corollary 34).It should be pointed out that this paper only deals with increasing quantifiers because fuzzy measures assumemonotonicity. Thus, quantifiers such as several, few, quite a few, small number, not many, not very many, close tofive, approximately ten cannot be modeled in our proposed setting.This paper is arranged as follows. For convenience of the reader, in Section 2 we review some notions and resultsfrom the theory of Sugeno’s fuzzy measures and integrals. In Section 3, (linguistic) quantifiers are formally definedin terms of fuzzy measure, and several operations of quantifiers are introduced. In Section 4, we construct a firstorder language with linguistic quantifiers and present semantics of such a logical language. In particular, the truthvaluation of quantified formulas is given by using Sugeno’s integrals. Section 5 is devoted to examine thoroughlylogical properties of linguistic quantifiers. In particular, we prove a prenex normal form theorem for logical formulaswith linguistic quantifiers. In Section 6, the notions of cardinal and numeric quantifiers are introduced so that we areable to establish a close link between the Sugeno integral semantics and the Zadeh’s cardinality-based semantics oflinguistic quantifiers. In Section 7, we present some simple applications to illustrate the utility of the results obtained\fM. Ying / Artificial Intelligence 170 (2006) 581–606583in the current paper. In Section 8, our Sugeno integral approach to evaluation of quantified statements is comparedwith others. A set of criteria for linguistic quantification was proposed in the previous literature. The relationshipbetween these criteria and the results obtained in the present paper is clarified. We draw conclusions and point outsome problems for further studies in Section 9.2. Fuzzy measures and Sugeno integralsThis is a preliminary section. In this section, we are going to review some notions and fundamental results neededin the sequel from the theory of fuzzy measures and Sugeno’s integrals. For details, we refer to [35] or [11, Chapter 5].The theory of fuzzy measures and integrals was originally proposed by Sugeno [35]. Fuzzy measure is a general-ization of the notion of measure in mathematical analysis, and it relaxes the condition of additivity for usual measureand only assume monotonicity. Thus, fuzzy measures are very general, and probability measures, Zadeh’s possibilitymeasures, Shafer’s belief functions among others [37] are shown to be special cases of fuzzy measures. Sugeno’sintegral is analogous to Lebesgue integral. The difference between them is that addition and multiplication in",
            {
                "entities": [
                    [
                        3009,
                        3037,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 143–165Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantic-based regularization for learning and inferenceMichelangelo Diligenti∗, Marco Gori, Claudio SaccàDepartment of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, Italya r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 13 August 2015Accepted 26 August 2015Available online 1 September 2015Keywords:Learning with constraintsKernel machinesFOLThis paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThis paper presents Semantic Based Regularization (SBR), a unified framework for inference and learning that is centered around the notion of a constraint and of the parsimony principle. Semantic Based Regularization bridges the ability of machine learning techniques to learn from continuous feature-based representations with the ability of modeling arbitrary pattern relationships, typically used in Statistical Relational Learning (SRL) to model and learn from high-level semantic knowledge. In order to provide a unified context for manipulating perceptual data and prior knowledge, we propose to use the unifying concept of a constraint, which is sufficiently general to represent different kinds of sensorial data along with their relations, as well as to express abstract knowledge on the tasks. We unify continuous and discrete computational mechanisms, so as to accommodate in the same framework very different stimuli. In this paper, we focus on the kernel machine mathematical and algorithmic apparatus to learn from feature-based pattern representations and on constraints resulting from a fuzzy translation of First Order Logic (FOL) formulas, expressing the prior knowledge about the learning task at hand.More specifically, SBR builds a multi-layer architecture having kernel machines at the input layer. The output of the kernel machines is fed to the higher layers implementing a fuzzy generalization of the FOL knowledge. Thanks to the * Corresponding author.E-mail addresses: diligmic@diism.unisi.it (M. Diligenti), marco@diism.unisi.it (M. Gori), sacc@unisi.it (C. Saccà).http://dx.doi.org/10.1016/j.artint.2015.08.0110004-3702/© 2015 Elsevier B.V. All rights reserved.\f144M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165basic properties of fuzzy FOL and kernel machines, the resulting model is continuous with respect to the feature values. Therefore, the high-level semantic inference provided by the logic can be back-propagated down to the kernel machines using any gradient-based schema. This process can be iterated during training until convergence. This is an extremely powerful technique to get advantage of the available unsupervised data, as the inference process performed on this data via the logic knowledge can be used to correct the output of the kernel machines.We substantially extend earlier studies in Diligenti et al. [10] by showing that SBR enables new fundamental tasks of learning and inference that rely on the joint informative evidence coming from real-valued features and simple pattern identifiers, along with the corresponding relations. In particular, the paper gives the following new main results, which are of fundamental importance to gain an overall view of theory and, especially, to enable a large set of applications in statistical relational learning domains:variable dimension domains and null inputs We extend the SBR framework [10] to truly hybrid domains, where real-valued feature pattern representations are integrated with pure symbolic entities (e.g. pattern identifiers). Indeed, in complex relational classification tasks, it is often the case that the entities are naturally representable by pat-tern spaces of different dimensions, including the remarkable case of “void patterns” in which only relational information is available.collective classification In this paper we propose a novel collective classification method to enforce the constraints on the test set, thus exploiting the full expressiveness of FOL, like in other statistical relational learning (SRL) ap-proaches. Once again, the distinctive feature of the solution proposed in this paper arises when considering that the collective computational scheme also naturally exploits real-valued feature pattern representations.probabilistic links We extend studies on the probabilistic interpretation of regularization networks [38] to our case of learning from constraints. From one side, this highlights connections with Markov Logic Networks (MLNs) [40], while from the other side, this interpretation clearly shows the natural integration of real-valued features and object identifiers in SBR.Furthermore, the paper presents how plain SVM, Transductive, and Laplacian SVMs can be derived as special cases of the proposed SBR framework. The paper also introduces new heuristics, connected to the ones employed in constraint satisfaction programming, to improve the quality of the found solutions. Finally, we present experimental results to show the effectiveness and generality of the approach.The paper is organized as follows: in the next section previous work in the field is reviewed. Section 3 introduces First Order Logic and its fuzzy extensions, while Section 4 discusses learning from constraints with kernel machines. Section 5presents how SBR generalizes several models commonly used in relational and transductive learning. Details on how training is performed in the SBR framework is presented in Section 6. In Section 7 a collective classification approach for SBR is presented and Section 8 presents connections between SBR and probabilistic models like Markov Logic Networks. The experimental evaluation of SBR is presented in Section 9 and, finally, Section 10 draws some conclusions.2. Previous workStatistical Relational Learning (SRL) combines robust parameter estimation in the presence of noise with learning complex relational structures. Probabilistic Relational Models (PRMs) [13] are an early SRL approach that learns a statistical model from a relational database. PRMs build a probability distribution over the attributes of the objects as an instance of a schema. A Bayesian network with one node for each attribute is built and parameters are estimated from the data. Relational Dependency Networks [34] learn a (local) conditional probability distribution for each node given its Markov blanket by using a conditional learner (like logistic regression or decision trees).Markov Logic Networks (MLNs) [40] have received a lot of attention in the SRL community and have been extensively applied in many fields like bioinformatics [28] and computer vision [46]. Markov Logic Networks generalize and combine first-order logic and probabilistic graphical models. Thanks to their flexibility, MLNs have been used to tackle all the SRL main tasks: collective classification, link prediction, link-based clustering, social network modeling, and object identification. Many papers have also studied how to learn the structure of Markov Logic Networks from data without requiring an expert to express the structure in terms of prior knowledge [23,22]. Hybrid Markov Logic Networks (HMLNs) [49] extend MLNs to deal with continuous variables.Probabilistic Soft Logic (PSL) [5] is another SRL approach, which relaxes MLNs to continuous fuzzy values in the [0, 1]interval and restricts the considered FOL formulas to the ones with conjunctive body and a single literal head. PSL weight training can be solved via a convex optimization problem, but it can face only a small subset of the tasks that are potentially solved by a MLN.One disadvantage of both MLNs and PSL in real-world applications is how they deal with entities that are associated to complex feature-based representations. Let’s take as an example the common scenario of a multi-class classification task where the patterns are represented by large vectors of numeric features. In order to perform learning and inference in this domain using classical SRL techniques, different approaches are possible:\fM. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165145• the value of a feature can be correlated with one output class using one specific rule. For example, let x be a generic pattern in the domain and f be a binary feature, it is possible to express the rule HasTrueValue( f , x) ∧ BelongsTo(x, c)for each category c. The training process will estimate a weight modeling the strength of this correlation. MLNs can capture a logistic regression model using thi",
            {
                "entities": [
                    [
                        3598,
                        3626,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 235 (2016) 1–25Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA formalization of programs in first-order logicwith a discrete linear orderFangzhen LinDepartment of Computer Science, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Konga r t i c l e i n f oa b s t r a c tArticle history:Received 17 December 2014Received in revised form 23 August 2015Accepted 28 January 2016Available online 11 February 2016Keywords:Program semanticsReasoning about programsFirst-order logicWe consider the problem of representing and reasoning about computer programs, and propose a translation from a core procedural iterative programming language to first-order logic with quantification over the domain of natural numbers that includes the usual successor function and the “less than” linear order, essentially a first-order logic with a discrete linear order. Unlike Hoare’s logic, our approach does not rely on loop invariants. Unlike the typical temporal logic specification of a program, our translation does not require a transition system model of the program, and is compositional on the structures of the program. Some non-trivial examples are given to show the effectiveness of our translation for proving properties of programs.© 2016 Elsevier B.V. All rights reserved.1. IntroductionIn computer science, how to represent and reason about computer programs effectively has been a major concern since the beginning. For imperative, non-concurrent programs that we are considering here, notable approaches include Dijkstra’s calculus of weakest preconditions [1,2], Hoare’s logic [3], dynamic logic [4], and separation logic [5]. For the most part, these logics provide rules for proving assertions about programs. In particular, for proving assertions about iterative loops, these logics rely on what have been known as Hoare’s loop invariants. In this paper, we propose a way to translate a program to a first-order theory with quantification over natural numbers. The properties that we need about natural numbers are that they have a smallest element (zero), are linearly ordered, and each of them has a successor (plus one). Thus we are essentially using first-order logic with a predefined discrete linear order. This logic is closely related to linear temporal logic, which is a main formalism for specifying concurrent programs [6].Given a program, we translate it to a first-order theory that captures the relationship between the input and output values of the program variables, independent of what one may want to prove about the program. For instance, trivially, the following assignmentX = X+Ycan be captured by the following two axioms:(cid:2) = X + Y ,(cid:2) = Y ,XYE-mail address: flin@cs.ust.hk.http://dx.doi.org/10.1016/j.artint.2016.01.0140004-3702/© 2016 Elsevier B.V. All rights reserved.\f2F. Lin / Artificial Intelligence 235 (2016) 1–25where X and Y denote the initial values of the corresponding program variables and Xtheir values after the statement is performed. Obviously, the question is how the same can be done for loops. This is where quantification over natural numbers comes in. Consider the following while loopand Y(cid:2)(cid:2)while X < M do { X = X+1 }It can be captured by the following set of axioms:(cid:2) = X,(cid:2) = X(N),(cid:2) = M,MX ≥ M → XX < M → XX(0) = X,∀n.X(n + 1) = X(n) + 1,X(N) ≥ M,∀n.n < N → X(n) < M,where N is a natural number constant denoting the total number of iterations that the loop runs to termination, and X(n)the value of X after the nth iteration. Thus the third axiom says that if the program enters the loop, then the output value of the program variable X , denoted by X, is X(N), the value of X when the loop exits.The purpose of this paper is to describe how this set of axioms can be systematically generated, and show by some examples how reasoning can be done with this set of axioms. Without going into details, one can already see that unlike Hoare’s logic, our axiomatization does not make use of loop invariants. One can also see that unlike typical temporal logic specification of a program, we do not need a transition system model of the program, and do not need to keep track of program execution traces. We will discuss related work in more detail later.(cid:2)2. PreliminariesWe use a typed first-order language. We assume a type for natural numbers (non-negative integers). Depending on the programs, other types such as integers may be used. For natural numbers, we use constant 0, linear ordering relation <(and ≤), successor function n + 1, and predecessor function n − 1. We follow the convention in logic to use lower case letters, possibly with subscripts, for logical variables. In particular, we use m and n for natural number variables, and x, y, and z for generic variables. The variables in a program will be treated as functions in logic, and written as either upper case letters or strings of letters.We use the following shorthands. The conditional expression:e1 = if ϕ then e2 else e3is a shorthand for the conjunction of the following two sentences:∀(cid:7)x.ϕ → e1 = e2,∀(cid:7)x.¬ϕ → e1 = e3,where (cid:7)x are all the free variables in ϕ and ei , i = 1, 2, 3. Typically, all free variables in ϕ occur in e1.Our most important shorthand is the following expression which says that e is the smallest natural number that satisfies ϕ(n):smallest(e, n, ϕ)is a shorthand for the following formula:ϕ(n/e) ∧ ∀m.m < e → ¬ϕ(n/m),where n is a natural number variable in ϕ, m a new natural number variable not in e or ϕ, ϕ(n/e) the result of replacing n in ϕ by e, similarly for ϕ(n/m). For example, smallest(M, k, k < N ∧ found(k)) says that M is the smallest natural number such that M < N ∧ found(M):M < N ∧ found(M) ∧ ∀n.n < M → ¬(n < N ∧ found(n)).Finally, we use the convention that free variables in a displayed sentence are implicitly universally quantified from outside. For instance, the following displayed formulan < M → ¬(n < N ∧ found(n))\fF. Lin / Artificial Intelligence 235 (2016) 1–253stands for ∀n.n < M → ¬(n < N ∧ found(n)), where the universal quantification is over the domain of natural numbers as nis a natural number variable. Notice however, in the macro smallest(M, k, k < N ∧ found(k)), k is not a free variable.The following are some useful properties about the smallest macro.Proposition 1. Let (cid:7)x be the free variables other than n in ϕ(n), and m a variable not in ϕ(n). We have that∀(cid:7)x.∃nϕ(n) → ∃m.smallest(m, n, ϕ(n)).Proposition 2. Let (cid:7)x be the free variables other than n in ϕ(n), and m a variable not in ϕ(n). We have that∀(cid:7)x, m.[smallest(m, n, ϕ(n)) ∧ m > 0] → [ϕ(m) ∧ ¬ϕ(m − 1)].Furthermore,∀(cid:7)x{∃n[(∀k.k > n → ϕ(k)) ∧ (∀k.k ≤ n → ¬ϕ(k))] →∀m[smallest(m, n, ϕ(n)) ≡ ϕ(m) ∧ ¬ϕ(m − 1)]},where k is a variable not in ϕ(n).Proof. For any given (cid:7)x and m, suppose smallest(m, n, ϕ(n)) ∧ m > 0. Then ϕ(m) and ∀k.k < m → ¬ϕ(k). Since m > 0, thus ¬ϕ(m − 1). Now suppose that ϕ(m) ∧ ¬ϕ(m − 1) and for some M,[(∀k.k > M → ϕ(k)) ∧ (∀k.k ≤ M → ¬ϕ(k))].This means that M = m − 1, and smallest(m, n, ϕ(n)). (cid:2)To motivate our next proposition, consider again the following loopwhile X < M do { X = X+1 }Given input M, the number N(M) of the iterations for this loop to exit is captured by the formula smallest(N(M), n, ¬ X(n) <M). It can be seen that N(M + 1) = N(M) + 1, i.e. the number of iterations before the loop exits on input M + 1 is one more than that of on input M. This can be proved using the following proposition.Proposition 3. Let (cid:7)x be the free variables other than n in ϕ1(n) and ϕ2(n), and m1, m2, k and t variables not in ϕ1 or ϕ2. We have∀(cid:7)x, t, m1, m2.[∀k(ϕ1(k) ≡ ϕ2(k + t)) ∧ ∀k(k < t → ¬ϕ2(k)) ∧smallest(m1, n, ϕ1(n)) ∧ smallest(m2, n, ϕ2(n))] →m2 = m1 + t3. A simple class of programsConsider the following simple class of programs P constructed from a set of array identifiers array, a set of functions operator, and a set of Boolean operators boolean-op:E ::= array(E,...,E) |operator(E,...,E)B ::= E = E |boolean-op(B,...,B)P ::= array(E,...,E) = E |if B then P else P |P; P |while B do PHere E denotes expressions, B boolean expressions, and P programs. Notice that instead of, for example “array[i][j]” commonly used in programming languages to refer to an array element, we use the notation “array(i,j)” more com-monly used in mathematics and logic.As one can see, programs here are constructed using assignments, sequences, if-then-else, and while loops. Other con-structs such as if-then and for-loop can be defined using these constructs. For instance, “if B then P” can be defined as “if B then P else X = X”.We assume a base first-order language L that contains functions and predicates that are static in the sense that their semantics are fixed and cannot be changed by programs. They include functions that correspond to operator, predicates \f4F. Lin / Artificial Intelligence 235 (2016) 1–25that correspond to boolean-op, and possibly other functions and predicates for formalizing the domain knowledge. In the following, we call L the base language.Given a program P , we extend the base language L by functions to represent program variables in the program. These functions are dynamic in that their values may be changed during the execution of a program. We assume that program variables are new, not already used in L. We also assume that there is no overloading so that two different program variables cannot have the same name but different arities. Thus we can use the same program variables as functions in our first-order language. Specifically, if V is a program variable for an n-ary array, then we add V and Vas new n-ary (cid:2)(x1, ..., xn) denote the values of the (x1, ..., xn)th cell in V at the input and the output, functions to L: V (x1, ..., xn) and Vrespectively, of the program P . For their values during the execution of P , we’ll introduce temporary function",
            {
                "entities": [
                    [
                        2833,
                        2861,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 182–183 (2012) 32–57Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExploiting symmetries for single- and multi-agent Partially ObservableStochastic DomainsByung Kon Kang, Kee-Eung Kim∗Department of Computer Science, KAIST, 373-1 Guseong-dong, Yuseong-gu, Daejeon 305-701, Republic of Koreaa r t i c l ei n f oa b s t r a c tArticle history:Received 29 January 2010Received in revised form 26 January 2012Accepted 26 January 2012Available online 30 January 2012Keywords:POMDPPOSGSymmetryGraph automorphism1. IntroductionWhile Partially Observable Markov Decision Processes (POMDPs) and their multi-agentextension Partially Observable Stochastic Games (POSGs) provide a natural and systematicapproach to modeling sequential decision making problems under uncertainty,thecomputational complexity with which the solutions are computed is known to beprohibitively expensive.In this paper, we show how such high computational resource requirements can bealleviated through the use of symmetries present in the problem. The problem of findingthe symmetries can be cast as a graph automorphism (GA) problem on a graphicalrepresentation of the problem. We demonstrate how such symmetries can be exploited inorder to speed up the solution computation and provide computational complexity results.© 2012 Elsevier B.V. All rights reserved.Markov Decision Processes (MDPs) have been a classical mathematical framework for sequential decision making prob-lems, in which the agent must make action decisions based on environment states. The number of steps at which the agentcan make decisions can either be finite or infinite, leading to finite-horizon and infinite-horizon problems, respectively.However, although computationally tractable, MDPs have often been shown inadequate to successfully model the agent’snoisy perception of the environment state. In order to incorporate the uncertainty about the state perception inherent inthe agent, an extended formalism called Partially Observable MDPs (POMDPs) has emerged [12,34,31].POMDPs provide a model for single-agent sequential decision making under state uncertainty thus turning the decisionmaking problem into one of planning [12]. Different from MDPs, POMDPs do not provide the agent with full observabilityof the states. Instead, the agent must infer which state it is in based on the noisy observations. This results in defining aprobability distribution over the states, defined as a belief state, to represent the uncertainty of the states. With this singleextra assumption, the computational complexity of solving a POMDP problem jumps from P-complete (MDP) to PSPACE-complete even for finite-horizon POMDPs [23]. Solving infinite-horizon POMDPs is known to be undecidable [17].There has been a lot of work on alleviating this intractability by means of computing approximate solutions. One ofthe most well-known works that shows both practicality and theoretical guarantees is Point-Based Value Iteration (PBVI)by Pineau et al. [25]. PBVI proceeds by sampling reachable belief states according to various heuristics in order to avoidthe curse of dimensionality induced by the continuous nature of the belief states. The value backups are performed only onthose sampled belief states before collecting additional belief states. The main factor that determines the performance ofPBVI is the belief point selection heuristic. The heuristics used are intended to capture the reachability of the belief points,thereby avoiding unnecessary computation on unreachable beliefs. One popular heuristic used is the Greedy Error Reduction* Corresponding author. Tel.: +82 42 350 3536; fax: +82 42 350 3510.E-mail addresses: bkkang@ai.kaist.ac.kr (B.K. Kang), kekim@cs.kaist.ac.kr (K.-E. Kim).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.01.003\fB.K. Kang, K.-E. Kim / Artificial Intelligence 182–183 (2012) 32–5733heuristic, which samples belief points that result in the largest error bound. PBVI belongs to a class of algorithms calledpoint-based methods, because value computation is performed on a finite set of belief states, often called belief points.1Heuristic Search Value Iteration (HSVI) by Smith and Simmons [30] is another point-based method that approximatesthe value function via heuristic exploration of belief states. It maintains an upper- and a lower-bound for the true valuefunction, and decreases the bound gaps by recursively selecting belief states. The upper bound is initialized at the cornersof the belief simplex and is maintained as a point set. Update to this bound is performed by adding a new belief point,whose value is computed as a projection onto a convex hull formed by belief-value pairs. The lower bound is a vector set,meaning that the value is updated at the newly added belief, much like the updates performed in PBVI. The belief point tobe added is selected by a depth-first search from the initial belief.Another approach by which the intractability of the POMDP solution can be eased (in a practical manner) is to takeadvantage of the structural regularities present in POMDPs. One popular method uses the concept of homomorphism toreduce the state space itself, thereby forming an equivalent model with a potentially much smaller size. This technique,often called model minimization, has been extensively studied in the MDP domain, making use of stochastic bisimulation ofthe states. Informally, bisimilar states can be grouped together to form a smaller state space than the original MDP, yetthe optimal policies of the original and the reduced MDP are directly related with each other. The structural characteristicsthat allow for state grouping are reward equivalence and block transition equivalence. The former property states that thestates in a group should yield the same reward for any given action, and the latter that grouped states should have thesame transition probability into the group of original destination states. It is known that the optimal policy of the reducedMDP can be lifted to be converted into the optimal policy of the original MDP, hence model reduction results in lesscomputation [8,10].A different structural feature that is of interest to us is automorphism. An automorphism of a model is a homomorphismto itself. By finding the automorphisms, or symmetries, present in the model, one may expect to reduce possibly redundantcomputation performed on the symmetric portion of the solution space. It is this feature that we propose to use on POMDPsin order to reduce computational resources needed for computing optimal solutions. In particular, we are interested in thePOMDP symmetry that is not related to reducing the size of the model, but can nonetheless be exploited to speed upconventional point-based POMDP algorithms introduced above.The subject of symmetry in sequential decision making has not been carried out actively, with a few exceptions: Ravin-dran and Barto [26] were the first to extend the model minimization method to cover symmetries in MDPs. More recently,Narayanamurthy and Ravindran [20] constructively proved that the problem of finding symmetries in MDPs belongs to thecomplexity class graph isomorphism-complete (GI-complete). In this latter work, the authors use a graph-based encoding ofthe MDP to cast the problem of finding MDP symmetries to that of graph automorphism (GA). Our work is similar to this,in that we also reduce the problem to discovering GA, but provides a simpler and more intuitive approach along with apractical guide to applying symmetries to existing algorithms. We also extend the domain to multi-agent settings.Another work similar to ours is that of permutable POMDPs by Doshi and Roy [9]. This work was presented in thecontext of preference elicitation where the belief states have permutable state distribution. Similarly to the approach wepresent, this permutable POMDP framework is based on the idea that the value functions of certain classes of POMDPs arepermutable with respect to the state permutation. That is, the components of the value function can be permuted accordingto the permutation of their corresponding states while maintaining value invariance. While the overall idea is in league withour approach, there are two important differences. First, the permutable POMDP only considers a specific type of symmetrythat can be found in preference elicitation problems and models similar to them. More specifically, they show how certainpreference elicitation problems can be set up to exhibit symmetric properties. That is, they first provide certain conditionsa state permutation should satisfy and show how a preference elicitation POMDP can have its parameters set in order tosatisfy the stated conditions. As opposed to such setting, our research aims to provide an algorithmic framework with whichsymmetries can be discovered and exploited in general POMDP problems. Second, their symmetry definition requires thatthe equality condition hold for all n! permutations, where n is the number of states. This is a very strict condition, and istherefore suitable for only a very limited set of problems. On the other hand, our formulation relaxes this restriction byconsidering the state, action, and observation permutations in groups.Partially Observable Stochastic Games (POSGs) are a multi-agent extension to the POMDPs, where the actions and obser-vations now take a collective form of all agents. This change induces another leap in the complexity hierarchy: planning infinite-horizon Decentralized POMDPs (DEC-POMDPs), which is a special class of POSGs with common payoffs, is known tobe NEXP-complete [3]. Planning in infinite-horizon DEC-POMDP is again undecidable since DEC-POMDPs is a generalizationof POMDPs. Hansen et al. [11] give an exact algorithm for solving POSGs, by means of Multi-Agent Dynamic Programming(MADP). MADP performs dynamic programming backups over an e",
            {
                "entities": [
                    [
                        3887,
                        3915,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 945–954www.elsevier.com/locate/artintReachability analysis of uncertain systems using bounded-parameterMarkov decision processesDi Wu, Xenofon Koutsoukos ∗EECS Department, Vanderbilt University, Nashville, TN 37235, USAReceived 8 September 2006; received in revised form 8 December 2007; accepted 17 December 2007Available online 23 December 2007AbstractVerification of reachability properties for probabilistic systems is usually based on variants of Markov processes. Currentmethods assume an exact model of the dynamic behavior and are not suitable for realistic systems that operate in the presenceof uncertainty and variability. This research note extends existing methods for Bounded-parameter Markov Decision Processes(BMDPs) to solve the reachability problem. BMDPs are a generalization of MDPs that allows modeling uncertainty. Our resultsshow that interval value iteration converges in the case of an undiscounted reward criterion that is required to formulate the prob-lems of maximizing the probability of reaching a set of desirable states or minimizing the probability of reaching an unsafe set.Analysis of the computational complexity is also presented.© 2007 Elsevier B.V. All rights reserved.Keywords: Reachability analysis; Uncertain systems; Markov decision processes1. IntroductionVerification of reachability properties for probabilistic systems is usually based on variants of Markov processes.Probabilistic verification aims at establishing bounds on the probabilities of certain events. Typical problems includethe maximum and the minimum probability reachability problems, where the objective is to compute the controlpolicy that maximizes the probability of reaching a set of desirable states, or minimize the probability of reaching anunsafe set. Such problems are important in many application domains such as planning for autonomous systems [1],system biology [2], and finance [3].Algorithms for verification of MDPs have been presented in [4,5]. Several other probabilistic models based onvariants of MDPs also have been considered [6,7]. These methods assume exact values of the transition probabilitieswhich typically are computed either based on detailed models using discrete approximation techniques [8] or have tobe estimated from data [9]. However, realistic systems often operate in the presence of uncertainty and variability, andmodeling and estimation errors can affect the transition probabilities and impact the solution. Such systems can bebest described using uncertain transition probabilities. An uncertain MDP which describes the routing of an aircraftbased on past weather data is presented in [10]. Computing uncertain transition probabilities for a robot path-finding* Corresponding author.E-mail addresses: wudipku@gmail.com (D. Wu), xenofon.koutsoukos@vanderbilt.edu (X. Koutsoukos).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.12.002\f946D. Wu, X. Koutsoukos / Artificial Intelligence 172 (2008) 945–954example based on a model of the continuous dynamics is described in [11]. Existing reachability analysis methods areinsufficient for dealing with such uncertainty.This research note extends existing methods for Bounded-parameter Markov Decision Processes (BMDPs) to solvethe reachability problem. Proposed by Givan, Leach and Dean [12], BMDPs are a generalization of MDPs that allowsmodeling uncertainty. A BMDP can be viewed as a set of exact MDPs (sharing the same state and action space)specified by intervals of transition probabilities and rewards and policies are compared on the basis of interval valuefunctions. An overview of BMDPs is presented in Section 2.The paper focuses on the problem of maximizing the probability of reaching a set of desirable states. The resultspresented in [12] are for dynamic programming methods assuming a discounted reward criterion. A discount factorensures the convergence of the iterative methods for the interval value functions. Probabilistic verification can beformulated based on the Expected Total Reward Criterion (ETRC) [13]. Under ETRC, the discount factor is set to 1,and the convergence of the iterative algorithms for BMDPs is more involved because the contraction property ofthe iteration operators does not hold globally and the interval value function may not be well defined unless properrestrictions on the intervals of transition probabilities and rewards are applied. The interval expected total reward forBMDPs is analyzed in Section 3. Further, proving the polynomial computational complexity of the algorithm requiresa different method using an appropriate weighted norm. Based on the ETRC, this paper presents a detailed analysis ofthe convergence and the computational complexity for the maximum probability reachability problem in Sections 4and 5 respectively. Minimum probability reachability and other problems based on the ETRC [13] can be addressedin a similar fashion. A simplified robot path-finding example and numerical results that illustrate the approach can befound in [11].Optimal solutions to several variants of uncertain MDP problems have been studied previously. MDPs with uncer-tain transition probabilities and a discounted reward criterion have been considered in [14,15]. Related methods thatconsider a discounted reward include the work in [16] which computes the optimal policy in models with compactconvex uncertain sets, the approach in [17] which computes the Pareto optimal policy which maximizes the averageexpected reward over all stationary policies under a specific partial order, and the work in [10] which solves a robustcontrol problem. The average reward problem for BMDPs has been studied in [18] and a similar average performancecriterion has been considered in [19]. An algorithm based on real-time dynamic programming for uncertain stochasticshortest path problems is presented in [20]. The algorithm requires that a goal state is reachable from any visited stateand proposes a reachability analysis pre-processing step which is based on graph analysis. Probabilistic reachabilityanalysis of uncertain MDPs is a significant problem which requires an undiscounted reward criterion and cannot betreated with these algorithms.Probabilistic verification of uncertain systems has been addressed also using model checking methods. A variantof uncertain MDPs has been presented in [21,22]. The main characteristic of the model is that uncertainty is resolvedthrough nondeterminism, i.e. at every step an adversary picks a probability distribution that satisfies the uncertaintransition probabilities. This differs from BMDPs where the transition probabilities are uncertain for a given actionselected by an external agent. The approach presented in [21] computes the probability distribution over the statesfor finite number of steps while the algorithms in [22] reduce the uncertain system to an MDP of a larger size forverifying a subset of probabilistic computation tree logic specifications without steady state operators.2. Bounded-parameter Markov decision processesWe first review some basic notions of BMDPs from [12] and establish the notation. A BMDP is defined as M =(cid:3)Q, A, ˆF , ˆR(cid:4) where Q is a set of states, A is a set of actions, ˆR is an interval reward function that maps each q ∈ Qto a closed interval of real values [R(q), R(q)], and ˆF is an interval state-transition distribution so that for p, q ∈ Qand α ∈ A,F p,q (α) (cid:2) Pr(Xt+1 = q|Xt = p, Ut = α) (cid:2) F p,q (α).For any action α and state p, the sum of the lower bounds of ˆFp,q (α) over all states q is required to be less than orequal to 1, while the sum of the upper bounds is required to be greater than or equal to 1.A BMDP M defines a set of exact MDPs. Let M = (cid:3)QM , AM , F M , RM (cid:4) be an MDP. If QM = Q, AM = A,RM (p) ∈ ˆR(p), and F Mp,q (α) ∈ ˆFp,q (α) for any α ∈ A and p, q ∈ Q, then we say M ∈ M. To simplify the presenta-tion, the rewards are assumed to be tight, however, the results can be easily generalized to the case of interval rewards.\fD. Wu, X. Koutsoukos / Artificial Intelligence 172 (2008) 945–954947Policies are defined as π : Q → A and are restricted into the set of stationary Markov policies Π . Let V denote theset of value functions on Q. For an exact MDP M, policy π , and discount factor γ ∈ (0, 1), the value function is thesolution of the equationVM,π (p) = R(p) + γ(cid:4)(cid:3)VM,π (q)π(p)F Mp,q(cid:2)q∈Qand can be computed by iteratively applying the policy evaluation operator denoted as VIM,π : V → V. For any policyπ and state p, the interval value function of the BMDP M for π at p is the closed interval(cid:5)ˆVπ (p) =infM∈MVM,π (p), supM∈M(cid:6).VM,π (p)(1)An MDP M ∈ M is π -maximizing if for any M (cid:7) ∈ M, VM,π (cid:3)dom VM (cid:7),π1 and likewise, M is π -minimizing iffor any M (cid:7) ∈ M, VM,π (cid:2)dom VM (cid:7),π . It is proved in [12] (Theorem 7 and Corollary 1) that for any policy π ∈ Π andany ordering of the states Q, there exist a π -maximizing MDP M(π) and a π -minimizing MDP M(π). This impliesthat for input V (or V ) there exists a single MDP independent of V (or V ) which simultaneously maximizes (orminimizes) VM,π (p) for all states p ∈ Q. Therefore, we can define the interval policy evaluation operator (cid:7)IVIπ as(cid:7)IVIπ ( ˆV )(p) =where(cid:6)(cid:5)IVIπ (V )(p), IVIπ (V )(p)IVIπ (V ) = minM∈MVIM,π (V ) = VIM(π),π (V )and IVIπ (V ) = maxM∈MVIM,π (V ) = VIM(π),π (V ).In order to define the optimal value function for a BMDP, two different orderings on closed real intervals areintroduced: [l1, u1] (cid:2)opt [l2, u2] ⇐⇒ (u1 < u2 ∨ (u1 = u2 ∧ l1 (cid:2) l2)) and [l1, u1] (cid:2)pes [l2, u2] ⇐⇒ (l1 < l2 ∨ (l1 =l2 ∧ u1 (cid:2) u2)). In addition, ˆU (cid:2)optˆV (q)) for each q ∈ Q.Then the optimistic optimal value function ˆVopt and the pessimistic optimal value function ˆVpes are defined as theupper bounds over all stationary policies using (cid:2)opt an",
            {
                "entities": [
                    [
                        2947,
                        2975,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 203 (2013) 19–34Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComplexity issues related to propagation completenessMartin Babka, Tomáš Balyo, Ondˇrej ˇCepek, Štefan Gurský, Petr KuˇceraVáclav Vlˇcek∗,Department of Theoretical Computer Science and Mathematical Logic, Faculty of Mathematics and Physics, Charles University in Prague,Malostranské nám. 25, 118 00 Praha 1, Czech Republica r t i c l ei n f oa b s t r a c tArticle history:Received 10 July 2012Received in revised form 14 June 2013Accepted 30 July 2013Available online 7 August 2013Keywords:Boolean functionsSatisfiabilityKnowledge compilationEmpowering implicatesUnit propagationPropagation completenessKnowledge compilation is a process of adding more information to a knowledge base inorder to make it easier to deduce facts from the compiled base than from the original one.One type of knowledge compilation occurs when the knowledge in question is representedby a Boolean formula in conjunctive normal form (CNF). The goal of knowledge compilationin this case is to add clauses to the input CNF until a logically equivalent propagationcomplete CNF is obtained. A CNF is called propagation complete if after any partialsubstitution of truth values all logically entailed literals can be inferred from the resultingCNF formula by unit propagation. The key to this type of knowledge compilation is theability to generate so-called empowering clauses. A clause is empowering for a CNF if it isan implicate and for some partial substitution of truth values it enlarges the set of entailedliterals inferable by unit propagation.In this paper we study several complexity issues related to empowering implicates,propagation completeness, and its relation to resolution proofs. We show several results:(a) given a CNF and a clause it is co-NP complete to decide whether the clause is anempowering implicate of the CNF, (b) given a CNF it is NP-complete to decide whetherthere exists an empowering implicate for it and thus it is co-NP complete to decidewhether a CNF is propagation complete, and (c) there exist CNFs to which an exponentialnumber of clauses must be added to make them propagation complete.© 2013 Published by Elsevier B.V.1. IntroductionOne of the most studied problems in computer science, both theoretical and applied, is the satisfiability problem for CNFformulas (SAT). The difficulty of SAT depends on the class of CNF formulas to which the input formula belongs. There arevarious techniques and algorithms for SAT for different classes of CNF formulas ranging from linear algorithms for Horn,quadratic (2-CNF) and SLUR formulas [1,2] to the very complex variants of the exponential DPLL [3,4] and CDCL [5–8]procedures implemented in general purpose SAT solvers. Even the most complicated SAT solvers usually perform a taskcalled unit propagation [3]. The goal of unit propagation is to infer as many logically entailed literals as possible from apartial truth assignment and the input formula. Although in general unit propagation is not a complete method (it does notinfer all logically entailed literals), it is complete for the class of propagation complete (PC) CNF formulas [9].PC formulas play an important role also in constraint programming, or more specifically, in CNF encodings of globalconstraints. There is a strong connection between propagation completeness of the CNF encoding and domain consistency* Corresponding author. Tel.: +420 221 914 138; fax: +420 221 914 323.E-mail addresses: babkys@gmail.com (M. Babka), biotomas@gmail.com (T. Balyo), ondrej.cepek@mff.cuni.cz (O. ˇCepek), stevko@mail.ru (Š. Gurský),kucerap@ktiml.mff.cuni.cz (P. Kuˇcera), vlcek@ktiml.mff.cuni.cz (V. Vlˇcek).0004-3702/$ – see front matter © 2013 Published by Elsevier B.V.http://dx.doi.org/10.1016/j.artint.2013.07.006\f20M. Babka et al. / Artificial Intelligence 203 (2013) 19–34of the encoded constraint [10,11]. It has been studied for several concrete global constraints such as the AllDifferentconstraint [12], the Sequence constraint [13], Regular, Among, and Generalized Sequence [10], or theGrammar con-straints [14].Some SAT solvers try to avoid searching in the state subspaces with no solution by learning from conflicts, i.e. byperforming conflict driven clause learning (CDCL) [5–8], the name CDCL is also used for the complete algorithm solving SATproblem. It is useful to learn clauses (called empowering implicates [9,15]) that allow unit propagation to infer more logicallyentailed literals after such a clause is added to the CNF formula than it was possible to infer before the addition. Therefore,to speed up the CDCL SAT solver search for a satisfying assignment, it is often very useful to learn (generate) empoweringimplicates and add them to the input CNF formula. Let us mention that today’s most successful SAT solvers for real-worldapplications are the ones using CDCL procedure.This process of adding empowering implicates to a CNF formula can be viewed as a special type of knowledge com-pilation where both the input and the output representation of the knowledge is a CNF formula. In general, knowledgecompilation is a process of adding more information to a given knowledge representation in order to make it computa-tionally easier to infer facts from the compiled representation [16,17], or a process of transforming a given knowledgerepresentation into another knowledge representation which is more tractable with respect to fact deduction, such as trans-forming a CNF into a BDD [18]. Nevertheless, in this paper we are interested only in the very limited case of knowledgecompilation that rests in adding empowering implicates to a CNF.It has been shown in [9], along with other properties of PC formulas, that a formula ϕ is PC if and only if there isno empowering implicate for ϕ. However, several complexity issues directly connected to propagation completeness andempowering implicates are left open in [9]. A short list of such questions is the following:1. Given a CNF formula ϕ and a clause C , what is the complexity of deciding whether C is an empowering implicatefor ϕ?2. Given a CNF formula ϕ that is not PC, how difficult is it to generate an empowering implicate for ϕ by resolution,where the “level of difficulty” is measured by the length of the resolution proof?3. Given a CNF formula ϕ, what is the complexity of deciding whether there exists an empowering implicate for ϕ?4. Given a CNF formula ϕ that is not PC, how many empowering implicates is it necessary to add to ϕ in order to makeit PC?In this paper we tackle all of the above listed problems. After reviewing basic definitions and notation in Section 2, wederive several simple properties of empowering implicates in Section 3. We address the following four questions as follows:1. In Section 3 we show that the first problem is co-NP complete. This is not a very difficult result, however, to the bestof our knowledge, it was not stated in the related literature yet.2. In Section 4 we tackle the second problem. We prove that for a non-PC CNF formula with s occurrences of literalsthere always exists a resolution proof of length O (s) of some empowering implicate. On the other hand, we constructexamples of CNF formulas where a resolution proof of length Ω(s) is needed for any empowering implicate, whichmeans that Θ(s) is an asymptotically tight bound for this problem. It is important to note that the upper boundresult does not require the derived empowering implicate to be prime. We show (by a simple modification of resultsconcerning refutation proofs [19,20]) that there exist CNF formulas such that in order to derive any prime empoweringimplicate of such CNF a resolution proof of an exponential length is needed.3. Section 5 contains the main results of this paper which are connected to the third problem. It was proved in [9] thatdeciding about an existence of an empowering implicate is in (cid:5) p2 . Using the results from Section 4 we strengthen thisresult by showing that the problem belongs to (cid:5) p= NP. Given the equivalence between propagation completeness and1non-existence of empowering implicates proved in [9], this immediately implies that testing propagation completenessbelongs to co-NP. Then we proceed with the hardness proof for this problem. We present a reduction from a well-knownNP-complete 3-dimensional matching problem which proves that deciding for a CNF formula whether there exists anempowering implicate for it is NP-hard (and thus testing propagation completeness is coNP-hard).4. The fourth question is answered in Section 5 as well by showing that there exist CNF formulas where an exponentialnumber (both with respect to the number of variables and the number of clauses) of empowering implicates must beadded in order to arrive at a PC formula. This strengthens the superpolynomial bound which follows from a combinationof results in [9] and [21] using a superpolynomial lower bound for certain monotone circuits from [22]. The connectionis discussed in detail in Section 2.5.We close the paper by giving few concluding remarks in Section 6.\fM. Babka et al. / Artificial Intelligence 203 (2013) 19–34212. Definitions2.1. Basic definitionsA Boolean function of n variables is a mapping f : {0, 1}n → {0, 1}. We say that a Boolean function fis satisfiable if thereis a vector (cid:4)x ∈ {0, 1}n such that f ((cid:4)x) = 1. A literal is either a variable (x, called positive literal) or its negation (¬x or x, callednegative literal). A clause is a disjunction of literals. We assume that no clause contains both positive and negative literalsof the same variable. A clause which contains just one literal is called a unit clause. Formula ϕ is in conjunctive normal form(CNF) if it is a conjunction of clauses (we also say that ϕ is a CNF formula). We shall often treat a clause as a set of itsliterals and a CNF formula as a set of its clauses. It is a well-known fact that every Bo",
            {
                "entities": [
                    [
                        3839,
                        3867,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 714–738www.elsevier.com/locate/artintCut-and-solve: An iterative search strategy for combinatorialoptimization problemsSharlee Climer ∗, Weixiong ZhangDepartment of Computer Science and Engineering, Washington University, One Brookings Drive, St. Louis, MO 63130-4899, USAReceived 26 August 2005; received in revised form 13 February 2006; accepted 23 February 2006Available online 17 April 2006AbstractBranch-and-bound and branch-and-cut use search trees to identify optimal solutions to combinatorial optimization problems.In this paper, we introduce an iterative search strategy which we refer to as cut-and-solve and prove optimality and terminationfor this method. This search is different from traditional tree search as there is no branching. At each node in the search path, arelaxed problem and a sparse problem are solved and a constraint is added to the relaxed problem. The sparse problems provideincumbent solutions. When the constraining of the relaxed problem becomes tight enough, its solution value becomes no betterthan the incumbent solution value. At this point, the incumbent solution is declared to be optimal. This strategy is easily adaptedto be an anytime algorithm as an incumbent solution is found at the root node and continuously updated during the search.Cut-and-solve enjoys two favorable properties. Since there is no branching, there are no “wrong” subtrees in which the searchmay get lost. Furthermore, its memory requirement is negligible. For these reasons, it has potential for problems that are difficultto solve using depth-first or best-first search tree methods.In this paper, we demonstrate the cut-and-solve strategy by implementing a generic version of it for the Asymmetric TravelingSalesman Problem (ATSP). Our unoptimized implementation outperformed state-of-the-art solvers for five out of seven real-worldproblem classes of the ATSP. For four of these classes, cut-and-solve was able to solve larger (sometimes substantially larger)problems. Our code is available at our websites.© 2006 Published by Elsevier B.V.Keywords: Search strategies; Branch-and-bound; Branch-and-cut; Anytime algorithms; Linear programming; Traveling Salesman Problem1. IntroductionLife is full of optimization problems. We are constantly searching for ways to minimize cost, time, energy, or someother valuable resource, or maximize performance, profit, production, or some other desirable goal, while satisfyingthe constraints that are imposed on us. Optimization problems are interesting as there are frequently a very largenumber of feasible solutions that satisfy the constraints; the challenge lies in searching through this vast solutionspace and identifying an optimal solution. When the number of solutions is too large to explicitly look at each one,two search strategies, branch-and-bound [4] and branch-and-cut [28], have been found to be exceptionally useful.* Corresponding author.E-mail addresses: sharlee@climer.us (S. Climer), zhang@cse.wustl.edu (W. Zhang).0004-3702/$ – see front matter © 2006 Published by Elsevier B.V.doi:10.1016/j.artint.2006.02.005\fS. Climer, W. Zhang / Artificial Intelligence 170 (2006) 714–738715Branch-and-bound uses a search tree to pinpoint an optimal solution. (Note there may be more than one optimalsolution.) If the entire tree were generated, every feasible solution would be represented by at least one leaf node. Thesearch tree is traversed and a relaxed variation of the original problem is solved at each node. When a solution to therelaxed subproblem is also a feasible solution to the original problem, it is made the incumbent solution. As othersolutions of this type are found, the incumbent is updated as needed so as to always retain the best feasible solutionfound thus far. When the search tree is exhausted, the current incumbent is returned as an optimal solution.If the number of solutions is too large to allow explicitly looking at each one, then the search tree is also too largeto be completely explored. The power of branch-and-bound comes from its pruning rules, which allow pruning ofentire subtrees while guaranteeing optimality. If the search tree is pruned to an adequately small size, the problem canbe solved to optimality.Branch-and-cut improves on branch-and-bound by increasing the probability of pruning. At some or all of thenodes, cutting planes [28] are added to tighten the relaxed subproblem. These cutting planes remove a set of solutionsfor the relaxed subproblem. However, in order to ensure optimality, these cutting planes are designed to never excludeany feasible solutions to the current unrelaxed subproblem.While adding cutting planes can substantially increase the amount of time spent at each node, these cuts candramatically reduce the size of the search tree and have been used to solve a great number of problems that werepreviously insoluble.Branch-and-bound and branch-and-cut are typically implemented in depth-first fashion due to its linear spacerequirement and other favorable features [49]. However, depth-first search can suffer from the problem of exploringsubtrees with no optimal solution, resulting in a large search cost. A wrong choice of a subtree to explore in an earlystage of a depth-first search is usually difficult to rectify. The Artificial Intelligence community has invested a greatdeal of effort in addressing this issue. Branching techniques [4], heuristics investigations [42], and search techniquessuch as limited discrepancy [24] and randomization and restarts [19] have been developed in an effort to combat thispersistent problem.In this paper, we introduce an iterative search strategy which overcomes the problem of making wrong choicesin depth-first branch-and-bound, while keeping memory requirements nominal. We refer to this search strategy ascut-and-solve and demonstrate it on integer linear programs. Being an iterative strategy, there is no search tree, onlya search path that is directly traversed. In other words, there is only one child for each node, so there is no need tochoose which child to traverse next. At each node in the search path, two relatively easy subproblems are solved.First, a relaxed solution is found. Then a sparse problem is solved. Instead of searching for an optimal solution inthe vast solution space containing every feasible solution, a very sparse solution space is searched. An incumbentsolution is found at the first node and updated as needed at subsequent nodes. When the search terminates, the currentincumbent solution is guaranteed to be an optimal solution. In this paper, we prove optimality and termination of thecut-and-solve strategy.The paper is organized as follows. In the next section, branch-and-bound and branch-and-cut are discussed ingreater detail. In the following section, the cut-and-solve strategy is described and compared with these prevalenttechniques. Next, we illustrate this strategy by applying it to a simple linear programming problem. Then a genericprocedure for using cut-and-solve is presented. This generic procedure is demonstrated by implementing an algorithmfor the Asymmetric Traveling Salesman Problem (ATSP). (The ATSP is the NP-hard problem of finding a minimum-cost Hamiltonian cycle for a set of cities in which the cost from city i to city j may not necessarily be equal to thecost from city j to city i.) We have tested a preliminary, unoptimized implementation of this algorithm and comparedit with branch-and-bound and branch-and-cut solvers. Our tests show that cut-and-solve is not always as fast as thesestate-of-the-art solvers for relatively simple problem instances. However, it is faster than these solvers on the largestinstances for five out of seven real-world problem classes, and solves larger (sometimes substantially larger) instancesfor four of these classes. This paper is concluded with a discussion of this technique and related work. A preliminaryversion of this paper appeared in [11].2. BackgroundIn this section, we define several terms and describe branch-and-bound and branch-and-cut in greater detail, usingthe Asymmetric Traveling Salesman Problem (ATSP) as an example.\f716S. Climer, W. Zhang / Artificial Intelligence 170 (2006) 714–738Branch-and-bound and branch-and-cut have been used to solve a variety of optimization problems. The method wepresent in this paper can be applied to any such problem. However, to make our discussion concrete, we will narrow ourfocus to integer linear programs (IPs). An IP is an optimization problem that is subject to a set of linear constraints. IPshave been used to model a wide variety of problems, including Traveling Salesman Problems (TSP) [22,36], ConstraintSatisfaction Problems (CSP) [15], and network optimization problems [45]. Moreover, a wealth of problems can becast as one of these more general problems. TSP applications include a vast number of scheduling, routing, andplanning problems such as the no-wait flowshop, stacker crane, tilted drilling machine, computer disk read head,robotic motion, and pay phone coin collection problems [30]. Furthermore, the TSP can be used to model surprisinglydiverse problems, such as the shortest common superstring problem, which is of interest in genetics research. CSPs areused to model configuration, design, diagnosis, spatio-temporal reasoning, resource allocation, graphical interfaces,and scheduling problems [15]. Finally, examples of network optimization problems include delay-tolerant networkrouting, cellular radio network base station locations, and the minimum-energy multicast problem in wireless ad hocnetworks. There exist interesting research problems that can be cast as IPs in virtually every field of computer science.Furthermore, there are a staggering number of commercial applications that can be cast as IPs.A general IP can be written in the following form:Z = min (or max)(cid:2)cixiisubject to:a set of linear constraintsxi ∈ I(1)(2)(3)where the ci values are instance",
            {
                "entities": [
                    [
                        3102,
                        3130,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1045–1063www.elsevier.com/locate/artintActive logic semantics for a single agent in a static worldMichael L. Anderson a,d,∗, Walid Gomaa b,e, John Grant b,c, Don Perlis a,ba Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USAb Department of Computer Science, University of Maryland, College Park, MD 20742, USAc Department of Mathematics, Towson University, Towson, MD 21252, USAd Department of Psychology, Franklin & Marshall College, Lancaster, PA 17604, USAe Department of Computer and Systems Engineering, Alexandria University, Alexandria, EgyptReceived 7 December 2006; received in revised form 14 November 2007; accepted 16 November 2007Available online 22 November 2007AbstractFor some time we have been developing, and have had significant practical success with, a time-sensitive, contradiction-tolerantlogical reasoning engine called the active logic machine (ALMA). The current paper details a semantics for a general version of theunderlying logical formalism, active logic. Central to active logic are special rules controlling the inheritance of beliefs in general(and of beliefs about the current time in particular), very tight controls on what can be derived from direct contradictions (P &¬P ),and mechanisms allowing an agent to represent and reason about its own beliefs and past reasoning. Furthermore, inspired by thenotion that until an agent notices that a set of beliefs is contradictory, that set seems consistent (and the agent therefore reasonswith it as if it were consistent), we introduce an “apperception function” that represents an agent’s limited awareness of its ownbeliefs, and serves to modify inconsistent belief sets so as to yield consistent sets. Using these ideas, we introduce a new definitionof logical consequence in the context of active logic, as well as a new definition of soundness such that, when reasoning withconsistent premises, all classically sound rules remain sound in our new sense. However, not everything that is classically soundremains sound in our sense, for by classical definitions, all rules with contradictory premises are vacuously sound, whereas in activelogic not everything follows from a contradiction.© 2007 Elsevier B.V. All rights reserved.Keywords: Logic; Active logic; Nonmonotonic logic; Paraconsistent logic; Semantics; Soundness; Brittleness; Autonomous agents; Time1. IntroductionReal agents have some important characteristics that we need to take into account when thinking about how theymight actually reason logically: (a) their reasoning takes time, meaning that agents always have only a limited, evolv-ing awareness of the consequences of their own beliefs,1 and (b) their knowledge is imperfect, meaning that someof their beliefs will need to be modified or retracted, and they will inevitably face direct contradictions and other in-* Corresponding author at: Department of Psychology, Franklin & Marshall College, P.O. Box 3003, Lancaster, PA 17604-3003, USA.E-mail addresses: michael.anderson@fandm.edu (M.L. Anderson), wgomaa@alex.edu.eg (W. Gomaa), jgrant@towson.edu (J. Grant),perlis@cs.umd.edu (D. Perlis).1 Levesque’s distinction between explicit and implicit beliefs [29] points to this same issue; however, our approach is precisely to model theevolving awareness itself, rather than trying to model the full set of (implicit) consequences of a given belief set.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.005\f1046M.L. Anderson et al. / Artificial Intelligence 172 (2008) 1045–1063consistencies. Indeed, real agents will not only often find their beliefs contradicted by experience, but will sometimesfind that their beliefs have been internally inconsistent for some time, although they are only now in a position tonotice this inconsistency, having derived a certain set of consequences that makes it apparent. The challenge from thestandpoint of classical logical formalisms is that, if an agent’s knowledge base can be inconsistent, then according toclassical logic, it is permissible to derive any formula from it.This fact about classical logics is commonly known by the Latin phrase ex contradictione quodlibet: from a con-tradiction everything follows. However, Graham Priest has coined the somewhat more vivid term explosive logics: alogic is explosive iff for all formulas A and B, (A&¬A) |= B. Priest defines a paraconsistent logic precisely as onewhich is not explosive [40–42]. Now, clearly real agents cannot tolerate the promiscuity of belief resulting from ex-plosive logics, and must somehow maintain control over their reasoning, watching for and dealing with contradictionsas they arise. The reasoning of real agents, that is, must be paraconsistent. But what sort of paraconsistent logic mightagents usefully employ, what methods might agents use to control inference and deal with contradictions, and howcan these logics (and methods) be modeled in terms of truth and consequence in structures?In the current paper we are primarily interested in the last of these questions. For some time we have been devel-oping, and have had significant practical success with a time-sensitive, contradiction-tolerant logical reasoning enginecalled the active logic machine (ALMA) [46]. Because ALMA was designed with the above challenges in mind,its underlying formalism, active logic [17,18,33,34], includes special rules controlling the inheritance of beliefs ingeneral (and of beliefs about the current time in particular), very tight controls on what can be derived from directcontradictions (P &¬P ), and mechanisms allowing an agent to represent and reason about its own beliefs and pastreasoning.Here we offer a semantics for a general version of active logic. We hope and expect it will be of interest as a specificmodel of formal reasoning for real-world agents that have to face both the relentlessness of time, and the inevitabilityof contradictions.In Sections 2–6 we will introduce the formal semantics for active logic, discuss a new definition of the conse-quence relation, and give examples of sound and unsound active logic inferences. This will be followed by some moreinformal discussion of the various properties of active logic (Section 7), a comparison of active logic with relatedapproaches (Section 8), and a discussion of the practical issues involved with the use of active logic in real-worldagents (Sections 9 and 10).2. A semantics for real-world reasoningIn this section we propose a semantics for a time-sensitive, contradiction-tolerant reasoning formalism, incorporat-ing the basic features of active logic.2.1. Starting assumptionsIn order to make the problem tractable for our first specification of the semantics, we will work under the followingassumptions concerning the agent, the world (i.e., everything apart from the agent), and their interactions:• There is only one agent a.• The agent starts its life at time t = 0 (t ∈ N) and runs indefinitely.• The world is stationary for t (cid:2) 0. Thus, changes occur only in the beliefs of the agent a.Given these assumptions, there is one and only one true complete theory of the world; however, given that theagent’s beliefs evolve over time, there is a different true complete theory of the agent for each time t.2.2. The language LIn order to express theories about such an agent-and-world, we define a sorted first-order language L. We defineit in two parts: the language Lw, a propositional language in which will be expressed facts about the world, and thelanguage La, a first-order language used to express facts about the agent, including the agent’s beliefs, for instance thatthe agent’s time is now t, that the agent believes P , or that the agent discovered a contradiction in its beliefs at a given\fM.L. Anderson et al. / Artificial Intelligence 172 (2008) 1045–10631047time. We write SnK to mean the set of sentences of any language K. We are using the complete set of connectives{¬, →} from which other connectives, such as ∧, and ∨, can be derived. We assume that double negations are removedfrom formulas. For the sentence symbols the subscripts are used to indicate different propositional sentences and, fora fixed subscript, the superscripts are used to indicate different apperceptions (see Section 4) of the agent of the sameproposition. The superscript 0 is used for the original sentence symbol (without superscript).Definition 1. Let Lw be a propositional language consisting of the following symbols:• a set S of sentence symbols (propositional or sentential variables) S = {Sji : i, j ∈ N} (N is the set of naturalnumbers)• the propositional connectives ¬ and →• left and right parentheses ( and )SnLw is the set of sentences of Lw formed in the usual way. These represent the propositional beliefs of the agent1 might mean “John is happy”. For later use we assume there is a fixed lexicographicabout the world. For instance S0ordering for the sentences in SnLw .Definition 2. Let σ, θ ∈ SnLw . We say that {σ, θ } is a direct contradiction if one of the following holds: either θ is theformula σ preceded by a negation, or σ is the formula θ preceded by a negation, that is θ = ¬σ or σ = ¬θ .Before giving the definition of the language La, we remark the following:i. In its current version La is a restricted form of first-order logic that is essentially propositional. In future work weintend to extend it to the full power of first-order logic.ii. La contains a belief predicate that captures the fact that the agent believed a certain proposition at some time t.We allow for sentences of the form: at time s the agent believed that she believed that she . . . . To allow for thisindefinite (however finite) nesting, the definition of La has to be inductive where at stage n + 1 all sentences fromthe previous levels are captured for the belief predicate.Definition 3. The language La is a sorted restricted version of first-order logic hav",
            {
                "entities": [
                    [
                        3516,
                        3544,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 570–584Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGeneralizing constraint satisfaction on trees: Hybrid tractability andvariable eliminationMartin C. Cooper a, Peter G. Jeavons b,∗, András Z. Salamon b,ca IRIT, University of Toulouse III, 31062 Toulouse, Franceb Computing Laboratory, University of Oxford, Oxford, OX1 3QD, UKc Oxford-Man Institute of Quantitative Finance, 9 Alfred Street, Oxford, OX1 4EH, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 17 August 2009Received in revised form 13 February 2010Accepted 24 March 2010Available online 27 March 2010Keywords:Constraint satisfactionTractabilityComputational complexityArc consistencyVariable orderingVariable eliminationis a central generic problem in artificialThe Constraint Satisfaction Problem (CSP)intelligence. Considerable progress has been made in identifying properties which ensuretractability in such problems, such as the property of being tree-structured. In this paperwe introduce the broken-triangle property, which allows us to define a novel tractableclass for this problem which significantly generalizes the class of problems with treestructure. We show that the broken-triangle property is conservative (i.e., it is preservedunder domain reduction and hence under arc consistency operations) and that there is apolynomial-time algorithm to determine an ordering of the variables for which the broken-triangle property holds (or to determine that no such ordering exists). We also presenta non-conservative extension of the broken-triangle property which is also sufficient toensure tractability and can also be detected in polynomial time.We show that both the broken-triangle property and its extension can be used to eliminatevariables, and that both of these properties provide the basis for preprocessing proceduresthat yield unique closures orthogonal to value elimination by enforcement of consistency.Finally, we also discuss the possibility of using the broken-triangle property in variable-ordering heuristics.© 2010 Elsevier B.V. All rights reserved.1. IntroductionThe Constraint Satisfaction Problem (CSP) is a central generic problem in artificial intelligence where each instanceconsists of a collection of variables which must be assigned values subject to specified constraints. Each CSP instance hasan underlying undirected graph, known as its constraint network, whose nodes are the variables of the instance, and whoseedges connect precisely those pairs of variables which are related by some specified constraint. Such a graph is sometimescalled the structure of the instance.There is a well-known efficient algorithm for solving any CSP instance whose underlying constraint network is a tree[1,2]. If establishing arc consistency leads to a domain wipe-out, then no solution exists; otherwise a solution exists and canbe found by a backtrack-free search if the variables are ordered from any designated root to the leaves.However, having tree structure is a very restrictive property. It is therefore worthwhile exploring more general problemclasses, to identify more widely-applicable properties which still allow efficient solution algorithms. Any subclass of thegeneral CSP which can be solved in polynomial time, and also can be identified in polynomial time, is called a tractablesubclass.* Corresponding author.E-mail addresses: cooper@irit.fr (M.C. Cooper), Peter.Jeavons@comlab.ox.ac.uk (P.G. Jeavons), Andras.Salamon@comlab.ox.ac.uk (A.Z. Salamon).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.03.002\fM.C. Cooper et al. / Artificial Intelligence 174 (2010) 570–584571There has been a considerable research effort in identifying tractable subclasses of the CSP over the past two decades.Most of this work has focused on one of two general approaches: either identifying forms of constraint which are sufficientlyrestrictive to ensure tractability no matter how they are combined [3,4], or else identifying structural properties of constraintnetworks which ensure tractability no matter what forms of constraint are imposed [2,5].The first approach has had considerable success in characterizing precisely which forms of constraint ensure tractabilityno matter how they are combined. A set of constraint types with this property is called a tractable constraint language. Ingeneral it has been shown that any tractable constraint language must have certain kinds of algebraic properties knownas polymorphisms [6]. A complete characterization of all possible tractable constraint languages has been established inthe following cases: conservative constraint languages (i.e., constraint languages containing all unary constraints) [7], andconstraint languages over a 2-element domain [8] or a 3-element domain [9].The second approach has also had considerable success in characterizing precisely which structures of constraint net-works ensure tractability no matter what constraints are imposed. For the class of problems where the arity of theconstraints is bounded above by some fixed constant (such as binary constraint problems) it has been shown that (subject tocertain technical assumptions) the only class of structures which ensure tractability are structures of bounded tree-width [10–12]. This result significantly extends the class of tree-structured CSPs while retaining tractability.In practice, constraint satisfaction problems usually do not possess a sufficiently restricted structure or use a sufficientlyrestricted constraint language to fall into any of these tractable classes. They may still have properties which ensure theycan be solved efficiently, but these properties concern both the structure of the constraint network and the form of theconstraints. Such properties have sometimes been called hybrid reasons for tractability [13–16], and they are less widely-studied and much less well-understood than the language properties and structural properties described above.A classical approach to tractability of CSPs is to identify conditions on the class of CSP instances that can be used toconstruct an ordering of variables which allows the instance to be solved efficiently. Freuder introduced a condition thatallows a variable ordering to be found in polynomial time, such that this variable ordering provides a backtrack-free searchprocedure [1]. The condition amounts to requiring that a level of consistency has been enforced that is at least as great as ameasure he called the width of the constraint graph. More generally, the amount of backtracking can be bounded in termsof the relationship between the level of consistency and the width of the constraint graph [17]. We note that Freuder’snotion of width is equivalent to the notion of tree-width which is now widely used in graph theory [18].The basic property described in this paper, which we call the Broken-Triangle Property (BTP), is a polynomial-time de-tectable property which defines a novel hybrid tractable class of binary CSP instances. The BTP can be viewed as forbiddingthe occurrence of certain subproblems of a fixed size within a CSP instance. A number of other properties of subproblemsof bounded size that guarantee tractability have previously been identified in the literature [19,20], but the BTP is unusualin that it also incorporates variable ordering information.The class of CSP instances that have the BTP with respect to some ordering is tractable: for all such instances thereis a polynomial-time procedure to determine a variable ordering which guarantees backtrack-free search. Our class is notcontained in the classes considered by Freuder, as we do not require a fixed relationship between tree-width and consistency[1,17]. We show that all tree-structured CSP instances satisfy the BTP, as well as many other instances that are not tree-structured (including some with unbounded tree-width).We also show that the BTP, and certain generalizations, can be used to define a variable-elimination strategy which canbe applied to any binary CSP. Even when no variables can be eliminated by this strategy, we show that it can still providea basis for a new form of variable-ordering heuristic. For example, if the BTP is satisfied on a subset S of the variables,then these variables should be placed at the end of the variable ordering. This guarantees that a search algorithm whichmaintains arc consistency during search will not backtrack on the variables in S.The paper is structured as follows. Sections 2 and 3 introduce the broken-triangle property and prove the tractabilityof binary CSP instances satisfying the BTP even in the case when the variable ordering is unknown a priori. Section 4shows that the BTP defines a tractable class that properly includes several other known tractable classes. Section 5 gives analternative characterization of instances which have the BTP, while Section 6 defines a non-conservative generalization ofthe BTP. Variable elimination by means of the BTP and its extension are discussed in Sections 7 and 8. Finally, in Section 9we discuss the possible use of the BTP in variable-ordering heuristics and prove the intractability of finding a maximumsubset of the variables on which a CSP instance has the BTP.2. The broken-triangle propertyIn this paper we focus on binary constraint satisfaction problems. A binary relation over domains D i and D j is a subsetof D i × D j . For a binary relation R, the reverse relation rev(R) is defined as {(v, u) | (u, v) ∈ R}.A binary CSP instance consists of a set of variables (where each variable is denoted by a number i ∈ {1, . . . , n}); for eachvariable i, a domain D i containing possible values for variable i; and a set of constraints. Each constraint is of the form(cid:4)(i, j), R(cid:5), where i and j are variables, the pair (i, j) is called the scope of the constraint, and R is a relation such thatR ⊆ D i × D j , specifying the ",
            {
                "entities": [
                    [
                        3636,
                        3664,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 202 (2013) 29–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the conditional independence implication problem:A lattice-theoretic approachMathias Niepert a,∗, Marc Gyssens b, Bassem Sayrafi c, Dirk Van Gucht da Computer Science & Engineering, University of Washington, 185 Stevens Way, Seattle, WA 98195-2350, USAb School for Information Technology, Hasselt University and Transnational University of Limburg, Martelarenlaan 42, B-3500 Hasselt, Belgiumc Computer Science Department, Birzeit University, PO Box 14, Birzeit, West Bank, Palestined Computer Science Department, Indiana University, Lindley Hall 215, 150 S. Woodlawn Ave., Bloomington, IN 47405-7104, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 4 July 2011Received in revised form 4 June 2013Accepted 19 June 2013Available online 28 June 2013Keywords:Conditional independenceProbability and lattice theoryConditional independence is a crucial notion in the development of probabilistic systemswhich are successfully employed in areas such as computer vision, computational biology,and natural language processing. We introduce a lattice-theoretic framework that permitsthe study of the conditional independence (CI) implication problem relative to the class ofdiscrete probability measures. Semi-lattices are associated with CI statements and a finite,sound and complete inference system relative to semi-lattice inclusions is presented. Thissystem is shown to be (1) sound and complete for inferring general from saturated CIstatements and (2) complete for inferring general from general CI statements. We alsoshow that the general probabilistic CI implication problem can be reduced to that forelementary CI statements. The completeness of the inference system together with itslattice-theoretic characterization yields a criterion we can use to falsify instances of theprobabilistic CI implication problem as well as several heuristics that approximate thisfalsification criterion in polynomial time. We also propose a validation criterion based onrepresenting constraints and sets of constraints as sparse 0–1 vectors which encode theirsemi-lattices. The validation algorithm works by finding solutions to a linear programmingproblem involving these vectors and matrices. We provide experimental results for thisalgorithm and show that it is more efficient than related approaches.© 2013 Elsevier B.V. All rights reserved.1. IntroductionConditional independence is an important concept in artificial intelligence and machine learning. It plays a fundamen-tal role in working with probabilistic systems successfully employed in areas such as computer vision, speech recognition,computational biology, and robotics. Numerous real-world systems can be modeled by a probability distribution over aset of random variables. Unfortunately, reasoning over the full joint probability distribution is intractable for all but thesmallest number of cases. It is the very notion of conditional independence that facilitates the decomposition of joint proba-bility distributions into smaller parts which are then processed in sophisticated ways to compute a-posteriori probabilities.Bayesian and Markov networks are among the most commonly used probabilistic graphical models leveraging conditional in-dependencies to answer probabilistic queries and to learn probabilistic parameters more efficiently [1]. A deeper theoretical* Corresponding author.E-mail addresses: mniepert@cs.washington.edu (M. Niepert), marc.gyssens@uhasselt.be (M. Gyssens), bassem.sayrafi@gmail.com (B. Sayrafi),vgucht@cs.indiana.edu (D. Van Gucht).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.06.005\f30M. Niepert et al. / Artificial Intelligence 202 (2013) 29–51investigation of the mathematical and algorithmic properties of conditional independence is therefore central to the under-standing of probabilistic models [2,3].A deep theoretical understanding of conditional independence and the way it is leveraged in probabilistic graphical mod-els, however, also allows us to understand the shortcomings of said models. Indeed, not every joint probability distributioncan be decomposed according to a graphical structure without loss of information [4,5]. Finding ways of assessing the suit-ability of graphical models for the representation of a given distribution is therefore crucial. In particular, Studený [6] hasbrought this issue to the forefront, leading to an impressive body of work on algebraic representations of conditional inde-pendence structures, providing deep links to algebraic geometry [6,7], supermodular functions on sets, and novel algorithmsfor reasoning with conditional independencies [8,9].More motivation for this research is provided by the problem of knowledge elicitation in the field of reasoning under un-certainty [10,11]. Consider the problem of eliciting knowledge from several domain experts to model a probabilistic system.The resulting incomplete expert feedback might be a combination of some specific subjective probabilities, (conditional)independency and dependency information for the random variables under consideration, and conditional probabilities. Sta-tistical tests on different heterogeneous data sets may provide additional sources of evidence. Each piece of informationcan be interpreted as a constraint on the joint probability distribution to be modeled, and finding a suitable model as aconstraint satisfaction problem (CSP), and the approach to harness CSP solvers for instances of this and related problems iswell-known [12,13]. However, (conditional) independence and dependence statements pose a special problem, because theyoften introduce non-linear constraints resulting in unfeasible CSP instances. Therefore, a remaining challenge is to test forconsistency of the (conditional) independence and dependence information collected from different sources, which requiresan algorithm deciding the implication problem for CI statements [14].A central notion in the realm of reasoning about conditional independence is, therefore, the probabilistic conditionalindependence implication problem, that is, to decide whether a set of CI statements implies a single CI statement relative tosome class of discrete probability measures. While it remains open whether the implication problem for the class of alldiscrete probability measures is decidable, it is known that there exists no finite, sound and complete inference system [15].However, there exist finite sound inference systems that have attracted special interest. The most prominent one is thesemi-graphoid axiom system (Pearl [3]), which we refer to as System G in the present paper. One of the main contributionsof this work is to extend the semi-graphoids to a finite inference system which we refer to as System A which, althoughnot sound, is complete for the general probabilistic implication problem. In the way that the semi-graphoid inference rulesprovide a lower bound on what can be inferred, System A provides an upper bound. We demonstrate that, in the generalcase where the number of variables is not fixed and where no finite axiomatization exists, considering both lower and upperbounds provides deep insights into the implication problem and allows us to develop a novel algorithm for both validatingand rejecting implication problem instances.The techniques we use to obtain these results are made possible through the introduction of a lattice-theoretic framework.We associate semi-lattices of sets of variables with CI statements. Derivability of a single CI statement from a set of CI state-ments in System A is then characterized by the inclusion of the semi-lattice of the former in the union of the semi-latticesof the latter. We also use this framework to show that derivability in System A in the context of arbitrary CI statementscan be reduced to derivability in the context of elementary CI statements, that is, CI statements that express independencebetween two single variables given a third set of variables. This result has important ramifications from a practical point ofview because the use of elementary CI statements allows for a canonical representation of CI statements. We then introducethe additive implication problem for CI statements relative to certain classes of real-valued functions and specify propertiesof these classes that guarantee either soundness or completeness of A . Through the concept of multi-information functionsinduced by probability measures [6], we finally link the additive implication problem for this class of functions to themultiplication-based probabilistic CI implication problem. This allows us to show, for instance, that System A is sound andcomplete for the inference of arbitrary CI statements from sets of saturated CI statements relative to both the class of allbinary probability measures and the class of all discrete probability measures. Saturated CI statements by definition involveall variables under consideration.The combination of the lattice-inclusion techniques and the completeness of System A for the general probabilisticconditional independence problem allows us to derive criteria that can be used to falsify or validate instances of this impli-cation problem. We introduce an approximate logical implication algorithm which combines these falsification and validationcriteria. The validation algorithm is based on our results regarding the reduction of derivability in System A for general CIstatements to derivability for elementary CI statements. It represents a set of such elementary CI statements as a sparse 0–1matrix, and validates instances of the implication problem by solving linear programs with this matrix as constraint ma-trix. Thus, by only requiring the algorithm to decide the majority of the probabilistic conditional independence implicationproblems, we can leverage line",
            {
                "entities": [
                    [
                        3768,
                        3796,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 183–206www.elsevier.com/locate/artintAverage-case analysis of best-first searchin two representative directed acyclic graphsAnup K. Sen a, Amitava Bagchi a, Weixiong Zhang b,∗a Indian Institute of Management Calcutta, Joka, D. H. Road, Calcutta 700 104, Indiab Department of Computer Science and Engineering, Washington University in Saint Louis,St. Louis, MO 63130, USAReceived 5 May 2003AbstractMany problems that arise in the real world have search spaces that are graphs rather than trees.Understanding the properties of search algorithms and analyzing their performance have been majorobjectives of research in AI. But most published work on the analysis of search algorithms hasbeen focused on tree search, and comparatively little has been reported on graph search. One of themajor obstacles in analyzing average-case complexity of graph search is that no single graph canserve as a suitable representative of graph search problems. In this paper we propose one possibleapproach to analyzing graph search. We take two problem domains for which the search graphsare directed acyclic graphs of similar structure, and determine the average case performance of∗on these graphs. The first domain relates to one-machine jobthe best-first search algorithm Asequencing problems in which a set of jobs must be sequenced on a machine in such a way thata penalty function is minimized. The second domain concerns the Traveling Salesman Problem.Our mathematical formulation extends a technique that has been used previously for analyzing treesearch. We demonstrate the existence of a gap in computational cost between two classes of probleminstances. One class has exponential complexity and the other has polynomial complexity. For thejob sequencing domain we provide supporting experimental evidence showing that problems exhibita huge difference in computational cost under different conditions. For the Traveling SalesmanProblem, our theoretical results reflect on the long-standing debate on the expected complexityof branch-and-bound algorithms for solving the problem, indicating that the complexity can bepolynomial or exponential, depending on the accuracy of the heuristic function used. 2004 Elsevier B.V. All rights reserved.∗Keywords: Graph search; Average-case complexity; A; Job sequencing; Traveling salesman* Corresponding author.E-mail addresses: sen@iimcal.ac.in (A.K. Sen), bagchi@iimcal.ac.in (A. Bagchi), zhang@cse.wustl.edu(W. Zhang).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.001\f184A.K. Sen et al. / Artificial Intelligence 155 (2004) 183–2061. Introduction and overviewIn many real-world applications, graph search can be shown to be more efficient thantree search. Sometimes, tree search is simply not feasible. Consider sequence alignment, animportant issue in computational biology that can be formulated as a shortest-path problemin a grid. It can be solved only with the help of graph search [5,12,17]. Problems thatarise in single-machine minimum-penalty job sequencing can be solved with the help ofeither graph search or tree search, but in this case graph search outperforms tree search interms of running time even when the evaluation function is non-order-preserving [26]. Inaddition, in the determination of a winner in a combinatorial auction [25], a solution can beobtained in principle by enumerating exhaustive partitions of items in a search space thathas the form of a graph. These examples demonstrate that graph search has many possibleapplications. Moreover, graph search usually needs much less memory than best-first treesearch, making larger problems solvable on current machines [27].Although graph search plays an important role in understanding, characterizing andsolving difficult combinatorial optimization problems, the average-case performance ofgraph search algorithms has hardly been analyzed at all. In sharp contrast, there is a largeliterature devoted to the analysis of the performance of tree search algorithms [2,6,7,11,16,20–22,31]. One objective of this paper, which extends the work already reported in [28], isto try and redress the balance.A major consideration that has hamstrung the research on the performance analysis ofgraph search algorithms is that no single graph can claim to be a representative graph forthe search spaces that arise in real-world applications. Therefore, general results on theperformance of graph search seem to be out of reach. One way out of this dilemma is to doa separate independent analysis of each individual problem, but this makes generalizationdifficult. Here we take a middle road. Our analysis is neither perfectly general nor confinedto an individual case. We choose to study a representative model of a set of relatedproblems, in the hope that this will not only shed more light on the individual problems,but perhaps also lead to a generalization that will help to achieve a deeper understandingof graph search.Here we look at two classes of problems. The first class consists of one-machinejob sequencing problems, and the second consists of the Traveling Salesman Problem(TSP). Job scheduling and job sequencing problems arise frequently in manufacturing andproduction systems as well as in information processing environments [23]. We considera class of problems in which N given jobs must be sequenced on a machine in such away that a specified function of job completion times is minimized. The function can havemany different forms and might involve the minimization of measures such as the mean joblateness and/or earliness or the weighted sum of quadratic functions of completion times.Our analytical model for the job sequencing problem has the form of a graph that definesa partial ordering on the subsets of a set of N elements (jobs) under the set inclusionproperty. N determines the problem size. The graph itself has 2N nodes, and is a directedacyclic graph (DAG) with one root node, one goal node and multiple solution paths. The setof N elements forms the root node at level 0, and the empty set is the goal node at level N .To make the analysis feasible, it is assumed, following [22], that the normalized errorsof heuristic estimates of nongoal nodes are independent, identically distributed (i.i.d.)\fA.K. Sen et al. / Artificial Intelligence 155 (2004) 183–206185random variables. Using this abstract model, we analyze the complexity of the best-firstgraph search algorithm A∗. The measure of complexity is the expected number of nodeexpansions. We choose A∗ in preference to other search algorithms because it is optimal interms of the number of node expansions among all algorithms that use the same heuristicinformation [8].There are two main theoretical results. First, it is shown that under certain weakconditions the expected number of distinct nodes expanded by A∗ increases exponentiallywith the number N of jobs for large N . This is consistent with previous experimentalresults on the one-machine job sequencing problem [27]. Second, special cases of interestare identified in which the expected number of node expansions made by A∗ is polynomialin N for large N . The results indicate that the expected complexity of A∗ graph searchon job sequencing problems has two distinct phases, one exponential and the otherpolynomial, demonstrating the existence of a huge gap similar to a phenomenon ofphase transition. Experimental results support the theoretical analysis. We summarize theprevious results for the exponential case and provide new test results on the polynomialcase.A similar, but not identical, search graph arises in a solution procedure for theTraveling Salesman Problem (TSP). In essence, all known algorithms for solving the TSPexactly are implicit enumeration methods based on the branch-and-bound procedure whichprogressively construct complete tours [9,10,18]. One difference between these algorithmsrelates to the branching rules that determine whether the search space is a tree or a graph[3]. Even though some of the best TSP algorithms use a tree search space, e.g., [30], itremains to be determined which search space, tree or graph, is more efficient. It is verylikely that the search space to use would depend on the application at hand. In addition, agraph search space, originally proposed for the TSP in [22], has been used as a benchmarkdomain in some computational experiments [24]. Therefore, it is worthwhile to examinegraph search spaces in the context of the TSP. It is interesting to note that the theoreticalresults derived for the job sequencing domain have their counterparts in the TSP domain,which means that A∗ may run in exponential or nonexponential or polynomial time in thenumber N of cities. We state and prove the corresponding theorems. These results mayshed light on the long-standing debate on the expected complexity of specific branch-and-bound algorithms for solving the TSP in [4]. It has been argued that a branch-and-boundalgorithm can find an optimal solution to the TSP in time polynomial in N under certainconditions [4], or in time exponential in N when such conditions are hard to satisfy [15,19].When run on graphs, A∗ can be viewed as a special type of branch-and-bound algorithmthat uses a best-first search strategy and exits as soon as a solution is found. Therefore theresults in this paper seem to indicate that the expected complexity of a branch-and-boundalgorithm for the TSP can be polynomial or nonexponential or exponential, dependingboth on the definition of the inter-city cost function and the accuracy of the heuristicfunction.The paper is organized as follows. The application domains and their representativesearch graphs are introduced in Section 2. Basic concepts relating to graph search andthe framework of our analysis are presented in Section 3. In Section 4 we examine thejob sequencing problem in greater detail, derive the expected compl",
            {
                "entities": [
                    [
                        2606,
                        2634,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 255–285www.elsevier.com/locate/artintAnyone but him: The complexity of precluding an alternative ✩Edith Hemaspaandra a, Lane A. Hemaspaandra b,∗, Jörg Rothe ca Department of Computer Science, Rochester Institute of Technology, Rochester, NY 14623, USAb Department of Computer Science, University of Rochester, Rochester, NY 14627, USAc Institut für Informatik, Heinrich-Heine-Universität Düsseldorf, 40225 Düsseldorf, GermanyReceived 1 February 2006; received in revised form 18 January 2007; accepted 29 January 2007Available online 7 February 2007AbstractPreference aggregation in a multiagent setting is a central issue in both human and computer contexts. In this paper, we studyin terms of complexity the vulnerability of preference aggregation to destructive control. In particular, we study the ability of anelection’s chair to, through such mechanisms as voter/candidate addition/suppression/partition, ensure that a particular candidate(equivalently, alternative) does not win. And we study the extent to which election systems can make it impossible, or compu-tationally costly (NP-complete), for the chair to execute such control. Among the systems we study—plurality, Condorcet, andapproval voting—we find cases where systems immune or computationally resistant to a chair choosing the winner nonethelessare vulnerable to the chair blocking a victory. Beyond that, we see that among our studied systems no one system offers the bestprotection against destructive control. Rather, the choice of a preference aggregation system will depend closely on which types ofcontrol one wishes to be protected against. We also find concrete cases where the complexity of or susceptibility to control variesdramatically based on the choice among natural tie-handling rules.© 2007 Elsevier B.V. All rights reserved.Keywords: Approval voting; Computational complexity; Computational resistance; Condorcet voting; Destructive control; Election systems;Plurality voting; Preference aggregation; Multiagent systems; Vote suppression1. IntroductionVoting provides a broad framework for collective decision-making. The literature on voting is vast and active, andspans such areas as AI, complexity, economics, operations research, and political science. As noted by Conitzer, Lang,and Sandholm [9], voting has been proposed as a mechanism for use in decision-making in various computational✩ Supported in part by grants NSF-CCR-0311021, NSF-CCF-0426761, DFG-RO-1202/9-1, and DFG-RO-1202/9-3, a Friedrich Wilhelm BesselResearch Award, and the Alexander von Humboldt Foundation’s TransCoop program. A preliminary version of this paper appeared in AAAI-05[E. Hemaspaandra, L. Hemaspaandra, J. Rothe, Anyone but him: The complexity of precluding an alternative, in: Proceedings of the 20th NationalConference on Artificial Intelligence, AAAI Press, 2005]. This work was done in part while the three authors were visiting Julius-Maximilians-Universität Würzburg, in part while the first two authors were visiting Heinrich-Heine-Universität Düsseldorf, and in part while the first author wason sabbatical at the University of Rochester.* Corresponding author.URLs: http://www.cs.rit.edu/~eh/ (E. Hemaspaandra), http://www.cs.rochester.edu/u/lane/ (L.A. Hemaspaandra),http://ccc.cs.uni-duesseldorf.de/~rothe/ (J. Rothe).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.005\f256E. Hemaspaandra et al. / Artificial Intelligence 171 (2007) 255–285settings, including planning [13,14] and collaborative filtering [29]. Voting also may be useful in many large-scalecomputer settings. Examples of much recent interest include the (web-page) rank aggregation problem, and relatedissues of reducing “spam” results in web search and improving similarity search, for which the use of voting systemshas been proposed [12,15]. In such an automated setting, it is natural to imagine decisions with thousands or millionsof “voters” and “candidates”.In Bartholdi, Tovey, and Trick’s seminal paper “How hard is it to control an election?” [3], the issue of constructivecontrol of election systems is studied: How hard is it for a chair (who knows all voters’ preferences) to—throughcontrol of the voter or candidate set or of the partition structure of an election—cause a given candidate (equivalently,alternative) to be the (unique) winner?To avoid any possible confusion, let us immediately stress that by “chair” we, following the use of Bartholdi, Tovey,and Trick [3], simply mean some entity that can carry out the given type of change to the structure of the election.Bartholdi, Tovey, and Trick probably chose to use the word “chair” because that role might typically be that of someauthority responsible for organizing the election and determining its structure. Note that the chair is not necessarilyone of the candidates, or the distinguished candidate c of our forthcoming problem specifications,1 or one of the voters(although we do not exclude these possibilities). (In particular, “chair” here does not mean “a special, designated voterwho if there is a tie is allowed to break the tie”—a meaning the term has in some other contexts, but not in this paper.)To avoid a different potential source of confusion, let us also immediately focus on the fact that in the Bartholdi,Tovey, and Trick [3] model, which is also adopted here, the chair has complete information on the voters’ preferences.This is a natural assumption in many, though certainly not all, situations.2 However, it is critical to note that since thecase where complete information is available to the chair is a special subcase of the more general setting that allowsinformation to be specified with any level of completeness, lower bounds obtained in the complete information settingare inherited by any natural incomplete information model (this point was made in this context even in the originalcontrol paper of Bartholdi, Tovey, and Trick [3]). This is worth stressing: All our NP-hardness results—obtained herein the model of complete information—are instantly inherited by any natural incomplete information model (e.g.,models in which missing preferences are filled in by an adversary of the chair; models in which missing preferencesare filled in as favorably for the chair’s goal as possible; models in which the chair must find an action that underat least k (k would be part of the input) of all possible completions of the unknown information allows the chair toobtain his/her desired outcome; models in which the chair must find an action that under at least 99 percent of allpossible completions of the unknown information allows the chair to obtain his/her desired outcome; etc.). Anotherangle to approach this from would be to note that our lower-bound results are sufficiently strong that they show thateven when the chair has all the information he or she could possibly ask for about preferences—namely, completeinformation—his/her task is nonetheless still NP-hard in many cases. Simply put, the complete-information modelis actually, as a matter of complexity-theoretic basics, a more challenging one in which to prove NP-hardness lowerbounds than a partial-information model would be (although the authors realize that this may seem counterintuitive).Bartholdi, Tovey, and Trick studied plurality and Condorcet voting, and seven natural types of control: addingcandidates, suppressing candidates, partition of candidates, run-off partition of candidates, adding voters, suppressingvoters, and partition of voters. They found that in some cases there is immunity to constructive control (if his/her1 It certainly is the case that in our model the chair will be trying to make the distinguished candidate c win. And so there will be many naturalsituations in which c and the chair coincide. However, that need not always be the case. It is possible to envision situations in which c does not wantc to win (e.g., elections for the chair of an academic department in which some faculty member out of duty would be willing to serve if electedbut would far rather someone else serve; or elections for who gets “removed from the island” on some reality TV show) or situations, even when cdoes want c to win, in which the actor working to make c win is someone other than c (e.g., in particularly bare-knuckled academic faculty hiring,a department chairperson might set a vote date when certain faculty members are out of town, as an attempt to help a certain one of the externalapplicants).2 For example, in a computer science department, after endless discussions, most people know what each person’s position is on key issues. Thisis an example of a rather small-scale, intimate, private election. Of course, one might reasonably point out that large-scale public elections amonghumans are examples where, though polling data may give some information, typically no one will know all voters’ preferences. However, we notethat, as mentioned in the paragraph to which this is a footnote, our lower-bound (NP-hardness) results for the case of complete information implyNP-hardness in the case of essentially any natural partial-information model. We also point out that large-scale elections among electronic agentsmight well have complete preference information available to the chair. (Even in cases of large-scale human elections, there are relatively broadsources of information, such as party affiliation information in voter registration records. Although this certainly isn’t perfectly predictive, it mightwell be useful in attempts, for example, to gerrymander district boundaries or even, and this is in some rough sense an example of control by addingvoters, to target get-out-the-vote drives.)\fE. Hemaspaandra et al. / Artificial Intelligence 171 (2007) 255–285257candidate was not already the3 unique winner, no action of the specified type by the chair can make the candidate theunique winner), in some cases there is (computational) res",
            {
                "entities": [
                    [
                        3416,
                        3444,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 514–534www.elsevier.com/locate/artintRandom constraint satisfaction:Easy generation of hard (satisfiable) instancesKe Xu a,∗,1, Frédéric Boussemart b,2, Fred Hemery b,2, Christophe Lecoutre b,∗,2a National Lab of Software Development Environment, School of Computers, Beihang University, Beijing 100083, Chinab CRIL (Centre de Recherche en Informatique de Lens), CNRS FRE 2499, rue de l’université, SP 16, 62307 Lens cedex, FranceReceived 18 April 2006; received in revised form 30 January 2007; accepted 9 April 2007Available online 14 April 2007AbstractIn this paper, we show that the models of random CSP instances proposed by Xu and Li [K. Xu, W. Li, Exact phase transitionsin random constraint satisfaction problems, Journal of Artificial Intelligence Research 12 (2000) 93–103; K. Xu, W. Li, Manyhard examples in exact phase transitions with application to generating hard satisfiable instances, Technical report, CoRR Reportcs.CC/0302001, Revised version in Theoretical Computer Science 355 (2006) 291–302] are of theoretical and practical interest.Indeed, these models, called RB and RD, present several nice features. First, it is quite easy to generate random instances ofany arity since no particular structure has to be integrated, or property enforced, in such instances. Then, the existence of anasymptotic phase transition can be guaranteed while applying a limited restriction on domain size and on constraint tightness. Inthat case, a threshold point can be precisely located and all instances have the guarantee to be hard at the threshold, i.e., to havean exponential tree-resolution complexity. Next, a formal analysis shows that it is possible to generate forced satisfiable instanceswhose hardness is similar to unforced satisfiable ones. This analysis is supported by some representative results taken from anintensive experimentation that we have carried out, using complete and incomplete search methods.© 2007 Elsevier B.V. All rights reserved.Keywords: Phase transition; Constraint network; Hard random instances1. IntroductionOver the past ten years, the study of phase transition phenomena has been one of the most exciting areas in Com-puter Science and Artificial Intelligence. Numerous studies have established that for many NP-complete problems(e.g., SAT and CSP), the hardest random instances occur, while a control parameter is varied accordingly, betweenan under-constrained region where all instances are almost surely satisfiable and an over-constrained region whereall instances are almost surely unsatisfiable. In the transition region, there is a threshold where half the instances are* Corresponding authors. Please correspond with the first author for the theory of this paper and the last author for the experiment.E-mail addresses: kexu@nldse.buaa.edu.cn (K. Xu), boussemart@cril.univ-artois.fr (F. Boussemart), hemery@cril.univ-artois.fr (F. Hemery),lecoutre@cril.univ-artois.fr (C. Lecoutre).1 Author partially supported by the National 973 Program of China (Grant No. 2005CB321901), NSFC Grant 60403003 and FANEDD Grant200241.2 Authors supported by the CNRS, the “programme COCOA de la Région Nord/Pas-de-Calais” and by the “IUT de Lens”.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.001\fK. Xu et al. / Artificial Intelligence 171 (2007) 514–534515satisfiable (and half the instances are unsatisfiable). Generating hard instances is important both for understanding thecomplexity of the problems and for providing challenging benchmarks [11].Another remarkable progress in Artificial Intelligence has been the development of incomplete algorithms forvarious kinds of problems. And, since this progress, one important issue has been to produce hard satisfiable instancesin order to evaluate the efficiency of such algorithms, as the approach that involves exploiting a complete algorithmin order to keep random satisfiable instances generated at the threshold can only be used for instances of limitedsize. Also, it has been shown that generating hard (forced) satisfiable instances is related to some open problems incryptography such as computing a one-way function [11,20].In this paper, we mainly focus on random CSP (Constraint Satisfaction Problem) instances. Initially, four “stan-dard” models, denoted A, B, C and D [16,39], have been introduced to generate random binary CSP instances.However, Achlioptas et al. [3] have identified a shortcoming of all these models. Indeed, they prove that randominstances generated using these models suffer from (trivial) unsatisfiability as the number of variables increases. Toovercome the deficiency of these standard models, several alternatives have been proposed.On the one hand, a model E has been proposed in [3] and a generalized model in [31]. However, the model Edoes not permit to tune the density of the instances and the generalized model requires an awkward exploitationof probability distributions. Also, other alternatives correspond to incorporating some “structure” in the generatedrandom instances. Roughly speaking, it involves ensuring that the generated instances be arc consistent [16] or pathconsistent [15]. The main drawback of all these approaches is that generating random instances is no more quite anatural and easy task.On the other hand, standard models have been revised [14,38,44,45] by controlling the way parameters change asthe problem size increases. The alternative model D scheme [38], where both the domain size and the average degree ofthe constraint graph increase with the number of variables, guarantees the occurrence of an asymptotic phase transitionas the constraint tightness is varied. The two revised models, called RB and RD [44,45] provide the same guaranteeby varying one of two control parameters around a critical value that, in addition, can be computed. Also, in [14],a range of suitable parameter settings is identified which allows to exhibit a non-trivial threshold of satisfiability.Their theoretical results apply to binary instances taken from model A and to “symmetric” binary instances from aso-called model B which, not corresponding to the standard one, associates the same relation with every constraint.The models RB and RD present several nice features:• it is quite easy to generate random instances of any arity as no particular structure has to be integrated, or propertyenforced, in such instances.• the existence of an asymptotic phase transition can be guaranteed while applying a limited restriction on domainsize and on constraint tightness. For instances involving constraints of arity k, the domain size is required to begreater than the kth root of the number of variables and the (threshold value of the) constraint tightness is requiredto be at most k−1k .• when the asymptotic phase transition exists, a threshold point can be precisely located, and all instances generatedfollowing models RB and RD have the guarantee to be hard at the threshold, i.e., to have an exponential tree-resolution complexity.• it is possible to generate forced satisfiable instances whose hardness is similar to unforced satisfiable ones.Concerning the last item, note that instances forced to be satisfiable are simply built by randomly generating firsta solution, and then a set of constraints guaranteed to support this solution. We show that under the same conditions,those used to establish the existence of an asymptotic phase transition in model RB, there is an asymptotic similaritybetween forced and unforced satisfiable instances of model RB with respect to the number and the distribution ofsolutions. We believe that this is one important aspect of our contribution.Also, remember that CSP is a generalization of the SAT problem which is the first proven NP-complete problem andplays a central role in computational complexity. In the study of phase transitions in NP-complete problems, random3-SAT has received most attention, both theoretically and experimentally, in the past decade or so. However, untilnow, the existence of the threshold phenomenon in random 3-SAT has not been established, not even the exact valueof the threshold point. As such, much of the work on random 3-SAT has been focused on proving lower bounds andupper bounds for the threshold point. Through a series of hard work, the current best lower bound and upper bound forrandom 3-SAT are 3.42 [22] and 4.506 [13], respectively. In contrast, the existence of phase transitions in model RBhas been established and the threshold points are also known exactly. In fact, these results about model RB are mainly\f516K. Xu et al. / Artificial Intelligence 171 (2007) 514–534obtained by direct application of the second moment method which, unfortunately, fails on random 3-SAT. The reasonfor this is that the distribution of the number of solutions for model RB is very uniform (i.e. almost all instanceshave the same number of solutions) while for random 3-SAT, this distribution is highly skewed (i.e. a few instanceshave far more solutions than most instances). From the viewpoint of phase transitions in NP-complete problems, it istherefore interesting to further investigate in which aspects random 3-SAT and model RB behave differently, and ifsuch comparisons can shed any light on the fundamental properties of NP-complete problems. In this paper, we willsee an example of such a comparison: when random 3-SAT and model RB are used to generate satisfiable instances,the same strategy can produce very different results.Finally, note that in experimental CSP studies, random instances of model B with varying tightness and densityare often used as benchmarks for algorithms. However, such instances cannot be used to evaluate the asymptoticperformance of algorithms. To fill this need, a good way is to generate random instances of increasing size (i.e.number of variables) which are guaranteed to be hard. An advantage of model RB over model B is that it provides as",
            {
                "entities": [
                    [
                        3297,
                        3325,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 220–257Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAdversarial patrolling with spatially uncertain alarm signalsNicola Basilico a,∗a Department of Computer Science, University of Milan, Milano, Italyb Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy, Giuseppe De Nittis b, Nicola Gatti ba r t i c l e i n f oa b s t r a c tArticle history:Received 15 June 2015Received in revised form 6 August 2016Accepted 26 February 2017Available online 4 March 2017Keywords:Security gamesAdversarial patrollingAlgorithmic game theoryWhen securing complex infrastructures or large environments, constant surveillance of every area is not affordable. To cope with this issue, a common countermeasure is the usage of cheap but wide-ranged sensors, able to detect suspicious events that occur in large areas, supporting patrollers to improve the effectiveness of their strategies. However, such sensors are commonly affected by uncertainty. In the present paper, we focus on spatially uncertain alarm signals. That is, the alarm system is able to detect an attack but it is uncertain on the exact position where the attack is taking place. This is common when the area to be secured is wide, such as in border patrolling and fair site surveillance. We propose, to the best of our knowledge, the first Patrolling Security Game where a Defenderis supported by a spatially uncertain alarm system, which non-deterministically generates signals once a target is under attack. We show that finding the optimal strategy is FNP-hard even in tree graphs and APX-hard in arbitrary graphs. We provide two (exponential time) exact algorithms and two (polynomial time) approximation algorithms. Finally, we show that, without false positives and missed detections, the best patrolling strategy reduces to stay in a place, wait for a signal, and respond to it at best. This strategy is optimal even with non-negligible missed detection rates, which, unfortunately, affect every commercial alarm system. We evaluate our methods in simulation, assessing both quantitative and qualitative aspects.© 2017 Elsevier B.V. All rights reserved.1. IntroductionSecurity Games model the task of protecting physical environments as a non-cooperative game between a Defender and an Attacker [1]. These games usually take place under a Stackelberg (a.k.a. leader–follower) paradigm [2], where the Defender (leader) commits to a strategy and the Attacker (follower) first observes such commitment and then best responds to it. As discussed in the seminal work [3], finding a leader–follower equilibrium is computationally tractable in games with one follower and complete information, while it becomes hard in Bayesian games with different types of Attacker. The availability of such computationally tractable aspects of Security Games led to the development of algorithms capable of scaling up to large problems, making them deployable in the security enforcing systems of several real-world applications. The first notable examples are the deployment of police checkpoints at the Los Angels International Airport [4] and the scheduling of federal air marshals over the U.S. domestic airline flights [5]. More recent case studies include the positioning of U.S. Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7]. Finally, a similar approach is being tested and evaluated in Uganda, Africa, for the * Corresponding author.E-mail address: nicola.basilico@unimi.it (N. Basilico).http://dx.doi.org/10.1016/j.artint.2017.02.0070004-3702/© 2017 Elsevier B.V. All rights reserved.\fN. Basilico et al. / Artificial Intelligence 246 (2017) 220–257221protection of wildlife [8]. Thus, Security Games emerged as an interesting game theoretical tool and then showed their on-the-field effectiveness in a number of real security scenarios.We focus on a specific class of security games, called Patrolling Security Games. These games are modeled as infinite-horizon extensive-form games in which the Defender controls one or more patrollers moving within an environment, represented as a finite graph. The Attacker, besides having knowledge of the strategy to which the Defender committed to, can observe the movements of the patrollers at any time and use such information in deciding the most convenient time and target location to attack [9]. When multiple patrollers are available, coordinating them at best is in general a hard task which, besides computational aspects, must also keep into account communication issues [10]. However, the patrolling problem is tractable, even with multiple patrollers, in border security (e.g., line and cycle graphs), when patrollers have homogeneous moving and sensing capabilities and all the vertices composing the border share the same features [11]. Scal-ing this model involved the study of how to compute patrolling strategies in scenarios where the Attacker is allowed to perform multiple attacks [12]. Similarly, coordination strategies among multiple defenders are investigated in [13]. In [14], the authors study the case in which there is a temporal discount on the targets. Extensions are discussed in [15], where coordination strategies between defenders are explored, in [16], where a resource can cover multiple targets, and in [17]where attacks can be detected at different stages with different associated utilities. Finally, some theoretical results about properties of specific patrolling settings are provided in [18]. In the present paper, we provide a new model of Patrolling Security Games in which the Defender is supported by an alarm system deployed in the environment.1.1. Motivating scenariosOften, in large environments, a constant surveillance of every area is not affordable while focused inspections triggered by alarms are more convenient. Real-world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], surveillance based on wireless sensor networks [22], and border patrolling [23]. Alarm systems are in practice affected by detection uncertainty, e.g., missed detections and false positives, and localization (a.k.a. spatial) uncertainty, e.g., the alarm system is uncertain about the exact target under attack. We summarily describe two practical security problems that can be ascribed to this category. We report them as examples, presenting features and requirements that our model can properly deal with. In the rest of the paper we will necessarily take a general stance, but we encourage the reader to keep in mind these two cases as reference applications for a real deployment of our model.1.1.1. Fight to illegal poachingPoaching is a widespread environmental crime that causes the endangerment of wildlife in several regions of the world. Its devastating impact makes the development of surveillance techniques to contrast this kind of activities one of the most important matters in national and international debates. Poaching typically takes place over vast and savage areas, making it costly and ineffective to solely rely on persistent patrol by ranger squads. To overcome this issue, recent developments have focused on providing rangers with environmental monitoring systems to better plan their inspections, concentrating them in areas with large likelihood of spotting a crime. Such systems include the use of UAVs flying over the area, alarmed fences, and on-the-field sensors trying to recognize anomalous activities.1 In all these cases, technologies are meant to work as an alarm system: once the illegal activity is recognized, a signal is sent to the rangers base station from where a response is undertaken. In the great majority of cases, a signal corresponds to a spatially uncertain localization of the illegal activity. For example, a camera-equipped UAV can spot the presence of a pickup in a forbidden area but cannot derive the actual location to which poachers are moving. In the same way, alarmed fences and sensors can only transmit the location of violated entrances or forbidden passages. In all these cases a signal implies a restricted, yet not precise, localization of the poaching activity. The use of Security Games in this particular domain is not new (see, for example, [8]). However, our model allows the computation of alarm response strategies for a given alarm system deployed on the field. This can be done by adopting a discretization of the environment, where each target corresponds to a sector, values are related to the expected population of animals in that sector, and deadlines represent the expected completion time of illegal hunts (these parameters can be derived from data, as discussed in [8]).1.1.2. Safety of fair sitesFairs are large public events attended by thousands of visitors, where the problem of guaranteeing safety for the hosting facilities can be very hard. For example, Expo 2015, the recent Universal Exposition hosted in Milan, Italy, saw an average of about 100,000 visits per day. This poses the need for carefully addressing safety risks, which can also derive from planned act of vandalism or terrorist attacks. Besides security guards patrols, fair sites are often endowed with locally installed monitoring systems. Expo 2015 employed around 200 baffle gates and 400 metal detectors at the entrance of the site. The internal area was constantly monitored by 4000 surveillance cameras and by 700 guards. Likely, when one or more of these devices/personnel identified a security breach, a signal was sent to the control room together with a circumscribed request of intervention. This approach is required because, especially in this kind of environments, detecting a security breach 1 See, for example, http :/ /wildlandsecurity.org/.\f222N. Basilico et al. / Artificial",
            {
                "entities": [
                    [
                        3682,
                        3710,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 365–377www.elsevier.com/locate/artintIf multi-agent learning is the answer,what is the question?Yoav Shoham ∗, Rob Powers, Trond GrenagerDepartment of Computer Science, Stanford University, Stanford, CA 94305, USAReceived 8 November 2005; received in revised form 14 February 2006; accepted 16 February 2006Available online 30 March 2007AbstractThe area of learning in multi-agent systems is today one of the most fertile grounds for interaction between game theory andartificial intelligence. We focus on the foundational questions in this interdisciplinary area, and identify several distinct agendasthat ought to, we argue, be separated. The goal of this article is to start a discussion in the research community that will result infirmer foundations for the area.1© 2007 Published by Elsevier B.V.1. IntroductionThe topic of learning in multi-agent systems, or multi-agent learning (MAL henceforth), has a long history ingame theory, almost as long as the history of game theory itself.2 As early as 1951, fictitious play [10] was proposedas a learning algorithm for computing equilibria in games and there have been proposals for how to evaluate thesuccess of learning rules going back to [23] and [5]. Since that time hundreds, if not thousands, of articles have beenpublished on the topic, and at least two books ([20] and [54]).In Artificial Intelligence (AI) the history of single-agent learning is as rich if not richer, with thousands of articles,many books, and some very compelling applications in a variety of fields (for some examples see [29,40], or [50]).While it is only in recent years that AI has branched into the multi-agent aspects of learning, it has done so with* Corresponding author.E-mail addresses: shoham@cs.stanford.edu (Y. Shoham), powers@cs.stanford.edu (R. Powers), grenager@cs.stanford.edu (T. Grenager).1 This article has a long history and owes many debts. A first version was presented at the NIPS workshop, Multi-Agent Learning: Theory andPractice, in 2002. A later version was presented at the AAAI Fall Symposium in 2004 [Y. Shoham, R. Powers, T. Grenager, On the agenda(s) ofresearch on multi-agent learning, in: AAAI 2004 Symposium on Artificial Multi-Agent Learning (FS-04-02), AAAI Press, 2004]. Over time ithas gradually evolved into the current form, as a result of our own work in the area as well as the feedback of many colleagues. We thank themall collectively, with special thanks to members of the multi-agent group at Stanford in the past three years. Rakesh Vohra and Michael Wellmanprovided detailed comments on the latest draft which resulted in substantive improvements, although we alone are responsible for the views putforward. This work was supported by NSF ITR grant IIS-0205633 and DARPA grant HR0011-05-1.2 Another more recent term for the area within game theory is interactive learning.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2006.02.006\f366Y. Shoham et al. / Artificial Intelligence 171 (2007) 365–377something of a vengeance. If in 2003 one could describe the AI literature on MAL by enumerating the relevant articles,today this is no longer possible. The leading conferences routinely feature articles on MAL, as do the journals.3While the AI literature maintains a certain flavor that distinguishes it from the game theoretic literature, thecommonalities are greater than the differences. Indeed, alongside the area of mechanism design, and perhaps thecomputational questions surrounding solution concepts such as the Nash equilibrium, MAL is today arguably one ofthe most fertile interaction grounds between computer science and game theory.The MAL research in both fields has produced some inspiring results. We will not repeat them here, since we cannotbe comprehensive in this article, but nothing we say subsequently should be interpreted as belittling the achievementsin the area. Yet alongside these successes there are some indications that it could be useful to take a step back and aska few basic questions about the area of MAL. One surface indication is the presence of quite a number of frustratingdead ends. For example, the AI literature attempting to extend Bellman-style single-agent reinforcement learning tech-niques (in particular, Q-learning [53]) to the multi-agent setting, has fared well in zero-sum repeated games (e.g., [36]and [38]) as well as common-payoff (or ‘team’) repeated games (e.g., [14,31,52]), but less well in general-sum sto-chastic games (e.g., [21,26,37]) (for the reader unfamiliar with this line of work, we cover it briefly in Section 4).Indeed, upon close examination, it becomes clear that the very foundations of MAL could benefit from explicit dis-cussion. What exact question or questions is MAL addressing? What are the yardsticks by which to measure answersto these questions? The present article focuses on these foundational questions.To start with the punch line, following an extensive look at the literature we have reached two conclusions:• There are several different agendas being pursued in the MAL literature. They are often left implicit and conflated;the result is that it is hard to evaluate and compare results.• We ourselves can identify and make sense of five distinct research agendas.Not all work in the field falls into one of the five agendas we identify. This is not necessarily a critique of workthat doesn’t; it simply means that one must identify yet other well-motivated and well defined problems addressedby that work. We expect that as a result of our throwing down the gauntlet additional such problems will be defined,but also that some past work will be re-evaluated and reconstructed. Certainly we hope that future work will alwaysbe conducted and evaluated against well-defined criteria, guided by this article and the discussion engendered by itamong our colleagues in AI and game theory. In general we view this article not as a final statement but as the start ofa discussion.In order to get to the punch line outlined above, we proceed as follows. In the next section we define the formalsetting on which we focus. In Section 3 we illustrate why the question of learning in multi-agent settings is inherentlymore complex than in the single-agent setting, and why it places a stress on basic game theoretic notions. In Section 4we provide some concrete examples of MAL approaches from both game theory and AI. This is anything but a com-prehensive coverage of the area, and the selection is not a value judgment. Our intention is to anchor the discussionin something concrete for the benefit of the reader who is not familiar with the area, and—within the formal confineswe discuss in Section 2—the examples span the space of MAL reasonably well. In Section 5 we identify five differentagendas that we see (usually) implicit in the literature, and which we argue should be made explicit and teased apart.We end in Section 6 with a summary of the main points made in this article.A final remark is in order. The reader may find some of the material in the next three sections basic or obvious;different readers will probably find different parts so. We don’t mean to insult anyone’s intelligence, but we err on theside of explicitness for two reasons. First, this article is addressed to at least two different communities with somewhatdifferent backgrounds. Second, our goal is to contribute to the clarification of foundational issues; we don’t want tobe guilty of vagueness ourselves.3 We acknowledge a simplification of history here. There is definitely MAL work in AI that predates the last few years, though the relative delugeis indeed recent. Similarly, we focus on AI since this is where most of the action is these days, but there are also other areas in computer sciencethat feature MAL material; we mean to include that literature here as well.\fY. Shoham et al. / Artificial Intelligence 171 (2007) 365–3773672. The formal settingWe will couch our discussion in the formal setting of stochastic games (aka Markov games). Most of the MALliterature adopts this setting, and indeed most of it focuses on the even more narrow class of repeated games. Fur-thermore, stochastic games also generalize Markov Decision Problems (MDPs), the setting from which much of therelevant learning literature in AI originates. These are defined as follows.A stochastic game can be represented as a tuple: (N, S, (cid:3)A, (cid:3)R, T ). N is a set of agents indexed 1, . . . , n. S is a setof n-agent stage games. (cid:3)A = A1, . . . , An, with Ai the set of actions (or pure strategies) of agent i (note that weassume the agent has the same strategy space in all games; this is a notational convenience, but not a substantiverestriction). (cid:3)R = R1, . . . , Rn, with Ri : S × (cid:3)A → R giving the immediate reward function of agent i for stage game S.T : S × (cid:3)A → Π(S) is a stochastic transition function, specifying the probability of the next stage game to be playedbased on the game just played and the actions taken in it.We also need to define a way for each agent to aggregate the set of immediate rewards received in each state. Forfinitely repeated games we can simply use the sum or average, while for infinite games the most common approachest=1 δt rt , where rt is the reward received atare to use either the limit average or the sum of discounted awardstime t.(cid:2)∞A repeated game is a stochastic game with only one stage game, while an MDP is a stochastic game with only oneagent.While most of the MAL literature lives happily in this setting, we would be remiss not to acknowledge the literaturethat does not. Certainly one could discuss learning in the context of extensive-form games of incomplete and/orimperfect information (cf. [28]). We don’t dwell on those since it would distract from the main discussion, and sincethe lessons we draw from our setting will apply there as well.Although we will not specifically include them, we a",
            {
                "entities": [
                    [
                        2957,
                        2985,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 865–888Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProperty persistence in the situation calculusRyan F. Kelly, Adrian R. Pearce∗Department of Computer Science and Software Engineering, The University of Melbourne, Victoria 3010, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 25 May 2009Received in revised form 6 May 2010Accepted 6 May 2010Available online 8 May 2010Keywords:Situation calculusAutomated reasoningProperty persistence1. IntroductionWe develop a new automated reasoning technique for the situation calculus that canhandle a class of queries containing universal quantification over situation terms. Althoughsuch queries arise naturally in many important reasoning tasks, they are difficult toautomate in the situation calculus due to the presence of a second-order induction axiom.We show how to reduce queries about property persistence, a common type of universally-quantified query, to an equivalent form that does not quantify over situations and so isamenable to existing reasoning techniques. Our algorithm replaces induction with a meta-level fixpoint calculation; crucially, this calculation uses only first-order reasoning with alimited set of axioms. The result is a powerful new tool for verifying sophisticated domainproperties in the situation calculus.© 2010 Elsevier B.V. All rights reserved.The situation calculus is one of the most popular and influential AI formalisms for reasoning about action and change,having found application in a wide variety of both theoretical and practical works [5,6,9,26,27,30]. A major contributorto the success of the formalism is that it combines a powerful modelling language built on first-order logic with easilyimplementable techniques for effective automated reasoning.A key challenge when working with the situation calculus is managing this balance between expressivity and effective-ness. An induction axiom is used to define the structure of situation terms, so answering arbitrary queries requires reasoningin second-order logic. While certain special cases are known to be decidable [31], such reasoning is prohibitively expensivein general [24].If queries are restricted to certain syntactic forms, it is possible to obtain much more effective reasoning procedures –for example, queries restricted to existential quantification over situations can be answered using only first-order logic [23],while queries containing only ground situation terms permit special-purpose techniques such as regression [26].However, there are many important reasoning tasks that require universal quantification over situations, for which thesituation calculus currently offers no effective reasoning tools. One simple example is the problem of goal impossibility –establishing that all possible situations fail to satisfy a goal. In this paper we study a subset of universally-quantified querieswhich we refer to as property persistence queries: under a particular situation calculus theory D, and given some formula φand situation σ , determine whether φ will hold in all situations in the future of σ :D |(cid:3) ∀s: σ (cid:5) s → φ[s]The need for second-order logic has traditionally limited automated reasoning about such queries. We introduce a newapproach to property persistence that is similar in spirit to the standard regression operator, by defining a meta-level* Corresponding author. Tel.: +613 8344 1399; fax: +613 9348 1184.E-mail addresses: rfk@csse.unimelb.edu.au (R.F. Kelly), adrianrp@unimelb.edu.au (A.R. Pearce).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.003\f866R.F. Kelly, A.R. Pearce / Artificial Intelligence 174 (2010) 865–888operator PD such that φ persists at σ if and only if PD(φ) holds at σ . We term the resulting formula the persistencecondition of φ and show how to calculate it as a fixpoint of applications of an operator based on regression; crucially, thiscalculation requires only first-order logic and a limited set of axioms. The persistence condition is also guaranteed to be ina form amenable to existing automated reasoning techniques.Importantly, our results do not require restrictions on the domain theory D – they are generally applicable to the fullfirst-order situation calculus, and are based purely on standard first-order reasoning techniques.The result is a powerful new technique for exploring sophisticated domain properties in the situation calculus. It allowssome second-order aspects of the theory to be “factored out” and handled using a special-purpose algorithm. The techniqueis always sound, and we show that it is complete for important standard variants of the situation calculus. Perhaps mostimportantly, it builds upon and integrates well with standard techniques for effective automated reasoning, so our techniqueis directly applicable to existing theories and systems based on the situation calculus.A preliminary version of this paper has previously appeared as [15]; this revised edition includes extended and additionalproofs, a more comprehensive discussion of the termination properties of our algorithm, and a detailed example of how thepersistence condition can be used to reason about goal impossibility – a deceptively simple task which is nonethelessbeyond the reach of existing reasoning techniques.The paper now proceeds with a brief review of the situation calculus, before formally defining the persistence conditionand establishing its effectiveness as a reasoning tool. Readers familiar with the situation calculus are encouraged to reviewthe background material in Sections 2 and 4, as we make several small modifications to the standard notation that greatlysimplify the development of our approach: the unique names axioms Duna are incorporated into a general backgroundtheory Dbg ; the Poss fluent is subsumed by a general class of action description predicates defined in Dad; we parameterisethe “future situations” predicate s (cid:2) s; and weuse the single-step variant of the regression operator, with corresponding definitions of regressable formulae.to assert that all intermediate actions satisfy a given predicate using s <α s(cid:7)(cid:7)2. The situation calculusThe situation calculus is a powerful formalism for describing and reasoning about dynamic worlds. It was first introducedby McCarthy and Hayes [22] and has since been significantly expanded and formalised [23,26]. We use the particular variantdue to Reiter et al. at the University of Toronto, sometimes called the “Toronto school” or “situations-as-histories” version.The formalisation below is based on the standard definitions from [16,23,25], with some simple modifications.The language Lsitcalc of the situation calculus is a many-sorted language of second-order logic with equality, containingthe following disjoint sorts:• Action terms denote individual instantaneous events that can cause the state of the world to change;• Situation terms are histories of the actions that have occurred in the world, with the initial situation represented by S 0and successive situations built using the function do : Action × Situation → Situation;• Object terms represent any other object in the domain.Fluents are predicates representing properties of the world that may change between situations, and so take a situationterm as their final argument. Predicates and functions that do not take a situation term are called rigid. We use the termprimitive fluent to describe fluents that are directly affected by actions, rather than being defined in terms of other fluents.No functions other than S0 and do produce values of sort Situation. For the sake of clarity we will not consider functionalfluents in this paper; this is a common simplifying assumption in the situation calculus literature and does not result in aloss of generality.Lsitcalc contains the standard alphabet of logical connectives, constants (cid:8) and ⊥, countably infinitely many variables ofeach sort, countably infinitely many predicates of each arity, etc.; for a complete definition, consult the foundational paperby Pirri and Reiter [23]. We follow standard naming conventions for the situation calculus: upper-case roman names indicateconstants; lower-case roman names indicate variables; Greek characters indicate meta-variables or formula templates. Allaxioms universally close over their free variables at outermost scope. The notation ¯t indicates a vector of terms of context-appropriate arity and type. The connectives ∧, ¬, ∃ are taken as primitive, with ∨, →, ≡, ∀ defined in the usual manner.Complex properties of the state of the world are represented using uniform formulae. These are basically logical combi-nations of fluents referring to a common situation term.Definition 1 (Uniform formulae). Let σ be a fixed situation term, R i an arbitrary rigid predicate, F i an arbitrary primitivefluent predicate, τi an arbitrary term that is not of sort Situation, and xi an arbitrary variable that is not of sort Situation.Then the formulae uniform in σ are the smallest set of syntactically-valid formulae satisfying:φ ::= F i( ¯τi, σ ) | R i( ¯τi) | τi = τ j | φi ∧ φ j | ¬φ | ∃xi: φWe will call a formula uniform if it is uniform in some situation. The important aspect of this definition is that theformula refers to no situation other than σ , which appears as the final argument of all fluents in the formula. In particular,uniform formulae cannot quantify over situations or compare situation terms, and cannot contain non-primitive fluents.\fR.F. Kelly, A.R. Pearce / Artificial Intelligence 174 (2010) 865–888867The meta-variable φ is used throughout to refer to an arbitrary uniform formula. The notation φ[s(cid:7)] represents a uniformformula with the particular situation sinserted into all its fluents, replacing whatever situation term was previously there.Note that this is simply a syntactic shorthand designed to",
            {
                "entities": [
                    [
                        3677,
                        3705,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1917–1939Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMechanisms for information elicitationAviv Zohar∗, Jeffrey S. RosenscheinSchool of Engineering and Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 22 March 2007Received in revised form 11 July 2008Accepted 10 August 2008Available online 23 August 2008Keywords:Information elicitationMechanism designInformation tradeWe study the computational aspects of information elicitation mechanisms in which aprincipal attempts to elicit the private information of other agents using a carefullyselected payment scheme based on proper scoring rules. Scoring rules, like many othermechanisms set in a probabilistic environment, assume that all participating agents sharesome common belief about the underlying probability of events. In real-life situationshowever, the underlying distributions are not known precisely, and small differences inbeliefs of agents about these distributions may alter their behavior under the prescribedmechanism.We examine two related models for the problem. The first model assumes that agentshave a similar notion of the probabilities of events, and we show that this approach leadsto efficient design algorithms that produce mechanisms which are robust to small changesin the beliefs of agents.In the second model we provide the designer with a more precise and discrete set ofalternative beliefs that the seller of information may hold. We show that constructionof an optimal mechanism in that case is a computationally hard problem, which is evenhard to approximate up to any constant. For this model, we provide two very differentexponential-time algorithms for the design problem that have different asymptotic runningtimes. Each algorithm has a different set of cases for which it is most suitable. Finally, weexamine elicitation mechanisms that elicit the confidence rating of the seller regarding itsinformation.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe old aphorism “Knowledge is power”, stated by Sir Francis Bacon some four centuries ago, is more relevant nowthan ever. The need to make informed choices causes correct and accurate information to be a desired and highly-valuedcommodity. As intelligent automated agents take on more tasks, and need to act independently within large systems, theirneed to buy and sell information increases.Information in stochastic environments is hard to evaluate, and may be easily faked. Any novice can give a predictionregarding the behavior of tomorrow’s stock market; by pure chance, those predictions may outperform those of even themost informed financial wizard.The question that naturally arises is how to pay for information that can only be verified with some probability. Thisis especially important in cases where in order to obtain the information, the seller itself has to invest some effort. Thepayments made by the buyer must be carefully set so as to induce the seller to invest the effort into acquiring the true* Corresponding author.E-mail addresses: avivz@cs.huji.ac.il (A. Zohar), jeff@cs.huji.ac.il (J.S. Rosenschein).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.005\f1918A. Zohar, J.S. Rosenschein / Artificial Intelligence 172 (2008) 1917–1939information. Otherwise, the seller might be tempted to avoid the cost of obtaining the information, and simply make some-thing up.Most current real-world information trading is done with reliable sources of information over an extended period oftime (for example, buying the same newspaper every day). This repeated form of interaction helps motivate the providerof information to supply accurate and reliable reports (not unlike the “shadow of the future” motivating cooperation in theiterated Prisoner’s Dilemma [1]). The potential for additional interactions in the future makes the information provider’sreputation valuable, and motivates the seller to provide accurate pieces of information.However, advances in technology and infrastructure such as the internet have made a multitude of information sourcesreadily available at a moment’s notice (via web services [2], for example). These tend to be smaller and much more spe-cialized information providers, which can accurately report about a small niche in which they specialize. Interactions withthese sources are often not repeated. Since there is no central authority that governs these sources, and no single authoritycan vouch for the reliability of the information they provide, it is left up to the buyer of information to sift through theinformation that is available and decide what to use.1One approach to the problem of source reliability is the use of reputation systems [3]. These systems are mechanismsthrough which agents provide feedback about the quality of service they received from a specific vendor; this feedbackis later viewed by other potential clients. Unfortunately, solid non-manipulable reputation systems are hard to create, andmost service providers on the internet are not currently rated by any such system.We are therefore interested in other ways of obtaining correct information from a previously unknown informationsource. We will assume that there is no repeated interaction, and the incentive for providing good service must exist withinevery transaction, on its own. The overall approach we take in this work is that of mechanism design. We shall attempt tocreate the incentives for delivering accurate reports by providing payments to the agents in a way that will guarantee thema higher payment when they are behaving well, i.e., when they provide correct information.We shall assume that agents are acting rationally and that they are not intentionally trying to sabotage the buyer—any use the buyer may make of the purchased information does not affect the seller. Instead, we adopt the assumptionthat information providers are only interested in receiving a higher payment and doing the least amount of work. A trulymalicious agent that is trying to intentionally deceive, regardless of monetary loss, will not give good information regardlessof the mechanism applied, and must therefore be dealt with in other ways. Such agents are often handled using securityand encryption tools that we shall not discuss here.1.1. An example scenario for information elicitationThere are many possible scenarios for information exchange, such as reviewing papers, obtaining predictions about thestock market, buying weather information, and so on. We present here one example to which we will refer throughout thepaper.Let us assume that Bob owns a car, and wants to decide if he should upgrade his emergency road service coverage.For this purpose, he wants to evaluate the mechanical condition of the car; this will help him predict the car’s chances ofbreaking down in the near future, and will help him decide whether the extra insurance is worthwhile. Since Bob knowsvery little about cars, he turns to an independent expert, a mechanic named Alice, and asks her to take a look under thehood.Knowing that Bob is not an expert, Alice can decide not to invest any effort in checking the car, and instead make upsome list of malfunctions that threaten to disable the car at any moment, or alternatively she may just say that the car isfine (she has no vested interest in whether Bob upgrades his coverage). How will Bob know that he was told the truth?Even if Alice invests effort in checking the car and says that the car is fine, an accidental malfunction could disable it thenext day (probably making Bob feel cheated).To ensure trust, Alice can make her wages conditioned on the future: if Alice says the car is in poor shape, Bob will geta refund if his car does not break down within the next six months, while if Alice reports that the car is fine, Bob gets arefund if the car does break down within six months. What are the exact payments that will ensure that Alice does herjob? There is naturally some probability that Alice will have to refund some of Bob’s money even if she checked the car andreported the truth to Bob.There might also be a situation in which Alice knowingly lies to Bob. If the chances that a car in good condition willbreak down are too high, Alice could decide to say the car is in bad condition, and thus ensure that she does not refundBob if his car breaks down (even though it was indeed in good condition).1.2. Information elicitation vs. preference elicitationMechanism design [4,5] is the study of how to set the rules and protocols of interaction among agents in a way that willencourage rational agents to behave in a prescribed way that leads to a desired outcome. The mechanism design literature1 As an example, consider querying some foreign weather service before traveling abroad. One will only know if the weather prediction they supplied isgood after arriving at the destination. One may not be likely to require the services of that supplier again.\fA. Zohar, J.S. Rosenschein / Artificial Intelligence 172 (2008) 1917–19391919provides many successful examples of mechanisms that “battle” the agent’s self-interest and successfully achieve outcomesthat are more socially oriented, or are beneficial to the designing agent in some way.Many times, in order to decide on an outcome, a mechanism tries to elicit the preferences of participating agents. Infor-mation elicitation scenarios are slightly different from preference elicitation as it is usually understood in the mechanismdesign literature. In preference elicitation scenarios, information revelation is most often used as a means to an end (i.e., toarrive at some desirable outcome). For example, an auctioneer may want to know the valuations potential buyers have foran expensive painting so that he can award this painting to the bidder that values it highest, and in the p",
            {
                "entities": [
                    [
                        3324,
                        3352,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1856–1875Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMonte-Carlo tree search and rapid action value estimation incomputer GoSylvain Gelly a,1, David Silver b,∗a Université Paris Sud, LRI, CNRS, INRIA, Franceb University College London, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 27 October 2010Received in revised form 22 March 2011Accepted 30 March 2011Available online 6 April 2011Keywords:Computer GoMonte-CarloSearchReinforcement learning1. IntroductionA new paradigm for search, based on Monte-Carlo simulation, has revolutionised theperformance of computer Go programs. In this article we describe two extensions tothe Monte-Carlo tree search algorithm, which significantly improve the effectiveness ofthe basic algorithm. When we applied these two extensions to the Go program MoGo, itbecame the first program to achieve dan (master) level in 9 × 9 Go. In this article we surveythe Monte-Carlo revolution in computer Go, outline the key ideas that led to the successof MoGo and subsequent Go programs, and provide for the first time a comprehensivedescription, in theory and in practice, of this extended framework for Monte-Carlo treesearch.© 2011 Elsevier B.V. All rights reserved.Monte-Carlo tree search [1] is a new paradigm for search, which has revolutionised computer Go [2,3], and is rapidlyreplacing traditional search algorithms as the method of choice in challenging domains such as General Game Playing [4],Amazons [5], Lines of Action [6], multi-player card games [7,8], and real-time strategy games [9].The key idea is to simulate many thousands of random games from the current position, using self-play. New positionsare added into a search tree, and each node of the tree contains a value that predicts who will win from that position. Thesepredictions are updated by Monte-Carlo simulation: the value of a node is simply the average outcome of all simulatedgames that visit the position. The search tree is used to guide simulations along promising paths, by selecting the childnode with the highest potential value [10]. This results in a highly selective search that very quickly identifies good movesequences.The evaluation function of Monte-Carlo tree search depends only on the observed outcomes of simulations, rather thanthe handcrafted evaluation functions used in traditional search algorithms. The evaluation function continues to improvefrom additional simulations; given infinite memory and computation, it will converge on the optimal search tree [10].Furthermore, Monte-Carlo tree search develops in a highly selective, best-first manner, expanding promising regions of thesearch space much more deeply.In this article we describe two major enhancements to Monte-Carlo tree search. The first extension, the Rapid ActionValue Estimation (RAVE) algorithm, shares the value of actions across each subtree of the search tree. RAVE forms a very fastand rough estimate of the action value; whereas normal Monte-Carlo is slower but more accurate. The MC–RAVE algorithmcombines these two value estimates in a principled fashion, so as to minimise the mean squared error.* Corresponding author.E-mail addresses: sylvain.gelly@m4x.org (S. Gelly), davidstarsilver@googlemail.com (D. Silver).1 Now at Google, Zurich.0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.007\fS. Gelly, D. Silver / Artificial Intelligence 175 (2011) 1856–18751857The second extension, heuristic Monte-Carlo tree search, uses a heuristic function to initialise the values of new positionsin the search tree. We demonstrate that an effective heuristic function can be learnt by temporal-difference learning andself-play; however, in general any heuristic can be provided to the algorithm.We applied these two extensions to the Go program MoGo, achieving a significant improvement to its performance in9 × 9 Go. The resulting program became the first program to achieve dan (master) level, and the first program to defeat ahuman professional player. This framework for Monte-Carlo tree search is now used in a wide variety of master-level Goprograms, including the first programs to achieve dan level at 19 × 19 Go.This article provides the first comprehensive description of this extended framework for Monte-Carlo tree search. It addsnew theory, results, pseudocode, and discussion to the original presentation of heuristic MC–RAVE [11,3,12]. In addition, weinclude a survey of the strongest Go programs based on prior approaches, and the strongest current programs based onMonte-Carlo methods.2. Simulation-based search2.1. Two-player gamesWe consider the class of two-player, perfect-information, zero-sum games such as chess, checkers, backgammon and Go.Without loss of generality, we call the player to move first Black and the player to move second White. Black and Whitealternate turns, at each turn t selecting an action at ∈ A(st), where st ∈ S is the current state, S is a finite state space, andA(s) is a finite set of legal actions in state s. The game finishes upon reaching a terminal state with outcome z. Black’s goalis to maximise z; White’s goal is to minimise z.We define a two-player policy π (s, a) = Pr(a|s) to be a stochastic action selection strategy that determines the probabilityof selecting actions in any given state. It consists of both a Black policy πB (s, a) that is used for Black moves, and a Whitepolicy πW (s, a) that is used for White moves, π = (cid:4)πB , πW (cid:5). We define the value function Q π (s, a) to be the expectedoutcome after playing action a in state s, and then following policy π for both players until termination,2Q π (s, a) = Eπ [z | st = s, at = a] ∀s ∈ S, a ∈ A(s).(1)∗(s, a) is the value function that maximises Black’s action value and minimises White’sThe minimax value function Qaction value, from every state and for every action,∗Q(s, a) = maxπBminπWQ π (s, a) ∀s ∈ S, a ∈ A(s).(2)A minimax policy deterministically plays Black moves so as to maximise Q∗(s, a). This is commonly called perfect play.Q∗(s, a), and plays White moves to minimise2.2. SimulationThe basic idea of simulation-based search [13] is to evaluate states online from simulated games. Each simulated game,which we call a simulation, starts from a root state s0, and sequentially samples states and actions, without backtracking,until the game terminates. At each step t of simulation, a simulation policy π (s, a) is used to select an action, at ∼ π (st , ·),and the rules of the game are used to generate the next state st+1. The outcome z of each simulated game is used to updatethe values of states or actions encountered during that simulation.2.3. Monte-Carlo simulationMonte-Carlo simulation is a simple simulation-based search algorithm for evaluating candidate actions from a rootstate s0. The search proceeds by simulating complete games from s0 until termination, using a fixed simulation policy,for example selecting actions uniformly amongst all legal moves. The value of each action a from s0, is estimated by themean outcome of all simulations starting with candidate action a.Monte-Carlo simulation provides a simple method for estimating the root value Q π (s0, a). N(s) complete games aresimulated by self-play with policy π from state s. The Monte-Carlo value (MC value) Q (s, a) is the mean outcome of allsimulations in which action a was selected in state s,Q (s, a) = 1N(s, a)N(s)(cid:2)i=1Ii(s, a)zi,(3)2 In two-player games a state is usually called a position and an action is usually called a move. The goodness of positions or moves is estimated by anevaluation function. We use these terms during informal discussions, but use state, action and value function in their precise sense.\f1858S. Gelly, D. Silver / Artificial Intelligence 175 (2011) 1856–1875where zi is the outcome of the ith simulation; Ii(s, a) is an indicator function returning 1 if action a was selected in state(cid:3)s during the ith simulation, and 0 otherwise; and N(s, a) =Ii(s, a) counts the total number of simulations in whichaction a was selected in state s.N(s)i=1In its most basic form, Monte-Carlo simulation is only used to evaluate actions, but not to improve the simulation policy.However, the basic algorithm can be extended by progressively favouring the most successful actions, or by progressivelypruning away the least successful actions [14,15].In some problems, such as backgammon [16], Scrabble [17], Amazons [5] and Lines of Action [6], it is possible to con-struct an accurate evaluation function. In these cases it can be beneficial to stop simulation before the end of the game, andbootstrap from the estimated value at the time of stopping. This approach, known as truncated Monte-Carlo simulation, bothincreases the simulation speed, and also reduces the variance of Monte-Carlo evaluation. In more challenging problems,such as Go [15], it is hard to construct an accurate evaluation function. In this case truncating simulations usually increasesthe evaluation bias more than it reduces the evaluation variance, and so it is better to simulate until termination.2.4. Monte-Carlo tree searchMonte-Carlo tree search (MCTS) uses Monte-Carlo simulation to evaluate the nodes of a search tree [1]. The values in thesearch tree are then used to select the best action during subsequent simulations. Monte-Carlo tree search is sequentiallybest-first: it selects the best child at each step of simulation. This allows the search to continually refocus its attention,each simulation, on the highest value regions of the state space. As the search tree grows larger, the values of the nodesapproximate the minimax value, and the simulation policy approximates the minimax policy.The search tree T contains one node, n(s), corresponding to each state s that has been seen during simulations. Eachnode contains a total count for the state, N(s), and an action value Q (s, a) and count N(s, a)",
            {
                "entities": [
                    [
                        3423,
                        3451,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 120–141Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA unifying action calculusMichael ThielscherSchool of Computer Science and Engineering, The University of New South Wales, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Knowledge representationReasoning about actionsSituation CalculusMcCarthy’s Situation Calculus is arguably the oldest special-purpose knowledge represen-tation formalism, designed to axiomatize knowledge of actions and their effects. Fourdecades of research in this area have led to a variety of alternative formalisms: Whilesome approaches can be considered instances or extensions of the classical Situation Cal-culus, like Reiter’s successor state axioms or the Fluent Calculus, there are also specialplanning languages like ADL and approaches based on a linear (rather than branching)time structure like the Event Calculus. The co-existence of many different calculi has twomain disadvantages: The formal relations among them is a largely open issue, and a lot oftoday’s research concerns the transfer of specific results from one approach to another. Inthis paper, we present a unifying action calculus, which encompasses (well-defined classesof) all of the aforementioned formalisms. Our calculus not only facilitates comparisons andtranslations between specific approaches, it also allows to solve interesting problems forvarious calculi at once. We exemplify this by providing a general, calculus-independent so-lution to a problem of practical relevance, which is intimately related to McCarthy’s questfor elaboration tolerant formalisms: the modularity of domain axiomatizations.© 2010 Elsevier B.V. All rights reserved.1. IntroductionJohn McCarthy’s Situation Calculus [22] is arguably the oldest special-purpose knowledge representation formalism. Theaim is to use classical logic to axiomatize knowledge of actions and their effects. This is relevant for a variety of areas in AI,including planning, intelligent agents, high-level cognitive robotics, natural language understanding, and general game play-ing. While the Situation Calculus is the classical approach for this purpose, a variety of different logic-based formalisms haveemerged in the course of the past decades, motivated mainly by the fundamental Frame Problem [25]. Besides prominentvariants of the Situation Calculus like Reiter’s successor state axioms [31] or the Fluent Calculus [41], planning languageslike STRIPS, ADL, and PDDL [5,29,26] have been developed, which allow for simple operational solutions to the Frame Prob-lem at the expense of a significantly limited expressiveness. Furthermore, the underlying branching time structure of theSituation Calculus has been replaced by a linear time structure in the Event Calculus and a number of other approaches[18,36,4,10]. The basic principles of knowledge representation for actions are also used in special-purpose formalisms likethe Game Description Language [8].The co-existence of a multitude of knowledge representation languages for actions has two significant consequences forthe research in this area. Firstly, there is a growing need both for comparative analysis of the expressiveness of differentapproaches as well as for translations from one specific language into another one. Previous studies along this line are [17,28,35,3], each of which concerns the comparison of two specific formalisms. However, a method that encompasses a widevariety of alternative formalisms at the same time may allow for a more uniform way of assessing and translating calculi.Secondly, issues of general interest need to be separately addressed within each individual language. This often leads to aE-mail address: mit@cse.unsw.edu.au.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.010\fM. Thielscher / Artificial Intelligence 175 (2011) 120–141121multiplication of research efforts. A notorious example is the Ramification Problem, that is, the problem of determining theindirect effects of actions [9], for which a variety of individual solutions have been developed for different formalisms, e.g.,[19,21,11,40,38,27]. A general method which enables a uniform treatment of problems across different calculi would help toavoid this multiplication of research efforts.In this paper, we address both of these issues at the same time by proposing a unifying action calculus, which isindependent of a specific solution to the Frame Problem and which is shown to be general enough to encompass a varietyof different action representation formalisms. Most notably, it abstracts from the underlying time structure (branching orlinear) and thus can be instantiated with both Situation Calculus-style approaches as well as Event Calculus-like languages.In so doing, our general calculus provides a uniform method for translating a variety of specific formalisms into eachother. Moreover, the unifying approach allows to abstract from specific formalisms when investigating problems of generalinterest. We exemplify this by providing a new, calculus-independent solution to a problem of practical relevance for anyaction representation language: the modularity of domain axiomatizations [13]. Our result is a contribution to McCarthy’squest for elaboration tolerant formalisms [24], since modularity is a prerequisite for elaboration tolerance: theories with avariety of dependencies among different parts may not allow for the addition of new information without disrupting theentire axiomatization [14]. We use our unifying action calculus to develop a general method for verifying that a given set ofdomain constraints, precondition axioms, and effect formulas is free of undesired, implicit dependencies. We exemplify therange of applicability of this result by instantiating it for several specific approaches, in particular the Situation-, Fluent-,and Event Calculus.The remainder of this paper is organized as follows. In the next section, we formally define an action calculus whichabstracts from a specific underlying time structure and is independent of a specific solution to the Frame Problem. Weillustrate the expressiveness of our definition by formalizing several example domains known from the literature, includingnondeterministic actions, indirect effects, and actions with duration. In Section 3, we show how our unifying calculus canbe used as an intermediary language for translations between specific languages. Specifically, we present two new results:a translation from ADL planning problems into the Event Calculus and a translation from the basic Fluent Calculus into anew extension—suitable for nondeterministic actions—of Reiter’s basic Situation Calculus. In the second part of the paper,in Section 4, we show how the unifying action calculus can be used to provide a calculus-independent solution to theproblem of implicit dependencies among domain axioms, and we again exemplify the range of applicability of this result byinstantiating it for several action formalisms. We conclude with a discussion in Section 5.2. A unifying action calculusThe purpose of this section is to develop a unifying action calculus that abstracts from a variety of existing axioma-tization techniques for describing actions and change. Logic-based action representation formalisms have in common twofundamental elements: Fluents [22] (sometimes called features [33]) represent properties of the domain that may change inresponse to the execution of actions (or events [18]). Fluents and actions are therefore basic sorts in the sorted logic languagewe are going to define. Action calculi also need to distinguish different points in time in order to axiomatize the changescaused by actions. We assume an abstract notion of time—which may be linear or branching—as the third fundamental sort.The three basic sorts are used for three fundamental predicates: The relation t1 < t2 denotes a (possibly partial) orderingon the time structure. Predicate Holds( f , t) is used to say that fluent fis true at time t. Finally, the intended meaning ofexpression Poss(a, s, t) is that it is possible to do action a beginning at time s and ending at time t. These three predicates,along with the three fundamental sorts, form the basis of a domain signature in our unifying action calculus.Definition 1. A domain signature is a finite, sorted logic language which includes the sorts fluent, action, and time alongwith the predicates<: time × timeHolds: fluent × timePoss: action × time × timeWe tacitly assume that a signature always includes the standard predicate “=”, interpreted as true equality. As usual, then,s (cid:2) t stands for s < t ∨ s = t.Throughout the paper we will denote variables of sort action by the letter a, variables of sort fluent by f and g, andvariables of sort time by s and t. We tacitly assume uniqueness-of-names [1] for all functions into fluent and action, whichis a common assumption in all standard action calculi.Next, we define the notion of a state formula, which allows to express properties of a domain at given times.Definition 2. Let (cid:3)t be a non-empty sequence of variables of sort time in a given domain signature. A state formula in (cid:3)t is afirst-order formula Φ[(cid:3)t] in which the variables in (cid:3)t occur free and such that1. for each occurrence of Holds( f , t) in Φ we have t ∈ (cid:3)t;\f122M. Thielscher / Artificial Intelligence 175 (2011) 120–1412. predicate Poss does not occur in Φ.Similar notions are used in many existing calculi but usually restricted to a single time point. As will be shown later inthis section, the more general concept is useful, for instance, when axiomatizing actions with ramifications.We are now in a position to formalize, in our calculus, three fundamental categories of domain axioms: domain con-straints, which describe state properties that hold at all times; preco",
            {
                "entities": [
                    [
                        3900,
                        3928,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 167 (2005) 103–136www.elsevier.com/locate/artintProtocols from perceptual observationsChris J. Needham ∗, Paulo E. Santos 1, Derek R. Magee,Vincent Devin 2, David C. Hogg, Anthony G. CohnSchool of Computing, University of Leeds, Leeds, LS2 9JT, UKReceived 28 July 2004; received in revised form 14 February 2005; accepted 14 April 2005Available online 27 July 2005AbstractThis paper presents a cognitive vision system capable of autonomously learning protocols fromperceptual observations of dynamic scenes. The work is motivated by the aim of creating a syn-thetic agent that can observe a scene containing interactions between unknown objects and agents,and learn models of these sufficient to act in accordance with the implicit protocols present in thescene. Discrete concepts (utterances and object properties), and temporal protocols involving theseconcepts, are learned in an unsupervised manner from continuous sensor input alone. Crucial to thislearning process are methods for spatio-temporal attention applied to the audio and visual sensordata. These identify subsets of the sensor data relating to discrete concepts. Clustering within contin-uous feature spaces is used to learn object property and utterance models from processed sensor data,forming a symbolic description. The PROGOL Inductive Logic Programming system is subsequentlyused to learn symbolic models of the temporal protocols presented in the presence of noise and over-representation in the symbolic data input to it. The models learned are used to drive a synthetic agentthat can interact with the world in a semi-natural way. The system has been evaluated in the domainof table-top game playing and has been shown to be successful at learning protocol behaviours insuch real-world audio-visual environments. 2005 Elsevier B.V. All rights reserved.* Corresponding author.E-mail address: chrisn@comp.leeds.ac.uk (C.J. Needham).1 Paulo Santos is now at Centro Universitario da FEI, Sao Paulo, Brazil.2 Vincent Devin is now at France Telecom R&D, Meylan, France.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.04.006\f104C.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136Keywords: Cognitive vision; Autonomous learning; Unsupervised clustering; Symbol grounding; Inductive logicprogramming; Spatio-temporal reasoning1. IntroductionThis paper presents a cognitive vision system capable of autonomously learning proto-cols involving rudimentary language and visual objects. In this system, models of visualobjects and utterances are obtained from unsupervised statistical learning algorithms. In or-der to form symbolic data for input into an inductive logic programming (ILP) system, thecontinuous perceptual observations are transformed using the models learned. Perceptualobservations are taken to be any sensory input; here acoustic and visual inputs are used.The concept of qualitative time is introduced, since only key frames are deemed to be ofimportance. The direct link between perception and action is exploited; a change in what isperceived can only be brought about by an action. The ILP system is used to construct setsof definite clauses that express rules of behaviour for the perceived actions from the sym-bolic description of the scenes. In particular, the protocols learned encode the connectionbetween utterances with visual objects that occur in the scene. This is intrinsically a solu-tion to the anchoring problem [8] which is an instance of the symbol grounding problem[15]. The sets of definite clauses obtained are further used by a synthetic agent to performactions in the world. Therefore, in this work we explore closing the loop between learn-ing the connection between perception and action via bridging the gap between computervision, pattern recognition and symbolic knowledge discovery.The framework presented below is evaluated in the domain of simple table-top games.In this domain the system was able to learn complete protocols for the rules of the games,when different verbal utterances are made and also some aspects of the dynamics involvedin playing the game (for instance, when objects should be placed on the table). The en-tire learning process is executed with minimal human intervention and assumes minimaldomain specific knowledge of the scenes or of game concepts. In earlier work [22], wedemonstrated that the same approach is capable of learning simple mathematical conceptssuch as numerical ordering and equality.1.1. The domain of table-top gamesWe have chosen to work in the domain of simple table-top games involving interactionof one or two players with a small number of visual objects and incorporating spokenutterances. The reason for choosing such scenarios is that games contain rich protocolsand their ‘complexity’ can be controlled by adding, excluding or modifying rules, actionsand/or objects in the domain. Moreover, it may be argued that many real-world social-interaction scenarios may be modelled as games [14], which suggests that our frameworkmay be relevant to the development of a fully autonomous system that could learn how tobehave in the real world.Experimental data is collected using two standard PCs, two webcams, and a microphonein the arrangement shown in Fig. 1. The games used in this work are described in greaterdetail in Section 4. Briefly, the following three games are played:\fC.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136105Fig. 1. Example of the data collection phase. A game is played on the table between two players. One camerapoints down at the table, and another captures the face of the participant to be replaced by the synthetic agent.The audio is captured by a microphone worn by this participant.(1) SNAP1. A generalised game of snap where two cards are played simultaneously, fol-lowed by an utterance dependent upon the figures on the cards. The utterances areeither “colour” (when only the colours in the figures are the same), “shape” (whenonly the shapes in the figures are the same), “same” (when shape and colour match)or “nothing” (if no feature in the figures match to each other). The cards are removed,and “play” is then uttered indicating to play the next two cards.(2) SNAP2. A variation of the above game where cards are placed one on top of anotherand the resulting utterance is dependent upon the card which is visible, and the card atthe previous time step.(3) Paper-scissors-stone (PSS). Played with two sets of three cards each depicting one ofpaper, scissors or stone. Two players simultaneously select one of the object cards andplace them on the table. When the two figures in the cards are perceived, utterances“win”, “lose” and “draw” are spoken by one of the players (the one to be simulated bythe synthetic agent). This player says “win” when its card beats the one shown by theother player—paper beats (wraps) stone, scissors beats (cuts) paper, and stone beats(blunts) scissors. A “play” is uttered when there are no cards on the table.1.2. OverviewAn overview of the framework is illustrated in Fig. 2. Firstly, attention mechanisms arenecessary to pick out salient (interesting) sounds, objects and features from the audio andvisual input streams obtained in a setup similar to that shown in Fig. 1.There are two phases of operation of our system: training and execution.• In the training (or learning) phase, the synthetic agent observes the world, withoutparticipating. In this phase, class induction is performed on the blobs and sounds thatare perceived, and class models are formed, which are used for classification of all theperceptual objects that have been seen in training. These are used to form a symbolic\f106C.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136Fig. 2. Overview of the learning framework for the synthetic agent.data description of the input signals. Protocol induction is then performed on thissymbolic data stream, from which a set of protocol models (or rules) is formed.• In the execution (or play) phase, the synthetic agent participates in games using thelearned protocol models. An inference engine is used for protocol instantiation to in-fer the synthetic agent’s (vocal) response to the current symbolic description of theworld.We assume no knowledge about the type of objects or sounds presented to the sys-tem. Therefore, unsupervised clustering of both the audio and visual feature vectors isperformed. Models are learned, based on this clustering, which can classify the perceptualinputs into classes. This provides a symbolic description of the input signals.Protocol models are represented as ordered sets of definite clauses expressed in Prologsyntax. This provides the necessary flexibility to represent the relations between objectsand actions that we require. Others have previously demonstrated the utility of (subsetsof) first-order predicate logic in high-level scene interpretation (e.g., Neumann and Weiss[30]).Inductive Logic Programming (ILP) in the form of PROGOL [28] is used for protocolinduction. The reason for choosing PROGOL resides in its capability to construct theoriesfrom only (possibly noisy) positive examples. This coincides with our aim to learn proto-col behaviour from observation in an unsupervised way. Moreover, ILP enables conceptgeneralisation (e.g., to extend rules learned from observation of certain objects to unseenentities) and for the knowledge learned to be presented in a format that allows us to assessits ‘complexity’ and accuracy, besides serving as tools for further reasoning—the symbolictheories obtained are used in this work to construct equivalence classes between utterancesin order to cope with over-clustering of the utterances in the audio signal.Once learning is complete, the synthetic agent can process the perceptual inputs andinfer the appropriate action response to the state of the world in real-time. The interactiveagent grounds learned perceptual models and learn",
            {
                "entities": [
                    [
                        2141,
                        2169,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 140–164Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMeasuring inconsistency in probabilistic logic: rationality postulates and Dutch book interpretation∗,1, Marcelo Finger 2Glauber De BonaDepartment of Computer Science, Institute of Mathematics and Statistics, University of São Paulo, Brazila r t i c l e i n f oa b s t r a c tArticle history:Received 25 October 2014Received in revised form 13 June 2015Accepted 15 June 2015Available online 19 June 2015Keywords:Probabilistic reasoningProbabilistic logicInconsistency measuresInconsistency measures have been proposed as a way to manage inconsistent knowledge bases in the AI community. To deal with inconsistencies in the context of conditional probabilistic logics, rationality postulates and computational efficiency have driven the formulation of inconsistency measures. Independently, investigations in formal epistemol-ogy have used the betting concept of Dutch book to measure an agent’s degree of incoherence. In this paper, we show the impossibility of joint satisfiability of the proposed postulates, proposing to replace them by more suitable ones. Thus we reconcile the rationality postulates for inconsistency measures in probabilistic bases and show that several inconsistency measures suggested in the literature and computable with linear programs satisfy the reconciled postulates. Additionally, we give an interpretation for these feasible measures based on the formal epistemology concept of Dutch book, bridging the views of two so far separate communities in AI and Philosophy. In particular, we show that incoherence degrees in formal epistemology may lead to novel approaches to inconsistency measures in the AI view.© 2015 Elsevier B.V. All rights reserved.1. Introduction“when you can measure what you are speaking about, you know something about it; but when you cannot [. . .] your knowledge is of a meagre and unsatisfactory kind;”— Lord Kelvin [45]Measuring has been a prominent activity in advancing scientific and technological development. Not all measures are alike and good measures express intuitive notions in a useful way. In the field of deductive logical reasoning, one usually has an intuition expressing that one theory is more inconsistent than other, capturing the idea that the “effort” to restore consistency is greater in one case than the other. Also, no effort is required to restore the consistency of a consistent theory.Based on those intuitions, there are several proposals for measuring inconsistency in knowledge bases over purely logical languages [19]. Some of these proposals involved attaching probabilities to formulas [29], or the combination of inconsis-tency factors [20]. Some of these measures are discrete or even qualitative, while others are more like distances, but all these measures have to behave like an information measure [6]. And to adhere to certain intuitions, a series of postulates * Corresponding author.E-mail addresses: debona@ime.usp.br (G. De Bona), mfinger@ime.usp.br (M. Finger).1 Supported by CAPES grant.2 Partially supported by CNPq grant PQ 306582/2014-7.http://dx.doi.org/10.1016/j.artint.2015.06.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\fG. De Bona, M. Finger / Artificial Intelligence 227 (2015) 140–164141for inconsistency measures for purely logical knowledge bases were proposed [21,22]; for example, the consistency postulatestates that the inconsistency measure of a consistent base is 0.Purely logical bases are known to be expressively limited in representing uncertainty required for real-world applications. In this work, we are interested in measuring the inconsistency of knowledge bases over logical probabilistic languages, which combine the deductive power of logical systems with the well-founded theory of probability. This kind of extension of purely logical systems can be traced back to the work of Boole [2], but has gained attention of AI researchers since the work of Nilsson [33], and has been extended to conditional probabilistic logic [37].In AI, one of the main uses of measuring inconsistency in a knowledge base is to guide the consolidation of inconsistent pieces of information. Within propositional logic, Grant and Hunter [13] showed how inconsistency measures can be used to direct the stepwise resolution of conflicts via the weakening or the discarding of formulas.In probabilistic bases, inconsistencies are rather common, specially when knowledge is gathered from different sources. To fix these probabilistic knowledge bases, one can, for instance, delete pieces of information, or change the probabilities’ numeric values (or intervals). In this case, an inconsistency measure helps one to detect if a change approximates consis-tency or not. In other areas, inconsistency measures for probabilistic logic have found applications in merging conflicting opinions, leading to an increased predictive power [47,25], and in quantifying the incoherence of procedures from classical statistical hypothesis testing [41].Example 1.1. Consider we are devising an expert system to assist medical diagnosis. Suppose a group of experts on a disease D is required to quantify the relationship between D and its symptoms. Suppose three conditional probabilities are presented:• the probability of a patient exhibiting symptom S1 given he/she has disease D is 50%;• the probability of a patient exhibiting symptom S2 given he/she exhibits symptom S1 and has disease D is 80%;• the probability of a patient exhibiting symptom S2 given he/she has disease D is 30%.A knowledge engineer, while checking those facts, finds that they are inconsistent: according to the first two items, the probability of symptom S2, given disease D, should be at least 50% × 80% = 40%, instead of 30%. He does not even know where each probability came from, but plans to change the probabilities, since consistency is a requirement. How should he proceed? Which probabilities is the degree of inconsistency most sensitive to? Once chosen which number to change, should it be raised or lowered in order to approximate consistency? These are the kind of questions an inconsistency measure can help to answer.The issue of measuring inconsistency in probabilistic bases has more recently been tackled by Thimm [44], Muiño [31]and Potyka [34], who developed measures based on distance minimization, tailored to the probabilistic case. Potyka focused on computational aspects, looking for efficiently computable measures [34]. Muiño was driven by the CADIAG-2 knowledge base, presenting its infinitesimal inconsistency degree, however based on a different semantics [31]. Thimm [44] adapted Hunter and Konieczny’s [22] desirable properties for inconsistency measures to the probabilistic setting, developing mea-sures that satisfy a set of rationality postulates.It was Thimm [44] who realized the importance of continuity as a Postulate for the probabilistic case, namely the property that a small change in the probability associated to formula (absent in the purely logical case) should lead only to small changes in the inconsistency measure. It was just natural that, (conditional) probabilistic logic being an extension of the classical cases, the continuity postulate was simply added to the postulates defining classical inconsistency measures.In this work, we argue that continuity cannot hold together with classical postulates such as consistency and indepen-dence, and some of these postulates must be abandoned or exchanged for other ones that restore joint satisfiability. So the first contribution of this work is that we identify and fix the possible problem with the postulates proposed by Thimm [44].Another contribution lies in showing that these measures of inconsistency have a direct counterpart in formal epistemol-ogy research over the coherence of an agent’s degrees of belief. It is known that inconsistent probabilistic beliefs correspond to a set of bets with guaranteed loss to the agent, which is called a “Dutch Book” [8,27]. This agent’s incoherence has been measured by formalizing the intuition that the greater the inconsistency the greater the corresponding sure loss, and vice versa [40,43]. Thus we interpret these incoherence measures via guaranteed losses as inconsistency measures, showing that existing measures based on distance minimization correspond to guaranteed losses that quantify an agent’s incoherence. To the best of our knowledge, no clear link has been shown between these two areas.Here is a bird’s-eye view of how we achieve these goals.After introducing probabilistic knowledge bases in Section 2, this paper develops three main contributions, in three different sections, dealing closely with three other works. In the following, we overview such contributions, together with the organization of the paper and their relation to the existing literature.Inconsistency measures for probabilistic knowledge bases were analyzed via rationality postulates by Thimm [44]. In Section 3, we argue for the incompatibility of such desirable properties. Firstly, we introduce the problematic postulates: consistency, independence and continuity. The independence postulate claims that a free conditional — a (conditional) prob-ability assignment that does not belong to any minimal inconsistent set — can be rule out without changing the degree of \f142G. De Bona, M. Finger / Artificial Intelligence 227 (2015) 140–164Table 1Inconsistency measures, where they are defined and a brief description.NotationIpIεpIsumSSKImaxSSKIa,sumSSK, Ib,sumSSKIa,maxSSK, Ib,maxSSKSection4.35.15.25.25.35.3ExplanationMinimum p-norm of the vector composed by the adjustments on the probability bounds to reach consistency.Minimum p-norm of the vector composed by the violations of each restriction corresponding to a probability bound. In the unconditional case, IεMaximum sure loss in a Dutch book if the sum of the stakes’ absolute",
            {
                "entities": [
                    [
                        3199,
                        3227,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 162 (2005) 89–120www.elsevier.com/locate/artintCompiling problem specifications into SAT ✩Marco Cadoli a,∗, Andrea Schaerf ba Dipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”,Via Salaria 113, I-00198 Roma, Italyb Dipartimento di Ingegneria Elettrica, Gestionale e Meccanica, Università di Udine,Via delle Scienze 208, I-33100 Udine, ItalyReceived 20 November 2001; accepted 21 January 2004Available online 10 December 2004AbstractWe present a compiler that translates a problem specification into a propositional satisfiabilitytest (SAT). Problems are specified in a logic-based language, called NP-SPEC, which allows thedefinition of complex problems in a highly declarative way, and whose expressive power is such asto capture all problems which belong to the complexity class NP. The target SAT instance is solvedusing any of the various state-of-the-art solvers available from the community. The system obtainedis an executable specification language for all NP problems which shows interesting computationalproperties. The performance of the system has been tested on a few classical problems, namelygraph coloring, Hamiltonian cycle, job-shop scheduling, and on a real-world scheduling application,namely the tournament scheduling problem. 2004 Elsevier B.V. All rights reserved.Keywords: Automatic generation of problem reformulation; Executable specifications; SAT problem;NP-complete problems✩ This paper is an extended and revised version of “Compiling problem specifications into SAT”, whichappeared in Proceedings of the European Symposium on Programming (ESOP 2001), Lecture Notes in ComputerScience, vol. 2028, Springer, Berlin, 2001, pp. 387–401.* Corresponding author.E-mail addresses: cadoli@dis.uniroma1.it (M. Cadoli), schaerf@uniud.it (A. Schaerf).URLs: http://www.dis.uniroma1.it/~cadoli (M. Cadoli), http://www.diegm.uniud.it/schaerf (A. Schaerf).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.006\f90M. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–1201. IntroductionWe present a system for writing and executing specifications for search problems,which makes use of NP-SPEC, a highly declarative specification language. NP-SPEC has aDATALOG-like syntax, i.e., PROLOG with no function symbols. Its semantics is based onthe notion of model minimality, an extension of the well-known least-fixed-point seman-tics of the Horn fragment of first-order logic [1]. NP-SPEC allows the user to express everyproblem belonging to the complexity class NP [2], which includes many notorious prob-lems interesting for real-world applications. Restriction of expressiveness to NP guaranteestermination and helps to obtain efficient executions.The core of our system is the compiler, called SPEC2SAT, that translates problemspecifications written in NP-SPEC into instances of the propositional satisfiability problem(SAT). An instance π of the original problem is translated into a formula T of propositionallogic in conjunctive normal form, in such a way that T is satisfiable if and only if π has asolution. Moreover, the system constructs the solution of π from the variable assignmentsthat satisfy T .A specification S of π is a set of metarules defining the search space, plus a set of rulesdefining the admissibility function. Both metarules and rules are transformed into a set ofclauses of T encoding their semantics. The translation of rules is based on their groundinstantiation over the Herbrand universe. Our algorithm for instantiation uses complexauxiliary data structures to avoid the generation of useless clauses insofar as possible.The approach of translation into SAT is motivated by the huge amount of research de-voted to such a problem in recent years (see, e.g., [3]), and the number of fast solversavailable from the research community. Such solvers, both complete and incomplete ones,are able to solve instances of hundreds of thousands of clauses in a few seconds, a resultinconceivable only a few years ago. In addition, the community working on SAT is stillvery active, and better and better SAT solvers are expected in the future.SAT is the prototypical NP-complete problem, and every instance π of a problem inNP can be translated into an instance of SAT of polynomial size in the size of π . In prac-tice, this idea has been exploited for a number of years in problems such as planning[4–6], scheduling [7], theorem proving in finite algebra [8], generation of test patterns forcombinatorial circuits [9], and cryptography [10]. Those papers showed that translating aproblem into SAT can give good performance in the resulting system, as compared withstate-of-the-art dedicated solvers.The shortcoming of those previous works is that the translator had to be done completelyby hand for each problem. Conversely, we aim at a system that automatically translates anyNP problem into SAT using the simple and declarative language NP-SPEC.In terms of performance, NP-SPEC obviously cannot outperform state-of-the-art solversof well-studied problems. However, we believe that it is a valuable tool for developing fastprototypes for new problems, or variations of known ones for which no specific solver isavailable. Nevertheless, experimental results show that our system is able to solve medium-size instances of various classical problems in reasonable time. In addition, it works muchfaster than the original NP-SPEC engine [11] which is based on a translation of the inputspecification in the logic programming language PROLOG.\fM. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–12091The paper is organized as follows. In Section 2 we introduce the language NP-SPECand recall the state of the art on SAT technology. In Section 3 we describe the compiler.In Section 4 we illustrate the performance of the system in four problems: graph color-ing, Hamiltonian cycle, job-shop scheduling, and tournament scheduling. Related work isdiscussed in Section 5. Finally, in Section 6 we draw conclusions and discuss future work.2. Preliminaries2.1. Overview of the NP-SPEC languageAs a first example, we show an NP-SPEC program for the Hamiltonian path NP-complete problem [2, Prob. GT39, p. 199], i.e., the problem where the input is a graphand the question is whether a traversal exists that touches each node exactly once.DATABASEn = 6;edge = {(1,2),(3,1),(2,3),(6,2),(5,6),(4,5),(3,5),// no. of nodesSPECIFICATION(1,4),(4,1)};Permutation({1..n},path).fail <-- path(X,P), path(Y,P+1), NOT edge(X,Y).// H1// H2The following comments are in order:• The input graph is defined in the DATABASE section, which is generally provided in aseparate file.• In the search space declaration (metarule H1) the user declares the predicate symbolpath to be a “guessed” one, implicitly of arity 2. All other predicate symbols are,by default, not guessed. Being guessed means that we admit all extensions for thepredicate, subject to the other constraints.• path is declared to be a permutation of the finite domain {1..n}. This means that itsextension must represent a permutation of order 6. As an example, {(1, 5), (2, 3), (3, 6),(4, 2), (5, 1), (6, 4)} is a valid extension.• Comments can be inserted using the symbol “//”.• Rule H2 is the constraint that permutations must obey in order to be Hamiltonian paths:a permutation fails, i.e., it is not valid, if two nodes X and Y which are adjacent inthe permutation are not connected by an edge. X and Y are adjacent because they holdplaces P and P+1 of the permutation, respectively.Running this program on the NP-SPEC compiler produces the following output:path: (1, 1) (2, 5) (3, 6) (4, 2) (5, 3) (6, 4)which means “1 is the first node in the path, 4 is the second node in the path, . . . , 3 is thesixth node in the path”, and is indeed an Hamiltonian path.\f92M. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–120More formally, an NP-SPEC program consists of a DATABASE section and a SPEC-IFICATION section (cf. Appendix A for the complete syntax). The DATABASE sectionincludes:• Definition of extensional relations of the kindr = {t1,...,tn},where r is the input relation name and each ti is a tuple of the same arity as r. Theonly constant symbols allowed in tuples are integers and strings.• Definition of constants.The SPECIFICATION section consists of two parts:• A search space declaration, which corresponds to the definition of the domain of theguessed predicates. In basic NP-SPEC it is a sequence of declarations of the form:(1) Subset(<domain>, <predicate_id>).(2) Permutation(<domain>, <predicate_id>).(3) Partition(<domain>, <predicate_id>, n).(4) IntFunc(<domain>, <predicate_id>, min..max).where <predicate_id> is the name of the guessed predicate and <domain> is afinite set defined either as an input relation, or as an enumeration, or by means of union(‘+’), intersection (‘*’), difference (‘-’), and Cartesian product (‘><’).<domain> identifies the domain upon which the extension of the predicate isguessed, and, for Subset, it must have the same arity as <predicate_id>. In theother cases <predicate_id> is a guessed predicate of arity equal to the arity aof <domain> plus 1. Such a declaration means that <predicate_id> can haveall extensions such that the first a arguments coincide with a member of <domain>,while the last one depends on the metapredicate. In particular:− For Permutation the extension of <predicate_id> must represent a bijec-tive function from <domain> to the interval {1..c}, where c is the cardinality of<domain>.− Declarations using metapredicate Partition have a further integer-valued argu-ment n that states the number of subsets in which the domain must be partitioned.The extension of <predicate_id> must represent a function from <domain>to the interval {1..n}, the last argument being any element of such an interval.Subset is indeed the special case of Partition in which n = 2, but the syn-tax is different (declaration Subset(<domain>",
            {
                "entities": [
                    [
                        1998,
                        2026,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 211 (2014) 34–50Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA branch and prune algorithm for the computation ofgeneralized aspects of parallel robots ✩S. Caro a, D. Chablat a, A. Goldsztejn b,∗, D. Ishii c, C. Jermann da CNRS, IRCCyN, Nantes, Franceb CNRS, LINA (UMR-6241), Nantes, Francec Tokyo Institute of Technology, Tokyo, Japand Université de Nantes, LINA (UMR-6241), Nantes, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 18 April 2013Received in revised form 6 February 2014Accepted 8 February 2014Available online 18 February 2014Keywords:Numerical constraintsParallel robotsSingularitiesGeneralized aspectsParallel robots enjoy enhanced mechanical characteristics that have to be contrasted witha more complicated design. In particular, they often have parallel singularities at someposes, and the robots may become uncontrollable, and could even be damaged, in suchconfigurations. The computation of the connected components in the set of nonsingularreachable configurations, called generalized aspects, is therefore a key issue in their design.This paper introduces a new method, based on numerical constraint programming, tocompute a certified enclosure of the generalized aspects. Though this method doesnot allow counting their number rigorously, it constructs inner approximations of thenonsingular workspace that allow commanding parallel robots safely. It also provides alower-bound on the exact number of generalized aspects. It is moreover the first generalmethod able to handle any parallel robot in theory, though its computational complexitycurrently restricts its usage to robots with three degrees of freedom. Finally, the constraintprogramming paradigm it relies on makes it possible to consider various additionalconstraints (e.g., collision avoidance), making it suitable for practical considerations.© 2014 Elsevier B.V. All rights reserved.1. IntroductionMechanical manipulators, commonly called robots, are widely used in the industry to automatize various tasks. Theyare mechanical assemblies of rigid links connected by mobile joints. Some joints are actuated and they allow commandingthe robot operating link, called its end-effector (or platform). One key characteristic of a robot is its reachable workspace,informally defined as the set of poses its end-effector can reach. Indeed, its size defines the scope of operational trajectoriesthe robot can perform. The workspace can be computed from the set of possible command inputs using the kinematicmodel of the robot, a system of equations relating the commands and the pose coordinates. The size of this system is oftenreferred to as the degrees of freedom (DOF) of the robot.Robots comply with either a serial or a parallel (or possibly a hybrid) assembly, whether its links are connected inseries or in parallel. Parallel robots [1,2] present several advantages with respect to serial ones: They are naturally stiffer,leading to better accuracy with larger loads, and allow high speed motions. These advantages are contrasted by a more✩This paper is an invited revision of a paper first published at the 18th International Conference on Principles and Practice of Constraint Programming(CP 2012).* Corresponding author.http://dx.doi.org/10.1016/j.artint.2014.02.0010004-3702/© 2014 Elsevier B.V. All rights reserved.\fS. Caro et al. / Artificial Intelligence 211 (2014) 34–5035complicated design that yields difficulties for the computation and the analysis of their workspace. First, one pose of therobot’s end-effector may be reached by several actuated joint commands (which correspond to different working modes), andconversely one input command may lead to several poses of its end-effector (which correspond to different assembly modes).Second, parallel robots generally have parallel singularities [3], i.e., specific configurations where they become uncontrollableand can even be damaged.One central issue in designing parallel robots is to compute its nonsingular workspace, together with the correspondingcommands, so that the robot can be safely operated. This amounts to computing the connected components of the set ofnonsingular configurations, called generalized aspect in [4]. This computation must be certified in terms of non-singularityand connectivity in order to guarantee safe operations. Few frameworks provide such certifications, among which algebraiccomputations and interval analysis. Algebraic methods are in general too expensive and apply only for polynomial systems.Still, the cylindrical algebraic decomposition was used in [5] with a connectivity analysis limited to robots with 2 DOFs.Though generalized aspects are mathematical objects that cannot, in general, be computed exactly using numerical meth-ods, interval analysis allows the rigorous computation of some approximation. It was used in [6] for robots having a singlesolution to their inverse kinematic problem; Though limited, this method can still tackle important classes of robots likethe Stewart platform. A quad-tree with certification of nonsingularity was built in [7] for some planar robots with 2 DOFs;This method can be extended to higher dimensional robots, but it requires the a priori separation of working modes by adhoc inequalities, and is not certified with respect to connectivity. Finally, the two works [8,9] propose algorithms based oninterval analysis to analyze the connectivity of set defined by inequalities constraints, but cannot be extended to equalityconstraints. In particular, the developments presented in the present paper somehow extend the interval-based path plan-ning method proposed in [8] for sets defined by inequality constraints only, to manifolds defined by equality, disequalityand inequality constraints.In this paper we propose a branch and prune algorithm incorporating the certification of the solutions and of their con-nectivity. This allows a fully automated and certified computation of what we call connected sets of nonsingular configurations(CSNCs), i.e., certified approximations of generalized aspects, from the model of arbitrary parallel robots, including robotswith multiple solutions to their direct and inverse kinematic problems, without requiring any a priori study to separate theirworking modes. Though the proposed method does not allow counting the number of CSNCs rigorously, it constructs in-ner approximations of the nonsingular workspace that allow commanding parallel robots safely. Although less important inpractice, a more accurate and costly connectivity analysis is also proposed, which enables separating non-connected CSNCs,hence providing a lower-bound on the exact number of generalized aspects. The algorithm is applicable to robots with anarbitrary number of DOF, although the complexity of the computations currently restricts its application to robots withthree DOFs. It is also very flexible as it can naturally take into account additional constraints such as, e.g., arm collisions,obstacle avoidance or joint limits. It is thus the first method able to handle such a large class of robots for the problem ofcomputing connected sets of nonsingular configurations. Its main limitation is its performances, due to the combinatorialexplosion of the number of computed boxes with the dimension of the problem and the prescribed computational precision.As a consequence, we have applied it to planar robots only at the moment.A motivating example is presented in Section 2 followed by some preliminaries about numerical constraint program-ming and robotics in Section 3. The proposed algorithm for certified singularity free connected components computation ispresented in Section 4. Finally, experiments on planar robots with 2 and 3 degrees of freedom are presented in Section 5.Notations. Boldface letters denote vectors. Thus f(x) = 0 denotes a system of equations f on a vector of variables x:f 1(x1, . . . , xn) = 0, . . . , fk(x1, . . . , xn) = 0. The Jacobian matrix of f(x) with respect to the subset xof the variables x is de-noted Fx(cid:3) (x). Interval variables are denoted using bracketed symbols, e.g., [x] = [x, x] := {x ∈ R | x (cid:2) x (cid:2) x}. Hence, [x] is aninterval vector (box) and [ A] = ([ai j]) is an interval matrix. IR denotes the set of intervals and IRn the set of n-dimensionalboxes. For an interval [x], we denote wid[x] := x − x its width, int[x] := {x ∈ R | x < x < x} its interior, and mid[x] := (x + x)/2its midpoint. These notations are extended to interval vectors.(cid:3)2. Motivating exampleDescription. Consider the simple PRRP1 planar robot depicted in Fig. 1 (left), which involves two prismatic joints (grayrectangles) sliding along two perpendicular directions. These prismatic joints are connected through three rigid bars (blacklines) linked by two revolute joints (circles) that allow free rotations between the rigid bars. The lengths of the prismaticjoints are respectively denoted by x and q, the end-effector pose x being along the horizontal direction and the commandq corresponding to the height along the vertical direction. Fig. 1 (left) shows one generic configuration of the robot. Notethat there is another symmetric (negative) pose x associated to the same command q, which is typical of parallel robots.From this configuration, every (vertical) change in q induces a unique corresponding (horizontal) change in x, hence thisconfiguration is nonsingular. Fig. 1 (right) shows two singular configurations. In the plain green pose (where the robot’s mainrigid bar is horizontal), increasing or decreasing the command q both entails a decrease of x. In the dashed red pose (where1 In robotics, manipulators are typically named according to the sequence of joints they are made of, e.g., P stands for prismatic joint and R stands forrevolute joint, actuated joints being underlined.\f36S. Caro et al. / Artificial Intelligence 211 (2014) 34–50Fig. 1. The PRRP in a generic pose (le",
            {
                "entities": [
                    [
                        3320,
                        3348,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 320 (2023) 103922Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintGoSafeOpt: Scalable safe exploration for global optimization of dynamical systems ✩Bhavya Sukhija a,∗Sebastian Trimpe b, Dominik Baumann c,da Department of Computer Science, ETH Zürich, Switzerlandb Institute for Data Science in Mechanical Engineering, RWTH Aachen University, Germanyc Department of Electrical Engineering and Automation, Aalto University, Espoo, Finlandd Department of Information Technology, Uppsala University, Sweden, Matteo Turchetta a, David Lindner a, Andreas Krause a, a r t i c l e i n f oa b s t r a c tArticle history:Received 31 March 2022Received in revised form 12 April 2023Accepted 14 April 2023Available online 20 April 2023Keywords:Model-free learningBayesian optimizationSafe learningLearning optimal control policies directly on physical systems is challenging. Even a single failure can lead to costly hardware damage. Most existing model-free learning methods that guarantee safety, i.e., no failures, during exploration are limited to local optima. This work proposes GoSafeOpt as the first provably safe and optimal algorithm that can safely discover globally optimal policies for systems with high-dimensional state space. We demonstrate the superiority of GoSafeOpt over competing model-free safe learning methods in simulation and hardware experiments on a robot arm.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionThe increasing complexity of modern dynamical systems often makes deriving mathematical models for traditional model-based control approaches forbiddingly involved and time-consuming. Model-free reinforcement learning (RL) meth-ods [1] are a promising alternative as they learn control policies directly from data. To succeed, they need to explore the system and its environment. Without a model, this can be risky and unsafe. Since modern hardware such as robots are ex-pensive and their repairs are time-consuming, safe exploration is crucial to apply model-free RL in real-world problems. This paper proposes GoSafeOpt, a model-free learning algorithm that can search for globally optimal policies while guaranteeing safe exploration with high probability.1.1. Related workAdvances in machine learning have motivated the usage of model-free RL algorithms for obtaining control policies [2–6]. However, directly applying these methods to policy optimization presents two major challenges: (i) Machine learning algorithms often require large amounts of data. In learning control, such data is often gathered by conducting experiments ✩This paper is part of the Special Issue: “Risk-aware Autonomous Systems: Theory and Practice”.* Corresponding author.krausea@ethz.ch (A. Krause), trimpe@dsme.rwth-aachen.de (S. Trimpe), dominik.baumann@aalto.fi (D. Baumann).E-mail addresses: bhavya.sukhija@inf.ethz.ch (B. Sukhija), matteo.turchetta@inf.ethz.ch (M. Turchetta), david.lindner@inf.ethz.ch (D. Lindner), https://doi.org/10.1016/j.artint.2023.1039220004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fB. Sukhija, M. Turchetta, D. Lindner et al.Artificial Intelligence 320 (2023) 103922Fig. 1. Illustrative example with disjoint safe regions in the policy space. The blue line depicts the objective, and the orange line is the constraint function. There are two safe regions that are marked in green. SafeOpt cannot explore the global optimum if it is initialized in the left region. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)with physical systems, which is time-consuming and wears out the hardware. (ii) Learning requires exploration, which can lead to unwarranted and unsafe behaviors.Challenges (i) and (ii) can be addressed jointly by Bayesian optimization (BO) with constraints. BO [7] is a class of black-box global optimization algorithms, that has been used in a variety of works [8–11] to optimize controllers in a sample-efficient manner. In constrained BO, there are two main classes of methods. On the one hand, approaches like [12–15] find safe solutions but allow unsafe evaluations during training. Herein, we focus on approaches that guar-antee safety at all times during exploration, which is crucial when dealing with expensive hardware. SafeOpt [16] and safe learning methods that emerged from it, e.g., [17–19], guarantee safe exploration with high probability by exploiting properties of the constraint functions, e.g., regularity. Unfortunately, these methods are limited to exploring a safe set con-nected with a known initial safe policy. Therefore, they could miss the global optimum in the presence of disjoint safe regions in the policy space (see Fig. 1). Disjoint safe regions appear when learning an impedance controller for a robot arm, as we show in our experiments and in many other applications [8,20,21]. To address this limitation [21] proposesGoSafe, which can provably and safely discover the safe global optimum in the presence of disjoint safe regions under mild conditions. To achieve this, it learns safe backup policies for different states and uses them to preserve safety when evaluating policies outside of the safe set. Specifically, it switches between actively exploring local safe regions in the state and policy space and safe global exploration. However, the active exploration in the state and policy space requires a coarse discretization of the space and is infeasible for all but the simplest systems with low-dimensional state spaces, [22] argues that dimension d > 3 is already challenging. As a result, GoSafe cannot only handle most real-world dynami-cal systems, and is restricted to impractical systems with low-dimensional state spaces. The concept of switching between two exploration stages is also pursued in the stagewise safe optimization algorithm proposed in [23]. However, also [23]is restricted to an optimum connected to a safe initialization. Lastly, the general idea of learning backup policies is related to safety filters and control barrier functions [24–26]. Nevertheless, those methods require either availability or learning of a dynamics model besides learning the policy and are, therefore, model-based. In this work, we focus on a model-free approach.1.2. ContributionsThis work presents GoSafeOpt, the first model-free algorithm that can globally search optimal policies for safety-critical, real-world dynamical systems, i.e., systems with high-dimensional state spaces. GoSafeOpt does not discretize and actively explores the state space. Therefore, it overcomes the main shortcomings and restrictions of GoSafe, while still performing safe global exploration. This makes GoSafeOpt the first and only model-free safe global exploration algorithm for real-world dynamical systems. Crucially, GoSafeOpt leverages the Markov property of the system’s state to learn backup policies which it uses to guarantee safety when evaluating policies outside the safe set. This novel mechanism for learning backup policies does not depend on the dimension of the state space. We provide high-probability safety guarantees for GoSafeOpt and we prove that it recovers the safe globally optimal policy under assumptions that hold for many practical cases. Finally, we validate it in both simulated and real safety-critical path following experiments on a robotic arm (see Fig. 2), which is prohibitive for GoSafe, the only competing model-free global safe search method. Further, we show that GoSafeOpt achieves considerably better performance than SafeOpt, a state-of-the-art method for local model-free safe policy search, and its high-dimensional variants. Table 1 compares GoSafeOpt to SafeOpt and GoSafe in terms of safety guarantees, scalability, global exploration, and sample efficiency. It shows that GoSafeOpt is the only method that can perform sample-efficient global exploration in high-dimensional systems while providing safety guarantees.2\fB. Sukhija, M. Turchetta, D. Lindner et al.Artificial Intelligence 320 (2023) 103922Fig. 2. Franka Emika Panda; seven degrees of freedom robot arm used for our evaluations.Table 1Comparison of GoSafeOpt and prior work on safe exploration based on their safety guarantees, scalability, global exploration, and sample efficiency.Safe explorationSAFEOPT [18]GOSAFE [21]GOSAFEOPT (ours)✓✓✓State space with dimension d > 3✓✗✓Global explorationSample efficient✗✓✓✓✗✓2. Problem settingWe consider a Lipschitz-continuous systemdx(t) = z(x(t), u(t)) dt,(1)where z(·) represents the unknown system dynamics, x(t) ∈ X ⊂ Rs is the system state and u(t) ∈ U ⊂ Rp is the input we apply to steer the system state to follow a desired trajectory xdes(t) ∈ X for all t ≥ 0. We assume that the system starts at a known initial state x(0) = x0.The control input u(t) we apply for a given state x(t) is specified by a policy π : X × A → U , with u(t) = π (x(t), a) :=π a(x(t)). The policy is parameterized by a ∈ A ⊂ Rd, where A is a finite parameter space.1 We encode our goal of following the desired trajectory xdes(t) through an objective function, f : A → R. Note, the trajectory of a deterministic system (1)is fully determined by its initial state x0 and the control policy. Therefore, the objective is independent of the state space X . We seek for a controller parametrization a ∈ A that optimizes f for a constant initial condition x0. Since the dynamics of the system in Eq. (1) is unknown, so is the objective f . Nonetheless, we assume we obtain a noisy measurement of f (a) at any a ∈ A by running an experiment. We aim at optimizing f from these measurements in a sample-efficient way. Additionally, to avoid the deployment of harmful policies, we formulate safety",
            {
                "entities": [
                    [
                        3154,
                        3182,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 250 (2017) 105–124Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLatent tree models for hierarchical topic detectionPeixian Chen a, Nevin L. Zhang a,∗Zhourong Chen a, Farhan Khawar aa Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kongb Ant Financial Services Group, Shanghai, Chinac Department of Mathematics and Information Technology, The Education University of Hong Kong, Hong Kong, Tengfei Liu b, Leonard K.M. Poon c, a r t i c l e i n f oa b s t r a c tArticle history:Received 2 May 2016Received in revised form 18 June 2017Accepted 26 June 2017Available online 29 June 2017Keywords:Probabilistic graphical modelsText analysisHierarchical latent tree analysisHierarchical topic detectionWe present a novel method for hierarchical topic detection where topics are obtained by clustering documents in multiple ways. Specifically, we model document collections using a class of graphical models called hierarchical latent tree models (HLTMs). The variables at the bottom level of an HLTM are observed binary variables that represent the presence/absence of words in a document. The variables at other levels are binary latent variables that represent word co-occurrence patterns or co-occurrences of such patterns. Each latent variable gives a soft partition of the documents, and document clusters in the partitions are interpreted as topics. Latent variables at high levels of the hierarchy capture long-range word co-occurrence patterns and hence give thematically more general topics, while those at low levels of the hierarchy capture short-range word co-occurrence patterns and give thematically more specific topics. In comparison with LDA-based methods, a key advantage of the new method is that it represents co-occurrence patterns explicitly using model structures. Extensive empirical results show that the new method significantly outperforms the LDA-based methods in term of model quality and meaningfulness of topics and topic hierarchies.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThe objective of hierarchical topic detection (HTD) is, given a corpus of documents, to obtain a tree of topics with more general topics at high levels of the tree and more specific topics at low levels of the tree. It has a wide range of potential applications. For example, a topic hierarchy for posts at an online forum can provide an overview of the variety of the posts and guide readers quickly to the posts of interest. A topic hierarchy for the reviews and feedbacks on a business/product can help a company gauge customer sentiments and identify areas for improvements. A topic hierarchy for recent papers published at a conference or journal can give readers a global picture of recent trends in the field. A topic hierarchy for all the articles retrieved from PubMed on an area of medical research can help researchers get an overview of past studies in the area. In applications such as those mentioned here, the problem is not about search because the user does not know what to search for. Rather the problem is about summarization of thematic contents and topic-guided browsing.* Corresponding author.E-mail address: lzhang@cse.ust.hk (N.L. Zhang).http://dx.doi.org/10.1016/j.artint.2017.06.0040004-3702/© 2017 Elsevier B.V. All rights reserved.\f106P. Chen et al. / Artificial Intelligence 250 (2017) 105–124Several HTD methods have been proposed previously, including the nested Chinese restaurant process (nCRP) [1,2], the hierarchical Pachinko allocation model (hPAM) [3,4], and the nested hierarchical Dirichlet process (nHDP) [5]. Those methods are extensions of latent Dirichlet allocation (LDA) [6]. Hence we refer to them collectively as LDA-based methods.In this paper, we present a novel HTD method called hierarchical latent tree analysis (HLTA). Like the LDA-based methods, HLTA is a probabilistic method and it involves latent variables. However, there are fundamental differences. The first differ-ence lies in the types of variables used in the models. In the LDA-based methods, observed variables are token variables (usually denoted as W d,n), and latent variables are constructs in a hypothetical document generation process, including a list of topics (usually denoted as β), a topic distribution vector for each document (usually denoted as θd), and a topic as-signment for each token in each document (usually denoted as Zd,n ). In contrast, each observed variable in HLTA stands for a word. It is a binary variable and represents the presence/absence of the word in a document. The latent variables in HLTA are considered as unobserved attributes of the documents. If we compare whether words occur in particular documents to whether students do well in various subjects, then the latent variables correspond to latent traits such as analytical skill, literacy skill, and general intelligence.In the LDA-based methods, each token variable stands for a location in a document, and its possible values are the words in a vocabulary. Here one cannot talk about conditional independence between words because the probabilities of all words must sum to 1. On the other hand, the output of HLTA is a tree-structured graphical model, where the word variables are at the leaves and the latent variables are at the internal nodes. Two word variables are conditionally independent given any latent variable on the path between them. Words that frequently co-occur in documents tend to be located in the same “region” of the tree. This fact is conducive to the discovery of meaningful topics and topic hierarchies. A drawback of using binary word variables is that word counts are discarded.The second difference lies in the definition and characterization of topics. Topics in the LDA-based methods are prob-abilistic distributions over a vocabulary. When presented to users, a topic is characterized using a few words with the highest probabilities. In contrast, topics in HLTA are clusters of documents. More specifically, all latent variables in HTLA are assumed to be binary. Just as the concept “analytical skill” partitions a student population into two soft clusters, with one cluster consisting of people with high analytic skill and the other consisting of people with low analytic skill, a latent variable in HLTA partitions a document collection into two soft clusters of documents. The document clusters are interpreted as topics. For presentation to users, a topic is characterized using the words that not only occur with high probabilities in topic but also occur with low probabilities outside the topic. The consideration of occurrence probabilities outside the topic is important because a word that occurs with high probability in the topic might also occur with high probability outside the topic. When that happens, it is not a good choice for the characterization of the topic.HLTA also differs from the LDA-based methods in several other ways. Those differences are more technical in nature and will be explained Section 4.The rest of the paper is organized as follows. We discuss related work in Section 2 and review the basics of latent tree models in Section 3. In Section 4, we introduce hierarchical latent tree models (HLTMs) and explain how they can be used for hierarchical topic detection. The HLTA algorithm for learning HLTMs is described in Sections 5–7. In Section 8, we present the results HTLA obtains on a real-world dataset and discuss some practical issues. In Section 9, we empirically compare HLTA with the LDA-based methods. Finally, we end the paper in Section 10 with some concluding remarks and discussions of future work.2. Related workTopic detection has been one of the most active research areas in Machine Learning in the past decade. The most commonly used method is latent Dirichlet allocation (LDA) [6]. LDA assumes that documents are generated as follows: First, a list {β1, . . . , βK } of topics is drawn from a Dirichlet distribution. Then, for each document d, a topic distribution θd is drawn from another Dirichlet distribution. Each word W d,n in the document is generated by first picking a topic Zd,n according to the topic distribution θd, and then selecting a word according to the word distribution β Zd,n of the topic. Given a document collection, the generation process is reverted via statistical inference (sampling or variational inference) to determine the topics and topic compositions of the documents.LDA has been extended in various ways for additional modeling capabilities. Topic correlations are considered in [7,3]; topic evolution is modeled in [8–10]; topic structures are built in [11,3,1,4]; side information is exploited in [12,13]; supervised topic models are proposed in [14,15]; and so on. In the following, we discuss in more details three of the extensions that are more closely related to this paper than others.The hierarchical Pachinko allocation model (hPAM) [3,4] is proposed as a method for modeling correlations among topics. It introduces multiple levels of supertopics on top of the basic topics. Each supertopic is a distribution over the topics at the next level below. Hence hPAM can also be viewed as an HTD method, and the hierarchical structure needs to be predetermined. To pick a topic for a token, it first draws a top-level topic from a multinomial distribution (which in turn is drawn from a Dirichlet distribution), and then draws a topic for the next level below from the multinomial distribution associated with the top-level topic, and so on. The rest of the generation process is the same as in LDA.The nested Chinese Restaurant Process (nCRP) [2] and the nested Hierarchical Dirichlet Process (nHDP) [5] are proposed as HTD methods. They assume that there is a true topic tree behind data. A prior distribution is placed over all possible trees using nCRP and nHDP respectively. An assumption is made as to how d",
            {
                "entities": [
                    [
                        3324,
                        3352,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 180–181 (2012) 20–33Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the approximation ability of evolutionary optimization withapplication to minimum set coverYang Yu a, Xin Yao b, Zhi-Hua Zhou a,∗a National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, Chinab Center of Excellence for Research in Computational Intelligence and Applications, School of Computer Science, University of Birmingham, Birmingham B15 2TT, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 23 December 2010Received in revised form 8 December 2011Accepted 8 January 2012Available online 10 January 2012Keywords:Evolutionary algorithmsApproximation algorithmApproximation ratiok-Set coverTime complexity analysisEvolutionary algorithms (EAs) are heuristic algorithms inspired by natural evolution. Theyare often used to obtain satisficing solutions in practice. In this paper, we investigate alargely underexplored issue: the approximation performance of EAs in terms of how closethe solution obtained is to an optimal solution. We study an EA framework named simpleEA with isolated population (SEIP) that can be implemented as a single- or multi-objectiveEA. We analyze the approximation performance of SEIP using the partial ratio, whichcharacterizes the approximation ratio that can be guaranteed. Specifically, we analyzeSEIP using a set cover problem that is NP-hard. We find that in a simple configuration,SEIP efficiently achieves an Hn-approximation ratio, the asymptotic lower bound, for theunbounded set cover problem. We also find that SEIP efficiently achieves an (Hk − k−18k9 )-approximation ratio, the currently best-achievable result, for the k-set cover problem.Moreover, for an instance class of the k-set cover problem, we disclose how SEIP, usingeither one-bit or bit-wise mutation, can overcome the difficulty that limits the greedyalgorithm.© 2012 Elsevier B.V. All rights reserved.1. IntroductionEvolutionary algorithms (EAs) [3] have been successfully applied to many fields and can achieve extraordinary perfor-mance in addressing some real-world hard problems, particularly NP-hard problems [16,18,17,4]. To gain an understandingof the behavior of EAs, many theoretical studies have focused on the running time required to achieve exact optimal so-lutions [14,33,26,2]. In practice, EAs are most commonly used to obtain satisficing solutions, yet theoretical studies of theapproximation ability of EAs have only emerged recently.He and Yao [15] first studied conditions under which the wide-gap far distance and the narrow-gap long distance problemsare hard to approximate using EAs. Giel and Wegener [12] investigated a (1 + 1)-EA for a maximum matching problem andfound that the time taken time to find exact optimal solutions is exponential but is only O (n2(cid:3)1/(cid:2)(cid:4)) for (1 + (cid:2))-approximatesolutions, which demonstrates the value of EAs as approximation algorithms.Subsequently, further results on the approximation ability of EAs were reported. For the (1 + 1)-EA, the simplest typeof EA, two classes of results have been obtained. On one hand, it was found that the (1 + 1)-EA has an arbitrarily poorapproximation ratio for the minimum vertex cover problem and thus also for the minimum set cover problem [11,28]. On theother hand, it was also found that (1 + 1)-EA provides a polynomial-time randomized approximation scheme for a subclass ofthe partition problem [32]. Furthermore, for some subclasses of the minimum vertex cover problem for which the (1 + 1)-EAgets stuck, a multiple restart strategy allows the EA to recover an optimal solution with high probability [28]. Another result* Corresponding author.E-mail addresses: yuy@lamda.nju.edu.cn (Y. Yu), x.yao@cs.bham.ac.uk (X. Yao), zhouzh@nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.01.001\fY. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3321for the (1 + 1)-EA is that it improves a 2-approximation algorithm to a (2 − 2/n)-approximation on the minimum vertexcover problem [10]. This implies that it might sometimes be useful as a post-optimizer.Recent advances in multi-objective (usually bi-objective) EAs have shed light on the power of EAs as approximationoptimizers. For a single-objective problem, multi-objective reformulation introduces an auxiliary objective function for whicha multi-objective EA is used as the optimizer. Scharnow et al. [30] first suggested that multi-objective reformulation couldbe superior to use of a single-objective EA. This was confirmed for various problems [24,25,11,27] by showing that while asingle-objective EA could get stuck, multi-objective reformulation helps to solve the problems efficiently.Regarding approximations, it has been shown that multi-objective EAs are effective for some NP-hard problems. Friedrichet al. [11] proved that a multi-objective EA achieves a (ln n)-approximation ratio for the minimum set cover problem, andreaches the asymptotic lower bound in polynomial time. Neumann and Reichel [23] showed that multi-objective EAs achievea k-approximation ratio for the minimum multicuts problem in polynomial time.In the present study, we investigate the approximation ability of EAs by introducing a framework called simple evolu-tionary algorithm with isolated population (SEIP), which uses an isolation function to manage competition among solutions.By specifying the isolation function, SEIP can be implemented as a single- or multi-objective EA. Multi-objective EAs previ-ously analyzed [22,11,23] can be viewed as special cases of SEIP in term of the solutions maintained in the population. Byanalyzing the SEIP framework, we obtain a general characterization of EAs that guarantee approximation quality.We then study the minimum set cover problem (MSCP), which is an NP-hard problem [9]. We prove that for the un-bounded MSCP, a simple configuration of SEIP efficiently obtains an Hk-approximation ratio (where Hk is the harmonicnumber of the cardinality of the largest set), the asymptotic lower bound [9]. For the minimum k-set cover problem, thisapproach efficiently yields an (Hk − k−18k9 )-approximation ratio, the currently best-achievable quality [13]. Moreover, for asubclass of the minimum k-set cover problem, we demonstrate how SEIP, with either one-bit or bit-wise mutation, canovercome the difficulty that limits the greedy algorithm.The remainder of the paper is organized as follows. After introducing preliminaries in Section 2, we describe SEIP inSection 3 and characterize its behavior for approximation in Section 4. We then analyze the approximation ratio achievedby SEIP for the MSCP in Section 5. In Section 6 we conclude the paper with a discussion of the advantages and limitationsof the SEIP framework.2. PreliminariesWe use bold small letters such as w, x, y, z to represent vectors. We denote [m] as the set {1, 2, . . . , m} and 2S as thei for the nth harmonic number. Note that Hn ∼ ln npower set of S, which consists of all subsets of S. We denote Hn =since ln n (cid:2) Hn (cid:2) ln n + 1.(cid:2)ni=11In this paper, we consider minimization problems as follows.Definition 1 (Minimization problem). Given an evaluation function f and a set of feasibility constraints C, find a solutionx ∈ {0, 1}n that minimizes f (x) while satisfying constraints in C. A problem instance can be specified by its parameters(n, f , C).In the definition of the minimization problem, solutions are represented in binary vectors. When the aim of a minimiza-tion problem is to find a subset from a universal set, we can equivalently use a binary vector to represent a subset, whereeach element of the vector indicates the membership of a corresponding element of the universe set. For example, givena universal set U = {1, 2, 3, 4, 5}, its subset S = {1, 3, 5} can be represented by a binary vector v = (1, 0, 1, 0, 1), and wedefine U (v) = S. Considering the equivalence between sets and binary vectors, we apply set operators (| · |, ∩, ∪, −, ⊆, ∈) tobinary vectors when there is no confusion. For example, |(1, 0, 1, 0, 1)| = 3, (1, 0, 1, 0, 1) ∩ (0, 0, 0, 1, 1) = (0, 0, 0, 0, 1), and(1, 0, 1, 0, 1) − (0, 0, 0, 1, 1) = (1, 0, 1, 0, 0). We denote x∅ = (0, . . . , 0) as the vector corresponding to the empty set.We investigate the minimum set cover problem (MSCP), which is an NP-hard problem.Definition 2 (Minimum set cover problem (MSCP)). Given a set of n elements U = [n] and a collection C = {S 1, S2, . . . , Sm} of mnonempty subsets of U , where each S i is associated with a positive cost w(S i), find a subset XS∈ X ∗ w(S)is minimized with respect to∗ ⊆ C such that(cid:2)(cid:3)S∈ X ∗ S = U .Using binary vector representation, we denote an instance of the MSCP by its parameters (n, w, C, U ), where |C| = m, byand w is the cost vector. The MSCP involves finding a vector xOPT , which is equivalent to its set representation Xsolving a constrained optimization problem∗xOPT = arg minx∈{0,1}m(cid:4)w · xS = U ,s.t.S∈C(x)\f22Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33where w · x is the inner product between vectors w and x, and C(x) denotes a set consisting of elements in the collectionC that are indicated by binary vector x.Definition 3 (Minimum k-set cover problem). An MSCP (n, w, C, U ) is a k-set cover problem if, for some constant k, it holdsthat |S| (cid:2) k for all S ∈ C , denoted as (n, w, C, U , k).A solution is called feasible if it satisfies all the constraints in C; otherwise, it is called an infeasible solution, or a partialsolution in this paper. Here, we assume that the evaluation function f is defined on the full input space, that is, it evaluatesall possible solutions regardless of their feasibility. For example, if we evaluate a solution x of the MSCP using w · x, thisevaluation function can be calculated for any solution.Given a minimization problem, we d",
            {
                "entities": [
                    [
                        3955,
                        3983,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 234–264www.elsevier.com/locate/artintConjunctive and disjunctive combination of belief functions inducedby nondistinct bodies of evidence ✩Thierry DenœuxUMR CNRS 6599 Heudiasyc, Université de Technologie de Compiègne, BP 20529, F-60205 Compiègne cedex, FranceReceived 2 August 2006; received in revised form 20 May 2007; accepted 25 May 2007Available online 5 June 2007AbstractDempster’s rule plays a central role in the theory of belief functions. However, it assumes the combined bodies of evidence tobe distinct, an assumption which is not always verified in practice. In this paper, a new operator, the cautious rule of combination,is introduced. This operator is commutative, associative and idempotent. This latter property makes it suitable to combine belieffunctions induced by reliable, but possibly overlapping bodies of evidence. A dual operator, the bold disjunctive rule, is alsointroduced. This operator is also commutative, associative and idempotent, and can be used to combine belief functions issuesfrom possibly overlapping and unreliable sources. Finally, the cautious and bold rules are shown to be particular members ofinfinite families of conjunctive and disjunctive combination rules based on triangular norms and conorms.© 2007 Elsevier B.V. All rights reserved.Keywords: Evidence theory; Dempster–Shafer theory; Transferable belief model; Distinct evidence; Idempotence; Information fusion1. IntroductionDempster’s rule of combination [3,28] is known to play a pivotal role in the theory of belief functions, togetherwith its unnormalized version introduced by Smets in the Transferable Belief Model (TBM) [30], hereafter referred toas the TBM conjunctive rule. Justifications for the origins and uniqueness of these rules have been provided by severalauthors [8,21,22,30]. However, although they appear well founded theoretically, the need for greater flexibility througha larger choice of combination rules has been recognized by many researchers involved in real-world applications.Two limitations of Dempster’s rule and its unnormalized version seem to be their lack of robustness with respectto conflicting evidence (a criticism which mainly applies to Dempster’s rule), and the requirement that the items ofevidence combined be distinct.The issue of conflict management has been addressed by several authors, who proposed alternative rules which,unfortunately, are generally not associative (see, e.g., [11,25,40], and reviews in [27] and [37]). The disjunctive ruleof combination [9,31] (hereafter referred to as the TBM disjunctive rule) is both associative and more robust thanDempster’s rule in the presence of conflicting evidence, and its use is appropriate when the conflict is due to poor✩ This paper is an extended version of [T. Denœux, The cautious rule of combination for belief functions and some extensions, in: Proceedingsof the 9th International Conference on Information Fusion, Florence, Italy, July 2006, Paper #114].E-mail address: Thierry.Denoeux@hds.utc.fr.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.008\fT. Denœux / Artificial Intelligence 172 (2008) 234–264235reliability of some of the sources. It may also be argued that problems with Dempster’s rule (and, to a lesser extent,with the TBM conjunctive rule) are often due to incorrect or incomplete modelisation of the problem at hand, and thatthese rules often yield reasonable results when they are properly applied [17]. In [37], an expert system approach isadvocated in case of large conflict, to determine its origin and revise the underlying hypotheses accordingly.The other, and perhaps more fundamental, limitation of Dempster’s rule lies in the assumption that the items of evi-dence combined be distinct or, in other words, that the information sources be independent. As remarked by Dempster[3], the real-world meaning of this notion is difficult to describe. The general idea is that, in the combination process,no elementary item of evidence should be counted twice. Thus, nonoverlapping random samples from a populationare clearly distinct items of evidence, whereas “opinions of different people based on overlapping experiences couldnot be regarded as independent sources” [3]. When the nature of the interaction between items of evidence can bedescribed mathematically, then it is possible to extend Dempster’s rule or the TBM conjunctive rule so as to includethis knowledge (see, e.g., [8,29]). However, it is often the case that, although two items of evidence (such as, e.g.,opinions expressed by two experts sharing some experiences, or observations of correlated random quantities) canclearly not be regarded as distinct, the interaction between them is ill known and, in many cases, almost impossible todescribe.In such a common situation, it would be very helpful to have a combination rule that would not rely on the distinct-ness assumption. An early attempt to provide such a rule is reported in [26], but it was limited to the combination ofsimple belief functions (i.e., belief functions having at most two focal sets, including the frame of discernment). Thismethod was extended to separable belief functions (i.e., belief functions that can be decomposed as the conjunctivesum of simple belief functions) in [15]. However, not all belief functions are separable, and the justification for thisapproach was unclear.A natural requirement for a rule allowing the combination of overlapping bodies of evidence is idempotence. Thearithmetic mean does possess this property, but it is not associative, another requirement often regarded as essential.Following an approach initiated by Dubois and Prade in [8], Cattaneo [1] studied a family of rules generalizing theTBM conjunctive rule, based on the definition of a joint belief function on a product space, whose marginals are thebelief functions to be combined. Inside this family, he proposed a rule minimizing the conflict, which happens to beidempotent. However, he showed that, within this particular family of rules, associativity is incompatible both withidempotency, and with conflict minimization.In contrast, associative and idempotent operators exist in possibility theory, based on the minimum triangular normand its dual, the maximum triangular conorm. Dubois and Yager [14] showed that aggregation operators for possibilitydistributions (or, equivalently, fuzzy set connectives) can be deduced from assumptions on multi-valued mappingsunderlying the possibility distributions viewed as consonant belief functions. This approach, however, has not madeit possible to extend possibilistic aggregation operators to arbitrary belief functions while maintaining such propertiesas associativity and idempotency. New operators satisfying these properties are proposed in this paper, following acompletely different approach based on some ideas suggested to the author by the late Philippe Smets [35].The rest of this paper is organized as follows. The underlying fundamental concepts, including the canonical de-composition and the relative information content of belief functions, are first recalled in Section 2. The cautiousconjunctive rule and its dual, the bold disjunctive rule are then introduced in Sections 3 and 4, respectively. The cau-tious and bold rules are shown in Section 5 to be particular members of infinite families of conjunctive and disjunctivecombination rules based on triangular norms and conorms. Finally, the efficiency of the cautious rule to combineinformation from dependent features in a classifier fusion problem is demonstrated experimentally in Section 6, andSection 7 concludes the paper.2. Fundamental conceptsIn this section, the main building blocks of new combination rules defined later are introduced. The basic con-cepts and terminology related to belief functions are first summarized in Section 2.1. Section 2.2 then focuses on thecanonical conjunctive decomposition of nondogmatic belief functions, which allows their representation in the formof conjunctive weight functions taking values in (0, +∞). This section is essential, as the cautious conjunctive ruleintroduced in this paper will be expressed as a function of conjunctive weights. Finally, Section 2.3 recalls knowndefinitions and results related to the ordering of belief functions according to their information content; a new partial\f236T. Denœux / Artificial Intelligence 172 (2008) 234–264ordering relation based on conjunctive weights is also introduced. This ordering relation will play an important rolein the derivation of the new combination rules.2.1. Basic definitions and notationsIn this paper, the TBM [33,38] is accepted as a model of uncertainty. An agent’s state of belief expressed on a finiteframe of discernment Ω = {ω1, . . . , ωK } is represented by a basic belief assignment (BBA) m, defined as a mappingfrom 2Ω to [0, 1] verifyingA⊆Ω m(A) = 1. Subsets A of Ω such that m(A) > 0 are called focal sets of m. A BBAm is said to be(cid:2)• normal if ∅ is not a focal set (this condition is not imposed in the TBM);• subnormal is ∅ is a focal set;• dogmatic if Ω is not a focal set;• vacuous if Ω is the only focal set;• simple if it has at most two focal sets and, if it has two, Ω is one of those;• categorical if it has only one focal set;• Bayesian if its focal sets are singletons.A subnormal BBA m can be transformed into a normal BBA m∗ by the normalization operation defined as follows:A simple BBA (SBBA) m such that m(A) = 1 − w for some A (cid:6)= Ω and m(Ω) = w can be noted Aw (theadvantage of this notation will become apparent later). The vacuous BBA can thus be noted A1 for any A ⊂ Ω, and acategorical BBA can be noted A0 for some A (cid:6)= Ω. A BBA m can equivalently be represented by its associated belief,implicability, plausibility and commonality functions defined, respectively, as:(cid:3)∗m(A) =k · m(A)if A (cid:6)= ∅,0otherwise,for all A ⊆ Ω, with k = (1 − m(∅))−1.",
            {
                "entities": [
                    [
                        3122,
                        3150,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 321 (2023) 103936Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintPolynomial combined first-order rewritings for linear and guarded existential rules ✩Georg Gottlob a, Marco Manna b, Andreas Pieris c,d,∗a Department of Computer Science, University of Oxford, UKb Department of Mathematics and Computer Science, University of Calabria, Italyc School of Informatics, University of Edinburgh, UKd Department of Computer Science, University of Cyprus, Cyprusa r t i c l e i n f oa b s t r a c tArticle history:Received 4 May 2021Received in revised form 19 April 2023Accepted 25 April 2023Available online 2 May 2023Keywords:OntologiesExistential rulesTuple-generating dependenciesGuardednessConjunctive queriesQuery answeringQuery rewritingCombined approachWe consider the problem of ontological query answering, that is, the problem of answering a database query (typically a conjunctive query) in the presence of an ontology. This means that during the query answering process we also need to take into account the knowledge that can be inferred from the given database and ontology. Building, however, ontology-aware database systems from scratch, with sophisticated optimization techniques, is a highly non-trivial task that requires a great engineering effort. Therefore, exploiting conventional database systems is an important route towards efficient ontological query answering. Nevertheless, standard database systems are unaware of ontologies. An approach to ontological query answering that enables the use of standard database systems is the so-called polynomial combined query rewriting, originally introduced in the context of description logics: the conjunctive query q and the ontology (cid:2) are rewritten in polynomial time into a first-order query q(cid:2) (in a database-independent way), while the database D and the ontology (cid:2) are rewritten in polynomial time into a new database D(cid:2) (in a query-independent way), such that the answer to q in the presence of (cid:2) over D coincides with the answer to q(cid:2) over D(cid:2). The latter can then be computed by exploiting a conventional database system.In this work, we focus on linear and guarded existential rules, which form robust rule-based languages for modeling ontologies, and investigate the limits of polynomial combined query rewriting. In particular, we show that this type of rewriting can be successfully applied to (i) linear existential rules when the rewritten query can use the full power of first-order queries, (ii) linear existential rules when the arity of the underlying schema is fixed and the rewritten query is positive existential, namely it uses only existential quantification, conjunction, and disjunction, and (iii) guarded existential rules when the underlying schema is fixed and the rewritten query is positive existential. We can show that the above results reach the limits (under standard complexity-theoretic assumptions such as PSpace (cid:3)= ExpTime) of polynomial combined query rewriting in the case of linear and guarded existential rules.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).✩This paper is an extended and revised version of the papers [1], [2] and [3].* Corresponding author.E-mail addresses: georg.gottlob@cs.ox.ac.uk (G. Gottlob), manna@mat.unical.it (M. Manna), apieris@inf.ed.ac.uk (A. Pieris).https://doi.org/10.1016/j.artint.2023.1039360004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fG. Gottlob, M. Manna and A. PierisArtificial Intelligence 321 (2023) 1039361. IntroductionOver the past two decades we have seen a shift from a world where most data used by public and private organizations was stored in well-structured relational databases of modest size and treated as complete to a world where data is very large, heterogeneous, distributed in different sources, and incomplete. This makes the task of extracting useful information from such data by means of queries extremely tedious and complex. At the same time, not only do we have massive amounts of data, but we also have very large amounts of knowledge about the application domain of the data in the form of taxonomies, or even full-fledged ontologies. This gave rise to a new research field, recently dubbed knowledge-enriched data management [4], that lies at the intersection of data management and knowledge representation and reasoning. A major challenge for knowledge-enriched data management is to provide end users with flexible and integrated access to data by exploiting the available knowledge about the underlying application domain. This builds on the hypothesis that end users may have a deep understanding of a specific domain of interest, but are not able to formulate complex queries and understand performance implications.Ontology-based data access (OBDA) [5], also known as ontology-based data integration, has been proposed as a general paradigm for addressing the above central challenge. It facilitates access to data by separating the end user from the raw data sources. This is done by using an ontology, which models the underlying application domain and is semantically linked with the data via declarative mappings, as a mediator between the data sources and the end user. The purpose of the ontology is two-fold:1. It provides an integrated global view of the data that is very close to the conceptual model of the underlying application domain of which the end user has a good understanding. This makes the raw data accessible via database queries formulated solely in the vocabulary of the ontology, without requiring any knowledge of the actual structure of the data sources.2. It enriches the possibly incomplete data sources with domain knowledge. This allows us to infer new knowledge, not explicit in the data, enabling more complete answers to queries.The main algorithmic task underlying the OBDA paradigm is querying knowledge-enriched data, or, in other words, querying data in the presence of an ontology. This means that during the query answering process we also need to take into account the inferred knowledge. This problem is known as ontological query answering.1.1. Query rewritingBuilding ontology-aware database systems from scratch, with sophisticated optimization techniques, is a highly non-trivial task that requires a great engineering effort. An alternative route towards efficient ontological query answering is to use conventional database management systems (DBMSs). The fact that DBMSs are unaware of ontologies can be addressed by query rewriting: the database query q (typically a conjunctive query) and the ontology (cid:2) are rewritten into a new query q(cid:2), the so-called rewriting, which computes the answer to q in the presence of (cid:2) over all input databases. It is, of course, essential that q(cid:2) is expressed in a language that can be handled by standard DBMSs. The typical language is that of first-order (FO) queries.The Pure Approach. What has been described above is the so-called pure approach to FO rewritability in the sense that the FO rewriting q(cid:2) should be powerful enough to compute the correct answer to the given query q under the given ontology (cid:2) over all input databases. This essentially means that the construction of q(cid:2) should be independent of any database. The advantage of such a pure approach to FO rewritability should be clear: we can pre-compute q(cid:2) offline, and whenever the database D changes, we simply need to re-evaluate q(cid:2) over D, without having to re-compute it. This approach has been successfully applied to a range of lightweight description logics, mainly the members of the DL-Lite family [6], as well as classes of existential rules such as linear existential rules [7,8]; details on existential rules are given below. On the other hand, such a pure approach to FO rewritability comes with two inevitable shortcomings:1. Query rewriting algorithms generate from a reasonably sized conjunctive query a very large FO query, which can be prohibitive for efficient execution by a standard database system. We actually know that even for lightweight ontology languages such as DL-LiteR [6], the logical underpinning of the OWL 2 QL profile of OWL 2,1 there is no FO rewriting of polynomial size, unless the polynomial hierarchy collapses [9]. Further strong evidence for the non-existence of an FO rewriting of polynomial size in the case of DL-LiteR was given in [10]. In particular, it was shown that the existence of such an FO rewriting is equivalent to a major open problem in computational complexity such as NC1 = NP/poly.2 We also know that an exponential blow-up is provably unavoidable when the rewriting should be an existential positive FO query (i.e., an FO query that uses only existential quantification, conjunction, and disjunction) [9].1 https://www.w3 .org /TR /owl2 -profiles /#OWL _2 _QL.2 NC1 is the class of decision problems decidable by uniform Boolean circuits with a polynomial number of gates of at most two inputs and depth O (log n), whereas NP/poly is the non-uniform analogue of NP.2\fG. Gottlob, M. Manna and A. PierisArtificial Intelligence 321 (2023) 1039362. FO rewritability applies only to lightweight ontology languages for which the data complexity of ontological query answering (i.e., when the query and the ontology are considered fixed) is very low. More precisely, the problem of eval-uating a fixed FO query over an input database is known to be in AC0,3 a class that is properly contained in DLogSPace. Therefore, useful formalisms with PTime-hard (or even DLogSpace-hard) data complexity, such as the description logic EL [11], are immediately excluded.The Combined Approach. To overcome t",
            {
                "entities": [
                    [
                        3547,
                        3575,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1119–1157www.elsevier.com/locate/artintAlternating-offers bargaining with one-sided uncertain deadlines:an efficient algorithmNicola Gatti ∗, Francesco Di Giunta, Stefano MarinoArtificial Intelligence and Robotics Laboratory, Dipartimento di Elettronica e Informazione, Politecnico di Milano,Piazza Leonardo da Vinci 32, 20133 Milano, ItalyReceived 4 February 2007; received in revised form 9 October 2007; accepted 17 November 2007Available online 4 March 2008AbstractIn the arena of automated negotiations we focus on the principal negotiation protocol in bilateral settings, i.e. the alternating-offers protocol. In the scientific community it is common the idea that bargaining in the alternating-offers protocol will play acrucial role in the automation of electronic transactions. Notwithstanding its prominence, literature does not present a satisfactorysolution to the alternating-offers protocol in real-world settings, e.g. in presence of uncertainty. In this paper we game theoreticallyanalyze this negotiation problem with one-sided uncertain deadlines and we provide an efficient solving algorithm. Specifically,we analyze the situation where the values of the parameters of the buyer are uncertain to the seller, whereas the parameters of theseller are common knowledge (the analysis of the reverse situation is analogous). In this particular situation the results present inliterature are not satisfactory, since they do not assure the existence of an equilibrium for every value of the parameters. From ourgame theoretical analysis we find two choice rules that apply an action and a probability distribution over the actions, respectively,to every time point and we find the conditions on the parameters such that each choice rule can be singularly employed to producean equilibrium. These conditions are mutually exclusive. We show that it is always possible to produce an equilibrium where theactions, at any single time point, are those prescribed either by the first choice rule or by the second one. We exploit this resultfor developing a solving algorithm. The proposed algorithm works backward by computing the equilibrium from the last possibledeadline of the bargaining to the initial time point and by applying at each time point the actions prescribed by the choice rule whoseconditions are satisfied. The computational complexity of the proposed algorithm is asymptotically independent of the number oftypes of the player whose deadline is uncertain. With linear utility functions, it is O(m · T ) where m is the number of the issuesand T is the length of the bargaining.© 2007 Elsevier B.V. All rights reserved.Keywords: Automated negotiations; Game theory; Multiagent systems1. IntroductionAutomated negotiation is a promising scenario of computer science where artificial intelligence can play a crucialrole: it can automate software agents allowing them to negotiate each other on behalf of users for buying and selling* Corresponding author. Tel.: +39 02 2399 3658; fax: +39 02 2399 3411.E-mail address: ngatti@elet.polimi.it (N. Gatti).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.007\f1120N. Gatti et al. / Artificial Intelligence 172 (2008) 1119–1157items [21]. This automation, as stated in literature, can lead to more effective negotiations since software agents workfaster than humans and are more prone in finding efficient agreements [35].Several negotiation settings can be found in the electronic commerce arena. The most common ones are usuallybilateral: a buyer and a seller negotiate a contract over one or more issues. In this paper we consider the principalsetting in bilateral negotiations: the bargaining [28]. In a bargaining two agents must reach an agreement regardinghow to distribute objects or a monetary amount and each player prefers to reach an agreement, rather than abstainfrom doing so; however, each agent prefers that agreement which most favors her interests. A real-world example thatdepicts this situation is a negotiation between a service provider and a customer over the price and the quality level ofa service.Classically, the study of bargaining is carried out employing game-theoretical tools [28,30] wherein one distin-guishes the negotiation protocol and the negotiation strategies: the protocol sets the negotiation rules, specifyingwhich actions are allowed and when [32]; the strategies define the behavior of an agent in any possible agent’s deci-sion node. Strategies can be pure or mixed.1 For any decision node of the game a pure strategy prescribes one action;a mixed strategy prescribes probability distributions over the actions. Given a protocol, the game-theoretical approachpostulates that rational agents should employ strategies that maximize their payoffs [29]. In this paper we a prioriassume agents to be rational; such an assumption will be supported a posteriori by the results provided in the paper.Indeed, we will show that the problem of computing a solution with rational agents is tractable.The principal protocol for bilateral bargaining, the alternating-offers protocol, pioneered by Ståhl in [37], hasreached an outstanding place in literature thanks to Rubinstein in [33]. It is considered to be the most satisfactorymodel of bargaining present in literature. Basically, an agent starts by offering a value for the issue under dispute(e.g., a price) to her opponent. The opponent can accept the offer or make a counteroffer. If a counteroffer is made,the process is repeated until one of the agents accepts. Rubinstein’s alternating-offers model is not accurate enoughto capture all the aspects involved in the electronic commercial transactions, where, typically, agents have reservationvalues and deadlines, negotiate over multiple issues, and have uncertain information. Therefore, refinements andextensions of [33] are commonly employed in computer science community to provide a more satisfactory model [10].Examples of real-world applications that employ bargaining techniques can be found in [1,2,24,26,31].The solution of the classic Rubinstein’s protocol is well known in the literature [28]. On the contrary, the study ofthe alternating-offers protocol in presence of extensions and refinements is hard and still open. Specifically, the twocrucial problems concern the development of algorithmic techniques to find equilibria in presence of issue multiplic-ity and information incompleteness. The problem of bargaining efficiently over multiple issues when information iscomplete has been recently addressed in [6,7] and refined in [12]. The equilibrium strategies can be easily computedby extending the classic backward induction method [14]. The computational complexity is O(m · T ), where m is thenumber of issues and T is the length of the bargaining. In presence of incomplete information, it is customary in gametheory to introduce probability distributions over the parameters that are not known by the agents. Notwithstanding,the analysis of bargaining with uncertain information is currently more a series of examples than a coherent set ofresults. Game theory provides an appropriate solution concept for extensive-form games with uncertain information,i.e., the sequential equilibrium [22], but no solving technique to find it. We recall that the backward induction methodcan be employed with success exclusively in presence of complete information [14]. Moreover, economic studiesonly provide equilibria in very narrow settings of information uncertainty, focusing mainly on discount factors andreservation values. For instance, in [34] Rubinstein analyzes a scenario with uncertainty over two possible discountfactors of one of the two agents, while in [3] Chatterjee and Samuelson analyze a scenario with uncertainty over thereservation values of both the buyer and the seller, where each player can be of two types. An interested reader canfind an exhaustive survey on bargaining with uncertain information in [4].The employment of the alternating-offers protocol in electronic commerce has put attention on the role of thedeadlines in the negotiation. The infinite horizon assumption, which is usually made in game theory literature, isnot realistic in real-world applications [36]. Furthermore, agents’ deadlines are usually uncertain, not being knowna priori by the agents themselves. Notwithstanding the importance of uncertain deadlines in negotiations, only fewworks have deeply analyzed their effects in the alternating-offers protocol with discount factors, discrete time, andrational agents, and no satisfactory solution is currently known. This prevents the employment of autonomous rational1 For the sake of simplicity, we use in the paper, as Kreps and Wilson in [22], the term “strategies” in the place of appropriate game theoreticalterm “behavioral strategies”.\fN. Gatti et al. / Artificial Intelligence 172 (2008) 1119–11571121agents in real-world applications and pushes scientific community to develop solutions for this bargaining problem.Classic results concerning the presence of deadlines in bargaining are the followings. In [25] Ma and Manove considera complete information finite horizon alternating-offers model without temporal discounting with continuous time andplayers’ option of strategic delay. In [13] Fershtman and Seidmann study a complete information bargaining modelwith random proposer and a deadline. In [16] Gneezy et al. study a variation of the ultimatum game. In [36] Sandholmand Vulkan analyze a slight variation of the war-of-attrition game: the surplus can be divided, time is continuous, thedeadlines are uncertain, and there are not discount factors. In [10] Fatima et al. study the alternating-offers protocolwith uncertainty over deadlines and reservation values in presence of bounded rational agents: more precisely, agentsmust employ predefined bidding tactics based on the negotiation decision functions paradigm [8]. Only r",
            {
                "entities": [
                    [
                        3182,
                        3210,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1161–1173www.elsevier.com/locate/artintHuman-level artificial general intelligence and the possibility of atechnological singularityA reaction to Ray Kurzweil’s The Singularity Is Near,and McDermott’s critique of KurzweilBen GoertzelNovamente LLC, San Francisco, CA, United StatesAvailable online 10 October 2007AbstractAn analysis of Ray Kurzweil’s recent book The Singularity Is Near is given, along with Drew McDermott’s recent critique.The conclusion is that Kurzweil does an excellent job of fleshing out one particular plausible scenario regarding the future of AI,in which human-level AI first arrives via human-brain emulation. McDermott’s arguments against the notion of Singularity viaiteratively self-improving AI, as described by Kurzweil, are considered and found wanting. However, it is pointed out that thescenario focused on by Kurzweil is not the only plausible one; and an alternative is discussed, in which human-level AI arrives firstvia non-human-like AI’s operating virtual worlds.© 2007 Elsevier B.V. All rights reserved.Keywords: Strong AI; AGI; Self-modifying software; Singularity virtual worlds; Language acquisition1. Narrow AI versus AGIThe AI field started out with grand dreams of human-level artificial general intelligence. During the last half-century, enthusiasm for these grand AI dreams—both within the AI profession and in society at large—has risen andfallen repeatedly, each time with a similar pattern of high hopes and media hype followed by overall disappointment.Throughout these fluctuations, though, research and development have steadily advanced on various fronts within AIand allied disciplines.Averaging across the various historical fluctuations, we may generalize that the original vision of human-level AIhas been dampened over time due to various coupled factors, including most prominently• overoptimistic promises by early AI researchers, followed by failures to deliver on these promises [6,8];• a deeper understanding of the underlying computational and conceptual difficulties involved in various mentaloperations that humans, in everyday life, consider trivial and simple [23,24].E-mail address: ben@goertzel.org.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.10.011\f1162B. Goertzel / Artificial Intelligence 171 (2007) 1161–1173These days most R&D carrying the label “AI” pertains to some sort of very narrowly-defined problem domain,shying away from the ambitious goals that are associated with AI in the popular media.Recently, in the first years of the 21st century, AI optimism has been on the rise again, both within the AI field andin the science and technology community as a whole. One possibility is that this is just another fluctuation—anotherinstance of excessive enthusiasm and hype to be followed by another round of inevitable disappointment. Anotherpossibility is that AI’s time is finally near, and what we are seeing now is the early glimmerings of a rapid growthphase in AI R&D, such as has not been seen in the field’s history to date.As evidence of the recent increase in AI optimism in some relevant circles, I note that the last few years haveseen an increasing number of conference special sessions and workshops focused on “Human-Level AI,” “ArtificialGeneral Intelligence” and related topics; for example (this is not a comprehensive list):• Integrated Intelligent Capabilities, Special Track of AAAI since 2006 (and planned to continue annually into theindefinite future);• Roadmap to Human-Level Intelligence. Special Session at WCCI, July-2006;• Building & Evaluating Models of Human-Level Intelligence, CogSci, July-2006;• Artificial General Intelligence Workshop, Bethesda MD, May-2006;• Between a Rock and a Hard Place: Cognitive Science Principles Meet AI-Hard Problems, AAAI Spring Sympo-sium Series, Mar-2006;• Towards Human-Level AI, NIPS Workshop, Dec-2005;• Achieving Human-Level Intelligence through Integrated Systems and Research, AAAI Fall Symposium Series,Oct-2004.In March 2008, the University of Memphis will host AGI-08, the first AI conference focusing specifically onartificial general intelligence and human-level AI, co-organized by the author and several colleagues, including StanFranklin, a long-established leader in the AI field. There have also been specific attempts to focus publications onhuman-level artificial general intelligence, e.g. a “Human-Level AI” issue of AI Magazine edited by Nick Cassimatis[5], and a series of edited volumes focused on AGI [15,16].And in the popular press, futurist pundits are more and more often heard proclaiming that the age of real AI is,this time, really coming soon—not like the false hopes of the past. The most widely-read example of this sort offuturist AI optimism is probably Ray Kurzweil’s recent book The Singularity Is Near (TSIN [21]), which projects theachievement of human-level AI by roughly 2029, followed by an AI-triggered radical transformation of mind, societyand economy by roughly 2045.Of course, the vast majority of academic and industry AI researchers remain deeply skeptical of the sort of opti-mistic rhetoric and perspective that Kurzweil’s book typifies. The annual AAAI conference remains focused on thesolution of important, fascinating, but very narrowly-defined technical problems, most of which are only loosely (if atall) connected to the problem of creating artificial general intelligence at the human level or beyond. More ambitiousAI ideas remain at the periphery.Kurzweil has called the currently mainstream sort of AI research “narrow AI”—meaning AI that focuses on thecreation of software solving specific, narrowly constrained problems. A narrow AI program need not understanditself or what it is doing, and it need not be able to generalize what it has learned beyond its narrowly constrainedproblem domain. For example, a narrow-AI program for playing chess need not be able to transfer any of its strategicor methodological insights to Shogi (Japanese chess) or checkers . . . and probably not even to Fisher random chess(though a human programmer might be able to take some of the knowledge implicit in a narrow-AI chess playingprogram and use this to make a better program for playing other games; in this case the general intelligence existsmainly in the human being not the programs). A narrow-AI program for driving a car in the desert need not be able toutilize its knowledge to drive a car in the city or a motorcycle in the desert. A narrow-AI program for parsing Englishcannot learn any other language, whether or not the other language has a similar syntactic and semantic structure.A narrow-AI program for diagnosing kidney cancer will always be useless for diagnosing gall bladder cancer (thoughthe same narrow-AI framework may be used by humans to create narrow-AI programs for diagnosing various sorts ofcancers).Kurzweil contrasts narrow AI with “strong AI,” but I find this terminology confusing due to its overlap withSearle’s better-known usage of the term “strong AI,” so I prefer the term AGI or “Artificial General Intelligence” for\fB. Goertzel / Artificial Intelligence 171 (2007) 1161–11731163the opposite of Kurzweil’s “narrow AI.” A related term sometimes used is “Human-Level AI,” but I consider this termless preferable for two reasons:• In the space of all possible minds, humans are not necessarily all that smart, so that the “human level” constraintactually may pose an overly strict limitation on the scope of future AGI work.• Defining what “human level” means is actually difficult, when one starts thinking about potential highly-general-intelligence AI systems with fundamentally non-human-like architectures. If one has an AGI system with verydifferent strengths and weaknesses than humans, but still with the power to solve complex problems across avariety of domains and transfer knowledge flexibly between these domains, it may be hard to meaningfully definewhether this system is “human-level” or not.For the rest of this essay I will stick with the term AGI, though using “Human-Level AI” when that is specificallywhat I mean.Now, one might argue that the position of AGI R&D on the margins of contemporary AI research is only correctand proper, since we don’t really know how to do human-level AGI yet; and the bulk of contemporary AI researchfocuses on more narrowly-defined research directions that have the benefit of far more easily leading to scientificallydemonstrable and/or pragmatically useful results. However, there are other branches of contemporary science wherethe overall modus operandi is not so conservative. For instance, physics currently devotes a significant amount ofattention to speculative mathematical theories of unified physics, which are no more soundly proven than anybody’scurrent approach to AGI. This work is considered justified because it is advancing understanding, and seems likely(according to the very theories being developed, which are not yet proven) to yield exciting experimental results infuture. And, the biopharmaceutical industry has devoted a huge amount of funding to areas such as gene-therapy basedmedicine, which has not yet led to any dramatic practical successes, and still involves a huge amount of uncertainty (forinstance, how to effectively deliver modified genes to the appropriate part of the organism being healed). Quantumcomputing is the focus of much excitement in spite of the fact that all known quantum computers are extremelyspecialized or extremely small (a handful of qubits), and the number of fundamental quantum computing algorithmsknown can be counted on the fingers of one hand. Modern science, in other areas, is willing to take a medium andlong term view and focus significant amounts of attention on the big problems. Other examples abound. But the fieldof AI, due to its particular history, has settled into a rather conservative pattern. Which makes the contrast betweenthe goings-on at th",
            {
                "entities": [
                    [
                        2284,
                        2312,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 165–189Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDifferential evolution for noisy multiobjective optimizationPratyusha Rakshit∗, Amit KonarElectronics and Telecommunication Engineering Department, Jadavpur University, Kolkata 700032, Indiaa r t i c l e i n f oa b s t r a c tArticle history:Received 20 December 2013Received in revised form 15 June 2015Accepted 15 June 2015Available online 18 June 2015Keywords:NoiseDifferential evolution for multiobjective optimizationSamplingInterquartile rangeSkewnessDominance probabilityWe propose an extension of multiobjective optimization realized with the differential evolution algorithm to handle the effect of noise in objective functions. The proposed extension offers three merits with respect to its traditional counterpart. First, an adaptive selection of the sample size for the periodic fitness evaluation of a trial solution based on the fitness variance in its local neighborhood is proposed. This avoids the computational complexity associated with the unnecessary reevaluation of quality solutions without disregarding the necessary evaluations for relatively poor solutions to ensure accuracy in fitness estimates. The second strategy is concerned with determining the expected value of the noisy fitness samples on the basis of their distribution, instead of their conventional averaging, as the fitness measure of the trial solutions. Finally, a new crowding-distance-induced probabilistic selection criterion is devised to promote quality solutions from the same rank candidate pool to the next generation, ensuring the population quality and diversity in the objective spaces. Computer simulations performed on a noisy version of a well-known set of 23 benchmark functions reveal that the proposed algorithm outperforms its competitors with respect to inverted generational distance, spacing, error ratio, and hypervolume ratio metrics.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe multiobjective optimization (MOO) literature has witnessed a radically different perspective in solving real-world problems using evolutionary computing methods. A MOO is concerned with mathematical optimization problems involving two or more complex, nonlinear, conflicting objectives to be optimized simultaneously. Usually, a derivative-free single-objective optimization algorithm generates new trial solutions that are biased toward the better region of the objective space, and weeds out poor solutions using a competitive selection over iterations. However, for a nontrivial MOO problem, there exists no single solution that simultaneously optimizes each objective. To jointly optimize multiple objective functions in a MOO [1], selection of trial solutions is performed by Pareto ranking, which is concerned with judiciously identify-ing nondominated trial solutions from the rest of the population. Pareto ranking is induced by the fitness measure of all objective functions for individual trial solutions.The objectives, being functions of certain variables describing a specific problem, usually return a unique value for the variables in their argument. However, in many scientific/engineering problems, it has been observed that even though the measurements of the variables remain constant, the objective functions return different values because of noise-induced dynamic variation of the objective surfaces. This class of problem is referred to as the “noisy optimization problem.” Noise * Corresponding author. Tel.: +91 9477399645.E-mail address: pratyushar1@gmail.com (P. Rakshit).http://dx.doi.org/10.1016/j.artint.2015.06.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\f166P. Rakshit, A. Konar / Artificial Intelligence 227 (2015) 165–189creeps into the picture because of technological limitations, modeling errors, and incomplete data, leading to different results from repeated evaluations for the same set of parameter values of the objective functions. In such circumstances, a quality trial solution in a MOO may be deprived of being promoted to the next generation because of its poor (noisy) fitness estimates, while a deceptive solution with illusive good fitness may not be discarded from the current population [2,3].This paper addresses the issues of uncertainty management (regarding the selection of qualitative trial solutions) in MOO in the presence of noise by incorporating the following three policies: adaptation of the sample size of a trial solution for its periodic fitness evaluation, expected fitness estimation from the measured noisy fitness samples, and crowding-distance-induced stochastic selection. First, the sample size for periodic fitness evaluation of each trial solution is adapted by means of the fitness variance in their local neighborhood. “Sampling” refers to the periodic fitness evaluation of a trial solution to diminish the risk of promoting inferior solutions in the noisy environment. It is worth mentioning that the adaptive selection of the sample size is momentous as increasing the sample size augments the quality measure of fitness at the cost of additional runtime. Here a nonlinear form (capturing the relationship between the sample size of a trial solution and the fitness variance in its local neighborhood) induced by an exponential function is regarded to efficiently balance the trade-off between runtime complexity and computational accuracy.Second, while measuring the fitness of a trial solution, traditional methods [4–6] refer to the average fitness of the samples. However, the average fitness presumes equal probability of occurrence of all fitness samples, and thus returns a poor fitness estimate when the noise variance (in the fitness measure of the solutions) in the local neighborhood of a selected trial solution is large. This problem is circumvented here by referring to the expected value of the fitness samples as the true fitness estimate of a trial solution. The expected fitness concerned with the occurrence probability of the fitness samples seems to give a better fitness measure of a given trial solution. We introduce a novel strategy to evaluate the expected fitness of the trial solutions from the distribution of the fitness samples in the entire sample space. In the present context, a density-based nonuniform partitioning of the fitness sample space is employed to capture the uncertainty involved in the fitness measurement of the noisy fitness samples.Finally, we develop a probabilistic selection (PS) policy to encapsulate the diversity as well as the quality of the non-dominated trial solutions even in noisy fitness landscapes. It is observed that the deterministic selection scheme of the crowding-distance-based sorting (used for promoting trial solutions from the same rank candidate pool to the next gen-eration), which is employed in traditional MOO algorithms, can lead to suboptimal or misleading sets of nondominated solutions in the noisy environment even when sampling is used [7]. The selection strategy here depends not only on the density of nondominated solutions surrounding an individual in the objective space, but also on the reliability of its mea-sured fitness samples. We develop a new probabilistic measure of the reliability based on the skewness of the distribution of the fitness samples. The degree of asymmetry of the distribution of the fitness samples is captured by skewness. Con-sequently, it provides a unique approach for identifying the rare fitness samples lying in the tail of the distribution. These infrequent samples (far away from the expected fitness) are assumed to occur because of the creeping of noise in the fitness landscapes. The rarer the occurrence of the infrequent samples (i.e., the closer the fitness samples are to the expected value with small skewness of the distribution), the greater is the degree of credibility of the fitness estimates of a given trial so-lution. The trial solutions having a greater crowding distance and a high grade of reliability (assessed using the probability of occurrence of no rare samples) are given more precedence during ranking of solutions in the same front.The evolutionary component of the proposed noisy MOO algorithm has been realized here by the differential evolution for MOO (DEMO) [8] algorithm for its proven merits in global optimization. Some of the attractive features of DEMO justi-fying its selection in the design of the proposed noisy optimization algorithm include the simplicity of its structure leading to ease of coding, very few control parameters, and faster convergence [48,49] in comparison with other MOO algorithms.Performance analysis of the proposed noisy optimization algorithm realized with DEMO—referred to as “differential evolution for noisy MOO” (DENMO) henceforth—is studied using the noisy version of a set of 23 benchmark functions. Exper-iments were undertaken to compare the potency of the proposed algorithm with differential evolution for MOO with noise (DEMON) [9], nondominated sorting genetic algorithm II (NSGA-II) with α-dominance operator (NSGA-II-A) [10], confidence-based dynamic resampling (CDR) [11], simulated annealing for noisy MOO [12], elitist evolutionary multiagent system [13], multiobjective evolutionary algorithm with robust features (MOEA-RF) [14], modified NSGA-II [7], noise-tolerant strength Pareto evolutionary algorithm [15], and Pareto front-efficient global optimization [16]. In this study, the objective functions are contaminated with noise samples taken from five noise distributions—namely, Gaussian, Poisson, Rayleigh, exponential, and random (with positive and negative expeditions of the noise amplitude within ±25% of the true fitness function values). Experiments reveal that the proposed realization outperforms other algorithms for four important performance metrics—that is, inverted generational distance (IGD), spacing, error ratio (ER), and hypervol",
            {
                "entities": [
                    [
                        3662,
                        3690,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 514–540www.elsevier.com/locate/artintDuality in permutation state spaces and the dual search algorithmUzi Zahavi a, Ariel Felner b,∗, Robert C. Holte c, Jonathan Schaeffer ca Computer Science Department, Bar-Ilan University, Ramat-Gan, Israelb Department of Information Systems Engineering, Ben-Gurion University, Israelc Computing Science Department, University of Alberta, Edmonton, Alberta, CanadaReceived 2 August 2006; received in revised form 27 June 2007; accepted 22 October 2007Available online 6 November 2007AbstractGeometrical symmetries are commonly exploited to improve the efficiency of search algorithms. A new type of symmetry inpermutation state spaces, duality, is introduced. Each state has a dual state. Both states share important attributes such as theirdistance to the goal. Given a state S, it is shown that an admissible heuristic of the dual state of S is an admissible heuristicfor S. This provides opportunities for additional heuristic evaluations. An exact definition of the class of problems where dualityexists is provided. A new search algorithm, dual search, is presented which switches between the original state and the dual statewhen it seems likely that the switch will improve the chance of reaching the goal faster. The decision of when to switch is veryimportant and several policies for doing this are investigated. Experimental results show significant improvements for a number ofapplications, for using the dual state’s heuristic evaluation and/or dual search.© 2007 Elsevier B.V. All rights reserved.Keywords: Heuristics; Search; Admissibility; Duality1. Introduction and overviewThe states of many combinatorial problems (e.g., Rubik’s cube, 15-puzzle) are defined as placements of a set ofm objects into a set of n locations (where n (cid:2) m). All the different ways to put the objects into the locations with atmost one object per location defines a state space which is called a permutation state space in this paper.1 Given twostates in a permutation state space, start and goal, and a set of operators that transform one state into another, searchalgorithms such as A∗ [8] and IDA∗ [12] can be used to find the shortest sequence of operators that transform startinto goal. These algorithms use a cost function f (n) = g(n) + h(n), where g(n) is the cost to reach state n from startand h(n) is an admissible (i.e. is always a lower bound) heuristic function estimating the cost from n to goal.* Corresponding author.E-mail addresses: zahaviu@cs.biu.ac.il (U. Zahavi), felner@bgu.ac.il (A. Felner), holte@cs.ualberta.ca (R.C. Holte), jonathan@cs.ualberta.ca(J. Schaeffer).1 Strictly speaking, a permutation would require n, the number of locations, to be exactly the same as m, the number of objects. We have relaxedthis requirement and only demand that n (cid:2) m. We use the term strict permutation state space to refer to state spaces in which the states arepermutations in the strict sense (m = n).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.10.019\fU. Zahavi et al. / Artificial Intelligence 172 (2008) 514–540515The effectiveness of the search is greatly influenced by the accuracy of h(n). When h(n) is more accurate, thenumber of nodes generated in a search decreases and the goal state is reached sooner [16]. There is a tradeoff for thisreduction, however. More accurate heuristics usually consume a larger time overhead per node generated and thereforethe percentage reduction in the actual time needed to solve a problem is smaller in practice than the percentagereduction in the total number of generated nodes. Usually, the reduction in the number of generated nodes dominatesthe constant time per node and therefore a time reduction is seen as well [4,17].In this paper a new type of symmetry is discussed—duality. It is based on the observation that in strict2 permutationstate spaces, i.e., when m = n, the roles played by objects and locations are interchangeable. By reversing these roles,a state, S, can be mapped to its dual representation, Sd . Given an admissible heuristic, h, the value h(Sd ) is a lowerbound on the distance from S to the goal. Taking the maximum of h(S) and h(Sd ) can result in a better heuristicvalue for S and, hence, less search. Further, if h(Sd ) > h(S), this can be exploited by using a search algorithm thatswitches representations when it appears likely to be beneficial. The dual search algorithm searches in the original ordual search space, switching representations to whichever has a higher heuristic value.The contributions of this paper are as follows:• A formal definition of duality is given, along with precise conditions for it to be applicable. The dual of a state, S,is another state, Sd , that is easily computed from S and shares key search-related properties with S, such as beingthe same distance from the goal. Therefore any admissible heuristic for Sd can be used as an admissible heuristicfor S.• A new type of search algorithm, dual search, is introduced. It has the unusual feature that it does not necessarilyvisit all the states on the solution path that it returns. Instead, it constructs its solution path from path segmentsthat it finds in disparate regions of the state space. The jumping from region to region is effected by choosing toexpand Sd instead of S whenever doing so improves the chances of achieving a cutoff in the search.• Using the heuristic evaluation of the dual state (h(Sd )) in the search shows a significant performance improvementfor a number of domains. Adding the dual search algorithm further improves the results. For all the domainsstudied, the results represent the best in the published literature.The idea of duality is also used in the constraint satisfaction problems (CSP) literature, where flipping the rolesof variables and constraints produces a dual version of the problem. Independent of our work, Hnich et al. discussmethods to use duality in CSP applications [9]. For example, they exploit duality by choosing to solve the variationof the problem that appears to be faster to solve. By contrast, in this paper we introduce duality ideas in the context ofheuristic state-space search.The paper is organized as follows. Sections 2 and 3 present background material. In Section 4, the notion of simpleduality is defined. Simple duality is a special case of duality that only applies to strict permutation states spaces.Section 5 discusses the properties of the dual heuristic. Section 6 presents a new search algorithm based on duality,DIDA∗ (Dual IDA∗). Section 7 provides experimental evidence for the benefits of using the heuristic evaluation of thedual state and for the dual search algorithm. Section 8 provides generalization of the duality notion to a wider varietyof permutation state spaces that are not necessarily strict. Experimental results for the general case are then providedin Section 9. A summary and suggestions for future work are provided in Section 10. Preliminary versions of thispaper appeared in [7,20].2. Problem domains and permutation state spacesThis section introduces the three application domains used in this paper and gives a formal definition of permutationstate spaces. Pattern databases, used as the heuristic evaluation function for our application domains, are described.2.1. The sliding-tile puzzlesOne of the classic examples in the AI literature of a single-agent path-finding problem is the sliding-tile puzzle.Three versions of this puzzle are the 3 × 3 8-puzzle, the 4 × 4 15-puzzle and the 5 × 5 24-puzzle. They consist of a2 We also provide generalization of this idea to permutation state spaces that are not necessarily strict.\f516U. Zahavi et al. / Artificial Intelligence 172 (2008) 514–540Fig. 1. The 8-, 15- and 24-puzzle goal states.Fig. 2. 3 × 3 × 3 Rubik’s cube.square frame containing a set of numbered square tiles, and an empty position called the blank. The legal operatorsare to slide any tile that is horizontally or vertically adjacent to the blank into the blank position. The problem isto rearrange the tiles from some random initial configuration into a particular desired goal configuration. The statespace grows exponentially in size as the number of tiles increases, and it has been shown [19] that finding optimalsolutions to the sliding tile problem is NP-complete. The 8-puzzle contains 9!/2 (181,440) reachable state, the 15-puzzle contains about 1013 reachable states, and the 24-puzzle contains almost 1025 states. The goal states of thesepuzzles are shown in Fig. 1.The classic heuristic function for the sliding-tile puzzles is called Manhattan distance. It is computed by countingthe number of grid units that each tile is displaced from its goal position, and summing these values over all tiles,excluding the blank. Since each tile must move at least its Manhattan distance to its goal position, and a legal moveonly moves one tile, the Manhattan distance is a lower bound on the minimum number of moves needed to solve aproblem instance.2.2. Rubik’s cubeRubik’s cube was invented in 1975 by Erno Rubik of Hungary. It is one of the most famous combinatorial puzzleof our time. The standard version consists of a 3 × 3 × 3 cube (Fig. 2), with different colored stickers on each of theexposed squares of the sub-cubes, or cubies. Any 3 × 3 × 1 edge plane of the cube can be rotated 90, 180, or 270degrees relative to the rest of the cube. In the goal state, all the squares on each side of the cube are the same color. Thepuzzle is scrambled by making a number of random moves, and the task is to restore the cube to its original goal state.There are about 4 × 1019 different reachable states. There are 20 movable cubies and 6 stable cubies in the center ofeach face. The movable cubies can be divided into eight corner cubies, with three faces each, and twelve edge cubies,with two faces each. Corner cubies can only move among corner positions, and edge cubi",
            {
                "entities": [
                    [
                        3067,
                        3095,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1064–1093www.elsevier.com/locate/artintAnalysing inconsistent first-order knowledgebasesJohn Grant a,b, Anthony Hunter c,∗a Department of Mathematics, Towson University, Towson, MD 21252, USAb Department of Computer Science, University of Maryland, College Park, MD 20742, USAc Department of Computer Science, University College London, Gower Street, London WC1E 6BT, UKReceived 31 December 2006; received in revised form 14 November 2007; accepted 14 November 2007Available online 22 November 2007AbstractIt is well-known that knowledgebases may contain inconsistencies. We provide a framework of measures, based on a first-orderfour-valued logic, to quantify the inconsistency of a knowledgebase. This allows for the comparison of the inconsistency of diverseknowledgebases that have been represented as sets of first-order logic formulae. We motivate the approach by considering someexamples of knowledgebases for representing and reasoning with ontological knowledge and with temporal knowledge. Analysingontological knowledge (including the statements about which concepts are subconcepts of other concepts, and which conceptsare disjoint) can be problematical when there is a lack of knowledge about the instances that may populate the concepts, andanalysing temporal knowledge (such as temporal integrity constraints) can be problematical when considering infinite linear timelines isomorphic to the natural numbers or the real numbers or more complex structures such as branching time lines. We addressthese difficulties by providing algebraic measures of inconsistency in first-order knowledgebases.© 2007 Elsevier B.V. All rights reserved.Keywords: Measuring inconsistency; Paraconsistent logics; Inconsistency tolerance; Analysing inconsistency; Conflict resolution1. IntroductionThe need for handling inconsistencies in knowledgebases has been well recognised in recent years. Inconsistenciesmay arise for various reasons such as when information sources are merged or in the presence of integrity constraints.The use of first-order logic becomes problematical because a single (local) inconsistency leads to the (global) incon-sistency of the entire knowledgebase. Paraconsistent logics allow for local inconsistency without global inconsistency.Paraconsistent reasoning is important in handling inconsistent information, and there have been a number of proposalsfor paraconsistent logics, such as Da Costa’s Cω logics [11], developments of C systems [9], Priest’s three-valued logicLPm [33], Belnap’s four-valued logic [5], and versions of Belnap’s four-valued logic restricted to minimal models [1],for reasoning with inconsistent information. Further approaches, such as techniques for analysing and querying incon-sistent databases and knowledgebases [2,3,12,31], techniques for merging knowledgebases [4,7,27,28], and analyticaltechniques for inconsistent software specifications [19], have been proposed (for reviews of some applications see* Corresponding author.E-mail addresses: jgrant@towson.edu (J. Grant), a.hunter@cs.ucl.ac.uk (A. Hunter).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.006\fJ. Grant, A. Hunter / Artificial Intelligence 172 (2008) 1064–10931065[6,16]). Whilst these methods provide potentially valuable ways of using inconsistent knowledgebases, they do notprovide an adequate way of summarising the nature of the inconsistencies.Our interest in this paper is in providing a measure for the inconsistency of a knowledgebase represented as a set offirst-order logic formulae. By providing such a measure we can compare different knowledgebases and evaluate theirquality of information. If given the opportunity to choose between different knowledgebases, we may try to choosethe one that is least inconsistent.Four-valued paraconsistent logics have been used as the basis of an approach to measuring inconsistency in knowl-edgebases [14,20,21]. In this, each inconsistent set of formulae is reflected in the four-valued models for the set, andthen the inconsistency is measured in the models. This approach to measuring inconsistency has already been seen asa useful tool in analysing a diverse range of information types including news reports [23], integrity constraints [14],ontologies [32], software specifications [8,30], and ecommerce protocols [10]. However, this approach of measuringinconsistency has been restricted to either a propositional language or a language with predicates but without functionsymbols.In this paper, we present a framework for measuring inconsistency for a full first-order language, together withexamples in analysing ontological and temporal knowledge. Dealing with a full first-order language is potentiallyimportant in diverse applications (such as reasoning about specifications [13]), but it does also raise issues with regardto analysing arbitrarily large, including infinite, domains. To address these issues, our framework provides algebraicmeasures of inconsistency in first-order knowledgebases.2. Overview of our approachIn this section, we provide an informal overview of our approach together with some examples to motivate andillustrate our approach. We start by recalling that many diverse applications in computer science require the ability torepresent and reason with knowledge in a form that is more expressive than propositional logic. Furthermore, in manyapplications, there is a need to analyse inconsistency arising in knowledge.To illustrate the need for systems and/or users to analyse inconsistency, consider diverse applications such as toolsfor analysing formal software specifications (where parts of the specifications may have come from different sources),systems for disambiguation in natural language processing (where there are conflicting syntactic, semantic, or prag-matic parses of the text/speech being parsed), and tools for developing ontologies based on description logics (wherethere may be multiple ontologies perhaps from multiple sources that need to be combined by an ontology engineerinto a single coherent and consistent ontology). In these examples, and in many other potential applications, there iseither the need for an automatic system to analyse the degree of inconsistency arising in the available knowledge, orthere is the need for a system to provide a user (such as a software or knowledge engineer) with an assessment of thedegree of inconsistency arising in the available knowledge. Once the system/user has access to an assessment of thedegree of inconsistency, the system/user can make a more intelligent and better informed decision on the course ofaction to take on the inconsistency.In this paper we assume a knowledgebase is a set of formulae of classical first-order logic. We impose no restrictionson this. It can include function symbols, variable symbols, and quantifier symbols. And of course, a knowledgebasecan be inconsistent, and indeed, any formula in a knowledgebase may be inconsistent.Our approach to measuring inconsistency in a knowledgebase is to consider the “four-valued models” of it. Each ofthese models is based on what we call a bistructure, which essentially is a pair of classical interpretations: One of theseinterpretations is used for the satisfaction of positive literals (i.e. the atoms), and the other is used for the satisfactionof negative literals. So in a bistructure, both an atom and its negation, or neither, can be satisfied. This gives a four-valued semantics, so that an atom may be regarded as being exactly one of “true” or “false” or “both true and false”or “neither true nor false” in a bistructure. The semantics for more complex formulae is given by a generalisation ofBelnap’s four valued logic, which is a paraconsistent logic that we call tolerant logic. For our purposes, this semanticsis simple and the set of models for any knowledgebase is always nonempty.Given a bistructure, we apply a simple measure of inconsistency, denoted Inc, that gives the proportion of the tuplesin the bistructure that are in conflict. The amount of conflict in a bistructure is the number of tuples that are both trueand false. This is normalised by the total number of tuples that are possible in the interpretations (which is a functionof the size of the domain), so we get a value in the [0, 1] interval. For example, if we have a bistructure with just onemonadic relation R and two domain objects a1 and a2, and the first classical interpretation has both (cid:3)a1(cid:4) and (cid:3)a2(cid:4) (for\f1066J. Grant, A. Hunter / Artificial Intelligence 172 (2008) 1064–1093R), and the second classical interpretation has (cid:3)a1(cid:4) (for ¬R), then there is conflict with respect to the tuple (cid:3)a1(cid:4) andso the proportion of tuples in conflict is 1/2. Note, this measure is not restricted to Herbrand interpretations.We then generalise this measure of inconsistency to sets of bistructures. In order to set up our framework, andconsider various properties, we deal with sets of bistructures in general. But in practice, if we want to analyse aknowledgebase, we consider the set of models for the knowledgebase.For a knowledgebase, since our measure of inconsistency of a model is dependent on the domain size, we considerthe models for each domain size in turn. For each domain size, we find the minimum degree of inconsistency in amodel from the models of this size, using a function denoted MicroInc, and then we summarise this value obtained foreach size in the form of a ratio of univariate polynomial functions (i.e. a rational function) where the variable is thecardinality of the domain. The polynomial that is the numerator gives the minimum number of tuples in conflict forthe models of domain size n, and the polynomial that is the denominator gives the maximum number of tuples in themodels of domain size n. By representing the degree of inconsistency in the form of such a rational function, we havea concise su",
            {
                "entities": [
                    [
                        3176,
                        3204,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 218 (2015) 23–55Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe limits of decidability in fuzzy description logics with general concept inclusions, Rafael Peñaloza a,b,∗, Felix Distel a,∗Stefan Borgwardt a,∗a Institute for Theoretical Computer Science, Technische Universität Dresden, 01062 Dresden, Germanyb Center for Advancing Electronics Dresden, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 25 November 2013Received in revised form 11 August 2014Accepted 25 September 2014Available online 2 October 2014Keywords:Fuzzy description logicsTriangular normsOntology consistencyDecidability1. IntroductionFuzzy description logics (DLs) can be used to represent and reason with vague knowledge. This family of logical formalisms is very diverse, each member being characterized by a specific choice of constructors, axioms, and triangular norms, which are used to specify the semantics. Unfortunately, it has recently been shown that the consistency problem in many fuzzy DLs with general concept inclusion axioms is undecidable. In this paper, we present a proof framework that allows us to extend these results to cover large classes of fuzzy DLs. On the other hand, we also provide matching decidability results for most of the remaining logics. As a result, we obtain a near-universal classification of fuzzy DLs according to the decidability of their consistency problem.© 2014 Elsevier B.V. All rights reserved.Description logics (DLs) [1] are a family of knowledge representation formalisms, designed to represent the terminological knowledge of a domain in a formally well-understood way. They form the base language for many large-scale knowledge bases, like Snomed CT1 and the Gene Ontology,2 but arguably their largest success to date is the recommendation by the W3C of the DL-based language OWL as the standard ontology language for the Semantic Web.3 DLs essentially allow to state relations between concepts, which represent subsets of a specific domain containing exactly those domain elements that share certain properties. Roles correspond to binary relations that allow to state connections between concepts. For example, the concept of a human father can be expressed asHuman (cid:3) Male (cid:3) ∃hasChild.(cid:5),which describes the set of all humans that are male and have a child. Here, Human and Male are atomic concept names, whereas hasChild is a role name. Domain-specific relations between concepts can be expressed in axioms such asbob : Male,Human (cid:6) ∀hasChild.Human,* Corresponding authors. Tel.: +49 351 463 38231; fax: +49 351 463 37959.E-mail addresses: stefborg@tcs.inf.tu-dresden.de (S. Borgwardt), felix@tcs.inf.tu-dresden.de (F. Distel), penaloza@tcs.inf.tu-dresden.de (R. Peñaloza).1 http :/ /www.ihtsdo .org /snomed-ct/.2 http :/ /www.geneontology.org/.3 http :/ /www.w3 .org /TR /owl2-overview/.http://dx.doi.org/10.1016/j.artint.2014.09.0010004-3702/© 2014 Elsevier B.V. All rights reserved.\f24S. Borgwardt et al. / Artificial Intelligence 218 (2015) 23–55saying that bob is a male individual, and that every human can only have human children, respectively. The former axiom is called an assertion, the latter a general concept inclusion (GCI). In DLs, various reasoning problems over a set of such axioms, called an ontology or knowledge base, are studied. The most fundamental one is to decide whether an ontology is consistent; that is, if the restrictions expressed by its axioms can actually be realized in a model. Different sets of constructors for expressing concepts, such as conjunctions ((cid:3)) or value restrictions (∀), lead to logics of varying expressivity, resulting in differences between the computational complexity of their consistency problems. For example, in the inexpressive DL EL, consistency is trivial, whereas other reasoning problems such as subsumption have only polynomial complexity. In the more expressive ALC, consistency without GCIs is PSpace-complete, and is ExpTime-complete in the presence of GCIs. The very expressive SROIQ, the formalism underlying the OWL 2 Direct Semantics, has a 2-NExpTime-complete consistency problem.In their classical form, however, DLs are not well-suited for representing and reasoning with the vagueness and impre-cision that are endemic to many knowledge domains, e.g. in the bio-medical fields. For example, one of the most common symptoms of diseases is the presence of fever, which is characterized by a high body temperature. Clearly, it is not possible to precisely distinguish high body temperatures from non-high body temperatures. In order to appropriately represent this knowledge, it is necessary to use a formalism capable of handling imprecision. Fuzzy variants of DLs have been introduced as a means of handling imprecise terminological knowledge. This is achieved by interpreting concepts as fuzzy sets. In a nut-shell, a fuzzy set associates with every element of the universe a value from the interval [0, 1], which expresses its degree of membership to the set. This makes it possible to express, e.g. that 38 °C is a high body temperature to degree 0.7, while 39 °C belongs to the same concept with degree 1.Compared to classical DLs, fuzzy DLs have an additional degree of freedom for choosing how to interpret the logical constructors. A standard approach, inherited from mathematical fuzzy logic [2,3], is to use a continuous triangular norm (t-norm) [4] to interpret conjunction. The three most commonly used t-norms, called Gödel, Łukasiewicz, and product, have the interesting property that all other continuous t-norms can be represented by composing copies of them in a certain way. From the chosen t-norm ⊗, the semantics of all other logical constructors is determined, generalizing the properties of the classical operators. Ontologies of fuzzy DLs generalize classical ontologies by annotating each axiom with a fuzzy value that specifies the degree to which the axiom holds. For example, a fuzzy assertion like (cid:9)bob : ∃hasFever.High ≥ 0.6(cid:11) can specify that an individual (in this case bob) belongs to a fuzzy concept (∃hasFever.High) at least to a certain degree (e.g. 0.6).For the last two decades, research on fuzzy DLs has covered many different logics, from the inexpressive EL [5] to the expressive SROIQ(D) [6], from simple fuzzy semantics [7] to ones covering all continuous t-norms [8], from acyclic terminologies [9] to GCIs [10]. Fuzzy reasoning algorithms were implemented [11,12] and the use of fuzziness in practical applications was studied [13,14]. Recently, the focus in the area changed when some tableau-based algorithms for DLs allowing general concept inclusions were shown to be incorrect [15,16]. This raised doubts about the decidability of the consistency problem in these logics, and eventually led to a plethora of undecidability results for fuzzy DLs [16–19]. In particular, one does not need to go beyond the expressivity of ⊗-ALC to get undecidability [18,19].The main goal of this paper is to characterize the limits of decidability in fuzzy DLs; in other words, we want to partition the family of fuzzy DLs according to the decidability of consistency in them. For the cases where the problem is decidable, we are also interested in finding precise complexity bounds. Given the sheer number of fuzzy DLs available, identified by the set of constructors, types of axioms, and t-norm that they use, it is infeasible to study each of them independently. Instead, we develop general methods for proving (un)decidability of these logics.Most of the known undecidability results [16,17,19] focus on one specific fuzzy DL; that is, undecidability is proven for a specific set of constructors, axioms, and chosen semantics. The papers [16,17] show undecidability of (extensions of) ⊗-ALCf,≥, where ⊗ is the product t-norm, while [19] shows the same for the Łukasiewicz t-norm. The only exception is [18], where undecidability is shown for ⊗-IALf,= for all t-norms ⊗ “starting” with the product t-norm. Abstracting from the details of each specific logic, all these proofs of undecidability follow the same basic pattern. In essence, it is shown that the logic satisfies a series of properties that allows it to encode the Post Correspondence Problem [20].In the first part of this paper, we generalize these ideas and describe a set of properties that together imply undecid-ability of a fuzzy DL. We use this general framework to strengthen all previously known undecidability results to cover all continuous t-norms except the Gödel t-norm, for which the problem is decidable [21]. Additionally, we present some vari-ants on the same ideas that allow us to prove undecidability of fuzzy DLs that do not fit precisely into the main framework. For instance, we show that the fairly inexpressive fuzzy DL ⊗-IEL= is undecidable for any continuous t-norm ⊗ except the Gödel t-norm. This can be strengthened to the even less expressive ⊗-NEL if ⊗ starts with the Łukasiewicz t-norm. These logics are of interest since they correspond to fuzzy variants of the prototypical classical DL ALC. Indeed, they have the same expressivity as ALC when their semantics is restricted to the two classical truth values.In the second part of the paper, we complement these results by considering fuzzy DLs based on t-norms that do not start with the Łukasiewicz t-norm, which in particular includes the product and Gödel t-norms. Under this assumption, we show that consistency is decidable even for the very expressive logic ⊗-SROIQf,≥ if axioms are not allowed to express upper bounds. We show an even stronger result: under these conditions, an ontology is consistent w.r.t. fuzzy semantics iff it is consistent w.r.t. crisp semantics, i.e. using only the classical truth values 0 and 1. Thus, ontology consistency in ⊗-SHOI is ExpTime-complete, and in ⊗-SROIQ it is 2-NExpTime-complete. If these restrictions are not met, then the p",
            {
                "entities": [
                    [
                        2955,
                        2983,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 1–24Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInconsistency measures for probabilistic logicsMatthias ThimmInstitute for Web Science and Technologies, Universität Koblenz–Landau, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 23 February 2012Received in revised form 27 July 2012Accepted 4 February 2013Available online 7 February 2013Keywords:Inconsistency measuresInconsistency managementProbabilistic reasoningProbabilistic conditional logic1. IntroductionInconsistencies in knowledge bases are of major concern in knowledge representation andreasoning. In formalisms that employ model-based reasoning mechanisms inconsistenciesrender a knowledge base useless due to the non-existence of a model.In order toinconsistencies are mandatory.restore consistency an analysis and understanding ofRecently, the field of inconsistency measurement has gained some attention for knowledgerepresentation formalisms based on classical logic. An inconsistency measure is a toolthat helps the knowledge engineer in obtaining insights into inconsistencies by assessingtheir severity. In this paper, we investigate inconsistency measurement in probabilisticincorporates uncertainty and focuses on the role ofconditionalconditionals, i.e. if–then rules. We do so by extending inconsistency measures for classicallogic to the probabilistic setting. Further, we propose novel inconsistency measures that arespecifically tailored for the probabilistic case. These novel measures use distance measuresto assess the distance of a knowledge base to a consistent one and therefore takes thecrucial role of probabilities into account. We analyze the properties of the discussedmeasures and compare them using a series of rationality postulates.logic, a logic that© 2013 Elsevier B.V. All rights reserved.The field of knowledge representation and reasoning [4] is concerned with formal representations of knowledge andhow these formalizations can be used for reasoning, i.e., how new information can be automatically inferred using a formalsystem. One of the big issues in knowledge representation is accuracy. Usually, the term “knowledge” is used to describestrict or objective information that is considered to be absolutely true in the given frame of reference, i.e. the real world.The counterpart, denoted by “subjective knowledge” or “beliefs”, is used to describe information that is assumed to be true bythe individual under consideration. While strict knowledge describes—by definition—a consistent state, subjective knowledgemight be flawed in several aspects. Besides being incorrect with respect to the real world, subjective knowledge can beincomplete, uncertain, or inconsistent. That is, for some piece of information I it might be unknown whether I is true orfalse (incompleteness), I might be believed only to a certain degree (uncertainty), or I might be in conflict with anotherpiece of information Iimplies that at least(inconsistency). Note that inconsistency of two pieces of information I and Iwith the state of the real world, anone of them is incorrect. However, even without the possibility to compare I and Iinconsistency can be detected by a being capable of reasoning, which is not necessarily true for incorrect information ingeneral. In this paper, we do not consider the general problem of incorrect information and always assume that representedpieces of information are subjective. However, as some terms like knowledge base have been established in the literature weadapt those conventions.(cid:2)(cid:2)(cid:2)Within the field of knowledge representation and reasoning there are several subfields that deal with incomplete, un-certain, and/or inconsistent knowledge such as default [27] and defeasible reasoning [19], argumentation [2,26], or possibilisticE-mail address: thimm@uni-koblenz.de.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.001\f2M. Thimm / Artificial Intelligence 197 (2013) 1–24and fuzzy reasoning [33]. Among the most established logical frameworks for dealing with uncertainty is probability theory[23,25]. There have been numerous works on combining probability theory with knowledge representation. For example,Bayesian networks and Markov nets allow for derivation of uncertain beliefs from other uncertain beliefs. Especially inapplication areas such as medical diagnosis, where the user has to rely crucially on the certainty of individual recommen-dations, reasoning using probabilistic models of knowledge serves well [24].In this paper we employ probabilistic conditional logic [28] for representing uncertain knowledge. In probabilistic condi-tional logic, knowledge is represented using probabilistic conditionals (ψ | φ)[p] with the intuitive meaning “if φ is truethen ψ is true with probability p”. Probabilistic conditional logic has been studied extensively under several aspects, e.g.effective reasoning mechanisms [9], default reasoning [20], or extensions with first-order logic fragments [15,16]. Moreover,the field of information theory provides a nice solution to the problem of incomplete information in probabilistic conditionallogic. Using the principle of maximum entropy [23] one can complete uncertain and incomplete information in order togain new information that was unspecified before, see also [28,14]. The expert system SPIRIT [30] is a working system thatemploys reasoning based on the principle of maximum entropy. It has been applied to various fields of operations researchsuch as project risk management [1] and portfolio selection [29]. Though reasoning with maximum entropy can deal withincomplete and uncertain information, it is not suitable for reasoning with inconsistent information. But inconsistency is aubiquitous matter and human beings have to deal with it all the time. In knowledge engineering and expert system design itbecomes most apparent when multiple experts try to build up a common knowledge base. However, the issue of extendingreasoning with maximum entropy to inconsistent knowledge bases has been dealt with in the literature only little so far,cf. [31,8,6].In this paper, we investigate inconsistencies in probabilistic conditional logic from an analytical perspective. One wayto analyze inconsistencies is by measuring them. An inconsistency measure is a function that quantifies the severity ofinconsistencies in knowledge bases. An inconsistency value of zero indicates no inconsistency (and therefore consistency)while the larger the inconsistency value, the more severe the inconsistency. Thus, an inconsistency measure can be seen asthe counterpart to an information measure [5] for the case of inconsistent information. Recently, there has been a gain inattention to approaches for measuring inconsistency in classical logics, see e.g. [13,11]. In general, an inconsistency measurecan be used to support the knowledge engineer in building a consistent knowledge base or repairing an inconsistent one. Forexample, Grant and Hunter [11] develop an approach for stepwise inconsistency resolution of inconsistent knowledge basesthat makes use of inconsistency measures. In their approach, a knowledge base is repaired by e.g. deleting or weakeningformulas. There, inconsistency measures serve as heuristics for selecting the right formula that has to be modified, i.e. byselecting that one that maximizes consistency gain. Inconsistency measures can also be used to determine which pieces ofinformation are most responsible for producing the inconsistency. In [13,36] the Shapley value [32] is used to distributethe inconsistency value of a knowledge base among the individual formulas. In a setting where knowledge is merged fromdifferent sources this information can help in identifying the responsible contributors.However, classical approaches for inconsistency measurement do not grasp the nuances of probabilistic knowledge andallow only for a very coarse assessment of the severity of inconsistencies. In particular, those approaches do not take thecrucial role of probabilities into account and exhibit a discontinuous behavior in measuring inconsistency. That is, a slightmodification of the probability of a conditional in a knowledge base may yield a discontinuous change in the value ofthe inconsistency. Consequently, we develop novel inconsistency measures that are more apt for the probabilistic setting.We do so by continuing and largely extending previous work [34–36]. In particular, the contributions of this paper are asfollows. First, we propose and discuss a series of rationality postulates for inconsistency measures in probabilistic conditionallogic. Many of those postulates are inspired by similar properties for the classical case—see e.g. [13]—and others specificallyaddress demands arising from the use of a probabilistic logic, such as the demand for a continuous behavior with respectto changes in the knowledge base. Second, we extend several inconsistency measures that were proposed for the classicalcase to the more expressive framework of probabilistic conditional logic and investigate their properties with respect to therationality postulates. Third, we pick up an extended logical formalization [21] of the inconsistency measure proposed in[34] for probabilistic conditional logic, generalize it, and define a family of inconsistency measures based on minimizing thedistance of a knowledge base to a consistent one. We also propose a novel compound measure that solves an issue with theprevious measure. We thoroughly investigate the properties of all measures with respect to the rationality postulates anddiscuss their advantages and disadvantages with the use of examples.The rest of this paper is organized as follows. We continue in Section 2 with an overview on probabilistic conditionallogic and introduce further notation. In Section 3 we approach the problem of incons",
            {
                "entities": [
                    [
                        4011,
                        4039,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 140–178www.elsevier.com/locate/artintMEBN: A language for first-order Bayesian knowledge basesKathryn Blackmond LaskeyDepartment of Systems Engineering and Operations Research, MS4A6, George Mason University, Fairfax, VA 22030, USAReceived 1 March 2006; received in revised form 13 August 2007; accepted 10 September 2007Available online 4 October 2007AbstractAlthough classical first-order logic is the de facto standard logical foundation for artificial intelligence, the lack of a built-in,semantically grounded capability for reasoning under uncertainty renders it inadequate for many important classes of problems.Probability is the best-understood and most widely applied formalism for computational scientific reasoning under uncertainty.Increasingly expressive languages are emerging for which the fundamental logical basis is probability. This paper presents Multi-Entity Bayesian Networks (MEBN), a first-order language for specifying probabilistic knowledge bases as parameterized fragmentsof Bayesian networks. MEBN fragments (MFrags) can be instantiated and combined to form arbitrarily complex graphical prob-ability models. An MFrag represents probabilistic relationships among a conceptually meaningful group of uncertain hypotheses.Thus, MEBN facilitates representation of knowledge at a natural level of granularity. The semantics of MEBN assigns a probabil-ity distribution over interpretations of an associated classical first-order theory on a finite or countably infinite domain. Bayesianinference provides both a proof theory for combining prior knowledge with observations, and a learning theory for refining a repre-sentation as evidence accrues. A proof is given that MEBN can represent a probability distribution on interpretations of any finitelyaxiomatizable first-order theory.© 2007 Elsevier B.V. All rights reserved.Keywords: Bayesian network; Graphical probability models; Knowledge representation; Multi-entity Bayesian network; Probabilistic logic;Uncertainty in artificial intelligence1. IntroductionFirst-order logic is primary among logical systems from both a theoretical and a practical standpoint. It has beenproposed as a unifying logical foundation for defining extended logics and interchanging knowledge among applica-tions written in different languages. However, its applicability has been limited by the lack of a coherent semantics forplausible reasoning. Among the many proposed logics for plausible inference, probability is the strongest contenderas a universal standard of comparison for plausible reasoning systems. Probability has proved its worth in applicationsfrom a wide variety of problem domains, and is a rationally justified calculus for plausible inference under uncertainty(e.g., [18,36,41,69]).Application of probability to complex, open-world problems requires languages based on expressive probabilisticlogics. The development of sufficiently expressive probabilistic logics has been hindered by the lack of modularityof probabilistic reasoning, the intractability of worst-case probabilistic inference, and the difficulty of ensuring thatE-mail address: klaskey@gmu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.006\fK.B. Laskey / Artificial Intelligence 172 (2008) 140–178141probability assessments give rise to a well-defined and unique probability distribution. The number of probabilitiesrequired to express a fully general probability distribution over truth-values of a collection of assertions is exponen-tial in the number of assertions, making a brute-force approach to specification and inference infeasible for all butthe simplest problems. These difficulties have been addressed by exploiting independence relationships to achieveparsimonious representation and efficient inference [59,61]. Recent years have seen a rapid evolution of increasinglypowerful languages for computational probabilistic reasoning (e.g., [10,16,27,30,31,35,40,43,44,46,48,56,60,64,66,68,71]).This paper presents multi-entity Bayesian networks (MEBN), a language for representing first-order probabilisticknowledge bases. The fundamental unit of representation in MEBN is the MFrag, a parameterized Bayesian networkfragment that represents uncertain relationships among a small collection of related hypotheses. MFrags allow knowl-edge to be specified at a natural level of granularity. Dependence relationships and local distributions are specified forconceptually meaningful clusters of related hypotheses. An MFrag can be instantiated multiple times by binding its ar-guments to different entities. MEBN thus provides a compact language for expressing complex graphical models withrepeated structure. A MEBN theory consists of a set of MFrags that satisfies consistency conditions ensuring existenceof a unique probability distribution over its random variables. MEBN theories can be used to reason consistently aboutcomplex expressions involving nested function application, arbitrary logical formulas, and quantification.The remainder of the paper is organized as follows. Section 2 provides an overview of formalisms for knowledgerepresentation and reasoning under uncertainty. Section 3 defines the MEBN language. Section 4 defines semantics,presents results on expressive power, and discusses inference. Section 5 reviews current research on expressive first-order languages. The final section is a summary and discussion. Proofs and algorithms are given in Appendix A.2. Probability and logicDavis [17] defines a logic as a schema for defining languages to describe and reason about entities in different do-mains of application. Certain key issues in representation and inference arise across a variety of application domains.A logic encodes particular approaches to these issues in a form that can be reused across languages, domains, andtheories.By far the most commonly used, studied, and implemented logical system is first-order logic (FOL), inventedindependently by Frege and Peirce in the late nineteenth century [24,62]. First-order logic is applied by defining a setof axioms, or sentences that make assertions about a domain. The axioms, together with the set of logical consequencesof the axioms, comprise a theory of the domain. Until referents for the symbols are specified, a theory is a syntacticstructure devoid of meaning. An interpretation for a theory specifies a definition of each constant, predicate andfunction symbol in terms of the domain. Each constant symbol denotes a specific entity; each predicate denotes aset containing the entities for which the predicate holds; and each function symbol denotes a function defined on thedomain. The logical consequences of a set of axioms consist of the sentences that are true in all interpretations, alsocalled the valid sentences.Special-purpose logics built on first-order logic give pre-defined meaning to reserved constant, function and/orpredicate symbols. Such logics provide built-in constructs useful in applications. There are logics that provide con-stants, predicates, and functions for reasoning about types, space and time, parts and wholes, actions and plans, etc.When a logic is applied to reason about a particular domain, the modeler assigns meaning to additional domain-specific symbols, and provides axioms to assert important properties of their intended referents. Formal ontologies[33,70] are usually expressed in languages based on first-order logic or one of its subsets.A first-order theory implies truth-values for the valid sentences and their negations, but provides no means toevaluate the plausibility of other sentences. Plausible reasoning is fundamental to intelligence, and plausible reason-ing logics have been an active area of research in artificial intelligence. Because probability is not truth-functional,naïve attempts to generalize the standard logical connectives and quantifiers to create combining rules for probabil-ities encountered many difficulties. Graphical probability models have become popular as a parsimonious languagefor representing knowledge about uncertain phenomena, a formalism for representing probabilistic knowledge in alogically coherent manner, and an architecture to support efficient algorithms for inference, search, optimization, andlearning. A graphical probability model expresses a probability distribution over a collection of related hypotheses asa graph and a collection of local probability distributions. The graph encodes dependencies among the hypotheses.The local probability distributions specify numerical probability information. Together, the graph and the local dis-\f142K.B. Laskey / Artificial Intelligence 172 (2008) 140–178Fig. 1. Bayesian network for diagnostic task.tributions specify a joint distribution that respects the conditional independence assertions encoded in the graph, andhas marginal distributions consistent with the local distributions [14,42,50,61,75]. A Bayesian network (e.g., [42,59,61] is a graphical probability model in which the dependency graph is an acyclic directed graph. An example of aBayesian network for a diagnostic task is given in Fig. 1. This Bayesian network represents a joint distribution overthe Cartesian product of the possible values of the random variables depicted in the graph.Some authors assume that random variables in a Bayesian network have finitely many possible values. Some requireonly that each random variable have an associated function mapping values of its parents to probability distributionson its set of possible values. In an unconstrained local distribution on finite-cardinality random variables, a separateprobability is specified for each value of a random variable given each combination of values of its parents. Becausethe complexity of specifying local distributions is exponential in the number of parents, constrained families of localdistributions are often used to simplify specification and inference. E",
            {
                "entities": [
                    [
                        3250,
                        3278,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 195 (2013) 440–469Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintImproving resource allocation strategies against human adversariesin security games: An extended studyRong Yang a,∗, Christopher Kiekintveld b, Fernando Ordóñez a,c, Milind Tambe a, Richard John aa University of Southern California, Los Angeles, CA, USAb University of Texas El Paso, El Paso, TX, USAc University of Chile, Santiago, Chilea r t i c l ei n f oa b s t r a c tArticle history:Received 16 December 2011Received in revised form 13 November 2012Accepted 15 November 2012Available online 20 November 2012Keywords:Bounded rationalityStackelberg gamesDecision-makingStackelberg games have garnered significant attention in recent years given their deploy-ment for real world security. Most of these systems, such as ARMOR, IRIS and GUARDShave adopted the standard game-theoretical assumption that adversaries are perfectly ra-tional, which is standard in the game theory literature. This assumption may not hold inreal-world security problems due to the bounded rationality of human adversaries, whichcould potentially reduce the effectiveness of these systems.In this paper, we focus on relaxing the unrealistic assumption of perfectly rational adver-sary in Stackelberg security games. In particular, we present new mathematical models ofhuman adversaries’ behavior, based on using two fundamental theory/method in humandecision making: Prospect Theory (PT) and stochastic discrete choice model. We also pro-vide methods for tuning the parameters of these new models. Additionally, we proposea modification of the standard quantal response based model inspired by rank-dependentexpected utility theory. We then develop efficient algorithms to compute the best responseof the security forces when playing against the different models of adversaries. In orderto evaluate the effectiveness of the new models, we conduct comprehensive experimentswith human subjects using a web-based game, comparing them with models previouslyproposed in the literature to address the perfect rationality assumption on part of the ad-versary.Our experimental results show that the subjects’ responses follow the assumptions ofour new models more closely than the previous perfect rationality assumption. We alsoshow that the defender strategy produced by our new stochastic discrete choice modeloutperform the previous leading contender for relaxing the assumption of perfect rational-ity. Furthermore, in a separate set of experiments, we show the benefits of our modifiedstochastic model (QRRU) over the standard model (QR).1© 2012 Elsevier B.V. All rights reserved.* Corresponding author.E-mail address: yangrong@usc.edu (R. Yang).1 This paper significantly extends our previous conference paper (Yang et al., 2011) [1] by providing (i) new methods for setting parameters of theProspect Theory model; (ii) an additional variant of Quantal Response model and a new algorithm to compute defender strategies against the new model;(iii) a more comprehensive set of experiments which includes multiple new algorithms and updated settings for the algorithms; (iv) new analysis of therobustness of different defender strategies and the predictive accuracy of different models; (v) additional discussion of related work.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.11.004\fR. Yang et al. / Artificial Intelligence 195 (2013) 440–4694411. IntroductionStackelberg game models have recently become important tools for analyzing real-world security resource allocationproblems, such as critical infrastructure protection [2] and robot patrolling strategies [3,4]. These models provide a sophisti-cated approach for generating unpredictable, randomized strategies that mitigate the ability of attackers to find weaknessesusing surveillance. The ARMOR [5], IRIS [6], GUARDS [7] and PROTECT [8] systems are notable examples where this approachhas been used to develop decision-support systems for real-world security problems. One of the key sets of assumptionsthat these systems make are about how attackers will choose attack strategies based on their preferences and observationsof the security policy. Typically, such systems have applied the standard game-theoretic assumption that attackers are per-fectly rational and will strictly maximize their expected utility. This is a reasonable starting point for the first generationof deployed systems. Unfortunately, this standard game-theoretic assumption leaves open the possibility that the defender’sstrategy is not robust against attackers using different decision procedures, and it fails to exploit known weaknesses in thedecision-making of human attackers.It is widely accepted that standard game-theoretic assumptions of perfect rationality are not ideal for predicting thebehavior of humans in multi-agent decision problems [9,10]. A large variety of alternative models have been studied inbehavioral game theory and cognitive psychology that capture some of the deviations of human decisions from perfectrationality. In the multi-agent systems community there is a growing interest in adopting these models to improve decisionsin agents that interact with humans or to provide better advice to human decision-makers in multi-agent decision-supportsystems [11,12]. Our work in this paper focuses on integrating these more realistic models of human behavior into thecomputational analysis of Stackelberg game models in security settings, which are often referred to as Stackelberg securitygames [13–15]. We also provide a case study in this general paradigm of introducing more realistic models of humanbehavior into game theoretic analysis. While there are quite a few studies looking at the problem of predicting humanbehavior, there are very few examples where this is actually included in a real decision-making system. Our work here isone of the first examples showing that this is possible, and actually improves performance in an important class of games.In order to move beyond perfect rationality assumptions to integrate more realistic models of human decision-making inreal-world security systems, we address several key challenges. First, the literature has introduced a multitude of potentialmodels on human decision making [16,9,17,10], but each of these models has its own set of assumptions and there is littleconsensus on which model is best for different types of domains. Therefore, there is an important empirical question ofwhich model best represents the salient features of human behavior in the important class of applied security games. Sec-ond, integrating any of the proposed models into a decision-support system (even for the purpose of empirically evaluatingthe model) requires developing new algorithms for computing solutions to Stackelberg security games, since most existingalgorithms are based on mathematically optimal attackers [18,19]. One notable exception is Cobra developed by Pita etal. [20]. Cobra is one example of modeling bounded rationality of human adversaries by taking into account(i) the anchoring bias of humans while interpreting the probabilities of several events [21,22];(ii) the limited computational ability of humans which may lead to deviation from their best response.To the best of our knowledge, Cobra is the best performing strategy for Stackelberg security games in experiments withhuman subjects. Thus, the open question is whether there are other approaches that allow for fast solutions and outperformCobra in addressing human behavior in security games.In this paper, we significantly expand the previous work on modeling human behavior in Stackelberg security games byimplementing and evaluating strategies based on two very important methods in literature of modeling human decision-making. The first relates to Prospect Theory (PT), which provides a descriptive framework for decision-making under un-certainty that accounts for both risk preferences (e.g. loss aversion) and variations in how humans interpret probabilitiesthrough a weighting function [16]. The other method adapts the ideas in the literature on discrete choice problems [23–26]to a game-theoretic framework with the basic premise that humans will choose better actions more frequently, but withsome noise in the decision-making process that leads to stochastic choice probabilities following a logit distribution. We firstpropose two mathematical models of the adversary’s decision-making based on Prospect Theory: one of them assumes theadversary maximizes ‘prospect’ in their decision making process and the other assumes the adversary makes bounded errorin computing such ‘prospect’ so he may deviate to a sub-optimal solution within a bound. We then propose two mathemat-ical models of how an adversary makes decisions based on using a logit discrete choice models. One model (QR) couplesthe quantal response of the adversary with the expected utility for attacking each target; the other model (QRRU) modifiesthe expected utility by adding extra weight to the target covered with minimum resources, inspired by rank-dependentexpected utility theory [27].Based on the above models of adversary decision making, computing the defender’s corresponding best response isalso challenging since it involves solving non-convex and non-linear optimization problems. We develop new techniques toaddress these problems. In particular, we develop a Mixed Integer Linear Program to compute the defender optimal strategyagainst the PT based models by representing the non-linear functions from Prospect Theory with piecewise approximations.Furthermore, we present a local search method with random restarts to compute the defender optimal strategy against thestochastic models of the adversary.\f442R. Yang et al. / Artificial Intelligence 195 (2013) 440–469Table 1Notations used in this paper.TxiqiRdiP diRaiP aiMSet of ",
            {
                "entities": [
                    [
                        3439,
                        3467,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 217 (2014) 43–75Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpatial reasoning with RCC8 and connectedness constraints in Euclidean spacesRoman Kontchakov a, Ian Pratt-Hartmann b,c,∗a Department of Computer Science and Information Systems, Birkbeck, University of London, UKb School of Computer Science, University of Manchester, UKc Institute of Mathematics and Computer Science, University of Opole, Poland, Michael Zakharyaschev aa r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2014Received in revised form 15 July 2014Accepted 31 July 2014Available online 7 August 2014Keywords:Qualitative spatial reasoningSpatial logicEuclidean spaceConnectednessSatisfiabilityComplexity◦◦The language RCC8 is a widely-studied formalism for describing topological arrangements of spatial regions. The variables of this language range over the collection of non-empty, +(Rn), and its regular closed sets of n-dimensional Euclidean space, here denoted RCnon-logical primitives allow us to specify how the interiors, exteriors and boundaries of these sets intersect. The key question is the satisfiability problem: given a finite set of atomic RCC8-constraints in m variables, determine whether there exists an m-tuple +(Rn) satisfying them. These problems are known to coincide for all of elements of RCn ≥ 1, so that RCC8-satisfiability is independent of dimension. This common satisfiability problem is NLogSpace-complete. Unfortunately, RCC8 lacks the means to say that a spatial region comprises a ‘single piece’, and the present article investigates what happens when this facility is added. We consider two extensions of RCC8: RCC8c, in which we can state that a region is connected, and RCC8c, in which we can instead state that a region has a connected interior. The satisfiability problems for both these languages are easily seen to depend on the dimension n, for n ≤ 3. Furthermore, in the case of RCC8c, we show that there exist finite sets of constraints that are satisfiable over +(R2), but only by ‘wild’ regions having no possible physical meaning. This prompts RCus to consider interpretations over the more restrictive domain of non-empty, regular +(Rn). We show that (a) the satisfiability problems for RCC8cclosed, polyhedral sets, RCP+(R) are distinct and both NP-complete; (equivalently, RCC8c+(R2) are identical and(b) the satisfiability problems for RCC8c over RC+(R2)+(R2) and RCPNP-complete; (c) the satisfiability problems for RCC8care distinct, and the latter is NP-complete. Decidability of the satisfiability problem for RCC8care not interestingly different from RCC8. We finish by answering the following question: given that a set of +(Rn), how complex is RCC8c- or RCC8cthe simplest satisfying assignment? In particular, we exhibit, for both languages, a sequence +(R2), such that the size of Φn grows polynomially of constraints Φn, satisfiable over RCPin n, while the smallest configuration of polygons satisfying Φn cuts the plane into a +(R2), RCC8cnumber of pieces that grows exponentially. We further show that, over RCagain requires exponentially large satisfying diagrams, while RCC8ccan force regions in satisfying configurations to have infinitely many components.+(R2) is open. For n ≥ 3, RCC8c and RCC8c+(R2) and RCP◦over RC-constraints is satisfiable over RC+(R) and RCP+(Rn) or RCP) over RCover RC◦◦◦◦◦© 2014 Elsevier B.V. All rights reserved.* Correspondence to: School of Computer Science, University of Manchester, UK.E-mail addresses: roman@dcs.bbk.ac.uk (R. Kontchakov), ipratt@cs.man.ac.uk (I. Pratt-Hartmann), michael@dcs.bbk.ac.uk (M. Zakharyaschev).http://dx.doi.org/10.1016/j.artint.2014.07.0120004-3702/© 2014 Elsevier B.V. All rights reserved.\f44R. Kontchakov et al. / Artificial Intelligence 217 (2014) 43–75Fig. 1. RCC8-relations over discs in R2.Fig. 2. Two arrangements of regions in the plane satisfying (1).1. IntroductionSpatial reasoning in everyday life possesses two distinctive—and related—characteristics: it is primarily concerned with extended, as opposed to point-like entities, and it typically invokes qualitative, as opposed to quantitative, concepts [1–3]. This observation has prompted consideration, within the Artificial Intelligence community, of representation languages whose variables range over some specified collection of extended spatial objects, and whose non-logical primitives are interpreted as qualitative spatial properties and relations involving those objects. As might be expected, the logical proper-ties of such languages depend on the geometry of the spaces over which they are interpreted—in most applications, two-and three-dimensional Euclidean space. The present article draws attention to some hitherto overlooked subtleties regarding this dependency.By far the best-known language for Qualitative Spatial Reasoning is RCC8, originally proposed—in essentially equivalent formulations—by Egenhofer and Franzosa [4], Egenhofer and Herring [5], Randell et al. [6] and Smith and Park [7]. This quantifier-free language allows us to specify how regions and their interiors are related to each other. It employs an infinite collection of variables r1, r2, . . . , ranging over spatial regions, together with six binary predicates: NTPP (non-tangential proper part), TPP (tangential proper part), EQ (equality), PO (partial overlap), EC (external contact) and DC (disjointness). The relations denoted by these predicates are illustrated, for closed discs in the plane, in Fig. 1. More formally: NTPP(r1, r2) if r1is included in the interior of r2; TPP(r1, r2) if r1 is included in r2 but not in its interior; PO(r1, r2) if the interiors of r1 and r2 intersect, but neither is included in the other; and EC(r1, r2) if r1 and r2 intersect, but their interiors do not. A constraintis a statement R(ri, r j), where R is one of these six predicates. For example, the constraintsEC(r1, r2), TPP(r1, r3), NTPP(r2, r4)(1)state that regions r1 and r2 are in external contact, with the former a tangential proper part of r3 and the latter a non-tangential proper part of r4. Fig. 2 shows two arrangements of regions satisfying these constraints.−1 and TPPThe RCC8-relations mentioned above were defined in [6] by means of a formalism referred to there as the Region −1, we Connection Calculus. Of these, the relations NTPP and TPP are asymmetric: counting their converses, NTPPobtain eight relations in all, hence the name RCC8. Syntactically, the original Region Connection Calculus is the language of first-order logic (with equality) over the signature consisting of a single binary predicate C , variously referred to as ‘contact’, or (confusingly) ‘connection.’ The origin of this predicate can be traced back, via Clarke [8,9], to the philosophical work of Whitehead [10] and de Laguna [11]. Semantically, one is supposed to think of C as holding between two regions just in case they share at least one point, though matters are somewhat muddied by the recurrent suggestion that this notion should be regarded as an (undefined) primitive. However, the etymology of the term RCC8 need not concern us further: it is now standardly used for the quantifier-free language featuring the six primitives illustrated in Fig. 1, and we simply follow suit. The motivation for focussing on this particular collection of primitives is not always clear. Egenhofer and Franzosa [4] and Egenhofer and Herring [5] classify relationships between regions in terms of intersections of their interiors, exteriors and boundaries and show, in particular, that only the RCC8 relations are possible between closed disc-homeomorphs in the −1 are Euclidean plane. Düntsch, Wang and McCloskey [12] observe that NTPP, TPP, EQ, PO, EC, DC, NTPPexactly the atoms of the smallest relation algebra defined on the set of closed discs in the Euclidean plane that contains the contact relation, C . In fact, Li and Ying [13] show that the set of closed disc-homeomorphs in the Euclidean planerealizes the same relation algebra. (See also Li and Li [14] for an interesting extension of this result.) In any case, the language RCC8 is by now firmly established as a basic formalism in the field of Qualitative Spatial Reasoning. In particular, −1 and TPP\fR. Kontchakov et al. / Artificial Intelligence 217 (2014) 43–7545Fig. 3. Non-regular and regular closed subsets of a) R2, and b) R3.the standard geographic query language for RDF data GeoSPARQL,1 suggested by the Open Geospatial Consortium, is based on the RCC8 relations.How are we to understand spatial reasoning in RCC8? Observe that, in (1), nothing is said about the relation between r3 and r4. What are the possibilities? A little thought suffices to convince us that DC and EC are both impossible. As we might say, the two sets of constraintsEC(r1, r2), TPP(r1, r3), NTPP(r2, r4), DC(r3, r4),EC(r1, r2), TPP(r1, r3), NTPP(r2, r4), EC(r3, r4)(2)(3)are unsatisfiable. Allowing ourselves to combine RCC8-constraints using arbitrary sentential connectives, we could express this knowledge as a formula(cid:2)(cid:3)EC(r1, r2) ∧ TPP(r1, r3) ∧ NTPP(r2, r4)(cid:2)→ ¬(cid:3)DC(r3, r4) ∨ EC(r3, r4),which we take to be true of all tuples of regions r1, . . . , r4. The validity of this formula thus represents a geometrical fact to which an agent employing RCC8 as a spatial representation language should have access. Satisfiability and validity being dual notions, it suffices, from a computational perspective, to consider only the former. And since, in this context, nothing essential is added by sentential connectives, we may confine attention in the sequel to finite sets of constraints, interpreted conjunctively. Following common practice, we refer to such a set as an RCC8-constraint network (or, simply, RCC8-network).When introducing the notion of satisfiability of RCC8-networks, we employed the term spatial region as if it needed no clarification, giving as examples the regions in Figs. 1 a",
            {
                "entities": [
                    [
                        3705,
                        3733,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1158–1193www.elsevier.com/locate/artintTemporal reasoning about fuzzy intervalsSteven Schockaert ∗,1, Martine De CockGhent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281-S9, 9000 Gent, BelgiumReceived 7 July 2007; received in revised form 14 December 2007; accepted 4 January 2008Available online 11 January 2008AbstractTraditional approaches to temporal reasoning assume that time periods and time spans of events can be accurately represented asintervals. Real-world time periods and events, on the other hand, are often characterized by vague temporal boundaries, requiringappropriate generalizations of existing formalisms. This paper presents a framework for reasoning about qualitative and metrictemporal relations between vague time periods. In particular, we show how several interesting problems, like consistency andentailment checking, can be reduced to reasoning tasks in existing temporal reasoning frameworks. We furthermore demonstratethat all reasoning tasks of interest are NP-complete, which reveals that adding vagueness to temporal reasoning does not increaseits computational complexity. To support efficient reasoning, a large tractable subfragment is identified, among others, generalizingthe well-known ORD Horn subfragment of the Interval Algebra (extended with metric constraints).© 2008 Elsevier B.V. All rights reserved.Keywords: Temporal reasoning; Interval algebra; Fuzzy set theory1. IntroductionTime plays a key role in many application domains, ranging from scheduling and planning [2,17,19] to naturallanguage understanding [29,34], multi-document summarization [6], question answering [22,32,39] and dynamic mul-timedia presentation [3,10,18]. Starting from Allen’s seminal work on qualitative interval relations (e.g., A happenedduring B, A overlaps with B; [1]), increasingly more expressive formalisms have been proposed to reason abouttime, among others allowing to specify metric constraints between two time points (e.g., p happened 4 time unitsbefore q; [12]), to combine qualitative and metric information [25,31], to specify constraints on the (relative) durationof events [35], and to specify arbitrary disjunctions of temporal constraints [23,27]. Most reasoning tasks of interest inthese formalisms are NP-complete. To cope with this, a lot of research efforts have been directed towards identifyingsubfragments of the various calculi in which reasoning becomes tractable [13,14,28,37], as well as towards derivingefficient solution strategies for NP-complete reasoning problems [8,36,45,46].Research, however, has largely focused on reasoning about time periods, and time spans of events, which canbe accurately represented as an interval. In contrast, many real-world events and time periods are characterized by* Corresponding author.E-mail addresses: steven.schockaert@ugent.be (S. Schockaert), martine.decock@ugent.be (M. De Cock).1 Research Assistant of the Research Foundation—Flanders.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.01.001\fS. Schockaert, M. De Cock / Artificial Intelligence 172 (2008) 1158–11931159Fig. 1. Fuzzy sets defining the vague time span of Picasso’s Blue, Rose, and Cubist periods.an inherently gradual or ill-defined beginning and ending. Typical examples are large-scale historical events like theRussian Revolution, the Great Depression, the Second World War, the Cold War, and the Dotcom Bubble, or historicaltime periods like the Middle Ages, the Renaissance, the Age of Enlightenment, and the Industrial Revolution, but alsosmall-scale events like sleeping and being born. Moreover, in natural language, vague temporal markers are frequentlyfound to convey underspecified temporal information: early summer, during his childhood, in the evening, etc. Notethat the vagueness of these events and time periods is fundamentally different from the uncertainty that exists amonghistoricians about, for example, the time period during which the Mona Lisa was painted.A formal definition of the notion of an event is difficult to provide. Clearly, an event is something that happens ata particular time and a particular place (e.g., World War II); it can have parts (e.g., the Battle of the Bulge), it canbelong to a certain category (e.g., Military Conflict) and it can have consequences (e.g., the Cold War) [47]. We will,however, abstract away from any particular formalization of events, and focus on their temporal dimension only. Assuch, we will conceptually make no difference between time periods and events. Vague time periods are naturallyrepresented as fuzzy sets [48]. A vague time period is then represented as a mapping A from the real line R to the unitinterval [0, 1]. For a time instant t (t ∈ R), A(t) expresses to what extent t belongs to the time period A. When A isa crisp time period, for all t in R, A(t) is either 0 (perfect non-membership) or 1 (perfect membership). When A is avague time period, on the other hand, A will typically be gradually increasing over an interval [t1, t2] and graduallydecreasing over an interval [t3, t4], where A(t) = 1 for t in [t2, t3] and A(t) = 0 for t < t1 and t > t4. As an example,consider Picasso’s Blue, Rose and Cubist periods. Regarding the definition of the Rose period, for example, we find2So 1904 is a transitional year and belongs neither truly to the blue period, nor to the rose period.Similarly, the ending of the Rose period, as well as the beginning and ending of the Cubist period are inherentlygradual. Fig. 1 depicts a possible definition of Picasso’s Rose period, as well as the ending of his Blue period and thebeginning of his Cubist period. These definitions reflect the gradual transition to the Rose period during 1904, as wellas Picasso’s experiments with new styles from 1906 and especially from 1907, eventually leading to his Cubist period.Clearly, the definition of a fuzzy set representing a vague time period is to some extent subjective. In fact, there is noreal reason why January 1, 1907 should belong to the Rose period to degree 0.8 and not to degree 0.75 or 0.85. Whatis most important is the qualitative ordering the membership degrees impose, e.g., June 1, 1907 is more compatiblewith the Rose period than the Cubist period; March 15, 1904 is less compatible with the Rose period than June 1,1907, etc.Applications based on classical temporal reasoning algorithms, like temporal question answering or multi-document summarization, fail to work correctly when the events or time periods involved are vague. For example,when extracting information about the life and work of Picasso from web documents, inconsistencies quickly arise:(1) Bread and Fruit Dish on a Table (1909) marks the beginning of Picasso’s “Analytical” Cubism . . . 32 http://pablo-picasso.paintings.name/rose-period/, accessed May 21, 2007.3 http://www.abcgallery.com/P/picasso/picassobio.html, accessed May 21, 2007.\f1160S. Schockaert, M. De Cock / Artificial Intelligence 172 (2008) 1158–1193(2) The first stage of Picasso’s cubism is known as analytical cubism. It began in 1908 and ended in 1912, . . . 4(3) The ‘Demoiselles d’Avignon’ of 1907 mark the beginning of his [Picasso’s] Cubist period in which he exceededthe classical form.5The solution to this problem is not to discard the least reliable sources until the resulting knowledge base is consistent,but to acknowledge that some of the temporal relations expressed in the sentences above are only true to some extent:the beginning of Picasso’s Analytical Cubism coincides with the beginning of cubism to some degree λ1, Picasso’sCubist period began with “Demoiselles d’Avignon” in 1907 to some degree λ2, Picasso’s Analytical Cubism began in1908 to some degree λ3, Picasso’s Analytical Cubism began with “Bread and Fruit Dish on a Table” in 1909 to somedegree λ4. The aim of this paper is to derive algorithms for reasoning about such fuzzy temporal information, e.g.,which values of λ1, λ2, λ3, λ4 result in a consistent interpretation of the sentences above? What conclusions can weestablish given a consistent set of (fuzzy) assertions about (vague) time periods? Our primary objective is to obtain atemporal reasoning framework that is, among others, suitable for natural language applications like multi-documentsummarization or question answering when some of the time periods and events involved are vague.The structure of this paper is as follows. In the next section, we review related work on fuzzy temporal informationprocessing, while Section 3 familiarizes the reader with some important preliminaries from fuzzy set theory andtemporal reasoning. In Section 4, we introduce our framework for representing fuzzy temporal information. Next, inSection 5, we introduce an algorithm to check the consistency of a set of assertions about fuzzy time periods. Thecomputational complexity of this problem is investigated in Section 6. Section 7 discusses how new information canbe derived from given information. Finally, Section 8 presents some concluding remarks and directions for futurework.2. Related workAlthough processing fuzzy temporal information is well studied in literature, research has tended to focus on mod-elling vague temporal information about crisp events (e.g., Picasso died in the early 1970s), rather than on modellingtemporal information about vague events. For example, in [16] possibility theory is employed to represent vague dates(e.g., early summer), and vague temporal constraints (e.g., A happened about three months before B). The underlyingassumption is that all events have crisp, albeit unknown, temporal boundaries; only our knowledge about these crispboundaries is vague. Based on this possibilistic approach, [5] introduced the notion of a fuzzy temporal constraintnetwork. In this framework, temporal information is represented as fuzzy temporal constraints, i.e., fuzzy restric-tions on the possible distances between time p",
            {
                "entities": [
                    [
                        3087,
                        3115,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1809–1832Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA new approach to estimating the expected first hitting timeof evolutionary algorithmsYang Yu, Zhi-Hua Zhou∗National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 12 December 2007Received in revised form 8 July 2008Accepted 9 July 2008Available online 12 July 2008Keywords:Evolutionary algorithmsExpected first hitting timeConvergence rateComputational complexity1. IntroductionEvolutionary algorithms (EA) have been shown to be very effective in solving practicalproblems, yet many important theoretical issues of them are not clear. The expected firsthitting time is one of the most important theoretical issues of evolutionary algorithms,since it implies the average computational time complexity. In this paper, we establisha bridge between the expected first hitting time and another important theoreticalissue, i.e., convergence rate. Through this bridge, we propose a new general approach toestimating the expected first hitting time. Using this approach, we analyze EAs withdifferent configurations, including three mutation operators, with/without population, arecombination operator and a time variant mutation operator, on a hard problem. Theresults show that the proposed approach is helpfulfor analyzing a broad range ofevolutionary algorithms. Moreover, we give an explanation of what makes a problem hardto EAs, and based on the recognition, we prove the hardness of a general problem.© 2008 Published by Elsevier B.V.Evolutionary algorithms (EAs) are a kind of optimization technique, inspired by the natural evolution process. Despitemany different implementations [1], e.g., genetic algorithm, genetic programming and evolutionary strategies, traditional evolu-tionary algorithms can be summarized below by four steps:(1) Generate an initial population of random solutions;(2) Reproduce new solutions based on the current population;(3) Remove relatively poor solutions in the population;(4) Repeat from Step 2 until a stop criterion is satisfied.In the evolutionary process, a population of randomly initialized solutions is maintained and evolved. Mutation and re-combination are two popular operators for reproduction in Step 2. A fitness function is employed to guide Step 3. Theevolutionary repetition stops when, e.g., an optimal solution is found or time runs out.EAs solve problems in straightforward ways and do not require, for example, continuous or differentiable functions orinversable matrices. So, EAs have been applied to bioinformatics [17], circuit design [3], data mining [9], information retrieval[4], etc. Despite the remarkable success achieved by EAs on practice problems, EAs are often criticized for the lack of a solidtheoretical foundation. Actually, such a theoretical foundation is very desired in order to gain deep understanding of thestrength and weakness of current EAs and thus develop better EAs.* Corresponding author.E-mail address: zhouzh@nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.07.001\f1810Y. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–1832The first hitting time of EAs is the time that, in a run, EAs find an optimal solution for the first time, and the expected firsthitting time (EFHT) is the average time that EAs require to find an optimal solution, which implies the average computationaltime complexity of EAs. It is evident that the EFHT is one of the most important theoretical issues of EAs.Many papers have been devoted to the analysis of simple EAs. The (1 + 1)-EA, i.e., EA without population, has beenstudied on the long path problem [22], the OneMax problem [23], the uni-model functions [5,7] and linear functions [6,7].Another EA without population has been studied on the OneMax problem [10]. More details can be found in Beyer et al.’ssurvey [2]. Owing to these efforts, several theoretical properties of EAs become more clear. In these works, however, adhoc approaches were used to analyze simple EAs on simple problems, yet a general approach that can be used to analyzewider kinds of EAs to gain deeper insights is more desired. Recently, several works [13–15] have been devoted to developinggeneral analysis approaches, which are summarized in the latest survey [19].He and Yao [13,15] have developed a general approach to analyzing a wide class of EAs based on drift analysis [11], whichis a significant advance. Intuitively, if we know the length of the whole path toward the optimum and the length of thedrift of the EA at each step, we can estimate the EFHT by dividing the path length by the step drift. However, no practicalmeasure of these quantities is known.He and Yao [14] have developed another framework based on the analytical solution of EFHT to analyze and compareEAs. Under this framework, two hard problem classes (i.e., problems that can only be solved in exponential time), the‘wide gap’ problem class and the ‘long path’ problem class, were identified. Since the analytical framework is derived fromhomogeneous Markov chain models, only EAs with static reproduction operators can be analyzed, although EAs with time-variant operators or adaptive operators are very popular and powerful [8].The convergence rate is another important theoretical issue of EAs, which implies how close the current state is to theoptimal area at each step. The convergence issue has been studied for years [12,16,21,23,25]. He and Yu [16] did a thoroughstudy based on the minorization method [20].In this paper, we present the first study on the relationship between the EFHT and the convergence rate, and establisha bridge between them. Through this bridge, we propose a new general approach to estimating the expected first hittingtime. In contrast to previous researches where easy problems (i.e., problems that can be solved in polynomial time) [6,15,23] were studied, we use the proposed approach to analyze EAs on a hard problem. The analyzed EAs involve variousconfigurations, including three mutation operators, with/without population, a recombination operator and a time variantmutation operator. The results show that the proposed approach is helpful for analyzing a broad range of EAs. Moreover,we give an explanation of what makes a problem hard to an EA, and based on the recognition, we prove the hardness of ageneral problem.The rest of this paper is organized as follows. In Section 2, we briefly review some related work and introduce how tomodel EAs using Markov chains. In Section 3, we introduce a new approach to estimating the EFHT, which is the main resultof this paper. In Section 4, we analyze several EAs on a hard problem using the proposed approach, which is followed bydiscussions in Section 5. Finally, in Section 6, we conclude the paper.2. Modeling EAs using Markov chainEAs evolve solutions from generation to generation. Each generation stochastically depends on the previous one, exceptthe initial generation which is randomly generated. This conditional independence can be modeled natually by Markov chains[12–14,18,24,25].Combinatorial optimization problems are among the most common problems in practice, whose solutions can be repre-sented by a sequence of symbols. In this paper, we use EAs to tackle them. To model this kind of EAs, we construct Markovchains with discrete state space. The key to construct such a Markov chain is to bijectively map the populations of an EAto the states of the Markov chain. A popular mapping [12,16,25] enables one state of the Markov chain to correspond toone possible population of the EA. Suppose an EA encodes a solution in a vector of length L, each component of the vectoris drawn from an alphabet set B, and each population contains M solutions. Let S denote the solution space. There are|S| = |B|L number of different solutions. Let X denote the population space. There are | X| =number of differentpossible populations [25]. A Markov chain which models the EA is constructed by taking X as the state space, i.e., a chain{ξt}+∞t=0 is built where ξt ∈ X .A population is called an optimal population if it contains at least one optimal solution. Let X∗ (∈ X) denote the set of all∗from an initial population. Thus, the process of an EA which seeks XM+|B|L −1M(cid:3)(cid:2)∗optimal populations. The goal of EAs is to reach Xcan be analyzed by studying the corresponding Markov chain [12,16].In the rest of this section, we introduce several notations and definitions. Given a Markov chain {ξt}+∞t=0 (ξt ∈ X) and atarget subspace X(cid:4)μt =∗ ⊂ X , let μt (t = 0, 1, . . .) denote the probability of ξt being in XP (ξt = x).∗, i.e.,x∈ X ∗Definition 1 (Convergence). Given a Markov chain {ξt}+∞to Xif∗t=0 (ξt ∈ X) and a target subspace Xlimt→+∞μt = 1.(1)∗ ⊂ X , {ξt}+∞t=0 is said to converge(2)\fY. Yu, Z.-H. Zhou / Artificial Intelligence 172 (2008) 1809–18321811In [16], convergence rate is measured by 1 − μt at step t, which is equivalent to that used in [25]. Therefore, we also use1 − μt as the measure of convergence rate in this paper.Definition 2 (Convergence rate). Given a Markov chain {ξt}+∞to Xat time t is 1 − μt .∗t=0 (ξt ∈ X) and a target subspace X∗ ⊂ X , the convergence rateDefinition 3 (Absorbing Markov chain). Given a Markov chain {ξt }+∞be an absorbing chain, ift=0 (ξt ∈ X) and a target subspace X∀t ∈ {0, 1, . . .}:P(cid:2)ξt+1 /∈ X(cid:3)∗ | ξt ∈ X∗= 0.∗ ⊂ X , {ξt}+∞t=0 is said to(3)We use absorbing Markov chains to model all the EAs studied in this paper, because absorbing Markov chains have goodtheoretical properties and can be practically achieved. An EA can be modeled by an absorbing Markov chain if it neverloses an optimal solution once found. Actually, most EAs for real problems satisfy this condition because, if an optimalsolution can be identified, the EA will stop when ",
            {
                "entities": [
                    [
                        3226,
                        3254,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 343–367Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEmpirical decision model learningMichele Lombardi a,∗a DISI, University of Bologna, Italyb DEI, University of Bologna, Italy, Michela Milano a, Andrea Bartolini ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 21 December 2015Accepted 10 January 2016Available online 13 January 2016Keywords:Combinatorial optimizationMachine learningComplex systemsLocal searchConstraint programmingMixed integer non-linear programmingSAT modulo theoriesArtificial neural networksDecision treesOne of the biggest challenges in the design of real-world decision support systems is coming up with a good combinatorial optimization model. Often enough, accurate predictive models (e.g. simulators) can be devised, but they are too complex or too slow to be employed in combinatorial optimization.In this paper, we propose a methodology called Empirical Model Learning (EML) that relies on Machine Learning for obtaining components of a prescriptive model, using data either extracted from a predictive model or harvested from a real system. In a way, EML can be considered as a technique to merge predictive and prescriptive analytics.All models introduce some form of approximation. Citing G.E.P. Box [1] “Essentially, all models are wrong, but some of them are useful”. In EML, models are useful if they provide adequate accuracy, and if they can be effectively exploited by solvers for finding high-quality solutions.We show how to ground EML on a case study of thermal-aware workload dispatching. We use two learning methods, namely Artificial Neural Networks and Decision Trees and we show how to encapsulate the learned model in a number of optimization techniques, namely Local Search, Constraint Programming, Mixed Integer Non-Linear Programming and SAT Modulo Theories. We demonstrate the effectiveness of the EML approach by comparing our results with those obtained using expert-designed models.© 2016 Elsevier B.V. All rights reserved.1. IntroductionAdvances in Combinatorial Optimization methods in the last decades have enabled their successful application to a broad range of industrial problems. Many of such approaches rely on the availability of some declarative system description. This typically consists of a hand-crafted mathematical model, obtained after thorough discussion with the domain experts by introducing some simplifying assumptions.Devising a good model is a complex task, especially challenging when dealing with real-world systems. A good model finds a proper balance between model complexity and model accuracy: on the one hand, excessive simplification may lead to “optimal” – but completely useless – solutions. On the other hand, incorporating too many details results in extremely hard computational issues. Despite this, a number of successful optimization approaches have been proposed in the literature and * Corresponding author.E-mail addresses: michele.lombardi2@unibo.it (M. Lombardi), michela.milano@unibo.it (M. Milano), a.bartolini@unibo.it (A. Bartolini).http://dx.doi.org/10.1016/j.artint.2016.01.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\f344M. Lombardi et al. / Artificial Intelligence 244 (2017) 343–367applied to real-life industrial problems, enabling in many cases1 huge savings in terms of resources (time, money, machines, energy).Nevertheless, many systems are still impervious to approaches such as Mixed Integer Linear Programming (MILP), Con-straint Programming (CP), or SAT (propositional SATisfiability) and this is often due to modeling issues. There are basically two kinds of “high-complexity systems” that are out-of-reach for traditional combinatorial approaches: (1) Complex Systems, which exhibit phenomena that emerge from a collection of interacting objects capable of self-organization and affected by memory or feedback; and (2) physical systems whose dynamic model is known, but its embedding in a combinatorial model is computationally intractable.A very common way for supporting decision-making in these systems is to design a predictive model (e.g., a simulator) based on real data and to use it via what-if analysis (see [2] for a recent reference). In what-if analysis, the decision maker repeatedly feeds scenarios (i.e. sets of decisions) to the predictive model to extract the values of certain observables of interest (e.g. quality measures). Inevitably, only a limited number of scenarios is investigated, and then the decision maker commits to the one showing the best behavior. In combinatorial problems the decision space might be so large that selecting scenarios manually or in isolation results in far-from-optimal choices.The aim of this paper is to bring such high-complexity systems within the reach of combinatorial decision making and optimiza-tion. The idea is to use Machine Learning (ML) to learn an approximate relation between decisions and their impact on the system. In particular, we devise a methodology, called Empirical Model Learning (EML) that: (1) learns relations be-tween decidables and observables2 from data, and (2) encapsulates these relations into components of an optimization model, namely objective functions or constraints. The training data for the learning techniques can be harvested from the real system or extracted from a predictive model (e.g. simulator). The integration into model components is not merely a matter of encoding, since in some cases an operational semantics for the efficient use of the component should be de-fined.The ability to integrate Machine Learning models in combinatorial optimization has the potential to play a major role in bridging the gap between predictive and prescriptive analytics. An EML based system may be capable of suggesting optimal decisions in a complex real-world setting, by taking advantage of recent developments in big data analysis and predictive model design.This paper provides three main contributions. First, we introduce the Empirical Model Learning approach in a general fashion. Second, we present a number of methods for embedding Machine Learning models (namely Decision Trees and Artificial Neural Networks) into several optimization techniques (Local Search, Mixed Integer Non-Linear Programming, Con-straint Programming, SAT Modulo Theories). Some of our embedding techniques have been presented in previous papers of ours [4,5]. Third, we show that despite the main idea behind EML being very simple, its application requires some care for obtaining an effective optimization approach. We highlight the main difficulties and suggest possible solutions by applying the EML approach on two practical examples.As motivating (and running) examples, we use two thermal-aware workload dispatching problems, defined over an ex-perimental multicore Intel CPU called “Single-chip Cloud Computer” (SCC, see [6]). Both problems consist in mapping a set of heterogeneous jobs on the platform cores so as to maximize some cost metric involving the platform efficiency. The efficiency of each core is affected by a number of complex factors including the thermal dynamics of the chip, the workload distribution, and the presence of low-level schedulers and thermal controllers. Although an accurate system simulator for the platform is available, it cannot be inserted into a decision model due to its high complexity and large run time. We show that EML allows considerable improvements over simpler optimization approaches either based on expert-designed heuristics, or on expert-designed models refined via function fitting.The paper is structured as follows: in Section 2 we provide a comparative analysis of related work. In Section 3 we introduce the example problems. In Section 4 we give a brief overview of the EML approach. Section 5 presents techniques for embedding Machine Learning models into Combinatorial Optimization models. Sections 6 and 7 discuss respectively how to design the core combinatorial structure of the optimization problem, and how to extract a system model from data: in both cases, our example problems are employed to present the process. We provide experimental results in Section 8 and concluding remarks in Section 9.2. Comparative analysis of related workThe EML approach combines elements of Combinatorial Optimization, Machine Learning, and Complex Systems/Simula-tion. In this section we provide a brief overview of approaches related to the integration of such research fields.Loosely related approaches Researchers have been interested for a long time in the integration of optimization techniques in Machine Learning. This is not surprising, given that training problems are fundamentally (very peculiar) optimization prob-lems. Works such as [7,8] have studied the core optimization problems in ML algorithms and proposed efficient methods 1 The reader may find some examples on the web page dedicated to the Franz Edelman Award at https :/ /www.informs .org /Recognize-Excellence /Franz-Edelman-Award.2 The names decidables and observables have been suggested by Peter Flach [3].\fM. Lombardi et al. / Artificial Intelligence 244 (2017) 343–367345for extracting knowledge from huge volumes of data. Other works (e.g. [9,10] and those presented in [11]) have applied Constraint Programming to Machine Learning tasks.In the optimization community, a substantial effort has been recently dedicated to using learning to improve a solution approach. Clustering methods have been employed for automatic algorithm selection (e.g. [12]). Several Machine Learning techniques have been used for predicting the run time of optimization algorithms, once again with the aim to perform algorithm selection (e.g. [13,14]). A few works have focused on learning customized optimization problem instances for testing new techniques (see [15]).Constraint acquisition Some papers [16–18] have focused on learning a set of constraints t",
            {
                "entities": [
                    [
                        3170,
                        3198,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 991–1017www.elsevier.com/locate/artintOn propositional definability ✩Jérôme Lang a, Pierre Marquis b,∗a IRIT, CNRS / Université Paul Sabatier, 118 route de Narbonne, 31062 Toulouse, Franceb CRIL, CNRS / Université d’Artois, rue Jean Souvraz, S.P. 18, 62307 Lens, FranceReceived 21 November 2006; received in revised form 19 December 2007; accepted 28 December 2007Available online 11 January 2008AbstractIn standard propositional logic, logical definability is the ability to derive the truth value of some propositional symbols given apropositional formula and the truth values of some propositional symbols. Although appearing more or less informally in variousAI settings, a computation-oriented investigation of the notion is still lacking, and this paper aims at filling the gap. After recallingthe two definitions of definability, which are equivalent in standard propositional logic (while based on different intuitions), anddefining a number of related notions, we give several characterization results, and many complexity results for definability. We alsoshow close connections with hypothesis discriminability and with reasoning about action and change.© 2008 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Propositional logic; Computational complexity; Definability; Hypothesis discriminability; Reasoning aboutaction and change1. IntroductionWhen reasoning about knowledge represented in propositional logic, exhibiting structure can be of a great help.By “structure” we mean some relationships which exist between some sets of propositional symbols and/or formulaswithin a propositional formula (cid:2). Such relationships are known under various names, including dependency, rele-vance, novelty, controllability, and some of them have been investigated, see among others [1,2].In this paper we focus on an additional form of dependency, called definability. Definability captures two differentintuitions: implicit definability and explicit definability. A propositional symbol y can be implicitly defined in a givenformula (cid:2) in terms of a set X of propositional symbols if and only if the knowledge of the truth values of thepropositional symbols of X (whatever they are) enables concluding about the truth value of y, while y can be explicitlydefined in (cid:2) in terms of X when there exists a formula (cid:3)X built up from X only, such that (cid:3)X is equivalent to y in (cid:2).✩ This paper is an extended and revised version of some parts of two papers: “Complexity results for independence and definability inpropositional logic”, appeared in the Proceedings of the Sixth International Conference on Principles of Knowledge Representation and Reasoning(KR’98), pages 356–367; and “Two forms of dependence in propositional logic: Controllability and definability”, appeared in the Proceedings ofthe Fifteenth National Conference on Artificial Intelligence (AAAI’98), pages 268–273.* Corresponding author.E-mail addresses: lang@irit.fr (J. Lang), marquis@cril.univ-artois.fr (P. Marquis).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.12.003\f992J. Lang, P. Marquis / Artificial Intelligence 172 (2008) 991–1017Table 1The complexity of DEFINABILITYFragment CDEFINABILITYPROPPS (general case)DNNFq-HornCNFIPcoNP-cin Pin PcoNP-cDefinability is acknowledged as an important logical concept for decades. It is closely related to the Craig/Lyndoninterpolation theorem [3]. Many studies in logic are about determining whether a given logic (standard or modal,propositional or first-order) satisfies the “basic” Beth property (whenever a theory implicitly defines a symbol interms of all others, there is an explicit definition of that symbol in terms of all others), or even the (stronger) projectiveBeth property (when implicit definability and explicit definability coincide). Thus classical first-order logic satisfiesthe “basic” Beth property (this is the famous Beth’s theorem [4]), as well as the projective one, while for instancefirst-order logic on finite structures does not (see e.g., [5]).Standard propositional logic has been known to satisfy the projective Beth property. In this paper, we consider de-finability in standard propositional logic from a computational point of view. We present several characterization andcomplexity results which prove useful for several AI applications, including hypothesis discrimination and reasoningabout actions and change.From a computational point of view, our results concern both time and space complexity. As to time complexity,we mainly considered the decision problem DEFINABILITY which consists in determining whether a given formula(cid:2) defines a given symbol y (or more generally a given set Y of symbols) in terms of a given set X of symbols. Weidentify its complexity both in the general case and under restrictions induced by a number of propositional fragments(formally defined in Section 2) that proved of interest in many AI contexts (see [6–9]); the results are summarized inTable 1.While the table shows that the definability problem is intractable in the general case (unless P = NP), it also showsthat:• The main propositional fragments which are tractable for SAT are also tractable for DEFINABILITY. Indeed, DNNFcontains (among others) all DNF formulas and all OBDD “formulas”, while q-HornCNF contains all renamableHorn CNF formulas. The fact that large propositional fragments (including complete ones, i.e., fragments intowhich any propositional formula has an equivalent, as DNNF is) is of great value from a practical perspective.• Nevertheless, tractability for SAT is not enough for ensuring tractability for DEFINABILITY. Thus the Blake frag-ment IP is tractable for SAT but likely not for DEFINABILITY. We also identify some sufficient conditions (referredto as stability conditions) under which a propositional fragment is tractable for SAT if and only if it is tractable forDEFINABILITY.About space complexity, we focus on the size of definitions; we show that in the general case, the size of anyexplicit definition of a symbol y in terms of a set of symbols X in (cid:2) is not polynomially bounded in the input size. Weidentified some sufficient conditions (polytime conditioning and polytime forgetting) on propositional fragments forensuring that definitions can be computed in polynomial time (hence are of polynomial size) when such definitionsexist. Interestingly, the influential DNNF fragment satisfies them, as well as the Blake fragment IP. The result for IPshows that it can be the case that computing an explicit definition of y on X in (cid:2) is easy when one knows that such adefinition exists, while deciding whether it exists is hard.The rest of the paper is organized as follows. In Section 2, we give some necessary background about propositionallogic and computational complexity. In Section 3 the notion of definability is presented, as well as a number ofrelated notions, including the notions of minimal defining family (or base), undefinable symbol, necessary symboland relevant symbol, as well as the notion of unambiguous definability. We also show how such notions relate oneanother and are connected to previous concepts, especially variable forgetting (see [2,10]) as well as the notions ofweakest sufficient and strongest necessary conditions [11]. In Section 4, we give a number of complexity results fordefinability and the related notions. We identify a number of tractable restrictions of the decision problems underconsideration. We also report some complexity results about the size of explicit definitions and present an algorithm\fJ. Lang, P. Marquis / Artificial Intelligence 172 (2008) 991–1017993for computing a base. In Section 5, we show that definability is closely related to hypothesis discriminability. InSection 6, we explain how many important issues in reasoning about action and change can be characterized in termsof definability. In Section 7, we briefly sketch how definability can prove useful to automated reasoning. In Section 8,we relate our results to the literature. Finally, Section 9 concludes the paper.2. Formal preliminaries2.1. Propositional logicLet PS be a finite set of propositional symbols (also called variables). PROPPS is the DAG-based propositionallanguage built up from PS, the connectives ¬, ∨, ∧, ⇒, ⇔ and the Boolean constants true and false in the usual way.Subsets of PS are denoted X, Y , etc. For every X ⊆ PS, PROPX denotes the sublanguage of PROPPS generated fromthe propositional symbols of X only.From now on, (cid:2) denotes a finite set of propositional formulas from PROPPS. Var((cid:2)) is the set of propositionalsymbols appearing in (cid:2) and |(cid:2)| is the size of (cid:2), i.e., the number of symbols used to write it. Elements of PS aredenoted x, y, etc. Specific formulas from PROPPS are of interest: a literal is a symbol x of PS (positive literal) ora negated one ¬x (negative literal). x and ¬x are two complementary literals. A clause (resp. term) is a disjunction(resp. conjunction) of literals, or the constant false (resp. true). A Conjunctive Normal Form formula (for short, a CNFformula) is a conjunction of clauses. A Disjunctive Normal Form formula (for short, a DNF formula) is a disjunctionof terms. A CNF formula is Krom [12] if and only if each clause in it contains at most two literals. A Krom formulais also said to be a 2-CNF formula or a quadratic formula. A CNF formula is Horn [13] if and only if each clause init contains at most one positive literal. A CNF formula (cid:2) is renamable Horn [14] if and only if there exists a Hornrenaming for it, i.e., a set V of symbols v such that replacing every occurrence of v ∈ V (resp. ¬v) in (cid:2) by thecomplementary literal ¬v (resp. v) leads to a Horn CNF formula. A CNF formula (cid:2) has a QH-partition [6] if andonly if there exists a partition {Q, H } of Var((cid:2)) s.t. for every clause δ of (cid:2), ",
            {
                "entities": [
                    [
                        3150,
                        3178,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1911–1950Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIndependent natural extensionGert de Cooman a, Enrique Miranda b, Marco Zaffalon c,∗a Ghent University, SYSTeMS Research Group, Technologiepark–Zwijnaarde 914, 9052 Zwijnaarde, Belgiumb University of Oviedo, Department of Statistics and Operations Research, C-Calvo Sotelo, s/n, 33007 Oviedo, Spainc IDSIA, Galleria 2, CH-6928 Manno (Lugano), Switzerlanda r t i c l ei n f oa b s t r a c tThere is no unique extension of the standard notion of probabilistic independence to thecase where probabilities are indeterminate or imprecisely specified. Epistemic independenceis an extension that formalises the intuitive idea of mutual irrelevance between differentsources of information. This gives epistemic independence very wide scope as well asappeal: this interpretation of independence is often taken as natural also in precise-probabilistic contexts. Nevertheless, epistemic independence has received little attentionso far. This paper develops the foundations of this notion for variables assuming valuesin finite spaces. We define (epistemically) independent products of marginals (or possiblyconditionals) and show that there always is a unique least-committal such independentproduct, which we call the independent natural extension. We supply an explicit formulafor it, and study some ofits properties, such as associativity, marginalisation andexternal additivity, which are basic tools to work with the independent natural extension.Additionally, we consider a number of ways in which the standard factorisation formulafor independence can be generalised to an imprecise-probabilistic context. We show,under some mild conditions, that when the focus is on least-committal models, using theindependent natural extension is equivalent to imposing a so-called strong factorisationproperty. This is an important outcome for applications as it gives a simple tool to makesure that inferences are consistent with epistemic independence judgements. We discussthe potential of our results for applications in Artificial Intelligence by recalling recent workby some of us, where the independent natural extension was applied to graphical models.It has allowed, for the first time, the development of an exact linear-time algorithm for theimprecise probability updating of credal trees.© 2011 Elsevier B.V. All rights reserved.Article history:Received 1 October 2010Received in revised form 8 June 2011Accepted 11 June 2011Available online 15 June 2011Keywords:Epistemic irrelevanceEpistemic independenceIndependent natural extensionStrong productFactorisationCoherent lower previsions1. Introduction1.1. Background and motivationThis is a paper on the notion of independence in probability theory. Anyone interested in or familiar with uncertainreasoning or statistics knows how fundamental this notion is. But what is independence?Most of us have been taught that two variables X1 and X2 are independent when their joint probability distributionP {1,2} factorises as the product of its marginals P 1 and P 2. This is the formalist route that defines independence through amathematical property of the joint, and that has its roots in the Kolmogorovian, measure- and integral-theoretic formalisa-tion of probability theory.* Corresponding author.E-mail addresses: gert.decooman@ugent.be (G. de Cooman), mirandaenrique@uniovi.es (E. Miranda), zaffalon@idsia.ch (M. Zaffalon).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.06.001\f1912G. de Cooman et al. / Artificial Intelligence 175 (2011) 1911–1950In Artificial Intelligence (AI)—thanks to Judea Pearl in particular [27]—, but also in the tradition of subjective probability—due to a large extent to Bruno de Finetti [17]—, independence has much more often an epistemic flavour: it is a subject whoregards two variables as independent, because she judges that learning about the value of any one of them will not affecther beliefs about the other. This means that the subject assesses that her conditional beliefs equal her marginal ones:P 1(·| X2) = P 1 and P 2(·| X1) = P 2, in more mathematical parlance.That the epistemic approach has become so popular, should not be all that surprising. The formalist approach comeswith the idea that independence is something given, which might hold or not: it is just a property of the joint. On theepistemic view, however, independence is something we are (to some extent) in control of. And this control is essential inorder to aggregate simple, independent components into complex multivariate models.It might be argued that the difference between the two approaches is mostly philosophical: in fact, the two routes areknown to be formally equivalent.1 But it turns out that we lose this formal equivalence as soon as we consider probabilitiesthat may be imprecisely specified, meaning that the available information is conveniently expressed through sets of proba-bilities (sets of mass functions). In this case the two routes diverge also mathematically, as we shall see further on. This isexemplified by the existence of the different notions of strong and epistemic independence, respectively.2 Of these two, strongindependence has been most thoroughly investigated in the literature. Studies of epistemic independence are confined toa relatively small number of papers [6,10,26,29] inspired by Peter Walley’s [30, Section 9.3] seminal ideas. We mention inparticular Paolo Vicig’s interesting study [29], for the case of coherent lower probabilities (which may be defined on infinitespaces), of some of the notions considered in this paper as well.This situation is somewhat unfortunate as the scope of strong independence is relatively narrow: in fact, its justificationseems to rely on a sensitivity analysis interpretation of imprecise probabilities. On this interpretation, one assumes that thereexists some (kind of ‘ideal’ or ‘true’) precise probability P T{1,2} for the variables X1 and X2 that satisfies stochastic indepen-dence, and that, due to the lack of time or other resources, can only be partially specified or assessed. Then one considersall the precise-probabilistic models P {1,2} that are consistent with the partial assessments and that satisfy stochastic inde-pendence. Taken together, they constitute the set of probabilities for the problem under consideration. This set models asubject’s (partial) ignorance about the true model P T{1,2}.It is questionable that this sensitivity analysis interpretation is broadly applicable, for the simple reason that it hingeson the assumption of the existence of the underlying ‘true’ probability P T{1,2}. Consider the situation where we wish tomodel an expert’s beliefs: the expert usually does not know much about ideal probabilities, and what she tells us is simplythat information about one variable does not influence her beliefs about the other. Moreover, we could well argue thatexpert knowledge is inherently imprecise to some extent, no matter the resources that we employ to capture it.3 Therefore,why not take the expert at her word and model only the information she provides us about the mutual irrelevance ofthe two variables under consideration? After all, forcing a sensitivity analysis interpretation here would amount to addingunwarranted assumptions, which may lead us to draw stronger conclusions than those the expert herself might be preparedto get to.In order to model such mutual irrelevance, we need a different understanding of imprecise probability models thatdoes not (necessarily) rely on precise probability as a more primitive notion: Walley’s behavioural theory of impreciseprobability [30], which models beliefs by looking at a subject’s buying and selling prices for gambles. The perceived mutualirrelevance of two sources of information can be formalised easily in this framework: we state that the subject is not goingto change her prices for gambles that depend on one variable, when the other variable is observed. This turns out to bestill equivalent to modelling the problem through a set of precise probabilities P {1,2} but, in contradistinction with thecase of sensitivity analysis, not all those probabilities satisfy stochastic independence in general. The reason for this is thatepistemic independence is a property of the set of probabilities that cannot be explained through the properties of theprecise probabilities that make up the set. This point is not without importance, as it shows that buying and selling pricesfor gambles are actually a more primitive and fundamental notion in a theory of personal probability.This illustrates that a behavioural theory of probability and the notion of epistemic independence fit nicely together.It also indicates that epistemic independence has a very wide scope, as it needs to meet fewer requirements than strongindependence in order to be employed. That being so, why has strong independence been studied and applied much moreextensively than its epistemic counterpart, even in work based on Walley’s approach? This is probably due to a numberof concurring factors: (i) a tendency in the literature to extend stochastic independence, perhaps somewhat uncritically, ina straightforward way to imprecise probabilities; (ii) the fact that epistemic independence does not appear to be as well-behaved as strong independence, for instance with respect to the graphoid axioms [6]4; and, perhaps more importantly,(iii) the lack of formal tools for handling epistemic independence assessments. To give a telling illustration of this lastpoint: epistemically independent products have so far been given a formal definition [30, Section 9.3] only for the case of1 There may be subtleties, however, related to events of probability zero. See Refs. [6, Notes 5 and 6 in Section 3], [30, Sections 6.5 and 6.10] and [1] formore information.2 Other possible ways to defi",
            {
                "entities": [
                    [
                        3587,
                        3615,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 909–924www.elsevier.com/locate/artintAnalyzing the degree of conflict among belief functionsWeiru LiuSchool of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, BT7 1NN, UKReceived 15 March 2005; received in revised form 6 April 2006; accepted 17 May 2006This paper is dedicated to Philippe Smets who sadly passed away in November 2005Available online 30 June 2006AbstractThe study of alternative combination rules in DS theory when evidence is in conflict has emerged again recently as an interestingtopic, especially in data/information fusion applications. These studies have mainly focused on investigating which alternativewould be appropriate for which conflicting situation, under the assumption that a conflict is identified. The issue of detection(or identification) of conflict among evidence has been ignored. In this paper, we formally define when two basic belief assignmentsare in conflict. This definition deploys quantitative measures of both the mass of the combined belief assigned to the emptyset beforenormalization and the distance between betting commitments of beliefs. We argue that only when both measures are high, it is safeto say the evidence is in conflict. This definition can be served as a prerequisite for selecting appropriate combination rules.© 2006 Elsevier B.V. All rights reserved.Keywords: Dempster–Shafer theory; Dempster’s combination rule; Conflicting beliefs; Betting commitments1. IntroductionWhen the Dempster–Shafer theory of evidence (DS theory) first appeared as a mechanism to model and reasonwith uncertain information in intelligent systems, criticisms on the counterintuitive results of applying Dempster’scombination rule to conflicting beliefs soon emerged (e.g., [18,28,29]) where an almost impossible choice (with avery lower degree of belief) by both sources came up as the most possible outcome (with a very high degree of belief).Since then, alternative combination rules have been explored to recommend where the mass of the conflictingbelief from the two sources should land (e.g., [4,19,26]). Recently, due to the increasing applications of DS theory inintelligent fusion processes, Dempster’s combination rule and its alternatives have been under the microscope again(e.g., [10,13,14,21]).In [13], the three well-known alternatives, i.e., Smets’s unnormalized combination rule (known as the conjunctivecombination rule) [19], Dubois and Prade’s disjunctive combination rule [4], and Yager’s combination rule, are ex-amined and a general combination framework is proposed. This new framework has a component that re-distributesthe mass of the combined belief assigned to the emptyset (the false assumption) in a flexible way that it specifieswhich subsets can share this mass and by what proportions. In this way, the three alternatives listed above can all besubsumed by the framework.E-mail address: w.liu@qub.ac.uk (W. Liu).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.002\f910W. Liu / Artificial Intelligence 170 (2006) 909–924In [14], the weighted average is recommended in certain situations, such as, one piece of evidence contradicts withseveral other pieces of evidence which are consistent, to preserve the opinion from majority sources.While the above two papers are still circling around the well-known alternatives, the method proposed in [10] takesa different approach. A new operator called the consensus operator is proposed which reduces a basic belief assign-ment on a set of values into a basic belief assignment on a binary set (a set with only two values), the combination isthen carried out on this binary set. Three examples, two are commonly regarded as involving conflicting beliefs andone is with consistent beliefs, are examined in comparison with Dempster’s rule of combination. It was concludedthat the consensus operator could always produce a rational result for combining even conflicting beliefs. However,since this method always focuses on two elements when performing combinations, it may not be suitable for manycomplex situations where multiple values (not just two) should be preserved.Furthermore, the consensus operator approach does not provide any indication whether the evidence to be combinedmay be conflicting. As it was concluded by the author “by looking at the result only, it does not tell whether the originalbeliefs were in harmony or in conflict” [10].To justify whether original beliefs are in conflict has a big impact on selecting alternative combination rules [21].So far there are no general mechanisms to measure the degree of conflict other than using the mass of the combinedbelief assigned to the emptyset before normalization, i.e., m⊕(∅) (see its definition in Section 2). In this paper, wemainly focus on this rather ignored topic. We study quantitatively when two sources can be defined as conflict. Weargue that the conventional explanation that a high mass value of the combined belief assigned to the emptyset beforenormalization indicates a conflict among the original beliefs may not always be accurate. For example, if we havetwo distinct and totally reliable sources providing two basic belief assignments m1 and m2 as m1(si) = m2(si) = 0.2(i = 1, 2, . . . , 5), then combining these basic belief assignments with Dempster’s rule yields the mass being assignedto the emptyset as 0.8 before normalization. Under the current convention, this amount of mass would warrant averdict that these two pieces of evidence are in conflict and Dempster’s rule should not be used. In fact, these twopieces of evidence are consistent and using Dempster’s rule produces a new basic belief assignment which is identicalto either of them.In order to avoid a wrong claim made by using only m⊕(∅), we propose an alternative method to measure theconflict among beliefs using a pair of values, the mass of the combined belief allocated to the emptyset before normal-ization and the distance between betting commitments. We also investigate the effect of these measures on decidingwhen Dempster’ rule can be applied. We believe that this result is significant given that it decides subsequently whetherDempster’s rule is appropriate and if not, what other rule should be considered.The rest of the paper is organized as follows. In Section 2, we review the basic definitions in DS theory. In Section 3,we first examine the commonly accepted convention that m⊕(∅) reveals the degree of conflict among two pieces ofevidence and the deficiency associated with this convention. We then investigate the meaning of pignistic transfor-mation and define the distance between betting commitments from two pignistic transformations. A formal definitionconsisting of two measures is proposed to judge when two pieces of evidence are in conflict. We also demonstrate thatthe distance between betting commitments is consistent with the distance between two pieces of evidence measuredby the method in [11]. In Section 4, we explore the properties and behaviour of this pair of measures. In Section 5,we look at the impact of this new definition on the decision of whether Dempster’s rule should be used in general andthen discuss in particular the cases which show the difference in the decisions when using only m⊕(∅) and using bothof the measures. Section 6 concludes the main contribution of the paper and discusses the difference between conflictanalysis and independence analysis among basic belief assignments.2. Basics of the Dempster–Shafer theoryWe review a few concepts commonly used in the Dempster–Shafer theory of evidence, as well as the conjunctivecombination rule [21] and the disjunctive combination rule [4]. Let Ω be a finite set called the frame of discernment.Definition 1. [20] A basic belief assignment (bba) is a mapping m : 2Ω → [0, 1] that satisfies(cid:2)A⊆Ω m(A) = 1.In Shafer’s original definition which he called the basic probability assignment [22], condition m(∅) = 0 is re-quired in Definition 1. Recently, some of the papers on Dempster–Shafer theory, especially since the establishment\fW. Liu / Artificial Intelligence 170 (2006) 909–924911of the Transferable Belief Model (TBM) [16], condition m(∅) = 0 is often omitted. A bba with m(∅) = 0 is called anormalized bba and is also known as a mass function.Definition 2. The belief function from a bba m is defined as bel : 2Ω → [0, 1],bel(A) =(cid:3)m(B).B⊆AWhen m(A) > 0, A is called a focal element of the belief function.Definition 3. [21] A categorical belief function is a belief function where its corresponding bba m satisfies(cid:4)m(B) =1 if B = A, where A (cid:6)= ∅, A (cid:6)= Ω, B ⊆ Ω,0 otherwise.(1)A categorical belief function has only one focal element and this element is neither empty nor the whole frame. Inother words, a categorical belief function assigns the total belief to a single proper subset of the frame.Definition 4. Let m1 and m2 be two bbas defined on frame Ω which are derived from two distinct sources. Let thecombined bba be m⊕ = m1 ⊕ m2 by Dempster’s rule of combination where ⊕ represents the operator of combination.Then(cid:2)m⊕(A) =B,C⊆Ω,B∩C=A m1(B)m2(C)(cid:2)B,C⊆Ω,B∩C=∅ m1(B)m2(C)1 −,∀A ⊆ Ω, A (cid:6)= ∅(cid:2)when(cid:2)B,C⊆Ω,B∩C=∅ m1(B)m2(C) (cid:6)= 1.B,C⊆Ω,B∩C=∅ m1(B)m2(C) is the mass of the combined belief assigned to the emptyset before normalizationand we denote it as m⊕(∅). In the following, whenever we use m⊕(∅), we always associate it with this explanationunless otherwise explicitly stated.The above rule is meaningful only when m⊕(∅) (cid:6)= 1, otherwise, the rule cannot be applied.Definition 5. [21] Let m1 and m2 be two bbas defined on frame Ω. Their conjunctive combination, denoted asm ∩(cid:9) = m1 ∩(cid:9) m2, is a new bba on Ω defined as:(cid:3)m ∩(cid:9)(A) =m1(B)m2(C),B,C⊆Ω,B∩C=A∀A ⊆ Ω,where ∩(cid:9) represents the operator of combination.Definition 6. [4] Let m1 and m2 be two bbas defined on frame Ω. Th",
            {
                "entities": [
                    [
                        3046,
                        3074,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 230 (2016) 134–172Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAffect control processes: Intelligent affective interaction using a partially observable Markov decision processJesse Hoey a,∗a David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, N2L 3G1, Canadab Centre for Theoretical Neuroscience, University of Waterloo, Waterloo, Ontario, N2L 3G1, Canadac Potsdam University of Applied Sciences, Institute for Urban Futures, Kiepenheuerallee 5, 14469 Potsdam, Germany, Tobias Schröder b,c, Areej Alhothali aa r t i c l e i n f oa b s t r a c tArticle history:Received 2 April 2014Received in revised form 12 August 2015Accepted 17 September 2015Available online 3 October 2015Keywords:AffectEmotionSociologyAffect control theoryMarkov decision processIntelligent tutoring systemAssistive technologyHuman–computer interactionThis paper describes a novel method for building affectively intelligent human-interactive agents. The method is based on a key sociological insight that has been developed and extensively verified over the last twenty years, but has yet to make an impact in artificial intelligence. The insight is that resource bounded humans will, by default, act to maintain affective consistency. Humans have culturally shared fundamental affective sentiments about identities, behaviours, and objects, and they act so that the transient affective sentiments created during interactions confirm the fundamental sentiments. Humans seek and create situations that confirm or are consistent with, and avoid and suppress situations that disconfirm or are inconsistent with, their culturally shared affective sentiments. This “affect control principle” has been shown to be a powerful predictor of human behaviour. In this paper, we present a probabilistic and decision-theoretic generalisation of this principle, and we demonstrate how it can be leveraged to build affectively intelligent artificial agents. The new model, called BayesAct, can maintain multiple hypotheses about sentiments simultaneously as a probability distribution, and can make use of an explicit utility function to make value-directed action choices. This allows the model to generate affectively intelligent interactions with people by learning about their identity, predicting their behaviours using the affect control principle, and taking actions that are simultaneously goal-directed and affect-sensitive. We demonstrate this generalisation with a set of simulations. We then show how our model can be used as an emotional “plug-in” for artificially intelligent systems that interact with humans in two different settings: an exam practice assistant (tutor) and an assistive device for persons with a cognitive disability.© 2015 Elsevier B.V. All rights reserved.1. IntroductionDesigners of intelligent systems have increasingly attended to theories of human emotion, in order to build software interfaces that allow users to experience naturalistic flows of communication with the computer. This endeavour requires a comprehensive mathematical representation of the relations between affective states and actions that captures, ideally, the subtle cultural rules underlying human communication and emotional experience. In this paper, we argue that Affect Control Theory (ACT), a mathematically formalized theory of the interplays between cultural representations, interactants’ * Corresponding author.E-mail addresses: jhoey@cs.uwaterloo.ca (J. Hoey), post@tobiasschroeder.de (T. Schröder), aalhothal@cs.uwaterloo.ca (A. Alhothali).http://dx.doi.org/10.1016/j.artint.2015.09.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\fJ. Hoey et al. / Artificial Intelligence 230 (2016) 134–172135identities,1 and affective experience [1], is a suitable framework for developing emotionally intelligent agents. To accomplish this, we propose a probabilistic and decision theoretic generalisation of ACT, called BayesAct, which we argue is more flexible than the original statement of the theory for the purpose of modelling human–computer interaction. BayesAct is formulated as a partially observable Markov decision process or POMDP. The key contributions of this new theory are: (1) to represent sentiments as probability distributions over a continuous affective space, thereby allowing these sentiments to be dynamic and uncertain; (2) to propose a new kind of agent based on affect control theory that has the ability to learn affective iden-tities of interactants; (3) to integrate the affective dynamics proposed by affect control theory with standard POMDP-based artificial intelligence; and (4) to introduce explicit utility functions to affect control theory that parsimoniously trade-off affective and propositional goals for a human-interactive agent. These contributions allow BayesAct to be used as an arti-ficially intelligent agent: they provide the computerised agent with a mechanism for predicting how the affective state of an interaction will progress (based on affect control theory) and how this will modify the object of the interaction (e.g. the software application being used). The agent can then select its strategy of action in order to maximize the expected values of the outcomes based both on the application state and on its affective alignment with the human.Affect control theory arises from the long tradition of symbolic interactionism that began almost three hundred years ago with the insights of Adam Smith [2] into the self as a mirror of the society in which it is embedded: the so-called looking-glass self [2]. These insights eventually led to the modern development of structural symbolic interactionism through Mead, Cooley, and Stryker [3], and culminating in Heise’s affect control theory (ACT) [1], which this paper extends. Although ACT, and symbolic interactionism in general, are very well established theories in sociology, they have had little or no impact in artificial intelligence. This paper is the first to propose affect control theory as a fundamental substrate for intelligent agents, by elaborating a POMDP-based formulation of the underlying symbolic interactionist ideas. This new theory allows ACT to be used in goal-directed human-interactive systems, and thereby allows A.I. researchers to connect to over fifty years of sociological research on cultural sentiment sharing and emotional intelligence. The theory also contributes a generalisation of affect control theory that we expect will lead to novel developments in sociology, social psychology, and in the emerging field of computational social science [4].The main contribution of this paper is therefore of a theoretical nature, which we demonstrate in simulation. We have also implemented the theory in a simple tutoring system and in an assistive technology that is designed to assist persons with dementia. We report the results of an empirical survey and demonstrative study with human participants in the case of the tutoring system. The assistive technology is further described in [5]. Therein, a prompting system delivers audio-visual cues to a person using a variety of different affective “styles”. The mapping from non-verbal behaviours of the user to the “style” of prompt is defined by BayesAct alone.1.1. Model overviewBayesAct is a partially observable Markov decision process (POMDP, see Fig. 1(a) and Section 2.2) model of an agent interacting with an environment. The environment is modelled, as usual in a POMDP, with a set of states, X. A BayesAct agent has actions, A, available to it, and these actions change the state of the environment according to a stochastic transition function. The environment model (states) are not assumed to be observable (they are latent), but the agent has access to a set of observations (cid:2)x, from which it can infer the state of the environment by using Bayes’ rule and a stochastic observation function that relates states to observations. Finally, a utility function, R, describes the preferences of the agent on a numerical scale. The utility function can be used by a Bayesian (sequential) decision maker to optimize decisions (action choices) in the long term.BayesAct is modelling the case where the environment contains humans (or other BayesAct agents) who are partially responsible for the state dynamics. BayesAct therefore includes a latent user model as part of its state space (shown as factor Y in Fig. 1(a)). The user model describes the identity (see footnote 1) of the agent and of the human it is interacting with, and conditions (stochastically) the dynamics of the state.The identities are modelled as four concurrently evolving discrete-time non-linear dynamical systems over a three di-mensional continuous affective space. The three dimensions are: evaluation (how good/bad something is), potency (how strong/weak), and activity (how active/passive). The space is referred to as “EPA” space, and it has been found by soci-ologists to capture over 80% of the variance in affective meanings ascribed by humans across cultures and languages [6], and is in some sense “fundamental” to human emotion (see Section 2.1). It has also been used by other works in affective computing (where it is referred to as “PAD” space or Pleasure–Arousal–Dominance, see Section 2.3).BayesAct departs from other works on affective computing because it also includes the dynamics of identities in the EPA space. These dynamics are learned from datasets of human sentiments about events, measured during decades of research by sociologists in different cultures around the world, and forming part of a sociological theory called affect control theory (ACT) ([1]; see Section 2.1). As the EPA space, the dynamics are found to be culturally stable and consistent [7]. The dynamics form part of the transition function (for the identities, Y) in the POMDP (see Section 3.2). The dynamics relate an agent’s stable (through tim",
            {
                "entities": [
                    [
                        3649,
                        3677,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 607–619www.elsevier.com/locate/artintComplexity of constructing solutions in the core based on synergiesamong coalitions ✩Vincent Conitzer ∗, Tuomas SandholmCarnegie Mellon University, Computer Science Department, 5000 Forbes Avenue, Pittsburgh, PA 15213, USAReceived 5 December 2004; received in revised form 10 January 2006; accepted 16 January 2006Available online 17 February 2006AbstractCoalition formation is a key problem in automated negotiation among self-interested agents, and other multiagent applications.A coalition of agents can sometimes accomplish things that the individual agents cannot, or can accomplish them more efficiently.Motivating the agents to abide by a solution requires careful analysis: only some of the solutions are stable in the sense that nogroup of agents is motivated to break off and form a new coalition. This constraint has been studied extensively in cooperativegame theory: the set of solutions that satisfy it is known as the core. The computational questions around the core have receivedless attention. When it comes to coalition formation among software agents (that represent real-world parties), these questionsbecome increasingly explicit.In this paper we define a concise, natural, general representation for games in characteristic form that relies on superadditivity.In our representation, individual agents’ values are given as well as values for those coalitions that introduce synergies. We showthat this representation allows for efficient checking of whether a given outcome is in the core. We then show that determiningwhether the core is nonempty is NP-complete both with and without transferable utility. We demonstrate that what makes theproblem hard in both cases is determining the collaborative possibilities (the set of outcomes possible for the grand coalition); wedo so by showing that if these are given, the problem becomes solvable in time polynomial in the size of the representation in bothcases. However, we then demonstrate that for a hybrid version of the problem, where utility transfer is possible only within thegrand coalition, the problem remains NP-complete even when the collaborative possibilities are given. Finally, we show that forconvex characteristic functions, a solution in the core can be computed efficiently (in O(nl2) time, where n is the number of agentsand l is the number of synergies), even when the collaborative possibilities are not given in advance. 2006 Elsevier B.V. All rights reserved.1. IntroductionCoalition formation is a key problem in automated negotiation among self-interested agents, and other multiagentapplications. A coalition of agents can sometimes accomplish things that the individual agents cannot, or can accom-plish them more efficiently. Motivating the agents to abide by a solution requires careful analysis: only some of the✩ The material in this paper is based upon work supported by the National Science Foundation under CAREER Award IRI-9703122, Grant IIS-9800994, ITR IIS-0081246, ITR IIS-0121678, a Sloan Fellowship, and an IBM Ph.D. Fellowship. A short, early version of this paper appeared inthe Eighteenth International Joint Conference on Artificial Intelligence (IJCAI-03).* Corresponding author.E-mail addresses: conitzer@cs.cmu.edu (V. Conitzer), sandholm@cs.cmu.edu (T. Sandholm).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.005\f608V. Conitzer, T. Sandholm / Artificial Intelligence 170 (2006) 607–619solutions are stable in the sense that no group of agents is motivated to break off and form a new coalition. Thisconstraint has been studied extensively in cooperative game theory: the set of solutions that satisfy it is known as thecore. The computational questions around the core have received less attention. When it comes to coalition formationamong software agents (that represent real-world parties), these questions become increasingly explicit.While the driving motivation of this work is coalition formation among software agents, the computation of stablesolutions may have applications beyond automated negotiation as well, for instance in electronic commerce. As anexample, consider a large number of companies, some subsets of which could form profitable virtual organizationsthat can respond to larger or more diverse orders than the individual companies can. Determining stable value divisionsallows one to see which potential virtual organizations would be viable in the sense that the companies in the virtualorganization would naturally stay together. As another example, consider a future online service that determines howmuch each employee of a company should be paid so that the company does not collapse as a result of employeesbeing bought away by other companies. The input to this service would be how much subsets of the company’semployees would be paid if they left collectively (for instance, a whole department could be bought away). Thisinput could come from salary databases or a manager’s estimate. The computational problem of determining a stablerenumeration would be crucial for such a service. Both of these example problems fit exactly under the model that westudy in this paper.The rest of the paper is organized as follows. In Section 2, we review the required concepts from cooperativegame theory. In Section 3, we define a concise general representation for games in characteristic form that relies onsuperadditivity, and show that it allows for efficient (relative to the size of the representation) checking of whethera given outcome is in the core. In Section 4, we show that determining whether the core is nonempty is NP-completeboth with and without transferable utility. In Section 5, we demonstrate that what makes the problem hard in bothcases is determining the collaborative possibilities (the set of outcomes possible for the grand coalition); we do so byshowing that if these are given, the problem becomes solvable in time polynomial in the size of the representation inboth cases. In Section 6, we show that for a hybrid version of the problem, where utility transfer is possible only withinthe grand coalition, the problem remains NP-complete even when the collaborative possibilities are given. Finally, inSection 7, we show that if the characteristic function is convex, a solution in the core can be constructed efficiently(in O(nl2) time, where n is the number of agents and l is the number of synergies), even when the collaborativepossibilities are not given in advance.2. Definitions from cooperative game theoryIn this section we review standard definitions from cooperative game theory, which we will use throughout thepaper. In the definitions, we follow Mas-Colell et al. [21].In general, how well agents in a coalition do may depend on what nonmembers of the coalition do (for example,see [2,6,10,22–24,28]). However, in cooperative game theory, coalition formation is usually studied in the contextof characteristic function games where the utilities of the coalition members do not depend on the nonmembers’actions [5,16,31,35–37]. (One way to interpret this is to consider the coalition members’ utilities to be the utilitiesthey can guarantee themselves no matter what the nonmembers do [1].)Definition 1. Given a set of agents A, a utility possibility vector uB for B = {b1, . . . , bnB(ub1 , . . . , ubnBA utility possibility set is a set of utility possibility vectors for a given set B.} ⊆ A is a vector) representing utilities that the agents in B can guarantee themselves by cooperating with each other.Definition 2. A game in characteristic form consists of a set of agents A and a utility possibility set V (B) for eachB ⊆ A.Sometimes games in characteristic form have transferable utility, which means agents in a coalition can transferutility among themselves. (Usually, this is done using monetary transfers.)Definition 3. A game in characteristic form is said to have transferable utility if for every B ⊆ A there is a numberv(B) (the value of B) such that V (B) = {uB = (uBb1(cid:1) v(B)}.b∈B uBb, . . . , uB(cid:1)):bnB\fV. Conitzer, T. Sandholm / Artificial Intelligence 170 (2006) 607–619609It is commonly assumed that the joining of two coalitions does not prevent them from acting as well as theycould have acted separately. In other words, the composite coalition can coordinate by choosing not to coordinate.This assumption is known as superadditivity. When superadditivity holds, it is always best for the grand coalition ofall agents to form.1 We will assume superadditivity throughout the paper. This makes our hardness results strongerbecause even a restricted version of the problem is hard.Definition 4. A game in characteristic form is said to be superadditive if, for any two disjoint subsets B, C ⊆ A,and for any uB ∈ V (B) and uC ∈ V (C), we have (uB , uC) ∈ V (B ∪ C). (In the case of transferable utility, this isequivalent to saying that for any B, C ⊆ A with B and C disjoint, v(B ∪ C) (cid:2) v(B) + v(C).)We now need a solution concept. In this paper, we study only what is arguably the best known solution concept,namely the core (see, for example, [16,21,35]). It was first introduced by Gillies [13]. An outcome is said to be in thecore if there is no subset of agents that can break off and form their own coalition in such a way that all of the agentsin that coalition are better off. The following definition makes this precise., . . . , uBDefinition 5. An outcome uA = (uA(uBb1) ∈ V (B) such that for all b ∈ B, uBsaying that the outcome is blocked by B if v(B) >coalition.1 , . . . , uAbnBn ) ∈ V (A) is blocked by coalition B ⊆ A if there exists uB =b . (In the case of transferable utility, this is equivalent tob∈B uAb .) An outcome is in the core if it is blocked by nob > uA(cid:1)In general, the core can be empty. If the core is empty, the game is inherently unstable because no matter whatoutcome is chosen, some subset of agents is motiva",
            {
                "entities": [
                    [
                        3433,
                        3461,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 382–409Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the power of structural decompositions of graph-basedrepresentations of constraint problemsGianluigi Greco a, Francesco Scarcello b,∗a Dept. of Mathematics, Università della Calabria, I-87036 Rende, Italyb DEIS, Università della Calabria, I-87036 Rende, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 21 January 2009Received in revised form 14 December 2009Accepted 17 December 2009Available online 4 January 2010Keywords:Constraint satisfactionDecomposition methodsHypergraphsDual graphsIncidence graphsPrimal graphsTreewidthThe Constraint Satisfaction Problem (CSP) is a centralissue of research in ArtificialIntelligence. Due to its intractability, many efforts have been made in order to identifytractable classes of CSP instances, and in fact deep and useful results have already beenachieved. In particular, this paper focuses on structural decomposition methods, which areessentially meant to look for near-acyclicity properties of the graphs or hypergraphs thatencode the structure of the constraints interactions. In general, constraint scopes comprisean arbitrary number of variables, and thus this structure may be naturally encoded viahypergraphs. However, in many practical applications, decomposition methods are appliedover suitable graph representations of the (possibly non-binary) CSP instances at hand.Despite the great interest in such binary approaches, a formal analysis of their power, interms of their ability of identifying islands of tractability, was missing in the literature.The aim of this paper is precisely to fill this gap, by studying the relationships amongbinary structural methods, and by providing a clear picture of the tractable fragmentsof CSP that can be specified with respect to each of these decomposition approaches,when they are applied to binary representations of non-binary CSP instances. In particular,various long-standing questions about primal, dual and incidence graph encodings areanswered. The picture is then completed by comparing methods on binary encodings withmethods specifically conceived for non-binary constraints.© 2009 Elsevier B.V. All rights reserved.1. Introduction and summary of resultsConstraint satisfaction is a central issue of research in Artificial Intelligence and other areas of computer science and ithas, in fact, an impressive spectrum of applications ranging from scheduling with preferences and deadlines, to temporalreasoning, machine learning, and plan design, just to cite a few. Formally, a constraint (S i, R i) consists of a constraintscope S i , i.e., a list of variables, and of an associated constraint relation ri containing the legal combinations of values forthe variables in S i . An instance of a constraint satisfaction problem (CSP), also called constraint network [6], is a triple I =(Var, U , C), where Var is a finite set of variables, U is a finite domain of values, and C = {C1, C2, . . . , Cq} is a finite set ofconstraints. A solution to a CSP instance is a substitution ϑ : Var −→ U , such that all constraints are simultaneously satisfied,i.e., for each 1 (cid:2) i (cid:2) q, S iϑ ∈ ri . By solving a CSP we mean determining whether the problem has a solution at all (i.e.,checking for constraint satisfiability) and, if so, computing one solution.* Corresponding author. Tel.: +39 0984 494752, fax: +39 0984 494713.E-mail addresses: ggreco@mat.unical.it (G. Greco), scarcello@deis.unical.it (F. Scarcello).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.12.004\fG. Greco, F. Scarcello / Artificial Intelligence 174 (2010) 382–409383Fig. 1. (a) A solution to the 4-queens problem, and (b) a crossword puzzle.Example 1.1 (n-queens). Consider the problem of placing n queens on (the n rows of) a chessboard so that no queen cancapture any other queen. This problem can be formalized as a constraint satisfaction problem as follows. The set Var containsa variable Q i for each queen to be placed in the i-th row, U = {1, . . . , n} represents the columns where each queen can beplaced, and for each pair of distinct queens Q i and Q j , the set C contains the constraint Ci, j = ((Q i, Q j), {(cid:5)pi, p j(cid:6) | pi (cid:7)=p j ∧ |pi − p j| (cid:7)= |i − j|}) stating, intuitively, that any two queens can be placed neither on the same column, nor on thesame diagonal of the board.As an example, for n = 3 the problem does not admit solutions. Instead, for n = 4, a possible solution is the substitutionϑ such that Q 1ϑ = 3, Q 2ϑ = 1, Q 3ϑ = 4, and Q 4ϑ = 2. This solution is depicted in Fig. 1(a).Note that in the n-queens problem each constraint is defined over two variables at most, and this is therefore an exampleof binary CSP. In other scenarios, instead, it is much more natural to define constraints over more than two variables, therebyleading to the general case of non-binary CSPs.Example 1.2 (Crossword puzzle). Fig. 1(b) shows a combinatorial crossword puzzle (taken from [10]), which is a typical non-binary CSP [6]. A set of legal words is associated to each horizontal or vertical array of white boxes delimited by blackboxes. A solution to the puzzle is an assignment of a letter to each white box such that to each white array is assigned aword from its set of legal words. This problem can be recast in a CSP as follows. There is a variable Xi for each white box,and a constraint C for each array D of white boxes. (For simplicity, we just write the index i for variable Xi .) The scope ofC is the list of variables corresponding to the white boxes of the sequence D, and the relation of C contains the legal wordsfor D.For the example, in Fig. 1, we have C1H = ((1, 2, 3, 4, 5), r1H ), C8H = ((8, 9, 10), r8H ), C11H = ((11, 12, 13), r11H ), C20H =((20, 21, 22, 23, 24, 25, 26), r20H ), C1V = ((1, 7, 11, 16, 20), r1V ), C5V = ((5, 8, 14, 18, 24), r5V ), C6V = ((6, 10, 15, 19, 26), r6V ),C13V = ((13, 17, 22), r13V ). Subscripts H and V stand for “Horizontal” and “Vertical,” respectively, resembling the usual nam-ing of definitions in crossword puzzles. A possible instance for the relation r1H is {(cid:5)h, o, u, s, e(cid:6), (cid:5)c, o, i, n, s(cid:6), (cid:5)b, l, o, c, k(cid:6)}.It is well known and easy to see that constraint satisfiability is an NP-complete problem, even when restricted overbinary instances (since it can encode, for example, graph colouring). Hence, much effort has been spent to identify tractableclasses of CSPs, and deep and useful results have already been achieved in the literature. In fact, the various successfulapproaches to single out tractable CSP classes can be divided into two main groups (see, e.g., [4,10]):(i) Techniques that look for tractable classes on the basis of the structure of the constraint scopes {S 1, . . . , Sq}, indepen-dently of the actual constraint relations r1, . . . , rq; and(ii) Techniques that exploit peculiar properties (such as combinatorial properties of the underlying algebras) of the con-straint relations r1, . . . , rq.In this paper, we shall deal with the former kind of techniques, usually called structural decomposition methods.1.1. Structural decomposition methodsMuch of the nature of constraint scope interactions can be captured using the constraint hypergraph H(I) = (V , H)associated to any CSP instance I = (Var, U , C), where V = Var and H = {var(S) | C = (S, r) ∈ C}, and var(S) denotes the setof variables in the scope S of the constraint C —in the following, we often denote the set of vertices V by N (H) and the setof hyperedges H by E(H). For instance, Fig. 2 shows the hypergraph Hcp associated to the crossword puzzle in Example 1.2.A fundamental property of hypergraphs is acyclicity (see, e.g., [2,9]). Indeed, it has been observed that constraint satis-fiability is feasible in polynomial time on the class of those CSP instances whose associated hypergraphs are acyclic (see,\f384G. Greco, F. Scarcello / Artificial Intelligence 174 (2010) 382–409Fig. 2. Hypergraph Hcp of the crossword puzzle in Example 1.2.e.g., [10]). However, in practice, constraint hypergraphs are hardly acyclic (for instance, the hypergraph Hcp in Fig. 2 is notacyclic), even though not very intricate. Therefore, there is a great deal of interest in the literature in identifying tractableclasses of constraint satisfaction problem instances by looking for nearly acyclic structures, as for they can be characterizedvia structural decomposition methods (see, e.g., [5,6,10,22]). These methods aim at transforming a given cyclic hypergraphinto an acyclic one, by organizing its edges or its nodes into a polynomial number of clusters, and by suitably arrangingthese clusters as a tree, called a decomposition tree. The original problem instance can then be evaluated over the decom-position tree, with a cost that is exponential in the cardinality of the largest cluster, also called width of the decomposition.In fact, the earliest decomposition techniques were designed to solve binary CSPs only, such as the n-queens problemof Example 1.1; that is, they have been designed to deal with scenarios where the constraint hypergraph is actually agraph (call them binary or graph methods). Subsequently, methods have been proposed which are capable of working onthe constraint hypergraph without assuming any bound on the number of variables involved in each of the constraintsand, hence, without limiting their applicability to the special case of binary CSPs. In particular, much research is currentlyaimed at defining completely novel methods exploiting the whole information encoded in the constraint hypergraph (callthem non-binary or hypergraph-based methods). However, many attempts to deal with general (i.e., non-binary) constraintproblems have historically been conceived to reuse existent methods for binary CSPs, by representing any instance I bysome graph, rather than by",
            {
                "entities": [
                    [
                        3652,
                        3680,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 156–192Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMagic Sets for disjunctive Datalog programs ✩Mario Alviano, Wolfgang Faber∗, Gianluigi Greco, Nicola LeoneDepartment of Mathematics, University of Calabria, 87036 Rende, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 13 January 2011Received in revised form 20 April 2012Accepted 24 April 2012Available online 26 April 2012Keywords:Logic programmingStable modelsMagic SetsAnswer set programmingData integrationIn this paper, a new technique for the optimization of (partially) bound queries overdisjunctive Datalog programs with stratified negation is presented. The technique exploitsthe propagation of query bindings and extends the Magic Set optimization technique(originally defined for non-disjunctive programs).An important feature of disjunctive Datalog programs is non-monotonicity, which callsfor non-deterministic implementations, such as backtracking search. A distinguishingcharacteristic of the new method is that the optimization can be exploited also duringthe non-deterministic phase. In particular, after some assumptions have been made duringthe computation, parts of the program may become irrelevant to a query under theseassumptions. This allows for dynamic pruning of the search space. In contrast, the effectof the previously defined Magic Set methods for disjunctive Datalog is limited to thedeterministic portion of the process. In this way, the potential performance gain by usingthe proposed method can be exponential, as could be observed empirically.The correctness of the method is established and proved in a formal way thanks to astrong relationship between Magic Sets and unfounded sets that has not been studied inthe literature before. This knowledge allows for extending the method and the correctnessproof also to programs with stratified negation in a natural way.The proposed method has been implemented in the DLV system and various experimentson synthetic as well as on real-world data have been conducted. The experimental resultson synthetic data confirm the utility of Magic Sets for disjunctive Datalog, and theyhighlight the computational gain that may be obtained by the new method with respectto the previously proposed Magic Set method for disjunctive Datalog programs. Furtherexperiments on data taken from a real-life application show the benefits of the MagicSet method within an application scenario that has received considerable attention inrecent years, the problem of answering user queries over possibly inconsistent databasesoriginating from integration of autonomous sources of information.© 2012 Elsevier B.V. All rights reserved.1. IntroductionDisjunctive Datalog is a language that has been proposed for modeling incomplete data [48]. Together with a lightversion of negation, in this paper stratified negation, this language can in fact express any query of the complexity class2 (i.e., NPNP) [22], under the stable model semantics. It turns out that disjunctive Datalog with stratified negation isΣ Pstrictly more expressive (unless the polynomial hierarchy collapses to its first level) than normal logic programming (i.e.,non-disjunctive Datalog with unstratified negation), as the latter can express “only” queries in NP. As shown in [22], the✩Preliminary portions of this paper appeared in the proceedings of the 20th International Conference on Logic Programming (ICLP’04).* Corresponding author.E-mail addresses: alviano@mat.unical.it (M. Alviano), faber@mat.unical.it (W. Faber), ggreco@mat.unical.it (G. Greco), leone@mat.unical.it (N. Leone).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.008\fM. Alviano et al. / Artificial Intelligence 187–188 (2012) 156–192157high expressive power of disjunctive Datalog has also some positive practical implications in terms of modeling knowledge,since many problems in NP can be represented more simply and naturally in stratified disjunctive Datalog than in normallogic programming. For this reason, it is not surprising that disjunctive Datalog has found several real-world applications[42,49,50,57,58], also encouraged by the availability of some efficient inference engines, such as DLV [43], GnT [37], Cmodels[46], or ClaspD [21]. As a matter of fact, these systems are continuously enhanced to support novel optimization strategies,enabling them to be effective over increasingly larger application domains. In this paper, we contribute to this developmentby providing a novel optimization technique, inspired by deductive database optimization techniques, in particular the MagicSet method [6,9,63].The goal of the original Magic Set method (defined for non-disjunctive Datalog programs) is to exploit the presenceof constants in a query for restricting the possible search space by considering only a subset of a hypothetical programinstantiation that is sufficient to answer the query in question. In order to do this, a top–down computation for answeringthe query is simulated in an abstract way. This top–down simulation is then encoded by means of rules, defining new MagicSet predicates. The extensions of these predicates (sets of ground atoms) will contain the tuples that are calculated duringa top–down computation. These predicates are inserted into the original program rules and can then be used by bottom–upcomputations to narrow the computation to what is needed for answering the query.Extending these ideas to disjunctive Datalog faces a major challenge: While non-disjunctive Datalog programs are deter-ministic, which in terms of the stable model semantics means that any non-disjunctive Datalog program has exactly onestable model, disjunctive Datalog programs are non-deterministic in the sense that they may have multiple stable models.Of course, the main goal is still isolating a subset of a hypothetical program instantiation, upon which the considered querywill be evaluated in an equivalent way. There are two basic possibilities how this non-determinism can be dealt with inthe context of Magic Sets: The first is to consider static Magic Sets, in the sense that the definition of the Magic Sets is stilldeterministic, and therefore the extension of the Magic Set predicates is equal in each stable model. This static behavior isautomatic for Magic Sets of non-disjunctive Datalog programs. The second possibility is to allow dynamic Magic Sets, whichalso introduce non-deterministic definitions of Magic Sets. This means that the extension of the Magic Set predicates maydiffer in various stable models, and thus can be viewed as being specialized for each stable model.While the nature of dynamic Magic Sets intuitively seems to be more fitting for disjunctive Datalog than static MagicSets, considering the architecture of modern reasoning systems for disjunctive Datalog substantiates this intuition: Thesesystems work in two phases, which may be considered as a deterministic (grounding) and a non-deterministic (modelsearch) part. The interface between these two is by means of a ground program, which is produced by the deterministicphase. Static Magic Sets will almost exclusively have an impact on the grounding phase, while dynamic Magic Sets alsohave the possibility to influence the model search phase. In particular, some assumptions made during the model searchmay render parts of the program irrelevant to the query, which may be captured by dynamic Magic Sets, but not (or onlyunder very specific circumstances) by static Magic Sets.In the literature, apart from our own work in [20], there is only one previous attempt for defining a Magic Set methodfor disjunctive Datalog, reported in [32,33], which will be referred to as Static Magic Sets (SMS) in this work. The basic ideaof SMS is that bindings need to be propagated not only from rule heads to rule bodies (as in traditional Magic Sets), but alsofrom one head predicate to other head predicates. In addition to producing definitions for the predicates defining Magic Sets,the method also introduces additional auxiliary predicates called collecting predicates. These collecting predicates howeverhave a peculiar effect: Their use keeps the Magic Sets static. Indeed, both magic and collecting predicates are guaranteedto have deterministic definitions, which implies that disjunctive Datalog systems can exploit the Magic Sets only during thegrounding phase. Most systems will actually produce a ground program which does contain neither magic nor collectingpredicates.In this article, we propose a dynamic Magic Set method for disjunctive Datalog with stratified negation under the stablemodel semantics, provide an implementation of it in the system dlv, and report on an extensive experimental evaluation.In more detail, the contributions are:(cid:2)(cid:2)(cid:2)(cid:2)We present a dynamic Magic Set method for disjunctive Datalog programs with stratified negation, referred to asDynamic Magic Sets (DMS). Different from the previously proposed static method SMS, existing systems can exploitthe information provided by the Magic Sets also during their non-deterministic model search phase. This featureallows for potentially exponential performance gains with respect to the previously proposed static method.We formally establish the correctness of DMS. In particular, we prove that the program obtained by the transfor-mation DMS is query-equivalent to the original program. This result holds for both brave and cautious reasoning.We highlight a strong relationship between Magic Sets and unfounded sets, which characterize stable models. Wecan show that the atoms which are relevant for answering a query are either true or form an unfounded set,which eventually allows us to prove the query-equivalence results.Our results hold for a disjunctive Datalog language with stratified negation under the stable model semantics. Inthe literat",
            {
                "entities": [
                    [
                        3772,
                        3800,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 295 (2021) 103458Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA review of possible effects of cognitive biases on interpretation of rule-based machine learning models ✩Tomáš Kliegr a,∗a Prague University of Economics and Business, Department of Information and Knowledge Engineering, Czech Republicb The Prague College of Psychosocial Studies, Czech Republicc Johannes Kepler University, Department of Computer Science, Linz, Austria, Štˇepán Bahník b, Johannes Fürnkranz ca r t i c l e i n f oa b s t r a c tArticle history:Received 3 October 2019Received in revised form 7 December 2020Accepted 20 January 2021Available online 26 January 2021Keywords:Cognitive biasCognitive illusionInterpretabilityMachine learningRule induction1. IntroductionWhile the interpretability of machine learning models is often equated with their mere syntactic comprehensibility, we think that interpretability goes beyond that, and that human interpretability should also be investigated from the point of view of cognitive science. The goal of this paper is to discuss to what extent cognitive biases may affect human understanding of interpretable machine learning models, in particular of logical rules discovered from data. Twenty cognitive biases are covered, as are possible debiasing techniques that can be adopted by designers of machine learning algorithms and software. Our review transfers results obtained in cognitive psychology to the domain of machine learning, aiming to bridge the current gap between these two areas. It needs to be followed by empirical studies specifically focused on the machine learning domain.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).This paper aims to investigate the possible effects of cognitive biases on human understanding of machine learning models, in particular inductively learned rules. We use the term “cognitive bias” as a representative for various cognitive phenomena that materialize themselves in the form of occasionally irrational reasoning patterns, which are thought to allow humans to make fast judgments and decisions.Their cumulative effect on human reasoning should not be underestimated as “cognitive biases seem reliable, systematic, and difficult to eliminate” [83]. The effect of some cognitive biases is more pronounced when people do not have well-articulated preferences [168], which is often the case in explorative data analysis.Previous works have analyzed the impact of cognitive biases on multiple types of human behavior and decision making. A specific example is the seminal book “Social cognition” by Kunda [90], which is concerned with the impact of cognitive biases on social interaction. Another, more recent work by Serfas [147] focused on the context of capital investment. Closer to the domain of machine learning, in their article “Psychology of Prediction”, Kahneman and Tversky [84] warned that cog-nitive biases can lead to violations of the Bayes theorem when people make fact-based predictions under uncertainty. These results directly relate to inductively learned rules, since these are associated with measures such as confidence and support expressing the (un)certainty of the prediction they make. Despite some early work [104,105] showing the importance of study of cognitive phenomena for rule induction and machine learning in general, there has been a paucity of follow-up ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail addresses: tomas.kliegr@vse.cz (T. Kliegr), bahniks@seznam.cz (Š. Bahník), juffi@faw.jku.at (J. Fürnkranz).https://doi.org/10.1016/j.artint.2021.1034580004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fT. Kliegr, Š. Bahník and J. FürnkranzArtificial Intelligence 295 (2021) 103458research. In previous work [53], we have evaluated a selection of cognitive biases in the very specific context of whether minimizing the complexity or length of a rule will also lead to increased interpretability, which is often taken for granted in machine learning research.In this paper, we attempt to systematically relate cognitive biases to the interpretation of machine learning results. We anchor our discussion on inductively learned rules, but note in passing that a deeper understanding of human cognitive bi-ases is important for all areas of combined human-machine decision making. We focus primarily on symbolic rules because they are generally considered to belong to the class of interpretable models, so that there is little general awareness that different ways of presenting or formulating them may have an important impact on the perceived trustworthiness, safety, or fairness of an AI system. In principle, our discussion also applies to rules that have been inferred by deduction, where, however, such concerns are maybe somewhat alleviated by the proved correctness of the resulting rules. To further our goal, we review twenty cognitive biases and judgmental heuristics whose misapplication can lead to biases that can distort the interpretation of inductively learned rules. The review is intended to help to answer questions such as: How do cognitive biases affect the human understanding of symbolic machine learning models? What could help as a “debiasing antidote”?This paper is organized as follows. Section 2 provides a brief review of related work published at the intersection of rule learning and psychology. Section 3 motivates our study by showing an example of a learnt rule and discussing sample cognitive biases that can affect its plausibility. Section 4 describes the criteria that we applied to select a subset of cognitive biases into our review, which eventually resulted in twenty biases. These biases and their respective effects and causes are covered in detail in Section 5. Section 6 provides a concise set of recommendations aimed at developers of rule learning algorithms and user interfaces. In Section 7 we state the limitations of our review and outline directions for future work. The conclusions summarize the contributions of the paper.2. Background and related workWe selected individual rules as learnt by many machine learning algorithms as the object of our study. Focusing on simple artefacts—individual rules—as opposed to entire models such as rule sets or rule lists allows a deeper, more focused analysis since a rule is a small self-contained item of knowledge. Making a small change in one rule, such as adding a new condition, allows to test the effect of an individual factor. In this section, we first motivate our work by putting it into the context of prior research on related topics. Then, we proceed by a brief introduction to inductive rule learning (Section 2.2) and a brief recapitulation of previous work in cognitive science on the subject of decision rules (Section 2.3). Finally, we introduce cognitive biases (Section 2.4) and rule plausibility (Section 2.5), which is a measure of rule comprehension.2.1. MotivationIn the following three paragraphs, we discuss our motivation for this review, and summarize why we think this work is relevant to the larger artificial intelligence community.Rules as interpretable models Given that neural networks and ensembles of decision trees are increasingly becoming the prevalent type of representation used in machine learning, it might be at first surprising that our review focuses almost exclusively on decision rules. The reason is that rules are widely used as a means for communicating explanations of a variety of machine learning approaches. In fact, quite some work has been devoted to explaining black-box models, such as neural networks, support vector machines and tree ensembles with interpretable surrogate models, such as rules and decision trees (for a survey on this line of work we refer, e.g., to [69]). As such a conversion typically also goes hand-in-hand with a corresponding reduction in the accuracy of the model, this approach has also been criticized [142], and the interest in directly learning rule-based models has recently renewed (see, e.g., [52,176,110,173]).Embedding cognitive biases to learning algorithms The applications of cognitive biases go beyond explaining existing machine learning models. For example, Taniguchi et al. [159] demonstrate how a cognitive bias can be embedded in a machine learn-ing algorithm, achieving superior performance on small datasets compared to commonly used machine learning algorithms with “generic” inductive bias.Paucity of research on cognitive biases in artificial intelligence Several recent position and review papers on explainability in Artificial Intelligence (xAI) recognize that cognitive biases play an important role in explainability research [106,126]. To our knowledge, the only systematic treatment of psychological phenomena applicable to machine learning is provided by the review of Miller [106], which focuses on reasons and thought processes that people apply during explanation selection, such as causality, abnormality and the use of counterfactuals. This authoritative review observes that there are currently no studies that look at cognitive biases in the context of selecting explanations. Because of the paucity of applicable research focusing on machine learning, the review of Miller [106]—like the present paper—takes the first step of applying influential psychological studies to explanation in the xAI context without accompanying experimental validation specific to machine learning. While Miller [106] summarizes the main reasoning processes that drive generation and understanding of explana-tions, our review focuses specifically on cognitive biases as psychological phenomena that can distort the interpretation of machine learning models if not prope",
            {
                "entities": [
                    [
                        3748,
                        3776,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 196 (2013) 1–25Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe complexity of mixed multi-unit combinatorial auctions:Tractability under structural and qualitative restrictionsValeria Fionda a, Gianluigi Greco b,∗a Faculty of Computer Science, Free University of Bozen-Bolzano, Italyb Department of Mathematics, University of Calabria, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 7 November 2011Received in revised form 17 December 2012Accepted 23 December 2012Available online 3 January 2013Keywords:Mixed multi-unit combinatorial auctionsComputational complexityStructural decomposition methodsMixed multi-unit combinatorial auctions (MMUCAs) are extensions of classical combina-torial auctions (CAs) where bidders trade transformations of goods rather than just setsof goods. Solving MMUCAs, i.e., determining the sequences of bids to be accepted by theauctioneer, is computationally intractable in general. However, differently from classicalcombinatorial auctions, little was known about whether polynomial-time solvable classesof MMUCAs can be singled out on the basis of their characteristics. The paper fills thisgap, by studying the computational complexity of MMUCA instances under structural andqualitative restrictions, which characterize interactions among bidders and types of bidsinvolved in the various transformations, respectively.© 2013 Elsevier B.V. All rights reserved.1. IntroductionMixed multi-unit combinatorial auctions (MMUCAs) are extensions of classical combinatorial auctions (CAs) where par-ticipants are allowed to bid not only on bundles of goods to buy, but also on bundles of goods to sell and of transformationsof goods [1].These mechanisms are particularly useful in the context of automatizing supply chain formation, where production pro-cesses often emerge as the result of complex interactions among producers and consumers [2]. Indeed, in these contexts,the auctioneer wants to obtain certain products based on the goods she initially owns, by exploiting a production processpossibly involving further goods to be acquired from suppliers or to be obtained via transformations operating on the goodscurrently available to her.Example 1.1. Consider the supply chain associated with the production of bicycles, which is illustrated in Fig. 1 according toan intuitive graphical notation where goods are represented as ovals, transformations as boxes, and where arrows indicateinputs and outputs of the various transformations. Assume that the auctioneer is presented with 6 different bids over thesingleton sets of transformations {t1}, {t2}, . . . ,{ t6}, whose associated prices are then reported in the boxes as well.The assembly of a bicycle from its constituents (i.e., frame, brakes, drive train, front wheel, back wheel, seat, and handlebars)is thus offered to the auctioneer through the bid over {t6}, which is sold for $10. However, the auctioneer owns only a subsetof such constituents (i.e., frame and brakes), plus two goods (i.e., chain and chainring) that are not immediately exploitableby t6. The auctioneer has therefore to ask suppliers for the missing goods (i.e., front wheel, back wheel, seat, and handlebars),which are made available trough the bids over {t3}, {t4}, and {t5}, for $10, $17, and $8, respectively. Note that t4 incidentallyproduces a dynamo, which is not part of the bicycle the auctioneer is willing to produce. Finally, note that the auctioneer* Corresponding author.E-mail addresses: fionda@inf.unibz.it (V. Fionda), ggreco@mat.unical.it (G. Greco).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.002\f2V. Fionda, G. Greco / Artificial Intelligence 196 (2013) 1–25Fig. 1. Mixed multi-unit combinatorial auction in Example 1.1.needs to accept one further bid (either over {t1} for $2, or over {t2} for $3) to assemble the chain and the chainrings into(cid:2)the drive train, in order for the latter to be taken as input by t6.A solution to a MMUCA instance is, roughly, any set of bids whose transformations can be arranged in a sequenceallowing the auctioneer to produce the desired goods. Among all possible solutions, in the Winner-Determination problemwe are interested in singling out those having the minimum total cost or, equivalently, guaranteeing the maximum possiblerevenue. For instance, it is easily seen that the minimum production cost in Example 1.1 is $29, which is witnessed by thesequence of transformations t1, t4, t6.The Winner-Determination problem for MMUCA instances has intensively been studied in recent years, by extending tothis novel setting several results originally conceived for classical CAs. In particular, languages have been defined and ana-lyzed which allow bidders to compose (atomic) bids in a natural and intuitive way [1], and motivated by their intractability(formally, NP-hardness), solution approaches have been proposed (see, e.g., [3]) that well-behave on realistic scenarios [4].Differently from classical CAs, however, little was known about whether polynomial-time solvable classes of MMUCAs canbe singled out based on the structural and topological properties of the instances at hand. As a matter of fact, by focusingon the kinds of interactions among bidders that are likely to occur in practice, classes of instances over which Winner-Determination is tractable—called “islands of tractability” in the literature—have been identified for classical CAs (such asstructured item graphs [5] or bounded hypertree-width dual hypergraphs [6]). However, none of these results had a counterpartin the case of MMUCAs.The aim of this paper is precisely to fill this gap, by depicting a clear and complete picture of the frontier of tractabilityfor MMUCA instances, with respect to both qualitative and structural parameters. In particular, note that the existence of asolution is not guaranteed in the case of MMUCAs. For instance, in Example 1.1, if the auctioneer does not initially own theframe, then no solution exists at all. Therefore, checking for the feasibility of the production process is an important andpeculiar source of complexity for MMUCA instances and, accordingly, attention will be focused not only on the Winner-Determination but also on the Feasibility problem of deciding whether a given instance admits a solution at all (no matterof its cost).Our contribution can be summarized as follows:(1) We chart the tractability frontier of the Feasibility problem for MMUCAs under qualitative restrictions, i.e., underrestrictions characterizing the types of bids in terms of the variety and quantity of goods involved in the varioustransformations. The analysis is carried out over three different bidding languages:• Atomic bids, where each bid is just defined over one set of transformations—this is the building block of the followingtwo languages;• OR-language, where bidders submit sets of atomic bids and accept to implement any combination of them for thesum of their prizes; and• XOR-language, where each bidder accepts to implement at most one atomic bid from the set of hers submitted atomicbids.In particular, for the above bidding languages, we analyze the scenario where each underlying atomic bid is definedover a set containing one transformation only (as in Example 1.1), as well as the more general case where each atomicbid is defined over an arbitrary set of transformations.(2) We study the complexity of Feasibility under structural restrictions of the networks originating from bidder interactions,motivated by the fact that many NP-hard problems in different application areas are known to be efficiently solvablewhen restricted to instances that can be modeled via (nearly)acyclic instances. Surprisingly, bad news emerged from\fV. Fionda, G. Greco / Artificial Intelligence 196 (2013) 1–253our investigation. Indeed, we show that Feasibility is hard on (nearly)acyclic instances too, and even for atomic bidsonly. In particular, this is the case for two natural ways of encoding bidder interactions, namely, for:• transformations graphs, where nodes are in one-to-one correspondence with transformations and an edge indicatesthat one transformation produces a good required by the other, and for• goods graphs, where nodes are in one-to-one correspondence with goods and an edge indicates the possibility oftransforming a good into another.(3) We study the complexity of the Winner-Determination problem on MMUCA instances, in order to single out tractableclasses of MMUCAs extending those defined in [5,6] for CAs. To this end, we propose a notion of intricacy of an instanceand we define a hypergraph encoding for bidders interactions. The two concepts are designed to evidence the sources ofqualitative and structural intractability, respectively, which emerged in our analysis of the complexity of the Feasibilityproblem. In fact, we show that on classes of instances with “small intricacy” and whose associated hypergraphs are(nearly)acyclic, Winner-Determination can be solved in polynomial time.Note that the analysis we carry out in this paper extends some preliminary results on the complexity of MMUCAs wediscussed in [7]. There, we focused in fact on atomic bids, in a setting where each bid is defined over a set containingone transformation, and where the free disposal assumption has been considered only. Moreover, the hypergraph-basedapproach to encode interactions among bidders and the associated results are entirely novel contributions of this paper.Organization The rest of the paper is organized as follows. Section 2 reports a few preliminaries on MMUCAs. The complex-ity of Feasibility under qualitative and structural restrictions is discussed in Section 3 and Section 4, respectively. Tractabilityislands for the Winner-Determination problem are isolated in Section 5, and conclusions are drawn in Section 6.2. Mixed multi-unit combinatorial auct",
            {
                "entities": [
                    [
                        3718,
                        3746,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 191–192 (2012) 20–41Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn truth-gaps, bipolar belief and the assertability of vague propositionsJonathan Lawry a,∗, Yongchuan Tang ba Intelligent Systems Laboratory, University of Bristol, Bristol BS8 1UB, UKb College of Computer Science, Zhejiang University, Hangzhou 310027, PR Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 September 2011Received in revised form 12 July 2012Accepted 18 July 2012Available online 1 August 2012Keywords:VaguenessTruth-gapsValuation pairsSemantic uncertaintyIntegrated uncertaintyBipolar belief measuresThis paper proposes an integrated approach to indeterminacy and epistemic uncertaintyin order to model an intelligent agent’s decision making about the assertability ofvague statements. Initially, valuation pairs are introduced as a model of truth-gaps forpropositional logic sentences. These take the form of lower and upper truth-valuationsrepresenting absolutely true and not absolutely false respectively. In particular, we considervaluation pairs based on supervaluationist principles and also on Kleene’s three-valuedlogic. The relationship between Kleene valuation pairs and supervaluation pairs is thenexplored in some detail with particular reference to a natural ordering on semanticprecision. In the second part of the paper we extend this approach by proposing bipolarbelief pairs as an integrated model combining epistemic uncertainty and indeterminacy.These comprise of lower and upper belief measures on propositional sentences, defined bya probability distribution on a finite set of possible valuation pairs. The properties of thesemeasures are investigated together with their relationship to different types of uncertaintymeasure. Finally, we apply bipolar belief measures in a preliminary decision theoretic studyso as to begin to understand how the use of vague expressions can help to mitigate therisk associated with making forecasts or promises. This then has potential applications tonatural language generation systems.© 2012 Elsevier B.V. All rights reserved.1. IntroductionA defining feature of vague concepts is that they admit borderline cases which neither definitely satisfy the conceptnor its negation. For example, there are some height values which would neither be definitely classified as being short nornot short. For propositions involving vague concepts this naturally results in truth-gaps. In other words, there are cases inwhich a proposition is neither absolutely true nor absolutely false. If Ethel’s height lies in a certain intermediate range then theproposition ‘Ethel is short’ may be inherently borderline. Such truth-gaps suggest that a non-Tarskian notion of truth may berequired to capture this aspect of vagueness even in a simple propositional framework. There has been a number of differentpossibilities proposed in the literature for this alternative model of truth including three-valued logics and supervaluations.In the sequel we will discuss and relate two different models of truth-gaps, supervaluationism and Kleene’s strong three-valued logic, in the context of a new framework for bipolar valuations. In particular, we will investigate propositionaltruth-models taking the form of a lower and an upper truth valuation on the sentences of the language. The underlyingidea is that, given such a valuation pair, the lower truth valuation represents the strong criterion of being absolutely true,while the upper valuation represents the weaker criterion of being not absolutely false. In this context, borderline statementsare those for which there is a difference between the lower and upper valuations (i.e. a truth-gap).* Corresponding author.E-mail addresses: j.lawry@bris.ac.uk (J. Lawry), tyongchuan@gmail.com (Y. Tang).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.004\fJ. Lawry, Y. Tang / Artificial Intelligence 191–192 (2012) 20–4121A different perspective on borderline cases relates to the notion of assertability. Here we take the view that conceptdefinitions are to a large extent determined by linguistic convention, and according to such conventions a statement may ormay not be assertable given a particular state of the world. Interestingly, a case can be made that assertability is inherentlybipolar, a phenomenon which manifests itself in a distinction between those propositions which convention would deemdefinitely assertable, and those which convention would not classify as incorrect, or perhaps even dishonest, to assert. Parikh[27] observes that:Certain sentences are assertible in the sense that we might ourselves assert them and other cases of sentences whichare non-assertible in the sense that we ourselves (and many others) would reproach someone who used them. But therewill also be the intermediate kind of sentences, where we might allow their use.For example, consider a witness in a court of law describing a suspect as being short. Depending on the actual heightof the suspect this statement may be deemed as clearly true or clearly false, in which latter case the witness could beaccused of perjury. However, there will also be an intermediate height range for which, while there may be doubt anddiffering opinions concerning the use of the description short, it would not be deemed as definitely inappropriate and hencethe witness would not be viewed as committing perjury. In other words, for certain height values of the suspect, it maybe acceptable to assert the statement ‘the suspect was short’, even though this statement would not be viewed as beingabsolutely true. Clearly there is a natural connection between this bipolar aspect of assertability and the idea of truth-gapsfor borderline cases outlined above. If a statement θ is absolutely true, a judgment which is of course dependent both onthe state of the world and on how linguistic convention defines the relevant concepts, then θ would be definitely assertable.On the other hand, provided that θ is not absolutely false then θ would be deemed acceptable to assert. The bipolarityof assertability would seem to be a special case of what Dubois and Prade [7] refer to as symmetric bivariate unipolarity,whereby judgments are made according to two distinct evaluations on unipolar scales, i.e. distinct evaluations about theassertability of a sentence and its negation. In the current context, we have a strong and a weak evaluation criterion wherethe former corresponds to definite assertability and the latter to acceptable assertability. As with many examples of thistype of bipolarity there is a natural duality between the two evaluation criteria in that a proposition is definitely assertableif and only if it is not acceptable to assert its negation.The adequate representation of epistemic uncertainty is of central importance in any effective model of belief. Typicallywe think of uncertainty as arising because of insufficient information about the state of the world. However, in the presenceof vagueness there may also be semantic uncertainty due to our having only partial knowledge of language conventions.For example, consider the proposition ‘Ethel is short’. Here an agent with certain knowledge of Ethel’s height may stillbe uncertain as to the truth of this proposition due to uncertainty about the conventions governing the definition of theconcept short. Such uncertainty may naturally arise from the distributed manner in which language is learnt across apopulation of communicating agents. Semantic uncertainty often occurs in conjunction with a lack of knowledge concerningthe underlying state of the world. In our example, the agent may also be uncertain as to the precise value of Ethel’s height.In the sequel then we propose an integrated model of semantic and stochastic uncertainty in the context of languageconventions which admit borderline cases. Here we view truth as a function of both the state of the world, e.g. Ethel’sheight, and language convention, e.g. the interpretation of the concept short in terms of height values. An integrated modelof epistemic uncertainty and truth-gaps can then take the form of a probability distribution on the cross product of the setof possible world states and the set of possible language conventions. Furthermore, if a convention maps each state of theworld to a valuation pair, then this naturally results in a probability distribution on possible valuation pairs. Given such adistribution we can immediately define lower and upper measures by evaluating the probabilities of those valuation pairsin which a given sentence is absolutely true and of those in which it is not absolutely false respectively. We refer to theselower and upper measures on the sentences of the language as a bipolar belief pair.We argue that valuation pairs are one of the most straight-forward representations of truth-gaps in natural languagepropositions. Hence, by taking a probability distribution over a set of possible valuation pairs for the language we generatea very natural integrated model of belief for propositions and sentences which involve vague concepts and about whichthere is inherent uncertainty. As such, the proposed framework provides an ideal platform from which we can begin toexplore issues concerning the utility of vagueness in communication. Certainly there are many potential applications ofsuch a study including in natural language generation [39], consensus modelling [24] and multi-agent dialogues [22]. In thispaper we shall focus mainly on the first of these application areas.A fundamental open problem in natural language generation is that of understanding why individuals often chooseto make vague assertions rather than semantically similar crisp (non-vague) ones. In particular, what are the practicaladvantages of such a decision from the perspective of an asserting agent? One approach is ",
            {
                "entities": [
                    [
                        3958,
                        3986,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 32–51Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal defense against election control by deleting voter groupsYue Yin a,∗a Key Lab of Intelligent Information Processing, ICT, CAS, University of Chinese Academy of Sciences, Beijing, Chinab Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United Statesc School of Computer Science and Engineering, Nanyang Technological University, Singapored Dept. of Computer Science, Ariel University, Israel, Yevgeniy Vorobeychik b,∗∗, Bo An c, Noam Hazon da r t i c l e i n f oa b s t r a c tArticle history:Received 5 June 2017Received in revised form 7 February 2018Accepted 15 February 2018Available online 21 February 2018Keywords:Election controlProtecting electionsSecurity gamesElection control encompasses attempts from an external agent to alter the structure of an election in order to change its outcome. This problem is both a fundamental theoretical problem in social choice, and a major practical concern for democratic institutions. Consequently, this issue has received considerable attention, particularly as it pertains to different voting rules. In contrast, the problem of how election control can be prevented or deterred has been largely ignored. We introduce the problem of optimal defense against election control, including destructive and constructive control, where manipulation is allowed at the granularity of groups of voters (e.g., voting locations) through a denial-of-service attack, and the defender allocates limited protection resources to prevent control. We consider plurality voting, and show that it is computationally hard to prevent both types of control, though destructive control itself can be performed in polynomial time. For defense against destructive control, we present a double-oracle framework for computing an optimal prevention strategy. We show that both defender and attacker best response subproblems are NP-complete, and develop exact mixed-integer linear programming approaches for solving these, as well as fast heuristic methods. We then extend this general approach to develop effective algorithmic solutions for defense against constructive control. Finally, we generalize the model and algorithmic approaches to consider uncertainty about voter preferences. Experiments conducted on both synthetic and real data demonstrate that the proposed computational framework can scale to realistic problem instances.1© 2018 Elsevier B.V. All rights reserved.* Principle corresponding author.** Corresponding author.E-mail addresses: melody1235813 @gmail .com (Y. Yin), yevgeniy.vorobeychik @vanderbilt .edu (Y. Vorobeychik), boan @ntu .edu .sg (B. An), noamh @ariel .ac .il(N. Hazon).1 A preliminary version of this work appeared in the Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI-16) [68]. There are several major advances in this article: (i) Whereas the earlier work considered only defense against destructive control, we extended the model to consider defense against constructive control as well. (ii) We analyzed the time complexity of preventing constructive control, and proposed a heuristic algorithm which computes the defense strategy to prevent constructive control in polynomial time (under certain circumstances). (iii) We proposed a mixed integer linear programming approach to compute a strong Stackelberg equilibrium of the game of defense against constructive control, and a more scalable approximation algorithm. (iv) We performed detailed experiments to evaluate the proposed algorithms.https://doi.org/10.1016/j.artint.2018.02.0010004-3702/© 2018 Elsevier B.V. All rights reserved.\fY. Yin et al. / Artificial Intelligence 259 (2018) 32–51331. IntroductionDemocratic institutions rely on the integrity of the voting process. A major threat to this integrity is the possibility that the process can be subverted by malicious parties for their own ends. Indeed, actual incidents of demonstrated and real attempts at vote manipulation and control bear out this concern. For example, the 2013 election in Pakistan was marred by a series of election-day bombings and shootings, resulting in over 150 people dead or injured, in an attempt to subvert the voting process [57], and the 2010 Sri Lanka election exhibited 84 major and 202 minor incidents of poll-related violence [7]. With the dawn of electronic and Internet voting, the additional threat of election control and manipulation through cyber attacks on electronic and Internet voting systems has emerged, with a number of documented demonstration attacks [3,62]. While recent allegations in the U.S. of deliberate cyber attacks aimed at influencing election outcomes have not been specifically against electronic voting systems [61], the collective evidence suggests that these are vulnerable, and may well become targets in the near future. Consequently, cyber security experts have repeatedly urged deployment of better auditing systems for electronic voting systems used in the U.S. elections, arguing that elections can be successfully manipulated through targeted attacks at voting machines and polling places, for example, in battleground states [56]. However, auditing all such systems is laborious and expensive, and few systematic methods for selective auditing have been deployed to date [33].We consider the general problem of protecting elections against malicious subversion, for example, through deployment of enhanced physical security at voting locations, or strategies for choosing which electronic voting machines or voting districts to audit. We model attacks on elections as targeting voter groups, such as voting machines or precincts, in order to change the identity of the election winner, a problem commonly known in prior literature as election control.The study of the computational complexity of election control was initiated by Bartholdi et al. [4], who considered the problem from the perspective of computational complexity. Since then it has received considerable attention in prior liter-ature (see Section 2). In this literature, a voting rule is viewed as resistant if control is NP-hard, and vulnerable otherwise. Many voting rules were shown to be resistant to several types of control, while plurality—which is widely used—can be controlled through voter deletion in polynomial time [4,27]. However, control is usually studied at the granularity of indi-vidual voters, and protection, when considered, is about designing voting rules which are NP-hard to control [19,28]. While these considerations are crucial if one is to understand vulnerability of elections, they are also limited in several respects. First, as the incidents of control described above attest, control can be exercised for groups of voters through a single at-tack, such as a denial-of-service attack on a voting station or a polling center (of which bombing is an extreme example). Second, NP-hardness of control is insufficient evidence for resistance: it is often possible to solve large instances of NP-hard problems in practice (see, e.g., [64] in the case of SAT). Resistance to election control in the broader sense, such as through allocation of limited protection resources to prevent attacks on specific voter groups, has, to our knowledge, neither been modeled nor investigated to date.To address these limitations, we consider the problem of optimally protecting elections against control. We model control as a denial-of-service (deletion) attack on a subset of voter groups, which may represent polling places or electronic vot-ing stations, with the goal of preventing the original winner from winning (destructive control) or making another candidate win (constructive control). We focus on plurality voting. Erdélyi et al. [18] show that constructive control by adding, deleting, and partitioning voters in this model is NP-hard, and recently Maushagen and Rothe [45] have shown NP-completeness of constructive and destructive control by partitioning voter groups for each non-trivial pure scoring rule. In contrast, we show that destructive control can be decided in polynomial time. We then consider the problem of defense against both types of control, modeling it as a Stackelberg game in which an outside party deploys limited protection resources to protect a collection of voter groups, allowing for randomization, and the adversary responds by attempting to subvert (control) the election. Specifically, defense against destructive control is modeled as a zero-sum game, while defense against constructive control is modeled as a nonzero-sum game. Protection resources may represent actual physical security for polling centers or voting stations, or resources devoted to auditing of specific electronic voting systems or electoral districts. We assume that the defender’s goal is to ensure that the same candidate wins with or without an election control attack. We show that the problem of choosing the minimal set of resources to guarantee that an election cannot be controlled is computation-ally hard for both destructive and constructive control. For general cases of defense against destructive control, we propose a double-oracle framework to compute an optimal protection. We prove that both the defender and attacker oracles are NP-complete when randomized strategies are allowed. On the positive side, we develop novel mixed-integer linear pro-gramming formulations for both oracles that enable us to compute a provably optimal solution for protecting elections from destructive control. Moreover, we develop heuristic defender and attacker oracles which significantly speed up computation in the framework. Our experiments demonstrate the effectiveness and scalability of our algorithmic approach.For defense against constructive control, we first introduce a heuristic algorithm which can compute the optimal defender",
            {
                "entities": [
                    [
                        3685,
                        3713,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1673–1699Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA linear approximation method for the Shapley valueShaheen S. Fatima a,∗, Michael Wooldridge b, Nicholas R. Jennings ca Department of Computer Science, Loughborough University, Loughborough LE11 3TU, UKb Department of Computer Science, University of Liverpool, Liverpool L69 3BX, UKc School of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 2 December 2007Received in revised form 22 May 2008Accepted 27 May 2008Available online 7 July 2008Keywords:Coalitional game theoryShapley valueApproximation methodThe Shapley value is a key solution concept for coalitional games in general and votinggames in particular. Its main advantage is that it provides a unique and fair solution, butits main drawback is the complexity of computing it (e.g., for voting games this complexityis #p-complete). However, given the importance of the Shapley value and voting games,a number of approximation methods have been developed to overcome this complexity.Among these, Owen’s multi-linear extension method is the most time efficient, being linearin the number of players. Now,in addition to speed, the other key criterion for anapproximation algorithm is its approximation error. On this dimension, the multi-linearextension method is less impressive. Against this background, this paper presents a newapproximation algorithm, based on randomization, for computing the Shapley value ofvoting games. This method has time complexity linear in the number of players, but has anapproximation error that is, on average, lower than Owen’s. In addition to this comparativestudy, we empirically evaluate the error for our method and show how the differentparameters of the voting game affect it. Specifically, we show the following effects. First, asthe number of players in a voting game increases, the average percentage error decreases.Second, as the quota increases, the average percentage error decreases. Third, the erroris different for players with different weights; players with weight closer to the meanweight have a lower error than those with weight further away. We then extend ourapproximation to the more general k-majority voting games and show that, for n players,the method has time complexity O(k2n) and the upper bound on its approximation erroris O(k2/n).√© 2008 Elsevier B.V. All rights reserved.1. IntroductionCoalition formation is a key form of interaction in multi-agent systems. It is the process of bringing together two ormore agents so as to achieve goals that individuals on their own cannot, or to achieve them more efficiently [2,18,22,23].Often, in such situations, there is more than one possible coalition and a player’s payoff depends on which one he joins.Given this, there are two key problems in this area. First, to ensure that none of the parties in a coalition has any incentiveto break away from it and join another coalition. Second, to determine how the players split the gains from cooperationbetween themselves.In this context, cooperative game theory deals with the problem of coalition formation and offers a number of solutionconcepts that possess desirable properties like stability, fair division of joint gains, and uniqueness [23,27]. Cooperative gametheory differs from its non-cooperative counterpart, in that, it allows the players to form binding agreements, and so there is* Corresponding author.E-mail addresses: S.S.Fatima@lboro.ac.uk (S.S. Fatima), M.J.Wooldridge@csc.liv.ac.uk (M. Wooldridge), nrj@ecs.soton.ac.uk (N.R. Jennings).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.05.003\f1674S.S. Fatima et al. / Artificial Intelligence 172 (2008) 1673–1699often an incentive to work together to receive the largest total payoff. Also, unlike non-cooperative game theory, cooperativegames are not specified through a description of the strategic environment (including the order of the players’ moves andthe set of actions at each move) and the resulting payoffs. Instead, cooperative game theory reduces this collection of datato the coalitional form, where each coalition is represented by a single real number. In short, there are no actions, moves, orindividual payoffs. The chief advantage of this approach, at least in multiple agent environments, is its practical usefulness.Specifically, it allows the abstraction of dealing with groups, rather than the individuals, and so much larger problems canbe handled.In more detail, cooperative game theory offers a number of solution concepts (such as the core, kernel, and Shap-ley value [23]) and a number of multi-agent systems researchers have used and extended these to facilitate automatedcoalition formation [26,31,33,34]. In so doing, a key challenge, from the multi-agent systems perspective, is to study thecomputational aspects of the solutions that game theory provides. This is important because many of these solutions arecomputationally hard to find and so of limited use in building actual systems. For example, computing the core is oftennp-complete [10], while computing the Shapley value is often #p-complete [12].To this end, this paper is concerned with efficiently computing the Shapley value [32]. In more detail, a player’s Shapleyvalue reflects how much that player contributes to a coalition—that is, how much value the agent adds to a coalition. Anagent who never adds much has a small Shapley value, while an agent that always makes a significant contribution has ahigh Shapley value. Now, the main advantage of the Shapley value, over solution concepts such as the core and the kernel, isthat it provides a solution that is both unique and fair. The former is desirable because it leaves no ambiguity; there is onlyone possible solution for a game and so the players know what they will gain from playing it. The latter property relates tohow the gains from cooperation are split between coalition members. In this case, a player’s Shapley value is proportionalto the contribution he makes as a member of a coalition; the greater the contribution, the higher its value. Thus, from aplayer’s perspective, both uniqueness and fairness are desirable properties.However, while uniqueness and fairness are both desirable properties, the Shapley value has one major drawback: formany coalitional games, it cannot be determined in polynomial time. One of the most common coalitional games is thevoting game (which is a means for the players to reach a consensus) and for this game, finding the Shapley value is #p-complete [12] (meaning that it is as hard as counting satisfying assignments of propositional logic formulae [25, p. 442]).Since #p-completeness subsumes np-completeness, this implies that computing the Shapley value for the voting game willbe intractable in general. In other words, it is practically infeasible to try to compute the exact Shapley value. However, thevoting game has practical relevance not only in the context of multi-agent systems [28,34], but also in human settings, as itis an important means of reaching consensus between multiple parties.Against this background, a number of approximation methods have been developed in order to overcome the problem ofcomputational hardness of finding the exact Shapley value (see Section 3 for details). These methods vary in terms of theirtime complexities. Among these, however, Owen’s multi-linear extension method [24] for a weighted voting game is one ofthe most time efficient, requiring time linear in the number of players. However, the accuracy with which it approximatesthe real value can be an issue in some cases (the method works well for those games for which all the players havesmall weights). To combat this, this paper presents a new approximation algorithm for computing the Shapley value for aweighted voting game. Our method is based on the technique of randomization and has time complexity that is linear inthe number of players, but has a lower approximation error than Owen’s method. In addition to this comparative study, weempirically evaluate the error for our method in a range of environments and show how the different parameters of thevoting game affect the error. We then extend our approximation method (for a weighted voting game) to the more generalk-majority voting games. For this, we show that for n players, the time complexity of our extended method is O(k2n) andthe upper bound on its approximation error is O(k2/n).√By undertaking this work, this paper makes a number of important contributions to the state of the art. First, and mostimportantly, it presents a new computationally efficient approximation algorithm for the Shapley value for weighted vot-ing games. The proposed method has linear time complexity, and is better than Owen’s method in terms of its error ofapproximation. Second, we extend our approximation method for a weighted voting game to the more general k-majorityvoting games. This is the first such method for this game. Finally, we provide a comprehensive error analysis of our approx-imation method. As mentioned earlier, we not only consider the worst case and obtain the upper bound on the error, butwe also consider a general case and show how the different parameters of the voting game affect this error. This analysisdistinguishes our work from the existing literature on approximation methods in that these have no error analysis1 (neitherfor the worst, nor the general case). Nevertheless, we believe such analysis is essential because it enables us to present acomplete picture of our method’s performance in terms of how far the approximation can be from the exact Shapley valueand how the different parameters of the voting game affect it.The remainder of the paper is organized as follows. Section 2 defines the Shapley value more formally and deta",
            {
                "entities": [
                    [
                        3784,
                        3812,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1079–1100Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintContractor programmingGilles Chabert a,∗, Luc Jaulin ba Ecole des Mines de Nantes LINA CNRS UMR 6241, 4, rue Alfred Kastler, 44300 Nantes, Franceb ENSIETA, 2, rue Fran cois Verny, 29806 Brest Cedex 9, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 22 February 2008Received in revised form 11 March 2009Accepted 15 March 2009Available online 18 March 2009Keywords:Constraint processingInterval methodsSolver designProgramming languagesThis paper describes a solver programming method, called contractor programming, thatcopes with two issues related to constraint processing over the reals. First, continuousconstraints involve an inevitable step of solver design. Existing softwares provide aninsufficient answer by restricting users to choose among a list of fixed strategies. Ourfirst contribution is to give more freedom in solver design by introducing programmingconcepts where only configuration parameters were previously available. Programmingconsists in applying operators (intersection, composition, etc.) on algorithms calledcontractors that are somehow similar to propagators.Second, many problems with real variables cannot be cast as the search for vectorssimultaneously satisfying the set of constraints, but a large variety of different outputsmay be demanded from a set of constraints (e.g., a paving with boxes inside and outside ofthe solution set). These outputs can actually be viewed as the result of different contractorsworking concurrently on the same search space, with a bisection procedure intervening incase of deadlock. Such algorithms (which are not strictly speaking solvers) will be madeeasy to build thanks to a new branch & prune system, called paver.Thus, this paper gives a way to deal harmoniously with a larger set of problems whilegiving a fine control on the solving mechanisms. The contractor formalism and the paversystem are the two contributions. The approach is motivated and justified through differentcases of study. An implementation of this framework named Quimper is also presented.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConstraint programming is a simple and efficient paradigm to handle a large class of combinatorial problems [40,10,44].In the presence of real-valued variables, constraint propagation algorithms combined with interval analysis [16,22,27,19,9]are also particularly well-suited, included for real-world applications (see, e.g., [33,21]). We shall refer to this interval variantof constraint programming as interval programming. Even then, interval programming has had only moderate success. In ouropinion, the reason is a lack of clear and unified formalism describing how solvers and derived programs are built. Thispaper is an attempt to fill this gap.We propose a framework that allows one to build a continuous solver with a few lines, in a high-level syntax. More thanjust another tuning language, a programming framework is proposed.1.1. MotivationThree reasons justify the introduction of a solver programming framework in presence of real variables.* Corresponding author.E-mail addresses: gilles.chabert@emn.fr (G. Chabert), luc.jaulin@ensieta.fr (L. Jaulin).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.002\f1080G. Chabert, L. Jaulin / Artificial Intelligence 173 (2009) 1079–11001. Constraint programming is a declarative paradigm which means that a programmer should spend most of the effort inmodeling conveniently the problem. This effort may involve breaking symmetries, introducing global or soft constraints,etc.. All these concepts are related to modeling and represent, by the way, very active fields of research. In theory, thesolver is a black box of which a programmer could ignore the details.Despite of this, there is always a need at some point to control the solver, as it is with all declarative languages (considerfor instance Prolog cuts that allow ruling out choices in the search). We can say that the overall efficiency one gets isthe combined result of efforts made on both aspects: modeling and solver control.With real variables, modeling languages are limited.1 Constraints can usually be nothing but equations which meansthat mathematics is de facto the ultimate modeling language.2 The consequence is that solver control becomes aninevitable step if one is to improve efficiency.2. Continuous solvers have a two-layered structure, namely interval analysis and constraint programming, The lower layerincludes interval arithmetics and interval numerical algorithms (e.g., an interval variant of the Newton iteration) withround-off considerations. The upper layer includes branch & prune algorithms for describing sets of reals defined byconstraints (or optimizing a criterion under constraints). Since these layers correspond to quite different scientific com-munities, there is a need more than ever for an interface between them. In concrete words, it would be useful to givea constraint programmer the ability to develop a continuous solver without digging into details of interval analysis.3. The last and possibly main point is related to the output of constraint solvers. With discrete domains, the output isalways the set of solutions (or a subset optimizing some criteria). But in continuous domains, there may be a largevariety of different outputs. First, one may look for a sub-paving (a set of boxes) encompassing the solutions and thisis precisely what most of the existing solvers provide. They act as root finders. Next, in case of a solution set witha non-null volume, several sub-pavings are expected, each satisfying a different property, basically: “may contain asolution”, “does contain a solution” or “contains only solutions”. Such solvers rather act as set describers. Actually, wewill see through the examples of Section 2 that the semantics behind the sub-pavings may completely change from oneproblem to the other.3 As we will show, neither a root finder nor a set describer is adapted for solving these problems. Ofcourse, ad-hoc solutions always exist, but the purpose is precisely to avoid a multiplicity of programs where a single onewould be enough. In practice, when people are facing a specific constraint problem that requires a specific algorithm,they have to reverse-engineer the code of an existing solver. Often, they redevelop it from scratch.1.2. ContributionWe propose a formalism and an algorithm, called paver.In the formalism, the different interval routines (evaluations, projections, existence tests, etc.) are all wrapped in thevery same object called contractor (see Section 3). Of course, the concept of contractor is not a novelty on its own. Our(first) contribution is to redefine various constraint programming techniques (propagation, shaving, parameter splitting, etc.)as operations over contractors that yield new contractors (Section 4). Syntactically, the contractor is then the unique atom,whence a certain simplicity. A solver can then be programed, rather than configured, by combining different contractors(examples are given in Sections 4.2, 4.3, 5.1 and 5.5).The paver algorithm is a generic solver. It takes a list of contractors, an initial box and follows a classical recursion: thecontractors are successively called on the current box until either it gets empty or no more contraction could be done. Inthe latter case, the box is bisected and contractors are called back again.The fact that different contractors work concurrently allows solving problems of quite different nature (see next section).This is our second contribution.Hence, contractor programming consists in two distinct steps: contractor design and paver design. The former refers to thedesign of the most possible efficient contractor for a given set (constraint) and shall be discussed in Section 4. The latterrefers to the selection of contractors that yield the desired output, regardless of efficiency.This framework is already supported by a real system named Quimper that will be introduced in Section 6.Thinking of contractor programming as an extension of constraint programming is valid to the extent that contractorshelp in modeling the output of a problem. But, fundamentally, there is not such an extension since constraints basically tellthe “what” whereas contractors tell the “how”.Note that branching will not be covered in this paper but one has to keep in mind that this part of the paver should becustomizable as well. Only plain bisection will be used in the examples (variable are selected with a round-robin heuristic).1 This limitation holds for numerical systems involving analytic expressions, which cover most of the mathematical models of physics problems. Butmodeling languages as such are not limited with real variables any more than with discrete ones (one may introduce table of constraints, piecewiseconstraints, etc.).2 There is still a notable exception: geometrical constraints. Geometry represents a semantic level above algebra; as an example, the “intersection of threespheres” can be introduced as a global constraints instead of three equivalent distance equations [1]. But, except in such cases, no improvement has to beexpected from the modeling side.3 We can say that no modeling language dedicated to the output exists so far, and this is another important distinction with discrete problems wherethis modeling aspect is not as ubiquitous (solvers using explanations are counter-examples).\fG. Chabert, L. Jaulin / Artificial Intelligence 173 (2009) 1079–110010811.3. Power of contractor programmingAs for every programming language, the power of contractor programming, i.e., the class of problems that can be solvedusing this paradigm would require the setting of computability theory to be described formally. Pavings obtained in ourframework are the results of algorithms that recur",
            {
                "entities": [
                    [
                        3387,
                        3415,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1290–1307Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDemocratic approximation of lexicographic preference modelsFusun Yaman a,∗, Thomas J. Walsh b, Michael L. Littman c, Marie desJardins da BBN Technologies, 10 Moulton St., Cambridge, MA 02138, USAb University of Arizona, Department of Computer Science, Tucson, AZ 85721, USAc Rutgers University, Department of Computer Science, Piscataway, NJ 08854, USAd University of Maryland Baltimore County, Computer Science and Electrical Engineering Department, Baltimore, MD 21250, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 5 August 2010Accepted 5 August 2010Available online 2 December 2010Keywords:Lexicographic modelsPreference learningBayesian methods1. IntroductionLexicographic preference models (LPMs) are an intuitive representation that corresponds tomany real-world preferences exhibited by human decision makers. Previous algorithms forlearning LPMs produce a “best guess” LPM that is consistent with the observations. Ourapproach is more democratic: we do not commit to a single LPM. Instead, we approximatethe target using the votes of a collection of consistent LPMs. We present two variations ofthis method—variable voting and model voting—and empirically show that these democraticalgorithms outperform the existing methods. Versions of these democratic algorithms arepresented in both the case where the preferred values of attributes are known and the casewhere they are unknown. We also introduce an intuitive yet powerful form of backgroundknowledge to prune some of the possible LPMs. We demonstrate how this backgroundknowledge can be incorporated into variable and model voting and show that doing soimproves performance significantly, especially when the number of observations is small.© 2010 Elsevier B.V. All rights reserved.Lexicographic preference models (LPMs) are one of the simplest yet most intuitive preference representations. An LPMdefines an order of importance on the variables that describe the objects in a domain and uses this order to make preferencedecisions. For example, the meal preference of a vegetarian with a weak stomach could be represented by an LPM such thata vegetarian dish is always preferred over a non-vegetarian dish, and among vegetarian or non-vegetarian items, mild dishesare preferred to spicy ones.Despite the simplicity of lexicographic LPMs, several studies on human decision making [4,20,9] experimentally demon-strate that humans often make decisions using lexicographic reasoning instead of mathematically more sophisticated meth-ods such as linear additive value maximization [6].Previous work on learning LPMs from a set of preference observations has been limited to autocratic approaches: oneof many possible consistent LPMs is picked heuristically and used for future decisions. However, it is highly likely thatautocratic methods will produce poor approximations of the target when there are few observations.In this paper, we present a democratic approach to LPM learning, which does not commit to a single LPM. Instead,we approximate a target preference using the votes of a collection of consistent LPMs. We present two variations of thismethod: variable voting and model voting. Variable voting operates at the variable level and samples the consistent LPMsimplicitly. The learning algorithm based on variable voting learns a weak order on the variables, such that each linearizationcorresponds to an LPM that is consistent with the observations. Model voting explicitly samples the consistent LPMs and* Corresponding author.E-mail addresses: fusun@bbn.com (F. Yaman), twalsh@cs.arizona.edu (T.J. Walsh), mlittman@cs.rutgers.edu (M.L. Littman), mariedj@cs.umbc.edu(M. desJardins).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.012\fF. Yaman et al. / Artificial Intelligence 175 (2011) 1290–13071291employs a weighted vote, where the weights are computed using Bayesian priors. The additional complexity of voting-basedalgorithms (compared to autocratic methods) is tolerable: both algorithms have low-order polynomial time complexity. Ourexperiments show that these democratic algorithms outperform both the average and worst-case performance of the state-of-the-art autocratic algorithm.We also investigate the effect of imperfect data on the learning algorithms. We consider two kinds of imperfections:faulty observations (noise) and hidden ties (ties that are broken arbitrarily). Our empirical evaluation demonstrates that all ofthe algorithms we consider are robust in the presence of hidden ties. However, even a small number of faulty observationssignificantly reduce the performance of the voting algorithms. On the other hand, the greedy algorithm is resilient: that is,the performance decline is proportional to the amount of noise in the data. We take a lesson from this, and adapting thevoting methods to consider the amount of noise in an environment, we empirically show the resulting heuristic is on parwith the greedy approach in the case of noisy observations.To further improve the performance of the learning algorithms when the number of observations is small, we introducean intuitive yet powerful form of background knowledge. The background knowledge defines equivalence classes on thevariables, indicating the most important set of variables, the second most important set, and so on. This representationpermits a user or designer to provide partial information about an LPM (or a class of LPMs) that can be used by the learnerto reduce the search space. We demonstrate how this background knowledge can be used with variable and model votingand show that doing so improves performance significantly, especially when the number of observations is small.In the rest of the paper, we give some background on LPMs (Section 2), then describe our voting-based methods (Sec-tion 3). After introducing these methods in the case where the preferred values of all attributes are known, we presentextensions of these algorithms to the case where preferred values are not known a priori (Section 4). We then introduce ourbackground knowledge representation, show how we can generalize the voting methods to exploit this background knowl-edge (Section 5), present an approach for handling noisy data (Section 6), and present experimental results of this work(Section 7). Finally, we present related work (Section 8) and discuss our future work and conclusions (Section 9).2. Lexicographic preference modelsIn this section, we briefly introduce the lexicographic preference model (LPM) and summarize previous results on learn-ing LPMs. In this work, we only consider binary variables whose domain is {0, 1}.1 For clarity in the introduction of ouralgorithms, we assume for now that the preferred value of each variable is known. This assumption will be removed inSection 4. Without loss of generality, we will assume that 1 is always preferred to 0.Given a set of variables, X = { X1, . . . , Xn}, an object A over X is a vector of the form [x1, . . . , xn]. We use the notationA( Xi) to refer the value of Xi in the object A. A lexicographic preference model L on X is a total order on a subset R of X .We denote this total order with (cid:2)L. Any variable in R is relevant with respect to L; similarly, any variable in I = X − Ris irrelevant with respect to L. If a variable A appears earlier in this total order than B ( A < B), then A is said to be moreimportant or to have a smaller rank than B.If A and B are two objects, then the preferred object given L is determined as follows:• Find the smallest (most important) variable X∗in (cid:2)L such that X∗has different values in A and B. The object that hasthe value 1 for Xis the most preferred.∗• If all relevant variables in L have the same value in A and B, then the objects are equally preferred (a tie).Example 1. Suppose X1 < X2 < X3 is the total order defined by an LPM L, and consider objects A = [1, 0, 1, 1], B =[0, 1, 0, 0], C = [0, 0, 1, 1], and D = [0, 0, 1, 0]. A is preferred over B because A( X1) = 1, and X1 is the most importantvariable in L. B is preferred over C because B( X2) = 1 and both objects have the same value for X1. Finally, C and D areequally preferred because they have the same values for the relevant variables.An observation o = ( A, B) is an ordered pair of objects, connoting that A is preferred to B. In many practical applications,however, preference observations are gathered from demonstration of an expert who breaks ties arbitrarily. That is, whenpresented with a situation in which a decision or choice must be made, if the expert judges the two alternatives to beequally good, the expert will in fact be indifferent, and will therefore be equally likely to choose either alternative. Thus, forsome observations, A and B may actually be tied in the preference order, although we cannot determine this directly fromthe observations. Therefore, an LPM L is said to be consistent with an observation ( A, B) iff L implies that A is preferredto B or that A and B are equally preferred.The problem of learning an LPM is defined as follows. Given a set of observations, find an LPM L that is consistent withthe observations. Previous work on learning LPMs was limited to the case where all variables are relevant. This assumptionentails that, in every observation ( A, B), A is strictly preferred to B, since ties can only happen when there are irrelevantattributes.1 The representation can easily be generalized to monotonic preferences with ordinal variables, such that 1 corresponds to a preference on the values inincreasing order, and 0 to a decreasing order, as shown by Yaman and desJardins [21] for conditional preference networks (CP-nets).\f1292F. Yaman et al. / Artificial Intelligence 175 (2011) 1290–1307Algorithm 1 greedyPermutationRequire: A set of variable",
            {
                "entities": [
                    [
                        3926,
                        3954,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 643–652www.elsevier.com/locate/artintExistential assertions and quantum levels onthe tree of the situation calculusFrancesco SavelliDipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Salaria 113, I-00198 Roma, ItalyReceived 14 February 2005; received in revised form 7 December 2005; accepted 5 January 2006Available online 8 February 2006AbstractIn a seminal paper, Reiter introduced a variant of the situation calculus along with a set of its properties. To the best of ourknowledge, one of these properties has remained unproved and ignored despite its relevance to the planning problem and theexpressivity of the theories of actions. We state this property in a more general form and provide its proof. Intuitively, whenevera theory of actions entails that there exists a situation satisfying a first order formula (e.g., a goal), at least one such situation mustbe found within a predetermined distance from the initial situation. This distance is finite and the same in all the models of thetheory, since it depends only on the theory and the formula at hand. 2006 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Reasoning about actions and change; Situation calculus1. IntroductionIn reasoning about actions and change with partial knowledge, computing a plan of actions that achieves a specifiedgoal can be impossible even if the existence of the plan is formally guaranteed. Indeed, if a logical theory of actionsdoes not include a complete axiomatic representation of the system’s state, no one plan (or finite disjunction of plans)might exist that simultaneously meets the goal in all the models of the theory, though each model might still containits own valid plan. When this is the case, no finite plan guaranteed to succeed can be built and executed in the realworld, even though its existence is actually entailed by the theory.This problem has a theoretical solution in the variant of the situation calculus [1] introduced by Reiter [2], whichhas represented one of the most influential approaches to laying formal foundations for planning, diagnosis, and agentspecification in artificial intelligence, besides having contributed new insights into database theory. For nearly fifteenyears, a diverse body of research has stemmed from Reiter’s seminal paper [2], and the original ideas and notionscontained therein are currently at the core of much work in cognitive robotics. All but one of the properties of theformalism were formally proved in a later paper [3] after cleaner and more systematic axiomatization, and have beenextensively employed in later research.E-mail address: Francesco.Savelli@dis.uniroma1.it (F. Savelli).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.002\f644F. Savelli / Artificial Intelligence 170 (2006) 643–652To the best of our knowledge, the theorem in [2] that provides the solution to the problem introduced abovehas never been mentioned again, and its formal justification has not appeared in literature. The theorem formallyguarantees that if a theory of actions entails the existence of a plan that achieves a given goal, a finite disjunctiveinstance can be built.This result is still theoretically very relevant as the research community begins to investigate more complexsystems, and consequently the problem of plan computability is being recasted in more sophisticated terms. One note-worthy example is the problem of “knowing how” to execute a program augmented with non-deterministic choicesand sensing actions [4,5] in cognitive robotics.In this paper we provide the missing proof of Reiter’s theorem. We state the result in more general terms and showits implications for the expressivity of the formalism. Intuitively, whenever an action theory entails that there existsa situation satisfying a first order formula (e.g., a goal), at least one such situation must be found inside a specialregion of the tree of situations that characterizes the models of the theory. This region takes the form of a finite subsetof all the levels of the tree, and it is the same in all the models of the theory, since it depends only on the theory andthe formula at hand. We dub the situation-tree levels belonging to this subset “quantum levels”.The rest of this paper is organized as follows. In Section 2 we recall the basic formal notions needed to make thispaper self-contained, and introduce some preliminary definitions and results that are straightforward consequencesof previous work. In Section 3 we state and prove some properties of the situation calculus, including the theoremmentioned above (Theorem 2 of [2]). In Section 4 we discuss the implications of these results for the expressivity ofthe situation calculus and for current research in reasoning about actions and change.2. The situation calculusWe assume the reader is familiar with the basic concepts of classical logic [6]. We recall some notations.In a formula, by τ1/τ2 we denote that the occurrences of τ1 are replaced by τ2. By (∀) or (∃) at the beginning ofa formula we intend that all the free variables occurring in the formula are universally or existentially closed. Givena function or constant symbol ω of a language L, ωM denotes the interpretation of ω in the structure M of L. Weextend the classical notation of entailment to set of sentences: M |= {φi}i∈N means that the structure M entails everysentence φ1, φ2, . . . of the set simultaneously. The meaning of T |= {φi}i∈N, where T is a theory, is likewise defined.We use the notations, definitions, and results given in [3], which provides systematic and formally completefoundations for the situation calculus as formulated in [2]. These notions are recalled in Sections 2.1, 2.2, and 2.3.Sections 2.4, 2.5, and 2.6 introduce notions that simply follow from previous results.2.1. The language LsitcalcThe language Lsitcalc is a three-sorted second order language with equality. The three sorts are action for actions,situation for situations, and a catch-all sort object for everything else depending on the domain of application.We adopt the following notations, with subscripts and superscripts: α and a for terms and variables of sort action,σ and s for terms and variables of sort situation; t and x for terms and variables of any sort.S0 is the constant denoting the initial situation, anddo : action × situation → situationis a special function that enables the inductive construction of successive situations. The term do(α, σ ) interprets thesituation resulting from performing the action α in the situation σ . Thus the termdo(αn, do(. . . , do(α2, do(α1, S0))))—abbreviated as do([α1, . . . , αn], S0)—interprets the situation obtained after the sequence of actions α1, . . . , αn hastaken place. (If n = 0, do([α1, . . . , αn], σ ) is σ .)Hence, situations represent sequences of actions, which should be viewed as histories of the dynamical domain,rather than as its states. This is a fundamental distinguishing feature of Reiter’s variant of the situation calculus.The actions are usually completely represented by a finite set of action function symbols with signature (action ∪object)n → action. As an example, consider the action function symbol moveOn(x, y) denoting the action of moving\fF. Savelli / Artificial Intelligence 170 (2006) 643–652645the object x on the object y. The term do(moveOn(book, table), S0) will interpret the situation in which this actionhas been applied to the two objects interpreted by the constant symbols book and table.Two special predicates are (cid:1) : situation × situation, which defines an ordering relation on situations, andPoss : action × situation, which defines which actions can be performed in a given situation.The dynamical properties of the domain are represented by function and predicate symbols with signatures(action ∪ object)n × situation → (action ∪ object) and (action ∪ object)n × situation. These functions and predi-cates are respectively called functional and relational fluents. Following the example above, the relational fluentsOn(x, y, s) and Holding(z, s) may mean that in the situation s the object x is on the object y, and that the object z isbeing held by the agent. Non-fluent functions or predicates can be used to represent properties and facts independentof any specific situation, like Flat(table) or Larger(table, book).The use of terms of sort situation in Lsitcalc is limited. The only constant and function symbols of this sort are S0and do. The only predicates allowed to take an argument of sort situation are Poss, (cid:1), the equality, and the relationalfluents. The only functions allowed to take an argument of sort situation are do and the functional fluents.In a structure M of Lsitcalc the domain is partitioned into the subsets Obj, Act, and Sit, reflecting the three sorts ofthe language. Terms of sorts object, action, and situation range respectively over these different domains. We use νfor an assignment to free variables of any sort.2.2. Basic action theoriesA formula of Lsitcalc is uniform in σ iff it is first order, it does not mention the predicates Poss or (cid:1), it does notmention equality on situations, it does not quantify over variables of sort situation, and σ is the only term of sortsituation that is mentioned in the fluents occurring in the formula. The set of these formulas can be syntacticallydefined by induction [3]. Intuitively, the key property of a formula uniform in σ is that it “concerns only σ ”.A basic action theory D is composed of the foundational axioms Σ, the set of action precondition axioms Dap, theset of successor state axioms Dss, the set of unique names axioms for the action function symbols Duna, and the initialdatabase DS0 . The structure of these sets and of their axioms are as follows.1• Σ contains four foundational, domain-independent axioms.(∀) do(a1, s1) = do(a2, s2) ⊃ a1 = a2 ∧ s1 = s2is a unique name ax",
            {
                "entities": [
                    [
                        2811,
                        2839,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 248 (2017) 123–157Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom model checking to equilibrium checking: Reactive modules for rational verificationJulian Gutierrez, Paul Harrenstein, Michael Wooldridge∗Department of Computer Science, University of Oxford, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 2 July 2015Received in revised form 2 April 2017Accepted 8 April 2017Available online 12 April 2017Keywords:Complexity of equilibriaReactive modulesTemporal logicModel checking is the best-known and most successful approach to formally verifying that systems satisfy specifications, expressed as temporal logic formulae. In this article, we develop the theory of equilibrium checking, a related but distinct problem. Equilibrium checking is relevant for multi-agent systems in which system components (agents) are assumed to be acting rationally in pursuit of delegated goals, and is concerned with understanding what temporal properties hold of such systems under the assumption that agents select strategies in equilibrium. The formal framework we use to study this problem assumes agents are modelled using Reactive Modules, a system modelling language that is used in a range of practical model checking systems. Each agent (or player) in a Reactive Modules game is specified as a nondeterministic guarded command program, and each player’s goal is specified with a temporal logic formula that the player desires to see satisfied. A strategy for a player in a Reactive Modules game defines how that player selects enabled guarded commands for execution over successive rounds of the game. For this general setting, we investigate games in which players have goals specified in Linear Temporal Logic (in which case it is assumed that players choose deterministic strategies) and in Computation Tree Logic (in which case players select nondeterministic strategies). For each of these cases, after formally defining the game setting, we characterise the complexity of a range of problems relating to Nash equilibria (e.g., the computation or the verification of existence of a Nash equilibrium or checking whether a given temporal formula is satisfied on some Nash equilibrium). We then go on to show how the model we present can be used to encode, for example, games in which the choices available to players are specified using STRIPS planning operators.© 2017 Elsevier B.V. All rights reserved.1. IntroductionOur main interest in this paper is in the analysis of concurrent systems composed of multiple non-deterministic computer programs, in which at run-time each program resolves its non-determinism rationally and strategically in pursuit of an individual goal, specified as a formula of temporal logic. Since the programs are assumed to be acting strategically, game theory provides a natural collection of analytical concepts for such systems [53]. If we apply game-theoretic analysis to such systems, then the main questions to be answered about such systems are not just “what computations might the system produce?”, but rather, “what computations might the system produce if the constituent programs act rationally?” If we interpret acting rationally to mean choosing strategies (for resolving non-determinism) that are in Nash equilibrium, then * Corresponding author.E-mail address: mjw@cs.ox.ac.uk (M. Wooldridge).http://dx.doi.org/10.1016/j.artint.2017.04.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f124J. Gutierrez et al. / Artificial Intelligence 248 (2017) 123–157this question amounts to asking “which of the possible computations of the system will be produced in equilibrium?” Further, if we use temporal logic as the language for expressing properties of our multi-agent and concurrent system (as is standard in the computer aided verification community [20]), then we can also interpret this question as “which temporal logic formulae are satisfied by computations arising from the selection of strategies in equilibrium?” We refer to this general problem as equilibrium checking [75].Related questions have previously been considered within computer science and artificial intelligence – see e.g., [14,23,29,30,51,13,8]. However, a common feature in this previous work is that the computational models used as the basis for analysis are highly abstract, and in particular are not directly based on real-world programming models or languages. For example, in [29] the authors define and investigate iterated Boolean games (iBG), a generalisation of Boolean games [36,37], in which each agent exercises unique control over a set of Boolean variables, and system execution proceeds in an infinite sequence of rounds, with each agent selecting a valuation for the variables under their control in each round. Each player has a goal, specified as a formula of Linear Temporal Logic (LTL), which it desires to see achieved. The iterated Boolean games model is simple and natural, and provides a compelling framework with which to pose questions relating to strategic multi-agent interaction in settings where agents have goals specified as logical formulae. However, this model is arguably rather abstract, and is some distance from realistic programming languages and system modelling languages; we discuss such work in more detail in the related work section towards the end of this article.In brief, our main aim is to study a framework without these limitations. Specifically, we study game-like systems in which players are specified using (a subset of) the Reactive Modules language [2], which is widely used as a system modelling language in practical model checking systems such as mocha [4] and Prism [43]. Reactive Modules is intended to support the succinct, high-level specification of concurrent and multi-agent systems. As we will see, Reactive Modulescan readily be used to encode other frameworks for modelling multi-agent systems (such as multi-agent STRIPS planning systems [10]).The remainder of the article is structured as follows:• We begin in the following section by motivating our work in detail, in particular by arguing that the classical notion of system correctness is of limited value in multi-agent systems, and introducing the idea of equilibrium checking as representing a more appropriate framework through which to understand the behaviour of such systems.• We then survey the logics LTL and CTL, and their semantic basis on Kripke structures, present srml – a sublanguage ofReactive Modules that we use throughout the article – and then develop a formal semantics for it.• We then introduce Reactive Modules games, in which the structure of the game (what we call the “arena”) is specified using Reactive Modules, and the preferences of players are specified by associating a temporal (LTL or CTL) goal formula with each player, which defines runs or computation trees that would satisfy the player’s goal.• We then investigate the complexity of various game-theoretic questions in Reactive Modules games, for both the LTL and the CTL settings, and conclude by discussing the complexity and expressiveness of our new framework against the most relevant related work. Table 2 at the end of the paper summarises our findings.• Finally, to demonstrate the wider applicability of our framework, we show how it can be used to capture propositional STRIPS games (cf. [22,12,25]), such as the MA-STRIPS model of Brafman and Domshlak [10].Although largely self-contained, our technical presentation is necessarily terse, and readers may find it useful to have some familiarity with temporal logics [20,18], model checking [16], complexity theory [54], and basic concepts of non-cooperative game theory [53].2. MotivationOur aim in this section is to motivate and introduce the idea of equilibrium checking as a multi-agent systems counter-part to the standard notion of verification and model checking. (Many readers will be familiar with much of this material – we beg their indulgence so that we can tell the story in its entirety.)Correctness and formal verification The correctness problem has been one of the most widely studied problems in computer science over the past fifty years, and remains a topic of fundamental concern to the present day [9]. Broadly speaking, the correctness problem is concerned with checking that computer systems behave as their designer intends. Probably the most important problem studied within the correctness domain is that of formal verification. Formal verification is the problem of checking that a given computer program or system P is correct with respect to a given formal (i.e., mathematical) specification ϕ. We understand ϕ as a description of system behaviours that the designer judges to be acceptable – a program that guarantees to generate a behaviour as described in ϕ is deemed to correctly implement the specification ϕ.A key insight, due to Amir Pnueli, is that temporal logic can be a useful language with which to express formal specifica-tions of system behaviour [56]. Pnueli proposed the use of Linear Temporal Logic (LTL) for expressing desirable properties of computations. LTL extends classical logic with tense operators X (“in the next state. . . ”), F (“eventually. . . ”), G (“always. . . ”), and U (“. . . until . . . ”) [20]. For example, the requirement that a system never enters a “crash” state can naturally be ex-pressed in LTL by a formula G¬crash. If we let (cid:2)P (cid:3) denote the set of all possible computations that may be produced by the program P , and let (cid:2)ϕ(cid:3) denote the set of state sequences that satisfy the LTL formula ϕ, then verification of LTL properties \fJ. Gutierrez et al. / Artificial Intelligence 248 (2017) 123–157125Fig. 1. Model checking. A model checker takes as input a model, representing a finite state abstraction of a system, together with a claim about the system behaviour, expressed in temporal logic. It the",
            {
                "entities": [
                    [
                        3456,
                        3484,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2010–2020Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiscovering theorems in game theory: Two-person games with uniquepure Nash equilibrium payoffs ✩Pingzhong Tang∗, Fangzhen LinDepartment of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Konga r t i c l ei n f oa b s t r a c tIn this paper we provide a logical framework for two-person finite games in strategic form,and use it to design a computer program for discovering some classes of games that haveunique pure Nash equilibrium payoffs. The classes of games that we consider are those thatcan be expressed by a conjunction of two binary clauses, and our program re-discoveredKats and Thisse’s class of weakly unilaterally competitive two-person games, and came upwith several other classes of games that have unique pure Nash equilibrium payoffs. It alsocame up with new classes of strict games that have unique pure Nash equilibria, where agame is strict if for both player different profiles have different payoffs.© 2011 Elsevier B.V. All rights reserved.Article history:Received 13 March 2011Received in revised form 29 June 2011Accepted 5 July 2011Available online 14 July 2011Keywords:Computer-aided theorem discoveryGame theoryPure Nash equilibriumUniqueness of pure Nash equilibrium payoffStrict gamesStrictly competitive games1. IntroductionThis paper pursues the perspective of Lin [11,12] that many interesting theorems can be automatically discovered byfirst specifying a class of conjectures in a logical language and then testing them systematically in some small domains. Thisapproach presents at least two challenges. The first concerns how to come up with a set of reasonable conjectures. Thisraises further issues, such as how to represent these conjectures, what is the yardstick for reasonableness, etc. The secondconcerns how to prove or refute the conjectures automatically.In general, using computers to discover theorems is a difficult endeavor. Nonetheless there have been various attempts.In one pioneer work, Petkovsek et al. [15] showed that to prove the following theorem,“The angle bisectors of every triangle intersect at one point”,it suffices to verify it in 64 non-isomorphic triangles, which can be automated by computers. In the same spirit, the authorswent on to demonstrate that certain forms of theorems concerning the close form of the sum of combinatorial sequencescan be completely discovered by computers programs.Langley [5] had briefly summarized the attempts of computer-aided discovery until 1998, ranging from mathematics tophysics, chemistry as well as biology. Among those attempts, Lenat’s AM system [6] and Fajtlowicz’s Graffiti [2] are alsoremarkable progresses on theorem discovery. The AM system aims at finding new concepts and theorems based on existingconcepts as well as a large amount of heuristic rules, which require extensive domain knowledge of the designers. Despite✩A short version appeared in Proceedings of IJCAI’09. Part of this paper also appeared in the PhD thesis of the first author. This work is partiallysupported by HK RGC GRF 616909 and CERG 616707.* Corresponding author.E-mail addresses: kenshin@cse.ust.hk (P. Tang), flin@cse.ust.hk (F. Lin).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.07.001\fP. Tang, F. Lin / Artificial Intelligence 175 (2011) 2010–20202011the complexity of design, the system managed to rediscover hundreds of common concepts as well as simple theorems.The Graffiti system, on the other hand, is more intuitive in design. First of all, the system itself does not attempt to proveanything. Alternatively, it aims at generating interesting conjectures in graph theory by guessing and testing some invariants,most of which are of forms a (cid:2) b, a = b, andbi , concerning two numerical features in a graph. It is worth someattention that Graffiti maintains the quality of the set of conjectures by filtering those implied by existing ones. In otherwords, the current set of conjectures are the strongest ones generated so far. This is similar to our approach in game theory,which will be introduced in detail later.ai (cid:2)(cid:2)(cid:2)Our work here continues the line of work in [11,9]. In both papers, the problem domain is formulated in a symboliclanguage. Conjectures about the domains are then represented by sentences in the underlying language. A computer programis then used to test through these conjectures to find those that are true in domains up to certain small size. Theseconjectures are either guaranteed to be true in the general case or checked manually. A parallel work applies the sameidea on social-choice theory [10,17], where we prove three of the most important impossibility theorems in a unifiedcomputer-aided framework. We also similarly discover several theorems that generalize Arrow’s conditions as well as anew theorem that better interprets Arrow’s IIA condition. Interestingly, this approach has recently been proved effectivein finding impossibility theorems in another field of social choice [3]. Similar idea can be found in automated mechanismdesign [7,8], where they use several parameters as domain language to describe a class of auctions and then search throughthe language to find the revenue-optimal auctions.In this paper, we will show how the same methodology can be used to discover some interesting theorems about pureNash equilibria. Traditional equilibrium analysis has been mostly focused on mixed strategy equilibria. Part of the reasonsfor this bias is that such an equilibrium always exists and algorithms such as the one by Lemke–Howson are guaranteed tofind one. Moreover, best response functions in games with mixed strategies are continuous and differentiable, allowing forstandard calculus techniques to be applied.However, pure Nash equilibria (PNEs) are also of interest, and there is already much work about them. Examples here in-clude the existence of PNEs in ordinal potential games [13], quasi-supermodular games [20] as well as games with dominantstrategies, and uniqueness of PNE payoffs1 in two-person strictly competitive games [14].As part of our project on using computers to discover theorems in game theory, this paper considers the possibility ofusing computers to discover new classes of two-person games that have unique PNE payoffs. Here is an overview of ourproject.• Step 1. We first formulate the notions of games, strictly competitive games and PNEs in first-order logic. Under ourformulation, a class of games corresponds to a first-order sentence.• Step 2. We then consider sentences that have similar syntactic form as that of strictly competitive games.• Step 3. We prove that a sentence of this form is a sufficient condition for a game to have a unique PNE payoff iff it isso for all 2 × 2 games.• Step 4. We then generate all sentences of the form in step 2, and check if any of them is a sufficient condition for a2 × 2 game to have unique PNE payoff.• Step 5. Finally, among these sufficient conditions, we collect weakest ones.We did not expect much as these conditions are rather simple, but to our surprise, our program returned a conditionthat is more general than the strict competitiveness condition. As it turned out, it exactly corresponds to Kats and Thisse’s[4] class of weakly unilaterally competitive two-person games. Our program also returned some other conditions. Two ofthem capture a class of “unfair” games where one player has advantage over the other. The remaining ones capture gameswhere everyone gets what he wants – each receives his maximum payoff in every equilibrium state, thus there is no realcompetition among the players. Thus one conclusion that we can draw from this experiment is that among all classes ofgames that can be expressed by a conjunction of two binary clauses, the class of weakly unilaterally competitive games isthe most general class of “competitive” and “fair” games that have unique PNE payoffs. Of course, this does not mean thatthe other conditions are not worth investigating. For instance, sometimes one may be forced to play an unfair game.For the same set of conditions, we also consider strict two-person games where different profiles have different payoffsfor each player. Among the results returned by our program, two of them are exactly the two conjuncts in Kats and Thisse’sweakly unilaterally competitive condition, but the others all turn out to be special cases of games with dominant strategies.Motivated by these results, we consider certain equivalent classes of games, and show that a strict game has a unique PNEiff it is best-response equivalent [16] to a strictly competitive game. This turns out to be a new and interesting result, andhas recently been published in Games and Economic Behavior [18].The rest of the paper is organized as follows. We first review some basic concepts in two-person games in strategic form,and then reformulate them in first-order logic. We then show that for a class of conditions, whether any of them entailsthe uniqueness of PNE payoff needs only to be checked on games up to certain size. We then describe a computer programbased on this result, and report our experimental results.1 Note that the uniqueness of PNE payoffs is also an ordinal property, which means all the PNEs in a game are equally preferred to all players. Inparticular, the notion of unique PNE payoffs is reduced to unique PNEs in strict games.\f2012P. Tang, F. Lin / Artificial Intelligence 175 (2011) 2010–20202. Two-person gamesA (two-person) game (in strategic form) is a tuple ( A, B, (cid:3)1, (cid:3)2), where A and B are sets of strategies of players 1 and 2,respectively, and (cid:3)1 and (cid:3)2 are total orders on A × B called preference relations for players 1 and 2, respectively.Instead of two preference relations, a two-person game can also be specified by two pay",
            {
                "entities": [
                    [
                        3390,
                        3418,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 197–238www.elsevier.com/locate/artintConservation principles and action schemes in the synthesis ofgeometric conceptsLuis A. PinedaInstituto de Investigaciones en Matemáticas Aplicadas y en Sistemas, Universidad Nacional Autónoma de México, Ciudad Universitaria,Coyoacán, México, D. F., México, 04510, MexicoReceived 17 February 2006; received in revised form 5 December 2006; accepted 15 December 2006Available online 22 December 2006AbstractIn this paper a theory for the synthesis of geometric concepts is presented. The theory is focused on a constructive process thatsynthesizes a function in the geometric domain representing a geometric concept. Geometric theorems are instances of this kind ofconcepts. The theory involves four main conceptual components: conservation principles, action schemes, descriptions of geometricabstractions and reinterpretations of diagrams emerging during the generative process. A notion of diagrammatic derivation inwhich the external representation and its interpretation are synthesized in tandem is also introduced in this paper. The theory isexemplified with a diagrammatic proof of the Theorem of Pythagoras. The theory also illustrates how the arithmetic interpretationof this theorem is produced in tandem with its diagrammatic derivation under an appropriate representational mapping. A secondcase study in which an arithmetic theorem is synthesized from an underlying geometric concept is also included. An interactiveprototype program in which the inference load is shared between the system and the human user is also presented. The paper isconcluded with a reflection on the expressive power of diagrams, their effectiveness in representation and inference, and the relationbetween synthetic and analytic knowledge in the realization of theorems and their proofs.© 2007 Elsevier B.V. All rights reserved.Keywords: Diagrammatic reasoning; Diagrammatic theorem-proving; Knowledge representation; Geometric description; Geometric abstraction;Conservation principles; Action schemes; Structured learning; Synthetic concepts1. Conservation principles and action schemesDiagrams have been used as representation aids in reasoning and theorem-proving since ancient times; thePythagoreans liked to illustrate things with pictures, and Euclid’s proofs made extensive use of diagrams [21]. Inits original formulation, Euclid’s method had two main features: on the one hand, every inference step was truth pre-serving and sustained on secure knowledge, and proofs were valid. On the other, a geometric concept was revealed inthe mind of the one who made or followed the proof; that is, the proof also rendered the geometric concept of what thetheorem was about. This knowledge can be thought of as the meaning of the representation expressing the theorem,and could be used operationally for problem-solving. Also, although in Euclid’s method a proof was presented as asequence of propositions, it was developed in conjunction with the construction or inspection of a diagram, and veryoften the propositions only made sense in relation to the diagram.E-mail address: luis@leibniz.iimas.unam.mx.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.12.003\f198L.A. Pineda / Artificial Intelligence 171 (2007) 197–238Euclid’s method of proof stood solidly for more than two millennium; however, the formalization of mathematicsthat followed Hilbert’s program at the beginning of the twentieth century changed the conception of the axiomaticmethod in an essential way: although a theorem was still derived out of the axioms by the application of valid infer-ence steps, the construction of the concept associated with the theorem was no longer an essential part of the process.While in the proof-theoretic sense a proof is rendered as a syntactic object consisting of a set of sentences, the conceptexpressed by such sentences can be best thought of as semantic object, and it was the construction of this latter objectthat became a contingent process. Furthermore, concepts may involve intuitions that cannot be easily formalized, andthis aspect of the process was better left out, as the main motivation for the modern proof-theoretic method was to se-cure truth. Also, as axioms and theorems were expressed as linguistic propositions, diagrams were no longer required.However, despite the tremendous success of the proof-theoretic method, and the logical interest in the validity ofdiagrammatic proofs and heterogeneous reasoning (e.g. [4,6]), the construction of the concept rendered by diagram-matic inference is still relevant for the philosophy and psychology of reasoning, and for knowledge representation andlearning in AI, among many other disciplines. These areas of AI are concerned with the acquisition, construction anduse of concepts, and the study of the processes by which geometric and arithmetic knowledge is synthesized presentsa very interesting and challenging problem. Also, the role of diagrams in inference is an important concern to allof these disciplines; furthermore, as diagrams are ubiquitous in computer science and technology, understanding thesemantic aspect of diagrammatic reasoning and problem-solving has a theoretical and practical value.In the present paper a theory of the synthesis of some geometric and arithmetic concepts in which diagrams play anessential role is presented; the theory is based on a referential machinery that permits the construction of complex geo-metric descriptions, and on a novel inferential scheme, and we hope that these mechanisms, in conjunction with theirassociated theory, will increase our understanding of the reasoning and learning processes involved in diagrammaticproofs, and more generally, in the processes underlying diagrammatic interpretation and inference.In this paper, geometric and arithmetic concepts are represented directly by functions expressed through the lambdacalculus; although this is in fact a representational choice, implemented in the prototype system presented below, thefunctions can also be thought of as the specification of the agent’s knowledge, independently of implementationconsiderations. In this view, learning consists in synthesizing a new function out of the functions already available andthe interaction of the agent with the world. This representational format has also the advantage that the computationalagent can ‘know’ the extension of a concept by simply evaluating the function representing such concept for a givenargument.In the present theory the synthesis of geometric concepts is based on two main knowledge objects which we referto as conservation principles and action schemes. The theory is focused on a constructive process that acts both on theexternal representation in which a sequence of diagrams is produced, and at the interpretation level, where the processresults in a function in the geometric domain representing a geometric concept. Geometric theorems are instances ofthis kind of concepts. Conservation principles are concepts of a very abstract character that permit an agent to knowwhether a property of an object is preserved after a process of change, if the change itself is produced by an actionscheme that preserves such property. Action schemes, in turn, are rules of a more concrete character that specifyactions that can be performed by an agent in relation to a focus of attention and a geometric context. In the presenttheory conservation principles are represented through higher-order functions; the form of these functions is illustratedwith the principle of conservation of area, as follows:λP λQλx.area(P (x)) = area(Q(x))(1)In (1), λ is the functional abstractor, P and Q are higher-order variables, and x is a first order variable. In the state-ment of the principle, P stands for a geometric description of a set of objects and Q stands for the description of thesame set of objects after a process of change has taken place; as will be shown below, P and Q are functional objectsthat map geometric objects into geometric objects, and P (x) and Q(x) denote a geometric object or configurationbefore and after a change, if the change itself is produced by an action scheme that preserves the property associatedwith the conservation principle, in this case, the area. The argument x is a focus object that remains fixed during thechange, and the principle as a whole asserts that the area of P (x) is the same as the area of Q(x) if the change isproduced in relation to the invariant reference x by an action scheme that is area preserving. An area preserving actionscheme is illustrated in Fig. 1.This action scheme rotates a right triangle by 3/2 π in a clockwise direction, in a context in which there is asecond right triangle with the same dimensions exactly, and the effect of the scheme is to align the two triangles by\fL.A. Pineda / Artificial Intelligence 171 (2007) 197–238199Fig. 1. First action scheme.Fig. 2. Second action scheme.their hypotenuses, as shown in the figure. Action schemes are also defined relative to a focus object that remains fixedduring the change; in addition, action schemes may have a “pivot” object which is a function of the focus, and providesan additional parameter for the articulation of the change. In the first scheme, the focus is the fixed right triangle, andthe pivot is the vertex aligned with a vertex of the triangle that is rotated by the scheme, as indicated by the bold doton the corresponding vertex; action schemes are generic and the objects involved can have any position, dimension,and orientation, as long as the relation between the objects on the left hand side of the scheme holds. In this firstscheme, the geometric configurations before and after the change are built up with the same “tiles”, do not overlap,and have the same area; accordingly, this action scheme is area preserving and its application grants the application ofthe conservation principle i",
            {
                "entities": [
                    [
                        3244,
                        3272,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 351–391www.elsevier.com/locate/artintRepresentation of occurrences for road vehicle trafficR. Gerber, H.-H. Nagel ∗Institut für Algorithmen und Kognitive Systeme, Universität Karlsruhe (TH), 76128 Karlsruhe, GermanyReceived 28 June 2004; received in revised form 17 July 2007; accepted 19 July 2007Available online 27 July 2007AbstractOur 3D-model-based Computer Vision subsystem extracts vehicle trajectories from monocular digitized videos recording roadvehicles in inner-city traffic. Steps are documented which import these quantitative geometrical results into a conceptual repre-sentation based on a Fuzzy Metric-Temporal Horn Logic (FMTHL, see [K.H. Schäfer, Unscharfe zeitlogische Modellierung vonSituationen und Handlungen in Bildfolgenauswertung und Robotik, Dissertation, 1996]). The facts created by this import stepcan be understood as verb phrases which describe elementary actions of vehicles in image sequences of road traffic scenes. Thecurrent contribution suggests a complete conceptual representation of elementary vehicle actions and reports results obtained byan implementation of this approach from real-world traffic videos.© 2007 Elsevier B.V. All rights reserved.Keywords: Computer vision; Knowledge representation; Temporal reasoning; Reasoning about actions and change; Fuzzy metric-temporal logic1. IntroductionAn adult is expected to be able to write down—not necessarily with style and precision—what he sees. Concedingsimilar, but appropriately adapted reservations, what is required to have a computer perform an analogous task?Obviously, an analogue to human seeing could be Computer Vision. The notion of an automatic report generator,too, is no longer considered as science fiction. It most likely turns into a challenge, however, to imagine the detailedcommunication between a computer vision (sub)system and an algorithmic report generator. What looks like the meredefinition of an interface will turn out to require the design of a system-internal logic-based conceptual representationof a text in combination with the design of an entire set of processes operating on this representation.Investigations to be discussed in the sequel address an important step towards the algorithmic transformation ofvideo signals into a natural language text which describes the recorded scene, in particular its temporal development.The presentation will first sketch an overall system concept in order to provide a framework for the subsequentdiscussion which will then concentrate on the conversion of geometric tracking results into elementary conceptualrepresentations of relevant aspects of the (short-term) development in the recorded scene. A preliminary version ofthis approach has been partially outlined in [10].* Corresponding author.E-mail address: nagel@iaks.uni-karlsruhe.de (H.-H. Nagel).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.07.001\f352R. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391Fig. 1. In the upper left panel, the image plane projection of a polyhedral model for a fastback has been overlaid to frame number 340 from an imagesequence recorded at a gas station. In addition, one can see the trajectory segment obtained by automatic model-based tracking of this vehicle whichwill be referred to as object_1. Frames 635, 1180, and 2131 show snapshots of various maneuvers of another vehicle (object_4), with analogousoverlays of a projected polyhedral model and the trajectory for this vehicle (see Section 1 for more explanations). The sketch in the bottom rowillustrates the maneuvers of object_4 in this sequence.Fig. 1 illustrates a coherent source of examples for different stages of such a transformation. The first frame1 #340in the upper left panel shows a snapshot where a fastback has already stopped at the second petrol pump on thefilling lane (see Fig. 2) closer to the observer (subsequently referred to as the ‘lower filling lane’). A second fastback(subsequently referred to as ‘object_1’) had just entered the gas station and selected the filling lane on the other side1 Based on special derivative operators which suitably interpolate between digitizations in even and odd scanlines of interlaced video (see, e.g.,[32]), actually each half-frame—or field in video-coding terminology—is evaluated in its own right, resulting in a temporal sampling rate of20 msec. This aspect reduces the approximation errors by the Extended Kalman-Filter used and thus improves the tracking quality. Beyond thisfact, however, it does not influence the conversion of geometric results to natural language concepts. In order to simplify the presentation, we shalluse the term frame henceforth without further qualifications.\fR. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391353Fig. 2. Groundplan sketch of the gas station.of the petrol pumps (‘upper filling lane’) in order to stop next to the second petrol pump, too. About 300 frames—i.e. 6 seconds—later, a third vehicle, a sedan (‘object_4’), entered the gas station and headed towards a passing lanebetween the upper filling lane and the gas station building. It passed object_1, changed back to the upper filling lane,stopped there and backed up slowly until it eventually stood next to the third petrol pump, immediately in front ofobject_1, around frame-time 1180. About 1000 frames (20 secs) later, after the fastback on the lower filling lanehad already left the gas station, object_1 started to move backwards to gain space in order to change to the passinglane. Object_1 then passed object_4 and headed towards the exit of the gas station. About three quarters of a minutelater around frame-time 4600, object_4 started to move forward and headed towards the exit, too. Examples will refermostly to the sequence of maneuvers performed by object_4 and object_1 during the period while this image sequencehad been recorded.The derivation of conceptual representations and textual descriptions of agent behavior from visual input hasbecome a research topic of constantly growing interest in the last few years. Such research has to deal with theuncertainties related to the geometric results estimated from video sequences and with bridging the semantic gapbetween (mainly geometric) computer vision results and (mainly conceptual) action descriptions. This contributionaddresses a basic topic related to the second aspect, namely isolatable agent activities or occurrences for non-humanagents, in particular rigid vehicles in videos recorded from road traffic. A discussion of relevant prior publications willbe postponed to the concluding sections because similarities and differences can be stated there more succinctly withrespect to what will be reported in the sequel.2. System outlineAlgorithmic text generation based on a recorded video sequence has to be concerned with at least two disciplines,namely computer vision and computational linguistics. Each of these two disciplines already covers several subdis-\f354R. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391Fig. 3. Coarse layer structure of the overall system (from [28]; ©2000 IEEE, by permission). The layers with light gray background constitute thecore Computer Vision subsystem for the extraction of a (mostly geometric) 3-D scene representation. The Conceptual Representation subsystemhas a medium gray background, the text generation is incorporated into the Natural Language Level with background in dark gray (see, too, thetext or [29]).ciplines. Any system for video-to-text transformation will thus be complex and, therefore, difficult to present and toanalyse. The following subsection provides an overview of our entire system approach, thereby setting the frame for amore detailed outline of steps in video-based text generation proper. More information about the development of thissystem concept during past decades can be found in [29], with recent developments being discussed in [2].2.1. Overall system structureThe transformation of video signals into a text describing the recorded temporal development within the depictedscene can be subdivided into three groups of processes—see Fig. 3:(1) The subsystem which controls the video recording and the subsequent processing steps up to and including theextraction of 3-D time-dependent geometric descriptions of the scene and, in particular, of visibly moving bodies.This subsystem comprises the layers devoted to the following subtasks:(a) Control of the recording equipment including actuators required, for example, to change pan and tilt of videocamera heads, zoom of camera lenses, etc.—the Sensor-Actuator-Level (SAL).(b) The Image-Signal-Level (ISL) devoted to image processing operations on the recorded video signal.(c) The Picture-Domain-Level (PDL) where information extracted from the image signal is aggregated intoPicture-Domain-Descriptors in the 2-D image plane.(d) The Scene-Domain-Level (SDL) which combines Picture-Domain-Descriptors with knowledge about thecamera and about the scene in order to obtain a three-dimensional representation of (at least) the geometryof temporal developments in the recorded scene.In the particular example illustrated by Fig. 1, this information comprises the 3-D vehicle status together withthe 3-D model of those vehicles which have been detected, initialized, and tracked. The vehicle status comprisesthe scene ground plane coordinates (x, y) of the model reference point, the vehicle orientation θ , speed v, and\fR. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391355steering angle2 ψ. The vehicle status is updated at each frame time point, i.e. every 20 msec, by a Kalman-Filterincorporated into a model-based tracking process—see [14,19,23].3(2) The quantitative 3-D spatio-temporal information provided by the model-based vehicle tracking subsystem isconverted into an elementary conceptual representation at the interface between the Scene-D",
            {
                "entities": [
                    [
                        2939,
                        2967,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 310 (2022) 103751Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConjure: Automatic Generation of Constraint Models from Problem SpecificationsÖzgür Akgün a,∗Ian Miguel a, Peter Nightingale ba School of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, UKb Department of Computer Science, University of York, Deramore Lane, Heslington, York YO10 5GH, UK, Alan M. Frisch b, Ian P. Gent a, Christopher Jefferson a, a r t i c l e i n f oa b s t r a c tArticle history:Received 22 November 2021Received in revised form 23 May 2022Accepted 6 June 2022Available online 9 June 2022Keywords:Constraint modellingConstraint programmingCombinatorial optimizationConstraint satisfaction problemWhen solving a combinatorial problem, the formulation or model of the problem is critical to the efficiency of the solver. Automating the modelling process has long been of interest because of the expertise and time required to produce an effective model of a given problem. We describe a method to automatically produce constraint models from a problem specification written in the abstract constraint specification language Essence. Our approach is to incrementally refine the specification into a concrete model by applying a chosen refinement rule at each step. Any non-trivial specification may be refined in multiple ways, creating a space of models to choose from.The handling of symmetries is a particularly important aspect of automated modelling. Many combinatorial optimisation problems contain symmetry, which can lead to redundant search. If a partial assignment is shown to be invalid, we are wasting time if we ever consider a symmetric equivalent of it. A particularly important class of symmetries are those introduced by the constraint modelling process: modelling symmetries. We show how modelling symmetries may be broken automatically as they enter a model during refinement, obviating the need for an expensive symmetry detection step following model formulation.Our approach is implemented in a system called Conjure. We compare the models produced by Conjure to constraint models from the literature that are known to be effective. Our empirical results confirm that Conjure can reproduce successfully the kernels of the constraint models of 42 benchmark problems found in the literature.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionEfficient decision-making is of central importance to a modern society. It is natural to represent and reason about decision-making problems in terms of constraints. For example, in scheduling a football league many constraints occur, such as: every team has to play every other, home and away; every match must be assigned a set of officials, and no official or team can be in two places at once; no team should be scheduled to play more than, say, four consecutive away games. Constraint programming [1] offers a means by which solutions to such problems can be found automatically. Constraint * Corresponding author.caj21@st-andrews.ac.uk (C. Jefferson), ijm@st-andrews.ac.uk (I. Miguel), peter.nightingale@york.ac.uk (P. Nightingale).E-mail addresses: ozgur.akgun@st-andrews.ac.uk (Ö. Akgün), alan.frisch@york.ac.uk (A.M. Frisch), ian.gent@st-andrews.ac.uk (I.P. Gent), https://doi.org/10.1016/j.artint.2022.1037510004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fÖ. Akgün, A.M. Frisch, I.P. Gent et al.Artificial Intelligence 310 (2022) 103751123456789language Essence 1.3given w, g, s : int(1..)letting Golfers be new type of size g * sfind sched : set (size w) ofpartition (regular, numParts g, partSize s)from Golferssuch thatforAll g1, g2 : Golfers, g1 < g2 .(sum week in sched . toInt(together({g1, g2}, week))) <= 1Fig. 1. An Essence problem specification of the Social Golfers Problem (Problem 10 at CSPLib.org). In a golf club there are a number of golfers who wish to play together in g groups of size s. Find a schedule of play for w weeks such that no pair of golfers play together more than once.solving of a given problem proceeds in two phases. First, the problem is modelled as a set of decision variables, and a set of constraints on those variables that a solution must satisfy. A decision variable represents a choice that must be made in order to solve the problem. The domain of potential values associated with each decision variable corresponds to the options for that choice. In our football league example, one might have two decision variables per match to represent each of the home and away teams. The second phase consists of using a constraint solver to find solutions to the model: assignments of values to decision variables satisfying all constraints.There are typically many possible models for a given problem, and the model chosen can dramatically affect the efficiency of constraint solving. This presents a serious obstacle for non-expert users, who have difficulty in formulating a good (or even correct) model from among the many possible alternatives. Modelling is therefore a critical bottleneck in the process of constraint solving, considered to be one of the key challenges facing the constraints field [2].It is desirable, therefore, to automate constraint modelling as far as possible. Several approaches have been taken to automate aspects of constraint modelling. Some approaches learn models from, variously, natural language [3], positive or negative examples [4–6], membership queries, equivalence queries, partial queries [7,8], generalisation queries [9] or ar-guments [10]. Other approaches include: automated transformation of medium-level solver-independent constraint models [11–17]; deriving implied constraints from a constraint model [18–22]; case-based reasoning [23]; and refinement of ab-stract constraint specifications [24] in languages such as ESRA [25], Essence [26], F [27] or Zinc [28–30]. We focus herein on the refinement approach, where a user writes a constraint specification describing a problem above the level of abstrac-tion at which modelling decisions are made. In Section 8 we discuss in more detail alternative approaches to automated constraint modelling by this method.This paper presents the automated constraint modelling system Conjure, which serves to demonstrate the efficacy of the refinement-based approach. A problem is input to Conjure in Essence, an abstract constraint specification language.Essence’s support for abstract decision variables with types such as set, multiset, relation and function, as well as nested types, such as set of sets and multiset of relations allows a problem to be specified without committing to constraint modelling decisions. To illustrate, consider the fragment of the Essence specification of the Social Golfers Problem [31]presented in Fig. 1. Given a number of weeks (w), a number of groups (g) and a group size (s), the problem is to find a schedule of play over the w weeks for the g × s golfers divided into g groups of size s, subject to a socialisation constraint among the golfers that stipulates that no pair of golfers play together more than once. The Social Golfers Problem is naturally conceived as finding a set of partitions of golfers subject to some constraints, which can be specified in Essence via a singleabstract decision variable, as presented in the figure where the variable is sched.Since these abstract types are not supported directly by constraint solvers,1 an Essence specification must be transformed (refined) into a constraint model. Automating this process presents a considerable challenge and the contributions of this work are in meeting that challenge. Principal among these is a carefully designed rule-based architecture implemented inConjure to refine an Essence specification into a constraint model. One key contribution is that Conjure can refine nested types without resorting to enumerating the values of the inner type (for example, refining a set of sets of integers without enumerating all possible values of the inner set). This capability is vital to refining many of the Essence specifications that we use in the evaluation. As we will demonstrate, different rule application pathways produce different constraint models, supporting an automated model selection process among the many possible alternatives. This approach also facilitates the automated production of channelled constraint models [32], in which a single abstract decision variable is refined in multiple ways. Channelling constraints are elegantly generated for an abstract decision variable A by creating the equality A = A and refining it with two different representations of A, thus ensuring the two representations take the same abstract value in all solutions. Channelled models have previously been created manually by experts, typically in an effort to simplify the statement of the problem constraints so as to strengthen the inference of the constraint solver and reduce search.A further important contribution of our rule-based architecture is in the treatment of symmetry, a structure-preserving transformation. In the context of a constraint problem, given a solution to a problem instance we can obtain another symmetric solution. Symmetry can lead to redundant search: if the constraint solver reaches a dead end in its search for a 1 Set variables are a notable exception, which are widely supported. However, the solvers that support set variables do not offer a choice as to the underlying representation of the set, and do not support nested sets.2\fÖ. Akgün, A.M. Frisch, I.P. Gent et al.Artificial Intelligence 310 (2022) 103751solution, we are wasting time if we ever consider a symmetric equivalent of it. A particularly important class of symmetries are those introduce",
            {
                "entities": [
                    [
                        3438,
                        3466,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 466–500Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEnactive artificial intelligence: Investigating the systemic organizationof life and mindTom Froese a,∗, Tom Ziemke ba Centre for Computational Neuroscience & Robotics (CCNR), Centre for Research in Cognitive Science (COGS), University of Sussex, Brighton, UKb Informatics Research Centre, University of Skövde, Skövde, Swedena r t i c l ei n f oa b s t r a c tArticle history:Received 3 August 2007Received in revised form 4 December 2008Accepted 12 December 2008Available online 25 December 2008Keywords:EmbodiedSituatedEnactiveCognitive scienceAgencyAutonomyIntentionalityDesign principlesNatural cognitionModelingThe embodied and situated approach to artificialintelligence (AI) has matured andbecome a viable alternative to traditional computationalist approaches with respect tothe practical goal of building artificial agents, which can behave in a robust and flexiblemanner under changing real-world conditions. Nevertheless, some concerns have recentlybeen raised with regard to the sufficiency of current embodied AI for advancing ourscientific understanding of intentional agency. While from an engineering or computerscience perspective this limitation might not be relevant, it is of course highly relevantfor AI researchers striving to build accurate models of natural cognition. We argue thatthe biological foundations of enactive cognitive science can provide the conceptual toolsthat are needed to diagnose more clearly the shortcomings of current embodied AI. Inparticular, taking an enactive perspective points to the need for AI to take seriously theorganismic roots of autonomous agency and sense-making. We identify two necessarysystemic requirements, namely constitutive autonomy and adaptivity, which lead us tointroduce two design principles of enactive AI.It is argued that the development ofsuch enactive AI poses a significant challenge to current methodologies. However, it alsoprovides a promising way of eventually overcoming the current limitations of embodiedAI, especially in terms of providing fuller models of natural embodied cognition. Finally,some practical implications and examples of the two design principles of enactive AI arealso discussed.© 2008 Elsevier B.V. All rights reserved.1. Introduction – setting the sceneThe field of artificial intelligence (AI) has undergone some important developments in the last two decades, as alsodiscussed by Anderson [1,2] and Chrisley [25] in recent papers in this journal. What started out with Brooks’ emphasis ofembodiment and situatedness in behavior-based AI and robotics in the late 1980s (e.g. [21]) has continued to be further de-veloped (e.g. [22,5,100]) and has considerably influenced the emergence of a variety of successful AI research programs suchas, for example, evolutionary robotics (e.g. [57,96]), epigenetic and developmental robotics (e.g. [15,79]), and the dynamicalsystems approach to adaptive behavior and minimal cognition (e.g. [11,13]).In other words, the embodied approach to AI1 has matured and managed to establish itself as a viable methodologyfor synthesizing and understanding cognition (e.g. [100,103]). Furthermore, embodied AI is now widely considered to avoidor successfully address many of the fundamental problems encountered by traditional “Good Old-Fashioned AI” [62], i.e.* Corresponding author.E-mail addresses: t.froese@gmail.com (T. Froese), tom.ziemke@his.se (T. Ziemke).1 In the rest of the paper we will use the term ‘embodied AI’, but intend it in a broad sense to include all of the abovementioned research programs.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.12.001\fT. Froese, T. Ziemke / Artificial Intelligence 173 (2009) 466–500467‘classical’ problems such as those pointed out in Searle’s [108] famous “Chinese Room Argument”, the notorious “frameproblem” (e.g. [84,33]), Harnard’s [59] formulation of the “symbol grounding problem”, or even the extensive Heideggeriancriticisms developed by Dreyfus [42,43,45]. Although there are of course significant differences between these criticisms,what they all generally agree on is that purely computational systems, as traditionally conceived by these authors, cannotaccount for the property of intentional agency. And without this property there is no sense in saying that these systemsknow what they are doing; they do not have any understanding of their situation [63]. Thus, to put it slightly differently, allthese arguments are variations on the problem of how it is possible to design an artificial system in such a manner thatrelevant features of the world actually show up as significant from the perspective of that system itself, rather than only inthe perspective of the human designer or observer.Given that embodied AI systems typically have robotic bodies and, to a large extent, appear to interact meaningfullywith the world through their sensors and motors, one might think that the above problems have either disappeared or atleast become solvable. Indeed, it has been argued that some dynamical form of such embodied AI is all we need to explainhow it is that systems can behave in ways that are adaptively sensitive to context-dependent relevance [139]. Nevertheless,there have been some warning signs that something crucial might still be amiss. In fact, for the researcher interested inthe philosophy of AI and the above criticisms, this should not come as a surprise. While Harnard’s [58] position is that ofa robotic functionalism, and thus for him the robotic embodiment is a crucial part of the solution to the symbol groundingproblem, this is not the case for Searle. Already Searle’s [108] original formulation of the Chinese Room Argument wasaccompanied by what he called the “robot reply” – envisioning essentially what we call embodied AI today, i.e. computerprograms controlling robots and thus interacting with the real world – but rejected that reply as not making any substantialdifference to his argument. Let us shift attention though, from these ‘classic’ philosophical arguments to a quick overviewof more recent discussions among practitioners of embodied AI, which will be elaborated in more detail in the followingsections.Already a decade ago Brooks [22] made the remark that, in spite of all the progress that the field of embodied AI hasmade since its inception in the late 1980s, it is certainly the case that actual biological systems behave in a considerablymore robust, flexible, and generally more life-like manner than any artificial system produced so far. On the basis of this‘failure’ of embodied AI to properly imitate even insect-level intelligence, he suggests that perhaps we have all missed somegeneral truth about living systems. Moreover, even though some progress has certainly been made since Brooks’ ratherskeptical appraisal, the general worry that some crucial feature is still lacking in our models of living systems neverthelessremains (e.g. [23]).This general worry about the inadequacy of current embodied AI for advancing our scientific understanding of naturalcognition has been expressed in a variety of ways in the recent literature. Di Paolo [36], for example, has argued that, eventhough today’s embodied robots are in many respects a significant improvement over traditional approaches, an analysis ofthe organismic mode of being reveals that “something fundamental is still missing” to solve the problem of meaning in AI.Similarly, one of us [143] has raised the question whether robots really are embodied in the first place, and has elsewhereargued [141] that embodied approaches have provided AI with physical grounding (e.g. [20]), but nevertheless have notmanaged to fully resolve the grounding problem. Furthermore, Moreno and Etxeberria [90] provide biological considerationswhich make them skeptical as to whether existing methodologies are sufficient for creating artificial systems with naturalagency. Indeed, concerns have even been raised, by ourselves and others, about whether current embodied AI systems canbe properly characterized as autonomous in the sense that living beings are (e.g. [110,146,147,52,61]). Finally, Heideggerianphilosopher Dreyfus, whose early criticisms of AI (cf. above) have had a significant impact on the development of modernembodied AI (or “Heideggerian AI”, as he calls it), has recently referred to these new approaches as a “failure” [46]. Forexample, he claims that embodied/Heideggerian AI still falls short of satisfactorily addressing the grounding problem becauseit cannot fully account for the constitution of a meaningful perspective for an agent.Part of the problem, we believe, is that while the embodied approach has mostly focused on establishing itself as a viablealternative to the traditional computationalist paradigm [2], relatively little effort has been made to make connections totheories outside the field of AI, such as theoretical biology or phenomenological philosophy, in order to address issues ofnatural autonomy and embodiment of living systems [144]. However, as the above brief overview of recent discussionsindicates, it appears that awareness is slowly growing in the field of embodied AI that something essential might stillbe lacking in current models in order to fulfill its own ambitions to avoid, solve or overcome the problems traditionallyassociated with computationalist AI,2 and thereby provide better models of natural cognition.We argue that it looks promising that an answer to the current problems might be gained by drawing some inspirationfrom recent developments in enactive cognitive science (e.g. [116–118,120,121,113,95]). The enactive paradigm originallyemerged as a part of embodied cognitive science in the early 1990s with the publication of the book The Embodied Mind[127] that has strongly influenced a large number of embodied cognition theorists",
            {
                "entities": [
                    [
                        3761,
                        3789,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1431–1459Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDefeasible inheritance with doubt index and its axiomaticcharacterizationErik Sandewall a,b,∗a Linköping University, Linköping, Swedenb Royal Institute of Technology, Stockholm, Swedena r t i c l ei n f oa b s t r a c tArticle history:Received 11 October 2008Received in revised form 29 July 2010Accepted 29 August 2010Available online 21 September 2010Keywords:Defeasible inheritanceMultiple inheritance with exceptionsNonmonotonic logicUnderlying semanticsThis article introduces and uses a representation of defeasible inheritance networks wherelinks in the network are viewed as propositions, and where defeasible links are taggedwith a quantitative indication of the proportion of exceptions, called the doubt index. Thisdoubt index is used for restricting the length of the chains of inference.The representation also introduces the use of defeater literals that disable the chainingof subsumption links. The use of defeater literals replaces the use of negative defeasibleinheritance links, expressing “most A are not B”. The new representation improves theexpressivity significantly.Inference in inheritance networks is defined by a combination of axioms that constrainthe contents of network extensions, a heuristic restriction that also has that effect,and a nonmonotonic operation of minimizing the set of defeater literals while retainingconsistency.We introduce an underlying semantics that defines the meaning of literals in a network,and prove that the axioms are sound with respect to this semantics. We also discuss theconditions for obtaining completeness.Traditional concepts, assumptions and issues in research on nonmonotonic or defeasibleinheritance are reviewed in the perspective of this approach.© 2010 Elsevier B.V. All rights reserved.1. Background and overviewNonmonotonic or defeasible inheritance is one of the classical topics in Knowledge Representation. It concerns structureswhere there is a number of classes, a subsumption predicate whereby one class can be subsumed by several superior classes,and a defeasible variant of the subsumption predicate where the propositions “A is defeasibly subsumed by B” and “B isdefeasibly subsumed by C” allow one to infer “A is defeasibly subsumed by C” unless there is information to the contrary.Propositions of this kind are commonly called links; the classes are referred to as nodes in inheritance networks.1.1. Earlier work on nonmonotonic inheritanceThe path-based approach to this topic defines methods for identifying paths, i.e. sequences of subsumption relationshipsor subsumption-related relationships in the given inheritance network describing the application at hand [56]. Paths maybe related as e.g. situators, preemptors, conflictors or defeaters, according to their structure, and this is used to definewhat paths are permitted by a given inheritance network [60]. Skeptical approaches define one single extension consisting* Address for correspondence: Linköping University, Linköping, Sweden.E-mail address: erisa@ida.liu.se.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.09.001\f1432E. Sandewall / Artificial Intelligence 174 (2010) 1431–1459of permitted paths; credulous approaches define a set of permitted extensions allowing for different possibilities. A creduloussystem can either select one of these extensions on extralogical grounds, or use the intersection of the permitted extensions.Extensions are usually characterized using rules that define or at least constrain the status of the various paths in a giveninheritance network. However, it would be useful to have an axiomatic representation of these constraints in the sense of aset of logic formulas that are satisfied in (permitted) extensions. This may facilitate the formal analysis of those constraints,and it should also be a first step towards integrating defeasible-inheritance information with other information about thedomain at hand.Given that defeasible inheritance is generally recognized as an example of nonmonotonic logic, it will not be sufficientto merely have a set of axioms; one also needs an appropriate nonmonotonic reasoning policy in the form of, for example,a circumscription policy or a preference relation on extensions. We shall use the term “axiomatic representation” for thecombination of a set of axioms and a nonmonotonic reasoning policy.Sandewall [47] proposed one such axiomatic representation and validated it by applying it to a set of test cases thatwere widely used in the literature at the time. Simonet [51] observed that this representation obtained unintended resultsfor some additional test cases that had emerged later, and proposed a modification of Sandewall’s representation. However,she also observed some other cases that even the modification did not handle as intended.Schlechta [49] has shown that no path-based approach to skeptical reasoning (in a reasonable sense of that term) canproduce the intersection of credulous extensions. Touretzky et al. [60] therefore observed that “we cannot even axiomatizeideal skepticism in our purely path-based formalism”.Unfortunately, the relation between the scenarios to be represented and the proposed representation was never obtainedin a systematic way in these works; it was always only shown by way of examples. Several authors, including [47] and [51],have remarked that it would be desirable to replace the use of examples by an underlying semantics for defeasible networks,but the large number of semantics for defeasible inheritance that have been proposed over the years (see Section 10.3) haveserved other purposes than clarifying the relation between the application at hand and its formal representation.Recent work on nonmonotonic inheritance generally pay less attention to the traditional representational questions andfocus instead on technical aspects of the nonmonotonic logic being used, such as its complexity properties, or the intro-duction of a priority ordering on the links in the network, which are sometimes represented as default rules [4,36,28]. Wepropose that it is important to check new theories of defeasible inheritance against a sufficient number of known, difficultcases of node configurations, and this aspect is emphasized in the present article.1.2. Overview of the articleThis article consists of the following sections:1. The present section;2. The investigated approach: the characteristic features of how we represent nonmonotonic inheritance, but without goinginto technical details;3. Representation of inheritance networks: defines the formal representation of a network as a set of propositions, anddefines the concept of extension of an inheritance network;4. Axioms and other restrictions: specifies the restrictions that we propose to apply to network extensions, i.e., the axiompart of the axiomatic representation;5. The Proportion Semantics: the underlying semantics which is used for verifying the soundness of the axioms in theaxiomatic representation, and for analyzing possible nonmonotonic policies in it;6. Explanation of the axioms;7. Inference operation: definition and motivation for the nonmonotonic policy component of the approach;8. Issues in commonsense inheritance: relates the approach and the results of the present article to some standard exam-ples and issues in the area;9. Object-level predicates and description logics: discusses an extension of the expressivity of the approach that is usedhere;10. Alternative approaches to defeasible inheritance;11. Conclusion.Appendix A contains a discussion of the possibility of also proving completeness for the set of axioms and suggests anapproach to doing this. Appendix B contains a number of additional examples besides those that are found in the text.2. The investigated approach2.1. Characteristic features of the representationIn this article we investigate an approach to the representation of defeasible inheritance that has two characteristicfeatures. First, defeasible subsumption links are annotated with a doubt index, i.e., a number indicating the extent to whichexceptions must be expected. A doubt annotated subsumption link between two classes c and d may be written c subm d,\fE. Sandewall / Artificial Intelligence 174 (2010) 1431–14591433where m is usually a small integer when given by the sources. These doubt indices are used to control the transitivity ofdefeasible subsumption, so that from c subm d and d subn e one will defaultwise conclude c subm+n e. However, therepresentation requires the use of a threshold K that sets a limit to the chaining, so that the conclusion in the example justshown is only accepted if m + n (cid:2) K . This provides a cut-off point beyond which further chaining is not admitted.The use of doubt annotated links distinguishes our approach from earlier approaches to defeasible inheritance, andindeed from earlier approaches to nonmonotonic reasoning in general.Secondly, the present approach corrects a deficiency in many earlier approaches to inheritance networks which can beillustrated by the following example. Consider a distinction between “white birds” and “grey birds”. Most doves are grey.In my park there are a lot of birds; most of them are doves. However, about half of them are white and the other halfare grey. We therefore have the sub predicate from birds-in-my-park to doves, and from doves to grey birds, and wewish to override the transitivity that is otherwise obtained by default. This is done using an additional ‘defeater’ predicatensub in our approach. Most traditional approaches have only one way of suppressing an inferred subsumption, namelyby asserting or inferring another subsumption that is incompatible with the one in question, and such approaches cannotexpress scenarios such as this one.The defeater predicate is analogous to exception links that",
            {
                "entities": [
                    [
                        3231,
                        3259,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 378–415Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe well-designed logical robot: Learning and experience fromobservations to the Situation CalculusFiora PirriDIS, Sapienza, University of Rome, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 21 January 2007Received in revised form 11 March 2010Accepted 14 March 2010Available online 3 April 2010Keywords:Visual perceptionAction spaceAction recognitionParametric probability modelLearning knowledgeInference from visual perception toknowledge representationTheory of actionLearning theory of action from visualperceptionThe well-designed logical robot paradigmatically represents, in the words of McCarthy, theabilities that a robot-child should have to reveal the structure of reality within a “languageof thought”. In this paper we partially support McCarthy’s hypothesis by showing that earlyperception can trigger an inference process leading to the “language of thought”. We showthis by defining a systematic transformation of structures of different formal languagessharing the same signature kernel for actions and states. Starting from early vision, visualfeatures are encoded by descriptors mapping the space of features into the space of actions.The densities estimated in this space form the observation layer of a hidden states modellabelling the identified actions as observations and the states as action preconditions andeffects. The learned parameters are used to specify the probability space of a first-orderprobability model. Finally we show how to transform the probability model into a modelof the Situation Calculus in which the learning phase has been reified into axioms forpreconditions and effects of actions and, of course, these axioms are expressed in thelanguage of thought. This shows, albeit partially, that there is an underlying structure ofperception that can be brought into a logical language.© 2010 Elsevier B.V. All rights reserved.To John and his surprising innate abilities1. Introduction1.1. ForewordIn this paper I discuss McCarthy’s exploration of the relation between appearance and reality in the “well-designed child”[77,79]. McCarthy’s arguments, in my opinion, are twofold. The first addresses the need to axiomatise the appearance–reality relation within a language of thought, while the second, addressing the archetype of inner abilities, contests the abilityof current learning methods to explain the appearance–reality relation. My thesis here is to show that early learning, viaperception, is necessary to tune knowledge formation. I argue that the perception of reality, although local and particular,can be shaped by learning the parameters of the appearance of events, and that these parameters provide a structure for asymbolic representation supporting the inference from appearance to reality.Other than the cited papers and many works that are on McCarthy’s web site, some of his arguments about learning aretaken from my personal conversations with him during these last 18 years of friendship.E-mail address: fiora.pirri@dis.uniroma1.it.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.016\fF. Pirri / Artificial Intelligence 175 (2011) 378–4153791.2. The well-designed childIn his notes on The well-designed child [77,79], John McCarthy argues that the Lockean view that knowledge is built fromsensations is not adequate for what he calls the designer stance, a theme taken from Dennett [31], who paradigmaticallyused it to understand and predict the structure and behaviour of biological and artificial systems.“In so far as we have an idea what innate knowledge of the world would be useful, AI can work on putting it intorobots, and cognitive science and philosophy can look for evidence of how much of it evolved in humans. This is thedesigner stance.”Evidence of evolution efficiency [77,79] supersedes the point of view, shared by behaviourism in psychology and pos-itivist philosophy, that knowledge proceeds from sensations. Evolution had gradually shaped optimal predispositions inhumans, in so determining a correspondence between an innate mental structure and facts about the world. The criticismof the Lockean child, nevertheless, is not addressed as a mind/body problem; instead, stepping aside it, McCarthy offers thebold view of the robot-child experiment: an AI (or possibly a psychological) system replicating the intelligent behaviourof a child. So what is innate and what can be learned? McCarthy recognises learning as central to the experiment design,but grounded in meanings independent of sensations and facts, “what a child learns about the world is based on its innatemental structure” [77,79]. Specifically, the innate mental structure is based on three interdependent aspects:1. “world characteristics”, such as appearance and reality, continuity of motion, gravity, and relations,2. “mental characteristics” such as central decision making, incompleteness of appearance, senses,3. “innate abilities” such as introspection, noise rejection, principle of mediocrity.These innate mental structures evolved for survival and control purposes, thus are necessitated by adaptation “A baby in-nately equipped to deal with them will outperform a Lockean baby”. They have been investigated also in neurophysiologicalstudies; for example, it is known that the vestibular system has specialised sensors, such as canals and otoliths, to detectgravity direction and disambiguate spatial orientation and localisation. Likewise there is a specialised motion sensitive areain the temporal cortex for both control of locomotion and perception of spatial relations. Most important, in connectionwith what McCarthy calls the principle of mediocrity, both imitation and the innate ability to put oneself in the place of othershave been explained by the mirror neurons discovered by Rizzolatti and colleagues [103,63,39].Psychological, neurological and neurophysiological findings on the function and structure of the brain justify the above-mentioned innate abilities. Innate structures take a step beyond the view (see e.g. Russell in [105]) that sensations alonedetermine knowledge. The question, from the designer stance, is whether it is possible, with a language of thought, inMcCarthy words, to represent the innate child’s brain structure by means of logical sentences?1.3. Appearance and Reality: the language of thoughtMcCarthy discusses the implementation of four innate structures, namely the relation of appearance and reality, persistentobjects, the spatial and temporal continuity of perception and the language of thought. In his notes on Appearance and Reality:a challenge to machine learning [78], that complements those on Appearance and Reality included in the Well-designed child,McCarthy says that classifying “experience is inadequate as a model of human learning and also inadequate for roboticapplications”. He argues that mere classification does not “dis-cover” (in the sense of “un-cover” and “reveal”) the hiddenreality behind appearance. To unlock reality behind appearance McCarthy suggests “brute force logical attitude toward makingtheir relations (appearance–reality) explicit”, and proposes to axiomatise their relation in a formal language, such as theSituation Calculus, as follows:(cid:2)holds(cid:3)appears(appearance, object), s(1)So, for each single object one would have an accurate description through the term appearance. Instances of the termappearance would need some recursive definition or some intended interpretation. These descriptions of the term “appear-ance” are not qualia,1 in the sense of attributes of pure perceptual experience [70,44], but designate quantifiable attributesof physical objects, e.g., as projected on the retina, however not necessarily evoking the sensory experience.A well-known argument about the relation between innate knowledge (abilities) and learned knowledge is that of Mary’sRoom [56,57,32] and it is interesting to compare it with McCarthy’s arguments. We recall that Jackson’s knowledge argumentwas the following. Mary is a perfect scientist who cannot see colours but knows all the cause-effect laws that regulate thehuman perception of colours and the utterance of colour nouns of any object whatsoever [56,57]. When she eventuallyis made capable to see colours would she learn anything? Would she have an experience inducing knowledge differentfrom her current knowledge which, by hypothesis is complete? Daniel Dennett in [32] rejects the argument that Maryderives incremental knowledge when she is allowed to see colours, based on the fact that her knowledge is complete.Furthermore, having reformulated the argument to make Mary a perfect logician [33,55] he argues that when Mary finallycan see the colours and she is offered a blue banana, then she is able to discover that she has been deceived as she knows1 Note that also in [76] McCarthy proposes a basic consciousness made of propositions and images of scenes and objects.\f380F. Pirri / Artificial Intelligence 175 (2011) 378–415what bananas look like (see also [32]). Dennett’s statement [33,55] is to clarify the abstract precondition of the knowledgeargument, describing the best circumstances under which Mary’s (RoboMary’s) knowledge is to be complete, so that shecan infer everything, just applying useful lemmas (actually her knowledge should be equivalent to its deductive closure).“What matters is whether Mary (or RoboMary) can deduce what it’s like to see red from her complete physical knowledge,not whether one could use one’s physical knowledge in some way or other to acquire knowledge of what it’s like to seein colour” [33]. Obviously if RoboMary has complete knowledge [33] her perceptual experience (or any form of knowledgeacquisition whatsoever) is unnecessary and irrelevant. In fact, by definition, nothing can be added to a complete theory,without m",
            {
                "entities": [
                    [
                        3231,
                        3259,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 316 (2023) 103829Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artint, Alessandro Allievi a,b, Holger Banzhaf c, Felix Schmitt d, Reward (Mis)design for autonomous driving ✩W. Bradley Knox a,b,∗Peter Stone b,ea Robert Bosch LLC, United States of Americab The University of Texas at Austin, United States of Americac Robert Bosch GmbH, Germanyd Bosch Center for Artificial Intelligence, Germanye Sony AI, United States of Americaa r t i c l e i n f oa b s t r a c tArticle history:Received 10 January 2022Received in revised form 30 September 2022Accepted 24 November 2022Available online 13 December 2022Keywords:Reinforcement learningReward designUtilityCostSafetyRiskAutonomous driving1. IntroductionThis article considers the problem of diagnosing certain common errors in reward design. Its insights are also applicable to the design of cost functions and performance metrics more generally. To diagnose common errors, we develop 8 simple sanity checks for identifying flaws in reward functions. We survey research that is published in top-tier venues and focuses on reinforcement learning (RL) for autonomous driving (AD). Specifically, we closely examine the reported reward function in each publication and present these reward functions in a complete and standardized format in the appendix. Wherever we have sufficient information, we apply the 8 sanity checks to each surveyed reward function, revealing near-universal flaws in reward design for AD that might also exist pervasively across reward design for other tasks. Lastly, we explore promising directions that may aid the design of reward functions for AD in subsequent research, following a process of inquiry that can be adapted to other domains.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).Treatments of reinforcement learning often assume the reward function is given and fixed. However, in practice, the correct reward function for a sequential decision-making problem is rarely clear. Unfortunately, the process for designing a reward function (i.e., reward design)—despite its criticality in specifying the problem to be solved—is given scant attention in introductory texts.1 For example, Sutton and Barto’s standard text on reinforcement learning [45, pp. 53–54, 469] devotes merely 4 paragraphs to reward design in the absence of a known performance metric. Anecdotally, reward design is widely acknowledged as a difficult task, especially for people without considerable experience doing so. Further, Dulac-Arnold et al. [14] recently highlighted learning from “multi-objective or poorly specified reward functions” as a critical obstacle hampering the application of reinforcement learning to real-world problems. Additionally, the problem of reward design is highly related to the more general problem of designing performance metrics for optimization—whether manual or auto-mated optimization—and is equivalent to designing cost functions for planning and control (Section 2), making a discussion ✩This paper is part of the Special Issue: “Risk-aware Autonomous Systems: Theory and Practice”.* Corresponding author.E-mail address: bradknox@cs.utexas.edu (W.B. Knox).1 Unless otherwise noted, any discussion herein of reward design focuses on the specification of the environmental reward, before any shaping rewards are added. We also focus by default on manual reward specification, which differs from inverse reinforcement learning and other methods for learning reward functions. However, we discuss the application of this work to such methods in Section 5.4.https://doi.org/10.1016/j.artint.2022.1038290004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fW.B. Knox, A. Allievi, H. Banzhaf et al.Artificial Intelligence 316 (2023) 103829of reward design relevant beyond reinforcement learning. This article contributes to an important step in reward design: evaluating a proposed reward function independently of which reinforcement learning algorithms are chosen to optimize with respect to it. To this end, in Section 4 we develop 8 sanity checks for identifying flaws in reward functions.Throughout this article, we use autonomous driving as a motivating example for reward design. AD also serves as a source of reward functions to demonstrate application of our 8 sanity checks. In Section 3, we describe challenges of reward design for autonomous driving. The sanity checks in Section 4 reveal pervasive issues in published reward functions for AD. Specifically, the majority of these reward functions—often all of them—fail the tests that are part of the first 3 sanity checks (Sections 4.1–4.3). In Section 5, we further explore obstacles to reward design for AD through initial attempts to design three attributes of an AD reward function, uncovering obstacles to doing so that a designer should consider. Section 5also includes a review of some government-mandated performance metrics, discussions of reward learning for AD and of multi-objective optimization for AD, and a proposal for designing reward for AD with a financial currency as its unit. Given the high envisioned impact of autonomous driving, the RL-for-AD community needs to consider reward design carefully if reinforcement learning will have a significant role in the development of AD.We do not seek to condemn the past efforts we review—which are excellent in many regards—but rather to provide understanding of common issues in reward design and guidance on identifying them. Additionally, this paper is not a general survey of reinforcement learning for autonomous driving; such surveys have been conducted by Zhu and Zhao [59]and Kiran et al. [26]. The contributions of this article include a deep discussion of what reward design for AD should entail, the development of 8 simple sanity checks for reward or cost functions, application of these sanity checks to identify prevalent flaws in published reward functions for AD (flaws that anecdotally appear common throughout RL, beyond AD), identifying pervasive usage of trial-and-error reward design (see Section 4.6), and revealing obstacles that arise in our initial attempt to design reward for AD. In particular, we do not claim to solve the problem of reward design for AD. Instead, we provide guidance for future efforts to design reward and other performance metrics for autonomous driving specifically as well as for other tasks with undefined reward functions.2. Background: objectives, utility functions, and reward functionsTo support our discussion of reward design, we first review what a reward function is. When attempting to decide between alternative decision-making or control algorithms—or, equivalently in this discussion, policies, which map each state to a probability distribution over actions—a common and intuitive approach is to define a performance metric J that scores each policy π according to J : π → R. If J (π A) > J (πB ), then π A is better according to J .2Definition of the performance metric J creates a ranking over policies and identifies the set of optimal policies, both of which are helpful for optimizing behavior in sequential decision-making tasks. However, different definitions of the performance metric typically create different rankings and sets of optimal policies, which generally change the result of a learning algorithm optimizing according to some J . Put simply, bad design of a performance metric function creates misalignment between what the designer—or other stakeholders—considers to be good behavior and what the learning algorithm does. A perfect optimization algorithm3 is only as good as the performance metric it is optimizing.J (π ) is typically defined as the expectation over outcomes created by π , where these outcomes can be directly observed but J (π ) cannot. More specifically, in episodic framings of tasks, J (π ) is defined as an expectation of G(τ ), which is the performance of a trajectory τ created by policy π . (Episodic task framings are the norm in reinforcement learning for AD and are assumed throughout this article unless otherwise noted.) Specifically, J (π ) = Eπ ,D,T [G(τ )], where τ is a trajectory generated by following π from a starting state drawn according to some initial state distribution D and the task’s state transition probabilities T . The mean of G(τ ) from trajectories generated therefore can serve as a practical, unbiased estimator of J (π ).The policy-performance metric J and the trajectory-performance metric G go by many names in the various fields that address the sequential decision-making problem. Fig. 1 shows some of these various terms. In many subfields, J is called an objective if its definition explicitly includes the goal of maximizing it (or of minimizing it, in some contexts). In utility theory, G is a utility function and J (π ) is the expected utility. In planning and control theory, both J (π ) and G(τ ) can be referred to as cost (and optimization seeks to minimize cost rather than maximize it, as we otherwise assume here). In evolutionary algorithms, J (π ) is referred to as the fitness of a policy. Fitness may simply be the mean of G(τ ) over nsamples of τ , not the expectation G(τ ). In reinforcement learning (RL), each transition within the trajectory elicits a rewardsignal according to a reward function R : S × A × S → R. The input for R is the state, action, and next state in the transition. In the undiscounted setting—which is implied in the episodic tasks this article assumes by default—the sum of a trajectory (T −1)τ ’s rewards is its return, which is reinforcement learning’s word for G(τ ). Therefore, G(τ ) =t=1 R(st, at, st+1), where trajectory τ = (s1, a1, s2, a2, ..., sT −1, aT −1, sT ). Policy-improvement algorithms in R",
            {
                "entities": [
                    [
                        3746,
                        3774,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 448–452www.elsevier.com/locate/artintLearning equilibrium as a generalization of learning to optimize ✩Dov Monderer ∗, Moshe TennenholtzFaculty of Industrial Engineering and Management, Technion – Israel Institute of Technology, Haifa 32000, IsraelReceived 15 May 2006; received in revised form 20 October 2006; accepted 21 December 2006Available online 26 January 2007AbstractWe argue that learning equilibrium is an appropriate generalization to multi-agent systems of the concept of learning to optimizein single-agent setting. We further define and discuss the concept of weak learning equilibrium.© 2007 Elsevier B.V. All rights reserved.Keywords: Learning; Machine learning; Learning equilibrium1. PrefaceIn [16], Shoham, Powers, and Grenager (SPG) present five distinct agendas in multi-agent learning. In this man-uscript we discuss their third agenda—the normative approach. SPG mention that the requirement that learningalgorithms would be an equilibrium may serve as a synonyms to this approach. We claim that the equilibrium ap-proach is indeed the right one if the question is: what should a mediator who makes recommendations to all players,recommend. The equilibrium property seems to be a necessary ingredient in such recommendations. As economistsdo not tend to consider mediators (competing firms do not go to a central mediator to determine their, say, pricingpolicy)1 it is of no surprise that the equilibrium agenda is not a major issue in the learning literature in economics.However, when, say eBay provides the participants a proxy service, then it actually plays the role of a mediator (andnot only of an organizer).The theory of learning in multi-agent systems inherits all the conceptual and practical difficulties of learning insingle-agent settings, as well as all difficulties of analyzing behavior in multi-agent settings. Therefore, in order todefine and understand the equilibrium approach to learning in multi-agent systems we phrase it as an extension ofwork on learning in single-agent systems.22. Learning in single-agent systemsRoughly speaking, one could partition work on learning in single-agent systems into two major but not necessarilyindependent categories:✩ Both authors thank the Israeli Science Foundation and the Fund for the Promotion of Research at the Technion for the support of their research.* Corresponding author.E-mail address: dov@ie.technion.ac.il (D. Monderer).1 Some well-known exceptions to this statement can be found in the literature on correlated equilibrium [4], and on communication equilibrium[8,15]. However, the general theme in economics is that there is no mediator in the system that recommends behavior to the agents.2 For the sake of exposition we introduce all notations in this paper with pure strategies.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.002\fD. Monderer, M. Tennenholtz / Artificial Intelligence 171 (2007) 448–452449• Descriptive theory-prediction: Given examples of past behavior of a system, and some background information,we would like to predict the future behavior of the system. Classical work in statistics, inductive inference andsupervised learning in AI fit into this category, as well as much work in data mining and the classification ofsubjects in psychology.• Normative theory-optimization: Given partial information about a system, our aim is to devise algorithms foroptimizing an agent’s behavior in the system. Typically, the interleaving of exploration and exploitation is needed.Work on reinforcement learning in AI, as well bandits problems fit into this category.We only discuss our view about the extension to multi-agent systems of the normative approach. That is, we usethe word learning in a single-agent setting as a synonym for optimization in dynamic situations with incompleteinformation.Consider a single agent facing a dynamic decision problem with incomplete information, D, defined by a set ofdynamic decision problems Dω with a parameter ω ∈ Ω. Each ω ∈ Ω is called a state of nature. Nature chooses ω, butthe agent does not know ω. However, he possesses some initial information about the state of nature, and he acquiresadditional partial information after every stage. For example, every Dω can be a Markov decision problem. If we havea prior probability distribution over the set Ω we call the problem a Bayesian dynamic decision problem. If we wantto stress the fact that such a prior probability does not exist we call the problem a Pre-Bayesian dynamic decisionproblem.3A strategy of the decision maker at each Dω is called a policy. A strategy of the agent in the decision problem withincomplete information, D, is called in this paper an algorithm. We assume that had the agent known ω he would havechosen an optimal policy, which would have given him the long-run value, v(ω), of Dω. More precisely, let Uω be thelong-run reward function of the problem Dω, and let S(ω) be the set of possible policies for this problem. A policyf ω ∈ S(ω) is an optimal policy at Dω ifmaxgω∈S(ω)Uω(gω) = Uω(f ω).The value of Dω is the real-valued function v defined on Ω as follows:v(ω) = maxgω∈S(ω)Uω(gω) ∀ω ∈ Ω.(1)(2)Ideally, in a dynamic decision problem with incomplete information an optimizing agent would use an algorithmthat guarantees v(ω) for every ω. This approach is mainly taken in machine learning. We accept this view; in ourview the right notion for a learning-to-optimize algorithm for a decision problem with incomplete information is thefollowing: It is an algorithm that yields an optimal policy at every ω.4 More precisely:Let f be an algorithm for D. For every ω we denote by fω, the policy induced by f on Dω.f is a learning-to-optimize algorithmin D if for every w, fω is an optimal algorithm in Dω, that ismaxgω∈S(ω)Uω(gω) = Uω(fω) ∀ω ∈ Ω.(3)An equivalent definition will be useful in the sequel.The set of all algorithms for D is denoted by S. For every f ∈ S and for every ω ∈ Ω define U (ω, f ) = Uω(fω).Obviously, f is a learning-to-optimize algorithm in D if and only ifU (ω, g) = U (ω, f ) ∀ω ∈ Ω.maxg∈S(4)Unfortunately, there exist dynamic decision problems for which a learning-to-optimize algorithms do not exist.In Bayesian dynamic decision problems it is customary to look for algorithms that maximize the long-run expectedreward of the agent. Such algorithms generally exist. We call such an algorithm an optimal Bayesian algorithm.3 In economics, it is customary to relate to a Bayesian model as a model with incomplete information. Until recently, a model without priors wasnot given a special name. Recently, such games have received several titles in various papers. In this paper we follow the terminology of [11], andwe refer to such games as pre-Bayesian.4 Practically, the definition would be more elaborate, and would refer to various accuracy parameters. Notice that we refer here to the long-runvalue mentioned above.\f450D. Monderer, M. Tennenholtz / Artificial Intelligence 171 (2007) 448–452That is, f is an optimal Bayesian algorithm if(cid:2)(cid:2)maxg∈SΩU (ω, g) dμ(ω) =U (ω, f ) dμ(ω),Ωwhere μ is the prior probability on Ω.5(5)It is important to note that in a Bayesian dynamic decision problem, every learning-to-optimize algorithm is alsoan optimal Bayesian algorithm, but the converse does not necessarily hold.63. Learning in multi-agent settingsWe take the position of a mediator who is about to assign algorithms to a set of selfish agents, N = {1, 2, . . . , n} whoare engaged in a multistage game with incomplete information, G.7 This game, G is defined by a set of multi-stagegames with complete information, Gω with a parameter ω ∈ Ω. Nature chooses a state of nature ω, but the agents donot know ω. However, each agent possesses some initial private information about the state of nature, and he acquiresadditional partial information after every stage. For example, every Gω can be a repeated game. If we have a priorprobability distribution over the set Ω we say that G is a Bayesian multi-stage game. If we want to stress the factthat such a prior probability does not exist we call G a pre-Bayesian multi-stage game. In the complete informationcase, when dealing with the multi-agent setting, the term policy used in the single agent setting is replaced by the termstrategy. As in the single agent setting, a strategy of an agent in G is called an algorithm.The first question is what is the analogous concept of an “optimal policy” in the single-agent setup in the game Gω,in which the agents know ω. This is one of the most important conceptual issues dealt with in game theory. We take theposition that in the presence of a mediator, optimality means equilibrium. That is, the strategy given to every agent i isoptimal if all other agents are using their strategies in the profile.8 Hence, the analogous definition to an optimal policyin the single agent decision problem with complete information is: A profile of strategies, f ω = (f ωn ) isan equilibrium profile in Gω ifi (gωU ωi (f ω) = maxU ω∈Si (ω)−i) ∀i ∈ N.2 , . . . , f ω1 , f ωi , f ω(6)gωiNote, however, that except for two-person zero-sum games, the concept of a value function does not have a well-defined meaning in the multi-agent model.It is important to stress again the existence of a mediator in order to understand our approach. We do not claimthat economic agents play in equilibrium. We do not claim that an agent who is facing a multi-agent decision problemshould use an equilibrium strategy; This is because we cannot be sure that other agents would use an equilibriumstrategy, and even if they do they may stick to another equilibrium. However, a reliable mediator who provides allagents with algorithms can expect players to use the algorithms only if the profile of algorithms is in equilibrium.Hence, we assume that had the agents known ω they would have chosen an optimal profile of strategies, i.e. theywould have behaved according to",
            {
                "entities": [
                    [
                        2895,
                        2923,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 257 (2018) 1–23Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstants and finite unary relations in qualitative constraint reasoningPeter JonssonDepartment of Computer and Information Science, Linköping University, SE-581 83 Linköping, Swedena r t i c l e i n f oa b s t r a c tArticle history:Received 30 May 2017Received in revised form 1 December 2017Accepted 13 December 2017Available online 20 December 2017Keywords:Constraint satisfactionQualitative reasoningComputational complexityExtending qualitative CSPs with the ability of restricting selected variables to finite sets of possible values has been proposed as an interesting research direction with important applications, cf. “Qualitative constraint satisfaction problems: an extended framework with landmarks” by Li, Liu, and Wang (2013) [48]. Previously presented complexity results for this kind of extended formalisms have typically focused on concrete examples and not on general principles. We propose three general methods. The first two methods are based on analysing the given CSP from a model-theoretical perspective, while the third method is based on directly analysing the growth of the representation of solutions. We exemplify the methods on temporal and spatial formalisms including Allen’s algebra and RCC-5.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThis introductory section is divided into two parts where we first discuss the background of this article and thereafter describe our results.1.1. BackgroundQualitative reasoning has a long history in artificial intelligence and the combination of qualitative reasoning and con-straint reasoning has been a very productive field. A large number of constraint-based formalisms for qualitative reasoning have been invented, most notably within temporal and spatial reasoning, and they have been investigated from many dif-ferent angles. It has been noted that a particular extension to qualitative CSPs is highly relevant: Cohn and Renz [25, p. 578]observe the followingOne problem with this [constraint-based] approach is that spatial entities are treated as variables which have to be instantiated using values of an infinite domain. How to integrate this with settings where some spatial entities are known or can only be from a small domain is still unknown and is one of the main future challenges of constraint-based spatial reasoning.and Li, Liu, and Wang [48, p. 33] writeE-mail address: peter.jonsson@liu.se.https://doi.org/10.1016/j.artint.2017.12.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f2P. Jonsson / Artificial Intelligence 257 (2018) 1–23There is a growing consensus, however, that breakthroughs are necessary to bring spatial/temporal reasoning theory closer to practical applications. One reason might be that the current qualitative reasoning scheme uses a rather re-stricted constraint language: constraints in a qualitative CSP are always taken from the same calculus and only relate variables from the same infinite domain. This is highly undesirable, as constraints involving restricted variables and/or multiple aspects of information frequently appear in practical tasks such as urban planning and spatial query processing.That is, they regard the question of how to extend constraint formalisms with constants and other unary relations1as being very important; the same observation has been made in a wider context by Kreutzmann and Wolter [44]. An interesting recent example where such extensions of qualitative formalisms are necessary is the article on spatial query processing by Nikolaou and Koubarakis [56].(cid:3) ⊆ D | DGiven a (finite or infinite) set of values D, we let Dc = {{d} | d ∈ D} (i.e. the set of constant relations over D) and is finite} (i.e. the set of finite unary relations over D). Let us consider finite-domain CSPs for a moment. D f = {DFor every finite constraint language (cid:2) over D, the computational complexity of CSP((cid:2) ∪ D f ) is known due to results by Bulatov [17]. This is an important complexity result in finite-domain constraint satisfaction and it has been reproven several times using different methods [2,18]. Very recently, the complexity of CSP((cid:2) ∪ Dc) and CSP((cid:2)) has also been determined [19,63].(cid:3)The situation is radically different when considering infinite-domain CSPs where similar powerful results are not known. This can, at least partly, be attributed to the fact that infinite-domain CSPs constitute a much richer class of problems than finite-domain CSPs: for every computational problem X , there is an infinite-domain constraint language (cid:2) X such that Xand CSP((cid:2) X ) are polynomial-time Turing equivalent [9]. Finite domain CSPs are, on the other hand, always members of NP. Hence, the majority of computational problems cannot be captured by finite-domain CSPs.Nevertheless, there exist concrete examples where interesting qualitative and/or infinite-domain CSPs have been ex-tended with finite unary relations and/or constant relations. A very early example is the article by Jonsson and Bäck-ström [38] (see also Koubarakis [43]) where several temporal formalisms (including the point algebra and Allen’s algebra) are extended by unary relations (and also other relations). A more recent example is the article by Li et al. [48] where the point algebra and Allen’s algebra are once again considered. Li et al. also study several other formalisms including the cardinal relation algebra and RCC-5 and RCC-8 over two-dimensional regions and where constants are assumed to be polyg-onal regions. The results for the temporal formalisms by Jonsson and Bäckström are not completely comparable with the results by Li et al.: Jonsson and Bäckström’s approach is based on linear programming while Li et al. use methods based on enforcing consistency and computational geometry. Consistency-enforcing methods have certain advantages such as lower time complexity and easier integration with existing constraint solving methods. At the same time, the linear programming method allows for more expressive extensions with retained tractability. Both consistency-based and LP-based methods have attracted attention lately, cf. Giannakopoulou et al. [30] and Kreutzmann and Wolter [44], respectively, and generalisations of the basic concepts have been proposed and analysed by de Leng and Heintz [26].We see that this line of research has to a large extent been based on analysing concrete examples. The approach in this article will be different: instead of studying concrete examples, we study basic principles and aim at providing methods that are applicable to many different constraint formalisms.1.2. Our resultsWe present three different methods. The first two methods are based on analysing the given CSP from a model-theoretical perspective. The third method is more of a toolbox for proving that the size of solutions (i.e., the number of bits needed for representing a solution) grows in a controlled way, and that problems consequently are in NP. We will now describe these methods in slightly more detail.Method I. The first method is based on exploiting ω-categoricity. This is a model-theoretical property of constraint languages and other mathematical structures that have gained a lot of attention in the literature. Briefly speaking, a constraint language (cid:2) is ω-categorical if (cid:2) is the unique countable model (up to isomorphism) of the set of all first-order sentences that are true in (cid:2). One of the interesting aspects of ω-categorical constraint languages is that they in some respects resemble constraint languages over finite domains: this is expressed by a famous result proved by Engeler, Ryll-Nardzewski, and Svenonius (see Theorem 11). From a model-theoretical point of view, ω-categoricity is a very strong assumption. Nevertheless, many interesting CSP problems can be formulated using ω-categorical constraint languages: examples include the point algebra, RCC-5, RCC-8, and Allen’s algebra. Among the ω-categorical constraint languages, the model-complete cores are particularly interesting. Such constraint languages allow us to define gadgets that can be used for simulating constants. This method is applicable to a wide selection of CSP((cid:2)) problems when (cid:2) is ω-categorical. The drawback with the method is that it may be difficult to compute the gadgets used for simulating constants. Given that (cid:2) is an ω-categorical model-complete core and that the gadgets can be computed efficiently, we verify (based on results by Bodirsky [5]) that CSP((cid:2)) is polynomial-time equivalent to CSP((cid:2) ∪ Dc). To demonstrate the strength of this method, we apply it to an extended version of Allen’s algebra. 1 Finite unary relations are sometimes referred to as landmarks in the AI literature. We will use the standard mathematical term throughout the article.\fP. Jonsson / Artificial Intelligence 257 (2018) 1–233This exercise shows, for example, that relations with higher arity than two does not pose any particular problem. This is an important observation since previous work (such as Li et al. [48]) has mostly focused on binary relations.Method II. The second method is based on homogeneity. This is a property of relational structures that has been studied for a long time in mathematics and logic. Some machinery is needed for the formal definition so we refrain from giving it here. However, we note that homogeneous relational structures have many interesting properties: for instance, they allow quantifier elimination and they are ω-categorical whenever the structure contains a finite number of relation symbols and the domain is countably infinite. Even though homogeneity is a very strong property of relational structures, there are many well-known examples within AI and computer science. An early example was provided by Hirsch [33] who proved that Allen’s algebra (with the st",
            {
                "entities": [
                    [
                        2548,
                        2576,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 186 (2012) 123–156Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for strategyproof classificationReshef Meir a,∗, Ariel D. Procaccia b, Jeffrey S. Rosenschein a,1a School of Engineering and Computer Science, Hebrew University, Jerusalem 91904, Israelb Computer Science Department, Carnegie Mellon University, 5000 Forbes, Pittsburgh, PA 15213, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 25 September 2011Received in revised form 12 March 2012Accepted 26 March 2012Available online 27 March 2012Keywords:Mechanism designClassificationGame theoryApproximationThe strategyproof classification problem deals with a setting where a decision maker mustclassify a set of input points with binary labels, while minimizing the expected error. Thelabels of the input points are reported by self-interested agents, who might lie in order toobtain a classifier that more closely matches their own labels, thereby creating a bias inthe data; this motivates the design of truthful mechanisms that discourage false reports.In this paper we give strategyproof mechanisms for the classification problem in tworestricted settings: (i) there are only two classifiers, and (ii) all agents are interested in ashared set of input points. We show that these plausible assumptions lead to strong positiveresults. In particular, we demonstrate that variations of a random dictator mechanism, thatare truthful, can guarantee approximately optimal outcomes with respect to any family ofclassifiers. Moreover, these results are tight in the sense that they match the best possibleapproximation ratio that can be guaranteed by any truthful mechanism.We further show how our mechanisms can be used for learning classifiers from sampleddata, and provide PAC-style generalization bounds on their expected error. Interestingly,our results can be applied to problems in the context of various fields beyond classification,including facility location and judgment aggregation.© 2012 Elsevier B.V. All rights reserved.1. IntroductionConsider a learning algorithm, which takes a labeled set of samples (“training data”) as input, and outputs a binary clas-sifier. The training data, typically hand-constructed by human experts, is supposed to reflect the knowledge of the expertson the current domain. The basic requirement from such an algorithm is to guarantee that the output classifier minimizesthe number of classification errors with respect to the ‘truth’ (according to the domain experts). Standard machine-learningliterature studies the performance of such algorithms given various distributions and concept classes (e.g., linear classifiers),sparse or noisy data, etc.However in many real-life situations, the experts have a personal interest in the outcome of the algorithm, and thereforethey cannot be assumed to be truthful. If an expert can bias the learned classifier in her favor by lying, then the reportedtraining data will no longer reflect the properties of the domain (or even the properties of the real training data). Optimizinga classifier based on such corrupted data may result in a very poor classifier, regardless of the guarantees supplied bylearning theory (which assumes truthfulness).We consider two interrelated settings. The first setting is decision-theoretic; a decision must be made based on datareported by multiple self-interested agents. The agents are concerned with the binary labels of a set of input points. Put* Corresponding author. Tel.: +972 2 6585188.E-mail addresses: reshef.meir@mail.huji.ac.il (R. Meir), arielpro@cs.cmu.edu (A.D. Procaccia), jeff@cs.huji.ac.il (J.S. Rosenschein).1 Tel.: +972 2 6585353.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.03.008\f124R. Meir et al. / Artificial Intelligence 186 (2012) 123–156another way, the agents may disagree on the labels of the points of the input space, and we do not assume any underlyingdistribution. The utility of an agent with respect to a given decision (i.e., a given classifier) is the number of points onwhich the label provided by the classifier agrees with the agent’s own label. The goal of the decision maker is to choose aclassifier that maximizes the social welfare—the sum of utilities. As we will see, results in this setting can also be appliedto problems in the context of various other fields, including facility location and judgment aggregation.The second setting is learning-theoretic, a variation of the standard Supervised Classification problem. Samples are drawnfrom some distribution over the input space, and are then labeled by experts. A classification mechanism receives thesampled data as input, and outputs a classifier. Unlike the standard setting in machine learning (but similarly to our firstsetting), the experts are assumed to be self-interested agents, and may lie in order to increase their utility. This settingmay seem far more involved than the first, as it deals with generalization from partial data (the dataset) to the underlyingdistribution. However, we show that under the standard assumptions of learning theory, the learning problem effectivelyreduces to finding a classifier that best fits the available data (i.e., to the first setting, above).In both settings the decision maker (or mechanism, or learning algorithm) aims to find a classifier that classifies theavailable data as well as possible. However, the agents may misreport their labels in an attempt to influence the finaldecision in their favor. The result of a decision making process based on such biased data may be completely unexpectedand difficult to analyze. A truthful learning mechanism eliminates any such bias and allows the decision maker to select aclassifier that best fits the reported data, without having to take into account the hidden interests of the agents. In otherwords, once we guarantee that agents are telling the truth, we may concentrate on the more standard goal of minimizingthe error. In order to obtain truthfulness, however, we may need to trade off optimality. Our goal is to provide mechanismsthat are both truthful and approximately optimal in terms of social welfare.1.1. Restrictions on the domainIn recent work [29] we showed that in an unrestricted domain, it is effectively impossible to design truthful mechanismsthat are close to optimal. This motivates the investigation of restricted domains. In this paper we consider several suchrestrictions, described below.1.1.1. Restricting the concept class: two functionsA seemingly simple case is when the concept class contains only two functions. This is equivalent to a (binary) decisionthat has to be made based on data points that are controlled by multiple (possibly) selfish agents, where the decisionaffects all the agents. The decision maker would like to make a decision which is consistent, as much as possible, with allthe available data. However, in our strategic setting the agents might misreport their data in an attempt to influence thefinal decision in their favor.As a motivating example, consider a decision that has to be made by the Workers’ committee of the TAs in the HebrewUniversity, regarding an ongoing strike. Each member of the committee (who represents one department) announces howmany TAs in his/her department support the strike, and how many oppose it. A final decision is made based on totalsupport for the strike. Suppose that 60% of the economics department opposes the strike. However, the representative ofthe economics department majors in game theory. She therefore knows that for the benefit of the majority of TAs in herdepartment, it would be better to state that everybody objects to the strike.21.1.2. Restricting the dataset: shared inputsOur main conceptual contribution in this paper, which leads to strong positive results, is the assumption of shared inputs.In the decision-theoretic setting, this means that the agents share the same set of input points, and only disagree on thelabels of these points. In the learning-theoretic setting, the shared inputs assumption implies that the agents are interestedin a common distribution over the input space, but, once again, differ with respect to the labels.The first restriction we described did not address the issue of shared inputs. However, as the two possible classifiersare constant, the identity of the input points (i.e., their location) is irrelevant—only their labels matter. Hence, the firstrestriction is in fact a very special case of the latter (see also footnote 17).As the shared inputs assumption is a weaker restriction than assuming two functions, the guarantees are also somewhatweaker. Nevertheless, they hold with respect to any concept class. We believe that in many environments the requirement ofshared inputs is satisfied. As an example, consider a large organization that is trying to fight congestion in an internal emailsystem by designing a smart spam filter. In order to train the system, managers are asked to review the last 1000 emailssent to the “all employees” mailing list (hence, shared inputs) and classify them as either “work-related” (positive label) or“spam” (negative label). Whereas the managers will likely agree on the classification of some of the messages (e.g., “BuyViagra now!!!” or “Christmas Bonus for all employees”), it is likely that others (e.g., “Joe from the Sales department goes ona lunch break”) would not be unanimously classified. Moreover, as each manager is interested in filtering most of what hesees as spam, a manager might try to compensate for the “mistakes” of his colleagues by misreporting his real opinion with2 In an attempt to avoid such misrepresentation, major decisions usually require a gathering of all TAs, and the use of a standard voting procedure.However, most decisions are taken with a much narrower quorum.\fR. Meir et al. / Artificial Intelligence 186 (2012",
            {
                "entities": [
                    [
                        3830,
                        3858,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 185–196www.elsevier.com/locate/artintDetermining the consistency of partial tree descriptionsManuel Bodirsky a,∗, Martin Kutz ba Humboldt-Universität zu Berlin, Germanyb Max-Planck-Institut für Informatik, Saarbrücken, GermanyReceived 1 June 2006; received in revised form 27 November 2006; accepted 15 December 2006Available online 22 December 2006AbstractWe present an efficient algorithm that decides the consistency of partial descriptions of ordered trees. The constraint languageof these descriptions was introduced by Cornell in computational linguistics; the constraints specify for pairs of nodes sets ofadmissible relative positions in an ordered tree. Cornell asked for an algorithm to find a tree structure satisfying these constraints.This computational problem generalizes the common-supertree problem studied in phylogenetic analysis, and also generalizes thenetwork consistency problem of the so-called left-linear point algebra. We present the first polynomial time algorithm for Cornell’sproblem, which runs in time O(mn), where m is the number of constraints and n the number of variables in the constraint.© 2006 Elsevier B.V. All rights reserved.Keywords: Tree descriptions; Constraint satisfaction problems; Graph algorithms; Left-linear point algebra1. IntroductionTree description languages became an important tool in computational linguistics over the last twenty years. Gram-mar formalisms have been proposed that derive logical descriptions of trees representing the syntax of a string [15,23,26]. Membership in a language is then equivalent to the satisfiability of the corresponding logical formula. In se-mantics, the paradigm of underspecification aims at manipulating the partial description of tree-structured semanticrepresentations of a sentence rather than at manipulating the representations themselves [17,25]. One of the key issuesin both constraint-based grammar and constraint-based semantic formalisms is to collect partial descriptions of treesand to solve them, i.e., to find a tree structure that satisfies all constraints.Cornell [13] introduced a simple but powerful tree description language, which contains constraints for dominance,precedence, and equality between nodes, and disjunctive combinations of these (a formal definition is given is Sec-tion 2). Cornell also gave a saturation algorithm based on local propagations, which turned out to be incomplete. Foran example of a tree description that shows this, see Section 3.4 in [3].In this article we present the first polynomial-time algorithm that tests satisfiability of a tree description from Cor-nell’s tree description language and directly constructs a solution to the problem instance, if one exists. A predecessorof this algorithm, which applies to a restricted language, was presented in [4]. The present algorithm, which solves the* Corresponding author.E-mail addresses: bodirsky@informatik.hu-berlin.de (M. Bodirsky), mkutz@mpi-inf.mpg.de (M. Kutz).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.12.004\f186M. Bodirsky, M. Kutz / Artificial Intelligence 171 (2007) 185–196general problem of Cornell’s full tree description language, runs in time O(nm), where n is the number of variablesand m the number of constraints in the input. The performance is achieved by a recursive strategy that works directlyon the constraint graph, and avoids local consistency techniques a la [14,19] that are frequently used in constraintsatisfaction.Significance of the results. Computational linguistics is not the only area in computer science and artificial intelli-gence where partial tree descriptions become relevant. In fact, a fragment of Cornell’s language has been introducedindependently in [12] (also see [16,21]), and is known there as the left-linear point algebra. The best known algorithmfor the so-called network satisfaction problem for the left-linear point algebra has a running time which is in O(n5),where n denotes the size of the input [21]. Since the left-linear point algebra is a fragment of Cornell’s language, ourquadratic time algorithm also yields a new and asymptotically faster algorithm for the left-linear point algebra. Detailsof this connection will be given in Section 3.1.The consistency problem we study can also be posed as a constraint satisfaction problem (CSP), as formalizedin e.g. [8]. The catch here is that the variables might take values from an infinite domain (it can be shown that theproblem cannot be modeled as a CSP with a finite domain); see also Section 3. One important direction of research inthis area is to systematically identify constraint languages that can be solved in polynomial time. In this context, ouralgorithmic result is interesting because it is neither based on group-theoretic techniques such as Gaussian elimination,nor on Datalog and local consistency techniques. This is in contrast to CSPs with finite domains, where all knownalgorithms for polynomial-time solvable algorithms involve at least one of the above two techniques [9,18].In computational biology, phylogenetic analysis is a field where we have to deal with partial information aboutevolutionary trees. An evolutionary tree for a set of species is a rooted tree where the leaves are bijectively labeledwith the species from the set. Constructing evolutionary trees from biological data is a difficult problem for a varietyof reasons (see [20]). Many approaches assume that the evolutionary tree is built from a set of taxa based on thecomparison of a single protein or a single position in aligned protein sequences, but very often the resulting tree willbe different depending on which particular protein or position is used. Several trees, each from a different protein orposition, must be built and be shown to be “generally consistent” before the implied evolutionary history is consideredreliable. The question whether such consistency tests can be automated motivates the so-called common-supertreeproblem [20]. We will describe in Section 3.2 how the common-supertree problem can be modeled in (a fragment of)Cornell’s tree description language. Therefore, the algorithm presented here also yields a new algorithm for (and anew perspective on) the common-supertree problem.Outline. In Section 2, we introduce standard terminology for rooted trees and define Cornell’s tree description lan-guage. This allows us to clearly describe in Section 3 the relationship between our results and results in qualitativetemporal reasoning in artificial intelligence, phylogenetic analysis in computational biology, the left-linear point al-gebra in the theory of relation algebras, and the general framework of constraint satisfaction problems. In Section 5,we introduce an algorithm for a small fragment of Cornell’s language. This fragment is already expressive enough tocapture the common-supertree problem mentioned above. The corresponding consistency-problem is non-trivial in thesense that the algorithm proposed by Cornell is inconsistent already for this fragment (see [3]). However, the simplic-ity of the language allows for a smaller and simpler description of an algorithm that decides consistency. Discussingthis language first will be instructive to deal with the consistency problem for the full language, which is far moreinvolved. For the full language, we first reduce the problem to a simpler tree description language (Section 5), provefundamental results for constraint-graphs that are associated to a partial tree description (Section 6), and finally usethese results to present our algorithm and prove its correctness (Section 7). Section 8 summarizes and poses questionsfor future research.2. Tree descriptionsThe trees considered here are always rooted, and we consider the edges as directed, pointing away from the root.By an ordered tree we mean a rooted tree with a linear order on the children of each vertex and we use the terms leftand right to compare them.We follow the notation of [2]. The set of vertices of a tree T is denoted by VT , and the vertices are usually calledu, v, or w. The expression u (cid:3) v denotes that u is the father of v and u (cid:3)∗ v (and v ∗(cid:4) u) means that u dominates v, i.e.,u is an ancestor of v in the tree (including u = v). We write u (cid:3)+ v (and v +(cid:4) u) if u (cid:3)∗ v and u (cid:5)= v. If for two verticesu and v neither u (cid:3)∗ v nor v (cid:3)∗ u, we say that u and v are disjoint, in symbols u ⊥ v. In this situation we distinguish\fM. Bodirsky, M. Kutz / Artificial Intelligence 171 (2007) 185–196187Fig. 1. The translation of the partial tree description of Fig. 1 into the restricted language.two cases: either u precedes or succeeds v. A vertex u precedes a vertex v (and v succeeds u), in symbols u ≺+ v(and v +(cid:8) u), if there is a common ancestor of u and v in the tree that has two children w1 and w2 with w1 (cid:3)∗ u andw2 (cid:3)∗ v and such that u is to the left of v. We write u ≺∗ v if either u ≺+ v or u = v.The right picture in Fig. 1 shows an example of a rooted tree with root α(x). In pictures we indicate the orderingof the children of a vertex by distinguishing between left and right. Here, α(v) ≺+ α(w) and α(y) ≺+ α(v), andα(x) (cid:3)+ α(w), for example.In an ordered tree, for every pair u, v of vertices exactly one of the following relations holds:+(cid:8) v,+(cid:4) v,u = v.u ≺+u (cid:3)+v,v,uuIt is important to note that the union of the relations (cid:3)+ and ≺+ forms a strict linear order on the set of all verticesof an ordered tree, which is easily seen to be the pre-order that results from a (recursive) tree traversal that lists eachnode before its descendants.We now define partial tree descriptions, due to Cornell [13], that allow to partially describe the structure of anordered tree using arbitrary disjunctions of these five cases. To distinguish clearly between equality in this languageand the common usage of the symbol ‘=’, we de",
            {
                "entities": [
                    [
                        3080,
                        3108,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 22–33Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInfinitary equilibrium logic and strongly equivalent logic programs ✩Amelia Harrison a,∗a University of Texas, Austin, TX, USAb Universidad Politécnica de Madrid, Madrid, Spainc University of Málaga, Málaga, Spain, Vladimir Lifschitz a,∗, David Pearce b, Agustín Valverde ca r t i c l e i n f oa b s t r a c tArticle history:Received 20 January 2016Received in revised form 9 November 2016Accepted 8 February 2017Available online 21 February 2017Keywords:Answer set programmingStrong equivalenceLogic of here-and-thereStrong equivalence is an important concept in the theory of answer set programming. Informally speaking, two sets of rules are strongly equivalent if they have the same meaning in any context. Equilibrium logic was used to prove that sets of rules expressed as propositional formulas are strongly equivalent if and only if they are equivalent in the logic of here-and-there. We extend this line of work to formulas with infinitely long conjunctions and disjunctions, show that the infinitary logic of here-and-there characterizes strong equivalence of infinitary formulas, and give an axiomatization of that logic. This is useful because of the relationship between infinitary formulas and logic programs with local variables.© 2017 Elsevier B.V. All rights reserved.1. IntroductionAnswer set programming (ASP) is a form of declarative programming based on the stable model semantics of logic programs [1–7]. The concept of strong equivalence plays an important role in the theory of ASP. Informally speaking, two sets of rules are strongly equivalent if they have the same meaning in any context.Compare, for instance, the rulesq(X, Z ) ← q(X, Y ), q(Y , Z ), p(X), p(Y ), p(Z )and← q(X, Y ), q(Y , Z ), not q(X, Z ), p(X), p(Y ), p(Z ).(1)(2)Both rules express the idea that relation q is transitive on domain p. But in many contexts these rules do not have the same meaning: the effect of adding (1) to a logic program describing p and q is, in general, not the same as the effect of adding (2). The first rule allows us to derive new facts about q; adding it to a program turns relation q into its transitive closure. The second rule is a constraint; adding it weeds out the stable models in which q is not transitive.✩This paper is an invited revision of a paper which first appeared at the 13th International Conference on Logic Programming and Non-monotonic Reasoning.* Corresponding author.E-mail addresses: ameliaj@cs.utexas.edu (A. Harrison), vl@cs.utexas.edu (V. Lifschitz), david.pearce@upm.es (D. Pearce), a_valverde@ctima.uma.es(A. Valverde).http://dx.doi.org/10.1016/j.artint.2017.02.0020004-3702/© 2017 Elsevier B.V. All rights reserved.\fA. Harrison et al. / Artificial Intelligence 246 (2017) 22–33The situation is different, however, if the program to which we add rules (1) and (2) contains the choice rule{q(X, Y )} ← p(X), p(Y )23(3)(“for any X , Y from p, decide arbitrarily whether to include q( X, Y ) in the stable model”). The set consisting of rules (1)and (3) is strongly equivalent to the set consisting of (2) and (3). Consequently, in the presence of choice rule (3), the program obtained by adding (1) has the same stable models as the program obtained by adding (2).According to Lifschitz et al. [8], strong equivalence is closely related to the 3-valued logic called the logic of here-and-there, which was introduced by Arend Heyting [9] long before the invention of computer programming.1 Consider the ground instances of rules (1)–(3):q(t1, t3) ← q(t1, t2), q(t2, t3), p(t1), p(t2), p(t3),← q(t1, t2), q(t2, t3), not q(t1, t3), p(t1), p(t2), p(t3),{q(t1, t2)} ← p(t1), p(t2)(t1, t2, t3 are arbitrary ground terms) and rewrite these ground rules as propositional combinations of ground atoms in the following way:q(t1, t2) ∧ q(t2, t3) ∧ p(t1) ∧ p(t2) ∧ p(t3) → q(t1, t3),¬(q(t1, t2) ∧ q(t2, t3) ∧ ¬q(t1, t3) ∧ p(t1) ∧ p(t2) ∧ p(t3)),p(t1) ∧ p(t2) → q(t1, t2) ∨ ¬q(t1, t2).(4)(5)(6)Formulas (4) and (5) are equivalent to each other in classical logic. But this fact cannot be established in the logic of here-and-there, which is weaker than classical logic. Formula (6) is a tautology; this fact cannot be established in the logic of here-and-there either. On the other hand, the equivalence between the set consisting of formulas of forms (4) and (6)and the set consisting of formulas of forms (5) and (6) can be proved even in this weaker logic. This example illustrates a general fact: two sets of rules written as propositional formulas are strongly equivalent if and only if they are equivalent in the logic of here-and-there [8, Theorem 1].In view of this relationship, proving strong equivalence can be often reduced to reasoning in a system of axioms and inference rules that is sound and complete with respect to the logic of here-and-there. Such formal systems have been known for a long time; see Section 5.1.The proof of the theorem relating strong equivalence to the logic of here-and-there is based on the characterization of stable models in terms of equilibrium logic [10]—a nonmonotonic counterpart of the logic of here-and-there.The statement of the theorem is not restricted to finite sets of formulas. This is important because a single rule with variables has infinitely many ground instances if we allow function symbols (or symbols for arbitrary integers) in ground terms. But some rules found in ASP programs can be represented by sets of propositional formulas only if we allow formulas themselves to be infinite; infinite sets of finite formulas do not suffice. Consider, for instance, the ruleq ← count{ X : p(X)} = 0.(7)The aggregate expression in the body means, informally speaking, that set p is empty. This rule can be thought of as an implication with an infinite conjunction in the body:(cid:2)t¬p(t) → q.Here t ranges over ground terms. The need for infinite conjunctions and disjunctions is common when rules contain local variables, such as X in the example above. Many ASP programs, in particular many programs in the input language of the grounder gringo and its subset, the ASP Core language [11], can be represented by formulas of this type [12].In many cases, first-order formulas can also be used to capture the meaning of ASP programs. For example, rule (7) can be represented using the first-order formula∀x¬p(x) → q.But possibilities of this approach are more limited. For instance, if count in (7) is replaced with sum, or 0 is replaced by a variable, the resulting rule cannot be represented using a first-order formula.In this paper, on the basis of the definition of a stable model for infinitary propositional formulas proposed by Miroslaw Truszczy ´nski [13], we extend to such formulas some definitions and theorems of the theory of strong equivalence and equilibrium logic. Our goals are1 The name “here-and-there” is appropriate in view of the fact that this logic can be described in terms of Kripke frames with two worlds, “Here” and “There.” It is known also as “the logic of present and future” or “the Smetanich logic.”\f24A. Harrison et al. / Artificial Intelligence 246 (2017) 22–33(i) to define the infinitary version of the logic of here-and-there,(ii) to define its nonmonotonic counterpart—the infinitary version of equilibrium logic,(iii) to verify that stable models of infinitary formulas in the sense of Truszczy ´nski can be characterized in terms of infinitary equilibrium logic,(iv) to verify that infinitary propositional formulas are strongly equivalent to each other iff they are equivalent in the infinitary logic of here-and-there,(v) to find an axiomatization of that logic.We will see that achieving goals (i)–(iv) is straightforward, given the work done earlier for finite formulas. Goal (v) is more challenging.A preliminary version of this paper was presented at the 2015 Conference on Logic Programming and Nonmonotonic Reasoning [14]. The material in Sections 2.4 and 5.3 is new to this version.2. Stable models and equilibrium logic in the infinitary setting2.1. Review: infinitary formulasLet (cid:2) be a propositional signature, that is, a set of propositional atoms. The syntax of infinitary formulas defined by Truszczy ´nski [13] can be described as follows. For every nonnegative integer r, (infinitary propositional) formulas (over (cid:2)) of rank r are defined recursively, as follows:• every atom from (cid:2) is a formula of rank 0,• if H is a set of formulas, and r is the smallest nonnegative integer that is greater than the ranks of all elements of H, • if F and G are formulas, and r is the smallest nonnegative integer that is greater than the ranks of F and G, then then H∧and H∨are formulas of rank r,F → G is a formula of rank r.(cid:2)as F ∨ G. The symbols (cid:8) and ⊥ will be understood as abbreviations for ∅∧respectively; ¬F stands for F → ⊥, and F ↔ G stands for (F → G) ∧ (G → F ). These conventions allow us to view We will write {F , G}∧and ∅∨finite propositional formulas over (cid:2) as a special case of infinitary formulas.as F ∧ G, and {F , G}∨A set or family of formulas is bounded if the ranks of its members are bounded from above. For any bounded family (cid:3)(Fα)α∈ A of formulas, we denote the formula {Fα : α ∈ A}∧by α∈ A Fα , and similarly for disjunctions.(cid:3)For example, if p1, p2, . . . and q are atoms then each ¬pi is a formula of rank 1, ¬pi is a formula of rank 2, andi¬pi → q(8)iis a formula of rank 3.Subsets of a signature (cid:2) will be also called interpretations of (cid:2). The satisfaction relation between an interpretation and a formula is defined recursively, as follows:• For every atom p from (cid:2), I |= p if p ∈ I .• I |= H∧• I |= H∨• I |= F → G if I (cid:13)|= F or I |= G.if for every formula F in H, I |= F .if there is a formula F in H such that I |= F .A model of a set H of infinitary formulas is an interpretation that satisfies all formulas in H. ",
            {
                "entities": [
                    [
                        2726,
                        2754,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1366–1389Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing rank dependent utility in graphical models for sequentialdecision problems ✩Gildas Jeantet, Olivier Spanjaard∗Laboratoire d’Informatique de Paris 6 (LIP6-CNRS), Université Pierre et Marie Curie (UPMC), 4 Place Jussieu, F-75252 Paris Cedex 05, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 2 March 2009Received in revised form 31 August 2010Accepted 31 August 2010Available online 2 December 2010Keywords:Algorithmic decision theoryRank dependent utilityDecision treesInfluence diagramsPlanning under uncertaintyThis paper is devoted to automated sequential decision in AI. More precisely, we focus hereon the Rank Dependent Utility (RDU) model. This model is able to encompass rationaldecision behaviors that the Expected Utility model cannot accommodate. However, thenon-linearity of RDU makes it difficult to compute an RDU-optimal strategy in sequentialdecision problems. This has considerably slowed the use of RDU in operational contexts.In this paper, we are interested in providing new algorithmic solutions to compute anRDU-optimal strategy in graphical models. Specifically, we present algorithms for solvingdecision tree models and influence diagram models of sequential decision problems. Fordecision tree models, we propose a mixed integer programming formulation that is validfor a subclass of RDU models (corresponding to risk seeking behaviors). This formulationreduces to a linear program when mixed strategies are considered. In the general case (i.e.,when there is no particular assumption on the parameters of RDU), we propose a branchand bound procedure to compute an RDU-optimal strategy among the pure ones. Afterhighlighting the difficulties induced by the use of RDU in influence diagram models, weshow how this latter procedure can be extended to optimize RDU in an influence diagram.Finally, we provide empirical evaluations of all the presented algorithms.© 2010 Elsevier B.V. All rights reserved.1. IntroductionIn many AI problems, agents must act under uncertainty (e.g. in robot control, relief organization, medical diagnosis,games, etc.). When the consequences of an action only depend on events whose probabilities are known, decision theoryunder risk provides useful tools to automate decisions. The purpose of this theory is indeed to design decision criteria toevaluate probability distributions on outcomes (called hereafter lotteries) according to the preferences of a decision maker.A popular criterion is the expected utility (EU) model proposed by von Neumann and Morgenstern [49]. In this model,an agent is endowed with a utility function u that assigns a numerical value to each outcome. The evaluation of a lotteryL = (p1, x1; . . . ; pn, xn) (i.e., the lottery that yields outcome xi with probability pi ) is then performed via the computation of(cid:2)its utility expectation: EU(L) =ni=1 pi u(xi). However, despite its intuitive appeal, the EU model does not make it possibleto account for all rational decision behaviors. An example of such impossibility is the so-called Allais’ paradox [2] (Table 1).We present below a very simple version of this paradox due to Kahneman and Tversky [23] (Table 2).Example 1 (Kahneman and Tverky’s example). Consider a choice situation where two options are presented to a decision(cid:3)maker. He chooses between lottery L1 and lottery L2 in a second(cid:3)1 in a first problem, and between lottery L2 and lottery L✩This paper extends preliminary results of the two authors [20].* Corresponding author.E-mail address: olivier.spanjaard@lip6.fr (O. Spanjaard).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.019\fG. Jeantet, O. Spanjaard / Artificial Intelligence 175 (2011) 1366–13891367Table 1Original Allais’ paradox. Columns represent probabilities,100M stands for 100 millions. Most people prefers si-(cid:3)multaneously L1 to L2 to L2.(cid:3)1 and LLottery0.01L1(cid:3)L1L2(cid:3)L2$100M$0M$100M$0M0.1$100M$500M$100M$500M0.89$100M$100M$0M$0MTable 2Kahneman and Tversky’s version. Columns represent(cid:3)outcomes. Most people prefers simultaneously L1 to L1and L(cid:3)2 to L2.LotteryL1(cid:3)L1L2(cid:3)L2$00.000.100.900.91$3000$40001.000.000.100.000.000.900.000.09(cid:3)1), while in the second problem he prefers L(cid:3)problem (see Table 2). In the first problem he prefers L1 to L1 (he is certain to earn $3000 with L1 while he might earn(cid:3)nothing with L2 is almost thesame as the probability of earning only $3000 with L2). The EU model cannot simultaneously account for both preferences.(cid:3)1 implies u(3000) > 0.1u(0) + 0.9u(4000). This is equivalent to 0.1u(3000) > 0.01u(0) +Indeed, the preference for L1 over L0.09u(4000), and therefore to 0.9u(0) + 0.1u(3000) > 0.91u(0) + 0.09u(4000) (by adding 0.9u(0) on both sides). Hence,(cid:3)1 implies the preference for L2 over Lwhatever utility function is used, the preference for L1 over L(cid:3)2 to L2 (the probability of earning $4000 with L(cid:3)2 in the EU model.Actually, Allais points out that this preference reversal, far from being paradoxical, is the consequence of a reasonablebehavior of preference for security in the neighborhood of certainty [3]. In other words, “a bird in the hand is worth two in the(cid:3)bush” (preference for L1 over L1). It is known as the certainty effect. The preference reversal can be explained as follows:when the probability of winning becomes low, the sensitivity to the value of earnings increases while the sensitivity tothe probabilities decreases. To encompass the certainty effect in a decision criterion, the handling of probabilities shouldtherefore not be linear. Given this situation, new models have been developed: some models are grounded on an alternativerepresentation of uncertainty such as the theory of possibility [12], others try to sophisticate the definition of expectedutility such as prospect theory [23], cumulative prospect theory [48] or the rank dependent utility (RDU) model introducedby Quiggin [40]. This latter model is one of the most popular generalization of EU. In this model, a non-linear probabilityweighting function ϕ is incorporated in the expectation calculus, which gives a greater expressive power. In particular, theRDU model is compatible with both versions of Allais’ paradox. Furthermore, the probability weighting function ϕ is alsouseful to model the attitude of the agent towards the risk. Indeed, unlike the EU model, the RDU model makes it possibleto distinguish between weak risk aversion (i.e., if an option yields a guaranteed utility, it is preferred to any other riskyoption with the same expected utility) and strong risk aversion (i.e., if two lotteries have the same expected utility, thenthe agent prefers the lottery with the minimum spread of possible outcomes). For this reason, the RDU criterion has beenused in search problems under risk in state space graphs, with the aim of finding optimal paths for risk-averse agents [38].Note that, within the AI community, the rank dependent utility function is best known under the name of Weighted OrderedWeighted Averaging operator [45,46]. In particular, the WOWA operator has been studied in several fields of AI where anaggregation function is required: synthesis of information [45], decision making under risk [34,36], metadata aggregationproblems [10], interactive techniques in multicriteria optimization [35].The algorithmic issues related to the use of RDU in sequential decision problems have prevented its adoption in thissetting until today. In a sequential decision problem under risk, one does not make a simple decision but one follows astrategy (i.e. a sequence of decisions conditioned by events) resulting in a non-deterministic outcome. This type of problemis in particular encountered in decision-theoretic planning [6,7]. This term refers to planners involving decision-theoretictools. Formally, the aim of a decision-theoretic planner is to find a plan optimizing a given decision criterion. For thispurpose, the lottery induced by each plan is evaluated according to a decision criterion (usually EU). Several representationformalisms can be used for sequential decision problems, such as decision trees [e.g. 41], influence diagrams [e.g. 44] orMarkov decision processes [e.g. 11,22]. A decision tree is an explicit representation of a sequential decision problem, whileinfluence diagrams or Markov decision processes are compact representations and make it possible to deal with decisionproblems of greater size. It is important to note that, in all these formalisms, the set of potential strategies is combinatorial(i.e., its size increases exponentially with the size of the instance). The computation of an optimal strategy for a givenrepresentation and a given decision criterion is then an algorithmic issue in itself. Contrary to the computation of a strategymaximizing EU, one cannot directly resort to dynamic programming for computing a strategy maximizing RDU (due to itsnon-linearity). Evaluating a decision tree or an influence diagram according to RDU (i.e., computing an optimal strategyaccording to RDU) raises therefore a challenging algorithmic problem. This is precisely the issue we tackle in this paper.The paper is organized as follows. In Section 2, we recall the main features of RDU. In Section 3, we place our work inthe stream of research aiming at incorporating risk-sensitivity in probabilistic planning problems. Then, in Section 4, afterdetailing how the RDU criterion should be used in a sequential decision problem, we propose two approaches for optimizingRDU in a decision tree, and we provide numerical tests for both approaches. In Section 5, we investigate the optimization ofRDU in an influence diagram. After recalling the influence diagram formalism, we highlight a difficulty that was not presentin the d",
            {
                "entities": [
                    [
                        3787,
                        3815,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 319 (2023) 103915Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintAutomated streamliner portfolios for constraint satisfaction problemsPatrick Spracklen, Nguyen Dang, Özgür Akgün∗, Ian MiguelSchool of Computer Science, University of St Andrews, St Andrews, Fife, KY16 9SX, UKa r t i c l e i n f oa b s t r a c tArticle history:Received 22 January 2022Received in revised form 20 March 2023Accepted 24 March 2023Available online 29 March 2023Keywords:Constraint programmingConstraint modellingConstraint satisfaction problemAlgorithm selectionConstraint Programming (CP) is a powerful technique for solving large-scale combinatorial problems. Solving a problem proceeds in two distinct phases: modelling and solving. Effec-tive modelling has a huge impact on the performance of the solving process. Even with the advance of modern automated modelling tools, search spaces involved can be so vast that problems can still be difficult to solve. To further constrain the model, a more aggressive step that can be taken is the addition of streamliner constraints, which are not guaranteed to be sound but are designed to focus effort on a highly restricted but promising portion of the search space. Previously, producing effective streamlined models was a manual, difficult and time-consuming task. This paper presents a completely automated process to the gen-eration, search and selection of streamliner portfolios to produce a substantial reduction in search effort across a diverse range of problems. The results demonstrate a marked im-provement in performance for both Chuffed, a CP solver with clause learning, and lingeling, a modern SAT solver.© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionChallenging combinatorial problems, from domains such as planning, scheduling, packing or configuration, often form problem classes: families of problem instances related by a shared high-level specification, with a common set of free pa-rameters. Constraint Programming (CP) and Propositional Satisfiability solving (SAT) offer powerful, complementary means to solve these problem classes. For either formalism, a model must be formulated, which describes the problem class in a format suitable for input to the intended solver. Since the search spaces involved can be vast, however, sometimes the model initially formulated for a problem class may give instances where it is too difficult for the solver to find a solution in a timely mannerIn response, a natural step is to constrain the model further in order to strengthen the inferences the solver can make, therefore detecting dead ends in the search earlier and reducing overall search effort. One approach is to add im-plied constraints, which can be inferred from the initial model and are therefore guaranteed to be sound. Manual [1,2]and automated [3–5] approaches to generating implied constraints have been successful. Other approaches include adding symmetry-breaking [6–9] and dominance-breaking constraints [10–12], both of which rule out members of equivalence classes of solutions while preserving at least one member of each such class.* Corresponding author.E-mail addresses: jlps@st-andrews.ac.uk (P. Spracklen), nttd@st-andrews.ac.uk (N. Dang), ozgur.akgun@st-andrews.ac.uk (Ö. Akgün), ijm@st-andrews.ac.uk (I. Miguel).https://doi.org/10.1016/j.artint.2023.1039150004-3702/© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fP. Spracklen, N. Dang, Ö. Akgün et al.Artificial Intelligence 319 (2023) 103915Fig. 1. Essence specification of the Car Sequencing Problem [14], shown to be NP-complete [15]. A number of cars (n_cars) are to be produced; they are not identical, because different classes (n_classes) are available (quantity) as variants on the basic model. The assembly line has different stations which install the various options (n_options) such as air conditioning and sun roof (each class of cars requires certain options, represented by usage). A maximum number of cars (maxcars) requiring a certain option can be sequenced within a consecutive subsequence block (blksize), otherwise the station will not be able to cope.If these techniques are inapplicable, or improve performance insufficiently, for satisfiable problems a more aggressive step is to add streamliner constraints [13], which are not guaranteed to be sound but are designed to focus effort on a highly restricted but promising portion of the search space. Streamliners trade the completeness (i.e. failing to find a solution when there is one) offered by implied, symmetry-breaking and dominance-breaking constraints for potentially much greater search reduction.Previously, producing effective streamlined models was a difficult and time-consuming task. It involved manually in-specting the solutions of small instances of the problem class in question to identify patterns to use as the basis for streamliners [13,16–18]. For example, Gomes and Sellmann [13] added a streamliner requiring a Latin Square structure when searching for diagonally ordered magic squares.The principal contribution of this paper is to demonstrate how a powerful range of streamliners can be generated and applied automatically. Our approach is situated in the automated constraint modelling system Conjure [19–21]. This system takes as input a specification in the abstract constraint specification language Essence [22,23]. Fig. 1 presents an example specifi-cation, which asks us to sequence cars on a production line so as not to exceed the capacity of any station along the line, each of which installs an option such as sun roof. Essence supports a powerful set of type constructors, such as set, multi set, function and relation, hence Essence specifications are concise and highly structured. Existing constraint solvers do not support these abstract decision variables directly. Therefore we use Conjure to refine abstract constraint specifications into concrete constraint models, using constrained collections of primitive variables (e.g. integer, boolean) to represent the abstract structure. The constraint modelling assistant tool Savile Row [24,25] is then used for producing solver dependent input. Savile Row supports several solving paradigms, including CP, SAT and SMT (satisfiability modulo theories).Our method exploits the structure in an Essence specification to produce streamlined models automatically, for example by imposing streamlining constraints on the function present in the specification in Fig. 1. The modified specification is refined automatically into a streamlined constraint model by Conjure. Identifying and adding the streamlining constraints at this level of abstraction is considerably easier than working directly with the constraint model, which would involve first recognising (for example) that a certain collection of primitive variables and constraints together represent a function – a potentially very costly process. Moreover, recovering high-level information from a low-level model expressed in a lower level constraint modelling language like OPL [26], MiniZinc [27] or Essence Prime [28] would be brittle with respect to the exact heuristics and modelling reformulations used inside Conjure and Savile Row. As with automated symmetry breaking during modelling [29,20], automated streamlining therefore motivates the adoption of a higher level language such as Essence and letting automated tools work out the best compilation – just as has happened in general programming languages.Our streamlining system completely automates the original manual process defined by Gomes and Sellmann [13]. As per their method, it does require an initial investment in generating and testing streamliners for the problem class at hand, but this effort is repaid in two ways. First, we assume a context common across automated algorithm selection [30] and machine learning in general: we expect to solve a large number of instances of the problem class, and so the effort made to formulate the best model that we can is amortised over that substantial solving effort. Second, successful streamlining can result in a vast reduction in search effort, allowing us to solve much harder instances than would otherwise be practically feasible. Our work significantly expands previous work on automated streamliner generation from high-level problem specifications [31]and automatic selection of streamlining constraints [32].2\fP. Spracklen, N. Dang, Ö. Akgün et al.Artificial Intelligence 319 (2023) 103915Fig. 2. Solving a problem instance using a streamlined Essence specification. Conjure is run once for a streamlined model, whereas Savile Row and the selected solver is run once per instance. The streamliner that is provided as input to Conjure is generated by a separate call to Conjure as part of Phase 1(Candidate Streamliner Generation).We demonstrate the effectiveness of our approach on both the CP and SAT solving paradigms, choosing representa-tive solvers for each. For CP, we use the learning solver chuffed [33], and for SAT, we use lingeling [34]. As presented in Section 8, our method can often produce a substantial reduction in search effort across a diverse range of problems. The automated streamlining system, Essence problem specifications and all the data used in this work for computational evaluation are available at https://www.github .com /stacs -cp /automated -streamliner-portfolios (see [35]).2. Architecture overviewWe begin with an overview of the architecture of our system, before explaining each of its components in detail in the subsequent sections. Given a problem class of interest, our streamlining approach proceeds in three main phases. Firstly, candidate streamliners are generated",
            {
                "entities": [
                    [
                        3512,
                        3540,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 823–851www.elsevier.com/locate/artintNegotiating with bounded rational agents in environments withincomplete information using an automated agent ✩Raz Lin a,∗, Sarit Kraus a,c, Jonathan Wilkenfeld b,c,d, James Barry da Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel 52900b Department of Government and Politics, University of Maryland, College Park, Maryland, USAc Institute of Advanced Computer Studies, University of Maryland, USAd Center for International Development and Conflict Management, University of Maryland, College Park, Maryland, USAReceived 6 March 2007; received in revised form 24 September 2007; accepted 24 September 2007Available online 17 October 2007AbstractMany tasks in day-to-day life involve interactions among several people. Many of these interactions involve negotiating over adesired outcome. Negotiation in and of itself is not an easy task, and it becomes more complex under conditions of incompleteinformation. For example, the parties do not know in advance the exact tradeoff of their counterparts between different outcomes.Furthermore information regarding the preferences of counterparts might only be elicited during the negotiation process itself.In this paper we propose a model for an automated negotiation agent capable of negotiating with bounded rational agents underconditions of incomplete information. We test this agent against people in two distinct domains, in order to verify that its modelis generic, and thus can be adapted to any domain as long as the negotiators’ preferences can be expressed in additive utilities.Our results indicate that the automated agent reaches more agreements and plays more effectively than its human counterparts.Moreover, in most of the cases, the automated agent achieves significantly better agreements, in terms of individual utility, than thehuman counterparts playing the same role.© 2007 Elsevier B.V. All rights reserved.Keywords: Bilateral negotiation; Bounded rationality; Incomplete information; Automated agent1. IntroductionVarious tasks in day-to day life require negotiation capabilities. These can be as simple and ordinary as hagglingover a price in the market, through deciding what show to watch on TV. On the other hand, it can also involve issuesover which millions of lives are at stake, such as interstate disputes [25] and nuclear disarmament [9]. No matter whatthe domain, the negotiation process itself is not an easy task. The parties will have conflicting interests with referenceto some aspects of the negotiation. On the other hand, both sides might also have the incentive to cooperate with each✩ This research was supported in part by NSF under grant #IIS-0208608. A preliminary version of this paper was published at ECAI 2006, Italy.This paper was selected for the Fast Track submission.* Corresponding author.E-mail addresses: linraz@cs.biu.ac.il (R. Lin), sarit@cs.biu.ac.il (S. Kraus), jwilkenf@gvpt.umd.edu (J. Wilkenfeld), jbarry6899@aol.com(J. Barry).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.007\f824R. Lin et al. / Artificial Intelligence 172 (2008) 823–851other, as reaching an agreement could be more beneficial for them than walking away without any agreement ([20],Chapter 7).Negotiation is a profession, yet on many occasions, ordinary people need to become involved in negotiation tasks.Thus, success in modeling such an agent has great advantages and implications: from using it for training people innegotiations, to assisting in e-commerce environments, as well as for the development of tools for modeling negotia-tion behavior in general. We propose a model of such an automated agent. Thus, we make a significant contributionin this respect.With regard to the negotiation model, we consider a setting of a finite horizon bilateral negotiation with incompleteinformation between an automated agent and a human counterpart. The negotiation is said to have a finite horizonif the length of every possible history of the negotiation is finite ([20], p. 90). Incomplete information is expressedas uncertainty regarding the utility preferences of the opponent, and we assume that there is a finite set of differentagent types. The negotiation itself consists of a finite set of multi-attribute issues and time-constraints. The negotiationconsists of multi-attribute issues if the parties have to negotiate an agreement which involves several attributes for eachissue. This can help in making complex decisions while taking into account multiple factors [10]. Costs are assignedto each agent, such that during the negotiation process, the agents might gain or lose utility over time. If no agreementis reached by the given deadline a status quo outcome is enforced.Our automated agent is capable of negotiating efficiently in such environments, as our experimental results show.Nonetheless, in order to allow our agent to negotiate efficiently in these settings, we had to decide how to allow itto deal with the uncertainty both regarding the environment and the opponent. To achieve this, we incorporated twomechanisms in the automated agent. The first deals with incomplete information regarding the opponent by using apractical learning algorithm based on Bayes’ theorem which updates the agent’s beliefs regarding its opponent. Thesecond mechanism deals with the bounded rationality of the opponent. While our model applies utility functions, itis a based on a non-classical decision making method. Instead of focusing on maximizing the expected utility, weare motivated by qualitative decision making approaches [4,24] and we use the maximin function and the qualitativevaluation of offers in our model. Using these methods our automated agent generates offers and decides whether toaccept or reject proposals it has received.We conducted three sets of experiments in which we matched our automated agent against (a) human negotiators,(b) an automated agent following an equilibrium strategy, and (c) against itself—that is, the same models of an agentplaying both sides. The experiments were run on two distinct domains. In the first domain, England and Zimbabwenegotiate in order to reach an agreement evolving from the World Health Organization’s Framework Convention onTobacco Control, the world’s first public health treaty. In the second domain a negotiation takes place after a successfuljob interview between an employer and a job candidate.By analyzing the results of the experiments we conducted, we show that our automated agent is capable of negoti-ating efficiently and reaching multi-attribute agreements in such environments.When playing one of the sides in the negotiation (England in the first domain and the job candidate in the seconddomain) our agent achieved significantly higher utility values than the human players, and agreements were reachedfaster than when an agent was not present in the negotiation. On the other hand, when the agent played the otherside, though it reached higher utility values than the human player, these results were not significantly higher than thehumans’ results.This paper contributes to research on automated negotiation in several ways. First, it tackles the problem ofmulti-attribute negotiation with incomplete information. Given the importance of negotiating efficiently in such anenvironment we provide a generic mechanism that achieves just that. Second, we present an automated negotiationagent which is domain independent and allows to experiment with almost any real-life domain. Together, the auto-mated negotiation environment will enable exploration of future research directions and thereafter it can be used tobetter understand behavioral and cognitive aspects of negotiations undertaken by human negotiators.The remainder of the paper is organized as follows. Section 2 provides an overview of bilateral negotiation withincomplete information. Section 3 surveys related work in the field of negotiation with incomplete information andbounded rational agents. Section 4 presents the design of the automated agent, including its beliefs updating anddecision making mechanisms. Section 5 describes the experimental setting and methodology and reviews the results.Finally, Section 6 provides a summary and lists recommendations for future work in this area.\fR. Lin et al. / Artificial Intelligence 172 (2008) 823–8518252. Problem descriptionWe consider a bilateral negotiation in which two agents negotiate to reach an agreement on conflicting issues.The negotiation can end either when (a) the negotiators reach a full agreement, (b) one of the agents opts out, thusforcing the termination of the negotiation with an opt-out outcome denoted OPT, or (c) a predefined deadline isreached, denoted dl, whereby, if a partial agreement is reached it is implemented or, if no agreement is reached,a status quo outcome, denoted SQ, is implemented. Since no agreement is worse than any agreement, and a statusquo is implemented if the deadline is reached, we assume that default values are assigned to each attribute. Thus, ifboth sides agree only on a subset of the issues and the deadline is reached, the unresolved issues are assigned withtheir default value and thus a partial agreement can be implemented. Let I denote the set of issues in the negotiation,Oi the finite set of values for each i ∈ I and O a finite set of values for all issues (O1 × O2 × · · · × O|I |). We allowpartial agreements, ⊥ ∈ Oi for each i ∈ I . An offer is then denoted as a vector (cid:5)o ∈ O. It is assumed that the agentscan take actions during the negotiation process until it terminates. Let Time denote the set of time periods in thenegotiation, that is Time = {0, 1, . . . , dl}. Time also impacts the agents’ utilities. Each agent is assigned a time costwhich influences its utility as time passes.In each period t ∈ Time of the negotiation, if the negotiation has not terminated earlier, each agent",
            {
                "entities": [
                    [
                        3109,
                        3137,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 165 (2005) 37–56www.elsevier.com/locate/artintAutomatic identification of music performers withlearning ensemblesEfstathios Stamatatos a, Gerhard Widmer b,c,∗a Department of Information and Communication Systems Engineering,University of the Aegean, Samos, Greeceb Department of Computational Perception, Johannes Kepler University, Linz, Austriac Austrian Research Institute for Artificial Intelligence, Vienna, AustriaReceived 29 April 2004Available online 14 March 2005AbstractThis article addresses the problem of identifying the most likely music performer, given a set ofperformances of the same piece by a number of skilled candidate pianists. We propose a set of verysimple features for representing stylistic characteristics of a music performer, introducing ‘norm-based’ features that relate to a kind of ‘average’ performance. A database of piano performances of22 pianists playing two pieces by Frédéric Chopin is used in the presented experiments. Due to thelimitations of the training set size and the characteristics of the input features we propose an ensembleof simple classifiers derived by both subsampling the training set and subsampling the input features.Experiments show that the proposed features are able to quantify the differences between music per-formers. The proposed ensemble can efficiently cope with multi-class music performer recognitionunder inter-piece conditions, a difficult musical task, displaying a level of accuracy unlikely to bematched by human listeners (under similar conditions). 2005 Elsevier B.V. All rights reserved.Keywords: Machine learning; Classification; Ensemble learning; Music* Corresponding author.E-mail addresses: stamatatos@aegean.gr (E. Stamatatos), gerhard.widmer@jku.at (G. Widmer).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.007\f38E. Stamatatos, G. Widmer / Artificial Intelligence 165 (2005) 37–561. IntroductionThe representation of music as given in the printed score is not able to capture everymusical nuance. Hence, a piece played exactly as notated in the printed score would soundmechanical and highly unmusical. Expressive music performance is the act of ‘shaping’a piece of music according to the artist’s understanding of the structure (or ‘meaning’) ofthe piece. Every skilled performer continuously modifies important parameters, such astempo and loudness, in order to stress certain notes or ‘shape’ certain passages. Expressiveperformance is what makes music come alive and what distinguishes one performer fromanother (and what makes some performers famous).Because of its central role in our musical culture, expressive performance is a centralresearch topic in contemporary musicology. One main direction in empirical performanceresearch aims at formulating rules or principles of expressive performance either with thehelp of human experts [7] or by processing large volumes of data using machine learningtechniques [25,26]. Another direction of research is based on implicit knowledge extractedfrom recordings of human performers using case-based reasoning techniques [13]. Obvi-ously, these directions attempt to explore the similarities between skilled performers insimilar musical contexts. On the other hand, the differences between performers have notbeen studied thoroughly. Repp [17] presented a statistical analysis of temporal common-alities and differences among distinguished pianists’ interpretations of a well-known pieceand demonstrated the individuality of some famous pianists. However, the differences inmusic performance are still expressed generally with aesthetic criteria rather than quanti-tatively.In this paper, we use AI (specifically: machine learning) techniques in an attempt toexpress the individuality of music performers (pianists) in machine-interpretable terms byquantifying the main parameters of expressive performance. In order to avoid any sub-jective evaluation of our approach, we apply it to a well-defined problem: the automaticidentification of music performers, given a set of piano performances of the same pieceof music by a number of skilled candidate pianists. From this perspective, our task can beviewed as a typical classification problem, where the classes are the candidate pianists.1A set of features that represent the stylistic properties of a performer is proposed, introduc-ing the ‘norm performance’ as a reference point, while ideas taken from machine learningresearch are applied to the construction of the classifier. The dimensions of expressive vari-ation that will be taken into account are the three main expressive parameters available toa pianist: timing (variations in tempo), dynamics (variations in loudness), and articulation(the use of overlaps and pauses between successive notes).Experimental results show that it is indeed possible for a machine to distinguish musicperformers (pianists) on the basis of their performance style. We will show that successfullearning from extremely limited training data can be achieved by maximally exploiting thegiven information via ensemble learning (based on subsampling both the data and the inputfeatures). From the point of view of machine learning, this constitutes another supporting1 In a sense, this is also related to currently ongoing efforts in the area of Music Information Retrieval (MIR),where much work is devoted to the automatic classification of music recordings according to style or artist (see,e.g., [22]).\fE. Stamatatos, G. Widmer / Artificial Intelligence 165 (2005) 37–5639case for the utility of ensemble learning methods, specifically, the combination of a largenumber of independent simple ‘experts’ [3]. The contribution of this work to musicologyis the identification (via machine learning methodology) of a set of global characteristicsof performance style that seem to be relevant to distinguishing different artists.On the other hand, it must be stressed that the presented results are rather limitedbecause of the limited empirical data available for this investigation. Obtaining precisemeasurements, in terms of timing deviations, dynamics, and articulation, of performancesof highly skilled artists is a difficult task. We are currently investing a large amount of ef-fort into developing new methods for extracting expressive details from given recordingsand hope to be able to report on much more extensive experiments in the future.This paper is organized as follows: the next section contains a brief description of thedata and terminology used in this study. Section 3 describes the proposed features forthe quantification of the music performance style. Section 4 explains how preliminary ex-perimentation was performed in order to establish the main parameters and strategy forlearning. Section 5 then presents the ensemble learning experiments performed and theresults achieved. Finally, Section 6 discusses the major conclusions drawn from this studyand future work directions.2. Data and terminologyThe data used in this study consists of performances played and recorded on a Boe-sendorfer SE290 computer-monitored concert grand piano, which is able to measure everykey and pedal movement of the artist with very high precision. 22 skilled performers,including professional pianists, graduate students and professors of the Vienna Music Uni-versity, played two pieces by Frédéric Chopin: the Etude op.10 no.3 (first 21 bars) and theBallade op.38 (initial section, bars 1 to 45). The digital recordings were then transcribedinto symbolic form (MIDI) and matched against the printed score [4]. Thus, for each notein a piece we have precise information about how it was notated in the score, and how itwas actually played in a performance. The parameters of interest are the exact time whena note was played (vs. when it ‘should have been played’ according to the score)—thisrelates to tempo and timing—the dynamic level or loudness of a played note (dynamics),and the exact duration of a played note, and how the note is connected to the following one(articulation). All this can be readily computed from our data.2In the following, the term Inter-Onset Interval (IOI) will be used to denote the timeinterval between the onsets of two successive notes of the same voice. We define Off-Time Duration (OTD) as the time interval between the offset time of one note and theonset time of the next note of the same voice, and Dynamic Level (DL) as the ‘loudness’2 Note that this is only incomplete performance information. For example, we currently do not use informationabout the pedalling behaviour. Also other expressive information related to the produced sound, such as the‘attack’ or ‘touch’ of the notes (if there is such a thing—see [10]), cannot be measured in our data, because ourdata is derived from symbolic MIDI events.\f40E. Stamatatos, G. Widmer / Artificial Intelligence 165 (2005) 37–56Fig. 1. The three main parameters used to characterize note-level performance details: Dynamic Level (DL),Inter-Onset Interval (IOI), and Off-Time Duration (OTD).of an individual note (in terms of the MIDI velocity parameter).3 The parameters are il-lustrated graphically in Fig. 1. The 22 pianists are referred to by their code names (#01,#02, etc.).3. Quantifying music performance style3.1. Score and normIf we define (somewhat simplistically) expressive performance as ‘intended deviationfrom the score’, then different performances differ in the way and extent the artist ‘deviates’from the score, i.e., from a purely mechanical (‘flat’) rendition of the piece, in terms oftiming, dynamics, and articulation. In order to be able to compare performances of piecesor sections of different length, we need to define features that characterize and quantifythese deviations at a global level, i.e., without reference to individual notes and how thesewere played.Fig. 2 shows the performances of the first 30 soprano notes of the Ballade by the pianists#01–#05 in terms of timin",
            {
                "entities": [
                    [
                        1850,
                        1878,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1407–1429Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintImplementing logical connectives in constraint programmingChristopher Jefferson b, Neil C.A. Moore b, Peter Nightingale b,∗, Karen E. Petrie aa School of Computing, University of Dundee, Dundee DD1 4HN, UKb School of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 31 July 2009Received in revised form 30 June 2010Accepted 2 July 2010Keywords:Constraint programmingConstraint satisfaction problemsPropagation algorithmsLogical connectivesCombining constraints using logical connectives such as disjunction is ubiquitous inconstraint programming, because it adds considerable expressive power to a constraintlanguage. We explore the solver architecture needed to propagate such combinations ofconstraints efficiently. In particular we describe two new features named satisfying sets andconstraint trees. We also make use of movable triggers (Gent et al., 2006) [1], and with thesethree complementary features we are able to make considerable efficiency gains.A key reason for the success of Boolean Satisfiability (SAT) solvers is their ability topropagate Or constraints efficiently, making use of movable triggers. We successfullygeneralise this approach to an Or of an arbitrary set of constraints, maintaining the crucialproperty that at most two constraints are active at any time, and no computation at allis done on the others. We also give an And propagator within our framework, whichmay be embedded within the Or. Using this approach, we demonstrate speedups of over10,000 times in some cases, compared to traditional constraint programming approaches.We also prove that the Or algorithm enforces generalised arc consistency (GAC) when allits child constraints have a GAC propagator, and no variables are shared between children.By extending the Or propagator, we present a propagator for AtLeastK, which expressesthat at least k of its child constraints are satisfied in any solution.Some logical expressions (e.g. exclusive-or) cannot be compactly expressed using And, Orand AtLeastK. Therefore we investigate reification of constraints. We present a fast genericalgorithm for reification using satisfying sets and movable triggers.© 2010 Published by Elsevier B.V.1. IntroductionProblems often consist of choices. Making an optimal choice which is compatible with all other choices made is difficult.Constraint programming (CP) is a branch of Artificial Intelligence, where computers help users to make these choices. Con-straint programming is a multidisciplinary technology combining computer science, operations research and mathematics.Constraints are a powerful and natural means of knowledge representation and inference in many areas of industry andacademia, arising in design and configuration; planning and scheduling; diagnosis and testing; and in many other contexts.A constraint satisfaction problem (CSP [2]) is a set of decision variables, each with an associated domain of potential values,and a set of constraints. For example, the problem might be to fit components (values) to circuit boards (decision variables),subject to the constraint that no two components can be overlapping. An assignment maps a variable to a value from itsdomain. Each constraint specifies allowed combinations of assignments of values to a subset of the variables. A solution to a* Corresponding author.E-mail addresses: caj@cs.st-andrews.ac.uk (C. Jefferson), ncam@cs.st-andrews.ac.uk (N.C.A. Moore), pn@cs.st-andrews.ac.uk (P. Nightingale),kpetrie@computing.dundee.ac.uk (K.E. Petrie).0004-3702/$ – see front matter © 2010 Published by Elsevier B.V.doi:10.1016/j.artint.2010.07.001\f1408C. Jefferson et al. / Artificial Intelligence 174 (2010) 1407–1429CSP is an assignment to all the variables which satisfies all the constraints. In this paper we consider solving CSPs throughbacktrack search with an inference step at each node [2].Modelling is the process of representing a problem as a CSP. To allow natural modelling of some problems, the logicalconnectives of And and Or are required between constraints. For example, in a school timetabling problem you may haveeither Teacher1 Or (Teacher2 And Teacher3) taking a particular class. It is also sometimes useful to be able to apply Not toa constraint, this is often done in CSP by means of reification. The reification of a constraint C produces another constraintCr , such that Cr has an extra Boolean variable r in its variable set, and (in any solution) r is set to true if and only if theoriginal constraint C is satisfied. In this paper we discuss the neglected area of how to efficiently implement these logicalconnectives across constraints, which are the fundamental building blocks of CSP models [3] (Chapter 11).During the search for a solution of a CSP, constraint propagation algorithms are used. These propagators make inferences,recorded as domain reductions, based on the domains of the variables constrained. If at any point these inferences result inany variable having an empty domain then search backtracks and a new branch is considered. Propagators and generalisedarc consistency (GAC) are important concepts in this paper. When considering a single constraint C , GAC is the strongestpossible consistency that a propagation algorithm can enforce. Enforcing GAC removes all domain values which are notcompatible with any solution of C . In [3] (Chapter 3), Bessiere defines GAC and discusses the complexity of enforcing it.In this paper we consider propagating logical combinations of constraints. For example, for constraints C1, C2, C3, C4 wemay wish to post the following expression and propagate it efficiently.(C1 ∧ C2) ⇒ (C3 ∨ C4)It is desirable to make use of existing propagators for C1, C2, C3 and C4 since these may be highly efficient specialisedpropagators.1.1. A traditional approachA traditional approach (probably the most common) is to individually create reified propagators for the four constraints.These introduce an additional Boolean variable representing the truth of the constraint (e.g. the reified form of C1 is theconstraint r1 ⇔ C1, so in any solution r1 is True if and only if C1 is satisfied). A logical expression can be enforced on theadditional Boolean variables to obtain the desired combination. The example above translates into the following collectionof constraints1:r1 ⇔ C1,(r1 ∧ r2) ⇒ (r3 ∨ r4)r3 ⇔ C3,r2 ⇔ C2,r4 ⇔ C4,This scheme has three major disadvantages. First, it can be very inefficient because every reified constraint is propagatedall the time. For example consider an Or of a set of n constraints. As we will demonstrate in Section 4, at most twoconstraints need to be actively checked at any time. However, a reification approach will propagate all n reified constraintsat all times. Second, developing reified propagators individually for each constraint is a major effort. Third, when a variableoccurs multiple times in an expression, the reified decomposition may propagate poorly. In this paper we address the firsttwo issues but not the third: we achieve the same level of consistency as the reified decomposition.1.2. Two vital features of a solver for a new approachThe key finding of this work is that two vital features of the solver must be combined to achieve efficient propagationof logical connectives. If either feature is not available, then the other is of limited benefit. The two features are constrainttrees, which allow a parent constraint to control the propagation of its children, and movable triggers which allow a constraintto change the events [3] (Chapter 14) it is interested in during search.Consider an Or of n constraints over disjoint variable sets. We will show that at most two of the constraints need to beconsidered at any time, because if two of the constraints are satisfiable then no propagation can occur. Once two satisfiableconstraints have been identified, all other constraints are presently irrelevant and no computation time should be wastedon them. This is essential to efficiency when n is large.Constraint trees allow us to stop checking irrelevant constraints. However, this is not enough to achieve zero cost forirrelevant constraints: there is a cost to generate trigger events for the constraints. It is necessary to remove triggers notcurrently of interest, hence movable triggers are also required.The following table summarises the costs caused by irrelevant constraints.ReificationConstraint treesStatic triggersAll reified constraintspropagated at all timesTrigger events received forall constraints at all timesMovable triggersAll reified constraintspropagated at all timesIrrelevant constraintscause no cost1 In some solvers it would be necessary to further decompose (r1 ∧ r2) ⇒ (r3 ∨ r4).\fC. Jefferson et al. / Artificial Intelligence 174 (2010) 1407–14291409Our implementations are in the Minion solver [4], though the presentation is not specific to Minion.1.3. OverviewThere are a number of solver architecture decisions which impinge on propagating logical combinations of constraints.In Section 3 we describe three architecture features which are key to the new algorithms presented in this paper. Satisfyingsets (Section 3.3) are novel to the best of our knowledge. We also provide the first implementation of constraint trees(Section 3.2). Movable triggers [1] are also described in Section 3.1 to aid understanding of the rest of the paper.In Section 4, we present a propagator for the constraint AtLeastK, which ensures that at least k of a set of constraintsare satisfied in any solution. Both And and Or are special cases of AtLeastK. Via the constraint trees framework, AtLeastKconstraints may be nested to any depth, and also may be reified using the algorithms given in Section 5. The AtLeastKpropagator maintains the crucial property that only k + 1 constraints are ",
            {
                "entities": [
                    [
                        3784,
                        3812,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 220–235Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDealing with logical omniscience: Expressiveness and pragmatics ✩Joseph Y. Halpern a, Riccardo Pucella b,∗a Cornell University, Ithaca, NY 14853, USAb Northeastern University, Boston, MA 02115, USAa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:LogicKnowledgeLogical omniscienceAwarenessImpossible worldsProbability1. IntroductionWe examine four approaches for dealing with the logical omniscience problem and theirpotential applicability: the syntactic approach, awareness, algorithmic knowledge, and im-possible possible worlds. Although in some settings these approaches are equi-expressiveand can capture all epistemic states, in other settings of interest (especially with proba-bility in the picture), we show that they are not equi-expressive. We then consider thepragmatics of dealing with logical omniscience—how to choose an approach and constructan appropriate model.© 2010 Elsevier B.V. All rights reserved.John McCarthy was a pioneer in the use of reasoning about knowledge in AI. His notion of what “any fool” knows, oneof the earliest uses of common knowledge, goes back to roughly 1970; it first appears in a published paper in [21]. It thusseems particularly appropriate for a paper on logics of knowledge to appear in this special issue of Artificial Intelligencededicated to John McCarthy and his work.Like most authors, McCarthy gave “possible-worlds” style semantics to knowledge. Logics of knowledge based onpossible-worlds semantics have been shown to be useful in many areas of knowledge representation and reasoning, rangingfrom security to distributed computing to game theory. In these models, an agent is said to know a fact ϕ if ϕ is true inall the worlds she considers possible. While reasoning about knowledge with this semantics has proved useful, as is wellknown, it suffers from what is known in the literature as the logical omniscience problem: under possible-world semantics,agents know all tautologies and know the logical consequences of their knowledge.While logical omniscience is certainly not always an issue, in many applications it is. For example, in the context ofdistributed computing, we are interested in polynomial-time algorithms, although in some cases the knowledge neededto perform optimally may require calculations that cannot be performed in polynomial time (unless P = NP) [26]; in thecontext of security, we may want to reason about computationally bounded adversaries who cannot factor a large compositenumber, and thus cannot be logically omniscient; in game theory, we may be interested in the impact of computationalresources on solution concepts (for example, what will agents do if computing a Nash equilibrium is difficult).Not surprisingly, many approaches for dealing with the logical omniscience problem have been suggested (see [10, Chap-ter 9] and [25]). A far from exhaustive list of approaches includes:• syntactic approaches [5,24,18], where an agent’s knowledge is represented by a set of formulas (intuitively, the set offormulas she knows);• awareness [7], where an agent knows ϕ if she is aware of ϕ and ϕ is true in all the worlds she considers possible;✩A preliminary version of this paper appeared in the Proceedings of the 11th Conference on Theoretical Aspects of Rationality and Knowledge, 2007, pp. 169–176.* Corresponding author.E-mail addresses: halpern@cs.cornell.edu (J.Y. Halpern), riccardo@ccs.neu.edu (R. Pucella).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.009\fJ.Y. Halpern, R. Pucella / Artificial Intelligence 175 (2011) 220–235221• algorithmic knowledge [12] where, roughly speaking, an agent knows ϕ if her knowledge algorithm returns “Yes” on a• impossible worlds [29], where the agent may consider possible worlds that are logically inconsistent (for example, wherequery of ϕ; andp and ¬p may both be true).Which approach is best to use, of course, depends on the application. One goal of this paper is to elucidate the aspectsof the application that make a logic more or less appropriate. We start by considering the expressive power of theseapproaches. In Section 3, we examine the expressiveness of the approaches for a general epistemic logic. It may seemthat there is not much to say with regard to expressiveness, since it has been shown that all these approaches are equi-expressive and, indeed, can capture all epistemic states (see [31,10] and Section 2). However, this result holds only if weallow an agent to consider no worlds possible. As we show, this equivalence no longer holds in contexts where agents mustconsider some worlds possible.This difference in expressive power is particularly relevant once we have probability in the picture. In Section 4, weexamine the logical omniscience problem in the context of an epistemic logic that can talk explicitly about probability, withformulas of the form K ((cid:3)(Primen) = 1/3), read “the agent knows that the probability that Primen is true is 1/3”. We showthat in the presence of probabilities, the approaches to dealing with logical omniscience that make sense in this setting arenot equi-expressive.But expressive power is only part of the story. We consider here (mainly by example) the pragmatics of dealing withlogical omniscience—an issue that has largely been ignored: how to choose an approach and construct an appropriatemodel. In Section 5, we examine the four main approaches to logical omniscience, and identify some guiding principles forchoosing an approach to model a situation, based on the source of the lack of logical omniscience in that situation. Comingup with an appropriate structure can be nontrivial. As a specific contribution, we illustrate a general approach to deriving animpossible-worlds structure based on an implicit description of the situation, which seems to be appropriate for a numberof situations of interest.2. The four approaches: a reviewWe now review the standard possible-worlds approach and the four approaches to dealing with logical omnisciencediscussed in the introduction. For ease of exposition we focus on the single-agent propositional case. While in many appli-cations it is important to consider more than one agent and to allow first-order features (indeed, this is true in some ofour examples), the issues that arise in dealing with multiple agents and first-order features are largely orthogonal to thoseinvolved in dealing with logical omniscience. Thus, we do not discuss these extensions here.2.1. The standard approachWe define a propositional language LK of knowledge. Starting with a set Φ of primitive propositions, we close off underconjunction (∧), negation (¬), and the K operator. As usual, we consider ϕ ∨ ψ to be an abbreviation for ¬(¬ϕ ∧ ¬ψ), andϕ ⇒ ψ to be an abbreviation for ¬ϕ ∨ ψ . K ϕ will usually be read as “the agent knows ϕ”, but because K ϕ ⇒ ϕ will notalways hold in our models, K ϕ will sometimes have a more natural reading as “the agent believes ϕ”. None of our resultsdepend on the reading of the operator.We give semantics to LK formulas using Kripke structures. For simplicity, we focus on approaches that satisfy the K45(cid:6), π ), where W is a nonemptyaxioms (as well as KD45 and S5).1 In this case, a K45 Kripke structure is a triple (W , W(cid:6) ⊆ W is the set of worlds that the agent considers possible, and π is anset of possible worlds (or worlds, for short), Winterpretation that associates with each world a truth assignment π (w) to the primitive propositions in Φ. Note that theagent need not consider every possible world (that is, each world in W ) possible. Then we have(M, w) |(cid:8) p iff π (w)(p) = true, where p ∈ Φ.(M, w) |(cid:8) ¬ϕ iff (M, w) (cid:10)|(cid:8) ϕ.(M, w) |(cid:8) ϕ ∧ ψ iff (M, w) |(cid:8) ϕ and (M, w) |(cid:8) ψ .(M, w) |(cid:8) K ϕ iff (M, w(cid:6)) |(cid:8) ϕ for all w(cid:6) ∈ W.(cid:6)This semantics suffers from the logical omniscience problem. In particular, one sound axiom is(cid:2)(cid:3)K ϕ ∧ K (ϕ ⇒ ψ)⇒ K ψ,which says that an agent’s knowledge is closed under implication. In addition, the knowledge generalization inference rule issound:From ϕ infer K ϕ.1 We could extend the investigation in this paper to more general structures satisfying weaker axioms, but consider the more standard setting sufficesfor the points we want to make. We expect similar results to the ones we obtain here to hold for more general structures, but have not checked the details.\f222J.Y. Halpern, R. Pucella / Artificial Intelligence 175 (2011) 220–235Thus, agents know all tautologies. As is well known, two other axioms are sound in K45 Kripke structures:K ϕ ⇒ K K ϕand¬K ϕ ⇒ K ¬K ϕ.These are known respectively as the positive and negative introspection axioms. (These properties characterize K45.)In the structures we consider, we allow Wto be empty, in which case the agent does not consider any worlds possible.(cid:6), π ) where(cid:6) (cid:10)= ∅. Thus, in a KD45 Kripke structure, the agent always considers at least one world possible. In KD45 Kripke structures,In such structures, K ϕ is true for all ϕ, including false. A KD45 Kripke structure is a K45 Kripke structure (W , WWthe axiom(cid:6)¬K (false)is sound, which implies that the agent cannot know inconsistent facts. The logic KD45 results when we add this axiom toK45. S5 Kripke structures are KD45 Kripke structures where W = W; that is, the agent considers all worlds in W possible.In S5 Kripke structures, the axiom(cid:6)K ϕ ⇒ ϕ,which says that the agent can know only true facts, is sound. Adding this axiom to the KD45 axioms gives us the logic S5.2.2. The syntactic approachThe intuition behind the syntactic approach for dealing with logical omniscience is simply to explicitly list, at every pos-(cid:6), π , C), where(cid:6), π ) is a K45 Kripke structure and C associates a set of formulas C(w",
            {
                "entities": [
                    [
                        3660,
                        3688,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1498–1527Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEfficient solutions to factored MDPs with imprecise transitionprobabilitiesKarina Valdivia Delgado a,∗, Scott Sanner b, Leliane Nunes de Barros a,ca EACH, Universidade de São Paulo, Av. Arlindo Béttio, 1000 – Ermelino Matarazzo São Paulo – SP, Brazilb NICTA and the Australian National University, Canberra, ACT 2601, Australiac IME, Universidade de São Paulo, Rua de Matão, 1010 – Cidade Universitária São Paulo – SP, Brazila r t i c l ei n f oa b s t r a c tArticle history:Received 3 December 2009Received in revised form 31 December 2010Accepted 31 December 2010Available online 4 January 2011Keywords:Probabilistic planningMarkov Decision ProcessRobust planningWhen modeling real-world decision-theoretic planning problems in the Markov DecisionProcess (MDP) framework, it is often impossible to obtain a completely accurate estimateoftransition probabilities. For example, natural uncertainty arises in the transitionspecification due to elicitation of MDP transition models from an expert or estimation fromdata, or non-stationary transition distributions arising from insufficient state knowledge. Inthe interest of obtaining the most robust policy under transition uncertainty, the MarkovDecision Process with Imprecise Transition Probabilities (MDP-IPs) has been introduced tomodel such scenarios. Unfortunately, while various solution algorithms exist for MDP-IPs,they often require external calls to optimization routines and thus can be extremely time-consuming in practice. To address this deficiency, we introduce the factored MDP-IP andpropose efficient dynamic programming methods to exploit its structure. Noting that thekey computational bottleneck in the solution of factored MDP-IPs is the need to repeatedlysolve nonlinear constrained optimization problems, we show how to target approximationtechniques to drastically reduce the computational overhead of the nonlinear solverwhile producing bounded, approximately optimal solutions. Our results show up to twoorders of magnitude speedup in comparison to traditional “flat” dynamic programmingapproaches and up to an order of magnitude speedup over the extension of factored MDPapproximate value iteration techniques to MDP-IPs while producing the lowest error of anyapproximation algorithm evaluated.© 2011 Elsevier B.V. All rights reserved.1. IntroductionMarkov Decision Processes (MDP) [1] have become the de facto standard model for decision-theoretic planning problemsand a great deal of research in recent years has aimed to exploit structure in order to compactly represent and efficientlysolve factored MDPs [2–5]. However, in many real-world problems, it is simply impossible to obtain a precise representationof the transition probabilities in an MDP. This may occur for many reasons, including (a) imprecise or conflicting elicitationsfrom experts, (b) insufficient data from which to estimate reliable precise transition models, or (c) non-stationary transitionprobabilities due to insufficient state information.For example, in an MDP for traffic light control, it is difficult to estimate the turn probabilities for each traffic lane thathas the option of going straight or turning. These lane-turning probabilities may change during the day or throughout theyear, as a function of traffic at other intersections, and based on holidays and special events; in general it is impossible to* Corresponding author. Tels.: +55 11 73326036, +55 11 30919878; fax: +55 11 30916134.E-mail addresses: kvd@usp.br (K.V. Delgado), ssanner@nicta.com.au (S. Sanner), leliane@ime.usp.br (L.N. de Barros).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.01.001\fK.V. Delgado et al. / Artificial Intelligence 175 (2011) 1498–15271499accurately model all of these complex dependencies. In this case it would be ideal to have a traffic control policy optimizedover a range of turn probabilities in order to be robust to inherent non-stationarity in the turn probabilities.To accommodate optimal models of sequential decision-making in the presence of strict uncertainty over the transitionmodel, the MDP with imprecise transition probabilities (MDP-IP) was introduced [6,7]. While the MDP-IP poses a robustframework for the real-world application of decision-theoretic planning, its general solution requires the use of computa-tionally expensive optimization routines that are extremely time-consuming in practice.To address this computational deficiency, we extend the factored MDP model to MDP-IPs by proposing to replace theusual Dynamic Bayes Net (DBN) [8] used in factored MDPs with Dynamic Credal Nets (DCNs) [9] to support compact factoredstructure in the imprecise transition model of factored MDP-IPs. Then we propose efficient, scalable algorithms for solvingthese factored MDP-IPs. This leads to the following novel contributions in this work:• We introduce the parameterized ADD (PADD) with polynomial expressions at its leaves and explain how to extend ADDproperties and operations to PADDs.• We extend the decision-diagram based SPUDD and APRICODD algorithms for MDPs [3,4] to MDP-IP algorithms thatexploit DCN structure via PADDs.• As shown in our experimental evaluation, the generalization of SPUDD and APRICODD to MDP-IPs using PADDs isjust the first step in obtaining efficient solutions. Observing that the key computational bottleneck in the solution ofMDP-IPs is the need to repeatedly solve nonlinear constrained optimization problems, we show how to target ourapproximations to drastically reduce the computational overhead of the nonlinear solver while producing provablybounded, approximately optimal solutions.As our results will demonstrate, using the above contributions we can obtain up to two orders of magnitude speedupin comparison to traditional “flat” dynamic programming approaches [6]. In addition, our best approximate factored MDP-IP solver yields an order of magnitude speedup over a direct generalization of state-of-the-art approximate factored MDPsolvers [4] for factored MDP-IPs (also implemented in this work) and consistently produces the lowest error of all approxi-mate solution algorithms evaluated.2. Markov decision processesFormally, an MDP is defined by the tuple M = (cid:3)S, A, P , R, T , γ (cid:4), where [1,10]:(cid:5)|s, a) is the conditional probability of reaching state s• S is a finite set of fully observable states;• A is a finite set of actions;• P (s• R : S × A → R is a fixed reward function associated with every state and action;• T is the time horizon (number of decision stages remaining) for decision-making;• γ = [0, 1) is a discount factor (the reward obtained t stages into the future is discounted in the sense that it is multiplied(cid:5) ∈ S when action a ∈ A is taken from state s ∈ S;by γ t ).A stationary policy π : S → A indicates the action a = π (s) to take in each state s (regardless of stage). The value of astationary policy π is defined as the expected sum of discounted rewards over an infinite horizon (|T | = ∞) starting instate s0 at stage 0 and following πV π (s) = Eπ(cid:4)(cid:4) s0 = sγ t Rt(cid:5),(cid:2)∞(cid:3)t=0(1)where Rt (abbreviation of Rt (st, π (st)) is the reward obtained at stage t when the agent is in state st and takes action π (st ).(1) can be decomposed and rewritten recursively based on the values of the possible successor states s(cid:6)(cid:5) ∈ S as follows:(cid:3)(cid:6)(cid:7)(cid:6).(2)V π (s) = R(cid:7)s, π (s)+ γ(cid:7)(cid:5)|s, π (s)(cid:5)V πsPss(cid:5)∈SOur objective is to find an optimal policy π ∗that yields the maximal value in each state, i.e., ∀s, π (cid:5)V π ∗ (s) (cid:2) V π (cid:5) (s).A well-known algorithm to solve an MDP is value iteration [1]. For t > 0, it constructs a series of t-stage-to-go valuefunctions V t . Starting with arbitrary V 0, value iteration performs value updates for all states s, computing V t based onV t−1. The Q-value for state s and action a is:Q t(s, a) = R(s, a) + γ(cid:6)P(cid:5)|s, as(cid:7)V t−1(cid:7)(cid:6)(cid:5)s(cid:3)s(cid:5)∈Swhere the best value attainable at decision stage t and state s is(3)\f1500K.V. Delgado et al. / Artificial Intelligence 175 (2011) 1498–1527Fig. 1. A credal set example represented by the gray region. The credal set is defined by the triplets {P (x1), P (x2), P (x3)} that belong to this region.V t(s) = maxa∈ AQ t(s, a).We define the greedy policy πV w.r.t. some V as follows:(cid:8)πV (s) = arg maxa∈ AR(s, a) + γ(cid:6)P(cid:5)|s, as(cid:7)(cid:6)V(cid:5)s(cid:9)(cid:7).(cid:3)s(cid:5)∈SAt the infinite horizon, the value function provably converges(cid:4)(cid:4)(cid:4)V t(s) − V t−1(s)(cid:4) = 0maxslimt→∞(4)(5)(6)leading to a stationary, deterministic optimal policy π ∗ = πV ∞ [1]. For practical MDP solutions, we are often only concernedwith (cid:4)-optimality. If we terminate the MDP when the following condition is met:(cid:4)(cid:4)(cid:4)V t(s) − V t−1(s)(cid:4) <maxs(cid:4)(1 − γ )2γthen we guarantee that the greedy policy πV tπ ∗[1].3. MDPs with imprecise transitionsloses no more than (cid:4) in value over an infinite horizon in comparison to(7)As described in our introductory traffic example, it is often necessary to work with imprecise probabilities in order torepresent incomplete, ambiguous or conflicting expert beliefs about transition probabilities. An MDP with imprecise transitionprobabilities (MDP-IP)1 is specifically designed for this setting and is simply an extension of the MDP where the transitionprobabilities can be imprecisely specified. That is, instead of a probability measure P (·|s, a) over the state space S, we havea set of probability measures. For example, let P ( X) be the probability density function for X = {x1, x2, x3} defined with thefollowing constraint set:(cid:10)C =P (x1) (cid:3) 2/3,P (x3) (cid:3) 2/3,2P (x1) (cid:2) P (x2),P (x1) + P (x2) + P (x3) = 1(cid:11).(8)T",
            {
                "entities": [
                    [
                        3787,
                        3815,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 255 (2018) 43–70Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFixpoint semantics for active integrity constraintsBart Bogaerts a,∗, Luís Cruz-Filipe ba KU Leuven, Department of Computer Science, Celestijnenlaan 200A, Leuven, Belgiumb University of Southern Denmark, Department of Mathematics and Computer Science, Campusvej 55, Odense, Denmarka r t i c l e i n f oa b s t r a c tArticle history:Received 4 July 2017Received in revised form 2 October 2017Accepted 18 November 2017Available online 23 November 2017Keywords:Active integrity constraintsApproximation fixpoint theoryActive integrity constraints (AICs) constitute a formalism to associate with a database not just the constraints it should adhere to, but also how to fix the database in case one or more of these constraints are violated. The intuitions regarding which repairs are “good” given such a description are closely related to intuitions that live in various areas of non-monotonic reasoning, such as logic programming and autoepistemic logic.In this paper, we apply approximation fixpoint theory, an abstract, algebraic framework designed to unify semantics of non-monotonic logics, to the field of AICs. This results in a new family of semantics for AICs. We study properties of our new semantics and relationships to existing semantics. In particular, we argue that two of the newly defined semantics stand out. Grounded repairs have a simple definition that is purely based on semantic principles that semantics for AICs should adhere to. And, as we show, they coincide with the intended interpretation of AICs on many examples. The second semantics of interest is the AFT-well-founded semantics: it is a computationally cheap semantics that provides upper and lower bounds for many other classes of repairs.© 2017 Elsevier B.V. All rights reserved.1. IntroductionOne of the key components of modern-day databases are integrity constraints: logical formulas that specify semantic relationships between the data being modeled that have to be satisfied at all times. When the database is changed (typically due to updating), it is necessary to check if its integrity constraints still hold; in the negative case, the database must be repaired.The problem of database repair has been an important topic of research for more than thirty years [1]. There are two major problems when deciding how to repair an inconsistent database: finding possible repairs and choosing which one to apply. Indeed, there are typically several ways to fix an inconsistent database, and several criteria to choose the “best” one have been proposed over the years. Among the most widely accepted criteria are minimality of change [45,25] – change as little as possible – and the common-sense law of inertia (discussed in, e.g., [33]) – do not change anything unless there is a reason for the change.A typical implementation of integrity constraints in database systems is by means of event–condition–action (ECA) rules [38,44], which specify update actions to be performed when a particular event (a trigger) occurs and specific con-ditions hold. ECA rules are widely used in practice, as they are simple to implement and their individual semantics is easy * Corresponding author.E-mail addresses: bart.bogaerts@cs.kuleuven.be (B. Bogaerts), lcfilipe@gmail.com (L. Cruz-Filipe).https://doi.org/10.1016/j.artint.2017.11.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f44B. Bogaerts, L. Cruz-Filipe / Artificial Intelligence 255 (2018) 43–70to understand. However, the lack of declarative semantics for ECA rules makes their interaction complex to analyze and their joint behavior hard to understand.The formalism of active integrity constraints (AICs) [27] was inspired by a similar idea. AICs express database dependen-cies through logic programming-style rules that include update actions in their heads. They come with a set of declarative semantics that identifies several progressively more restricted classes of repairs, which can be used as criteria to select a preferred repair [13]. These repairs can be computed directly by means of tree algorithms [17], which have been imple-mented as a prototype [16].Example 1.1. We motivate the use of AICs in practice by means of a simple example. Consider a company’s database, including tables employee and dept (relating employees to the department where they work). In particular, each employee is assigned to a unique department; if an employee is listed as working in two different departments, then the database is inconsistent, and this inconsistency must be fixed by removing one of those entries.We can write this requirement as the following AIC.∀x, y, z : employee(x), dept(x, y), dept(x, z), y (cid:4)= z ⊃ −dept(x, y)The intended meaning of this rule is: if all the literals in the lefthandside (body) of the rule are true in some state of the database, for particular values of x, y and z, then the database is inconsistent, and this inconsistency can be solved by performing the action on the right.Suppose that the database isDB = {employee(john), dept(john, finance), dept(john, hr)} .This database is inconsistent, and applying our AIC with x = john, y = finance and z = hr gives us a possible fix consisting of the action “remove dept(john, finance)”. Observe, however, that the instantiation x = john, y = hr and z = finance detects the same inconsistency, but proposes instead the fix “remove dept(john, hr)”: in general, there can be several different ways to repair inconsistencies.AICs may also interact with each other. Suppose that we add the constraint∀x, y, z : supervisor(x, y), dept(x, z), ¬dept( y, z) ⊃ +dept( y, z)(1)stating that employees can only supervise people from their own department, and that whenever this constraint is violated, the department of the supervisee needs to be updated (i.e., the supervisor table and the department of the supervisor are deemed correct). If the database is nowDB = {employee(john), employee(ann), dept(john, finance), dept(ann, hr), supervisor(ann, john)}then this AIC detects an inconsistency, and suggests that it be fixed by adding the entry dept(john, hr). The database is still inconsistent, though, since there are now two entries for John in the dept table; restoring inconsistency would also require removing the entry dept(john, finance).An alternative repair of the integrity constraint that the supervisee and supervisor should belong to the same department would be to change the department information associated with ann. By using active integrity constraints, we discard this solution: rule (1) only allows to insert a new department for the supervisee. If we additionally also want to allow changing ann’s department, we need an extra constraint. (cid:2)It is striking that many intuitions about what “good” repairs are, such as minimality of change, are similar to intuitions that surfaced in other domains of non-monotonic reasoning, such as logic programming [39] and default logic [34]. Still, it has been hard to find satisfying semantics for AICs. As shown by Cruz-Filipe et al. [17], the semantics of so-called founded repairs [12] unexpectedly fails to respect the common-sense law of inertia, while the more restricted semantics of justified repairs [13] forbids natural repairs in some cases. That work proposed the operational semantics of well-founded repairs, which however is not modular [14] and is therefore severely restricted in its practical applicability.In this work, we begin by defining a new semantics for AICs that avoids these problems: grounded repairs. Grounded repairs are natural counterparts to existing semantics in various non-monotonic reasoning domains such as logic program-ming; we discuss how they relate to other semantics for AICs. We also argue that grounded repairs match our intuitions regarding AICs on a broad set of examples.We then give a more abstract characterization of the different semantics for AICs by associating with each set of AICs ηa semantic operator Tη. This operator immediately induces several semantics:(i) weak repairs are fixpoints of Tη;(ii) repairs are minimal fixpoints of Tη;(iii) grounded repairs are grounded fixpoints [7] of Tη.The first two semantics are pre-existing semantics for AICs that we recover in an operator-based fashion.\fB. Bogaerts, L. Cruz-Filipe / Artificial Intelligence 255 (2018) 43–7045Next, we define a three-valued variant of Tη . In the terminology of approximation fixpoint theory (AFT) [19] our three-valued operator is an approximator of the original semantic operator. Given such an approximator Tη, AFT induces a few more semantics:(iv) the Kripke–Kleene repair is the Kripke–Kleene fixpoint of Tη;(v) the AFT-well-founded repair is the well-founded fixpoint of Tη;(vi) (partial) stable repairs are (partial) stable fixpoints of Tη;(vii) partial grounded repairs are partial grounded fixpoints of Tη.We again study properties of these new semantics and study how they compare to existing semantics. Furthermore, we argue that, from a practical point of view, the AFT-style well-founded semantics is very valuable. Indeed, we show that the AFT-well-founded repair can be computed in polynomial time, and that, on a broad set of practical examples, it corresponds to the intuitions underlying database repairs, providing natural upper and lower bounds on the set of acceptable repairs (formally: the AFT-style well-founded model approximates all justified, stable and grounded repairs).All our semantics are defined within the framework of approximation fixpoint theory, a general algebraic framework for studying logics with a fixpoint semantics. This framework was initially developed by Denecker, Marek and Truszczy ´nski, henceforth referred to as DMT [20], after identifying analogies in the semantics of logic programming [39], autoepistemic logic (AEL) [32] and default logic, hereafter abbreviated to DL [34]. The theory defi",
            {
                "entities": [
                    [
                        3416,
                        3444,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1245–1284www.elsevier.com/locate/artintWhat makes propositional abduction tractableGustav Nordh a,∗,1, Bruno Zanuttini ba LIX, École Polytechnique, Route de Saclay, F-91 128 Palaiseau, Franceb GREYC, UMR CNRS 6072, Université de Caen, Bd. du Maréchal Juin, F-14 032 Caen Cedex, FranceReceived 10 April 2007; received in revised form 28 January 2008; accepted 5 February 2008Available online 12 February 2008AbstractAbduction is a fundamental form of nonmonotonic reasoning that aims at finding explanations for observed manifestations. Thisprocess underlies many applications, from car configuration to medical diagnosis. We study here the computational complexity ofdeciding whether an explanation exists in the case when the application domain is described by a propositional knowledge base.Building on previous results, we classify the complexity for local restrictions on the knowledge base and under various restrictionson hypotheses and manifestations. In comparison to the many previous studies on the complexity of abduction we are able to givea much more detailed picture for the complexity of the basic problem of deciding the existence of an explanation. It turns out thatdepending on the restrictions, the problem in this framework is always polynomial-time solvable, NP-complete, coNP-complete,or (cid:2)PBased on these results, we give an a posteriori justification of what makes propositional abduction hard even for some classesof knowledge bases which allow for efficient satisfiability testing and deduction. This justification is very simple and intuitive, butit reveals that no nontrivial class of abduction problems is tractable. Indeed, tractability essentially requires that the language forknowledge bases is unable to express both causal links and conflicts between hypotheses. This generalizes a similar observation byBylander et al. for set-covering abduction.© 2008 Elsevier B.V. All rights reserved.2 -complete.Keywords: Abduction; Propositional logic; Computational complexity1. IntroductionAbduction is the fundamental reasoning process which consists of explaining observations by plausible causestaken from a given set of hypotheses. For instance, it is an abduction problem to try to derive diseases from ob-served symptoms, according to known rules relating both. This process was extensively studied by Peirce [6], and itsimportance to Artificial Intelligence was first emphasized by Morgan [38] and Pople [41].From the application point of view, abduction has demonstrated its importance. It has been applied in particular toexplanation-based diagnosis (e.g., medical diagnosis [7]), to text interpretation [29], and to planning [28]. It is alsothe fundamental process underlying ATMSs [13].* Corresponding author.E-mail addresses: nordh@lix.polytechnique.fr (G. Nordh), zanutti@info.unicaen.fr (B. Zanuttini).1 Partially supported by the Swedish–French Foundation and the National Graduate School in Computer Science (CUGS), Sweden.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.02.001\f1246G. Nordh, B. Zanuttini / Artificial Intelligence 172 (2008) 1245–1284The formalization and resolution of abduction problems have been studied in numerous formalisms, among whichset-covering [7], default logic [22], logic programming [21,36]. We are interested here in its resolution in classicalpropositional logic.We adopt a complexity-theoretic point of view. More precisely, we are interested in the complexity of decidingwhether an abduction problem has a solution when the underlying knowledge base is propositional. Thus our studyfollows Selman and Levesque’s [48] and Eiter and Gottlob’s [20] seminal papers. We also build on two classificationspreviously obtained in our framework [12,40].Even in the simple setting of propositional logic, deciding whether an abduction problem has a solution is in general(cid:2)P2 -complete. Consequently, like for most hard computational problems, several approaches have been studied forsolving it efficiently: Exhibiting tractable classes obtained by restrictions over the knowledge base [12,16,20,24,51];heuristic approaches, in particular through computation of prime implicates [14,15,37,49] and through reducing theproblem to QBF and using generic QBF solvers [19]; compilation [8,35]; and approximation [31,50].In this paper we adopt the approach consisting of trying to find tractable restrictions over the knowledge base. Ourcontribution is twofold.First, we identify the complexity of abduction, with varying restrictions over the representations of manifestationsand hypotheses, for every constraint language and every clausal or equational language restricting the (propositional)knowledge base, under reasonable assumptions on the representation of the constraints. Concerning manifestations,we study the restrictions where they are expressed as a positive, negative, or unrestricted literal, clause, term, or CNF.Concerning hypotheses, we study the restrictions where they are expressed by a set of literals which is positive, neg-ative, closed under complement, or unrestricted. To that aim, we use the now well-known Schaefer’s framework [46]and Post’s lattice [42]. Precisely, we proceed as follows.• We first prove a relatively small number of tractability and hardness results for particular constraint languages.• Using Post’s classification and these results, we then derive the complexity of abduction for any constraint lan-guage.• In a similar manner, and at the same time, we obtain the complexity of abduction for any clausal or equationallanguage.We exhibit new polynomial and new hard restrictions. We also discover that abduction is always either in P,NP-complete, coNP-complete, or (cid:2)P2 -complete, depending on the restrictions. Such a result could not be taken forgranted, due to Ladner’s result stating that if P (cid:3)= NP, then there exist problems in NP that are neither in P nor NP-complete [33]. Moreover, the fact that some restrictions yield NP-complete, and others coNP-complete problems issurprising at first sight. It reveals in particular that abduction is a very rich problem in terms of completeness resultsin different complexity classes. Thus our results can be used as starting points for establishing complexity results forother problems, in particular in nonmonotonic reasoning.From the application point of view, our tables of complexity allow the designers of knowledge-based agents orexpert systems to choose the appropriate knowledge representation language, according to the tradeoff between theexpressiveness required and the constraints on resolution of abduction problems. Moreover, when a representationlanguage that is hard for abduction must be used, the precise complexity of the corresponding problem allows tochoose heuristic approaches for solving it. For instance, with an appropriate reduction an NP-complete problem canbe solved by a satisfiability solver, while a (cid:2)P2 -complete one cannot; a more generic QBF solver (or a specializedQBF∃,2-solver) must be used.Our second contribution is to identify a simple set of minimal conditions yielding NP-completeness for languageswhich allow for efficient deduction (and are thus good candidates for knowledge representation). For instance, whenterms have to be explained, we discover that abduction is NP-hard exactly when the language for knowledge bases canboth express causal links from hypotheses to individual manifestations and forbid some combinations of hypotheses.This generalizes similar observations by Bylander et al. [7] about set-covering abduction.From this condition it follows that tractability can occur only in very restricted cases, i.e., when there can be nocausal dependency at all or when causes can all be assumed together. For instance, in medical diagnosis this meansthat diseases must not rule each other out for the task to be tractable. We also argue that these conditions give intuitionsabout results beyond Schaefer’s framework of constraint languages, and we revisit some previously known results inthat manner. In this spirit, our observations allow to adopt a unified point of view on the results exhibited with manydifferent restrictions in the literature.\fG. Nordh, B. Zanuttini / Artificial Intelligence 172 (2008) 1245–12841247The use of Post’s lattice and Schaefer’s framework for studying the complexity of reasoning problems is sometimesconsidered to be overlimitating. For instance, it does not encompass the class of all Horn formulas; this is because Hornclauses can be arbitrarily long. In this study, we adopt these powerful tools coming from complexity-theory and showhow to overcome some of these limitations. Indeed, we use them to show results about infinite constraint languagesas well as about finite ones, and we formulate the former in terms of classes of CNF formulas. These extensions aredirectly motivated by AI-applications where it is common to model the knowledge base using an infinite constraintlanguage represented in terms of classes of CNF formulas.To put our results in context, we briefly discuss the results from the literature on the complexity of abduction thatare most relevant to our present study. Our starting point is Selman and Levesque’s [48], and Eiter and Gottlob’s [20]classical results. Selman and Levesque [48] proved that deciding whether an abduction problem over a Horn knowl-edge base has an explanation is NP-complete, even when the hypotheses are given as a set of positive literals andthe manifestation is a single positive literal. Similarly, Eiter and Gottlob [20] proved that when the knowledge baseis given by a general propositional formula, the problem becomes (cid:2)P2 -complete. Moreover they note that when theknowledge base is given by a definite Horn formula, the hypotheses are positive literals, and the manifestations aregiven by a positive term, then the problem is in P.From these results it is clear that the c",
            {
                "entities": [
                    [
                        3081,
                        3109,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 161–184www.elsevier.com/locate/artintA spectrum of compromise aggregation operators for multi-attributedecision makingXudong Luo ∗, Nicholas R. JenningsSchool of Electronics and Computer Science, The University of Southampton, Highfield, Southampton SO17 1BJ, United KingdomReceived 4 May 2006; received in revised form 8 November 2006; accepted 10 November 2006AbstractIn many decision making problems, a number of independent attributes or criteria are often used to individually rate an alternativefrom an agent’s local perspective and then these individual ratings are combined to produce an overall assessment. Now, in caseswhere these individual ratings are not in complete agreement, the overall rating should be somewhere in between the extremes thathave been suggested. However, there are many possibilities for the aggregated value. Given this, this paper systematically exploresthe space of possible compromise operators for such multi-attribute decision making problems. Specifically, we axiomaticallyidentify the complete spectrum of such operators in terms of the properties they should satisfy, and show the main ones that arewidely used—namely averaging operators, uninorms and nullnorms—represent only three of the nine types we identify. For eachtype, we then go onto analyse their properties and discuss how specific instances can actually be developed. Finally, to illustratethe richness of our framework, we show how a wide range of operators are needed to model the various attitudes that a user mayhave for aggregation in a given scenario (bidding in multi-attribute auctions).© 2006 Elsevier B.V. All rights reserved.Keywords: Aggregation operator; Uninorm; Nullnorm; Risk; Multi-attribute decision making; Multi-attribute auction1. IntroductionDecision making is a central concern in the area of artificial intelligence and it is thus an essential component ofmany intelligent systems. For this reason, many decision making models have been developed (such as knowledge-based reasoning [5,47], case-based reasoning [37], neural networks [20], and constraint satisfaction techniques [44,48]). Now, in many cases, the decision making that is performed needs to consider multiple criteria or attributes. Insuch cases, the decision making agent is faced with a set of decision alternatives and the ratings per alternative percriterion (that indicate the degree of satisfaction of the criteria by the alternative) which then have to be fused togetherin order to produce an overall rating. This fusion process is carried out by some form of aggregation operation [9,60].In most cases, this operation is some form of weighted arithmetic mean [19]. Now, this works well in situations inwhich any differences are viewed as being in conflict because the operator reflects a form of compromise behaviouramong the various criteria. However, when these conditions do not hold, arithmetic mean is a poor choice. Thus, in* Corresponding author.E-mail addresses: xl@ecs.soton.ac.uk (X. Luo), nrj@ecs.soton.ac.uk (N.R. Jennings).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.11.004\f162X. Luo, N.R. Jennings / Artificial Intelligence 171 (2007) 161–184general, the type of aggregation used should reflect the user’s individual choice of behaviour among criteria. Giventhis observation, we seek to develop a comprehensive set of possibilities for this task and to do so we turn to fuzzyset theory (see [17] for a view on the importance and impact of this line of research on the general area of artificialintelligence). Our motivation for this choice can be summarised by the following insight [3]:“In fuzzy set theory, membership functions of fuzzy sets play the role similar to utility functions—the role of de-grees of preference. Many authors, including Zadeh himself, refer to membership functions as ‘a kind of utilityfunctions’. The equivalence of utility and membership functions extends from semantical to syntactical level. Al-though this is not the only possible interpretation of membership functions, it allows one to formulate and solveproblems of multiple criteria decision making using the formalism of fuzzy set theory.”In more detail, in fuzzy set theory, the two most widely used aggregation operators are t-norms and t-conormsthat model “AND” and “OR” fuzzy connectives [14,23,32], respectively. However, their main limitation in terms ofaggregation is that the ensuing result is not a compromise between low and high ratings, which, in many cases, isa serious shortcoming [64,65]. To rectify this, alternative aggregation operators have been proposed as a means ofobtaining such a compromise (e.g., averaging operators [1,16,24,26,35], uninorm operators with a neutral element[52,62], and nullnorms (or t-operators) [8,50,51]). Furthermore, the general cases of the two extremes (minimum andmaximum) are t-norm and t-conorm and thus aggregation operators for obtaining a compromise between a pair oft-norms and t-conorms have also been developed (e.g., γ -operators [64], exponential compensatory operators [57],and convex-linear compensatory operators [39,57]). However, in all of this work, there is no common, systematicframework that enables the complete space of possibilities to be mapped out. This means that the sometimes subtledifferences between all these operators are not always readily apparent and that whole families of possibilities may bemissed out. This paper seek to rectify this shortcoming by systematically mapping out the space of possibilities.By way of illustration, consider the following applications of these operators in a variety of intelligent systems.Firstly, they have been employed in a number of agent-based systems. For example, in an agent-based automatednegotiation system that we have developed for business to consumer e-commerce, such an operator is employed toaggregate the satisfaction degree for a product and its purchasing conditions in order to decide whether or not it isacceptable [43]. In this case, when a customer does not like the product sufficiently much on its own, but the purchasingconditions (e.g., finance deal and delivery time) are very attractive, the aggregated acceptance degree for the goods issomewhere in-between the individual ratings, and thus the customer may decide to make the purchase if the overalldeal is sufficiently attractive. Similarly, in an agent-based meeting scheduling system, we use an operator to aggregateall the participating agents’ individual ratings for a possible common time slot into an overall rating for that slot [45].Thus, in this case, when some agents are inclined to reject a meeting time proposal and others are inclined to acceptit, the aggregated rating for the proposal is somewhere in-between their individual ratings. Secondly, aggregationoperators have been employed in expert systems. For example, in distributed expert systems, such operators have beenexploited to synthesise different expert systems’ uncertainties (ratings) for a particular conclusion [63]. Thus, when aconclusion is convincing for some expert systems, but not for others, the aggregated uncertainty for the conclusion isin-between the individual uncertainties. Similarly, in stand-alone rule-based systems, such operators have been usedto aggregate uncertainties (ratings) of the same proposition that are drawn in parallel from different sources [2,46,56]. Thus, when uncertainty from some sources do not support the proposition, but the ones from the others do, itsaggregated uncertainty is in-between the individual uncertainties. Finally, aggregation operators have been employedin many other decision making systems. For example, in fuzzy rule systems, such operators are used to aggregate theoutput of individual rules to obtain the overall system output [61]; in specific kinds of artificial neural networks whereuncertainty handling is necessary, they are used as a threshold function [56]; and in video query systems, they are usedto aggregate matching degrees of video attributes to a global matching degree [13].In each of the above cases, clearly the different applications provide a range of requirements that need differenttypes of aggregation. Moreover, the choice of a specific compromise operator in a specific situation is likely to varyfrom user to user because they each have their own view on how to do the aggregation. For example, when aggregatingtwo ratings, some users might be optimistic and believe the result should not be lower than either of the two; somemight be pessimistic and believe the result should not be higher than either of the two; and some might be more neutraland believe the result should be in-between. In addition, in some situations a user may want to set up a threshold sothat ratings higher than it are regarded as being positive and ratings lower than it as being negative, in which case the\fX. Luo, N.R. Jennings / Artificial Intelligence 171 (2007) 161–184163situation becomes even more complex. In particular, even if we assume that the result of aggregating two conflictingratings (i.e., one higher than the threshold and one lower) is in-between the two, there are still a number of differentways (as discussed above) to aggregate two positive ratings or two negative ones.Such issues are important in a number of contexts. On the one hand, cognitive psychology has showed that thehuman brain is very efficient at processing bipolar (negative and positive) information [6,7,54]. It is believed that thisis so because of the way in which a large part of this expertise is acquired, and also likely to be a result of the cognitiveevolution of species. One the other hand, whenever we want decision making agents to act on behalf of users, the agentmust be capable of reflecting their individual nuances, preferences and attitudes to risk [10,40–42]. In both of thesecases, flexible aggregation is an integral component of this.Despite its importance, ",
            {
                "entities": [
                    [
                        3148,
                        3176,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 56–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the succinctness of some modal logicsTim French a, Wiebe van der Hoek b,∗, Petar Iliev b, Barteld Kooi ca School of Computer Science and Software Engineering, University of Western Australia, Australiab Department of Computer Science, University of Liverpool, UKc Faculty of Philosophy, University of Groningen, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 24 February 2012Received in revised form 12 February 2013Accepted 16 February 2013Available online 18 February 2013Keywords:Knowledge representationModal logicSuccinctnessEpistemic logicFinite model theory of modal logicDescription logicsBoolean modal logicOne way of comparing knowledge representation formalisms that has attracted attentioni.e., we can ask whether one ofrecently is in terms of representational succinctness,the formalisms allows for a more ‘economical’ encoding of information than the other.Proving that one logic is more succinct than another becomes harder when the underlyingsemantics is stronger. We propose to use Formula Size Games (as put forward by Adlerand Immerman (2003) [1], but we present them as games for one player, called Spoiler),games that are played on two sets of models, and that directly link the length of a playin which Spoiler wins the game with the size of a formula, i.e., a formula that is true inthe first set of models but false in all models of the second set. Using formula size games,we prove the following succinctness results for m-dimensional modal logic, where one hasa set I = {i1, . . . , im} of indices for m modalities: (1) on general Kripke models (and alsoon binary trees), a definition [∀Γ ]ϕ =[i]ϕ (with Γ ⊆ I) makes the resulting logicexponentially more succinct for m > 1; (2) several modal logics use such abbreviations[∀Γ ]ϕ, e.g., in description logics the construct corresponds to adding role disjunctions,and an epistemic interpretation of it is ‘everybody in Γ knows’. Indeed, we show that onepistemic models (i.e., S5-models), the logic with [∀Γ ]ϕ becomes more succinct for m > 3;(3) the results for the logic with ‘everybody knows’ also hold for a logic with ‘somebodyknows’, and (4) on epistemic models, Public Announcement Logic is exponentially moresuccinct than epistemic logic, if m > 3. The latter settles an open problem raised by Lutz(2006) [18].i∈Γ(cid:2)© 2013 Elsevier B.V. All rights reserved.1. IntroductionThe study of the expressive power of logics is one of the major topics in mathematical logic and computer science. Thegeneral framework for such investigations can be described as follows. We begin with the question of whether a particularformalism can express some property on some class of models or not. The intuitive notion of property is given a formalexpression through the concept of query and, therefore, the formal version of our initial question is whether a particularquery is definable in some logic under investigation. Such questions are of great theoretical interest. However, it has beenargued in [10] that, as far as knowledge representation formalisms are concerned, the comparison of two such formalisms,L1 and L2, cannot be meaningfully accomplished just in terms of expressive power or the computational complexity of theirinference problems. This is due to the fact that often we have the following situation:1. L1 and L2 are equally expressive, and/or2. L1 and L2 have the same complexity of the satisfiability problem, or* Corresponding author.E-mail addresses: tim@csse.uwa.edu.au (T. French), wiebe@csc.liv.ac.uk (W. van der Hoek), pvi@liverpool.ac.uk (P. Iliev), B.P.Kooi@rug.nl (B. Kooi).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.003\fT. French et al. / Artificial Intelligence 197 (2013) 56–85573. The complexities of L1 and L2 are different but so high that it cannot be honestly claimed to be of any practicalrelevance.Therefore, the authors of [10] suggest that a better comparison criterion is the representational succinctness of such for-malisms. Intuitively, if we are interested in some particular query Q that is expressible with formulae ϕ1 and ϕ2 fromL1 and L2 respectively, we can ask if there is a significant difference in the lengths of ϕ1 and ϕ2. Hence, the notion ofsuccinctness is a refinement of the notion of expressivity.In this paper we present a number of succinctness results related to three well-known extensions of multimodal logic(ML) which have a popular epistemic and knowledge representation interpretation. A brief overview of our main theoremsis as follows.(cid:2)Adding formulae of the form [∀Γ ]ϕ to ML results in exponential succinctness on the well-known class of equivalencemodels S5, the typical semantics for epistemic logic. Intuitively, a formula [∀Γ ]ϕ is best thought of as an abbreviation[i]ϕ. Such an abbreviation arises naturally in many branches of modal logic. For example, inof the ML-formulaepistemic logic [6,25], [∀Γ ] is called the ‘everybody knows’-modality. In boolean modal logic [9], [∀Γ ] corresponds to amodality of the form [i1 ∪ · · · ∪ in], where {i1, . . . , in} = Γ ; in the parlance of Description logics [2], [∀Γ ] corresponds toadding role disjunctions to the description logic ALC (as in ‘sibling’ being defined as the role disjunction of ‘brother’and ‘sister’). Finally, in dynamic logic [11], [∀Γ ]ϕ expresses that after every execution of any program from Γ , ϕ holds(demonic non-determinism).i∈Γ(cid:3)Similarly, adding formulae of the form [∃Γ ]ϕ to ML results in exponential succinctness on S5. A formula [∃Γ ]ϕ can be[i]ϕ. Again, such formulae arise naturally in epistemic logic wherethought of as an abbreviation of the ML-formulathe modality [∃Γ ] is called the ‘somebody knows’ modality. In Dynamic logic, this modality would represent angelicnon-determinism: there is choice of a program from Γ , such that ϕ will hold after every execution of it.Finally, adding formulae of the form [ψ]ϕ to ML again results in exponential succinctness on S5, which answers aquestion left open in [18]. The modal operator [ψ] was introduced in [21] as a means for formalising the intuitive notionof ‘public announcement’. Intuitively, a formula [ψ]ϕ is evaluated at a point w in a Kripke model by first discarding allpoints that do not satisfy ψ and then, if w has survived this procedure, we see whether ϕ is true at w in the newlyobtained model.i∈ΓThe first of the above results can be explained in the following way. We show that for every natural number n, thereis a set of S5 models Mn and a property P of these models such that there is formula of the form [∀Γ ]ϕ, whose lengthis linear in n, that expresses P but every equivalent formula from ML has length exponential in n. Similarly for the secondand third results. This highlights the crucial importance of the class of models we use in our proofs. Intuitively, provingsuch a result with respect to a set of models N for which we have no special requirements for the nature of the relationsseems easier than when we impose additional conditions on the models. This is so, because the more conditions we imposeon our models, the greater the chance to find a formula of sub-exponential length equivalent to [∀Γ ]ϕ. Later we will seethat such results depend not only on the class of models used but on the number of variables and relation symbols in thelanguage, too.The paper is organised as follows. In Section 2, we briefly introduce some classes of functions needed to define thenotion of succinctness, or, better what it means that one logic is exponentially more succinct than another. We also providea lemma (Lemma 1) which offers a sufficient condition to decide this: all our proofs of succinctness rely on this lemma. Inthis section, we also define the four modal languages ML, [∀Γ ]ML, [∃Γ ]ML and [ϕ]ML that we deal with in this paper. Howdo we demonstrate that any formula equivalent to ψ ∈ L2 must have at least a certain length? In Section 2.3, we proposeto use (an adaptation of) Formula Size Games (FSGs) introduced in [1]. FSGs establish a direct link between the number ofmoves needed for one player to win a game, and the length of formulae associated with the game (Theorem 1). We alsoprove the principle of diverging pairs (Theorem 2), which guarantees under which condition the number of moves neededto win certain sub-games, contribute to the number of moves to win the overall-game.Then, Section 3 presents our succinctness results. In particular, in Section 3.1, we employ FSGs to show that both [∀Γ ]MLand [∃Γ ]ML are exponentially more succinct than ML, on the general class of Kripke models K (Theorem 3). The theorem alsoestablishes this for [ϕ]ML, but the proof for this is in [18]. Finally, Theorem 4 generalises this result of succinctness of thesethree modal languages to the class of models S5, i.e., models where the underlying accessibility relations are equivalences.We conclude in Section 4, stating some open problems and conjectures.The present paper is a greatly extended version of [8].2. Preliminaries2.1. Defining succinctnessWhen studying succinctness, we want to say that, in order to express a certain sequence of properties, the length offormulae in one language grows faster than in another language. To reason about relative growth of functions, one oftenuses either the so-called o-notation (also called asymptotic analysis), or a notation based on limits: both approaches are\f58T. French et al. / Artificial Intelligence 197 (2013) 56–85equivalent (see e.g., [5]). We feel that the latter notation is often intuitively more clear, but on the other hand the o-nota-tion enables us to prove Lemma 1. (The latter lemma provides a sufficient condition for proving succinctness: the readerinterested in our succinctness results may start reading Lemma 1 and use that as a working definition of succi",
            {
                "entities": [
                    [
                        3837,
                        3865,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 219 (2015) 67–91Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIntegrating representation learning and skill learning in a human-like intelligent agent∗Nan Li, Noboru Matsuda, William W. Cohen, Kenneth R. Koedinger5000 Forbes Ave, Pittsburgh, PA 15232, USAa r t i c l e i n f oa b s t r a c tArticle history:Received 18 April 2012Received in revised form 2 July 2014Accepted 5 November 2014Available online 4 December 2014Keywords:Agent learningRepresentation learningStudent modelingBuilding an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of “deep features”, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning “deep features” reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system’s instructional strategy.© 2014 Elsevier B.V. All rights reserved.1. IntroductionOne of the fundamental goals of artificial intelligence is to understand and develop intelligent agents that simulate human-like intelligence. A considerable amount of effort [1–3] has been put toward this challenging task. Further, education in the 21st century will be increasingly about helping students not just learn content but to become better learners. Thus, we have a second goal of improving our understanding of how humans acquire knowledge and how students vary in their abilities to learn.* Corresponding author.E-mail addresses: nli1@cs.cmu.edu (N. Li), Noboru.Matsuda@cs.cmu.edu (N. Matsuda), wcohen@cs.cmu.edu (W.W. Cohen), koedinger@cmu.edu(K.R. Koedinger).http://dx.doi.org/10.1016/j.artint.2014.11.0020004-3702/© 2014 Elsevier B.V. All rights reserved.\f68N. Li et al. / Artificial Intelligence 219 (2015) 67–91To contribute to both goals, there have been recent efforts [4–7] in developing intelligent agents that model human learning of math, science, or a second language. Although such agents produce intelligent behavior with less human knowl-edge engineering than before, there remains a non-trivial element of knowledge engineering in the encoding of the prior domain knowledge given to the simulated student agent at the start of the learning process. For example, to build an algebra learning agent, the agent developer needs to provide prior knowledge by coding functions that describe, for instance, how to extract a coefficient or how to add two algebraic terms. Such manual encoding of prior knowledge can be time-consuming and the constructed prior knowledge may not naturally correspond with a human student’s prior knowledge.Since real students entering a course do not usually have substantial domain-specific or domain-relevant prior knowl-edge, it is not realistic in a model of human learning to assume this knowledge is given rather than learned. For example, for students learning about algebra, we cannot assume that they all know beforehand what a coefficient is, or what the dif-ference between a variable term and a constant term is. An intelligent system that models automatic knowledge acquisition with a small amount of prior knowledge could be helpful both in reducing the effort in knowledge engineering intelligent systems and in advancing the cognitive science of human learning.Previous work in cognitive science [8,9] showed that one of the key factors that differentiates experts and novices in a field is their different prior knowledge of world state representation. Experts view the world in terms of deep functional fea-tures (e.g., coefficient and constant in algebra), while novices only view in terms of shallow perceptual features (e.g., integer in an expression). Deep features are often domain-specific, whereas shallow perceptual features are domain-independent. Having the correct representation of the deep features aids the process of solving the domain task. For example, in algebra, students need to learn to encode equation input into “terms” and “coefficients”. A shallow feature encoding of a coefficient (e.g., of the “5” in “5x”) is as a number before a letter. A deep feature encoding requires the learner to develop knowl-edge, which may include implicit perceptual processing capabilities, to recognize coefficients more generally such as the “-5” in “-5x”, the “a” in “ax”, the “3” in “3(x+2)”, the “-1” in “-x”. In general, experts develop deep feature knowledge that allows them to see the world in the way novices do not – expert readers see “run” as a word whereas novices see letters or just lines, experts in physics see force contact points whereas novices see blocks and inclined planes, chess experts see configurations of pieces like a knight fork whereas novices see pieces. Such deep feature perception knowledge is learned for specific domains, perhaps as much by implicit experience as by explicit instruction. In algebra, students learn to see terms and coefficients in equations building upon more general prior knowledge of numbers. That prior knowledge may be the basis for initial shallow feature encoding as in the example above. In general, we consider deep features as part of rep-resentation knowledge. Representation knowledge organizes low-level perceptual input into a structured form that assists the agent to understand and solve problems in a particular domain. Even if the same perceptual input was given, for dif-ferent problem solving tasks in different domains, the ideal representation of the world can be different for different tasks. Deep features can be viewed as the key features that differentiate a well-structured representation from a poorly-structured representation.Deep feature learning is a major component of human expertise acquisition, but has not received much attention in AI. Learning deep features changes the representation on which future learning is based and, by doing so, improves future learning. However, how these deep features are acquired is not clear. Therefore, we have recently developed a learning algorithm that acquires deep features automatically with only domain-independent knowledge (e.g., what is an integer) as input [10]. We evaluated the effectiveness of the algorithm in learning deep features, but not its impact on future skill learner.In order to evaluate how the deep feature learner could affect future learning of an intelligent agent, in this paper, we integrated this deep feature learning algorithm into SimStudent [11], an agent that learns problem-solving skills by example and by feedback on performance. The original SimStudent relies on a hand-engineered representation that encodes an expert representation given as prior knowledge. This limits its ability to model novice students. The extended SimStudent first acquires the representation of the problems using the deep feature learner. Then, it makes use of the learned representation to acquire skill knowledge in later tasks. Integrating the deep feature learner into the original SimStudent both reduces the amount of engineering effort and builds a better model of student learning.We show that the extended SimStudent with better representation learning performs much better than the original Sim-Student when neither of them are given domain-specific knowledge. Furthermore, we also show that even compared to the original SimStudent with the domain-specific knowledge, the extended SimStudent is able to learn nearly as well without being given domain-specific knowledge. For the sake of simplicity, we only report experiment results in the algebra domain in this paper, but similar results are also observed in other domains [12]. In addition, we use the extended SimStudent to automatically discover models of real students, and show that the discovered models are better student models than human-generated models [13]. Although not reported here, we further use the extended SimStudent to better understand how problem orders affect learning effectiveness by inspecting SimStudent’s learning processes and learning outcomes, which are not easily obtainable from human subjects [14].To summarize, the main contributions of this paper are two-fold. By integrating representation learning into skill learn-ing, 1) we reduce the amount of knowledge engineering effort required in constructing an intelligent agent; 2) we get a better model of human behavior.In the following sections, we start with a brief review of SimStudent. We then present the deep feature learning algo-rithm together with its evaluation results. Next, we ",
            {
                "entities": [
                    [
                        3130,
                        3158,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 585–596Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInformation loss in knowledge compilation:A comparison of Boolean envelopesPeter Schachte, Harald Søndergaard∗, Leigh Whiting, Kevin HenshallDepartment of Computer Science and Software Engineering, The University of Melbourne, Victoria 3010, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 18 March 2009Received in revised form 14 March 2010Accepted 27 March 2010Available online 1 April 2010Keywords:Boolean approximationCo-clonesKnowledge basesTractable inferenceSince Selman and Kautz’s seminal work on the use of Horn approximation to speed up thequerying of knowledge bases, there has been great interest in Boolean approximation forAI applications. There are several Boolean classes with desirable computational propertiessimilar to those of the Horn class. The class of affine Boolean functions, for example,has been proposed as an interesting alternative to Horn for knowledge compilation. Toinvestigate the trade-offs between precision and efficiency in knowledge compilation,we compare, analytically and empirically, four well-known Boolean classes, and theircombinations, for ability to preserve information. We note that traditional evaluationwhich explores unit-clause consequences of random hard 3-CNF formulas does not tellthe full story, and we complement that evaluation with experiments based on a variety ofassumptions about queries and the underlying knowledge base.© 2010 Elsevier B.V. All rights reserved.1. Introduction: Boolean approximationThe problem of efficient inference from propositional knowledge is of fundamental importance for symbolic reasoning,as used for example in circuit verification. Knowledge compilation, as introduced by Selman and Kautz [16] is a particulartechnique that uses approximations of a knowledge base to speed up querying, at the expense of completeness. As is oftenthe case with powerful ideas, the approach is simple. Let a knowledge base ϕ be given and let ϕ↑be a logical consequence(an upper approximation) of ϕ, with ϕ↑belonging to some class (Horn, for example) of Boolean functions for which thequestion of logical consequence is tractable. For any query α, a positive answer to the question “ϕ↑ |(cid:4) α?” affirms “ϕ |(cid:4) α.”A negative answer is of no help. However, if a lower approximation ϕ↓is also available (as assumed in the Selman–Kautz framework), a negative answer to the question “ϕ↓ |(cid:4) α?” can similarly be used to answer “ϕ |(cid:4) α” in the negative.Otherwise one has to fall back on some standard (expensive) method for resolving “ϕ |(cid:4) α,” or answer “don’t know.”We shall follow Kavvadias et al. [8] and refer to a unique best upper approximation as an “envelope” (and to the dualconcept as a “core”—although we will not need that much, as cores are not well-defined for the classes discussed in thispaper).Three factors determine the effectiveness of knowledge compilation: (1) the time required to compute the approxima-tions, amortised over all queries of the same knowledge base; (2) the time saved by evaluating queries using approxima-tions; and (3) the proportion of queries for which the approximate knowledge base yields a definite answer. The secondfactor is determined by the choice of Boolean function class with tractable inference, and the first by availability of anefficient algorithm for calculating approximations in the class. Both of these aspects have received considerable attention,* Corresponding author. Tel.: +61 3 8344 1342; fax: +61 3 9348 1184.E-mail addresses: schachte@unimelb.edu.au (P. Schachte), harald@unimelb.edu.au (H. Søndergaard), leighwhiting@gmail.com (L. Whiting),kevin.henshall@gmail.com (K. Henshall).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.03.003\f586P. Schachte et al. / Artificial Intelligence 174 (2010) 585–596including in-depth study [10]. Del Val [6] has shown that Selman and Kautz’s Horn envelope algorithm carries over to allBoolean function classes closed under subsumption. He has proposed an improved algorithm that is applicable if, addition-ally, the complement of a class is closed under resolution. Moreover, del Val has discussed the case of first-order predicatelogic, showing how the original concepts can be extended in that direction as well [6].While computational questions have received much attention, less has been said about information loss in knowledgecompilation. In their study, Selman and Kautz [16] analysed how well the generated approximations preserve information.They applied their method to a large number of hard propositional formulas in 3-CNF and analytically derived an estimateof how many queries of the forms x, x ∨ y, and x ∨ y ∨ z could be answered successfully, based on the approximationsalone. The results were very encouraging, particularly as the less expressive class of conjunctive (unit Horn) functions weresubstituted for the Horn class to simplify analysis. One aim of this note is to extend and complement the Selman–Kautzanalysis with an empirical analysis of fidelity, not only for Horn approximations, but also for (upper) Krom, contra-dualHorn, and affine approximations.A second aim is to understand how fidelity varies with underlying assumptions about knowledge bases and queries.Selman and Kautz’s analysis was for random hard 3-CNF knowledge bases. These are strong Boolean functions, close to halfof which are unsatisfiable and lead to unsatisfiable approximations, while the rest typically have relatively few models. Eachapplication of knowledge compilation is different, but it must be expected that some applications involve somewhat weakerBoolean functions, or at least that inconsistent knowledge bases be repaired. How well will approximation to differentclasses preserve information in that setting? Here we empirically measure information loss in approximation to the fourdifferent classes and their combinations, using three different test sources: (1) random Boolean functions, (2) random 3-CNF, including random hard 3-CNF (as in the Selman–Kautz analytical investigation), and (3) structured functions arisingfrom encodings of combinatorial problems. We measure information loss in two different ways: by counting the number ofmodels added in envelopes, and by calculating the fraction of random queries entailed by the original function but not byits approximation. Results from the different experiments are given in Sections 5–7.A third aim is to investigate to what extent combinations of Boolean classes can improve the success rate for acceleratedquery-answering. This question presents itself naturally, owing to this observation (Proposition 2): For any query α whichcan be expressed in 3-CNF, whether a knowledge base ϕ entails α can be decided completely from ϕ’s Horn and contra-dual Horn envelopes. An interesting corollary is that, given the assumptions used in Selman and Kautz’s analysis [16], onecan obtain not just better results by using both envelopes, but perfect ones—100% accuracy is achieved without the needfor any lower approximations. Related conclusions are drawn in Section 8.2. Boolean co-clonesLet B = {0, 1} and let V be a countably enumerable set of variables. A valuation μ : V → B is an assignment of truthvalues to the variables in V . Let I = V → B denote the set of V -valuations. A Boolean function over V is a functionϕ : I → B. We let B denote the set of all Boolean functions over V . The ordering on B is the usual: x (cid:2) y iff x = 0 ∨ y = 1.B is ordered pointwise, so that the ordering relation corresponds exactly to classical entailment, |(cid:4). A valuation μ is a modelfor ϕ, denoted μ |(cid:4) ϕ, if ϕ(μ) = 1. We use the usual connectives, including + for exclusive or. We let (cid:8)x, y, z(cid:9) denote themedian1 operation: (cid:8)x, y, z(cid:9) = (x ∧ y) ∨ (x ∧ z) ∨ ( y ∧ z). These connectives will also be applied to valuations with the obviousintention (pointwise application).In this study we are concerned with the four Schaefer classes [1]:Krom (K): ϕ is Krom iff for all valuations μ, μ(cid:11), (cid:8)μ, μ(cid:11), μ(cid:11)(cid:11)(cid:9) |(cid:4) ϕ whenever μ |(cid:4) ϕ, μ(cid:11) |(cid:4) ϕ, and μ(cid:11)(cid:11) |(cid:4) ϕ. Syntacti-cally, K is the set of functions that can be written in conjunctive normal form with at most two literals per clause,and its members are also referred to as 2-CNF or bijunctive., and μ(cid:11)(cid:11)Horn (H): ϕ is Horn iff for all valuations μ and μ(cid:11)that can be written in conjunctive normal formclause., (μ ∧ μ(cid:11)) |(cid:4) ϕ whenever μ |(cid:4) ϕ and μ(cid:11) |(cid:4) ϕ. H is the set of functions((cid:4)1 ∨ · · · ∨ (cid:4)k), k (cid:3) 0, with at most one positive literal (cid:4) per(cid:2)Contra-dual Horn (N): ϕ is contra-dual2 Horn iff for all valuations μ and μ(cid:11)These are the functions that can be written in conjunctive normal formnegative literal (cid:4) per clause.Affine (A): ϕ is affine iff for all valuations μ, μ(cid:11), and μ(cid:11)(cid:11), (μ + μ(cid:11) + μ(cid:11)(cid:11)) |(cid:4) ϕ whenever μ |(cid:4) ϕ, μ(cid:11) |(cid:4) ϕ, and μ(cid:11)(cid:11) |(cid:4) ϕ [15].A Boolean function is affine iff it can be written as a conjunction of terms c0 + c1x1 + c2x2 + · · · + ckxk, whereci ∈ {0, 1} and xi ∈ V for all i ∈ {0, . . . , k}.3, (μ ∨ μ(cid:11)) |(cid:4) ϕ whenever μ |(cid:4) ϕ and μ(cid:11) |(cid:4) ϕ.((cid:4)1 ∨ · · · ∨ (cid:4)k), k (cid:3) 0, with at most one(cid:2)There are other classes of interest, including k-Horn [4] and k-quasi-Horn, for which envelopes are also well-defined.Some well-studied classes, however, including the class of unate functions and the class of renamable Horn functions, do not1 Or “majority” operation; we prefer the terminology and notation suggested by Knuth [9].2 We follow Halmos [7] in using this term.3 In the cryptography/coding community, “affine” is used for wh",
            {
                "entities": [
                    [
                        3876,
                        3904,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 694–729Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSampleSearch: Importance sampling in presence of determinismVibhav Gogate a,∗,1, Rina Dechter ba Computer Science & Engineering, University of Washington, Seattle, WA 98195, USAb Donald Bren School of Information and Computer Sciences, University of California, Irvine, Irvine, CA 92697, USAa r t i c l ei n f oa b s t r a c tThe paper focuses on developing effective importance sampling algorithms for mixedprobabilistic and deterministic graphical models. The use ofimportance sampling insuch graphical models is problematic because it generates many useless zero weightsamples which are rejected yielding an inefficient sampling process. To address thisrejection problem, we propose the SampleSearch scheme that augments sampling withsystematic constraint-based backtracking search. We characterize the bias introduced bythe combination of search with sampling, and derive a weighting scheme which yields anunbiased estimate of the desired statistics (e.g., probability of evidence). When computingthe weights exactly is too complex, we propose an approximation which has a weakerguarantee of asymptotic unbiasedness. We present results of an extensive empiricalevaluation demonstrating that SampleSearch outperforms other schemes in presence ofsignificant amount of determinism.© 2010 Elsevier B.V. All rights reserved.Article history:Received 31 July 2009Received in revised form 1 October 2010Accepted 21 October 2010Available online 5 November 2010Keywords:Probabilistic inferenceApproximate inferenceImportance samplingMarkov chain Monte CarloBayesian networksMarkov networksSatisfiabilityModel countingConstraint satisfaction1. IntroductionThe paper investigates importance sampling algorithms for answering weighted counting and marginal queries over mixedprobabilistic and deterministic networks [1–4]. The mixed networks framework treats probabilistic graphical models such asBayesian and Markov networks [5], and deterministic graphical models such as constraint networks [6] as a single graphicalmodel. Weighted counts express the probability of evidence of a Bayesian network, the partition function of a Markovnetwork and the number of solutions of a constraint network. Marginals seek the marginal distribution of each variable,also called belief updating or posterior estimation in a Bayesian or Markov network.It is straightforward to design importance sampling algorithms [7–9] for approximately answering counting and marginalqueries because both are variants of summation problems for which importance sampling was designed. Weighted counts isthe sum of a function over some domain while a marginal is a ratio between two sums. The main idea is to transform asummation into an expectation using a special distribution called the proposal (or importance) distribution from which itwould be easy to sample. Importance sampling then generates samples from the proposal distribution and approximates theexpectation (also called the true average or the true mean) by a weighted average over the samples (also called the sampleaverage or the sample mean). The sample mean can be shown to be an unbiased estimate of the original summation, andtherefore importance sampling yields an unbiased estimate of the weighted counts. For marginals, importance sampling hasto compute a ratio of two unbiased estimates yielding an asymptotically unbiased estimate only.* Corresponding author.E-mail addresses: vgogate@cs.washington.edu (V. Gogate), dechter@ics.uci.edu (R. Dechter).1 This work was done when the author was a graduate student at University of California, Irvine.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.009\fV. Gogate, R. Dechter / Artificial Intelligence 175 (2011) 694–729695In presence of hard constraints or zero probabilities, however, importance sampling may suffer from the rejection prob-lem. The rejection problem occurs when the proposal distribution does not faithfully capture the constraints in the mixednetwork. Consequently, many samples generated from the proposal distribution may have zero weight and would not con-tribute to the sample mean. In extreme cases, the probability of generating a rejected sample can be arbitrarily close to oneyielding completely wrong estimates.In this paper, we propose a sampling scheme called SampleSearch to remedy the rejection problem. SampleSearch com-bines systematic backtracking search with Monte Carlo sampling. In this scheme, when a sample is supposed to be rejected,the algorithm continues instead with randomized backtracking search until a sample with non-zero weight is found. Thisproblem of generating a non-zero weight sample is equivalent to the problem of finding a solution to a satisfiability (SAT)or a constraint satisfaction problem (CSP). SAT and CSPs are NP-complete problems and therefore the idea of generatingjust one sample by solving an NP-complete problem may seem inefficient. However, recently SAT/CSP solvers have achievedunprecedented success and are able to solve some large industrial problems having as many as a million variables within afew seconds.2 Therefore, solving a constant number of NP-complete problems to approximate a #P-complete problem suchas weighted counting is no longer unreasonable.We show that SampleSearch generates samples from a modification of the proposal distribution which is backtrack-free.The backtrack-free distribution can be obtained by removing all partial assignments which lead to a zero weight sample. Inparticular, the backtrack-free distribution is zero whenever the target distribution from which we wish to sample is zero.We propose two schemes to compute the backtrack-free probability of the generated samples which is required for com-puting the sample weights. The first is a computationally intensive method which involves invoking a CSP or a SAT solverO (n × d) times where n is the number of variables and d is the maximum domain size. The second scheme approximatesthe backtrack-free probability by consulting information gathered during SampleSearch’s operation. This latter scheme hasseveral desirable properties: (i) it runs in linear time, (ii) it yields an asymptotically unbiased estimate, and (iii) it canprovide upper and lower bounds on the exact backtrack-free probability.Finally, we present empirical evaluation demonstrating the power of SampleSearch. We implemented SampleSearch ontop of IJGP-wc-IS [10], a powerful importance sampling technique which uses a generalized belief propagation algorithm [11]called Iterative Join Graph Propagation (IJGP) [12,13] to construct a proposal distribution and w-cutset (Rao-Blackwellised)sampling [14] to reduce the variance. The search was implemented using the minisat SAT solver [15]. We conducted ex-periments on three tasks: (a) counting models of a SAT formula, (b) computing the probability of evidence in a Bayesiannetwork and the partition function of a Markov network, and (c) computing posterior marginals in Bayesian and Markovnetworks.For model counting, we compared against three approximate algorithms: ApproxCount [16], SampleCount [17] and Rel-sat [18] as well as with IJGP-wc-IS, our vanilla importance sampling scheme on three classes of benchmark instances. Ourexperiments show that on most instances, given the same time-bound SampleSearch yields solution counts which are closerto the true counts by a few orders of magnitude compared with the other schemes. It is clearly better than IJGP-wc-ISwhich failed on all benchmark SAT instances and was unable to generate a single non-zero weight sample in ten hours ofCPU time.For the problem of computing the probability of evidence in a Bayesian network, we compared SampleSearch withVariable Elimination and Conditioning (VEC) [19], an advanced generalized belief propagation scheme called Edge DeletionBelief Propagation (EDBP) [20] as well as with IJGP-wc-IS on linkage analysis [21] and relational [22] benchmarks. Ourexperiments show that on most instances the estimates output by SampleSearch are more accurate than those output byEDBP and IJGP-wc-IS. VEC solved some instances exactly, however on the remaining instances it was substantially inferior.For the posterior marginal task, we experimented with linkage analysis benchmarks, with partially deterministic gridbenchmarks, with relational benchmarks and with logistics planning benchmarks. Here, we compared the accuracy ofSampleSearch against three other schemes: the two generalized belief propagation schemes of Iterative Join Graph Prop-agation [12,13] and Edge Deletion Belief Propagation [20] and an adaptive importance sampling scheme called EvidencePre-propagated Importance Sampling (EPIS) [23]. Again, we found that except for the grid instances, SampleSearch consis-tently yields estimates having smaller error than the other schemes.Based on this large scale experimental evaluation, we conclude that SampleSearch consistently yields very good approxi-mations. In particular, on large instances which have a substantial amount of determinism, SampleSearch yields an order ofmagnitude improvement over state-of-the-art schemes.The paper is based on earlier conference papers [24,25]. The present article contains more detailed and general analysis,full proofs, new bounding approximations (described in Section 4.2.1), as well as new experimental results.The rest of the paper is organized as follows. In Section 2, we present notation and preliminaries on graphical models andimportance sampling. In Section 3, we present the rejection problem and show how to overcome it using the backtrack-freedistribution. Section 4 describes the SampleSearch scheme and various improvements. In Section 5, we present experimentalresults and we conclude in Section 6.2 See results of SAT competitions available at http://www.satcompetition.org/.\f696V. Gogate, R.",
            {
                "entities": [
                    [
                        3794,
                        3822,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 70–94Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstrained clustering by constraint programmingThi-Bich-Hanh Dao∗, Khanh-Chuong Duong, Christel VrainUniv. Orléans, INSA Centre Val de Loire, LIFO, EA 4022, F-45067, Orléans, Francea r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 12 May 2015Accepted 23 May 2015Available online 29 May 2015Keywords:Constrained clusteringBi-criterion clusteringConstraint programmingModelingGlobal optimization constraintFiltering algorithmConstrained Clustering allows to make the clustering task more accurate by integrating user constraints, which can be instance-level or cluster-level constraints. Few works consider the integration of different kinds of constraints, they are usually based on declarative frameworks and they are often exact methods, which either enumerate all the solutions satisfying the user constraints, or find a global optimum when an optimization criterion is specified. In a previous work, we have proposed a model for Constrained Clustering based on a Constraint Programming framework. It is declarative, allowing a user to integrate user constraints and to choose an optimization criterion among several ones. In this article we present a new and substantially improved model for Constrained Clustering, still based on a Constraint Programming framework. It differs from our earlier model in the way partitions are represented by means of variables and constraints. It is also more flexible since the number of clusters does not need to be set beforehand; only a lower and an upper bound on the number of clusters have to be provided. In order to make the model-based approach more efficient, we propose new global optimization constraints with dedicated filtering algorithms. We show that such a framework can easily be embedded in a more general process and we illustrate this on the problem of finding the optimal Pareto front of a bi-criterion constrained clustering task. We compare our approach with existing exact approaches, based either on a branch-and-bound approach or on graph coloring on twelve datasets. Experiments show that the model outperforms exact approaches in most cases.© 2015 Elsevier B.V. All rights reserved.1. IntroductionConstrained Clustering has received much attention this last decade. It allows to make the clustering task more accurate by integrating user constraints. Several kinds of constraints can be considered. First, constraints may be used to limit the size or the diameter of clusters; second, they can enforce expert knowledge instances that must be or cannot be in the same cluster (must-link or cannot-link constraints). Much work has focused on instance-based constraints and has adapted classi-cal clustering methods to handle must-link or cannot-link constraints. A small number of earlier studies have considered the integration of different kinds of constraints. These studies are based on declarative frameworks and offer exact methods that either enumerate all the solutions satisfying the user constraints, or find a global optimum when an optimization criterion is given. For instance, in [1] a SAT based framework for constrained clustering has been proposed, integrating many kinds of user constraints but limited to clustering tasks into two clusters. A framework for conceptual clustering based on Integer Linear Programming has also been proposed in [2]. In [3], we have presented a model based on Constraint Programming for * Corresponding author.E-mail addresses: thi-bich-hanh.dao@univ-orleans.fr (T.-B.-H. Dao), khanh-chuong.duong@univ-orleans.fr (K.-C. Duong), christel.vrain@univ-orleans.fr(C. Vrain).http://dx.doi.org/10.1016/j.artint.2015.05.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\fT.-B.-H. Dao et al. / Artificial Intelligence 244 (2017) 70–9471constrained clustering. This model allows to choose one among different optimization criteria and to integrate various kinds of user constraints. As far as we know, the approach we propose is the only one able to handle different optimization crite-ria and all popular constraints, for any number of clusters. It is based on Constraint Programming (CP): in such a paradigm, a constraint optimization problem or a constraint satisfaction problem is modeled by defining variables with their domains and by expressing constraints on these variables. Solving a CP problem relies on two operations: constraint propagation that reduces the domain of the variables by removing inconsistent values and branching that divides the problem in subprob-lems, by taking an unassigned variable and by splitting its domain into several parts. It is important to notice that modeling a task in Constraint Programming implies several choices, which have a high impact on the efficiency of the approach: the choice of the variables and the choice of the constraints for the model, the development of filtering algorithms dedicated to the task and the use of adapted search strategies for solving the model. A point in favor of CP is that the requirement of getting an exact solution can be relaxed by using metaheuristics or local search methods. For the time being, we have fully investigated exact methods, to push the efficiency of the framework as far as possible. Approximate search strategies could be integrated in the future.In this paper, we propose a new model for Constrained Clustering, still based on Constraint Programming, but signifi-cantly improved compared to the previous model [3]. In the previous model, two sets of variables were introduced, namely a variable for each cluster identifying a cluster by one of its points and a variable for each point expressing its assignment to a cluster. The number of clusters had to be set beforehand. The new model we present here contains only a variable for each point, giving the index of the cluster the point belongs to. As a result, the constraints enforcing the solution to be a partition and breaking symmetries are entirely different. The new model is lighter in terms of the number of variables. It also enables to remove the restriction on the number of clusters; only bounds on the number of clusters are required. Moreover, in order to make this model efficient, we have developed dedicated global constraints for three optimization criteria: minimizing the maximal diameter, maximizing the split between clusters, and minimizing the within-cluster sum of dissimilarities.The approach we propose may be easily embedded in a general process for the task of Constrained Clustering. Consider-ing Data Mining as an iterative and interactive process composed of the classical steps of task formulation, data preparation, application of a tool, thus requiring to set parameters, and validation of the results, a user can specify the task at hand including or not some constraints and decide to change the settings according to the results. He/she may decide to change the constraints, removing or relaxing some constraints, adding or hardening other constraints. The modularity and declara-tivity of our model allow this easily. In this paper, we illustrate the integration of our model in a more complex process by considering a bi-criterion clustering problem, namely finding the Pareto front when minimizing the maximal diameter and maximizing the minimal split. To achieve this, our framework is integrated in an algorithm, which alternatively calls our model to minimize the maximal diameter and then to maximize the split between clusters with adapted constraints.Our contributions are as follows.• We propose a new model based on Constraint Programming, allowing to find an optimal solution for clustering under constraints, given an optimization criterion. This new model improves substantially the previous one, it is more modular (each criterion is implemented by a global constraint) and it is much more efficient.• We show that such a framework can easily be embedded in a more general process and we illustrate this on the problem of finding the optimal Pareto front of a bi-criterion constrained clustering task. As far as we know, this is the first approach to handle bi-criterion clustering in presence of user-constraints.• We propose new global optimization constraints with dedicated filtering algorithms, thus allowing to make the model more efficient.• We compare this model with existing exact approaches, based either on a branch-and-bound approach [4] or on graph coloring [5] on twelve datasets. Experiments show that the model we propose is generally more efficient. Moreover we compare the two models based on CP that we have developed and we show that the different changes (search strategy and development of global constraints) allow to improve the model.The paper is organized as follows. Section 2 is dedicated to preliminaries on Constrained Clustering and Constraint Programming. Related work is presented in Section 3. Section 4 is devoted to the presentation of both CP models, the first one presented in [3] and the new one. The filtering algorithms for the optimization criteria are presented in Section 5. We show in Section 6 how our framework can be easily integrated for solving a bi-criterion constrained clustering task. Experiments are presented in Section 7, showing the performance and the flexibility of our approach.2. Preliminaries2.1. Constrained clusteringCluster analysis is a Data Mining task that aims at partitioning a given set of objects into homogeneous and/or well-separated subsets, called classes or clusters. It is often formulated as the search for a partition such that the objects inside the same cluster are similar, while being different from the objects belonging to other clusters. These requirements are usually expressed by an optimization criterion and the clustering task is usually defined as finding a partition of objects \f72T.-B.-H. Dao et al. / Artificial Intelligenc",
            {
                "entities": [
                    [
                        3762,
                        3790,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 890–913Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLoop-separable programs and their first-order definabilityYin Chen a,∗, Fangzhen Lin b, Yan Zhang c, Yi Zhou ca Department of Computer Science, South China Normal University, Guangzhou, Guangdong, Chinab Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kongc Intelligent Systems Lab, School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiaa r t i c l ei n f oa b s t r a c tAn answer set program with variables is first-order definable on finite structures if the setof its finite answer sets can be captured by a first-order sentence. Characterizing classesof programs that are first-order definable on finite structures is theoretically challengingand of practical relevance to answer set programming. In this paper, we identify a non-trivial class of answer set programs called loop-separable programs and show that they arefirst-order definable on finite structures.© 2010 Elsevier B.V. All rights reserved.Article history:Received 23 December 2009Received in revised form 18 December 2010Accepted 18 December 2010Available online 22 December 2010Keywords:Answer set programmingFirst-order definabilityKnowledge representationNonmonotonic reasoning1. IntroductionThis work is about answer set programming (ASP), a constraint-based programming paradigm that has been foundapplications in a wide range of areas including bioinformatics [9,12,29] and the semantic web [11,27]. Currently in ASPapplications, a program normally has two parts: a finite set of rules with variables, and a finite set of ground facts. Theformer represents general domain knowledge and the latter the specific instance of the problem that one wants to solve.Since current ASP solvers can only deal with rules without variables [14,20,22,28], the latter is used to ground the formerinto a set of propositional rules, and together they are given to an ASP solver.Recently there has been work on extending answer set semantics to programs with variables [4,13,23,25], and to considerthe possibility of constructing an ASP solver that can deal with rules with variables [4]. Against this backdrop, in this paperwe consider the problem of first-order definability of answer set programs with variables. This is a problem because ingeneral, the answer sets of a program with variables correspond to a second-order sentence [13,23] or an infinite set offirst-order sentences [4].The study on non-grounding based method for computing answer sets/stable models has been carried out by someresearchers [10,16]. The motivation of developing this approach is to avoid large sets of facts after grounding a programcontaining variables. By introducing concepts such as constrained non-ground stables [10] and covers/anticovers [16], usingthis approach we can derive some kind of compact representations of the stable models of the original program, so thatstable models may be partially pre-computed at compile-time.Although both the approach mentioned above and the first-order definability of logic programs address non-groundinglogic programs, the foundation of these two topics are actually quite different. In this paper, our study will be based on thefirst-order stable model semantics and identify a class of programs that is first-order definable on finite structures, whilethe non-ground approach only provided an alternative method to compute stable models of a propositional logic program.* Corresponding author.E-mail addresses: ychen@scnu.edu.cn (Y. Chen), flin@cse.ust.hk (F. Lin), yan@scm.uws.edu.au (Y. Zhang), yzhou@scm.uws.edu.au (Y. Zhou).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.12.001\fY. Chen et al. / Artificial Intelligence 175 (2011) 890–913891While our work presented in this paper is the first in-deep study on the first-order definability of answer set programswith variables, we should mention that the related problem has been addressed in propositional case. In particular, Dungand Kanchanasut have shown that every propositional logic program Π can be transformed into a propositional theory T Πsuch that the set of stable models of Π is exactly the set of models of T Π [8]. More recently, Lin and Zhao proved a similarresult by using loop-formulas [22].Studying the first-order definability of answer set programs has both theoretical and practical values. Firstly, since thesemantics of first-order answer set programs is defined based on second-order logic, it becomes an immediate issue tounderstand the expressive power of first-order answer set programs. Results of the first-order definability will providepartial answers to this issue and help us to achieve a better understanding on the difference between first-order answer setprograms and classical first-order logic. Results in this aspect will provide an important theoretical foundation for first-orderanswer set programming.Secondly, as evident from the work in Datalog and finite model theory, proving first-order definability results are usuallyhighly challenging. Very often, new proof techniques have to be developed, which may also be useful for other problemsolving. For instance, as it will be shown in this paper, in order to prove our first-order definability result, we extend theexpansion tree concept in Datalog [3] to ASP and apply it to loop-separable programs. We believe that both the notion ofloop-separable programs and the new expansion tree concept proposed in this paper may be useful for other related studiesin first-order answer set programming.Finally, knowing that a program is first-order definable is certainly helpful if one wants to construct an ASP solver forfirst-order answer set programs. It initiates the possibility of exploiting first-order inference tools, e.g. model generators andtheorem provers, to reason on programs that are first-order reducible. Also, it can be helpful for SAT-based propositionalASP solvers. This is because current SAT-based ASP solvers compute loop formulas incrementally as needed. If we know thatthe given program can be captured by a first-order sentence, then it may be more effective to bypass loop formulas andjust instantiate the first-order sentence on a given instance directly.In this paper, we show that if a program is so-called loop-separable, then it is first-order definable on finite structures.Furthermore, it is decidable whether a program is loop-separable. As we shall see, the notion of loop-separable programsdepends on a careful study of how rules interacts with first-order loops introduced in [4]. It also includes all first-orderdefinable classes of programs that we knew of, like the class of program with finite set of complete loops.The rest of the paper is organized as follows. Section 2 presents basic logic concepts and notions which will be usedin our following study. Section 3 introduces the notion of first-order definability, and Section 4 defines a class of programscalled loop-separable program. Section 5 contains the detailed proof that loop-separable programs are first-order definable.Section 6 considers some special subclasses of loop-separable programs and discusses some related work. Finally, Section 7concludes this paper with some discussions.2. First-order answer set programs with extensional databases2.1. PreliminariesWe consider a second-order language with equality but without function symbols. A vocabulary consists of a finite setof constant symbols and a finite non-empty set of relation symbols including equality =. Given a vocabulary τ , we denote byC(τ ) the sets of constant symbols in τ , and by P(τ ) the set of relation symbols. The notions of term, atom, (first-order orsecond-order) formula and (first-order or second-order) sentence are defined as usual. An atom is called an equality atomif it is an atom of the form t1 = t2, and a proper atom otherwise. We use Var(O) to denote the set of variables occurringin O, which can be a term, atom, formula, sentence or other expressions. Given a vocabulary τ , the unique name assumption(or UNA for short) on τ , denoted by Σuna(τ ) (or Σuna when τ is obvious from the context), is the conjunction of ci (cid:3)= c j forany two different constant ci, c j in C(τ ).¬∀x(Q (x) ⊃ P (x)). For the given tuples of relation symbols P = (P 1, . . . , P k) and P (cid:7) = (P(1 (cid:2) i (cid:2) k) have the same arity, we use P < P (cid:7)Let P and Q be two relation symbols or variables of the same arity. P < Q stands for the formula ∀x(P (x) ⊃ Q (x)) ∧(cid:7)(cid:7)(cid:7)1, . . . , Pk), where all P i and P(cid:2)iki=1(cid:2)ki=1AAAn ), where A is a finite set called the domain of A,A finite structure A of vocabulary τ is a tuple ( A, cm , R1 , . . . , cAA(the interpretation of a k-ary relation symbol R i ) (1 (cid:2) i (cid:2) n),∈ A (the interpretation of constant ci ) (1 (cid:2) i (cid:2) m), and Rciia k-ary relation on A. In the following, we use Dom(A) to denote the domain of structure A. Unless stated otherwise, thedomains of all structures are assumed to be finite in this paper.(cid:7)i(x) ⊃ P i(x)).to denote the formulaGiven two tuples s = (s1, . . . , sn) and ¯t = (t1, . . . , tn) of the same length, we use s = ¯t to denote the formulai=1 si = ti ,and s (cid:3)= ¯t the formula ¬(s = ¯t). A binding is an expression of the form x/t, where x is a variable, and t a term, and asubstitution is a set of bindings containing at most one binding for each variable. If ϕ is a first-order formula (term, tuple ofterms, etc.), and θ a substitution, we denote by ϕθ the result of replacing every free variable in ϕ according to θ .∀x(P i(x) ⊃ P(cid:7)i(x)) ∧ ¬A1 , . . . , R∀x(PGiven a set of variables or relation variables V and a structure A, an assignment σ on V over A is function that assignseach variable in V to a domain element in Dom(A",
            {
                "entities": [
                    [
                        3845,
                        3873,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 483–513www.elsevier.com/locate/artintQuantifying the uncertainty of a belief net response:Bayesian error-bars for belief net inferenceTim Van Allen a, Ajit Singh b, Russell Greiner c,∗, Peter Hooper da Apollo Data Technologies, 12729 N.E. 20th Suite 7, Bellevue, WA 98005, USAb Center for Automated Learning and Discovery, Carnegie Mellon University, Pittsburgh, PA 15213, USAc Department of Computing Science, University of Alberta, Edmonton, Alberta T6G 2E8, Canadad Department of Mathematical and Statistical Sciences, University of Alberta, Edmonton, Alberta T6G 2G1, CanadaReceived 22 June 2006; received in revised form 8 September 2007; accepted 10 September 2007Available online 26 September 2007AbstractA Bayesian belief network models a joint distribution over variables using a DAG to represent variable dependencies and net-work parameters to represent the conditional probability of each variable given an assignment to its immediate parents. Existingalgorithms assume each network parameter is fixed. From a Bayesian perspective, however, these network parameters can be ran-dom variables that reflect uncertainty in parameter estimates, arising because the parameters are learned from data, or because theyare elicited from uncertain experts.Belief networks are commonly used to compute responses to queries—i.e., return a number for P(H = h | E = e). Parameteruncertainty induces uncertainty in query responses, which are thus themselves random variables. This paper investigates this queryresponse distribution, and shows how to accurately model this distribution for any query and any network structure. In particular,we prove that the query response is asymptotically Gaussian and provide its mean value and asymptotic variance. Moreover, wepresent an algorithm for computing these quantities that has the same worst-case complexity as inference in general, and alsodescribe straight-line code when the query includes all n variables. We provide empirical evidence that (1) our approximation ofthe variance is very accurate, and (2) a Beta distribution with these moments provides a very accurate model of the observed queryresponse distribution. We also show how to use this to produce accurate error bars around these responses—i.e., to determine thatthe response to P(H = h | E = e) is x ± y with confidence 1 − δ.© 2007 Elsevier B.V. All rights reserved.Keywords: Bayesian belief network; Variance; Bucket elimination; Credible interval; Error bars1. IntroductionBayesian belief nets (BNs), which provide a succinct model of a joint probability distribution, are used in anever increasing range of applications [13]. They are typically built by first finding an appropriate structure (either byinterviewing an expert, or by selecting a good model from training data), and then using a training sample to estimate* Corresponding author.E-mail addresses: tim@apollodatatech.com (T. Van Allen), ajit+@cs.cmu.edu (A. Singh), greiner@cs.ualberta.ca (R. Greiner),hooper@stat.ualberta.ca (P. Hooper).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.004\f484T. Van Allen et al. / Artificial Intelligence 172 (2008) 483–513the parameters [22]. The resulting belief net is then used to answer queries—e.g., compute the conditional probabilityP(Cancer=true | Smoke=true, Gender=male). These responses clearly depend on the training sample usedto instantiate the parameters, in that different training samples will produce different parameters, which will lead todifferent responses.This paper investigates how variability within a sample induces variance in a query response, and presents a tech-nique for estimating the posterior distribution of the query responses produced by a belief net. Stated informally, ourgoal is an algorithm that takes• a belief net structure that we assume is correct (i.e., an I -map of the true distribution D [34])• a prior distribution over the network parameters Θ• a data sample S generated from D• a query of the form “What is q(Θ) = P(H = h | E = e, Θ)?”and returns both the expected value and the approximate variance of the query response q(Θ), based on the posteriordistribution of parameters given the sample. By using these moments and an appropriate distributional form, weapproximate the density of q(Θ), from which we can produce explicit [L, U ] ⊆ [0, 1] bounds such that 100(1 − δ)%of the posterior density is within the interval. In other words, the algorithm returns both a point-estimate of the answerand error bars around it.(cid:2)There are many other ways to use this variance around a query response. (1) In general, a good classifier shouldminimize Mean Squared Error, which can be expressed as “Bias2 + Variance” [36]. The results in this paper providea way to compute variance, which we then used as part of the Bias2 + Variance measure to estimate the quality ofdifferent belief net structures, when seeking the best classifier. Empirical evidence [18] suggests that this measure is,in fact, one of the most effective discriminative model selection criteria. (2) The maximum likelihood approach tocombining the responses of various independent belief net classifiers Pj involves weighting their respective (mean)probabilities by 1/variance; i.e., P ∗(hi|e) ∝j Pj (hi | e)/varj (hi|e). We [32] show that this works very well inpractice. (3) We could use query variance to detect outliers, as it could help differentiate sampling variation from trueoutliers [33]. (4) In classification, high probability is frequently taken as a proxy for confidence. Error bars provide amore statistically rigorous measure of confidence. For example, imagine we have determined that action1 (e.g., “applytreatmentX”) is optimal if P(+c | e) > 0.5, as this condition means action1 maximizes expected utility (MEU) [27].In the “traditional view”, we would be more comfortable taking action1 for larger values of P(+c | e)—e.g., moreconfident given e(cid:5) if P(+c | e(cid:5)) = 0.7, versus e(cid:5)(cid:5) when P(+c | e(cid:5)(cid:5)) = 0.6. Now imagine we know that P(+c | e(cid:5)) =0.7 ± 0.5 and P(+c | e(cid:5)(cid:5)) = 0.6 ± 0.001. In either case, the MEU response is still to take action1, as the expected utilitydepends only on the expected value of the response, but not on other characteristics of the posterior distribution.However, we should be more confident in taking this action in the second situation, e(cid:5)(cid:5), as there is less “probabilitymass” on the other side of the 0.5 decision boundary. This could also be useful when making decisions in safety-criticalscenarios, as this analysis can help to quantify the chance of a bad outcome, after taking the appropriate action—“gooddecision, bad outcome”. (5) Finally, if an expert is available to also provide the query response, error bars can be usedto validate a given belief net structure. For example, if an expert claims that P(B = 1 | D = 0, C = 1) = 0.5 but ourtechnique asserts that this response is in [0.26, 0.34] with 99% confidence, then we may question the validity of thenetwork. However, if our technique instead asserts that this response is in [0.17, 0.58] with 99% confidence, we maynot need to question the network structure.This paper provides a way to quantify this variance of a response. In particular, we show how to approximatethe posterior distribution of the query response, from which credible intervals (“Bayesian error-bars”) can be readilycomputed. The overall process is shown in Fig. 1. We begin with a network structure, with a prior on its parameters.The COMPUTEPOSTERIOR routine uses a data sample to perform a Bayesian update of this prior, yielding a posteriordistribution over the network parameters. Next, the MEANVAR algorithm calculates the mean and approximate vari-ance of the query response. Finally, the COMPUTEERRORBAR routine uses these moments to produce a model of theposterior distribution of the query response, from which it computes a 1 − δ credible interval. The COMPUTEPOSTE-RIOR and COMPUTEERRORBAR subroutines are well understood; our main contribution is defining and implementingMEANVAR.Section 2 provides the required background: defining belief nets and describing the Bayesian framework we use.This section also describes the COMPUTEPOSTERIOR and COMPUTEERRORBARS steps. Section 3 presents the the-\fT. Van Allen et al. / Artificial Intelligence 172 (2008) 483–513485Fig. 1. Overview of the overall process for computing error bar around the query response.oretical justification for MEANVAR. Given a set of explicitly specified assumptions, we prove that the query responsedistribution is asymptotically univariate Gaussian, and provide a closed-form formula for its asymptotic variance.1This theorem is the basis for our approximation of the posterior distribution.Section 4 presents an algorithm, MEANVAR, for computing these variances: In particular, it first describes the+ algorithm (an extension of the well-known Bucket Elimination algorithm [14]) that computes both theBUCKELIMresponse and also the derivative of the response wrt each of the CPtable entries; MEANVAR uses these derivatives forcomputing our approximation to the variance. This section provides theorems that state that the algorithm is correct,and that its asymptotic computational cost is the same as inference. Appendix A analyzes the special case wherethe query P(H = h | E = e) is “complete”, in that E specifies a value for every variable except H. It also provides astraightforward linear-time algorithm for this case.While our variance approximation is asymptotically accurate, it is not clear whether our error bar algorithm willwork well in practice, especially for a small sample, as our approximation is only first-order, and COMPUTEERROR-BAR inherits the assumption that the posterior query response will be Gaussian. We therefore perform experiments,based on Monte Carlo simulations, over a range of belief net structures and queries. The ",
            {
                "entities": [
                    [
                        3127,
                        3155,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 243 (2017) 26–44Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCCEHC: An efficient local search algorithm for weighted partial maximum satisfiabilityChuan Luo a,b, Shaowei Cai c,∗a Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, Chinab State Key Laboratory of Mathematical Engineering and Advanced Computing, Wuxi 214125, Chinac State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing 100190, Chinad College of Information Science and Technology, Jinan University, Guangzhou 510632, Chinae Institute for Integrated and Intelligent Systems, Griffith University, Brisbane 4111, Australiaf Department of Material Science and Engineering, Massachusetts Institute of Technology, MA 02139, USA, Kaile Su d,e, Wenxuan Huang fa r t i c l e i n f oa b s t r a c tArticle history:Received 13 May 2015Received in revised form 19 October 2016Accepted 14 November 2016Available online 17 November 2016Keywords:Local searchWeighted partial maximum satisfiabilityEmphasis on hard clauses1. IntroductionWeighted maximum satisfiability and (unweighted) partial maximum satisfiability (PMS) are two significant generalizations of maximum satisfiability (MAX-SAT), and weighted partial maximum satisfiability (WPMS) is the combination of the two, with more important applications in practice. Recently, great breakthroughs have been made on stochastic local search (SLS) for weighted MAX-SAT and PMS, resulting in several state-of-the-art SLS algorithms CCLS, Dist and DistUP. However, compared to the great progress of SLS on weighted MAX-SAT and PMS, the performance of SLS on WPMS lags far behind. In this paper, we present a new SLS algorithm named CCEHC for WPMS. CCEHC employs an extended framework of CCLS with a heuristic emphasizing hard clauses, called EHC. With strong accents on hard clauses, EHC has three components: a variable selection mechanism focusing on configuration checking based only on hard clauses, a weighting scheme for hard clauses, and a biased random walk component. Extensive experiments demonstrate that CCEHC significantly outperforms its state-of-the-art SLS competitors. Further experimental results on comparing CCEHC with a state-of-the-art complete solver show the effectiveness of CCEHC on a number of application WPMS instances, and indicate that CCEHC might be beneficial in practice. Also, empirical analyses confirm the effectiveness of each component underlying the EHC heuristic.© 2016 Elsevier B.V. All rights reserved.The maximum satisfiability (MAX-SAT) problem is the optimization version of the Boolean satisfiability (SAT) problem, which is a prototypical NP-complete problem and is of great importance in a variety of fields of computer science, mathe-matical logic and artificial intelligence. In the context of the SAT and MAX-SAT problems, a propositional formula F is usually (cid:3)expressed in conjunctive normal form (CNF) [1], i.e., F =j lij, where each lij is a literal, which is either a Boolean vari-able or its negation. A CNF formula can be expressed as a set of clauses, where a clause is a disjunction of literals, and each CNF formula is a conjunction of clauses.(cid:2)i* Corresponding author.E-mail addresses: chuanluosaber@gmail.com (C. Luo), shaoweicai.cs@gmail.com (S. Cai), k.su@griffith.edu.au (K. Su), key01027@mit.edu (W. Huang).http://dx.doi.org/10.1016/j.artint.2016.11.0010004-3702/© 2016 Elsevier B.V. All rights reserved.\fC. Luo et al. / Artificial Intelligence 243 (2017) 26–4427Given a propositional formula in conjunctive normal form (CNF), the SAT problem is to decide whether an assignment exists such that all clauses in this CNF formula are satisfied; the MAX-SAT problem is to seek out an assignment that maximizes the number of satisfied clauses in the CNF formula; the weighted MAX-SAT problem, where each clause is associated with a positive integer as its weight, is to find an assignment that maximizes the total weight of satisfied clauses, and is an important generalization of MAX-SAT; the (unweighted) partial maximum satisfiability (PMS) problem, where clauses are divided into hard ones and soft ones, is to find an assignment that satisfies all hard clauses and maximizes the number of satisfied soft clauses, and is also an important generalization of MAX-SAT. The weighted partial maximum satisfiability (WPMS) problem is the combination of both weighted MAX-SAT and PMS, and is a significant generalization of MAX-SAT: Given a CNF formula, the WPMS problem, where clauses are divided into hard ones and soft ones, and each soft clause is associated with a positive integer as its weight, is to seek out an assignment that satisfies all hard clauses and maximizes the total weight of satisfied soft clauses. In theory, MAX-SAT and its generalizations (i.e., weighted MAX-SAT, PMS and WPMS), are typically NP-hard problems, and it is well known that optimal solutions to these problems are hard to approximate [2]. Thus, it is very interesting to explore high-performance heuristic procedures to solve these hard problems. In this paper, our focus is on the WPMS problem.In practice, as many combinatorial problems in real-world applications usually contain hard and soft constraints [3] and also soft constraints often have different priorities, encoding such real-world problems into the WPMS problem is more natural and direct than encoding them into SAT, MAX-SAT, weighted MAX-SAT or PMS. In fact, many important realistic problems in a wide range of real-world applications, such as computational protein design [4,5], set covering [6], coalition structure generation [7] and so on, can be encoded and solved as WPMS instances.There are two popular categories of practical algorithms for solving MAX-SAT: complete algorithms and stochastic local search (SLS) algorithms. Complete algorithms are able to prove the optimality of the solution, but they may not return a good-quality solution for large-sized instances within reasonable time [8]. Complete algorithms can be classified into two main classes: branch and bound MAX-SAT algorithms [9–11] which are based on DPLL procedures [12,13], and SAT based algorithms [14–16] which successively call an efficient CDCL (Conflict-Driven Clause Learning) SAT solver [17,18]. Although SLS algorithms are typically incomplete, i.e., they do not guarantee the optimality of the solutions they find, SLS algorithms are often able to find good-quality solutions within a reasonable time frame [19,3]. SLS algorithms are usually evolving out of GSAT [20] and WalkSAT [21]. However, there is little work on SLS algorithms for solving WPMS, and almost all of the existing solvers for solving WPMS are complete ones.Recently, significant breakthroughs have been achieved on SLS algorithms for solving weighted MAX-SAT and PMS, re-sulting in state-of-the-art SLS algorithms namely CCLS [22] and Dist [3] as well as Dist’s improvement DistUP [23]. The CCLSalgorithm makes great progress in solving weighted MAX-SAT. CCLS won several categories in the incomplete solver track of the MAX-SAT Evaluations 2013 and 2014, thanks to the configuration checking strategy [24], which has been successfully applied to SAT [25] and minimum vertex cover [26]. The CCLS algorithm can be used to solve WPMS by translating WPMS into weighted MAX-SAT, as the translation can be very straightforward via setting the weight of each hard clause to the total weight of all soft clauses plus 1. However, when it comes to the WPMS problem, CCLS loses its power and shows ineffec-tiveness, as can be seen from the competition results of the incomplete solver track of the MAX-SAT Evaluation 2014.1 The Dist algorithm shows great success on solving PMS, and won several categories in the incomplete solver track of the MAX-SAT Evaluation 2014, and also competes well with state-of-the-art complete algorithms on some classes of PMS application instances, such as advanced encryption standard and protein [3]. Dist can also be adapted to solve WPMS, and is indeed the current best SLS algorithm for solving WPMS, winning the random WPMS category and the crafted WPMS category in the incomplete solver track of the MAX-SAT Evaluation 2014. Particularly, the competition results of the MAX-SAT Evaluation 2014 show that Dist performs better than several state-of-the-art complete algorithms on the crafted WPMS benchmark. The DistUP algorithm, an improvement of Dist by using unit propagation as its initialization procedure, shows improvement over Dist on industrial instances. However, CCLS, Dist and DistUP are not dedicated to solving WPMS specifically, and their performance for solving WPMS could be further improved. Compared to the great progress of SLS algorithms on solving weighted MAX-SAT and PMS, the performance of SLS algorithms on solving WPMS lags far behind. This motivates us to design a more efficient SLS algorithm for solving WPMS. Inspired by the success of Dist as well as DistUP, our ambition is to solve more classes of structured problems and real-world ones.In this work, we present a new SLS algorithm named CCEHC (Configuration Checking with Emphasis on Hard Clauses) for solving WPMS. Our CCEHC algorithm employs an extended framework of CCLS with a heuristic emphasizing hard clauses, called EHC. With strong focus on hard clauses, the EHC heuristic has three components: a variable selection mechanism focusing on a forbidding mechanism of configuration checking based only on hard clauses, a weighting scheme for hard clauses, and an approach of biased random walk. Our main contributions in this paper are summarized as follows.Firstly, we identify an efficient algorithm framework for solving WPMS. It is surprising that our algorithm framework is based on CCLS instead of Dist, though CCLS shows worse performance on solving WPMS compared to Dist.Secondly, we propose a new variable selection mechanism focusing on a ",
            {
                "entities": [
                    [
                        3455,
                        3483,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 252 (2017) 267–294Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe first international competition on computational models of argumentation: Results and analysis ✩Matthias Thimm a,∗a Institute for Web Science and Technologies, Universität Koblenz–Landau, Germanyb Université Côte d’Azur, CNRS, Inria, I3S, France, Serena Villata ba r t i c l e i n f oa b s t r a c tArticle history:Received 14 June 2016Received in revised form 15 June 2017Accepted 18 August 2017Available online 30 August 2017Keywords:Formal argumentationAlgorithmsWe report on the First International Competition on Computational Models of Argumenta-tion (ICCMA’15) which took place in the first half of 2015 and focused on reasoning tasks in abstract argumentation frameworks. Performance of submitted solvers was evaluated on four computational problems wrt. four different semantics relating to the verification of the acceptance status of arguments, and computing jointly acceptable sets of arguments. In this paper, we describe the technical setup of the competition, and give an overview on the submitted solvers. Moreover, we report on the results and discuss our findings.© 2017 Elsevier B.V. All rights reserved.1. IntroductionArgumentation is a core technique for humans to reach conclusions in the presence of conflicting information and mul-tiple alternatives. It is used both as a means for persuasion in dialogues as well as one owns deliberation mechanism. An argument can be regarded as some concise set of pieces of information that supports a certain conclusion, such as “As Tweety is a bird and birds usually fly, Tweety supposedly flies”. Arguments may support contradicting conclusions—consider e.g. “As Tweety is a penguin and penguins do not fly, Tweety does not fly despite the fact that he is a bird”—and the pro-cess of argumentation aims at comparing and weighing arguments and counterarguments and ultimately deciding which arguments prevail. While the field of argumentation theory [96] studies the structure and interaction of arguments from a philosophical perspective, within artificial intelligence, the field of computational models of argumentation [6,8] has gained some attention in recent years. In general, this field is concerned with logical formalizations of models of argumentation that can be used by automatic reasoning systems to cope with uncertainty and inconsistency. Thus, these models are closely related to approaches to non-monotonic reasoning and offer a novel perspective on those. After some earlier works of e.g. Pollock [82] and Simari & Louie [87], abstract argumentation frameworks have been proposed by Dung [35] as a general and abstract formalism to represent arguments and their interactions and have, since then, been most influential. In abstract ar-gumentation frameworks, arguments are represented as vertices in a directed graph and an arc from a vertex A to a vertex B means that A is a counterargument for B or that A “attacks” B. Thus, this model abstracts from most issues of argu-mentation scenarios—including the inner structure of arguments—and provides a clean formal view on the issue of conflict between arguments. Given an abstract argumentation framework the central question is to decide whether arguments are acceptable, i.e., whether they “survive” the attacks of their counterarguments due to backing by other arguments. A set of jointly acceptable arguments is then also called extension.✩This paper was submitted to the Competition Section of the journal.* Corresponding author.E-mail address: thimm@uni-koblenz.de (M. Thimm).http://dx.doi.org/10.1016/j.artint.2017.08.0060004-3702/© 2017 Elsevier B.V. All rights reserved.\f268M. Thimm, S. Villata / Artificial Intelligence 252 (2017) 267–294Abstract argumentation provides a nice framework to discuss issues of non-monotonic reasoning in general as many other non-monotonic formalisms such as default theory and logic programs under the stable model semantics can be cast into abstract argumentation frameworks, cf. [35]. On the other hand, the multitude of different semantics and extensions go beyond the expressivity of previous formalisms and provide a novel general approach to non-monotonic reasoning, cf. e.g. [39]. This makes abstract argumentation frameworks a versatile knowledge representation formalism. Many research topics have been spawned around these frameworks including, among others, semantical issues [4], extensions on support [31], quantitative approaches [38,90,65], and in particular algorithms [30]. The computational challenges of various reasoning problems are vast and range up to the second level of the polynomial hierarchy for certain semantics [40,44]. Among the first implementations for reasoning with abstract argumentation frameworks—which appeared around 2008—were Dungine [88] and ASPARTIX [47]. More followed in the years after and, starting from 2013 up till now, a number of comparative analyses among argumentation solvers have been conducted, e.g., [42,10,43,95,11,12,14,27], in order to address a systematic performance comparison. Following the tradition of the communities of other approaches to knowledge representation and reasoning, such as the SAT and the Answer Set Programming (ASP) communities, a public competition for solver evaluation was planned soon after.This paper reports on the First International Competition on Computational Models of Argumentation (ICCMA’15) which took place in the first half of 2015. The results of the competition had been officially presented at the International Work-shop on Theory and Applications of Formal Argument (TAFA’15) which was co-located with the 24th International Joint Conference on Artificial Intelligence (IJCAI’15) in Buenos Aires, Argentina. The competition called for solvers on four classical computational problems in abstract argumentation frameworks wrt. the four classical semantics proposed in [35], includ-ing enumerating all extensions of a particular semantics and deciding whether a certain argument is contained in all of them. Submitted solvers were evaluated wrt. their runtime performance on these tasks on a series of artificially generated argumentation frameworks.Abstract argumentation frameworks are arguably the most investigated formalism for formal argumentation. However, there are also formalisms for structured argumentation, such as deductive argumentation [8] and defeasible logic program-ming [55]. In structured argumentation, arguments are a set of (e.g. propositional) formulas (the support of an argument) that derive a certain conclusion (the claim of an argument). The attack relation between arguments is then derived from logical inconsistency. For ICCMA’15 only problems of abstract argumentation have been considered as this is simple and well-understood formalism for representing computational argumentation. However, considering tracks on structured argu-mentation may be a worthwhile endeavor for future competitions.The competition received 18 solvers from research groups in Austria, China, Cyprus, Finland, France, Germany, Italy, Romania, and the UK. The solvers were based on different approaches and algorithmic design patterns to solve problems, ranging from reductions to SAT or ASP problems to novel heuristic algorithms. This paper gives an overview on the setup of the competition, the submitted solvers, and the results. More specifically, the remainder of this paper is organized as follows. In Section 2 we provide some necessary background on abstract argumentation and give an overview on the computational tasks considered in the competition. In Section 3 we describe the technical setup of the competition, including the approach for benchmark generation, the used evaluation methodology, and the technical interface requirements. In Section 4 we give an overview on the submitted solvers. Afterwards, we present and analyze the results of the competition in Section 5 and we discuss the lessons learned from this first experience in Section 6. We conclude with a summary in Section 7. Appendix Aprovides pseudo code of the graph generators used for creating the benchmark graphs of the competition. Appendix B gives detailed graph-theoretic statistics on the benchmark graphs.2. Background and competition overviewIn the following, we give a brief overview on abstract argumentation, the computational problems considered in the competition, and some brief overviews on answer set programming and satisfiability solving. The latter are intended to provide some formal background on the inner workings of solvers based on reductions to those.2.1. Abstract argumentationAbstract argumentation frameworks [35] take a very simple view on argumentation as they do not presuppose any internal structure of an argument. Abstract argumentation frameworks only consider the interactions of arguments by means of an attack relation between arguments.Definition 1 (Abstract argumentation framework). An abstract argumentation framework AF is a tuple AF = (Arg, →) where Argis a set of arguments and → is a relation → ⊆ Arg × Arg.For two arguments A, B ∈ Arg the relation A → B means that argument A attacks argument B. Abstract argumentation frameworks can be concisely represented by directed graphs, where arguments are represented as nodes and edges model the attack relation. Note that we only consider finite argumentation frameworks here, i.e., argumentation frameworks with a finite number of arguments.\fM. Thimm, S. Villata / Artificial Intelligence 252 (2017) 267–294269Fig. 1. A simple argumentation framework.Example 1. Consider the abstract argumentation framework AF = (Arg,→) depicted in Fig. 1. Here it is Arg = {A1, A2, A3,A4, A5} and → = {(A2, A1), (A2, A3), (A3, A4), (A4, A5), (A5, A4), (A5, A3), (A5, A6), (A6, A6)}.Semantics are usually given to abstract argumentation frameworks by means of extensions [35]. An extension E of an argumentatio",
            {
                "entities": [
                    [
                        3672,
                        3700,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 204–233www.elsevier.com/locate/artintA logical approach to efficient Max-SAT solving ✩Javier Larrosa a,∗, Federico Heras a, Simon de Givry ba Universitat Politecnica de Catalunya, Barcelona, Spainb INRA, Toulouse, FranceReceived 2 August 2006; received in revised form 11 May 2007; accepted 15 May 2007Available online 29 May 2007AbstractWeighted Max-SAT is the optimization version of SAT and many important problems can be naturally encoded as such. Solvingweighted Max-SAT is an important problem from both a theoretical and a practical point of view. In recent years, there has beenconsiderable interest in finding efficient solving techniques. Most of this work focuses on the computation of good quality lowerbounds to be used within a branch and bound DPLL-like algorithm. Most often, these lower bounds are described in a proceduralway. Because of that, it is difficult to realize the logic that is behind.In this paper we introduce an original framework for Max-SAT that stresses the parallelism with classical SAT. Then, we extendthe two basic SAT solving techniques: search and inference. We show that many algorithmic tricks used in state-of-the-art Max-SATsolvers are easily expressible in logical terms in a unified manner, using our framework.We also introduce an original search algorithm that performs a restricted amount of weighted resolution at each visited node. Weempirically compare our algorithm with a variety of solving alternatives on several benchmarks. Our experiments, which constituteto the best of our knowledge the most comprehensive Max-SAT evaluation ever reported, demonstrate the practical usability of ourapproach.© 2007 Elsevier B.V. All rights reserved.Keywords: Max-SAT; Search; Inference1. IntroductionWeighted Max-SAT is the optimization version of the SAT problem and many important problems can be naturallyexpressed as such. They include academic problems such as Max-Cut or Max-Clique, as well as real problems indomains like routing [3], bioinformatics [4], scheduling [5], probabilistic reasoning [6] and electronic markets [7].In recent years, there has been a considerable effort in finding efficient exact algorithms. These works can be dividedinto theoretical [8–10] and empirical [11–15]. A common drawback of all these algorithms is that in spite of theclose relationship between SAT and Max-SAT, they cannot be easily described with logic terminology. For instance,✩ This paper includes and extends preliminary work from [J. Larrosa, F. Heras, Resolution in Max-SAT and its relation to local consistency forweighted CSPs, in: Proc. of the 19th IJCAI, Edinburgh, UK, 2005, pp. 193–198; J. Larrosa, F. Heras, New inference rules for efficient Max-SATsolving, in: Proc. of AAAI-06, Boston, MA, 2006].* Corresponding author.E-mail addresses: larrosa@lsi.upc.edu (J. Larrosa), fheras@lsi.upc.edu (F. Heras), degivry@toulouse.inra.fr (S. de Givry).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.006\fJ. Larrosa et al. / Artificial Intelligence 172 (2008) 204–233205the contributions of [11–14] are good quality lower bounds to be incorporated into a depth-first branch and boundprocedure. These lower bounds are mostly defined in a procedural way and it is very difficult to see the logic that isbehind the execution of the procedure. This is in contrast with SAT algorithms where the solving process can be easilydecomposed into atomic logical steps.In this paper we introduce an original framework for (weighted) Max-SAT in which the notions of upper andlower bound are incorporated into the problem definition. Under this framework classical SAT is just a particularcase of Max-SAT, and the main SAT solving techniques can be naturally extended. In particular, we extend the basicsimplification rules (for example, idempotency, absorption, unit clause reduction, etc.) and introduce a new one,hardening, that does not make sense in the SAT context. We also extend the two fundamental SAT algorithms: DPLL(based on search) and DP (based on inference). We also show that the complexity of the extension of DP is exponentialon the formula’s induced width (which is hardly a surprise, since this is also the case of other inference algorithms forgraphical models [16,17]). Interestingly, our resolution rule includes, as special cases, many techniques spread overthe recent Max-SAT literature. One merit of our framework is that it allows to see all these techniques as inferencerules that transform the problem into an equivalent simpler one, as it is customary in the SAT context.The second contribution of this paper is more practical. We introduce an original search algorithm that incorporatesthree different forms of resolution at each visited node: neighborhood resolution, chain resolution and cycle resolution.Our experimental results on a variety of domains indicate that our algorithm is generally much more efficient than itscompetitors. This is especially true as the ratio between the number of clauses and the number of variables increases.Note that these are typically the hardest instances for Max-SAT. Our experiments include random weighted andunweighted Max-SAT, Max-One, Max-Cut, Max-Clique, and combinatorial auctions.The structure of the paper is as follows: In Section 2 we review SAT terminology. In Section 3 we present Max-SAT and introduce our framework. In Section 4 we extend the essential solving techniques from SAT to Max-SAT.Section 5 summarizes in a unified way several specialized forms of resolution that can be used to simplify Max-SATformula. Section 6 describes our solver. Section 7 reports our experimental work, which corroborate the efficiency ofour solver compared to other state-of-the-art solving alternatives. Section 8 discusses related work. Finally, Section 9concludes and points out directions of future work.2. Preliminaries on SATIn the sequel X = {x1, x2, . . . , xn} is a set of Boolean variables. A literal is either a variable xi or its negation ¯xi .The variable to which literal l refers is noted var(l) (namely, var(xi) = var( ¯xi) = xi ). If variable xi is assigned totrue literal xi is satisfied and literal ¯xi is falsified. Similarly, if variable xi is instantiated to false, literal ¯xi is satisfiedand literal xi is falsified. An assignment is complete if it gives values to all the variables in X (otherwise it is partial).A clause C = l1 ∨ l2 ∨ · · · ∨ lk is a disjunction of literals such that ∀1(cid:2)i,j (cid:2)k, i(cid:5)=j var(li) (cid:5)= var(lj ). It is customaryto think of a clause as a set of literals, which allows to use the usual set operations. If x ∈ C (resp. ¯x ∈ C) we saythat x appears in the clause with positive (resp. negative) sign. The size of a clause, noted |C|, is the number ofliterals that it has. var(C) is the set of variables that appear in C (namely, var(C) = {var(l) | l ∈ C}). An assignmentsatisfies a clause if and only if it satisfies one or more of its literals. Consequently, the empty clause, noted (cid:2), cannotbe satisfied. Conversely, a clause which contains the negation of the empty clause, noted ¬(cid:2), is always satisfiedand can be discarded. Sometimes it is convenient to think of clause C as its equivalent C ∨ (cid:2). A logical formulaF in conjunctive normal form (CNF) is a conjunction of different clauses, normally expressed as a set. A satisfyingcomplete assignment is called a model of the formula. Given a CNF formula, the SAT problem consists in determiningwhether there is any model for it or not. The empty formula, noted ∅, is trivially satisfiable. A formula containing theempty clause is trivially unsatisfiable and we say that it contains an explicit contradiction.2.1. Graph concepts [18]The structure of a CNF formula F can be described by its interaction graph G(F) containing one vertex associatedto each Boolean variable. There is an edge for each pair of vertices that correspond to variables appearing in the sameclause. Given a graph G and an ordering of its vertices d, the parents of a node xi is the set of vertices connected toxi that precede xi in the ordering. The width of xi along d is the number of parents that it has. The width of the graphalong d, denoted wd , is the maximum width among the vertices.\f206J. Larrosa et al. / Artificial Intelligence 172 (2008) 204–233Fig. 1. On the left, a graph G. On the right, the induced graph G∗d where d is the lexicographic order.The induced graph of G(F) along d, denoted G∗d (F), is obtained as follows: The vertices of G are processedfrom last to first along d. When processing vertex xi , we connect every pair of unconnected parents. The inducedwidth of G along d, denoted w∗d , is the width of the induced graph. The induced width (also known as tree-width,k-tree number or the dimension of the graph) is a measure of how far a graph is from acyclicity and it is a fundamentalstructural parameter in the characterization of many combinatorial algorithms. Computing the ordering d that providesthe minimum induced width is an NP-hard problem [19].Example 1. Consider the formula F = { ¯x1 ∨ x4, x1 ∨ x4, x2 ∨ x3, x2 ∨ x4, x2 ∨ ¯x5, x4 ∨ x5}. Its interaction graph G(F)is depicted in Fig. 1(a). The induced graph G∗d along the lexicographical order is depicted in Fig. 1(b). Dotted edge(x1, x2) is the only new edge with respect to the original graph. When processing node x5, no new edges are added,because the parents x2 and x4 of x5 are already connected. When processing node x4, the edge connecting x2 and x1 isadded because both variables are parents of x4 and they were not connected. When processing x3, x2 and x1, no newedges are added. The induced width w∗d is 2 because nodes x5 and x4 have width 2 (namely, they have two parents) inthe induced graph.2.2. SAT algorithmsCNF formulas can be simplified using equivalences or reductions. Well known equivalences are idempotencyC ∧ C ≡ C, absorption C ∧ (C ∨ B) ≡ C and unit clause reduction l ∧ (¯l ∨ C)",
            {
                "entities": [
                    [
                        3009,
                        3037,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 619–637Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPanlingual lexical translation via probabilistic inference∗MausamMarcus Sammer, Jeff Bilmes, Stephen Soderland, Oren Etzioni, Daniel S. Weld, Kobi Reiter 1, Michael Skinner 1,Department of Computer Science and Engineering, Box 352350, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 23 June 2009Received in revised form 8 April 2010Accepted 8 April 2010Available online 10 April 2010Keywords:Lexical translationMultilingualityThis paper introduces a novel approach to the task of lexical translation between languagesfor which no translation dictionaries are available. We build a massive translation graph,automatically constructed from over 630 machine-readable dictionaries and Wiktionaries.In this graph each node denotes a word in some language and each edge (v i, v j) denotesa word sense shared by v i and v j . Our current graph contains over 10,000,000 nodes andexpresses more than 60,000,000 pairwise translations.The composition of multiple translation dictionaries leads to a transitive inference problem:if word A translates to word B which in turn translates to word C , what is the probabilitythat C is a translation of A? The paper describes a series of probabilistic inferencealgorithms that solve this problem at varying precision and recall levels. All algorithmsenable us to quantify our confidence in a translation derived from the graph, and thustrade precision for recall.We compile the results of our best inference algorithm to yield PanDictionary, a novelmultilingual dictionary. PanDictionary contains more than four times as many translationsas in the largest Wiktionary at precision 0.90 and over 200,000,000 pairwise translationsin over 200,000 language pairs at precision 0.8.© 2010 Elsevier B.V. All rights reserved.1. IntroductionIn the era of globalization, inter-lingual communication is becoming increasingly important. Nearly 7000 languages are inuse today [18] necessitating machine translation (MT) systems between about 49 million language-pairs. In contrast popularMT systems like Google Translate handle only on the order of a thousand language pairs. It is difficult to see how statisticalMachine Translation (MT) methods can scale to this large number of language pairs, since they depend on aligned corpora,which are very expensive to generate, and are available at the requisite scale for only a tiny number of language pairs[5,28,33,30,7].This paper considers scaling MT in the context of a far easier task: lexical translation. Lexical translation is the task oftranslating individual words or phrases (e.g., “sweet potato”) from one language to another. Because lexical translation doesnot require aligned corpora as input, it is feasible for a much broader set of languages than statistical MT. While lexicaltranslation has a long history (cf. [24,20,9,23]), interest in it peaked in the 1990s. Yet, as this paper shows, the proliferationof Machine-Readable Dictionaries (MRDs) and the rapid growth of multilingual Wiktionaries offers the opportunity to scalelexical translation to an unprecedented number of languages.* Corresponding author. Tel.: +1 206 685 1964; fax: +1 206 543 2969.E-mail address: mausam@cs.washington.edu (Mausam).1 Current address: Google Inc., 651 N 34th St., Seattle, WA 98105, USA.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.020\f620Mausam et al. / Artificial Intelligence 174 (2010) 619–637Fig. 1. A fragment of the translation graph for two senses of the English word ‘spring’. Edges labeled ‘1’ and ‘3’ are for spring in the sense of a season, and‘2’ and ‘4’ are for the flexible coil sense. The graph shows translation entries from an English dictionary merged with ones from a French dictionary.Of course, lexical translation cannot replace statistical MT, but it is useful for several applications, including the trans-lation of search-engine queries, meta-data tags,2 library classifications and recent applications like cross-lingual imagesearch [11] of http://www.panimages.org, and enhancement of multilingual Wikipedias [1]. Also, lexical translation is a valu-able component in knowledge-based Machine Translation (MT) systems, e.g., [4,6]. The increasing international adoption ofthe Web yields opportunities for new applications of lexical translation systems.The fundamental contribution of this paper is a novel approach to lexical translation, which automatically compilesvarious machine-readable multilingual and bilingual dictionaries available on the Web into a unique translation graph. A nodev in the translation graph represents a word in a particular language. An edge (v i, v j) denotes a word sense shared by v iand v j . Fig. 1 shows a snippet of the translation graph. We demonstrate that inference over this translation graph can yielda massive, multilingual dictionary with coverage superior to the union of input dictionaries at comparable precision.Inference over the translation graph necessitates matching word senses across multiple, independently-authored dictio-naries. For example, if one dictionary says that ‘udaherri’ and ‘printemps’ translate ‘spring’ another says that ‘koanga’ and‘spring’ are translations of ‘printemps’, then we need to infer whether the two dictionaries are referring to the same sense –resulting in ‘udaherri’ a translation of ‘koanga’, or not (see Fig. 1). Because of the millions of translations in the dictionaries,a feasible solution to this sense matching problem has to be scalable; because sense matches are imperfect and uncertain, thesolution has to be probabilistic. The key technical contribution of this paper is a set of methods that perform probabilisticsense matching to infer lexical translations between two languages that do not share a translation dictionary. For example,our algorithm can conclude that the Basque word ‘udaherri’ is a translation of the Maori word ‘koanga’.We presentthree differenttechniques for probabilistic inference – TransGraph, unpruned SenseUniformPaths(uSenseUniformPaths) and SenseUniformPaths. TransGraph uses heuristic-based formulae for inference, while the second,uSenseUniformPaths, reasons about graph topology via random walks and probabilistic graph sampling. SenseUniform-Paths adds constraints based on the graph topology on uSenseUniformPaths that improve precision.We use SenseUniformPaths to construct PanDictionary – a novel lexical resource that spans over 200 million pairwisetranslations in over 200,000 language pairs at 0.8 precision, a four-fold increase when compared to the union of its inputtranslation dictionaries.This paper combines and extends our previous two papers [11,31] and overall, makes the following contributions:1. We introduce a novel approach to the task of lexical translation, which compiles a large number of machine readabledictionaries in a single resource called a translation graph. We employ probabilistic reasoning and inference over thetranslation graph to infer translations that are not expressed by any of the input dictionaries.2. We develop three inference algorithms: TransGraph, unpruned SenseUniformPaths, and SenseUniformPaths. All thesealgorithms return new translations with associated confidence values, so we can trade precision for recall. We empiri-cally compare the three algorithms and find that SenseUniformPaths outperforms the others by returning many moretranslations at high precisions.3. We use SenseUniformPaths to compile PanDictionary – a massive, sense-distinguished multilingual dictionary. Ourempirical evaluations show that depending on the desired precision PanDictionary is 4.5 to 24 times larger than theEnglish Wiktionary (http://en.wiktionary.org). Moreover, it expresses about 4 times the number of pairwise translationscompared to the union of its input dictionaries (at precision 0.8).The remainder of the paper is organized as follows. Section 2 introduces the construction of the translation graph. Wedescribe the three methods for inference and compare them in Section 3. Section 4 describes the compilation of PanDic-2 Meta-data tags appear in community Web sites such as http://flickr.com and http://del.icio.us.\fMausam et al. / Artificial Intelligence 174 (2010) 619–637621tionary and compares its coverage with the English Wiktionary. Section 5 considers related work on lexical translation. Thepaper concludes in Sections 7 and 6 with conclusions and directions for future work.2. The translation graphThis section describes the properties of translation graph and its construction from multiple dictionaries. The translationgraph is an undirected graph defined as a triple (cid:3)V, E, Ψ (cid:4).V and E denote the usual sets of vertices and edges. Each vertex v ∈ V in the graph is an ordered pair (w, l) where w isa word in a language l. Undirected edges in the graph denote translations between words: an edge e ∈ E between (w 1, l1)and (w 2, l2) represents the belief that w 1 and w 2 share at least one word sense. Additionally, an edge is labeled by aninteger denoting an ID for the word sense. Ψ is a set of inequality constraints between sense IDs. It is a set of pairs of senseIDs, such that if the pair (cid:3)id1, id2(cid:4) ∈ Ψ then the senses represented by the IDs are known to be distinct, i.e., they representdifferent word senses.Fig. 1 shows a fragment of a translation graph, which was constructed from two sets of translations for the word ‘spring’from an English Wiktionary, and two corresponding entries from a French Wiktionary for ‘printemps’ (spring season) and‘ressort’ (flexible spring). Translations of the season ‘spring’ have edges labeled with sense ID = 1, the flexible coil sense hasID = 2, translations of ‘printemps’ have ID = 3, and so forth. For this fragment Ψ = {(cid:3)1, 2(cid:4), (cid:3)3, 4(cid:4)}.Note that s",
            {
                "entities": [
                    [
                        3540,
                        3568,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 669–695Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTask decomposition on abstract states, for planning undernondeterminismUgur Kuter a,∗a Department of Computer Science and Institute of Systems Research and Institute of Advanced Computer Studies, University of Maryland, College Park,MD 20742, USAb Institute for Scientific and Technological Research (IRST), Fondazione Bruno Kessler, Via Sommarive 18, Povo, 38050 Trento, Italy, Dana Nau a, Marco Pistore b, Paolo Traverso ba r t i c l ei n f oa b s t r a c tArticle history:Received 1 October 2007Received in revised form 26 November 2008Accepted 26 November 2008Available online 6 December 2008Keywords:Planning in nondeterministic domainsHierarchical task-network (HTN) planningBinary decision diagramsAlthough several approaches have been developed for planning in nondeterministicdomains, solving large planning problems is still quite difficult. In this work, we presenta new planning algorithm, called Yoyo, for solving planning problems in fully observablenondeterministic domains. Yoyo combines an HTN-based mechanism for constraining itssearch and a Binary Decision Diagram (BDD) representation for reasoning about sets ofstates and state transitions.We provide correctness theorems for Yoyo, and an experimental comparison of it withMBP and ND-SHOP2, the two previously-best algorithms for planning in nondeterministicdomains. In our experiments, Yoyo could easily deal with problem sizes that neither MBPnor ND-SHOP2 could scale up to, and could solve problems about 100 to 1000 times fasterthan MBP and ND-SHOP2.© 2009 Elsevier B.V. All rights reserved.1. IntroductionAlthough many highly efficient algorithms have been built for classical planning, the applicability of these algorithmshas been quite limited, due to the restrictive assumptions of classical planning. Hence, there is rapidly growing interestin planning domains that violate some of these assumptions—for example, nondeterministic planning domains, in which theactions may have nondeterministic outcomes.1Although several approaches have been developed for planning in nondeterministic domains, the problem is still veryhard to solve in practice, even under the simplifying assumption of full observability, i.e., the assumption that the state ofthe world can be completely observed at run-time. Indeed, in the case of nondeterministic domains, the planning algorithmmust reason about all possible different execution paths to find a plan that works despite the nondeterminism, and thedimension of the generated conditional plan may grow exponentially.Before our development of the Yoyo algorithm described in this paper, the two best-performing algorithms for planningin nondeterministic domains were MBP [1,2] and ND-SHOP2 [3]:• MBP uses a suite of planning algorithms based on Symbolic Model Checking, which represent states symbolically usingOrdered Binary Decision Diagrams (BDDs) [4]. In experimental studies, MBP’s planning algorithms have easily scaled upto rather large-sized problems [2]. This is due largely to the fact that BDDs can represent large sets of states as compact* Corresponding author.E-mail addresses: ukuter@cs.umd.edu (U. Kuter), nau@cs.umd.edu (D. Nau), pistore@itc.it (M. Pistore), traverso@itc.it (P. Traverso).1 Unfortunately, the phrase “nondeterministic outcomes” seems to have two meanings in the current literature: some researchers attach probabilities tothe outcomes (as in a Markov Decision Process), and others omit the probabilities (as in a nondeterministic automaton). Our usage is the latter one.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.012\f670U. Kuter et al. / Artificial Intelligence 173 (2009) 669–695Fig. 1. Average running times in seconds for MBP and ND-SHOP2 in the Hunter–Prey Domain as a function of the grid size, with one prey. ND-SHOP2 wasnot able to solve planning problems in grids larger than 10 × 10 due to memory-overflow problems.formulae that refer to the salient properties of those states. As an example, suppose that in the blocks world, we havea formula f that represents some set of states S, and we want to reason about the set of all states in S in which theblock a is on the table. This set of states could be represented by a formula like f ∧ ontable(a).• ND-SHOP2 is a planner for nondeterministic domains that uses a Hierarchical Task Network (HTN) decompositiontechnique that is like that of the well-known SHOP2 planner [5] for deterministic domains. ND-SHOP2’s HTNs pro-vide domain-specific information to constrain the planner’s search. Among the actions that are applicable to a state,ND-SHOP2 will only consider those actions that it can obtain via HTN decomposition, and this can prevent explorationof large portions of the search space if there are reasons to believe that those portions are unpromising. For example, inthe blocks world, if the objective is to move a stack of blocks from one location to another, then we would only want toconsider actions that move those particular blocks, rather than any of the other blocks in the domain. Under the rightconditions, ND-SHOP2 can perform quite well; for example, [3] describes some cases where it outperforms MBP.ND-SHOP2 and MBP use very different techniques for reducing the size of the search space: MBP reasons about largesets of states as aggregate entities, and ND-SHOP2 focuses only on those parts of the search space that are produced viaHTN decomposition. As a consequence, there are situations in which each algorithm can substantially outperform the other.As a simple example, consider the well-known Hunter–Prey domain [6]. In the Hunter–Prey domain, the world is ann × n grid in which the planner is a hunter that is trying to catch one or more prey. The hunter has five possible actions;move north, south, east, or west, and catch (the latter is applicable only when the hunter and prey are in the same location).The prey has also five actions: the four movement actions plus a stay-still action—but instead of representing the prey as aseparate agent, its possible actions are encoded as the nondeterministic outcomes for the hunter’s actions. In this domain, asolution is any policy (i.e., a set of state-action pairs telling the hunter what to do under various conditions) for which thereis a guarantee that all of the prey will eventually be captured.There are some sets of Hunter–Prey problems in which ND-SHOP2 is exponentially faster than MBP, and other sets ofHunter–Prey problems where the reverse is true:• Fig. 1 shows the average running times required by MBP and ND-SHOP2 on hunter–and–prey problems with one prey,as a function of increasing grid sizes.2 ND-SHOP2 ran out of memory in large problems, because the solution policiesin this domain contain a huge number of state-action pairs and ND-SHOP2 represents most of these state-action pairsexplicitly. MBP, on the other hand, uses compact propositional formulas to represent sets of states that share salientcommon properties, and it searches a search space whose nodes are these formulas (rather than having a separate nodefor each state). This dramatically reduces the size of the search space, hence MBP’s small running time.• Fig. 2 shows the average running times required by MBP and ND-SHOP2 when we fix the grid size to 4 × 4, but increasethe number of prey to catch (we made the movements of prey dependent on each other by assuming that a prey cannotmove to a location next to another prey). In this case, ND-SHOP2 outperforms MBP, because it is able to use a simpleyet extremely effective pruning heuristic to constrain its search: “choose one prey and chase it while ignoring others;when you catch that prey, choose another and chase it, and continue in this way until all of the prey are caught”.2 All of the experiments were run on an AMD Duron 900 MHz laptop with 256 MB memory running Linux Fedora Core 2, using a time limit of 40 minutesfor each problem. Each data point is an average of 20 randomly-generated problems. In our experiments, if a planning algorithm could not solve a problemwithin this time limit (or it required more memory than available on our experimental computer), it was run again on another problem of the same size.Each data point for which there were more than five such failures was omitted from the results shown in the figures. Thus the data make the worse-performing algorithm (ND-SHOP2 in Fig. 1 and MBP in Fig. 2) look better than it really was—but this makes little difference since the disparity in thealgorithms’ performance is so great.\fU. Kuter et al. / Artificial Intelligence 173 (2009) 669–695671Fig. 2. Average running times in seconds for MBP and ND-SHOP2 in the Hunter–Prey Domain as a function of the number of prey, with a fixed 4 × 4 grid.Fig. 3. A visual characterization of the planning domains in which Yoyo does best.MBP, on the other hand, must consider all applicable actions at each node of its search space, which produces a largerbranching factor and hence a much larger search space.This paper presents a formalism and a novel algorithm, called Yoyo, that combines the power of the HTN-based search-control strategies with a BDD-based state representation. Yoyo implements an HTN-based forward-chaining search as inND-SHOP2, built on top of MBP’s techniques for representing and manipulating BDDs.This combination has required a complete rethinking of the ND-SHOP2 algorithm, in order to take advantage of sit-uations where the BDD representation will allow it to avoid enumerating states explicitly. In a backward-search plannersuch as MBP, each goal or subgoal is a set of states that can be represented quite naturally as a BDD. But forward-searchalgorithms like ND-SHOP2 normally apply actions to individual states, hence BDDs cannot be used effectively unless we candetermine which sets of states can usefully be combined into a sin",
            {
                "entities": [
                    [
                        3731,
                        3759,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 586–614Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe extended global cardinality constraint: An empirical surveyPeter NightingaleSchool of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 1 March 2010Received in revised form 18 October 2010Accepted 18 October 2010Available online 21 October 2010Keywords:Global cardinality constraintConstraint programmingGlobal constraintsPropagation algorithmsThe Extended Global Cardinality Constraint (EGCC) is a vital component of constraint solv-ing systems, since it is very widely used to model diverse problems. The literature containsmany different versions of this constraint, which trade strength of inference against compu-tational cost. In this paper, I focus on the highest strength of inference usually considered,enforcing generalized arc consistency (GAC) on the target variables. This work is an exten-sive empirical survey of algorithms and optimizations, considering both GAC on the targetvariables, and tightening the bounds of the cardinality variables. I evaluate a number of keytechniques from the literature, and report important implementation details of those tech-niques, which have often not been described in published papers. Two new optimizationsare proposed for EGCC. One of the novel optimizations (dynamic partitioning, generalizedfrom AllDifferent) was found to speed up search by 5.6 times in the best case and 1.56times on average, while exploring the same search tree. The empirical work represents byfar the most extensive set of experiments on variants of algorithms for EGCC. Overall, thebest combination of optimizations gives a mean speedup of 4.11 times compared to thesame implementation without the optimizations.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConstraint programming is a powerful and flexible means of solving combinatorial problems. Constraint solving of acombinatorial problem proceeds in two phases. First, the problem is modelled as a set of decision variables, and a set ofconstraints on those variables that a solution must satisfy. A decision variable represents a choice that must be made inorder to solve the problem. The domain of potential values associated with each decision variable corresponds to the optionsfor that choice.Consider a sports scheduling problem, where each team plays every other team exactly once in a season. No team canplay two or more matches at the same time. Each team plays in a particular stadium at most twice during the season. Inthis example one might have two decision variables per match, representing the two teams. For a set of matches played inthe same stadium, a global cardinality constraint [24] could be used to ensure no more than two occurrences of each team.The second phase consists of using a constraint solver to search for solutions: assignments of values to decision variablessatisfying all constraints. The simplicity and generality of this approach is fundamental to the successful application ofconstraint solving to a wide variety of disciplines such as scheduling, industrial design and combinatorial mathematics [34,11].The Global Cardinality Constraint (GCC) is a very important global constraint, present in various constraint solving toolk-its, solvers and languages. It restricts the number of occurrences of values assigned to a set of variables. In the originalversion of the constraint [24], each value is given a lower bound and upper bound. In any solution, the number of occur-rences of the value must fall within the bounds. The literature contains many propagation algorithms for this constraint,E-mail address: pn@cs.st-andrews.ac.uk.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.005\fP. Nightingale / Artificial Intelligence 175 (2011) 586–614587which trade strength of inference against computational cost, for example bound consistency [13,19], range consistency [18],and generalized arc-consistency (GAC) [24,18]. GCC is widely used in a variety of constraint models, for diverse problemssuch as routing and wavelength assignment [30], car sequencing [25], and combinatorial mathematics [11].Returning to the sports scheduling example, GCC can be used to express the stadium constraint (that a team plays in aparticular stadium at most twice during the season). Each value (representing a team) is given the bounds (0, 2), and thevariables are all slots at a particular stadium.GCC has been generalized by replacing the fixed bounds on values with cardinality variables [18], where each cardinalityvariable represents the number of occurrences of a value. To avoid confusion, I refer to this as the Extended Global Cardi-nality Constraint (EGCC). Thus an EGCC constraint has target variables (where the number of occurrences of some values areconstrained) and cardinality variables.In this paper, I focus on the highest strength of inference (enforcing GAC) on the target variables. This allows the study ofvarious methods in great depth, and leads to some surprising conclusions. I also survey methods for pruning the cardinalityvariables in depth. The main contributions of the paper are as follows.• A literature survey of GAC propagation algorithms for the target variables, and their optimizations, in Section 3.• Discussion of important implementation decisions in Section 3 that are frequently omitted from original papers, perhapsdue to lack of space. For example, how to find augmenting paths for Régin’s algorithm [24].• The proposal of two new optimizations in Section 3.4. One of these is based on modifying the flow network of Régin’salgorithm for greater efficiency, and the other is a novel generalization of the dynamic partitioning optimization ofAllDifferent [6].• A careful description of three concrete algorithms for pruning the cardinality variables in Section 4.• Easily the largest empirical study of GAC propagation methods for the target variables of EGCC, in Section 5. Thisinvolves two basic algorithms and seven optimizations.• Experimental conclusions and implementation advice for GAC for the target variables, in Section 6.• An empirical study of pruning the cardinality variables, comparing the three methods, in Section 5.8, leading to experi-mental conclusions in Section 6.• It is shown that an appropriate combination of optimizations is over 4 times faster on average than a careful butunoptimized implementation of Régin’s algorithm (Section 5.10), for our benchmark set.• A fast variant of EGCC is typically orders of magnitude better than a set of occurrence constraints. Even when EGCCpropagation was least effective, it slowed the solver down by only 1.66 times or less in our experiments (Section 5.10).2. Background2.1. PreliminariesFor CSP P = (cid:2)X , D, C(cid:3), a constraint Ck ∈ C consists of a sequence of m > 0 variables Xk = (cid:2)xk1 , . . . , xkmA CSP P = (cid:2)X , D, C(cid:3) is defined as a set of n variables X = (cid:2)x1, . . . , xn(cid:3), a set of domains D = (cid:2)D(x1), . . . , D(xn)(cid:3) whereD(xi) (cid:2) Z, |D(xi)| < ∞ is the finite set of all potential values of xi , and a conjunction C = C1 ∧ C2 ∧ · · · ∧ Ce of constraints.(cid:3) with domainsDk = (cid:2)D(xk1 ), . . . , D(xkm )(cid:3) s.t. Xk is a subsequence1 of X , Dk is a subsequence of D, and each variable xki and domainD(xki ) matches a variable x j and domain D(x j) in P . Ck has an associated set C S⊆ D(xk1 ) × · · · × D(xkm ) of tuples whichspecify allowed combinations of values for the variables in Xk.Although I define a constraint Ck to have scope (cid:2)xk1 , . . . , xkm(cid:3), when discussing a particular constraint I frequently omitkthe k subscript, and refer to the variables as (cid:2)x1, . . . , xm(cid:3), and to the domains as (cid:2)D(x1), . . . , D(xm)(cid:3).A literal is defined as a variable-value pair, xi (cid:8)→ j such that xi ∈ X and j ∈ Z. To prune a literal is to remove the valuek , andj from the domain D(xi). In the context of a constraint Ck, I refer to a tuple τ of values as being acceptable iff τ ∈ C Svalid iff |τ | = m and ∀ j: τ [ j] ∈ D(xk j ) (i.e. each value in the tuple is in its respective domain).A solution to a CSP P = (cid:2)X , D, C(cid:3) is a tuple τ of size | X| where ∀i: τ [i] ∈ D(xi) (τ represents an assignment to allisvariables), and all constraints are satisfied by τ : for each constraint Ck in C with scope (cid:2)xk1 , . . . , xkmk (τ (cid:11)constructed where ∀ j: τ (cid:11)[ j] = τ [k j], and τ (cid:11) ∈ C SGeneralized Arc-Consistency (GAC) for constraint Ck is defined as a function from domains Dk to a set of literals P . Notek is defined in terms of Dk. A literal xi (cid:8)→ j where j ∈ D(xi) is in P iff it is not present in any tuple in C Sk :k : τ [i] = j. Literals in P are not part of any acceptable and valid tuple of the constraint, therefore they can be prunedthat the set C S(cid:3)τ ∈ C Swithout reducing the set of solutions of the CSP P .(cid:3), a new tuple τ (cid:11)is acceptable).2.1.1. Graph theoryRégin’s algorithm [24] and Quimper’s algorithm [18] for pruning EGCC make use of network flow and bipartite matchingtheory [2] as well as strongly connected components [31]. Similarly, Régin’s AllDifferent algorithm [23] makes use of resultsfrom graph theory, in particular maximum bipartite matching [1] and strongly connected components.1 I use subsequence in the sense that (cid:2)1, 3(cid:3) is a subsequence of (cid:2)1, 2, 3, 4(cid:3).\f588P. Nightingale / Artificial Intelligence 175 (2011) 586–614A bipartite graph G = (cid:2)V , E(cid:3) is defined as a set of vertices V and a set of edges E ⊆ V × V , where the edges areinterpreted as having no direction and the vertices can be partitioned into two sets V 1 and V 2 such that no two elementsin the same set are adjacent.A digraph G = (cid:2)V , E(cid:3) is defined as a set of vert",
            {
                "entities": [
                    [
                        3879,
                        3907,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 25–41www.elsevier.com/locate/artintA Real generalization of discrete AdaBoost ✩Richard Nock a,∗, Frank Nielsen ba Université des Antilles-Guyane, UFR DSE—Ceregmia, Campus de Schoelcher, BP 7209, 97275 Schoelcher, Martinique, Franceb SONY CS Labs (FRL), 3-14-13 Higashi Gotanda, Shinagawa-Ku, Tokyo 141-0022, JapanReceived 1 June 2006; received in revised form 16 October 2006; accepted 16 October 2006Available online 21 November 2006AbstractScaling discrete AdaBoost to handle real-valued weak hypotheses has often been done under the auspices of convex optimization,but little is generally known from the original boosting model standpoint. We introduce a novel generalization of discrete AdaBoostwhich departs from this mainstream of algorithms. From the theoretical standpoint, it formally displays the original boostingproperty, as it brings fast improvements of the accuracy of a weak learner up to arbitrary high levels; furthermore, it bringsinteresting computational and numerical improvements that make it significantly easier to handle “as is”. Conceptually speaking,it provides a new and appealing scaling to R of some well known facts about discrete (ada)boosting. Perhaps the most popularis an iterative weight modification mechanism, according to which examples have their weights decreased iff they receive theright class by the current discrete weak hypothesis. In our generalization, this property does not hold anymore, as examples thatreceive the right class can still be reweighted higher with real-valued weak hypotheses. From the experimental standpoint, ourgeneralization displays the ability to produce low error formulas with particular cumulative margin distribution graphs, and itprovides a nice handling of those noisy domains that represent Achilles’ heel for common Adaptive Boosting algorithms.© 2006 Elsevier B.V. All rights reserved.Keywords: AdaBoost; Boosting; Ensemble learning1. IntroductionIn supervised learning, it is hard to exaggerate the importance of boosting algorithms. Loosely speaking, a boostingalgorithm repeatedly trains a moderately accurate learner, gets its weak hypotheses, combines them, to finally outputa strong classifier which boosts the accuracy up to arbitrary high levels [14,15]. (Discrete) Adaboost, undoubtfullythe most popular provable boosting algorithm [7], uses weak hypotheses with outputs restricted to the discrete setof classes that it combines via leveraging coefficients in a linear vote. Strong theoretical issues have motivated theextension of this discrete AdaBoost [8] to handle real-valued weak hypotheses as well [8,17,26,29]. Even when onlyfew of them are true generalizations of discrete AdaBoost [17,29], virtually all share a strong background in convex✩ Extends the paper from the same name that was awarded the Best Paper Award at the 17th European Conference on Artificial Intelligence(2006).* Corresponding author. Fax: (+596) 596 72 74 03.E-mail addresses: Richard.Nock@martinique.univ-ag.fr (R. Nock), Nielsen@csl.sony.co.jp (F. Nielsen).URLs: http://www.univ-ag.fr/~rnock (R. Nock), http://www.csl.sony.co.jp/person/nielsen/ (F. Nielsen).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.10.014\f26R. Nock, F. Nielsen / Artificial Intelligence 171 (2007) 25–41optimization originally rooted in a “key” to boosting in AdaBoost: a strictly convex exponential loss integrated intoa weight update rule for the examples, loss which upperbounds the error and approximates the expected binomiallog-likelihood. However, very little is often known for these algorithms from the seminal boosting model standpoint[14,15,27], a model which roughly requires convergence to reduced true risk under very weak assumptions (with highprobability).In this paper, we propose a new real AdaBoost, a generalization of discrete AdaBoost that handles arbitrary real-valued weak hypotheses. With respect to former real AdaBoosts, the weight update is fundamentally different as itdoes not integrate anymore the convex exponential loss; also, the leveraging coefficients for the weak hypothesesdiffer in the output; finally, these leveraging coefficients are given in closed form and their computation can noweasily be delayed until the end of boosting, which is not the case for conventional real AdaBoosts [8,17,29]. The majortheoretical key feature of this algorithm is that it is a provable boosting algorithm in the original sense. Another point isthat it saves computation time with respect to previous generalizations of discrete AdaBoost, that need to approximatethe solution of a convex minimization problem at each boosting iteration [17,29]. From the experimental standpoint,the weight update rule, which does not require anymore the approximation of logarithms or exponentials, is less proneto numerical errors. Finally, it prevents or reduces some numerical instabilities that previous generalizations [17,29]face when the weak hypotheses reach perfect, or perfectly wrong, classification. This might explain why experimentsclearly display that our algorithm handles noise more efficiently than discrete or real AdaBoosts. Noise handling hassoon be described as AdaBoost’s potential main problem, see [2].As a matter of fact, it is quite interesting that our algorithm is indeed a generalization of discrete AdaBoost, as whenthe weak hypotheses have outputs constrained to the set of classes, both algorithms coincide. From this standpoint,our paper also brings a relevant conceptual contribution to boosting. Indeed, we give a complete generalization to R ofpopular (discrete) boosting properties, and this is sometimes clearly not trivial. For example, discrete AdaBoost is veryoften presented as an algorithm that reweights lower the examples that have received the right class. Scaled to R, thisis not true anymore. Roughly speaking, provided a so-called Weak Learning Assumption holds (which states that theclassifier is slightly different from random), lower reweighting occurs only for examples that receive the right class,and on which a measure of the classifier’s confidence exceeds a measure of its average confidence (over all examples,known as a margin). Only on the discrete prediction framework do these two properties coincide. Furthermore, thisscaling property does not hold for previous real AdaBoosts [8,17,26,29].Section 2 presents some definitions, followed by a section on our generalization of discrete AdaBoost. Section 4presents and discusses experimental results, and a last section concludes the paper.2. Definitions and related workOur framework is rooted into the original weak/strong learning and boosting frameworks, and Valiant’s PAC (Prob-ably Approximately Correct) model of learnability [7,15,30]. We have access to a domain X of observations, whichcould be {0, 1}n, Rn, etc. Here, n is the number of description variables. More precisely, we collect examples, that is,couples (observation, class) written (x, y) ∈ X × {−1, +1}. “+1” is called the positive class (or label), and “−1” thenegative class. In this paper, we deal only with the two-classes case. Well known transformations exist that allow itsextension to multiclass, multilabel frameworks [29]. In this paper, boldfaces such as x denote n-dimensional vectors,calligraphic faces such as X denote sets and blackboard faces such as S denote subsets of R, the set of real numbers.Unless explicitely stated, sets are enumerated following their lower-case, such as {xi: i = 1, 2, . . .} for vector sets,and {xi: i = 1, 2, . . .} for other sets (and for vector entries). We make the assumption that examples are sampled inde-pendently, following an unknown but fixed distribution D over X × {−1, +1}. Our objective is to induce a classifieror hypothesis H : X → R, that matches the best possible the examples drawn according to D.For this objective, we define a strong learner as an algorithm which is given two parameters 0 < ε, δ < 1, samplesaccording to D a set S of m examples, and returns a classifier or hypothesis H : X → R such that with probability(cid:2) 1 − δ, its true risk (cid:4)D,H is bounded as follows:(cid:4)(cid:3)H (x)(1)Here, sign(a) is +1 iff a (cid:2) 0, and −1 otherwise. The time complexity of the algorithm is required to be polynomial inrelevant parameters, among which 1/ε, 1/δ, n. To be rigorous, the original models [15,30] also mention dependenceson concepts that label the examples. Examples are indeed supposed to be labeled by a so-called target concept,= (cid:4)D,H (cid:3) ε.Pr(x,y)∼D(cid:2)sign(cid:6)= y(cid:5)\fR. Nock, F. Nielsen / Artificial Intelligence 171 (2007) 25–4127Input: sample S = {(xi , yi ), xi ∈ X , yi ∈ {−1, +1}}w1 ← u;for t = 1, 2, . . . , T doGet (ht : X → S) ← WL(S, wt );Find αt ∈ R;Update: ∀1 (cid:3) i (cid:3) m,wt+1,i ← wt,i × exp(−αt yi ht (xi ))/Zt ; (2)endOutput: HT (x) =(cid:6)Tt=1 αt ht (x)Fig. 1. An abstraction of AdaBoost.which is unknown but fixed. Distribution D is in fact used to retrieve the examples from this target concept, andthe time complexity of the algorithm is also required to be polynomial in its size. Hereafter, we shall omit for thesake of clarity this notion of target concept, which is not important for our purpose, since our analysis may also befit to handle it as well. A weak learner (WL) has basically the same constraints, with two notable exceptions: (i) theweak hypotheses it delivers have outputs that can be restricted to a subset S ⊆ R, and (ii) (1) is only required tohold with ε = 1/2 − γ for some γ > 0 a constant or inverse polynomial in relevant parameters (this still has tobe verified regardless of D). Since predicting the classes at random, such as with an unbiased coin, would yieldPr(x,y)∼D[sign(random(x)) (cid:6)= y] = 1/2, ∀D, it comes that a weak learner is only required to perform slightly betterthan random prediction. In the original models, it is even assumed that δ is also an inverse polynomial in relevantparameters, whi",
            {
                "entities": [
                    [
                        3243,
                        3271,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 240 (2016) 19–35Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintH-index manipulation by merging articles: Models, theory, and experiments ✩René van Bevern a,b,d,∗Manuel Sorge d, Toby Walsh d,e,fa Novosibirsk State University, Novosibirsk, Russian Federationb Sobolev Institute of Mathematics, Siberian Branch of the Russian Academy of Sciences, Novosibirsk, Russian Federationc Institut für Informatik, Friedrich-Schiller-Universität Jena, Germanyd Institut für Softwaretechnik und Theoretische Informatik, TU Berlin, Germanye University of New South Wales, Sydney, Australiaf Data61, Sydney, Australia, Christian Komusiewicz c,d, Rolf Niedermeier d, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 March 2016Received in revised form 26 July 2016Accepted 5 August 2016Available online 10 August 2016Keywords:Citation indexHirsch indexParameterized complexityExact algorithmsAI’s 10 to watch1. IntroductionAn author’s profile on Google Scholar consists of indexed articles and associated data, such as the number of citations and the H-index. The author is allowed to merge articles; this may affect the H-index. We analyze the (parameterized) computational complexity of maximizing the H-index using article merges. Herein, to model realistic manipulation scenarios, we define a compatibility graph whose edges correspond to plausible merges. Moreover, we consider several different measures for computing the citation count of a merged article. For the measure used by Google Scholar, we give an algorithm that maximizes the H-index in linear time if the compatibility graph has constant-size connected components. In contrast, if we allow to merge arbitrary articles (that is, for compatibility graphs that are cliques), then already increasing the H-index by one is NP-hard. Experiments on Google Scholar profiles of AI researchers show that the H-index can be manipulated substantially only if one merges articles with highly dissimilar titles.© 2016 Elsevier B.V. All rights reserved.The H-index is a widely used measure for estimating the productivity and impact of researchers, journals, and institu-tions. Hirsch [22] defined the index as follows: a researcher has H-index h if h of the researcher’s articles have at least hcitations and all other articles have at most h citations. Several publicly accessible databases such as AMiner, Google Scholar, Scopus, and Web of Science compute the H-index of researchers. Such metrics are therefore visible to hiring committees and funding agencies when comparing researchers and proposals.1✩An extended abstract of this article appeared at IJCAI 2015 [4]. This version provides full proof details, new kernelization results, as well as additional E-mail addresses: rvb@nsu.ru (R. van Bevern), christian.komusiewicz@uni-jena.de (C. Komusiewicz), rolf.niedermeier@tu-berlin.de (R. Niedermeier), experiments.* Corresponding author at: Novosibirsk State University, ul. Pirogova 2, 630090 Novosibirsk, Russian Federation.manuel.sorge@tu-berlin.de (M. Sorge), toby.walsh@nicta.com.au (T. Walsh).1 Our study on H-index manipulation is not meant to endorse or discourage the use of the H-index as an evaluation tool. In this regard, we merely aim to raise awareness for the various possibilities for manipulation.http://dx.doi.org/10.1016/j.artint.2016.08.0010004-3702/© 2016 Elsevier B.V. All rights reserved.\f20R. van Bevern et al. / Artificial Intelligence 240 (2016) 19–35Although the H-index of Google Scholar profiles is computed automatically, profile owners can still affect their H-index by merging articles in their profile. The intention of providing the option to merge articles is to enable researchers to identify different versions of the same article. For example, a researcher may want to merge a journal version and a version on arXiv.org, which are found as two different articles by Google’s web crawlers. This may decrease a researcher’s H-index if both articles counted towards it before merging, or increase the H-index since the merged article may have more citations than each of the individual articles. Since the Google Scholar interface permits to merge arbitrary pairs of articles, this leaves the H-index of Google Scholar profiles vulnerable to manipulation by insincere authors.In extreme cases, the merging operation may yield an arbitrarily large H-index even if each single article is cited only a few times: If the author has, for example, h2 articles that are cited once, each by a distinct article from another author, then the H-index of the profile is 1. Creating h merged articles, each consisting of h original articles, gives a profile with H-index h. This is the maximum H-index achievable with h2 citations.Increasing the H-index even by small values could be tempting in particular for young researchers, who are scrutinized more often than established researchers.2 Hirsch [22] estimates that, for the field of physics, the H-index of a successful researcher increases by roughly one per year of activity. Hence, an insincere author might try to save years of research work with the push of a few buttons.H-index manipulation by article merging has been studied by de Keijzer and Apt [9]. In their model, each article in a profile comes with a number of citations. Merging two articles, one with x and one with y citations, replaces these articles by a new article with x + y citations. The obtained article may then be merged with further articles to obtain articles with even higher citation numbers. In this model, one can determine in polynomial time whether it is possible to improve the H-index by merging, but maximizing the H-index by merging is strongly NP-hard [9]. We extend the results of de Keijzer and Apt [9] as follows.1. We propose two further ways of measuring the number of citations of a merged article. One of them seems to be the measure used by Google Scholar.2. We propose a model for restricting the set of allowed merge operations. Although Google Scholar allows merges be-tween arbitrary articles, such a restriction is well motivated: An insincere author may try to merge only similar articles in order to conceal the manipulation.3. We consider the variant of H-index manipulation in which only a limited number of merges may be applied in order to achieve a desired H-index. This is again motivated by the fact that an insincere author may try to conceal the manipulation by performing only few changes to her or his own profile.4. We analyze each problem variant presented here within the framework of parameterized computational complexity [8,12,19,25]. That is, we identify parameters p—properties of the input measured in integers—and aim to design fixed-parameter algorithms, which have running time f (p) · n O (1) for a computable function findependent of the input size n. In some cases, this allows us to give efficient algorithms for realistic problem instances despite the NP-hardness of the problems in general. We also show parameters that presumably cannot lead to fixed-parameter algorithms by showing some problem variants to be W[1]-hard for these parameters.5. We evaluate our theoretical findings by performing experiments with real-world data based on the publication profiles of AI researchers. In particular, we use profiles of some young and up-and-coming researchers from the 2011 and 2013 editions of the IEEE “AI’s 10 to watch” list [1,33].Related work Using the models introduced here, Elkind and Pavlou [27] recently studied manipulation for two alternatives to the H-index: the i10-index, the number of articles with at least ten citations, and the g-index [14], which is the largest number g such that the g most-cited articles are cited at least g times on average. They also considered the scenario where merging articles can influence the profiles of other authors. In a follow-up work to our findings, we analyzed the complex-ity of unmerging already merged articles so to manipulate the H-index with respect to the citation measures introduced here [5]. Notably, in the model corresponding to Google Scholar, the complexity is much lower for unmerging rather than for merging articles.A different way of manipulating the H-index is by strategic self-citations [10,28]; Bartneck and Kokkelmans [3] consider approaches to detect these. Strategic self-citations take some effort and are irreversible. Thus, they can permanently damage an author’s reputation. In comparison, article merging is easy, reversible and usually justified.Bodlaender and van Kreveld [6] showed that, in a previous version of the Google Scholar interface, which only allowed merges of articles displayed together on one page, it was NP-hard to decide whether a given set of articles can be merged at all.The problem of maximizing the H-index in the model of de Keijzer and Apt [9] is essentially a special case of the scheduling problems Bin Covering [2,7] and Machine Covering [20,29].A considerable body of work on manipulation can be found in the computational social choice literature [15,16]. If we view citations as articles voting on other articles, then the problem we consider here is somewhat analogous to strategic candidacy [13].2 In fact, for senior researchers with many citations, the H-index is barely more expressive than the total citation count [32].\fR. van Bevern et al. / Artificial Intelligence 240 (2016) 19–3521Fig. 1. Vertices represent articles in our profile W , arrows represent citations, numbers are citation counts (note that, in general, there may be articles in V \\ W , which are not in our profile and not displayed here). The articles on a gray background in (a) have been merged in (b)–(d), and citation counts are given according to the measures sumCite, unionCite, and fusionCite, respectively. The arrows represent the citations counted by the corresponding measure.1.1. Our modelsWe propose two new models for the merging of articles. These mode",
            {
                "entities": [
                    [
                        3362,
                        3390,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 422–439www.elsevier.com/locate/artintDecomposition of structural learning about directed acyclic graphsXianchao Xie a, Zhi Geng a,∗, Qiang Zhao a,ba School of Mathematical Sciences, LMAM, Peking University, Beijing 100871, Chinab Institute of Population Research, Peking University, Beijing 100871, ChinaReceived 8 February 2005; received in revised form 21 November 2005; accepted 16 December 2005Available online 3 February 2006AbstractIn this paper, we propose that structural learning of a directed acyclic graph can be decomposed into problems related to itsdecomposed subgraphs. The decomposition of structural learning requires conditional independencies, but it does not requirethat separators are complete undirected subgraphs. Domain or prior knowledge of conditional independencies can be utilized tofacilitate the decomposition of structural learning. By decomposition, search for d-separators in a large network is localized to smallsubnetworks. Thus both the efficiency of structural learning and the power of conditional independence tests can be improved. 2005 Elsevier B.V. All rights reserved.Keywords: Bayesian network; Conditional independence; Decomposition; Directed acyclic graph; Junction tree; Structural learning; Undirectedgraph1. IntroductionDirected acyclic graphs (DAGs) are widely used to represent independencies, conditional independencies andcausal relationships among variables [5,6,8,15,18,19,24]. Structure recovery of DAGs has been discussed by manyauthors [5,12,19,24,27]. Search for d-separators of vertex pairs is a key issue for orientation of directed edges and forrecovering DAG structures and causal relations among variables. To recover structure of DAGs, Verma and Pearl [27]presented the inductive causation (IC) algorithm which searches for a d-separator S from all possible variable subsetssuch that two variables u and v are independent conditional on S. A systematic way of searching for d-separatorsin increasing order of cardinality was proposed in [23,24]. The PC algorithm limits possible d-separators to verticesthat are adjacent to u and v [19,24]. A decomposition approach of searching for d-separators was presented in [11].To decompose a graph into two subgraphs, the approach in [11] needs a moral graph and it requires two conditions:(i) variable sets in two subgraphs are independent conditional on their separator and (ii) the separator must be acomplete subgraph in the moral graph. The two conditions are often used to define decomposition of an undirectedgraph, see Definitions 2.1 and 2.2 in [15].In this paper, we present a decomposition approach for recovering structures of DAGs. The ultimate use of the con-structed DAGs is to interpret association and causal relationships among variables. Decomposition in our approach* Corresponding author.E-mail addresses: xie1981@water.pku.edu.cn (X.C. Xie), zgeng@math.pku.edu.cn (Z. Geng), zhq@math.pku.edu.cn (Q. Zhao).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.12.004\fX.C. Xie et al. / Artificial Intelligence 170 (2006) 422–439423only needs an undirected independence graph which may not be a moral graph and may have extra edges added tothe moral graph, and further it only requires condition (i) of conditional independencies but it does not require condi-tion (ii) of complete separators. Thus the decomposition is weaker than the weak decomposition defined in [15] andalso than that proposed in [11]. Deleting condition (ii) from decomposition conditions is important since it is difficultwith domain or prior knowledge to judge whether a separator is complete or not. In many practical applications, con-dition (i) of conditional independencies can be judged with domain or prior knowledge or with incompletely observeddata patterns, such as Markov chain, chain graphical models, dynamic or temporal models, file-matching for largedatabases and split questionnaire survey sampling [6,16,20].Section 2 gives notation and definitions. In Section 3, we show a condition for decomposing structural learningof DAGs. Construction of d-separation trees to be used for decomposition is discussed in Section 4. We propose themain algorithm and then give an example in Section 5 to illustrate our approach for recovering the global structureof a DAG. Section 6 discusses the complexity and advantages of the proposed algorithms. Conclusions are given inSection 7. The proofs of our main results and algorithms are given in Appendix A.2. Notation and definitions2.1. Directed acyclic graphs and undirected graphsLet (cid:2)GV = (V , (cid:2)EV ) denote a DAG where V = {X1, . . . , Xn} is the vertex set and (cid:2)EV the set of directed edges.A directed edge from a vertex u to a vertex v is denoted by (cid:3)u, v(cid:4). We assume that there is no directed loop in (cid:2)GV . Wesay that u is a parent of v and v is a child of u if there is a directed edge (cid:3)u, v(cid:4), and denote the set of all parents of avertex v by pa(v). We say that two vertices u and v are adjacent in (cid:2)GV if there is an edge connecting them. A path lbetween two distinct vertices u and v is a sequence of distinct vertices in which the first vertex is u, the last one is vand two consecutive vertices are connected by an edge, that is, l = (c0 = u, c1, . . . , cm−1, cm = v) where (cid:3)ci−1, ci(cid:4) or(cid:3)ci, ci−1(cid:4) is contained in (cid:2)EV for i = 1, . . . , m (m (cid:1) 1), and ci (cid:5)= cj for all i (cid:5)= j . We say that u is an ancestor of v and vis a descendant of u if there is a path between u and v in (cid:2)GV and all edges on this path point at the direction toward v.The set of ancestors of v is denoted as an(v), and define An(v) = an(v) ∪ {v}. A path l is said to be d-separated bya set of vertices Z if and only if(1) l contains a ‘chain’: u → v → w or a ‘fork’ u ← v → w such that the middle vertex v is in Z, or(2) l contains a ‘collider’ u → v ← w such that the middle vertex v is not in Z and no descendant of v is in Z.Two distinct sets X and Y of vertices are d-separated by a set Z if Z d-separates every path from any vertex in X toany vertex in Y ; We call Z a d-separator of X and Y . In a DAG (cid:2)GV , a collider u → v ← w is called a v-structure if uand w are non-adjacent in (cid:2)GV .Let ¯GV = (V , ¯EV ) denote an undirected graph where ¯EV is a set of undirected edges. An undirected edge betweentwo vertices u and v is denoted by (u, v). For a subset A of V , let ¯GA = (A, ¯EA) be the subgraph induced by Aand ¯EA = {e ∈ ¯EV | e ∈ A × A} = ¯EV ∩ (A × A). An undirected graph is called complete if any pair of vertices isconnected by an edge. For an undirected graph, we say that vertices u and v are separated by a set of vertices Z ifeach path between u and v passes through Z. We say that two distinct vertex sets X and Y are separated by Z if andonly if Z separates every pair of vertices u and v for any u ∈ X and v ∈ Y . We say that an undirected graph ¯GV isan undirected independence graph for a DAG (cid:2)GV if the fact that a set Z separates X and Y in ¯GV implies that Zd-separates X and Y in (cid:2)GV . We say that ¯GV can be decomposed into subgraphs ¯GA and ¯GB if(1) A ∪ B = V , and(2) C = A ∩ B separates A \\ B and B \\ A in ¯GV .The above decomposition does not require that the separator C is complete, which is required for weak decompositiondefined in [15] and for decomposition of search for v-structures proposed in [11]. In the next section, we show that aproblem of structural learning of a DAG can also be decomposed into problems for its decomposed subgraphs even ifthe separator is not complete.\f424X.C. Xie et al. / Artificial Intelligence 170 (2006) 422–439(a)(b)Fig. 1. A directed graph, a moral graph and a triangulated graph. (a) The DAG (cid:2)GV . (b) The moral graph (cid:2)GmV . (c) A triangulated graph (cid:2)GtV .(c)Define a moral graph (cid:2)GmA triangulated graph is an undirected graph whose every cycle of length (cid:1) 4 possesses a chord [15]. For anundirected graph ¯GV which is not triangulated, we can add extra edges to it such that it becomes to be a triangulatedgraph, denoted by ¯GtV .V for a DAG (cid:2)GV to be an undirected graph ¯GV = (V , ¯EV ) whose vertex set is V andwhose edge set is constructed by marrying parents and dropping directions, that is, ¯EV = {(u, v): (cid:3)u, v(cid:4) or (cid:3)v, u(cid:4) ∈(cid:2)EV } ∪ {(u, v): (u, w, v) forms a v-structure} [15]. An undirected edge added for marrying parents is called a moraledge. The moral graph (cid:2)GmV is an undirected independence graph for (cid:2)GV [15].Example 1. Consider a DAG (cid:2)GV in Fig. 1(a). 2 → 4 ← 3 and 4 → 7 ← 6 are two v-structures. A path l = (2, 1, 5)is d-separated by vertex 1, and another path l(cid:11) = (2, 4, 7, 6, 5) is d-separated by an empty set since 4 → 7 ← 6 is acollider. Vertices 2 and 5 are d-separated by vertex 1. an(4) = {1, 2, 3} and An(4) = {1, 2, 3, 4}. The moral graph (cid:2)GmVis shown in Fig. 1(b), whose edges (2, 3) and (4, 6) are moral edges. Set {2, 3, 5} separates {1} and {4, 6, 7}, and thus(cid:2)GmV can be decomposed into two undirected subgraphs over {1, 2, 3, 5} and {2, . . . , 7}. An undirected independencegraph for (cid:2)GV may have extra undirected edges added to the moral graph, say edges (1, 4) and (1, 6) added to (cid:2)GmV , seedashed edges in Fig. 1(c). The graph in Fig. 1(c) is a triangulated graph of (cid:2)GmV .Given a DAG (cid:2)GV , a joint distribution or density of variables X1, . . . , Xn isP (x1, . . . , xn) =n(cid:1)i=1P (xi | pai),where P (xi | pai) is the conditional probability or density of Xi given pa(Xi) = pai . The DAG (cid:2)GV and the distributionP are said to be compatible [19] and P obeys the global directed Markov property of (cid:2)GV [15]. Let X Y denotethe independence of X and Y , and X Y | Z the conditional independence of X and Y given Z. If sets X and Y ared-separated by Z, then X is independent of Y conditional on",
            {
                "entities": [
                    [
                        3046,
                        3074,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 850–864Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAllDifferent-based filtering for subgraph isomorphismChristine SolnonUniversité de Lyon, Université Lyon 1, LIRIS, UMR5205 CNRS, F-69622, Francea r t i c l ei n f oa b s t r a c tThe subgraph isomorphism problem involves deciding if there exists a copy of a patterngraph in a target graph. This problem may be solved by a complete tree search combinedwith filtering techniques that aim at pruning branches that do not contain solutions. Weintroduce a new filtering algorithm based on local all different constraints. We show thatthis filtering is stronger than other existing filterings — i.e., it prunes more branches — andthat it is also more efficient — i.e., it allows one to solve more instances quicker.© 2010 Elsevier B.V. All rights reserved.Article history:Received 24 December 2009Received in revised form 3 May 2010Accepted 3 May 2010Available online 6 May 2010Keywords:Subgraph isomorphismConstraint programmingAll different constraint1. IntroductionGraphs are widely used in real-life applications to represent structured objects such as, for example, molecules, images,or biological networks. In many of these applications, one looks for a copy of a pattern graph into a target graph [4]. Thisproblem, known as subgraph isomorphism, is NP-complete in the general case [6].Subgraph isomorphism problems may be solved by a systematic exploration of the search space composed of all possibleinjective matchings from the set of pattern nodes to the set of target nodes: starting from an empty matching, one incre-mentally extends a partial matching by matching a non-matched pattern node to a non-matched target node until eithersome edges are not matched by the current matching (the search must backtrack to a previous choice point and go onwith another extension) or all pattern nodes have been matched (a solution has been found). To reduce the search space,this exhaustive exploration is combined with filtering techniques that aim at removing candidate couples of non-matchedpattern-target nodes. Different levels of filtering may be considered; some are stronger than others (they remove morenodes), but also have higher time complexities.In this paper, we describe and compare existing filtering algorithms for the subgraph isomorphism problem, and weintroduce a new filtering algorithm which is stronger. We experimentally evaluate this new filtering algorithm on a widebenchmark of instances, and we show that it is much more efficient on many instances.2. Definitions and notationsA graph G = (N, E) consists of a node set N and an edge set E ⊆ N × N, where an edge (u, uThe set of neighbors of a node u is denoted adj(u) and is defined by adj(u) = {uconsider non-directed graphs, such that (u, uin Section 5.(cid:3)) ∈ E ⇔ (u(cid:3)) is a couple of nodes.(cid:3)) ∈ E}. In this paper, we implicitly(cid:3), u) ∈ E. The extension of our work to directed graphs is discussed(cid:3) | (u, uA subgraph isomorphism problem between a pattern graph G p = (N p, E p) and a target graph Gt = (Nt, Et) consists indeciding whether G p is isomorphic to some subgraph of Gt . More precisely, one should find an injective matching f : N p →Nt , that associates a different target node to each pattern node, and that preserves pattern edges, i.e.,E-mail address: christine.solnon@liris.cnrs.fr.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.002\fC. Solnon / Artificial Intelligence 174 (2010) 850–864851(cid:2)∀u, u(cid:3)(cid:3)∈ E p,(cid:2)f (u), f(cid:3)(cid:3)(cid:2)(cid:3)u∈ EtThe function fis called a subisomorphism function.Note that the subgraph is not necessarily induced so that two pattern nodes that are not linked by an edge may bematched to two target nodes which are linked by an edge. This problem is also called subgraph monomorphism or subgraphmatching in the literature.In the following, we assume G p = (N p, E p) and Gt = (Nt, Et) to be the underlying instance of subgraph isomorphism) nodes of G pproblem, and we assume without loss of generality that N p ∩ Nt = ∅. We usually denote u or u(resp. Gt ).(resp. v or vWe denote #S the cardinality of a set S. We also define N = N p ∪ Nt , E = E p ∪ Et , np = #N p , nt = #Nt , e p = #E p ,(cid:3)(cid:3)et = #Et , and dp and dt the maximal degrees of the graphs G p and Gt .3. Filtering for subgraph isomorphismSubgraph isomorphism problems may be modeled as constraint satisfaction problems in a very straightforward way.In this section, we first show how to model and solve subgraph isomorphism problems within a constraint satisfactionframework. Then, we describe different filtering algorithms for subgraph isomorphism in Sections 3.3 to 3.6, and we comparethem in Section 3.7.3.1. Modeling and solving subgraph isomorphism by means of constraintsA constraint satisfaction problem (CSP) is defined by a set of variables, such that each variable is associated with adomain (i.e., the set of values that it may be assigned to), and a set of constraints (i.e., relations that restrict the set ofvalues that may be assigned to some variables simultaneously). Solving a CSP involves finding an assignment of values toall variables such that all constraints are satisfied.A subgraph isomorphism problem may be modeled as a CSP by associating a variable (denoted xu ) with every patternnode u. The domain of a variable xu (denoted D u ) contains the set of target nodes that may be matched to u. Intuitively,assigning a variable xu to a value v corresponds to matching the pattern node u to the target node v. The domain D u isusually reduced to the set of target nodes the degree of which is higher or equal to the degree of u as node u may bematched to node v only if #adj(u) (cid:2) #adj(v).Constraints ensure that the assignment of variables to values corresponds to a subisomorphism function. There are twokinds of constraints:• edge constraints ensure that pattern edges are preserved, i.e.,(cid:2)∀u, u(cid:3)(cid:3)∈ E p,(xu, xu(cid:3) ) ∈ Et• difference constraints ensure that the assignment corresponds to an injective function, i.e.,(cid:2)∀u, u(cid:3)(cid:3)∈ N 2p,u (cid:11)= u(cid:3) ⇒ xu (cid:11)= xu(cid:3)Within this framework, solving a subgraph isomorphism problem involves finding an assignment of the variables that sat-isfies all constraints. We shall consider that a variable is assigned whenever its domain is reduced to a singleton, i.e.,D u = {v} ⇔ xu = v.Subgraph isomorphism problems modeled as CSPs may be solved by building a search tree that explores all possiblevariable assignments until finding a solution. The size of this search tree may be reduced by using filtering techniqueswhich propagate constraints to remove values from domains.We briefly recall some basic principles of constraint propagation in Section 3.2. Then, we describe different filteringtechniques that may be used to solve subgraph isomorphism problems in Sections 3.3 to 3.6. Note that some of thesefilterings (i.e., FC(Diff ), GAC(AllDiff ), FC(Edges), and AC(Edges)) are generic constraint propagation techniques that may beused to solve any CSP whereas some others (i.e., LV2002 and ILF(k)) are dedicated to the subgraph isomorphism problem.3.2. Recalls on constraint propagationConstraint propagation aims at filtering variable domains by removing inconsistent values, that is, values that do notbelong to any solution. This constraint propagation step may be done at each choice point of the search. If it removes allvalues in the domain of a variable, then the search can backtrack to a previous choice.A pioneering work for constraint propagation has been done in 1972 by Waltz for a scene drawing application [19].Since then, many different constraint propagation algorithms have been proposed. These algorithms achieve different partialconsistencies and also have different time and space complexities. In this section, we do not aim at describing all existingpropagation algorithms. We only briefly describe two basic and well-known generic techniques, that is, forward-checking andmaintaining arc-consistency. The reader may refer to [17,10] for more information.\f852C. Solnon / Artificial Intelligence 174 (2010) 850–864Forward-checking The basic idea of forward-checking is to propagate all constraints involving a variable just after its as-signment in order to remove from the domains of the non-assigned variables any value which is not consistent with thisassignment. More precisely, after the assignment of xi to v i , one propagates binary constraints between xi and any non-assigned variable x j by removing from the domain of x j any value v j such that the assignment {(xi, v i), (x j, v j)} violatesthe constraint holding between xi and x j . When constraints have arities greater than two, one may propagate constraintssuch that all variables but one are assigned.Maintaining arc-consistency A stronger filtering, but also a more expensive one, is obtained by maintaining arc-consistency,also called 2-consistency. Roughly speaking, a binary CSP is arc-consistent if each value v i in the domain of a variable xihas at least one support in the domain of every other variable, thus ensuring that if xi is assigned to v i then each othervariable still has at least one consistent value in its domain. More precisely, given a variable xi ∈ X and a value v i ∈ D(xi),a support of (xi, v i) for a variable x j is a value v j ∈ D(x j) such that the partial assignment {(xi, v i), (x j, v j)} is consistent.A binary CSP ( X, D, C) is arc-consistent if every value in every domain has at least one support in the domain of each othervariable.To maintain arc-consistency while constructing a partial assignment A, we filter variable domains after each variableassignment by removing non-supported values. Such a filtering must be repeated until no more domain is reduced: as soonas a value is removed, we must chec",
            {
                "entities": [
                    [
                        3513,
                        3541,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 265–299www.elsevier.com/locate/artintRedundancy in logic II: 2CNF and Horn propositional formulaePaolo LiberatoreDipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Ariosto 25, 00185 Roma, ItalyReceived 9 August 2006; received in revised form 4 June 2007; accepted 15 June 2007Available online 27 June 2007AbstractWe report results about the redundancy of formulae in 2CNF form. In particular, we give a slight improvement over the trivialredundancy algorithm and give some complexity results about some problems related to finding Irredundant Equivalent Subsets(I.E.S.) of 2CNF formulae. The problems of checking whether a 2CNF formula has a unique I.E.S. and checking whether a clausein is all its I.E.S.’s are polynomial. Checking whether a 2CNF formula has an I.E.S. of a given size and checking whether a clauseis in some I.E.S.’s of a 2CNF formula are polynomial or NP-complete depending on whether the formula is cyclic. Some resultsabout Horn formulae are also reported.© 2007 Elsevier B.V. All rights reserved.Keywords: Propositional logic; Computational complexity; Redundancy1. IntroductionProblems related to redundancy in logic and similar fields has been investigated by a number of authors. Ginsberg[9] and Schmolze and Snyder [25] studied the problem of redundancy of production rules. Several authors investi-gated the problem of minimizing a formula, with particular emphasis on Horn formulae [1,11,12,19,20,28]. Gottloband Fermüller [10] gave results about the redundancy of a literal in a first-order clause. Liberatore [17,18] providedcomplexity results for the CNF case and for some non-classical logics. Büning and Zhao [3] studied the problems ofequivalence and extension-equivalence of irredundant formulae. Various authors have studied the problem of minimalunsatisfiability [2,7,21].In this article, we report about the complexity of some problems related to the redundancy of formulae in 2CNF andHorn form. In particular, the considered problems are that of checking whether a formula is redundant, establishingthe minimal size of an Irredundant Equivalent Subset (I.E.S.) of a formula, and checking whether a clause is in someI.E.S.’s of a formula. The first problem is polynomial due to the polynomiality of consistency checking for 2CNF andHorn formulae, but a slight improvement over the trivial algorithm exists. For the two other problems, complexity isshown to be polynomial or NP-complete depending on the structure of the formula.There are several reasons for checking redundancy of a formula and for finding an irredundant and equivalentsubset of it. Most of these reasons apply to all kind of formulae, regardless of whether they are general propositionalE-mail address: paolo@liberatore.org.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.06.003\f266P. Liberatore / Artificial Intelligence 172 (2008) 265–299formulae, 2CNF, Horn, or formulae of non-classical logics. Some are peculiar to tractable restrictions such as 2CNFand Horn.Generally, a logic formula may come either from a user directly encoding a domain of interest or from an automatedtranslation from some formal language. In the first case, the presence of a redundant part of a formula may indicate thatsome aspects of the domain are either of particular importance or not sufficiently understood. Intentional redundancyof information about a particular part of a domain may indicate a will or need to be sure that part of the domainis correctly encoded. On the other hand, an unintentional redundancy may indicate undetected problems with theencoding, such as multiple people using the same names for expressing different concepts. Simplifying a formulaby removing redundancy shows which parts are really needed; this may result in error detection if redundancy wasunintentional, and in a confirmation of correctness if it was intentional.If a formula results from a translation, its redundancy may give the same indications on the information in thelanguage it was originally expressed. However, it may also highlight problems that are introduced by the translationitself. As an example, while each of a set of formulae may be correct by itself, their merging may result in an incon-sistent formula because of the different meaning of the variables in different formulae [16]. The same problem mayhowever also generate redundancy. Depending on the particular scenario, redundancy may also results from severalsources providing the same information. Either way, detecting redundancy tells something significant.On the technical side, redundancy has been sometimes intentionally added to formulae to speed-up consistencyand entailment solving. Removing redundancy is a way to make such formulae easier to understand to humans.On the other hand, increasing the size of formulae generally makes solving harder. This is particular important forthose cases where consistency and entailment are polynomial problems, such as 2CNF and Horn. If a set of clausesoriginally contains a large number of redundant clauses, removing some redundant ones may provide a speedup dueto the reduction in size of the original formula. This gain is useful when the same formula is for example checkedfor consistency with or entailment to several different formulae, because the cost of redundancy removal is amortizedamong several consistency or entailment tests.The results presented in this paper differ from previous work in either the settings or in the specific analyzedproblems, or both. Related work regarding different settings are those by Ginsberg [9] and Schmolze and Snyder [25],as they are about production rules and not propositional formulae. Gottlob and Fermüller [10] also worked in adifferent logic, the first-order one, but also studied a different problem, that or redundancy within a single clauserather than the redundancy of a clause within a set of clauses. Liberatore [18] investigated redundancy for somenon-classical logics.Related work regarding propositional logic can be roughly divided into three classes. First, we have the investiga-tions into making a propositional formula as small as possible while preserving equivalence. This problem originatesfrom the article where the polynomial hierarchy has been introduced [20], and has been then subject of a number ofother studies [1,11,12,19,28]; emphasis is often of Horn formulae. These results differ from the ones in the presentarticle because they are about a different problem. Minimizing a formula means producing an equivalent formula ofminimal size; such formula can be syntactically very different from the original one, to the point of not sharing anyrecognizable part with it. Minimization and redundancy elimination are therefore different tasks, and they serve dif-ferent purposes: minimization produces a formulae of strictly minimal size; redundancy elimination is not required toreduce size as much as possible, but preserves the structure of the original formula by not adding any new part to it.The other two classes of related work are about the problems where irredundancy is a restriction over the alloweddata and about subproblems of irredundancy. In the first class falls the work of Büning and Zhao [3], who studiedproblems under the restriction that the involved formulae are irredundant. In the second class we have the problem ofminimal unsatisfiability [2,7,21]; this problem can be considered as the subcase of irredundancy when the consideredformula is assumed to be unsatisfiable. In this article, we also work in this settings by showing results for 2CNFunsatisfiable formulae.Liberatore [17] provided complexity results for the CNF case. The present article contains a similar study, butfor the 2CNF and Horn case. These special cases are generally considered of importance because consistency andentailment is polynomial, rather than NP-complete, in them. While the Horn case is generally considered the mostimportant of these two subcases, attention to the 2CNF case has also been given, as shown by a number of recentarticles on the subject [4,5,13,26,27,29].The rest of the paper is organized as follows. In the next section, we give a technical overview of the presentedresults. We then give some general theorems that will be used for proving those results. In the following four sections,\fP. Liberatore / Artificial Intelligence 172 (2008) 265–299267results will be shown for the problems of redundancy checking and Irredundant Equivalent Subsets (I.E.S.). In partic-ular, Section 4 contains result about redundancy checking; Section 5 contains the easiest results about I.E.S.’s; Section6 is about the size of I.E.S.’s; and Section 7 is about the problem of checking whether a clause is in some I.E.S.’s of agiven formula. Section 8 contains some results about Horn formulae. Technical lemmas and proofs are moved to theappendix for ease of reading.2. Overview of resultsThe first problem we consider is that of checking the redundancy of a 2CNF formula. Since a formula is redundantif and only if it is equivalent to one of its subsets and checking equivalence for 2CNF formulae is polynomial, theproblem is polynomial. We slightly improve over the trivial algorithm by showing that redundancy can be checked intime O(nm), where n is the number of variables and m is the number of clauses of the formula.The other problems we consider are about the irredundant equivalent subsets (I.E.S.) of a formula. In particular, thefollowing problems are easily shown to be polynomial for formulae in 2CNF: check whether a formula is an I.E.S. ofanother one; check whether a clause is in all I.E.S.’s of a formula; and check whether a formula has an unique I.E.S..The last two problems are polynomial thanks to the following results [17]: a clause γ is in all I.E.S.’s of a formula Πif and only if Π\\{γ } |= γ ; a formula Π has an unique I.E.S. if and only if {γ ∈ Π | Π\\{γ } (cid:3)|= γ } |=",
            {
                "entities": [
                    [
                        2872,
                        2900,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 673–693Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom Bidirectional Associative Memory to a noise-tolerant, robust ProteinProcessor Associative Memory ✩Omer Qadir∗, Jerry Liu, Gianluca Tempesti, Jon Timmis, Andy TyrrellDepartment of Electronics, University of York, Heslington, YO10 5DD, York, UKa r t i c l ei n f oa b s t r a c tProtein Processor Associative Memory (PPAM) is a novel architecture for learning associ-ations incrementally and online and performing fast, reliable, scalable hetero-associativerecall. This paper presents a comparison of the PPAM with the Bidirectional AssociativeMemory (BAM), both with Kosko’s original training algorithm and also with the more pop-ular Pseudo-Relaxation Learning Algorithm for BAM (PRLAB). It also compares the PPAMwith a more recent associative memory architecture called SOIAM. Results of training forobject-avoidance are presented from simulations using player/stage and are verified byactual implementations on the E-Puck mobile robot. Finally, we show how the PPAM iscapable of achieving an increase in performance without using the typical weighted-sumarithmetic operations or indeed any arithmetic operations.© 2010 Elsevier B.V. All rights reserved.Article history:Received 8 March 2010Received in revised form 19 October 2010Accepted 21 October 2010Available online 27 October 2010Keywords:Self-organisingSelf-regulatingAssociative MemoryProtein processingHetero-associativeBAMPRLABSOIAMSABREMobile robotics1. IntroductionThe work in this paper stems from research into parallel architectures targeted towards problems in the domain of AI.Although, many architectures exist that attempt solutions for problems in this domain [38,2,22,37,3,21]. These are based onArithmetic and Logic Units (ALUs) and often are simply Von Neumann style processors (with a few modifications) connectedtogether in parallel. Despite the abundance of AI algorithms and machine learning techniques, the state of the art still failsto capture the rich analytical properties of biological beings or their robustness. In our architecture, computation is movedinto memory and intelligence is expected to emerge from memory operations rather than ALU operations. It is basedon the connectionist approach, which affords a level of inherent fault-tolerance, which is further enhanced by a designcomposed of a large number of elements, none of which are individually critical to the overall correct operation. This isin contrast to more traditional approaches to fault-tolerance where each module or component is designed to be uniqueand (hot or cold) spares are maintained which can be used to replace faulty modules. In our architecture, faults shouldresult in graceful degradation, rather than nodes having to be replaced. It is postulated that such an architecture is bettersuited to implementing artificial intelligence than the more traditional ALU based architectures. Although some portions areinspired by biological neural networks, the objective is not to build an architecture for Artificial Neural Networks. Note that✩The research is supported by EPSRC under grant no. FP/F06219211.* Corresponding author.E-mail addresses: oq500@ohm.york.ac.uk (O. Qadir), yl520@ohm.york.ac.uk (J. Liu), gt512@ohm.york.ac.uk (G. Tempesti), jt517@ohm.york.ac.uk(J. Timmis), amt@ohm.york.ac.uk (A. Tyrrell).URL: http://www-users.york.ac.uk/~oq500/ (O. Qadir).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.008\f674O. Qadir et al. / Artificial Intelligence 175 (2011) 673–693the current version does not fully satisfy the original motivation of designing an architecture for hardware, however, it issuitable for software implementations.Traditional memory stores data at a unique address and can recall the data upon presentation of the complete uniqueaddress. Auto-associative memories are capable of retrieving a piece of data upon presentation of only partial informationfrom that piece of data. Hetero-associative memories, on the other hand can recall an associated piece of data from onecategory of input upon presentation of data from another category of inputs. Hopfield networks [13] have been shown to actas auto-associative memories [6] since they are capable of remembering data by observing a portion of the data. Biologicalneural networks, on the other hand, are hetero-associative memories since they can remember a completely different itemto the one presented as input. Bidirectional Associative Memories (BAM) [18] are Artificial Neural Networks that have longbeen used for performing hetero-associative recall. This paper starts by investigating the efficacy of BAMs for performinghetero-associative recall in the context of AI for robotics. Association is performed between sonar values and the actionsneeded to avoid obstacles on a robot. Two different training algorithms are examined for the generation of the correlationmatrix in the BAM, namely the original BAM training algorithm outlined in Kosko [18] and the popular Pseudo-RelaxationLearning Algorithm for BAM (PRLAB) first presented in Oh and Kothari [27]. Even though the PRLAB guarantees optimallearning, distinguishing between values that are closely spaced is a weakness of the BAM. Nevertheless, such values arerealistic inputs for a real-time, noisy environment and we show that although parameters are optimized to maximize recall,even small confusions can result in major problems for a mobile robot, particularly in an online learning environment. Thepaper goes on to compare the structural differences between the Protein Processor Associative Memory (PPAM) and theBAM and then presents some results of implementations of the PPAM on the same problem. It discusses the robustness andnoise tolerance of the PPAM architecture and also compares this with noise tolerance reported by Sudo et al. [35] for theSelf-Organising Incremental Associative Memory (SOIAM). The paper is structured as follows: Section 2 is a brief discussionof BAM and PRLAB – their constraints and advantages. Section 3 outlines the experimental method, setup, parameter tuningand details the experiments performed. Section 4 presents the results of the BAM implementation on the player/stage robot.Section 5 describes the PPAM ending with a structural comparison of the BAM and the PPAM. Section 6 reviews the resultsfrom the PPAM implementation on the player/stage robot. Section 7 discusses the results and noise tolerance propertiescomparing them with SOIAM and also presents some inferences that can be drawn from the results. Section 8 summarises,concludes and discusses future directions.2. Bidirectional Associative MemoriesBidirectional Associative Memories [18] are a generalization of the Hopfield networks [13] both of which have theirbeginnings in the Correlation Matrix Memories ([17], cited in [1]). BAMs have long been the subject of analysis and haveformed the basis of many later models. Attempts to find the best training algorithm include [5] which uses an exponentialrule, [33] which uses genetic algorithms, [45] which uses descending gradient method, [7] which uses linear programmingtechniques among others. [32] is a non-iterative Morphological BAM while [41] is a non-iterative feedforward BAM. [1] isyet another variation based on two binary meta-operators and called the Alpha–Beta BAM. Cao et al. [4] discuss higher orderBAMs with time delays and Lu et al. [23] consider the effects of topology on the performance of Hopfield-type associativememories.Like other traditional neural networks, this 2-layer, non-linear, recurrent neural network starts by training on a definedtraining dataset and then moves on to the actual test set. The weighted-sum approach means that the capabilities canbe analysed and proven on paper using mathematics. Furthermore, the original training algorithm does not require batchlearning and therefore is easily adaptable for online learning. On the other hand, it results in sub-optimal utilization ofcapacity. Furthermore, as shown by Kosko [18], the BAM can get confused when storing one-to-many or many-to-onerelationships. In addition, if too many pairs are trained, the correlation matrix becomes unstable and the BAM is likely toforget all previously learnt pairs.Obviously it is desirable to maximise the storage capacity or at least to quantify it and many attempts have been madein this (latter) direction. Tanaka et al. [36] perform statistical physical analysis and estimate the capacity of pairs to beretrievable allowing a finite fraction of retrieval error to be 0.1998N where N is the number of neurons in each layerof two layers. The fact that the capacity of a BAM is tied to the number of nodes is a drawback in terms of scalability.Wang and Vachtsevanos [39] derive the storage capacity of a discrete BAM which is further verified by our experimentalresults. It shows that the storage capacity is much smaller than expected because of the mis-learning behavior where theBAM connection matrix confuses similar patterns because of the bipolar encoding scheme. Since bipolar encoding performsbetter on average than binary encoding, as shown by Kosko [18], this mis-learning is unavoidable.In essence, the problem is to maximise the number of patterns superimposed on one memory medium, namely, theweights of connections in a correlation matrix. Therefore, to guarantee recall, the training vectors must be orthogonal. Oneobvious solution is to re-encode non-orthogonal training data so that it becomes orthogonal as done by Simpson ([34], citedin [27]). Of course this does imply that the complete training set is known in advance, an assumption that is not valid foronline, real-time learning where training data is encountered sequentially and the complete size is not known in advance.PRLAB [27] is an iterative learning algorithm for discrete BAMs that maximises the storage capacity of the BAM witho",
            {
                "entities": [
                    [
                        3545,
                        3573,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 814–847Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic for reasoning about counterfactual emotions ✩Emiliano Lorini∗, François SchwarzentruberInstitut de Recherche en Informatique de Toulouse (IRIT), 118 route de Narbonne, 31062 Toulouse Cedex, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 December 2009Received in revised form 22 November 2010Accepted 22 November 2010Available online 2 December 2010Keywords:Modal logicEmotionsSTITThe aim of this work is to propose a logical framework for the specification of cognitiveemotions that are based on counterfactual reasoning about agents’ choices. The prototypicalcounterfactual emotion is regret. In order to meet this objective, we exploit the well-knownSTIT logic (Belnap et al. (2001) [9], Horty (2001) [30], Horty and Belnap (1995) [31]). STITlogic has been proposed in the domain of formal philosophy in the nineties and, morerecently, it has been imported into the field of theoretical computer science where itsformal relationships with other logics for multi-agent systems such as ATL and CoalitionLogic (CL) have been studied. STIT is a very suitable formalism to reason about choices andcapabilities of agents and groups of agents. Unfortunately, the version of STIT with agentsand groups has been recently proved to be undecidable and not finitely axiomatizable. Inthis work we study a decidable and finitely axiomatizable fragment of STIT with agentsand groups which is sufficiently expressive for our purpose of formalizing counterfactualemotions. We call df STIT our STIT fragment. After having extended df STIT with knowledgemodalities, in the second part of article, we exploit it in order to formalize four typesof counterfactual emotions: regret, rejoicing, disappointment, and elation. At the end ofthe article we present an application of our formalization of counterfactual emotions to aconcrete example.© 2010 Elsevier B.V. All rights reserved.1. IntroductionA major objective of AI is to develop interactive cognitive systems which are more attractive and closer to the users andthat can be considered as believable interlocutors [8]. In this perspective, a challenge for AI is to build artificial agents whichare capable of: reasoning about emotions, showing their affective states and personalities, ascribing emotions to humans,predicting the effects of their actions on emotions of humans, and adapting their behaviors accordingly. With the aim ofcreating a new generation of emotional interaction systems, the study of affective phenomena has become a “hot” topic inAI where the domain of Affective Computing [44] has emerged in the last few years.Recently, some researchers have been interested in developing logical frameworks for the formal analysis of emotions(see, e.g., [39,40,58,20]). Their main concern is to exploit logical methods in order to provide a rigorous specification ofhow emotions should be implemented in an artificial agent. The design of agent-based systems where agents are capable ofreasoning about and of displaying some kind of emotions can indeed benefit from the accuracy of logical methods. Theselogical frameworks for the specification of emotions are based on the so-called BDI logics (see e.g. [17,41]). BDI logics allowto model agents’ mental states such as beliefs, desires, intentions, ideals, values, etc., which are the cognitive constituentsof emotions.✩This work is an extended and improved version of the article “A logic for reasoning about counterfactual emotions” appeared in the Proceedings of theTwenty-first International Joint Conference on Artificial Intelligence (IJCAI’09), pp. 867–872.* Corresponding author. Tel.: +33 0561556447; fax: +33 561556258.E-mail addresses: lorini@irit.fr (E. Lorini), schwarze@irit.fr (F. Schwarzentruber).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.022\fE. Lorini, F. Schwarzentruber / Artificial Intelligence 175 (2011) 814–847815Although the application of logical methods to the formal specification of emotions has been quite successful, there isstill much work to be done in the field of computational and logical modeling of ‘counterfactual emotions’. In line withpsychological theories of ‘counterfactual emotions’, we use this term to denote those emotions such as regret which ariseduring ‘counterfactual thinking’, that is, when “[. . . ] reality is compared to an imagined view of what might have been” [33,p. 136]. In other terms, counterfactual emotions are based on an agent’s alteration of a factual situation and in the agent’simagination of an alternative situation that could have realized if something different was done [49].The aim of our work is to advance the state of the art on computational modeling of affective phenomena by providinga logic which supports reasoning about this kind of emotions. Our major concern here is to find a fair trade off betweenexpressivity and complexity of the formalism. We want a logic which is sufficiently expressive to capture the fundamentalconstituents of counterfactual emotions and, at the same time, with good mathematical properties in terms of decidabilityand complexity. To this aim, we exploit a well-known logic called STIT [9,30]. STIT logic has been proposed in the domainof formal philosophy in the nineties and, more recently, it has been imported into the field of theoretical computer sciencewhere its formal relationships with other logics for multi-agent systems have been studied (see, e.g., [12]). It is a verysuitable formalism to reason about counterfactual choices of agents and of groups. Unfortunately, the version of STIT withagents and groups proposed by Horty [30] has been recently proved to be undecidable and not finitely axiomatizable [29].In this work we study a decidable and finitely axiomatizable fragment of this logic which is sufficiently expressive for ourpurpose of formalizing counterfactual emotions.The paper is organized as follows. In Section 2 we introduce one of the most influential research approach to emotions:appraisal theory. We provide a general overview of existing models of emotions proposed in this area by devoting spe-cial attention to appraisal models of counterfactual emotions. We discuss how counterfactual emotions such as regret anddisappointment are defined in these models.Section 3 is the first step in developing a representation language for the formalization of counterfactual emotions. Weintroduce a fragment of the version of STIT logic with agents and groups proposed by Horty [30]. We call df STIT our STITfragment. Differently from Horty’s logic, we prove that our fragment is decidable and finitely axiomatizable.In Section 4, we exploit the STIT fragment df STIT in order to formalize counterfactual statements of the form “group J(or agent i) could have prevented χ to be true”. These statements are indeed basic constituents of counterfactual emotionsand will be fundamental for the formalization of counterfactual emotions given in Section 6.In Section 5, we extend the STIT fragment df STIT studied in Section 3 with knowledge operators. This is a necessarystep in order to capture the subjective dimension of the affective phenomena we intend to analyze in our work. We providedecidability results and a complete axiomatization for our epistemic extension of df STIT. We decided to present first theSTIT fragment without knowledge and then the extension with knowledge operators rather than to present a direct versionof a STIT fragment with knowledge operators for several reasons. The first one is because the STIT fragment withoutknowledge studied in Section 3 is interesting in itself since it already allows to express counterfactual statements which arean interesting component of counterfactual emotions. The second one is because the proof of decidability and the proof ofcompleteness of the STIT fragment with knowledge become much simpler after having studied the STIT fragment withoutknowledge.In Section 6, the logical framework of Section 5, is finally applied to the formalization of counterfactual emotions. Weprovide a formalization of four types of counterfactual emotions: regret and its positive counterpart rejoicing, disappointmentand its positive counterpart elation. The formal definitions of these four emotions will be based on the psychological modelsof counterfactual emotions discussed in Section 2. Section 7 presents an application of our logical formalization of counter-factual emotions to a concrete example. Before concluding we discuss in Section 8 some related works in the area of logicalmodeling of emotions and affective agents.Proofs of the main theorems are collected in the annex at the end of the article.2. Emotion theoriesOur general objective in this work is to provide a formal model of emotions which can be used as an abstract speci-fication for the design of artificial agents interacting with humans. To ensure the accuracy of a such a formal model, it isimportant to consider how emotions have been defined in the psychological literature. Indeed, in order to build artificialagents with the capability of recognizing the emotions of a human user, of anticipating the emotional effects of their actionson the human, of affecting the user’s emotions by the performance of actions directed to his emotions (e.g. actions aimedat reducing the human’s stress due to his negative emotions, actions aimed at inducing positive emotions in the human),we must endow such agents with an adequate model of human emotions.There exist several theoretical approaches to emotions in psychology. We here consider one of the most influential calledappraisal theory (see [53] for a broad introduction to the developments in appraisal theory).In Section 2.1, we provide a general introduction to appraisal theory by reviewing some of the most popular modelsproposed in this area. Then, in Sectio",
            {
                "entities": [
                    [
                        3953,
                        3981,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 186 (2012) 95–122Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnytime coalition structure generation in multi-agent systems withpositive or negative externalitiesTalal Rahwan a,∗,1, Tomasz Michalak a,b,1, Michael Wooldridge c, Nicholas R. Jennings a,da School of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ, UKb Institute of Informatics, University of Warsaw, Warsaw 02-097, Polandc Department of Computer Science, University of Liverpool, Liverpool L69 3BX, UKd Department of Computing and Information Technology, King Abdulaziz University, Saudi Arabiaa r t i c l ei n f oa b s t r a c tArticle history:Received 2 February 2011Received in revised form 29 October 2011Accepted 17 March 2012Available online 29 March 2012Keywords:Mechanism designClassificationGame theoryApproximationMuch of the literature on multi-agent coalition formation has focused on CharacteristicFunction Games, where the effectiveness of a coalition is not affected by how the otheragents are arranged in the system. In contrast, very little attention has been given to themore general class of Partition Function Games, where the emphasis is on how the formationof one coalition could influence the performance of other co-existing coalitions in thesystem. However, these inter-coalitional dependencies, called externalities from coalitionformation, play a crucial role in many real-world multi-agent applications where agentshave either conflicting or overlapping goals.Against this background, this paper is the first computational study of coalitional gameswith externalities in the multi-agent system context. We focus on the Coalition StructureGeneration (CSG) problem which involves finding an exhaustive and disjoint division ofthe agents into coalitions such that the performance of the entire system is optimized.While this problem is already very challenging in the absence of externalities, due to theexponential size of the search space, taking externalities into consideration makes it evenmore challenging as the size of the input, given n agents, grows from O (2n) to O (nn).Our main contribution is the development of the first CSG algorithm for coalitional gameswith either positive or negative externalities. Specifically, we prove that it is possible tocompute upper and lower bounds on the values of any set of disjoint coalitions. Buildingupon this, we prove that in order to establish a worst-case guarantee on solution quality itis necessary to search a certain set of coalition structures (which we define). We also showhow to progressively improve this guarantee with further search.Since there are no previous CSG algorithms for games with externalities, we benchmarkour algorithm against other state-of-the-art approaches in games where no externalitiesare present. Surprisingly, we find that, as far as worst-case guarantees are concerned, ouralgorithm outperforms the others by orders of magnitude. For instance, to reach a boundof 3 given 24 agents, the number of coalition structures that need to be searched by ouralgorithm is only 0.0007% of that needed by Sandholm et al. (1999) [1], and 0.5% of thatneeded by Dang and Jennings (2004) [2]. This is despite the fact that the other algorithmstake advantage of the special properties of games with no externalities, while ours doesnot.© 2012 Elsevier B.V. All rights reserved.* Corresponding author.E-mail address: tr@ecs.soton.ac.uk (T. Rahwan).1 Both Talal Rahwan and Tomasz Michalak are principle authors of this paper.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.03.007\f96T. Rahwan et al. / Artificial Intelligence 186 (2012) 95–1221. IntroductionThe ability to create effective coalitions is one of the key goals of multi-agent systems research. Coalitional games aremodels that capture opportunities for cooperation by explicitly modeling the ability of the agents to take joint actions asprimitives [3]. In this context, one of the key challenges is to generate a coalition structure, i.e., an exhaustive and disjointdivision of the set of agents, such that the performance of the entire system is optimized. This Coalition Structure Generation(CSG) problem has received much attention in the multi-agent system literature [4,1,5,2,6].(cid:3)To date, work on the CSG problem in the AI community has focused primarily on a class of coalitional games known asCharacteristic Function Games (CFGs), where the effectiveness, or value, of a coalition is not affected by the way non-membersare partitioned. There are, however, many settings where this assumption does not hold. Such settings are known as PartitionFunction Games, or PFGs [7]. Specifically, in PFGs a coalition’s value may be influenced by the formation of another coalition(cid:3) = {C1, C2 ∪ C3}, the value of C1 may bein the system. For instance, given two coalition structures: CS = {C1, C2, C3} and CSdue to the merger of C2 with C3. Such an effect is known as an externality from coalition formationdifferent in CS than in CSand, in this example, it is induced upon C1 by the merge of C2 and C3, which leads to the formation of coalition C2 ∪ C3.2Games with externalities have been widely studied in economics and other social sciences, where interdependenciesbetween coalitions play an important role. Examples include collusion in oligopolies, where cooperating companies seekto undermine the competitive position of other firms in the market, as well as various forms of international (macro-economic/environmental) policy coordination between countries [8,9]. For instance, when high-tech companies decide tocooperate in order to develop a new technology standard, other companies lose some of their competitive position, i.e., theyare subject to negative externalities. For instance, in the 1970’s, Japanese firms established the Very Large Scale Integration(VLSI) consortium as well as the Fifth Generation Computer Systems (FGCS) project [10]. Another example is the decisionby one group of countries to reduce pollution, which has a positive impact on other countries or regions, i.e., it inducespositive externalities (see, e.g., Finus [11], Yi [10]).The issue of externalities is also becoming increasingly important in domains in which multi-agent system techniques areapplied. In e-commerce, for example, the British company, Aerogistics,3 enables small- and medium-size aircraft componentmanufacturers and service providers to form online, ad hoc supply-chain coalitions to bid for manufacturing projects toolarge for any individual participant. Since all components must ultimately conform to the same standards, the cost ofstandarization procedures incurred by any coalition depends on the number and structure of other winning coalitions.In many multi-agent systems, negative externalities between a coalition and non-members can be caused by sharingresources [12,1]. Thus, if agents, after forming a coalition, consume more resources than before, then this means thatfewer resources are now available to the other coalitions. This is the case, for instance, in congestion games [13]. Negativeexternalities can also be caused by conflicting goals. Intuitively, by satisfying its own goals, a coalition may actually movethe world further from the other coalitions’ goals [14]. Conversely, overlapping or partially overlapping goals may causepositive externalities as some coalitions may satisfy goals of other coalitions [1].In spite of so many important applications, very little attention has been given to the computational aspects of gameswith externalities. In particular, there exist no algorithms in the literature to solve the CSG problem in PFGs. To this end, itshould be noted that the space of possible solutions to the CSG problem is the same for both CFGs and PFGs, with O (nn)solutions for n agents. The main difference, however, lies in the size of the input, which is O (2n) for CFGs, but O (nn) forPFGs. This is because, for every coalition, the input contains a single value — representing its performance — in the CFG case,while in the PFG case it contains as many values as there are possible partitions of the agents outside that coalition (seeSection 2 for more details). This makes the CSG problem significantly more challenging compared to the CFG case, which isalready NP-complete [1]. In fact, it can easily be shown that for the general case of PFGs it is not possible to solve the CSGproblem without examining every possible coalition structure. Intuitively, even if all but one have been examined, this lastone may be arbitrarily better than the rest.Against this background, we focus on two important classes of PFGs:+• PFG— coalitional games with weakly positive externalities. In this class, externalities are always non-negative, i.e., themerge of any two coalitions is never detrimental to other coalitions in the system.−• PFG— coalitional games with weakly negative externalities. Here, all externalities are non-positive, i.e., the merge ofany two coalitions is never beneficial to other coalitions in the system.4It should be stressed that nearly all the examples of coalitional games with externalities that are listed above belong toeither one or the other class! Specifically, cartels, environmental policy coordination between countries, and multi-agent+systems with partially overlapping goals are all games with positive externalities. That is, they belong to the class PFG.Conversely, collusion in oligopolies, exogenous coalition formation in e-market places, as well as multi-agent systems withshared resources and/or conflicting goals all belong to the PFGclass.−2 In the remainder of this paper we will refer to coalitional games as, simply, games, and to externalities from coalition formation as, simply, externalities.3 See www.aerogistics.com for more details.4 Throughout the paper, we will refer to weakly positiv",
            {
                "entities": [
                    [
                        3690,
                        3718,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 203–221Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintWikipedia-based WSD for multilingual frame annotationSara Tonelli∗, Claudio Giuliano, Kateryna TymoshenkoFondazione Bruno Kessler, via Sommarive 18, I-38100 Trento, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 11 November 2010Received in revised form 9 May 2012Accepted 16 June 2012Available online 18 June 2012Keywords:Frame annotationMultilingual FrameNetsWord sense disambiguationFrameNet–Wikipedia mapping1. IntroductionMany applications in the context of natural language processing have been proven toachieve a significant performance when exploiting semantic information extracted fromhigh-quality annotated resources. However, the practical use of such resources is oftenbiased by their limited coverage. Furthermore, they are generally available only for Englishand few other languages.We propose a novel methodology that, starting from the mapping between FrameNetlexical units and Wikipedia pages, automatically leverages from Wikipedia new lexical unitsand example sentences. The goal is to build a reference data set for the semi-automaticdevelopment of new FrameNets. In addition, this methodology can be adapted to performframe identification in any language available in Wikipedia.Our approach relies on a state-of-the-art word sense disambiguation system that is firsttrained on English Wikipedia to assign a page to the lexical units in a frame. Then, thismapping is further exploited to perform frame identification in English or in any otherlanguage available in Wikipedia. Our approach shows a high potentialin multilingualsettings, because it can be applied to languages for which other lexical resources suchas WordNet or thesauri are not available.© 2012 Elsevier B.V. All rights reserved.The FrameNet database [1,2] is an English lexical resource based on the description of some prototypical situations, theframes, and the frame-evoking words or expressions associated to them, the lexical units. Every frame corresponds to ascenario involving a set of participants, the frame elements, that are typically the semantic arguments shared by all lexicalunits in a frame. Given the rich semantic information provided by frames, there have been several attempts to exploit thisknowledge to improve diverse natural language processing (NLP) tasks, from question answering [3] to relation extraction[4], and entailment rules generation [5]. The integration of this semantic paradigm in existing NLP tools, however, has beenhindered by difficulties in creating systems for frame semantic parsing. Some attempts have been made, using FrameNetdata for training [6–8]. Since large amounts of data with high-quality annotation are currently available only in English [1]and German [9], however, the applicability of supervised approaches has been limited to these two languages. Alternativeapproaches based on systems that are not trained directly of FrameNet have been only partially explored by investigatingthe integration between FrameNet and WordNet [10–12] and the use of distributional approaches [13,14].In this article, Wikipedia is used as an extensive, multilingual repository of frame information in order to achieve twomain goals: first, to devise a novel approach to multilingual frame identification, a subtask of frame semantic parsing, withouttraining a system directly on FrameNet. Then, to retrieve a large amount of frame example sentences in different languages.* Corresponding author. Tel.: +39 0461 314 542; fax: +39 0461 314 591.E-mail addresses: satonelli@fbk.eu (S. Tonelli), giuliano@fbk.eu (C. Giuliano), tymoshenko@fbk.eu (K. Tymoshenko).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.002\f204S. Tonelli et al. / Artificial Intelligence 194 (2013) 203–221We rely on Wikipedia because of several reasons. First of all, it is the largest existing repository of encyclopedicknowledge, freely available in 282 languages. It combines free-form natural language content with structural informa-tion, represented by intra- and inter-language links. Furthermore, it generally shows high editorial quality, especially theWikipedia versions of widely used languages.In order to exploit Wikipedia to perform frame annotation, a strategy to link this resource to FrameNet has been pro-posed. However, we are aware that inter-operability between FrameNet and Wikipedia may be hindered by the differentstructure, granularity and extension of the two resources. Therefore, three main research questions are addressed in thisarticle: (i) Is it possible to link FrameNet and Wikipedia and to exploit the outcome of this mapping for frame identifica-tion? (ii) Which strategy can be chosen to devise a frame identification system that is not directly trained on FrameNetexamples? And how does it compare with state-of-the-art systems? (iii) Can the same strategy be employed to support thedevelopment of non-English FrameNets? To which extent?The first question has been partially addressed in the preliminary work by Tonelli and Giuliano [15], in which the idea touse Wikipedia as a multilingual repository of frame information was first presented. The second problem, instead, has notbeen tackled before. We address it by comparing our approach with a state-of-the-art frame semantic parser for English.As for multilingual frame annotation, the acquisition of frame example sentences from Italian Wikipedia was introducedby [15], although it was only marginally evaluated. On the contrary, a methodology to use the same frame identifica-tion approach for different languages is presented for the first time in this article, and is evaluated by comparing it withWordNet-based strategies [11].This article is structured as follows. We introduce FrameNet and Wikipedia in Section 2. We present past research workrelated to our approach in Section 3. A general description of our methodology is provided in Section 4. The Wikipedia-based disambiguation system is described and compared with the state of the art in Section 5. The methodology for mappingframe–lexical unit pairs with Wikipedia pages is described and evaluated in Section 6, in which the first of our researchquestions is addressed (see items above). Then, in Section 7 a new frame identification approach is described and applied toEnglish lexical units. A thorough evaluation and a comparison with the state-of-the-art SEMAFOR system [8] are reported,addressing our second research topic. Section 8 is devoted to our third research question and details a two-fold strategyfor the creation of multilingual FrameNets: first, example sentences and lexical units in a new language are extracted fromWikipedia, and then the word sense disambiguation (WSD) system is used for multilingual frame identification. Finally, wedraw some conclusions and discuss future work in Section 9.2. FrameNet and Wikipedia: description and terminologyFrameNet [1,2] is a lexical resource for English, based on frame semantics [16], that is being created in the context of theBerkeley FrameNet project.1 Its aim is to collect the range of semantic and syntactic combinatorial possibilities of each wordin each of its senses through the annotation of example sentences. The conceptual model is based on three main elements:• Semantic frames: Cognitive schemata or scenarios necessary to understand the meaning of words. They describe situa-tions, objects and events and the participants involved in them.• Lexical units (LUs): Words, multiwords, idiomatic expressions evoking a frame.• Frame elements (FEs): Semantic roles involved in the situation or event expressed by a frame. They apply to all LUs inthe same frame.FrameNet 1.3, released in 2006, is comprised of more than 10,195 lexical units, 6000 of which are fully annotated, andnearly 800 semantic frames with hierarchical relations. An essential element of the FrameNet database is the corpus-basedevidence, i.e., every lexical has to be instantiated by at least one example sentence. In FrameNet 1.3, more than 135,000sentences have been manually annotated with frame information.As an example, we report in Table 1 the FrameNet entry for the Wearing frame.In the first row, the frame definition in natural language is reported, while the second includes the list of the coreframe elements. The third row contains part of the LU list including all frame-evoking predicates, while in the fourth a fewexample sentences are reported. All LUs are printed in bold, while the phrases bearing a FE label are reported betweensquare brackets, followed by the role label.In the remainder of this article, we call frame semantic annotation the annotation of sentences with both frame and FE(or role) information, as performed by frame-semantic parsers (e.g. [6] and [8]). The sub-task of assigning a frame label toa lexical unit in a sentence is called frame identification. This concerns both lexical units that are listed in FrameNet, theso-called seen LUs, and those that are not present in the resource, the unseen LUs. When frame identification is applied tounseen LUs, and leads to the acquisition of new LUs, it is also known as LU induction [13].The second resource we take into account in this work is Wikipedia, the largest online repository of encyclopedic knowl-edge. At the moment of writing, there are 20 million articles in 282 languages (over 3.82 million in English alone) written1 http://framenet.icsi.berkeley.edu/index.php.\fS. Tonelli et al. / Artificial Intelligence 194 (2013) 203–221205Table 1Wearing frame.Frame: WearingDef.FEsLUsEx.The words in this frame refer to what clothing a wearer (or a specific body_part of the wearer) has on.body_partclothingwearerThe body part of the wearer which is covered by the clothing.This FE identifies the clothing that the wearer wears.The person whose clothing is under discussion.attired.",
            {
                "entities": [
                    [
                        3836,
                        3864,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1180–1193Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelational preference rules for control ✩Ronen I. BrafmanDepartment of Computer Science, Ben-Gurion University, PO Box 653, Beer-Sheva 84105, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 28 February 2009Received in revised form 4 July 2010Accepted 4 July 2010Available online 1 December 2010Keywords:Preference modelsPreference rulesRelational modelsRule-based systemsCommand and control automationValue functions are defined over a fixed set of outcomes. In work on preference handlingin AI, these outcomes are usually a set of assignments over a fixed set of state variables.If the set of variables changes, a new value function must be elicited. Given that inmost applications the state variables are properties (attributes) of objects in the world,this implies that the introduction of new objects requires re-elicitation of preferences.However, often, the user has in mind preferential information that is much more generic,and which is relevant to a given type of domain regardless of the precise number ofobjects of each kind and their properties. Such information requires the introduction ofrelational models. Following in the footsteps of work on probabilistic relational models(PRMs), we suggest in this work a rule-based, relational language of preferences. Thislanguage extends regular rule-based languages and leads to a much more flexible approachfor specifying control rules for autonomous systems. It also extends standard generalized-additive value functions to handle a dynamic universe of objects. Given any specific set ofobjects this specification induces a generalized-additive value function over assignments tothe controllable attributes associated with these objects. We then describe a prototype of adecision support system for command and control centers we developed to illustrate andstudy the use of these rules.© 2010 Elsevier B.V. All rights reserved.1. IntroductionMuch of the work in AI on preference handling has focused on tools for modeling preferences of lay users, often inapplications related to electronic commerce, such as support for online selection of goods [29,12,10,4], tools for prefer-ence elicitation in combinatorial auctions [33], recommender systems [12], etc. Some work also targets the more classicaldecision-analysis setting which is usually mediated by an expert decision analyst, supporting the elicitation process of thedetailed classical structures used there, namely utility functions (e.g., [11,17]). However, much less work considers the useof preferences as a key tool in the design of complex systems.The idea of using preferences to design autonomous systems is quite intuitive. Autonomous systems make many decisionsduring their run-time, and ideally, their choices should be the ones maximally preferred among available choices at thecurrent context. A preference-based design explicitly models the designer’s preferences for different choices in differentcontexts, and uses a generic mechanism for selecting a preferred feasible choice at run-time.A preference-based design can provide a uniform declarative and modular approach for the design and specificationof certain autonomous systems. It is naturally amenable to customization, both before and during deployment, either byproviding additional information about the context, or allowing for additional user-specific preferences. Compared withelectronic commerce-based applications which deal with users who usually spend little time with the system and require✩A preliminary version of this paper appears in the Proceedings of the International Conference on Knowledge Representation and Reasoning, 2008 [9].E-mail address: brafman@cs.bgu.ac.il.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.010\fR.I. Brafman / Artificial Intelligence 175 (2011) 1180–11931181an interface that is immediately intuitive, the design context allows for more sophisticated and rich methods. A systemdesigner is likely to be willing to spend more than a few minutes on her system, and she can be expected to spend timelearning how to effectively specify her preference. On the other hand, the designer’s willingness to adopt a new tool islikely to depend greatly on the convenience and intuitive appeal of this tool, and on the amount of learning required touse it effectively without expert assistance. This puts the system design context somewhere between the end-user contextand the decision analysis context, and motivates the need for formalisms that address this setting. These formalisms mustprovide sufficient expressiveness while remaining intuitive.Decision-theoretic agent design is not a new paradigm. It pervades the classic text of [32], and recent work in roboticsshows that it can be very successful [24]. A full-fledged decision-theoretic approach requires maintaining a probabilisticstate estimate and a utility function. The main drawback of using classical, propositional probability distributions and utilityfunctions is that they limit the agent’s knowledge to a fixed set of propositions or objects. Thus, more generic knowledgeabout certain classes of objects, or relationships, cannot be captured. This limits the applicability of these systems to asingle fixed, static domain. On the probabilistic side, relational and object-oriented probabilistic models provide tools thatallow designers to describe generic probabilistic models that can then be used in diverse contexts in which the number andproperties of concrete object instances may be quite different. On the preference side, we are not there yet, although theneed to model preferences may be more pressing, as they are harder to learn from data because of their subjective nature.This need for preference representation tools that support the system design and control context and provide the abilityto express relational preferences in an intuitive manner that system designers can easily grasp, motivates this paper. Its maincontribution is the introduction of a simple relational preference formalism whose semantics generalizes that of generalizedadditive value functions. In addition, it explains how optimal choices can be computed given such a specification usingstandard techniques, such as variable elimination, but also, how this problem can be reduced to the problem of computingthe most probable explanation given a probabilistic relational model (PRM), leveraging existing algorithms for these models.Finally, we describe a concrete application domain, which is of independent interest, which serves to motivate this type offormalism and illustrate its possible application.Relational Preference Rules (RPRs) specify preferences for systems that act in dynamic environments where both the setof objects and their state change constantly. They combine ideas from rule-based systems and earlier preference formalismsleading to a simple rule-based syntax with weights attached to different choices. The basic idea is very simple: for everyvalue of a controllable attribute, specify what conditions affect its desirability, and how happy we would be to see this valuein this context. The syntax is simple:(cid:2)(Condition on attributes other than v) → v :(cid:4)(cid:3)list of (weight,value of v) pairsReaders familiar with formalisms such CP-nets [6] and especially UCP-nets [5] will see the clear resemblance to theconditional preference/utility tables used there, with one main difference: the conditions expressed in those formalisms arepropositional, whereas here we have conditions over relations. Indeed, given any concrete set of objects, these rules inducea concrete value function, which is induced by all possible groundings of these rules. Like rule-based systems, preferencerules-based systems can be used in process and decision control applications in which rule-based systems are currentlyused. They retain the natural form of rule-based systems, but are much more flexible because their conclusions are notbased on rigid deduction, but rather on optimization.Preference rules bare certain resemblance to soft constraint logic programs (SCLP) [2], though their semantics is different.They are also closely related to generalized-additive value functions [16,1], as each ground rule is a factor in the inducedvalue function. They can also be viewed as specifying a linear value function where the basis functions correspond to therules. Similar rules have been suggested as a formalism to specify the behavior of a multi-agent system. And of course,these rules were motivated by PRMs, of which Markov Logic is the most similar, semantically [31]. We will discuss theserelations in more depth in Section 4.The rest of this paper is structured as follows: In Section 2 we describe and discuss the syntax and semantics of pref-erence rules. Section 3 discusses the complexity of inference and how these rules can be transformed into Markov Logictheories. In Section 4 we discuss related work. In Section 5 we describe a system prototype we built using the methodol-ogy described in this paper. This system shows how preference rules can be used to select which information to displayto decision makers in a real-time command and control center. We conclude with a discussion of future challenges inSection 6.2. Preference rulesWe introduce the syntax and semantics of preference rules, and follow up with a discussion of some of our choices.2.1. The languageWe adopt an object-oriented world model. Objects are instances of certain object classes. A set of attributes is associatedwith every instance of every class. The value of these attributes may be a simple type, such as integers, reals, strings, or anobject class. Object-valued attributes capture binary relations between objects, and, in principle, any n-ary relation can be\f1182R.I. Brafman / Artificial Intelligence ",
            {
                "entities": [
                    [
                        3905,
                        3933,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1011–1038www.elsevier.com/locate/artintBounded model checking for knowledge and real timeAlessio Lomuscio a,1, Wojciech Penczek b,c,2, Bo˙zena Wo´zna d,∗,3a Department of Computing, Imperial College London, 180 Queen’s Gate, London SW7 2BZ, United Kingdomb Institute of Computer Science, PAS, Ordona 21, 01-237 Warsaw, Polandc Institute of Informatics, Podlasie Academy, Sienkiewicza 51, Siedlce, Polandd Institute of Mathematics and Computer Science, Jan Dlugosz University, Armii Krajowej 13/15, 42-200 Cz¸estochowa, PolandReceived 23 August 2006; received in revised form 2 April 2007; accepted 11 May 2007Available online 24 May 2007AbstractWe present TECTLK, a logic to specify knowledge and real time in multi-agent systems. We show that the TECTLK modelchecking problem is decidable, and we present an algorithm for bounded model checking based on a discretisation method. Weexemplify the use of the technique by means of the “Railroad Crossing System”, a popular example in the multi-agent systemsliterature.© 2007 Elsevier B.V. All rights reserved.Keywords: Temporal epistemic logics; Model checking; Interpreted systems; Real time systems1. IntroductionReasoning about knowledge [9] has always been a core concern in artificial intelligence. This is hardly surprisinggiven that knowledge is a key concept to model intelligent, rational activities, human or artificial. A plethora offormalisms have been proposed and refined over the years, many of them based on formal logic. One of the mostwidely studied is based on variants of modal logics and is commonly referred to as temporal epistemic logic [9].Rather than providing a computational engine for artificial agents’ reasoning, epistemic logic, at least in this line, isseen as a specification language for modelling and reasoning about systems, much in common with formal methodsin computer science. Formal properties of the logics such as completeness, decidability and complexity have beenexplored [10,12,13,20].Specification languages are most useful when they can be verified automatically. In this effort both theorem provingand model checking techniques as well as tools for epistemic logic have been developed. In the model checkingapproach the question of whether or not a system of agents S satisfies a property P is tackled by trying to establish* Corresponding author.E-mail addresses: A.Lomuscio@imperial.ac.uk (A. Lomuscio), penczek@ipipan.waw.pl (W. Penczek), b.wozna@ajd.czest.pl (B. Wo´zna).1 The author acknowledges partial support from the EPSRC (grant GR/S49353).2 The author acknowledges partial support from the Royal Society (grant ESEP 2004/R3-EU).3 The research presented here was conducted while B. Wo´zna was supported by EPSRC (grant GR/S49353). The author also acknowledgespartial support from the Ministry of Science and Information Society Technologies under grant number 3 T11C 011 28.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.005\f1012A. Lomuscio et al. / Artificial Intelligence 171 (2007) 1011–1038whether or not MS |= φP , where MS is a suitable model for S and φP is an appropriate logical formula representingP ; we refer to [8] for more details.In particular, for what concerns temporal epistemic logic, model checking techniques based on BDD [26,29],bounded model checking [23], unbounded model checking [16] have been developed and their implementation eitherpublicly released [11,26] or made available via a web-interface [22].While, one could now argue that verification via model checking of temporal epistemic logic has now become ofage, in many respects the area is still lacking support for many essential functionalities. One of these is real-time.While the formalisms above deal with discrete sequence of events, it is often of both theoretical and practical interestto refer to a temporal model that assumes a dense sequence of events and uses operators able to represent densetemporal intervals. The aim of this work is to make a first step in this direction. In particular, recent contributionshave focused on extending model checking techniques and tools [14,23,25,26,28,32], to adapt them to the needs ofmulti-agent systems (MAS) formalisms [6,9,14,15].Specifically, we make two contributions: first we present a logic, that we call TECTLK, to reason about realtime and knowledge in MAS; second, we present a bounded model checking technique for verifying automaticallyproperties of multi-agent systems expressed in this logic.The rest of the paper is organised as follows. The next section defines Real Time Interpreted Systems, the semanticson which we work with throughout the paper. In Section 3 the logic TECTLK is introduced. Section 4 deals withthe discretisation process necessary for the bounded model checking algorithm, discussed in Section 5. Section 6shows how this method can be applied to the “railroad crossing system”, a typical multi-agent system example of timedependent systems. We conclude in Section 7 by discussing some related work.2. Real Time Interpreted SystemsIn this section we briefly recall the concept of timed automata, which were introduced in [2], and define Real TimeInterpreted Systems.2.1. Timed automataLet R = [0, ∞) be a set of non-negative real numbers, R+ = (0, ∞) a set of positive real numbers, N = {0, 1, . . .}a set of natural numbers, X a finite set of real variables, called clocks, x ∈ X , c ∈ N, and ∼ ∈ {(cid:2), <, =, >, (cid:3)}. Theclock constraints over X are defined by the following grammar:cc := true | x ∼ c | cc ∧ cc.The set of all the clock constraints over X is denoted by C(X ). Note that inequalities involving differences of clocksare not in C(X ).A clock valuation on X is a tuple v ∈ R|X |. The value of the clock x in v is denoted by v(x). For a valuation v andδ ∈ R, v + δ denotes the valuation v(cid:7) such that for all x ∈ X , v(cid:7)(x) = v(x) + δ. For a subset of clocks X ⊆ X , v[X := 0]denotes the valuation v(cid:7) such that v(cid:7)(x) = 0 for all x ∈ X, and v(cid:7)(x) = v(x) for all x ∈ X \\ X. The satisfaction relation|= for a clock constraint cc ∈ C(X ) and v ∈ R|X | is defined inductively as follows:v |= true,v |= (x ∼ c) iff v(x) ∼ c,(cid:7)v |= (cc ∧ cc(cid:7)) iff v |= cc iff v |= cc.For a clock constraint cc ∈ C(X ), by (cid:2)cc(cid:3) we denote the set of all the clock valuations satisfying cc, i.e., (cid:2)cc(cid:3) ={v ∈ R|X | | v |= cc}.Definition 1 (Timed automaton). A timed automaton is a tuple T A = (Z, L, l0, E, X , I), where Z is a finite set ofactions, L is a finite set of locations, l0 ∈ L is an initial location, X is a finite set of clocks, E ⊆ L×Z×C(X )×2X ×Lis a transition relation, and I : L → C(X ) is a location invariant function, assigning to each location l ∈ L a clockconstraint defining the conditions under which T A may stay in l.Each element e of E is denoted by l a,cc,X−−−−→ l(cid:7), where l is the source location, l(cid:7) is the target location, a is an action,cc is the enabling condition for e, and X ⊆ X is the set of clocks reset when performing e.\fA. Lomuscio et al. / Artificial Intelligence 171 (2007) 1011–10381013Fig. 1. A timed automaton.The clocks of a timed automaton are used to express its timing conditions. We differentiate between enablingconditions and invariant conditions. An enabling condition is a temporal constraint which must be satisfied for thetransition to occur. An invariant condition I(l) specifies the temporal constraint that must be satisfied for the automatonto remain in l.in,x(cid:2)300,∅−−−−−−−→ t2, t2out,true,∅−−−−−→ t3, and t3Example 1. Fig. 1 shows a timed automaton consisting of four locations: t0, t1, t2, and t3, where t0 is the initial loca-approach,true,{x}−−−−−−−−−−→ t1,tion, one clock x, the set of actions Z = {approach, in, out, exit}, and the following transitions: t0exit,x(cid:3)500,∅−−−−−−−−→ t0. The invariant of the location t0 is true, whereas all the otherst1locations are labelled with the invariant x (cid:2) 500. Intuitively, the example models a system starting from t0 and movingto t1 by the action “approach” thereby causing the clock to be reset. The automaton must then execute the action “in”between the clock values of 300 and 500, thereby reaching location t2. From t2 the action “out” must be performedbefore the clock reaches the value of 500 resulting in t3. From t3 the action “exit” must be performed before the clockreaches the value of 500 resulting in t0. Note that the enabling condition in t3 is in this case redundant.We take a timed-automaton as a fine-grained model of a real-time agent. A (real-time) multi-agent system will bedefined as a set of communicating timed automata combined via parallel composition into a global timed automaton.In the composition the transitions not corresponding to a shared action are interleaved, whereas the transitions labelledwith a shared action are synchronised. Several definitions of parallel composition exist. Here we use multi-way syn-chronisation [27], i.e., we require that each component with a communication transition (labelled by a shared action)has to perform this action when the global transition occurs.Formally, let T Ai = (Zi, Li, l0i , Ei, Xi, Ii) be a timed automaton for i = 1, . . . , m, Li ∩ Lj = ∅ for all i, j ∈{1, . . . , m} and i (cid:12)= j , and let Z(a) = {1 (cid:2) i (cid:2) m | a ∈ Zi} denote the set of indices of the timed automata whose setsof actions contain the action a. The parallel composition is defined as follows.Definition 2 (Parallel composition). A parallel composition of m timed automata T Ai is a timed automaton T A =m(Z, L, l0, E, X, I), where Z =i=1 Ii(li).Each global transition is such thatXi , I(l1, . . . , lm) =mi=1 Li , l0 = (l0mi=1 Zi , L =m), X =1 , . . . , l0mi=1(cid:2)(cid:4)(cid:3)(cid:2)((l1, . . . , lm), a, cc, X, (l(cid:5)cci, X =cc =(cid:7)1, . . . , l(cid:6)(cid:7)m)) ∈ E iff (∀i ∈ Z(a))(li, a, cci, Xi, lXi, and (∀j ∈ {1, . . . , m} \\ Z(a)) l(cid:7)i) ∈ Ei,= l",
            {
                "entities": [
                    [
                        2992,
                        3020,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 164 (2005) 47–80www.elsevier.com/locate/artintMaxSolver: An efficient exact algorithm for(weighted) maximum satisfiabilityZhao Xing, Weixiong Zhang ∗Department of Computer Science and Engineering, Washington University in Saint Louis,Saint Louis, MO 63130, USAReceived 17 April 2004Available online 2 March 2005AbstractMaximum Boolean satisfiability (max-SAT) is the optimization counterpart of Boolean satisfiabil-ity (SAT), in which a variable assignment is sought to satisfy the maximum number of clauses in aBoolean formula. A branch and bound algorithm based on the Davis–Putnam–Logemann–Lovelandprocedure (DPLL) is one of the most competitive exact algorithms for solving max-SAT. In this pa-per, we propose and investigate a number of strategies for max-SAT. The first strategy is a set ofunit propagation or unit resolution rules for max-SAT. We summarize three existing unit propaga-tion rules and propose a new one based on a nonlinear programming formulation of max-SAT. Thesecond strategy is an effective lower bound based on linear programming (LP). We show that the LPlower bound can be made effective as the number of clauses increases. The third strategy consistsof a binary-clause first rule and a dynamic-weighting variable ordering rule, which are motivated bya thorough analysis of two existing well-known variable orderings. Based on the analysis of thesestrategies, we develop an exact solver for both max-SAT and weighted max-SAT. Our experimentalresults on random problem instances and many instances from the max-SAT libraries show that ournew solver outperforms most of the existing exact max-SAT solvers, with orders of magnitude ofimprovement in many cases. 2005 Elsevier B.V. All rights reserved.Keywords: Weighted maximum satisfiability; DPLL; Unit propagation; Linear programming; Nonlinearprogramming; Variable ordering* Corresponding author.E-mail addresses: zx2@cse.wustl.edu (Z. Xing), zhang@cse.wustl.edu (W. Zhang).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.004\f48Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–801. Introduction and overviewBoolean satisfiability (SAT) is an archetypical decision problem in artificial intelligence,logic and theory of computation. SAT with more than two literals (variables or their nega-tions) per clause is NP-complete [6,29]. Maximum Boolean satisfiability (max-SAT) is theoptimization counterpart of SAT, whose aim is to maximize the number of satisfied clauses.Max-SAT is more general than SAT; the solution to max-SAT can be used to answer thequestion of its decision counterpart, but not vice versa. Therefore, max-SAT is more diffi-cult to solve than SAT. Max-SAT is NP-hard [15] even when each clause has no more thantwo literals, while SAT with two literals per clause (2-SAT) is polynomial soluble.Weighted max-SAT is an extension of max-SAT in which a clause carries a weight, rep-resenting the significance of the clause or an induced penalty if it is violated. In weightedmax-SAT, the objective is to maximize the total weight of the satisfied clauses. Max-SATand weighted max-SAT have many real-world applications in domains such as scheduling,configuration problems, probabilistic reasoning, auction, and pattern recognition [14,20].For simplicity, in this paper, when we mention max-SAT, we refer to both weighted and un-weighted max-SAT. Following the convention for SAT, we refer to the ratio of the numberof clauses to the number of variables as the “constrainedness” of max-SAT.The Davis–Putnam–Logemann–Loveland (DPLL) algorithm for SAT [10] can be ex-tended to a branch-and-bound (BnB) algorithm for max-SAT. A BnB-based DPLL algo-rithm has been shown to be among the most competitive for max-SAT [43]. Much efforthas been devoted to improving the performance of such a BnB-based DPLL algorithm formax-SAT by combining the techniques previously developed for SAT [4,28,43] and manymethods used in Operations Research (OR), such as integer linear programming (ILP) andcutting plane methods [12,23,28]. However, these efforts have enjoyed limited success, es-pecially on large, complex problems. In particular, the current OR-based approaches aremore effective than the DPLL-based algorithms only on max-2-SAT [28], which is max-SAT with no more than two literals per clause. On the other hand, even though a BnB-basedDPLL algorithm is an efficient algorithm for max-SAT, it can handle relatively small prob-lems with moderate degrees of constrainedness.Therefore, despite the previous effort, much work is still needed in order to developefficient algorithms for both max-SAT and weighted max-SAT, and special care is requiredwhen extending SAT techniques to max-SAT. In principle, most techniques developed forSAT can be extended to max-SAT [14,20,43]. However, the SAT techniques take advantageof the fact that SAT is a decision problem, so that a search avenue can be abandoned assoon as a constraint violation becomes evident. This fact has been explicitly captured inthe unit propagation or unit resolution methods and different variable orderings used bythe DPLL algorithm and its variants. In contrast, the study of unit propagation methodsand variable orderings for max-SAT is limited. It is important to note that max-SAT hasits own intrinsic features that are remarkably different from its decision counterpart. Manyexisting techniques for SAT must be carefully reconsidered when being applied to max-SAT. Overall, it is much harder to develop an effective and efficient algorithm for max-SATthan for SAT, and the research of developing efficient exact max-SAT solver deserves muchattention, due to the generality and importance of the problem.\fZ. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–8049Aiming at solving difficult max-SAT and weighted max-SAT problems optimally, wereview the previous research on max-SAT, those taking the DPLL framework for SAT inparticular, and develop an efficient exact max-SAT algorithm based on DPLL. Our algo-rithm has three ingredients, which can be viewed as novel extensions to the main ideasbehind the existing methods for SAT. The first is a combination of four unit propaga-tion rules for max-SAT. Three of these rules were proposed by others in previous studies;we analyze them extensively in this research. The fourth, new unit propagation rule isdeveloped in this research based on an integer nonlinear programming formulation ofmax-SAT. This is an innovative contribution, enlarging our arsenal of unit propagationsfor max-SAT. We also consider different ways to combine these four propagation rules inour study.The second element of our max-SAT algorithm is an effective lookahead lower boundto estimate the minimum number of clauses unsatisfiable at a node during the search. Ourlower bound is based on linear programming (LP) [21]. This is a remarkable contribution;it is perhaps the first successful application of LP to max-SAT, despite similar (but notsuccessful) previous efforts to apply integer LP (ILP) to max-SAT [12,23,28].The third ingredient consists of two new variable-ordering or branching rules, whichwere inspired by the results of a close examination of two popular variable-ordering rulesfor SAT, i.e., the Mom’s rule [8,30] and the two-side Jeroslow–Wang rule [24], on max-SAT. The first new variable-ordering rule is designed for max-2-SAT. As its name, binary-clause first rule, indicates, this rule gives a higher priority to a variable in binary clausesthan those in unit clauses. The second new rule is designed to cope with large range ofconstrainedness values of max-3-SAT instances. It is a dynamic variable-ordering heuristicthat is able to dynamically change its variable ordering from close to the Mom’s rule toclose to the two-sided Jeroslow–Wang rule as the constrainedness increases.The paper is organized as follows, we first discuss max-SAT and describe two types ofmathematical formulation of the problem in Section 2. In Section 3, we review the DPLLalgorithm for SAT and how it can be extended to max-SAT. We discuss various factors thataffect its performance, including initial upper bound, value ordering, lower bound from unitclauses, and two existing variable ordering rules. In Section 4, we present four unit propa-gation rules for max-SAT. In Section 5, we develop a lower bound function based on linearprogramming, and discuss why LP-based lower bound is effective on highly constrainedproblem instances. In Section 6, we propose the binary-clause first and dynamic-weightingvariable ordering rules. We present experimental results of our new strategies, and describean efficient max-SAT algorithm that combines all our new strategies in Section 7. We alsosystematically compare our new solver with the most existing max-SAT solvers in Sec-tion 7. Finally, we discuss some related work in Section 8, and conclude in Section 9.Preliminary results of the research and an extended abstract of this paper appeared in[45].2. Formulation of maximum satisfiabilityA satisfiability problem (SAT) is a Boolean formula involving a set of Boolean variablesand a conjunction of a set of disjunctive clauses of literals, which are variables and their\f50Z. Xing, W. Zhang / Artificial Intelligence 164 (2005) 47–80negations. A clause with only one literal is called unit clause, a clause with two literalsis named binary clause, a clause with three literals is referred to as a clause of size three,and so on. A clause is satisfied if at least one of its literals takes value T , and a formula issatisfied if all the clauses are satisfied. The conjunction defines constraints on the possiblecombinations of variable assignments. SAT is to find a variable assignment that satisfiesall the clauses. Specially, 3-SAT is SAT where each clause has three literals. When thereexists no variable assignment to satisfy all clauses, it is required to find an assignmentthat maximizes the total number (or weight) of satisf",
            {
                "entities": [
                    [
                        2053,
                        2081,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1655–1671Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVoting almost maximizes social welfare despite limited communication ✩Ioannis Caragiannis a, Ariel D. Procaccia b,∗a Research Academic Computer Technology Institute & Department of Computer Engineering and Informatics, University of Patras, Greeceb School of Engineering and Applied Sciences, Harvard University, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 7 December 2010Received in revised form 14 March 2011Accepted 23 March 2011Available online 5 April 2011Keywords:Computational social choiceIn cooperative multiagent systems an alternative that maximizes the social welfare—the sumof utilities—can only be selected if each agent reports its full utility function. This may beinfeasible in environments where communication is restricted. Employing a voting rule tochoose an alternative greatly reduces the communication burden, but leads to a possiblegap between the social welfare of the optimal alternative and the social welfare of theone that is ultimately elected. Procaccia and Rosenschein (2006) [13] have introduced theconcept of distortion to quantify this gap.In this paper, we present the notion of embeddings into voting rules: functions that receivean agent’s utility function and return the agent’s vote. We establish that very low distortioncan be obtained using randomized embeddings, especially when the number of agents islarge compared to the number of alternatives. We investigate our ideas in the contextof three prominent voting rules with low communication costs: Plurality, Approval, andVeto. Our results arguably provide a compelling reason for employing voting in cooperativemultiagent systems.© 2011 Elsevier B.V. All rights reserved.1. IntroductionA major challenge that arises in the design and implementation of multiagent systems is the aggregation of the pref-erences of the agents. Voting theory provides a neat solution by giving extremely well-studied methods of preferenceaggregation. In recent years the theoretical aspects of computational voting have been enthusiastically investigated, es-pecially within the AI community (see, e.g., [15, Chapter 1] and the many references therein). Moreover, voting has beenapplied for preference aggregation in areas as diverse as Planning, Scheduling, Recommender Systems, Collaborative Filtering,Information Extraction, and Computational Linguistics (see, e.g., [7,12,16]).While the appeal of voting in the context of heterogeneous, competitive multiagent systems is apparent, some multiagentsystems are centrally designed and fully cooperative (e.g., systems for planning and scheduling, recommender systems, collab-orative filtering, and so on). We believe that, to date, the benefit of employing voting in such domains was unclear. Indeed,agents are normally assumed to compute a utility for every possible alternative. If the agents are cooperative then they cansimply communicate their utilities for the different alternatives, and subsequently select an alternative that maximizes thesocial welfare, i.e., the sum of utilities.However, accurately conveying an agent’s utility function for each alternative may be very costly in terms of commu-nication. This could prove to be a serious obstacle in domains where communication is restricted. Communication maybe limited by the physical properties of the system (e.g., slow or error-prone transmitters, systems with low energy con-✩A preliminary version of the paper appeared in the Proceedings of AAAI’10.* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), arielpro@seas.harvard.edu (A.D. Procaccia).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.005\f1656I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671sumption requirements, etc.) or the representation of the full utility functions may require a huge amount of information.Blumrosen et al. [1] outline additional persuasive reasons why communication should be restricted in multiagent settings.Fortunately, some prominent voting rules—functions that select an alternative given the preferences of the agents—imposea very small communication burden [5], and are moreover resistant to errors in communication [14].For example, consider the paradigmatic cooperative multiagent system domain: scanning an area on Mars with multiplerovers (which are known to have limited communication capabilities). Suppose the rovers must select or update their jointplan (this may happen very often), and there are one million alternatives. Moreover, suppose each rover computes a utilityfor each alternative on a scale of one to one million (this is, in fact, a very coarse scale). A rover would need to communicate106 · log(106) ≈ 20 · 106 bits in order to report its utility function. In contrast, under the Plurality voting rule, where eachagent votes for a single alternative and the alternative with most votes wins, a rover only needs to transmit twenty bits. Eventhough current applications may involve a small number of rovers, the research in wireless communication systems alreadyenvisages large-scale applications (e.g., for environment monitoring, disaster relief, battlefield operations and surveillance)with many ultra-small, possibly mobile, wireless devices such as sensors or mini-robots that cooperate towards a commongoal. Such devices are expected to be fully autonomous, a property that calls for low energy consumption and, consequently,for low communication requirements. The Harvard Micro Air Vehicles Project1 provides a concrete example of such a system.In this paper we shall argue that, in some cooperative multiagent systems, exact maximization of the social welfare canbe replaced by very simple voting rules (given an extra ingredient that we present below). The benefit is a huge reductionin the communication burden, whereas the cost, a deterioration in the social welfare of the outcome, will be shown to bealmost negligible in some settings. This arguably provides a pivotal reason for employing voting in cooperative multiagentsystems, and in AI in general.1.1. Our approachThe degree to which the social welfare of the outcome can decrease when voting is used is captured by the notionof distortion, introduced by Procaccia and Rosenschein [13]. They focus on voting rules that receive as input a ranking ofthe alternatives, and, crucially, assume that each agent reports a ranking such that the alternative that is ranked in thekth place has the kth highest utility. Under this assumption, they define the distortion of a voting rule to be the worst-caseratio between the maximum social welfare over all the alternatives, and the social welfare of the winner of the election; theworst-case is taken over all the possible utility functions of the agents. After proving some impossibility results, Procacciaand Rosenschein further restrict the structure of the utility functions. Even under this additional (very strong) assumption,they show that the distortion of most prominent voting rules is linear in the number of alternatives. The approach ofProcaccia and Rosenschein is descriptive: they propose to use the notion of distortion as a criterion in the comparison ofdifferent voting rules.Our main conceptual contribution is the consideration of embeddings into voting rules. An embedding is a set of instruc-tions that inform each agent how to vote, based only on the agent’s own utility function, that is, without any communicationor coordination between different agents. More accurately, an embedding into a specific voting rule is a function from utilityfunctions to votes that are valid under the voting rule. For instance, consider the simple Plurality rule described above. Givena utility function, an embedding into Plurality returns the alternative that the agent votes for. Procaccia and Rosenscheinimplicitly use one specific embedding, but many different embeddings exist. In this sense, our approach is algorithmic: wewish to design embeddings in a way that minimizes the distortion.We redefine the notion of distortion to take embeddings into account. The distortion of an embedding into a voting rule isstill the worst-case ratio between the maximum social welfare and the social welfare of the winner, but now the winnerdepends both on the voting rule and on the embedding, that is, on the way the utilities of the agents are translated intovotes. The worst-case is taken over all possible utilities; we do not make any assumption regarding the utilities, except thatthey are normalized.We take the idea of embeddings into voting rules one step further by allowing randomized embeddings. A randomizedembedding randomly chooses the agent’s vote, according to some probability distribution. The distortion is defined similarly,by taking into account the expected social welfare of the winner of the election. As we shall see, randomization gives usgreat power and flexibility, and ultimately provides us with the tools to design truly low-distortion embeddings.We wish to design low-distortion embeddings into voting rules with low communication complexity. Indeed, given thateach of our cooperative agents votes according to the instructions provided by the embedding (in a fully decentralized way),then an alternative with social welfare close to optimal may be elected in the face of restricted communication. We find theexistence of low-distortion embeddings rather striking, as the social welfare is a centralized concept.1.2. Our resultsWe study the distortion of embeddings into three voting rules: Plurality, Approval (each agent approves a subset ofalternatives), and Veto (each agent gives a “negative point” to one alternative). Plurality and Veto have the smallest com-1 http://robobees.seas.harvard.edu.\fI. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711657m",
            {
                "entities": [
                    [
                        3803,
                        3831,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 754–775www.elsevier.com/locate/artintAn application of formal argumentation:Fusing Bayesian networks in multi-agent systemsSøren Holbech Nielsen a,∗, Simon Parsons ba Department of Computer Science, Aalborg University, Aalborg, Denmarkb Department of Computer and Information Science, Brooklyn College, City University of New York, Brooklyn, 11210 NY, USAReceived 19 October 2006; received in revised form 28 March 2007; accepted 16 April 2007Available online 29 April 2007AbstractWe consider a multi-agent system where each agent is equipped with a Bayesian network, and present an open framework forthe agents to agree on a possible consensus network. The framework builds on formal argumentation, and unlike previous solutionson graphical consensus belief, it is sufficiently general to allow for a wide range of possible agreements to be identified.© 2007 Elsevier B.V. All rights reserved.Keywords: Argument in agent systems; Argumentation frameworks; Application; Bayesian networks1. IntroductionLately research in distributed systems has intensified, spurred by increased availability of sophisticated electronicdevices and cheap networking equipment. Within this field, the crossover area of multi-agent systems (MAS), thatincorporates parts of artificial intelligence research, has been heavily researched, with each device being modeledas an autonomous agent capable of acting on its environment, reflecting on observations of its surroundings andcommunicating with other agents. To implement such reflective capabilities, a model-based agent architecture is oftenemployed, where the agent carries within it a formal model of its surroundings and acts on mathematical inferencesdrawn from this model. Hence, the more accurate the model is the more successful the agent will be in achieving itsobjectives. Therefore it is beneficial for the agent to (i) update its model when observations of the agent’s surroundingindicate that the model is inaccurate, and (ii) communicate with other agents about their models and alter its ownmodel to reflect model aspects common to the models of most other agents.In this text we investigate how Bayesian networks (BNs) can be used as internal models in a multi-agent set-ting, and more specifically how (ii) can be implemented with the help of argumentation theory. Previously the twomethodologies have mainly been studied together with a view to incorporating the efficiency and precision of BNsinto argumentation theory (e.g. [24]), or as an exercise in converting models of one theory into models of the other(e.g. [27] and [30]). Here, we instead try to exploit strong points of both reasoning methods: BNs constitute a com-* Corresponding author.E-mail addresses: soeren.holbech@gmail.com (S.H. Nielsen), parsons@sci.brooklyn.cuny.edu (S. Parsons).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.005\fS.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775755pact, elegant, and mathematically correct framework for drawing diagnostic or causal inferences from observations tohypothesis variables, even in face of noisy observations, and they can be constructed and altered automatically fromobservation data, and are thus good choices for internal models. Argumentation theory, on the other hand, provides amethodology for transparently extracting a consistent “truth” from a set of conflicting and/or overlapping views, andfurthermore has strong roots in dialectics, which makes distributed agent-oriented implementations natural.Playing along with these strengths, we envision a MAS of cooperating agents, where each agent has a BN as amodel of the domain it is situated in, and aim at providing a framework built on principles of formal argumentationtheory in which the agents, starting from their individual domain models, can end up agreeing on a single networkrepresenting their joint domain knowledge.The task of fusing several BNs into one compromise BN has previously been addressed with an a priori specifiedview to what constitutes a compromise [4,10,14,21,23], with no apparent consensus on the goal of network fusionamong the authors, and has mainly been considered a centralized operation. Matzkevich and Abramson [14] disregardthe strength of independency statements in the input networks, and seek to obtain a graph that contains all arcs fromthe input networks or their reverses. Sagrado and Moral [4] similarly disregard the quantitative parts of the inputnetworks, and gives rules for constructing graphs that imply either all independency statements implied by at leastone of the input BNs, or only those independency statements implied by all input BNs. Richardson and Domingos [23]also disregard the quantitative parts of the input networks, and construct a prior distribution over all graph structuresfrom the input BNs. This prior is then used as basis for a standard greedy search based on a separate database.Finally, Pennock and Wellman [21] derive a series of impossibility results for the general problem of combiningprobability distributions, and Il and Chajewska [10] uses some of the results from [21] to adapt standard greedy searchscore functions to use the input BNs, rather than a database, as their basis. The differing objectives of these papersstems from differences in interpretations of BNs: They are seen as either specifying flow of information, specifyingindependencies between variables, representing expert experience, or summarizing data. In this paper, we do notcommit ourselves to any specific compromise objective. Rather, we establish a general framework in which any kindof compromise can be reached, with the exact nature of this specified by a compromise score function and possiblya heuristic for walking search trees. The advantages of our approach include that a general purpose argumentationengine can be implemented, and reused in contexts with different definitions of compromise; efficient distributedimplementations are natural; in cases where agents almost agree a priori, little information need to be shared amongthe agents; and anytime compromises can be achieved.The text is structured as follows: In Section 2 we briefly cover the methodology that we need. In particular, weneed some concepts of graph theory, the main theory of BNs and their equivalence classes, and finally theory of anargumentation framework. Following this, in Section 3 we specify the problem that we wish to solve more formally,and present the strategy for doing so. The actual results then follow. First, Section 4 describes how we encode BNsin our framework. Then Section 5 presents a formal argumentation system whose preferred extensions correspond toproper BNs, and Section 6 contains the debating guide-lines that must be followed by agents. We end with a discussionof these results in Section 7.2. PreliminariesBefore we proceed with the theory needed for the results later in the paper, we briefly clarify the notation: asa general rule, sets are printed in boldface type (S, pa(V ), . . .), and individual entities are printed in plain letters(A, xi, . . .), except data structures, which are printed in calligraphic letters (G, A, . . .), and general classes, which areprinted in gothic type (C). By convention we use ≡ to mean “is defined to be” or “defined as”, and decline to use {and } when listing singleton sets. The material is necessarily heavy on definitions, and to help the reader refer back,each term is emphasized where it is defined.2.1. GraphsHere we briefly introduce the terms of graph theory and notation that are used in the remainder of the text. Formore elaboration on the concepts introduced, see e.g. [13].A graph is a pair G ≡ (X, E), where X is the finite set of nodes of the graph, and E ⊆ (X × X) \\ {(X, X): X ∈ X}is a set of ordered pairs called edges of the graph. For any two nodes X and Y , if both (X, Y ) and (Y, X) is in E we\f756S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775Fig. 1. A simple graph.say that there is an undirected link (or just a link) between X and Y and that they are neighbors. If only (X, Y ) is inE, then we say that there is an arc from X to Y , that X is a parent of Y , and that Y is a child of X. The set of parentsof a node X is denoted pa(X). If X is a neighbor, parent, or child of Y , we say that X and Y are adjacent. A tripleof nodes (X, Y, Z) is said to constitute a v-structure, if Y is a child of both X and Z, and X and Z are not adjacent.When depicting a graph we use circles for nodes, lines for links, and arrows for arcs, as shown in Fig. 1. From thefigure it can be seen that pa(C) = G, that C is a neighbor of both B and D, that C has no children, and that (A, B, F )is the only v-structure in the graph.For two nodes X1 and Xk, we say that there is a path from X1 to Xk, if either (X1, Xk) is in E, or there are distinctnodes X2, . . . , Xk−1 different from X1 and Xk, such that (Xi−1, Xi) is in E for all 2 (cid:2) i (cid:2) k. We denote the path(X1, . . . , Xk) and say that its length is k − 1. If, for one of the edges (X, Y ) in a path, (Y, X) is not in E then we saythat the path is directed, if not it is undirected. A path (X, . . . , Y ), where X and Y are the same node, we call a cycle.Given a cycle (X1, . . . , Xk−1, X1) of length k (cid:3) 4, we say that the cycle has a chord if there is a pair of nodes Xiand Xj , where |i − j | (cid:3) 2 and Xi and Xj are not the pair X1 and Xk−1, such that Xi and Xj are adjacent. A cycleof length k (cid:3) 4 with no chord is called chordless. If there is a directed path from a node X to a node Y , then we saythat Y is a descendant of X. The set of descendants of X is denoted by desc(X). If, for any two nodes X and Y ina set Y , either X is the same node as Y , or there is an undirected path from X to Y , and this holds for no other setZ ⊃ Y , then we call Y a chain component. For examples, consider the graph in Fig. 1: There are no cy",
            {
                "entities": [
                    [
                        2912,
                        2940,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 249 (2017) 19–46Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstrained coalition formation on valuation structures: Formal framework, applications, and islands of tractabilityGianluigi Greco a,∗a Department of Mathematics and Computer Science, University of Calabria, Italyb DIMES Department, University of Calabria, Italy, Antonella Guzzo ba r t i c l e i n f oa b s t r a c tArticle history:Received 20 September 2016Received in revised form 5 April 2017Accepted 17 April 2017Available online 21 April 2017Keywords:Coalitional gamesSolution conceptsComputational complexityTreewidthMarginal contribution networksCoalition structure generation is the problem of partitioning the agents of a given environment into disjoint and exhaustive coalitions so that the whole available worth is maximized. While this problem has been classically studied in settings where all coalitions are allowed to form, it has been recently reconsidered in the literature moving from the observation that environments often forbid the formation of certain coalitions. By following this latter perspective, a model for coalition structure generation is proposed where constraints of two different kinds can be expressed simultaneously. Indeed, the model is based on the concept of valuation structure, which consists of a set of pivotalagents that are pairwise incompatible, plus an interaction graph prescribing that a coalition C can form only if the subgraph induced over the nodes/agents in C is connected.It is shown that valuation structures can be used to model a number of relevant problems arising in real-world application domains. Then, the complexity of coalition structure generation over valuation structures is studied, by assuming that the functions associating each coalition with its worth are given as input according to some compact encoding—rather than explicitly listing all exponentially-many associations. In particular, islands of tractability are identified based on the topological properties of the underlying interaction graphs and on suitable algebraic properties of the given worth functions. Finally, stability issues over valuation structures are studied too, by considering the core as the prototypical solution concept.© 2017 Elsevier B.V. All rights reserved.1. Introduction1.1. Constrained coalition structure generationCoalition structure generation is a fundamental problem in the study of coalition formation processes for multi-agent systems, which naturally occurs whenever agents can benefit form working together by forming coalitions (see, e.g., [59,31]). The problem is defined over a pair (cid:3)N, v(cid:4), referred to as a coalitional game, where N = {a1, . . . , an} is a set of agents and where v is a valuation function that, for each coalition C , i.e., non-empty set C ⊆ N of agents, returns a real number v(C)meant to express the worth that the members of C can jointly achieve by cooperating (see, e.g., [71,53]). The goal is to find * Corresponding author.E-mail addresses: ggreco@mat.unical.it (G. Greco), antonella.guzzo@unical.it (A. Guzzo).http://dx.doi.org/10.1016/j.artint.2017.04.0050004-3702/© 2017 Elsevier B.V. All rights reserved.\f20G. Greco, A. Guzzo / Artificial Intelligence 249 (2017) 19–46Fig. 1. Interaction graph in Example 1.2, with optimal coalition structures for the basic setting (left), and when a1 and a2 are pivotal agents (right).an optimal coalition structure, i.e., a partition {C1, . . . , Ck} of the agents into disjoint and exhaustive coalitions whose total value (cid:2)ki=1 v(Ci) is maximized.Example 1.1. Consider the coalitional game (cid:3)N, v(cid:4) where N = {a1, a2, a3} and where v is the valuation function such that:⎧⎨⎩v({a3}) = 0v({a1}) = v({a2}) = v({a2, a3}) = v({a1, a3}) = 1v({a1, a2}) = v({a1, a2, a3}) = 3Note that the optimal coalition structures are {{a1, a2, a3}} and {{a1, a2}, {a3}}. Their associated value is v({a1, a2, a3}) =v({a1, a2}) + v({a3}) = 3. (cid:2)While coalition structure generation has been classically studied in the literature by assuming that all coalitions are allowed to form, in real-world applications it is often the case that some coalition structures are inadmissible, because they violate a number of constraints induced by the specific semantics of the application at hand (see, e.g., [59]).Constraints on the coalition structures that are allowed naturally emerge in those settings where cooperation is guided by an underlying structure reflecting, for instance, physical limitation, legal banishments, and social relationships. In these cases, it is natural to assume that if two disconnected agents are not connected by intermediaries in a given coalition, then they might not be able to cooperate at all. In particular, following Myerson’s influential work [51], this intuition has been often formalized (see, e.g., [15,70,9]) by equipping each coalitional game (cid:3)N, v(cid:4) with an undirected graph G = (N, E), called interaction graph, defined over the set of the agents, and by considering a coalition C as a feasible one, only if the subgraph of G induced over the nodes in C is connected.In fact, in addition to the “topological” constraints induced by the underlying interaction graphs, other kinds of con-straints might occur in concrete domains when dealing with the coalition structure generation problem. For instance, the formation of certain coalitions might be prohibited by anti-trust laws or it might be subject to constraints on the coalition sizes. Settings of this kind have been also studied in the literature [26,65,56] and a general and unifying framework of these works has been proposed too [58]. In that framework, a coalitional game is equipped with two sets, N and P , of “negative” and “positive” constraints respectively. A negative constraint n ∈ N is a set of agents, and it prescribes that no coalition C such that C ⊇ n can be formed. Positive constraints are again formalized as set of agents, and they prescribe that for each feasible coalition C , there must exist a constraint p ∈ P such that C ⊇ p. As a matter of fact, however, the framework of [58] does not support the definition of interaction graphs and, despite its generality, it cannot simulate the topological constraints that are induced by them.Example 1.2. Consider again the setting of Example 1.1 and the interaction graph reported on the left of Fig. 1. Note, for instance, that coalition {a1, a3} is not allowed to form. Then, we claim that this simple scenario cannot be modeled via positive and negative constraints. Indeed, if a negative constraint n = {a1, a3} is considered, then the coalition {a1, a2, a3}would be not feasible precisely because of n. More generally, because of the feasibility of {a1, a2, a3} and by the monotone semantics of negative constraints, no negative constraint can be defined at all.Consider now the use of positive constraints. We know that {a1} is feasible and, hence, it must occur as a positive constraint. However, in absence of negative constraints, this immediately entails that {a1, a3} is feasible, too. (cid:2)As a matter of fact, topological constraints and positive/negative constraints have been separate worlds, so far. In the paper, we move from this observation and we propose to study a setting for coalition structure generation based on the concept of valuation structure, which basically consists of an interaction graph associated with certain kinds of negative constraints. In a nutshell, a set S of pairwise “incompatible” (pivotal) agents can be defined, so that every coalition C must satisfy the condition |S ∩ C| ≤ 1 in order to be a feasible one. Indeed, note that this is equivalent to having a negative constraint S, for each subset S(cid:10) ⊆ S with |S(cid:10)| = 2.(cid:10)Example 1.3. Assume that a1 and a2 are two pivotal agents in the setting of Example 1.1. Then, the feasible coalitions are further reduced to {a1}, {a2}, {a3}, and {a2, a3}, because the coalitions {a1, a2, a3} and {a1, a2} would be no longer allowed to form. In this scenario, which is graphically illustrated on the right of Fig. 1, an optimal coalition structure is {{a1}, {a2, a3}}whose associated value is a2. Hence, the incompatibility of a1 and a2 leads to reduce the total available worth. (cid:2)\fG. Greco, A. Guzzo / Artificial Intelligence 249 (2017) 19–46211.2. ContributionThe intuition underlying our formalization is that pivotal agents in S possess some specific properties differentiating themselves from the remaining agents in N \\ S. As an extreme case, a pivotal agent might well be an abstraction for some given parameter/object involved in the problem, i.e., it is not necessarily a “true” agent of the system. For instance, S might model a set of competing facilities to which the agents in N \\ S have to be connected. In fact, as the starting point of our analysis,(1) We define a framework for equipping coalitional games with valuation structures and we show that constraints induced by pivotal agents, combined with the underlying interaction graphs, are capable of expressing a number of relevant problems arising in a number of real application scenarios.Motivated by their relevance from the knowledge representation viewpoint, the paper then embarks on a systematic study of algorithmic and complexity issues arising with them. Prior to detailing these technical contributions, however, it is appropriate to recall that there is an extensive literature studying computational issues and proposing efficient solution algorithms for coalition structure generation, which we can partition in two groups based on the kinds of game encoding considered in the research.Classically, valuation functions are viewed as “black boxes” that, on input a coalition C , return the value v(C). In partic-ular, encoding and representation issues are not taken into account. In this context, exact solution approaches or algorithms with wor",
            {
                "entities": [
                    [
                        3174,
                        3202,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 503–535Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcise finite-domain representations for PDDL planning tasks ✩Malte HelmertInstitut für Informatik, Albert-Ludwigs-Universität Freiburg, Georges-Köhler-Allee 052, 79110 Freiburg, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 16 November 2007Received in revised form 22 October 2008Accepted 29 October 2008Available online 25 November 2008Keywords:Automated planningProblem reformulationPDDL+SASWe introduce an efficient method for translating planning tasks specified in the standardPDDL formalism into a concise grounded representation that uses finite-domain statevariables instead of the straight-forward propositional encoding.Translation is performed in four stages. Firstly, we transform the input task into anequivalent normalform expressed in a restricted fragment of PDDL. Secondly, wesynthesize invariants of the planning task that identify groups of mutually exclusivepropositions which can be represented by a single finite-domain variable. Thirdly, weperform an efficient relaxed reachability analysis using logic programming techniques toobtain a grounded representation of the input. Finally, we combine the results of the thirdand fourth stage to generate the final grounded finite-domain representation.The presented approach has originally been implemented as part of the Fast Downwardplanning system for the 4th International Planning Competition (IPC4). Since then, it hasbeen used in a number of other contexts with considerable success, and the use of concisefinite-domain representations has become a common feature of state-of-the-art planners.© 2008 Elsevier B.V. All rights reserved.1. IntroductionConsider the transportation planning task illustrated in Fig. 1. There are three cars, a train, and two parcels, located intwo cities comprising several locations each. The cars may move along a network of roads within their respective city oforigin, while the train moves along a single railway link that connects the two cities. Parcels may be loaded into any vehiclethat is present at the same location, and parcels carried by a vehicle may be unloaded to the current location of that vehicleat any time. The objective is to move each parcel to a designated goal location.1.1. PDDL representationsIn order to find a plan for this example task using a general-purpose planning system, we must first represent it in away that such a system can reason about. Since its inception in 1998 [38], the Planning Domain Definition Language (PDDL)has become the de-facto standard language for representing classical planning tasks. The original PDDL formalism, as usedin the first two International Planning Competitions, was purely logic-based and can be considered a syntactic variant ofthe earlier ADL language [39] (excluding the support for functional fluents, which are present in ADL). Since then, thelanguage has been extended to more easily express additional aspects of real-world planning tasks, such as numbers anddurations [21], state variables whose values are derived from the values of other state variables [18], and most recently planconstraints and preferences [24].✩This work was partly supported by the German Research Council (DFG) as part of the Transregional Collaborative Research Center “AutomaticVerification and Analysis of Complex Systems” (SFB/TR 14 AVACS). See www.avacs.org for more information.E-mail address: helmert@informatik.uni-freiburg.de.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.013\f504M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 1. A transportation planning task. Deliver parcel p1 from C to G and parcel p2 from F to E, using the cars c1, c2, c3 and train t. The cars may only useroads (thin edges), the train may only use the railway (thick edge).In PDDL, planning tasks are described in terms of objects of the world (cars, locations, parcels), predicates that describestatic or dynamic relations that hold between these objects (whether or not two given locations are connected by a road,whether or not a given parcel is currently inside a given vehicle), operators that manipulate these relations (moving a carfrom one location to another, unloading a parcel), an initial state that describes the situation before plan execution, and agoal specification describing the objectives that solution plans must achieve.While PDDL itself is a (restricted) first-order formalism, all state-of-the-art planning systems compile the input specifi-cation into a propositional representation at an early stage by grounding predicates, operators and goal specifications. Manyplanners go even further and transform the grounded task into a particularly simple syntactic form called propositionalSTRIPS, where states of the world can be represented as sets of (satisfied) atomic propositions and operators are representedin terms of which propositions must be true for the operator to be applicable (preconditions), which propositions the op-erator makes true (add effects), and which propositions it makes false (delete effects). The example task can be naturallymodelled in propositional STRIPS; (part of) such a representation is shown in Fig. 2.PDDL- or STRIPS-based representations of planning tasks have a number of desirable features. Due to the close rela-tionship to first-order logic (for ungrounded PDDL) and propositional logic (for grounded PDDL), the semantics are easy tounderstand for researchers and practitioners with a background in formal logics. Moreover, representing all properties of aworld state in terms of truth values has the appeal of simplicity. There is a certain mathematical elegance to the formalism,and it clearly achieves the language designers’ maxim of describing planning tasks in terms of their “physics, not advice”[38].1.2. Finite-domain representationsThe absence of any form of “advice” from the PDDL representation is appropriate for a language designed for generalproblem solvers, but it comes at a price, to be paid by planning algorithms that have to reason about the represented task.In particular, the state space induced by a propositional representation such as the one shown in Fig. 2 is very unstructured.A priori, a proposition like at-p1-a (stating that the first parcel is at location A) bears no closer relationship to at-p1-b(stating that the first parcel is at location B) than to, say, in-p2-t (stating that the second parcel is currently inside thetrain). However, if we take into account their intended meaning, propositions that represent potential locations of the sameparcel are clearly more closely related to each other than to ones that encode properties of the other parcel. In particular,only one of the propositions of the form at-p1-x can be true at the same time in any feasible world state. To the planner,there appear to be as many as 235 ≈ 3.4 · 1010 feasible world states in the example task, corresponding to all valuationsof the 35 propositional state variables, yet in truth the number of relevant states is only 11616 ≈ 1.2 · 104, as all othervaluations are not reachable from the given initial state.An alternative representation of the example task is shown in Fig. 3. This representation uses general finite-domainvariables, not just binary ones, to represent the state of the world. For example, a single variable p1 with a domain of11 values completely encodes the state of the first parcel, subsuming the information of all propositions at-p1-x andin-p1- y from the STRIPS encoding. Using this representation, the set of feasible world states coincides with the set ofsyntactically legal ones.In this article, we present an efficient algorithm for translating planning tasks specified in PDDL 2.2 into a compactfinite-domain representation. The algorithm has been implemented as part of the Fast Downward planner [29] and used bya number of other planning algorithms [3,27,31,48,49]. It extends an earlier algorithm by Edelkamp and Helmert [15] whichalso translates PDDL tasks to finite-domain representations, but is limited to a much smaller language fragment (STRIPS, notyping, no domain constants in operator definitions).As far as we know, no other algorithms for this problem have been described in the literature, so the main contributionof this article is the first description of a method to generate concise finite-domain representations from arbitrary (non-\fM. Helmert / Artificial Intelligence 173 (2009) 503–535505Fig. 2. Propositional STRIPS representation of the transportation planning task.numeric, non-temporal) PDDL tasks. From a high-level perspective, our approach follows very similar ideas to the algorithmof Edelkamp and Helmert, but the generalization beyond STRIPS requires significant extensions to the core components ofthe translation algorithm, invariant synthesis (Section 5) and grounding (Section 6). (Indeed, even though the emphasis in thisarticle is on the overall goal of transforming PDDL tasks into a concise finite-domain representation, we believe that theinvariant synthesis and grounding algorithms we present are also useful for planning algorithms that work on traditionalPDDL representations, so the algorithms presented in Sections 5 and 6 may be seen as additional contributions of thispaper.)1.3. Why finite-domain representations?Before diving into more technical matters, let us briefly discuss why compact finite-domain representations might bedesirable. We already noted that in the STRIPS representation, unlike the finite-domain representation, there is a vastlylarger number of syntactically valid states than feasible (reachable) states in the planning task. This is not necessarilyproblematic – for example, a planning algorithm based on forward search, such as Hoffmann and Nebel’s FF [33], will neverencounter any of the infeasible states, so there is no obvious advantage",
            {
                "entities": [
                    [
                        3628,
                        3656,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 256 (2018) 160–180Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief revision, minimal change and relaxation: A general framework based on satisfaction systems, and applications to description logicsMarc Aiguier a, Jamal Atif b,∗a MICS, Centrale Supelec, Université Paris-Saclay, Franceb Université Paris-Dauphine, PSL Research University, CNRS, UMR 7243, LAMSADE, 75016 Paris, Francec LTCI, Télécom ParisTech, Université Paris-Saclay, Paris, France, Isabelle Bloch c, Céline Hudelot aa r t i c l e i n f oa b s t r a c tArticle history:Received 13 November 2015Received in revised form 7 July 2017Accepted 11 December 2017Available online 17 December 2017Keywords:Abstract belief revisionRelaxationAGM theorySatisfaction systemsDescription logicsBelief revision of knowledge bases represented by a set of sentences in a given logic has been extensively studied but for specific logics, mainly propositional, and also recently Horn and description logics. Here, we propose to generalize this operation from a model-theoretic point of view, by defining revision in the abstract model theory of satisfaction systems. In this framework, we generalize to any satisfaction system the characterization of the AGM postulates given by Katsuno and Mendelzon for propositional logic in terms of minimal change among interpretations. In this generalization, the constraint on syntax independence is partially relaxed. Moreover, we study how to define revision, satisfying these weakened AGM postulates, from relaxation notions that have been first introduced in description logics to define dissimilarity measures between concepts, and the consequence of which is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. We show how the proposed general framework can be instantiated in different logics such as propositional, first-order, description and Horn logics. In particular for description logics, we introduce several concrete relaxation operators tailored for the description logic ALC and its fragments EL and ELU , discuss their properties and provide some illustrative examples.© 2018 Elsevier B.V. All rights reserved.1. IntroductionBelief change, the process that makes an agent’s beliefs evolve with newly acquired knowledge, is one of the classical but still challenging problems in artificial intelligence. It is gaining more and more interest these days, due to the emergence of new logical-based knowledge representation frameworks enjoying good complexity properties, allowing them to tackle large scale knowledge bases, and to reason on massive datasets. Among these logical frameworks, one can mention Description Logics (DLs) and Horn Clause theories. Description logics, for instance, are now pervasive in many knowledge-based repre-sentation systems such as ontological reasoning, semantic web, scene understanding, cognitive robotics, to mention a few. In all these domains, the expert knowledge is not fixed, but rather a flux evolving over time, hence requiring the definition of rational change operators.* Corresponding author.E-mail addresses: marc.aiguier@centralesupelec.fr (M. Aiguier), jamal.atif@dauphine.fr (J. Atif), isabelle.bloch@telecom-paristech.fr (I. Bloch), celine.hudelot@centralesupelec.fr (C. Hudelot).https://doi.org/10.1016/j.artint.2017.12.0020004-3702/© 2018 Elsevier B.V. All rights reserved.\fM. Aiguier et al. / Artificial Intelligence 256 (2018) 160–180161Studying the rationality of belief change operators, when knowledge bases are logical theories, i.e. sets of sentences in a given logic, goes back to the seminal work of Alchourròn, Gardenfors and Makinson [1], that gave birth to what is now known as AGM theory. Three change operations are studied within this framework, expansion, contraction and revision. Belief expansion consists in adding new knowledge without checking consistency, while both contraction and revision consist in consistently removing and adding new knowledge, respectively. We focus in this paper on belief revision.Although defined in the abstract framework of logics given by Tarski [40] (so called Tarskian logics), postulates of the AGM theory make strong assumptions on the considered logics. Indeed, in [1] the considered logics have to be closed under the standard propositional connectives in {∧, ∨, ¬, ⇒}, to be compact (i.e. inference depends on a finite set of axioms), and to satisfy the deduction theorem (i.e. entailment and implication are equivalent). While compactness is a standard property of logics, to be closed under the standard propositional connectives is more questionable. Indeed, many logics (called hereafter non-classical logics) such as description logics, equational logic or Horn clause logic, widely used for various modern applications in computing science, do not satisfy such a constraint. Recently, in many works, belief change has been studied in such non-classical logics [12,17,34,35]. For instance, Ribeiro et al. in [35] studied contraction at the abstract level of Tarskian logics, and recently Zhuang et al. in [42] proposed an extension of AGM contraction to arbitrary logics. The adaptation of the AGM postulates for revision for non-classical logics has been studied but only for specific logics, mainly description logics [16,17,28,29,31,33,41] and Horn logics [11,43]. The reason is that revision can be abstractly defined in terms of expansion and retraction following the Levi identity [23], but this requires the use of negation, which rules out some non-classical logics that do not consider this connective [34].The AGM postulates were interpreted in terms of minimal change in [22], in the sense that the models of the revision should be as close as possible, according to some metric, to the models of the initial knowledge set. However, to the best of our knowledge, the generalization of the AGM theory with minimality criteria on the set of models of knowledge bases has never been proposed. The reason is that semantics is not explicit in the abstract framework of logics defined by Tarski.We propose here to generalize AGM revision but in the abstract model theory of satisfaction systems, which formalizes the intuitive notion of logical systems, including syntax, semantics and the satisfaction relation. This notion was introduced in [18] under the name of “rooms”, and then of “satisfaction systems” in [38]. See also [26]. Then, we propose to generalize to any satisfaction system the approach developed in [22] for propositional logic and in [30] for description logics. In this abstract framework, we will also show how to define revision operators from the relaxation notion that has been introduced in description logics to define dissimilarity measures between concepts [14,15]. The main idea is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. This notion of relaxation, defined in an abstract way through a set of properties, turns out to generalize several revision operators introduced in different contexts e.g. [9,20,25,29]. This is another key contribution of our work.To concretize our abstract framework, we provide examples of relaxations in propositional logics, first order logics, and Horn logic. The case of description logics (DLs) is more detailed. This is motivated, as mentioned above, by their broad scope of applications, including reasoning on large web data.The paper is organized as follows. Section 2 reviews some concepts, notations and terminology about satisfaction systems which are used in this work. In Section 3, we adapt the AGM theory in the framework of satisfaction systems, and then give an abstract model-theoretic rewriting of the AGM postulates. We then show in Section 3.2 that any revision operator satis-fying such postulates accomplishes an update with minimal change to the set of models of knowledge bases. In Section 3.3, we introduce a general framework of relaxation-based revision operators and show that our revision operators lead to faith-ful assignments and then also satisfy the AGM postulates. In Section 4, we illustrate our abstract approach by providing revision operators in different logics, including classical logics (propositional and first order logics) and non-classical ones (Horn and description logics). The case of DL is further developed in Section 4.4, with several examples. Finally, Section 5 is dedicated to related works.2. Satisfaction systemsSatisfaction systems [26] generalize Tarski’s classical “semantic definition of truth” [39] and Barwise’s “Translation Ax-iom” [4]. For the sake of generalization, sentences are simply required to form a set. All other contingencies such as inductive definition of sentences are not considered. Similarly, models are simply seen as elements of a class, i.e. no particular struc-ture is imposed on them.2.1. Definition and examplesDefinition 1 (Satisfaction system). A satisfaction system R = (Sen, Mod, |=) consists of• a set Sen of sentences,• a class Mod of models, and• a satisfaction relation |=⊆ Mod × Sen.\f162M. Aiguier et al. / Artificial Intelligence 256 (2018) 160–180Let us note that the non-logical vocabulary, so-called signature, over which sentences and models are built, is not speci-fied in Definition 1.1 Actually, it is left implicit. Hence, as we will see in the examples developed in the paper, a satisfaction system always depends on a signature.Example 1. The following examples of satisfaction systems are of particular importance in computer science and in the remainder of this paper.Propositional Logic (PL) Given a set of propositional variables (cid:2), we can define the satisfaction system R(cid:2) = (Sen, Mod,|=) where Sen is the least set of sentences finitely built over propositional variables in (cid:2) and Boolean connectives in {¬, ∨}, Mod contains all the mappings ν : (cid:2) → {0, 1} (0 and 1 are the usual tr",
            {
                "entities": [
                    [
                        3381,
                        3409,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 196 (2013) 26–52Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPhysical search problems with probabilistic knowledge ✩Noam Hazon a,∗,1, Yonatan Aumann b, Sarit Kraus b, David Sarne ba Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USAb Department of Computer Science, Bar-Ilan University, Ramat Gan, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 31 August 2011Received in revised form 30 September2012Accepted 24 December 2012Available online 3 January 2013Keywords:Graph searchEconomic searchThis paper considers the problem of an agent or a team of agents searching for a resourceor tangible good in a physical environment, where the resource or good may possiblybe obtained at one of several locations. The cost of acquiring the resource or good ata given location is uncertain (a priori), and the agents can observe the true cost onlywhen physically arriving at this location. Sample applications include agents in explorationand patrol missions (e.g., an agent seeking to find the best location to deploy sensingequipment along its path). The uniqueness of these settings is in that the cost of observinga new location is determined by distance from the current one, impacting the considerationfor the optimal search order. Although this model captures many real world scenarios, ithas not been investigated so far.We analyze three variants of the problem, differing in their objective: minimizing the totalexpected cost, maximizing the success probability given an initial budget, and minimizingthe budget necessary to obtain a given success probability. For each variant, we firstintroduce and analyze the problem with a single agent, either providing a polynomialsolution to the problem or proving it is NP-complete. We also introduce a fully polynomialtime approximation scheme algorithm for the minimum budget variant. In the multi-agentcase, we analyze two models for managing resources, shared and private budget models.We present polynomial algorithms that work for any fixed number of agents, in the sharedor private budget model. For non-communicating agents in the private budget model, wepresent a polynomial algorithm that is suitable for any number of agents. We also analyzethe difference between homogeneous and heterogeneous agents, both with respect to theirallotted resources and with respect to their capabilities. Finally, we define our problem inan environment with self-interested agents. We show how to find a Nash equilibrium inpolynomial time, and prove that the bound on the performance of our algorithms, withrespect to the social welfare, is tight.© 2013 Elsevier B.V. All rights reserved.1. IntroductionFrequently, in order to successfully complete its task, an agent may need to explore (i.e., search) its environment andchoose among different available options. For example, an agent seeking to purchase a product over the Internet needs toquery several electronic merchants in order to learn their posted prices; a robot searching for a resource or a tangible goodneeds to travel to possible locations where the resource is available and learn the configuration in which it is available, as✩This paper extends two earlier conference papers (Aumann et al., 2008 [6]; Hazon et al., 2009 [31]).* Corresponding author.E-mail addresses: noamh@cs.cmu.edu (N. Hazon), aumann@cs.biu.ac.il (Y. Aumann), sarit@cs.biu.ac.il (S. Kraus), sarned@cs.biu.ac.il (D. Sarne).1 This work was done while the author was at Bar-Ilan University.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.003\fN. Hazon et al. / Artificial Intelligence 196 (2013) 26–5227well as the difficulty of obtaining it there. In these environments, the benefit associated with an opportunity is revealedonly upon observing it. The only knowledge available to the agent prior to observing the opportunity is the probabilityassociated with each possible value of each prospect.While in virtual environments the exploration can sometimes be considered costless, in physical environments travelingand observing typically entails a cost. Furthermore, traveling to a new location may increase or decrease the distance toother locations, so the cost associated with exploring other unexplored locations changes. For example, consider a Roverrobot with the goal of mining a certain mineral. Potential mining locations may be identified based on satellite imaging,each location associated with some uncertainty regarding the difficulty of mining there. In order to assess the amount ofbattery power required for mining at a specific location, the robot needs to physically visit there. The robot’s battery isthus used not only for mining the mineral but also for traveling from one potential location to another. Consequently, anagent’s strategy in an environment associated with search costs should maximize the overall benefit resulting from thesearch process, defined as the value of the option eventually used, minus the costs accumulated along the process, ratherthan merely finding the best valued option.In physical environments, it is common to use a team of agents rather than a single agent. Extending the single agentsolution to multi-agent strategy may require subdividing the search space among the different agents. However, if agentshave means of communication, then they may not wish to become too distant, as they can call upon each other for assis-tance. For example, even if a Rover does not have sufficient battery power for mining at a given location, it may be usefulfor it to travel to the site in order to determine the exact mining cost, and call for other robots that do have the necessarybattery power. In this case, the scheduling of the robots’ travel times is key, and must be carefully planned. If the agents arenot fully cooperative, a selfish behavior should also be considered. Each one of the agents will try to minimize its travelingcosts while still achieving the group’s goal.Finally, agents may be of different types, or with different amounts of resources. For example, Rover robots may beentering the mission with differing initial battery charges. They may also differ in their capabilities, like a team of Rovers inwhich some were specifically designed for mining missions, and thus require less battery power for the same mining task.This paper aims at taking the first steps in understanding the characteristics of such physical search environments, bothfor the single and multi agent cases, and developing efficient exploration strategies for the like. Our main focus is on the casewhere the opportunities are aligned along a path, as in the case of perimeter patrol [60,19,2,3]. We note that many singleand multi-agent coverage algorithms convert their complex environment into a simple long path [52,25,32]. Furthermore,we show that the problem in more general metric spaces is NP-complete, even for a tree graphs. For exposition purposes,in the remainder of the paper we use the classical procurement application where the goal of the search is purchasing aproduct and the value of each observed opportunity represents a price. Of course, this is only one example of the generalsetting of exploration in a physical environment, and the discussion and results of this paper are relevant to any suchsetting, provided that exploration and fulfilling the task consume the same type of resource.We consider three variants of the problem, differing in their objective. The first (Min-Expected-Cost) is the problem ofan agent that aims to minimize the expected total cost of completing its task. The second (Max-Probability) considers anagent that is given a budget for the task (which it cannot exceed) and aims to maximize the probability it will completethe task (e.g., reach at least one opportunity with a budget large enough to successfully buy the product). In the last variant(Min-Budget) the agent is required to guarantee a pre-defined probability of completing the task, and aims to minimize theoverall budget that will be required to achieve the said success probability. We also consider the multi-agent extensionsof these variants. While the first variant fits mostly product procurement applications, the two latter variants fit well intoapplications of robots engaged in remote exploration, operating with a limited amount of battery power (i.e., a budget).1.1. Summary of resultsWe first consider the single agent case. We prove that in general metric spaces all three problem variants are NP-hard.Thus, as mentioned, we focus on the setting where all locations are located along a path. For this setting we provide poly-nomial algorithms for the Min-Expected-Cost problem. We show the other two problems (Min-Budget and Max-Probability)to be NP-complete even for the path. Thus, we consider further restrictions and also provide an approximation scheme. Weshow that both problems are polynomial if the number of possible prices is constant. Even with this restriction, we showthat these problems are NP-complete on a tree graph. For the Min-Budget problem, we provide an FPTAS (fully-polynomial-time-approximation-scheme), that provides a (1 + (cid:2)) approximation for any (cid:2) > 0, in time O (poly(n(cid:2)−1)), where n is thesize of the input.For the multi-agent case, we first analyze a shared budget model, where all the resources and costs are shared amongall the agents. We show that if the number of agents is fixed, then all of the single-agent algorithms extend to k-agents,with the time bounds growing exponentially in k. Therefore the computation of the agents’ strategies can be performedwhenever the number of agents is relatively moderate, a common scenario in many physical environments where severalagents cooperate in exploration and search. If the number of agents is part of the input then the multi-agent versions ofMin-Budget and Max-Probability ar",
            {
                "entities": [
                    [
                        3666,
                        3694,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 295–315Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLogic programs with abstract constraint atoms: The roleof computations ✩Lengning Liu a, Enrico Pontelli b,∗, Tran Cao Son b, Miroslaw Truszczy ´nski aa Department of Computer Science, University of Kentucky, Lexington, KY 40506, USAb Department of Computer Science, New Mexico State University, Las Cruces, NM 88003, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 3 September 2008Received in revised form 16 November 2009Accepted 23 November 2009Available online 27 November 2009Keywords:Logic programs with abstract constraintatomsAnswer setsComputationsWe provide a new perspective on the semantics of logic programs with arbitrary abstractconstraints. To this end, we introduce several notions of computation. We use the results ofcomputations to specify answer sets of programs with constraints. We present the rationalebehind the classes of computations we consider, and discuss the relationships among them.We also discuss the relationships among the corresponding concepts of answer sets. Oneof those concepts has several compelling characterizations and properties, and we proposeit as the correct generalization of the answer-set semantics to the case of programs witharbitrary constraints. We show that several other notions of an answer set proposed inthe literature for programs with constraints can be obtained within our framework as theresults of appropriately selected classes of computations.© 2009 Elsevier B.V. All rights reserved.1. Introduction and motivationWe study logic programs with arbitrary abstract constraints, or simply, constraints. Programs with constraints providea general framework to study semantics of extensions of logic programs with aggregates. It is due to the fact that nor-mal logic programs, programs with monotone and convex constraints (proposed by Marek and Truszczy ´nski [31], Liu andTruszczy ´nski [25]), and several classes of programs with aggregates (e.g., [6,14,35,40]) can be viewed as special programswith arbitrary constraints.The original definition of the syntax of programs with constraints, along with a possible semantics, has been proposedby Marek and Remmel [29]. An alternative semantics was later proposed by Son, Pontelli, and Tu [42], and revisited by Shenand You [38] and by You, Yuan, Liu, and Shen [45].In this paper, we introduce a general framework for defining and investigating semantics for programs with constraints.We base our development on the notion of computation. The proposed framework builds on general principles that can beelicited from the semantics of traditional normal logic programs (i.e., logic programs with negation as failure).The answer-set semantics of logic programs was introduced by Gelfond and Lifschitz [20]. The semantics generalizes thestable-model semantics of Gelfond and Lifschitz [19], which was proposed for the class of normal logic programs only, tologic programs with two negations (negation as failure and classical negation). In the paper, we consistently use the termanswer-set semantics, as it is currently more widely used, and as the bulk of our paper is concerned with programs thatare not normal.✩An extended abstract of this paper appeared in the Proceedings of the 2007 International Conference on Logic Programming.* Corresponding author.E-mail addresses: lliu1@cs.uky.edu (L. Liu), epontell@cs.nmsu.edu (E. Pontelli), tson@cs.nmsu.edu (T.C. Son), mirek@cs.uky.edu (M. Truszczy ´nski).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.11.016\f296L. Liu et al. / Artificial Intelligence 174 (2010) 295–315The answer-set semantics forms the foundation of Answer-Set Programming (ASP) [30,33,18]. Intuitively, an answer setof a program represents the set of “justified” beliefs of an agent, whose knowledge is encoded by the program. Over theyears, researchers have developed several characterizations of answer sets, that identify and emphasize their key featuresand suggest ways to compute them.The original definition of answer sets [19] introduces a “guess-and-check” approach to computing answer sets of aprogram. The process starts by guessing an interpretation, to be used as a candidate answer set, and then proceeds invalidating it. The validation consists of recomputing the guessed interpretation, starting from the empty set and iterativelyapplying the immediate consequence operator [43] for the Gelfond–Lifschitz reduct of the program [19]. The interpretation isaccepted only if it is the limit of this iterative process. In this approach, once the guess is made, the validation is entirelydeterministic.Other characterizations of answer sets suggest an alternative scheme for constructing answer sets. The process starts,also in this case, from the empty set. At each step, we add to the set under construction the heads of some of the rulesapplicable at that step. Typically, we use all the rules selected during the previous steps (if they are no longer applicable,the construction terminates with failure) plus some additional ones. When the process stabilizes—i.e., no new elements canbe introduced in the set—the result is an answer set [27,32]. In this approach, we replace the initial non-deterministic stepof guessing an entire interpretation with local non-deterministic choices of rules to fire at each step of the construction.Similarly, the task of validation is distributed across the computation. Observe that this approach for characterizing answersets represents the underlying model that is employed by several ASP solvers, where 3-valued partial models [44] areextended to stable models.Example 1. Let us consider the program P 1 consisting of the following rules:a ← not bb ← not ac ← ad ← bThis program has two answer sets: {a, c} and {b, d}.1In the “guess-and-check” approach, we might guess {a, c} as a candidate answer set. To verify the guess, we computethe Gelfond–Lifschitz reduct, consisting of the rules:a ←c ← ad ← bThe validation requires determining the least fixpoint of the immediate consequence operator of the reduct program—i.e.,the least Herbrand model of the reduct program—which corresponds to {a, c}. Since it coincides with the initial guess, theguess is validated as an answer set. In the same way, we can also validate the guess {b, d}. However, the validation of {a}fails—since the reduct program contains the rulesa ←c ← ad ← band the iteration of its immediate consequence operator converges to {a, c}, which is different from the initial guess {a}.The alternative approach we mentioned starts with the empty interpretation, ∅, which makes two rules applicable:a ← not b and b ← not a. The algorithm needs to select some of them for application, say, it selects a ← not b. The choiceresults in the new interpretation {a}. Two rules are applicable now: a ← not b and c ← a. Let us select both rules forapplication. The resulting interpretation is {a, c}. The same two rules that were applicable in the previous step are stillapplicable and no other rules are applicable. Thus, there is no possibility to add new elements to the current set. Thecomputation stabilizes at {a, c}, thus making {a, c} an answer set.We note that the first approach starts with a tentative answer set of the program, while the second starts with the emptyinterpretation. In the first approach, we guess the entire answer set at once and, from that point on, proceed in a determin-istic fashion. In the second approach we construct an answer set incrementally making non-deterministic choices along the1 Since neither in this example, nor anywhere else in the paper, do we consider classical negation, following the tradition of logic programming, wedescribe an answer set using a set of atoms—that contains all the atoms that are true; the remaining atoms are considered false by default.\fL. Liu et al. / Artificial Intelligence 174 (2010) 295–315297way. Thus, each approach involves non-determinism. However, in the second approach, the role of non-determinism couldbe potentially more limited.In this paper, we cast these two approaches in terms of abstract principles related to a notion of computation. We then liftthese principles to the case of programs with abstract constraints and derive from the approach a well-motivated semanticsfor such programs.The recent interest in ASP has been fueled by the development of inference engines to compute answer sets of logicprograms, most notably systems like Smodels [34], Cmodels [23], clasp [16] and DLV [22], which allow programmers totackle complex real-world problems (e.g., [2,21,13]). To facilitate declarative solutions of problems in knowledge represen-tation and reasoning, researchers proposed extensions of the logic programming language, which support aggregates [33,6,8,14,17,35,39].These development efforts stimulated interest in logic programming formalisms based on abstract constraint atoms, orig-inally proposed by Marek and Remmel [29] and Marek and Truszczy ´nski [31]. The objective was not to introduce aknowledge representation language but rather an abstract framework, in which one could study semantics of knowledgerepresentation systems obtained by extending the syntax of logic programs aggregates. The need arose as the introductionof constraints and aggregates into logic programming created a challenge to extend the semantics. Researchers proposedseveral possible approaches [14,8,40,42,11,41]. These approaches all agree on large classes of programs, including• normal logic programs (every extension contains that class),• programs with monotone aggregates such as weight atoms with all weights non-negative and without the upperbound given (they can be regarded as special programs with monotone constraints, as presented by Marek andTruszczy ´nski [31]), and• programs with convex aggregates such as weight atoms with all weights non-negative and with bo",
            {
                "entities": [
                    [
                        3638,
                        3666,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1570–1603Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInconsistent heuristics in theory and practiceAriel Felner a,∗Zhifu Zhang c, Uzi Zahavi b, Robert Holte c, Jonathan Schaeffer c, Nathan Sturtevant c,a Department of Information Systems Engineering, Ben-Gurion University of the Negev, Beer-Sheva 85104, Israelb Department of Computer Science, Bar-Ilan University, Ramat-Gan 52900, Israelc Department of Computing Science, University of Alberta, Edmonton, Alberta, T6G2E8, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 July 2010Received in revised form 10 February 2011Accepted 10 February 2011Available online 18 February 2011Keywords:Heuristic searchAdmissible heuristicsInconsistent heuristics∗AIDA∗1. Introduction and overview.In the field of heuristic search it is usually assumed that admissible heuristics areconsistent,implying that consistency is a desirable attribute. The term “inconsistentheuristic” has, at times, been portrayed negatively, as something to be avoided. Part of thisis historical: early research discovered that inconsistency can lead to poor performance∗(nodes might be re-expanded many times). However, the issue has never been fullyfor A∗investigated, and was not re-considered after the invention of IDAThis paper shows that many of the preconceived notions about inconsistent heuristicsare outdated. The worst-case exponential time of inconsistent heuristics is shown to onlyoccur on contrived graphs with edge weights that are exponential in the size of the graph.Furthermore, the paper shows that rather than being something to be avoided, inconsistentheuristics often add a diversity of heuristic values into a search which can lead to areduction in the number of node expansions. Inconsistent heuristics are easy to create,contrary to the common perception in the AI literature. To demonstrate this, a number ofmethods for achieving effective inconsistent heuristics are presented.Pathmax is a way of propagating inconsistent heuristic values in the search from parentto children. This technique is generalized into bidirectional pathmax (BPMX) whichpropagates values from a parent to a child node, and vice versa. BPMX can be integrated∗. When inconsistent heuristics are used with BPMX, experimental resultsinto IDA. Positive results are alsoshow a large reduction in the search effort required by IDApresented for Asearches.and A∗∗∗© 2011 Elsevier B.V. All rights reserved.Heuristic search algorithms such as A[22] are guided by the cost function f (n) = g(n) + h(n), where g(n)is the cost of the current path from the start node to node n and h(n) is a heuristic function estimating the cost from n toa goal node. If h(n) is admissible (i.e., is always a lower bound) these algorithms are guaranteed to find optimal paths.∗[15] and IDA∗The Aalgorithm is guaranteed to return an optimal solution only if an admissible heuristic is used. There is no re-quirement that the heuristic be consistent.1 It is usually assumed that admissible heuristics are consistent. In their popularAI textbook Artificial Intelligence: A Modern Approach, Russell and Norvig write that “one has to work quite hard to concoct∗* Corresponding author.E-mail addresses: felner@bgu.ac.il (A. Felner), zahaviu@biu.ac.il (U. Zahavi), holte@cs.ualberta.ca (R. Holte), jonathan@cs.ualberta.ca (J. Schaeffer),nathanst@cs.ualberta.ca (N. Sturtevant), zhang@cs.ualberta.ca (Z. Zhang).1 A heuristic is consistent if for every two states x and y, h(x) (cid:2) c(x, y) + h( y) where c(x, y) is the cost of the shortest path between x and y. Derivationsand definitions of consistent and inconsistent heuristics are provided in Section 3.0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.02.001\fA. Felner et al. / Artificial Intelligence 175 (2011) 1570–16031571heuristics that are admissible but not consistent” [38]. Many researchers work under the assumption that “almost all admis-sible heuristics are consistent” [25]. Some algorithms require that the heuristic be consistent (such as Frontier A[30], whichsearches without the closed list).2 The term “inconsistent heuristic” has, at times, been portrayed negatively, as somethingthat should be avoided. Part of this is historical: early research discovered that inconsistency can lead to poor performance∗for A. However, the issue of inconsistent heuristics has never been fully investigated or re-considered after the invention of∗IDA. This paper argues that these perceptions about inconsistent heuristics are wrong. We show that inconsistent heuris-tics have many benefits. Further, they can be used in practice for many search domains. We observe that many recentlydeveloped heuristics are inconsistent.∗A known problem with inconsistent heuristics is that they may cause algorithms like Ato find shorter paths to nodesthat were previously expanded and inserted into the closed list. If this happens, then these nodes must be moved back tothe open list, where they might be chosen for expansion again. This phenomenon is known as node re-expansion. Awith aninconsistent heuristic may perform an exponential number of node re-expansions [32]. We present insights into this phe-nomenon, showing that the exponential time behavior only appears in contrived graphs where edge weights and heuristicvalues grow exponentially with the graph size. For IDA, it is important to note that node re-expansion is inevitable due tothe algorithm’s depth-first search. The use of an inconsistent heuristic does not exacerbate this. Because no history of pre-whether the heuristic is consistentvious searches is maintained, each separate path to the node will be examined by IDAor not.∗∗∗∗Inconsistent heuristics often add a diversity of heuristic values into a search. We show that these values can be used toescape heuristic depressions (regions of the search space with low heuristic values), and can lead to a large reduction in thesearch effort. Part of this is achieved by our generalization of pathmax into bidirectional pathmax. The idea of pathmax wasintroduced by Mero [34] as a method for propagating inconsistent values in the search from a parent node to its children.Pathmax causes the f -values of nodes to be monotonic non-decreasing along any path in the search tree. The pathmax ideafor undirected state spaces is generalized into bidirectional pathmax (BPMX). BPMX propagates values in a similar mannerto pathmax, but does this in both directions (parent to child, and child to parent). BPMX turns out to be more effective∗than pathmax in practice. It can easily be integrated into IDA. Using BPMX, thepropagation of inconsistent values allows a search to escape from heuristic depressions more quickly.and, with slightly more effort, into A∗Trivially, one can create an inconsistent heuristics by taking a consistent heuristic and degrading some of its values. Theresulting heuristic will be less informed. Contrary to the perception in the literature, informed inconsistent heuristics areeasy to create. General guidelines as well as a number of simple methods for creating effective inconsistent heuristics areprovided. The characteristics of inconsistent heuristics are analyzed to provide insights into how to effectively use them tofurther reduce the search effort.Finally, experimental results show that using inconsistent heuristics with BPMX yields a significant reduction in the-based search applications. The application domains used are the sliding-tile∗search effort required for many IDApuzzle, Pancake problem, Rubik’s cube, TopSpin and pathfinding in maps.∗- and AThe paper is organized as follows. In Section 2 we provide background material. Section 3 defines consistent and in-consistent heuristics. Section 4 presents a study of the behavior of Awith inconsistent heuristics. BPMX is introduced inSection 5 and its attributes when used with inconsistent heuristics are studied. Methods for creating inconsistent heuristicsare discussed in Section 6. Extensive experimental results for IDAare provided in Sections 7 and 8, respectively.Finally we provide our conclusions in Section 9.∗and for A∗∗Portions of this work have been previously published [14,21,44–47]. This paper summarizes this line of work and tiestogether all the results. In addition new experimental results are provided.2. Terminology and backgroundThis section presents terminology and background material used for this research.2.1. TerminologyThroughout the paper the following terminology is used. A state space is a graph whose vertices are called states. Theexecution of a search algorithm (e.g., A) from an initial state creates a search graph. A search tree spans that graphaccording to the progress of the search algorithm. The term node is used throughout this paper to refer to the nodes of thesearch tree. Each node in the search tree corresponds to some state in the state space. The search tree may contain nodesthat correspond to the same state (via different paths). These are called duplicates.∗and IDA∗The fundamental operation in a search algorithm is to expand a node (i.e., to compute or generate the node’s successorsin the search tree). We assume that each node expansion takes the same amount of time. This allows us to measure thetime complexity of the algorithms in terms of the total number of node expansions performed by the algorithm in solving∗2 The breadth-first heuristic search algorithm [49], a competitor to Frontier A, does not have this requirement and works with inconsistent heuristicstoo.\f1572A. Felner et al. / Artificial Intelligence 175 (2011) 1570–1603Fig. 1. 3 × 3 × 3 Rubik’s cube.a given problem.3 The space complexity of a search algorithm is measured in terms of the number of nodes that need tobe stored simultaneously.A second measure of interest is the number of unique states that are expanded at least once during the search. Thephrase num",
            {
                "entities": [
                    [
                        3824,
                        3852,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 214 (2014) 66–88Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLogical characterizations of regular equivalence in weighted social networks ✩Tuan-Fang Fan a, Churn-Jung Liau b,∗a Department of Computer Science and Information Engineering, National Penghu University of Science and Technology, Penghu 880, Taiwanb Institute of Information Science, Academia Sinica, Taipei 115, Taiwana r t i c l e i n f oa b s t r a c tArticle history:Received 4 August 2013Received in revised form 21 May 2014Accepted 24 May 2014Available online 28 May 2014Keywords:Weighted social networkMany-valued modal logicRegular equivalenceBisimulationReasoning under uncertainty or imprecisionSocial network analysis is a methodology used extensively in social science. Classical social networks can only represent the qualitative relationships between actors, but weighted social networks can describe the degrees of connection between actors. In a classical social network, regular equivalence is used to capture the similarity between actors based on their links to other actors. Specifically, two actors are deemed regularly equivalent if they are equally related to equivalent others. The definition of regular equivalence has been extended to weighted social networks in two ways. The first definition, called regular similarity, considers regular equivalence as an equivalence relation that commutes with the underlying graph edges; while the second definition, called generalized regular equivalence, is based on the notion of role assignment or coloring. A role assignment (resp. coloring) is a mapping from the set of actors to a set of roles (resp. colors). The mapping is regular if actors assigned to the same role have the same roles in their neighborhoods. Recently, it was shown that social positions based on regular equivalence can be syntactically expressed as well-formed formulas in a kind of modal logic. Thus, actors occupying the same social position based on regular equivalence will satisfy the same set of modal formulas. In this paper, we present analogous results for regular similarity and generalized regular equivalence based on many-valued modal logics.© 2014 Elsevier B.V. All rights reserved.1. IntroductionSocial network analysis (SNA) is a methodology used extensively in social and behavioral sciences, as well as in political science, economics, organization theory, and industrial engineering [58,34,64]. Positional analysis of a social network tries to find similarities between nodes in the network [6,9,25,45,65]. While many traditional clustering methods are based on the attributes of the individual nodes, SNA is more concerned with the structural similarity between the nodes. In SNA, a category, called a social role or social position, is defined in terms of the similarities of the patterns of relations between the nodes, rather than the attributes of the nodes. For example, one useful way to think about the social role “husband” is to consider it as a set of patterned interactions with a member or members of some other social categories, such as “wife” and “child” (and probably others) [34]. One of the most widely studied notions in the positional analysis of social networks is called regular equivalence [6,20,56,57]. According to Borgatti and Everett [6], two actors are regularly equivalent if they are equally related to equivalent others.✩This is a significantly extended version of [26].* Corresponding author.E-mail addresses: dffan@npu.edu.tw (T.-F. Fan), liaucj@iis.sinica.edu.tw (C.-J. Liau).http://dx.doi.org/10.1016/j.artint.2014.05.0070004-3702/© 2014 Elsevier B.V. All rights reserved.\fT.-F. Fan, C.-J. Liau / Artificial Intelligence 214 (2014) 66–8867Interestingly, Marx and Masush [51] showed that social positions based on regular equivalence can be syntactically expressed as well-formed formulas in a kind of modal logic. Thus, actors that have the same social position based on regular equivalence will satisfy the same set of modal formulas. Traditionally, modal logic has been considered the logic for reasoning about modalities, such as necessity, possibility, time, actions, beliefs, knowledge, and obligations. However, semantically, it is essentially a language for describing relational structures [3]. A relational structure is simply a collection of relations on a given universe; therefore, social networks can be represented by relational structures in mathematics. The logical characterization of social positions implies that modal formulas are semantically invariant with respect to regular equivalence.In recent years, weighted social networks have also received considerable attention because they can represent both the qualitative relationships and the degrees of connection between nodes [2,27,28,43,54,63]. The notion of regular equivalence is extended to weighted social networks based on two alternative definitions of regular equivalence [28]. While the two definitions are equivalent for ordinary networks, they induce different generalizations for weighted networks. The first generalization, called regular similarity, is based on the definition of regular equivalence as an equivalence relation that commutes with the underlying graph edges [9]. By the definition, regular similarity is a fuzzy relation that describes the degree of similarity between actors in the network. The second generalization, called generalized regular equivalence, is based on the definition of role assignment or coloring [45]. A role assignment (resp. coloring) is a mapping from the set of actors to a set of roles (resp. colors). The mapping is regular if actors assigned to the same role have the same roles in their neighborhoods. Consequently, generalized regular equivalence is an equivalence relation that can determine the role partition of actors in a weighted social network.Because of the importance of weighted social networks, we explore the logical characterizations of regular similarity and generalized regular equivalence. In this paper, we use many-valued modal logics to characterize the two kinds of relations. On one hand, we show that the truth values of many-valued modal logic formulas are invariant with respect to generalized regular equivalence. On the other hand, we demonstrate that the maximum regular similarity between any two actors is equal to the minimum equivalence between degrees of the two actors satisfying many-valued modal logic formulas.The remainder of this paper is organized as follows. In Section 2, we review some basic concepts about social networks, fuzzy relations, and positional analysis. In Sections 3 and 4, we present the logical characterizations of regular similar-ity and generalized regular equivalence respectively. In Section 5, we discuss issues related to further generalizations and applications of the logical characterizations. Section 6 contains our concluding remarks.2. Preliminaries2.1. Social networksSocial networks are defined by actors and relations (or nodes and edges in terms of graph theory) [34]. Generally, a social network is defined as a relational structure N = (U , (R i)i∈I ), where U is the set of nodes; I is an index set; and for each i ∈ I , R i ⊆ U ki is a ki -ary relation on the domain U , where ki is a positive integer. If ki = 1, then R i is called an attribute or a property. In practice, most SNA methods only consider a simplified version of a social network with binary relations. For ease of presentation, we focus on a social network with unary and/or binary relations. Thus, the social network considered in this paper is a structure N = (U , (P i)i∈I , (R j) j∈ J ), where the universe U is a finite set of actors; P i ⊆ U for all i ∈ I ; and R j ⊆ U × U for all j ∈ J . Although practical social networks are always concerned with finite sets of attributes and relations, our results do not rely on the finitary assumptions about attributes and relations. Therefore, we only assume that the set of actors is finite and do not impose additional restrictions on the index sets I and J . In terms of graph theory, N is a labeled graph, where U is a set of nodes labeled with subsets of I , and each R j denotes a set of (labeled) edges. For each x ∈ U , the out-neighborhood and in-neighborhood of x with respect to a binary relation R, denoted respectively by Rx and Rx, are defined as follows:−(cid:2)Rx =−Rx =y ∈ U(cid:2)y ∈ U(cid:4)(cid:3)(cid:3) (x, y) ∈ R,(cid:3)(cid:4)(cid:3) ( y, x) ∈ R.(1)(2)If E is an equivalence relation on U and x is an actor, the E-equivalence class of x is equal to its neighborhood, i.e., x. Note that the latter equality holds because of the symmetry of E. For any X ⊆ U , we use [ X]E to denote [x]E = Ex = Ethe set {[x]E | x ∈ X}.−Several equivalence relations have been proposed for exploring the structural similarity between actors. Among them, regular equivalence has been studied extensively [6,9,25,45,65]. Although there are several definitions of regular equivalence, we only consider two of them in this paper. The first, proposed by Boyd and Everett [9], states that an equivalence relation E is a regular equivalence with respect to a binary relation R if it commutes with R; i.e.,E · R = R · E,(3)where E · R = {(x, y) | ∃z ∈ U , (x, z) ∈ E ∧ (z, y) ∈ R} is the composition of E and R. By this definition, if E is a regular equivalence with respect to R and (x, y) ∈ E, then for each z ∈ Rx (resp. Ry) such (cid:7) ∈ R y (resp. Rx), there exists z−−\f68T.-F. Fan, C.-J. Liau / Artificial Intelligence 214 (2014) 66–88(cid:7)) ∈ E. The property leads naturally to the second definition of regular equivalence, which is based on role as-that (z, zsignment [45]. It states that an equivalence relation E is a regular equivalence with respect to a binary relation R if for x, y ∈ U ,(x, y) ∈ E ⇒(cid:5)[Rx]E = [R y]E and(cid:6)(cid:7)x−R(cid:6)−Ry(cid:7)(cid:8).E=E(4)According to this definition, if x and y are regularly ",
            {
                "entities": [
                    [
                        3625,
                        3653,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 319 (2023) 103918Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintThe first AI4TSP competition: Learning to solve stochastic routing problems ✩Yingqian Zhang a,∗,1, Laurens Bliek a,1, Paulo da Costa a,1, Reza Refaei Afshar a,1, Robbert Reijnen a,1, Tom Catshoek b,1, Daniël Vos b,1, Sicco Verwer b,1, Fynn Schmitt-Ulms c,2, André Hottung d,2, Tapan Shah e,2, Meinolf Sellmann f,2, Kevin Tierney d,2, Carl Perreault-Lafleur g,2, Caroline Leboeuf g,2, Federico Bobbio g,2, Justine Pepin g,2, Warley Almeida Silva g,2, Ricardo Gama h,2, Hugo L. Fernandes i,2, Martin Zaefferer l,2, Manuel López-Ibáñez j,2, Ekhine Irurozki k,2a Eindhoven University of Technology, Netherlandsb Delft University of Technology, Netherlandsc McGill University, Canadad Bielefeld University, Germanye General Electric, USAf InsideOpt, USAg Université de Montréal, Canadah Polytechnic Institute of Viseu, Portugali Rockets of Awesome, New York City, USAj University of Manchester, UKk Telecom Paris, Francel DHBW Ravensburg, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 25 January 2022Received in revised form 31 October 2022Accepted 31 March 2023Available online 3 April 2023Keywords:AI for TSP competitionTravelling salesman problemRouting problemStochastic combinatorial optimizationSurrogate-based optimizationDeep reinforcement learningThis paper reports on the first international competition on AI for the traveling salesman problem (TSP) at the International Joint Conference on Artificial Intelligence 2021 (IJCAI-21). The TSP is one of the classical combinatorial optimization problems, with many variants inspired by real-world applications. This first competition asked the participants to develop algorithms to solve an orienteering problem with stochastic weights and time windows (OPSWTW). It focused on two learning approaches: surrogate-based optimization and deep reinforcement learning. In this paper, we describe the problem, the competition setup, and the winning methods, and give an overview of the results. The winning methods described in this work have advanced the state-of-the-art in using AI for stochastic routing problems. Overall, by organizing this competition we have introduced routing problems as an interesting problem setting for AI researchers. The simulator of the problem has been made open-source and can be used by other researchers as a benchmark for new ✩This paper was submitted to the Competition Section of the journal.* Corresponding author.E-mail address: yqzhang@tue.nl (Y. Zhang).1 The organization team.2 The winning teams.https://doi.org/10.1016/j.artint.2023.1039180004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fY. Zhang, L. Bliek, P. da Costa et al.Artificial Intelligence 319 (2023) 103918learning-based methods. The instances and code for the competition are available at https://github .com /paulorocosta /ai -for-tsp -competition.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionMany real-world optimization problems are combinatorial optimization problems (COPs) with the objective to find an op-timal solution among a finite set of possible solutions. COPs are proven to be NP-Complete, thus solving them to optimality is computationally expensive and mostly impractical for large instances. COPs have been studied extensively in various re-search communities, including discrete mathematics, theoretical computer science, and operations research. An efficient way of finding acceptable solutions for COPs is through heuristic approaches. The time complexity of heuristics is mainly poly-nomial, although they may provide solutions that are far from optimal. Besides, these approaches must be redesigned if the problem assumption and settings are changed. Recent years have seen rapidly growing interest in using machine learning (ML) to dynamically learn heuristics and find close-to-optimal solutions for COPs [1]. Among COPs, routing problems such as the traveling salesman problem (TSP) are well-known, and they emerge in many real-life applications. The TSP has several variants that include uncertainty, making the problem challenging for traditional exact and heuristic algorithms. TSP and its variants are some of the most well-studied COPs in the ML literature. Previous works on deep neural network approaches for routing problems have focused on learning to construct good tours [2–13] and on learning to search for good solu-tions [14–27], leveraging supervised and deep reinforcement learning (DRL). Other approaches considered surrogate-based optimization (SBO) [28–33], using ML models to guide the search for good tours.In this competition, the participants solve a variant of TSP using ML methods. The selected variant of TSP contains stochastic weights, where the cost of traveling between two nodes is stochastic. Each node also has a prize, and collecting the prize depends on the arrival time of an agent. These assumptions make this variant of TSP similar to real-life problems. For example, in real life, the required time to travel from one city to another depends on road construction work and traffic jams. Moreover, visiting a location is usually assigned with time bounds that must be respected. To solve this problem variant, the participants must use one of two ML methods: SBO or DRL. Both of these methods have shown considerable promise in generating solutions for routing problems in previous works.We emphasize that the primary goal of this competition is to bring new surrogate-based and DRL-based approaches into practice for solving a difficult variant of TSP. This is done by attracting ML researchers and challenging them to solve this difficult routing problem. The solutions may be built upon existing work adapted for the particular TSP variant. Although some previous work has focused on prize collecting (orienteering) problems or stochastic weights, few researchers take the combination of these assumptions into account. This motivates us to establish a platform that provides the opportunity for AI researchers to develop SBO and DRL approaches for solving a well-known routing problem. As a byproduct, the competition provides several winning methods and a simulator for generating problem instances that researchers can use to benchmark their ML-based approaches. In summary, the objective of organizing this competition is threefold: (1) to introduce routing problems as an interesting problem setting for ML researchers; (2) to advance the state-of-the-art in using ML for routing problems; and (3) to provide a challenging problem and a simulator for researchers to benchmark their ML-based approaches.We divide the competition into two tracks, each requiring different knowledge from sub-fields of AI:• Track 1 (SBO): Given one instance, previously tried tours, and the total reward (sum of the prizes collected in a tour) for those tours, the goal is to learn a model predicting the reward for a new tour. Then an optimizer finds the tour that gives the best reward according to that model, and that tour is evaluated, giving a new data point. Then the model is updated, and this iterative procedure continues for a fixed number of steps. Over time, the model becomes more accurate, giving better and better tours. This procedure is used in SBO algorithms such as Bayesian optimization [34].• Track 2 (DRL): We consider an environment (simulator) that can generate a set of multiple instances I following the same generating distribution. We expect as output (partial) solutions containing the order in which the nodes should be visited. The environment returns general instance features and the stochastic travel time for traversing the last edge in a given solution. The goal is to maximize the prizes collected while respecting time-related constraints over multiple samples of selected test instances. This procedure is related to neural combinatorial optimization [4].The first competition, named the AI4TSP competition, was an IJCAI-21 (International Joint Conference on Artificial Intel-ligence) competition. It ran from May 27 to July 12, 2021, and was organized by the Delft University of Technology and the Eindhoven University of Technology. By the deadline of the final test phase, we had received four submissions in the SBO track and three submissions in the DRL track. The submissions are tested on up to 1, 000 problem instances with up to 200nodes, and the winners are determined by ranking the total quality of their solutions. The results of the competition have been officially announced in the Data Science Meets Optimization (DSO) workshop, which was co-located with IJCAI-21.2\fY. Zhang, L. Bliek, P. da Costa et al.Artificial Intelligence 319 (2023) 1039182. Problem description and methodologyBoth tracks look at the orienteering problem with stochastic weights and time windows (OPSWTW), which is a simplified version of the time-dependent OPSWTW [35]. This problem is similar to the traveling salesman problem (TSP), where nodes need to be visited while respecting a maximum tour time and opening and closing times of the nodes in order to maximize some measure of rewards. We detail the problem in the section below.2.1. OPSWTWIn the TSP, the goal is to find the tour with the smallest cost that visits all locations (customers) in a network exactly once. However, in practical applications, one rarely knows all the travel costs between locations precisely. Moreover, there could be specific time windows at which customers need to be served, and certain customers can be more valuable than others. Lastly, the salesman is often constrained by a maximum capacity or travel time, representing a limiting factor in the number of nod",
            {
                "entities": [
                    [
                        2677,
                        2705,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2021–2060Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms and mechanisms for procuring services with uncertaindurations using redundancyS. Stein a,∗, E.H. Gerding a, A.C. Rogers a, K. Larson b, N.R. Jennings aa Intelligence, Agents, Multimedia Group, School of Electronics and Computer Science, University of Southampton, Southampton, United Kingdomb Cheriton School of Computer Science, University of Waterloo, Waterloo, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 16 September 2010Received in revised form 22 April 2011Accepted 15 July 2011Available online 23 July 2011Keywords:Mechanism designMulti-agent systemsService-oriented computingUncertaintyRedundancyIn emerging service-oriented systems, such as computational clouds or grids, softwareagents are able to automatically procure distributed services to complete computationaltasks. However, service execution times are often highly uncertain and service providersmay have incentives to lie strategically about this uncertainty to win more customers. Inthis paper, we argue that techniques from the field of artificial intelligence are instrumentalto addressing these challenges.To this end, we first propose a new decision-theoretic algorithm that allows a singleservice consumer agent to procure services for a computational task with a strict deadline.Crucially, this algorithm uses redundancy in a principled manner to mitigate uncertainexecution times and maximise the consumer’s expected utility. We present both anoptimal variant that uses a novel branch-and-bound formulation, and a fast heuristic thatachieves near-optimal performance. Using simulations, we demonstrate that our algorithmsoutperform approaches that do not employ redundancy by up to 130% in some settings.Next, as the algorithms require private information about the providers’ capabilities, weshow how techniques from mechanism design can be used to incentivise truthfulness.As no existing work in this area deals with uncertain execution times and redundantinvocations, we extend the state of the art by proposing a number of payment schemesfor these settings. In a detailed analysis, we prove that our mechanisms fulfil a rangeof desirable economic properties,including incentive compatibility, and we discusssuboptimal variants that scale to realistic settings with hundreds of providers. We showexperimentally that our mechanisms extract a high surplus and that even our suboptimalvariants typically achieve a high efficiency (95% or more in a wide range of settings).© 2011 Elsevier B.V. All rights reserved.1. IntroductionIncreasingly, participants in large distributed systems are able to discover and automatically procure the services ofothers. This allows service consumers to complete complex computational tasks on demand, but without the need to investin and maintain expensive hardware. Already, such a service-oriented approach is gaining popularity in a large range ofapplication areas, including grids, peer-to-peer systems, and cloud and utility computing [12,48,21].Despite its benefits, flexible service procurement poses new challenges that have not been addressed satisfactorily bycurrent research. In particular, as they are offered by external providers that are beyond the consumer’s direct control,* Corresponding author.E-mail addresses: ss2@ecs.soton.ac.uk (S. Stein), eg@ecs.soton.ac.uk (E.H. Gerding), acr@ecs.soton.ac.uk (A.C. Rogers), klarson@cs.uwaterloo.ca (K. Larson),nrj@ecs.soton.ac.uk (N.R. Jennings).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.07.002\f2022S. Stein et al. / Artificial Intelligence 175 (2011) 2021–2060services may display significant uncertainty in their behaviour. Thus, the execution time of services can be highly uncertain,due to concurrent access by other consumers, hardware or network problems and the provider’s scheduling policies. Thisis particularly problematic when services take a long time to complete, as is common for many computationally intensivetasks, and when consumers need to obtain their results by a certain deadline.Furthermore, in large systems, many different providers may offer functionally equivalent services that are heterogeneousin their quality and costs. This requires consumers to make appropriate decisions about which services to procure, balancingthe probability of success with the overall cost. In particular, instead of only procuring a single provider, the consumer maybenefit by redundantly procuring multiple service providers that will attempt the same task. For example, when facedwith a high-priority task but with a long deadline, a consumer may at first invoke an unreliable service at a low cost.However, as the time approaches the deadline and the task is still not completed, it may invoke another, more costly butalso more reliable service to ensure that the task is completed in time. Alternatively, when a critical task has to be completedurgently, the consumer may be better off (both in terms of costs and probability of success) by selecting multiple cheapservices immediately instead of a single premium service. This creates a challenge for the consumer, who has to make thesedecisions and wants to maximise its profit.However, even when a consumer can make optimal decisions about which services to procure and whether to employredundancy, it is faced with a second, highly related challenge. This is the fact that service providers are inherently self-interested agents and, thus, they may choose to misrepresent their capabilities if this promises to increase their profits. Forinstance, a provider may exaggerate its speed, in order to entice potential customers to procure its service, or it may inflateits costs to elicit higher payments. In these cases, consumers may end up procuring unsuitable services that are unableto complete the task in a timely or effective manner. Put differently, the consumer’s decisions may be based on wronginformation and therefore lead to suboptimal procurement strategies.Clearly, both the problems of dealing with uncertain execution times and the providers’ possible strategic behavioursare closely interrelated. More specifically, in order to address the first challenge satisfactorily, we also have to ensure thatproviders truthfully reveal their capabilities to the consumer. However, as we will see later, ensuring truthfulness, in turn,requires us to solve the service procurement problem optimally. For this reason, we address both of these intertwinedchallenges in this paper.Now, there is an array of existing techniques that apply to our setting. In particular, decision theory and computationalsearch techniques have been used to design agents that can take optimal actions in uncertain environments, while mech-anism design has been employed successfully to incentivise truthfulness in multi-agent systems. Unfortunately, however,none of the existing approaches are readily applicable to the scenario we consider here (see Section 2 for details). For thisreason, we combine and extend the current state of the art from multiple sub-fields of artificial intelligence and demonstratehow the resulting techniques can be applied to a realistic large-scale problem.In more detail, to address the first problem of uncertain execution times, we make the following contributions in ourwork:• We are the first to characterise the optimal solution to a generic service procurement problem where a service consumercan procure multiple service providers dynamically and redundantly over time, in order to complete a task by a givendeadline. To find this efficiently, we combine analytical optimisation with computational search techniques. In moredetail, we present a novel branch-and-bound algorithm that exploits specific characteristics of the procurement scenarioand that we empirically show to reduce the search for the optimal solution, on average, by over 99.9%. As this algorithmrelies on finding optimal procurement times from a continuous domain, we derive efficient closed-form solutions forboth settings with (i) independent execution durations and with (ii) perfectly correlated durations.• While our branch-and-bound algorithm quickly finds a solution in settings with dozens of providers, it does not scaleto significantly larger systems. Hence, we also present a suboptimal heuristic algorithm to the service procurementproblem. This combines some of our analytical results from the optimal algorithm with a greedy local search in a novelmanner. As a result, it is capable of scaling to settings with hundreds or even thousands of providers.• We evaluate both algorithms extensively using simulations. In doing this, we show empirically that they achieve anup to 130% improvement over techniques that do not use redundancy, that they also consistently outperform existingad hoc techniques that are used in practice and finally that our heuristic solution achieves near-optimal performance.We also note that although our algorithms perform particularly well in environments where service durations areindependently distributed, redundancy can still be beneficial in settings with perfect correlation, resulting in an averageimprovement of over 27% in certain scenarios.As the first part of our work relies on having full information about the providers’ capabilities, we also address thesecond interrelated problem of strategic behaviour with the following contributions:• To apply our algorithms in settings with private information, we extend the state of the art in mechanism design andpropose a number of novel incentive compatible mechanisms to deal with our service procurement problem. Unlikeexisting approaches, which have so far concentrated on services with a deterministic runtime and which allocate a taskonly to a single provider agent, our mechanisms can deal specifically with uncertain execution durations and ",
            {
                "entities": [
                    [
                        3663,
                        3691,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 434–439www.elsevier.com/locate/artintNo regrets about no-regretYu-Han ChangIntelligent Systems Division, USC Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, USAReceived 16 May 2006; received in revised form 26 October 2006; accepted 13 December 2006Available online 13 February 2007AbstractNo-regret is described as one framework that game theorists and computer scientists have converged upon for designing andevaluating multi-agent learning algorithms. However, Shoham, Powers, and Grenager also point out that the framework has seriousdeficiencies, such as behaving sub-optimally against certain reactive opponents. But all is not lost. With some simple modifications,regret-minimizing algorithms can perform in many of the ways we wish multi-agent learning algorithms to perform, providingsafety and adaptability against reactive opponents. We argue that the research community should have no regrets about no-regretmethods.© 2007 Elsevier B.V. All rights reserved.Keywords: Multi-agent learning; Regret-minimization; Game theory1. IntroductionTraditional no-regret algorithms sometimes perform sub-optimally because the regret criterion only compares thealgorithm’s performance to the possible alternate outcomes in the individual stage games of a repeated game, assumingthe opponent’s action stays fixed. For example, a typical no-regret agent playing Prisoner’s Dilemma would end upalways defecting, since this minimizes the algorithm’s regret relative to the other possible action of cooperating, giventhe observed sequence of opponent actions. However, it is relatively simple to extend standard no-regret approachesto handle and avoid these suboptimal cases. In fact, I would argue that such modified no-regret algorithms hold muchpromise for the future direction of multi-agent learning.Regret minimization methods, sometimes also referred to as experts algorithms or hedging algorithms, provide theclearest method for evaluating agent performance in general multi-agent settings. Since we would often like to assumethat the opponent in multi-agent learning problems is unknown, it is usually difficult to evaluate agent performance,which depends on the type of opponent the agent ends up playing against. Regret-minimization approaches circumventthis problem by defining performance in terms of a comparison class of possible strategies that the agent itself iscapable of executing. Thus, no assumptions need to be made about the opponent’s strategy. Furthermore, as Shohamet al. have stated, many regret-minimizing algorithms can also guarantee safety in addition to universal consistency.These benefits can be extended to the case where the agent faces reactive opponents as well. Instead of consideringsingle actions at each time step, our modified regret framework considers multi-period strategies by dividing up theE-mail address: ychang@ISI.EDU.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.12.007\fY.-H. Chang / Artificial Intelligence 171 (2007) 434–439435sequence of games into intervals. The regret criterion can now take into account reactive strategies such as “Tit-for-Tat”. Two issues arise from this setup: 1) an action’s potential reward can no longer be observed unless that action isactually played, since the reward depends on the opponent’s current reactive strategy, which cannot be observed, and2) computational complexity grows exponentially as we consider longer intervals and a larger set of more complexstrategies. The first issue can be resolved by using a no-regret algorithm such as Auer, Cesa-Bianchi, Freund, andSchapire’s EXP3 algorithm [1], which extends Freund and Schapire’s multiplicative weight algorithm [6] to the caseof partial information. We propose to alleviate the second issue by choosing the set of possible strategies carefully andby incorporating learning algorithms as experts in a modified version of the EXP3 algorithm [4].2. Mathematical backgroundFor most of this article, we will focus our attention on repeated games, though the techniques described can po-tentially be extended to stochastic games. The repeated game setting already captures much of the complexity of themulti-agent learning problem, where we need to focus on our ability to learn about and react to the opponent. In astochastic game, we also need to learn about and adapt to the external environment. Here we will focus on modelingthe states of the opponent and set aside the problem of additionally modeling the states of the external environment atthe same time.During each stage game of the repeated game, each player simultaneously chooses to play a particular actionai ∈ Ai and receives reward based on the joint action taken. We use the terms policy and strategy interchangeably.While Nash equilibrium is the accepted solution concept for a single stage game, in repeated game and stochastic gamesettings, modern game theory often takes a more general view of optimality, a view that has also gained acceptancein the machine learning community [3,5]. The key difference is the treatment of the history of actions taken in thegame. Here we define a behavioral strategy β : H → Ai , where H =t H t and H t is the set of all possible histories oflength t. Histories are observations of joint actions, ht = (ai, a−i, ht−1). For simplicity, we will assume A = A1 = A2.(cid:2)Definition 1. A τ -length behavioral strategy βτ : H τ → A is a mapping from the set of all possible histories H τ toactions a ∈ A. Let Bτ be the set of all possible τ -length behavioral strategies βτ .We note that |Bτ | = |A||A|2τ. In the case where we take H t = H , we could even consider learning algorithmsthemselves to be a possible “behavioral strategy” for playing a repeated game.This definition of our strategy space is clearly more powerful, and allows us to define a much larger set of potentialequilibria. However, when the opponent is not rational, it is no longer advantageous to find and play an equilibriumstrategy. In fact, given an arbitrary opponent, the Nash equilibrium strategy may return a lower payoff than some otheraction. Indeed, the payoff may be worse than the original Nash equilibrium value. Thus, we turn to regret minimizationalgorithms.2.1. Regret-minimizationIn repeated games, the standard regret minimization framework enables us to perform almost as well as the bestaction, if that single best action were played in every time period. We will frequently refer to the EXP3 algorithm (andits variants) explored by Auer et al. [1] as an example of this type of algorithm. In the original formulation of EXP3,we choose single actions to play, but we do not get to observe the rewards we would have received if we had chosendifferent actions.We need to be a bit more precise about the definition of regret here. Auer et al. consider an adversarial settingwhere the reward function is actually a sequence of reward functions that change at each time period. We denote thecumulative reward for executing an algorithm H for T time periods by RH , and this is compared with the cumulativereward the agent could have received had it chosen to execute a fixed action a for all T time periods, Rmax = maxa Ra.Since the algorithm H is randomized, we will be discussing expected regret Rmax − E[RH ]. The authors show thatT K ln K, where K is the number of actionthe performance of EXP3 exhibits an expected regret bound of 2choices, and T is the number of rounds we play the game. In situations where the rewards for all possible actions areobserved at each period, this upper bound on the expected regret can be reduced to O(T ln K ).e − 1√√√\f436Y.-H. Chang / Artificial Intelligence 171 (2007) 434–439Generally speaking, these regret-minimizing algorithms hedge between possible actions by keeping a weight foreach action that is updated according to the action’s historical performance. The probability of playing an action isthen its fraction of the total weights mixed with the uniform distribution. Intuitively, better experts perform better, getassigned higher weight, and are played more often. Sometimes these algorithms are called experts algorithms, since wecan think of the actions as being recommended by a set of experts. This set is also referred to as our comparison class.This comparison class provides a clear means of evaluating our algorithm’s performance by pegging this evaluationmetric on a set of strategies and assumptions that we know how to execute.It is important to note that most of these existing methods only compare our performance against strategies that arebest responses to what are often called oblivious or myopic opponents. That is, the opponent does not learn or react toour actions, instead playing a pre-selected, but possibly arbitrary, fixed string of actions. Under most circumstances,however, we might expect an intelligent opponent to change their strategy as they observe our own sequence of plays.For example, consider the game of repeated Prisoner’s Dilemma. If we follow the oblivious opponent assumption,then the best choice of action on hindsight would always be to defect, since we’re assuming that the oblivious opponentwill not change his next action in response to our defection. This approach would assign low scores (high regret) tocooperative strategies, and thus miss out on the chance to earn higher rewards by cooperating with opponents such asa Tit-for-Tat opponent, which cooperates with us as long as we also cooperate. These opponents can be called reactiveopponents.Our extension of the regret framework deals with reactive opponents by expanding our comparison class of strate-gies to include reactive, or behavioral, strategies. Now, instead of only comparing against the best action from thestage game assuming that the opponent’s action stays fixed, we can also compare our performance against strategiessuch as “Tit-for-Tat” with the assumption that the opponent chooses i",
            {
                "entities": [
                    [
                        3005,
                        3033,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 225 (2015) 51–76Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn redundant topological constraintsSanjiang Li a,b,∗a Centre for Quantum Computation & Intelligent Systems, University of Technology Sydney, Sydney, Australiab Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, Chinac Baidu (China) Co., Ltd., Shanghai, Chinad Department of Infrastructure Engineering, University of Melbourne, Melbourne, Australia, Zhiguo Long a, Weiming Liu c, Matt Duckham d, Alan Both da r t i c l e i n f oa b s t r a c tArticle history:Received 13 May 2014Received in revised form 26 March 2015Accepted 29 March 2015Available online 2 April 2015Keywords:Qualitative spatial reasoningRegion connection calculusRedundancyPrime subnetworkDistributive subalgebraRedundancy checking is an important task in the research of knowledge representation and reasoning. In this paper, we consider redundant qualitative constraints. For a set (cid:2)of qualitative constraints, we say a constraint (xR y) in (cid:2) is redundant if it is entailed by the rest of (cid:2). A prime subnetwork of (cid:2) is a subset of (cid:2) which contains no redundant constraints and has the same solution set as (cid:2). It is natural to ask how to compute such a prime subnetwork, and when it is unique. We show that this problem is in general intractable, but becomes tractable if (cid:2) is over a tractable subalgebra S of a qualitative calculus. Furthermore, if S is a subalgebra of the Region Connection Calculus RCC8 in which weak composition distributes over nonempty intersections, then (cid:2) has a unique prime subnetwork, which can be obtained in cubic time by removing all redundant constraints simultaneously from (cid:2). As a by-product, we show that any path-consistent network over such a distributive subalgebra is minimal and globally consistent in a qualitative sense. A thorough empirical analysis of the prime subnetwork upon real geographical data sets demonstrates the approach is able to identify significantly more redundant constraints than previously proposed algorithms, especially in constraint networks with larger proportions of partial overlap relations.© 2015 Elsevier B.V. All rights reserved.1. IntroductionQualitative spatial reasoning is a common subfield of artificial intelligence and geographical information science, and has applications ranging from natural language understanding [13], robot navigation [46], geographic information systems (GISs) [18], sea navigation [54], to high level interpretation of video data [48].Typically, the qualitative approach represents spatial information by introducing a relation model on a domain of spatial entities, which could be points, line segments, rectangles, or arbitrary regions. In the literature, such a relation model is often called a qualitative calculus [34]. In the past three decades, dozens of spatial (as well as temporal) qualitative calculi have been proposed in the literature (cf. [11]). Among these, Interval Algebra (IA) [1] and the RCC8 algebra [41] are widely known as the most influential qualitative calculi for representing qualitative temporal and, respectively, spatial information. Other well-known qualitative calculi include Point Algebra (PA) [51], Cardinal Relation Algebra (CRA) [33], Rectangle Algebra (RA) [24], the RCC5 algebra [41], etc.* Corresponding author at: Centre for Quantum Computation & Intelligent Systems, University of Technology Sydney, Sydney, Australia.(M. Duckham), aboth@student.unimelb.edu.au (A. Both).E-mail addresses: sanjiang.li@uts.edu.au (S. Li), zhiguo.long@student.uts.edu.au (Z. Long), liuweiming@baidu.com (W. Liu), matt@duckham.orghttp://dx.doi.org/10.1016/j.artint.2015.03.0100004-3702/© 2015 Elsevier B.V. All rights reserved.\f52S. Li et al. / Artificial Intelligence 225 (2015) 51–76Using a qualitative calculus M, we represent spatial or temporal information in terms of relations in M, and formulate a spatial or temporal problem as a set of qualitative constraints (called a qualitative constraint network). A qualitative constraint has the form (xR y), which specifies that the two variables x, y are related by the relation R. The consistency problemis to decide whether a set of qualitative constraints can be satisfied simultaneously. The consistency problem has been investigated in depth for many qualitative calculi in the literature, see e.g., [51,50,33,40,39,43,42,14,55,37,28,35,45,30].In this paper, we consider the important problem of redundant qualitative constraints. Given a set (cid:2) of qualitative constraints, we say a constraint (xR y) in (cid:2) is redundant if it is entailed by the rest of (cid:2), i.e., removing (xR y) from (cid:2) will not change the solution set of (cid:2). It is natural to ask when a network contains redundant constraints and how to get a non-redundant subset without changing the solution set. We call a subset of (cid:2) a prime subnetwork of (cid:2) if it contains no redundant constraints and has the same solution set as (cid:2).The redundancy problem (i.e., the problem of determining if a constraint is redundant in a network) is related to the minimal label problem (cf. [38,8,20,36,3]). A qualitative constraint network (cid:2) is called minimal if for each constraint (xR y)in (cid:2), R is the minimal (i.e., the strongest) relation between x, y that is entailed by (cid:2). Roughly speaking, the minimal network removes ‘redundant’ or ‘unnecessary’ basic relations from each constraint, while the redundancy problem removes ‘redundant’ or ‘unnecessary’ constraints from the constraint network.We show in this paper that it is in general co-NP hard to determine if a constraint is redundant in a qualitative constraint network. But if all constraints in (cid:2) are taken from a tractable subclass1 S then a prime subnetwork can be found in poly-nomial time. For example, if S is a tractable subclass of RCC5 or RCC8 that contains all basic relations, then we can find a prime subnetwork in O (n5) time. Furthermore, if S is a subalgebra of RCC5 or RCC8 in which weak composition distributes over nonempty intersections, then (cid:2) has a unique prime subnetwork, which is obtained by removing all redundant con-straints from (cid:2). We also devise a cubic time algorithm for computing this unique prime subnetwork, which has the same time complexity as the two approximate algorithms of Wallgrün [52].As a by-product, we identify an important class of subalgebras of qualitative calculi, called distributive subalgebras. A sub-algebra D of a qualitative calculus M is called distributive if weak composition distributes over nonempty intersections in D. We show that any path-consistent network over a distributive subalgebra is weakly globally consistent and minimal, where weakly global consistency is a notion similar to but weaker than the well-known notion of global consistency (cf. Definition 5). For RCC8, we identify two maximal distributive subalgebras which are not contained in any other distributive subalgebras, one contains 41 relations and the other contains 64. The 41 relations contained in the first subalgebra are exactly the convex RCC8 relations identified in [8].In this paper, we are mainly interested in topological constraints, as these are the most important kind of qualitative spatial information. A large part of our results can easily be transplanted to other qualitative calculi like PA, IA, CRA and RA. In particular, let M be one of PA, IA, CRA and RA and S a distributive subalgebra of M over which path-consistency implies consistency. Then we can show that any path-consistent network over S is globally consistent and minimal.2 For ease of presentation, we state and prove these results only for RCC5 and RCC8, but indicate in Table 5 which result is applicable to which calculus.1.1. MotivationAs in the case of propositional logic formulas [32], redundancy of qualitative constraints “often leads to unnecessary computation, wasted storage, and may obscure the structure of the problem” [5].3 Finding a prime subnetwork can be useful in at least the following aspects: a) computing and storing the relationships between spatial objects and hence saving space for storage and communication; b) facilitating comparison (or measure the distance) between different constraint networks; c) unveiling the essential network structure of a network (e.g., being a tree or a graph with a bounded tree-width); and d) adjusting geometrical objects to meet topological constraints [52].To further motivate our discussion, we focus on one specific application to illustrate the application area a. and briefly explain how redundancy checking or finding a prime subnetwork helps to solve the application areas b–d.Fig. 1 gives a small example of a set of spatial regions formed by the geographic “footprints” associated with placenames in the Southampton area of the UK. The footprints are derived from crowd-sourced data, formed from the convex hull of the sets of coordinate locations at which individuals used the placenames on social media (cf. [25]). Communicating and reasoning with the qualitative aspects of such data may require the storage and manipulation of large numbers of complex geometries with millions of vertices or large constraint networks with millions of relations.Even for the small example in Fig. 1, the 84 footprints then require 84 ∗ 83/2 = 3486 stored relations. The moderate-sized footprint data set from which Fig. 1 is adapted contains a total of 3443 footprints which leads to a constraint network with 5,925,403 relations. Similarly, a moderate-sized geographic data set of only 1559 statistical areas in Tasmania, explored further in later sections, contains in total 3,093,551 vertices. In the case of both footprints and statistical areas, many of the relationships can be inferred, and computing the prime subnetwork can potentially reduce the number of",
            {
                "entities": [
                    [
                        3764,
                        3792,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 248 (2017) 46–84Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCommonsense reasoning about containers using radically incomplete informationErnest Davis a,∗a Computer Science Dept., New York University, 251 Mercer St., New York, NY 10012, USAb Psychology and Neural Science Depts., New York University, New York, NY 10012, USAc College of Arts and Science, New York University, New York, NY 10012, USA, Gary Marcus b, Noah Frazier-Logue ca r t i c l e i n f oa b s t r a c tArticle history:Received 3 January 2016Received in revised form 30 January 2017Accepted 29 March 2017Available online 4 April 2017Keywords:Commonsense reasoningPhysical reasoningSpatial reasoningContainersIn physical reasoning, humans are often able to carry out useful reasoning based on radically incomplete information. One physical domain that is ubiquitous both in everyday interactions and in many kinds of scientific applications, where reasoning from incomplete information is very common, is the interaction of containers and their contents. We have developed a preliminary knowledge base for qualitative reasoning about containers, expressed in a sorted first-order language of time, geometry, objects, histories, and actions. We have demonstrated that the knowledge suffices to justify a number of commonsense physical inferences, based on very incomplete knowledge.© 2017 Elsevier B.V. All rights reserved.1. Physical reasoning based on radically incomplete informationIn physical reasoning, humans, unlike programs for scientific computation, are often able to carry out useful reasoning based on radically incomplete information. If AI systems are to achieve human levels of reasoning, they must likewise have this ability. The challenges of radically incomplete information are often far beyond the scope of existing automated reasoners based on simulation [11]; rather they require alternative reasoning techniques specifically designed for incomplete information.As a vivid example, consider the human capacity to reason about containers — boxes, bottles, cups, pails, bags, and so on — and the interactions of containers with their contents. For instance, you can reason that you can carry groceries in a grocery bag and that they will remain in the bag with only very weak specifications of the shape and material of the groceries being carried, the shape and material of the bag, and the trajectory of motion. Containers are ubiquitous in everyday life, and children start to learn how containers work at a very early age [21] (Fig. 1).1Containers likewise are central in a wide range of applications and domains.2 For example, in a separate study we have recently begun of the reasoning needed to understand a biology textbook [36], we find that physical containers of many different kinds and scales appear in domains relevant to biology. Some examples:* Corresponding author.E-mail addresses: davise@cs.nyu.edu (E. Davis), gary.marcus@nyu.edu (G. Marcus), N.Frazier.logue@nyu.edu (N. Frazier-Logue).1 Ironically, the working of a baby bottle nipple is beyond the scope of this paper.2 Containment is also often used metaphorically. For instance, Lakoff and Johnson [25] and Reddy [35] discuss the use of containment as a metaphor for the relation between a linguistic expression and its meaning; e.g. “Your argument has no content”. Similarly, in the context of computers, the relation between a memory location such as a variable and its value is often conceptualized as containment.http://dx.doi.org/10.1016/j.artint.2017.03.0040004-3702/© 2017 Elsevier B.V. All rights reserved.\fE. Davis et al. / Artificial Intelligence 248 (2017) 46–8447Fig. 1. Infant learning about containers.Fig. 2. A lake divides into two lakes when the water level falls.• The membrane of a cell is a container that holds the contents of the cell. Many of the primary processes in the cell are concerned with bringing material into the container and expelling material from the container.• The skin or other outer layer of an animal is a container for the animal. Again, many of the central life processes — eating, breathing, excreting — deal with transporting material into and out of the container.• In a discussion of speciation (p. 493), it is mentioned that a subpopulations of a water creature can be isolated if the water level of a lake falls, dividing it into two lakes. Here the container is the lake bed, and the phenomenon depends on the somewhat non-obvious fact that a liquid container that bounds a single connected region at one level may bound two regions at a lower level (Fig. 2).In this paper we describe the initial stages of development of a knowledge-based system for reasoning about manipu-lating containers, in which knowledge of geometry and physics and problem specifications are represented by propositions. Below, we outline the system, and show that this approach suffices to justify a number of commonsense physical infer-ences, based on very incomplete knowledge of the situation and of the dynamic laws that govern the objects involved. These inferences have been automatically verified using the first-order theorem prover SPASS [42].1.1. Incomplete informationThe issues of complete and incomplete information can easily be misunderstood, so let us make clear what we have in mind. Of course, few representations are truly complete or entirely precise; in virtually any representation, some aspects are omitted, some are simplified, and some are approximated. However, techniques such as simulation, or STRIPS-like represen-tations, require that the initial conditions of the scenario and that the dynamics of the microworld be fully specified relative to a given level of description. That is, the representational framework specifies some number of critical relations between entities and properties of entities. A complete representation of a situation relative to that framework enumerates all the entities that are relevant to the situation, and specifies all the relations in the framework that hold between those entities. The description must be detailed and precise enough that the situation at the next time step is likewise fully specified, in the same sense.For instance, the standard blocks world representation omits the size, shape, and physical characteristics of the blocks involved, and the trajectory of the actions. Situations are describe purely in terms of the predicate On(t,x,y) (object x is on object y at time t) and actions are described in terms of Puton(t,x,y) (the agent puts object x onto y at time t). However, the dynamic theory is a complete account at this level of description; that is, a complete enumeration of the On relations that hold in one situation completely determines what actions are feasible, and determines all the On relations that will hold once the action is executed. Additionally, most projection and most planning problems provide a complete enumeration of the On relations that hold in the initial situation.By contrast, in the theory that we develop in this paper, both general domain axioms and problem specifications may give full specifications of some of the features involve, but leave others partially specified or wholly unspecified. For instance, inference 1 (section 8) specifies that initially object Ox1 is inside box Ob1, but it does not specify whether or not there are any other objects inside Ob1 nor does it specify whether Ox1 is in contact with box Ob1, nor does it specify the spatial relation of the agent to either of these. The physical laws given specify that if the agent drops an object that it is holding, \f48E. Davis et al. / Artificial Intelligence 248 (2017) 46–84the object will end up in a stable state, but the theory does not in general specify where it will end up, or where it will pass through while it is falling, or how it might impact other objects. The theory does support the inference that if it is inside an open container when dropped, it will remain inside the container, and not come into contact with any object outside the container. Some necessary conditions and some sufficient conditions are given for the feasibility of the agent being able to move from a starting to an ending positions are given, but the necessary conditions are much weaker than the sufficient conditions; in many cases, it is indeterminate.2. ContainersWe begin with a general discussion of the properties of containers as encountered in everyday situations and of the characteristics of commonsense reasoning about containers.A container can be made of a wide range of materials, such as rigid materials, paper, cloth, animal body parts, or combinations of these. The only requirement is that the material should maintain its shape to a sufficient degree that holes do not open up through which the contents can escape. Under some circumstances, there can even be a container whose bottom boundary is a liquid; for instance, an insect can be trapped in a region formed by the water in a basin and an upside-down cup. A container can also have a wide range of shapes (precise geometric conditions for different kinds of containers are given in section 6.1).The material of the contents of a container is even less constrained. In the case of a closed container, the only constraint is that the material of the contents cannot penetrate or be absorbed into the material of the container (e.g. you cannot carry water in a paper bag or carry light in a cardboard box); and that the contents cannot destroy the material of the container (you cannot keep a gorilla in a balsa wood cage). Using an open container requires additionally that the contents cannot fly out the top [8]. Using a container with holes requires that the contents cannot fit or squeeze through the holes.Those are all the constraints. In the case of a closed container, the material of the contents can be practically anything with practically any kind of dynamics. For i",
            {
                "entities": [
                    [
                        3570,
                        3598,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 406–416www.elsevier.com/locate/artintWhat evolutionary game theory tells us about multiagent learningKarl Tuyls a,∗, Simon Parsons ba Institute for Knowledge and Agent Technology, Maastricht University, The Netherlandsb Department of Computer and Information Science, Brooklyn College, City University of New York, 2900 Bedford Avenue, Brooklyn,11210 NY, USAReceived 1 May 2006; received in revised form 8 January 2007; accepted 9 January 2007Available online 26 January 2007AbstractThis paper discusses If multi-agent learning is the answer, what is the question? [Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Intelligence 171 (7) (2007) 365–377, this issue] from the perspectiveof evolutionary game theory. We briefly discuss the concepts of evolutionary game theory, and examine the main conclusions from[Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Intelligence 171 (7)(2007) 365–377, this issue] with respect to some of our previous work. Overall we find much to agree with, concluding, however,that the central concerns of multiagent learning are rather narrow compared with the broad variety of work identified in [Y. Shoham,R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Inteligence 171 (7) (2007) 365–377,this issue].© 2007 Elsevier B.V. All rights reserved.Keywords: Evolutionary game theory; Replicator dynamics; Multiagent learning1. IntroductionIn If multi-agent learning is the answer, what is the question? by Shoham, Powers and Grenager [20], the authorsmake a valiant effort to analyse the state of the field of multiagent learning, to summarise the results that have beenachieved within the field, to discern the major research directions that have been followed, and to issue a call to arms.In short, Shoham et al. conclude that most work in multiagent learning can be placed into one of five “buckets” eachof which is associated with a distinct research agenda (these descriptions are taken directly from the “caricatures” inSection 5 of [20]):(1) Computational: learning algorithms are a way to compute the properties of a game.(2) Descriptive: learning algorithms describe how natural agents learn in the context of other learners.(3) Normative: learning algorithms give a means to determine which sets of learning rules are in equilibrium withone another.(4) Prescriptive, cooperative: learning algorithms describe how agents should learn in order to achieve distributedcontrol of dynamic systems.(5) Prescriptive, non-cooperative: learning algorithms describe how agents should act to obtain high rewards.* Corresponding author.E-mail addresses: k.tuyls@micc.unimaas.nl (K. Tuyls), parsons@sci.brooklyn.cuny.edu (S. Parsons).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.004\fK. Tuyls, S. Parsons / Artificial Intelligence 171 (2007) 406–416407In addition [20]:Not all work in the field falls into one of these buckets. This means that either we need more buckets, or some workneeds to be revisited or reconstructed so as to be well-grounded.The authors also point out that research in multiagent learning is often unclear about which of these agendas it ispursuing—and that, in contrast one needs to be very clear about one’s aims—that the field cannot progress by defining“arbitrary learning strategies and analys(ing) whether the resulting dynamics converge in certain cases to a Nashequilibrium or some other solution concept”, and that the field needs to take evaluation more seriously, especially onsome set of standard problems.We basically agree with all of the points that we have quoted above, and below will expand on those that wefeel our background leaves us best qualified to discuss. However, we do have one major point of disagreement withthe views expressed in [20]. The point we disagree with is the idea that there is some overall taxonomy of researchagendas into which all work can be slotted. This is not explicitly stated—all that Shoham et al. say is what we quotedabove, that there are five distinct agendas to which some additional ones may need to be added—but the existence ofan underlying taxonomy into which these additional categories can be slotted seems to be implied.Our objection is neatly summarised by the following passage from McWhorter’s The Power of Babel: A naturalhistory of language [15] in which the author tries to express how the original language, spoken by our commonancestors, became the many thousands of languages that descended from it. He starts by saying “I have implied thatspeech varieties have developed like a bush, starting from a single sprout and branching in all directions, each branchthen developing subbranches, and so on . . . ” before going on to explain that the inter-relationships between languages,the constant process of adoption of terms from one language into another, and the formation of dialects, creoles andintertwined languages means that [15, page 94]:we might do just as well with another analogy, say stewing a good spring lamb stew without much juice (becausethe juice messes up the analogy). Clearly, one can distinguish the lamb from the peas from the potatoes from thecarrots from the leeks from the rosemary leaves. Yet all of these ingredients, if it’s a good stew, are suffused withjuice and flavor from the other items as well. Every now and then, you even encounter a piece of something that,covered with liquid and cooked out of its original shape and consistency, you have to work to figure out the originalidentity of . . . Overall, there is nothing in this stew that tastes or even looks like it would if you had just dumped itinto a pot of boiling water by itself.It seems to us that multiagent learning is such a stew and though it is very helpful to identify the variousingredients—especially if, to stretch the metaphor, some of them would be better taken out of the pot—to concentrateon the constituents misses some of the essence. It is the places in which the agendas that make up the stew meldinto new things, things that cannot be put into a taxonomy because they are a mixture, that we often find the mostinteresting work.1That said, we should reiterate that we are largely in agreement with the agendas identified in [20], and in the nextsection amplify our agreement by examining all five agendas through the lens of evolutionary game theory (EGT),which is an area of multiagent learning in which we have been working, and one that is not much discussed in [20].Following that exploration, we return to our point about the interplay between agendas, illustrating our discussionwith some of our recent work.2. The five research agendas from the perspective of evolutionary game theoryIn this section we will use EGT to illustrate our reaction to the analysis of multiagent learning presented in [20]. Todo this, we first consider what each of the five research agendas means in terms of EGT, taking them in the order thatbest fits our argument, rather than the order in which they are presented by Shoham et al.1 Though one has to be especially careful to be clear what one is doing at these junctures.\f408K. Tuyls, S. Parsons / Artificial Intelligence 171 (2007) 406–4162.1. Normative and descriptive agendasOur view of EGT is that it represents a move away from the normative agenda (in the terms of [20]) and towards thedescriptive agenda. In particular, as summarised by [6], recent years have seen an important shift in game theory awayfrom classical solution concepts such as Nash equilibrium, and towards EGT solution concepts such as the evolutionarystable strategy2 (ESS) and the replicator equations. The obvious reasons for this are that the Nash equilibrium is hardto compute, often does not describe the best way to behave, both in terms of optimality and stability, and is not ableto deal with highly dynamic situations. EGT [8,10,13,19] suffers less from these problems, and in our opinion, thedescriptive approach that it embodies matches the overall goals of multiagent learning much better than the normativeapproach that is the preserve of traditional game theory (GT). In the subsequent sections we will explain the basis forthese beliefs.2.1.1. From game theory to evolutionary game theoryWhen John Maynard-Smith applied game theory to biology [13,14], and thus invented evolutionary game theory,he relaxed the premises behind GT. Classical GT is a normative theory, in the sense that it expects players or agentsto be perfectly rational and behave accordingly [24,27,29]. In classical game theory, interactions between rationalagents are modelled as games of two or more players that can choose from a set of strategies and the correspondingpreferences. Game theory is thus the mathematical study of interactive decision making in the sense that the agentsinvolved in the decisions take into account their own choices and those of others. Choices are determined by stablepreferences concerning the outcomes of their possible decisions, and strategic interaction whereby agents take intoaccount the relation between their own choices and the decisions of other agents.Players in the classical setting have a perfect knowledge of the environment and the payoff tables, and try tomaximise their individual payoff. However, under the biological circumstances considered by Maynard-Smith, itbecomes impossible to judge what choices are the most rational. Instead of figuring out, a priori, how to optimise itsactions, the question now facing a player becomes how to learn to optimise its behaviour and maximise its return,and it does this based on local knowledge and through a process of trial and error. This learning process matches theconcept of evolution in biology, and forms the basis of EGT. In contrast to classical GT, then, EGT is a descriptivetheory, describing this process of l",
            {
                "entities": [
                    [
                        2933,
                        2961,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1369–1406Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintKernel functions for case-based planningIvan SerinaFree University of Bozen-Bolzano, Viale Ratisbona, 16, I-39042 Bressanone, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 5 September 2008Received in revised form 14 July 2010Accepted 16 July 2010Available online 30 July 2010Keywords:Case-based planningDomain-independent planningCase-based reasoningHeuristic search for planningKernel functionsCase-based planning can take advantage of former problem-solving experiences by storingin a plan library previously generated plans that can be reused to solve similar planningproblems in the future. Although comparative worst-case complexity analyses of plangeneration and reuse techniques reveal that it is not possible to achieve provable efficiencygain of reuse over generation, we show that the case-based planning approach can be aneffective alternative to plan generation when similar reuse candidates can be chosen.In this paper we describe an innovative case-based planning system, called OAKplan,which can efficiently retrieve planning cases from plan libraries containing more than tenthousand cases, choose heuristically a suitable candidate and adapt it to provide a goodquality solution plan which is similar to the one retrieved from the case library.Given a planning problem we encode it as a compact graph structure, that we callPlanning Encoding Graph, which gives us a detailed description of the topology of theplanning problem. By using this graph representation, we examine an approximate retrievalprocedure based on kernel functions that effectively match planning instances, achievingextremely good performance in standard benchmark domains.The experimental results point out the effect of the case base size and the importanceof accurate matching functions for global system performance. Overall, we show thatOAKplan is competitive with state-of-the-art plan generation systems in terms of numberof problems solved, CPU time, plan difference values and plan quality when cases similarto the current planning problem are available in the plan library.© 2010 Elsevier B.V. All rights reserved.1. IntroductionPlanning is a process which usually involves the use of a lot of resources. The efficiency of planning systems can beimproved by avoiding repeating the planning effort whenever it is not strictly necessary. For example this can be donewhen the specification of the goals undergoes a variation during plan execution or execution time failures turn up: it isthen advisable to change the existing plan rather than replanning from scratch. One might even think of basing the wholeplanning process on the modification of plans, a procedure also known as planning from second principles [47]. In fact thismethod does not generate a plan from scratch, but aims at exploiting the knowledge contained in plans that were generatedbefore. The current problem instance Π is thus employed to search for a plan in a library that, maybe after a number ofchanges, might turn out useful to solve Π .In Case-Based Planning (CBP), previously generated plans are stored as cases in memory and can be reused to solvesimilar planning problems in the future. CBP can save considerable time over planning from scratch, thus offering a po-tential (heuristic) mechanism for handling intractable problems. Similarly to other Case-Based Reasoning (CBR) systems,CBP is based on two assumptions on the nature of the world [38]. The first assumption is that the world is regular: sim-E-mail address: ivan.serina@unibz.it.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.07.007\f1370I. Serina / Artificial Intelligence 174 (2010) 1369–1406ilar problems have similar solutions; as a consequence, solutions for similar problems are a useful starting point for newproblem-solving. The second assumption is that the types of problems an agent encounters tend to recur; hence futureproblems are likely to be similar to current problems.Different case-based planners differ on how they store cases, how they adapt a solution to a new problem, whether theyuse one or more cases for building a new solution or not, etc. [58]. From a theoretical point of view, in the worst case,adapting an existing plan to solve a new problem is not more efficient than a complete regeneration of the plan [47]. More-over finding a good reuse candidate in a plan library may be already very expensive, because it leads to more computationalcosts than those that can be saved by reusing the candidate. In fact, the retrieval of a good plan from a library of plansrepresents a serious bottleneck for plan reuse in domain independent case-based planning systems. This happens becausethe problem of defining the best matching among the objects of two planning problems is NP-hard.In this paper we present some data structures and new matching functions that efficiently address the problem ofmatching planning instances, which is NP-hard in the general case. These functions lead to a new case-based plannercalled OAKplan (acronym of Object Assignment Kernel case-based planner), which is competitive with state of the art plangeneration systems when sufficiently similar reuse candidates can be chosen.Following the formalisation proposed by Liberatore [39], a planning case is a pair (cid:2)Π0, π0(cid:3), where Π0 is a planningproblem and π0 is a plan for it, while a plan library is a set of cases {(cid:2)Πi, πi(cid:3) | 1 (cid:2) i (cid:2) m}. Our approach is based on acompact graph representation which uses the initial and goal facts in order to define a detailed description of the topologyof the planning problem examined. On the basis of this graph representation we use ideas from different research areas. Inparticular a lot of work has been done in molecular biology to analyse efficiently chemical databases which typically containthousands of molecules encoded as graphs. Similarly to the rascal system [51], we use graph degree sequences [55] in orderto filter out unpromising planning cases and reduce the set Cds = {(cid:2)Πi, πi(cid:3)} of cases that have to be examined accuratelyup to a suitable number.1Following Nebel and Koehler’s formalisation of matching functions [47], we examine the problem of defining a matchbetween the objects of the current planning problem and those of the selected planning cases. Since an exact matchingevaluation is infeasible from a computational point of view even for a limited number of candidate cases [47], we developan approximate evaluation based on kernel functions [56] to define a match among the objects of the planning problemsconsidered. Our kernel functions are inspired by Fröhlich et al.’s work [19–21] on kernel functions for molecular structures,where a kernel function can be thought of as a special similarity measure that can be defined among arbitrarily structuredobjects, like vectors, strings, trees or graphs [35,65]. The computational attractiveness of kernel methods comes from thefact that they can be applied in high-dimensional feature spaces without suffering the high cost of explicitly computing themapped data [56].In contrast to other CBP approaches that define exact matching functions among the objects of Π0 and those of theplan library whose computation requires exponential time [29,34,47], our kernel functions can compute in polynomial timean approximate matching function for each element of the set Cds; this matching function can choose a subset of thecandidate plans efficiently for the successive plan evaluation phase. These plans are evaluated accurately through a simulatedexecution that determines the capacity of a plan πi to solve the current planning problem. This phase is performed byexecuting πi and evaluating the presence of inconsistencies corresponding to the unsupported preconditions of the actionsof πi ; in the same way the presence of unsupported goals is identified. The best plan is then adapted, if necessary, in orderto be applicable to the current initial state and solve the current goals. This phase is based on the lpg-adapt system [16]which has shown excellent performance in many domains. When the adaptation phase is concluded, a new planning casecorresponding to the current planning problem and its solution plan can be inserted into the library or can be discarded.OAKplan can efficiently retrieve planning cases from plan libraries with more than ten thousand elements, heuristicallychoose a suitable candidate, possibly the best one, and adapt it to provide a good quality solution plan similar to the oneretrieved from the case base. We hope that this work will be able to renew interest in the case-based planning approach.Current research in planning has been devoted primarily to generative planning since no effective retrieval functions wereavailable in the past. To the best of our knowledge this is the first case-based planner that performs an efficient domain in-dependent objects matching evaluation. We examine it in comparison with state of the art plan generation systems showingthat the case-based planning approach can be an effective alternative to plan generation when “sufficiently similar” reusecandidates can be chosen. This is a major improvement on previous approaches on CBP which can only handle small planlibraries (see Section 5) and can hardly be compared with plan generation systems.The paper is organised as follows. Section 2 introduces the essential notions required by the paper. In particular weexpose the notion of union of graphs which is fundamental for the definition of the graphs used by our matching functionsand we introduce the basic concepts of kernel functions. Section 3 presents the main phases of our case-based plannerexamining the different steps required by the Retrieval and Evaluation phases in detail. In Section 4 a detailed analysis ",
            {
                "entities": [
                    [
                        3749,
                        3777,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 305 (2022) 103682Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSensitive loss: Improving accuracy and fairness of face representations with discrimination-aware deep learningIgnacio Serna a,∗a School of Engineering, Universidad Autonoma de Madrid, Spainb Center for Humans & Machines, Max Planck Institute for Human Development, Berlin, Germany, Aythami Morales a, Julian Fierrez a, Nick Obradovich ba r t i c l e i n f oa b s t r a c tArticle history:Received 8 October 2020Received in revised form 27 January 2022Accepted 8 February 2022Available online 14 February 2022Keywords:Machine behaviorBiasFairnessDiscriminationMachine learningLearning representationsFaceBiometricsWe propose a discrimination-aware learning method to improve both the accuracy and fairness of biased face recognition algorithms. The most popular face recognition benchmarks assume a distribution of subjects without paying much attention to their demographic attributes. In this work, we perform a comprehensive discrimination-aware experimentation of deep learning-based face recognition. We also propose a notational framework for algorithmic discrimination with application to face biometrics. The experiments include three popular face recognition models and three public databases composed of 64,000 identities from different demographic groups characterized by sex and ethnicity. We experimentally show that learning processes based on the most used face databases have led to popular pre-trained deep face models that present evidence of strong algorithmic discrimination. Finally, we propose a discrimination-aware learning method, Sensitive Loss, based on the popular triplet loss function and a sensitive triplet generator. Our approach works as an add-on to pre-trained networks and is used to improve their performance in terms of average accuracy and fairness. The method shows results comparable to state-of-the-art de-biasing networks and represents a step forward to prevent discriminatory automatic systems.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionArtificial Intelligence (AI) is developed to meet human needs that can be represented in the form of objectives. To this end, the most popular machine learning algorithms are designed to minimize a loss function that defines the cost of wrong solutions over a pool of samples. This is a simple but very successful scheme that has enhanced the performance of AI in many fields, such as Computer Vision, Speech Technologies, and Natural Language Processing. But this optimization of specific computable objectives may not lead to the behavior one may expect or desire from AI. International agencies, academia, and industry are alerting policymakers and the public to the unforeseen effects and behaviors of AI agents, not initially considered during the design phases [1]. In this context, aspects such as trustworthiness and fairness should be included as learning objectives and not taken for granted. (See Fig. 1.)Machine vision in general and face recognition algorithms, in particular, are good examples of recent advances in AI [3–6]. The performance of automatic face recognition has been boosted during the last decade, achieving very competitive * Corresponding author.E-mail addresses: ignacio.serna@uam.es (I. Serna), aythami.morales@uam.es (A. Morales), julian.fierrez@uam.es (J. Fierrez), obradovich@mpib-berlin.mpg.de (N. Obradovich).https://doi.org/10.1016/j.artint.2022.1036820004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fI. Serna, A. Morales, J. Fierrez et al.Artificial Intelligence 305 (2022) 103682Fig. 1. The objective of the learning process is an abstraction of the expected behavior of an AI. There is usually no direct path between the machine expected behavior and the machine behavior, which is normally evaluated in terms of its utility. Learning objectives are usually determined by factors such as task, data, algorithms, and experimental protocols, losing sight of key aspects of the expected behavior such as fairness. Figure inspired by the standard model proposed in [2].accuracies in the most challenging scenarios [7]. These improvements have been made possible due to advances in machine learning (e.g., deep learning), powerful computation (e.g., GPUs), and larger databases (e.g., on a scale of millions of images). However, recognition accuracy is not the only aspect to be considered when designing biometric systems. There is currently a growing need to study AI behavior in order to better understand its impact on our society [1]. Face recognition systems are especially sensitive due to the personal information present in face images (e.g., identity, sex, ethnicity, and age). The number of published works pointing out the potential discriminatory effects in the results of face detection and recognition algorithms is large [8–17].In this environment, only a limited number of works analyze how biases affect the learning process of algorithms dealing with personal information [18,19]. There is a lack of understanding regarding how demographic information affects popular and widely used pre-trained AI models beyond their performance.On the other hand, the right to non-discrimination is deeply rooted in the normative framework that underlies various national and international regulations, and can be found, for example, in Article 7 of the Universal Declaration of Human Rights and Article 14 of the European Convention on Human Rights, among others. As evidence of these concerns, the European Parliament passed the General Data Protection Regulation (GDPR)1 in April 2018, a set of laws aimed at regulating the collection, storage, and use of personal information. According to paragraph 71 of GDPR, controllers of sensitive data processing, have to “implement appropriate technical and organizational measures” that “prevent, inter alia, discriminatory effects”.The aim of this work is to analyze face recognition models using a discrimination-aware perspective and to demonstrate that learning processes involving such a discrimination-aware perspective can be used to train more accurate and fairer algorithms. The main contributions of this work are:• A comprehensive analysis of the causes and effects of biased learning processes, including: (i) discrimination-aware performance analysis based on three public datasets, with 64K identities equally distributed across demographic groups; (ii) study of deep representations and the role of sensitive attributes such as sex and ethnicity; (iii) complete analysis of demographic diversity present in some of the most popular face databases, and analysis of new databases available to train models based on diversity.• Based on our analysis of the causes and effects of biased learning algorithms, we propose an efficient discrimination-aware learning method to mitigate bias in deep face recognition models: Sensitive Loss. The method is based on the inclusion of demographic information in the popular triplet loss representation learning. Sensitive Loss incorporates fairness as a learning objective in the training process of the algorithm. The method works as an add-on that is applied over pre-trained representations to improve their performance and fairness without requiring a complete re-training. We evaluated the method in three public databases, showing an improvement in both overall accuracy and fairness. Our results show how to incorporate discrimination-aware learning rules to significantly reduce bias in deep learning models.Preliminary work in this research line was presented in [20]. Key improvements here over [20] include: (i) in-depth anal-ysis of the state-of-the-art, including an extensive survey of face recognition databases; (ii) inclusion of two new datasets in 1 EU 2016/679 (General Data Protection Regulation). Available online at: https://gdpr-info .eu/.2\fI. Serna, A. Morales, J. Fierrez et al.Artificial Intelligence 305 (2022) 103682Fig. 2. Face recognition block diagrams. The screener is an algorithm that given two face images decides if they belong to the same person. The trainer is an algorithm that generates the best data representation for the screener.the experiments involving 40,000 new identities and more than 1M images; and (iii) a novel discrimination-aware learning method called Sensitive Loss.The rest of the paper is structured as follows: Section 2 summarizes the related work. Section 3 presents our general formulation of algorithmic discrimination. Section 4 presents the proposed discrimination-aware learning method. Section 5describes the evaluation procedure. Section 6 presents the experimental results. Finally, Section 7 summarizes the main conclusions.2. Related work2.1. Face recognition: methodsA face recognition algorithm, like other machine learning systems, can be divided into two different algorithms: screener and trainer. Both algorithms are used for different purposes. [21].∗The screener takes the characteristics of an individual and returns a prediction of that individual’s outcome, while the trainer produces the screener itself. In our case, the screener (see Fig. 2) is an algorithm that, given two face images, generates an output associated with the probability that they belong to the same person. This probability is obtained by comparing the two learned representations from a face model defined by the parameters w. These parameters are previously trained from a given dataset D (see Fig. 2). If properly trained, the output of the trainer would be a model with parameters w, capable of representing the input data (e.g., face images) in a highly discriminant feature space x.The most popular architecture used to mode",
            {
                "entities": [
                    [
                        3615,
                        3643,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 454–482www.elsevier.com/locate/artintRestricted gradient-descent algorithm for value-functionapproximation in reinforcement learningAndré da Motta Salles Barreto a,∗, Charles W. Anderson ba Programa de Engenharia Civil/COPPE, Universidade Federal do Rio de Janeiro, Rio de Janeiro, RJ, Brazilb Department of Computer Science, Colorado State University, Fort Collins, CO 80523, USAReceived 22 May 2006; received in revised form 22 August 2007; accepted 23 August 2007Available online 6 September 2007AbstractThis work presents the restricted gradient-descent (RGD) algorithm, a training method for local radial-basis function networksspecifically developed to be used in the context of reinforcement learning. The RGD algorithm can be seen as a way to extractrelevant features from the state space to feed a linear model computing an approximation of the value function. Its basic idea is torestrict the way the standard gradient-descent algorithm changes the hidden units of the approximator, which results in conservativemodifications that make the learning process less prone to divergence. The algorithm is also able to configure the topology of thenetwork, an important characteristic in the context of reinforcement learning, where the changing policy may result in differentrequirements on the approximator structure. Computational experiments are presented showing that the RGD algorithm consistentlygenerates better value-function approximations than the standard gradient-descent method, and that the latter is more susceptible todivergence. In the pole-balancing and Acrobot tasks, RGD combined with SARSA presents competitive results with other methodsfound in the literature, including evolutionary and recent reinforcement-learning algorithms.© 2007 Elsevier B.V. All rights reserved.Keywords: Reinforcement learning; Neuro-dynamic programming; Value-function approximation; Radial-basis-function networks1. IntroductionSutton and Barto [77] and Kaelbling et al. [37] describe reinforcement learning as a class of problems, rather thanas a set of techniques. In this paradigm, an agent must learn how to act through direct interaction with an environment.The only information available to the agent is a reinforcement signal providing evaluative feedback for the decisionsmade.This rather informal definition is sufficient to explain the increasing interest in the field from the artificial intelli-gence and machine learning communities. First of all, this framework is a crude but appealing model of what actuallyhappens in nature, and the analogy with animal behavior is almost irresistible [64,76]. From an engineering perspec-tive, the reinforcement-learning paradigm is also tempting, since it transfers to the learning system the burden offiguring out how to accomplish a task. This way, instead of providing a set of examples with the desired behavior, as* Corresponding author.E-mail addresses: andremsb@lncc.br (A. da Motta Salles Barreto), anderson@cs.colostate.edu (C.W. Anderson).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.08.001\fA. da Motta Salles Barreto, C.W. Anderson / Artificial Intelligence 172 (2008) 454–482455in supervised learning, the designer is left with the much simpler task of representing a problem in terms of rewardand punishment signals only. If, for example, one wanted to have a mobile robot travel from one point to another, itcould be done by simply giving the robot a reward when the goal was reached.In order for the above scenario to be true, however, several obstacles other than those in the robot’s trajectorymust be overcome. One of the major difficulties arises from the combination of reinforcement learning and functionapproximation. If one wants to solve real-world reinforcement learning tasks—where the number of possible statesof the system is usually too large to allow an exhaustive exploration—it is necessary to provide the agent with theability to generalize. Nevertheless, as is now well known (though not completely understood), the combination ofreinforcement learning algorithms with function approximators can easily become unstable, and finding a feasibleway to merge both paradigms is today an active area of research in machine learning.This paper presents an attempt in this direction, namely a training method for local radial-basis function networksespecially designed to be used in the context of reinforcement learning. The restricted gradient-descent (RGD) algo-rithm is essentially a modified version of the standard gradient-descent method, and as such it inherits both its qualitiesand drawbacks. However, the restrictions imposed by RGD on the application of gradient-descent’s delta rule make itless prone to divergence. In the RGD algorithm the center of the radial functions are always moved toward the currentstate, which tends to confine them to the convex-hull formed by the training data. Also, the widths of the radial-basisfunctions are only allowed to shrink, and thus they can not possibly diverge to infinity. Obviously, these restrictionson the delta rule limit the trajectory of the approximator’s parameter vector in the parameter space. This lost of flexi-bility is compensated by the on-line allocation of new hidden units, which results in a monotonically increasing of theapproximation granularity.This work is organized as follows. Section 2 presents a brief review of reinforcement learning, focusing on methodsthat rely on the concept of a value function to address this problem. As mentioned, the stability of such methods canbe affected by the use of function approximators. This issue is discussed in more detail in Section 3. One way toalleviate the instability caused by the use of approximators is to adopt linear models operating on features extractedfrom the original state space. Section 4 discusses the concept of “features” used in this paper, as well as a way toselect them using local radial-basis functions. Section 5 presents the RGD algorithm, which can be seen as a strategyto extract relevant features from the state space. This algorithm is applied in Section 6 to a series of computationalexperiments. Particularly, the performance of RGD is compared to that of the standard gradient-descent method andto several traditional reinforcement-learning algorithms using other techniques to approximate the value function.Section 7 presents an overall analysis of the experiments and a hypothesis explaining the stable behavior of therestricted gradient-descent algorithm. Finally, in Section 8 the main conclusions about this research are presented, andsome possible directions for future work are discussed.2. Reinforcement learningThe goal of the agent in reinforcement learning is to find a policy π —a mapping from states to actions—thatmaximizes the expected return. The return Rt is the total reward the agent receives in the long run from time t on:Rt = rt+1 + γ rt+2 + γ 2rt+3 + · · · =∞(cid:2)i=0γ irt+i+1,where γ ∈ [0, 1] is the discount factor. This parameter determines the relative importance of the individual rewards,depending on how far in the future they are.The rewards r ∈ (cid:5) are given by the environment to the agent each time it performs an action. Usually, this inter-action happens in discrete steps: at each time step t, the agent selects an action a ∈ A(st ) as a function of the currentstate st ∈ S. The sets S and A(st ) are part of the environment and represent the possible states of the system and theavailable actions in each state st . As a response to the action a, the agent receives from the environment a rewardrt+1 and a new state st+1. This loop is repeated indefinitely or until the agent reaches a terminal state. The interactionbetween agent and environment can be formalized as a Markov decision process [10,14,54].One way to address the reinforcement-learning problem is to search for a good solution in the policy space directly.This could be done, for example, by parametrizing π and then have an evolutionary algorithm search for good policies[35,88]. Another approach is to compute an approximation of the gradient of the average reward with respect to theparametrized policy, which can be used to perform gradient ascent [7,8,73].\f456A. da Motta Salles Barreto, C.W. Anderson / Artificial Intelligence 172 (2008) 454–482Another way to deal with the reinforcement learning problem is to use methods derived from dynamic program-ming [9,14,54]. One advantage of this approach is the fact that dynamic programming has been studied for a longtime, and is now supported by a strong and well understood theoretical basis. Central to the dynamic programmingapproach is the concept of a value function. The action-value function of a given policy π associates each state–actionpair (s, a) with the expected return when performing action a in state s and following π thereafter:Qπ (s, a) ≡ Eπ {Rt | st = s, at = a},where Eπ { } denotes the expected value when following policy π . Since the notation above is widely adopted, theaction-value function is usually referred to as the Q-function. Once the Q-function of a particular policy πk is known,we can derive a new policy, πk+1, which is greedy with respect to Qπk (s, a):πk+1(s) = arg maxa∈A(s)Qπk (s, a).(1)The policy πk+1 is guaranteed to be at least as good as (if not better than) the policy πk. This is the fundamentalidea of the reinforcement learning algorithms based on dynamic programming: given an initial arbitrary policy π0,compute its value function Qπ0 (s, a) and then generate a better policy π1 which is greedy with respect to this function.The next step is to compute Qπ1 (s, a), use it to generate a new policy π2, and so on. Under certain assumptions, thesuccessive alternation of these two steps—policy evaluation and policy improvement—can be shown to converge tothe optimal policy π ∗, which maximizes the expected return on every state.Of course, the above process ",
            {
                "entities": [
                    [
                        3117,
                        3145,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 163 (2005) 1–45www.elsevier.com/locate/artintKnowledge transformation and fusion indiagnostic systems ✩Mingsheng Ying a,ba State Key Laboratory of Intelligent Technology and Systems,Department of Computer Science and Technology, Tsinghua University, Beijing 100084, Chinab Laboratory of Intelligent Information Processing, Department of Computer Science and Engineering,Fudan University, Shanghai 230031, ChinaReceived 1 August 2003; accepted 3 October 2004Available online 8 December 2004AbstractDiagnostic systems depend on knowledge bases specifying the causal, structural or functionalinteractions among components of the diagnosed objects. A diagnostic specification in a diagnos-tic system is a semantic interpretation of a knowledge base. We introduce the notion of diagnosticspecification morphism and some operations of diagnostic specifications that can be used to modelknowledge transformation and fusion, respectively. The relation between diagnostic methods in thesource system and the target system of a specification morphism is examined. Also, representationsof diagnostic methods in a composed system modelled by operations of specifications are given interms of the corresponding diagnostic methods in its component systems. 2004 Elsevier B.V. All rights reserved.Keywords: Diagnostic system; Diagnostic specification; Notion of diagnosis; Knowledge transformation;Knowledge fusion; Specification morphism; Operations of specification✩ This work was partly supported by the National Foundation of Natural Sciences of China (Grant No:60496321, 60321002, 60273003) and the Key Grant Project of Chinese Ministry of Education (Grant No: 10403).E-mail address: yingmsh@tsinghua.edu.cn (M. Ying).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.10.008\f2M. Ying / Artificial Intelligence 163 (2005) 1–451. IntroductionTo diagnose is to determine the nature of a trouble (for example, a disease) from ob-servations of signs and symptoms, and it is an important human ability, with importantapplications in medicine, industrial processes and computer software, among others. Dueto its importance, diagnostic reasoning has long been an active research area of ArtificialIntelligence. Throughout the 1970’s, several expert systems aimed in whole or in part at di-agnosis were developed (e.g., MYCIN [21]), exploring different knowledge representationand reasoning techniques, but the field lacked unified underlying principles.One of the first formal theories of diagnosis is Reggia, Nau and Wang’s set-coveringmodel for diagnostic expert systems [18], where causal knowledge of abnormality isrepresented by binary relations. Diagnosis then reduces to determining whether actuallyobserved findings can be inferred from observed defects and the causal relations.In 1987, a logical theory of diagnosis was proposed by Reiter [19], and it is usuallycalled the theory of consistency-based diagnosis. This theory was largely extended by deKleer et al. [10] in 1992. Their main idea is to establish a model of the normal structureand behavior of the diagnosed objects. Diagnosis is then modelled as finding a discrepancybetween the normal behavior predicted from the model and the actually observed abnormalbehavior. The discrepancy in this approach is formalized as logical inconsistency.Another logical theory of diagnosis, called abductive diagnosis, was developed by Coxand Pietrzykowski [9], Console et al. [3,7,8] and others around 1990. They used logi-cal implications from causes to effects to represent causal knowledge, and a diagnosis isthen formalized as reasoning from effects (observed findings) to causes (abnormalities orfaults).Lucas [13] recently introduced a framework allowing these and other formal theories(for example, heuristic classification [6], goal-directed diagnosis [20] and explicit means-end model [12]), to be compared in a unified way. It consists mainly of two parts: (1)diagnostic specification, a mapping from defects to observable findings, specifying thecausal relation from defects to findings; and (2) notion of diagnosis, a mapping from ob-served findings to defects, modelling how to get a diagnostic solution from the observedfindings. This is a high-level formalism of diagnosis, and various formal theories of diag-nosis can be expressed in it, including consistency-based diagnosis, abductive diagnosisand heuristic classification. In this framework a diagnostic specification need not corre-spond to a unique notion of diagnosis. Different strategies of diagnosis can be introducedaccording to varied philosophical considerations or practical purposes. In [13], given a di-agnostic specification, Lucas proposed a hierarchy consisting of six notions of diagnosisinduced by it, namely, most general subset diagnosis, most general superset diagnosis,most general intersection diagnosis, most specific subset diagnosis, most specific supersetdiagnosis as well as most specific intersection diagnosis. The six notions of diagnosis forma flexible spectrum in which one notion may refine another. Thus, they provide the userwith an opportunity to choose a diagnosis method suited to his own criterion.A diagnostic specification in Lucas’s formalism is intended to serve as a semantic in-terpretation of the knowledge base in a diagnostic system. But the cost of gathering andprocessing knowledge is often very high. Such a situation makes effective reuse of knowl-edge essential. One of the mechanisms that support reuse of knowledge is knowledge\fM. Ying / Artificial Intelligence 163 (2005) 1–453transformation which maps various different knowledge bases to each other, enabling acommon interfaces between different domains and application systems. Many differentformal representations of knowledge transformation have already been proposed; for ex-ample, conditional rules [4], function [5], logical relations [11], and tables and procedures[22]. Another important mechanism for effective use and reuse of knowledge is the fusionand merging of different knowledge resources, often represented in terms of operationson knowledge bases. Examples include Stanford’s ontology algebra [24] and Barwise andSeligman’s theory of information flow [1].This leads us to explore the possibility of reusing knowledge in diagnostic systems.In this paper, we consider the following two problems concerning change, evolution ofknowledge for diagnosis as well as gathering and combining diagnostic knowledge frommultiple sources: (1) if the knowledge base in one diagnostic system is transformed intothe knowledge base in another, then to what extent can the diagnostic method adoptedin the first system be reused in the second? and (2) if the knowledge bases in a set ofdiagnostic systems are fused or merged to construct a larger one, how we can producea suitable diagnostic method for the composed system from the diagnostic methods ofits components? In order to solve the first problem, the notion of diagnostic specificationmorphism is introduced. As a solution to the second problem, some algebraic operations ofdiagnostic specifications are proposed to model the construction of a complex diagnosticsystem composed from simpler ones.This paper is organized as follows: in Section 2, we recall some basic notions from [13].We also present some new results in this section. First, it is shown that some global proper-ties such as monotonicity and interaction freeness of partial diagnostic specifications, canbe extended to the whole specifications generated by them. Second, for the six diagnosticnotions in the Lucas refinement diagnosis spectrum, some properties of the Galois con-nection style are observed. Third, some necessary and sufficient conditions under whichthe six diagnostic notions respects the given diagnostic specification are found. Fourth, weshow that certain relations between diagnostic specifications are preserved and some globalproperties of diagnostic specifications are inherited by the six diagnostic notions inducedfrom them. These results are useful in the analysis and comparison of various notions ofdiagnosis. In Section 3, the notion of diagnostic specification morphism is introduced formodelling transformations of knowledge bases in different diagnostic systems. It is shownthat the relation that a notion of diagnosis respects a diagnostic specification can be pre-served by some morphisms. Also, it is demonstrated that certain global properties of thesource diagnostic specification may be transferred by a specification morphism to the tar-get specification. Thus, some diagnosis methods depending heavily on these properties canbe safely reused after knowledge transformation. We prove that some partial specificationmorphism can be smoothly extended to a specification morphism. This gives a conve-nient technique for constructing specification morphisms because in many applicationsdiagnostic knowledge bases are often specified only partially. The relationship betweenthe diagnostic strategies in the source diagnostic system and the target system of a mor-phism is thoroughly analyzed. The obtained results provide us with a logical support forknowledge reuse in diagnostic systems. Section 4 is devoted to examining carefully variousoperations of diagnostic specifications. These operations aim at describing different waysto fuse and merge diagnostic knowledge bases. They include optimistic and pessimistic\f4M. Ying / Artificial Intelligence 163 (2005) 1–45fusions, optimistic merging and pessimistic merging, sum, and direct product. For each ofthem, we examine how the global properties of component systems are preserved by thecomposed system. We also clarify the relationship between the diagnostic methods in thecomponent systems and those in the composed system. These results enable us to know towhat an extent the diagnostic strategies used in a diagnostic system can be reused when itis embedded into a larger system.To conclude this",
            {
                "entities": [
                    [
                        1809,
                        1837,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 25–48Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintNon-Markovian control in the Situation Calculus ✩Alfredo GabaldonCenter for Artificial Intelligence, New University of Lisbon, Lisbon, Portugala r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Reasoning about actionsSituation CalculusIn reasoning about actions,it is commonly assumed that the dynamics of domainssatisfies the Markov Property: the executability conditions and the effects of all actionsare fully determined by the present state of the system. This is true in particular inIn this paper, we generalizeReiter’s Basic Action Theories in the Situation Calculus.Basic Action Theories by removing the Markov property restriction, making it possibleto directly axiomatize actions whose effects and executability conditions may depend onpast and even alternative, hypothetical situations. We then generalize Reiter’s regressionoperator, which is the main computational mechanism used for reasoning with Basic ActionTheories, so that it can be used with non-Markovian theories.© 2010 Elsevier B.V. All rights reserved.Since the 1960’s when John McCarthy’s papers (in particular the 1969 paper with Pat Hayes) appeared introducing theSituation Calculus, researchers have been studying and working on this language for reasoning about dynamic domains. TheSituation Calculus, one of John’s many great inventions, is the topic of this paper and I am delighted to have this opportunityto make a contribution to a special issue in John’s honor.1. IntroductionAn assumption commonly made in formalisms for reasoning about the effects of actions is the so called Markov property:the executability of an action and its effects are entirely determined by the current state or situation. In particular, Reiter’sBasic Action Theories [2], a Situation Calculus [3,4] based axiomatization, define the value of a fluent after the executionof an action in terms of a formula that can only talk about the situation in which the action would be executed. Thepreconditions of an action are specified by formulas with the same restriction. In this paper we generalize Basic ActionTheories by removing this restriction. The generalized theories will allow the executability conditions and the effects of anaction to depend not only on what holds when the action is to occur, but also on whether certain conditions were satisfiedat different points in the past and even alternative hypothetical evolutions of the system.As an example, imagine a robot that works in a biological research facility with different safety-level areas. The dynamicsis such that a material will be considered contaminated after the robot touches it if the robot has been to a low safety areaor has directly been in contact with a hazardous material, and has not been to the disinfection station since then. So theeffect of touching the material depends on the history of robot activities. We could also imagine that the robot cannotexecute the action open(Entrance, Lab1) if temp(Lab1) > 30 was ever true since the last time closed(Entrance, Lab1) occurred.The latter is an example of an action with non-Markovian preconditions.In simple scenarios, it is not difficult to extend a theory to preserve the necessary history by means of new statevariables, especially when the domain is finite. But in complex domains it may not be obvious how to do it, and the✩A preliminary abstract of this paper appeared in Proc. of AAAI’02 (A. Gabaldon (2002) [1]).E-mail address: ag@di.fct.unl.pt.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.012\f26A. Gabaldon / Artificial Intelligence 175 (2011) 25–48resulting theory may be substantially more complex, with a larger number of state variables and corresponding axiomsdescribing their dynamics.Our goal in this paper is to generalize Reiter’s Basic Action Theories [5,2] by removing the Markov property requirementand generalize the main reasoning mechanism used with these theories, namely the regression operator R, so that itcan be used with non-Markovian theories, and applied to Situation Calculus formulas that refer to the past, to alternativeevolutions, and to definite future situations.This generalized regression operator is not only useful in cases where the action theory is non-Markovian. Even if thebackground theory is Markovian, the operator is useful for answering queries that refer to past situations through quan-tification and the subsequence relation (cid:2). This is not possible with Reiter’s original regression operator. In [2, Section 4.8],Reiter presents a few specialized procedures for evaluating certain historical queries with respect to a database log (a se-quence of ground action terms) and a Markovian action theory. Those queries are a very small subset of the class of queriesthat the generalized regression operator we present here can handle.Our work is relevant to a variety of research problems that involve the formalization of dynamic properties:(1) Some work in database theory has been concerned with the semantics of dynamic integrity constraints [6,7]. Theseconstraints are typically expressed in Past Linear Temporal Logic, a logic with temporal connectives Previous, Sometimein the past, Always in the past, and Since. In a formalization of a database system in the Situation Calculus, suchtemporal connectives amount to references to past situations, and the constraints to restrictions on when a sequence ofactions can be considered a “legal” database system evolution. These past temporal logic connectives have an encodingas formulas in the non-Markovian Situation Calculus and hence the latter can be used as a logical framework forthe study, specification and modeling of databases with dynamic integrity constraints. The advantage of carrying outsuch work in this framework is that all the different aspects of the problem, i.e. database dynamics, transactions andconstraints, can be captured within the same Situation Calculus framework.(2) Also in the area of databases, more specifically in work on database transaction systems, the rollback operation, whichreverts a database back to its original state after a long transaction fails or is canceled, clearly has a non-Markovianflavor: its effects depend not on what is true in the state it is executed, but on the state right before the transactionbeing reversed started. Indeed, Kiringa [8] and Kiringa and Gabaldon [9,10] present logical specifications of databasetransactions in the non-Markovian Situation Calculus.(3) In planning, domain dependent knowledge for search control has been used with great success [11,12]. Bacchus andKabanza’s forward-chaining planning system, TLPlan, uses search control knowledge in the form of temporal logic for-mulas. The same approach has been applied in the Situation Calculus with some simple planners written in Golog [2].The latter planners perform a forward search, eliminating partial plans if they lead to “bad situations.” Search controlknowledge is encoded through a predicate badSituation(s) whose definition is restricted to properties of the currentsituation s. The generalization of the action theories and the regression operator we shall develop here allows the def-inition of this predicate to refer to any situation that precedes s and bounded future situations. As we mention above,past temporal logic expressions can be encoded as Situation Calculus formulas suitable for regression with our gen-eralized operator and be used in the definition of badSituation(s). In other words, the generalized regression operatorallows one to use temporal search control knowledge of a similar form and expressive power as used in TLPlan directlyin Golog planners with the badSituation(s) predicate. Search control knowledge in this context is further explored inour recent work [13,14].(4) Another area where non-Markovian features arise naturally is in specifying reward functions in decision theoretic plan-ning. There, agents are often rewarded based on their long-term behavior rather than just on the current state of affairs.Bacchus, Boutilier and Grove [15,16] have developed techniques for solving such non-Markovian Decision Processes.More recent work on non-Markovian rewards appears in [17,18].(5) Finally, some time ago John McCarthy [19] described a programming language called “Elephant 2000” which, amongother features, “does not forget.” This is a language that would allow one to write programs that explicitly and directlyrefer to past states of the programming environment. The generalized regression operator we present here could formthe foundation for a non-forgetting Golog [20]. Such a dialect of Golog would allow test conditions that refer to thepast, for instance, as in the statement if (P since Q ) then δ.This paper is organized as follows: we start in Section 2 with an overview of the Situation Calculus and Reiter’s BasicAction Theories. In Section 3 we introduce a class of Situation Calculus formulas that can refer to past and finite futuresituations and can be regressed, and based on this, our generalization of action theories for non-Markovian control. InSection 4 we present a regression operator that works for those formulas and theories and prove its correctness, followedby a Prolog implementation in Section 5 and our concluding remarks in Section 6.2. Overview of the Situation Calculus and Basic Action TheoriesThe Situation Calculus [3,4] is a dialect of classical logic for representing and reasoning about dynamically changingworlds. A theory in this language consists of a collection of axioms describing how the world changes when actions occur.Accordingly, the ontology of the Situation Calculus includes three main ingredients: actions, situations, and fluents. Situ-\fA. Gabaldon / Artificial Intelligence 175 (2011) 25–4827ations refer to possible evolutions",
            {
                "entities": [
                    [
                        3694,
                        3722,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 72–102Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOrdered completion for logic programs with aggregatesVernon Asuncion a, Yin Chen b, Yan Zhang a, Yi Zhou a,∗a Artificial Intelligence Research Group (AIRG), School of Computing, Engineering and Mathematics, University of Western Sydney, Australiab Department of Computer Science, South China Normal University, Guangzhou, Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 7 August 2013Received in revised form 16 March 2015Accepted 21 March 2015Available online 25 March 2015Keywords:Knowledge representation and reasoningAnswer Set ProgrammingAggregatesFirst-order logicLogic programmingWe consider the problem of translating first-order answer set programs with aggregates into first-order sentences with the same type of aggregates. In particular, we show that, on finite structures, normal logic programs with convex aggregates, which cover both monotone and antimonotone aggregates as well as the aggregates appearing in most benchmark programs, can always be captured in first-order logic with the same type of aggregates by introducing auxiliary predicates. More precisely, we prove that every finite stable model of a normal program with convex aggregates is corresponding to a classical model of its enhanced ordered completion. This translation then suggests an alternative way for computing the stable models of such kind of programs. We report some experimental results, which demonstrate that our solver GROCv2 is comparable to the state-of-the-art answer set solvers. We further show that convex aggregates form a maximal class for this purpose. That is, we can always construct a normal logic program under any given non-convex aggregate context and prove that it can never be translated into first-order sentences with the same type of aggregates unless NP = coNP.© 2015 Elsevier B.V. All rights reserved.1. IntroductionIn this paper, we consider to translate first-order Answer Set Programming (ASP), a predominant declarative program-ming paradigm in the area of knowledge representation and logic programming [3,20,24,25], into first-order logic. Work in this direction is not only of theoretical interests but also of practical relevances as it suggests an alternative way to implement ASP.Recently, Asuncion et al. [2] proposed a notion of ordered completion (a first-order sentence with some extra predicates) for first-order normal logic programs, and showed that the stable models of a normal program are exactly corresponding to the classical models of its ordered completion on finite structures. Interestingly, there is no such translation on arbi-trary structures nor prohibiting extra predicates. Based on this translation, they developed a new ASP solver, which first translates a program to its ordered completion, then grounds this first-order sentence, and finally calls an SMT solver. This is significantly different from previous ASP solvers, which ground the first-order programs directly. A first implementation shows that this new solver is promising as it performs relatively well for the Hamiltonian Circuit program, particularly on big instances [2].However, their work cannot handle aggregates, a very important building block for modern Answer Set Programming. The reason why aggregates are crucial in answer set solving is twofold. Firstly, they enhance the expressive power of ASP, and often they can simplify the representation task. For many applications, one can write a simpler and more elegant logic * Corresponding author.E-mail address: y.zhou@uws.edu.au (Y. Zhou).http://dx.doi.org/10.1016/j.artint.2015.03.0070004-3702/© 2015 Elsevier B.V. All rights reserved.\fV. Asuncion et al. / Artificial Intelligence 224 (2015) 72–10273program by using aggregates, for instance, the job scheduling program [28]. Secondly and more importantly, aggregates can improve the efficiency of ASP solving [19]. Normally, the program using aggregates can be solved much faster [12].In this paper, we consider the problem of extending ordered completion for programs with aggregates. This is a challeng-ing task as some programs with aggregates are expressive enough to capture disjunctive logic programming (see in [16]), thus can never be captured in first-order logic with the same type of aggregates providing some general assumptions in the computational complexity theory (see Proposition 6 in [2]).Hence, an important task is to draw a boundary between the normal programs with aggregates that can be captured in first-order logic with the same type of aggregates and those programs that cannot. For this purpose, we extend the notion of convex constraints proposed by Liu and Truszczy ´nski [23] into first-order convex aggregates. We show that the class of convex aggregates is exactly the boundary we need in the sense that• First-order normal logic programs with convex aggregates can always be captured in first-order logic with the same type of aggregates on finite structures. More precisely, we extend the notion of ordered completion for first-order normal logic programs with convex aggregates, and show that every stable model of such a program is corresponding to a classical model of its enhanced ordered completion.• Given any non-convex aggregate context, there exists a normal program under this context such that it can never be translated into first-order sentences with the same type of aggregates unless NP = coNP.In fact, the class of convex aggregates is expressive enough to capture both monotone and antimonotone aggregates [23] as well as the aggregates appearing in most benchmark programs [5]. Therefore, based on our theoretical results, we are able to develop an alternative ASP solver for first-order normal programs with convex aggregates. Following this idea, we implement a new ASP solver GROCv2. Our experimental results demonstrate that GROCv2 is comparable to the state-of-the-art ASP solvers.The paper is organized as follows. Section 2 reviews basic concepts and notations that we will need through out the paper. Section 3 presents the ordered completion for logic programs with aggregates, and proves the main theorems. Sec-tion 4 introduces the implementation of the ASP solver GROCv2, and reports some experimental results. Finally, Sections 5and 6 discuss some related work and draw our conclusions respectively. We leave the very long proofs of some theorems to Appendix A for a more fluent reading.2. PreliminariesWe consider a second-order language without functions but with equality =. A signature contains a finite set of constants and a finite set of predicates. A term is either a variable or a constant. A standard atom is an expression P (t), where P is a predicate and t is a tuple of terms which matches the arity of P . An equality atom is an expression t1 = t2, where t1 and t2are terms.be two multisets. We denote by M ⊆ MA multiset (also called a bag) is a pair M = (Ms, M f ), where Ms is a set and M fis a function, called the multiplicity function, from Ms to N, i.e., the set of positive integers {1, 2, 3, . . .}. A multiset (Ms, M f ) is finite if Ms is finite. Let M and if M(cid:3) ⊆ M. For convenience, a multiset M, where Ms = {a1, . . . , an} and M f (ai) = ci (1 ≤ i ≤ n), is also denoted as M ⊆ Mand M} }. The order of the elements is irrelevant. For example, { {a, a, b, c} } is the multiset M, { {a1, . . . , a1, . . . , an, . . . , an, . . . , ai, . . . , ai(cid:5)(cid:3)(cid:4)(cid:2)(cid:5)(cid:5)(cid:2)c1(cid:3)s and for all elements a ∈ Ms, M f (a) ≤ M(cid:3)f (a). We write M = Mif Ms ⊆ M(cid:3)(cid:4)cn(cid:3)(cid:4)ci(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)where Ms = {a, b, c} and M f (a) = 2, M f (b) = M f (c) = 1.2.1. The syntax of aggregatesAggregate is a crucial auxiliary building block for answer set programming [12,13,16,19,22,23,28]. We first define the syntax of aggregates in the first-order case. We assume a set of aggregate symbols AG and a (fixed) set of comparison operators on numbers CO = {<, ≤, =, (cid:7)=, ≥, >}.Definition 1. An aggregate atom δ is an expression of the formop(cid:9)v : ∃wQ 1(y1) ∧ · · · ∧ Q s(ys) ∧ ¬R1(z1) ∧ · · · ∧ ¬Rt(zt)(cid:12) (cid:13) t,1where• op ∈ AG is an aggregate symbol,• Q i(yi) (1 ≤ i ≤ s) and R j(z j) (1 ≤ j ≤ t) are standard atoms or equality atoms. In addition,Q 1(y1) ∧ · · · ∧ Q s(ys) ∧ ¬R1(z1) ∧ · · · ∧ ¬Rt(zt)is called the body of δ, denoted by Bd(δ),1 Here, w could be empty. In this case, (1) is simply written as op(cid:9)v : Bd(δ)(cid:12) (cid:13) t.(1)(2)\f74V. Asuncion et al. / Artificial Intelligence 224 (2015) 72–102• v and w are tuples of variables mentioned in (2), and v ∩ w = ∅,• (cid:13)∈ CO is a comparison operator on numbers,• t is a term, and we assume that variables occurring in t are not in v ∪ w.For convenience, we use P s(δ) and N g(δ) to denote the sets {Q 1(y1), . . . , Q s(ys)} and {R1(z1), . . . , Rt (zt)} respectively. Given an aggregate atom δ of the form (1), a variable in δ is a free variable if it is not a variable in v ∪ w.Example 1. Let sum and card be aggregate symbols in AG. The following are two aggregate atoms:card(cid:9)x : P (x)(cid:12) = 2,sum(cid:9)x : P (x)(cid:12) ≤ 5.Intuitively, they are equivalent to the weight constraints2{p(X)}2,{p(X) = X}5in smodels [29], and the aggregate atoms#count{ X : p(X)} = 2,#sum{ X : p(X)} ≤ 5in DLV [14] and ASP-Core-2.2 (cid:2)An atom is either an equality atom, or a standard atom, or an aggregate atom. A first-order formula with aggregates (or formula for short) is built from atoms and logical connectives as usual. A formula without aggregate atom is called a classicalformula in this paper. The free variable of a formula is defined as usual. We use free(φ) to denote the set of free variables of a formula φ.2.2. The semantics for first-order logic with aggregatesAs aggregate is an extra building block, we need to extend the standard semantics for classical first-orde",
            {
                "entities": [
                    [
                        3686,
                        3714,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 222 (2015) 157–181Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlaying with knowledge: A virtual player for “Who Wants to Be a Millionaire?” that leverages question answering techniquesPiero Molino, Pasquale LopsPierpaolo Basile∗, Giovanni Semeraro, Marco de Gemmis∗, Department of Computer Science, University of Bari Aldo Moro, Via E. Orabona 4, I-70125 Bari, Italya r t i c l e i n f oa b s t r a c tArticle history:Received 5 November 2013Received in revised form 29 January 2015Accepted 6 February 2015Available online 12 February 2015Keywords:Language gameQuestion answeringNatural language processingArtificial intelligenceDecision makingThis paper describes the techniques used to build a virtual player for the popular TV game “Who Wants to Be a Millionaire?”. The player must answer a series of multiple-choice questions posed in natural language by selecting the correct answer among four different choices. The architecture of the virtual player consists of 1) a Question Answering(QA) module, which leverages Wikipedia and DBpedia datasources to retrieve the most relevant passages of text useful to identify the correct answer to a question, 2) an Answer Scoring (AS) module, which assigns a score to each candidate answer according to different criteria based on the passages of text retrieved by the Question Answering module, and 3) a Decision Making (DM) module, which chooses the strategy for playing the game according to specific rules as well as to the scores assigned to the candidate answers.We have evaluated both the accuracy of the virtual player to correctly answer to questions of the game, and its ability to play real games in order to earn money. The experiments have been carried out on questions coming from the official Italian and English boardgames. The average accuracy of the virtual player for Italian is 79.64%, which is significantly better than the performance of human players, which is equal to 51.33%. The average accuracy of the virtual player for English is 76.41%. The comparison with human players is not carried out for English since, playing successfully the game heavily depends on the players’ knowledge about popular culture, and in this experiment we have only involved a sample of Italian players. As regards the ability to play real games, which involves the definition of a proper strategy for the usage of lifelines in order to decide whether to answer to a question even in a condition of uncertainty or to retire from the game by taking the earned money, the virtual player earns e 114,531 on average for Italian, and e 88,878 for English, which exceeds the average amount earned by the human players to a greater extent (e 5926 for Italian).© 2015 Elsevier B.V. All rights reserved.* Corresponding authors.marco.degemmis@uniba.it (M. de Gemmis), pierpaolo.basile@uniba.it (P. Basile).E-mail addresses: piero.molino@uniba.it (P. Molino), pasquale.lops@uniba.it (P. Lops), giovanni.semeraro@uniba.it (G. Semeraro), http://dx.doi.org/10.1016/j.artint.2015.02.0030004-3702/© 2015 Elsevier B.V. All rights reserved.\f158P. Molino et al. / Artificial Intelligence 222 (2015) 157–1811. IntroductionThe work on intelligent computer games has a long history and has been one of the most successful and visible results of Artificial Intelligence research [34]. Indeed, today artificial systems are able to compete and sometimes challenge human players in several complex games. Most of these games are closed world ones, meaning that they have a finite number of possible choices, which allows the researchers to solve them in a formal way, even though they are hard to play due to the exponential dimensions of the search spaces. A more challenging type of games is represented by open world games, such as sport games or crosswords: they are less structured and, moreover, both the states of the game and the actions of the player cannot be easily enumerated, making the search through the space of possible solutions practically unfeasible. One of the most recent results in this field is the success of Watson, the open-domain question answering system built by IBM Research, which in February 2011 beat the two highest ranked players of the quiz show Jeopardy! [17,18].We are particularly interested to games related to human language. They are classified in word games, in which word meanings are not important, and language games, in which word meanings play an important role [27]. Language games generally require a wide linguistic and common sense knowledge. “Who Wants to Be a Millionaire?” (WWBM) is a perfect example of a language game in which the player provides an answer to a question posed in natural language by selecting the correct answer out of four possible ones. Even though the number of possible answers is limited to four, being able to successfully play this game heavily depends on the player’s knowledge, her understanding of the questions and her ability to balance the confidence in the answer against the risk taken in answering.This article describes the architecture of a Virtual Player for the WWBM game, which leverages Question Answering (QA) techniques and both Wikipedia and DBpedia open knowledge sources in order to incorporate the knowledge useful for playing the game. A preliminary work that describes the architecture of the virtual player is presented in [37]. The current work extends the previous work along the following directions: the use of DBpedia; the decision making strategy integrated to manage the “lifelines” characterizing the game; the possibility to retire from the game; the use of machine learning techniques to improve the process of scoring the candidate answers to a question. Extended related work about question answering, answer validation and language games are also provided, along with more extensive experiments on both the Italian and the English versions of the game.Motivated by the challenge to develop an effective virtual player for the WWBM game, in this paper we address two issues, one related to the more general topic of designing effective QA systems, while the other concerns specific aspects of the game. Hence, we investigate the following research questions:• RQ1. To what extent can a QA system be designed in a language-independent way, by preserving its effectiveness?We cope with this question by proposing a general architecture of a QA and Answer Scoring (AS) framework which exploits resources or algorithms specifically designed for a given language exclusively for basic NLP operations, such as part-of-speech tagging or stemming. In order to assess the effectiveness of the framework for at least two different languages, we performed experiments on English and Italian.• RQ2. Can Wikipedia and DBpedia serve as effective knowledge bases for answering WWBM game questions?We address this question by developing a virtual player based on the proposed QA framework, which leverages Wikipedia and DBpedia open knowledge sources to find the correct answers. Besides the QA framework, the virtual player adopts a decision making strategy to play the game with all its rules, i.e. usage of “lifelines”, answering in a condition of uncertainty, retiring from the game by taking the earned money. Experiments are performed to compare the accuracy of the virtual player against that of human players.The paper is organized as follows: Section 2 describes the rules of the game, while related work in the areas of language games, QA and AS are presented in Section 3. The architecture of the virtual player, the details of the QA and AS modules, and the decision making strategy adopted to play the game are provided in Sections 4–7. Section 8 reports the results of an extensive evaluation performed on Italian and English versions of the game. Finally, conclusions are reported in Section 9.2. Rules of the gameWWBM is a language game, broadcast by many TV channels in several countries, in which a player must correctly answer a series of 15 multiple-choice questions of increasing difficulty. Questions are posed in natural language and the correct answer is selected among four possible choices.Fig. 1 shows an example of the question Who directed Blade Runner?, and the four possible answers A) Harrison FordB) Ridley Scott C) Philip Dick D) James Cameron. There are no time limits to answer the questions. Moreover, contestants read the question in advance, and then at any time they can decide whether to attempt an answer or quit the game by keeping the earned money. Each question has a certain monetary value (level 1: e 500; level 2: e 1000; level 3: e 1500; level 4: e 2000; level 5: e 3000; level 6: e 5000; level 7: e 7000; level 8: e 10,000; level 9: e 15,000; level 10: e 20,000; level 11: e 30,000; level 12: e 70,000; level 13: e 150,000; level 14: e 300,000; level 15: e 1,000,000). If the answer is correct, the player earns a certain amount of money and continues to play by answering questions of increasing difficulty until either she reaches the last question or she retires from the game by taking the earned money. There are three guarantee points where the money is banked and cannot be lost even if the player gives an incorrect answer to one of \fP. Molino et al. / Artificial Intelligence 222 (2015) 157–181159Fig. 1. An example of “Who Wants to Be a Millionaire?” question.the next questions: 3000, 20,000 and 1,000,000 Euros, corresponding to the milestone questions 5, 10, 15, respectively. At any point, the contestant may use one or more of three “lifelines”, which provide her with some form of assistance:• 50:50: this lifeline removes two wrong answers, leaving the player with a binary choice between the correct answer and the incorrect one;• Poll the Audience: the player asks the studio audience to pronounce about the correct answer. The percentages of the audience for the 4 different answers are given to the player, who has the last word ",
            {
                "entities": [
                    [
                        3067,
                        3095,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1007–1026Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the measure of conflicts: Shapley Inconsistency Values ✩Anthony Hunter a,∗, Sébastien Konieczny ba Department of Computer Science, University College London, UKb CRIL – CNRS, Université d’Artois, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 16 July 2007Received in revised form 9 June 2010Accepted 9 June 2010Available online 18 June 2010Keywords:Inconsistency managementInconsistency toleranceInconsistency measuresConflict resolutionParaconsistencyShapley valuesThere are relatively few proposals for inconsistency measures for propositional belief bases.However inconsistency measures are potentially as important as information measures forartificial intelligence, and more generally for computer science. In particular, they can beuseful to define various operators for belief revision, belief merging, and negotiation. Themeasures that have been proposed so far can be split into two classes. The first class ofmeasures takes into account the number of formulae required to produce an inconsistency:the more formulae required to produce an inconsistency, the less inconsistent the base.The second class takes into account the proportion of the language that is affected by theinconsistency: the more propositional variables affected, the more inconsistent the base.Both approaches are sensible, but there is no proposal for combining them. We addressthis need in this paper: our proposal takes into account both the number of variablesaffected by the inconsistency and the distribution of the inconsistency among the formulaeof the base. Our idea is to use existing inconsistency measures in order to define a gamein coalitional form, and then to use the Shapley value to obtain an inconsistency measurethat indicates the responsibility/contribution of each formula to the overall inconsistencyin the base. This allows us to provide a more reliable image of the belief base and of theinconsistency in it.© 2010 Elsevier B.V. All rights reserved.1. IntroductionThere are numerous works on reasoning under inconsistency. One can quote for example paraconsistent logics, argu-mentation frameworks, belief revision and fusion, etc. All these approaches illustrate the fact that the dichotomy betweenconsistent and inconsistent sets of formulae that comes from classical logics is not sufficient for describing these sets. Asshown by these works, normally when given two inconsistent sets of formulae, they are not trivially equivalent. They donot contain the same information and they do not contain the same contradictions.Measures of information à la Shannon have been studied in logical frameworks (see for example [31]). Roughly theyinvolve counting the number of models of the set of formulae (the less models, the more informative the set). The problemis that these measures regard an inconsistent set of formulae as having a null information content, which is counter-intuitive(especially given all the proposals for paraconsistent reasoning). So generalizations of measures of information have beenproposed to solve this problem [39,53,36,32,24].In comparison, there are relatively few proposals for inconsistency measures [22,27,35,32,28,18]. However, these mea-sures are potentially important in diverse applications in artificial intelligence, such as belief revision, belief merging, andnegotiation, and more generally in computer science. Already some provisional studies indicate that measuring inconsistency✩This paper is a revised and extended version of the paper “Shapley Inconsistency Values” presented at KR’06.* Corresponding author.E-mail addresses: a.hunter@cs.ucl.ac.uk (A. Hunter), konieczny@cril.fr (S. Konieczny).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.06.001\f1008A. Hunter, S. Konieczny / Artificial Intelligence 174 (2010) 1007–1026may be seen to be a useful tool in analysing a diverse range of information types including news reports [29], integrity con-straints [18], software specifications [9,10,42], and ecommerce protocols [12].The current proposals for measuring inconsistency can be classified in two approaches. The first approach involves“counting” the minimal number of formulae needed to produce the inconsistency. The more formulae needed to producethe inconsistency, the less inconsistent the set [35]. This idea is an interesting one, but it rejects the possibility of a morefine-grained inspection of the (content of the) formulae. In particular, if one looks to singleton sets only, one is back to theinitial problem, with only two values: consistent or inconsistent.The second approach involves looking at the proportion of the language that is touched by the inconsistency. This allowsus to look inside the formulae [27,32,18]. This means that two formulae viewed as two whole belief bases (singleton sets)can have different inconsistency measures. But, in these approaches one can identify the set of formulae with its conjunction(i.e. the set {ϕ, ϕ(cid:3)} has the same inconsistency measure as the set {ϕ ∧ ϕ(cid:3)}). This can be sensible in some applications, butthis means that the distribution of the contradiction among the formulae is not taken into account.What we propose in this paper is a definition for inconsistency measures that allow us to take the best of the twoapproaches. This will allow us to build inconsistency measures that are able to look inside the formulae, but also to takeinto account the distribution of the contradiction among the different formulae of the set.The above-mentioned approaches define inconsistency measures, i.e. functions that associate a number to each belief base.These global base-level measures are sufficient for a variety of applications. But in some cases we need an evaluation ona finer level, that is for each formula of the base. We call these functions, that associate a number to each formula of abase, inconsistency values. Such a function allows us to identify which are the most problematic formulae of a belief basewith respect to the inconsistency. This can be very useful for applications such as belief revision or negotiation. Theseinconsistency values provide a more detailed view of the inconsistency, and they can be used to defined new inconsistencymeasures which more accurately reflect the inconsistency of the whole base.To this end we will use a notion that comes from coalitional game theory: the Shapley value. This value assigns toeach player the payoff that this player can expect from her utility for each possible coalition. The idea is to use existinginconsistency measures (that allow us to look inside the formulae) in order to define a game in coalitional form, and thento use the Shapley value to obtain an inconsistency measure with the desired properties. From these inconsistency values, itis possible to define new interesting inconsistency measures. We present these measures, we state a set of logical propertiesthey satisfy, and we show that they are more interesting than the other existing measures.The plan of the paper is as follows: After some preliminaries in the next section, Section 3 introduces inconsistencymeasures that count the number of formulae needed to produce an inconsistency. Section 4 presents the approaches wherethe inconsistency measure depends on the number of variables touched by the inconsistency. Section 5 introduces theproblem studied in this paper and illustrates that the naive solution is not adequate. Section 6 gives the definition ofcoalitional games and of the Shapley value. Section 7 introduces the inconsistency measures based on Shapley value. Thenwe study the logical properties of these measures in Section 8, and we provide a complete axiomatization of a particularmeasure in Section 9 through a set of intuitive axioms. Section 10 sketches the possible applications of those measures forreasoning and for belief change operators. Finally Section 11 concludes by giving perspectives of this work and its possibleapplications for belief change operators.2. PreliminariesWe will consider a propositional language L built from a finite set of propositional symbols P . We will use a, b, c, . . . todenote the propositional variables, and Greek letters α, β, ϕ, . . . to denote the formulae. An interpretation is a total functionfrom P to {0, 1}. The set of all interpretations is denoted W . An interpretation ω is a model of a formula ϕ, denoted ω |(cid:5) ϕ,if and only if it makes ϕ true in the usual truth-functional way. Mod(ϕ) denotes the set of models of the formula ϕ, i.e.Mod(ϕ) = {ω ∈ W | ω |(cid:5) ϕ}. We will use ⊆ to denote the set inclusion, and we will use ⊂ to denote the strict set inclusion,i.e. A ⊂ B iff A ⊆ B and B (cid:2) A. Let A and B be two subsets of C , we note C = A ⊕ B if A and B form a partition of C, i.e.C = A ⊕ B iff C = A ∪ B and A ∩ B = ∅. We will denote the set of real numbers by R.A belief base K is a finite set of propositional formulae. More exactly, as we will need to identify the different formulaeof a belief base in order to associate them with their inconsistency value, we will consider belief bases K as vectors offormulae. For logical properties we will need to use the set corresponding to each vector, so we suppose that there is afunction mapping each vector K = (α1, . . . , αn) into ¯K , the set {α1, . . . , αn}. As it will never be ambigous, in the followingwe will omit the graphical distinction and write K as both the vector and the set.Let us note KL the set of belief bases definable from formulae of the language L. A belief base is consistent if there isat least one interpretation that satisfies all its formulae.If a belief base K is not consistent, then one can define the minimal inconsistent subsets of K as:MI(K ) =(cid:2)(cid:3) ⊆ KK(cid:3)(cid:3) K(cid:3) (cid:13) ⊥ and ∀K(cid:3)(cid:3) ⊂ K(cid:3), K(cid:4)(cid:3)(",
            {
                "entities": [
                    [
                        3880,
                        3908,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 190–213Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal social choice functions: A utilitarian view ✩Craig Boutilier a,1, Ioannis Caragiannis b, Simi Haber c, Tyler Lu a,2, Ariel D. Procaccia d,∗, Or Sheffet ea Dept. of Computer Science, University of Toronto, Canadab Computer Technology Institute “Diophantus” and Dept. of Computer Engineering and Informatics, University of Patras, Greecec Dept. of Mathematics, Bar-Ilan University, Israeld Computer Science Dept., Carnegie Mellon University, United Statese Center for Research on Computation and Society, Harvard SEAS, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 12 April 2014Received in revised form 11 June 2015Accepted 14 June 2015Available online 25 June 2015Keywords:Computational social choiceWe adopt a utilitarian perspective on social choice, assuming that agents have (possibly latent) utility functions over some space of alternatives. For many reasons one might consider mechanisms, or social choice functions, that only have access to the ordinal rankings of alternatives by the individual agents rather than their utility functions. In this context, one possible objective for a social choice function is the maximization of (expected) social welfare relative to the information contained in these rankings. We study such optimal social choice functions under three different models, and underscore the important role played by scoring functions. In our worst-case model, no assumptions are made about the underlying distribution and we analyze the worst-case distortion—or degree to which the selected alternative does not maximize social welfare—of optimal (randomized) social choice functions. In our average-case model, we derive optimal functions under neutral (or impartial culture) probabilistic models. Finally, a very general learning-theoretic model allows for the computation of optimal social choice functions (i.e., ones that maximize expected social welfare) under arbitrary, sampleable distributions. In the latter case, we provide both algorithms and sample complexity results for the class of scoring functions, and further validate the approach empirically.© 2015 Elsevier B.V. All rights reserved.1. IntroductionClassic models in social choice theory assume that the preferences of a set of agents over a set of alternatives are represented as linear orders; a social choice function, given these preferences as input, outputs a single socially desirable alternative. A host of clever social choice functions have been designed to satisfy various normative criteria. Most work in computational social choice studies computational aspects of these models, addressing questions such as the complexity of computing social choice functions [5,17] or manipulating them (see the survey by Faliszewski and Procaccia [13]).E-mail addresses: cebly@cs.toronto.edu (C. Boutilier), caragian@ceid.upatras.gr (I. Caragiannis), simi@math.biu.ac.il (S. Haber), tl@cs.toronto.edu (T. Lu), ✩A preliminary version of this paper appeared in the proceedings of EC’12.* Corresponding author.arielpro@cs.cmu.edu (A.D. Procaccia), osheffet@seas.harvard.edu (O. Sheffet).1 Currently on leave at Google, Inc., Mountain View, CA.2 Currently at Google, Inc., Mountain View, CA.http://dx.doi.org/10.1016/j.artint.2015.06.0030004-3702/© 2015 Elsevier B.V. All rights reserved.\fC. Boutilier et al. / Artificial Intelligence 227 (2015) 190–213191Under ordinal preferences, an axiomatic approach to obtaining a socially desirable outcome seems—on the face of it—necessary, absent concrete measures of the quality of an alternative. In contrast, some work in economics assumes cardinalpreferences and takes a utilitarian approach. This viewpoint dates to the work of Bentham at the end of the 18th century, who argued that “it is the greatest happiness of the greatest number that is the measure of right and wrong.” This axiom suggests that happiness can be quantified, and indeed, having coined the term utility, Bentham proposed that the goal of government is to maximize the sum of individual utilities—the social welfare (defying contemporary wisdom that the goal of government is to enrich the coffers of the ruler). The utilitarian approach is prevalent, for example, in mechanism design, and perhaps even more so in algorithmic mechanism design [25].In this paper we view the social choice problem through this utilitarian lens. Our premise is that agents have (possibly implicit) utility functions, and the goal of a social choice function is to maximize the (utilitarian) social welfare3—i.e., (possibly weighted) sum of agent utilities—of the selected alternative. The utilitarian perspective is not appropriate for all social choice problems (a point we discuss further below). However, the methods of social choice—especially voting systems—are finding increasing application in recommender systems, web search, product design, and many more practical domains, in which the primary aim is often, as in much of mechanism design, to aggregate preferences so that utility or efficiency is maximized. Indeed, one motivation for our work is the development of group recommendation systems for a variety of domains, including low-stakes consumer applications and higher profile public policy and corporate decisions. Our work can be viewed as a step toward supporting groups of users making decisions using social choice functions that are automatically optimized for their needs. In these settings, a utilitarian perspective is often called for.If we could directly access the utilities of agents, the socially desirable alternative could be easily identified. However, such access is often not feasible for a variety of reasons. As a result, we use agent preference orders as a proxy for their utility functions; and the social choice function, taking preference orders as input, should perform well with respect to the underlying utilities. From this point of view, a social choice function is optimal if it maximizes social welfare given the available information. Using a preference order as proxy for utility in this fashion serves several purposes. First, behavioral economists have argued that people find it difficult to construct utilities for alternatives. Second, the cognitive and commu-nication burden of articulating precise utilities has long been recognized within decision analysis, behavioral economics, and psychology. By contrast, simply comparing and ordering alternatives is considerably easier for most people, which makes soliciting preference orders more practical than eliciting utilities. Furthermore, choice behavior among alternatives can of-ten be interpreted as revealing ordinal (rather than cardinal) preference information, providing ready access to (sometimes incomplete) orders in many of the domains described above. Hence we content ourselves with orders as inputs.1.1. Our resultsOur study of optimal social choice functions incorporates three distinct but related models, each with its own assump-tions regarding available information and therefore its own notion of optimality. One common thread is that the family of scoring functions—social choice functions that score alternatives based only on their position in each agent’s preference order—plays a key role in optimizing social welfare.In Section 3 we study a model where no information about agents’ utility functions is available when constructing the so-cial choice function. A worst-case analysis is thus called for. We believe that the study of this model is of theoretical interest, but it is certainly the least practical of our three models. Specifically, given a collection of agents’ preferences—a preference profile—there are many consistent collections of utility functions—utility profiles—that induce this preference profile in the natural way (by ranking alternatives with higher utility closer to the top). The distortion of a social choice function on a preference profile is the worst-case ratio (over feasible utility profiles) of the social welfare of the best alternative to the social welfare of the alternative that is selected by the function. A worst-case optimal social choice function minimizes the distortion on every preference profile.√We first derive upper and lower bounds on the least distortion that one can hope for, focusing on randomized social choice functions. We show that there exists a preference profile where every randomized social choice function must have m), where m is the number of alternatives. We complement this result with a randomized social distortion at least (cid:2)(∗choice function whose distortion on every preference profile is O(m). A slightly weaker upper bound is obtained via a randomized variation of a natural scoring function that we call the harmonic scoring function (a new canonical scoring function that may be of independent interest). Finally, we establish that the worst-case optimal social choice function (which achieves minimum distortion on every profile) is polynomial-time computable. The proof is based on linear programming, and (roughly speaking) relies on embedding the dual of a sub-problem within a carefully constructed larger LP, in order to avoid quadratic constraints.m log√In Section 4 we study an average-case model, assuming a known distribution D over utility functions. We assume that the utility function of each agent is drawn independently from D. Given reported agent preferences, one can compute the expected utility any agent has for an alternative with respect to D. An average-case optimal social choice function selects an alternative that maximizes expected social welfare given the reported profile. We show that when D is neutral, i.e., symmetric with respect to alternatives, the average-case optimal social choice function must be a scoring function. The 3 Hereinafter, we simply write “social welfare” to refer t",
            {
                "entities": [
                    [
                        3372,
                        3400,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 248–278Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for electric vehicle scheduling in large-scale mobility-on-demand schemesEmmanouil S. Rigas a,∗a Aristotle University of Thessaloniki, 54124, Thessaloniki, Greeceb Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, UK, Sarvapali D. Ramchurn b, Nick Bassiliades aa r t i c l e i n f oa b s t r a c tArticle history:Received 17 July 2016Received in revised form 14 February 2018Accepted 10 June 2018Available online 18 June 2018Keywords:Mixed integer programmingHeuristic searchLocal searchMax-flowElectric vehiclesShared vehiclesMobility on demandWe study a setting where Electric Vehicles (EVs) can be hired to drive from pick-up to drop-off points in a Mobility-on-Demand (MoD) scheme. The goal of the system is, either to maximize the number of customers that are serviced, or the total EV utilization. To do so, we characterise the optimisation problem as a max-flow problem in order to determine the set of feasible trips given the available EVs at each location. We then model and solve the EV-to-trip scheduling problem offline and optimally using Mixed Integer Programming (MIP) techniques and show that the solution scales up to medium sized problems. Given this, we develop two non-optimal algorithms, namely an incremental-MIP algorithm for medium to large problems and a greedy heuristic algorithm for very large problems. Moreover, we develop a tabu search-based local search technique to further improve upon and compare against the solution of the non-optimal algorithms. We study the performance of these algorithms in settings where either battery swap or battery charge at each station is used to cope with the EVs’ limited driving range. Moreover, in settings where EVs need to be scheduled online, we propose a novel algorithm that accounts for the uncertainty in future trip requests. All algorithms are empirically evaluated using real-world data of locations of shared vehicle pick-up and drop-off stations. In our experiments, we observe that when all EVs carry the same battery which is large enough for the longest trips, the greedy algorithm with battery swap with the max-flow solution as a pre-processing step, provides the optimal solution. At the same time, the greedy algorithm with battery charge is close to the optimal (97% on average) and is further improved when local search is used. When some EVs do not have a large enough battery to execute some of the longest trips, the incremental-MIP generates solutions slightly better than the greedy, while the optimal algorithm is the best but scales up to medium sized problems only. Moreover, the online algorithm is shown to be on average at least 90% of the optimal. Finally, the greedy algorithm scales to 10-times more tasks than the incremental-MIP and 1000-times more than the static MIP in reasonable time.© 2018 Elsevier B.V. All rights reserved.1. IntroductionIn a world where over 60% of the total population will be living in, or around, cities the current personal transportation model is not sustainable as it is based almost entirely on privately owned internal combustion engine vehicles. These * Corresponding author.E-mail addresses: erigas@csd.auth.gr (E.S. Rigas), sdr1@soton.ac.uk (S.D. Ramchurn), nbassili@csd.auth.gr (N. Bassiliades).https://doi.org/10.1016/j.artint.2018.06.0060004-3702/© 2018 Elsevier B.V. All rights reserved.\fE.S. Rigas et al. / Artificial Intelligence 262 (2018) 248–278249vehicles cause high pollution (e.g., air and sound), and face low utilization rates1 [52]. Electric Vehicles (EVs) can be an efficient alternative to those using internal combustion engines when it comes to running costs [17], environmental impact, and quality of driving. However, these advantages come with a trade-off, as EVs have short ranges and long charging times. To address such issues, cities typically resort to building a large number of charging stations with fast chargers, or battery swapping capabilities. Now, such facilities are only worth building if there are enough EVs to use them. However, drivers will not buy EVs if charging stations are not first available, leading to a catch-22 situation.In order to increase vehicle utilization, Mobility-on-Demand (MoD) schemes have been advocated [30]. MoD involves vehicles that are used by either individuals, or small groups of commuters, thus providing them with an alternative from using their privately owned vehicles. Such systems have the potential to reduce traffic congestion in urban areas, as well as the need for large numbers of parking spots.2 By doing so, MoD also aims to achieve considerably higher vehicle utilization rates compared to individually owned ones (i.e., few vehicles will cover the transportation needs of many commuters). Moreover, other advantages include the fact that car ownership is reduced, as well as less up-front charges which means low-income people may be better served.Given the benefits of EVs and MoD schemes, in this paper we explore scenarios within which EVs could be used within MoD schemes, and consider their associated optimisation challenges. By addressing these challenges, the advantages of the two transportation modes would be combined [30,10]. Moreover, the use of EVs in MoD schemes offer an opportunity to further market EVs to potential car owners as they get to try the technology before buying it. In this way, EV-equipped MoD schemes would help popularise EVs, while at the same time having a positive impact in urban traffic conditions as well as the environment.To date, a number of MoD schemes, such as ZipCar,3 or CarShare4 have been proposed, albeit most of them using normal cars. However, EVs present new challenges for MoD schemes. For example, EVs have a limited range that requires them to either charge regularly or have their battery swapped when they stop. Moreover, if such MoD schemes are to become popular, it is important to ensure that charging/swap capacity is managed and scheduled to allow for the maximum number of consumer requests to be serviced across a large geographical area. In addition, in order for MoD schemes to be economically sustainable, and given the higher cost of buying EVs compared to conventional vehicles, it is important to have them working at maximum capacity and servicing the maximum number of customers around the clock.Against this background, we model the MoD scheme for EVs and develop a number of algorithms to solve the problem of scheduling trips for MoD consumers in order to maximize the number of trip requests serviced while coping with the limited range of EVs. These algorithms attempt to deal with the computational complexity of the scheduling problem in a number of contexts (online v/s offline, with battery swap or battery charge, small-sized or large problems). Thus, we first recast the scheduling problem as a max-flow problem whose solution lets us determine the (upper limit) of trip requests able to be executed given a set of available EVs. Then, we show how the scheduling of trips in the MoD scheme is a highly combinatorial problem, for which an optimal offline solution, where all demand is known in advance, scales only up to medium sized problems (tens of EVs and hundreds of trips). Thus, to cope with large problems, we also develop two near-optimal offline solutions, namely an incremental MIP and a greedy heuristic, as well as a tabu search-based local search technique to further improve the solution quality of the non-optimal algorithms. Moreover, to tackle the online version of the problem, where demand is not known in advance, we develop an online scheduling algorithm. In all cases, and given the limited range of EVs, we consider situations where they can either have their battery swapped (with a fully charged one), or charged at the stations. The work presented here has been initiated at [38] with basic versions of the MIP and the greedy algorithms for battery swapping. Specifically, this paper advances the state of the art as follows:1. We provide a characterisation of the MoD scheme as a max-flow problem. By solving this problem, we are able to determine the set of all feasible trips given a set of available EVs.2. We propose an optimal Mixed Integer Programming (MIP) formulation of the problem of scheduling EVs in a MoD scheme that maximizes the number of completed tasks (i.e., trip requests from consumers) or the EV utilization (i.e., number of time points each EV is travelling), either using battery swap or battery charging at each station.3. Given the average scalability of the optimal solution, we develop an incremental-MIP and a greedy heuristic algorithm which are shown to generate near-optimal solutions with considerably lower execution times.4. We propose a tabu search-based local search technique in order to further improve the solution quality of the non-optimal algorithms.5. We propose a battery swap optimization algorithm which minimizes the number of necessary battery swaps in order to reduce the need for spare batteries and thus, cost.1 EVs can be used as energy storage devices when not being driven. In this way (renewable) energy utilization can increase. Thus, in the EVs domain the word utilization refers to both the driving and the use of them as energy storage devices.2 Demand for travel is not reduced. However, the fact that multiple users end up using the same cars means that there are fewer cars on the road and hence, less congestion (i.e., this indirectly can improve congestion as it could reduce the number of cars parked at the sides of the roads. Such parked cars create some congestion).3 http://www.zipcar.com/.4 http://www.enterprisecarshare .com/.\f250E.S. Rigas et al. / Artificial Intelligence 262 (2018) 248–2786. We propose an online algorithm for scheduling EV trips across the MoD that can cope with uncertainty in the numbe",
            {
                "entities": [
                    [
                        3435,
                        3463,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 739–778www.elsevier.com/locate/artintSolving logic program conflict through strong and weak forgettings ✩Yan Zhang a,∗, Norman Y. Foo ba Intelligent Systems Laboratory, School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiab School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, AustraliaReceived 6 September 2005; received in revised form 23 February 2006; accepted 23 February 2006Available online 29 March 2006AbstractWe consider how to forget a set of atoms in a logic program. Intuitively, when a set of atoms is forgotten from a logic program,all atoms in the set should be eliminated from this program in some way, and other atoms related to them in the program mightalso be affected. We define notions of strong and weak forgettings in logic programs to capture such intuition, reveal their closeconnections to the notion of forgetting in classical propositional theories, and provide a precise semantic characterization forthem. Based on these notions, we then develop a general framework for conflict solving in logic programs. We investigate varioussemantic properties and features in relation to strong and weak forgettings and conflict solving in the proposed framework. Weargue that many important conflict solving problems can be represented within this framework. In particular, we show that allmajor logic program update approaches can be transformed into our framework, under which each approach becomes a specificconflict solving case with certain constraints. We also study essential computational properties of strong and weak forgettings andconflict solving in the framework.© 2006 Elsevier B.V. All rights reserved.Keywords: Conflict solving; Knowledge representation; Answer set semantics; Logic program update; Computational complexity1. Introduction1.1. MotivationOne promising approach in the research of reasoning about knowledge dynamics is to represent agents’ knowledgebases as logic programs on which necessary updates/revisions are conducted as a way of modeling agents’ knowledgeevolution. A key issue in this study is to solve various conflicts and inconsistencies in logic programs, e.g. [15].We observe that some typical conflict solving problems in applications are essential in reasoning about agents’knowledge change, but they may not be properly handled by traditional logic program updates. Let us consider a✩ Some results presented in this paper were published in IJCAI-2005 and AAAI-2005 [Y. Zhang, N.Y. Foo, K. Wang, Solving logic programconflict through strong and weak forgettings, in: Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI-05), 2005,pp. 627–632; Y. Zhang, N.Y. Foo, A unified framework for representing logic program updates, in: Proceedings of the 20th National Conferenceon Artificial Intelligence (AAAI-05), 2005, pp. 707–712].* Corresponding author.E-mail addresses: yan@cit.uws.edu.au (Y. Zhang), norman@cse.unsw.edu.au (N.Y. Foo).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.02.002\f740Y. Zhang, N.Y. Foo / Artificial Intelligence 170 (2006) 739–778scenario. John wants Sue to help him to complete his assignment. He knows that Sue will help him if she is not sobusy. Tom is a good friend of John and wants John to let him copy John’s assignment. Then John learns that Sue hatesTom, and will not help him if he lets Tom copy his assignment, which will be completed under Sue’s help. While Johndoes not care whether Sue hates Tom or not, he has to consider Sue’s condition to offer him help. What is John goingto do? We formalize this scenario in a logic programming setting. We represent John’s knowledge base ΠJ :r1: complete(John, Assignment) ← help(Sue, John),r2: help(Sue, John) ← not Busy(Sue),r3: goodFriend(John, Tom) ←,r4: copy(Tom, Assignment) ← goodFriend(John, Tom), complete(John, Assignment),and Sue’s knowledge base ΠS :r5: hate(Sue, Tom) ←,r6: ← help(Sue, John), copy(Tom, Assignment).In order to take Sue’s knowledge base into account, John may update his knowledge base ΠJ in terms of Sue’sΠS . In this way, John obtains a solution: Π final= {r1, r2, r3, r5, r6} or its stable model, from which we know thatSue will help John to complete the assignment and John will not let Tom copy his assignment. Although the conflictbetween ΠJ and ΠS has been solved by updating, the result is somehow not always satisfactory. For instance, whileJohn wants Sue to help him, he may have no intention to contain the information that Sue hates Tom into his newknowledge base.JAs an alternative, John may just weaken his knowledge base by forgetting atom copy(Tom, Assignment) fromΠJ in order to accommodate Sue’s constraint on help. Then John will have a new program Π final(cid:4)= {r1, r2, r3}—John remains a maximal knowledge subset which is consistent with Sue’s condition without being involved in Sue’spersonal feeling about Tom.JThe formal notion of forgetting in propositional theories was initially considered by Lin and Reiter from a cognitiverobotics perspective [18] and has recently received a great attention in KR community. It has been shown that thetheory of forgetting has important applications in solving knowledge base inconsistencies, belief update and merging,abductive reasoning, causal theories of actions, and reasoning about knowledge under various propositional (modal)logic frameworks, e.g. [13,14,19,24]. Then a natural question is: whether can we develop an analogous theory offorgetting in logic programs and apply it as a foundational basis for various conflict solving in logic programs? Thispaper provides an answer to this question.1.2. Summary of contributions of this paperThe main contributions of this paper can be summarized as follows.(1) We define two notions of strong and weak forgettings in logic programs under answer set programming semantics.We reveal their close connections to the notion of forgetting in classical propositional theories, and provide aprecise semantic characterization for them.(2) Based on these notions, we develop a general framework for conflict solving called logic program contexts.Under this framework, conflicts can be solved by strongly or/and weakly forgetting certain sets of atoms fromcorresponding programs. We show that our framework is general enough to represent many important conflictsolving problems. In particular, for the first time we demonstrate that all major logic program update approachescan be transformed into our framework.(3) We investigate essential computational properties in relation to strong and weak forgettings and conflict solvingin the proposed framework. Specifically, we show that under the answer set programming with no disjunctionin the head, the associated inference problem for strong and weak forgettings is coNP-complete, and the irrele-vance problem related to strong and weak forgettings and conflict solving is coDP-complete. We also study othercomputational problems related to the computation of strong and weak forgetting and conflict solving.\fY. Zhang, N.Y. Foo / Artificial Intelligence 170 (2006) 739–7787411.3. Structure of the paperThe rest of this paper is organized as follows. We first present preliminary definitions and concepts in Section 2.In Section 3, we give formal definitions of strong and weak forgettings in logic programs, and present their essentialproperties. Based on notions of strong and weak forgettings, in Section 4 we propose a framework called logic programcontexts for general conflict solving in logic programs. In Section 5, we investigate various semantic properties andfeatures in relation to strong and weak forgettings and conflict solving in the proposed framework. In Section 6, weshow that our conflict solving framework is general enough to represent all major logic program update approaches. InSection 7, we study essential computational properties of strong and weaking forgettings and conflict solving. Finally,in Section 8 we conclude the paper with some discussions.2. PreliminariesWe consider finite propositional normal logic programs in which each rule is of the form:a ← b1, . . . , bm, not c1, . . . , not cn,(1)where a is either a propositional atom or empty, b1, . . . , bm, c1, . . . , cn are propositional atoms, and not presents thenegation as failure. From (1) we know that a normal logic program does not contain classical negation and has nodisjunction in the head. When a is empty, rule (1) is called a constraint. Given a rule r of the form (1), we denotehead(r) = {a}, pos(r) = {b1, . . . , bm}, neg(r) = {c1, . . . , cn}, and body(r) = pos(r) ∪ neg(r). Therefore, rule (1) maysimply be represented as the form:head(r) ← pos(r), not neg(r),(2)here we denote not neg(r) = {not c1, . . . , not cn}. We also use atom(r) to denote the set of all atoms occurring in rule r.For a program Π , we define notions head(Π) =r∈Π neg(r),body(Π) =r∈Π atom(r). Given sets of atoms P and Q, we may use notionr∈Π body(r), and atom(Π) =r∈Π head(r), pos(Π) =r∈Π pos(r), neg(Π) =(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:4)r: head(r) ←(cid:3)pos(r) − P(cid:4), not(cid:4)(cid:3)neg(r) − Qto denote rule r (cid:4) obtained from r by removing all atoms occurring in P and Q in the positive and negation as failureparts respectively.The stable model of a program Π is defined as follows. Firstly, we consider Π to be a program in which each ruledoes not contain negation as failure not. A finite set S of propositional atoms is called a stable model of Π if S is thesmallest set such that for each rule a ← b1, . . . , bm from Π , if b1, . . . , bm ∈ S, then a ∈ S. Now let Π be an arbitrarynormal logic program. For any set S of atoms, program Π S is obtained from Π by deleting (1) each rule from Π thatcontains not c in the body if c ∈ S; and (2) all subformulas of not c in the bodies of the remaining rules. Then S isa stable model of Π if and only i",
            {
                "entities": [
                    [
                        3135,
                        3163,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1644–1672Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantic forgetting in answer set programming ✩Thomas Eiter a, Kewen Wang b,∗,1a Institut für Informationssysteme, Technische Universität Wien, Favoritenstraße 9-11, A-1040 Vienna, Austriab School of Information and Communication Technology, Griffith University, Brisbane QLD 4111, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 3 November 2007Received in revised form 6 May 2008Accepted 24 May 2008Available online 29 May 2008Keywords:Answer set programmingNonmonotonic logic programsKnowledge representationForgettingComputational complexityThe notion offorgetting, also known as variable elimination, has been investigatedextensively in the context of classical logic, but less so in (nonmonotonic) logic program-ming and nonmonotonic reasoning. The few approaches that exist are based on syntacticmodifications of a program at hand.In this paper, we establish a declarative theoryof forgetting for disjunctive logic programs under answer set semantics that is fullybased on semantic grounds. The suitability of this theory is justified by a number ofdesirable properties. In particular, one of our results shows that our notion of forgettingcan be entirely captured by classicalforgetting. We present several algorithms forcomputing a representation of the result of forgetting, and provide a characterization ofthe computational complexity of reasoning from a logic program under forgetting. Asapplications of our approach, we present a fairly general framework for resolving conflictsin inconsistent knowledge bases that are represented by disjunctive logic programs, and weshow how the semantics of inheritance logic programs and update logic programs from theliterature can be characterized through forgetting. The basic idea of the conflict resolutionframework is to weaken the preferences of each agent by forgetting certain knowledge thatcauses inconsistency. In particular, we show how to use the notion of forgetting to providean elegant solution for preference elicitation in disjunctive logic programming.© 2008 Published by Elsevier B.V.1. IntroductionFor intelligent agents, the ability to discard irrelevant information has been recognized as an important feature (that ismastered well by humans) and received broad attention in artificial intelligence, both from a cognitive and a computationalperspective. In the area of knowledge representation, this ability is often referred to as forgetting [49] or variable elimina-tion [9], but has been studied under many different names including irrelevance, independence, irredundancy, novelty, orseparability (see [34,63] for more details).Forgetting has its root in Boolean Algebra [6] where it is a fundamental reasoning process. C.I. Lewis [41] has pointed outthat, for purposes of application of Boolean logic to commonsense reasoning, the elimination/forgetting is a process moreimportant than solution2 since most processes of reasoning take place through the elimination of “middle” variables. Boolewrites of such middle variables that it “usually happens in commonsense reasoning, and especially when we have morethan one premises, that some of the elements [in the premises] are not required to appear in the conclusion”.✩Preliminary versions of this paper with some of the results have been presented at AAAI 2006 and at NMR 2006.* Corresponding author.E-mail addresses: eiter@kr.tuwien.ac.at (T. Eiter), k.wang@griffith.edu.au (K. Wang).1 Part of the work was done while this author was visiting Technische Universität Wien.2 In [41] a problem is formulated as a Boolean equation such that a solution of the Boolean equation corresponds to a solution of the given problem. Inparticular, solving a Boolean equation is treated as a process of eliminating/forgetting variables that represent unknowns.0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.05.002\fT. Eiter, K. Wang / Artificial Intelligence 172 (2008) 1644–16721645Forgetting and its applications have been investigated extensively in the context of classical logic, for example, [5,34,36,37,49,55,56,67], but less so in nonmonotonic logic programming and reasoning. In this context, it was first considered in[70,71], where two types of forgetting—strong and weak forgetting—have been defined by first transforming a logic programP into a reduced form and then deleting some rules (and literals) from it. While this approach works well in a number ofcases, it has two major drawbacks. First, its semantic underpinning is not fully clear. Specifically, the relationship betweenthe intended semantics of a logic program, in terms of its answer sets, and the result of the syntactic transformations thatare carried out by strong and weak forgetting is unclear. Second, this approach does not address desirable properties fora reasonable notion of forgetting in nonmonotonic logic programming. In particular, one may ask what is the difference ofthese notions of forgetting from traditional approaches to deletion of rules/literals in logic programming and databases.A further aspect is that both strong and weak forgetting are syntax-sensitive, i.e., programs that are semantically equiva-lent may have different results after forgetting about the same literal. For example, the programs P = {p ← . q ← not p}and Q = {p ←} are equivalent under the answer set semantics. Weak forgetting about p from P yields the programWForgetLP(P , p) = {q ←} and from Q the program WForgetLP(Q , p) = { }; clearly, these programs are not equivalent.While the role of syntax in logic programming is, with respect to reading of rules as in classical logic well-acknowledged,one might argue that relative to the semantics of this syntax, equivalent programs should behave in the same way. Inparticular, in this example the result of forgetting about p in P and Q should yield semantically the same result (note that,under answer set semantics, the second rule in P is redundant).A similar phenomenon can be observed for strong forgetting. Consider P = {q ← not p. q ← not q} and Q = {q ←}. Thenthese two programs are equivalent under the answer set semantics. However, the results of strong forgetting about p fromP and Q are SForgetLP(P , p) = {q ← not q} and SForgetLP(Q , p) = {q ←}, respectively, which are obviously not equivalent.The discrepancy is here even more noticeable: the result of strong forgetting about an atom from a consistent program canbe inconsistent.Thus, an alternative notion of forgetting for nonmonotonic logic programming is highly desirable. In this paper, we chooseanswer set programming (ASP) [44] as the underlying nonmonotonic logic. ASP is a new paradigm of logic programmingunder the answer set semantics [29], which is becoming a major tool for knowledge representation and reasoning due toits simplicity, expressive power, and connection to major nonmonotonic logics. A number of efficient ASP solvers, such asDLV, Smodels, ASSAT, Cmodels, or Clasp are available (see [3]), which can handle large problem instances.Prior to defining a notion of forgetting for nonmonotonic logic programming, we may pose the question what desirableproperties a reasonable theory of forgetting should have. The following ones appear to be natural candidates for us. Let Pbe a logic program and let Pbe the result of forgetting about a literal l in P .(cid:4)(F1) The proposed notion of forgetting should be a “natural” generalization of, and relate to, forgetting in classical logic., i.e., the vocabulary stays the same.(F2) No new symbols are introduced in P(F3) The reasoning under P(F4) The result of forgetting is not sensitive to syntax in that the results of forgetting about l in semantically equivalentis equivalent to the reasoning under P if l is ignored.(cid:4)(cid:4)programs should also be semantically equivalent.(F5) The semantic notion of forgetting is coupled with a syntactic counterpart, i.e., there is effective constructible syntax forrepresenting the result of forgetting.(cid:4)Property (F1) specifies the major intuition behind forgetting and clarifies the difference of forgetting from deletion. (F2) isnecessary because the forgetting is to eliminate the symbols to be forgotten. This is a difference between forgetting andsome approaches to revision, update, and deletion, such as [1,10,16,19,31]; note that to combine forgetting with other ap-proaches to adding new information is a different issue. Property (F3) provides a semantic justification for the forgetting.Note that Pand P may have different answer sets in general (see Proposition 1); (F4) guarantees that the notion of forget-ting is semantically well-defined. Finally, property (F5) is useful for applications of forgetting in knowledge representation.To the best of our knowledge, there is no theory of forgetting in nonmonotonic reasoning or logic programming whichis based on the above criteria; notice that properties (F3) and (F4) do not hold for weak and strong forgetting from [70,71](see Section 7 for more discussion). However, the definition of forgetting in classical logic cannot be directly adapted tologic programming (cf. Section 3.1). The main contributions of the present paper are as follows.• We establish a declarative, semantically defined notion of forgetting for disjunctive logic programs under answer set se-mantics called semantic forgetting. The suitability of semantic forgetting is justified by a number of desirable properties,including the ones given above.• As one of them, we show that our notion of forgetting naturally captures classical forgetting. As we show, this canbe exploited for reasoning under forgetting about a literal from a logic program by resorting to representations of anonmonotonic logic program in terms of classical logic [39,50,51].• As another such property, for every consistent disjunctive program P and literal l, a",
            {
                "entities": [
                    [
                        4001,
                        4029,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 955–990www.elsevier.com/locate/artintUnderstanding the role of noise in stochastic local search:Analysis and experimentsOle J. MengshoelRIACS, NASA Ames Research Center, Mail Stop 269-3, Moffett Field, CA 94035, USAReceived 3 November 2006; received in revised form 17 September 2007; accepted 17 September 2007Available online 1 February 2008AbstractStochastic local search (SLS) algorithms have recently been proven to be among the best approaches to solving computationallyhard problems. SLS algorithms typically have a number of parameters, optimized empirically, that characterize and determinetheir performance. In this article, we focus on the noise parameter. The theoretical foundation of SLS, including an understandingof how to the optimal noise varies with problem difficulty, is lagging compared to the strong empirical results obtained usingthese algorithms. A purely empirical approach to understanding and optimizing SLS noise, as problem instances vary, can be verycomputationally intensive. To complement existing experimental results, we formulate and analyze several Markov chain models ofSLS in this article. In particular, we compute expected hitting times and show that they are rational functions for individual probleminstances as well as their mixtures. Expected hitting time curves are analytical counterparts to noise response curves reported inthe experimental literature. Hitting time analysis using polynomials and convex functions is also discussed. In addition, we presentexamples and experimental results illustrating the impact of varying noise probability on SLS run time. In experiments, wheremost probable explanations in Bayesian networks are computed, we use synthetic problem instances as well as problem instancesfrom applications. We believe that our results provide an improved theoretical understanding of the role of noise in stochastic localsearch, thereby providing a foundation for further progress in this area.© 2008 Elsevier B.V. All rights reserved.Keywords: Stochastic local search; Noise; Markov chain models; Expected hitting times; Rational functions; Noise response curves; Probabilisticreasoning; Bayesian networks; Most probable explanation; Systematic experiments; Polynomial approximation; Convexity1. IntroductionThe stochastic local search (SLS) approach has proven to be highly competitive for solving a range of hard compu-tational problems including satisfiability of propositional logic formulas [11,18,45,46] as well as computing the mostprobable explanation [22,27,30] and the maximum a posteriori hypothesis [36,37] in Bayesian networks. While thedetails of different SLS algorithms vary [18], by definition they all use stochasticity or noise. In this article we focuson noise during local search rather than, say, noisy initialization.Empirically, it turns out that noise has a dramatic impact on the run time of SLS algorithms [14,17,26,44,45]. Intu-itively, there is a fundamental trade-off between using high and low levels of noise in SLS. Let 0 (cid:2) p (cid:2) 1 represent theprobability of taking a noise step. The argument for using low noise p is that this enables an SLS algorithm to greedilyE-mail address: omengshoel@riacs.edu.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.010\f956O.J. Mengshoel / Artificial Intelligence 172 (2008) 955–990climb hills without taking unnecessary downhill noise steps. The argument for using high noise p is that this providesthe SLS algorithm with a powerful mechanism to escape local (but non-global) optima [17]. Empirically—and de-pending on the problem instance, the SLS algorithm, and its input parameters including noise level—an approximatelyoptimal noise level ˆp∗ can be found. The difficulty of approximating the optimal noise p∗ [26] has led to the devel-opment of adaptive noise, in which p is not static but varies as the SLS algorithm runs [7,14,26]. However, noiseadaptation is still an active area of research and we believe the present work provides several key insights that shouldbenefit further progress.Our main contributions in this article are as follows. Based on the seminal WALKSAT architecture [44,45], we in-troduce a simple but general SLS algorithm called SIMPLESLS. SIMPLESLS performs noisy steps with probability p,and greedy steps with probability 1 − p. We show that expected hitting times for SIMPLESLS are rational functionsP (p)/Q(p), where P (p) and Q(p) are polynomials. This explicitly provides a functional form corresponding tonoise response curves previously only established empirically in the SLS literature [7,8,14,16,26]. We also considerthe use of polynomials and convex functions. Convexity is important because local optimality implies global opti-mality, a dramatic simplification compared to unrestricted optimization. Rational functions as well as their specialcase polynomials can be used to analytically determine optimal noise levels; the latter are used in experiments in thisarticle.Using Markov chain analysis, and in particular by analyzing expected hitting times for trap Markov chains, weclearly show the impact of different settings of the noise parameter p when the difficulty of the problem instancevaries, a key concern in stochastic local search. Trap Markov chains are an idealized model for how SLS gets trappedby local (but non-global) optima in a search space, and how noise p impacts the capability of SLS to escape suchtraps. Further, we show that optimal noise probability p∗ varies dramatically depending on the problem instance.In particular, the optimal noise parameter varies from p∗ = 0 for easy problem instances to p∗ close to 1 for hardproblem instances.We back up our analysis with empirical results using Bayesian networks (BNs), both synthetic and from applica-tions. BNs play a central role in a wide range of uncertainty reasoning applications including diagnosis, probabilisticrisk analysis, language understanding, intelligent data analysis, error correction coding, and biological analysis. Manyinteresting computational BN problems, including MPE computation, are NP-complete or harder [37,40,47], henceheuristic methods such as SLS are of interest. In this work we study the problem of computing the most probable ex-planation (MPE) in Bayesian networks. We use an SLS algorithm known as stochastic greedy search (SGS) to searchfor MPEs in BNs. SGS can simulate SIMPLESLS and is a flexible, operator-based SLS approach in which differentinitialization and search operators can easily be investigated [27,30].Our approach to generating synthetic BNs includes satisfiability (SAT) as a special case (see [40,47] for the reduc-tion). Let V be the number of variables in propositional logic or the number of root nodes in BNs. Further, let C be thenumber of clauses in propositional logic or the number of non-root nodes in BNs. For V > 0, the ratio C/V is well-defined and has turned out to be useful in predicting inference difficulty for randomly generated problem instances[33,34]. An easy–hard–easy pattern in inference difficulty as a function of the C/V -ratio has been observed for SAT[34]. For BNs, an easy–hard–harder pattern has been established when inference difficulty is measured in terms ofupper bounds on minimal maximal clique size (or treewidth) [29,33]. Upper bounds on optimal clique tree size andoptimal maximal clique size can be computed using tree clustering [24]. In this article, we use the C/V -ratio directlyto characterize the difficulty of synthetic BNs for SLS.There is a clear relationship between our Markov chain approach and observed SLS run times. We illustrate that ouridealized trap Markov chain models are relevant to experiments with real problem instances. For a few small probleminstances we show complete search spaces and derive corresponding Markov chains. With these in hand, we compare(i) bounding hitting time results derived from idealized trap Markov chain models; (ii) analytical hitting time resultsderived from Markov chain models (which were created from real problem instances along with the behavior of SIM-PLESLS); (iii) real observed SGS run times for the same problem instances; and (iv) polynomial regression resultsfor the SGS run times A key point relating Markov chain models to classes of real problem instances is suggestedby the following: Increasing problem instance hardness as controlled by C/V -ratio corresponds, roughly speaking,to increasing the size of the trap in a trap Markov chain. Consequently, mixtures of problem instances that are easyon average (small C/V and small traps) should be solved by greedier (less noisy) SLS algorithms than mixtures ofproblem instances that are hard on average (large C/V and large traps). In experiments with synthetic problem in-stances, we indeed observe these patterns as C/V is varied. To complement our experiments with synthetic problems,\fO.J. Mengshoel / Artificial Intelligence 172 (2008) 955–990957we also investigate BNs from applications while also using more advanced initialization and noise algorithms. Here,we found that noise can sometimes have a rather minor impact on SLS performance while in other cases the impactcan be dramatic. Generally, the empirical results support our Markov chain-based analysis.We believe this work is significant for the following reasons. First, by using Markov chain hitting time analysisand introducing an explicit noise parameter p, this research provides an improved understanding of what role noiseplays in stochastic local search. Such theoretical understanding has traditionally been limited [14,16,44], even thoughthere exists research based on Markov chains which explores the role of traps and local maxima in SLS [15]. Second,while the experimental results of SLS are very impressive, their empirical basis means that these algorithms are quitecomputationally intense to optimize [26]. We believe that this work paves the way for imp",
            {
                "entities": [
                    [
                        3324,
                        3352,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 409–421www.elsevier.com/locate/artintDiscovering the linear writing order of a two-dimensional ancienthieroglyphic scriptShou de Lin ∗, Kevin KnightInformation Sciences Institute, University of Southern California, USAReceived 8 February 2005; received in revised form 28 November 2005; accepted 6 December 2005Available online 17 January 2006AbstractThis paper demonstrates how machine learning methods can be applied to deal with a real-world decipherment problem wherevery little background knowledge is available. The goal is to discover the linear order of a two-dimensional ancient script, Hi-eroglyphic Luwian. This paper records a complete decipherment process including encoding, modeling, parameter learning,optimization, and evaluation. The experiment shows that the proposed approach is general enough to recover the linear orderof various manually generated two-dimensional scripts without needing to know in advance what language they represent and howthe two-dimensional scripts were generated. Since the proposed method does not require domain specific knowledge, it can beapplied not only to language problems but also order discovery tasks in other domains such as biology and chemistry. 2005 Elsevier B.V. All rights reserved.Keywords: Ancient script; Decipher; Luwian; Hieroglyphic; Unsupervised learning; Estimation-maximization; Linear order; Discovery; Writingsystem; Natural language process1. IntroductionThe Hieroglyphic Luwian script is a two-dimensional script discovered in middle Asia, preserved on rock datingback to 700–1300 BCE [4]. Unlike modern scripts that possess a clear linear order for reading (for example, left-to-right, top-down for English), the Luwian symbols seem not to be arranged regularly enough to indicate any specificwriting order (e.g., see the upper line in Fig. 1). This paper discusses a general process to discover the writing order(e.g., see the second line in Fig. 1) for this type of two-dimensional script.So far, there is no convincing evidence about the precise order of this script. A linguistic authority says “it is asystem which may leave in doubt the correct order of reading” [4]. Up to the present day there has not yet beenmuch effort focused on applying machine learning methods for decipherment. Knight and Yamada [5] propose a gen-eral framework to discover the text-to-speech relationships for unknown scripts by applying a finite-state transducermodel together with the EM (Expectation-Maximization) algorithm to learn parameters. Sproat [7] claims that theorthography of a language represents a consistent level of linguistic representation, and the mapping from this levelto surface spelling is a regular relation. He proposes to use a rule-based system (realized by finite state automata)* Corresponding author.E-mail addresses: sdlin@isi.edu (S. de Lin), knight@isi.edu (K. Knight).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.12.001\f410S. de Lin, K. Knight / Artificial Intelligence 170 (2006) 409–421Fig. 1. A snapshot of the two-dimensional Luwian script (upper) and one sample linear order of symbols (lower).to encode the regularities. Both works aim at finding the relationships among writing symbols and their sounds. Wehave not yet seen computational approaches for order discovery in any ancient writing system, including HieroglyphicLuwian.The challenges of discovering the linear order for unknown scripts are threefold:(1) Modeling: Without any knowledge or examples of linear order, we have to abandon enlisting help from eithersupervised training or rule writing. This task is as difficult as asking somebody who knows no English to figureout the linear order of a set of English characters written in two-dimensional manner. The challenge lies in howto model this problem as something that can be handled by machine using unsupervised techniques.(2) Complexity: In general the number of possible orderings increases exponentially with the number of symbols.Hence we face a huge search space.(3) Evaluation: As with all kinds of human discovery problems, there is no easily obtained linear data for this script,which makes it hard to verify the results.The next section describes how we model the linear-order discovery task as an unsupervised learning problem.We also provide an intuition indicating how the proposed approach resembles what human beings might do for thistask. In Section 3, we show how the model described in Section 2 can be applied (and refined) to deal with a real-world problem. Additionally, we will discuss how to reduce the search complexity to polynomial. We describe severalevaluation strategies and results in Section 4 and conclude in the last section.2. ModelingOur general strategy is as follows: we model the way the Luwians generated the script with Shannon’s noisy-channel model [6], which allows us to further translate the problem into a traveling-salesman-like problem. We thenapply the EM algorithm to learn the parameters (i.e., a Luwian language model) within the model. Finally we applythese parameters to compute the associated probability for each plausible order in order to extract the one with thehighest probability as the result.2.1. Noisy channel modelWe start by exploiting the noisy-channel model as shown in Fig. 2.We assume that the ancient people have the original linear script in mind before writing, and then they carve thescripts in a two-dimensional manner on the stone. When time passed (as did the Luwians), the only remains are thetwo-dimensional scripts on the rocks as observed. Based on Shannon’s model, the original linear script is the inputX to the noisy channel. The way the Luwians wrote down the script can be treated as a noisy channel that perturbsthe original one-dimensional source text X into a two-dimensional appearance Y . This noisy channel (represented asP(Y | X) here) is a black box to us since we do not know how those two-dimensional scripts were generated. Once\fS. de Lin, K. Knight / Artificial Intelligence 170 (2006) 409–421411Fig. 2. The noisy channel model representing how Luwian people wrote the script.Fig. 3. (a) The two-dimensional English. (b)–(d) Three arbitrary linear orders.the problem is modeled as a noisy channel, it is obvious that this order-discovery task can be represented as findingthe X that maximizes P(Y | X).This formula can further be decomposed into two components, P(X) and P(Y | X), by Bayes’ rule (see Eq. (1)).1P(X) can be generated by the language model of the script, which essentially stands for how frequently this scriptshould occur in a large sample of ancient Luwian literature. P(Y | X) can be treated as the noisy channel that representshow the Luwian people wrote down the script. Shannon’s model together with Bayes’ rule tells us that the desiredlinear order X should not only appear frequently in the Luwian literature (i.e., high P(X)), but also possess a highchance of producing the observed two-dimensional script Y .2.2. Linear order for known languageWe would like to demonstrate the idea described in Section 2.1 with a toy example: we assume that we are askedto find the linear order of a known two-dimensional language, say the English in Fig. 3(a), without being told how itwas generated.argmaxXp(X | Y ) = argmaxp(X) ∗ P(Y | X)X(1)According to Eq. (1), we need to search for an order X that maximizes P(X) ∗ P(Y | X). In this example, we ignoreP(Y | X), since we assume there is no indication of how this script was generated. Therefore we only need to maximizeP(X). In other words, whichever permutation of sequence appears to be valid English is a plausible candidate. Peoplecan scramble the characters mentally, and sooner or later they will find out it probably means “good job!” (Fig. 3(b)),as this permutation occurs more frequently to English speakers than others (e.g., gdbojoo! in 3(c) and goodj!ob in3(d)). What happens in the human mind mimics the procedure of maximizing P(X), where meaningful sentencespossess higher P(X) than meaningless ones.This toy example demonstrates that our model, to some extent, reflects how human beings solve the same puzzle.A machine can also perform such an analysis, if it knows which English orders are more probable than others. One wayto compute this is to exploit an n-gram English language model, which can be easily obtained by a simple statisticalanalysis of a large English corpus. Assuming that English letter-bigram probabilities are given, we can program themachine to enumerate all possible orders and compute their associated probabilities (e.g., p(X) = p(goodjob!) =p(g) ∗ p(o | g) ∗ p(o | o) ∗ p(d | o) ∗ p(j | d) ∗ p(b | j) ∗ p(b | o) ∗ p(! | b)). After that, we extract the sequence withthe highest probability as the result. The probability of 3(c) and 3(d) should be much lower than 3(b) since p(d | b)in 3(c) and p(o |!) in 3(d) do not occur too often in English. In this sense, if the bigram language model is known,then the linear-order discovering problem is similar to the traveling salesman problem in a graph (where the nodesrepresent letters and the weighted links represent the corresponding bigram probability between letters), except thatthe salesman does not have to go back to the origin.1 In fact there should be an extra term P(Y ) in Bayes’ rule deduction. However, P(Y ) can be ignored in the optimization process since it modelsthe probability of the observed output, which should be identical for all X.\f412S. de Lin, K. Knight / Artificial Intelligence 170 (2006) 409–421Fig. 4. Applying EM to refine the language model and P(X) recursively.2.3. EM for unknown scriptsSection 2.2 shows that it is possible to recover the linear order of a known script from its two-dimensional form.However, this approach is not applicable to the decipherment of the Luwian script, whose language model is unknown.On the other hand, when the order probability P(X) is known, it is possible to apply the met",
            {
                "entities": [
                    [
                        2975,
                        3003,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 298 (2021) 103502Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExplaining individual predictions when features are dependent: More accurate approximations to Shapley values ✩Kjersti Aas∗, Martin Jullum, Anders LølandNorwegian Computing Center, P.O. Box 114, Blindern, N-0314 Oslo, Norwaya r t i c l e i n f oa b s t r a c tArticle history:Received 3 October 2019Received in revised form 5 January 2021Accepted 29 March 2021Available online 31 March 2021Keywords:Feature attributionShapley valuesKernel SHAPDependenceExplaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from such models by learning simple, interpretable explanations. Shapley value is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent. Since Shapley values currently suffer from inclusion of unrealistic data instances when features are correlated, the explanations may be very misleading. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionInterpretability is crucial when a complex machine learning model is to be applied in areas such as medicine [1], fraud detection [2] or credit scoring [3]. In many applications, complex hard-to-interpret machine learning models like deep neural networks, random forests and gradient boosting machines are currently outperforming the traditional, and to some extent interpretable, linear/logistic regression models. However, often there is a clear trade-off between model complexity and model interpretability, meaning that it is often hard to understand why these sophisticated models perform so well. This lack of explanation constitutes a practical issue – can I trust the model? [4], and a legal issue – those who develop the model can be required by law to explain what the model does to those who are exposed to automated decisions (the General Data Protection Regulation [5]). In response, a new line of research has emerged that focuses on helping users to interpret the predictions from advanced machine learning methods.Existing work on explaining complex models can be divided into two main categories; global and local explanations. The former tries to describe the model as a whole, in terms of which variables/features that influenced the general model the most. Two common methods for such an overall explanation are permutation based feature importance [6] or partial depen-dence plots [7]. Local explanations, on the other hand, try to identify how the different input variables/features influenced a specific prediction/output from the model, and are often referred to as individual prediction explanation methods. Such ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail addresses: kjersti.aas@nr.no (K. Aas), martin.jullum@nr.no (M. Jullum), anders.loland@nr.no (A. Løland).https://doi.org/10.1016/j.artint.2021.1035020004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fK. Aas, M. Jullum and A. LølandArtificial Intelligence 298 (2021) 103502explanations are particularly useful for complex models which behave rather different for different feature combinations, meaning that the global explanation is not representative for the local behavior.Local explanation methods may further be divided into two categories: model-specific and model-agnostic (general) ex-planation methods. In this paper the focus is on the latter. The methods in this category usually try to explain individual predictions by determining simple, interpretable explanations of the model specifically for a given prediction. Three exam-ples are Explanation Vectors [8], LIME (Local Interpretable Model-agnostic Explanations) [4] and Shapley values [9–11]. The latter approach, which builds on concepts from cooperative game theory [12], has a series of desirable theoretical properties [11].The Shapley value is a method originally invented for assigning payouts to players depending on their contribution towards the total payout. In the explanation setting, the features are the players and the prediction is the total payout. In this framework, the difference between the prediction and the average prediction is perfectly distributed among the features. This property distinguishes Shapley values from other methods like for example LIME, which does not guarantee perfectly distributed effects. It should be noted that LIME and Shapley values actually explain two different things. For instance, if the prediction to be explained is the probability of person A crashing his car, the sum of the Shapley values for all features is equal to the difference between this prediction and the mean probability of a person crashing his car, where the mean is taken over all persons having a driver license. The sum of the LIME values is also equal to the difference between this prediction and a mean probability, but here the mean is taken over all persons “similar to” person A. That is, Shapley values explain the difference between the prediction and the global average prediction, while LIME explains the difference between the prediction and a local average prediction. Appropriate model explanations should be consistent with how humans understand that model. In their study, [11] found a much stronger agreement between human explanations and Shapley values than with LIME.Shapley values have also been used for measuring global feature importance. For instance, it has been used to partition the R2 quantity among the d features in a linear regression model (“Shapley regression values”), both assuming independent features [13], and more recently also for dependent features [14–16]. A general Shapley framework for global additive importance measures is suggested by [17].The main disadvantage of the Shapley value is that the computational complexity grows exponentially and becomes in-tractable for more than, say, ten features. This has led to approximations like the Shapley Sampling Values [9,10] and Kernel SHAP [11]. The latter requires less computational power to obtain a similar approximation accuracy. Hence, in this paper, the focus is on the Kernel SHAP method. While having many desirable properties, this method assumes feature independence. In observational studies and machine learning problems, it is very rare that the features are statistically independent, meaning that the Shapley value methods suffer from inclusion of predictions based on unrealistic data instances when features are correlated. This is the case even if a simple linear model is used.The main contribution of this paper is to extend the Kernel SHAP method to handle dependent features. The methodology has been implemented in the R-package shapr available on CRAN [18]. Our paper is a revised version of an unpublished paper [19], which, to the best of our knowledge, was the first to address and account for dependence within Shapley value based individual prediction explanation.Later there has been several papers discussing the difference between our approach and the original Kernel SHAP method, termed respectively the observational and the interventional approach in the succeeding literature. Lundberg and Lee [11] advocate the observational approach, but uses the interventional approach for computational reasons. Janzing et al. [20] argue for a causal interpretation of Shapley values, where they replace conventional “conditioning by observation” with “conditioning by intervention”, as in Pearl’s do-calculus [21]. Frye et al. [22] suggest so-called asymmetric Shapley val-ues as a way to incorporate causal knowledge in the real world by restricting the possible permutations of the features when computing the Shapley values to those consistent with a partial causal ordering. In line with our approach, they then apply conventional conditioning by observation to make sure that the explanations respect the multivariate distribution of the data, which they denote the “data manifold”. Heskes et al. [23] generalize the work on causal Shapley values further, partly based on our approach. They define our approach as “symmetric conditional Shapley values”. Chen et al. [24] argue that neither is preferable in general, but that the choice between the observational (“true to the data”) or interventional (“true to the model”) approach is application dependent.All the above-mentioned approaches are model-agnostic in the sense that they can be used to explain any machine learning method. In addition to these methods, there is a method called TreeSHAP [25] which is specially designed for tree ensemble methods like XGBoost [26]. According to the authors, TreeSHAP accounts for some of the feature dependence, but not all. As will be apparent from our simulation experiments, this method can be inaccurate when the features are dependent.The rest of this paper is organized as follows. Section 2 reviews the Shapley values and the Kernel SHAP method. Sec-tion 3 contains the main contribution of the paper, that is the proposed approaches for accounting for the dependence, while Section",
            {
                "entities": [
                    [
                        3698,
                        3726,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1757–1789Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecentralized MDPs with sparse interactionsFrancisco S. Melo a,∗, Manuela Veloso ba GAIPS – INESC-ID, TagusPark, Edifício IST, 2780-990 Porto Salvo, Portugalb Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 26 April 2010Received in revised form 29 April 2011Accepted 7 May 2011Available online 10 May 2011Keywords:Multiagent coordinationSparse interactionDecentralized Markov decision processesCreating coordinated multiagent policies in environments with uncertainty is a challengingproblem, which can be greatly simplified if the coordination needs are known to belimited to specific parts of the state space. In this work, we explore how such localinteractions can simplify coordination in multiagent systems. We focus on problems inwhich the interaction between the agents is sparse and contribute a new decision-theoreticmodel for decentralized sparse-interaction multiagent systems, Dec-SIMDPs, that explicitlydistinguishes the situations in which the agents in the team must coordinate from thosein which they can act independently. We relate our new model to other existing modelssuch as MMDPs and Dec-MDPs. We then propose a solution method that takes advantageof the particular structure of Dec-SIMDPs and provide theoretical error bounds on thequality of the obtained solution. Finally, we show a reinforcement learning algorithm inwhich independent agents learn both individual policies and when and how to coordinate.We illustrate the application of the algorithms throughout the paper in several multiagentnavigation scenarios.© 2011 Elsevier B.V. All rights reserved.1. IntroductionDecision-theoretic models, such as Dec-MDPs and Dec-POMDPs, provide a rich framework to tackle decentralizeddecision-making problems. However, using these models to create coordinated multiagent policies in environments withuncertainty is a challenging problem, even more so if the decision-makers must tackle issues of partial observability. Assuch, solving finite-horizon Dec-POMDPs is a NEXP-complete problem and thus computationally too demanding to solveexcept for the simplest scenarios.Recent years have witnessed a profusion of work on Dec-POMDP-related models that aim at capturing some of thefundamental features of this class of problems, such as partial observability, without incurring the associated computationalcost. In this paper, we contribute to this area of research, and introduce a new model for cooperative multiagent decision-making in the presence of partial observability. Our model is motivated by the observation that, in many real-world scenarios,the tasks of the different agents in a multiagent system are not coupled at every decision step but only in relativelyinfrequent situations. We refer to such problems as having sparse interactions.Multi-robot systems provide our primary motivation, as the interaction among different robots is naturally limited byeach robot’s physical boundaries, such as workspace or communication range, and limited perception capabilities. Therefore,when programming a multi-robot system to perform some task, one natural approach is to subdivide this task into smallertasks that each robot can then execute autonomously or as part of a smaller group. As an example, consider the scenarioin Fig. 1. In this scenario, three robots must navigate to their goal locations, marked with dashed lines. While Robot 3 can* Corresponding author.E-mail address: fmelo@inesc-id.pt (F.S. Melo).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.05.001\f1758F.S. Melo, M. Veloso / Artificial Intelligence 175 (2011) 1757–1789Fig. 1. Example of a simple navigation task.navigate to its goal, disregarding the remaining robots, Robots 1 and 2 need to coordinate so as not to cross the narrowdoorway simultaneously. However, this coordination needs only occur around the doorway.Other examples include problems of sequential resource allocation, in which groups of agents must interact only tothe extent that they need to share some common resource. In this context, several methods have been proposed thatleverage sparse interactions by decomposing the global problem into several smaller local problems that can be solvedmore efficiently, and then combining the obtained solutions [1,2]. Such approaches, however, are not particularly concernedwith partial observability issues. Additional examples include problems of task allocation, where the different agents ina multiagent system are assigned to different subtasks, and the interactions between the agents when performing suchsubtasks is localized to small regions of the joint state space [3]. Such problems include emergency response scenarios,where emergency teams are assigned different subtasks (for example, assisting different victims) and interact only in specificlocalized situations.Several approaches have exploited simplified models of interaction in multiagent settings. For example, learning tasksinvolving multiple agents can be partitioned in a state-wise manner, allowing different agents to independently learn theresulting “smaller tasks” [4]. Similarly, a hierarchical learning algorithm can be used that considers only interactions betweenthe different agents at a higher control level, while allowing the agents to learn lower level tasks independently [5]. Otherworks use coordination graphs to compactly represent dependences between the actions of different agents, thus capturingthe local interaction between them [6,7]. Local interactions have also been exploited to minimize communication duringpolicy execution [8] and in the game-theoretic literature to attain compact game representations. Examples include graphicalgames [9] and action-graph games [10].In this article we consider Dec-MDPs with sparse interactions, henceforth Dec-SIMDPs. Dec-SIMDPs leverage the indepen-dence between agents to decouple the decision process in significant portions of the joint state space. In those situationsin which the agents interact—the interaction areas—Dec-SIMDPs rely on communication to bring down the computationalcomplexity of the joint decision process. Dec-SIMDPs balance the independence assumptions with observability: in anygiven state, the agents are either independent or can share state information (e.g., by communicating).1 A related modelhas recently been proposed under the designation of distributed POMDPs with coordination locales [13]. We postpone untilSection 6 a more detailed discussion of this and other related models.The contributions of this article are threefold. We provide a precise formalization of the Dec-SIMDP model and discussthe relation with well-established decision-theoretic models such as Dec-MDPs, MMDPs and MDPs. We then contribute twonew algorithms that exhibit significant computational savings when compared to existing algorithms for Dec-SIMDPs, andillustrate their application in several simple navigation tasks. Finally, we investigate the influence of interaction areas in theperformance of a multiagent system and contribute a new learning algorithm that allows each agent in one such system toindividually learn those interaction areas.2. Decision-theoretic models for multiagent systemsWe now review several standard decision-theoretic models that are relevant for our work [14–16]. We start with singleagent models, namely Markov decision processes (MDPs) and their partially observable counterparts (POMDPs) before mov-ing to multiagent models such as multiagent MDPs (MMDPs) and their partially observable counterparts (Dec-POMDPs). Weestablish the notation we use and review some fundamental concepts of later relevance.To fully specify the different models in this section, we should explicitly include the initial state x0 or a distributionthereof. However, in order to avoid cluttering the notation, we omit the explicit reference to this initial state, with theunderstanding that one such state is implicit.1 Both independence assumptions and communication can significantly bring down the computational complexity in Dec-POMDP related models [11,12].\fF.S. Melo, M. Veloso / Artificial Intelligence 175 (2011) 1757–178917592.1. Markov decision processesA Markov decision process (MDP) describes a sequential decision problem in which a single agent must choose an action atevery time step to maximize some reward-based optimization criterion. We use MDPs in the Dec-SIMDP model proposed inSection 3 to describe an agent in those situations where its actions are independent of other agents—i.e., in those situationswhere the agent can be modeled individually.Formally, an MDP is a tuple M = (X, A, P, r, γ ), where X represents the finite state space, A represents the finiteaction space, P(x, a, y) represents the transition probability from state x to state y when action a is taken, and r(x, a)represents the expected reward for taking action a in state x. The scalar γ is a discount factor.A Markov policy is a mapping π : X × A → [0, 1] such that, for all x ∈ X ,(cid:2)a∈Aπ (x, a) = 1.Solving an MDP consists of determining a policy π so as to maximize, for all x ∈ X ,V π (x) = EπX(t), A(t)(cid:3)(cid:4)γ tr∞(cid:2)t=0(cid:7)(cid:5) (cid:6)(cid:6) X(0) = x,where X(t) denotes the state at time step t, A(t) denotes the action taken at that time instant such that(cid:8)(cid:6)(cid:6) H(t) = h(cid:9)(cid:8)(cid:6)(cid:9)(cid:6) X(t) = xP= PA(t) = a= π (x, a),where H(t) = { X(0), A(0), . . . , X(t − 1), A(t − 1), X(t)} is the random variable corresponding to the history of the MDP up totime t, and h denotes a particular realization of H(t) such that X(t) = x. We write A(t) ∼ π to denote the above dependenceof A(t) on the policy π . We define the Q -function associated with a policy π asA(t) = a(cid:3)Q π (x, a) = Eπ(cid:4)",
            {
                "entities": [
                    [
                        3749,
                        3777,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 80–103Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTeaming up humans with autonomous synthetic charactersRui Prada∗, Ana PaivaIST-Technical University of Lisbon and INESC-ID, Avenida Prof. Cavaco Silva – Taguspark, 2744-016 Porto Salvo, Portugala r t i c l ei n f oa b s t r a c tArticle history:Received 3 August 2007Received in revised form 17 August 2008Accepted 24 August 2008Available online 7 September 2008Keywords:Group dynamicsTeamworkSocial intelligenceAutonomous synthetic charactersBelievabilityComputer–human interactionAutonomous synthetic characters have the potential to promote the social engagement ofusers in virtual environments, enhancing their interaction experience. In computer games,for example, poor interaction with game characters can drastically detract from the gamingexperience, making the design of autonomous synthetic characters an important issue. Inparticular, in Role Playing Games (RPGs), for example, users and autonomous charactersoften perform in a group. Usually, the role of such characters is very limited since theylack the social skills to perform coherently in group scenarios.The goal of the work presented here is to endow autonomous synthetic characters withsocial skills that allow them to perform in groups with human members. However, tosuccessfully achieve this, it is not enough to assure that the characters behave in a coherentmanner from an individual perspective or that they are able to perform the group taskoptimally. It is also necessary that the autonomous characters exhibit behaviours that arecoherent with the group’s composition, context and structure.For this reason, we have developed a model to support group dynamics of autonomousinspired by theories developed in human socialsynthetic characters (SGD model)psychological sciences. This model defines the knowledge that each individual should buildabout the others and the group, and how this knowledge drives their interactions. Themodel was used in a collaborative computer game that was tested with users. The resultsshowed that the model had a positive effect on the users’ social engagement, namely, ontheir trust and identification with the group.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe creation of autonomous synthetic characters has been widely studied in the past years, especially because such char-acters can improve the interaction of users with virtual environments [7]. For this reason, autonomous synthetic charactershave been used in several different domains such as entertainment [11,45], business [9] and education [59,65]. They havebeen particularly important in computer games that make use of narrative, such as Role Playing Games (RPGs), because theyconstitute the main driving force to create successful narrative experiences that improve gameplay [39,66].The crucial issue in designing autonomous synthetic characters is making them believable or creating the “illusion oflife” for the user [8]. In other words, autonomous synthetic characters must be coherent with the users’ expectations.The work presented here focuses on believability issues of autonomous synthetic characters when they interact as agroup. The work is focused on groups with few members (small groups) who are committed to a collaborative task andwithout a strong organisational structure. Thus, we are not concerned with large groups such as crowds or complex societies.In addition, our goal is to engage the user as an active member of the group.* Corresponding author.E-mail addresses: rui.prada@gaips.inesc-id.pt (R. Prada), ana.paiva@gaips.inesc-id.pt (A. Paiva).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.006\fR. Prada, A. Paiva / Artificial Intelligence 173 (2009) 80–10381Typically, autonomous characters lack the necessary social skills to interact in a group. Therefore, their role in the groupis very restricted, and their autonomy is limited. For example, in RPGs, the autonomous characters only take secondaryroles, such as a salesperson, while the main characters are controlled by the user.Moreover, most of the studies conducted on the believability of autonomous synthetic characters are focused on theinteractions of a single user with a single character [9,57]. However, in group scenarios, it is not enough to ensure that thecharacters behave in a coherent manner from an individual perspective; it is also necessary that they exhibit behaviours thatare coherent with the group’s composition, context and structure. On the other hand, approaches to create team-orientedautonomous agents focus primarily on the optimal results of the group [46,70,77]. Although the group’s performance mayaffect the experience of users when interacting in a group, their perception about their experience is highly influenced bytheir social identification and their trust of the group [3,22]. In fact, these two factors are closely related to the satisfactionof people in group interactions [4].In order to achieve such an experience and properly engage users with the group, we argue that autonomous members’behaviours cannot be solely driven by their need to solve the task but also by the socio-emotional dimensions of the group,such as the structure of interpersonal relations.To prove this, we have developed a model for group dynamics (SGD model) that allows each individual character toreason about other characters and the group. This model was inspired by theories developed in human social psychologicalsciences and is driven by a characterisation of the different types of interactions that may occur in the group, taking intoaccount the socio-emotional interactions as well as the task-related ones.We have implemented the model into the behaviour of autonomous synthetic characters that collaborate with the userin the resolution of tasks within a virtual environment (a collaborative game). This game was developed with the purposeof testing the effects of our model in users’ interaction experiences. The results of the experiment showed that the modelhad a positive effect on the users’ trust and social identification with the group.This paper is organised as follows. First, we discuss related work concerning the interaction of autonomous characters in agroup. Then, we present the fundamentals of group dynamics on which we grounded our model followed by the descriptionof the model itself. Then, we describe the computer game that we developed to test our model and the experiment thatwas conducted to assess the effects of the model in the users’ interaction experience. We finish with some conclusions andcomments regarding future work.2. Related workThe problem of multiple autonomous synthetic agents that interact in a group has been previously addressed by severalresearchers. The focus of their approaches can be seen in two different perspectives: (1) centred on believability issues ofthe group interactions or (2) centred on the efficiency of the group’s performance. We will briefly describe some of themost relevant work and make some comments regarding the focus of the work presented in this paper.The first example of the first perspective can be found in Reynolds’ Boids [63], which implements a flocking behaviour ina group of flying creatures. In the same line of work, we can additionally find research concerning the generation of crowds[53] that is often used in commercial systems for film creation. One well-known example of this is “The Lord of the Rings”film trilogy [54], which includes numerous fighting scenes involving armies of thousands of warriors, most of these beingplayed by synthetic actors generated by the MASSIVE1 platform.The Boids’ flocking behaviour and crowd generation make use of emergent group dynamics and result in a believablelife-like group behaviour. However, agents in these examples do not have deep social awareness and lack the ability to buildsocial relations, which we believe to be essential for the interaction with a user. In addition, these groups do not have anexplicit common goal.Guye-Vuilleme [28] has extended the work on the generation of the behaviour of crowds by introducing a model for thesimulation of the movement and interaction of individuals driven by the group’s social context. This includes behavioursfor social avoidance of collisions, social approach and the calculation of suitable interaction distances and angles. The socialcontext consists of a model of interpersonal relationships of individuals. Although incorporating interpersonal relations toinfluence the autonomous characters’ behaviours, Guye-Vuilleme’s crowds cannot be seen as performing teamwork, sincethey do not have an explicit collaborative task.Another example is the AlphaWolf [71] system, which simulates the behaviour of a pack of six grey wolves. In thissystem, the different synthetic characters are able to build domination-submission relationships. These relations are builtin the form of emotional memories that drive the characters’ behaviour. In addition, three users can interact with thesystem and influence the behaviour of three of the wolves. AlphaWolf has successfully implemented a believable simulationof group interactions in a pack of wolves, and it has engaged the user in such interactions. However, the user and thesynthetic characters do not engage in the resolution of a collaborative task and do not have a strong notion of group.Schmitt and Rist [67] developed a model of virtual group dynamics for small group negotiations. In their system, usersdelegate the task of scheduling their appointment meetings to a virtual agent. The agents will later meet in an arena andnegotiate the times and dates of the meetings. Each agent has an individual personality and builds social attraction relations1 For more details on MASSIVE, please check http://www.massivesoftware.com.\f82R. Prada, A. Paiva / Artificial Intelligence 173",
            {
                "entities": [
                    [
                        3766,
                        3794,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1579–1604Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHeuristics for planning with penalties and rewards formulated in logicand computed through circuitsBlai Bonet a,∗, Héctor Geffner ba Departamento de Computación, Universidad Simón Bolívar, Caracas, Venezuelab Departamento de Tecnología, ICREA & Universitat Pompeu Fabra, 08003 Barcelona, Spaina r t i c l ei n f oa b s t r a c tArticle history:Received 17 August 2007Received in revised form 2 March 2008Accepted 6 March 2008Available online 29 March 2008Keywords:PlanningPlanning heuristicsPlanning with rewardsKnowledge compilationThe automatic derivation of heuristic functions for guiding the search for plans is afundamental technique in planning. The type of heuristics that have been considered sofar, however, deal only with simple planning models where costs are associated withactions but not with states. In this work we address this limitation by formulating amore expressive planning model and a corresponding heuristic where preferences in theform of penalties and rewards are associated with fluents as well. The heuristic, that isa generalization of the well-known delete-relaxation heuristic, is admissible, informative,but intractable. Exploiting a correspondence between heuristics and preferred models,and a property of formulas compiled in d-DNNF, we show however that if a suitablerelaxation of the domain, expressed as the strong completion of a logic program withno time indices or horizon is compiled into d-DNNF, the heuristic can be computed forany search state in time that is linear in the size of the compiled representation. Thisrepresentation defines an evaluation network or circuit that maps states into heuristicvalues in linear-time. While this circuit may have exponential size in the worst case, asfor OBDDs, this is not necessarily so. We report empirical results, discuss the applicationof the framework in settings where there are no goals but just preferences, and illustratethe versatility of the account by developing a new heuristic that overcomes limitations ofdelete-based relaxations through the use of valid but implicit plan constraints. In particular,for the Traveling Salesman Problem, the new heuristic captures the exact cost while thedelete-relaxation heuristic, which is also exponential in the worst case, captures only theMinimum Spanning Tree lower bound.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe automatic derivation of heuristic functions from problem descriptions in Strips and other action languages has beenone of the key developments in recent planning research [14,51]. Provided with these heuristics, the search for plans be-comes more focused, and if the heuristics are admissible (do not overestimate), the optimality of plans can be ensured[55]. The type of heuristics that have been considered so far, however, have serious limitations. Basically they are eithernon-admissible [12,40] or not sufficiently informative [39], and in either case they are restricted to cost functions whereplan costs depend on actions but not on states. As a result, the tradeoffs that can be expressed are limited; in particular, itis not possible to state a preference for achieving or avoiding an atom p in the way to the goal, or take this preference intoaccount when searching for plans.* Corresponding author.E-mail addresses: bonet@ldc.usb.ve (B. Bonet), hector.geffner@upf.edu (H. Geffner).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.004\f1580B. Bonet, H. Geffner / Artificial Intelligence 172 (2008) 1579–1604In this work, we address these limitations by formulating the derivation of heuristic functions in a logical framework.We have shown elsewhere that the heuristic represented by the planning graph [11] can be understood as a precise formof deductive inference over the stratified theory that encodes the problem [31]. Here our goal is not to reconstruct anexisting heuristic but to use a logical formulation for producing a new one. The advantages of a logical framework aretwo: the derivation of heuristic information is an inference problem that can be made transparent with the tools of logic,and powerful algorithms have been developed that make certain types of logical inferences particularly effective. The latterincludes algorithms for checking satisfiability [52], computing answer sets [61], and compiling CNF formulas into tractablerepresentations [25].Here we consider preferences over actions a and fluents p that are expressed in terms of real costs c(a) and c(p). Actioncosts are assumed to be non-negative, while fluent costs can be positive or negative. Negative costs express rewards. Thecost of a plan is assumed to be given by the sum of the action costs plus the sum of the atom costs for the atoms madetrue by the plan. We are interested in computing a plan with minimum cost. This is a well defined task, which as we willsee, remains well-defined even when there are no goals but just preferences. In such a case, the best plans simply try tocollect rewards while avoiding penalties, and if there are no rewards, since action costs are non-negative, the best plan isempty.The cost model is not fully general but is considerably more expressive than the one underlying classical planning. Aswe will see, the model generalizes recent formulations that deal with over-subscription or soft goals [60,64], which in oursetting can be modeled as terminal rewards, rewards that are collected when the propositions hold at the end of the plan.On the other hand, the costs and rewards are combined additively, so unlike other recent frameworks [8], partially-orderedpreferences are not handled.+cThe definition of the planning model is motivated by the desire to have additional expressive power and a principledand feasible computational approach for dealing with it. For this, we want a useful heuristic, with a clear semantics, capableof capturing interesting cost tradeoffs, and a feasible algorithm for computing it. We will be able to express in the model,for example, navigation problems where coins of different values are to be collected by avoiding as much as possible certaincells, or blocks-world problems where a tallest tower is to be constructed, or where the number of blocks that touch thetable is to be minimized. In order to test the effectiveness of the approach we will also consider classical planning taskswhere we will assess the approach empirically in relation to existing heuristics and planners.+cThe heuristic hthat we develop is simple and corresponds to the optimal cost of the relaxed problem where thedelete-lists of all actions are ignored [12]. Since searching with this heuristic, even in the classical setting, involves anintractable computation in every state s visited [15], planners such as HSP and FF resort to polynomial but non-admissibleapproximations [12,40]. In this work, while considering the more general cost structure, we take a different approach: wefor each search state, but pay the price of an intractable computation only once, as preprocessing.compute the heuristic hThis preprocessing yields what can be deemed as an evaluation network or circuit where we can plug any search stateand obtain its heuristic value in linear time. Of course, the time to construct this evaluation network and the size of thenetwork may both be exponential, yet this is not necessarily so. The evaluation network, indeed, is nothing else but thedirected acyclic graph that results from compiling a relaxation of the planning theory into d-DNNF, a form akin to OBDDsintroduced in [21,22] that renders efficient a number of otherwise intractable queries and transformations [25]. The heuristicvalues are then obtained as the cost of the ‘best’ models, which can be computed in linear time once the relaxed theory iscompiled into d-DNNF [26].The framework defined by the formulation of the heuristic hin terms of logic and their computation in terms ofcompiled d-DNNF representations is then evaluated empirically over a broad set of problems, where the heuristic is used toguide the search for optimal plans.+cAn important characteristic of the logical encoding of the delete-relaxation heuristic is that unlike the standard logicalencodings of planning problem [44], no explicit temporal stratification in the form of time indices or horizons is needed. Thisfollows from the use of positive logic programs for expressing the effects of the actions as an intermediate representation,and the focus on the models that are minimal in the sense that true fluents must have a well-founded justification. Suchminimal models capture an implicit stratification that is in correspondence with the explicit temporal stratification adoptedby the standard logical approaches to planning. A concrete result of this implicit stratification is that the resulting heuristicestimates the true optimal cost of the problem, and not the optimal cost given a specific temporal horizon.The paper is a revised version of [13] where the results are extended to a new class of heuristics that complement theuse of the delete-relaxation with valid plan constraints.1 Valid plan constraints are formulas defined over the set of actionand fluent symbols that are satisfied by some optimal plan. Making valid plan constraints explicit in a problem hence doesnot affect the true cost of a problem but can boost the value of the heuristic while keeping it admissible. We show forexample the new heuristic is optimal for problems like the Traveling Salesman Problem (TSP), where the delete-relaxation+c , which is also exponential in the worst case (unless P = NP), yields only the Minimum Spanning Tree (MST)heuristic hlower bound (for references on the TSP and MST; see [18,48,56]).The plan for the paper is the following: we present in order the cost model, the heuristic h+c , the correspondence+c and",
            {
                "entities": [
                    [
                        3580,
                        3608,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 619–668Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDeterministic planning in the fifth international planning competition:PDDL3 and experimental evaluation of the plannersAlfonso E. Gerevini a,∗, Patrik Haslum b, Derek Long c, Alessandro Saetti a, Yannis Dimopoulos da Dipartimento di Elettronica per l’Automazione, Università degli Studi di Brescia, Brescia, Italyb NICTA & The Australian National University, Canberra, Australiac Department of Computer and Information Sciences, University of Strathclyde, Glasgow, UKd Department of Computer Science, University of Cyprus, Cyprusa r t i c l ei n f oa b s t r a c tArticle history:Received 7 November 2007Received in revised form 29 October 2008Accepted 31 October 2008Available online 21 November 2008Keywords:Automated planningPlanning systemsPDDLPlanning languagesKnowledge representation in planningPreferences in planningPlan constraintsInternational planning competitionBenchmarks for planningExperimental evaluation of planningsystemsThe international planning competition (IPC) is an important driver for planning research.The general goals of the IPC include pushing the state of the art in planning technology byposing new scientific challenges, encouraging direct comparison of planning systems andtechniques, developing and improving a common planning domain definition language, anddesigning new planning domains and problems for the research community. This paperfocuses on the deterministic part of the fifth international planning competition (IPC5),presenting the language and benchmark domains that we developed for the competition,as well as a detailed experimental evaluation of the deterministic planners that enteredIPC5, which helps to understand the state of the art in the field.We present an extension of pddl, called pddl3, allowing the user to express strong and softconstraints about the structure of the desired plans, as well as strong and soft problemgoals. We discuss the expressive power of the new language focusing on the restrictedversion that was used in IPC5, for which we give some basic results about its compilabilityinto pddl2. Moreover, we study the relative performance of the IPC5 planners in terms ofsolved problems, CPU time, and plan quality; we analyse their behaviour with respect tothe winners of the previous competition; and we evaluate them in terms of their capabilityof dealing with soft goals and constraints, and of finding good quality plans in general.Overall, the results indicate significant progress in the field, but they also reveal thatsome important issues remain open and require further research, such as dealing withstrong constraints and computing high quality plans in metric-time domains and domainsinvolving soft goals or constraints.© 2009 Elsevier B.V. All rights reserved.1. IntroductionThe international planning competition (IPC for short) is an important driver for research in AI planning that is bien-nially held in conjunction with the International Conference on Automated Planning and Scheduling. The general goals ofthe IPC include pushing the state of the art in planning technology by posing new scientific challenges, encouraging andconducting direct comparison of planning systems and techniques, developing and improving a common planning domaindefinition language, pddl [29,36,41], and designing new planning domains and problems for the research community thatare increasingly realistic. This paper focuses on the deterministic part of the fifth international planning competition (IPC5* Corresponding author.E-mail addresses: gerevini@ing.unibs.it (A.E. Gerevini), patrik.haslum@anu.edu.au (P. Haslum), derek.long@cis.strath.ac.uk (D. Long), saetti@ing.unibs.it(A. Saetti), yannis@cs.ucy.ac.cy (Y. Dimopoulos).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.012\f620A.E. Gerevini et al. / Artificial Intelligence 173 (2009) 619–668for short), which is the classical part of the competition addressing planning problems where the initial state is completelyspecified and the relevant effects of the available actions are deterministic. We present the language and benchmark do-mains developed for the competition, and a detailed experimental evaluation of the deterministic planners that enteredIPC5.While IPC5 shares the same general goals of the previous planning competitions, it has some important novel featuresmaking this event significantly different from the previous competitions [1,41,50,51]. In particular, the deterministic track ofIPC5 emphasises the importance of plan quality, which is crucial in many applications, but which previously did not receivesufficient attention. Motivated by a desire to capture plan quality, a significant new version of pddl, called pddl3, has beendesigned. pddl3 includes some new constructs that can better characterise plan quality by allowing the user to express bothstrong and soft constraints on the structure of the desired plans. pddl3 also includes soft problem goals through which wecan express over-constrained planning problems (called “over-subscription” problems in [15,23,62]).Plan trajectory constraints are particular linear temporal logic formulae expressing constraints on possible actions in theplans and on intermediate states reached by the plans (such constraints are also known as “temporally extended goals” [2,5]). Soft goals and constraints are preferences that we wish to satisfy in order to generate a good plan, but that do not haveto be achieved in order for the plan to be correct. Strong plan constraints, in contrast, express properties that the acceptableplans must satisfy. Moreover, they allow the user to provide control knowledge to domain-independent planners supportingthe extended pddl language. By adding them as goal conditions, we can prevent a planner from exploring parts of the planspace, as, e.g., in [3,48], possibly making its exploration faster or guiding the planner towards better quality solutions. Thisis not the way plan constraints were used in IPC5, but such possible use is another motivation for introducing them intopddl.Dealing with (strong or soft) plan trajectory constraints and soft goals poses a new challenge to fully automated planning.While soft constraints have been extensively studied in the CSP literature (e.g., [9,24,60]), only recently has the planningcommunity started to investigate them [14,15,21,53,62,63]. When using soft constraints and goals, it can be useful to givedifferent importance to them. For this purpose, pddl3 allows the domain modeler to assign different penalties to violatedconstraints and unachieved goals.In order to make the language extensions more accessible for the competitors, IPC5 used a first version of pddl3, calledpddl3.0, where we have imposed some simplifying restrictions, such as a limited form of modal operator nesting in thespecification of trajectory constraints. While there is more than one way to specify the importance of a soft constraint orgoal, as a first attempt to tackle this issue, in pddl3.0 we have chosen a simple quantitative approach: each soft constraintand goal is associated with a numerical weight representing the cost of its violation in a plan (and hence also its relativeimportance with respect to the other specified soft constraints and goals). Weighted soft constraints and goals are part ofthe plan metric expression, and the best quality plans are those optimising such an expression. Using this approach we canexpress that certain plans are preferred to others.In order to evaluate the performance of the competing planners, the organisers of IPC5 developed several new planningdomains and a large collection of new benchmark problems over these domains, that can also serve as a reference forfuture research. Some of the new domains are inspired by new applications of planning technology, e.g., to problems ofmolecular biology, or to known problems that have been investigated in other fields of computer science, such as thetravelling purchaser problem studied in operations research.A total of twelve planners entered IPC5. Even though they did not all attempt all of the problems, the size of the result-ing data set is substantial. Given the limited amount of time available during the competition for analysing these results andassigning the awards, the organisers of IPC5 used an informal evaluation method similar to the one used for the previouscompetition [41], with the main difference that the evaluation criteria focused on the number of solved problems and planquality, rather than CPU time and scalability.1 The winners of IPC5 were: MaxPlan and SATPLAN (version 2006) for thepropositional optimal planning subtrack, and SGPlan5 for satisficing (sub-optimal) planning subtrack [13].2 In this paper,we analyse the performance of the IPC5 planners more rigorously, and much more in detail, in terms of their relative per-formance, advancement with respect to the state-of-the-art in fully-automated deterministic planning systems, and qualitiesof the solutions found for the IPC5 benchmarks.In summary, the main contributions of our work are:• An extension of the pddl language that supports soft goals and soft and strong state trajectory constraints representingtemporally extended goals;• Some basic results about the expressiveness of pddl3.0 and its compilability into the previous versions of the language;• A detailed evaluation of the relative performance of the twelve IPC5 planners, for each domain category involvingdifferent fragments of pddl3.0;• An evaluation of the performance of the IPC5 winners with respect to the winners of the previous IPC and of the qualityof solutions they computed;1 A detailed description of the IPC5 evaluation criteria used to assign the IPC5 awards is available on the competition website: ipc5.ing.unibs.it.2 The term “satisficing”, introduced for planning in [41",
            {
                "entities": [
                    [
                        3917,
                        3945,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1219–1244www.elsevier.com/locate/artintFully generated scripted dialogue forembodied agentsKees van Deemter a,∗, Brigitte Krenn b, Paul Piwek c, Martin Klesen d,Marc Schröder d, Stefan Baumann ea Computing Science Department, University of Aberdeen, Scotland, UKb Austrian Research Centre for Artificial Intelligence (OEFAI), University of Vienna, Austriac Centre for Research in Computing, The Open University, UKd German Research Centre for Artificial Intelligence (DFKI), Saarbruecken, Germanye IfL Phonetik, University of Cologne, GermanyReceived 13 March 2007; received in revised form 29 January 2008; accepted 14 February 2008Available online 29 February 2008AbstractThis paper presents the NECA approach to the generation of dialogues between Embodied Conversational Agents (ECAs). Thisapproach consist of the automated construction of an abstract script for an entire dialogue (cast in terms of dialogue acts), whichis incrementally enhanced by a series of modules and finally “performed” by means of text, speech and body language, by a castof ECAs. The approach makes it possible to automatically produce a large variety of highly expressive dialogues, some of whoseessential properties are under the control of a user. The paper discusses the advantages and disadvantages of NECA’s approach toFully Generated Scripted Dialogue (FGSD), and explains the main techniques used in the two demonstrators that were built. Thepaper can be read as a survey of issues and techniques in the construction of ECAs, focusing on the generation of behaviour (i.e.,focusing on information presentation) rather than on interpretation.© 2008 Published by Elsevier B.V.Keywords: Embodied conversational agents; Fully generated scripted dialogue; Multimodal interfaces; Emotion modelling; Affective reasoning;Natural language generation; Speech synthesis; Body language1. IntroductionA number of scientific disciplines have started, in the last decade or so, to join forces to build Embodied Conver-sational Agents (ECAs): software agents with a human-like synthetic voice and a computer-animated body, who canengage in a conversation in natural language. Although many techniques in this area are shared between all ECAs,this paper focuses on one particular “family” of ECAs, whose behaviour is determined by an automatically generatedscripted dialogue, rather than by autonomous agents that make their own decisions. Let us start by explaining what ascripted dialogue is.* Corresponding author.E-mail address: k.vdeemter@abdn.ac.uk (K. van Deemter).0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.02.002\f1220K. van Deemter et al. / Artificial Intelligence 172 (2008) 1219–1244Scripted dialogues follow a master plan. Perhaps the most basic example of scripted dialogue is the stage dialogue,in which actors behave according to a script that was written not by themselves but by a playwright. Two actorsplaying Romeo and Juliet, for example, do what they do not because they want to, necessarily, but because someoneelse (Shakespeare, or someone adapting his work) wants them to. The communication between the actors is arguablyfake; the ‘real’ flow of information goes from the script writer to the audience. The same is true for the dialoguesbetween people in a TV commercial, where the real communication is from manufacturer to customer.This paper describes an approach to the computational production of scripted dialogues that has arisen from theNECA1 project, and which is henceforth called the NECA approach to scripted dialogue. In the NECA approach, thegeneration of dialogue behaviour is centralised: the heart of the NECA system is an automated script writing engine.This engine produces a script that can be performed by ECAs. The ECAs are comparable to actors: like their humancounterparts, they are carrying out a script that was written by someone else.ECAs appear to have entered the world of scripted dialogue in a number of systems described in [2]. Initially,scripts were mapped to words and gestures in a fairly direct manner (up to fully canned text). In this paper, however,we show how the approach can be made more powerful when combined with techniques from Natural LanguageGeneration (NLG), which is why we speak of fully generated scripted dialogue (FGSD). NLG programs are ableto express any well-formed input information in a language such as English or German, for example. NLG makesit possible to express one and the same content in many different ways. This makes it possible to create an endlessvariety of different actors, each of which acts out any role that is given to them, following a single set of rulesthat govern his or her manner of speaking and moving. This is especially important—and especially challenging—when different ECAs take on distinct ‘personalities’, and when their expressive power starts to include the expressionof emotion, as is more and more often the case. Henceforth, when we speak of ‘expressive’ dialogues, we meanmultimodal dialogues that are not only able to express factual information, but the affective state of the characters init as well.Although research on ECAs is different from work on computer games, it is instructive to compare the two en-deavours. Games programmers create characters that display sophisticated behaviours and are often able to engagein a dialogue with each other. However, the creation of such games is time consuming and involves a great deal ofhandcrafting. Even so, the amount of variation displayed by the characters tends to be limited: the number of differ-ent dialogues is typically small and these are always performed in the same way, with only minor variations. Gamescould arguably become more interesting, enjoyable and useful if the characters in them displayed more richly variedbehaviour (cf. [23] on ECAs). Taking the notion of a computer game as a point of departure, the goal of most workon ECAs can be viewed as: making it easier and cheaper to create a large variety of appealing and effective dialoguesin a controlled way. The Holy Grail of this work—which can be applied to games and more ‘serious’ applicationsalike—is to create tools that allow the (semi-)automatic construction of dialogues between believable and highly ex-pressive characters. NECA aims for that Holy Grail. It is for this reason that variation of the generated dialogues—atall levels, and involving all modalities—is such a central design constraint for NECA, which motivates many aspectsof the approach, including the choice for fully generated dialogues.Generating scripted dialogues involves a specific set of tasks, different from the ones involved in the constructionof autonomous agents. In scripted dialogue, there is no need to recognise or understand verbal input, for example.The challenge is to generate dialogues between agents who behave as if they understood each other and reactedto each other in believable ways. “Believable” implies, of course, that the content and form of the dialogues has tobe appropriate. ECA systems based on autonomous agents [13,43,72,81] interact with real people as well as withECAs. This comes naturally to them, as it were. ECA systems based on scripted dialogue, by contrast, find interactionwith people more difficult, because all possible interactions must be built into the script. However, they also havecertain advantages, particularly in terms of the alignment between modalities, and in terms of their ability to ensurethat the generated dialogues fulfil constraints on, for example, their total length, their style, and their internal coher-ence [68].This paper presents NECA’s approach to the creation of varied and expressive dialogues, with respect to all thedifferent levels and modalities, and their synchronisation. Section 2 sketches the two different applications that1 ‘NECA’ stands for Net Environment for Embodied Emotional Conversational Agents, see www.ofai.at/research/nlu/NECA/. We speak of theNECA approach or system to refer to the ideas underlying the two demonstrators developed in the project.\fK. van Deemter et al. / Artificial Intelligence 172 (2008) 1219–12441221Fig. 1. eShowroom: selection of actor personality.were explored in order to test the generality of our methods. Section 3 discusses architectural issues. Section 4 de-scribes how the initial dialogue scripts are produced. Section 5 explains how these scripts are subsequently treatedby the Multimodal Natural Language Generation module. Sections 6 and 7 focus on speech and gestures respec-tively.In the course of the paper, we will explain in some detail how NECA differs from alternatives proposed in theliterature, thereby allowing the paper to be read as a review of the state of the art in the construction of ECAs, aswell as an introduction into Fully Generated Scripted Dialogue. The wide-ranging character of the paper allows someimportant issues to emerge, such as the trade-off between quality and flexibility, and the advantages of an incrementalsystem architecture. These issues are highlighted in the Conclusion (Section 8).2. Two NECA applicationsEach of the two NECA demonstrators takes an existing demonstrator as its point of departure: The eShowroomdemonstrator was inspired by work on collaborating presentation agents [1]; Socialite is an extension of the SysisNetLife platform, a community-building tool where users are represented by avatars [48]. In both cases, we havestuck with the names under which these demonstrators’ predecessors were known. Both systems, however, were verysubstantially enhanced in terms of the generality of their architecture, and in terms of the variety and quality of thedialogues produced.In the eShowroom scenario, a car sales dialogue between a seller and a buyer is simulated. The purpose of thisapplication is to entertain the site visitor and to educate him or her about cars. User interaction is restricted: users canset a few parameters which",
            {
                "entities": [
                    [
                        2645,
                        2673,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 1017–1029www.elsevier.com/locate/artintEvent calculus and temporal action logics comparedErik T. MuellerIBM Thomas J. Watson Research Center, P.O. Box 704, Yorktown Heights, NY 10598, USAReceived 11 November 2005; received in revised form 8 May 2006; accepted 8 May 2006Available online 12 June 2006AbstractWe compare the event calculus and temporal action logics (TAL), two formalisms for reasoning about action and change.We prove that, if the formalisms are restricted to integer time, inertial fluents, and relational fluents, and if TAL action typespecifications are restricted to definite reassignment of a single fluent, then the formalisms are not equivalent. We argue thatequivalence cannot be restored by using more general TAL action type specifications. We prove however that, if the formalisms arefurther restricted to single-step actions, then they are logically equivalent.© 2006 Elsevier B.V. All rights reserved.Keywords: Commonsense reasoning; Reasoning about action and change; Event calculus; Temporal action logics (TAL)1. IntroductionReasoning about action and change is a fundamental area of research within artificial intelligence. This is an im-portant area because action and change are pervasive aspects of the world in which intelligent agents operate. Over theyears, a number of formalisms and frameworks for reasoning about action and change have been developed. Amongthem are the situation calculus [25,33], the event calculus [19,36], features and fluents [34,35], action languages [7–9],and the fluent calculus [12,41,42].Although there has been some cross-pollination, the various formalisms have been developed in relative isolation,and the relationship between them is not always well understood. But understanding the relationship between theformalisms is important for the following reasons:• It helps to advance the field. An understanding of the space of possible formalisms and where each formalism issituated in this space is essential to their refinement.• It enables sharing of reasoning tools. A number of reasoning tools are available, as shown in Table 1. If problemsin one formalism can be translated into another formalism, they can be solved using reasoning tools for the otherformalism.• It enables sharing of problem libraries developed for each of the formalisms and reasoning tools.• It facilitates collaboration. Researchers working using one formalism can understand and build on the results ofresearchers using another formalism.E-mail address: etm@us.ibm.com (E.T. Mueller).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.001\f1018E.T. Mueller / Artificial Intelligence 170 (2006) 1017–1029Table 1Tools for reasoning about action and changeFormalismSituation calculusEvent calculusTALC+EFluent calculusToolKM [3]http://www.cs.utexas.edu/users/mfkb/km.htmlEvent calculus planner [39]http://www.iis.ee.ic.ac.uk/~mpsha/planners.htmlDiscrete Event Calculus Reasoner [28]http://decreasoner.sourceforge.net/VITAL [20]http://www.ida.liu.se/~jonkv/vital/CCALC [9,23]http://www.cs.utexas.edu/users/tag/cc/E-RES [14,15]http://www.ucl.ac.uk/~uczcrsm/LanguageE/FLUX [43]http://www.fluxagent.org/Two major streams of research in reasoning about action and change are temporal action logics (TAL) [4–6,21],which has its origins in the features and fluents framework, and the event calculus [29,37]. TAL and the event calculusappear to be similar because they both have characterizations in classical logic and both use linear time. But theirexact relationship has been unclear.In this paper, we compare the event calculus with support for events with duration [26,37] and TAL 1.0 [4,5].1We start by restricting the event calculus and TAL 1.0 to integer time, inertial fluents, and relational fluents. Wefurther restrict TAL 1.0 action type specifications to definite reassignment of a single fluent. We then prove that theserestricted versions are not equivalent. We show that equivalence cannot be restored even if more general TAL actiontype specifications are used. We then further restrict the two formalisms to single-step actions and prove that theseversions are logically equivalent.2. Past workIn the past, four approaches have been used to compare formalisms for reasoning about action and change:(1) Two formalisms are proved to be logically equivalent.(2) A syntactic translation is defined from a domain description in one formalism to a domain description in anotherformalism, and the two domain descriptions are proved to entail the same results. Translations may be providedin one or both directions.(3) Semantic (model theoretic) conditions are defined under which a domain description in one formalism matchesa domain description in another formalism, and matching domain descriptions are proved to entail the sameresults.(4) A general formalism is defined, and formalisms are shown to be special cases of the general formalism.In order to ease comparison, the formalisms are often extended or restricted in various ways.The first approach is used by Kowalski and Sadri [17,18], who consider a version of the event calculus extendedwith branching time, but without concurrent events, continuous change, and release from the commonsense law ofinertia. They show that this version of the event calculus is logically equivalent to a version of the situation calculussimilar to that of Reiter [32]. The first approach is also used by Mueller [27], who proves that, if the domain of thetimepoint sort is restricted to the integers, the continuous event calculus is logically equivalent to a discrete version ofthe event calculus.We use the first approach in this paper.1 We use the variant of TAL 1.0 in which actions are treated as first-class citizens [5, pp. 19–20].\fE.T. Mueller / Artificial Intelligence 170 (2006) 1017–10291019The second approach is used by a number of researchers. Kartha [16] defines a translation from domain descriptionsof action language A [8] into three versions of the situation calculus [1,30,31]. He asserts that for any sequence ofevents, the A domain description and the situation calculus translations entail the same truth values of fluents.Thielscher [40] restricts A to a single sequence of actions, and restricts ego world semantics [35] to inertial fluents,relational fluents, and single-step actions. He defines a translation from A domain descriptions to ego world semanticsdomain descriptions, and defines a translation from ego world semantics domain descriptions to A domain descrip-tions. He sketches proofs that in both cases, the models of the domain descriptions entail the same event occurrencesand fluent truth values.Giunchiglia and Lifschitz [11] define a translation from unrestricted domain descriptions of action language C [10]into the situation calculus, and define a classical logic translation of the transition semantics of C domain descriptions.They prove that for any domain description, the two translations are logically equivalent. They also define a translationfrom restricted C domain descriptions to TAL domain descriptions, and define another classical logic translation ofthe transition semantics of C domain descriptions. They prove that for any domain description, the first translation isa conservative extension of the second translation.The third approach is used by Miller and Shanahan [26], who consider a version of the E action language [13] anda version of the event calculus without release from the commonsense law of inertia, continuous change, and stateconstraints. They define semantic conditions under which an E domain description matches an event calculus domaindescription. They prove that, if an E domain description matches an event calculus domain description, the domaindescriptions entail the same event occurrences and fluent truth values.The fourth approach is used by Van Belleghem, Denecker, and De Schreye [44], who define a general formalismthat encompasses both the situation calculus and a version of the event calculus without concurrent events, continuouschange, and release from the commonsense law of inertia. They describe how the situation calculus and this versionof the event calculus are obtained by restricting the general formalism.Bennett and Galton [2] define a versatile event logic (VEL) whose semantics includes a number of formalisms fortemporal reasoning, and present ways of describing the situation calculus and the event calculus within VEL. Theyconsider a version of the event calculus without continuous change and release from the commonsense law of inertia.A related approach is that of Sandewall [35], who defines ontological families and the intended models of a do-main description of a given family. The correctness of any particular formalism is then assessed against these formalspecifications.3. The event calculus and TALHow shall we go about proving logical equivalence of the event calculus with events with duration and TAL 1.0?As shown in Table 2, the formalisms do not support the same features. In addition, the formalisms do not addressindirect effects and nondeterministic effects using the same language features. Indirect effects are represented in theevent calculus using causal constraints and effect constraints [38], whereas they are represented in TAL 1.0 usingdependency constraints [5, pp. 16–18]. Nondeterministic effects are represented in the event calculus using determin-ing fluents [37, pp. 419–420], whereas they are represented in TAL 1.0 using disjunctions in reassignment operators[4, pp. 35–36].At this point, we have two choices. We can either extend the formalisms with their missing features, or we canrestrict the formalisms to their common features. We choose the second approach. We disallow causal constraints,continuous change, continuous time, and effect constraints in the event calculus, and we disallow dependency con-straints, disjunctions in reassignment operators, durational fl",
            {
                "entities": [
                    [
                        2643,
                        2671,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 228 (2015) 45–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBi-goal evolution for many-objective optimization problemsMiqing Li a, Shengxiang Yang b,∗a Department of Computer Science, Brunel University, London UB8 3PH, UKb Centre for Computational Intelligence (CCI), School of Computer Science and Informatics, De Montfort University, Leicester LE1 9BH, UK, Xiaohui Liu aa r t i c l e i n f oa b s t r a c tArticle history:Received 22 August 2014Received in revised form 14 June 2015Accepted 20 June 2015Available online 3 July 2015Keywords:Evolutionary multi-objective optimizationMany-objective optimizationProximityDiversityBi-goal evolutionThis paper presents a meta-objective optimization approach, called Bi-Goal Evolution (BiGE), to deal with multi-objective optimization problems with many objectives. In multi-objective optimization, it is generally observed that 1) the conflict between the proximity and diversity requirements is aggravated with the increase of the number of objectives and 2) the Pareto dominance loses its effectiveness for a high-dimensional space but works well on a low-dimensional space. Inspired by these two observations, BiGE converts a given multi-objective optimization problem into a bi-goal (objective) optimization problem regarding proximity and diversity, and then handles it using the Pareto dominance relation in this bi-goal domain. Implemented with estimation methods of individuals’ performance and the classic Pareto nondominated sorting procedure, BiGE divides individuals into different nondominated layers and attempts to put well-converged and well-distributed individuals into the first few layers. From a series of extensive experiments on four groups of well-defined continuous and combinatorial optimization problems with 5, 10 and 15 objectives, BiGE has been found to be very competitive against five state-of-the-art algorithms in balancing proximity and diversity. The proposed approach is the first step towards a new way of addressing many-objective problems as well as indicating several important issues for future development of this type of algorithms.© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionReal-world problems commonly involve multiple objectives/criteria which are required to be optimized simultaneously. For example, an individual would like to maximize the chance of being healthy and wealthy while still having fun and time for family and friends. A software engineer would be interested in finding the cheapest test suite while achieving full coverage (e.g., statement coverage, branch coverage and decision coverage). When prescribing radiotherapy to a cancer patient, a doctor would have to balance the attack on tumor, potential impact on healthy organs, and the overall condition of the patient. These multi-objective optimization problems (MOPs) can be seen in many fields, including engineering, science, medicine and logistics. They share the same issue of pursuing several objectives at the same time, and have long been regarded as a substantial challenge in artificial intelligence (AI) [73,25].There have been a variety of approaches for MOPs, including traditional mathematical programming methods, local search techniques, and evolutionary algorithms (EAs). Inspired by biological evolution mechanisms, EAs have been demon-strated to be successful in diverse AI applications [73,10]. For example, an EA-based AI planner, Divide and Evolutionary * Corresponding author.E-mail address: syang@dmu.ac.uk (S. Yang).http://dx.doi.org/10.1016/j.artint.2015.06.0070004-3702/© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f46M. Li et al. / Artificial Intelligence 228 (2015) 45–65(DaE) [8], won the Deterministic Temporal Satisficing track during the International Planning Competition (IPC7) at the 21st International Conference on Automated Planning and Scheduling (ICAPS 2011).1 Recently, DaE has been successfully applied to multi-objective AI planning (called MO-DaE) [58]. MO-DaE, working with a well-known multi-objective EA, i.e., the indicator-based EA (IBEA) [99], has shown clear advantage over the metric-based approach using LPG metric sensitive planner [58].A key strength of EAs for MOPs is their population-based feature which allows individuals to simultaneously approximate different parts of the Pareto front within a single execution [19,97]. Intuitively, the search process of an EA has two basic goals:• minimizing the distance of the population to the Pareto front (i.e., proximity) and• maximizing the distribution of the population along the Pareto front (i.e., diversity).Since the optimal outcome of an MOP is a set of Pareto optimal solutions, the Pareto dominance relation naturally becomes a criterion to distinguish between solutions. Given two solutions p and q for an MOP, p is said to Pareto dominate q, if and only if p is better than q for at least one objective and is not worse for any of the others. The Pareto dominance reflects the weakest assumption about the preferred structure of the decision-maker.As the primary selection criterion in the evolutionary multi-objective optimization (EMO) area, Pareto dominance is commonly used to evaluate the proximity of solutions. When Pareto dominance fails (e.g., the interested solutions are non-dominated to each other), EMO algorithms often introduce a density-based criterion to maintain diversity of the population. For example, the nondominated sorting genetic algorithm II (NSGA-II) [23] separates individuals in a population into dif-ferent layers (ranks) by their Pareto dominance relation, and prefers 1) individuals in lower layers and 2) individuals with lower crowding degrees (measured by the crowding distance [23]) when they are located in the same layer.An MOP with more than three objectives is called a many-objective optimization problem. Many-objective optimization is an important but very challenging topic and there has been increasing interest in the use of EAs to tackle many-objective optimization problems [14,16,26,35]. Although Pareto-based algorithms are the most popular approaches, they scale up poorly with the number of objectives [18,48,75]. When dealing with an MOP with many objectives, Pareto dominance often loses its effectiveness to differentiate individuals [57], which makes most individuals in a population become incomparable in terms of proximity (e.g., in NSGA-II most individuals fall into the first layer). Consequently, the density-based selection criterion will play a decisive role in determining the survival of individuals during the evolutionary process, leading to the individuals in the final population distributed widely over the objective space but far from the desired Pareto front [85].A straightforward way to handle this problem (i.e., the ineffectiveness of Pareto-based algorithms in many-objective opti-mization) is to modify the Pareto dominance relation. Some interesting attempts include loosening the dominance condition or controlling the dominance angle, such as (cid:2)-dominance [22,36,61,84], α-dominance [43], (cid:2)-box dominance [60], and dom-inance area control [78]. By relaxing the area of an individual dominating, these dominance relations are able to provide sufficient selection pressure towards the Pareto front. However, how to set a proper value of the parameter(s) to determine the relaxation degree is a crucial issue in these methods, needing further studies [62,69,79].On the other hand, the way of comparing individuals according to their quantitative difference in objectives has been found to be effective in converging towards the Pareto front. Many recent EMO algorithms originate from this motivation, introducing a variety of new criteria to distinguish between individuals, e.g., average ranking [52,70], fuzzy Pareto optimality [37,39], subspace partition [2,51], preference-inspired rank [88,87], grid-based rank [70,92], distance-based rank [32,71,91], and density adjustment strategies [1,66]. These methods provide ample alternatives to deal with many-objective optimiza-tion problems, despite some having the risk of leading the population to concentrate in one or several sub-areas of the whole Pareto front [50,67,81,65].Recently, there has been significant interest in the use of selection criteria that involve both proximity and diversity to solve MOPs. Some such criteria, like the decomposition-based [94] and indicator-based [99] criteria, have been shown to be very promising in many-objective optimization [15,20,41,44,85]. The former uses the idea of single-objective aggregated optimization, decomposing an MOP into a number of scalar subproblems and optimizing them simultaneously. The latter defines an optimization criterion with regard to a specified performance indicator and uses this criterion to guide the search of the population. The indicator hypervolume is one of the most popular indicator-based criteria due to its good theoretical and empirical properties [7,13,29,42,101]. Whereas super-polynomial time complexity is required in the calculation of the hypervolume indicator (unless P = N P ) [11], lots of effort is being made to reduce its computational cost, in terms of both the exact computation [6,12,90] and the approximate estimation [4,14,49]. Nevertheless, balancing proximity and diversity using one single criterion is not an easy task [76,38,69,68], especially for a many-objective optimization problem in which the conflict between the objectives is generally more serious than that in an MOP with two or three objectives [75,1].In fact, evolving a population towards the optimum as well as diversifying its individuals over the whole Pareto front in many-objective optimization is, by ",
            {
                "entities": [
                    [
                        3715,
                        3743,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1470–1494Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEnhanced qualitative probabilistic networks for resolving trade-offs ✩Silja Renooij∗, Linda C. van der GaagDepartment of Information and Computing Sciences, Utrecht University, P.O. Box 80.089, 3508 TB Utrecht, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 18 October 2006Received in revised form 9 April 2008Accepted 14 April 2008Available online 20 April 2008Keywords:Probabilistic reasoningQualitative reasoningTrade-off resolutionQualitative probabilistic networks were designed to overcome, to at least some extent, thequantification problem known to probabilistic networks. Qualitative networks abstract fromthe numerical probabilities of their quantitative counterparts by using signs to summarisethe probabilistic influences between their variables. One of the major drawbacks of thesequalitative abstractions, however, is the coarse level of representation detail that doesnot provide for indicating strengths of influences. As a result, the trade-offs modelledin a network remain unresolved upon inference. We present an enhanced formalism ofqualitative probabilistic networks to provide for a finer level of representation detail.An enhanced qualitative probabilistic network differs from a basic qualitative network inthat it distinguishes between strong and weak influences. Now, if a strong influence iscombined, upon inference, with a conflicting weak influence, the sign of the net influencemay be readily determined. Enhanced qualitative networks are purely qualitative in nature,as basic qualitative networks are, yet allow for resolving some trade-offs upon inference.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe formalism of probabilistic networks introduced in the 1980s [26], is an intuitively appealing formalism for capturingknowledge of complex problem domains along with the uncertainties involved. Associated with the formalism are powerfulalgorithms for reasoning with uncertainty in a mathematically correct way. These algorithms for probabilistic inference allowfor causal reasoning, diagnostic reasoning as well as case-specific reasoning; probabilistic inference, however, is known tobe NP-hard [7]. Applications of probabilistic networks can be found in areas such as (medical) diagnosis and prognosis,planning, monitoring, vision, and information retrieval (see, for example, [1,2,4,5,20,31]).A probabilistic network basically is a concise representation of a joint probability distribution on a set of statisticalvariables. It consists of an acyclic directed graph encoding the relevant variables from a domain of application along withtheir probabilistic interrelationships. Associated with each variable is a set of conditional probability distributions describingthe relationship of the variable with its predecessors in the graph. The first task in constructing a probabilistic network isto identify the important domain variables, their values, and their interdependencies. This knowledge is then modelled ina directed graph, referred to as the network’s qualitative part. The final task is to obtain the probabilities that constitutethe network’s quantitative part. As (conditional) probability distributions are to be stated for each variable in the graph, thenumber of required probabilities can be quite large, even for small applications. While the construction of the qualitativepart of a probabilistic network is generally considered feasible, its quantification is a far harder task. Probabilistic informationavailable from literature or data is often insufficient or unusable, and domain experts have to be relied upon to assess the✩This research was (partly) supported by the Netherlands Organisation for Scientific Research (NWO). We would very much like to thank Hans Bodlaenderfor his advice relating to the complexity issues addressed in this paper.* Corresponding author.E-mail addresses: silja@cs.uu.nl (S. Renooij), linda@cs.uu.nl (L.C. van der Gaag).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.04.001\fS. Renooij, L.C. van der Gaag / Artificial Intelligence 172 (2008) 1470–14941471required probabilities [14]. Unfortunately, experts are often uncomfortable with having to provide probabilities. Moreover,the problems of bias encountered when directly eliciting probabilities from experts are widely known [19]. The usuallylarge number of probabilities required for a probabilistic network, as a consequence, tends to pose a major obstacle to theirapplication [14,18].To mitigate the quantification bottleneck to at least some extent, qualitative probabilistic networks have been intro-duced [34]. Qualitative networks in essence are qualitative abstractions of probabilistic networks. Like a probabilisticnetwork, a qualitative network encodes variables and the probabilistic relationships between them in a directed graph.However, while the relationships between the represented variables are quantified by conditional probabilities in a prob-abilistic network, these relationships are summarised in its qualitative abstraction by qualitative signs capturing stochasticdominance. The probabilistic information captured by signs is more robust than exact numbers are and is more easilyobtained from domain experts [10]. Elicitation methods to this end are being designed [33].Originally, the benefits of using qualitative probabilistic networks included the complexity of inference: for reasoningwith a qualitative probabilistic network, an efficient algorithm is available, based on the idea of propagating and combiningthese signs [11]. In practice, however, nowadays the complexity of probabilistic inference is less of a problem and interestin qualitative probabilistic networks has shifted more to the construction and validation phase of probabilistic networks forreal-life application domains. As the assessment of the various probabilities required is a hard task, it is performed onlywhen the probabilistic network’s graph is considered robust. Now, by assessing signs for the influences modelled in thegraph, a qualitative network is obtained that can be exploited for studying the projected probabilistic network’s reasoningbehaviour prior to the assessment of probabilities. Patterns of qualitative influences can also be used to recognise differenttypes of causal interaction, such as the noisy-or, which greatly simplify the quantification effort [24]. In addition, qualitativesigns can be used in several ways as constraints on the quantification. For example, by interpreting the signs as continuoussubintervals of the probability interval, the constraints they impose on the conditional probability distributions involved canbe used for stepwise quantification of a probabilistic network: once a conditional probability table for a certain variableis filled, the interval associated with all direct influences upon that variable can be tightened [28]. These semi-qualitativeprobabilistic networks can also include assessments based on probabilistic logic and credal sets [6]. More recently, the signsof qualitative probabilistic networks have been used to constrain the probabilities learned from small data sets [3,15,17]. Ata somewhat higher level, the constraints imposed by qualitative influences can be used to bound the entire space of pos-sible joint probability distributions over the network’s variables [13]. Finally, the qualitative signs can be used for verifyingmonotonicity properties in a probabilistic network [32], and for explanation of the (qualitative) probabilistic network’s rea-soning processes [10]. Given the increasing variety of useful applications of qualitative probabilistic networks, it is importantto derive as much information as possible from such networks.Qualitative probabilistic networks, by their nature, have a coarse level of representation detail. Influential relationshipsbetween variables can be modelled as positive, negative, zero or ambiguous, but no indication of their strengths can beprovided as in a quantified network. One of the major drawbacks of this coarse level of representation detail is the easewith which the ambiguous ‘?’-sign arises upon inference. Ambiguous signs typically arise from trade-offs. A qualitativenetwork models a trade-off if two nodes in the network’s digraph are connected by multiple parallel reasoning chains withconflicting signs. In the absence of a notion of strength of influences, qualitative networks do not provide for resolving suchtrade-offs. Inference with a qualitative network for a real-life domain of application, as a consequence, often introducesambiguous signs. Moreover, once an ambiguous sign has been generated, it will spread throughout major parts of thenetwork. Although not incorrect, ambiguous signs provide no information whatsoever about the influence of one variableon another and are therefore not very useful in practice.Ambiguous results from inference can be averted by enhancing the formalism of qualitative probabilistic networks toprovide for a finer level of representation detail. Roughly speaking, the finer the level of detail, the more trade-offs can beresolved during inference. The finer levels of detail, however, typically come at the price of a higher computational com-plexity of inference. The problem of trade-off resolution for qualitative networks has been addressed by various researchersand we detail the relation between their work and ours in the Related work section of this paper. In short, S. Parsons, for ex-ample, has introduced the concept of categorical influence, which is either an influence that serves to increase a probabilityto 1, or an influence that decreases a probability to 0, and thus serves to resolve any trade-off in which it is involved [25].Parsons has also studied the use of order-of-magnitude reasoning in the context of quali",
            {
                "entities": [
                    [
                        4166,
                        4194,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 193 (2012) 129–148Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA defeasible reasoning model of inductive concept learning fromexamples and communicationSantiago Ontañón a,c,∗, Pilar Dellunde a,b, Lluís Godo a, Enric Plaza aa IIIA-CSIC, Artificial Intelligence Research Institute, Spanish Council for Scientific Research, Campus UAB, 08193 Bellaterra, Catalonia, Spainb Universitat Autònoma de Barcelona, 08193 Bellaterra, Catalonia, Spainc Computer Science Department, Drexel University, Philadelphia, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 27 September 2011Received in revised form 14 June 2012Accepted 29 August 2012Available online 30 August 2012Keywords:InductionLogicArgumentationMachine learningConcept learning1. IntroductionThis paper introduces a logical model of inductive generalization, and specifically of themachine learning task of inductive concept learning (ICL). We argue that some inductiveprocesses, like ICL, can be seen as a form of defeasible reasoning. We define a consequencerelation characterizing which hypotheses can be induced from given sets of examples, andstudy its properties, showing they correspond to a rather well-behaved non-monotoniclogic. We will also show that with the addition of a preference relation on inductivetheories we can characterize the inductive bias of ICL algorithms. The second part of thepaper shows how this logical characterization of inductive generalization can be integratedwith another form of non-monotonic reasoning (argumentation), to define a model ofmultiagent ICL. This integration allows two or more agents to learn, in a consistent way,both from induction and from arguments used in the communication between them. Weshow that the inductive theories achieved by multiagent induction plus argumentation aresound, i.e. they are precisely the same as the inductive theories built by a single agent withall data.© 2012 Elsevier B.V. All rights reserved.Inductive generalization is the basis for machine learning methods which learn general hypotheses from examples. How-ever, with the exception of a few isolated proposals [1–4], there has been little effort towards specific logical models ofinductive generalization. The lack of a formal logical model of induction may have hindered the development of approachesthat combine induction with other forms of logical reasoning.In this paper we do not tackle induction in its more general definition, but limit ourselves to inductive generalization,and specifically, to the common task of inductive concept learning (ICL), which is the most well studied induction problemin machine learning. We will argue that inductive generalization is a form of defeasible reasoning, and define an inductiveconsequence relation (denoted by |∼) characterizing which hypotheses can be induced from given sets of examples, andshow its logical properties.Relationships between inductive reasoning and non-monotonic reasoning have already been established by Flach in [1,5],where he presents a logical analysis of induction and considers several postulates for a general inductive consequence* Corresponding author at: Computer Science Department, Drexel University, Philadelphia, USA.E-mail addresses: santi@iiia.csic.es, santi@cs.drexel.edu (S. Ontañón), pilar@iiia.csic.es, pilar.dellunde@uab.cat (P. Dellunde), godo@iiia.csic.es (L. Godo),enric@iiia.csic.es (E. Plaza).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.08.006\f130S. Ontañón et al. / Artificial Intelligence 193 (2012) 129–148relation along with representation theorems in terms of preferential models, in the tradition of non-monotonic reasoning1[7]. However, while the work of Flach aims at defining general rationality postulates for induction in general, our focus ison characterizing a particular form of induction (ICL), which allows us to develop a more concrete model (see Appendix Bfor an in-depth comparison of our proposal with Flach’s). Moreover, Flach presents a logical characterization of inductionfocusing on hypothesis generation rather than hypothesis selection, i.e. intending to model which are the valid hypotheses onecan induce from a set of examples, but not which of those hypotheses is the best one. In this paper, within the framework ofICL, we go one step further and propose that hypothesis selection can also be logically characterized by means of a preferencerelation on inductive theories (suitable sets of hypotheses), and propose some preference relations which capture the typicalbiases used in ICL algorithms (like parsimony or margin maximization).There are two main implications of defining a logical model of inductive generalization. First, it allows for a betterunderstanding of ICL algorithms, and second, it facilitates the integration of inductive reasoning with other forms of logicalreasoning, as we will show by integrating ICL with computational argumentation to define a model of multiagent ICL.This paper extends the preliminary work in [8], modeling inductive generalization as a non-monotonic logic, extending theproperties satisfied, and using preference relations to model bias in ICL.The second part of this paper presents an integration of two non-monotonic forms of reasoning: induction and argu-mentation. This integration shows the advantage of having a logical model of induction. For instance, a multiagent inductionsystem such as [9] already introduced the idea of integrating inductive learning and argumentation in an implemented sys-tems, but lacked any formal grounding for such an integration. In particular, in this paper we present a model of multiagentICL obtained by directly integrating our inductive consequence relation with computational argumentation. In this approach,argumentation is used to model the communication between agents, and ICL models their internal learning processes.The remainder of this paper is organized as follows. Section 2 introduces the problem of inductive concept learning astypically framed in the machine learning literature. Then, Section 3 introduces a logical model of induction and proposesan inductive consequence relation, while Section 4 deals with preferences over inductive theories. In Section 5 we recallbasic notions of computational argumentation and we introduce the notion of argumentation-consistent induction. Next,Sections 6 and 7 define a model of multiagent ICL by integrating our logical model of ICL with computational argumen-tation. The paper closes discussing some related work and with the conclusions. We have also included two appendices:Appendix A contains a generalization of Theorem 1 to n agents, and Appendix B provides more details on the comparisonof our inductive consequence relation with Flach’s previous work.2. BackgroundInductive concept learning (ICL) [10] using inductive techniques is not defined formally in the literature of machinelearning; rather it is usually defined as a task, as follows:Given:Find1. A space X of instances2. A space of hypotheses or generalizations H , modeled as a set of mappings h : X → {0, 1}3. A target concept c, modeled as a partially known mapping c : X → {0, 1}4. A set D of training examples (for which c is known), where a training example is a pair (cid:5)xi, c(xi)(cid:6)A hypothesis h ∈ H such that h(x) = c(x) for each instance x in the set of training examples DThis strictly Boolean definition is usually weakened to allow the equality h(x) = c(x) not being true for all examples inD but just for a percentage, and the difference is called the error of the learnt hypothesis.Another definition of inductive concept learning is that used in Inductive Logic Programing (ILP) [11], where the back-ground knowledge, in addition to the examples, has to be taken into account. Nevertheless, ILP also defines ICL as a task tobe achieved by an algorithm, as follows:Given:Find+−and negative Eexamples of a predicate p1. A set of positive E2. A set of Horn rules (background knowledge) B3. A space of hypotheses H (a sublanguage of Horn logic language)A hypothesis h ∈ H such that• ∀e ∈ E• ∀e ∈ E+ : B ∧ h |(cid:10) e (h is complete)− : B ∧ h (cid:11)|(cid:10) e (h is consistent)These definitions, although widespread, are unsatisfactory and leave several issues without a precise characterization. Forexample, the space of hypotheses H is usually expressed only by conjunctive formulas. However, most concepts need morethan one conjunctive formula (more than one generalization) but this is “left outside” of the definition and is explained as1 A similar work for abductive reasoning is that of Pino-Pérez and Uzcátegui [6].\fS. Ontañón et al. / Artificial Intelligence 193 (2012) 129–148131part of the strategy of an inductive algorithm. For instance, the set-covering strategy [12] consists of finding one definition(cid:12)that covers only part of the positive examples in D, proceeding then to eliminate the covered examples to obtain a new Dthat will be used in the next step. Another example is that, typically, smaller hypotheses are preferred to longer hypotheses;but again, that is left out of the definition.In this paper our goal is not to provide a definition of the task of inductive concept learning, but to provide a logicalcharacterization of the inductive inference processes required for performing such task.3. Inductive generalization for concept learningInductive generalization can be seen as having two main components: hypothesis generation and hypothesis selection[1]. We will model the former using an inductive consequence relation, that defines which statements are valid inductive con-sequences of given a set of examples, and the later using a preference relation, which determines which of those statementsare “better” than others. This section formally defines our inductive consequence relation.3.1. An inductive consequence relationIn order to present",
            {
                "entities": [
                    [
                        3566,
                        3594,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 286–310www.elsevier.com/locate/artintOn the evaluation of argumentation formalisms ✩Martin Caminada a, Leila Amgoud b,∗a Institute of Information and Computing Sciences, Universiteit Utrecht, Utrecht, The Netherlandsb Institut de Recherche en Informatique de Toulouse, 118 route de Narbonne, 31062 Toulouse Cedex 9, FranceReceived 9 March 2006; received in revised form 26 February 2007; accepted 26 February 2007Available online 3 March 2007AbstractArgumentation theory has become an important topic in the field of AI. The basic idea is to construct arguments in favor andagainst a statement, to select the “acceptable” ones and, finally, to determine whether the original statement can be accepted or not.Several argumentation systems have been proposed in the literature. Some of them, the so-called rule-based systems, use a particularlogical language with strict and defeasible rules. While these systems are useful in different domains (e.g. legal reasoning), theyunfortunately lead to very unintuitive results, as is discussed in this paper. In order to avoid such anomalies, in this paper we areinterested in defining principles, called rationality postulates, that can be used to judge the quality of a rule-based argumentationsystem. In particular, we define two important rationality postulates that should be satisfied: the consistency and the closure of theresults returned by that system. We then provide a relatively easy way in which these rationality postulates can be warranted for aparticular rule-based argumentation system developed within a European project on argumentation.© 2007 Elsevier B.V. All rights reserved.Keywords: Formal argumentation; Nonmonotonic logic; Commonsense reasoning1. IntroductionAgents express claims and judgments when engaged in decision making, drawing conclusions, imparting informa-tion, and when persuading and negotiating with other agents. Information may be uncertain and incomplete, or theremay be relevant but partially conflicting information. Also, in multi-agents systems, conflicts of interest are inevitable.To address these problems, agents can use argumentation, a process based on the exchange and valuation of argumentsfor and against opinions, proposals, claims and decisions.Argumentation, in its essence, can be seen as a particular useful and intuitive paradigm for doing nonmonotonicreasoning. The advantage of argumentation is that the reasoning process is composed of modular and quite intuitivesteps, and thus avoids the monolithic approach of many traditional logics for defeasible reasoning. The process ofargumentation starts with the construction of a set of arguments based on a given knowledge base. As some of thesearguments may attack each other, one needs to apply a criterion for determining the sets of arguments that can be re-garded as “acceptable”: the argument-based extensions. The last step is then to examine whether a particular statement✩ This work has been supported by the EU-ASPIC project.* Corresponding author.E-mail addresses: martinc@cs.uu.nl (M. Caminada), amgoud@irit.fr (L. Amgoud).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.003\fM. Caminada, L. Amgoud / Artificial Intelligence 171 (2007) 286–310287can be regarded as justified. This can for instance be the case if every extension contains an argument which has thisstatement as its conclusion. An interesting property of the argumentation approach is that it can be given dialecticalproof procedures that are quite close to the process by which humans would discuss an issue. The similarity withhuman-style discussions gives formal argumentation an advantage that can be useful in many contexts.Argumentation has developed into an important area of study in artificial intelligence over the last fifteen years,especially in sub-fields such as nonmonotonic reasoning (e.g. [19,25,26,28,43,45]), multiple-source information sys-tems (e.g. [7,9,21]), decision making (e.g. [2,11,12,20,30–32]), and modeling interactions between agents (e.g. [3,8,10,14,18,35–38,41]). Several argumentation systems have been developed for handling inconsistency in knowledgebases (e.g. [5,15–17,29,33,34,39,42,44]), in other words for inference. All these systems are built around a logicallanguage and an associated consequence relation that is used for defining an argument. Some of these systems, calledrule-based systems, use a particular logical language defined over a set of literals, and two kinds of rules: strict rulesand defeasible ones. Arguments and conflicts among them are first identified, and then an acceptability semantics (e.g.Dung’s semantics) is applied in order to determine the “acceptable” arguments. Examples of such systems are Prakkenand Sartor’s system [42], Garcia and Simari’s system [33], Governatori et al.’s system [34], and Amgoud et al.’s sys-tem [4]. Such systems are suitable in some domains like legal reasoning, where knowledge cannot be represented ina classical propositional language for instance. Unfortunately, existing rule-based systems fail to meet the objectivesof an inference system, and can lead to very unintuitive results. Indeed, with these systems it may be the case that anagent believes that “if a then it is always the case that b”, and the system returns as output a but not b. Worse yet, ifthe agent also believes that “if c then it is always the case that ¬b”, the system may return a and c, which means thatthe output of the system is indirectly inconsistent.In what follows, we will focus only on rule-based argumentation systems. In order to avoid anomalies like theones discussed above, the aim of this paper is twofold: on the one hand, as in the field of belief revision, where thewell-known AGM-postulates serve as general properties a system for belief revision should fulfill, we are interested indefining some principles (called rationality postulates) that any rule-based argumentation system should obey. Thesepostulates will govern the sound definition of an argumentation system and will avoid anomalous results. In this paperwe focus particularly on two important postulates: the closure and the consistency of the results that an argumentationsystem may produce. These postulates are violated in systems such as [4,33,34,42]. On the other hand, we studyvarious ways in which these postulates can be warranted in the argumentation system developed in [4], as well as invarious other systems.This paper is structured as follows. First, in Section 2, we recall the basic concepts behind argumentation theory.We present the abstract argumentation framework of Dung [28], as well as one particular instantiation of it, forwhich we have chosen the ASPIC argumentation formalism [4]. In Section 3, we show some examples that yieldvery unintuitive and undesirable results, not only for the ASPIC argumentation system, but also for various otherargumentation formalisms. Then, in Section 4, we state a number of postulates, based on the analysis of the examplesin Section 3, that we think any rule-based argumentation formalism should satisfy. Section 5 proposes a numberof generic solutions which can be applied to the argumentation formalism described in Section 2, as well as to otherargumentation formalisms where similar problems occur (such as [33,34,42]). Two main solutions are suggested, eachof which satisfies all the earlier mentioned rationality postulates. The first approach is applicable to formalisms thatmake use of classical logic, the other one is applicable to formalisms that do not. Section 6 then contains an overviewof the main results of this paper, as well as some open research issues.2. Argumentation processArgumentation can be seen as a reasoning process consisting of the following four steps:(1) Constructing arguments (in favor of/against a “statement”) from a knowledge base.(2) Determining the different conflicts among the arguments.(3) Evaluating the acceptability of the different arguments.(4) Concluding, or defining the justified conclusions.Some argumentation formalisms also allow arguments to be of different strengths, but for the sake of simplicity wewill not address this issue in the current paper. Many argumentation formalisms are built around an underlying logical\f288M. Caminada, L. Amgoud / Artificial Intelligence 171 (2007) 286–310language L and an associated notion of logical consequence, defining the notion of argument. Argument constructionis a monotonic process: new knowledge cannot rule out an argument but only gives rise to new arguments which mayinteract with the first argument. Since the knowledge bases may give rise to inconsistent conclusions, the argumentsmay be conflicting too. Consequently, it is important to determine among all the available arguments, the ones that areultimately acceptable. In [28], an argumentation system is defined as follows:Definition 1 (Argumentation system). An argumentation system is a pair (cid:3)A, Def (cid:4) where A is a set of arguments andDef ⊆ A × A is a defeat relation. We say that an argument A defeats an argument B iff (A, B) ∈ Def (or A Def B).Starting from the set of all (possibly conflicting) arguments, it is important to know which of them can be relied onfor inferring conclusions and for making decisions. To answer this question, different attempts for defining semanticsfor the notion of acceptability have been made. Some approaches return a unique set of acceptable arguments, calledan extension, giving a unique status to each argument, whereas others return several extensions, allowing multiplestatus for arguments. In [28] different semantics for the notion of acceptability have been proposed. These last havebeen recently refined in [13,24]. In what follows, only Dung’s semantics are recalled for illustration purposes.Definition 2 (Conflict-free, Defense). Let A and B be sets of arguments, and let B ⊆ A.• B is conflict-free iff there exist no A, B in B such tha",
            {
                "entities": [
                    [
                        3199,
                        3227,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 222 (2015) 49–66Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFinding core for coalition structure utilizing dual solution ✩Atsushi Iwasaki a,∗a Graduate School of Information Systems, University of Electro-Communications, Tokyo, Japanb Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japanc National Institute of Informatics, Tokyo, Japan, Suguru Ueda c, Naoyuki Hashimoto b, Makoto Yokoo ba r t i c l e i n f oa b s t r a c tArticle history:Received 21 December 2013Received in revised form 13 January 2015Accepted 19 January 2015Available online 24 January 2015Keywords:Game theoryCooperative gamesCoreCoalition structureWhen forming the grand coalition is not possible or optimal, agents need to create a coalition structure. The idea of the core can be extended to such a case. In this paper, we propose an innovative exact algorithm called CoreD to check core-non-emptiness for coalition structures. A more straightforward exact algorithm based on existing techniques, which we call CoreP, first obtains the value of optimal coalition structure by solving an integer programming problem. Then, it checks whether that value can be divided without making a blocking (dissatisfied) coalition. In contrast, CoreD first finds a minimal value of the optimal coalition structure so that there exists no blocking coalition. Next, it checks whether the optimal value equals the minimal value We empirically show that when the core is empty, CoreD is by far superior to CoreP. Also, to find a second-best payoff vector +when the core is empty, we propose a new solution concept called the weak ε-core, which can utilize the approximate value of the optimal coalition structure. Based on the idea of CoreD, we further develop an algorithm for checking the non-emptiness of the weak ε-core+.© 2015 Elsevier B.V. All rights reserved.1. IntroductionCoalition formation is an important capability in automated negotiation among self-interested agents. As a result, coali-tional game theory has attracted much attention from AI and multi-agent systems (MAS) researchers [7,12]. In a traditional model of coalitional game theory, it is assumed that all coalitions are possible and that the characteristic function is super-additive; when two coalitions are merged, the merged coalition can obtain at least the sum of the values of the two original coalitions. However, organizing a large coalition can be costly, e.g., such coordination overhead as communication costs. If time is limited, the agents may not have time to carry out the communications and the computations required to coordinate effectively within the composite coalition, and so component coalitions may be more advantageous.Furthermore, in many real-world applications, there can be inherent constraints on possible coalitions. For example, in many countries, antitrust laws prohibit the formation of certain coalitions of companies (cartels) that can dominate an entire market. Constraints may be placed on coalition sizes to permit or prohibit particular sizes. There can be some underlying graphical structure that determines the possible communication patterns among agents. Therefore, it is natural to assume ✩This paper is an extended version of a conference paper that appeared as [17].* Corresponding author.E-mail addresses: iwasaki@is.uec.ac.jp (A. Iwasaki), s-ueda@nii.ac.jp (S. Ueda), hashimoto@agent.inf.kyushu-u.ac.jp (N. Hashimoto), yokoo@inf.kyushu-u.ac.jp (M. Yokoo).http://dx.doi.org/10.1016/j.artint.2015.01.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f50A. Iwasaki et al. / Artificial Intelligence 222 (2015) 49–66that making a coalition is possible only when its members can communicate with each other. There exist several works that have considered such constraints on possible coalitions [41,11,29,35,31,21].When the grand coalition, i.e., the coalition of all agents, is not possible or optimal, the agents should be divided into smaller coalitions; agents need to create a coalition structure to maximize the reward they can obtain [37]. Furthermore, to make a coalition structure stable, agents need to agree how to divide among themselves the reward obtained by the coalition structure. The core [13], which is a prominent solution concept in the traditional model of coalitional game theory, can be extended to such a case when the grand coalition is not possible or optimal and agents form a coalition structure [2].For instance, consider a coalitional form game with three agents: A = {a, b, c}. The characteristic function v represents a mapping from a coalition S (a subset of agents) to the worth or the value earned by the coalition: v({a}) = v({b}) = 0, v({c}) = 3, v({a, b}) = 12, v({b, c}) = v({c, a}) = 8, and v({a, b, c}) = 15. A payoff vector y = ( ya, yb, yc) that belongs to the core can be computed by linear programming in such a way that for every coalition S, v(S) does not exceed the total payoff of the agents in S and such that the total payoff equals v( A). In this example, the core payoff vector is y = (p, 12 − p, 3), where p ∈ [5, 7]. Let us turn to a case where the grand coalition is prohibited in the above example. The concept of the core can be extended to this situation. The agents can create coalition structure CS = {{a, b}, {c}} and obtain 15 reward and share it efficiently. The coalition structure {{a, b}, {c}} is optimal in the sense that the total payoff V (CS) is maximized. The payoff vector in the core for the coalition structure is the same as in the first example.Checking whether the core is non-empty or not in itself is done in polynomial time in the number of allowed coalitions because it is formulated as a linear programming problem. However, Conitzer and Sandholm [8] pointed out that it requires many constraints for all the subcoalitions and the size of the representation (input) is exponential in the number of agents. Any algorithm for computing the core payoff vector requires time exponential as long as it reads all the input. If a coalition is prohibited or if its value is not explicitly specified, the algorithm may need to compute every value of such coalitions. Computing a value of a coalition is not necessarily straightforward because the agents must solve a complex collaborative planning problem.In general, as we noted below, computing an optimal coalition structure is known to be NP-hard and checking whether there exists a core for the (optimal) coalition structure or not is NP-complete unless its value is explicitly provided. Thus, our research goal is to develop an exact algorithm whose average runtime is much faster than traditional methods, although the worst-case complexity is doomed to be exponential in the number of explicitly given coalitions. Based on existing techniques, we can construct an algorithm to check core-non-emptiness for coalition structures, which we call CoreP. In this ∗) is obtained by solving an integer programming (IP) problem [25]. algorithm, the value of optimal coalition structure V (CS∗) can be divided without making a blocking (dissatisfied) coalition by solving a linear The algorithm checks whether V (CSprogramming (LP) problem [8].In this paper, we propose an exact algorithm called CoreD, which utilizes the dual problem of the linear relaxation of the above IP problem. Experimental evaluations show that CoreD is by far superior to CoreP when the core is empty. To find a +second-best payoff vector when the core is empty, we introduce a new approximate solution concept called weak ε-corefor the weak ε-core for the optimal coalition structure. The weak ε-core is defined for a particular coalition structure that may or may not be not optimal, relaxes only the non-blocking condition with parameter ε, and efficiently distributes the does not specify a particular coalition rewards that the coalition structure earns. On the other hand, the weak ε-corestructure beforehand. It then relaxes the efficiency condition of the weak ε-core (for the optimal coalition structure), in addition to the non-blocking condition, and efficiently distributes the reward that the dual solution provides. Thus, the sum of the elements in the payoff vector, i.e., the sum of the rewards distributed to agents, can be less than the value of the optimal coalition structure, but the difference must be at most ε · n, where n is the number of agents. Based on the idea of CoreD, we also develop an algorithm for checking the non-emptiness of the weak ε-corecalled ECore+(ε).++This paper is organized as follows. Section 2 briefly describes the basic terms and notations and Section 3 introduces an existing technique for checking core-non-emptiness, proposes our proposed technique, and derives an associated theorem. Based on the our technique, Section 4 develops a novel solution concept, which we call weak ε-core. Section 5 empirically examines our proposed algorithm from some criteria. Section 6 describes four issues to our contributions, and Section 7concludes this paper.+1.1. Related worksThis subsection briefly explores related works. In traditional models of coalitional game theory, it is assumed that all coalitions are possible and that the characteristic function is super-additive. Forming the grand coalition is guaranteed to be optimal and the main research topic is how to divide the gain of the grand coalition among agents. The traditional theory of coalitional games provides a number of solution concepts, such as the core [13], the Shapley value [39], and the nucleolus [38].More recently, AI and MAS researchers have been considering the case where forming the grand coalition is not possible or not optimal. In such cases, agents should form a coalition structure to maximize the reward they can obtain. This problem is called the coalition structure generation (CSG) problem and has been an active research topic in AI and MAS.Sandholm et al. [37] ",
            {
                "entities": [
                    [
                        3578,
                        3606,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 189 (2012) 19–47Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiscovering hidden structure in factored MDPsAndrey Kolobov∗, Mausam, Daniel S. WeldDept. of Computer Science and Engineering, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 1 August 2010Received in revised form 8 April 2012Accepted 9 May 2012Available online 15 May 2012Keywords:Markov Decision ProcessMDPPlanning under uncertaintyGeneralizationAbstractionBasis functionNogoodHeuristicDead end1. IntroductionMarkov Decision Processes (MDPs) describe a wide variety of planning scenarios rangingfrom military operations planning to controlling a Mars rover. However, today’s solutiontechniques scale poorly, limiting MDPs’ practical applicability. In this work, we proposealgorithms that automatically discover and exploit the hidden structure of factored MDPs.Doing so helps solve MDPs faster and with less memory than state-of-the-art techniques.Our algorithms discover two complementary state abstractions — basis functions andnogoods. A basis function is a conjunction of literals; if the conjunction holds true in a state,this guarantees the existence of at least one trajectory to the goal. Conversely, a nogood is aconjunction whose presence implies the non-existence of any such trajectory, meaning thestate is a dead end. We compute basis functions by regressing goal descriptions through adeterminized version of the MDP. Nogoods are constructed with a novel machine learningalgorithm that uses basis functions as training data.Our state abstractions can be leveraged in several ways. We describe three diverseapproaches — GOTH, a heuristic function for use in heuristic search algorithms suchas RTDP; ReTrASE, an MDP solver that performs modified Bellman backups on basisfunctions instead of states; and SixthSense, a method to quickly detect dead-end states.In essence, our work integrates ideas from deterministic planning and basis function-basedapproximation, leading to methods that outperform existing approaches by a wide margin.© 2012 Elsevier B.V. All rights reserved.Markov Decision Processes (MDPs) are a popular framework for modeling problems involving sequential decision-makingunder uncertainty. Examples range from military-operations planning to user-interface adaptation to the control of mobilerobots [1,36]. Unfortunately, however, existing techniques for solving MDPs, i.e. deciding which actions to execute in varioussituations, scale poorly, and this dramatically limits MDPs’ practical utility.Humans perform surprisingly well at planning under uncertainty, largely because they are able to recognize and reuseabstractions, generalizing conclusions across different plans. For example, after realizing that the walls of a particular Marscrater are too steep for the rover to escape, a human planner would abandon attempts to collect any of the rock samples inthe crater, while a traditional MDP solver might rediscover the navigational problem as it considered collecting each samplein turn.This article presents new algorithms for automatically discovering and exploiting such hidden structure in MDPs. Specif-ically, we generate two kinds of abstraction, basis functions and nogoods, each of which describes sets of states that share asimilar relationship to the planning goal. Both basis functions and nogoods are represented as logical conjunctions of statevariable values, but they encode diametrically opposite information. When a basis function holds in a state, this guarantees* Corresponding author.E-mail addresses: akolobov@cs.washington.edu (A. Kolobov), mausam@cs.washington.edu (Mausam), weld@cs.washington.edu (D.S. Weld).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.05.002\f20A. Kolobov et al. / Artificial Intelligence 189 (2012) 19–47that a certain trajectory of action outcomes has a positive probability of reaching the goal. Our algorithms associate weightswith each basis function, encoding the relative quality of the different trajectories. In contrast, when a nogood holds in astate, it signifies that the state is a dead-end; no trajectory can reach the goal from this state. Continuing the Mars roverexample, a conjunction that described presence in the steep-walled crater would be a nogood.Our notions of basis function and nogood are similar to the rules learned in logical theories in explanation-based learn-ing and constraint satisfaction [27,14], but our work applies them in a probabilistic context (e.g., learns weights for basisfunctions) and provides new mechanisms for their discovery. Previous MDP algorithms have also used basis functions [21,39], but to perform generalization between different problems in a domain rather than during the course of solving a singleproblem. Other researchers have used hand-generated basis functions in a manner similar to ours [22,23,20], but we presentmethods for their automatic generation.1.1. Discovering nogoods and basis functionsWe generate basis functions by regressing goal descriptions along an action outcome trajectory using a determinizedversion of the probabilistic domain theory. Thus, the trajectory is potentially executable in all states satisfying the basisfunction. This justifies performing Bellman backups on basis functions, rather than states — generalizing experience acrosssimilar states. Since many basis functions typically hold in a given state, the value of a state is a complex function of theapplicable basis functions.We discover nogoods using a novel machine learning algorithm that operates in two phases. First it generates candidatenogoods with a probabilistic sampling procedure using basis functions and previously discovered dead ends as trainingdata. It then tests the candidates with a planning graph [6] to ensure that no trajectories to the goal could exist from statescontaining the nogood.1.2. Exploiting nogoods and basis functionsWe present three algorithms that leverage our basis function and nogood abstractions to speed MDP solution and reducememory usage.• GOTH uses a full classical planner to generate a heuristic function for an MDP solver for use as an initial estimate of statevalues. While classical planners have been known to provide an informative approximation of state value in probabilisticproblems, they are too expensive to call from every newly visited state. GOTH amortizes this cost across multiple statesby associating weights to basis functions and thus generalizing the heuristic computation. Empirical evaluation showsGOTH to be an informative heuristic that saves MDP solvers considerable time and memory.• ReTrASE is a self-contained MDP solver based on the same information-sharing insight as GOTH. However, unlike GOTH,which sets the weight of each basis function only once to provide the starting guess at states’ values, ReTrASE learnsthe basis functions’ weights by evaluating each function’s “usefulness” in a decision-theoretic way. By aggregating theweights, ReTrASE constructs a state value function approximation and, as we show empirically, produces better policiesthan the participants of the International Probabilistic Planning Competition (IPPC) on many domains while using littlememory.• SixthSense is a method for quickly and reliably identifying dead ends, i.e., states with no possible trajectory to the goal, inMDPs. In general, this problem is intractable — one can prove that determining whether a given state has a trajectoryto the goal is PSPACE-complete [19]; therefore, it is unsurprising that modern MDP solvers often waste considerableresources exploring these doomed states. SixthSense acts as a submodule of an MDP solver, helping it detect and avoiddead ends. SixthSense employs machine learning, using basis functions as training data, and is guaranteed never togenerate false positives. The resource savings provided by SixthSense are determined by the fraction of dead ends inthe MDP’s state space and reach 90% on some IPPC benchmark problems.In the rest of the paper, we present these algorithms, discuss their theoretical properties, and evaluate them empirically.Section 2 reviews the background material and introduces relevant definitions, illustrating these with a running example.Sections 3, 4, and 5 present descriptions of and empirical results on GOTH, ReTrASE, and SixthSense respectively. Section 6discusses potential extensions of the presented algorithms. Finally, Section 7 describes the related work and Section 8concludes the paper.2. Preliminaries2.1. ExampleThroughout the paper, we will be illustrating various concepts with the following scenario, called GremlinWorld. Con-sider a gremlin that wants to sabotage an airplane and stay alive in the process. To achieve the task, the gremlin can pickup several tools. The gremlin can either tweak the airplane with a screwdriver and a wrench, or smack it with a hammer.\fA. Kolobov et al. / Artificial Intelligence 189 (2012) 19–4721(define (domain GremlinWorld)(:types tool)(:predicates (has ?t - tool)(gremlin-alive)(plane-broken))(:constants Wrench - toolScrewdriver - toolHammer - tool)(:action pick-up:parameters (?t - tool):precondition (and (not (has ?t))):effect (and (has ?t)))(:action tweak:parameters ():precondition (and (has Screwdriver):effect (and (plane-broken)))(has Wrench))(:action smack:parameters ():precondition (and (has Hammer)):effect (and (plane-broken)(probabilistic 0.9)(and (not (gremlin-alive))))))(define (problem GremlinProb)(:domain GremlinWorld)(:init (gremlin-alive))(:goal (and (gremlin-alive) (plane-broken))))Fig. 1. A PPDDL-style description of the example MDP, GremlinWorld, split into domain and problem parts.However, smacking will, with high probability, lead to accidental detonation of the airplane’s fuel, which destroys the air-plane but also kills the gremlin. Fig. 1 describes this s",
            {
                "entities": [
                    [
                        3876,
                        3904,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 133–155Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLocal properties in modal logicHans van Ditmarsch a, Wiebe van der Hoek b,∗, Barteld Kooi ca Department of Logic, University of Seville, Spainb Department of Computer Science, University of Liverpool, UKc Faculty of Philosophy, University of Groningen, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 18 August 2011Received in revised form 1 March 2012Accepted 22 April 2012Available online 2 May 2012Keywords:Knowledge representationModal logicCorrespondenceCanonicityLocal propertiesEpistemic logicIn modal logic, when adding a syntactic property to an axiomatisation, this property willsemantically become true in all models, in all situations, under all circumstances. Forinstance, adding a property like Ka p → Kb p (agent b knows at least what agent a knows)to an axiomatisation of some epistemic logic has as an effect that such a property becomesglobally true, i.e., it will hold in all states, at all time points (in a temporal setting), afterevery action (in a dynamic setting) and after any communication (in an update setting),and every agent will know that it holds, it will even be common knowledge. We propose away to express that a property like the above only needs to hold locally: it may hold in theactual state, but not in all states, and not all agents may know that it holds. We achieve thisby adding relational atoms to the language that represent (implicitly) quantification over allformulas, as in ∀p(Ka p → Kb p). We show how this can be done for a rich class of modallogics and a variety of syntactic properties. We then study the epistemic logic enrichedwith the syntactic property ‘knowing at least as much as’ in more detail. We show that theenriched language is not preserved under bisimulations. We also demonstrate that addingpublic announcements to this enriched epistemic logic makes it more expressive, which isfor instance not true for the ‘standard’ epistemic logic S5.© 2012 Elsevier B.V. All rights reserved.1. IntroductionModal logic has become the framework for formalising areas in computer science and artificial intelligence as diverse asdistributed computing [14], reasoning about programs [15], verifying temporal properties of systems [17], game theoreticreasoning [25], and specifying and verifying multi-agent systems [31]. Regarding the latter example alone, since Moore’spioneering work [19] on knowledge and action, agent theories like intention logic [5] and BDI [20] use modal logic (wherethe modalities represent time, action, informational attitudes like knowledge or belief, or motivational attitudes like desiresor intentions) to analyse interactions between modalities, like perfect recall, no-learning, realism, or different notions of com-mitment. As for epistemic modal logic, since the seminal work of Hintikka [16], modal epistemic logic has played a keyrole in knowledge representation, witnessed by the literature on reasoning about knowledge in computer science [7], andartificial intelligence [18]. The current activities in dynamic epistemic logic [1,27] can be seen as providing a modal logicalanalysis in the area of belief revision, thereby providing it with a natural basis for multi-agent belief revision, giving anaccount of the change of higher order information, and capturing this all in one and the same object language: a modallanguage, indeed.The popularity of modal logic in those areas is partly explained by its appealing semantics: the notion of state isa very powerful one when it comes to modeling computations of a machine, or describing possibilities that an agent* Corresponding author.E-mail addresses: hvd@us.es (H. van Ditmarsch), wiebe@csc.liv.ac.uk (W. van der Hoek), B.P.Kooi@rug.nl (B. Kooi).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.007\f134H. van Ditmarsch et al. / Artificial Intelligence 187–188 (2012) 133–155thinks/desires/fears to be possible. Another strong feature of modal logic is its flexibility: the fact that temporal, dynamic,informational and motivational attitudes can be represented by modalities does not mean that they all satisfy the same laws.Rather, depending on the interpretation one has in mind, one can decide to either embrace or abandon certain principlesfor each of the modalities used. Syntactically, this means one assumes a number of axioms or inference rules for a modalityor for the interaction of some modalities, and more often than not, this semantically corresponds to assuming some specificproperties of the associated accessibility relations in the corresponding models.In the context of epistemic logic for instance, adding specific modal axioms allows one to specify that the knowingagent is veridical (Ka p → p): if agent a knows that p, then p must be true, or that he is positively (Ka p → Ka Ka p) ornegatively (¬Ka p → Ka¬Ka p) introspective. Those axioms happen to correspond (in a precise way: correspondence theoryfor modal logic is already some decades old, cf. [23]) to reflexivity, transitivity and Euclidicity of the associated accessibilityrelation Ra, respectively. Moreover, the axioms are canonical for it: adding the syntactic axiom to a modal logic enforces thecanonical model for the logic to have the corresponding property, which then in turn implies that completeness of the logicwith respect to the class of models satisfying that relational property is guaranteed. At this point, it is important to note thedifference between Ka p → p as a formula and that as a scheme, or axiom: as a formula, it merely expresses that regardingthe atom p, agent a does not know it without it being true. However, when we assume it as an axiom, or as a scheme, itmeans that we declare it to hold for every substitution instance of p, in other words, we assume that for all formulas ϕ,the implication Kaϕ → ϕ holds.It is often argued (indeed, already by Hintikka in [16]) that a distinguishing feature between knowledge and belief isthat whereas knowledge is veridical, belief need not be, i.e., the scheme Ba p → p should not be assumed as an axiom forbelief. This then simply entails that epistemic logics have veridicality as an axiom, and doxastic logics have not. Semanticallyspeaking: the accessibility relations denoting knowledge are reflexive, those denoting belief need not be. But how then todeal with a situation where we want to express that “currently, a’s beliefs happen to be true”? If we add Ba p → p asan axiom to our logic, the effect is that in all models (with respect to which the logic is complete), and in all states, allinstances of that axiom are true, i.e., for all models M, for all states s and for all formulas ϕ, we then have M, s |(cid:5) Baϕ → ϕ.Given a model M and a state s we can express that a’s belief that an individual proposition q holds is correct: M, s |(cid:5) Baq ∧q.And we can express that a’s belief about q is correct: M, s |(cid:5) (Baq → q) ∧ (Ba¬q → ¬q). But what we cannot express inmodal logic is that Baϕ → ϕ holds for all ϕ in one state, without claiming at the same time it should hold throughout themodel. As a consequence, we cannot express in the object language that agent b thinks that agent a’s beliefs are correct,while agent c believes that a is wrong about a proposition q. The closest one gets to expressing that would be to say thatfor all ϕ, in M, s we have M, s |(cid:5) Bb(Baϕ → ϕ) ∧ Bc((Baq ∧ ¬q) ∨ (Ba¬q ∧ q)) (but here, the quantification over ϕ is on ameta-level, and not in the scope of Bb). Neither can we say, in a temporal doxastic context, that a’s beliefs now are correct,but tomorrow they need not be.To give another example of the same phenomenon, suppose one adds the scheme Ka p → Kb p to a modal logic (b knowseverything that a knows). Semantically, this means Rb ⊆ Ra. If the logic is about a set of agents A, then it becomes commonknowledge among A that b knows at least what a knows! And if there is a notion of time, we have that it will always bethe case that b knows at least what a knows, and, when having modalities for actions, it follows that no action can makeit come about that a has a secret for b, in particular, it is impossible to inform a about something that b does not alreadyknow—this rules out dynamics which are, in contrast, very possible in dynamic epistemic logic.So, the general picture in modal logic that we take as our starting point is the following. One has a modal logic to whichone adds an axiom scheme θ (say, Ba p → p). If one is lucky, the scheme corresponds to a relational property Θ(x) (in thecase above, Rxx). However, adding θ to the logic means having Θ(x) true everywhere, implying that θ is always true. Whatwe are after is looking at ways to enforce the scheme θ locally. To do so, we will add a marker (cid:2) to the modal language,such that (cid:2) is true locally, in a state s, if and only if Θ is true, locally (i.e., Rss holds).In [28], in the context of a multi-agent logic S5, this is done for the scheme ‘knowing at least as much as’. The expressiona (cid:3) b in [28], when true at w means formally ‘a considers at least as many accessible worlds from w as b’, and informally‘a is at least as uncertain as b about the actual state of affairs at w’, is an example of such a marker (cid:2)(a, b), namedSup(a, b) here, and in this case Θ(a, b)(x) is the property ∀ y(Rbxy ⇒ Raxy). The results of [28] are generalised in [29] tomore general modal logics K(+ϕ1, . . . , +ϕn) for formulas ϕi satisfying some additional condition, and this is also the mainfocus of our current contribution.It is also possible to add several markers at the same time. This then enables that not only can we make global propertieslocally true, but it also allows for more subtle quantifications over formulas than is allowed in modal logic. This makes itpossible to express properties like ",
            {
                "entities": [
                    [
                        3956,
                        3984,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2223–2245Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintParallel belief revision: Revising by sets of formulasJames Delgrande∗, Yi JinSchool of Computing Science, Simon Fraser University, Burnaby, B.C. V5A 1S6, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 30 July 2010Received in revised form 2 October 2011Accepted 3 October 2011Available online 7 October 2011Keywords:Knowledge representation and reasoningBelief changeIterated belief revisionEpistemic statesThe area of belief revision studies how a rational agent may incorporate new informationabout a domain into its belief corpus. An agent is characterised by a belief state K , andreceives a new item of information α which is to be included among its set of beliefs.Revision then is a function from a belief state and a formula to a new belief state.We propose here a more general framework for belief revision, in which revision is afunction from a belief state and a finite set of formulas to a new belief state. In particular,we distinguish revision by the set {α, β} from the set {α ∧ β}. This seemingly innocuouschange has significant ramifications with respect to iterated belief revision. A problem inapproaches to iterated belief revision is that, after first revising by a formula and then by aformula that is inconsistent with the first formula, all information in the original formulais lost.This problem is avoided here in that, in revising by a set of formulas S, the resulting beliefstate contains not just the information that members of S are believed to be true, butalso the counterfactual supposition that if some members of S were later believed to befalse, then the remaining members would nonetheless still be believed to be true. Thusif some members of S were in fact later believed to be false, then the other elementsof S would still be believed to be true. Hence, we provide a more nuanced approach tobelief revision. The general approach, which we call parallel belief revision, is independentof extant approaches to iterated revision. We present first a basic approach to parallelbelief revision. Following this we combine the basic approach with an approach due to Jinand Thielscher for iterated revision. Postulates and semantic conditions characterising theseapproaches are given, and representation results provided. We conclude with a discussionof the possible ramifications of this approach in belief revision in general.© 2011 Elsevier B.V. All rights reserved.1. IntroductionAn agent situated in a sufficiently complex domain will have only incomplete and possibly inaccurate information aboutthat domain. Consequently, such an agent would be expected to receive new information about the domain which it wouldincorporate into its belief corpus. Since new information may conflict with the agent’s accepted beliefs, the agent may alsohave to discard some of its beliefs before the new information can be consistently incorporated. Belief revision is the areaof knowledge representation that addresses how an agent may incorporate new information about a domain into its beliefcorpus. It is generally accepted that there is no single best revision operator, and different agents may have different revisionfunctions. However, revision functions are not arbitrary, but may be considered as being guided or characterised by variousrationality criteria, expressed formally as a set of postulates. The original and best-known set of postulates is called the AGMpostulates [1,16] named after the developers of this framework. As well, several formal constructions of revision functions* Corresponding author.E-mail addresses: jim@cs.sfu.ca (J. Delgrande), yij@cs.sfu.ca (Y. Jin).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.10.001\f2224J. Delgrande, Y. Jin / Artificial Intelligence 176 (2012) 2223–2245have been proposed based, for example, on an ordering on sentences of the language or on an ordering on possible states ofthe world. Ideally, a set of postulates is linked with a formal construction by a representation result, showing that a revisionfunction that satisfies a postulate set can be represented by the formal construction, and vice versa.The foundations of AGM revision are well studied and well understood.1 Subsequently, there has been a great deal ofattention paid to iterated belief revision, which addresses logical relations among a sequence of revisions involving possibly-conflicting observations. While there has been much progress in the area of iterated belief revision, virtually all such worksuffers from the following problem: if one revises by a formula and then by a formula that is inconsistent with this formula,then the agent’s beliefs are exactly the same as if only the second revision had taken place.For example, consider the situation where there was a party, but where you have no knowledge about whether Alice (a)or Bob (b) were there. You are subsequently informed by a reliable source that both Alice and Bob went to the party. Thiswould correspond to a revision by a ∧ b, and your resulting belief state would be one in which you believe a ∧ b to betrue. You later learn that Alice in fact did not go to the party. Not only do you now accept ¬a, but in all major approachesto iterated belief revision, including [9,6,32,21], you no longer accept b either. While there may indeed be cases where it’sreasonable to no longer believe Bob was at the party (for example perhaps Bob is Alice’s spouse), this certainly shouldn’tbe a required outcome.This example can be exaggerated to emphasise the point: Consider where an agent initially has no contingent beliefs,and so its beliefs are characterised by the set of tautologies. Next, a substantial body of knowledge, given by the conjunctionp1 ∧ · · · ∧ p1012 , is loaded into the agent’s knowledge base. If we subsequently revise by, say, the negation of p1, then allother knowledge is lost. That is, if the agent’s original (tautological) beliefs were given by K and ∗ is the revision function,we would obtain:(cid:2)(cid:3)K ∗ (p1 ∧ · · · ∧ p1012 )∗ ¬p1 ≡ K ∗ ¬p1.(1)Thus all other information is lost, except for the newly-negated item. Again, this is clearly too strong a condition to imposeon every revision function in all circumstances.We suggest that this problem is appropriately addressed not by modifying the foundations of belief revision, but ratherby providing a more nuanced or expressive approach to revision. Specifically, we propose that the second argument of arevision function be generalised to be a set of formulas. This then distinguishes revision by a set of formulas from revisionby the conjunction of that set of formulas. Consider again our Alice/Bob example, where again at the outset you have nobeliefs about whether either of them attended a party or not, but you are subsequently informed that they both went tothe party. Consequently, if you were now asked “Do you believe that Alice went to the party?”, clearly you would answer inthe affirmative. Assume further that you have no reason to believe that Alice and Bob know each other well, nor have beenin contact; i.e. each individual’s attendance is independent of the other’s. If you were asked “If it were in fact the case thatAlice did not go, would you still believe that Bob went?”, then again you would answer in the affirmative. However, it canbe noted that this last question is a counterfactual query, in that as far as you know the antecedent is false. We are not goingto be concerned with counterfactuals per se in this paper; however, this does have implications for further revisions: If youwere subsequently informed that in fact Alice did not go, then you should in turn continue to believe that Bob went. If, onthe other hand, you had some reason to believe that Alice and Bob’s attendance were linked – for example that they’re acouple – then this would no longer apply.The key point here is that we are treating the propositions A and B as separate items of information. Our central thesisis that revision by a conjunction and revision by the set of conjuncts should be treated differently. If a formula is takenas representing some item of information, then informally a conjunction represents a single item of information, while thecorresponding set of conjuncts represents a collection of items of information. To be sure, the conjunction α ∧ β and theset {α, β} have the same logical content, in that they entail exactly the same formulas. Hence an agent’s contingent beliefsshould be the same regardless of whether a revision is by a conjunction or a corresponding set of formulas. However,as argued above, in revising by a set {α, β} the agent’s resulting belief state should be such that, if there is no knownconnection between α and β, then if β were subsequently learned to be false, then α should still be believed to be true.To this end, we develop an account of belief revision that we call parallel belief revision in which the second argument toa revision function is a finite set of formulas. Thus, if the agent’s belief state is given by K2 and ∗ is a revision function, thenwe distinguish K ∗ {α ∧ β} from K ∗ {α, β}. In the former, revision is by a single formula that happens to be expressed as aconjunction. If a subsequent revision contradicts this formula, then this formula is simply no longer believed. On the otherhand, if the agent views α and β as independent, then it makes sense that α is believed in K ∗ {α, β} ∗ {¬β}, since if oneelement of the input set is contradicted, this need not affect belief in other element. Essentially, for a revision K ∗ {α, β}, theagent comes to believe not only that α and β are contingently true, but also counterfactual assertions such as if β were falsethen α would (where “reasonable”) still be believed to be true. In terminology introduced in the next section, the agent’sbelief state or",
            {
                "entities": [
                    [
                        3855,
                        3883,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 240–252Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUsing Wikipedia to learn semantic feature representations of concreteconcepts in neuroimaging experimentsFrancisco Pereira∗, Matthew Botvinick, Greg DetrePsychology Department and Princeton Neuroscience Institute, Princeton University, Princeton, NJ 08540, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Available online 10 July 2012Keywords:WikipediaMatrix factorizationfMRISemantic features1. IntroductionIn this paper we show that a corpus of a few thousand Wikipedia articles about concreteor visualizable concepts can be used to produce a low-dimensional semantic featurerepresentation of those concepts. The purpose of such a representation is to serve asa model of the mental context of a subject during functional magnetic resonance imaging(fMRI) experiments. A recent study by Mitchell et al. (2008) [19] showed that it waspossible to predict fMRI data acquired while subjects thought about a concrete concept,given a representation of those concepts in terms of semantic features obtained withhuman supervision. We use topic models on our corpus to learn semantic features fromtext in an unsupervised manner, and show that these features can outperform those inMitchell et al. (2008) [19] in demanding 12-way and 60-way classification tasks. We alsoshow that these features can be used to uncover similarity relations in brain activation fordifferent concepts which parallel those relations in behavioral data from human subjects.© 2012 Elsevier B.V. All rights reserved.Over the last few years machine learning classifiers have increasingly been used to demonstrate that the pattern of brainactivation measured with functional magnetic resonance imaging (fMRI) contains information about stimuli being seen,subject decisions and many other aspects of task performance (see [9,18,26,10,29]). Recently, however, interest has expandedto discovering how the information present is encoded and also to testing hypotheses about that encoding. One approach todoing this is to postulate a model for the information being created in response to stimuli and learning a mapping betweenthat information and brain activation patterns; this model can then be tested on new stimuli not used in building it and forwhich the true brain activation patterns are known (a very elegant example of this for visual cortex by [11]). Conversely,one can also test such models by trying to reproduce the stimulus that gave rise to the brain activation patterns from thosepatterns. Examples of these would be reconstruction of a simple visual stimulus [20], a pattern of dots mentally visualizedby the subject [32] and producing a structural and semantic description of a stimulus scene [23].All of the examples above pertain to visual cortex and pictorial stimuli, as there are many models for the informationprocessing being carried out by visual cortex. But what model should one consider if one is interested in the meaning ofa concept, as opposed to its visual representation?When considering the representation of the meaning of a concept in someone’s mind, one possible view is that therepresentation is made up of several semantic features, present to varying degrees. Examples could be whether it is aliveversus inanimate or, if the latter, a man-made artifact versus something natural. Features can also be shared between* Corresponding author.E-mail address: fpereira@princeton.edu (F. Pereira).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.005\fF. Pereira et al. / Artificial Intelligence 194 (2013) 240–252241concepts belonging to the same semantic category, e.g. one would expect “saw” and “hammer” to share something by virtueof their both being tools.A pioneering study [19] showed that one could predict the brain activation in response to a line drawing of a concreteconcept, together with the noun naming it, if given semantic feature values for that concept and the patterns of brainactivation for other concepts. The authors also introduced a procedure for obtaining semantic feature values from a textcorpus which required specifying a number of verbs and computing their occurrence with nouns naming concepts in a largecorpus.Our paper is close in spirit to this, and is motivated by two related questions. The first is whether one can discovera “semantic space” to represent concrete concepts, by learning semantic features from a relatively small corpus. Our firstcontribution is to show that this can be done from a corpus containing Wikipedia articles defining concepts, rather thanjust instances of the words naming the concepts, as would be the case in standard corpora. Furthermore, the use of topicmodels [3] for this means that any number of features may be produced in principle, sidestepping the need to specify verbs.The second question is how to determine whether such a corpus reflects, to some degree, the semantic representations ofthose concepts in the mind of human subjects, using fMRI data. For this we will show that we can use the semantic featurerepresentation learned to predict semantic feature values from brain activation, instead of brain activation from semanticfeature values. This semantic feature representation can be used to decode the subject’s mental context, as well as revealsimilarity structure between representations of related concepts that is not readily apparent if we solely consider fMRIdata.2. Related workThere are many theories for how semantic information is represented in the brain (see [22] for an extensive review).Almost all of these theories rely to some extent on the notion of features, the attributes of a particular concrete concept [16](e.g. “is alive” or “is made of wood”). From that perspective, features are used for including or excluding concepts fromparticular categories, for judging similarity between concepts or for making semantic judgments (often in conjunction withcategorical or taxonomic structure).One way of obtaining features is by painstakingly asking subjects to produce them for many different concrete concepts,and tallying those that are named often, those that are deemed most important to distinguishing concepts or categories,etc. The result of this is known as a semantic feature production norm [16]. This does not guarantee that every relevantfeature will be generated – in fact, those that are distinctive are more likely to come up – and has the further problem thatno data is available for concepts not included in the norm.It is possible to address this issue without resorting to subjects by making the assumption that semantic features whichdistinguish the meanings of concepts are reflected in the usage statistics of the nouns naming them within a very largetext corpus. This relies on the notion that those features would be shared by most people thinking about the same concept,as talking to someone about concepts such as chair or table requires a common understanding of the characteristics of thatconcept. The pioneering paper that inspired our work [19] uses this approach, relying on one further assumption.Some of the theories treat semantic knowledge as something stored amodally, independent of perception or actionrelevant to the acquisition and use of the knowledge [6]. Others postulate that that knowledge is stored involving sensoryor functional processing areas and, furthermore, making a semantic judgment might require retrieval of interaction orperception with the situation the judgment is about and possibly even a simulation of that (e.g. What does a peach feel likewhen held? What happens once it is dropped?) [1].Motivated by the latter perspective, [19] assumed that key semantic features in the meaning of a concept would cor-respond to basic sensory and motor activities, actions performed on objects, and actions involving changes to spatialrelationships. They then hand-picked 25 verbs1 related to these activities and actions and computed the co-occurrence of thenoun naming each concept with those 25 verbs in a large text corpus (Google n-gram corpus http://ngrams.googlelabs.com).The 25 co-occurrence counts for each concept became the semantic feature values, after normalization to a unit length vec-tor. The hypothesis underlying this procedure is that the 25 verbs are a good proxy for the main characteristics of a concept,and that their frequent co-occurrence with the corresponding noun in text means that many different sources (and people)have that association in mind when using the noun.The authors then showed that these features corresponded, to some degree, to information present in the brain ofa subject; this was accomplished by showing that one could predict the brain activation in response to a line drawingof a concrete concept, together with the noun naming it, if given semantic feature values for that concept and the patternsof activation for other concepts.There are multiple approaches for learning features from text data, with Latent Semantic Analysis (LSA [13]) beingperhaps the best known, and a tradition of using them to perform psychological tasks or tests with word stimuli (see [31,8]or [21] for applications to EEG, for instance). This work can be seen analytically as operating on a word-by-document matrixand using that to derive a lower-dimensional vector space (or a simplex) where words reside; an excellent review of this and1 See, hear, listen, taste, smell, eat, touch, rub, lift, manipulate, run, push, fill, move, ride, say, fear, open, approach, near, enter, drive, wear, break andclean.\f242F. Pereira et al. / Artificial Intelligence 194 (2013) 240–252Fig. 1. A complex pattern of activation is expressed as a combination of three basic patterns.related vector space approaches is [33]. [12] has shown that features similar to those in [6] – in the form concept–relation–feature – co",
            {
                "entities": [
                    [
                        3641,
                        3669,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1343–1366Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintData reductions, fixed parameter tractability, and random weightedd-CNF satisfiability ✩Yong GaoDepartment of Computer Science, Irving K. Barber School of Arts and Sciences, University of British Columbia Okanagan, Kelowna, Canada V1V 1V7a r t i c l ei n f oa b s t r a c tArticle history:Received 19 December 2008Received in revised form 11 June 2009Accepted 13 June 2009Available online 17 June 2009Keywords:Weighted CNF satisfiabilityFixed parameter tractabilityData reductionRandom instancesPhase transitionsProbabilistic analysisResolution complexityData reduction is a key technique in the study of fixed parameter algorithms. In the AIliterature, pruning techniques based on simple and efficient-to-implement reduction rulesalso play a crucial role in the success of many industrial-strength solvers. Understandingthe effectiveness and the applicability of data reduction as a technique for designingheuristics for intractable problems has been one of the main motivations in studying thephase transition of randomly-generated instances of NP-complete problems.In this paper, we take the initiative to study the power of data reductions in the contextof random instances of a generic intractable parameterized problem, the weighted d-CNFsatisfiability problem. We propose a non-trivial random model for the problem and studythe probabilistic behavior of the random instances from the model. We design an algorithmbased on data reduction and other algorithmic techniques and prove that the algorithmsolves the random instances with high probability and in fixed-parameter polynomial timeO (dknm) where n is the number of variables, m is the number of clauses, and k is thefixed parameter. We establish the exact threshold of the phase transition of the solutionprobability and show that in some region of the problem space, unsatisfiable randominstances of the problem have parametric resolution proof of fixed-parameter polynomialsize. Also discussed is a more general random model and the generalization of the resultsto the model.© 2009 Elsevier B.V. All rights reserved.1. IntroductionThe theory of parameterized complexity and fixed-parameter algorithms is becoming an active research area in recentyears [24,46]. Parameterized complexity provides a new perspective on hard algorithmic problems and fixed-parameteralgorithms have found applications in a variety of research fields. Parameterized problems also arise in many areas ofartificial intelligence (AI) research, including satisfiability, automated reasoning, logic programming, constraint programming,and probabilistic inference [8,10,47,48]. We refer the reader to [34,35] for thorough survey of recent literature.Data reduction is a key technique in designing efficient algorithms for fixed parameter tractable problems [37,46] andexact exponential-time branch-and-reduce algorithms (also known as the search-tree method) for NP-hard problems [27].In several areas of AI, pruning techniques based on simple and efficient-to-implement reduction rules have also been widelyused, most notably in satisfiability testing and constraint processing where backtracking interleaved with the use of highly-efficient implementation of unit propagation and consistency propagation has played a key role in the success of most✩Part of the results appeared in the Proceedings of AAAI’08 [Y. Gao, Phase transitions and complexity of weighted satisfiability and other intractableparameterized problems, in: Proceedings of the 23th AAAI Conference on Artificial Intelligence (AAAI’08), 2008, pp. 265–270. [28]]. The research is supportedby National Science and Engineering Research Council of Canada (NSERC) RGPIN 327587-06 and RGPIN 327587-09.E-mail address: yong.gao@ubc.ca.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.005\f1344Y. Gao / Artificial Intelligence 173 (2009) 1343–1366industrial-strength solvers, and in heuristic state space search where a heuristic function is usually employed to reducethe search space. The power of data reductions have also been demonstrated empirically for many NP-hard problems orintractable parameterized problems such as clique cover [36], dominating set [4], road network related problem [50], andHamiltonian cycle [49]. Experiments also revealed that simple data reduction rules usually have a much better performancethan those predicted by theoretical analyses [11,36,40].Despite the many success stories, our understanding of the effectiveness and the applicability of data reduction as atechnique for designing heuristics for intractable problems is far from complete. The continued interest over the past morethan ten years in the study of the phase transition phenomenon of random instances of NP-complete problems is largelymotivated by the expectation that such study will help shed lights on why simple heuristics work on typical probleminstances and in what situations. See [1,7,14,19,20,30–33,38,51] and references therein. Recently, the problem of detectingbackdoor sets has attracted much attention. The existence of small-sized backdoors naturally leads to efficient algorithms forproblems that are otherwise hard to solve. While the backdoor detection problem are NP-complete and/or fixed-parameterintractable for many types of backdoors, practical SAT-solvers have been found to be able to exploit the existence of small-sized backdoors effectively [23,48].In this work, we take the initiative to extend this line of research on phase transitions to intractable parameterized prob-lems. We hope that the current work on the fixed-parameter tractability of random instances of intractable parameterizedproblems, together with the previous work on the typical-case behavior of random NP-complete problems, will help shedfurther light on the power of data-reduction based heuristics and on the hardness of detecting small-sized backdoors.We study random instances of the weighted d-CNF satisfiability problem (WEIGHTED d-SAT).1 An instance (F , k) of theproblem consists of a d-CNF formula F and a fixed parameter k > 0. The question is to decide if there is a satisfyingassignment that has a Hamming distance k to the all-zero assignment.A random instance of weighted d-CNF satisfiability over n Boolean variables consists of a fixed parameter k and a randomd-CNF formula F n,pk,d generated as follows: for each subset of d variables and with probability p = p(n), a clause over the dvariables is selected uniformly at random from the set of 2d − 1 possible clauses that contain at least one negated literal.This random model of CNF formulas is similar to the various random models used in the study of the standard propositionalsatisfiability problem. Due to a recent result of Marx [41] on the complexity of parameterized Boolean constraint satisfac-tion problems, forbidding clauses that contain positive literals only is not a serious restriction as far as the parameterizedtractability is concerned. A more detailed argument about this will be given in Section 2.We also discuss a more general model F n,pWe design and analyze an algorithm based on data reduction and other algorithmic techniques. It is shown that thealgorithm solves random instances from F n,pk,d with high probability and in fixed-parameter polynomial time O (dknm) wheren is the number of variables and m is the number of clauses in the formula. We establish the exact threshold of the phasetransition of the solution probability and show that in some region of the problem space, unsatisfiable random instances ofthe problem have parametric resolution proof of fixed-parameter polynomial size. The results obtained in this paper give analmost complete characterization of the typical-case behavior of the random instances of WEIGHTED d-SAT.(cid:2)), 1 < dnegated literals areforbidden. Except for the exact threshold of the phase transition and the complexity of typical instances for certain rangeof p, this model seems to pose an interesting challenge for researchers in the areas of AI and theoretical computer science.To the best knowledge of the author, this work is the first in the literature on the fixed-parameter tractability of randominstances of intractable parameterized problems. We expect that the proposed random models and their analysis will helpfacilitate future studies on other parameterized problems such as the backdoor detection problem, on the solution spacegeometry of the standard satisfiability problem, and on the design of more effective neighborhood operators for local searchalgorithms.(cid:2) < d, where clauses containing less than dk,d (d(cid:2)1.1. Main resultsThroughout this paper, we will use n for the number of Boolean variables, m for the number of clauses, and d for theclause size in a CNF formula. We will use k for the parameter of the WEIGHTED d-SAT problem. The symbol p = p(n) isreserved for the clause probability and c for a constant usually appearing in the expression of p. All logarithms in this paperare natural logarithms, i.e., to the base e.The main results of this paper include(1) an algorithm and its analysis showing that instances from the random distribution F n,pcally” fixed-parameter tractable for any clause-probability p(n), in particularly for p = c log n(2) the exact threshold of the phase transition of F n,pk,d ,(3) results on the parametric resolution complexity of random unsatisfiable instances, and(4) extension of some of the above results to a more general model F n,p(cid:2)).k,d (dk,d of WEIGHTED d-SAT are “typi-nd−1 where c > 0 is a constant,1 In AI literature, k is usually used for clause size. Unfortunately, in the study of parameterized algorithms, k is always reserved for the parameter. Wedecide to use k as the parameter and use d for the clause size.\fTable 1The behavior of random instances from F n,punknown. c∗is the thresho",
            {
                "entities": [
                    [
                        3945,
                        3973,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 236–263Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStable models and circumscriptionPaolo Ferraris a, Joohyung Lee b, Vladimir Lifschitz c,∗a Google, Inc., 1600 Amphitheatre Parkway, Mountain View, CA 94043, United Statesb Department of Computer Science and Engineering, Arizona State University, 699 South Mill Avenue, Tempe, AZ 85281, United Statesc Department of Computer Sciences, University of Texas at Austin, 1 University Station C0500, Austin, TX 78712, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Available online 13 April 2010Keywords:Answer set programmingCircumscriptionNonmonotonic reasoningProgram completionStable models1. IntroductionThe concept of a stable model provided a declarative semantics for Prolog programswith negation as failure and became a starting point for the development of answer setprogramming. In this paper we propose a new definition of that concept, which coversmany constructs used in answer set programming and, unlike the original definition, refersneither to grounding nor to fixpoints. It is based on a syntactic transformation similar toparallel circumscription.© 2010 Elsevier B.V. All rights reserved.Answer set programming (ASP) is a form of declarative logic programming oriented towards knowledge-intensive searchproblems, such as product configuration and planning. It was identified as a new programming paradigm ten years ago [25,29], and it has found by now a number of serious applications. An ASP program consists of rules that are syntacticallysimilar to Prolog rules, but the computational mechanisms used in ASP are different: they use the ideas that have led to thecreation of fast satisfiability solvers for propositional logic [11].ASP is based on the concept of a stable model [9]. According to the definition, to decide which sets of ground atoms are“stable models” of a given set of rules we first replace each of the given rules by all its ground instances. Then we verifya fixpoint condition that is similar to the conditions employed in the semantics of default logic [33] and autoepistemiclogic [28] (see [19, Sections 4, 5] for details).In this paper we investigate a new approach to defining the concept of a stable model. It is based on a syntactictransformation similar to circumscription [26,27]. The new definition refers neither to grounding nor to fixpoints. It turnsout to be more general, in a number of ways, than the original definition.This treatment of stable models may be of interest for several reasons. First, it provides a new perspective on theplace of stable models within the field of nonmonotonic reasoning. We can distinguish between “fixpoint” nonmonotonicformalisms, such as default logic and autoepistemic logic, and “translational” formalisms, such as program completion [1]and circumscription. In the past, stable models were seen as part of the “fixpoint tradition.” The remarkable similaritybetween the new definition of a stable model and the definition of circumscription is curious from this point of view.Second, we expect that the new definition of a stable model will provide a unified framework for useful answer setprogramming constructs that have been defined and implemented by different research groups. For instance, it may help uscombine choice rules in the sense of lparse [34] with aggregates in the sense of dlv [3]. A step in this direction is describedin [14].* Corresponding author.E-mail address: vl@cs.utexas.edu (V. Lifschitz).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.011\fP. Ferraris et al. / Artificial Intelligence 175 (2011) 236–263237Third, our definition is applicable to non-Herbrand models. In such a model, different ground terms may have the samevalue. This may be useful for knowledge representation purposes; we may wish to write, for instance:Father(Jack) = Father(Jane).This possibility is related also to the use of arithmetic functions in ASP, when different ground terms may have the samevalue (2 + 2 = 1 + 3).The new definition of a stable model is introduced in Section 2, and its relation to the original definition is discussedin Section 3. Several useful theorems about the new concept are stated in Section 4. Then we extend the idea of strongequivalence to this framework (Section 5), relate general stable models to program completion (Section 6), and define“pointwise stable models,” which are similar to pointwise circumscription (Section 7). In Section 8, we show how ourtheory of stable models handles strong (or classical) negation, and Section 9 discusses related work. Proofs of theorems arecollected in Appendix A.To make the presentation more self-contained, we include brief reviews of parallel and pointwise circumscription (Sec-tions 2.2 and 7.1) and of two approaches to the stable model semantics proposed earlier (Section 3.1).This article is an extended version of the conference paper [6].2. Stable models2.1. Logic programs as first-order sentencesThe concept of a stable model will be defined here for first-order sentences,1 possibly containing function constantsand equality. Logic programs are viewed in this paper as alternative notation for first-order sentences of special types. Forinstance, we treat the logic programp(a, a),p(a, b),q(x) ← p(x, y)as shorthand forp(a, a) ∧ p(a, b) ∧ ∀xy(cid:2)(cid:3)p(x, y) → q(x).The constraint← p(x), not q(x)(1)(2)(3)is identified with the formula(cid:2)∀x¬(cid:3)p(x) ∧ ¬q(x),and the disjunctive rulep(x); q( y) ← r(x, y)with(cid:2)r(x, y) →(cid:2)∀xy(cid:3)(cid:3)p(x) ∨ q( y).As another example, take the choice rule(cid:4)(cid:5)p(x)← q(x).It says, informally speaking: for every x such that q(x), choose arbitrarily whether or not to include p(x) in the stable model.We can treat this rule as shorthand for(cid:2)(cid:3)(cid:3).(4)(cid:2)q(x) →∀xp(x) ∨ ¬p(x)This formula is logically valid, so that appending it as a conjunctive term to any sentence F would not change the class ofmodels of F . But the class of stable models of F may change, as we will see, after appending (4).The next example involves an aggregate. The rulep(x) ← # card(cid:4)(cid:5)y: q(x, y)< 2means intuitively: if the cardinality of the set { y: q(x, y)} is less than 2 then include p(x) in the stable model. We can treatthis rule as an abbreviation for the formula(cid:2)∀x¬∃ y1 y2(cid:2)q(x, y1) ∧ q(x, y2) ∧ y1 (cid:9)= y2(cid:3)(cid:3)→ p(x).(5)1 A sentence is a formula without free variables.\f238P. Ferraris et al. / Artificial Intelligence 175 (2011) 236–2632.2. Review of circumscriptionSince the new definition of a stable model is similar to the definition of parallel circumscription, we will begin with abrief review of the latter.Both definitions use the following notation. If p and q are predicate constants of the same arity then p (cid:2) q stands forthe formula(cid:2)(cid:3)p(x) → q(x),∀xwhere x is a tuple of distinct object variables. If p and q are tuples p1, . . . , pn and q1, . . . , qn of predicate constants thenp (cid:2) q stands for the conjunction(p1 (cid:2) q1) ∧ · · · ∧ (pn (cid:2) qn),and p < q stands for (p (cid:2) q) ∧ ¬(q (cid:2) p). In second-order logic, we apply the same notation to tuples of predicate variables.Let p be a list of distinct predicate constants.2 The circumscription operator with the minimized predicates p, denoted byCIRCp, is defined as follows: for any first-order formula F , CIRCp[F ] is the second-order formula(cid:2)F ∧ ¬∃u(cid:3)(u < p) ∧ F (u),where u is a list of distinct predicate variables of the same length as p, and F (u) is the formula obtained from F bysubstituting the variables u for the constants p.3If the list p is empty then we understand CIRCp[F ] as F . We will drop the subscript in the symbol CIRCp when this doesnot lead to confusion.For any sentence F , a p-minimal (or simply minimal) model of F is an interpretation of the underlying signature thatsatisfies CIRCp[F ]. Since the first conjunctive term of CIRCp[F ] is F , it is clear that every minimal model of F is a modelof F .Example 1. If F is formula (2) then CIRCpq[F ] is(cid:3)(cid:3)(cid:2)(cid:2)∀xyp(a, a) ∧ p(a, b) ∧∧ ¬∃uv(cid:2)(cid:2)(cid:3)(u, v) < (p, q)p(x, y) → q(x)∧ ∀xy(cid:2)u(a, a) ∧ u(a, b) ∧(cid:2)u(x, y) → v(x)(cid:3)(cid:3)(cid:3).It can be equivalently rewritten without second-order variables as follows:(cid:2)∀x(cid:3)p(x, y) ↔ (x = a ∧ y = a) ∨ (x = a ∧ y = b)(cid:2)q(x) ↔ x = a∧ ∀xExample 2. Let F be the formula(cid:2)(cid:3)p(x, y) → t(x, y)∀xy∧ ∀xyz(cid:2)(cid:3)t(x, y) ∧ t( y, z) → t(x, z)(“p is a subset of t, and t is a transitive relation”). Then CIRCt[F ] is(cid:3).(6)(7)(cid:2)∀xy(cid:3)p(x, y) → t(x, y)(u < t) ∧ ∀xy(cid:2)∧ ¬∃u∧ ∀xyz(cid:2)(cid:3)p(x, y) → u(x, y)(cid:2)(cid:3)t(x, y) ∧ t( y, z) → t(x, z)(cid:2)∧ ∀xyzu(x, y) ∧ u( y, z) → u(x, z).(cid:3)(cid:3)This condition cannot be expressed by a first-order formula, but its meaning is straightforward: it says that t is the transitiveclosure of p.If we conjoin (7) withp(a, b) ∧ p(b, c)(8)and include both p and t in the list of minimized predicates then the circumscription formula will become expressible infirst-order logic as(cid:2)∀xy(cid:3)p(x, y) ↔ (x = a ∧ y = b) ∨ (x = b ∧ y = c)∧ ∀xy(cid:2)(cid:3)t(x, y) ↔ (x = a ∧ y = b) ∨ (x = b ∧ y = c) ∨ (x = a ∧ y = c).(9)2 In this paper, equality is not considered a predicate constant, so that it is not allowed to be a member of p.3 This definition of the circumscription operator allows F to have free variables, unlike the definition from [17]. Similarly, the definition of the stablemodel operator below is applicable to formulas with free variables, unlike the definition proposed in the conference paper [6].\fP. Ferraris et al. / Artificial Intelligence 175 (2011) 236–2632392.3. Operator SMWe will now define the stable model operator with the intensional predicates p, denoted by SMp. Some details of thedefinition depend on which propo",
            {
                "entities": [
                    [
                        3631,
                        3659,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 238 (2016) 96–118Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMaking the right exceptions ✩,✩✩Harald Bastiaanse, Frank Veltman∗Institute for Logic, Language and Computation, Universiteit van Amsterdam, P.O. Box 94242, 1090 GE Amsterdam, The Netherlandsa r t i c l e i n f oa b s t r a c tArticle history:Received 2 December 2013Received in revised form 26 May 2016Accepted 30 May 2016Available online 2 June 2016Keywords:CircumscriptionDefaultsNonmonotonic logicInheritance networksThis paper is about the logical properties of sentences of the form S’s are normally P, and starts from the idea that any logical theory for such sentences should meet the following simple requirement:If the only available information about some object x is that x has property S, it must be valid to infer by default that x has all the properties P that objects with property Snormally have.We investigate how this requirement can be met by theories developed within the framework of circumscription, and specify a constraint – the exemption principle – that must be satisfied to do so. This principle determines in cases of conflicting default rules which objects are exempted from which rules, and, as such, is the main source for the capricious logical behavior of the sentences we are interested in.To facilitate comparison (and implementation) we supply an algorithm for inheritance networks and prove that arguments that can be expressed in both frameworks are valid on the circumscriptive account if and only if the inheritance algorithm has a positive outcome.© 2016 Elsevier B.V. All rights reserved.1. IntroductionDiscussions often end before the issues that started them have been resolved. In the 1980s and 1990s default reasoning was a hot topic in the field of logic and AI. The result of this discussion was not one single theory that met with general agreement, but a collection of alternative theories, each with its merits, but none entirely satisfactory. This paper aims to give a new impetus to this discussion.The issue is the logical behavior of sentences of the formS’s are normally PSuch sentences function as default rules. What they mean is roughly this: when you are confronted with an object with property S, and you have no evidence to the contrary, you are legitimized to assume that this object has property P .The research for this paper was partly financed by the Netherlands Organisation for Scientific Research (project NWO-360-20-200), whose support is ✩gratefully acknowledged.This paper has a long history. Successive drafts have been presented between 2009 and 2015 in Amsterdam, Groningen, Gent, Göttingen, Westport, ✩✩Ann Arbor, Beijing, and Guangzhou. We thank the audiences for their valuable feedback. We also want to thank the referees, whose suggestions led to significant improvements both in content and in presentation.* Corresponding author.E-mail addresses: bastiaanse_harald@hotmail.com (H. Bastiaanse), f.veltman@uva.nl (F. Veltman).http://dx.doi.org/10.1016/j.artint.2016.05.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\fH. Bastiaanse, F. Veltman / Artificial Intelligence 238 (2016) 96–11897The ‘evidence to the contrary’ can vary. Sometimes it simply consists in the empirical observation that the object con-cerned is in fact an exception to the rule. On other occasions the evidence may be more indirect. Consider:premise 1premise 2premise 3premise 4A’s are normally ES’s are normally not ES’s are normally Ac is A and c is Sby defaultc is not EThis is a case of conflicting defaults.1 At first sight one might be tempted to draw both the conclusion that c is E (from premises 1 and 4) and that c is not E (from premises 2 and 4), and maybe on second thought to draw neither. But the third premise states that objects with the property S normally have the property A as well. So, apparently, normal S’s are exceptional A’s, as the rule that A’s are normally E does not hold for them. In other words, only the S-defaults apply to c. So, presumably, c is not E.Default reasoning has been formalized in various ways, and within each of the existing theoretical frameworks a number of strategies have been proposed to deal with conflicting defaults. In the following we will focus on two of these frameworks, Circumscription (McCarthy [1,2]), and Inheritance Networks (Horty et al. [3]), and implement a new strategy to deal with conflicting rules in each of these.2. Naive circumscriptionWithin the circumscriptive approach a sentence of the form S’s are normally P is represented by a formula of the form∀x((Sx ∧ ¬ Ab SxP x x) → P x).Here Ab SxP x x is a one place predicate. The subscript ‘SxP x’ serves as an index, indicating the rule concerned. If an object asatisfies the formula Ab SxP x x, this means that a is an abnormal object with respect to this rule.More generally, let L0 be a language of monadic first order logic. With each pair (cid:6)ϕ(x), ψ(x)(cid:7),2 we associate a new one-place predicate Abϕ(x)ψ(x), thus obtaining the first order language L.A default rule is a formula of L of the form∀x((ϕ(x) ∧ ¬ Abϕ(x)ψ(x) x) → ψ(x)).Here, ϕ(x) and ψ(x) must be formulas of L0 that are quantifier-free and in which no individual constant occurs. The formula ϕ(x) is called the antecedent of the rule, Abϕ(x)ψ(x) x is its abnormality clause, and ψ(x) its consequent. Again, the index ϕ(x)ψ(x) is there just to indicate that it concerns the abnormality predicate of the rule with antecedent ϕ(x) and consequent ψ(x). When it is clear which variable is at stake we will write Abϕψ rather than Abϕ(x)ψ(x). And often we will shorten ‘∀x((ϕ(x) ∧ ¬ Abϕψ x) → ψ(x))’ further to∀x(ϕ(x) (cid:2) ψ(x)).Since it is clear from the antecedent and the consequent of a default rule what the abnormality clause is, this should not cause confusion.3In ordinary logic, for an argument to be valid, the conclusion must be true in all models in which the premises are true. The basic idea underlying circumscription is that not all models of the premises matter but only the most normal ones – only the ones in which the extension of the abnormality predicates is inclusion-wise minimal given the information at hand. Formally:Definition 2.1.(i) Let L be a language as described above, and let A = (cid:6)A, I(cid:7) and A(cid:8) = (cid:6)A(cid:8), I(cid:8)(cid:7) be two models for L with the following properties:(a) A = A(cid:8)(b) for all individual constants c, I(c) = I(cid:8)(c);;1 If a concrete example is wanted, substitute ‘adult’ for A, ‘employed’ for E, and ‘student’ for S.2 Notation: we write ϕ(x) to denote a formula ϕ of L0 in which (at most) the variable x occurs freely.3 Some readers may not like the fact that in this set up the formulas ∀x(Sx (cid:2) P x) and ∀ y(S y (cid:2) P y) are not logically equivalent, because they contain different abnormality predicates. We could remedy this defect by introducing the same abnormality predicate Abϕ(·)ψ(·) for all pairs (cid:6)ϕ(x), ψ(x)(cid:7), indepen-dent of the free variable x occurring in ϕ(x) and ψ(x). Here ‘·’ refers to a symbol that does not belong to the vocabulary of L0, and by ϕ(·), we mean the expression that one obtains from ϕ(x) by replacing each free occurrence of x by an occurrence of ·.Some readers may insist that on top of this we should enforce that whenever ϕ(x) is logical equivalent to χ (x), and ψ(x) to θ(x), ∀x(ϕ(x) (cid:2) ψ(x))gets equivalent to ∀x(χ (x) (cid:2) θ(x)). This can be done by stipulating that we are only interested in models that assign the same extension to Abϕ(·)ψ(·) and Abχ (·)θ (·) if ϕ(x) is logical equivalent to χ (x) and ψ(x) to θ(x). However, for our purposes, we can keep things simple.\f98H. Bastiaanse, F. Veltman / Artificial Intelligence 238 (2016) 96–118(c) for all abnormality predicates Abϕψ , I( Abϕψ ) ⊆ I(cid:8)( Abϕψ ).Then A is at least as normal as A(cid:8).(ii) Let C be a class of models. Then A = (cid:6)A, I(cid:7) is an optimal model in C iff A ∈ C and there is no model in C that is more normal than A.(iii) Let (cid:6) be a set of sentences. Then (cid:6) |=c ϕ iff ϕ is true in all optimal models of (cid:6).Notice that in (i) of this definition nothing is said about the interpretation of ordinary predicates. A can be at least , while for all P ∈ L0, the interpretations I(P ) and I(cid:8)(P ) are totally different. However, in practice we as normal as A(cid:8)are always looking for the most normal models within a given class C, and it may very well happen that within C the interpretation of the ordinary predicates is heavily constrained or even fixed.If (cid:6) |=c ϕ, we say that ϕ follows by circumscription from (cid:6). Here is an example.premise 1 Adults normally have a bank accountpremise 2 Adults normally have a driver’s licensepremise 3premise 4John is an adultJohn does not have a driver’s licenseby defaultJohn is an adult with a bank accountThis can be formalized aspremise 1premise 2premise 3premise 4∀x(( Ax ∧ ¬ Ab A B x) → Bx)∀x(( Ax ∧ ¬ Ab A D x) → Dx)A j¬D jby circumscription B jIt is easy to check that the conclusion B j follows by circumscription from the premises.This example illustrates why the abnormality predicates have a double index referring to both the antecedent and the consequent of the rule, rather than a single one referring to just the antecedent. It is not sufficient to distinguish between normal and abnormal A’s, and formalize a sentence like Adults normally have a bank account as ∀x(( Ax ∧ ¬ Ab A x) → Bx). The distinction has to be more fine grained. An object with the property A can be a normal A in some respects and an abnormal A in other. Even though John is an abnormal adult in not having a driver’s license, he is a normal adult in having a bank account, or at least we want to be able to conclude by default that he is. If we had formalized the argument in the following way, we would not have gotten very far.4premise 1 ∀x(( Ax ∧ ¬ Ab A x) → Bx)premise 2 ∀x(( Ax ∧ ¬ Ab A x) → Dx)pr",
            {
                "entities": [
                    [
                        3060,
                        3088,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 413–436Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUsing arguments for making and explaining decisions ✩Leila Amgoud∗, Henri PradeInstitut de Recherche en Informatique de Toulouse, CNRS – University of Toulouse III, 118 route de Narbonne, 31062 Toulouse, Cedex 09, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 8 November 2006Received in revised form 13 November 2008Accepted 17 November 2008Available online 24 November 2008Keywords:Decision makingArgumentationArguments play two different roles in day life decisions, as well as in the discussion ofmore crucial issues. Namely, they help to select one or several alternatives, or to explainand justify an already adopted choice.This paper proposes the first general and abstract argument-based framework for decisionmaking. This framework follows two main steps. At the first step, arguments for beliefs andarguments for options are built and evaluated using classical acceptability semantics. At thesecond step, pairs of options are compared using decision principles. Decision principlesare based on the accepted arguments supporting the options. Three classes of decisionprinciples are distinguished: unipolar, bipolar or non-polar principles depending on whetheri) only arguments pros or only arguments cons, or ii) both types, or iii) an aggregationof them into a meta-argument are used. The abstract modelis then instantiated byexpressing formally the mental states (beliefs and preferences) of a decision maker. Inthe proposed framework, information is given in the form of a stratified set of beliefs.The bipolar nature of preferences is emphasized by making an explicit distinction betweenprioritized goals to be pursued, and prioritized rejections that are stumbling blocks tobe avoided. A typology that identifies four types of argument is proposed. Indeed, eachdecision is supported by arguments emphasizing its positive consequences in terms ofgoals certainly satisfied and rejections certainly avoided. A decision can also be attackedby arguments emphasizing its negative consequences in terms of certainly missed goals,or rejections certainly led to by that decision. Finally, this paper articulates the optimisticand pessimistic decision criteria defined in qualitative decision making under uncertainty,in terms of an argumentation process. Similarly, different decision principles identified inmultiple criteria decision making are restated in our argumentation-based framework.© 2008 Elsevier B.V. All rights reserved.1. IntroductionDecision making, often viewed as a form of reasoning toward action, has raised the interest of many scholars includingphilosophers, economists, psychologists, and computer scientists for a long time. Any decision problem amounts to selecting✩The present paper unifies and develops the content of several conference papers [L. Amgoud, J.-F. Bonnefon, H. Prade, An argumentation-based approachto multiple criteria decision, in: Proceedings of the 8th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty(ECSQARU’05), 2005, pp. 269–280; L. Amgoud, H. Prade, A bipolar argumentation-based decision framework, in: Proceedings of the 11th InternationalConference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU’06), 2006, pp. 323–330; L. Amgoud, H. Prade,Comparing decisions in an argumentation-based setting, in: Proceedings of the 11th International Workshop on Non-Monotonic Reasoning (NMR’06), 2006;L. Amgoud, H. Prade, Explaining qualitative decision under uncertainty by argumentation, in: Proceedings of the 21st National Conference on ArtificialIntelligence (AAAI’06), 2006, pp. 219–224 [2,7–9]].* Corresponding author.E-mail address: amgoud@irit.fr (L. Amgoud).URL: http://www.irit.fr/~Leila.Amgoud/ (L. Amgoud).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.006\f414L. Amgoud, H. Prade / Artificial Intelligence 173 (2009) 413–436the “best” or sufficiently “good” action(s) that are feasible among different alternatives, given some available informationabout the current state of the world and the consequences of potential actions. Note that available information may beincomplete or pervaded with uncertainty. Besides, the goodness of an action is judged by estimating, maybe by means ofseveral criteria, how much its possible consequences fit the preferences or the intentions of the decision maker. This agentis assumed to behave in a rational way [41,42,49], at least in the sense that his decisions should be as much as possibleconsistent with his preferences. However, we may have a more requiring view of rationality, such as demanding for theconformity of decision maker’s behavior with postulates describing how a rational agent should behave [45].Decision problems have been considered from different points of view. We may distinguish two main trends, which arecurrently influencing research in artificial intelligence (AI): classical decision theory on the one hand, and cognitively-orientedapproaches such as practical reasoning or beliefs-desires-intentions (BDI) settings on the other hand.1.1. Classical decision making vs. practical reasoningClassical decision theory, as developed mainly by economists, has focused on making clear what is a rational decisionmaker. Thus, they have looked for principles for comparing different alternatives. A particular decision principle, such asthe classical expected utility [45], has been justified on the basis of a set of rationality postulates to which the preferencerelation between actions should obey. This means that in this approach, rationality is captured through a set of postulatesthat describe what is a rational decision behavior. Moreover, a minimal set of postulates is identified in such a way that itcorresponds to a unique decision principle. The inputs of this approach are a set of candidate actions, and a function thatassesses the value of their consequences when the actions are performed in a given state, together with complete or partialinformation about the current state of the world. In other words, such an approach distinguishes between knowledge andpreferences, which are respectively encoded in practice by a distribution function assessing the plausibility of the differentstates of the world, and by a utility function encoding preferences by estimating how good a consequence is. The output is apreference relation between actions encoded by the associated principle. Note that such an approach aims at rank-orderinga group of candidate actions rather than focusing on a candidate action individually. Moreover, the candidate actions aresupposed to be feasible. Roughly speaking, we may distinguish two groups of works in AI dealing with decision that followthe above type of approach. The first group is represented by researches using Bayesian networks [40], on planning underuncertainty (e.g. [21]). Besides, some AI works have aimed at developing more qualitative frameworks for decision, but stillalong the same line of thoughts (e.g. [22,27,47]).Other researchers working on practical reasoning, starting with the generic question “what is the right thing to do foran agent in a given situation” [41,43], have proposed a two steps process to answer this question. The first step, oftencalled deliberation [49], consists of identifying the goals of the agent. In the second step, they look for ways of achievingthose goals, i.e. for plans, and thus for intermediary goals and sub-plans. Such an approach raises issues such as: howare goals generated ? are actions feasible ? do actions have undesirable consequences ? are sub-plans compatible ? arethere alternative plans for achieving a given goal, . . . . In [16], it has been argued that this can be done by representingthe cognitive states, namely agent’s beliefs, desires and intentions (thus the so-called BDI architecture). This requires arich knowledge/preference representation setting, which contrasts with the classical decision setting that directly uses anuncertainty distribution (a probability distribution in the case of expected utility), and a utility (value) function. Besides,the deliberation step is merely an inference problem since it amounts to finding a set of desires that are justified on thebasis of the current state of the world and of conditional desires. Checking if a plan is feasible and does not lead to badconsequences is still a matter of inference. A decision problem only occurs when several plans or sub-plans are possible,and one of them has to be chosen. This latter issue may be viewed as a classical decision problem. What is worth noticingin most works on practical reasoning is the use of argument schemes for providing reasons for choosing or discarding anaction (e.g. [30,35]). For instance, an action may be considered as potentially useful on the basis of the so-called practicalsyllogism [48]:• G is a goal for agent X• Doing action A is sufficient for agent X to carry out goal G• Then, agent X ought to do action AThe above syllogism is in essence already an argument in favor of doing action A. However, this does not mean that theaction is warranted, since other arguments (called counter-arguments) may be built or provided against the action. Thosecounter-arguments refer to critical questions identified in [48] for the above syllogism. In particular, relevant questionsare “Are there alternative ways of realizing G?”, “Is doing A feasible?”, “Has agent X other goals than G?”, “Are thereother consequences of doing A which should be taken into account?”. Recently in [10,11], the above syllogism has beenextended to explicitly take into account the reference to ethical values in arguments. Anyway, the idea of using argumentsfor justifying or discarding candidate decisions is certainty very old, and its account in the literature at least dates",
            {
                "entities": [
                    [
                        3978,
                        4006,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 235 (2016) 63–94Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief and truth in hypothesised behavioursStefano V. Albrecht a,∗a The University of Texas at Austin, United Statesb Masdar Institute of Science and Technology, United Arab Emiratesc The University of Edinburgh, United Kingdom, Jacob W. Crandall b, Subramanian Ramamoorthy ca r t i c l e i n f oa b s t r a c tArticle history:Received 27 July 2015Received in revised form 29 January 2016Accepted 29 February 2016Available online 4 March 2016Keywords:Autonomous agentsMultiagent systemsGame theoryType-based methodThere is a long history in game theory on the topic of Bayesian or “rational” learning, in which each player maintains beliefs over a set of alternative behaviours, or types, for the other players. This idea has gained increasing interest in the artificial intelligence (AI) community, where it is used as a method to control a single agent in a system composed of multiple agents with unknown behaviours. The idea is to hypothesise a set of types, each specifying a possible behaviour for the other agents, and to plan our own actions with respect to those types which we believe are most likely, given the observed actions of the agents. The game theory literature studies this idea primarily in the context of equilibrium attainment. In contrast, many AI applications have a focus on task completion and payoff maximisation. With this perspective in mind, we identify and address a spectrum of questions pertaining to belief and truth in hypothesised types. We formulate three basic ways to incorporate evidence into posterior beliefs and show when the resulting beliefs are correct, and when they may fail to be correct. Moreover, we demonstrate that prior beliefs can have a significant impact on our ability to maximise payoffs in the long-term, and that they can be computed automatically with consistent performance effects. Furthermore, we analyse the conditions under which we are able complete our task optimally, despite inaccuracies in the hypothesised types. Finally, we show how the correctness of hypothesised types can be ascertained during the interaction via an automated statistical analysis.© 2016 Elsevier B.V. All rights reserved.1. IntroductionThere is a long history in game theory on the topic of Bayesian or “rational” learning (e.g. [73,35,65,63]). Therein, players maintain beliefs about the behaviours, or “types”, of other players in the form of a probability distribution over a set of alternative types. These beliefs are updated based on the observed actions, and each player chooses an action which is expected to maximise the payoffs received by the player, given the current beliefs of the player. The principal questions studied in this context are the degree to which players can learn to make correct predictions, and whether the interaction process converges to solutions such as Nash equilibrium [74].This general idea, which we here refer to as the type-based method, has received increasing interest in the artificial intelligence (AI) community, where it is used as a method to control a single agent in a system composed of multiple agents (e.g. [4,11,52,25]). This interest is, in part, motivated by applications that require efficient and flexible interaction * Corresponding author.E-mail address: svalb@cs.utexas.edu (S.V. Albrecht).http://dx.doi.org/10.1016/j.artint.2016.02.0040004-3702/© 2016 Elsevier B.V. All rights reserved.\f64S.V. Albrecht et al. / Artificial Intelligence 235 (2016) 63–94with agents whose behaviours are initially unknown. Example applications include adaptive user interfaces, robotic elderly care, and automated trading agents. Learning to interact from scratch in such settings is notoriously difficult, due to the essentially unconstrained nature of what the other agents may be doing and the fact that their behaviours are a priori unknown. The type-based method is seen as a way to reduce the complexity of such problems by focusing on a relatively small set of points in the infinite space of possible behaviours.More concretely, the idea is to hypothesise (“guess”) a set of types, each of which specifies a possible behaviour for the other agents. A type may be of any structural form, and here we simply view it as a “blackbox” programme which takes as input the interaction history and chooses actions for the next step in the interaction. Such types may be specified manually by a domain expert or generated automatically, e.g. from a corpus of historical data or the problem description. By compar-ing the predictions of the types with the observed actions of the agents, we can form posterior beliefs about the relative likelihood of types. The beliefs and types are in turn utilised in a planning procedure to find an action which maximises our expected payoffs with respect to our beliefs. A useful feature of this method is the fact that we may hypothesise any types of behaviours, which gives us the flexibility to interact with a variety of agents. Moreover, since each type specifies a com-plete behaviour, we can plan actions in the entire interaction space, including in situations that have not been encountered before.Nonetheless, there are several questions and concerns associated with this method, pertaining to the evolution and impact of beliefs as well as the implications and detection of incorrect hypothesised types. Specifically, how should evidence (i.e. observed actions) be incorporated into beliefs and under what conditions will the beliefs be correct? What impact do prior beliefs have on our ability to maximise payoffs in the long-term? Furthermore, under what conditions will we be able to complete our task even if our hypothesised types are incorrect? And, finally, how can we ascertain the correctness of our hypothesised types during the interaction?The AI literature on the type-based method has focused on experimental evaluations, exploration mechanisms, and com-putational issues arising from recursive beliefs, but not or only partially on the questions outlined above. (We defer a detailed discussion of related works to Section 2). On the other hand, the game theory literature addresses such questions primarily in the context of equilibrium attainment in repeated games (cf. Section 2). However, there are several reasons why this renders the game theory literature of limited applicability to domains such as the ones mentioned earlier. First, equilibrium concepts such as Nash equilibrium are based on normative assumptions, including perfect rationality with re-spect to one’s payoffs. However, such normative assumptions are difficult to justify in situations in which we assume no prior knowledge about the behaviour of other agents. For example, there is evidence that humans do not satisfy such strict assumptions (e.g. [64]). Second, an equilibrium solution prescribes behaviours for all involved agents, whereas we control only a single agent and assume no control over the choice of behaviour for the other agents. Finally, the existence of multi-ple equilibria with possibly differing payoff profiles means that equilibrium attainment may itself not be synonymous with payoff maximisation for our controlled agent.The purpose of the present article is to improve our understanding of the type-based method by providing insight into the questions outlined above. Our analysis is based on stochastic Bayesian games, which are an extension of Bayesian games [56] that include stochastic state transitions, and Harsanyi–Bellman Ad Hoc Coordination (HBA), which can be viewed as a general algorithmic description of the type-based method [4]. After discussing related work in Section 2 and technical preliminaries in Section 3, the article makes the following contributions:• Section 4 considers three basic methods to incorporate observations into posterior beliefs and analyses the conditions under which they converge to the true distribution of types, including in processes in which type assignments may be randomised and correlated. We also discuss examples to show when beliefs may fail to converge to the correct distribution.• Section 5 investigates the impact of prior beliefs on payoff maximisation in a comprehensive empirical study. We show that prior beliefs can indeed have a significant impact on the long-term performance of HBA, and that the magnitude of the impact depends on the depth of the planning horizon (i.e. how far we look into the future). Moreover, we show that automatic methods can compute prior beliefs with consistent performance effects.• Section 6 analyses what relation the hypothesised types must have to the true types in order for HBA to be able to complete its task, despite inaccuracies in the hypothesised types. We formulate a hierarchy of increasingly desirable termination guarantees and analyse the conditions under which they are met. In particular, we give a novel characteri-sation of optimality which is based on the concept of probabilistic bisimulation [69].• Section 7 shows how the truth of hypothesised types can be contemplated during the interaction in the form of an automated statistical analysis. The presented algorithm can incorporate multiple statistical features into the test statis-tic and learns its distribution during the interaction process, with asymptotic correctness guarantees. We show in a comprehensive set of experiments that the algorithm achieves high accuracy and scalability at low computational costs.Finally, Section 8 concludes this work and discusses directions for future work. Elements of this work appeared in [2,7,6,5].\fS.V. Albrecht et al. / Artificial Intelligence 235 (2016) 63–94652. Related workThis section discusses related work and situates our work within the literature. We distinguish between research on the type-based method in the areas of game theory and artificial intelligence.2.1. Type-based method in game ",
            {
                "entities": [
                    [
                        3449,
                        3477,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 312 (2022) 103771Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQ-Learning-based model predictive variable impedance control for physical human-robot collaboration ✩Loris Roveda a,∗Dario Piga aa Istituto Dalle Molle di studi sull’Intelligenza Artificiale (IDSIA), Scuola Universitaria Professionale della Svizzera Italiana (SUPSI), Università della Svizzera italiana (USI), via la Santa 1, 6962, Lugano, Switzerlandb Politecnico di Milano, Department of Mechanical Engineering, via La Masa 1, 20156, Milano, Italy, Andrea Testa b, Asad Ali Shahid a, Francesco Braghin b, a r t i c l e i n f oa b s t r a c tArticle history:Received 21 September 2021Received in revised form 18 July 2022Accepted 6 August 2022Available online 11 August 2022Keywords:Physical human-robot collaborationIndustry 4.0Machine learningModel-based reinforcement learning controlNeural networksQ-LearningStabilityVariable impedance controlPhysical human-robot collaboration is increasingly required in many contexts (such as industrial and rehabilitation applications). The robot needs to interact with the human to perform the target task while relieving the user from the workload. To do that, the robot should be able to recognize the human’s intentions and guarantee safe and adaptive behavior along the intended motion directions. The robot-control strategies with such attributes are particularly demanded in the industrial field, where the operator guides the robot manually to manipulate heavy parts (e.g., while teaching a specific task). With this aim, this work proposes a Q-Learning-based Model Predictive Variable Impedance Control (Q-LMPVIC) to assist the operators in a physical human-robot collaboration (pHRC) tasks. A Cartesian impedance control loop is designed to implement a decoupled compliant robot dynamics. The impedance control parameters (i.e., setpoint and damping parameters) are then optimized online in order to maximize the performance of the pHRC. For this purpose, an ensemble of neural networks is designed to learn the modeling of the human-robot interaction dynamics while capturing the associated uncertainties. The derived modeling is then exploited by the model predictive controller (MPC), enhanced with the stability guarantees by means of Lyapunov constraints. The MPC is solved by making use of a Q-Learning method that, in its online implementation, uses an actor-critic algorithm to approximate the exact solution. Indeed, the Q-learning method provides an accurate and highly efficient solution (in terms of computational time and resources). The proposed approach has been validated through experimental tests, in which a Franka EMIKA panda robot has been used as a test platform. Each user was asked to interact with the robot along the controlled vertical z Cartesian direction. The proposed controller has been compared with a model-based reinforcement learning variable impedance controller (MBRLC) previously developed by some of the authors in order to evaluate the performance. As highlighted in the achieved results, the proposed controller is able to improve the pHRC performance. Additionally, two industrial tasks (a collaborative assembly and a collaborative deposition task) have been demonstrated to prove the applicability of the proposed solution in real industrial scenarios.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).✩This paper is part of the Special Issue: “Risk-aware Autonomous Systems: Theory and Practice”.* Corresponding author.francesco.braghin@polimi.it (F. Braghin), dario.piga@supsi.ch (D. Piga).E-mail addresses: loris.roveda@idsia.ch (L. Roveda), andrea8.testa@mail.polimi.it (A. Testa), asadali.shahid@idsia.ch (A.A. Shahid), https://doi.org/10.1016/j.artint.2022.1037710004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fL. Roveda, A. Testa, A.A. Shahid et al.Artificial Intelligence 312 (2022) 1037711. Introduction1.1. ContextTo meet customers needs, which are becoming more and more oriented on tailor-made products, companies are updat-ing their production processes by means of new flexible and agile tools [1]. In this context, collaborative robotics plays a key role [2], providing powerful solutions to assist the operators in the execution of different activities, such as co-manipulation [3,4], task’s knowledge transfer to the robotic system [5,6], easy programmable and deployable applications [7], etc. Physical human-robot collaboration (pHRC) is currently one of the most investigated topics [8]. In fact, pHRC is nowadays demanded in many fields of applications, both for collaborative robots [9] and exoskeletons [10]. However, many open issues in the state of the art are still to be overcome, in particular considering safety/stability guarantees in the human-robot inter-action, human-robot dynamics modeling, human’s intention recognition (for active assistance/empowering purposes), and computation efficiency (for real-time control adaptation and optimization).To tackle the above mentioned issues within the pHRC scenario, this paper proposes a Q-Learning-based Model Predictive Variable Impedance Control (Q-LMPVIC) to assist the operator while physically interacting with a collaborative robot. Based on Cartesian impedance control (providing to the controlled manipulator a compliant and decoupled behavior in the Carte-sian space), an MPC is designed in order to online optimize its parameters (i.e., setpoint and damping parameters) to assist the user along the detected intended motion direction(s), maximizing the collaboration performance. The MPC exploits a learned human-robot interaction dynamics model, obtained by means of an ensemble of neural networks. Therefore, the lack of sophisticated analytical models for the human-robot interaction dynamics is overcome, employing a method that is capable to capture the complexity and uncertainties of such a dynamics. An MPC objective function is designed in order to minimize the user’s effort during the collaboration with the robot. Indeed, the user’s intention of motion can be detected, making it possible to assist him/her along the intended direction(s) of motion. The designed MPC is also enhanced with stability guarantees by means of Lyapunov constraints. In such a way, safety/stability issues are tackled by the proposed methodology. The MPC is then (online) solved making use of a Q-Learning method, exploiting an actor-critic algorithm to approximate its exact solution. The obtained solution is accurate and highly efficient, being able to tackle the issue related to computation efficiency that might compromise the implementation of the controller for real applications.In the following Section, the state of the art related to the pHRC control is addressed, to highlight the open issues in the field and the solutions provided by the proposed approach.1.2. Related workAmong other strategies [11,12], physical human-robot collaboration (pHRC) is commonly enabled by implementing a low-level impedance controller [13], that provides the robot with a safe and compliant behavior, suitable for interacting with the surrounding environment (including human subjects [14]). The impedance control parameters (i.e., mass/inertia, stiffness, damping, and setpoint) are then tuned/adapted by means of high-level control strategies during the execution of a task [15], e.g., to achieve human-like adaptability skills [16,17], to maximize the human-robot collaboration performance [18], etc. Such high-level control strategies can be designed using the analytical models of the human-environment interaction [19]. However, the solutions realized through these methods are limited by the specific modeling adapted and the impossibility of the models to capture the complex interaction dynamics. Therefore, machine learning (ML)-based approaches have been investigated to implement flexible controllers. Two types of ML-based solutions are available in the state of the art: model-based ML approaches [20], and model-free ML approaches [21]. Model-based ML approaches provide powerful algorithms for control tuning purposes that are capable of capturing the complex and uncertain interaction dynamics. The main drawback of such strategies consists in the limited variation of task conditions that can be faced by the proposed controllers. In order to be effective, the adopted models should accurately represent the target scenario, losing generalizability [22]. Model-free approaches, on the other hand, allow to achieve acceptable results in a wide set of scenarios by exploiting an autonomous tuning through trial-and-error. However, the tuning procedures are costly (both in terms of the computational resources and the time), requiring a vast amount of trails to achieve the target performance [4].Many efforts are, therefore, put into the development of combined solutions exploiting the advantages of both model-based and model-free ML solutions. In [23] is implemented a systematic approach to optimize the gains of an admittance controller online, without any prior knowledge of the target position or other task characteristics. A fuzzy Q-Learning algo-rithm is used to regulate damping so that the robot trajectory approaches the minimum jerk and the cooperation becomes more effective. The partitioning of the robot state with fuzzy sets is an efficient method to deal with the curse of dimen-sionality of continuous space. However, it requires a number of parameters to be manually tuned and it works selecting a deterministic action from a small set using fuzzy Q values to obtain a quicker convergence. According to [24], restricting the search for optimal action to the agent’s action set or a restricted set of Q values, it is a myopic idea. Herein, their",
            {
                "entities": [
                    [
                        3873,
                        3901,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1137–1160www.elsevier.com/locate/artintWhy Heideggerian AI failed and how fixing it would require makingit more Heideggerian ✩Hubert L. DreyfusUniversity of California, Department of Philosophy, 314 Moses Hall 2390, Berkeley, CA 94720-2390, USAAvailable online 10 October 20071. The convergence of computers and philosophyWhen I was teaching at MIT in the early sixties, students from the Artificial Intelligence Laboratory would cometo my Heidegger course and say in effect: “You philosophers have been reflecting in your armchairs for over 2000years and you still don’t understand how the mind works. We in the AI Lab have taken over and are succeeding whereyou philosophers have failed. We are now programming computers to exhibit human intelligence: to solve problems,to understand natural language, to perceive, and to learn.”1 In 1968 Marvin Minsky, head of the AI lab, proclaimed:“Within a generation we will have intelligent computers like HAL in the film, 2001.”2As luck would have it, in 1963, I was invited by the RAND Corporation to evaluate the pioneering work of AlanNewell and Herbert Simon in a new field called Cognitive Simulation (CS). Newell and Simon claimed that bothdigital computers and the human mind could be understood as physical symbol systems, using strings of bits or streamsof neuron pulses as symbols representing the external world. Intelligence, they claimed, merely required making theappropriate inferences from these internal representations. As they put it: “A physical symbol system has the necessaryand sufficient means for general intelligent action.”3As I studied the RAND papers and memos, I found to my surprise that, far from replacing philosophy, the pio-neers in CS had learned a lot, directly and indirectly from the philosophers. They had taken over Hobbes’ claim thatreasoning was calculating, Descartes’ mental representations, Leibniz’s idea of a “universal characteristic”—a set ofprimitives in which all knowledge could be expressed,—Kant’s claim that concepts were rules, Frege’s formalizationof such rules, and Russell’s postulation of logical atoms as the building blocks of reality. In short, without realizing it,AI researchers were hard at work turning rationalist philosophy into a research program.At the same time, I began to suspect that the critical insights formulated in existentialist armchairs, especiallyHeidegger’s and Merleau-Ponty’s, were bad news for those working in AI laboratories—that, by combining rational-✩ The essence of this article will appear in the book “The Mechanization of Mind in History”, MIT Press.E-mail address: dreyfus@cogsci.berkeley.edu.1 This isn’t just my impression. Philip Agre, a PhD student at the AI Lab at that time, later wrote:I have heard expressed many versions of the propositions . . . that philosophy is a matter of mere thinking whereas technology is a matter of realdoing, and that philosophy consequently can be understood only as deficient.Philip E. Agre, Computation and Human Experience (Cambridge: Cambridge University Press, 1997), 239.2 Marvin Minsky as quoted in a 1968 MGM press release for Stanley Kubrick’s 2001: A Space Odyssey.3 Newell, A. and Simon, H.A., Computer Science as Empirical Inquiry: Symbols and Search, Mind Design, John Haugeland, Edt. (Cambridge,MA, MIT Press), 1988.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.10.012\f1138H.L. Dreyfus / Artificial Intelligence 171 (2007) 1137–1160ism, representationalism, conceptualism, formalism, and logical atomism into a research program, AI researchers hadcondemned their enterprise to reenact a failure.2. Symbolic AI as a degenerating research programUsing Heidegger as a guide, I began to look for signs that the whole AI research program was degenerating.I was particularly struck by the fact that, among other troubles, researchers were running up against the problem ofrepresenting significance and relevance—a problem that Heidegger saw was implicit in Descartes’ understanding ofthe world as a set of meaningless facts to which the mind assigned what Descartes called values, and John Searle nowcalls functions.4But, Heidegger warned, values are just more meaningless facts. To say a hammer has the function of being for ham-mering leaves out the defining relation of hammers to nails and other equipment, to the point of building things, and tothe skills required when actually using the hammer—all of which reveal the way of being of the hammer which Hei-degger called readiness-to-hand. Merely assigning formal function predicates to brute facts such as hammers couldn’tcapture the hammer’s way of being nor the meaningful organization of the everyday world in which hammering hasits place. “[B]y taking refuge in ‘value’-characteristics,” Heidegger said, “we are . . . far from even catching a glimpseof being as readiness-to-hand.”5Minsky, unaware of Heidegger’s critique, was convinced that representing a few million facts about objects in-cluding their functions, would solve what had come to be called the commonsense knowledge problem. It seemed tome, however, that the deep problem wasn’t storing millions of facts; it was knowing which facts were relevant in anygiven situation. One version of this relevance problem was called “the frame problem.” If the computer is running arepresentation of the current state of the world and something in the world changes, how does the program determinewhich of its represented facts can be assumed to have stayed the same, and which would have to be updated?As Michael Wheeler in his recent book, Reconstructing the Cognitive World, puts it:[G]iven a dynamically changing world, how is a nonmagical system . . . to take account of those state changes inthat world . . . that matter, and those unchanged states in that world that matter, while ignoring those that do not?And how is that system to retrieve and (if necessary) to revise, out of all the beliefs that it possesses, just thosebeliefs that are relevant in some particular context of action?6Minsky suggested that, to avoid the frame problem, AI programmers could use what he called frames—descriptionsof typical situations like going to a birthday party—to list and organize those, and only those, facts that were normallyrelevant. Perhaps influenced by a computer science student who had taken my phenomenology course, Minsky sug-gested a structure of essential features and default assignments—a structure Husserl had already proposed and alreadycalled a frame.7But a system of frames isn’t in a situation, so in order to select the possibly relevant facts in the current situationone would need frames for recognizing situations like birthday parties, and for telling them from other situations suchas ordering in a restaurant. But how, I wondered, could the computer select from the supposed millions of frames inits memory the relevant frame for selecting the birthday party frame as the relevant frame, so as to see the currentrelevance of, say, an exchange of gifts rather than money? It seemed to me obvious that any AI program using framesto organize millions of meaningless facts so as to retrieve the currently relevant ones was going to be caught in a4 John R. Searle, The Construction of Social Reality (New York: The Free Press, 1995).5 Martin Heidegger, Being and Time, J. Macquarrie & E. Robinson, Trans. (New York: Harper & Row, 1962), 132–133.6 Michael Wheeler, Reconstructing the Cognitive World: The Next Step (Cambridge, MA: A Bradford Book, The MIT Press, 2007), 179.7 Edmund Husserl, Experience and Judgment (Evanston: Northwestern University Press, 1973), 38.To do the same job, Roger Schank proposed what he called scripts such as a restaurant script. “A script,” he wrote, “is a structure that describesappropriate sequences of events in a particular context. A script is made up of slots and requirements about what can fill those slots. The structureis an interconnected whole, and what is in one slot affects what can be in another. A script is a predetermined, stereotyped sequence of actionsthat defines a well-known situation.” R.C. Schank and R.P. Abelson, Scripts, Plans, Goals and Understanding: An Inquiry into Human KnowledgeStructures (Hillsdale, NJ: Lawrence Erlbaum, 1977) 41. Quoted in: Views into the Chinese Room: New Essays on Searle and Artificial Intelligence,John Preston and Mark Bishop, Eds (Oxford: Clarendon Press, 2002).\fH.L. Dreyfus / Artificial Intelligence 171 (2007) 1137–11601139regress of frames for recognizing relevant frames for recognizing relevant facts, and that, therefore, the frame problemwasn’t just a problem but was a sign that something was seriously wrong with the whole approach.Unfortunately, what has always distinguished AI research from a science is its refusal to face up to and learn fromits failures. In the case of the relevance problem, the AI programmers at MIT in the sixties and early seventies limitedtheir programs to what they called micro-worlds—artificial situations in which the small number of features that werepossibly relevant was determined beforehand. Since this approach obviously avoided the real-world frame problem,MIT PhD students were compelled to claim in their theses that their micro-worlds could be made more realistic, andthat the techniques they introduced could be generalized to cover commonsense knowledge. There were, however, nosuccessful follow-ups.8The work of Terry Winograd is the best of the work done during the micro-world period. His “blocks-world”program, SHRDLU, responded to commands in ordinary English instructing a virtual robot arm to move blocksdisplayed on a computer screen. It was the parade case of a micro-world program that really worked—but of courseonly in its micro-world. So to produce the expected generalization of his techniques, Winograd started working on anew Knowledge Representation Language, (KRL). His group, he said, was “concerned with developing a formalism,or ‘r",
            {
                "entities": [
                    [
                        3413,
                        3441,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 648–672Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMechanism design for the truthful elicitation of costly probabilisticestimates in distributed information systemsAthanasios Papakonstantinou, Alex Rogers∗, Enrico H. Gerding, Nicholas R. JenningsSchool of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 27 October 2009Received in revised form 8 October 2010Accepted 20 October 2010Available online 23 October 2010Keywords:Multiagent systemsScoring rulesAuction theoryMechanism designThis paper reports on the design of a novel two-stage mechanism, based on strictly properscoring rules, that allows a centre to acquire a costly forecast of a future event (such asa meteorological phenomenon) or a probabilistic estimate of a specific parameter (suchas the quality of an expected service), with a specified minimum precision, from oneor more agents. In the first stage, the centre elicits the agents’ true costs and identifiesthe agent that can provide an estimate of the specified precision at the lowest cost.Then, in the second stage, the centre uses an appropriately scaled strictly proper scoringrule to incentivise this agent to generate the estimate with the required precision, andto truthfully report it. In particular, this is the first mechanism that can be applied tosettings in which the centre has no knowledge about the actual costs involved in thegeneration an agents’ estimates and also has no external means of evaluating the qualityand accuracy of the estimates it receives. En route to this mechanism, we first considera setting in which any single agent can provide an estimate of the required precision,and the centre can evaluate this estimate by comparing it with the outcome which isobserved at a later stage. This mechanism is then extended, so that it can be applied ina setting where the agents’ different capabilities are reflected in the maximum precisionof the estimates that they can provide, potentially requiring the centre to select multipleagents and combine their individual results in order to obtain an estimate of the requiredprecision. For all three mechanisms (the original and the two extensions), we provetheir economic properties (i.e. incentive compatibility and individual rationality) and thenperform a number of numerical simulations. For the single agent mechanism we comparethe quadratic, spherical and logarithmic scoring rules with a parametric family of scoringrules. We show that although the logarithmic scoring rule minimises both the mean andvariance of the centre’s total payments, using this rule means that an agent may face anunbounded penalty if it provides an estimate of extremely poor quality. We show thatthis is not the case for the parametric family, and thus, we suggest that the parametricscoring rule is the best candidate in our setting. Furthermore, we show that the ‘multipleagent’ extension describes a family of possible approaches to select agents in the firststage of our mechanism, and we show empirically and prove analytically that there isone approach that dominates all others. Finally, we compare our mechanism to the peerprediction mechanism introduced by Miller et al. (2007) [29] and show that the centre’stotal expected payment is the same in both mechanisms (and is equal to total expectedpayment in the case that the estimates can be compared to the actual outcome), while thevariance in these payments is significantly reduced within our mechanism.© 2010 Elsevier B.V. All rights reserved.* Corresponding author. Tel.: +44 0 23 8059 7681; fax: +44 0 23 8059 2865.E-mail address: acr@ecs.soton.ac.uk (A. Rogers).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.007\fA. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–6726491. IntroductionReal-time information about the state of the world is increasingly being made available through distributed online sys-tems that are owned by different stakeholders and accessed by multiple users. In such systems, it is important to developprocesses that can evaluate the information provided to users and provide some guarantees to its quality. This is partic-ularly so in cases where the information in question is an imprecise probabilistic estimate or forecast whose generationinvolves some cost. Examples include forecasts of future events such as weather conditions [41], where the costs are thoseof running a large scale weather prediction model, or probabilistic estimates of the quality of service within a reputationsystem [18] where such costs represent the computational task of accessing and evaluating previous interactions records. Insuch settings, it is reasonable to assume that the providers of such information are rational self-interested agents, and assuch, may have an incentive to misreport their estimates, or to allocate less costly resources to their generation, if they canincrease their own utility by doing so (e.g. by being rewarded for a more precise estimate than is actually provided or byclaiming to expend more resources than was actually done).1 Thus, an information buyer must present the providers witha payment scheme that incentives the agents to commit resources to generating their estimates, and to truthfully reportthem.A number of researchers have proposed the use of strictly proper scoring rules to address these challenges [25,36]. Mech-anisms using these rules reward accurate estimates or forecasts by making a payment to agents based on the differencebetween an event’s predicted and actual outcome (observed at some later stage). Such mechanisms have been shown toincentivise agents to truthfully report their estimates in order to maximise their expected payment [37]. This principle canbe demonstrated through a meteorological scenario, which uses a logarithmic scoring rule. Specifically, we consider that arisk-neutral agent is asked to provide a probabilistic prediction of whether it will rain or not the following day. The agent’strue estimate of the probability of rain tomorrow is denoted by p, and the prediction that it actually reports to the centreis denoted by (cid:2)p.We first consider the perfectly plausible sounding rule that the agent should be rewarded in proportion to how confi-dently it predicted the actual outcome. That is:S((cid:2)p|x = rain) = (cid:2)p and S((cid:2)p|x = no rain) = 1 − (cid:2)pwhere x is the actual outcome verified the next day. In this case, the agent’s expected utility is given by:U (p,(cid:2)p) = p(cid:2)p + (1 − p)(1 − (cid:2)p)(1)(2)Now, for any particular true belief, p, the agent will seek to report a value of (cid:2)p which will maximise its expected utility. Inthis case, we note that ∂ U (p,(cid:2)p)/∂(cid:2)p = 2p − 1, which is independent of (cid:2)p. Thus, we must consider the boundary conditionsand find that if p < 1/2, then the agent maximises its expected reward by reporting (cid:2)p = 0, and if p > 1/2, then the agentmaximises its expected reward by reporting (cid:2)p = 1. Clearly, under this scoring rule the agent will misreport its true beliefs,and thus, the centre will not receive a true estimate of the probability of rain tomorrow.In contrast, consider the case when the logarithmic scoring rule is used such that the agent is now rewarded in propor-tion to the logarithm of the probability with which it predicted the actual outcome; that is:S((cid:2)p|x = rain) = ln(cid:2)p and S((cid:2)p|x = no rain) = ln(1 − (cid:2)p)In this case, the agent’s expected utility is given by:U (p,(cid:2)p) = p ln(cid:2)p + (1 − p) ln(1 − (cid:2)p)and its derivative is given by:∂ U (p,(cid:2)p)∂(cid:2)p= p − (cid:2)p(cid:2)p(1 − (cid:2)p)(3)(4)(5)Now, solving ∂ U (p,(cid:2)p)/∂(cid:2)p = 0 gives (cid:2)p = p, and thus, the agent will truthfully report its true belief regarding the probabilityof the outcome.Due to the attractive property outlined above, strictly proper scoring rules have recently been used in computer scienceto promote the honest exchange of beliefs between agents [44], and within reputation systems to promote truthful reportingof feedback regarding the quality of a service experienced [19–21]. Furthermore, Miller et al. [29,28] have exploited the factthat any affine transform of a strictly proper scoring rule is also a strictly proper scoring rule, and have shown how anappropriately scaled strictly proper scoring rule can be used induce agents to commit costly resources to generate theirestimates.21 Note that problems of this type are often categorised as principal-agent problems [11,35] since there is an asymmetry of information between thecontractor and contractee.2 We shall describe their approach in detail in Section 3 since our results build upon their setting.\f650A. Papakonstantinou et al. / Artificial Intelligence 175 (2011) 648–672While these approaches are effective in the specific cases that they consider, they all rely on the fact that the cost ofthe agent providing the estimate or forecast is known by the centre. This is not the case in our scenario where these costsrepresent private information known only to each individual agent (since they are dependent on the specific computationalresources available to the agent). In this paper, we use techniques from mechanism design [24], and specifically auction theory[23], to address this challenge. In particular, through the use of an auction protocol that uses strictly proper scoring rules todetermine the payments to the agents, we incentivise the agents to truthfully reveal their costs to the centre and to generateand truthfully report an estimate at a required precision. In more detail, we introduce a novel two-stage mechanism. In thefirst stage, the centre elicits the agents’ true costs and identifies the agent that can provide an estimate of the specifiedprecision at the lowest co",
            {
                "entities": [
                    [
                        3862,
                        3890,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1346–1365Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSequential decision making with partially ordered preferences ✩Daniel Kikuti, Fabio Gagliardi Cozman∗, Ricardo Shirota FilhoEscola Politécnica, Universidade de São Paulo, Av. Prof. Mello Moraes, 2231 São Paulo, SP, Brazila r t i c l ei n f oa b s t r a c tThis paper presents new insights and novel algorithms for strategy selection in sequentialdecision making with partially ordered preferences;is, where some strategiesmay be incomparable with respect to expected utility. We assume that incomparabilityamongst strategies is caused by indeterminacy/imprecision in probability values. Weinvestigate six criteria for consequentialist strategy selection: Γ -Maximin, Γ -Maximax,Γ -Maximix, Interval Dominance, Maximality and E-admissibility. We focus on the populardecision tree and influence diagram representations. Algorithms resort to linear/multilinearprogramming; we describe implementation and experiments.that© 2010 Elsevier B.V. All rights reserved.Article history:Received 28 February 2009Received in revised form 11 August 2010Accepted 11 August 2010Available online 2 December 2010Keywords:Sequential decision making underuncertaintyPartially ordered preferencesSets of probability measuresCriteria of choiceConsequentialist and resolute normsLinear and multilinear programming1. IntroductionIt is often possible, in a decision problem, to express preferences that are completely ordered; that is, for every twoalternatives, the decision maker either prefers one to the other, or is indifferent between them. In fact, expected utilitytheory is based on the assumption that revealed preferences are completely ordered. However, preferences are often partiallyordered; examples can be found in the theory of CP-nets and the theory of nondeterministic planning, as briefly discussedin Section 2. When preferences are partially ordered, two alternatives may be incomparable and incomparability may fail tobe transitive.In this paper we focus on preferences that can be represented by a single utility function and a set of probabilitymeasures. Whenever there are incomplete or partial beliefs, or disagreements amongst experts concerning chances, onemay fail to assign a precise probability value to every event, thus producing a partial order with respect to expected utility[3,46,73]. This is the situation we wish to focus on. Section 2 contains the necessary background on these topics.The literature describes many criteria of choice when preferences are partially ordered [71]. These criteria are coveredin Section 3 and can be roughly divided into two groups: (1) criteria that enforce a complete ordering amongst choices(Γ -Maximin, Γ -Maximax and Γ -Maximix); and (2) criteria that select a set of incomparable actions (Interval Dominance,Maximality and E-admissibility). Practical approaches to decision making with sets of probabilities have been mainly limitedto the first category; however, recent discussions [60] have highlighted theoretical and behavioral problems when usingthis group of criteria, and the second group of criteria has been advocated as a more adequate approach. Nevertheless,incomparability comes at a cost, and very little has been observed in the literature in terms of algorithmic progress, mainlydue to computational complexity and inability to deal with incomparable choices.✩This work has been financially supported by FAPESP, grants 2003/11165-9, 2004/09568-0, 2005/58090-9, 2008/03995-5.* Corresponding author.E-mail addresses: danielkikuti@yahoo.com.br (D. Kikuti), fgcozman@usp.br (F.G. Cozman), ricardo.shirota@poli.usp.br (R.S. Filho).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.017\fD. Kikuti et al. / Artificial Intelligence 175 (2011) 1346–13651347There are also distinct behavioral norms when it comes to sequential decision making with partially ordered preferences;that is, whenever a sequence of decisions must be made. For instance, a decision maker may be resolute in that she commitsherself to a complete strategy once and for all, or consequentialist in that she allows herself to change the current strategyin case another one is appropriate in view of the future possible choices.The interplay between criteria of choice, behavioral norms, and models such as decision trees and influence diagramshas not been explored in the literature; this paper aims at filling this gap to some extent. There are indeed insights to belearned from an organized discussion of criteria of choice and behavioral norms; for instance, we discuss in Section 5 thefact that the standard LIMID model clashes with a consequentialist stance.Another, more substantial, contribution of the paper is the development of algorithms for consequentialist sequentialdecision making expressed through decision trees [56] and influence diagrams [34]. Algorithms for decision making underΓ -Maximin and similar criteria have appeared in many settings [58,69,74], while algorithms for decision making underMaximality and E-admissibility have been suggested by Kyburg and Pittarelli [43] and proposed more recently by Kikutiet al. [42] and Utkin and Augustin [72].1 Section 3 presents algorithms and computational analysis for several criteria ofchoice. The most valuable contribution of Section 3 is the algorithm for E-admissibility. We also present a new algorithmfor strategy selection using linear programming in a family of decision trees where partial preferences have considerableregularity.Sections 4 and 5 respectively present algorithms for decision making in problems specified through decision trees andinfluence diagrams. We should note the scarcity of previous literature on influence diagrams under partially ordered prefer-ences, perhaps due to the fact that several criteria of choice require the manipulation of an exponential number of strategies.To reduce this complexity, we examine “ordered” LIMIDs, and we analyze both their conceptual foundation (in particulartheir clash with consequentialism) and their computational properties.In short, we present novel results and algorithms for sequential decision making with decision trees and influencediagrams, plus new insights for single-stage decision making under Interval Dominance and E-admissibility. The broadergoal of the paper is to combine both the philosophical underpinnings and the computational properties of partially orderedpreferences, a combination we feel is missing in the current literature.2. Partially ordered preferences, behavioral norms, and credal setsThroughout, our decision makers must select one or more actions within a finite set of possible alternatives A ={a1, . . . , am}. Performing action a yields a reward a(ω) for each state of nature ω; the set of states of nature is assumed tobe a finite set Ω = {ω1, . . . , ωn}. We assume that a(ω) is a real number expressed in utiles. Even though some theories ofpreference allow multiple utilities to be defined for a single decision problem [2], in this paper we assume that utilities areprecisely fixed in a given decision problem, and consequently every action is identified with a single real-valued functionover the states of nature. Note that a utility function is a function that returns a value in utiles for each possible outcome;so we are assuming that a single utility function is fixed.The connection between preference and expected utility, in decision making under risk [47], is based on the axiomati-zation of preference relations. Denote the strict preference of ai over a j by ai (cid:3) a j , and define indifference between twoactions as ai ∼ a j ⇔ ¬(ai (cid:3) a j) ∧ ¬(a j (cid:3) ai). Suppose (cid:3) satisfies (recall that actions are functions that can be multiplied andadded) [23]:Axiom 1 (completeness). The relation (cid:3) is complete and negatively transitive (recall that (cid:3) is negatively transitive if itsatisfies for all ai , a j , ak: (ai (cid:2) a j) ∧ (a j (cid:2) ak) ⇒ (ai (cid:2) ak)).Axiom 2 (independence). For α ∈ (0, 1], ai (cid:3) a j ⇒ αai + (1 − α)ak (cid:3) αa j + (1 − α)ak (this axiom says that whenever ai (cid:3) a j ,a compound action made of ai and ak will be preferred to a compound action made of a j and ak, where α denotes the ratioof mixture between the actions).Axiom 3 (continuity). If ai (cid:3) a j (cid:3) ak, then there exists α, β ∈ (0, 1) such that αai + (1 − α)ak (cid:3) a j (cid:3) βai + (1 − β)ak.Then there must exist a single probability measure P and a related expected utility representation for (cid:3); that is, thevalue of an action ai is given by E[ai] =j=1 P (ω j)ai(ω j), and ai (cid:3) a j if and only if E[ai] > E[a j].(cid:2)nSeveral theories relax these axioms, attempting to accommodate various observed decision making patterns [1,20,40]. Forinstance, lexicographic preferences violate Axiom 3 and are encoded through expected utility vectors, ordered with respectto a lexicographic hierarchy [5,23]. Other theories violate Axiom 2 and lead to non-additive functionals that representpreferences [49, Section 2.3]. Partially ordered preferences violate Axiom 1 by assuming that preferences are not completelyordered; this is exactly the situation we examine in the present paper. If we assume a single utility function and doif and only if E P [ai] > E P [a j] for all P innot require the preference relation (cid:3) to be complete, we have that ai (cid:3) a j1 Most results are based on material presented in Kikuti et al. [42] and Kikuti and Cozman [41]. The third author participated in developing the columngeneration method, and the experiments, reported in Section 4.3.\f1348D. Kikuti et al. / Artificial Intelligence 175 (2011) 1346–1365Fig. 1. A sequential decision problem represented through a decision tree.a set of probability measures [26,61,62]. That is, the preference relation (cid:3) can be completely represented by a set",
            {
                "entities": [
                    [
                        3803,
                        3831,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 190 (2012) 1–31Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGenerating diverse plans to handle unknown and partially knownuser preferences ✩Tuan Anh Nguyen a,∗,1, Minh Do b,2, Alfonso Emilio Gerevini c, Ivan Serina d,Biplav Srivastava e, Subbarao Kambhampati aa School of Computing, Informatics, and Decision System Engineering, Arizona State University, Brickyard Suite 501, 699 South Mill Avenue, Tempe, AZ 85281, USAb NASA Ames Research Center, Mail Stop 269-3, Moffett Field, CA 94035-0001, USAc Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Via Branze 38, I-25123 Brescia, Italyd Free University of Bozen–Bolzano, Viale Ratisbona, 16, I-39042 Bressanone, Italye IBM India Research Laboratory, New Delhi and Bangalore, Indiaa r t i c l ei n f oa b s t r a c tArticle history:Received 12 January 2011Received in revised form 16 May 2012Accepted 16 May 2012Available online 18 June 2012Keywords:PlanningPartial preferencesDiverse plansHeuristicsSearch1. IntroductionCurrent work in planning with preferences assumes that user preferences are completelyspecified, and aims to search for a single solution plan to satisfy these. In many realworld planning scenarios, however, the user may provide no knowledge or at best partialknowledge of her preferences with respect to a desired plan. In such situations, ratherthan presenting a single plan as the solution, the planner must instead provide a set ofplans containing one or more plans that are similar to the one that the user really prefers.In this paper, we first propose the usage of different measures to capture the quality ofsuch plan sets. These are domain-independent distance measures based on plan elements(such as actions, states, or causal links) if no knowledge of the user preferences is given,or the Integrated Convex Preference (ICP) measure in case incomplete knowledge of suchpreferences is provided. We then investigate various heuristic approaches to generate setsof plans in accordance with these measures, and present empirical results that demonstratethe promise of our methods.© 2012 Elsevier B.V. All rights reserved.In many real world planning scenarios, user preferences on plans are either unknown or at best partially specified(cf. [33]). In such cases, the planner’s task changes from finding a single optimal plan to finding a set of representativesolutions or options. The user must then be presented with this set in the hope that she will find at least one of theconstituent plans desirable and in accordance with her preferences. Most work in automated planning ignores this reality,and assumes instead that user preferences (when expressed) will be provided in terms of a completely specified objectivefunction.✩This work is an extension of the work presented in Srivastava et al. (2007) [51] and Nguyen et al. (2009) [42].* Corresponding author.E-mail addresses: natuan@asu.edu (T.A. Nguyen), minh.b.do@nasa.gov (M. Do), gerevini@ing.unibs.it (A.E. Gerevini), ivan.serina@unibz.it (I. Serina),sbiplav@in.ibm.com (B. Srivastava), rao@asu.edu (S. Kambhampati).1 Authors listed in alphabetical order, with the exception of the first and the last.2 Company affiliation: Stinger Ghaffarian Technologies (SGT) Inc.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.05.005\f2T.A. Nguyen et al. / Artificial Intelligence 190 (2012) 1–31In this article, we study the problem of generating a set of plans using partial knowledge of the user preferences. This setis generated in the hope that the user will find at least one desirable according to her preferences. Specifically, we considertwo qualitatively distinct scenarios:• The planner is aware that the user has some preferences on the solution plan, but it is not provided with any knowledgeon those preferences.• The planner is provided with incomplete knowledge of the user preferences in the form of plan attributes (such as theduration or cost of a flight, or the importance of delivering all priority packages on time in a logistics problem). Eachof these plan attributes has a different and unknown degree of importance, represented by weights or trade-off values.In general, users find it hard to indicate the exact value of a trade-off, but are more likely to indicate that one attributeis more (or less) important than another. For instance, a business executive may consider the duration of a flight as amore important factor than its cost. Incompletely specified preferences such as these can be modeled with a probabilitydistribution on weight values,3 and can therefore be assumed as input to the planner (together with the attributesthemselves).In both of the cases above, our focus is on returning a set of plans. In principle, a larger plan set implies that the userhas a better chance of finding the plan that she desires; however, there are two problems — one computational, and theother comprehensional. Plan synthesis, even for a single plan, is costly in terms of computational resources used; for a largeset of plans, this cost only increases. The comprehensional problem, moreover, is that it is unclear if the user will be ableto completely inspect a set of plans in order to find the plan she prefers. What is clearly needed, therefore, is the abilityto generate a set of plans with the highest chance of including the user’s preferred plan among all sets of bounded (small)number of plans. An immediate challenge in this direction is formalizing what it means for a meaningful set of plans — inother words, we want to define a quality measure for plan sets given an incomplete preference specification.We propose different quality measures for the two scenarios listed above. In the extreme case where the user is unableto provide any knowledge of her preferences, we define a spectrum of distance measures between two plans based on theirsyntactic features in order to define the diversity measure of plan sets. These measures can be used regardless of the userpreferences, and by maximizing the diversity of a plan set we increase the chance that the set is uniformly distributed inthe unknown preference space. This makes it more likely that the set contains a plan that is close to the one desired by theuser.The quality measure can be refined further when some knowledge of the user preferences is provided. We assume that itis specified as a convex combination of the plan attributes mentioned above, and incomplete in the sense that a distributionof trade-off weights, not their exact values, is available. The complete set of best plans (plans with the best value function)can then be pictured as the lower convex hull of the Pareto set on the attribute space. To measure the quality of any(bounded) set of plans on the complete optimal set, we adapt the idea of Integrated Preference Function (IPF) [14], and inparticular its special case, the Integrated Convex Preference (ICP). This measure was developed in the Operations Research(OR) community in the context of multi-criteria scheduling, and is able to associate a robust measure of representativenesswith any set of solution schedules [21].Armed with these quality measures, we can formulate the problem of planning with partial user preferences as find-ing a bounded set of the plans that has the best quality value. Our next contribution therefore is to investigate effectiveapproaches for using quality measures to search for a high quality plan set efficiently. For the first scenario — when thepreference specification is not provided — two representative planning approaches are considered. The first, GP-CSP [19],typifies the issues involved in generating diverse plans in bounded horizon compilation approaches; while the second, LPG[27], typifies the issues involved in modifying the heuristic search planners. Our investigations with GP-CSP allow us tocompare the relative difficulties of enforcing diversity with each of the three different distance measures defined in theforthcoming sections. With LPG, we find that the proposed quality measure makes it more effective in generating plan setsover large problem instances. For the second case — when part of the user preferences is provided — we also present aspectrum of approaches that can solve this problem efficiently. We implement these approaches on top of Metric-LPG [28].Our empirical evaluation compares these approaches both among themselves as well as against the methods for gener-ating diverse plans ignoring the partial preference information, and the results demonstrate the promise of our proposedsolutions.The rest of this paper is organized as follows. We start with a comprehensive discussion of related work in Section 2.Section 3 reviews fundamental concepts in preferences and introduces formal notations. In Section 4, we formalize theproposed quality measures for plan sets for the two cases of unknown and partially known user preferences. Sections 5and 6 present and experimentally evaluate heuristic approaches for generating plan sets with respect to the introducedquality measures. Finally, Section 7 characterizes the limitations of our approaches, and Section 8 presents conclusions andoutlines future directions.3 If there is no prior information about this probability distribution, one option is to initialize it with the uniform distribution and gradually improve itbased on interaction with the user.\fT.A. Nguyen et al. / Artificial Intelligence 190 (2012) 1–3132. Related workThere are currently very few research efforts in the planning literature that explicitly consider incompletely specifieduser preferences during planning. The most common approach for handling multiple objectives is to assume that a specificway of combining the objectives is available [44,20], and then search for an optimal plan with respect to this function.In a sense, such work can be considered as assuming a comple",
            {
                "entities": [
                    [
                        3405,
                        3433,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1317–1359www.elsevier.com/locate/artintRedundancy in logic III: Non-monotonic reasoningPaolo LiberatoreUniversità di Roma “La Sapienza”, Dipartimento di Informatica e Sistemistica, Via Ariosto 25, I-00185 Roma, ItalyReceived 14 October 2005; received in revised form 15 February 2008; accepted 18 February 2008Available online 4 March 2008AbstractResults about the redundancy of certain versions of circumscription and default logic are presented. In particular, propositionalcircumscription where all variables are minimized and skeptical default logics are considered. This restricted version of circum-scription is shown to have the unitary redundancy property: a CNF formula is redundant (it is equivalent to one of its proper subsets)if and only if it contains a redundant clause (it is equivalent to itself minus one clause); default logic does not have this property ingeneral. We also give the complexity of checking redundancy in the considered formalisms.© 2008 Elsevier B.V. All rights reserved.Keywords: Logical redundancy; Non-monotonic reasoning; Computational complexity; Circumscription; Default logic1. IntroductionIn this paper, we study the problem whether a circumscriptive [36] or default [44] theory is redundant, that is, itcontains unnecessary parts. Formally, a theory is redundant if it is equivalent to one of its proper subsets; a part isredundant in a theory if the theory is not semantically changed by the removal of the part. The problem of redundancyin other settings has been extensively analyzed in the literature. The complexity of establishing whether a CNF, 2CNF,and Horn formula is redundant has been studied by the author of the present article [26,30], who also analyzed someproblems related to irredundant equivalent subsets of formulae. These problems are all considered in the settings ofclassical propositional logic.The related problem of minimizing a propositional theory, in particular when in Horn form, has been analyzedby several authors [1,22,23,34,37,52]. Minimization is significantly different from redundancy: a formula is minimalif there is no shorter formula that is equivalent to it. Minimal formulae are also irredundant, but not the other wayaround: a formula may be irredundant because no part can be removed from it, but still a completely different formulais both shorter than it and equivalent to it. For example, {a ∨ b, a ∨ ¬b} is irredundant (because none of the twoclauses can be removed from it while maintaining equivalence with the original set) but is not minimal (because it isequivalent to the shorter set {a}). There are motivations for studying both minimization and redundancy. Minimizationproduces the shortest possible formula equivalent to a given one, and this has obvious advantages; making a formulairredundant may not produce a formula as short as the minimal ones, but has the additional advantage of not changingthe structure of the original formula, but only to remove parts from it.E-mail address: paolo@liberatore.org.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.02.003\f1318P. Liberatore / Artificial Intelligence 172 (2008) 1317–1359A related problem is that of studying the properties of formulae that are already known to be irredundant. Büningand Zhao [7] studied the problems of equivalence and extension-equivalence of irredundant formulae. Also related isthe problem of minimal unsatisfiability, that is, checking whether an unsatisfiable formula would become satisfiableas soon as a clause is removed from it [5,14,43].Other authors have studied redundancy in settings different from that in this article. Ginsberg [18] and Schmolzeand Snyder [48] studied the redundancy of production rules. Gottlob and Fermüller [17] studied the redundancy of aliteral within a clause in first-order logic.The settings considered in this article are those of circumscription and default logic, which are two of the most stud-ied [2,4,6,10,13,29,31,36,38,44] forms of non-monotonic reasoning, as opposite to classical logic, which is monotonic.A logic is monotonic if the consequences of a set of formulae monotonically non-decrease with the set. In other words,all formulae that are entailed by a set are also entailed by every superset of it. Circumscription and default logic do nothave this property, and are therefore non-monotonic. For circumscription, we assume that all variables are minimized;the rationale for this restriction is that fixed and varying variables can be efficiently eliminated [8,9], which showsthat the minimized variables are the “core” of the circumscription formalism. Other authors have indeed consideredcircumscription only under this restriction [6,25,40]. This shows that this restriction of circumscription is of inter-est; however, results about redundancy in this case do not necessarily extend to the general case, as discussed in theconclusions.For default logic, there are several semantics; for most of them, one can choose between the “credulous” and“skeptical” approach. In this article, we consider the skeptical approach under the original semantics [44] and threesimilar ones: justified [33], constrained [11,46], and rational [39]. We however also consider the case in which weassume that the semantics of a theory is the set of its extensions, without combining these extensions in a skepticalmanner. The results obtained in this case hold for the credulous approach under the original semantics (where nototherwise stated, the skeptical approach is assumed). The properties of redundancy in the credulous approach underthe other semantics is left open. Since redundancy is defined in terms of equivalence (namely, equivalence of a formulato a proper subset of it), it is affected by the kind of equivalence used. In particular, equivalence can be defined in twoways for default logic: equality of extensions and equality of consequences. This leads to two different definitions ofredundancy in default logic.Both circumscription and default logic differ from classical propositional logic. This difference affects redundancy.If a CNF formula contains a redundant clause, it is redundant (equivalent to one of its proper subsets); the converse istrue in propositional logic, but not in all logics. In particular, it may be the case that a formula is equivalent to one ofits proper subsets, but none of its clauses is redundant. We will indeed show a situation in default logic where {a, b}is equivalent to ∅ but neither to {a} nor to {b}, which means that {a, b} is redundant but does not contain any singleredundant element.The property that a formula is redundant if and only if it contains a redundant clause is called unitary redundancy.Classical logic has this property; other logics, like default logic, do not. We show three different sufficient conditionsfor this property to hold in a logic; one of them involves monotonicity, another involves cumulativity [35]. A propertythat entails unitary redundancy is that of monotonic redundancy: if (cid:2)(cid:4) ⊆ (cid:2)(cid:4)(cid:4) ⊆ (cid:2) and (cid:2)(cid:4) and (cid:2) are equivalent then(cid:2)(cid:4)(cid:4) and (cid:2) are equivalent as well. This is the property for which the sufficient conditions are actually proved; unitaryredundancy follows.Regarding the specific non-monotonic formalisms considered here, we show that monotonic redundancy, and there-fore unitary redundancy, holds for circumscription and for the redundancy of the background theory in default logicwhen all defaults are categorical (prerequisite-free) and normal. In the general case, default logic does not have theunitary redundancy property (and therefore does not have the monotonic redundancy property either). We also consid-ered the redundancy of defaults in a default theory. In this case, monotonic and unitary redundancy hold for justifieddefault logic but not for the other three considered semantics.Regarding the complexity results, we show that checking whether a clause is redundant in a formula and whether aformula is redundant according to circumscriptive inference are (cid:2)p2 -complete problems. For default logic, the resultsare as follows. Checking redundancy, based on extensions, of a clause in the background theory is (cid:2)p2 -complete forReiter and justified default logics, and (cid:2)p3 -complete for constrained and rational default logic; checking redundancybased on skeptical consequences is (cid:2)p3 -complete for all four semantics. Checking redundancy of a background theoryis (cid:3)p4 -complete, respectively, for equivalence based on extensions and skeptical consequences. Theproofs of the latter two results are of some interest by themselves, as they are done by first showing that the problems3 -complete and (cid:3)p\fP. Liberatore / Artificial Intelligence 172 (2008) 1317–135913192 -complete and (cid:2)pare (cid:2)p3 -complete, respectively, and then showing that such complexity results can be raised onelevel in the polynomial hierarchy. This technique allows for a proof of hardness for a class such as (cid:3)p4 withoutinvolving complicated QBFs such as ∃W ∀X∃Y ∀Z.F . Regarding the credulous approach, we prove that equality ofextensions and equality of credulous consequences coincide for the Reiter default logic, but not for the other threeconsidered semantics. Regarding the redundancy of defaults, we only considered Reiter default logic with equivalencebased on equality of extensions; we proved that the redundancy of a default is (cid:2)p2 -complete and the redundancy of aset of defaults is (cid:3)p3 -complete in this case.For the sake of clarity, long proofs and very technical parts are in the appendix.2. PreliminariesIf (cid:2) and (cid:4) are sets, (cid:2)\\(cid:4) denotes the set of elements that are in (cid:2) but not in (cid:4). This operator is often calledset subtraction because the elements of (cid:4) are “subtracted” from (cid:2). An alternative definition of this ",
            {
                "entities": [
                    [
                        3119,
                        3147,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 1–14Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFixing balanced knockout and double elimination tournaments ✩Haris Aziz a,∗Paul Stursberg d, Toby Walsh aa Data61, CSIRO and UNSW Sydney, Australiab Carnegie Mellon University, USAc IBM Research, USAd Technische Universität München, Germany, Serge Gaspers a, Simon Mackenzie b, Nicholas Mattei c, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 February 2017Received in revised form 24 April 2018Accepted 19 May 2018Available online 25 May 2018Keywords:Knockout tournamentsSeedings of a tournamentComputational complexityBalanced knockout tournaments are one of the most common formats for sports competi-tions, and are also used in elections and decision-making. We consider the computational problem of finding the optimal draw for a particular player in such a tournament. The problem has generated considerable research within AI in recent years. We prove that checking whether there exists a draw in which a player wins is NP-complete, thereby settling an outstanding open problem. Our main result has a number of interesting implications on related counting and approximation problems. We present a memoization-based algorithm for the problem that is faster than previous approaches. Moreover, we highlight two natural cases that can be solved in polynomial time. All of our results also hold for the more general problem of counting the number of draws in which a given player is the winner. Finally, we show that our main NP-completeness result extends to a variant of balanced knockout tournaments called double-elimination tournaments.© 2018 Elsevier B.V. All rights reserved.1. IntroductionBalanced knockout tournaments are one of the most widely-used formats for sports competitions [7,10,13]. A prominent example is the Wimbledon Men’s Singles tennis tournament in which 128 players enter the tournament and the player who wins seven consecutive matches right from the first round to the final wins the tournament. The format is also used in certain elimination style election and decision making schemes and has received considerable interest in the field of artificial intelligence [12,16,17,23,34,36,37,27,1] as well as social sciences [5,21,22,25,33]. Knockout tournaments which are balanced are of particular interest, as they are considered to be fair [20] and allow a large number of matches to be played in parallel.Consider the setting in which there is a set of players N = [n] (we use the notation [n] := {1, . . . , n}) where n = 2c for some integer c.1 Given N, an ordered balanced knockout tournament T(N, π ) is defined as a balanced binary tree with nThis is a revised and expanded version of Aziz et al. [3] with additional proof details as well as new results for tournaments with kings and double ✩elimination tournaments.* Corresponding author.N.Mattei@ibm.com (N. Mattei), paul.stursberg@ma.tum.de (P. Stursberg), toby.walsh@data61.csiro.au (T. Walsh).1 The setting is general enough to cover the case where some players get byes in the first round. In that case we can consider a dummy player who always loses to the player who gets a bye.E-mail addresses: haris.aziz@unsw.edu.au (H. Aziz), serge.gaspers@data61.csiro.au (S. Gaspers), simonm@andrew.cmu.edu (S. Mackenzie), https://doi.org/10.1016/j.artint.2018.05.0020004-3702/© 2018 Elsevier B.V. All rights reserved.\f2H. Aziz et al. / Artificial Intelligence 262 (2018) 1–14leaf nodes where the seeding π specifies the labeling of the leaf nodes with respect to N. All ordered balanced knockout tournaments that are isomorphic to each other (with respect to the labeling of the leaf nodes) are said to have the same draw. They are represented by a single (unordered) balanced knockout tournament (BKT) T(N, σ ) where σ denotes the draw. The set of all draws is denoted by (cid:4). Whereas the total number of seedings is n!, the number of draws is n!2n−1 as all pairwise matchups in the leaf nodes are the same if adjacent elements of the seeding are swapped, but even this grows very rapidly. For a tournament like Wimbledon, n = 128 and the number of distinct draws is ≈ 2.2665 · 10177. This is significantly more than the number of atoms in the universe, or even a googol.A BKT T(N, σ ) is conducted in the following fashion. Players that correspond to sibling leaf nodes play a match against each other. The winner of the match proceeds up the tree to the next round. The winner of T(N, σ ) is the player who reaches the root node. We are given a pairwise comparison matrix P such that P i j ∈ [0, 1] denotes the probability of player i beating player j in a pairwise elimination match and 0 ≤ P i j = 1 − P ji ≤ 1. We call P deterministic if P i j ∈ {0, 1} for all players i, j ∈ N. In this case, we say that player i beats player j if P i j = 1. Given N, P and a draw σ , each player i ∈ N has a certain probability wp(i, N, P , σ ) of being the winner of T(N, σ ). This probability can be computed in time O (n2) via a recursive formulation [36]. We denote by mwp(i, N, P ) := maxσ ∈(cid:4)(wp(i, N, P , σ )) the maximum possible winning probability of i in T(N, σ ) taken over all draws σ ∈ (cid:4).We can now define the Probabilistic Tournament Fixing Problem (PTFP) in which the probability of each player beating another player is known and the goal is to find a draw that maximizes the probability of a certain player winning the BKT.Probabilistic Tournament Fixing Problem (PTFP)Instance: Player set N, pairwise comparison matrix P , a distinguished player iQuestion: Does there exist a draw σ for the player set N for which the probability of i∗∗ ∈ N, and target probability q ∈ [0, 1].winning T(N, σ ) is at least q?PTFP was proposed by Vu et al. [36] and has been studied in numerous papers (see e.g., [29–31]). It is a well-motivated problem in sports analytics [28]. PTFP has been shown to be NP-hard for various restrictions, including the case where the entries of P are restricted to {0, 12 , 1} [36] and the case where the matrix P is deterministic and certain matches are not allowed [34].Nevertheless, the computational complexity of a particularly natural and interesting special case, the Tournament Fixing Problem (TFP), has remained a major open question. In the TFP, the matrix P is deterministic and all matches are allowed. The winner of each match is deterministically known beforehand and the question is whether there exists a draw for which a given player wins in the corresponding BKT.Tournament Fixing Problem (TFP)Instance: Player set N, deterministic pairwise comparison matrix P , and a distinguished player iis the winner of T(N, σ )?Question: Does there exist a draw σ for the player set N for which i∗∗ ∈ N.TFP is equivalent to checking whether there exists a seeding π for which iis the winner of T(N, π ). We note that TFP is a special case of the problem with the same name as defined in Vassilevska Williams [34], where there can be additional constraints by which certain matches are disallowed. TFP is also a special case of #TFP — the problem of counting the number of draws for which a given player is the winner. This count can be used to compute the probability of a player winning in a draw chosen uniformly at random. It can also be interpreted as the relative strength of the player.∗Contributions We first settle the computational complexity of TFP by showing that it is NP-complete. The question was explicitly stated as an open problem a number of times [12,19,35,26,29–31,34,36,37]. As a corollary, we show that unless P = NP, there exists no polynomial-time approximation algorithm for computing the maximal winning probability of a player. This inapproximability result provides additional motivation for the line of work in which heuristic algorithms have been proposed for PTFP [37]. Another corollary is that there exists no fully polynomial time randomized approximation scheme(FPRAS) for counting the number of draws for which a player is the winner.In view of these intractability results, we identify two natural cases for which even #TFP (and hence also TFP) can be solved in polynomial time. In the first case, the players can be divided into a constant number of player types. This setting appeals to the scenario where players can be divided into groups based on similar intrinsic ability. In the second case, there is a linear ordering on the ability of players with a constant number of exceptions where a player with lower ability beats a player with higher ability.2 Finally, we provide an exact memoization-based algorithm to solve #TFP that is faster than known exact approaches to solve the problem: it runs in time O (2.8285n) and uses space O (1.7548n). If only polynomial space is available, the running time becomes 4n+o(n), and we give a range of possible time-space trade-offs.Finally, we consider double-elimination tournaments which are a variant of knockout tournaments in which the losers get a second chance to win the overall tournament. We show that TFP is NP-complete for this problem as well thereby answering another open problem [32].2 The condition is quite natural since in many competitions there is a clear-cut ranking of the players according to their skills with only a few pairs of players for which the weaker player can beat the stronger player. For example, as of 15/01/2014, Nikolay Davydenko was the only tennis player among the men’s top 64 who had a winning head-to-head record against Rafael Nadal. Russell and van Beek [26] as well as Mattei and Walsh [24] provide an extended discussion and empirical data on these phenomena.\fH. Aziz et al. / Artificial Intelligence 262 (2018) 1–143Related work After the work of Vu et al. [36], PTFP and TFP have been studied in a number of research papers. Vassilevska Williams [34] identified various sufficient conditions for a player to be a winner of a BKT, e.g. if he is a king who beats half of all players. I",
            {
                "entities": [
                    [
                        3372,
                        3400,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1221–1244Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA novel sequence representation for unsupervised analysis of humanactivitiesRaffay Hamid∗, Siddhartha Maddi, Amos Johnson, Aaron Bobick, Irfan Essa, Charles IsbellCollege of Computing, Georgia Institute of Technology – Atlanta, GA, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 30 October 2007Received in revised form 12 March 2009Accepted 25 May 2009Available online 30 May 2009Keywords:Temporal reasoningScene analysisComputer visionFormalizing computational models for everyday human activities remains an open chal-lenge. Many previous approaches towards this end assume prior knowledge about thestructure of activities, using which explicitly defined models are learned in a completelysupervised manner. For a majority of everyday environments however, the structure of thein situ activities is generally not known a priori. In this paper we investigate knowledgerepresentations and manipulation techniques that facilitate learning of human activities ina minimally supervised manner. The key contribution of this work is the idea that globalstructural information of human activities can be encoded using a subset of their localevent subsequences, and that this encoding is sufficient for activity-class discovery andclassification.In particular, we investigate modeling activity sequences in terms of their constituentsubsequences that we call event n-grams. Exploiting this representation, we propose acomputational framework to automatically discover the various activity-classes taking placein an environment. We model these activity-classes as maximally similar activity-cliques ina completely connected graph of activities, and describe how to discover them efficiently.Moreover, we propose methods for finding characterizations of these discovered classesfrom a holistic as well as a by-parts perspective. Using such characterizations, we presenta method to classify a new activity to one of the discovered activity-classes, and to auto-matically detect whether it is anomalous with respect to the general characteristics of itsmembership class. Our results show the efficacy of our approach in a variety of everydayenvironments.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConsider a household kitchen where different activities, such as making omelets, washing dishes, or eating cereal etc.,can take place. Each one of these activities can be performed in many different ways. To build systems that can be proactiveand assistive in such environments, it is not plausible to learn each and every one of the in situ activities in a completelysupervised manner. We are therefore interested in knowledge representations and manipulation techniques that allow com-putational systems to analyze human activities with minimal supervision.The importance of these systems that can learn our everyday activities can be motivated by the variety of applicationsthat they promise to offer. For instance, they have the potential to help us monitor peoples’ health as they age, as well asin fighting crime through improved surveillance. Their medical applications include identifying and evaluating crucial parts* Corresponding author.E-mail addresses: raffay@cc.gatech.edu (R. Hamid), maddis@cc.gatech.edu (S. Maddi), amos@cc.gatech.edu (A. Johnson), afb@cc.gatech.edu (A. Bobick),irfan@cc.gatech.edu (I. Essa), isbell@cc.gatech.edu (C. Isbell).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.05.002\f1222R. Hamid et al. / Artificial Intelligence 173 (2009) 1221–1244Fig. 1. Illustration of an example event. A person shown washing some dishes in the sink of a kitchen.of surgical procedures, and providing surgeons with useful feedback. Similarly, they can help us improve our productivity inoffice environments by detecting important events around us to enhance our involvement in various tasks.One of the key challenges in building such perceptual systems is the big gap that exists between the low level sensoryinputs such as pixel values or microphone voltages, and higher level inferences such as what dish is being prepared in akitchen, or whether someone forgot to add salt in it etc. A natural way to bridge this gap is to have a set of intermediatecharacterizations that can appropriately channel the low-level perceptual information all the way to higher level inferencestage. The granularity at which these intermediate characterizations should be defined presents a trade-off between howexpressive the characterizations are, versus the robustness with which they can be detected through low-level sensory data.In the following, we define a set of such intermediate characterizations that we shall use throughout this paper.1.1. Elements of activity dynamicsOne way of looking at everyday environments is in terms of a set of perceptually detectable key-objects [22]. A key-objectmay be defined as:Key-object: An object present in an environment that provides functionalities that may be required for the execution ofactivities of interest in that environment.We assume that a list of key-objects for an environment is known a priori. An illustrative figure showing a list of key-objects in a kitchen environment is shown in Fig. 1. Various operations on the key-objects can be used to define a set ofperceptually detectable activity-descriptors. We call these descriptors Events which are defined as:Event: A particular interaction among a subset of key-objects over a finite duration of time.Fig. 1 shows an example event of a person washing utensils in a sink.Event vocabulary: The set of interesting events that can take place in an environment.An event vocabulary for a household kitchen may consist of events like person opens the fridge door, person turns the stoveon, person turns the faucet on, etc. We assume that such an event vocabulary is known a priori.Activity: A finite sequence of events.To illustrate the notion of activities in an everyday environment, an example activity of making scrambled eggs is describedbelow:Make Scrambled Eggs= Enter Kitchen → Turn Stove On → Get Eggs → Fry Eggs →Turn Stove Off → Leave KitchenWe assume that the start and end events of activities are known a priori, and that every activity must be finished beforeanother is started, i.e. the question of overlapping activities is not included in our problem domain.\fR. Hamid et al. / Artificial Intelligence 173 (2009) 1221–12441223Fig. 2. General framework. 1. Starting with a corpus of activities, we extract their contiguous subsequences using some activity representation. 2. Based onthe frequential information of these subsequences, we define a notion of activity similarity and use it to automatically discover different activity-classes. 3.We characterize the discovered classes both at holistic and by-parts levels. 4. We classify a test activity to one of the discovered classes, and compare it tothe previous members of its membership class in order to detect anomalies.1.2. Main hypothesisWe want to learn everyday human activities using some activity representation that does not require us to manuallyencode the structural information of these activities in a completely supervised manner. By structural information of anactivity, we mean the various events constituting that activity, and the temporal order in which these constituent eventsare arranged. Our approach to this challenge is based on our hypothesis that we can learn the global structure of activitiessimply by using their local event subsequences. In particular, our main hypothesis states:Hypothesis statement: “The structure of activities can be encoded using a subset of their contiguous event subsequences, and thisencoding is sufficient for activity discovery and recognition”.At the heart of our hypothesis is the question whether we can have an appropriately descriptive yet robustly detectableevent vocabulary to describe human activities in a variety of everyday environments. Such intermediate sets of charac-terizations have been previously shown to exist for representing various temporal processes including speech [32], textdocuments [36], and protein sequences [4].We posit that the key-objects in everyday environments pose a set of spatial and temporal constraints on the way wegenerally execute our activities in these environments [22]. For instance, one has to open a fridge before one can get milkout of it. Similarly, one must turn a stove on before one can use it to fry eggs, etc. We believe that these constraintscan be used to construct a set of robustly detectable events that can appropriately describe the various activities takingplace in an environment. These events can channel the low-level information detected from the sensors, in a manner thatfacilitates making useful higher-level inferences. This idea of learning activity structure by using statistics of their local eventsubsequences is essential to move us away from the traditional grammar driven approaches for activity modeling, and adopta more data-driven perspective.1.3. Key contributionsThe main contribution of this work is a data-driven perspective towards activity analysis. We view this approach towardsautomatic analysis of human activities in four principled ways:1. Representation of activities in terms of their local event subsequences2. Discovery of the various activity-classes in an environment3. Characterization of the discovered activity-classes, and4. Detection of activities that deviate from characteristics of discovered classes.A brief description of these main contributions follows. A block diagram illustrating the general overview of our proposedframework is given in Fig. 2.1.3.1. Activity representationWe propose a novel activity representation that considers activities in terms of their contiguous event subsequencesof some fixed length. In particular, we consider act",
            {
                "entities": [
                    [
                        3588,
                        3616,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1195–1218www.elsevier.com/locate/artintThe measurement of ranks and the laws of iterated contractionMatthias Hild a, Wolfgang Spohn b,∗,1a Darden Graduate School of Business Administration, PO Box 6550, Charlottesville, VA 22906, USAb Department of Philosophy, University of Konstanz, 78457 Konstanz, GermanyReceived 2 February 2007; received in revised form 28 December 2007; accepted 14 March 2008Available online 20 March 2008AbstractRanking theory delivers an account of iterated contraction; each ranking function induces a specific iterated contraction behavior.The paper shows how to reconstruct a ranking function from its iterated contraction behavior uniquely up to multiplicative constantand thus how to measure ranks on a ratio scale. Thereby, it also shows how to completely axiomatize that behavior. The completeset of laws of iterated contraction it specifies amend the laws hitherto discussed in the literature.© 2008 Elsevier B.V. All rights reserved.Keywords: Ranking theory; Belief revision theory; Difference measurement; Contraction; Iterated contraction1. IntroductionRanking theory, as first presented in Spohn ([30, Section 5.3] and [31]) is well known to offer a complete modelof the dynamics of belief, i.e., it allows to state an arbitrarily iterable rule of belief change. By contrast, AGM beliefrevision theory, as summarized by Gärdenfors [13], founders at the problem of iterated belief change, as observed inSpohn ([30, Section 5.2] and [31, Section 3]), because it violates the principle of categorical matching, as Gärdenfors,Rott [14, p. 37] called it later on. Both theories agree, though, on single belief changes.There is a price to pay for the greater strength of ranking theory; it makes substantial use of numerical degreesof (dis-)belief. While one can well see how the dynamics of belief works on the basis of these degrees, one maywonder about the meaning of these degrees; they look arbitrary and seem to lack intuitive access (unlike subjectiveprobabilities, for instance). By contrast, AGM belief revision theory, in order to justify its revision postulates, onlyappeals to entrenchment orderings, an ordinal and intuitively well grasped notion.This difference does not weigh much for those interested in computing, but for the more philosophically minded—recall that both, AGM and ranking theorizing, originated in philosophy—there remains a problem. What do numericalranks mean? Where exactly is the difference between two numerically different, but ordinally equivalent rankingfunctions? Just in vague feelings concerning the strength of belief? This would certainly be a poor answer.* Corresponding author.E-mail addresses: matthias@hild.org (M. Hild), wolfgang.spohn@uni-konstanz.de (W. Spohn).1 We are indebted to three anonymous referees. Their extensive reviews helped improving this paper considerably.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.002\f1196M. Hild, W. Spohn / Artificial Intelligence 172 (2008) 1195–1218Is there really an objection? This is debatable. Historically, though, this kind of objection has played a most im-portant role. Cardinal utility became acceptable only after von Neumann, Morgenstern [34, Chapter 3] proved thatpreferences conforming to certain axioms determine cardinal utilities on an interval scale. Thus, the cardinal conceptturned out to be definable by, or reducible to, the ordinal concept; one cannot accept the one and reject the other.Ranks likewise are psychological magnitudes, and hence it appears legitimate, at least from an operationalistic pointof view, to demand a measurement theory for them, too.Perhaps, though, the concern is not operationalism, but rather logic. Customarily, any logical calculus is ennobledby a correctness and completeness, i.e., soundness theorem. There are calculi that live well without such a theorem.Still, we need not rehearse the historic examples for the tremendous insight delivered by such soundness theorems. Ifthe calculus looks sensible, if the semantics is intelligible, and if a soundness theorem proves them to be equivalent,then mutual support makes for a nearly unassailable theory.AGM belief revision theory has these virtues. Originally, it came in a logical disguise; its beginnings reach backto Gärdenfors’ [12] epistemic approach to the logic of counterfactuals. Its soundness theorem was that the revisionpostulates (K∗1–8) (cf. Alchourrón et al. [1, Sections 2+3], or Gärdenfors [13, Section 3.3]) and the contractionpostulates (K÷1–8) (cf. Alchourrón et al. [1, Sections 2+3], or Gärdenfors [13, Section 3.4]) were proved to beexactly those justified by an underlying entrenchment relation (cf. Alchourrón et al. [1, Section 4], or Gärdenfors [13,Chapter 4]). Indeed, many of those proposing postulates for iterated belief change also offered a model relative towhich the postulates are correct and complete. By contrast, ranking theory did not offer a comparable result, thusgiving rise to the impression that ranks are somehow arbitrary.The aim of this paper is to show that ranking theory, despite its greater strength, can meet these concerns. It willpresent a rigorous measurement of ranks on a ratio scale in terms of iterated contractions, thus fully satisfying whateveroperationalistic requirements one tends to impose. So, when Rott [28] emphasizes in his concluding Section 15 that hehas made “it fully clear that no numbers are needed for any of the belief change methods considered”, we think this issimply a false opposition; the appropriate method of belief change automatically guarantees the numbers. Moreover,the paper will specify a complete set of laws of iterated contraction, something much desired in its own right and in thepresent context comparable to a soundness theorem in logic. The connection will, of course, be that the measurementresult is in effect the proof of the completeness of the laws proposed.The basic idea of this paper is quite simple. It is to exploit iterated contractions for getting information about thecomparative size of rank differences. If the iterated contractions behave appropriately, these rank difference compar-isons will behave appropriately, too, i.e., such that the theory of difference measurement as propounded in Krantz etal. [21, Chapter 4] applies. It requires some skill, though, to find an elaboration of this guiding idea that is intuitivelyilluminating as well as formally sound.The plan of the paper is straightforward. In Section 2 we shall briefly introduce ranking theory as far as neededin the rest of the paper. In Section 3 we shall equally briefly introduce the required basics of the theory of differencemeasurement. Section 4 works up to the announced measurement result. Section 5 then states the complete laws ofiterated contraction entailed by this result and gives a comparative discussion of them, in order to explain their contentas well as how far they go beyond the present discussion of iterated contraction. Section 6, finally, proves that themeasurement theory indeed entails these laws. A conclusion will round up the paper.A few words about the history of this paper: Its core ideas are already found in Hild [18], a rough first draft thatremained unpublished; in particular the present Sections 5 and 6 were already far developed there. The other authorindependently had the same ideas, less well and less completely realized in Spohn [32], a mere internet publication.Somehow, it took us a long time to start elaborating these ideas in full detail. To our knowledge, the present paper isthe first mature presentation of the issue.2. A brief sketch of ranking theoryRanking theory assumes propositions to be the objects of belief, and not sentences or sentence-like representa-tions. This is an important and debatable decision right at the beginning of all epistemological theorizing. As thingspresently stand, it is at the same time a decision between being able and not being able to pursue a substantial way ofepistemological theorizing. AGM belief revision theory only apparently proceeds in a different way. It takes sentencesand sets of sentences as being in the domain of their belief change operators. At the same time it postulates so-called“extensionality” axioms stating that logically equivalent sentences show exactly the same behavior (are members of\fM. Hild, W. Spohn / Artificial Intelligence 172 (2008) 1195–12181197the same belief sets, produce the same revision results, etc.). So, it differs only superficially. Then, however, it alwaysseemed to us easier to deal with identical propositions than with logically equivalent sentences (even though the morecomplicated way has become standard in the literature).Anyway, let us simply stick to propositions without further discussion. Let W be a set of possibilities, e.g., possibleworlds, centered worlds, or small worlds, or what have you, and let A be any Boolean algebra of subsets of W ; theelements of A are called propositions. Only in Section 4 we shall require some further assumptions about the richnessof the Boolean algebra considered.The core notion of ranking theory is this:Definition 2.1. κ is a negative ranking function for A iff κ is a function from A into R+ = R ∪ {∞} such that for allA, B ∈ A:(a) κ(A) (cid:2) 0, κ(W ) = 0, and κ(∅) = ∞,(b) κ(A ∪ B) = min{κ(A), κ(B)}[the law of disjunction (for negative ranks)].Spohn [30,31] originally referred to such functions as ordinal conditional functions. Since Goldszmidt, Pearl [15],they were mostly called ranking functions. We have now added the adjective “negative”. The reason is their standardinterpretation: negative ranks (that are non-negative numbers) are degrees of disbelief. Thus, κ(A) = 0 says that A isnot disbelieved at all according to κ; κ(A) > 0 says that A is disbelieved, and the stronger the larger κ(A). Hence,¯A is disbelieved to some degree, i.e., iff κ( ¯A) > 0. So, the axioms (2.1a) and (2.1b) s",
            {
                "entities": [
                    [
                        2969,
                        2997,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 104–144Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCoherence graphsEnrique Miranda a,∗, Marco Zaffalon ba Rey Juan Carlos University, Department of Statistics and Operations Research, C-Tulipán, s/n, 28933 Móstoles, Spainb IDSIA, Galleria 2, CH-6928 Manno (Lugano), Switzerlanda r t i c l ei n f oa b s t r a c tArticle history:Received 23 April 2008Received in revised form 14 August 2008Accepted 4 September 2008Available online 11 September 2008Keywords:Walley’s strong and weak coherenceCoherent lower previsionsGraphical modelsProbabilistic logicSatisfiabilityWe study the consistency of a number of probability distributions, which are allowed to beimprecise. To make the treatment as general as possible, we represent those probabilisticassessments as a collection of conditional lower previsions. The problem then becomesproving Walley’s (strong) coherence of the assessments. In order to maintain generalityin the analysis, we assume to be given nearly no information about the numbers thatmake up the lower previsions in the collection. Under this condition, we investigatethe extent to which the above global task can be decomposed into simpler and morelocal ones. This is done by introducing a graphical representation of the conditionallower previsions that we call the coherence graph: we show that the coherence graphallows one to isolate some subsets of the collection whose coherence is sufficient for thecoherence of all the assessments; and we provide a polynomial-time algorithm that findsthe subsets efficiently. We show some of the implications of our results by focusing onthree models and problems: Bayesian and credal networks, of which we prove coherence;for which we provide an optimal graphical decomposition;the compatibility problem,probabilistic satisfiability, of which we show that some intractable instances can insteadbe solved efficiently by exploiting coherence graphs.© 2008 Elsevier B.V. All rights reserved.1. IntroductionWe focus on studying the consistency of a number of conditional and unconditional distributions of some variables.In order to make our treatment as general as possible, we are going to represent these probabilistic assessments usingthe theory of coherent lower previsions developed by Walley in [33], which is based on de Finetti’s work about subjectiveprobability [10,11]. This allows us to study the case where the above distributions are imprecise, i.e., where each of themis actually a closed convex set of precise distributions, which includes as a particular case that where our assessments areprecise probabilities. It also allows us to work with any type of variable, without placing restrictions on the admissiblepossibility spaces (finite, countable, continuous). The approach by Walley includes also as particular cases most of the otherimprecise probability models appearing in the literature.Studying the consistency problem is important both for theoretical and applied reasons. On the theoretical side, it hasbeen shown by de Finetti that a subjective theory of precise probability (such as the Bayesian theory) can be founded ona single axiom of consistency. Williams [35] and later Walley have shown that this continues to hold when such a theoryis generalised to handle imprecision in probability. In these theories proving consistency is therefore a necessary step toexploit all the tools they provide us with, such as Bayes’ rule and its generalisations. The application of these tools alone,* Corresponding author.E-mail addresses: enrique.miranda@urjc.es (E. Miranda), zaffalon@idsia.ch (M. Zaffalon).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.09.001\fE. Miranda, M. Zaffalon / Artificial Intelligence 173 (2009) 104–144105on the other hand, does not necessarily lead to self-consistent inference, even in the case of precise probabilities, as shownby Walley.On the applied side, it is a very common requirement that an inference method should not give rise to inconsistencies.This requirement is present, for example, in probabilistic logic [26], where one has to check first of all that the availableassessments are self-consistent. It is also present in the many other models and methods designed so as to give rise toa joint distribution, which is often regarded as a feature that ensures global consistency. Exactly this argument was used,for example, to support Bayesian networks versus rule-based systems already at the time of Pearl’s seminal work [27]. Butconsistency is quite a subtle concept to deal with. The following striking example adapted from [33, Section 7.3.5] showsthat the existence of a compatible joint is not always a good way to get rid of inconsistencies.Example 1. Let X1, X2 be two variables taking values in {1, 2, 3}, and assume that X1 = 3 if and only if X2 = 3, and for theother cases we have the contradictory information X1 = X2 and X1 (cid:3)= X2. We can model this by the conditional probabilitiesP ( X1 = 3| X2 = 3) = 1 = P ( X2 = 3| X1 = 3), P ( X1 = 1| X2 = 1) = 1 = P ( X1 = 2| X2 = 2) and P ( X2 = 1| X1 = 2) = 1 = P ( X2 =2| X1 = 1). Despite the contradiction, it can be checked that the assessments are compatible with the joint mass functiondetermined by P ( X1 = 3, X2 = 3) = 1, in the sense that this joint induces the above conditionals by Bayes’ rule when theconditioning events have positive probability.1The key here is that Bayes’ rule cannot be always applied because of the presence of events with zero probability; thistechnical issue prevents the contradiction from being identified. It follows that in order to check consistency we generallyneed stronger tools than those based on the existence of a compatible joint distribution. Walley’s notion of coherenceappears to be one such tool.In fact, Walley considers two different consistency concepts for conditional lower previsions, called weak coherence and(strong) coherence (these will be introduced in Section 2, along with other material about Walley’s theory). What we showin Section 3 is that a number of conditional lower previsions are weakly coherent when they can all be induced by the samejoint via Bayes’ rule (or its generalisation for the imprecise case) and marginalisations. In other words, we show that weakcoherence is the generalisation to imprecise probability of the consistency criterion based on the existence of a compatiblejoint. Coherence, on the other hand, strengthens weak coherence and it can be shown that the difference between weakand strong coherence is indeed related to conditioning on sets of probability zero (see [21]).Our goal in this paper is to simplify the verification of the weak or the strong coherence of a number of assessments. Toachieve this, we introduce in Section 5 a new graphical representation called coherence graphs. We prove in Section 6 thatcoherence graphs allow us to decompose the task of verifying weak and strong coherence in a number of simpler tasks.Specifically, they help us determine a partition of the set of assessments with the property that coherence (resp., weakcoherence) within each of the elements of the partition implies coherence (resp., weak coherence) of all the assessments.We prove moreover that this is the finest partition with this property in the case of weak coherence. Besides, this partitionof our set of assessments can be determined with a polynomial-time algorithm, which we present in Section 7.Then we move to show some of the implications of our results for artificial intelligence by considering three well-knownrelated research fields. In Section 8.1, we consider Bayesian networks [27] and their extension to imprecise probability calledcredal networks [8]. By joining coherence graphs with a notion of probabilistic independence, we show for the first timeand to a very large extent that Bayesian and credal networks are coherent models. In Section 8.2 we focus on the so-called compatibility problem (see [9] and the references therein for a recent overview), i.e., the problem of deciding whethera number of distributions has a compatible joint. In this case we exploit our results about weak coherence to delivernew graphical criteria that enable one to optimally decompose such a problem, under a very general formulation. Finally,in Section 8.3 we relate our results to a powerful form of probabilistic satisfiability based on consistency that has beenrecently proposed in [34]. In particular, we discuss how probabilistic satisfiability can be used to check the consistency ofa number of (possibly imprecise) conditional and unconditional mass functions, and we outline that this task can easilybecome intractable as a consequence of the NP-hardness of the problem [5]. Moreover, we show that coherence graphs candecompose such a task in a way that makes it possible to solve some instances of the problem that would otherwise beintractable.As we said, our results are very general, in the sense that they are applicable for variables taking values on finite orinfinite spaces, and that we can also consider precise or imprecise representations. We make nevertheless some assumptions,like the logical independence of the variables studied or the representation of our assessments through a functional definedon a sufficiently large domain. In Section 9, we comment on the extent to which these assumptions can be relaxed. Thisis an important problem in order to relate our work more tightly with other areas of research. Finally, we conclude thepaper in Section 10 with some additional discussion. To make the paper easier to read, we have relegated all the proofs toAppendix A.1 This consistency notion is what we shall call later in this paper weak coherence. Note that the contradictory assessments X1 = X2 and X1 (cid:3)= X2 can alsobe modelled by other conditional probabilities that do not even satisfy this consistency notion, for instance P ( X1 = 1| X2 ",
            {
                "entities": [
                    [
                        3746,
                        3774,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 167–185Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSafe inductions and their applications in knowledge representation ✩Bart Bogaerts a,∗a Department of Computer Science, KU Leuven, 3001 Heverlee, Belgiumb Department of Computer Science, KU Leuven, Campus De Nayer, 2860 Sint-Katelijne-Waver, Belgium, Joost Vennekens a,b, Marc Denecker aa r t i c l e i n f oa b s t r a c tIn many knowledge representation formalisms, a constructive semantics is defined based on sequential applications of rules or of a semantic operator. These constructions often share the property that rule applications must be delayed until it is safe to do so: until it is known that the condition that triggers the rule will continue to hold. This intuition occurs for instance in the well-founded semantics of logic programs and in autoepistemic logic. In this paper, we formally define the safety criterion algebraically. We study properties of so-called safe inductions and apply our theory to logic programming and autoepistemic logic. For the latter, we show that safe inductions manage to capture the intended meaning of a class of theories on which all classical constructive semantics fail.© 2018 Elsevier B.V. All rights reserved.Article history:Received 1 December 2017Received in revised form 13 March 2018Accepted 25 March 2018Available online 28 March 2018Keywords:Approximation fixpoint theoryLattice operatorInductive definitionsInduction processConstructionWell-founded semanticsGroundednessLogic programmingAutoepistemic logicAbstract argumentation1. IntroductionIn many fields of computational logic, natural forms of induction show up. Such an induction can be seen as a sequence of semantic structures obtained by iterative applications of rules or a semantic operator. For instance, in logic programming, it is natural to think of sequences of interpretations where at each stage a number of rules whose bodies are satisfied are triggered (i.e., their head is added to the current interpretation). For positive logic programs, all such sequences converge to the minimal model. For non-positive programs, this strategy may yield meaningless results. For instance, for the program(cid:2)(cid:3)P =ab ← ¬a,one such sequence isA short version of this paper was published in the proceedings of the IJCAI’17 conference [6]. This paper extends the previous work with more ✩theoretical results, examples, proofs of all propositions and applications of the work to argumentation frameworks.* Corresponding author.E-mail addresses: bart .bogaerts @cs .kuleuven .be (B. Bogaerts), joost .vennekens @cs .kuleuven .be (J. Vennekens), marc .denecker @cs .kuleuven .be(M. Denecker).https://doi.org/10.1016/j.artint.2018.03.0080004-3702/© 2018 Elsevier B.V. All rights reserved.\f168B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185N1 = ∅, {b}, {b, a},the limit of which is not even a supported model of the logic program. On the other hand, the sequenceN2 = ∅, {a}is another such sequence that does end in the intended model of P , namely its perfect model. Intuitively, what is wrong with N1 is that the rule b ← ¬a is applied too soon, before the value of a is established. For stratified programs, like P , this problem has been resolved, e.g., by Apt et al. [2]. For the general case, the well-founded semantics [33] offers a solution that uses three-valued interpretations instead of two-valued interpretations.In recent work, the notions of natural and safe inductions for inductive definitions were introduced [15,16]. It was argued that this kind of process forms the essence of our understanding of inductive definitions.In this paper, we lift those ideas of safe and natural inductions to a more general setting: we provide a principled study of such inductions in the context of approximation fixpoint theory (AFT) (Denecker, Marek and Truszczy ´nski (DMT) [10]), an algebraic theory that provides a unifying framework of semantics of nonmonotonic logics. We show convergence of safe inductions in this general setting and study the relationship between (algebraic) safe inductions and various fixpoints defined in approximation fixpoint theory.By presenting our theory in AFT, our results are broadly applicable. DMT [10] originally developed AFT to unify seman-tics of logic programs [32], autoepistemic logic [26] and default logic [28]. Later, it was also used to define semantics of extensions of logic programs, such as HEX logic programs [1] and an integration of logic programs with description log-ics [23]. Strass [30] showed that many semantics for Dung’s argumentation frameworks (AFs) [17] and abstract dialectical frameworks (ADFs) [7] can be obtained by direct application of AFT. Bogaerts and Cruz-Filipe [3] showed that AFT has applications in database theory, for defining semantics of active integrity constraints [19].The theory we present in this paper induces for each of the above logics notions of (safe) inductions and a safe semantics. Our complexity results are obtained for general operators and hence can also be transferred to various logics of interest. Throughout the paper, we give examples from logic programming.In Section 7, we apply our theory to autoepistemic logic. There we show that safe inductions induce a constructive semantics that captures the intended semantics of a class of theories for which classical constructive semantics fail. This failure was recently exposed and solved using a notion of set-inductions which is based on sets of lattice elements instead of intervals (which are standard in AFT) [5]. We show that safe inductions provide an alternative solution to this problem. Our solution is more direct: in contrast to set-inductions or well-founded inductions [14], safe inductions do not require any form of approximation; they are sequences in the original lattice. For logic programming, this means that they are sequences of interpretations such that some atoms are derived in each step. For AEL, this means that they are sequences of possible world structures such that additional knowledge is derived in each step.In Section 8, we apply our theory to Dung’s argumentation frameworks [17], where we show the surprising result that two different operators that exist for a given argumentation framework have the same safely defined point. Furthermore, this point corresponds to an existing semantics: it is the so-called grounded extension.The rest of this paper is structured as follows. In Section 2, we give preliminaries regarding lattices and operators. In Section 3, we define (safe) inductions and provide some basic results. We continue by studying complexity of some inference problems related to safe inductions in Section 4. In Section 5, we recall the basics of AFT; we use this in Section 6 to study how (safe) inductions relate to various fixpoints studied in AFT. Afterwards, in Sections 7 and 8, we apply our general theory to autoepistemic logic and argumentation frameworks respectively. We conclude in Section 9.2. Preliminaries: lattices and operators(cid:4)A partially ordered set (poset) (cid:5)L, ≤(cid:7) is a set L equipped with a partial order ≤, i.e., a reflexive, antisymmetric, transitive relation. We write x < y for x ≤ y ∧ x (cid:9)= y. If S is a subset of L, then x is an upper bound, respectively a lower bound of S if for every s ∈ S, it holds that s ≤ x, respectively x ≤ s. An element x is a least upper bound, respectively greatest lower boundof S if it is an upper bound that is smaller than every other upper bound, respectively a lower bound that is greater than every other lower bound. If S has a least upper bound, respectively a greatest lower bound, we denote it lub(S), respectively glb(S). As is custom, we sometimes call a greatest lower bound a meet, and a least upper bound a join and use the related S = lub(S) and x ∨ y = lub({x, y}). We call (cid:5)L, ≤(cid:7) a complete lattice if every notations subset S of L has a least upper bound and a greatest lower bound. A complete lattice has a least element ⊥ and a greatest element (cid:13).S = glb(S), x ∧ y = glb({x, y}), An operator O : L → L is monotone if x ≤ y implies that O (x) ≤ O ( y) and anti-monotone if x ≤ y implies that O ( y) ≤O (x). An element x ∈ L is a prefixpoint, a fixpoint, a postfixpoint of O if O (x) ≤ x, respectively O (x) = x, x ≤ O (x). Every monotone operator O in a complete lattice has a least fixpoint [31], denoted lfp(O ), which is also O ’s least prefixpoint and the limit of any terminal monotone induction of O , defined below.(cid:5)Definition 2.1. A monotone induction of a lattice operator O : L → L is an increasing sequence (for some ordinal β) (xi )i≤β of elements xi ∈ L satisfying\fB. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185169• x0 = ⊥,• xi ≤ xi+1 ≤ O (xi), for successor ordinals i + 1 ≤ β,• xλ = lub({xi | i < λ}), for limit ordinals λ ≤ β.A monotone induction is terminal if O (xβ ) = xβ .Logic programming. Let (cid:4) be an alphabet, i.e., a collection of symbols which are called atoms. A literal is an atom p or the negation ¬q of an atom q. The former are called positive literals; the latter are called negative literals. A logic program Pis a set of rules r of the form h ← ϕ, where h is an atom called the head of r, denoted head(r), and ϕ is a conjunction of literals called the body of r, denoted body(r). An interpretation I of (cid:4) is a subset of (cid:4). The set of interpretations 2(cid:4) forms a lattice equipped with the order ⊆. The truth value (t or f) of a propositional formula ϕ in a structure I , denoted ϕ I , is defined as usual. With a logic program P , we associate an immediate consequence operator T P [32] that maps a structure I to the structure{p ∈ (cid:4) | ∃r ∈ P : head(r) = p ∧ body(r)I = t}.This is an operator on the lattice (cid:5)2(cid:4), ⊆(cid:7). We call a logic program P positive if for each rule r ∈ P , body(r) consists of only",
            {
                "entities": [
                    [
                        2763,
                        2791,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1752–1782Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintModelling and solving temporal reasoning as propositional satisfiabilityDuc Nghia Pham a,b,∗, John Thornton a,b, Abdul Sattar a,ba SAFE Program, NICTA Ltd., Queensland, Australiab Institute for Integrated and Intelligent Systems, Griffith University, Queensland, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 24 November 2006Received in revised form 2 June 2008Accepted 11 June 2008Available online 19 June 2008Keywords:Temporal reasoningInterval AlgebraSatisfiabilitySatisfiability modulo theoriesDPLLSearchRepresenting and reasoning about time dependent information is a key research issue inmany areas of computer science and artificial intelligence. One of the best known andwidely used formalisms for representing interval-based qualitative temporal information isAllen’s interval algebra (IA). The fundamental reasoning task in IA is to find a scenario thatis consistent with the given information. This problem is in general NP-complete.In this paper, we investigate how an interval-based representation, or IA network, can beencoded into a propositional formula of Boolean variables and/or predicates in decidabletheories. Our task is to discover whether satisfying such a formula can be more efficientthan finding a consistent scenario for the original problem. There are two basic approachesto modelling an IA network: one represents the relations between intervals as variablesand the other represents the end-points of each interval as variables. By combining thesetwo approaches with three different Boolean satisfiability (SAT) encoding schemes, weproduced six encoding schemes for converting IA to SAT. In addition, we also showedhow IA networks can be formulated into satisfiability modulo theories (SMT) formulae basedon the quantifier-free integer difference logic (QF-IDL). These encodings were empiricallystudied using randomly generated IA problems of sizes ranging from 20 to 100 nodes.A general conclusion we draw from these experimental results is that encoding IA into SATproduces better results than existing approaches. More specifically, we show that the newpoint-based 1-D support SAT encoding of IA produces consistently better results than theother alternatives considered. In comparison with the six different SAT encodings, the SMTencoding came fourth after the point-based and interval-based 1-D support schemes andthe point-based direct scheme. Further, we observe that the phase transition region mapsdirectly from the IA encoding to each SAT or SMT encoding, but, surprisingly, the locationof the hard region varies according to the encoding scheme. Our results also show a fixedperformance ranking order over the various encoding schemes.© 2008 Elsevier B.V. All rights reserved.1. Introduction and backgroundRepresenting and reasoning about time dependent information (i.e. temporal reasoning) is a central research issue in manyreal world AI applications such as planning, plan recognition, scheduling, natural language understanding, and medicaldiagnosis [36]. The basic research tasks include the design and development of efficient reasoning methods to check theconsistency of temporal information, to infer new information and to answer temporal queries [10].Temporal reasoning is an important subdiscipline within the field of constraint satisfaction research and has been subdi-vided into two basic areas: qualitative and quantitative temporal reasoning.* Corresponding author at: SAFE Program, NICTA Ltd., Queensland, Australia.E-mail addresses: duc-nghia.pham@nicta.com.au (D.N. Pham), john.thornton@nicta.com.au (J. Thornton), abdul.sattar@nicta.com.au (A. Sattar).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.003\fD.N. Pham et al. / Artificial Intelligence 172 (2008) 1752–178217531.1. Quantitative temporal reasoningQuantitative problems have to deal with situations where there is definite metric information about time intervals, suchas one event being at least 20 minutes long or starting at exactly 2 o’clock. Such scenarios can be treated as temporal con-straint satisfaction problems (TCSPs) where variables represent continuous domain time points and constraints representsets of intervals that restrict the domains of particular variables [11]. For example, we could represent the unary con-straint T i that time point xi occurs within the intervals ([a1, b1], [a2, b2]) as (a1 (cid:2) xi (cid:2) b1) ∨ (a2 (cid:2) xi (cid:2) b2) or the binaryconstraint T i j that the duration between time points xi and x j lies within the interval [a1, b1] as (a1 (cid:2) x j − xi (cid:2) b1).A general TCSP can be represented as a directed constraint graph with nodes representing variables and edges represent-ing binary constraints, where each edge can be labelled with a set of intervals. If we further specify that each edge must belabelled with a single interval we arrive at a simple temporal problem (STP) [10].Deciding the consistency of a general TCSP is known to be NP-complete whereas finding the consistency of an STP canbe decided in polynomial time using shortest-path algorithms [11]. This has led to the development of methods that decidethe consistency of a TCSP by selecting one disjunct label from each edge and testing whether the resulting problem is aconsistent STP.Subsequent work has looked at disjunct temporal problems (DTPs) that allow the inclusion of non-binary constraints.Techniques for solving these problems treat the task of selecting a consistent STP from the original DTP as a meta-CSP [50]that takes each constraint in the original problem as a variable in the meta-problem and performs a backtracking searchwith forward-checking over the space of possible STPs.A DTP can also be represented as a satisfiability (SAT) problem, consisting of clauses containing disjunctions of literalsthat each represent a temporal constraint (e.g. x1 − x2 (cid:2) 2). Such problems can be solved using generic SAT solvers thatadditionally test the consistency of the underlying STP problems represented by the clauses during the search [3]. Currently,some of the most promising results in the DTP area have been produced using SAT solvers that incorporate the latestadvances from the general SAT solving complete search community [5].1.2. Qualitative temporal reasoningHowever, there are notions of time used in day to day decision making that do not refer directly to quantitative metricdata about time points or durations. For example, we may have a constraint that one event must start before another oroccur during a third event. Here we are only concerned with the relative time ordering of events and not with exactlywhen each event starts and stops. For instance, consider the ordering of events in the construction of a house. Here weare typically unable to predict or control exactly when a particular task will occur but we do have hard constraints aboutnot fitting out the interior until the roof is attached. These qualitative temporal relations were formalised in Allen’s intervalalgebra (IA) [1].In IA there are 13 atomic relations that define all the possible qualitative arrangements that can exist between twotime intervals. These relations cover the basic situations that two events can be before, during, overlapping, meeting, starting,finishing or equal to each other (see Table 1). As with the formulation of a TCSP, an IA problem can be expressed as directedconstraint graph. However, here each node represents an interval of unspecified length and the edges represent constraintslabelled by sets of atomic relations. In this form, IA is an expressively rich framework and, as with the general TCSP, thereasoning problem is computationally intractable. Existing IA techniques are typically based on the backtracking approach(proposed by Ladkin and Reinefeld [29]), which uses path consistency as forward checking. Although this approach hasTable 1The 13 IA atomic relations. Note that the endpoint relations X− < X+and Y− < Y+have been omittedAtomic relationSymbolX before YY after XX meets YY met by XX overlaps YY overlapped by XX during YY includes XX starts YY started by XX finishes YY finished by XX equals YbbimmiooiddissiffieqMeaningX(cid:2)(cid:3) Y(cid:2)(cid:3)X(cid:2) (cid:3) Y(cid:2) (cid:3)X(cid:2) (cid:3)(cid:2) (cid:3)YX(cid:2) (cid:3)(cid:3)(cid:2)YX(cid:2) (cid:3)(cid:2)(cid:3)YX(cid:2) (cid:3)(cid:3)(cid:2)YX(cid:2)(cid:2)Y(cid:3)(cid:3)Endpoint relations− < Y−, X+ < Y−, X− < Y+ < YXX++− < Y+ = Y−, X−, X− < Y+ < YXX++− < Y+ > Y−, X−, X− < Y+ < YXX++− > Y+ > Y−, X−, X− < Y+ < YXX++− = Y+ > Y−, X−, X− < Y+ < YXX++− > Y+ > Y−, X−, X− < Y+ = YXX++− = Y+ > Y−, X−, X− < Y+ = YXX++\f1754D.N. Pham et al. / Artificial Intelligence 172 (2008) 1752–1782been further improved [36,53], all variants still rely on path consistency checking at each step to prune the search space.This native IA approach has the advantage of being fairly compact, but is disadvantaged by the overhead of continuallyensuring path-consistency. Additionally, the native IA representation of variables and constraints means that state-of-the-artlocal search and complete search techniques (such as unit propagation look ahead in Satz [32] or nogood recording andnon-chronological backtracking in Chaff [35]) cannot be easily transferred to the IA domain.In practice, existing native IA backtracking approaches are only able to find consistent solutions for relatively smallgeneral IA instances [48,51]. On the other hand, recent research has shown that modelling and solving hard combinato-rial problems (including DTPs and planning problems) as SAT instances can produce significant performance benefits oversolving problems in their original form [5,24,26,41]. These results have motivated us to undertake the current study.In other related work, stochastic local search techniques (SLS) were applied ",
            {
                "entities": [
                    [
                        3851,
                        3879,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 267 (2019) 39–57Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProbably bounded suboptimal heuristic searchRoni Stern a,∗a Ben Gurion University of the Negev, Israelb University of Toronto, Canada, Gal Dreiman a, Richard Valenzano ba r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2017Received in revised form 15 June 2018Accepted 8 August 2018Available online 25 October 2018Keywords:Artificial intelligenceHeuristic searchFinding an optimal solution to a search problem is often desirable, but can be too difficult in many cases. A common approach in such cases is to try to find a solution whose suboptimality is bounded, where a parameter (cid:2) defines how far from optimal a solution can be while still being acceptable. A scarcely studied alternative is to try to find a solution that is probably optimal, where a parameter δ defines the confidence required in the solution’s optimality. This paper explores this option and introduces the concept of a probably bounded-suboptimal search (pBS search) algorithm. Such a search algorithm accepts two parameters, (cid:2) and δ, and outputs a solution that with probability at least 1 − δ costs at most 1 + (cid:2) times the optimal solution. A general algorithmic framework for pBS search algorithms is proposed. Several instances of this framework are described and analyzed theoretically and experimentally on a range of search domains. Results show that pBS search algorithms are often faster than a state-of-the-art bounded-suboptimal search algorithm. This shows in practice that finding solutions that satisfy a given suboptimality bound with high probability can be done faster than finding solutions that satisfy the same suboptimality bound with certainty.© 2018 Elsevier B.V. All rights reserved.1. IntroductionConsider a search problem in which we must find a path in a state space from a given initial state to a goal state. Given enough memory and running time, standard heuristic search algorithms like the Aalgorithm [1] can solve a given search problem optimally, i.e., find the lowest-cost path from the initial state to a goal. However, it is often the case that there is not enough memory or runtime to find an optimal solution. For such cases, a range of search algorithms have been proposed that return suboptimal solutions [2–5]. In particular, bounded-suboptimal search algorithms are algorithms that are guaranteed to return a solution whose cost is at most (1 + (cid:2)) times the optimal solution. Ideal bounded-suboptimal algorithms introduce a natural tradeoff between solution quality and search runtime: when (cid:2) is high, solutions are returned quickly but can have poorer quality, while when (cid:2) is low solutions are harder to find but usually have higher quality (i.e., lower cost).∗Bounded-suboptimal search algorithms are very strict, in the sense that the cost of the solution they return must be at most 1 + (cid:2) times the cost of an optimal solution. Current techniques to achieve this guarantee rely on admissible heuristics – heuristics that are a lower bound on the optimal solution cost. Such heuristics are often inaccurate, resulting in increased search runtime.* Corresponding author.E-mail addresses: sternron@post.bgu.ac.il (R. Stern), gal.dreiman@gmail.com (G. Dreiman), rvalenzano@cs.toronto.edu (R. Valenzano).https://doi.org/10.1016/j.artint.2018.08.0050004-3702/© 2018 Elsevier B.V. All rights reserved.\f40R. Stern et al. / Artificial Intelligence 267 (2019) 39–57In this paper, we propose an alternative type of solution quality guarantee. Search algorithms with this quality guarantee return solutions that are optimal with high probability. Instead of controlling the suboptimality of the returned solution (i.e., (cid:2)), these algorithms accept a parameter δ that controls the confidence in which the returned solution is optimal. δ allows a similar tradeoff of solution quality and runtime, where increasing δ is expected to decrease the search effort at the cost of increasing the likelihood that a suboptimal solution will be returned.Both types of solution quality guarantees can be combined, through the novel notion of a probably bounded-suboptimal search (pBS search). A pBS search algorithm is given two parameters, (cid:2) and δ, and is required to return a solution that is at most 1 + (cid:2) times the optimal solution, with probability higher than 1 − δ. We call 1 + (cid:2) the desired suboptimality, and 1 − δthe required confidence. Introducing and defining the concept of a pBS search is the first main contribution of this work.In many domains the solution found by current bounded-suboptimal search algorithms has a much lower (i.e., better) suboptimality in practice than the suboptimality guaranteed by the bound. Since there is usually a tradeoff between runtime and solution quality, this means the user of the search algorithm paid in runtime more than it was needed for the desired solution quality. A key benefit of the novel form of bounded suboptimality we propose is that it provides users of search algorithms with more control over the time-quality tradeoff. We observed this experimentally: by using some of the pBS algorithms we propose it is often possible to obtain a solution with the desired suboptimality significantly faster by only slightly relaxing the required confidence from 1.0 to 0.9.The second contribution is a general framework for developing pBS algorithms called Psf. Psf has two main building blocks: a solution generator and a stopping condition. The solution generator can be any algorithm that produces a sequence of solutions. The stopping condition is responsible for identifying when the current solution is sufficient, in the sense that it has the desired suboptimality with the required confidence. We propose three such stopping conditions – Absolute, h-ratio, and Open-based – and prove that using these conditions results in a pBS search algorithm. For the Absolute and h-ratioconditions we also propose a solution generator that is specifically designed to satisfy these stopping conditions quickly. These stopping conditions and new solution generator are the third contribution of this work.Finally, we evaluate the different instances of Psf experimentally on four search domains: the Pancakes puzzle, Dockyard robot, Vacuum cleaner, and grid-based pathfinding. The experiments on these diverse set of domains show that varying both (cid:2) and δ offers a flexible control over the solution quality versus runtime tradeoff: in general, increasing either (cid:2) or δ results in smaller running time and lower solution quality. In particular, setting δ > 0 indeed allows us to find solutions faster.Some of the material in this work was previously published in the proceedings of the Symposium on Combinatorial Search (SoCS) [6,7]. This paper summarizes and goes well beyond these two conference papers. In particular, it extends these prior works by:• The experimental evaluation in these prior conference publications considered only one domain: the 15-puzzle. This work significantly extends that evaluation through the implementation and evaluation of all Psf instances on four additional domains (see Section 5).• The theoretical basis of pBS search is properly defined and analyzed. This includes several corrections to the original work (see Appendix B).• For the Absolute and h-ratio stopping conditions, we propose a solution generator that is specifically designed for them, which is based on recent bounded-cost search algorithms (see Section 6).In addition, in previous work [6,7], this line of research was referred to as Probably Approximately Correct (PAC) search, since it was inspired by the notion of PAC learning from the theoretical machine learning literature [8]. Given that there are significant differences between the concept of PAC and the solution quality guarantees considered in this paper, we have changed the name to probably bounded-suboptimal search to avoid confusion. A comparison of these related concepts can be found in Section 8.2. Preliminaries and backgroundA graph search problem or a search problem is defined by a graph G, a source vertex s ∈ V , and a non-empty set of target vertices T ⊆ V . The edges in G are associated with a non-negative cost, denoted by c(e), and the cost of a path p in G, denoted c(p), is the sum of costs of its constituent edges. A solution to a search problem P is a path in G from s to a vertex in T . A solution is called optimal if there is no other solution that has a lower cost. Let Opt P denote the cost of the optimal solution to P . The suboptimality of a solution is the ratio between its cost and Opt P . Hence, the suboptimality of an optimal solution is 1. Note that alternative forms of suboptimality have also been introduced [9] and the concepts in this paper can easily be extended to them. For clarity, we focus in this paper on the aforementioned definition of suboptimality.A search algorithm is a procedure that accepts a search problem and tries to return a solution to it. Note that in some cases the underlying graph G is not given to the search algorithm explicitly, e.g., because it is too large to fit in memory. Instead, the search algorithm can be given a source vertex s and a set of state transition operators, which implicitly define G as the set of all states reachable by applying sequences of state transition operators to s.\f2.1. Properties of search algorithmsR. Stern et al. / Artificial Intelligence 267 (2019) 39–5741Let cost( A, P ) denote the cost of the solution returned by algorithm A when given problem P . A search algorithm A is called an optimal search algorithm if for every search problem P it holds that cost( A, P ) = OptP . A search algorithm A is called a bounded-suboptimal search algorithm if it accepts a parameter (cid:2) and for every problem P it holds that cost( A, P ) ≤(1 + (cid:2)) ",
            {
                "entities": [
                    [
                        3432,
                        3460,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 500–529Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAllocation and scheduling of Conditional Task GraphsMichele Lombardi, Michela Milano∗DEIS Universita’ di Bologna, Viale Risorgimento, 2, 40136 Bologna, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 29 October 2008Received in revised form 22 February 2010Accepted 22 February 2010Available online 24 February 2010Keywords:Constraint ProgrammingProbabilistic reasoningScenariosConditional Task GraphsConditional constraintsOptimizationWe propose an original, complete and efficient approach to the allocation and schedulingof Conditional Task Graphs (CTGs). In CTGs, nodes represent activities, some of themare branches and are labeled with a condition, arcs rooted in branch nodes are labeledwith condition outcomes and a corresponding probability. A task is executed at run timeif the condition outcomes that label the arcs in the path to the task hold at scheduleexecution time; this can be captured off-line by adopting a stochastic model. Tasks needfor their execution either unary or cumulative resources and some tasks can be executedon alternative resources. The solution to the problem is a single assignment of a resourceand of a start time to each task so that the allocation and schedule is feasible in eachscenario and the expected value of a given objective function is optimized. For thisproblem we need to extend traditional constraint-based scheduling techniques in twodirections: (i) compute the probability of sets of scenarios in polynomial time, in orderto get the expected value of the objective function; (ii) define conditional constraintsthat ensure feasibility in all scenarios. We show the application of this framework onproblems with objective functions depending either on the allocation of resources to tasksor on the scheduling part. Also, we present the conditional extension to the timetableglobal constraint. Experimental results show the effectiveness of the approach on a set ofbenchmarks taken from the field of embedded system design. Comparing our solver with ascenario based solver proposed in the literature, we show the advantages of our approachboth in terms of execution time and solution quality.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConditional Task Graphs (CTG) are directed acyclic graphs whose nodes represent activities, linked by arcs representingprecedence relations. Some of the activities are branches and are labeled with a condition; at run time, only one of the suc-cessors of a branch is chosen for execution, depending on the occurrence of a condition outcome labeling the correspondingarc. The truth or the falsity of those condition outcomes is not known a priori: this sets a challenge for any off-line designapproach, which should take into account the presence of such elements of uncertainty. A natural answer to this issue isadopting a stochastic model. Each activity has a release date, a deadline and needs a resource to be executed. The problemis to find a resource assignment and a start time for each task such that the solution is feasible whatever the run timescenario is and such that the expected value of a given objective function is optimized. We take into account differentobjective functions: those depending on the resource allocation of tasks and those depending on the scheduling side of theproblem.* Corresponding author.E-mail address: michela.milano@unibo.it (M. Milano).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.004\fM. Lombardi, M. Milano / Artificial Intelligence 174 (2010) 500–529501Fig. 1. Some pseudo-code and a its translation into a CTG.CTG are ubiquitous to a number of real life problems. In compilation of computer programs [13], for example, CTGs areused to explicitly take into account the presence of conditional instructions. Similarly, in the field of system design [39],CTGs are used to describe applications with if-then-else statements; in this case tasks represent processes and arcs are datacommunications. Once a hardware platform and an application is given, to design a system amounts to allocate platformresources to processes and to compute a schedule; in this context, taking into account branches allows better resource usage,and thus lower costs. CTG may be used also in the Business Process Management (BPM) [34] and in workflow management[30], as a mean of describing operational business processes with alternative control paths.For solving the allocation and scheduling problem of CTG we need to extend the traditional constraint based techniqueswith two ingredients. First, to compute the expected value of the objective function, we need an efficient method forreasoning on task probabilities in polynomial time. For example, we have to compute the probability a certain task executesor not, or, more in general, the probability of a given set of scenarios with uniform features (e.g. the same objective functionvalue). Second, we need to extend traditional constraints to take into account the feasibility in all scenarios.For this purpose, we define a data structure called Branch/Fork Graph – BFG. We show that if the CTG satisfies a propertycalled Control Flow Uniqueness – CFU, the above mentioned probabilities can be computed in polynomial time. CFU is aproperty that holds in a number of interesting applications, such as for example the compilation of computer programs,embedded system design and in structured business processes.The paper is organized as follows: Section 2 presents some applications where CTG is a convenient representation ofproblem entities and their relations; in Section 3 we provide some preliminary notions on Constraint-Based Scheduling.Section 4 introduces the concept of Conditional Task Graphs, Control Flow Uniqueness, sample space and scenarios anddefines the scheduling and allocation problem we consider. In Section 5 we define the data structure used for implementingefficient probabilistic reasoning, namely the Branch/Fork Graph and related algorithms. In Section 6 we use these algorithmsfor efficiently computing the expected value of three objective function types, while in Section 7 we exploit the BFG forimplementing the conditional variant of the timetable global constraint. Section 8 discusses related work and Section 9shows experimental results and a comparison with a scenario based approach.2. Applications of CTGsConditional Task Graphs can be used as a suitable data structure for representing activities and their temporal relationsin many real life applications. In these scenarios, CTG allocation and scheduling becomes a central issue.In compilation of computer programs [13], for example, CTGs are used to explicitly take into account the presenceof conditional instructions. For instance, Fig. 1 shows a simple example of pseudo-code and a natural translation intoa CTG; here each node corresponds to an instruction and each branch node to an “if” test; branch arcs are label withthe outcome they represent. In this case, probabilities of condition outcomes can be derived from code profiling. Clearly,computer programs may contain loops that are not treated in CTGs, but modern compilers adopt the loop unrolling [17]technique that can be used here for obtaining cycle free task graphs.Similarly, in the field of embedded system design [39] a common model to describe a parallel application is the taskgraph. The task graph has a structure similar to a data flow graph, except that the tasks in a task graph represent largerunits of functionality. However, a task graph model that has no control dependency information can only capture datadependency in the system specification. Recently, some researchers in the co-synthesis domain have tried to use conditionaltask graph to capture both data dependencies and control dependencies of the system specification [42,18]. Once a hardwareplatform and an application is given, to design a system amounts to allocate platform resources to processes and to computea schedule; in this context, taking into account branches allows better resource usage, and thus lower costs. However, thepresence of probabilities makes the problem extremely complex since the real time and quality of service constraints shouldbe satisfied for any execution scenario. Embedded system design applications will be used in this paper to experimentallyevaluate the performance and quality of our approach.CTG appear also in Business Process Management (BPM) [34] and in workflow management [30] as a mean of describingoperational business processes with alternative control paths. Workflows are instances of workflow models, that are repre-sentations of real-world business processes [41]. Basically workflow models consist of activities and the ordering amongstthem. They can serve different purposes: they can be employed for documentation of business processes or can be used asinput to a Workflow Management System that allows their machine-aided execution.\f502M. Lombardi, M. Milano / Artificial Intelligence 174 (2010) 500–529One of the most widely used systems for representing business processes is BPEL [27]. BPEL is a graph-structured lan-guage and allows to define a workflow model using nodes and edges. The logic of decisions and branching is expressedthrough transition conditions and join conditions. Transition conditions and join conditions are both Boolean expressions.As soon as an activity is completed, the transition conditions on their outgoing links are evaluated. The result is set as thestatus of the link, which is true or false. Afterwards, the target of each link is visited. If the status of all incoming links isdefined, the join condition of the activity is evaluated. If the join condition evaluates to false, the activity is called dead andthe status of all its outgoing links is set to false. If the join condition evaluates",
            {
                "entities": [
                    [
                        3605,
                        3633,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 748–788Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPractical solution techniques for first-order MDPs ✩Scott Sanner a,∗, Craig Boutilier ba Statistical Machine Learning Group, National ICT Australia, Canberra, ACT, 0200, Australiab Department of Computer Science, University of Toronto, Toronto, ON M5S 3H5, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 21 October 2007Received in revised form 4 November 2008Accepted 9 November 2008Available online 24 November 2008Keywords:MDPsFirst-order logicPlanningin the number of domain objects and exponentialMany traditional solution approaches to relationally specified decision-theoretic planningproblems (e.g., those stated in the probabilistic planning domain description language,or PPDDL) ground the specification with respect to a specific instantiation of domainobjects and apply a solution approach directly to the resulting ground Markov decisionprocess (MDP). Unfortunately, the space and time complexity of these grounded solutionapproaches are polynomialin thepredicate arity and the number of nested quantifiers in the relational problem specification.An alternative to grounding a relational planning problem is to tackle the problem directlyat the relational level. In this article, we propose one such approach that translates anexpressive subset of the PPDDL representation to a first-order MDP (FOMDP) specificationand then derives a domain-independent policy without grounding at any intermediate step.However, such generality does not come without its own set of challenges—the purpose ofthis article is to explore practical solution techniques for solving FOMDPs. To demonstratethe applicability of our techniques, we present proof-of-concept results of our first-orderapproximate linear programming (FOALP) planner on problems from the probabilistic trackof the ICAPS 2004 and 2006 International Planning Competitions.Crown Copyright © 2008 Published by Elsevier B.V. All rights reserved.1. IntroductionThere has been an extensive line of research over the years aimed at exploiting structure in order to compactly repre-sent and efficiently solve decision-theoretic planning problems modeled as Markov decision processes (MDPs) [12]. Whiletraditional approaches from operations research typically use enumerated state and action models [62], these have provedimpractical for large-scale AI planning tasks where the number of distinct states in a model can easily exceed the limits ofprimary and secondary storage on modern computers.Fortunately, many MDPs can be compactly described by using a factored state and action representation and exploitingvarious independences in the reward and transition functions [12]. The independencies and regularities laid bare by suchrepresentations can often be exploited in exact and approximate solution methods as well. Such techniques have permittedthe practical solution of MDPs that would not have been possible using enumerated state and action models [22,36,38,75].However, factored representations are only one type of structure that can be exploited in the representation of MDPs.Many MDPs can be described abstractly in terms of classes of domain objects and relations between those domain objectsthat may change over time. For example, a logistics problem specified in the probabilistic planning domain description✩Parts of this article appeared in preliminary form in [S. Sanner, C. Boutilier, Approximate linear programming for first-order MDPs, in: Uncertainty inArtificial Intelligence (UAI-05), Edinburgh, Scotland, 2005, pp. 509–517; S. Sanner, C. Boutilier, Practical linear evaluation techniques for first-order MDPs,in: Uncertainty in Artificial Intelligence (UAI-06), Boston, MA, 2006].* Corresponding author.E-mail address: ssanner@nicta.com.au (S. Sanner).0004-3702/$ – see front matter Crown Copyright © 2008 Published by Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.003\fS. Sanner, C. Boutilier / Artificial Intelligence 173 (2009) 748–788749language (PPDDL) [89] may refer to domain objects such as boxes, trucks, and cities. If the objective is to deliver all boxesto their assigned destination cities then the locations of these boxes and trucks may change as a result of actions takenin pursuit of this objective. Since action templates such as loading or unloading a box are likely to apply generically todomain objects and can be specified independently of any ground domain instantiation (e.g., 4 trucks, 5 boxes, and 9 cities),this permits compact MDP descriptions by exploiting the existence of domain objects, relations over these objects, and theability to express objectives and action effects using quantification.Unfortunately, while relational specifications such as PPDDL permit very compact, domain-independent descriptions ofa variety of MDPs, this compactness does not translate directly to effective solutions of the underlying planning problems.For example, one approach to solving a relational decision-theoretic planning problem might first construct sets of statevariables and actions for all possible ground instantiations of each relation and action with respect to a specific domain(e.g., 4 trucks, 5 boxes, and 9 cities). Then this approach might apply known solution techniques to this ground factoredrepresentation of an MDP. Unfortunately, such an approach is domain-specific; and the size of the ground MDP growspolynomially in the number of domain objects, and exponentially in the predicate arity and the number of nested quantifiersin the problem specification. For sufficiently large domains and complex relational MDP specifications, grounding may notbe a viable option.An alternative approach to grounding is to apply a solution approach directly at the relational level. In this article,we discuss one such technique that translates an expressive subset of the relational PPDDL representation to a first-orderMDP (FOMDP) [14] specification. A symbolic policy may then be derived with respect to this FOMDP, resulting in a domain-independent solution that exploits a purely lifted version of the Bellman equations and avoids grounding at any intermediatestep. This stands in contrast to alternate first-order approaches discussed in Section 6.2 that induce symbolic representationsof the solution from samples of the Bellman equation in ground problem instances.Unfortunately, the use of first-order logical languages to describe our FOMDP specification and solution introduces theneed for computationally expensive logical simplification and theorem proving. While this means that exact solutions arenot tractable for many FOMDPs, there is often a high degree of regularity and structure present in many FOMDPs that canbe exploited by the approximate (heuristic) solution techniques proposed in this article. To this end, this article continuesthe tradition of exploiting structure to find effective solutions for large MDPs.After providing a review of MDPs and relevant solution techniques in Section 2 and the FOMDP formalism and itssolution via symbolic dynamic programming [14] in Section 3, we make the following contributions to the practical solutionof FOMDPs:(1) Section 3.2.2: We show how to translate a subset of PPDDL problems including universal and conditional effects toFOMDPs.(2) Section 4.1: We show how to exploit the logical structure of reward, value, and transition functions using first-orderextensions of algebraic decision diagrams (ADDs) [4] for use in both exact and approximate FOMDP solutions.(3) Section 4.2: We apply additive decomposition techniques to universal reward specifications in a manner that leads toefficient solutions for our FOMDP representation and reasonable empirical performance on example problems.(4) Section 5.3: We show how to generalize the approximate linear programming technique for MDPs [19,36,72] to the caseof FOMDPs by casting the optimization problem in terms of a first-order linear program.(5) Section 5.4: We define a linear program (LP) with first-order constraints and provide a constraint generation algorithmthat utilizes a relational generalization of variable elimination [91] to exploit constraint structure in the efficient solutionof this first-order LP (FOLP).To demonstrate the efficacy of our techniques, we present proof-of-concept results of our first-order approximate linearprogramming (FOALP) planner on problems from the probabilistic track of the ICAPS 2004 and 2006 International Plan-ning Competitions in Section 5.6. Following this, we discuss a number of related first-order decision-theoretic planningapproaches and discuss the relative advantages and disadvantages of each in Section 6. We conclude with a discussion ofpossible extensions to our techniques in Section 7.2. Markov decision processesMarkov decision processes (MDPs) were first introduced and developed in the fields of operations research and eco-nomics [6,41,73]. The MDP has since been adopted as a model for decision-theoretic planning with fully observable state inthe field of artificial intelligence [7,8,12] and as such provides the formal underpinning for the framework that we describein this article. In this section, we describe various algorithmic approaches for making optimal sequential decisions in MDPsthat we later generalize to the case of first-order MDPs. The following presentation derives from Puterman [62].2.1. The MDP model and optimality criteriaFormally, a finite state and action MDP is specified by a tuple (cid:3)S, A, T , R, h, γ (cid:4). S is a set of distinct states. An agentin an MDP can effect changes to its state by executing actions from the set A. We base our initial presentation in thissection on finite state and action MDPs; but in much of what follows, we will assume an infinite, discrete state and action\f750S. Sanner, C. Boutilier / Artificial Intelligence 173 (2009) 748–788space. The standard techniques for",
            {
                "entities": [
                    [
                        3993,
                        4021,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 199–200 (2013) 45–66Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLifting integrity constraints in binary aggregationUmberto Grandi∗, Ulle EndrissInstitute for Logic, Language and Computation, University of Amsterdam, Postbus 94242, 1090 GE Amsterdam, The Netherlandsa r t i c l ei n f oa b s t r a c tWe consider problems in which several individuals each need to make a yes/no choiceregarding a number of issues and these choices then need to be aggregated into a collectivechoice. Depending on the application at hand, different combinations of yes/no may beconsidered rational. We describe rationality assumptions as integrity constraints using asimple propositional language and we explore the question of whether or not a givenaggregation procedure willlift a given integrity constraint from the individual to thecollective level, i.e., whether the collective choice will be rational whenever all individualchoices are.© 2013 Elsevier B.V. All rights reserved.Article history:Received 25 April 2012Received in revised form 24 April 2013Accepted 3 May 2013Available online 6 May 2013Keywords:Collective decision makingComputational social choiceMulti-issue domainsCombinatorial voteJudgment aggregation1. IntroductionSocial Choice Theory (SCT) is the study of mathematical models for collective decision making. In recent times, this disci-pline has received increasing attention in Artificial Intelligence (AI), as testified by a large number of papers on social choiceat the major AI conferences and by the creation of an entirely new research agenda under the name of Computational SocialChoice [6]. There are several good reasons for this trend. On the one hand, a number of methods developed in AI and, moregenerally, in Computer Science have turned out to be useful to deepen our understanding of social choice and, in somecases, can even suggest an entirely new perspective on classical problems. Examples include the complexity-theoretic analy-sis of optimisation problems arising in social choice [15,16] and the creation of new choice procedures inspired by classicaltechniques in knowledge representation [27]. On the other hand, methods from SCT have natural important applications inAI. They can, e.g., be employed to achieve consensus amongst the autonomous software agents in a multiagent system [39],to aggregate the output of several search engines [2], or to inform the design of online recommender systems [34]. Oneparticular problem of interest for AI is the case of social choice in combinatorial domains, in which the space of alternativesfrom which the individuals have to choose has a multi-attribute structure [26,7]. Classical examples include voting in mul-tiple referenda, where we have to decide which of a set of propositions to accept, or electing a committee, where we haveto decide how to fill each seat. There have been several attempts to tackle the high complexity that arises in this context byusing tools from AI, such as methods for modelling preferences inspired by knowledge representation [28,38]. Finally, SCTprovides tools for the analysis of collective choices of groups of agents, and as such is of immediate relevance to the studyof multiagent systems.A central problem in SCT, and, in view of our previous discussion, in all its applications to AI, is the problem of ag-gregation: Suppose a group of agents each supply a particular piece of information regarding a common problem and wewant to aggregate this information into a collective view to obtain a summary of the individual views provided. A classical* Corresponding author at: Department of Mathematics, University of Padova, Via Trieste 63, 35121 Padova, Italy. Tel.: +39 (0) 498271357; fax: +39 (0)498271499.E-mail addresses: umberto.uni@gmail.com (U. Grandi), ulle.endriss@uva.nl (U. Endriss).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.05.001\f46U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66example is that of preferences [3]: each agent declares their individual preferences over a set of alternatives by providingan ordering over this set, and we are asked to amalgamate this information into a collective ranking that represents theindividual preferences provided. The same methodology has also been applied more recently to a number of other types ofinformation, such as beliefs [23,24] and judgments [29].One of the main features of the study of aggregation is the problem of collective rationality: given a rationality assumptionthat bounds the choices of the individuals, we ask whether the output of an aggregator still satisfies the same rationalityassumption. To understand this problem better, consider the following example: three autonomous agents need to decideon whether to perform a collective action. This action is performed if two parameters are estimated to exceed a certainthreshold. We can model the choice situation with a multi-attribute domain in which there are three issues at stake: “thefirst parameter is above the threshold” (T 1), “the second parameter is above the threshold” (T 2), and “the action should beperformed” ( A). The rationality assumption that links the three issues together can be modelled using a simple propositionalformula, namely T 1 ∧ T 2 → A. The individual views on the three issues are then aggregated using the majority rule, whichaccepts an issue if a majority of the individual agents do. Consider now the following situation:Agent 1Agent 2Agent 3MajorityT 1YesNoYesYesT 2YesYesNoYesAYesNoNoNoIn the situation described above the collective action A is not performed, even though a majority of the individuals thinkthat the first parameter exceeds the threshold and a (different) majority agree that also the second parameter exceeds thethreshold. Situations like the one above are considered paradoxical: even if each individual agent is rational (i.e., each ofthem satisfies the rationality assumption), the collective view derived using the majority rule is not. That is, the majorityrule fails to lift the integrity constraint T 1 ∧ T 2 → A from the individual to the collective level. This example shows thatthe majority rule violates collective rationality in certain specific cases. Similar examples can be devised for a number ofdifferent situations ranging from voting to rank aggregation, to the development of a collective judgment in court cases.Classical work in SCT was restricted to particular studies of collective rationality in a given aggregation situation and fora given class of aggregation procedures. Dokow and Holzman [11], for instance, characterise binary domains of aggregationover which every procedure that satisfies certain desirable axiomatic properties, namely, independence and unanimity, isdictatorial (see Section 8). This is a good example for the use of the axiomatic method in economic theory: the aim is toidentify the appropriate set of axiomatic properties (e.g., to model real-world economies, specific moral ideals, etc.) andthen to prove a characterisation (or impossibility) result for those axioms. Given the wide variety of potential applicationsin AI, on the other hand, in this context we require instead a systematic study that, depending on the situation at hand,can give answers to the problem of collective rationality. With every new application the principles underlying a systemmay change; so we may be more interested in devising languages for expressing a range of different axiomatic propertiesrather than identifying the “right” set of axioms; and we may be more interested in developing methods that will help usto understand the dynamics of a range of different social choice scenarios rather than in technical results for a specific suchscenario.In this paper we put forward a general framework that encompasses most of the classical studies of collective rationalityin SCT, and that can prove useful to diverse research areas in AI. We base our framework on binary aggregation, in whichindividuals are required to choose from a multi-issue domain where issues represent different binary choices. Classicalframeworks for the study of aggregation, such as preference and judgment aggregation, can be embedded in this framework.We model rationality assumptions using a simple propositional language, and we give a precise definition of collectiverationality with respect to a given rationality assumption. We classify rationality assumptions with respect to their syntacticproperties, and we give a systematic treatment of the question of how to relate collective rationality with respect to asyntactically defined sublanguage to classical axiomatic properties from SCT. For instance, we have already seen that themajority rule is not collectively rational with respect to the integrity constraint T 1 ∧ T 2 → A. It is also not collectivelyrational with respect to the 3-clause T 1 ∨ T 2 ∨ A: to see this, consider a scenario with three agents, where each agentaccepts exactly one issue, and no two agents accept the same issue. On the other hand, as we shall see, any 2-clause willalways be lifted, i.e., the majority rule is collectively rational with respect to the language of 2-clauses. We will then beable to describe the majority rule in terms of classical axioms (see Proposition 2) or in terms of the subset of integrityconstraints it lifts (see Theorem 28). It is results of this kind that we shall explore in depth in this paper, establishing a linkbetween standard axiomatic requirements from SCT and collective rationality with respect to fragments of the propositionallanguage.This paper expands our initial work on this topic [20], complementing it with further results from previous work [21,19,18].The paper is organised as follows. We begin by defining the basic notions that constitute the framework of binaryaggregation with integrity constraints in Section 2. In this secti",
            {
                "entities": [
                    [
                        3979,
                        4007,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 223 (2015) 65–81Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimizing ontology alignments through a Memetic Algorithm using both MatchFmeasure and Unanimous Improvement RatioXingsi Xue a,b, Yuping Wang a,∗a School of Computer Science and Technology, Xidian University, Xi’an, Shaanxi, Chinab School of Information Science and Engineering, Fujian University of Technology, Fuzhou, Fujian, Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 1 April 2014Received in revised form 14 February 2015Accepted 1 March 2015Available online 5 March 2015Keywords:Ontology alignmentMemetic AlgorithmMatchFmeasureUnanimous Improvement RatioThere are three main drawbacks of current evolutionary approaches for determining the weights of ontology matching system. The first drawback is that it is difficult to simultaneously deal with several pairs of ontologies, i.e. finding a universal weight configuration that can be used for different ontology pairs without adjustment. The second one is that a reference alignment between two ontologies to be aligned should be given in advance which could be very expensive to obtain especially when the scale of ontologies is considerably large. The last one arises from f-measure, a generally used evaluation metric of the alignment’s quality, which may cause the bias improvement of the solution. To overcome these three defects, in this paper, we propose to use both MatchFmeasure, a rough evaluation metric on no reference alignment to approximate f-measure, and Unanimous Improvement Ratio (UIR), a measure that complements MatchFmeasure, in the process of optimizing the ontology alignments by Memetic Algorithm (MA). The experimental results have shown that the MA using both MatchFmeasure and UIR is effective to simultaneously align multiple pairs of ontologies and avoid the bias improvement caused by MatchFeasure. Moreover, the comparison with state-of-the-art ontology matching systems further indicates the effectiveness of the proposed method.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOntologies are regarded as the solution to data heterogeneity on the semantic web. However, because of human sub-jectivity, the ontologies could themselves introduce heterogeneity: given two ontologies, one entity can be given different names or simply be defined in different ways. Addressing this heterogeneity problem requires to identify correspondences between entities of various ontologies. This process is commonly known as ontology alignment which can be described as follows: given two ontologies with each describing a set of discrete entities (which can be classes, properties, instances, etc.), we have to find the relationships (e.g., equivalence or subsumption) that hold between these entities [1].It is highly impractical to align the ontologies manually when the size of ontologies is considerably large. Thus, numerous ontology matching systems have arisen over the years. Each of them could provide, in a fully automatic or semi-automatic way, a numerical value of similarity between elements from separate ontologies that can be used to decide whether those * Corresponding author.E-mail address: ywang@xidian.edu.cn (Y. Wang).http://dx.doi.org/10.1016/j.artint.2015.03.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f66X. Xue, Y. Wang / Artificial Intelligence 223 (2015) 65–81elements are semantically similar or not. Since none of the similarity measures could provide the satisfactory result inde-pendently, most ontology matching systems combine a set of different similarity measures together by aggregating their aligning results. How to select the appropriate similarity measures, weights and thresholds in ontology aligning process in order to obtain a satisfactory alignment is called meta-matching which can be viewed as an optimization problem and be addressed by evolutionary approaches like Memetic Algorithms (MA).Since modeling the meta-matching problem is a complex (nonlinear problem with many local optimal solutions) and time-consuming task (large scale problem), particularly when the number of similarity measures is significantly large, ap-proximate methods are usually used for computing the parameters. From this point of view, evolutionary optimization methods could represent an efficient approach for addressing this problem. However, the slow convergence and premature convergence are two main shortcomings of the classical evolutionary algorithms (e.g. Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) algorithm) for this kind of problem. It makes these algorithms incapable of effectively searching the optimal solution for large scale and complex problems. Starting from these considerations, our work investigates the methodology of using an emergent class of evolutionary algorithms, named Memetic Algorithms (MA), to efficiently tackle the meta-matching problem. MA is a population-based search method which combines genetic algorithms (global search) and local refinements (local search). This marriage between global search and local search allows keeping high population diversity via strong mutation (thus, reducing the possibility of the premature convergence) and increasing the convergence speed via the local search (in fact, local search can greatly improve the solution quality and thus make the solution ap-proaches to optimal solution more quickly). Therefore, MA is very suitable to the problem considered.Nevertheless, there are three main drawbacks of current evolutionary approaches for determining the weights of ontology matching systems. The first drawback is that it is difficult to simultaneously deal with several pairs of ontologies, i.e. finding a universal weight configuration that can be used for different ontology pairs without adjustment. The second one is that a reference alignment between two ontologies to be aligned should be given in advance which could be very expensive to obtain especially when the scale of ontologies is considerably large. The last one arises from f-measure, a generally used evaluation metric of the ontology alignment’s quality, which may cause the bias improvement of the solution. To be specific, the improvement of f-measure does not say anything about whether both evaluation metrics involved (i.e. recall and precision) are simultaneously improved or not. In other words, no matter how large a measured improvement in f-measure is, it can still be extremely dependent on how we are weighting the evaluation metrics involved. To overcome these three defects, in this paper, we propose to use both MatchFmeasure, a rough evaluation metric on no reference alignment to approximate f-measure, and Unanimous Improvement Ratio (UIR) [27], a measure that complements MatchFmeasure, in the process of optimizing the ontology alignments by Memetic Algorithm (MA). In particular, our proposed method applies to the specific scenario that the target ontologies are the variations of the same source ontology. For example, given a source ontology O A , three target ontologies O B , O C and O D which are different variations of O A in terms of different lexical, linguistic and ontology structure respectively, the goal of our proposed method is to determine the optimal parameters, in terms of both MatchFmeasure and UIR, for the ontology matching tasks that match O A with O B , O A with O C and O Awith O D respectively. Moreover, the obtained parameter set could be reused in the task of matching O A with O E which is another target ontology that has different lexical, linguistic and ontology structure from O A at the same time.The remainder of the paper is organized as follows: Section 2 gives a brief foundation of our work; Section 3 presents the related work about MA and evolutionary algorithm for the ontology alignment problem; Section 4 provides a detailed description of the basic concepts of the similarity measures, the aggregation strategy and the ontology alignment evaluation metrics; Section 5 presents the details of MA based on MatchFmeasure and UIR; Section 6 shows the experimental results of our approach; finally, in Section 7, we draw conclusions and propose the future improvement.2. FoundationThere are numerous definitions of ontology over years. But the most frequently referenced one was given by Gruber in 1993 which defined the ontology as an explicit specification of a conceptualization. For the convenience of understanding the work in this paper, the ontology is defined as following:Definition 1. (See [25].) An ontology is a 9-tuple O = (C, P , I, A, ≤C , ≤P , φC P , φC I , φP I ), where:• C is a nonempty set of classes,• P is a nonempty set of properties,• I is a set of instances (it can be empty),• A is a set of axioms which should not be empty,• ≤C is a partial order on C , called class hierarchy or taxonomy,• ≤P is a partial order on P , called property hierarchy,• φC P : P → C × C is a function which associates a property p ∈ P with two linked classes through the property p. We denote the domain by dom(p) := π1(φC P (p)) and the range by ran(p) := π2(φC P (p)) where π1() and π2() are two functions obtaining the domain class and range class respectively,• φC I : C → P(I) is a function which associates a concept c ∈ C with a subset of I representing the instances of the concept c,\fX. Xue, Y. Wang / Artificial Intelligence 223 (2015) 65–8167• φP I : P → P(I 2) is a function which associates a property p ∈ P with a subset of Cartesian product I × I representing the pair of instances related through the property p.In general, classes, properties and individuals are referred as entities.At present, ontologies are viewed as a practical way to conceptualize information that is expressed in electronic for-mat, and are used in many applications from different areas. However, certain systems that encompass a large number of components associated with different domains would ge",
            {
                "entities": [
                    [
                        3297,
                        3325,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 670–684Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMonte Carlo tree search in KriegspielPaolo Ciancarini∗, Gian Piero FaviniDipartimento di Scienze dell’Informazione, University of Bologna, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 20 September 2009Received in revised form 4 April 2010Accepted 4 April 2010Available online 9 April 2010Keywords:GamesChessKriegspielIncomplete informationMonte Carlo tree search1. IntroductionPartial information games are excellent examples of decision making under uncertainty. Inparticular, some games have such an immense state space and high degree of uncertaintythat traditional algorithms and methods struggle to play them effectively. Monte Carlo treesearch (MCTS) has brought significant improvements to the level of computer programsin games such as Go, and it has been used to play partial information games as well.However, there are certain games with particularly large trees and reduced informationin which a naive MCTS approach is insufficient: in particular, this is the case of gameswith long matches, dynamic information, and complex victory conditions. In this paper weexplore the application of MCTS to a wargame-like board game, Kriegspiel. We describe andstudy three MCTS-based methods, starting from a very simple implementation and movingto more refined versions for playing the game with little specific knowledge. We comparethese MCTS-based programs to the strongest known minimax-based Kriegspiel program,obtaining significantly better experimental results with less domain-specific knowledge.© 2010 Elsevier B.V. All rights reserved.Partial information games provide a good model and testbed for many real-world situations involving decision mak-ing under uncertainty. They can be very difficult for a computer program to play well. These games typically require acombination of complex tasks such as heuristic search, belief state reconstruction, and opponent modeling.Moreover, some games are particularly challenging because at any time the number of possible, indistinguishable statesfar exceeds the storage and computational abilities of present-day computers. In this paper, the focus is on one such game,Kriegspiel or invisible chess. The game is interesting for at least three reasons. Firstly, its rules are identical to those of Chess,a very well-known game; however, the players’ perception of the board is different, only being able to see their own pieces.Secondly, it is a game with a huge number of states and limited means of acquiring information. Finally, the nature ofuncertainty is entirely dynamic. These issues put Kriegspiel in a category different from other partial information gamessuch as Stratego or Phantom Go (the partial information variant of Go [1]), wherein a newly discovered piece of informationremains valid for the rest of the game. Information in Kriegspiel is scarce, precious, and ages fast.In fact, even if it is an old game, well known to game theorists and even discussed by von Neumann and Morgensternin [2] under the name of blind chess, the first attempt to build an effective Kriegspiel playing program came only in 2005and was based on Monte Carlo sampling [3]. It was, however, defeated by our first program, described in [4] and based ona form of minimax on a game tree of data structures called metapositions. These had been first defined in [5] for a partialinformation variant of Shogi, that is Japanese Chess. Our program was better than other competing programs, but was notgood enough to compete with the best human players.* Corresponding author.E-mail address: cianca@cs.unibo.it (P. Ciancarini).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.017\fP. Ciancarini, G.P. Favini / Artificial Intelligence 174 (2010) 670–684671Fig. 1. The four phases of Monte Carlo tree search: selection, expansion, simulation and backpropagation.In this paper we present and study different ways of applying Monte Carlo tree search to Kriegspiel. Monte Carlo treesearch has been imposing itself over the past years as a major tool for games in which traditional minimax techniquesdo not yield good results due to the size of the state space and the difficulty of crafting an adequate evaluation function.The game of Go is the primary example, albeit not the only one, of a tough environment for minimax where Monte Carlotree search was able to improve the level of computer programs considerably [6,7]. Since Kriegspiel shares the two traits ofbeing a large game and a difficult one to express with an evaluation function (unlike its complete information counterpart),it is only natural to test a similar approach.The paper is organized as follows. Section 2 contains a high-level introduction to Monte Carlo tree search (MCTS), withan emphasis on its successful application to Phantom Go. In Section 3, we introduce the game of Kriegspiel, its rules,and what makes it similar, yet very different, to Phantom Go. Section 4 contains the most significant research results onKriegspiel, especially those related to previous Monte Carlo methods. We give a high-level view of three MCTS approachesin Section 5, showing how they are similar and where they differ; the corresponding programs are then described in greaterdetail separately. Section 6 contains some experimental tests comparing the strength and the performance of the variousprograms. Finally, we give our conclusions and some future research directions in Section 7.2. Monte Carlo tree searchMonte Carlo tree search (MCTS) is an evolution of some simpler and older methods based on Monte Carlo sampling.While the core concept is still the same – a program plays a large number of random simulated games and picks the movethat seems to yield the highest victory ratio – the purpose of MCTS is to make the computation converge to the right valuemuch more quickly than pure Monte Carlo. This is accomplished by guiding the simulations with a game tree that grows toaccommodate new nodes over time; more promising nodes are, in theory, reached first and visited more often than nodesthat are likely to be unattractive.MCTS is an iterative method that performs the same four steps until its available time runs out. These steps are summa-rized in Fig. 1.• Selection. The algorithm selects a leaf node from the tree based on the number of visits and their average value.• Expansion. The algorithm optionally adds new nodes to the tree.• Simulation. The algorithm somehow simulates the rest of the game one or more times, and returns the value of thefinal state (or their average, if simulated multiple times).• Backpropagation. The value is propagated to the node’s ancestors up to the root, and new average values are computedfor these nodes.After performing these phases as many times as time allows, the program chooses the root’s child that has received themost visits and plays the corresponding move. This may not necessarily coincide with the node with the highest meanvalue. A discussion about why the mean operator alone does not make a good choice is contained in [8].\f672P. Ciancarini, G.P. Favini / Artificial Intelligence 174 (2010) 670–684MCTS should be thought of as a method rather than a specific algorithm, in that it does not dictate hard policies forany of the four phases. It does not truly specify how a leaf should be selected, when a node should be expanded, howsimulations should be conducted or how their values should be propagated upwards. In practice, however, game-playingprograms tend to use variations of the same algorithms for several of the above steps.Selection as a task is similar in spirit to the n-bandit problem since the program needs to strike a balance betweenexploration (devoting some time to new nodes) and exploitation (directing the simulations towards nodes that have shownpromise so far). For example, programs can make use of the UCT algorithm (Upper Confidence bound applied to Trees) firstgiven in [6]. This algorithm chooses at each step the child node maximizing the quantity(cid:2)U i = v i + cln Nni,where v i is the value of node i, N is the number of times the parent node was visited, ni is the number of times node iwas visited, and c is a constant that favors exploitation if low, and exploration if high.Expansion varies dramatically depending on the game being considered, its state space and branching factor. In gen-eral, most programs will expand a node after it has been visited a sufficient number of times. Simulation also dependswildly on the type of game. There is a large literature dealing with MCTS simulation strategies for the game of Go alone.Backpropagation offers the problem of which backup operator to use when calculating the value of a node.2.1. MCTS and partial information in Phantom GoMonte Carlo tree search has been used successfully in large, complex partial information games, most notably PhantomGo. This game is the partial information version of the classic game of Go: the player has no direct knowledge of hisopponent’s stones, but can infer their existence if he tries to put his own stone on an intersection and discovers he isunable to. In that case, he can try another move instead. [1] describes an MCTS algorithm for playing the game, obtaininga good playing strength on a 9 × 9 board. A thorough comparison of several Monte Carlo approaches to Phantom Go, withor without tree search, has recently been given in [9]. We are especially interested in Phantom Go because its state spaceand branching factor are much larger than most other (already complex) partial information games such as poker, for whichgood Monte Carlo strategies exist; see, for example, [10].MCTS algorithms for Phantom Go are relatively straightforward in that they mostly reuse knowledge and methods fromtheir Go counterparts: in fact, they mostly differ from Go programs because in the simulation phase the st",
            {
                "entities": [
                    [
                        3800,
                        3828,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 570–590www.elsevier.com/locate/artintOn the notion of concept IMichael FreundLaLICC, University of Paris Sorbonne, 28 rue Serpente, 75006 Paris, FranceReceived 25 September 2006; received in revised form 11 September 2007; accepted 15 September 2007Available online 20 September 2007AbstractIt is well known that classical set theory is not expressive enough to adequately model categorization and prototype theory. Re-cent work on compositionality and concept determination showed that the quantitative solution initially offered by classical fuzzylogic also led to important drawbacks. Several qualitative approaches were thereafter tempted, that aimed at modeling member-ship through ordinal scales or lattice fuzzy sets. Most of the solutions obtained by these theoretical constructions however are ofdifficult use in categorization theory. We propose a simple qualitative model in which membership relative to a given concept fis represented by a function that takes its value in a finite abstract set Af equipped with a total order. This function is recursivelybuilt through a stratification of the set of concepts at hand based on a notion of complexity. Similarly, the typicality associated witha concept f will be described using an ordering that takes into account the characteristic features of f . Once the basic notions ofmembership and typicality are set, the study of compound concepts is possible and leads to interesting results. In particular, weinvestigate the internal structure of concepts, and obtain the characterization of all smooth subconcepts of a given concept.© 2007 Elsevier B.V. All rights reserved.Keywords: Categorization; Concept; Extension; Intension; Typicality; Membership; Modular orders; Fuzzy sets; Formal concepts analysis1. IntroductionIn this paper we propose a new framework for the study of some basic notions classically used in categorizationtheory. In particular, we shall be concerned with the problem of finding a suitable theoretical apparatus to model thenotions of membership and typicality that underlie prototype theory. It is well recognized since the work of EleanorRosch [18] that membership, for instance, is not an all-or-not matter: the classical set-theoretical or the two-valuelogic model are of therefore of little use to render count of most of the cognition process. This drove Zadeh and hisfollowers [24] and [25] to propose a representation of concepts by fuzzy sets, membership being modeled through areal function with values in the unit interval. Such a representation nevertheless lead to counterintuitive results: see forinstance the seminal papers of Kamp and Partee and of Osherson and Smith [12,16,17]. At a quite elementary level,for instance, it was observed that the membership degree relative to a compound concept could never be greater thanthe degree induced by any of its components, a result that cannot be accepted for both theoretical and experimentalreasons. Even for elementary concepts, the representation of concepts as quantitative fuzzy sets poses problems:vague concepts like to-be-an-adult or to-lie are given continuous values in the unit interval, but what does it meanE-mail address: Michael.Freund@paris4.sorbonne.fr.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.003\fM. Freund / Artificial Intelligence 172 (2008) 570–590571to qualify somebody as adult ‘with degree .4837’? In particular, as observed by several authors (for instance [14])there is no reason why the same set–the unit interval—should serve as a uniform criterion, being invariably referredto as a measure of membership whatever the concept at hand. True, in practice membership is often evaluated throughstatistical data, and the membership degree identified with a simple frequency. But the fact that, say, 87 individualsout of 100 consider a car seat as a piece of furniture by no means involves that, in an agent mind, the membershipdegree of a car-seat relative to the concept to-be-a-piece-of-furniture is equal .87.These drawbacks led to various solutions which all aimed at replacing the primitive quantitative model by a qual-itative one: thus, attention focused on ordinal scales and on lattice fuzzy sets—see for instance [11] or [25]. For abrief analysis of the most recent work on this area, the reader may refer to [14] or [3]. However, we consider that thesolutions that were proposed are not fully adapted to model prototype theory, and that they cannot be easily exploitedto address the classical questions raised by categorization theory.In a different area, Peter Gärdenfors [9] or [8] proposed a geometrical model as a framework for concept theory:a concept is defined as a convex region of a multidimensional space, each dimension corresponding to a basic quality.Convexity is related with a notion of betweenness that is supposed to be meaningful for the relevant quality dimen-sions: if two objects are exemplars of a concept, such will be the case for any object that lies ‘between’ them. Thetypical instances of a concept are those which are located ‘near the center’ of the considered region. This Geometryof Thought, as the author calls it, provides interesting tracks in the analysis of concepts. However, it is mostly basedon quantitative notions, which we find not best appropriate to model the cognition process. Furthermore, it does notseem that the distinction between vague and sharp concepts is fully taken into account.For these reasons, we propose to revisit the basic notions linked with categorization theory and treat them froma qualitative point of view. Concerning membership, for instance, and rather than dealing with uniform gradationfunctions that take their values in the unit interval, we represent membership relative to a concept by a function whoseset of values depends on the chosen concept. This set is endowed with a total order that can be used to evaluate towhich degree a object falls under this concept. We think indeed that such a representation is the most adequate tomodel notions like: object x plainly falls under the concept f , object x falls definitely not under the concept f orobject x falls more than object y under the concept f . These notions, which are the basis of categorization theory, arealso the firsts one should deal with in order to understand the problems that arise with vague concepts: for instance,an agent may consider that an elevator is definitely less a vehicle than a chairlift, while being unable at the same timeto attribute a precise numerical membership degree to any of these items. We propose in this paper an example ofconstruction such an order, by making use of the set of defining features attached to the concepts at hand. Postulatingthe existence of such a set is part of most of the theories on categorization: see for instance [1,4,21,22] or morerecently [2], where a concept is assimilated with a set of properties which things that fall under the concept typicallyhave or are believed to have. These defining features, from the point of view of the agent, help understanding thechosen concept; they are individually necessary and collectively sufficient to decide whether or not an item is anexemplar of this concept. Given a vague concept f , we shall use this associated defining feature set to compare thef -membership of two items in the following way: an object x will be considered as falling less under f than an objecty if it falls less than y under the f -defining features. The circularity of this definition will be avoided by attributingto each concept a complexity level: the sharp concepts, those for which membership is an all-or-not matter, will begiven complexity level 0; at level 1, we shall rank all the vague concepts whose defining feature set only consistsof sharp concepts; at level 2, we will have the vague concepts whose defining feature set consists of concepts thathave complexity level equal to 0 or 1, and so on. This ranking will eventually render possible a recursive definition ofmembership, and, consequently, the construction of a membership order among the set of objects at hand.Having represented concepts by means of order-functions poses the problem of finding an adequate representationof the notion of typicality. Since the work of E. Rosch, a considerable amount of study has been carried out on thisnotion, and it is now widely accepted that, relative to a given concept, objects may be classified following their degreeof typicality. Although a precise and general definition of this typicality degree is still missing, one generally agrees onthe fact that such a degree has to faithfully reflect the number of characteristic features attached to the concept at hand,together with the relative pertinence, or the frequency, of these features [15, Chapter 2]. Nevertheless the attempts at arigorous construction are rare, and none of them seem to have gained general recognition. Besides, researchers in thisdomain restricted themselves to elementary cases, dealing with sharp concepts, for which membership is an all-or-notmatter, or with concepts with sharp features. In particular, they did not seem to be concerned with situations in whichthe typicality relative to a concept depends on the membership relative to another concept: in order to determine the\f572M. Freund / Artificial Intelligence 172 (2008) 570–590relative typicality of a hen as a bird, for instance, they would not consider that it is necessary to first evaluate itsmembership degree relative to the concept to-fly. We think on the contrary that typicality must be determined throughmembership, and that these two notions are correlatedWe therefore propose the construction of a ‘typicality order’—in fact a partial preorder—clear and easy to evaluate,that faithfully conforms with our intuition. This order is meant to reflect a particular agent’s judgment at a precisetime. It is based on the agent’s choice, for each conc",
            {
                "entities": [
                    [
                        3326,
                        3354,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 1137–1174www.elsevier.com/locate/artintControlled generation of hard and easy Bayesian networks:Impact on maximal clique size in tree clusteringOle J. Mengshoel a,∗, David C. Wilkins b, Dan Roth ca RIACS, NASA Ames Research Center, Mail Stop 269-3, Moffett Field, CA 94035, USAb Center for the Study of Language and Information, Stanford University, Stanford, CA 94305, USAc Department of Computer Science, University of Illinois, Urbana-Champaign, 201 N. Goodwin, Urbana, IL 61801, USAReceived 1 July 2005; received in revised form 20 September 2006; accepted 24 September 2006Available online 30 October 2006AbstractThis article presents and analyzes algorithms that systematically generate random Bayesian networks of varying difficulty levels,with respect to inference using tree clustering. The results are relevant to research on efficient Bayesian network inference, suchas computing a most probable explanation or belief updating, since they allow controlled experimentation to determine the impactof improvements to inference algorithms. The results are also relevant to research on machine learning of Bayesian networks,since they support controlled generation of a large number of data sets at a given difficulty level. Our generation algorithms, calledBPART and MPART, support controlled but random construction of bipartite and multipartite Bayesian networks. The Bayesiannetwork parameters that we vary are the total number of nodes, degree of connectivity, the ratio of the number of non-root nodesto the number of root nodes, regularity of the underlying graph, and characteristics of the conditional probability tables. The maindependent parameter is the size of the maximal clique as generated by tree clustering. This article presents extensive empiricalanalysis using the HUGIN tree clustering approach as well as theoretical analysis related to the random generation of Bayesiannetworks using BPART and MPART.© 2006 Elsevier B.V. All rights reserved.Keywords: Probabilistic reasoning; Bayesian networks; Tree clustering inference; Maximal clique size; C/V -ratio; Random generation;Controlled experiments1. IntroductionEssentially all inference problems studied using the Bayesian network (BN) formalism are known to be computa-tionally hard in the general case [14,60,66]. Given the central role of BNs in a wide range of automated reasoning ap-plications, for example in medical diagnosis [3,43,67], probabilistic risk analysis [9,45], language understanding [10,12], intelligent data analysis [40,54,61], error correction coding [27,28,48,49], and biological pedigree analysis [68],developing efficient algorithms for these inference problems is an important research problem. The performance ofexact Bayesian network inference algorithms—including tree clustering algorithms [2,33,38,39,46,65], conditioningalgorithms [16,17,22,32,57,58,64], and elimination algorithms [19,47,72]—depends on the treewidth or the optimal* Corresponding author.E-mail addresses: omengshoel@riacs.edu (O.J. Mengshoel), dwilkins@stanford.edu (D.C. Wilkins), danr@cs.uiuc.edu (D. Roth).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.09.003\f1138O.J. Mengshoel et al. / Artificial Intelligence 170 (2006) 1137–1174maximal clique size of a BN’s induced clique tree [5,17,20,21]. Treewidth was initially a theoretical concept relatedto graph minors [59]; it has more recently been established that the notion of treewidth plays a key role in the analysisof algorithms [8,20,44].A significant component of research on inference in BNs has to be experimental and rely on the use of BN instances.Similar experiments are needed and have indeed been performed for other problems, including the satisfiability prob-lem (SAT) [1,13,26,55,62,63]. For SAT, it has been established empirically that there is a phase transition in theprobability of satisfiability of an instance drawn from a certain distribution [55]. This phase transition phenomenonhas been found to be closely related to a parameter describing the constrainedness of instances, namely the ratio be-tween the number of variables V and the number of clauses C, denoted the C/V -ratio. Interestingly, it has been foundthat algorithmic hardness also varies with the C/V -ratio, at least for certain algorithms [55]. As the C/V -ratio is var-ied, there is a variation in problem difficulty (or hardness), as measured in mean or median inference time for certainalgorithms across a sample of problems. Maximal hardness for several algorithms occurs in the phase transition region.Experimental work in Bayesian network inference can also be performed using randomly generated instances.In this article, we investigate the following research questions: How should BNs for experimentation be randomlygenerated, such that their computational hardness can be understood, analyzed, and controlled? More specifically, isit fruitful to generalize the C/V -ratio from SAT to a BN setting? If it is, what is the relationship between the C/V -ratio and treewidth or maximal clique size? Answering these research questions is important for several reasons.Generating problem instances randomly, a common practice in the BN community [7,17,34,35,41,56,69,70], mayresult in easy inference problems that do not present a challenge to inference algorithms [4,11,25], even thoughworst case complexity results show that both exact and approximate MPE computation is NP-hard [1,66]. In thisarticle we extend previous research on randomly generating BN instances and present an experimental paradigmfor systematically generating increasingly hard random Bayesian network instances for tree clustering. We describetwo algorithms for controlled generation of BNs, the bipartite (BPART) and multipartite (MPART) constructionalgorithms, and prove several properties for the BNs that they construct. For the BPART case, this includes thedistribution over the root node out-degrees and the minimum out-degree as well as the (small) probability that anirregular BN is also regular. For MPART networks [41] we analyze the relationship to BPART BNs and in particularpresent a formula for the probability that an MPART BN is bipartite. We characterize properties of the BN generationalgorithms in order to better understand the factors that in turn contribute to the hardness of inference, so that thoroughbenchmarking and comparison of algorithms can be performed.The inference approach we focus on, tree clustering as implemented in the HUGIN algorithm, was introduced as abelief updating algorithm [46], and was later extended to encompass belief revision [18]. Thus, in the tree clusteringapproach, computing marginal distributions and most probable explanations (MPEs) are closely related. In particular,they both depend on the total clique tree size as well as the maximal clique size of a BN’s clique tree. In a BN, let V bethe number of root nodes and C the number of non-root nodes. We show that the C/V -ratio is a key parameter for BNinference hardness, as it is for SAT [11,55]. Analytically, we provide a conservative lower bound on total clique treesize and introduce a new class of BNs, only-child BNs, for which we give sufficient conditions for Hamiltonicity andlongest cycle. Formation of cycles, including Hamiltonian cycles, is important because they often need fill-in edges inorder for a triangulated graph to be constructed, and cycles thus significantly contribute to clique tree size.Even when the topology is restricted to the BPART or MPART types, we identify several input parameters thatcan be varied when randomly generating BNs. We empirically study a few of these parameters in detail and showhow changing them affects properties of the generated BNs which again can increase computational hardness for treeclustering. For both the BPART and MPART constructions, generating random networks may result in very easyinstances, but a careful selection of the parameters along the dimensions we discuss, even while keeping the size ofthe networks fixed, gradually increases the complexity of inference and results in networks that the tree clusteringalgorithm cannot handle. A main empirical result is that the C/V -ratio can be used to predict an upper bound on thetreewidth (or optimal maximal clique size) of the induced clique trees for samples of BPART and MPART BNs. Ourselection of families of hard networks extends research on generating hard instances for the satisfiability problem [4,11,25,55] as well as existing research in the BN community [34,41,70]. Increasing the C/V -ratio causes, for certainvalues for C and V , an approximately linear increase in the upper bound on treewidth or the number of nodes in thelargest clique. In other words, we obtain an easy-hard-harder pattern for tree clustering algorithms including HUGIN,which contrasts with the easy-hard-easy pattern observed for SAT formulas using the Davis–Putnam algorithm [55].Experimenters may thus use the C/V -ratio directly, instead of or as a complement to maximal clique size or treewidth.\fO.J. Mengshoel et al. / Artificial Intelligence 170 (2006) 1137–11741139In addition to the C/V -ratio, we study the regularity of a BNs underlying graph and the distributional nature ofconditional probability tables.The rest of this article is organized as follows. Section 2 introduces Bayesian network definitions and notation aswell as the MPE problem. In Section 3 we briefly describe inference and in particular tree clustering and the HUGINalgorithm as well as the concepts of maximal clique size and treewidth. Section 4 discusses the use of applicationBNs and randomly generated BNs for experimentation. In particular, Bayesian networks generated by the BPARTalgorithm as well as the MPART algorithm are presented and analyzed; there are also results on their relationship.Section 5 discusses the interaction between properties of randomly generated BNs and their hardness for tree c",
            {
                "entities": [
                    [
                        3200,
                        3228,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1360–1399www.elsevier.com/locate/artintSemiring induced valuation algebras:Exact and approximate local computation algorithmsJ. Kohlas a,1, N. Wilson b,∗,2a Department of Informatics, University of Fribourg, Switzerlandb Cork Constraint Computation Centre, Department of Computer Science, IrelandReceived 4 April 2006; received in revised form 7 March 2008; accepted 18 March 2008Available online 27 March 2008AbstractLocal computation in join trees or acyclic hypertrees has been shown to be linked to a particular algebraic structure, called val-uation algebra. There are many models of this algebraic structure ranging from probability theory to numerical analysis, relationaldatabases and various classical and non-classical logics. It turns out that many interesting models of valuation algebras may bederived from semiring valued mappings. In this paper we study how valuation algebras are induced by semirings and how thestructure of the valuation algebra is related to the algebraic structure of the semiring. In particular, c-semirings with idempotentmultiplication induce idempotent valuation algebras and therefore permit particularly efficient architectures for local computation.Also important are semirings whose multiplicative semigroup is embedded in a union of groups. They induce valuation algebraswith a partially defined division. For these valuation algebras, the well-known architectures for Bayesian networks apply. We alsoextend the general computational framework to allow derivation of bounds and approximations, for when exact computation is notfeasible.© 2008 Elsevier B.V. All rights reserved.Keywords: Semirings; Local computation; Join tree decompositions; Soft constraints; Uncertainty; Valuation networks; Valuation algebras1. IntroductionMany different formalisms from artificial intelligence, including constraint systems, probabilistic networks, sys-tems of possibility measures or belief functions, from database theory, from logic, statistics and from numericalanalysis exhibit a common structure permitting local computation, i.e. computation on acyclic hypertrees, or jointrees. This algebraic structure has first been isolated in an abstract setting and related to local computation in [59],see also [37,53]. It has been further extended and studied in detail in [34]. The algebraic structure has been called avaluation algebra in [34].* Corresponding author.E-mail addresses: juerg.kohlas@unifr.ch (J. Kohlas), n.wilson@4c.ucc.ie (N. Wilson).URL: http://diuf.unifr.ch/tcs/juerg.kohlas (J. Kohlas).1 Research supported by grant No. 2100–042927.95 of the Swiss National Foundation for Research.2 This material is based partly upon works supported by the Science Foundation Ireland under grant No. 00/PI.1/C075 and grant No. 05/IN/I886.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.003\fJ. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–13991361In a valuation algebra, each piece of information φ, called a valuation, has an associated set s of variables; φ givesinformation about variables s. For example, in a constraint satisfaction problem or relational database φ may expressa relation on s, saying which assignments of these variables are feasible. Alternatively, in a soft constraints system itmay express preferences for different assignments, or in a system for reasoning with uncertainty such as possibilitytheory or Bayesian networks, it may express degrees of uncertainty of the different assignments to variables s.It is assumed that we have a way of combining valuations, through an operation ⊗, which gives their combinedeffect; the combination operator is associative and commutative. If ψ is another valuation on variables t then thecombination φ ⊗ ψ is a valuation on variables s ∪ t, since φ and ψ together say something about variables s ∪ t.Valuation algebras also assume another operation, called projection or marginalization, which focuses informationonto a smaller set of variables. Suppose u is a subset of s. Then φ↓u represents what valuation φ tells us about u. If,for example, φ is a probability distribution or potential, then φ↓u is the marginal on u. Alternatively, if φ represents abinary constraint relating variables X1 and X2 then it tells us which assignments to {X1, X2} are possible, and φ↓{X1}tells us which assignments to X1 are possible.The inputs of many important computational reasoning problems can be expressed as a collection of valuationsφ1, . . . , φk (in an appropriate valuation algebra), where the associated sets of variables are all fairly small. The combi-nation of these gives us the combined effect of all our information. For example, in a constraint satisfaction problem,the combination represents all the solutions, and in a relational database, the combination is the join of all the relations.In a Bayesian network, the combination represents the full probability distribution over all the variables. It will veryoften be infeasible to represent this whole combination directly, since involves all the variables, for which there are anexponential number of assignments. Typically we are interested in what the information tells us about certain smallsets of variables. So, for particular sets u, we want to compute the projection of the whole combination to u. This isknown as the projection problem. Direct computation is very often not feasible. For a single set u, an approach basedon sequential variable elimination can be used to compute the associated marginal. For the computation for severalsets u, faster methods have been developed based on use of an appropriate join tree, that is, a tree whose nodes areassociated with sets of variables which satisfy the running intersection property: that if variable X is associated withtwo nodes then it is associated with every node in the path between the two nodes.Such join tree algorithms for computing several marginals have two parts: an inward phase where information ispassed iteratively from the leaves to a chosen root node; and an outward phase where information is distributed outagain, iteratively from the root to all the nodes. As discussed below (and in more detail in [34]) there are a number ofdifferent variations on this local computational architecture.It turns out that many important examples of valuation algebras can be induced by valuations taking values in asemiring. This has first been proposed in the domain of constraint systems, where classical crisp constraints are gener-alized to fuzzy constraints, weighted constraints and partially satisfied constraints [8,9]. But probability potentials asused in Bayesian networks [41] belong also to the same class of valuations, as do relational systems [4,42]. Possibilitypotentials and Spohn potentials [60] provide further examples of valuations based on semirings. Other instances andapplications of semiring-induced valuation algebras are described in [1].In the second section we introduce semirings and give several examples which are related to important valuationalgebras. A semiring consists of a set A with two operations on it, conventionally labeled + and ×, both of which weassume to be associative and commutative; it is also assumed that × distributes over +. An example is the nonnegativereal numbers under addition and multiplication. A valuation on variables s in the induced valuation algebra is a func-tion which assigns a nonnegative real number to each assignment to variables s. Combination is based on pointwisemultiplication, and marginalization involves summation over the values of variables being eliminated. This semiringinduced valuation algebra is therefore that of probability potentials, used for reasoning with Bayesian networks.Any semiring induces a valuation algebra in just the same way, as shown in Section 3, which also discusses localcomputation based on these semirings.In this paper we study valuation algebras induced by semirings in some detail. In particular, we want to knowhow the structure of a valuation algebra is conditioned by the structure of the inducing semiring. These are importantquestions for practical purposes: Valuation algebras provide the structure needed for local computation architectures.There exist particularly efficient architectures which use some form of division in the valuation algebra [29,41].It is therefore important to know, what properties of the inducing semiring guarantee the existence of a concept ofdivision in the induced valuation algebra and thus the usability of the corresponding architecture for local computa-tion [34,37]. Further, idempotent valuation algebras, so-called information algebras, have interesting properties and\f1362J. Kohlas, N. Wilson / Artificial Intelligence 172 (2008) 1360–1399allow particularly simple local computation architectures. Therefore it is important to know which semirings leadto idempotent valuation algebras. Idempotent valuation algebras and their corresponding computational structure areanalyzed in Section 4, and in Section 5 we study semirings which induce valuation algebras with division and discusstheir local computation architectures. This study helps to extend computational schemes, well known in probabilitynetworks and relational algebra, to more general structures and to develop generic architectures for local computation[47].It may well happen that, for a problem of interest, exact local computation is not feasible. For certain importantsystems of valuations, it has been demonstrated, e.g., in [24], how the local computations can be approximated usingthe ‘mini-buckets’ and ‘mini-clustering’ techniques. We show in Section 6 how this kind of technique can be appliedvery generally to valuation algebras, in particular, those induced by a semiring; we focus especially on computingupper and lower bounds. We also consider the use of constraint propagation for improving the efficiency of localcomputation.Provisional ve",
            {
                "entities": [
                    [
                        2886,
                        2914,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 105–132Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBounded treewidth as a key to tractability of knowledge representationand reasoning ✩Georg Gottlob a, Reinhard Pichler b, Fang Wei c,∗a Computing Laboratory, Oxford University, Oxford OX1 3QD, UKb Institut für Informationssysteme, Technische Universität Wien, A-1040 Vienna, Austriac Institut für Informatik, Albert-Ludwigs-Universität Freiburg, D-79110 Freiburg i. Br., Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 9 October 2008Received in revised form 6 October 2009Accepted 15 October 2009Available online 20 October 2009Keywords:Fixed-parameter tractabilityTreewidthMonadic datalogAbductionClosed world reasoningDisjunctive logic programming1. IntroductionSeveral forms of reasoning in AI – like abduction, closed world reasoning, circumscription,and disjunctive logic programming – are well known to be intractable. In fact, many ofthe relevant problems are on the second or third level of the polynomial hierarchy. Inthis paper, we show how the notion of treewidth can be fruitfully applied to this area. Inparticular, we show that all these problems become tractable (actually, even solvable inlinear time), if the treewidth of the involved formulae or programs is bounded by someconstant.Clearly, these theoretical tractability results as such do not immediately yield feasiblealgorithms. However, we have recently established a new method based on monadicdatalog which allowed us to design an efficient algorithm for a related problem in thedatabase area. In this work, we exploit the monadic datalog approach to construct newalgorithms for logic-based abduction.© 2009 Elsevier B.V. All rights reserved.In the nineteen-nineties, several forms of reasoning in AI – like abduction, closed world reasoning, circumscription, anddisjunctive logic programming – were shown to be highly intractable. In fact, many relevant problems in this area are onthe second or even third level of the polynomial hierarchy [20–22].In recent years, parameterized complexity has evolved as an interesting approach to dealing with intractability [19]. It hasturned out that many hard problems become tractable if some problem parameter is fixed or bounded by a fixed constant.If a problem enjoys this property we speak of fixed-parameter tractability (FPT, for short). In the arena of graph problems,an important parameter thus investigated is the so-called treewidth of a graph G, which is a measure of the “tree-likeness”of G. If the treewidth of the graphs under consideration is bounded by a fixed constant, then many otherwise intractableproblems become tractable, e.g., 3-colorability, Hamiltonicity, etc. More generally, treewidth can be considered for arbitraryfinite structures. Treewidth has also been applied to some areas of AI, notably to constraint satisfaction [2].A deep result and mathematical tool for deriving new FPT-results is Courcelle’s Theorem [14], which states that if someproperty of finite structures is expressible by a Monadic Second Order (MSO, for short) sentence then this property isdecidable in linear time for structures whose treewidth is bounded by a fixed constant. Courcelle’s Theorem has been further✩This is an extended and enhanced version of results published in Gottlob, Pichler and Wei (2006, 2008) [29,31]. The work was supported by the AustrianScience Fund (FWF), project P20704-N18.* Corresponding author.E-mail addresses: georg.gottlob@comlab.ox.ac.uk (G. Gottlob), pichler@dbai.tuwien.ac.at (R. Pichler), fwei@informatik.uni-freiburg.de (F. Wei).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.10.003\f106G. Gottlob et al. / Artificial Intelligence 174 (2010) 105–132developed in several works, e.g., in the recent paper [24], where also an efficient algorithm for counting the solutions of aSAT or Generalized SAT problem is presented.In this paper, we revisit several intractable problems in AI. Our goal is to harness the powerful machinery of Courcelle’sTheorem in the area of knowledge representation and reasoning. We show that virtually all decision problems arising in thecontext of abduction, closed world reasoning, circumscription, and disjunctive logic programming become tractable if thetreewidth of the involved formulae or programs is bounded by some constant. The central idea for deriving these FPT-resultsis to encode the decision problems in terms of MSO sentences.Clearly, an MSO description as such is not an algorithm and it is a highly non-trivial task to turn a theoretical tractabilityresult based on Courcelle’s Theorem into a feasible computation. Actually, recipes to devise concrete algorithms based onCourcelle’s Theorem can be found in the literature, see e.g. [3,12,11,25]. The basic idea of these algorithms is to transformthe MSO evaluation problem into an equivalent tree language recognition problem and to solve the latter via an appropri-ate finite tree automaton (FTA) [17,46,47]. In theory, this generic method of turning an MSO description into a concretealgorithm looks very appealing. However, in practice, it has turned out that even relatively simple MSO-formulae may leadto a “state explosion” of the FTA [26,41]. Hence, it was already stated in [32] that the algorithms derived via Courcelle’sTheorem are “useless for practical applications”. The main benefit of Courcelle’s Theorem is that it provides “a simple wayto recognize a property as being linear time computable”. In other words, proving the FPT of some problem by showingthat it is MSO expressible is the starting point (rather than the end point) of the search for an efficient algorithm.In [30], we proposed monadic datalog (i.e., datalog where all intensional predicate symbols are unary) as a practical toolfor devising efficient algorithms in situations where the FPT has been established via Courcelle’s Theorem. Above all, weproved that if some property of finite structures is expressible in MSO then this property can also be expressed by meansof a monadic datalog program over the decomposed structure: we mean by this that the original structure is augmented withnew elements and new relations that encode one of its tree decompositions. Moreover, this approach was put to work bydesigning an efficient algorithm for the PRIMALITY problem (i.e., the problem of deciding if some attribute is part of a keyin a given relational schema). In this paper, we show that this monadic datalog approach can also be applied to difficultknowledge representation and reasoning tasks. We thus present new algorithms for logic-based abduction and we report onexperimental results with an implementation of these algorithms.1.1. Summary of resultsThe main contribution of our paper is twofold: First, we prove the fixed-parameter tractability of many relevant decisionproblems arising in abduction, closed world reasoning, circumscription, and disjunctive logic programming. Second, we showhow such theoretical tractability results can be actually turned into feasible computations. We only present new algorithmsfor logic-based abduction. However, the ideas underlying the construction of these algorithms are, of course, also applicableto the hard problems in the other areas mentioned above. Hence, the FPT-results shown here indeed open the grounds forthe development of new parameterized algorithms for these problems.1.2. Structure of the paperThe rest of the paper is organized as follows. After recalling some basic definitions and results in Section 2, we proveseveral new fixed-parameter tractability results via Courcelle’s Theorem in Section 3. In Section 4, we present our newalgorithms for logic-based abduction. Experimental results are discussed in Section 5. A conclusion is given in Section 6.Appendices A and B are provided in order to encapsulate some lengthy, technical details which are not required for theunderstanding of the main body of the text.2. Preliminaries2.1. Finite structures and treewidthAiLet τ = {R1, . . . , R K } be a set of predicate symbols. A finite structure A over τ (a τ -structure, for short) is given by a⊆ Aαi , where αi denotes the arity of R i ∈ τ . All structures and trees consideredfinite domain A = dom(A) and relations Rin this work are assumed to be finite. Hence, in the sequel, the finiteness will usually not be explicitly mentioned.A tree decomposition T of a τ -structure A is defined as a pair (cid:5)T , ( At )t∈T (cid:6) where T is a rooted tree and each At is asubset of A with the following properties: (1) Every a ∈ A is contained in some At . (2) For every R i ∈ τ and every tuple} ⊆ At . (3) For every a ∈ A, the set {t | a ∈ At} induces a(a1, . . . , aαi ) ∈ Rsubtree of T ., there exists some node t ∈ T with {a1, . . . , aαiCondition (3) above is usually referred to as the connectedness condition. The sets At are called the bags (or blocks) of T .The width of a tree decomposition (cid:5)T , ( At)t∈T (cid:6) is defined as max{| At| | t ∈ T } − 1. The treewidth of A is the minimal widthof all tree decompositions of A. It is denoted as tw(A). Note that forests are the simple loop-free graphs of treewidth atmost 1.AiFor given w (cid:2) 1, it can be decided in linear time if some structure has treewidth at most w. Moreover, in case of apositive answer, a tree decomposition of width w can be computed in linear time [8]. Strictly speaking, the result in [8]\fG. Gottlob et al. / Artificial Intelligence 174 (2010) 105–132107Fig. 1. Tree decomposition T of formula F .refers to tree decompositions of graphs rather than arbitrary structures. However, we can associate a graph G (the so-calledprimal or Gaifman graph) with every structure A by taking the domain elements as the vertices of the graph. Moreover,two vertices are adjacent in G if and only if the corresponding domain elements jointly occur in some tuple in A. It can beeasily shown that G has precisely the same ",
            {
                "entities": [
                    [
                        3719,
                        3747,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 167 (2005) 13–30www.elsevier.com/locate/artintWord sense disambiguation with picturesKobus Barnard a,∗, Matthew Johnson ba Computer Science Department, University of Arizona, USAb Department of Engineering, University of Cambridge, USAReceived 25 July 2004; received in revised form 21 February 2005; accepted 14 April 2005Available online 11 August 2005AbstractWe introduce using images for word sense disambiguation, either alone, or in conjunction withtraditional text based methods. The approach is based on a recently developed method for automat-ically annotating images by using a statistical model for the joint probability for image regions andwords. The model itself is learned from a data base of images with associated text. To use the modelfor word sense disambiguation, we constrain the predicted words to be possible senses for the wordunder consideration. When word prediction is constrained to a narrow set of choices (such as possiblesenses), it can be quite reliable. We report on experiments using the resulting sense probabilities asis, as well as augmenting a state of the art text based word sense disambiguation algorithm. In orderto evaluate our approach, we developed a new corpus, ImCor, which consists of a substantive portionof the Corel image data set associated with disambiguated text drawn from the SemCor corpus. Ourexperiments using this corpus suggest that visual information can be very useful in disambiguatingword senses. It also illustrates that associated non-textual information such as image data can helpground language meaning. 2005 Elsevier B.V. All rights reserved.Keywords: Word sense disambiguation; Image auto-annotation; Region labeling; Statistical models* Corresponding author.E-mail address: kobus@cs.arizona.edu (K. Barnard).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.04.009\f14K. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–30Fig. 1. Five senses of bank, illustrated using images from the Corel dataset.1. IntroductionA significant portion of words in natural language have a number of possible meanings(senses), depending on context. This is illustrated in Fig. 1 with the arguably overused“bank” example. A priori, the word “bank” has a number of meanings including financialinstitution and a step or edge as in “snow bank” or “river bank”. Words which are spelledthe same but have different meanings (polysemes) confuse attempts to automatically attachmeaning to language. As there are many such ambiguous words in natural language texts,word sense disambiguation—determining the exact sense of words—has been identifiedas an important component of natural language processing, and has been studied by manyresearchers leading to a large body of literature [2–4,27,32,40,41,47,49,50].Since the words are spelled the same, resolving what they mean requires a considerationof context. A purely natural language based approach considers words near the one inquestion. Thus in the bank example, words like “financial” or “money” are strong hints thatthe financial institution sense is meant. Interestingly, despite much work, and a number ofinnovative ideas, doing significantly better than choosing the most common sense remainsdifficult [47].In this paper we develop a method for using image information to disambiguate thesenses of words. We posit that image information can be an orthogonal source of infor-\fK. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–3015mation for distinguishing senses. In the extreme case, disambiguation using nearby textalone is impossible as in the sentence: “He ate his lunch down by the bank”. In suchcases, alternative sources of information offer attractive possibilities for grounding theword meanings. Even when not essential, non-textual information has the capacity to behelpful. Our method for using associated visual information can be used alone, or in con-junction with text based methods. Naturally, when no images are available, the system mustfall back on non-image methods. Incorporation of computer vision into the word sensedisambiguation process is a novel approach. As far as we know, all other word sense disam-biguation methods use document text and/or additional text carrying domain or documentcontext semantic information. However, we acknowledge related work using WordNet [42]to propagate sense (and thus semantic) information between feature based classes in thecontext of multimedia information systems [12,13].To use image information we exploit a recently developed method for predicting likelywords for images [5,9,22]. The method is based on a statistical model for the joint proba-bility distribution of words and image region features. The model is learned from a trainingset of images with associated text. Additional details are provided below (Section 3).To use the model for word sense disambiguation, we constrain the predicted words to befrom the set of senses for the word under consideration. In general, when word prediction isconstrained to a narrow set of choices (such as possible senses), it can be quite reliable. Wereport on experiments using the resulting sense probabilities as is, as well as augmentingtwo state of the art text based word sense disambiguation algorithms.In order to evaluate our approach, it was necessary to develop a new corpus, ImCor,which consists of a substantive portion of the Corel image data base associated with disam-biguated text drawn from the SemCor corpus. (We have made ImCor available for researchpurposes [31].) Our experiments using this corpus suggest that visual information can bevery useful for disambiguating word senses.This work suggests approaches to exploiting multiple data modes to increase our abilityto automatically search and browse multi-media information. For example, text data on theweb is often augmented with image data. Searches based on text currently do not make useof that information, even though in many cases it would be helpful. While computationalmethods for effectively understanding arbitrary visual data are still a long way off, usingvisual features to improve the rankings of query results may not require such a full under-standing. For example, if text data can be better sense disambiguated by using image data,then an unambiguous query can be better executed against this data.2. Disambiguating words using textual contentResearch into automatic methods for disambiguating word senses has resulted in a va-riety of ways of using the surrounding text, or the “textual context”, to infer word sense.Disambiguating sense is a semantic problem, and the underlying assumption is that theword to be disambiguated is semantically linked to the nearby words, as text tends to besemantically coherent. Co-occurrence statistics will reflect semantic linking, and thus re-searchers have developed methods based on statistical models for senses [16]. A largenumber of other methods attempt to quantify this linking using known word semantics. For\f16K. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–30example, word classes, as defined by a Thesaurus, can be integrated into a combined weightof indicators in the textual context [48]. Going further, most word sense disambiguation al-gorithms use a semantic network such as WordNet [42]. WordNet is a machine-readabledictionary covering a large proportion of the English language (152,059 words) organizedinto 115,424 sets of synonyms (synsets). It provides relationships between the sets, themost commonly used one being the hypernym (“is a”) relationship. The graph created byhypernym relationships forms a tree in which every node is a hypernym of its children. Thepath connecting two words can be used to define semantic distances, which has been usedin word sense disambiguation algorithms [2,20,35,41].Usage statistics are also helpful for word sense disambiguation. In WordNet, the “sensenumber” roughly corresponds to decreasing common usage frequency (the first WordNetsense is that which it considers to be most commonly used). Going further, researchers haveexploited the SemCor sense-attributed corpus [28,41,43,46]. SemCor, short for the Word-Net Semantic Concordance [26], consists of 25% of the Brown corpus [25] files whichhave been fully tagged with part-of-speech and is sense disambiguated.A number of word sense disambiguation methods have been compared at the threeSenseval conferences [1,23,33]. Based on the results from the second Senseval we choseto implement an algorithm based on iterative word sense disambiguation, SMUaw [41].We were also intrigued by the fact that choosing the most common sense according toWordNet evaluates higher than many of the algorithms currently in use [47]. Thus we alsoimplemented an algorithm which provides a usage distribution over the senses to provideadditional evaluation of our algorithm [36].There has been some work done incorporating multiple alternative knowledge sources tohelp disambiguate words in context. In [19], “world knowledge” derived from alternativesynset contexts obtained through WordNet was used to supplement a learning algorithmand showed marked improvement over the unaided version. Another interesting exampleis found in [44], where, for every word being disambiguated, a feature set is formed basedon multiple sources, including the part of speech of neighboring words, morphologicalform, the unordered set of neighboring words, local collocations and verb-object syntacticrelation. During training, disambiguated sentences were mined for features, so that duringtesting, a feature set obtained for a word can be compared against many training sets. Theproposal is that the similarity so found is directly proportional to the probability that thesense of the word in a training set is the correct sense for the test word. While this systemrelied on the surrounding text to obtain the feature set during testing, training data couldhave po",
            {
                "entities": [
                    [
                        1881,
                        1909,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 449–478Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSoft arc consistency revisitedM.C. Cooper a, S. de Givry b, M. Sanchez b, T. Schiex b,∗a IRIT, University of Toulouse III, 31062 Toulouse, Franceb UBIA, UR-875, INRA, F-31320 Castanet Tolosan, Francec Center for Machine Perception, Czech Technical University, 12135 Praha 2, Czech Republica r t i c l ei n f oa b s t r a c t, M. Zytnicki b, T. Werner cArticle history:Received 31 January 2009Received in revised form 25 January 2010Accepted 28 January 2010Available online 2 February 2010Keywords:Valued constraint satisfaction problemWeighted constraint satisfaction problemSoft constraintsConstraint optimizationLocal consistencySoft arc consistencyGraphical modelSubmodularitylocal cost functions defined over discrete variables.The Valued Constraint Satisfaction Problem (VCSP) is a generic optimization problemIt hasdefined by a network ofapplications in Artificial Intelligence, Operations Research, Bioinformatics and has beenused to tackle optimization problems in other graphical models (including discrete MarkovRandom Fields and Bayesian Networks). The incremental lower bounds produced by localconsistency filtering are used for pruning inside Branch and Bound search.In this paper, we extend the notion of arc consistency by allowing fractional weights and byallowing several arc consistency operations to be applied simultaneously. Over the rationalsand allowing simultaneous operations, we show that an optimal arc consistency closure cantheoretically be determined in polynomial time by reduction to linear programming. Thisdefines Optimal Soft Arc Consistency (OSAC).To reach a more practical algorithm, we show that the existence of a sequence of arcconsistency operations which increases the lower bound can be detected by establishingarc consistency in a classical Constraint Satisfaction Problem (CSP) derived from the originalcost function network. This leads to a new soft arc consistency method, called, Virtual ArcConsistency which produces improved lower bounds compared with previous techniquesand which can solve submodular cost functions.These algorithms have been implemented and evaluated on a variety of problems, includingtwo difficult frequency assignment problems which are solved to optimality for the firsttime. Our implementation is available in the open source toulbar2 platform.© 2010 Elsevier B.V. All rights reserved.1. IntroductionGraphical model processing is a central problem in AI. The optimization of the combined cost of local cost functions,central in the valued CSP framework [52], captures problems such as weighted Max-SAT, Weighted CSP or Maximum Prob-ability Explanation in probabilistic networks. It also has applications in areas such as resource allocation [9], combinatorialauctions, optimal planning, and bioinformatics [50]. Valued constraints can be used to code both classical crisp constraintsand cost functions.Since valued constraint satisfaction is NP-hard, heuristics are required to speed up brute-force exhaustive search. Byshifting weights between cost functions, soft arc consistency allows us to transform a problem in an equivalent problem.This problem reformulation can provide strong, incrementally maintainable lower bounds which are crucial for Branch andBound search [44].* Corresponding author.E-mail addresses: cooper@irit.fr (M.C. Cooper), simon.degivry@toulouse.inra.fr (S. de Givry), marti.sanchez@toulouse.inra.fr (M. Sanchez),thomas.schiex@toulouse.inra.fr (T. Schiex), matthias.zytnicki@toulouse.inra.fr (M. Zytnicki), werner@cmp.felk.cvut.cz (T. Werner).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.001\f450M.C. Cooper et al. / Artificial Intelligence 174 (2010) 449–478Similarly to classical arc consistency in CSPs (constraint satisfaction problems), previously-defined soft arc consistencyproperties are enforced by the chaotic application of local soft arc consistency operations shifting integer costs between differentscopes, until a fixpoint is reached [19,3]. Unlike the arc consistency closure in CSPs, this fixpoint is often not unique andmay lead to different lower bounds. In this paper, we instead consider local consistencies enforced by carefully plannedsequences of soft arc consistency operations which necessarily increase the lower bound. Since costs may need to be dividedinto several parts in order to be shifted in several directions, the resulting transformed problem may contain fractionalcosts. By allowing the introduction of rational multiples of costs, we both avoid the intractability of finding an optimal softarc consistency closure involving only integer costs [19] and produce a strictly stronger notion of soft arc consistency.The two new techniques presented in this paper aim at finding a reformulation of the original problem P with an op-timized constant cost term c∅. This constant cost provides an explicit lower bound provided that all costs are non-negative.Optimal soft arc consistency (OSAC) identifies a sequence of soft arc consistency operations (shifting of costs between costfunctions, of which at most one has arity greater than 1) which yields an optimal reformulation. Intermediate reformula-tions may contain negative costs provided all costs in the final version are non-negative. Such operations can be found inpolynomial time by solving a linear program [54]. We considerably extend this result by showing that a polynomial-timealgorithm exists even in the presence of crisp constraints coded by infinite costs and an upper bound coded by using anaddition-with-ceiling aggregation operator.Alternatively, we show that when a problem is not Virtual Arc Consistent (VAC), it is possible to find a sequence of softarc consistency operations which improve the lower bound and are such that all intermediate problems have non-negativecosts. Our iterative VAC algorithm is based on applying arc consistency in a classical CSP which has a solution if and onlyif P has a solution of cost c∅. We show that OSAC is strictly stronger than VAC. However, finding a lower bound using ourVAC algorithm is much faster than establishing OSAC, and hence has potentially many more practical applications.The idea of using classical local consistency to build lower bounds in Max-CSP or Max-SAT is not new. On Max-CSPproblems, [48] used independent arc inconsistent subproblems to build a lower bound. For Max-SAT, [45] used minimal UnitPropagation inconsistent subproblems to build a lower bound. These approaches do not use problem transformations butrely on the fact that the inconsistent subproblems identified are independent and costs can simply be summed. They lack theincrementality of soft consistency operations. In Max-SAT again, [31] used Unit Propagation inconsistency to build sequencesof integer problem transformations but possibly strictly above the arc level, generating higher-arity weighted clauses (costfunctions). OSAC and VAC remain at the arc level by allowing rational costs. It should be pointed out that our VAC algorithmis similar to the “Augmenting DAG” algorithm independently proposed by [39] for preprocessing 2-dimensional grammars,recently reviewed in [56]. Our approach is more general, in that we can treat cost functions of arbitrary arity, infinite costsand a finite upper bound.Note that the special case of real-valued binary VCSPs over Boolean domains has been extensively studied under thename of quadratic pseudo-Boolean function optimization [7]. In the case of Boolean domains, it is well known that findingan equivalent quadratic posiform representation (i.e. an equivalent binary VCSP) with an optimal value of c∅ can be formu-lated as a linear programming problem [30] and can even be solved by finding a maximum flow in an appropriately definednetwork [7]. It is also worth noting that in this special case of Boolean binary VCSPs, determining whether there exists azero-cost solution is an instance of 2SAT and hence can be completely solved in polynomial time.The two new notions presented in this paper (optimal soft arc consistency and virtual arc consistency) can be applied tooptimization problems over finite domains of arbitrary size, involving local cost functions of arbitrary arity. Crisp constraintscan be coded by infinite costs and an upper bound can be coded by using an addition-with-ceiling aggregation operator. Weshow that the resulting arc consistency properties have attractive theoretical properties, being capable of solving differentpolynomial classes of weighted CSP without detecting them a priori. We also show their strengths and limitations on variousrandom and real problem instances. Some of the problems considered are solved for the first time to optimality using theselocal consistencies.We begin in Section 2 with the definition of a valued constraint satisfaction problem. Section 3 introduces the notion ofan equivalence-preserving transformation and gives the three basic equivalence-preserving transformations that are requiredto establish all forms of soft arc consistency considered in this paper. In Section 4 we review previously defined notions ofsoft arc consistency. These definitions are necessary to define the soft arc consistency EDAC [43], with which we compareboth theoretically and experimentally the new notions of soft arc consistency defined in this paper. Section 5 defines OSAC(Optimal Soft Arc Consistency) and Section 6 reports the results of experimental trials which demonstrate the potentialutility of OSAC during preprocessing. The rest of the paper is devoted to Virtual Arc Consistency (VAC) which providesa practical alternative to OSAC which can be applied during search. Section 7 introduces VAC and shows formally theconnection between this definition and the existence of a sequence of soft arc consistency operations which increase thelower bound. Section 8 introd",
            {
                "entities": [
                    [
                        3754,
                        3782,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 247 (2017) 151–169Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRepresentations for robot knowledge in the KnowRobframeworkMoritz Tenorth∗, Michael BeetzInstitute for Artificial Intelligence, Universität Bremen, Am Fallturm 1, 28359 Bremen, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 20 May 2015Accepted 28 May 2015Available online 3 June 2015Keywords:Knowledge representationAutonomous robotsKnowledge-enabled roboticsIn order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in AI research, and propose to re-consider a KR system as a semantically annotated view on information and algorithms that are often already available as part of the robot’s control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot’s hardware as well as inference procedures that operate on this common representation. The KnowRobsystem has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot’s performance.© 2015 Published by Elsevier B.V.1. IntroductionAs robotic agents, such as robot factory workers, co-workers, and home assistant robots, scale towards more and more complex tasks in open environments, they will require more flexibility in plan execution. Plans that explicitly spell out every detail of a task only perform well as long as the execution context remains static, but are difficult to adapt in an open, dynamic world. A promising approach for increasing flexibility is to postpone decisions from programming time to execution time by only including the essential aspects of the task in the plan. Humans successfully use this technique when explaining tasks to other humans in terms of vague instructions such as “set the table” or “pour water into the glass”. Similarly, instruction sheets that are commonly used in factories and chemical laboratories only briefly summarize the main actions, leaving less important aspects open. The parts that are not spelled out are usually those that can be adapted to the situation at hand. While such information gaps can increase overall flexibility, they need to be filled appropriately before the plan can be executed. To this end, a robot needs to supply the “delta” between the information in the (abstract, symbolic and often vague) instructions and the (specific, explicit, and often real-valued) parameters needed by its action components. * Corresponding author.E-mail addresses: tenorth@cs.uni-bremen.de (M. Tenorth), beetz@cs.uni-bremen.de (M. Beetz).http://dx.doi.org/10.1016/j.artint.2015.05.0100004-3702/© 2015 Published by Elsevier B.V.\f152M. Tenorth, M. Beetz / Artificial Intelligence 247 (2017) 151–169Fig. 1. Left: Example situation in a classical ‘blocks world’ environment. Using logical inference on the scene representation, the system can determine whether all preconditions are fulfilled for moving block A to position A. Right: Visualization of a scene model from the KnowRob robot knowledge base. While the situation is much more complex, efficient algorithms exist for computing e.g. stability or reachability.(cid:3)This means that it has to interpret the instructions given the current execution context and its background knowledge, and come up with suitable values that can be understood by its motion generation and control components.This robotics use case requires capabilities of a knowledge representation and reasoning (KR&R) system that differ from what is commonly investigated in AI research. Let us consider the example in the left part of Fig. 1 that shows a typical scene in the blocks world that is still a common scenario in KR research. Researchers in knowledge representation model the scenario as a dynamical system in a knowledge base and approach control, prediction, and analysis tasks by inferring their solutions purely based on this model. The knowledge bases are based on logical [36], STRIPS- or PDDL-based [27,14], probabilistic [18], or other representations. For example, in the logical approach, researchers try to axiomatize the system dynamics, in particular the conditions under which actions can be successfully performed, and the causal laws that relate actions to their effects, such that the solutions of control, prediction, and analysis tasks become the logical consequences of the respective axiomatization.While these approaches are very elegant as they approach a variety of control problems in a uniform framework, they also typically yield a number of implementation and applicability issues. Since the tasks are solved by inference and search, the computational costs are often high and not predictable. When the physics of the domain become more complicated, the number of axioms grows very fast as we have seen in the axiomatizations of the famous egg-cracking problem [28]. Many approaches thus abstract away from geometric and physical properties that, however, are crucial for robots as they often determine the outcome and feasibility of an action. For the employed coarse-grained discretizations, it is often difficult to find the appropriate level of abstraction for continuous quantities which are pervasive in robotics applications. Once ab-stracted, information cannot be accessed on a finer level of detail. Examples of inferences that depend upon such continuous quantities are the reachability of objects and the stability of object placements [7].The right part of Fig. 1 visualizes how the scene of the block-stacking task may more realistically look like for the robot. It can easily be seen that it is significantly more complex than the blocks world model, making the application of many AI reasoning methods difficult. However, all of this information is already present in the robot’s internal data structures: the robot’s pose and movements, recognized objects, environment structures, etc. And for many inference tasks, such as the visibility of objects or the reachability of locations, there are efficient and well-understood algorithms in robotics that operate on these data structures. Reachability can be computed by inverse kinematics calculations [38]. Visibility can be computed by rendering the scene from a given viewpoint [29]. These algorithms do not require abstraction into a symbolic knowledge base, and by operating on the original data, can often compute much more detailed results than logical inference.In this paper, we argue that instead of abstracting the data into a purely symbolic knowledge base, robots shall rather keep the original, high-resolution, continuous data and only compute a “symbolic view” on it as needed. This on-demand abstraction can always provide the appropriate level of detail: Robotics algorithms can operate on the original data, logi-cal inferences can be computed on a more abstract symbolic level. Queries can combine inferences made at all levels of abstraction.This is the approach taken by the KnowRob knowledge processing system that we present in this article. It consists of a (rather shallow) symbolic knowledge base that provides semantic representations of the robot’s data structures that primar-ily serves as integration layer for various inference algorithms. The representation can be shallow compared to expressive AI reasoning methods since few inferences are done at this level. For example, it does not have to model the appearance of objects if the visibility reasoning algorithm can read it from a linked 3D model. And it does not have to model physical laws if an algorithm for computing object stability can read its physical properties from a CAD model and parameterize a simulator with them. The role of a KR system therefore shifts from a world model that has to be consistent and complete towards a semantic integration layer. The correctness of inferences is then determined by the correctness of the algorithms \fM. Tenorth, M. Beetz / Artificial Intelligence 247 (2017) 151–169153rather than a complete and correct axiomatization that would anyway be difficult to guarantee if information is read from noisy sensors.The remainder of this paper is organized as follows. We start with an overview of lessons learned while investigat-ing knowledge-enabled robot control and explain how the findings have been implemented in the KnowRob system. The following section explains the representations of objects, their parts, properties, and locations in the environment as well as the robot’s self-model. It is followed by the representations of events and actions at the instance and class level and methods for projecting the effects of actions on objects. We evaluate our approach by the knowledge content, scalability, example queries showing inferences it enables, examples of robot experiments and its adoption by the open-source research community. The paper finishes with a comparison with related approaches and our conclusions.While parts of the KnowRob system have been described in several earlier (conference) papers, this article tries to set th",
            {
                "entities": [
                    [
                        3551,
                        3579,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 232 (2016) 76–113Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCharacteristic function games with restricted agent interactions: Core-stability and coalition structuresGeorgios Chalkiadakis a, Gianluigi Greco b,∗a Technical University of Crete, Chania, Greeceb Department of Mathematics and Computer Science, University of Calabria, Italyc Athens University of Economics and Business, Athens, Greece, Evangelos Markakis ca r t i c l e i n f oa b s t r a c tArticle history:Received 15 January 2014Received in revised form 14 December 2015Accepted 17 December 2015Available online 23 December 2015Keywords:Coalitional gamesSolution conceptsComputational complexityTreewidthMarginal contribution networksIn many real-world settings, the structure of the environment constrains the formation of coalitions among agents. These settings can be represented by characteristic function games, also known as coalitional games, equipped with interaction graphs. An interaction graph determines the set of all feasible coalitions, in that a coalition C can form only if the subgraph induced over the nodes/agents in C is connected. Our work analyzes stability issues arising in such environments, by focusing on the core as a solution concept, and by considering the coalition structure viewpoint, that is, without assuming that the grand-coalition necessarily forms.The complexity of the coalition structure core is studied over a variety of interaction graph structures of interest, including complete graphs, lines, cycles, trees, and nearly-acyclic graphs (formally, having bounded treewidth). The related stability concepts of the least core and the cost of stability are also studied. Results are derived for the setting of compactcoalitional games, i.e., for games that are implicitly described via a compact encoding, and where simple calculations on this encoding are to be performed in order to compute the payoff associated with any coalition. Moreover, specific results are provided for compact games defined via marginal contribution networks, an expressive encoding mechanism that received considerable attention in the last few years.© 2015 Elsevier B.V. All rights reserved.1. Introduction1.1. Coalitional games and interaction graphsCooperative game theory aims to provide models of cooperation among interacting agents. One of the prevalent classes of games used within this framework is the class of characteristic function games. A characteristic function game (CFG) is defined over a set N = {1, . . . , n} of agents and is determined by a payoff function v : 2N (cid:3)→ R, such that, for each coalition C , i.e., for any non-empty set C ⊆ N of agents, the value v(C) expresses the payoff that the members of C can jointly achieve by cooperating among themselves [1,2]. The outcome is an allocation, i.e., a payoff vector x = (cid:6)x1, . . . , xn(cid:7) ∈ Rn assigning some payoff to each agent i ∈ N. Characteristic function games are also known as coalitional games with transferable utility, as it is assumed that the agents forming a coalition C can distribute the payoff v(C) among themselves in any way. The * Corresponding author.E-mail addresses: gehalk@intelligence.tuc.gr (G. Chalkiadakis), ggreco@mat.unical.it (G. Greco), markakis@gmail.com (E. Markakis).http://dx.doi.org/10.1016/j.artint.2015.12.0050004-3702/© 2015 Elsevier B.V. All rights reserved.\fG. Chalkiadakis et al. / Artificial Intelligence 232 (2016) 76–11377Fig. 1. Coalitional games in Example 1.1 and Example 1.3.question of interest for such games, is to identify desirable (e.g., fair and stable) outcomes in terms of worth distributions, which are called solution concepts.Characteristic function games provide a rich framework for understanding and reasoning about cooperative actions and have a wide spectrum of applications in different areas of research. Indeed, while they have been traditionally grounded in the game theory and economic literature, they have gained popularity in the context of multi-agent systems and artificial intelligence research as a means of studying interactions among autonomous agents (see, e.g., [3–9]). Moreover, they have recently attracted attention in engineering too, because of their use in the design of intelligent protocols and middleware algorithms for wireless communication networks [10–12]. As an example, we next illustrate a wireless cooperative file sharing system, where mobile subscribers cluster together by downloading (portions of) files of interest over long-range cellular links, and by exchanging them over a wireless ad-hoc network (see, e.g., [13]).Example 1.1. Consider the setting with three mobile users (hence, N = {1, 2, 3}) that is illustrated in the left part of Fig. 1, and a function v such that, for each coalition C ⊆ N, v(C) is meant to express the payoff that users in C can jointly achieve when clustering together and cooperating to download the given file of interest. In particular, assume that v({1}) = 10, v({2}) = 5, v({3}) = 4, v({1, 2}) = 17, v({2, 3}) = 10, and v({1, 2, 3}) = 22. Intuitively, the payoff of each coalition C is meant to express the sum of the utilities that the agents in C get when the file is downloaded minus the cost that they overall incur for the download, with this cost being proportional to the time required and to certain technological features, such as bandwidth and energy consumption.For instance, when 1 and 2 cluster together, each of them can download only half of the file and then share the portion via the wireless connection. While doing so, each of them increases the throughput due to the better performance of the wireless network when compared to the cellular links, and reduces the overall downloading costs. This is reflected in the payoff function v, which is such that v({1, 2}) ≥ v({1}) + v({2}). Similarly, 2 and 3 can cluster together leading to the payoff v({2, 3}) ≥ v({2}) + v({3}).In contrast, note that users 1 and 3 are outside of each other’s transmission range, hence it is impossible for them to cluster together (and, in fact, the payoff function is not specified for this coalition). However, user 2 might still act as a bridge between them, so that when all users join together, the resulting payoff is v({1, 2, 3}) = 22. Indeed, it is advantageous for the users to cluster all together, because v({1, 2, 3}) ≥ v({1, 2}) + v({3}), v({1, 2, 3}) ≥ v({1}) + v({2, 3}), and v({1, 2, 3}) ≥v({1}) + v({2}) + v({3}). While doing so, each user gets the payoff that can be achieved by downloading the whole file alone, and a surplus of v({1, 2, 3}) − (v({1}) + v({2}) + v({3})) = 22 − (10 + 5 + 4) = 3 still remains to be divided among (cid:2)them. As the above example demonstrates, characteristic function games might be defined within an environment imposing restrictions on the formation of coalitions. Indeed, users 1 and 3 are outside each other’s transmission range, and the coalition {1, 3} cannot form.In general, for reasons that might range from physical limitations and constraints to legal banishments, certain agents might not be allowed to form coalitions with certain others. Sensor networks, communication networks, or transportation networks, within which units are connected through bilateral links, provide natural settings for such classes of games. In many multiagent coordination settings, agents might be restricted to communicate or interact with only a subset of other agents in the environment, due to limited resources or existing physical barriers. Another example is provided by hierarchies of employees within an enterprise, where employees at the same level work together under the supervision of a boss, i.e., of an employee at the immediately higher level in the hierarchy. In all these settings, the environment can be seen to possess some structure that forbids the formation of certain coalitions. This can be formalized as an interaction graph G = (N, E), an undirected graph, where agents are transparently viewed as nodes so that a coalition C is feasible, i.e., allowed to form, only if the subgraph of G induced over the nodes of C is connected [14]. For instance, it is immediate to check that the graph shown in the left part of Fig. 1, is the interaction graph associated with the game of Example 1.1, where all coalitions are allowed to form but {1, 3}.Note that when an interaction graph G is the complete graph over N, then G induces no structural restrictions and we are back to the basic setting where a game is completely specified by its payoff function (and all coalitions are allowed to form). Hence, the setting with interaction graphs generalizes the basic one.\f78G. Chalkiadakis et al. / Artificial Intelligence 232 (2016) 76–1131.2. Stability and coalition structuresThe main solution concept adopted in the literature in order to deal with the problem of stability in characteristic function games (i.e., what are the incentives for the agents to stay in formed coalitions), is, arguably, the core [15,16].In settings without any restriction on the possible interactions among the agents, the core is defined as the set of all allocations that are stable because there is no coalition having an incentive to deviate, that is, as the set{x ∈ Rn | x(N) = v(N) and x(C) ≥ v(C), for each coalition C ⊆ N},(cid:2)where x(C) is a shorthand for i∈C xi . Note that it is implicitly assumed here that the grand-coalition of all players in Nforms and, accordingly, the solution concept suggests how the total payoff v(N) can be divided among them in a way that is stable [2].In the presence of an interaction graph, the core can be smoothly adapted so as to focus only on feasible coali-tions [17–19], as illustrated below—formal definitions are provided in Section 2.Example 1.2. The core of the characteristic function game defined in Example 1.1 consists of all allocations (cid:6)x1, x2, x3(cid:7) ∈ R3that are solutions to the following set of lin",
            {
                "entities": [
                    [
                        3369,
                        3397,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 297 (2021) 103486Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA unifying look at sequence submodularity ✩Sara Bernardini a,∗a Department of Computer Science, Royal Holloway University of London, Egham, Surrey, TW20 0EX, UKb Department of Mathematical Sciences, Politecnico di Torino, Torino, 10129, Italyc Augmenta Inc., Toronto, M5A 1E1, Canada, Fabio Fagnani b, Chiara Piacentini ca r t i c l e i n f oa b s t r a c tArticle history:Received 11 September 2020Received in revised form 9 January 2021Accepted 16 February 2021Available online 24 February 2021Keywords:SubmodularitySequence submodularityGreedy algorithmsSuboptimal algorithmsDetection problemsSearch-and-trackingEnvironmental monitoringSchedulingRecommender systems1. IntroductionSeveral real-world problems in engineering and applied science require the selection of sequences that maximize a given reward function. Optimizing over sequences as opposed to sets requires exploring an exponentially larger search space and can become prohibitive in most cases of practical interest. However, if the objective function is submodular (intuitively, it exhibits a diminishing return property), the optimization problem becomes more manageable. Recently, there has been increasing interest in sequence submodularityin connection with applications such as recommender systems and online ad allocation. However, mostly ad hoc models and solutions have emerged within these applicative contexts. In consequence, the field appears fragmented and lacks coherence. In this paper, we offer a unified view of sequence submodularity and provide a generalized greedy algorithm that enjoys strong theoretical guarantees. We show how our approach naturally captures several application domains, and our algorithm encompasses existing methods, improving over them.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).Many real-world applications in engineering and applied science have at their core the selection of sequences of objects that maximize a reward. In information gathering missions, for example, the objects are observations and the goal is to select a sequence of them that maximizes the information gain [1,2]. In a similar fashion, a movie recommender system aims to provide its users with sequences of items that maximize relevance [3,4]. The crucial point in these applications is that the value of the sequence depends not only on the objects belonging to it, but also on their relative order. This is because the value of each object changes based on its position in the sequence.If optimizing over sets is already a daunting task, optimizing over sequences quickly becomes unmanageable when the problem at hand grows. However, the identification of special properties in the objective function helps in making the task more approachable. Submodularity, in particular, has emerged as a powerful feature that can be leveraged to control complexity in the maximization of both set and sequence functions. Submodularity can be understood intuitively as a dimin-ishing return condition. Consider again an information-gathering mission. Each new observation increases the information gain, but it does it to a smaller extent than the previous observations, with gain vanishing at infinity.In areas as variegated as optimization, machine learning, economics, medicine and sensor networks, there has been a vast amount of work on the maximization of submodular set functions (see Section 2). Only recently, the scientific commu-✩This paper is an invited revision of a paper which first appeared at the 2020 International Conference Automated Planning and Scheduling (ICAPS-20).* Corresponding author.E-mail address: sara.bernardini@rhul.ac.uk (S. Bernardini).https://doi.org/10.1016/j.artint.2021.1034860004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fS. Bernardini, F. Fagnani and C. PiacentiniArtificial Intelligence 297 (2021) 103486nity has started to pay closer attention to sequence submodularity prompted by applications such as online ad allocation [5]and recommendations in online shopping [6], entertainment [3] and courses [7]. However, having arisen in specific applica-tive contexts, the proposed models as well as the corresponding algorithms lack generality and require making restrictive assumptions on the objective function to maintain efficiency.In this paper, to remedy the current ad hoc approach and lack of coherence in the field, we offer a unified view of sequence submodularity. By abstracting away specific applicative details, we show that the optimization problem that lies behind several applications can be captured by a particular type of recursive submodular function. We study its structure and, based on its properties, we propose a generalized greedy algorithm that has theoretical guarantees as strong as its classical counterpart on set functions but does not require unrealistic restrictive assumptions. Our generalized algorithm encompasses and improves the specific algorithms that have been developed for several practical applications. Another property that confers flexibility to our approach is that we can easily enforce constraints on the cardinality of the elements in the sequence (e.g. all elements must be distinct) in the domain description, which is particularly useful in applicative problems.The paper is organized as follows. After discussing related work in Section 2, we state the problem formally and introduce our running example in Section 3. In Section 4, we recall the concept of submodularity for sequence functions and show how, in general, a simple generalization of the classical greedy algorithm from sets to sequences fails to achieve good performance for several optimization problems of practical relevance. Subsequently, in Section 5, we propose and analyze a new greedy algorithm that is proven to achieve the same performance as the classical one for submodular set functions (Theorem 1). In Section 6, we study how this result can be applied to the general class of problems that we are interested in solving (Theorem 2 and Corollary 1) and, in Sections 7 and 8, we present several different application domains, which demonstrate the expressiveness and generality of our approach. Finally, Section 9 provides explicit numerical simulations for two of the applicative setups discussed in the previous two sections, while Sections 10 offers conclusive thoughts.2. Related workWork on submodularity spreads across multiple fields, including optimization [8,9], machine learning [10,11], economics [12,13], medicine [14] and sensor networks [15,16]. This body of work focuses on set functions and, as most of the problems considered are NP-complete, revolves around finding good approximations of the optimal solution via greedy approaches, which are very effective for non-decreasing, submodular functions [9]. We do not review this literature here as set functions are not our focus. For a comprehensive review on this topic, we refer the readers to the literature [17].Only recently, work on sequence submodularity has emerged. Streeter and Golovin [18] first considered this problem in the context of online resource allocation applications. Shortly after, Alaei and Malekian [5] introduced the term sequence submodularity and showed that if the submodular function is non-decreasing and differentiable, a greedy approach always achieves a solution that is at least 1 − 1e of the optimal one for the maximization problem.Zhang et al. [15] consider string submodularity, which is a weaker concept as the submodularity holds for the prefix relationship instead of for any type of subsequence relationship. They improve on Alaei and Malekian’s approximation by introducing additional constraints on the degree of string submodularity (curvature) of the objective function.Other authors have defined sequence submodularity within a graph-based setting. Tschiatschek et al. [4] consider cases in which dependencies between elements of a sequence can be captured via directed acyclic graphs (DAGs) and present an algorithm with theoretical guarantees for them. However, repetitions in the sequence are not allowed and DAG submodular functions are not necessarily string or sequence submodular.Mitrovic et al. [7] extend this graph-based framework to graphs and hypergraphs with bounded in or out degrees.Finally, Qian et al. [19] take a departure from the greedy approach and propose a Pareto optimization method for se-quence selection. They show that, for any class of submodular functions previously studied, their approach can always reach the best known approximation guarantee.Mitrovic et al. [20], on the other hand, consider the case in which the value of a sequence depends not only on the items selected and their order but also on the states of the items, which might be initially unknown (adaptive submodularity).Against the backdrop of this body of work, we aim to show that the submodular functions appearing in practical ap-plications do not satisfy the constraints imposed by the approaches highlighted here. However, they do present a common structure that can be exploited to equip a suitably modified greedy algorithm with strong theoretical guarantees.3. Problem statementIn this section, we formally introduce the optimization problems that we study in this paper. Let (cid:2) be a set and H((cid:2))be the language over (cid:2), i.e. the set of sequences of elements in (cid:2) of any length including the empty sequence ∅. Let Hd((cid:2))denote the sub-language consisting of all sequences in H((cid:2)) with distinct elements. If S = (S 1, . . . , Sn) ∈ H((cid:2)), with S ibeing the element of sequence S in position i, we denote with |S| = n the length of the sequen",
            {
                "entities": [
                    [
                        3903,
                        3931,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 160 (2004) 105–143www.elsevier.com/locate/artintA causal approach to nonmonotonic reasoningAlexander BochmanComputer Science Department, Holon Academic Institute of Technology, 52 Golomb St., Holon 58102, IsraelReceived 11 January 2004; accepted 24 July 2004AbstractWe introduce logical formalisms of production and causal inference relations based on in-put/output logics of Makinson and Van der Torre [J. Philos. Logic 29 (2000) 383–408]. Theseinference relations will be assigned, however, both standard semantics (giving interpretation totheir rules), and natural nonmonotonic semantics based on the principle of explanation closure.The resulting nonmonotonic formalisms will be shown to provide a logical representation of ab-ductive reasoning, and a complete characterization of causal nonmonotonic reasoning from McCainand Turner [Proc. AAAI-97, Providence, RI, 1997, pp. 460–465]. The results of the study suggestproduction and causal inference as general nonmonotonic formalisms providing an alternative repre-sentation for a significant part of nonmonotonic reasoning. 2004 Elsevier B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Causality; Abduction; Reasoning about action and change1. IntroductionThe field of nonmonotonic reasoning is so abundant with different formalisms, thatan attempt to introduce and justify yet another one appears to be doomed from the verybeginning. Nevertheless, this is precisely the main aim of this study.1 Accordingly, we haveto explain, first of all, what was the problem such that the new formalism is the suggestedsolution.E-mail address: bochmana@hait.ac.il (A. Bochman).1 A preliminary version of this paper has appeared as [7].0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.07.002\f106A. Bochman / Artificial Intelligence 160 (2004) 105–143To begin with, studies in nonmonotonic reasoning have given rise to two basicallydifferent approaches that could be called, respectively, preferential and explanatory non-monotonic reasoning, with little interaction between them.2 The first approach encom-passes nonmonotonic inference relations of [20], as well as a general theory of beliefchange. A detailed description of this approach can be found in [6]. The second approachincludes various default and modal nonmonotonic logics, as well as logic programming. Infact, all the papers in the famous 1980 issue of the Artificial Intelligence on NonmonotonicReasoning could be seen as belonging to this latter camp (though McCarthy’s circumscrip-tion is expressible also by the first approach). The formalism suggested in the present paperwill also belong to the explanatory approach.The above two approaches reflect, respectively, two different senses in which a logi-cal system can be nonmonotonic. First, its rules may not admit addition of new premises,that is, they do not satisfy Strengthening the Antecedent. Second, adding further rules tothe system may possibly invalidate earlier conclusions. These two kinds of nonmonotonic-ity are largely independent. Thus, preferential inference relations are nonmonotonic in thefirst sense, but monotonic in the second sense, since addition of new conditionals does notinvalidate previous derivations. On the other hand, default logic exemplifies monotonic-ity of the first kind and nonmonotonicity of the second kind. Default rules freely admitstrengthening of their pre-requisites and justifications, since this does not change the setof extensions (see [5]). However, adding arbitrary new rules to a default theory may cre-ate new extensions, so the nonmonotonic conclusions made earlier will not, in general, bepreserved.We believe that nonmonotonic reasoning should give us a more direct and adequatedescription of the actual ways we think about the world than, say, the classical logic. Inthis respect, the preferential nonmonotonic reasoning has a definite advantage over exist-ing explanatory counterparts in that it provides a direct semantic representation for its mainnonmonotonic objects, namely default conditionals “If A, then normally B”. This semanticrepresentation allows us to assess our default claims and determines, ultimately, the actualchoice of default assumptions made in particular circumstances. Default logic and its rel-atives take a different, less direct, route to assessing what can be inferred from a givenset of default rules. Namely, they require from the user to provide an explicit informationabout when one default can ‘block’ another default. This information is used as a sole fac-tor in determining acceptable combinations of defaults. This strategy can be remarkablysuccessful in resolving difficult cases of default interaction, which can be seen as the mainreason why the explanatory nonmonotonic reasoning so far has had a greater impact onpractical applications of nonmonotonic reasoning in AI. Still, the explanatory approach re-mains largely syntactic in nature, and does not give us a transparent and systematic way ofrepresenting empirical data. More precisely, due to the fact that default rules do not havea direct semantic interpretation, the task of knowledge representation in these formalismsbecomes really an art rather than a systematic methodology.32 They have been called, respectively, classical and argumentative nonmonotonic reasoning in [6].3 As was rightly mentioned by the reviewer, this is actually the problem with many other KR formalisms aswell.\fA. Bochman / Artificial Intelligence 160 (2004) 105–143107An additional, more specific, problem with the explanatory approach consists in theepistemic understanding of default rules it presupposes. A distinctive feature of both de-fault and modal nonmonotonic logics is that they are inherently epistemic formalisms.Namely, they are essentially based on such notions as belief and knowledge, unlike theextensional classical logic used for a direct representation of facts about the world. Accord-ingly, the intended semantic models of these formalisms represent (possibly incomplete)sets of beliefs one can have, while their rules allow to make inferences based on absenceof belief, or consistency, with respect to candidate belief sets (cf. the introductory sectionsof [33]). It seems that this modal formulation of many nonmonotonic formalisms is mainlydue to historical reasons: at the time these formalisms have emerged, modal logics alreadyreigned in the literature as a standard paradigm of logical representation. The epistemicinterpretation strongly influenced also logic programming in that the negation as failurehas often been formulated as absence of knowledge (or derivation).Due to its modal character, default logic has turned out to be a logically weak formalismthat does not support many classical inference principles (such as reasoning by cases). Ithas also other well-known shortcomings, and numerous variants of default logic have beensuggested in attempts to overcome them and make it more in accord with our intuitions.On our opinion, however, a relatively modest success of these attempts has shown that it isimpossible to radically improve default logic without abandoning its underlying epistemicinterpretation.The shortcomings of default logic became especially vivid in attempts to apply it toone of the primary application fields of nonmonotonic reasoning, a formal representationof actions and change. It was realized quite early that classical logic alone cannot providean efficient representation for reasoning about change due to the famous frame problem[30]—a problem of giving an efficient description for the state of the world after perform-ing an action that would avoid computationally unbearable reproduction of all the factsthat remain unaffected. There was also a related ramification problem of determining theindirect effects (ramifications) of actions that arise due to the laws of the domain. Andit was only natural to expect that nonmonotonic reasoning should help in resolving theseproblems.After some less successful attempts to formalize temporal nonmonotonic reasoning inexisting nonmonotonic logics, a dominant recent approach to solving these problems hasbeen based on causal reasoning. Given a set of action and causal rules describing the do-main, the causal approach employs a distinction between facts that hold in a situationversus facts that are caused (explained) by other facts and the rules. The corresponding ex-planation closure assumption amounts to a requirement that all facts that hold in a situationshould be either caused by other occurrent facts, or else preserve their truth-values in time(due to the associated inertia assumption). A natural formalization of these principles hasbeen given in the framework of causal theories, introduced in [26]. A causal theory is a setof causal rules that express causal (or explanatory) relations among propositions. The non-monotonic semantics of such theories is determined by causally explained models, namelythe models that both satisfy the causal rules and such that every fact holding in them isexplained by some causal rule. The resulting nonmonotonic formalism has been shown toprovide a plausible and efficient solution for both the frame and ramification problem (see[17,21,37] for a detailed exposition and applications in representing action domains). Re-\f108A. Bochman / Artificial Intelligence 160 (2004) 105–143lated causal approaches to representing actions and change have been suggested in [23,36,38], to mention only a few.From the point of view of the present study, the causal reasoning constitutes an impor-tant conceptual shift in the general framework of explanatory nonmonotonic reasoning,since it is based on a direct and transparent description of factual and causal (explanatory)information about the world. In other words, it shows that the epistemic view of non-monotonic reasoning is not the only possibility. Accordingly, the primary aim of our studywill consist in",
            {
                "entities": [
                    [
                        1790,
                        1818,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 639–669Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPartial observability and learnability ✩Loizos MichaelOpen University of Cyprus, Cyprusa r t i c l ei n f oa b s t r a c tArticle history:Received 11 November 2007Received in revised form 30 March 2010Accepted 30 March 2010Available online 1 April 2010Keywords:Partial observabilityAppearanceRealityMasking processSensingMissing informationAutodidactic learningProbably approximately correctInformation recoveryReductionWhen sensing its environment, an agent often receives information that only partiallydescribes the current state of affairs. The agent then attempts to predict what it has notsensed, by using other pieces of information available through its sensors. Machine learningtechniques can naturally aid this task, by providing the agent with the rules to be used formaking these predictions. For this to happen, however, learning algorithms need to bedeveloped that can deal with missing information in the learning examples in a principledmanner, and without the need for external supervision. We investigate this problem herein.We show how the Probably Approximately Correct semantics can be extended to deal withmissing information during both the learning and the evaluation phase. Learning examplesare drawn from some underlying probability distribution, but parts of them are hiddenbefore being passed to the learner. The goal is to learn rules that can accurately recoverinformation hidden in these learning examples. We show that for this to be done, oneshould first dispense the requirement that rules should always make definite predictions;“don’t know” is sometimes necessitated. On the other hand, such abstentions should not bedone freely, but only when sufficient information is not present for definite predictions tobe made. Under this premise, we show that to accurately recover missing information, itsuffices to learn rules that are highly consistent, i.e., rules that simply do not contradictthe agent’s sensory inputs. It is established that high consistency implies a somewhatdiscounted accuracy, and that this discount is, in some defined sense, unavoidable, anddepends on how adversarially information is hidden in the learning examples.Within our proposed learning model we prove that any PAC learnable class of monotone orread-once formulas is also learnable from incomplete learning examples. By contrast, weprove that parities and monotone-term 1-decision lists, which are properly PAC learnable,are not properly learnable under the new learning model. In the process of establishing ourpositive and negative results, we re-derive some basic PAC learnability machinery, such asOccam’s Razor, and reductions between learning tasks. We finally consider a special caseof learning from partial learning examples, where some prior bias exists on the manner inwhich information is hidden, and show how this provides a unified view of many previouslearning models that deal with missing information.the proposed learning model goes beyond a simple extension ofWe suggestsupervised learning to the case of incomplete learning examples. The principled andgeneral treatment of missing information during learning, we argue, allows an agent toemploy learning entirely autonomously, without relying on the presence of an externalteacher, as is the case in supervised learning. We call our learning model autodidactic toemphasize the explicit disassociation of this model from any form of external supervision.© 2010 Elsevier B.V. All rights reserved.that✩A preliminary version of this work appeared as: Loizos Michael, Learning from partial observations, in: Manuela M. Veloso (Ed.), Proceedings of theTwentieth International Joint Conference on Artificial Intelligence (IJCAI’07), January 2007, pp. 968–974. This work was completed while the author was atthe School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USA, and was supported by grant NSF-CCF-04-27129.E-mail address: loizos@ouc.ac.cy.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.03.004\f640L. Michael / Artificial Intelligence 174 (2010) 639–6691. IntroductionIt can be argued that a central aspect of a fully autonomous agent is the ability to learn the rules that govern its envi-ronment, without any form of external supervision. An autonomous agent senses its environment and obtains informationthat is often incomplete, which serves, then, as input to the learning process. Such settings necessitate, thus, the use oflearning algorithms that can deal with such incomplete learning examples.In this work we propose a framework within which learning from incomplete learning examples can be formally studied.For concreteness, our framework can be viewed as an extension of the Probably Approximately Correct semantics [28]. Ourgoal is to show that it is possible to learn rules that accurately predict information missing in an agent’s sensory readings,and that these rules can be obtained efficiently, and be accompanied by formal PAC-like guarantees, irrespectively of howinformation is hidden in the learning examples available during the learning and evaluation phases. We note, however, andpoint out throughout this work, that the problem of learning from incomplete learning examples goes beyond learningclassification rules as in the original PAC model. We view the results of this work as a first step towards the more ambitiousgoal of devising learning algorithms that can identify more general rules.Our exposition starts in Section 2, where the problem of learning from incomplete information is put into context,as the problem underlying the process of scientific discovery: identifying the structure of some underlying reality, givenonly partial appearances of that reality. We continue to show how the PAC semantics can be extended to this effect.As in the PAC model, learning examples are drawn independently at random from some underlying probability distribu-tion. Unlike the PAC model, these examples are never directly accessible by an agent. Instead, some arbitrary stochasticprocess hides parts of these examples, giving rise to what we call partial observations. These observations are then givento the agent, both during the learning phase as a means to facilitate learning, and during the evaluation phase as theinput on which learned rules are to be applied to make predictions, and against which these predictions are to betested.Due to lack of complete information during the evaluation phase, we allow learned rules to make “don’t know” pre-dictions, but only when the rules cannot be unambiguously evaluated on a given observation. Under this provision, wedefine a rule to be consistent with an observation if the rule’s prediction does not directly contradict what is stated inthe observation. In particular, if the observation does not offer any information on some target attribute, then any pre-diction is consistent. Learning is successful if highly consistent rules can be obtained efficiently in the relevant learningparameters.We then consider a stronger notion oflearnability, that of deriving rules that make predictions in a mannernot only consistent with an observation, but accurate with the underlying example. Thus, even if the observationdoes not offer any information on some target attribute, the prediction may be accurate or not depending on whatthe hidden underlying value of the target attribute is. We show that this more stringent notion oflearnability isinformation-theoretically unattainable when information is hidden adversarially in observations. We introduce a metriccalled concealment to capture the extent of this adversity, and show that consistency, accuracy, and concealment aretied together in a natural manner: consistency implies accuracy discounted by some factor determined by the conceal-ment. This allows us to focus on the conceptually simpler notion of consistent learnability for the remaining of thiswork.Section 3 discusses some of the choices we have made in our learning model, and contrasts them against existing work inStatistical Analysis and Learning Theory. Three main aspects are discussed: (i) when are “don’t know” predictions allowed,and what does it mean to predict “don’t know”; (ii) to what extent is autonomy possible when learning; and (iii) howmuch regularity is assumed in the way information is missing in learning examples. This discussion shows, in particular,that unlike most previous work, our learning framework does without the assumption of an external teacher. We call thelearning framework autodidactic in recognition of this property.The two subsequent sections provide positive and negative learnability results for autodidactic learnability. Section 4establishes that certain machinery available in the PAC model applies also, in some form, in the context of autodidacticlearnability. In particular, Occam’s Razor [4] applies unchanged as in PAC learnability, while reductions between learningtasks [23] can be formalized in a way that accommodates the more stringent requirements that need to be met for auto-didactic learnability. Using reductions we then establish that any PAC learnable concept class that contains only monotoneor read-once formulas can also be learned autodidactically. Hence, in a broad set of domains, the lack of complete infor-mation does not render learnability any harder. By contrast, Section 5 establishes that incomplete information may in somecases diminish learnability. We show that, although they are properly PAC learnable, the concept classes of parities andmonotone-term 1-decision lists are not properly learnable in the autodidactic model, unless RP = NP.The case where information is not hidden completely arbitrarily in learning examples is examined in Section 6. We argue,and demonstrate, that depending on how structured such informatio",
            {
                "entities": [
                    [
                        4168,
                        4196,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 289 (2020) 103384Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQuantifying controllability in temporal networks with uncertainty ✩Shyan Akmal a,b,1, Savana Ammons a,c,1, Hemeng Li a,d,1, Michael Gao a,e,1, Lindsay Popowski a, James C. Boerkoel Jr. a,∗a Harvey Mudd College, Claremont, CA, USAb Massachusetts Institute of Technology, Cambridge, MA, USAc University of Illinois at Urbana-Champaign, Champaign, IL, USAd Cornell University, Ithaca, NY, USAe Stanford University, Stanford, CA, USAa r t i c l e i n f oa b s t r a c tArticle history:Received 1 November 2019Received in revised form 16 July 2020Accepted 7 September 2020Available online 23 September 2020Keywords:SchedulingTemporal planningControllabilityProbabilistic simple temporal networksSimple temporal networks with uncertaintyControllability for Simple Temporal Networks with Uncertainty (STNUs) has thus far been limited to three levels: strong, dynamic, and weak. Because of this, there is currently no systematic way for an agent to assess just how far from being controllable an uncontrollable STNU is. We provide new insights inspired by a geometric interpretation of STNUs to introduce the degrees of strong and dynamic controllability — continuous metrics that measure how far a network is from being controllable. We utilize these metrics to approximate the probabilities that an STNU can be dispatched successfully offline and online respectively. We introduce new methods for predicting the degrees of strong and dynamic controllability for uncontrollable networks. We further generalize these metrics by defining likelihood of controllability, a controllability measure that applies to Probabilistic Simple Temporal Networks (PSTNs). Finally, we empirically demonstrate that these metrics are good predictors of actual dispatch success rate for STNUs and PSTNs.© 2020 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionWhen tasked with making a schedule, a planner would ideally have the capability to pick exact times for every event that could occur. In practice however, autonomous agents rarely have control over all events affecting their plans. For example, imagine a chemist named Dr. V running a small experiment. She first combines 20 mL of chemical W and chemical X in a beaker. The exact amount of time it takes these chemicals to react is uncertain: all Dr. V knows is that it will take between twenty and thirty-one minutes for the reaction to finish (unfortunately, not much is known about the reaction rates of chemicals W and X). Within ten minutes of this reaction completing, she must add 20 mL of chemical Y to the mixture, ✩This paper is an invited revision of a paper [1] which first appeared at the 2019 International Conference on Automated Planning and Scheduling (ICAPS-19).* Corresponding author.lpopowski@hmc.edu (L. Popowski), boerkoel@hmc.edu (J.C. Boerkoel).E-mail addresses: naysh@mit.edu (S. Akmal), sammons@hmc.edu (S. Ammons), hl2359@cornell.edu (H. Li), mgao@hmc.edu (M. Gao), URL: https://www.heatlab.org (J.C. Boerkoel).1 Work on this paper was primarily completed while an undergraduate student at Harvey Mudd College.https://doi.org/10.1016/j.artint.2020.1033840004-3702/© 2020 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fS. Akmal, S. Ammons, H. Li et al.Artificial Intelligence 289 (2020) 103384Fig. 1. An STNU representation of Dr. V’s experiment.which catalyzes a new reaction taking thirty to thirty-five minutes. Finally, Dr. V must collect a product, precipitate Z, from the solution within ten minutes of the reaction completing.To run the experiment successfully, Dr. V needs to schedule several different events. She is able to select times for some events, such as the addition of chemical Y, but other events, such as the completion times of the reactions, are not under her control. There are multiple different strategies Dr. V can use to deal with this uncertainty in timing and ensure the experiment’s success. The effectiveness of different types of scheduling strategies is related to the scheduling problem’s controllability — how easily the experiment can be successfully executed given its inherent uncertainty. Currently, all forms of controllability discussed in the literature are discrete — they tell Dr. V whether her experiment is controllable or not, but do not tell her “how” controllable or uncontrollable the experiment is.In this paper, we extend the notion of controllability by introducing two new continuous metrics on temporal networks: the degrees of strong and dynamic controllability [1]. These metrics are motivated by a geometric interpretation of STNUs as pairs of polytopes and characterize how far a network is from being controllable given different types of execution strategies. These metrics naturally relate to the probability that a network can be successfully dispatched. In that context, we define optimization problems for determining the probability of successful dispatch given online/offline plans, and offer approximate solutions to these problems. Finally, we show that the degrees of both strong and dynamic controllability extend naturally and effectively to PSTNs [2].2. Background2.1. Simple Temporal NetworksA Simple Temporal Network (STN) is a tuple S = (cid:3)T , C(cid:4), where T is the set of temporal events ti , and C is the set of binary constraints on T [3]. Each element in C is of the form t j − ti ≤ ci j , for some ci j ∈ R. By convention, the event t0 ∈ T in an STN represents a fixed reference point assigned time zero. Because of this, when we say that an STN has n temporal events, we really mean that it has n time-points in addition to this reference event. A solution to an STN is an assignment of values to the timepoints ti that satisfies all constraints. A common approach to checking if an STN is consistent, that it has a solution, is to apply a shortest-path algorithm to a weighted, directed graph representation of the STN called a distance graph. If a negative cycle is discovered during the shortest-path process, it implies that the STN is inconsistent and thus no solutions exist; otherwise the resulting distance graph is a representation of the space of solutions.2.2. Simple Temporal Networks with UncertaintyA Simple Temporal Network with Uncertainty (STNU) is an STN that explicitly models uncertainty [4]. In an STNU, the set of events T is partitioned into a set of controllable events T c and a set of uncontrollable events T u . An agent is allowed to schedule specific times for the events in T c , but the times for events in T u are determined by “Nature,” a force external to the agent. For every t j ∈ T u , there exists a unique ti ∈ T c forming a contingent constraint of the form t j − ti ∈. We use Cc to denote the set of these contingent constraints, and Cr to denote the remaining requirement constraints between events in T . Then an STNU is defined as a quadruple (cid:3)T c, T u, Cr, Cc(cid:4) satisfying the aforementioned properties.(cid:2) j, u j(cid:2)(cid:3)In an STNU, a decision is an assignment of time values to each of the controllable events. A realization is a selection of values for contingent edges (relative start times of the uncontrollable events) assigned by Nature. The set of all possible realizations forms the realization space (cid:3) for the STNU. If a decision does not violate any of the constraints between pairs of controllable events, we say the decision is admissible. A decision together with a realization determines a schedule σ for the network. If σ satisfies all constraints in the STNU, we call σ a valid schedule.For example, Dr. V’s experiment from the introduction can be modeled as an STNU. There are five events of interest: the beginning of the first reaction, the conclusion of this initial reaction, the addition of chemical Y, the completion of the subsequent reaction, and the extraction of the precipitate. If we measure time relative to the experiment’s start, we can refer to these events as ti , where i ranges from 0 to 4 respectively. Events t0, t2 and t4 are under Dr. V’s control, while events t1 and t3 are uncontrollable. This STNU representation of the experiment is depicted in Fig. 1. Events in the network are drawn as nodes. Requirement and contingent edges are drawn as straight and curvy arrows respectively. The edges are labeled by intervals indicating the lower and upper bounds of the STNU’s constraints.2\fS. Akmal, S. Ammons, H. Li et al.2.3. ControllabilityArtificial Intelligence 289 (2020) 103384An STNU is controllable when an agent has a reasonable way of working around the uncertainty in the network to schedule events. Prior research has focused primarily on detecting three types of controllability: strong, dynamic, and weak. We focus on strong and dynamic controllability, since they are important for dispatch. We omit weak controllability from our discussion because it is less relevant to STNU execution [4]. Henceforth in this paper, we use the term “uncontrollable STNU” to refer to both STNUs that are not strongly controllable and those that are not dynamically controllable.An STNU is strongly controllable if there is a single fixed decision the agent can make that guarantees success regardless of how Nature behaves. More formally, a network is strongly controllable if there exists a decision δ such that for all ω ∈ (cid:3), the schedule determined by δ and ω is valid [4]. We call such a decision a strong decision. Using the example from the introduction, one can check that Dr. V’s experiment is not strongly controllable because there is no fixed decision she can make to guarantee the experiment’s success before it takes place.An STNU is dynamically controllable ",
            {
                "entities": [
                    [
                        3342,
                        3370,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 207 (2014) 1–22Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelating constraint answer set programming languages andalgorithmsYuliya LierlerDepartment of Computer Science, The University of Nebraska at Omaha, 6001 Dodge Street, Omaha, NE 68182, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 9 October 2012Received in revised form 28 October 2013Accepted 29 October 2013Available online 11 November 2013Keywords:(Constraint) answer set programmingConstraint satisfaction processingSatisfiability modulo theoriesRecently a logic programming language AC was proposed by Mellarkod et al. [1] tointegrate answer set programming and constraint logic programming. Soon after that,a clingcon language integrating answer set programming and finite domain constraints,as well as an ezcsp language integrating answer set programming and constraint logic pro-gramming were introduced. The development of these languages and systems constitutesthe appearance of a new AI subarea called constraint answer set programming. All theselanguages have something in common. In particular, they aim at developing new efficientinference algorithms that combine traditional answer set programming procedures andother methods in constraint programming. Yet, the exact relation between the constraintanswer set programming languages and the underlying systems is not well understood.In this paper we address this issue by formally stating the precise relation between sev-eral constraint answer set programming languages – AC, clingcon, ezcsp – as well as theunderlying systems.© 2013 Published by Elsevier B.V.1. IntroductionConstraint answer set programming (CASP) is a novel, promising direction of research whose roots can be traced backto propositional satisfiability (SAT). SAT solvers are efficient tools for solving Boolean constraint satisfaction problems thatarise in different areas of computer science, including software and hardware verification. Answer set programming (ASP)extends computational methods of SAT using ideas from knowledge representation, logic programming, and nonmonotonicreasoning. As a declarative programming paradigm, it provides a rich, and yet simple modeling language that, among otherfeatures, incorporates recursive definitions. Satisfiability modulo theories (SMT) extends computational methods of SAT byintegrating non-Boolean symbols defined via a background theory in other formalisms, such as first order theory or aconstraint processing language. The key ideas behind such integration are that (a) some constraints are more naturallyexpressed by non-Boolean constructs and (b) computational methods developed in other areas of automated reasoning thanSAT may complement its technology in an effective manner processing these constraints.Constraint answer set programming draws on both of these extensions of SAT technology: it integrates answer set pro-gramming with constraint processing. This new area has already demonstrated promising results, including the developmentof the CASP solvers acsolver [1] (Texas Tech University), clingcon1 [2,3] (Potsdam University, Germany), ezcsp2 [4] (KO-DAK), idp3 [5] (KU Leuven). These systems provide new horizons to knowledge representation as a field by broadening theapplicability of its computational tools. CASP not only provides new modeling features for answer set programming but1 http://www.cs.uni-potsdam.de/clingcon/.2 http://marcy.cjb.net/ezcsp/index.html.3 http://dtai.cs.kuleuven.be/krr/software/idp.0004-3702/$ – see front matter © 2013 Published by Elsevier B.V.http://dx.doi.org/10.1016/j.artint.2013.10.004\f2Y. Lierler / Artificial Intelligence 207 (2014) 1–22also improves grounding and solving performance by delegating processing of constraints over large and possibly infinitedomains to specialized systems. The origins of this work go back to [6,7].Drescher and Walsh [8,9] (inca, NICTA, Australia), Liu et al. [10] (mingo, Aalto University, Finland) took an alternativeapproach to tackling CASP languages – a translational approach. In the former case, the CASP programs are translated intoASP programs (Drescher and Walsh proposed a number of translations). In the latter, the program is translated into integerlinear programming formalism. The empirical results demonstrate that this is also a viable approach towards tackling CASPprograms.The general interest towards CASP paradigms illustrates the importance of developing synergistic approaches in the au-tomated reasoning community. To do so effectively one requires a clear understanding of the important features of theCASP-like languages and underlying systems. Current CASP languages are based on the same principal ideas yet relatingthem is not a straightforward task. One difficulty lies in the fact that these languages are introduced together with a spe-cific system architecture in mind that rely on various answer set programming, constraint satisfaction processing, constraintlogic programming, and integer linear programming technologies. The syntactic differences stand in the way of clear un-derstanding of the key features of the languages. For example, the only CASP language that was compared to its earliersibling was the language ezcsp. Balduccini [4] formally stated that the ezcsp language is a special case of AC. Relating CASPsystems formally is an even more complex task. The variations in underlying technologies complicate clear articulation oftheir similarities and differences. For instance, the main building blocks of the CASP solver acsolver [1] are the ASP sys-tem smodels [11] and sicstus Prolog.4 The technology behind clingcon [2,3] is developed from the ASP solver clasp [12]and the constraint solver gecode [13]. In addition, the CASP solvers adopt different communication schemes among theirheterogeneous solving components. For instance, the system ezcsp relies on blackbox integration of ASP and CSP tools inorder to process the ezcsp language [4]. Systems acsolver and clingcon promote tighter integration of multiple automatedreasoning methods.The broad attention to CASP suggests a need for a principled and general study of methods to develop unifying ter-minology and formalisms suitable to capture variants of the languages and solvers. This work can be seen as a step inthis direction. First, it presents a formal account that illustrates a precise relationship between the languages of acsolver,clingcon, and ezcsp. Second, it formally relates the systems that take a hybrid approach to solving in CASP. In particular, itaccounts for systems acsolver, clingcon, and ezcsp.Usually backtrack search procedures (Davis–Putnam–Logemann–Loveland (DPLL)-like procedures [14]), the backbone ofCASP computational methods are described in terms of pseudocode. In [15], the authors proposed an alternative approachto describing DPLL-like algorithms. They introduced an abstract graph-based framework that captures what the “states ofcomputation” are and what transitions between states are allowed. This approach allows us to model a DPLL-like algorithmby a mathematically simple and elegant object, a graph, rather than a collection of pseudocode statements. We develop asimilar abstract framework for performing precise formal analysis on relating the constraint answer set solvers acsolver,clingcon, and ezcsp. Furthermore, this framework allows an alternative proof of correctness of these systems. This workclarifies and extends state-of-the-art developments in the area of constraint answer set programming and, we believe, willpromote further progress in the area.More on related work Another direction of work related to the developments in CASP is research on HEX-programs [16].These programs integrate logic programs under answer set semantics with external computation sources via external atoms.They were motivated by the need to interface ASP with external computation sources, for example, to allow the synergyof ASP and description logic computations within the context of the semantic web. CASP has a lot in common with HEX-programs. System dlvhex5 [17] computes models of such programs. It allows defining plug-ins for inference on externalatoms and as such can be used as a general framework for developing CASP solvers (but it does not provide any specificcomputational mechanism by default).Heterogeneous nonmonotonic multi-context systems [18] is another formalism related both to CASP and HEX-programs.CASP and HEX-programs can be seen as one of the possible incarnations of a special case of multi-context systems. Multi-context systems provide a more general formalism where “contexts” written in different logics relate with each other viabridge rules. Intuitively, CASP provides two contexts: one in the language of answer set programming and another one inthe language of constraint programming. Yet, the bridge rules are of extremely simplistic nature in CASP, in particular, theyrelate atoms in a logic program to constraints of constraint processing.Paper structure We start by reviewing AC programs introduced by Mellarkod et al. [1] and the notion of an answer setfor such programs. In the subsequent section we introduce the clingcon language and formally state its relation to the AClanguage. We then define a new class of weakly-simple programs and demonstrate that the acsolver algorithm is applicablealso to such programs. We review a transition system introduced by Lierler [19,20] to model smodels. We extend thistransition system to model the acsolver algorithm and show how the newly defined graph can characterize the computationbehind the system acsolver. We define a graph suitable for modeling the system clingcon and state a formal result on the4 http://www.sics.se/isl/sicstuswww/site/index.html.5 http://www.kr.tuwien.ac.at/research/systems/dlvhex/.\fY. Lierler / Artificial Intelligence 207 (2014) 1–223relation between the acsolver and clingcon algorithms. At last we ill",
            {
                "entities": [
                    [
                        3659,
                        3687,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 193–219Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFirst-order logical filteringAfsaneh Shirazi∗, Eyal AmirUniversity of Illinois at Urbana-Champaign, Department of Computer Science, Urbana, IL 61801, USAa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:FilteringFirst-order logicBelief updateSituation calculus1. IntroductionLogical filtering is the process of updating a belief state (set of possible world states) aftera sequence of executed actions and perceived observations. In general, it is intractable indynamic domains that include many objects and relationships. Still, potential applicationsfor such domains (e.g., semantic web, autonomous agents, and partial-knowledge games)encourage research beyond intractability results.In this paper we present polynomial-time algorithms for filtering belief states that areencoded as First-Order Logic (FOL) formulas. Our algorithms are exact in many cases ofinterest. They accept belief states in FOL without functions, permitting arbitrary arity forpredicates, infinite universes of elements, and equality. They enable natural representationwith explicit references to unidentified objects and partially known relationships, stillmaintaining tractable computation. Previous results focus on more general cases that areintractable or permit only imprecise filtering. Our algorithms guarantee that belief-staterepresentation remains compact for STRIPS actions (among others) with unbounded-sizedomains. This guarantees tractable exact filtering indefinitely for those domains. The restof our results apply to expressive modeling languages, such as partial databases and beliefrevision in FOL.© 2010 Elsevier B.V. All rights reserved.Many everyday scenarios are dynamic and partially observable: a robot in one room cannot see the state of anotherroom, a camera overlooking a bookshelf cannot detect the title of a book that is obscured, and one cannot readily observethe amount of money an agent has. Many applications in such domains compute information about the current world state(belief state, i.e. set of possible states or a distribution over such a set) after performing actions and perceiving observations.This computation is called filtering (also, state estimation, belief update, and database progression). They use this informationto make decisions (e.g., “increase the asking price for my car”), answer questions (e.g., “where is my calculus book?”), andexplore (e.g., “go to room 2 and sense the state of the circuit break”).Filtering is intractable in general for discrete domains [17], and much research is dedicated to its approximation instochastic domains (e.g., [6,15,20]). Still, these approximations introduce unbounded errors many times, take unboundedcomputation time in others, and are not usable in most deterministic domains.Recent progress on logical methods for filtering of propositional belief states (sets of states) [3] with actions and obser-vations has shown that exact filtering is tractable when belief states are represented as propositional formulas, and certainnatural assumptions are met. Still, many domains have propositional encodings that are too large. In some domains, propo-sitional representation is not possible at all. This includes domains with large numbers of objects, unknown numbers of* Corresponding author.E-mail addresses: hajiamin@cs.uiuc.edu (A. Shirazi), eyal@cs.uiuc.edu (E. Amir).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.015\f194A. Shirazi, E. Amir / Artificial Intelligence 175 (2011) 193–219AlgorithmAssumptionsTime (1 step)SpaceDeduction filter (Section 3.2)Factored filter (Section 4)Unit-case filter (Section 5.1)STRIPS filter (Section 5.2)STRIPS filter (Section 5.2)none1:1 actions; Finite FOL filtering of atoms;precompilation stage1:1 Unit-Cases actions; UNAaSTRIPS actions; known success; UNA; ϕ inclausal formb; cases fully instantiatedSTRIPS actions; known success; UNA; ϕ in2-clausalc formunbounded (lazy computation)precompilation unbounded; O (|ϕ| · C)O (Rl(l + |ϕ| + p))O ((l|ψ|)2e)O (m2(R + n)2R )unboundedO (|ϕ| · C), C depends on pre-compilationO (Rl(l + |ϕ| + p))O ((l|ψ|)2e);O (m2(R + n)2R ) for any t > 0time stepsLegend: ϕ: input (initial) belief state; m: number of predicate symbols; R: maximum arity of predicates; n: number of constant symbols (not objects, whichmay be infinitely many); l: total number of cases for action a’s successor-state axioms; p: number of distinct atoms in the precondition of a; e: number ofdistinct affected literals of a.a UNA: Unique-Names Assumption.b Clausal form: Conjunction of disjunctions in ∃∗∀∗c 2-clausal: Every clause has (cid:2) 2 literals.fragment of FOL.Fig. 1. The algorithms presented in this paper, their properties, and their assumptions for correct filtering. All algorithms assume no function symbols. Noalgorithm assumes a finite domain or requires a closed-world assumption (CWA). (The CWA is made in many planning domains. It assumes that the onlyobjects in the domain are those mentioned explicitly.)objects, and observations with partial knowledge about identity of objects. Propositional methods are very inefficient insuch domains, and representations are typically large and cumbersome.In this paper we present tractable algorithms and theoretical results for filtering belief states that are represented in First-Order Logic (FOL). These representations permit belief states of infinite sizes, uncertainty about the number of objects andtheir identity, and observations that do not distinguish between some objects. It also enables more compact representationsthan those of propositional logic.More specifically (detailed results table is presented in Fig. 1), we present the following algorithms and complexitybounds on their performance: First, we show that when actions are partial functions that map states 1:1, we can filterarbitrary FOL belief-state formulas in time O (|ψ| · C), for ψ the input belief state representation, after a precompilationstage of the domain (not including ψ ). The output size is O (|ψ| · C), for C a constant (possibly large) that depends on ouractions’ definitions (not on the input sequence of actions or the initial belief state).Second, we examine in more detail two action representations that permit faster and more compact filtering withoutprecompilation of the domain. Both of those classes of domains represent the effects of actions by cases.For the first class of actions we show that filtering takes time O (Rl · (|ψ| + l + p)) for R the arity of predicate fluents, lthe total number of cases into which filtered actions break, and p the number of distinct atoms appearing in preconditionsof the action and in cases. The belief state returned has representation size O (Rl · (|ψ| + l + p)). To obtain these results weassume that actions are 1:1 and can be broken into cases conditioned on unit clauses (this is defined formally in Section 5.1),and that different constant symbols refer to different elements in our domain (this is the Unique Names Assumption (UNA)).We present a different result for the second class of action representations, namely, STRIPS actions [18] in two differentscenarios. In the first scenario we assume that every action case for a but one instantiates all variables in every affectedpredicate (thus making it a proposition). Also, we assume the UNA and that actions are executable when they are filtered.Given those, we show that filtering takes time O ((l|ψ|)2e) per action, for e the number of affected literals for action a. Also,we show that the resulting belief state formula is represented in space bounded by O ((l|ψ|)2e) (here, |ψ| is the size of theinput belief state).Focusing on filtering sequences of length T > 0, and assuming input belief states that have only clauses of (cid:2) 2 literals, weget a final, better result. Assuming UNA and STRIPS actions, not assuming full-instantiation of cases (cases may instantiatesubsets of variables), we show that the same algorithm for STRIPS actions takes time O (m2(R + n)2R ) per action, for mpredicates of arity at most R and n constant symbols. The output belief-state space representation is bounded by O (m2(R +n)2R ) regardless of the number of filtering steps. Thus, filtering a sequence of t > 0 actions and observations takes time(tm2(R + n)2R ).Notice that the domain may still be large (or infinite) when R, m, n are small, so this result enables tractable filteringfor some very large domains. This result guarantees tractable filtering for arbitrary sequence lengths with such domains. Itapplies to standard STRIPS actions, among others.These results support a growing belief that FOL can be used efficiently for representing and updating partial knowledge[40,66,53,41,65].En route to these contributions we relate deterministic Situation Calculus [53] with a FOL transition model [4]. In thetransition model, every belief state is a set of FOL structures over the FOL language of a state. We encode this set ofstructures with FOL formulas. We re-state results of [40,64] showing that filtering such belief states can be captured exactlyby deduction in FOL and that deduction can be carried out one time step at a time, if all we wish is to answer queries abouta particular future or past state.This forms the foundations for the rest of our results, which give an efficient (polynomial-time) exact algorithm forcomputing this deduction, under some common conditions as mentioned above.The rest of the paper is organized as follows. Section 2 describes the semantics that we use for FOL filtering. In Section 3we provide a naive algorithm for filtering and prove its correctness. Section 4 offers a polynomial time algorithm for FOL\fA. Shirazi, E. Amir / Artificial Intelligence 175 (2011) 193–219195filtering that requires domain precompilation and is exact for 1:1 actio",
            {
                "entities": [
                    [
                        3597,
                        3625,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 453–490www.elsevier.com/locate/artintPartially observable Markov decisionprocesses with imprecise parametersHideaki Itoh ∗, Kiyohiko NakamuraDepartment of Computational Intelligence and Systems Science, Interdisciplinary Graduate School of Science and Engineering,Tokyo Institute of Technology, 4259-G3-46 Nagatsuta-cho, Midori-ku, Yokohama, Kanagawa 226-8502, JapanReceived 11 May 2005; received in revised form 7 March 2007; accepted 16 March 2007Available online 24 March 2007AbstractThis study extends the framework of partially observable Markov decision processes (POMDPs) to allow their parameters,i.e., the probability values in the state transition functions and the observation functions, to be imprecisely specified. It is shownthat this extension can reduce the computational costs associated with the solution of these problems. First, the new framework,POMDPs with imprecise parameters (POMDPIPs), is formulated. We consider (1) the interval case, in which each parameter isimprecisely specified by an interval that indicates possible values of the parameter, and (2) the point-set case, in which each prob-ability distribution is imprecisely specified by a set of possible distributions. Second, a new optimality criterion for POMDPIPs isintroduced. As in POMDPs, the criterion is to regard a policy, i.e., an action-selection rule, as optimal if it maximizes the expectedtotal reward. The expected total reward, however, cannot be calculated precisely in POMDPIPs, because of the parameter impre-cision. Instead, we estimate the total reward by adopting arbitrary second-order beliefs, i.e., beliefs in the imprecisely specifiedstate transition functions and observation functions. Although there are many possible choices for these second-order beliefs, weregard a policy as optimal as long as there is at least one of such choices with which the policy maximizes the total reward. Thusthere can be multiple optimal policies for a POMDPIP. We regard these policies as equally optimal, and aim at obtaining one ofthem. By appropriately choosing which second-order beliefs to use in estimating the total reward, computational costs incurred inobtaining such an optimal policy can be reduced significantly. We provide an exact solution algorithm for POMDPIPs that doesthis efficiently. Third, the performance of such an optimal policy, as well as the computational complexity of the algorithm, areanalyzed theoretically. Last, empirical studies show that our algorithm quickly obtains satisfactory policies to many POMDPIPs.© 2007 Elsevier B.V. All rights reserved.PACS: 07.05.Mh; 02.50.LeKeywords: POMDP; Second-order beliefs; Parameter set; Probability interval* Corresponding author.E-mail addresses: hideaki@dis.titech.ac.jp (H. Itoh), nakamura@dis.titech.ac.jp (K. Nakamura).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.03.004\f454H. Itoh, K. Nakamura / Artificial Intelligence 171 (2007) 453–4901. IntroductionThe theory of partially observable Markov decision processes (POMDPs) is normative for sequential decisionmaking under uncertainty [2,15,35,51]. It provides a general framework for designing intelligent agents [8,30], andseveral real-world applications have been reported (e.g., [29,38]). Let us consider a toy example called the tigerproblem:Imagine an agent standing in front of two closed doors. Behind one of the doors is a tiger and behind the other is alarge reward. If the agent opens the door with the tiger, then a large penalty is received (presumably in the form ofsome amount of bodily injury). Instead of opening one of the two doors, the agent can listen, in order to gain someinformation about the location of the tiger. Unfortunately, listening is not free; in addition, it is also not entirelyaccurate. There is a chance that the agent will hear a tiger behind the left-hand door when the tiger is really behindthe right-hand door, and vice versa [30].What is the best action-selection rule for this agent? By a standard POMDP, this problem can be modeled asfollows: The possible states of the environment are sl (meaning that the tiger is behind the left-hand door) and sr(behind the right-hand door). Assume that the agent’s initial belief in the states is that sl and sr are equally probable(i.e., Pr(sl) = Pr(sr ) = 0.5). The agent can choose its action among LEFT (open the left door), RIGHT (open the rightdoor), and LISTEN (listen to the tiger). The action LEFT results in +10 reward when the state is sr , but −100 when itis sl, while these rewards are reversed for the action RIGHT. The action LISTEN costs as much as −1 reward, but theagent obtains a noisy observation TL (meaning that the tiger is likely to be behind the left-hand door) or TR (the tigeris likely to be behind the right-hand door). If the state is sl, TL is observed with probability 0.85 and TR is observedwith probability 0.15 (i.e., Pr(TL|sl) = 0.85 and Pr(TR|sl) = 0.15), while we similarly have Pr(TR|sr ) = 0.85 andPr(TL|sr ) = 0.15.An action-selection rule for the agent is called a policy. A policy is called optimal when it maximizes the expectedtotal reward. In this example, the optimal policy is (1) choose the action LISTEN several times until the agent’s beliefthat the tiger is on the right (or left) side becomes sufficiently strong and then (2) choose the action LEFT (or RIGHT)accordingly. POMDP theory tells us how the optimal policy can be derived.POMDPs, however, cannot be used when their parameters (e.g., Pr(TL|sl) = 0.85) are not specified precisely. Theparameters remain imprecise for various reasons [5,13,32] including limited data, insufficient inference time, dis-agreement among experts [34,49], and model abstraction [12,20,23]. Here we mention four examples. First, supposethat Pr(TL|sl) is estimated by an experiment that examines the frequency with which TL is observed when the stateis sl. Such an estimate is subject to a statistical error. For this case, intervals (e.g., 95% confidence intervals) maybe used to express the uncertainty. Second, suppose that a human expert can be consulted to determine the value ofPr(TL|sl). The expert would determine the value by his or her own subjective belief; he or she might say that Pr(TL|sl)would be equal to 0.85. However, he or she might find it hard to explain why Pr(TL|sl) should be precisely 0.85 andnot 0.849 for example. Thus in this situation intervals can be used to express the expert’s belief more faithfully. Third,suppose that there are multiple experts consulted. Even if each expert could specify a precise value for each parameter,the values might differ from each other. In this case, a set of distributions may be adopted to express the disagreeduncertainty. For example, we have (Pr(TL|sl), Pr(TR|sl)) ∈ {(0.84, 0.16), (0.85, 0.15)} if one expert specified the dis-tribution (Pr(TL|sl), Pr(TR|sl)) as (0.84, 0.16), while another expert specified it as (0.85, 0.15). Last, suppose thatthe tiger problem is an abstracted version of a more complex problem. For example, the probability distribution ofobserving TL or TR, given sl, might actually also depend on the temperature of the sonic sensor. Suppose that if thetemperature is high (denoted by thigh), the distribution is (Pr(TL|sl, thigh), Pr(TR|sl, thigh)) = (0.84, 0.16). Similarly,if the temperature is low, the distribution is (Pr(TL|sl, tlow), Pr(TR|sl, tlow)) = (0.85, 0.15). The agent, however, maywant to neglect such a small dependence on the temperature. In this case, again a set of distributions may be adoptedto express the abstracted uncertainty as (Pr(TL|sl), Pr(TR|sl)) ∈ {(0.84, 0.16), (0.85, 0.15)}.Motivated by these examples, in this paper, we introduce POMDPs with imprecise parameters (POMDPIPs). Weconsider two cases. One is the interval case, in which each parameter is imprecisely specified by an interval, e.g.,Pr(TL|sl) ∈ [0.84, 0.86]. The other is the point-set case, in which each distribution is specified by a set of distributions,e.g., (Pr(TL|sl), Pr(TR|sl)) ∈ {(0.84, 0.16), (0.85, 0.15)}. In this paper, we will consider the parameter imprecision inthe state transition functions (i.e., the probability functions that model how a state is changed by each action) and the\fH. Itoh, K. Nakamura / Artificial Intelligence 171 (2007) 453–490455observation functions (i.e., the probability functions that model which observation is obtained). Other imprecisions,such as the imprecision in the reward function, remain to be considered in the future.Another motivation for the introduction of POMDPIPs arises from the fact that the POMDPs are computationallyexpensive to solve [36,42]. By solving a POMDP, we mean obtaining its optimal policy. Although several algorithmsthat can solve POMDPs in finite time [11,24,51,57,58] have been developed, within a given non-prohibitive time pe-riod, only relatively small-sized POMDPs can be solved by these algorithms. This high computational cost can be dueto the fact that the algorithms seek the optimal policy that strictly maximizes the expected reward. In many problems,however, such a strict optimization is meaningless, since the expected reward cannot be precisely evaluated becauseof the parameter imprecision. For such problems, it may often be sufficient to maximize the expected reward that isroughly estimated by using the imprecise parameters. Such rough optimization may require a lower computationalcost.Thus motivated, in this paper, we will formulate an optimality criterion for POMDPIPs in the following manner.We will begin by considering a hypothetical situation in which strict optimization can be performed for POMD-PIPs. To perform strict optimization, we need more information than POMDPIPs. Let us assume hypotheticallythat the agent can specify correct second-order beliefs (e.g., [19,41]), i.e., the beliefs in the models, where wedefine a model as a pair of the state transition function and the observation function. For instance, take",
            {
                "entities": [
                    [
                        2905,
                        2933,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1973–2000Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGeneralised arc consistency for the AllDifferent constraint:An empirical surveyIan P. Gent∗, Ian Miguel, Peter NightingaleSchool of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, UKa r t i c l ei n f oa b s t r a c tArticle history:Available online 17 October 2008Keywords:Constraint programmingConstraint satisfaction problemsGlobal constraintsAllDifferentThe AllDifferent constraint is a crucial component of any constraint toolkit, language orsolver, since it is very widely used in a variety of constraint models. The literature containsinference againstmany different versions of this constraint, which trade strength ofcomputational cost. In this paper, we focus on the highest strength of inference, enforcing aproperty known as generalised arc consistency (GAC). This work is an analytical survey ofoptimizations of the main algorithm for GAC for the AllDifferent constraint. We evaluateempirically a number of key techniques from the literature. We also report importantimplementation details of those techniques, which have often not been described inpublished papers. We pay particular attention to improving incrementality by exploitingthe strongly-connected components discovered during the standard propagation process,since this has not been detailed before. Our empirical work represents by far the mostextensive set of experiments on variants of GAC algorithms for AllDifferent. Overall, thebest combination of optimizations gives a mean speedup of 168 times over the sameimplementation without the optimizations.© 2008 Elsevier B.V. All rights reserved.1. IntroductionConstraints are a powerful and natural means of knowledge representation and inference in many areas of industry andacademia. Consider, for example, the production of a university timetable. This problem’s constraints include: the mathslecture theatre has a capacity of 100 students; art history lectures require a venue with a slide projector; no student canattend two lectures simultaneously. Constraint solving of a combinatorial problem proceeds in two phases. First, the problemis modelled as a set of decision variables, and a set of constraints on those variables that a solution must satisfy. A decisionvariable represents a choice that must be made in order to solve the problem. The domain of potential values associated witheach decision variable corresponds to the options for that choice. In our example one might have two decision variables perlecture, representing the time and the venue. For each class of students, the time variables of the lectures they attend mayhave an AllDifferent constraint on them to ensure that the class is not timetabled to be in two places at once. The secondphase consists of using a constraint solver to search for solutions: assignments of values to decision variables satisfying allconstraints. The simplicity and generality of this approach is fundamental to the successful application of constraint solvingto a wide variety of disciplines such as scheduling, industrial design and combinatorial mathematics [29].The AllDifferent constraint expresses that a vector of variables take distinct values. It is a crucial component of anyconstraint system, since it is very widely used in a variety of constraint models, for diverse problems such as quasigroupconstruction and completion, sports scheduling, timetabling and golomb ruler construction. The literature contains many* Corresponding author.E-mail addresses: ipg@cs.st-andrews.ac.uk (I.P. Gent), ianm@cs.st-andrews.ac.uk (I. Miguel), pn@cs.st-andrews.ac.uk (P. Nightingale).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.006\f1974I.P. Gent et al. / Artificial Intelligence 172 (2008) 1973–2000different versions of this constraint, which trade strength of inference against computational cost. Indeed, choosing anappropriate level of consistency is sometimes vital to solving a CSP efficiently [26]. Van Hoeve surveys various strengths ofinference [28], including the weak and fast pairwise decomposition described in Section 6.1.2, bound and range consistency,and generalised arc consistency (GAC). The classic GAC algorithm for the AllDifferent constraint is given by Régin [21]. Inthis paper, we focus on the highest strength of inference (enforcing GAC). Limiting ourselves to GAC allows us to studyvarious optimizations in great depth, but does mean that the scope of the paper does not include optimizations of boundsand range consistency algorithms.This work is an analytical survey of optimizations of the main algorithm for generalised arc consistency (GAC) for theAllDifferent constraint. While based on a survey of published optimizations, we extend the literature in three ways. First, weprovide extensive implementation details of the optimizations we cover. Such details are often omitted from initial publica-tions, for example for reasons of space. Providing such details should save future workers from having to reinvent the wheel.Second, we provide extensive empirical analyses to show the value or otherwise of the techniques we survey. Importantly,we are able to evaluate optimizations in combination with each other. Third, we go into particular detail on techniqueswhich have not been described in the literature before, and some new techniques we introduce here. In the former cate-gory, we show how to explore incrementality in strongly connected components during search. In the latter category, weintroduce methods for reducing the number of necessary propagations using dynamic triggers, and an optimization for thecase where variables are assigned.In Section 2 of this paper, we review key background material, present Régin’s algorithm at a high level, and surveyoptimizations for it that have been proposed in the literature. We discuss incremental matching, domain counting, theuse of a priority queue, staged propagation, processing strongly connected components independently, important edges,advisors, and fixpoint reasoning. In Section 3 we give implementation details for the algorithm. The detailed survey of keyimplementation issues is one of the contributions of this paper.In Section 4, we give extensive details of how to exploit strongly connected components (SCCs) to improve efficiency inAllDifferent propagation. In Régin’s algorithm, we find a set of SCCs in a graph formed from allowed values and a matchingbetween variables and values. Edges between distinct SCCs represent impossible values. As we move down a branch in thesearch tree, an SCC can only remain the same or split into new SCCs. Thus, when we remove a variable–value pair, weneed only study the individual SCC which contained the deleted variable–value pair. Since this may contain only a smallfraction of all the variables in the original constraint, we can greatly reduce the amount of work that this incrementalpropagation requires. This paper presents this technique in detail for the first time, since it has previously been in thefolklore rather than the literature. We show empirically that this is a very valuable optimization in Section 6. We also givea further, minor, optimization to the computation of SCCs, for the common case that we have assigned a variable to avalue.In Section 5, we show how to exploit “dynamic triggers” for GAC AllDifferent. In a standard algorithm we have to do somework when any value is deleted. Katriel proved that there is a small set of variable–value pairs such that no propagation ispossible if any other value is deleted [16] and gave a probabilistic algorithm to exploit the idea. We extend this idea to atechnique which maintains GAC deterministically, while reducing the number of times the propagator is called. This can beimplemented in Minion using dynamic triggers [10]. We show in fact marginally better performance on a version where weimplement dynamic triggers internally within the AllDifferent propagator. This has the added advantage that it is portableto solvers which do not have a dynamic trigger infrastructure. We give full details in Section 5 with experimental results inSection 6.4. We conclude that the technique is of benefit mainly where GAC AllDifferent performs badly, so it may not begenerally useful.Our empirical work in Section 6 represents by far the most extensive set of experiments on variants of GAC algorithmsfor AllDifferent. We implement most (although not all) of the optimizations we have surveyed. Implementations are basedon the state-of-the-art Minion constraint solver [9]. Our comparisons are never with a straw-man implementation, as alltechniques use the same implementation except for the addition of optimizations or the replacement of one techniquewith another. Our results make a number of points. In some cases, we confirm standard advice from the literature onhow to implement GAC AllDifferent. We show in Section 6.3 that incremental matching can reduce runtime, and that asan expensive constraint the AllDifferent constraint should be propagated in a separate queue after cheaper constraints.Also, we show that it is worthwhile to combine the GAC AllDifferent algorithm and a cheaper algorithm into a hybridstaged propagator. Against existing advice from the literature, we show that a simpler matching algorithm can be moreeffective than a more complex one. And, although not reported in the literature before, we show that exploiting stronglyconnected components is particularly beneficial, with an average speedup of about 3 times. We summarise our advice tofuture implementers in Section 7.Compared with a vanilla implementation of Régin’s algorithm, our best combination of techniques is always better thannot using them, and can speedup search by thousands of times. We get a mean speedup of 168 times over the vanillaimplementation. We hope that our survey will help other ",
            {
                "entities": [
                    [
                        3803,
                        3831,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 274 (2019) 44–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDistributional semantics of objects in visual scenes in comparison to textTimo Lüddecke a,∗Minija Tamosiunaite a,b, Florentin Wörgötter aa Georg-August-University Göttingen, Third Institute of Physics, Germanyb Vytautas Magnus University, Faculty of Informatics, Lithuania, Alejandro Agostini a, Michael Fauth a, a r t i c l e i n f oa b s t r a c tArticle history:Received 24 July 2017Received in revised form 31 May 2018Accepted 4 December 2018Available online 7 February 2019Keywords:Object semanticsVision and languageSemanticsDistributional hypothesisComputer visionThe distributional hypothesis states that the meaning of a concept is defined through the contexts it occurs in. In practice, often word co-occurrence and proximity are analyzed in text corpora for a given word to obtain a real-valued semantic word vector, which is taken to (at least partially) encode the meaning of this word. Here we transfer this idea from text to images, where pre-assigned labels of other objects or activations of convolutional neural networks serve as context. We propose a simple algorithm that extracts and processes object contexts from an image database and yields semantic vectors for objects. We show empirically that these representations exhibit on par performance with state-of-the-art distributional models over a set of conventional objects. For this we employ well-known word benchmarks in addition to a newly proposed object-centric benchmark.© 2019 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionIt remains a matter of debate, which aspects constitute the meaning of a word or of an object in a scene and the term meaning is heavily discussed in different fields. Here we are specifically concerned with the distributional representation hypothesis by Harris [17], which states that the company of a word determines its meaning (distributional semantics). This study sets out to test this hypothesis on images.For the definition of meaning in the above sense, natural language processing (NLP) uses semantic vectors, which repre-sent word-neighborhoods in a sentence. This approach has proven to be useful in many different applications, e.g. for text translation between different languages [27], for determining the sentiment of a sentence [33] and for question answering [39]. Thesaurus generation, spelling correction, and query expansion count among further applications discussed by Turney and Pantel [37].Analogously, context in visual scenes is also important for defining the meaning of objects. It might serve as a basis for a variety of approaches in image understanding that involve interactions across multiple objects, e.g. determining useful robotic actions or finding task-relevant objects in a scene. Thus, in this work, inspired by NLP approaches, we develop methods to obtain semantic vector representations of objects by considering their respective contexts in real world scenes that are composed of multiple objects.* Corresponding author.E-mail address: timo.lueddecke@phys.uni-goettingen.de (T. Lüddecke).https://doi.org/10.1016/j.artint.2018.12.0090004-3702/© 2019 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fT. Lüddecke et al. / Artificial Intelligence 274 (2019) 44–6545Fig. 1. By assessing object co-occurrences and visual features we obtain semantic vectors for objects (right, actual output).Texts and scenes are akin structures, both being composed of many individual but inter-related constituents: words or objects. The location of a word in a sentence but also that of an object in a scene is subject to some constraints. On the one hand, these constraints can be fundamental, e.g. imposed by grammar or physics. The violation of these constrains will render a sentence wrong or make a scene impossible or nonsensical. E.g., grammar forbids two subsequent articles as much as a chair can not stand on the ceiling due to gravity.On the other hand, obeying only grammatical constraints does not guarantee that a sentence will make sense and the laws of physics will also not guarantee that a room has a useful structure. For making sense also the respective neighbor-hoods need to be appropriate, i.e. the context in which words are used or the arrangement of items in a room.Furthermore, context can help to disentangle multiple meanings of words or objects. For example in natural language, the meaning of a polyseme depends on its context and, similarly, multi-functional objects are employed differently depending on the situation. In the same way that e.g. the word “board” acquires a particular sense (out of many) by contextual words, objects surrounding a coffee cup in a scene constrain the set of useful actions involving the cup (e.g. at a coffee klatsch v.s. when the same cup is in the sink with dirty dishes).However, it is only text analysis where there has been a long history of approaches that address the question of distribu-tional semantics and that derive the meaning of a word, at least to some degree, from context. Interest in these approaches recently revived by the success of large-scale methods [28,29] exhibiting remarkable performance in judging similarity or analogy of concepts. By contrast, little work has been done on obtaining meanings of objects by considering their scene contexts. This should, however, be possible, in particular due to the large-scale data-sets that have recently been published in the computer vision community, which allow now for the investigation of distributed semantics in the domain of objects. Therefore, it seems justified to investigate the learning of semantic vectors not only of words but also of objects.In this work we study the hypothesis that the spatial context contributes to the meaning of an object in a scene, anal-ogously to surrounding words defining the meaning of a word. To gather evidence we design an algorithm that extracts semantic vectors from scenes as visualized in Fig. 1. We aim at analyzing a big enough set of images to arrive at a represen-tation, where semantic vectors for similar objects would group together. Fig. 1 schematically shows this for cake, spoon, forkand knife, which group together (see schema with object names) but remain separate from bicycle, motorcycle and car, which form a different group. Just from common sense one would hope to obtain such clustering results, but there are obvious differences between sentences and scenes. In contrast to a scene, a text is a linear structure, i.e. each word has a predeces-sor and a successor. Thus, while there is the straightforward assumption that the distributional hypothesis should also hold for images, it remains quite a question whether or not the more complex 3D layout of the visual world (or its 2D image projections) might not render context relations too spread out? Hence, we ask: Will scenes provide equally strong context relations than text? In this paper we address this question comparing a large set of different NLP as well as image-based methods.1.1. Overview of the approachA schematic introduction to our approach in comparison to linguistic approaches is presented in Fig. 2. Common distri-butional models (top) take natural language text corpora, determine word sequences, and generate context vectors by word co-occurrence. A context vector describes the surrounding of individual entities (such as words) by an array of real numbers. Different methods are used to combine such vectors so that finally semantic vector representations emerge for different con-cepts that can be compared. In essence, our approach (middle) is similar, but it only considers concepts that are objects. We take scene datasets and extract different image descriptors, which are (see numbering in the figure): 1) Human-assigned object labels, 2) object labels automatically obtained by applying an RCNN [14] to detect objects, and 3) CNN activations, which are features generated using pre-trained convolutional neural networks. From all three approaches we extract context vectors for each object in each scene. Context vectors are then merged together to create the unique semantic vector for a specific object class. This allows directly comparing not only the three types of descriptors but also benchmarking our results against automatic NLP-based methods (top) as well as against human rater-based methods (bottom). This is done by measuring semantic distances between objects (the inverse of semantic similarity) in the respective semantic vector spaces.\f46T. Lüddecke et al. / Artificial Intelligence 274 (2019) 44–65Fig. 2. Flow diagrams of the analyzes performed here with standard natural language processing, our new approach, as well as based on human labeling. In red, we show the abbreviation of the different analysis methods used (for descriptions see Methods). (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)1.2. ContributionsWe propose a simple algorithm to compute semantic vectors for object classes in segmented images and extensively compare this with existing (text-based) methods. This paper is to our knowledge the first to specifically focus on objects in scenes. In addition to the analysis of existing data, we also collected a dataset of similarity and relatedness judgments for 250 object pairs from 20 raters specifically slanted towards everyday objects.Our analysis shows that the obtained image-based representations are on par with existing text-based representation methods. Quality can be further improved by concatenating different context models. These findings indicate that not only text might serve as a basis for distr",
            {
                "entities": [
                    [
                        3312,
                        3340,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 51–71Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic of delegationTimothy J. Norman a,∗, Chris Reed ba Department of Computing Science, University of Aberdeen, Aberdeen AB24 3UE, Scotland, UKb School of Computing, University of Dundee, Dundee DD1 4HN, Scotland, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 29 October 2008Received in revised form 1 October 2009Accepted 4 October 2009Available online 13 October 2009Keywords:DelegationGroupsImperativesResponsibilityAgent communication1. IntroductionDelegation is a foundational concept for understanding and engineering systems thatinteract and execute tasks autonomously. By extending recent work on tensed actionlogic, it becomes possible to pin down a specific interpretation of responsibility witha well specified semantics and a convenient and intuitive logic for expression. Oncedescriptions of direct agent responsibility can be formed, there is a foundation uponwhich to characterise the dynamics of how responsibility can be acquired, transferred anddischarged and, in particular, how delegation can be effected. The resulting logic, designedspecifically to cater for responsibility and delegation, can then be employed to offer anaxiological and semantic exploration of the related concepts of forbearance, imperativesand group communication.© 2009 Published by Elsevier B.V.Delegation is a concept that pervades agent-based computing — tasks such as the purchase of goods within an electronicinstitution may be delegated to a software agent acting on behalf of a user [14,16], a goal may be delegated from oneagent to another each representing different commercial organisations via, for example, the Contract Net protocol [49], oran agent representing a manager within one organisation may, by virtue of their organisational position, delegate a taskto an agent representing a subordinate [33]. Understanding the nature and complexities of delegation, therefore, has thepotential to impact upon a wide audience within AI. In this paper we address the problem of understanding delegationdirectly by presenting a responsibility-based semantics of delegation (Section 2), that provides for an axiological account ofhow responsibility is transferred during delegation. With the basic mechanics of delegation in place, several tricky cases arethen examined in detail, including:(1) the interaction between delegation and time (and specifically, how axioms of delegation might be extended in a tensedlogic) (Section 3.1);(2) the relationship between responsibility and the concept of forbearance (and in particular, whether the Refref conjec-ture [2], by which activity is claimed to be equivalent to refraining from refraining, is a defensible axiom) (Section 3.2);and(3) the way in which group-addressed communication can effect delegative transfer of responsibility (and specifically, howdistributive and collective responsibility [43] is composed from the responsibilities of the individuals in a group) (Sec-tion 3.3).* Corresponding author.E-mail addresses: t.j.norman@abdn.ac.uk (T.J. Norman), chris@computing.dundee.ac.uk (C. Reed).0004-3702/$ – see front matter © 2009 Published by Elsevier B.V.doi:10.1016/j.artint.2009.10.001\f52T.J. Norman, C. Reed / Artificial Intelligence 174 (2010) 51–71Finally, with a rich account of delegation in place, we explore how imperative communication can be used to executedelegation, how responsibility is acquired as a result, and how it can be discharged through appropriate action meeting theconstraints of whole-hearted satisfaction [23] (Section 4).2. FoundationThe first step in characterising delegation is to construct a model of agent responsibility, so that the former can bedefined as a special case of the latter in which particular actions (often communicative actions) lead to a transfer of re-sponsibility. Such a model needs to tie together agent intentions, actions, and states of the world. Elsewhere [42] we haveargued that to handle this richness competently, it is necessary to adopt an approach that represents both states and eventsas first class objects. The argument there, and subsequent exploration of the system that results, leans heavily on founda-tional work carried out by Hamblin [23] in his investigation of imperatives. In this section we summarise a logic designed tocapture the nature of the imperative based upon Hamblin’s Action-State Semantics. The logic captures, at both the semanticand syntactic levels, the important ontological distinction between ‘responsibility for the achievement of a state of affairs’(captured by the modality S) and ‘responsibility for the execution of an action’ (captured by the modality T). This is one ofthe key distinguishing features of the language, which we refer to as ST.2.1. SyntaxIn presenting the syntax of our language, ST, we begin by defining the set of well-formed formulae, then briefly discussaxioms and rules of inference of the modalities S and T and of a standard Peircean tense logic which is used to enable theexpression of tensed responsibility formulae. This, along with the Hamblinian semantics of ST summarised in Section 2.2,lays the groundwork for the detailed analysis of the nature of delegation presented in Section 3.Basic atoms of the language ST include states of affairs, referred to using upper case Roman letters ( A, B, C , . . . ), actions,which are referred to using lower case Greek letters (α, β, γ , . . . ), and agents, for which we use x, y, . . . . We denote that aspecific agent, x, executes action α in the following manner: αx. Where the agent of an action is not specified, it is assumedthat the action is carried out by some agent but it is not important which one.The modalities S and T are relativised to specific agents and refer to state formulae and event formulae respectively. Inthis way, Sx A refers to agent x being responsible for the achievement of the state of affairs A, and Txα refers to x beingresponsible for the execution of action α. Note that these modal statements do not specify any particular action for agent x.In satisfying Txα, for example, agent x may order some other agent, y, to carry out α.Any sentence in the language may be tensed through the use of the modalities G (always true in all futures) and H(always true in all pasts), and their respective duals, F (true at some point in a possible future) and P (true at some point ina possible past). Tensed sentences are S-formulae; to say that something will be true, or that some action has been done,etc. is a state of affairs. It is, however, entirely reasonable to permit tense operators to range over both states and events:states of affairs may have held in the past, and events may happen in the future, etc.We may now define the well-formed formulae of our language ST. The basic atoms of our language are divided intotwo classes: (i) event formulae — those that consist entirely of propositional expressions of action (bound or unbound), and(ii) state formulae — all others. All such basic atoms are wffs. By conventional Propositional Logic (PL), for any two wffs, φand ψ , that are event formulae, φ ∨ ψ , φ ∧ ψ , φ → ψ and ¬φ are also wffs that are event formulae. Similarly for any twowffs that are state formulae, any PL combination of them is also a wff that is a state formula. For the action modalities,any wffs that are event formulae can be used to form a further wff with the T modality: Txα, Txαx, Tx(α y ∨ β), etc., whichare themselves state formulae. Any wff that is a state formula can be used to form a further wff with the S modality Sx A,SxT yαz, etc. that are state formulae. Finally, for any ψ that is either an event formula or a state formula, Gψ , Hψ , Fψ andPψ are also wffs that are state formulae.The logic of modality Sx is that of a regular modal system of type RT [10, p. 237]. This is the smallest system containingall axioms of Propositional Logic and closed under the rule of inference RE:REA ↔ BSx A ↔ Sx Bwith the additional axiom T, which is characteristic of logic of successful actionTSx A → Aand, of course, the distribution axiom K, which is minimally true of all modal logicsKSx( A → B) → (Sx A → Sx B)Unlike other models of agentive action [3,11,26] however, we include neither the rule of necessitation ( A/Sx A) nor that ofanti-necessitation (¬ A/¬Sx A). Consequently the logic of Sx is non-normal. A key advantage of including neither of theseaxioms is that we may include the equivalence R without introducing inconsistency. Axiom R captures the intuition that ifan agent is responsible for achieving A and responsible for achieving B then it is responsible for achieving the conjunction of\fT.J. Norman, C. Reed / Artificial Intelligence 174 (2010) 51–7153Gφ → ψ → (Gφ → Gψ)Hφ → ψ → (Hφ → Hψ)φ →(cid:3)Hφ → (Gφ → GHφ)(cid:2)Gφ → FφHφ → PφGφ → GGφHφ → HHφFig. 1. Axioms of a Peircean tense logic.these states, and that if an agent is responsible for achieving the conjunction of A and B then it is responsible for achievingeach conjunct. In the logic of action specified by Jones and Sergot [26], for example, including axiom Sx( A ∧ B) → Sx A ∧ Sx Balong with the rule of anti-necessitation will lead to a contradiction. Axiom R for modality Sx is:RSx( A ∧ B) ↔ Sx A ∧ Sx BFinally, we include axiom D in the logic of Sx, which captures the intuition that an agent cannot be responsible for theachievement of contradictory states of affairsDSx A → ¬Sx¬ AThe characterisation of modality Tx is identical to that of Sx; both being regular modal systems of type RT. It should benoted, however, that these modalities operate over different worlds in their interpretation (see Section 2.2).To enable us to explore the interpretation of responsibility over time, we require the use of a logic of time. For ourpurposes we adopt a simple Peircean tense logic. In this logic of time, there are two basic modalities: G and H. Their dualswith respec",
            {
                "entities": [
                    [
                        3271,
                        3299,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1122–1152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe local geometry of multiattribute tradeoff preferencesMichael McGeachie a,∗, Jon Doyle ba Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USAb Department of Computer Science, North Carolina State University, Raleigh, NC 27695-8206, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 2 March 2009Received in revised form 10 August 2010Accepted 10 August 2010Available online 2 December 2010Keywords:Decision theoryPreference representationMultiattribute tradeoffsCeteris paribus reasoningExisting representations for multiattribute ceteris paribus preference statements haveprovided useful treatments and clear semantics for qualitative comparisons, but havenot provided similarly clear representations or semantics for comparisons involvingquantitative tradeoffs. We use directional derivatives and other concepts from elementarydifferential geometry to interpret conditional multiattribute ceteris paribus preferencecomparisons that state bounds on quantitative tradeoff ratios. This semantics extends thefamiliar economic notion of marginal rate of substitution to multiple continuous or discreteattributes. The same geometric concepts also provide means for interpreting statementsabout the relative importance of different attributes.© 2010 Elsevier B.V. All rights reserved.1. Building value functions from preferences and tradeoffsKnowledge of someone’s preferences can be used to make decisions on their behalf. Following the work of von Neumannand Morgenstern [35], direct and complete elicitation of preferences and their representation in the form of utility functionshas enabled decision analysts to advise decision makers on how to decide specific questions. To go beyond manual construc-tion of specific decision models, and to automate decision analysis in a way that applies in a broad range of mundane andfleeting human activities, one must find richer representations that permit making decisions with imprecise, incomplete,and accumulating information about preferences.We pursue this end by presenting semantics for several different types of preference statements that build on earliersemantics for ceteris paribus preferences (preference other things being equal) [38,14]. We focus on quantitative tradeoffstatements, such as “having a CPU speed of 3 GHz is at least twice as important as having 4 GB memory and a 250 GB diskin my new computer purchase.” Such statements say that some outcomes that satisfy one condition (CPU speed of 3 GHz)are preferred to some outcomes that satisfy another condition (4 GB memory and 250 GB disk), and also bound belowhow much better the former are than the latter. We provide semantics for numerous types of statements of this charac-ter, including multiattribute tradeoffs that relate more than one attribute at a time; tradeoffs over discrete or continuousdomains; conditional or unconditional tradeoffs; and quantitative or purely qualitative comparisons. We also treat relatedtypes of statements about attribute importance, such as “increasing CPU speed is at least twice as important as increasingmemory and disk size in my new computer purchase.” Such statements say that the weight given to some attribute orattributes in a decision should be greater than that given to other attributes.Computing expected utility of actions requires a numerical utility or value function that represents preferences in thesense that the numerical representation assigns a greater value to one outcome than to a second outcome if the preferencestatements entail that the first outcome is preferred to the second. Building on earlier constructions [32], we accompany* Corresponding author.E-mail addresses: mmcgeach@csail.mit.edu (M. McGeachie), Jon_Doyle@ncsu.edu (J. Doyle).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.014\fM. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521123the semantics for ceteris paribus preferences statements with companion algorithms for compiling utility or value functionsfrom collections of multiattribute tradeoff statements.1.1. Decision-analytic methodologyOur methodology seeks to extend traditional decision analysis by relaxing assumptions and restrictions on the form andcharacter of the preference information captured in the preference acquisition process. In particular, we aim for represen-tations of preference information that permit automation of the process of constructing decision models starting at earlierpoints in the process than has been possible with traditional modeling methods.In traditional decision analysis methodology [33,25], a human decision analyst does considerable work in understandingand analyzing a decision informally before the point at which the tools of traditional decision theory [35,34,19] are broughtto bear. The decision analyst first interviews the decision maker about what dimensions or attributes of the decision are ofconsequence. The decision analyst then assesses utility functions on each of these dimensions by standard gambles or othermeans. This assessment requires the decision maker to think carefully about the upper and lower bounds of each dimension,to consider his or her attitude toward risky hypothetical choices, and to determine which attributes are utility independentof other attributes. The relative importance of each dimension must then be assessed, at which point the decision analystcan combine the results into a multiattribute utility function that models the preferences of the decision maker.This traditional methodology has the virtue of producing considered and complete decision models appropriate to thedecision at hand. It also, however, demands much effort on the part of the decision maker by requiring careful attentionto complexities of the decision that might not have been considered previously, and that perhaps should not be answeredimmediately with only the information currently on hand. All this makes the interviewing and analysis steps lengthy andtime-consuming in many cases, so that one mainly applies decision analysis in detail to repetitive decisions in which the costof analysis can be amortized over many individual decisions, and to one-off decisions of great import, such as governmentalpolicy or complicated life-or-death medical decisions.We seek to begin the process of formalization earlier than with traditional decision analytic techniques. The traditionalformal techniques apply once the analyst has done much of the work needed to identify the dimensions along which pref-erences vary. Our preference semantics allows one to formalize partial information about preferences. Such information maybe stated and captured naturally without any requirement that the stated preferences involve independent or fundamentalattributes, and without explicit indications of utility independence or preferential independence. In our view, such inde-pendence relations properly reflect conclusions reached during the analysis of some decision, as inferences from the wholebody of stated conditions on preferences, rather than presuppositions underlying the entire analysis. We thus address theidentification of dependencies and independencies among attributes in our numerical-compilation methods, which performanalyses that yield model-structuring conclusions akin to those reached by a human analyst at the point at which thehuman analyst begins quantitative assessment procedures. Our approach thus supports protracted incremental deliberationprior to the introduction of traditional formal decision analysis, and helps automate the initial steps previously relegated toinformal reasoning that produce the formal framing of a problem.1.2. IllustrationTo illustrate these ideas, we describe a fictitious scenario in which Mike, a human, informs an automated personalshopping agent of his preferences so that it can watch for online deals on computer hardware he may find attractive. Mikewill buy a new laptop if there is a good deal on one he likes. Mike does not try to tell the agent all about his preferences atthe start, as without detailed knowledge of what is currently available he might not yet have developed definite preferencesregarding the options. Mike instead gives his agent information about his preferences bit by bit as he learns more aboutwhat preferences are germane.His agent retrieves a list of laptops for sale at various vendors’ websites. Seeing the list, Mike decides that, with respectto price and speed, a $1500, 3 GHz machine is preferable to a $2000, 3.4 GHz machine, other things being equal. Thispreference sets up a tradeoff between price and speed, so the agent then filters out the results that are very expensive eventhough they are somewhat faster than average. Thinking about it a little more, Mike decides that the first machine is muchbetter than the other one, in fact that it is at least five times better.Looking at some of the expensive options with many attractive features, Mike then realizes that adding features andadding ounces of weight at the same time is not what he wants. Mike tells the agent that Weight is more important thanPrice. The agent readjusts its evaluation of options, and shows more laptops ordered by weight, with several attractivelight-weight options at the top of the list.Mike sees that there are some good machines available that are light, moderately powerful, and within his price range,but realizes that he must decide how big a screen and what resolution he needs to do his work on the road, since thisscreen on a 4.5 pound machine for $1700 is better than aadversely impacts the price and the weight. Mike decides a 12(cid:3)(cid:3)screen on a 6 pound machine for $1800. This suffices to order the remaining options in a way that satisfies Mike, ",
            {
                "entities": [
                    [
                        4021,
                        4049,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 416–427Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom systems to logic in the early development of nonmonotonicreasoningErik SandewallDepartment of Computer and Information Science, Linköping University, Linköping, Swedena r t i c l ei n f oa b s t r a c tArticle history:Available online 8 April 2010Keywords:Nonmonotonic reasoningFrame problemTruth maintenanceDefeasible inheritance history of AIThis note describes how the notion of nonmonotonic reasoning emerged in ArtificialIntelligence from the mid-1960’s to 1980. It gives particular attention to the interplaybetween three kinds of activities: design of high-level programming systems for AI, designof truth-maintenance systems, and the development of nonmonotonic logics. This wasnot merely a development from logic to implementation; in several cases there was adevelopment from a system design to a corresponding logic. The article concludes withsome reflections on the roles and relationships between logicist theory and system designin AI, and in particular in Knowledge Representation.© 2010 Elsevier B.V. All rights reserved.1. John McCarthy and nonmonotonic reasoningNonmonotonic reasoning has emerged as one of the most central concepts in artificial intelligence. It is nowadays anaccepted notion in formal logic, and several other disciplines address knowledge representation problems where nonmono-tonic reasoning would seem to have a natural role. John McCarthy is of course the founding father that both initiated thisdevelopment and gave it a large part of its structure and direction.The purpose of the present article is to describe the beginnings of nonmonotonic reasoning (nonmon) in Artificial Intel-ligence, that is, the initial development that preceded and led up to the special issue of the Artificial Intelligence journal in1980 whereby nonmonotonic reasoning was established as a topic of its own, and where circumscription (which is arguablythe major approach to nonmonotonic reasoning today) was first presented in a journal article. I participated in the develop-ment of the field during those early years, and the present article is based partly on my recollections of my own activitiesas well as those of fellow researchers, and partly on communication with these during the preparation of this article.Defeasible reasoning has also been studied in philosophical logic during about the same time as in artificial intelligence.Although there has been some interaction between the fields more recently in this respect, that was not the case duringthe early years. The present article will therefore be strictly restricted to the early development within A.I. research.Some of the early publications on nonmon are quite well-known, in particular the article “Some philosophical prob-lems from the standpoint of Artificial Intelligence” by John McCarthy and Patrick Hayes in the 1968 Machine Intelligenceworkshop [23]. Other work during those formative years included the introduction of the thnot operator in Carl Hewitt’sPlanner system [13,14], and the first proposal for a default rule for the frame problem, in my article at the 1971 MachineIntelligence workshop [35].These early articles are manifestations of the search process where several researchers tried different mechanisms forobtaining nonmonotonic reasoning and different ways of understanding the knowledge representation problems where itseems to be required. One important aspect of that search process is that logic-based approaches and computationallybased approaches were tried concurrently and with frequent interactions, and truth maintenance became an important issueE-mail address: erisa@ida.liu.se.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.013\fE. Sandewall / Artificial Intelligence 175 (2011) 416–427417from the systems-oriented point of view. This early connection between logic and systems is less visible today, and in factthe logic-based work dominates among contemporary research contributions. It may however be worthwhile not to let thesystems aspect fall into oblivion since truth maintenance may well reemerge as an important issue, in particular in cognitiverobotic systems.In spite of the diversity of approaches that were tried, there is actually a single starting-point for this early work, namely,John McCarthy’s paper on Programs with Common Sense. This short article was presented at the Teddington Conference onthe Mechanization of Thought Processes in December 1958 and it was circulated and reprinted repeatedly, in particular aspart of a book [22]. It is important as a starting-point for two reasons. This paper is recognized as the initial proposal forthe use of formal logic as the formal and theoretical framework for artificial intelligence systems. However, it also makesthe proposal for a deliberating software system, that is, a system that works continuously at interpreting its inputs andanalyzing its possible futures and its future actions. McCarthy’s proposal was to organize such a system in such a waythat it continuously draws conclusions from carefully selected subsets of its available knowledge, including conclusions thatspecify actions to be performed by the system. In this way a deliberating system differs from a reactive system that merelyresponds to queries or requests, and which idles when there is no such input. McCarthy used the term the advice taker forthe proposed first version of such a software system, with restricted capabilities.The logicist aspect of the Advice-taker paper has had a strong influence on what we know today as research in knowl-edge representation. The deliberating-system aspect is also important since continuous “forward” reasoning from known orbelieved facts leads to the need for truth maintenance in any system where default conclusions are permitted. It is thereforefundamental for cognitive robotics, and more generally for every cogitating system that is set to operate autonomously insome environment.2. Ambiguity logicThe Advice-taker proposal, as well as the ongoing discussion at the Stanford AI Lab in the mid-to-late 1960’s, inspiredmy own work on a representational language called “ambiguity logic,” and on its implementation as a programming systemcalled Lisp A. This language belonged to the same category of so-called “programming languages for AI research” [1] asPlanner and QA4. It was more or less concurrent with Planner but independent of it, and it preceded QA3 and QA4 intime. Several aspects of nonmonotonicity started in the context of Lisp A, so therefore it will be described in some detailhere.The ‘logic’ part of this work started from a suggestion in another one of McCarthy’s early articles [18], to the effect thatit would be useful for representation purposes to have “ambiguous” functions, that is, functions with more than one value.An obvious example is the function “the wife of” in a multicultural context. In ambiguity logic, one would represent sucha function in more conventional terms, as follows. Consider an application domain containing some kind of identifiableobjects where it is natural to have functions from object to object, but for some arguments the function has no value, andfor some other arguments it may have several values. Terms in ambiguity logic are interpreted as sets of such objects. Thereare no expressions for individual objects, only for sets of them, but instead there is a special predicate * of one argumentthat is true iff the argument is a singleton set, having exactly one member. The subset and subset-equal relations are usedas usual.Furthermore, for each ambiguously valued “function” f on the object level that the application offers, one introduces acorresponding function F on the set level, where (F A) is the set of all objects that are a value of the function f applied tosome member of A. Set-level functions of more than one argument are defined similarly. Obviously every such function F ismonotonic with respect to the subset relation in each of its arguments. The basic concept in ambiguity logic was thereforethe subset relation on sets of objects, rather than the use of predicates as they occur in predicate logic. There is an evidentsimilarity with modern description-language representations.Predicates on the object level are considered as functions whose value is one of the two objects T or F; consequentlytheir counterparts on the set level have four possible values.In addition to the monotonic functions, including predicates, that are constructed from object-level counterparts, it isconvenient to also have some special functions that are not monotonic. The subset relation itself should only be consideredto have the value {T} or {F} and is not monotonic, and the same holds for the * predicate in its single argument.Quantification can be expressed using the subset relation: an object-level predicate p is true for all members of a set A iff(P A) ⊆ {T}, and it is true for some member of the set iff {T} ⊆ (P A). The generalization to predicates of severalarguments is trivial. Implication can be handled in a similar fashion.Expressions of the form { f (x) | x ∈ A} had a counterpart in ambiguity logic where one could write a function as(rho (x)(F x))If R is this function, then (R A) denotes the union of all (F Ai) for all singleton subsets Ai of A. The reason for expressingthis with a lambda-expression-like construct was that one can then write recursive definitions very conveniently.One use of the rho operator was for writing quantified expressions. For example, if P was a predicate and the statements((rho (x)(P x)) A) ⊆ {T}\f418E. Sandewall / Artificial Intelligence 175 (2011) 416–427C ⊆ A(* C)had been asserted, so that in particular C was known to be a singleton subset of A, then the instantiation of the “quantified”statement was obtained as follows and using the monotonicity of the rho-exp",
            {
                "entities": [
                    [
                        3823,
                        3851,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 209 (2014) 11–28Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcept drift detection via competence modelsNing Lu, Guangquan Zhang∗, Jie LuDecision Systems & e-Service Intelligence (DeSI) Lab, Centre for Quantum Computation & Intelligent Systems (QCIS), Faculty of Engineeringand Information Technology, University of Technology, Sydney, PO Box 123, Broadway, NSW 2007, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 1 November 2012Received in revised form 16 October 2013Accepted 9 January 2014Available online 10 January 2014Keywords:Concept driftCompetence modelCase-base maintenanceIncremental supervised learningClassificationDetecting changes of concepts, such as a change of customer preference for telecomservices, is very important in terms of prediction and decision applications in dynamicenvironments. In particular, for case-based reasoning systems, it is important to knowwhen and how concept drift can effectively assist decision makers to perform smartermaintenance operations at an appropriate time. This paper presents a novel method fordetecting concept drift in a case-based reasoning system. Rather than measuring the actualcase distribution, we introduce a new competence model that detects differences throughchanges in competence. Our competence-based concept detection method requires no priorknowledge of case distribution and provides statistical guarantees on the reliability of thechanges detected, as well as meaningful descriptions and quantification of these changes.This research concludes that changes in data distribution do reflect upon competence.Eight sets of experiments under three categories demonstrate that our method effectivelydetects concept drift and highlights drifting competence areas accurately. These resultsdirectly contribute to the research that tackles concept drift in case-based reasoning, andto competence model studies.© 2014 Elsevier B.V. All rights reserved.1. IntroductionLearning under concept drift poses an additional challenge to existing learning algorithms. Instead of considering all thepast training data, or making a stationary distribution assumption [1–3], an effective learner should be able to track thesechanges and quickly adapt to them [4]. Otherwise, as concept drifts, the induced pattern may not be relevant to the newdata [5,6], which may result in an increasing number of errors [7].The issue of concept drift refers to the change of distribution underlying the data [4,8]. More formally, the problem canbe framed as follows. If we denote the feature vector as x and the class label as y, then the data stream will be an infinitesequence of (x, y). If the concept drifts, it means the distribution of p(x, y) is changing between the current data chunk andthe yet-to-come data. If we decompose p(x, y) into the following two parts as p(x, y) = p(x) × p( y|x), we could say thereare two sources of concept drift: one is p(x), which evolves with time t, and can also be written as p(x|t), and the other isp( y|x), the conditional probability of feature x [2].Concept drift can be categorized into two basic types: virtual concept drift (or drift in data distribution), and real conceptdrift (or drift in decision concepts) [8]. Other kinds of concept drift have also been defined and discussed; for example, basedon the extent of drift, Stanley [9] mentioned three kinds of drift: sudden drift, moderate drift and slow drift. Based on classdistribution, Forman [10] classified concept drift into three categories: shifting class distribution – shifting the distributionamong categories but remaining stable within a given class; shifting sub-class distribution – shifting distribution sub-classes* Corresponding author.E-mail addresses: Ning.Lu@uts.edu.au (N. Lu), Guangquan.Zhang@uts.edu.au (G. Zhang), Jie.Lu@uts.edu.au (J. Lu).0004-3702/$ – see front matter © 2014 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2014.01.001\f12N. Lu et al. / Artificial Intelligence 209 (2014) 11–28within a category, but remaining stable within a given sub-class; and fickle concept drift – individual cases may take ondifferent ground truth labels at different times. Zhang et al. [2] defined and analyzed two kinds of concept drift in theirstudies: loose concept drifting, in which the genuine concepts remain relatively stable, whereas the vision of the drift ismainly caused by the biased observation of instances; and rigorous concept drifting, in which the genuine concepts undergocontinuous change, although such changes can worsen in the face of biased observation. Tsymbal et al. [11] discusseda special scenario of concept drift called local concept drift, by which they mean that the change of concept or datadistribution occurs only in some regions of the instance space.Based on the literature, many learning algorithms have been used as base models to handle concept drift. These includerule-based learning [4,8,12], decision trees and their incremental versions [5,13,14], info-fuzzy networks [15], clustering[16], support vector machines [17], and case-based reasoning (CBR) [11,18–20]. Among them, the CBR method has threereported advantages for handling the concept drift problem [21]. First, CBR performs well with disjointed concepts. Second,CBR, as a lazy learner, is easy to update. Third, CBR allows easy sharing of knowledge for particular types of problems,making it easier to maintain multiple distributed case-bases. Therefore, this study focuses on concept drift detection forCBR.According to a literature review [22], the first attempt to handle concept drift with the case-based technique was IB3[20], which discards noisy and outdated cases by monitoring each case’s accuracy and retrieval frequency. IB3 has beencriticized for being suitable only for gradual concept drift, and for its costly adaptation process [4]. The Locally WeightedForgetting (LWF) algorithm [23], which reduces the weights of the k-nearest neighbors of a new case and discards a case ifits weight falls below a threshold θ , was believed to be one of the best adaptive learning algorithms of its time. Klinkenberg[17] later showed in his experiments that instance weighting techniques tend to overfit the data and perform more poorlythan analogous instance selection techniques. Elwell and Polikar [24] presented an ensemble learning algorithm for non-stationary environments (Learn++.NSE) that assumes data are incrementally acquired in batches. For each incoming datasetDt , their algorithm trains an independent base classifier ht which is forced to emphasize misclassified data by adjusteddata weighting. Then, a weight is assigned to each base classifier based on its performance on the latest dataset. The finalclassification result is determined by weighted majority voting of all base classifiers. Recent research and development incase-base maintenance (CBM) provides a number of methods for updating all knowledge containers [25] of a CBR system.Among them, the competence-based CBM methods [19,26–30] and case-base mining technologies [31] have been empiri-cally shown to be capable of preserving the competency of a CBR system while removing noisy and redundant cases. Fewstudies, however, discussed when to trigger maintenance operations, which is also an important consideration, according toWilson and Leake’s CBM framework [32]. In addition, current methods are incapable of distinguishing between noisy casesand cases representing a new concept. Knowing whether concept drift happens could help to recognize obsolete cases thatconflict with current concepts and distinguish noise cases from novel cases. Moreover, developing a detection method thatis able to explain where and how concept drifts could facilitate further decision capabilities and be suitable for handlinglocal concept drift problems [11].Motivated by these issues, we propose a new method of concept drift detection for CBR systems, which compares thecase distributions of existing cases with newly available cases. The proposed method requires no prior knowledge about thecase distribution, but estimates the probability distribution and detects change via a competence model. Besides determiningwhether there is a concept drift, our method also quantifies and describes the detected change in terms of the competencemodel. To the best of our knowledge, no literature has reported any research that uses a competence model for conceptdrift detection purposes.Compared with other famous non-parametric methods, our detection method demonstrates the following advantages:1) it can be easily adopted in multi-dimensional data while maintaining similar results in one-dimensional data; 2) it ismore stable and achieves better results as shown in experiments, especially for small samples, because data can sharedistribution contributions among related competence areas, rather than splitting strictly by cutting edges, which makes itmore tolerable to sample bias; 3) it is able to describe the detected changes by highlighting some competence areas, whichis testified by a real world application.The novelty and main contribution of this paper lie in the endeavor to discover the difference between the inner natureof the competence group model and our proposed competence closure model. The detailed definitions and theorems affordother researchers an inside view of case-base competence, which has never been discussed in the literature. The theoreticalstudy provided in this paper also reveals the essential differences between the two competence models, and identifies threeimportant aspects of the competence closure model which the competence group model does not possess. Compared withour previous work on competence-based concept drift detection [33], which aims to investigate the impact of concept drifton case-base competence and assert to the possibility of detecting change via competence models, this paper additiona",
            {
                "entities": [
                    [
                        3996,
                        4024,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 160 (2004) 1–34www.elsevier.com/locate/artintGeneralized Region Connection Calculus ✩Sanjiang Li ∗, Mingsheng YingState Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology,Tsinghua University, Beijing 100084, P.R. ChinaReceived 7 June 2002; accepted 18 May 2004AbstractThe Region Connection Calculus (RCC) is one of the most widely referenced system of high-level(qualitative) spatial reasoning. RCC assumes a continuous representation of space. This contrastssharply with the fact that spatial information obtained from physical recording devices is nowadaysinvariably digital in form and therefore implicitly uses a discrete representation of space. Recently,Galton developed a theory of discrete space that parallels RCC, but question still lies in that canwe have a theory of qualitative spatial reasoning admitting models of discrete spaces as well ascontinuous spaces? In this paper we aim at establishing a formal theory which accommodates bothdiscrete and continuous spatial information, and a generalization of Region Connection Calculus isintroduced. GRCC, the new theory, takes two primitives: the mereological notion of part and thetopological notion of connection. RCC and Galton’s theory for discrete space are both extensions ofGRCC. The relation between continuous models and discrete ones is also clarified by introducingsome operations on models of GRCC. In particular, we propose a general approach for constructingcountable RCC models as direct limits of collections of finite models. Compared with standard RCCmodels given rise from regular connected spaces, these countable models have the nice property thateach region can be constructed in finite steps from basic regions. Two interesting countable RCCmodels are also given: one is a minimal RCC model, the other is a countable sub-model of thecontinuous space R2. 2004 Elsevier B.V. All rights reserved.✩ This work was partly supported by the National Foundation of Natural Science of China (60305005,60496321, 60321002).* Corresponding author.E-mail addresses: lisanjiang@tsinghua.edu.cn (S. Li), yingmsh@tsinghua.edu.cn (M. Ying).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.05.012\f2S. Li, M. Ying / Artificial Intelligence 160 (2004) 1–34Keywords: (Generalized) Region Connection Calculus; Qualitative spatial reasoning; (Generalized) Booleanconnection algebra; Mereology; Mereotopology; Continuous space; Discrete space1. IntroductionQualitative Spatial Reasoning (QSR) is an important subfield of AI which has appli-cations in areas such as Geographical Information Systems(GIS) [4,24,52], spatial querylanguages [10], natural languages [1] and many other fields. We invite the reader to consult[11] for an introduction and an overview of current trends.This paper focus on one of the most important formalism for QSR, viz. the RegionConnection Calculus (RCC). RCC was initially described by Randell, Cohn and Cui in [31,32], which is intended to provide a logical framework for incorporating spatial reasoninginto AI systems.RCC takes regions rather than points as fundamental notion and is based on a singleprimitive (binary relation) C (for connection). Unlike other mereotopologies, RCC makesno distinction between closed, open, and semi-open regions and does not support the notionof boundaries. It is also a well-known result that regular connected topological spacesprovide models of the RCC axioms by taking a region to mean a non-empty regular closedset and saying two regions are connected if they have common points [25]. But since eachregion is infinitely divisible, it has nothing to do with discrete spaces (in the sense that eachregion is a union of atomic regions). Randell, Cui and Cohn [32] suggest ways of atomicversions of RCC, but, as commented by Bennett [3], each of the alternatives seem morecomplex than is desirable and have not been worked out in detail. They also suggest in thatpaper that the problem lies with the definition of P, but a revised definition was not given.On the other hand, discrete spaces are evidently important in implementations of spa-tial information systems, and their mereotopological aspects have only recently begun tobe investigated [22,24,30,39,44]. As noted by Galton in [24], high-level qualitative ap-proaches to handling spatial information are widely perceived as having little relevanceto the domain of low-level quantitative data inhabited by “real-world” applications, andthe congruity between the continuous space models favored by high-level approaches andthe discrete, digital representations used at the lower level is one amongst many possiblereasons for this.Recently, Galton [24] attempts to bridge this gap by developing a high-level qualitativespatial theory of discrete space that parallels RCC, but questions still lie in, e.g., “Can wehave a high-level theory of QSR which admits models of continuous spaces as well as dis-crete spaces?” and “What is the relation between continuous spaces (e.g., R2) and discretespaces (e.g., Z2)?”. In the present paper we try to answer these questions by introducing ageneralized theory of RCC. The new theory, termed Generalized Region Connection Cal-culus (GRCC henceforth), is a subtheory of both RCC1 and Galton’s theory for discretespace.1 We are concerned in this paper with only ‘strict’ RCC [45], i.e., the extensionality of C is an axiom.\fS. Li, M. Ying / Artificial Intelligence 160 (2004) 1–343The original formulation of RCC is inspired by the earlier work of Whitehead [48] andClarke [7,8]. These systems are all based on a single primitive, namely the concept ofconnection, and notions such as part are defined in terms of connection. This use of a sin-gle primitive relation is seen by Smith as problematic. In [42, p. 288], Smith puts: “Thesystem has a single primitive, that of connection, in terms of which the notion of part isdefined by means of what, intuitively, appears to be a logical trick. This means that themereological and topological components of the resultant theories are difficult or impos-sible to separate formally. The power of the approach is thus reduced, since experimentsin axiom-adjustment at different points in the theory cannot be carried out in controlledfashion”.This possible deficiency of the RCC theory, however, as Stell [45], as well as this pa-per, has shown, can be completely avoided. In [45], Stell introduces Boolean connectionalgebras (BCAs) and proves that these structures are equivalent to models of the RCC ax-ioms.2 Such an algebra is able to provide a neat separation of mereological and topologicalaspects of a set of regions. Moreover, by replacing the Boolean algebra by Łukasiewiczalgebra, Roy and Stell [38] obtain a theory of vague spatial regions. The present paper isalso strongly influenced by Stell’s idea on the treatment of spatial regions.In the GRCC theory proposed in this paper, however, we use two primitive notions: themereological notion of part P and the topological notion of connection C. This treatmentis not novel, the reader may consult for instance the work of Varzi [47] and Mosolo andVieu [30] for more discussion. In [47], Varzi systematically examines three main ways ofcombining mereologies (as theories of parthood) and topologies (as theories of wholeness)to build general mereotopologies, namely unified theories of parts and wholes. Both work,particularly that of Mosolo and Vieu [30], also investigate the possibilities of characterizingatomicity in these mereotopologies.Our mereology of GRCC (as well as the reformulated RCC theory) falls under the firstaccount of Varzi’s classifications, where mereology and topology form two independent(though mutually related) domains. Indeed, the mereological part of GRCC is the sameas the Closed Extensional Mereology (CEM) [47] (with the additional requirement thatthe universe exists). The GRCC theory is then obtained by adding three additional axiomsto the Ground Mereotopology CEMT [47]. The first requires a region a is connected tothe (mereological) sum of two regions b, c if and only if it is connected to either one ofb, c; the second stipulates in essence the universe is self-connected; the third requires thereexist at least two different regions. The original RCC theory is then obtained by adding toGRCC an additional axiom which requires that any region other than the universe cannotbe connected to all regions. Moreover, the theory of Galton for discrete space [24] is also anextension of the (atomistic) GRCC theory. Indeed, Galton’s theory is obtained by addingto GRCC three more axioms. The first two stipulate that the Boolean algebra is atomiccomplete and the third requires two regions are connected if and only if there are twoconnected atoms contained respectively in these two regions.2 The fact that each RCC model leads to a Boolean algebra is also pointed out independently by Düntsch,Wang and McCloskey [17].\f4S. Li, M. Ying / Artificial Intelligence 160 (2004) 1–34Eschenbach [22] also introduces a formal theory of Closed Region Calculus (CRC)based on two primitives: P for mereological notion of part and DC for the topological no-tion of disconnection or separation. CRC is similar to RCC and the 9-intersection calculus[19]. It provides the same terminology and justifies the same composition table, but differswith respect to the ontology. The main difference between CRC and RCC is that a finiteset of regions that is explicitly represented in a spatial information system can be a modelof CRC [22]. Our theory of GRCC is also a generalization of CRC in essence, it differsfrom CRC mainly in two aspects. The first is that GRCC is a first order theory while CRCis second order. The second lies in that the two theories use different topological primitivesand different systems of axioms.The fact that GRCC admits both continuous spaces and discrete spaces as models makesit possible to study the rela",
            {
                "entities": [
                    [
                        2256,
                        2284,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1410–1448Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA general framework for explaining the results of a multi-attributepreference modelChristophe LabreucheThales Research & Technology, RD128, 91767 Palaiseau cedex, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 13 August 2010Accepted 13 August 2010Available online 1 December 2010Keywords:PreferencesDecision theoryArgumentationWeight1. IntroductionThe automatic generation of an explanation of the prescription made by a multi-attributedecision model is crucial in many applications, such as recommender systems. This task iscomplex since the quantitative models are not designed to be easily explainable. The majorlimitation of the previous research is that there is no formal justification of the argumentsthat are selected in the explanation. The goal of this paper is to define a general frameworkto justify which arguments shall be selected, in the case where the decision model is basedon weights assigned to the attributes. Due to the complexity of explaining a preferencemodel based on utility theory, several explanation reasonings are necessary to cover allcases – ranging from situations where the prescription is trivial to situations where theprescription is much more tight. The set of selected arguments is, in this framework, anon-dominated element of a combinatorial structure in the sense of an order relation.Our general approach is instantiated precisely on three models: the probabilistic expectedutility model, the qualitative pessimistic minmax model and the concordance rule, whichare all constructed from a weight vector.© 2010 Elsevier B.V. All rights reserved.In decision making under uncertainty, social choice and multi-criteria decision making, which are the three main domainsof decision theory [40,48], explicit analytical models are constructed to represent the preferences of a decision makerregarding how to combine various dimensions, which are the states of nature, the voters and the criteria respectively.Decision theory mainly focuses on specifying how a rational agent should behave, which results in the justification, throughaxiomatic characterizations, of the decision models that should be used [54,51,37,41]. Another well-developed researcharea in decision theory concerns the elicitation of the decision maker preferences, and has led to the design of elaborateelicitation methods.Decision models are traditionally mainly quantitative, which is the case for instance of the expected utility model [54,51]. More recently, qualitative models have been developed in AI in order to overcome the difficulty of the elicitation of theinformation necessary for these models [24,19,12,20]. A wide class of quantitative and qualitative models are parameterizedby a weight vector where a weight is assigned to each dimension [26,49]. We are interested in these models in this paper.The final part of the decision process, after the model has been elicited, is usually not studied in decision theory. It isgenerally reduced to the application of the decision model on the options of interest. If an individual constructs his decisionmodel and is convinced about its relevance, then it is not necessary to explain to him the result of the application of thedecision model. However there are many practical situations in which the decision needs to be justified to some actorswho did not participate to its construction. These actors are not interested in the technicality of the decision model. On theE-mail address: christophe.labreuche@thalesgroup.com.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.008\fC. Labreuche / Artificial Intelligence 175 (2011) 1410–14481411contrary, they wish to have a synthetic explanation of the decision. It shall be automatically generated. According to Klein[35], such an explanation should be intuitive, comprehensive and persuasive.The automatic generation of an explanation of the outcome of a decision model is not an easy task since the modelsfrom decision theory are not designed to provide the reasons that support the recommendation [35]. By contrast, decisionframeworks from AI have, by construction, the ability to naturally provide such an explanation. This is for instance the caseof the belief–desire–intention representation architecture [11], argumentation [25] and conditional preference networks [9].In [18,3,2], an argumentation-based framework for making and explaining a decision is proposed. A preference relation overthe candidate options is derived from the positive and negative acceptable arguments that support each option and from anordering on the arguments. Another extension of argumentation to incorporate preferences can be found in [42].In the context of multi-criteria decision making and more specifically multi-attribute value theory (MAVT) [26,34,30],there are a few works which aim at generating an explanation of the outcome of the decision model [35,14,43]. The gener-ation process is split into two parts: the selection of the arguments (i.e. the criteria) to be presented, and the structurationand expression of the selected arguments in natural language. The second part is well-developed in Ref. [14]. One can notethat the expression of a selected content in natural language has been extensively studied in the literature – see for instance[13,27] to cite a few. Concerning the selection part, the three previously mentioned works [35,14,43] use the same idea.It consists in selecting the k (where k is a parameter) criteria that have the largest contribution to the overall utility. Thisapproach is not satisfactory for the following reasons. First of all, the textual explanation does not mention the weights ofthe criteria [14]. This is a major drawback since the weights are essential in the MAVT model. Secondly, there is no formaljustification of the arguments that are selected, and in particular of the choice of the k parameter.The aim of this paper is to develop a formal framework that justifies the selection of the arguments. This work isespecially dedicated to situations in which the recipient of the explanation is not the individual who has designed thedecision model. This general framework is designed for any decision model based on weights. It adapts itself automaticallyto the complexity of the decision. The easier the decision, the simpler the explanation. Premises of this work can be foundin two conference papers [38,39].Section 2 describes weighted decision models. We introduce three particular models that will be used to validate ourframework: the expected utility model [54,51], the weighted minmax model [22] and the weighted majority model [44].The general explanation framework is presented in Section 3. In order to adapt to the complexity of the situation, severalargumentation reasonings are introduced. They are called anchors by analogy to the concept of anchor defined by Grize torefer to some implicit information used to convince an audience [32]. A subset of criteria can be selected for the explanationif these criteria are decisive in some sense depending on the anchor. Such a subset is called an explanation set. The set ofthese explanation sets forms a combinatorial structure. One then aims at finding the non-dominated explanation sets inthis structure, in the sense of an order relation expressing the simplicity of the explanation set. In the following Sections 4through 7, this general framework is thoroughly developed on each anchor and each of the three weighted decision models.From the properties satisfied by the non-dominated explanation sets, we show that the explanation to be generated can bederived. A method or algorithm to compute a non-dominated explanation set is given in each case. We will not deal withthe expression of the selected arguments in natural language. However, examples of texts that can be generated will bepresented. Some experimental results are presented in Section 8. The proofs of the results are given in Section 10.2. Decision models based on a weight vectorDecision theory [40,48] is interested in preference representation and gathers different domains such as Multi-CriteriaDecision Making (MCDM) [49,28,10], Decision Making under Uncertainty (DMU) [36,51] and Social Choice (SC) [6,29]. Thetypical decision problem studied in decision theory consists in selecting one alternative among a set X of candidate options,where the alternatives are described by several dimensions. This selection is obtained by the construction of a preferencerelation over X . The set of finite dimensions is denoted by N = {1, . . . , n}, and the alternatives are characterized on eachdimension i ∈ N by a value in a set Xi . In MCDM, N is the set of decision criteria, Xi is the attribute representing criterion i,and each alternative is characterized by a value on each attribute, that is X = X1 × · · · × Xn. The criteria are often conflicting[49]. As an example, one may have cost criteria and performance criteria, which cannot be met at the same time. The maindifficulty is then to find a good compromise between the criteria. In DMU, the elements of N are the states representing thepossible situations, X1 = · · · = Xn =: C is the set of possible consequences, and an alternative (also called act) is a mappingfrom N to C , that is X = C N . The consequence of selecting a particular alternative depends on which state of nature willoccur. Moreover the attitude of the decision maker (DM) towards uncertainty influences his choice strategy [51]. In SC, N isthe set of voters, X1 = · · · = Xn =: C is the set of candidates, and the alternatives are also the candidates, that is X = C . Thedifficulty is to find a fair consensus among the opinions of the voters [5].The preference relation over the alternatives in X is usually constructed from a prefere",
            {
                "entities": [
                    [
                        3762,
                        3790,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 462–471www.elsevier.com/locate/artintRanking functions and rankings on languagesFranz HuberCalifornia Institute of Technology, USAReceived 8 June 2005; received in revised form 24 October 2005; accepted 26 October 2005Available online 21 November 2005AbstractThe Spohnian paradigm of ranking functions is in many respects like an order-of-magnitude reverse of subjective probabilitytheory. Unlike probabilities, however, ranking functions are only indirectly—via a pointwise ranking function on the underlyingset of possibilities W —defined on a field of propositions A over W . This research note shows under which conditions rankingfunctions on a field of propositions A over W and rankings on a language L are induced by pointwise ranking functions on W andthe set of models for L, ModL, respectively. 2005 Elsevier B.V. All rights reserved.Keywords: Extension theorem for rankings on languages; Probabilities; Ranking functions; Rankings on languages; Spohn1. Introduction: Pointwise ranking functionsThe Spohnian paradigm of ranking functions [16,17] is in many respects like an order-of-magnitude reverse ofsubjective probability theory [9]. “Ranks represent degrees”—or rather: grades—“of disbelief” ([19]: 6). Whereas ahigh probability indicates a high degree of belief, a high rank indicates a high grade of disbelief.There are many parallels between probability theory and ranking theory [16,18], and in Footnote 22 of his [16]Spohn “wonder[s] how far the mathematical analogy [of his ranking functions to probabilities] could be extend-ed”.1 The starting point of this paper is one of the few places where ranking theory differs from subjective probabilitytheory as well as qualitative-logical approaches to the representation of epistemic states such as entrenchment order-ings in belief revision theory: the domain on which these models are defined, that is, what they take to be the objectsof belief.Unlike probabilities, ranking functions are only indirectly—via a pointwise ranking function on a non-empty set ofpossibilities (possible worlds, models) W —defined on some finitary/σ -/complete field A over W , i.e., a set of subsetsof W containing the empty set and closed under complementation and finite/countable/arbitrary intersections. Let ushave a closer look.E-mail address: franz@caltech.edu (F. Huber).1 Ranking theory is very similar to possibility theory [5], and it would be highly desirable to know to what extent the results below also hold forpossibility measures. Unfortunately this goes beyond the scope of this research note.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.10.016\fF. Huber / Artificial Intelligence 170 (2006) 462–471463A function κ from W into the set of natural numbers N is a pointwise ranking function on W iff κ(ω) = 0 for atleast on ω ∈ W . A pointwise ranking function κ : W → N is extended to a function (cid:4)κ on a field A over W with rangeN ∪ {∞} by defining, for each A ∈ A,(cid:1)(cid:4)κ (A) =min{κ(ω): ω ∈ A},∞,if A (cid:5)= ∅,if A = ∅.As will be seen below, it is useful to allow that some possibility ω ∈ W is sent to ∞, which amounts to ω being a“virtually impossible possibility” (according to κ). In order to distinguish the more restricted notion of a pointwiseranking function as defined above from the more liberal one allowing for virtually impossible possibilities, let us callthe former natural pointwise ranking functions (because the range of κ is restricted to the set of natural numbers N ).Pointwise ranking functions κ are functions defined on a non-empty set of possibilities W that take natural numbersor ∞ as values. They are extended to functions (cid:4)κ on a field A over W by stipulating that the rank of any non-emptyproposition A ∈ A equals the minimum rank of the possibilities in A, i.e., (cid:4)κ (A) = min{κ(ω): ω ∈ A}, and the emptyproposition is sent to ∞.In case W is a finite set of possibilities and A its powerset, every possibility corresponds to a proposition (viz.the singleton containing it). But already when W is the set of all models ModL for a propositional language Lwith infinitely many propositional variables and A is the field {Mod(α) ⊆ W : α ∈ L}, no possibility corresponds toa proposition. Furthermore, one has to specify a ranking over uncountably many possibilities in order to assign apositive finite rank to a single proposition. But clearly, we often have a definite opinion about a single proposition(represented in terms of a sentence) even if we do not have an idea of what the underlying set of possibilities lookslike—let alone what our ranking over these possibilities might be. For instance, I strongly disbelieve that one can buya bottle of Schilcher for less than 1 Euro, though I lack the relevant enological vocabulary in order to know whatall the possibilities are. Indeed, it seems the underlying set of possibilities should not matter for my disbelief in thisproposition.More generally, we should be able to theorize about our epistemic states even if all we are given is a rankingover the sentences or propositions of some language or field, and we have no ranking over the underlying set ofpossibilities. After all, what we as ordinary or scientific believers do have are plenty of beliefs and grades of beliefin various propositions—usually if not always via beliefs and grades of belief in sentences or other representations ofthese propositions. When we want to attach ranks to sentences, pointwise ranking theory first has us specify a set ofpossible worlds for the language the sentences are taken from; then we have to specify a ranking over these possibleworlds, which in turn induces a ranking over sets of possible worlds; and only then can we identify the rank of asentence with the rank of the proposition containing exactly the possible worlds making our sentence true.This is a bit awkward. What one would like to do is to start with a ranking of the sentences in L, and then be ableto induce a pointwise ranking function on the corresponding set of possible worlds that yields the original ranking.The question is whether this is always possible. In order to answer it, let us first define ranking functions on fields ofpropositions and rankings on languages. (For a similar generalization of pointwise ranking functions see [21].)2. Ranking functions and rankings on languages(Finitely minimitive) ranking functions are functions (cid:4) from a field A over a set of possibilities W into the set ofnatural numbers extended by ∞2 such that for all A, B ∈ A:(1) (cid:4)(∅) = ∞;(2) (cid:4)(W ) = 0;(3) (cid:4)(A ∪ B) = min{(cid:4)(A), (cid:4)(B)}.If A is a σ -field/complete field, (cid:4) is a σ -minimitive/completely minimitive ranking function iff, in addition to (1)–(3),we have for every countable/possibly uncountable B ⊆ A:2 One can also take the set of ordinal numbers smaller than or equal to some limit ordinal β and send ∅ to β, but we do not need this generalityhere.\f464(cid:2)(4) (cid:4)(B) = min{(cid:4)(B): B ∈ B}.F. Huber / Artificial Intelligence 170 (2006) 462–471In case A is finite, i.e., if A contains only finitely many elements, these distinctions collapse. According to (4), therange of ranking functions has to be well-ordered. Therefore N is a natural choice. A ranking function (cid:4) on A isa pre-ranking iff (cid:4) is a finitely minimitive ranking function on A such that(cid:7)(cid:3)(cid:4)(cid:5)(cid:6)(cid:4)(A): A ∈ B= minB(cid:4)for every countable B ⊆ A such thatB ∈ A. A ranking function (cid:4) is regular iff (cid:4)(A) < (cid:4)(∅) for every non-emptyA ∈ A. The conditional ranking function (cid:4)(· | ·) : A × A → N ∪ {∞} based on the ranking function (cid:4) : A → N ∪ {∞}is defined such that for all A, B ∈ A with B (cid:5)= ∅,(cid:2)(cid:1)(5) (cid:4)(B | A) =(cid:4)(B ∩ A) − (cid:4)(A),0,if (cid:4)(A) < ∞,if (cid:4)(A) = ∞.The second clause says that, conditional on a (virtually) impossible proposition, no non-tautological proposition isbelieved in (cid:4). Goldszmidt and Pearl ([9]: 63) define (cid:4)(B | A) = ∞ for A = ∅, which means that, conditional on theimpossible proposition, every proposition is maximally believed in (cid:4). We further stipulate that (cid:4)(∅ | A) = ∞ for everyA ∈ A, which completes the definition of a conditional ranking function and ensures that (cid:4)(· | A) : A → N ∪ {∞} is aranking function.If the function (cid:4)κ : A → N ∪ {∞} is induced by a (natural) pointwise ranking function κ : W → N , (cid:4)κ is a (regularand) completely minimitive ranking function. The converse is not true. The triple A = (cid:9)W, A, (cid:4)(cid:10) with W a set ofpossibilities, A a finitary/σ -/complete field over W , and (cid:4) : A → N ∪ {∞} a ranking function is called a finitary/σ -/complete ranking space. A is called regular iff (cid:4) is regular, and A is called natural iff (cid:4) is induced by some naturalpointwise ranking function κ.A proposition A ∈ A is believed in (cid:4) iff (cid:4)(A) > 0. (cid:4)’s belief set Bel(cid:4) = {A ∈ A: (cid:4)(A) > 0} is consistent anddeductively closed in the finite/countable/complete sense whenever (cid:4) is finitely/σ -/completely minimitive. Here Bel isB (cid:5)= ∅ for every finite/countable/possibly uncountable B ⊆ Bel;consistent in the finite/countable/complete sense iffand Bel is deductively closed in the finite/countable/complete sense iff for all A ∈ A: A ∈ Bel wheneverB ⊆ A forsome finite/countable/possibly uncountable B ⊆ Bel.3(cid:8)(cid:8)Observation 1. For any ranking space A = (cid:9)W, A, (cid:4)(cid:10) and all A, B ∈ A:1. min{(cid:4)(A), (cid:4)(A)} = 0.2. A ⊆ B ⇒ (cid:4)(B) (cid:1) (cid:4)(A).Rankings κ : L → N ∪ {∞} on languages L are defined such that for all α, β ∈ L:0. α (cid:12)(cid:13) β ⇒ (cid:4)(α) = (cid:4)(β).1. α (cid:13) ⊥ ⇒ (cid:4)(α) = ∞.2. (cid:13) α ⇒ (cid:4)(α) = 0.3. (cid:4)(α ∨ β) = min{(cid:4)(α), (cid:4)(β)}.4. β (cid:5)(cid:13) ⊥ ⇒ (cid:4)(β | α) = (cid:4)(α ∧ β) − (cid:4)(α",
            {
                "entities": [
                    [
                        2671,
                        2699,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2170–2197Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFoundations of instance level updates in expressive description logicsHongkai Liu a, Carsten Lutz b, Maja Miliˇci ´c c, Frank Wolter d,∗a Institut für Theoretische Informatik, TU Dresden, Germanyb Fachbereich Informatik, Universität Bremen, Germanyc School of Computer Science, The University of Manchester, UKd Department of Computer Science, University of Liverpool, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 9 July 2010Received in revised form 25 June 2011Accepted 14 August 2011Available online 23 August 2011Keywords:Description logicsABoxesUpdates1. IntroductionIn description logic (DL), ABoxes are used for describing the state of affairs in an applicationdomain. We consider the problem of updating ABoxes when the state changes, assumingthat update information is described at an atomic level, i.e., in terms of possibly negatedABox assertions that involve only atomic concepts and roles. We analyze such basic ABoxupdates in several standard DLs, in particular addressing questions of expressibility andsuccinctness: can updated ABoxes always be expressed in the DL in which the originalABox was formulated and, if so, what is the size of the updated ABox? It turns out thatDLs have to include nominals and the ‘@’ constructor of hybrid logic for updated ABoxes tobe expressible, and that this still holds when updated ABoxes are approximated. Moreover,the size of updated ABoxes is exponential in the role depth of the original ABox and thesize of the update. We also show that this situation improves when updated ABoxes areallowed to contain additional auxiliary symbols. Then, DLs only need to include nominalsfor updated ABoxes to exist, and the size of updated ABoxes is polynomial in the size ofboth the original ABox and the update.© 2011 Elsevier B.V. All rights reserved.Description Logics (DLs) are a traditional family of knowledge representation formalisms which, in recent years, haveplayed an important role as a logical underpinning of ontology languages such as the W3C recommendation OWL [1]. In DLs,a knowledge base (KB) typically consists of two parts: a TBox to store intensional knowledge, i.e., a general formalization ofthe relevant concepts and relationships of the application domain; and an ABox to store extensional knowledge, i.e., instancelevel assertions that describe the current state of affairs in the application. Just like database systems, DL knowledge basesare not static entities, but have to be modified when the application domain evolves. This raises the fundamental updateproblem, which consists of rewriting the knowledge base to incorporate new information from the application withoutunnecessarily losing any existing knowledge. In the case of a DL knowledge base, at least three different incarnations of theupdate problem can be distinguished:• TBox updates, triggered by changes of the intensional knowledge of the application domain;• ABox updates, which have to be carried out when the intensional knowledge remains stable, but the state of affairs inthe application changes;* Corresponding author.E-mail addresses: liuhkai@tcs.inf.tu-dresden.de (H. Liu), clu@uni-bremen.de (C. Lutz), maja.milicic@manchester.ac.uk (M. Miliˇci ´c), frank@csc.liv.ac.uk(F. Wolter).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.003\fH. Liu et al. / Artificial Intelligence 175 (2011) 2170–21972171• KB updates, which do not distinguish between the two levels of knowledge and allow simultaneous modification of theTBox and the ABox.In typical applications, instance level knowledge stored in the ABox tends to change frequently whereas intensional knowl-edge in the TBox often remains stable for longer periods of time. Moreover, automatic TBox modifications are rarely desiredbecause the TBox is typically the result of a careful and time-consuming manual modeling process, and thus its syntacticstructure should not be changed in a radical way.These observations lead us to study ABox updates as a fundamental and basic form of updates in a DL context. A centralproperty of DL ABoxes is that they store incomplete knowledge, reflected by an open world semantics and the use of com-pound logical expressions that can involve disjunction and existential quantification. It follows that, technically, updating DLABoxes is equivalent to updating logical theories, a problem with a long tradition in both the database and AI communities[4–8].In the database and AI literature, for a long time no proper distinction was made between updates as studied in thispaper and the related notion of a revision. While the purpose of update is to bring the knowledge base up to date whenthe world described by it changes, revision aims at incorporating new knowledge that was obtained about a static world.Katsuno and Mendelzon [6] discuss this distinction in detail, show that update and revision are fundamentally differentoperations, and give 8 postulates that any rational update operator should satisfy. The prototypical update semantics thatcomplies with these postulates is Winslett’s well-known PMA semantics [4] whose general idea can, in our context, bestated as follows. The models of the original knowledge base K are viewed as those states of the world that are consideredpossible; when K is to be updated with new information U , then the models of the resulting updated knowledge baseK(cid:3)should satisfy U , but also be ‘as close as possible’ to the models of K (the principle of minimal change). In the caseof updating propositional theories and logical databases as considered in [6,4], the difficulty of defining what ‘as close aspossible’ means mainly derives from the following two features: (i) the newly added information may be non-deterministic,e.g. when it involves disjunction; and (ii) the updated theory must satisfy additional domain constraints stated in theform of a logical background theory. As discussed in more detail in Section 6 of this paper, the combination of thesefeatures with the first-order quantification present in description logics leads to serious semantic difficulties and also tocomputational problems. For this reason, we concentrate on a simple, yet fundamental form of update where (i) the newlyadded information U consists of a set of ground literals, i.e., sets of ABox assertions A(a) or r(a, b) and their negations,where A is a concept name and r a role name (thus both are atomic); and (ii) no background theory is present, i.e., theknowledge base K comprises only an ABox, but no TBox. In this case, there seems to be only one sensible formalizationof ‘as close as possible’: the models of K(cid:3)are obtained from the models of K by (deterministically!) applying the changesdictated by the ground literals in U . This semantics, which we adopt in the current paper, can thus be viewed as anincarnation of Winslett’s semantic that avoids the potentially controversial cases.As a starting point for the current paper, we observe that, in standard ‘expressive’ DLs such as those between ALC andALCQIO, we can find an ABox A and update U of the restricted form described above such that the result of updatingA with U cannot be expressed in the given DL. As a concrete example, take the following ABox A, which is formulated inALC, the basic expressive DL with Boolean operators. It states that John is a parent with only happy children, that Peter ishis child, and that Mary is a person:john:Person (cid:4) ∃has-child.Person (cid:4) ∀has-child.(Person (cid:4) Happy)has-child(john, peter)mary:Person.Suppose now that the situation changes by Mary becoming unhappy. The result of updating A with U = {Mary : ¬Happy} canbe represented by the following ABox A(cid:3), which is formulated in ALCO, the extension of ALC with nominals (individualnames inside concept descriptions):john:Person (cid:4) ∃has-child.Person (cid:4) ∀has-child.(cid:2)Person (cid:4)(cid:2)Happy (cid:7) {mary}(cid:3)(cid:3)has-child(john, peter)mary:Person (cid:4) ¬Happy.To understand why A(cid:3)is appropriate, note that A provides no information about whether or not Mary is a child of John.Because we cannot exclude that this is the case, John may now have an unhappy child, which is Mary. Thus, the newknowledge concerning Mary also resulted in an update of the knowledge concerning John. Using the nominal {mary} inthe assertion for john is actually unavoidable as it can be shown that there is no ALC-ABox that is equivalent to theALCO-ABox A(cid:3). As a consequence, the update of the ALC-ABox A with U cannot be expressed in ALC.We say that a description logic L does not have updates if there are an L-ABox A and update U such that the resultof updating A with U cannot be expressed in L. The first main aim of this paper is to understand how the problem of non-expressibility of updated ABoxes can be overcome. In particular, we consider two options: (i) increasing the expressive power ofDLs by adding additional constructors and (ii) relaxing the definition of updated ABoxes.\f2172H. Liu et al. / Artificial Intelligence 175 (2011) 2170–2197Regarding (i), we show that the addition of nominals (as in the example above) and the ‘@’ constructor from hybrid logicsuffices to ensure the existence of updated ABoxes in all DLs between ALC and ALCQIO. Intuitively, the ‘@’ constructorenables ‘jumps’ between individuals by allowing the formation of concepts such as @aC which is satisfied at any point of aninterpretation whenever the individual a satisfies the concept C . We also show that the ‘@’-constructor (but not nominals)can be replaced by Boolean ABoxes, i.e., ABoxes that admit Boolean operators to be applied to ABox assertions.Regarding (ii), we consider the following definitions of updated ABoxes. An ABox A(cid:3)is• a semantic update of A with U if the models of A(cid:3)are precisely those interpre",
            {
                "entities": [
                    [
                        3459,
                        3487,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2075–2098Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLearning heuristic functions for large state spacesShahab Jabbari Arfaee a, Sandra Zilles b,∗, Robert C. Holte aa University of Alberta, Department of Computing Science, Edmonton, Alberta, Canada T6G 2H8b University of Regina, Department of Computer Science, Regina, Saskatchewan, Canada S4S 0A2a r t i c l ei n f oa b s t r a c tArticle history:Received 19 September 2010Received in revised form 27 July 2011Accepted 1 August 2011Available online 5 August 2011Keywords:Heuristic searchPlanningLearning heuristics∗We investigate the use of machine learning to create effective heuristics for searchor heuristic-search planners such as FF. Our method aims toalgorithms such as IDAgenerate a sequence of heuristics from a given weak heuristic h0 and a set of unsolvedtraining instances using a bootstrapping procedure. The training instances that can besolved using h0 provide training examples for a learning algorithm that produces aheuristic h1 that is expected to be stronger than h0. If h0 is so weak that it cannot solveany of the given instances we use random walks backward from the goal state to createa sequence of successively more difficult training instances starting with ones that areguaranteed to be solvable by h0. The bootstrap process is then repeated using hi in lieu ofhi−1 until a sufficiently strong heuristic is produced. We test this method on the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world. In every case∗to solve randomly generated problemour method produces a heuristic that allows IDAinstances quickly with solutions close to optimal.The total time for the bootstrap process to create strong heuristics for these large statespaces is on the order of days. To make the process effective when only a single probleminstance needs to be solved, we present a variation in which the bootstrap learning ofnew heuristics is interleaved with problem-solving using the initial heuristic and whateverheuristics have been learned so far. This substantially reduces the total time needed tosolve a single instance, while the solutions obtained are still close to optimal.© 2011 Elsevier B.V. All rights reserved.1. IntroductionModern heuristic search and planning systems require good heuristics. A popular approach to creating heuristics fora state space is abstraction: from the state space description one creates a description of an abstract state space that iseasier to search; exact distances in the abstract space give admissible estimates of distances in the original space [4,5,16,24,34,36]. One limitation of this approach is that it is often memory-intensive. This has led to the study of compressionschemes [3,7,42], disk-based methods [52], and distributed methods [8]. These methods extend the range of problems towhich abstraction is applicable, but since combinatorial problems grow in size exponentially it is easy to imagine problemsso large that, with the computers of the foreseeable future, even the best heuristics created by these systems will be tooweak to enable arbitrary instances to be solved reasonably quickly.A second limitation of abstraction is that it can only be applied to state spaces given in a suitable declarative form.There are situations in which there is no such state-space description, for example, if a planner is controlling a system orcomputer game, or when such a description would be vastly less efficient than a “hard-coded” one, or when the state spaceis described declaratively but in a different language than the abstraction system requires. We call such representations* Corresponding author.E-mail addresses: jabbaria@cs.ualberta.ca (S. Jabbari Arfaee), zilles@cs.uregina.ca (S. Zilles), rholte@ualberta.ca (R.C. Holte).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.001\f2076S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098opaque. With an opaque representation, a state space is defined by a successor function that can be called to compute astate’s children but cannot otherwise be reasoned about. By definition, abstraction cannot be applied to create heuristicswhen the state space is represented opaquely.An approach to the automatic creation of heuristics that sidesteps both of these limitations is to apply machine learningto a set of states whose distance-to-goal is known (the training set) to create a function that estimates distance-to-goalfor an arbitrary state, i.e., a heuristic function. This idea has been applied with great success to the 15-puzzle and otherstate spaces of similar size (see Ernandes and Gori [9] and Samadi, Felner, and Schaeffer [41]), but could not be appliedto larger spaces, e.g., the 24-puzzle, because of the excessive time it would take to create a sufficiently large training setcontaining a sufficiently broad range of possible distances to goal. To overcome this obstacle, Samadi et al. [41] reverted tothe abstraction approach: instead of learning a heuristic for the 24-puzzle directly they learned heuristics for two disjointabstractions of the 24-puzzle and combined them to get a heuristic for the 24-puzzle. This approach inherits the limitationsof abstraction mentioned above and, in addition, the crucial choices of which abstractions to use and how to combine themare made manually.Ernandes and Gori [9] proposed a different way of extending the machine learning approach to scale to arbitrarilylarge problems, but never implemented it. We call this approach “bootstrap learning of heuristic functions” (bootstrapping,for short). The contribution of the present paper is to validate their proposal by supplying the details required to makeautomatic bootstrapping practical and showing experimentally that it succeeds on state spaces that are at or beyond thelimit of today’s abstraction methods.Bootstrapping is an iterative procedure that uses learning to create a series of heuristic functions. Initially, this proce-dure requires a heuristic function h0 and a set of states we call the bootstrap instances. Unlike previous machine learningapproaches to creating heuristics, there are no solutions given for any instances, and h0 is not assumed to be strong enough[29]) is run with h0 in an attempt toto solve any of the given instances. A standard heuristic search algorithm (e.g., IDAsolve the bootstrap instances within a given time limit. The set of solved bootstrap instances, together with their solutionlengths (not necessarily optimal), is fed to a learning algorithm to create a new heuristic function h1 that is intended to bebetter than h0. After that, the previously unsolved bootstrap instances are used in the same way, using h1 as the heuristicinstead of h0. This procedure is repeated until all but a handful of the bootstrap instances have been solved or until asuccession of iterations fails to solve a large enough number of “new” bootstrap instances (ones that were not solved onprevious iterations).∗If the initial heuristic h0 is too weak to solve a sufficient number of the given bootstrap instances within the given timelimit we use a random walk method to automatically generate bootstrap instances at the “right” level of difficulty (easyenough to be solvable with h0, but hard enough to yield useful training data for improving h0).As in the earlier studies by Ernandes and Gori [9] and Samadi et al. [41], which may be seen as doing one step of thebootstrap process with a very strong initial heuristic, the learned heuristic might be inadmissible, i.e., it might sometimesis not guaranteed to find optimal solutions with the learned heuristic. Withoverestimate distances, and therefore IDAbootstrapping, the risk of excessive suboptimality of the generated solutions is much higher than with the one-step methodsbecause on each iteration the learning algorithm might be given solution lengths larger than optimal, biasing the learnedheuristic to even greater overestimation. The suboptimality of the solutions generated is hence an important performancemeasure in our experiments.∗We test our method experimentally on four problem domains that are at, or beyond, the limit of what current abstractionmethods can solve optimally—the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world—ineach case starting with an initial heuristic so weak that the previous, one-step methods would fail because they would notbe able to generate an adequate training set in a reasonable amount of time. In all the domains, bootstrapping succeeds in∗to solve randomly generated problem instances quickly with solutions that are veryproducing a heuristic that allows IDAclose to optimal. On these domains our method systematically outperforms Weighted IDA[30] and BULB [15].∗The time it takes for our bootstrap method to complete its learning on these large state spaces is on the order of days.This is acceptable when the learned heuristic will be used to solve many instances, but a different approach is neededin order to solve a single instance quickly. For this we introduce a method that interleaves the bootstrapping process forcreating a succession of ever stronger heuristics with a process that uses the set of heuristics that are currently available(initially just h0) to try to solve the given instance. The total time required to solve a single instance using this methodis substantially less than the learning time for the bootstrap method, and the solutions it produces are of comparablesuboptimality. For example, with this method the total time to solve an instance of the 24-puzzle is just 14 minutes, onaverage, and the solution found is only 6.5% longer than optimal. When applied to the blocksworld instances used in theIPC2 planning competition, our interleaving method solves all the instances within the 30-minute time limit, and almost allare solve",
            {
                "entities": [
                    [
                        3947,
                        3975,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 86–110Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomated query learning with Wikipedia and genetic programmingPekka Malo∗, Pyry Siitari, Ankur SinhaAalto University, School of Economics, P.O. Box 21210, FI-00076 Aalto, Finlanda r t i c l ei n f oa b s t r a c tArticle history:Available online 19 June 2012Keywords:WikipediaGenetic programmingConcept recognitionInformation filteringAutomatic indexingQuery definitionMost of the existing information retrieval systems are based on bag-of-words model andare not equipped with common world knowledge. Work has been done towards improvingthe efficiency of such systems by using intelligent algorithms to generate search queries,however, not much research has been done in the direction of incorporating human-and-society level knowledge in the queries. This paper is one of the first attempts where suchinformation is incorporated into the search queries using Wikipedia semantics. The paperpresents Wikipedia-based Evolutionary Semantics (Wiki-ES) framework for generatingconcept based queries using a set of relevance statements provided by the user. The querylearning is handled by a co-evolving genetic programming procedure.To evaluate the proposed framework, the system is compared to a bag-of-words basedgenetic programming framework as well as to a number of alternative document filteringtechniques. The results obtained using Reuters newswire documents are encouraging. Inparticular, the injection of Wikipedia semantics into a GP-algorithm leads to improvementin average recall and precision, when compared to a similar system without humanknowledge. A further comparison against other document filtering frameworks suggeststhat the proposed GP-method also performs well when compared with systems that donot rely on query-expression learning.© 2012 Elsevier B.V. All rights reserved.1. IntroductionA central challenge in building expert systems for information retrieval (IR) is to provide them with common worldknowledge. As succinctly put by Hendler and Feigenbaum [23], in order to build any system with “significant levels ofcomputational intelligence, we need significant bodies of knowledge in knowledge bases”. That is, if a system is expected tounderstand the general semantics in text, closer to the way human brains do, then it should have access to the extensivebackground knowledge that people use while interpreting concepts (units of knowledge) and their dependencies. Of course,statistical methods and natural language processing can be used to extract semantics from text or data, but the ability oftext collections to convey human- and society-level semantics is quite limited [67]. Currently, there is an ongoing questto find new ways of integrating semantic knowledge into document modelling along with multiple other aspects (suchas document timeliness and novelty) without time-consuming knowledge engineering; see e.g. Pasi et al. [48]; Meij et al.[37]; Navigli and Crisfulli [45]; and references therein. One of the emerging trends is to use socially developed resources ofsemantic information.In this paper, we consider the use of Wikipedia as a source of common world knowledge for an automated query learningsystem. The purpose is to assist users to express their information needs as queries which are written in terms of Wiki-pedia’s concepts instead of word tokens. The proposed system extends the Inductive Query By Example (IQBE) paradigm of* Corresponding author.E-mail addresses: pekka.malo@aalto.fi (P. Malo), pyry.siitari@aalto.fi (P. Siitari), ankur.sinha@aalto.fi (A. Sinha).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.006\fP. Malo et al. / Artificial Intelligence 194 (2013) 86–11087Smith and Smith [59] and Chen et al. [9] by incorporating human-level semantics using Wikipedia. The underlying principleof IQBE is quite simple: assume that a user provides a small collection of relevant (and irrelevant) example documents,the task is to learn a query based on those documents. The learnt query is then used to filter relevant documents from anewstream or document database according to the topic definition implied by the sample collection. The approach proposedin this paper uses concept-relatedness information contained in Wikipedia’s link-structure to learn semantic queries usinga co-evolutionary procedure. This transition from an ordinary boolean query [55] to a semantified query is necessary forintegrating human- and society-level semantic information into the information retrieval (IR) system. The use of concept-based knowledge enables the IR systems to detect the relevance of a document based on the central concepts and notjust words. It also allows the system to identify those documents as relevant which contain concepts closely related to thequery concepts. The paper contributes towards construction of an IR framework where Wikipedia-concept based queries arelearnt using a co-evolving genetic programming (GP) algorithm. The proposed framework is called Wiki-ES (Wikipedia-basedEvolutionary Semantics).The traditional automated query learning systems usually represent both queries and documents using a bag-of-wordsapproach. Moreover, the recent studies on IQBE paradigm have almost exclusively focused on finding the best evolutionaryalgorithms and fitness functions for learning boolean queries; see e.g. Cordón et al. [12,13], García and Herrera [21], andLópez-Herrera et al. [30,29]. The use of IQBE systems is largely motivated by the portability of queries, which allows themto be interpreted as additional query generation components that can be placed on top of other retrieval systems witha boolean query interface. However, restricting the query and document models to word-level information eliminates thepossibility of leveraging human-level semantics on how the different topics and concepts are related. It should be notedthat a query is composed of a number of concepts, and it represents the topic the user wants to search. To illustratethe difference between word based search and concept based search, consider a situation where a user is searching forinformation on a particular topic, for which he crafts a simple query “economy AND espionage”. Then, suppose that a newlyarrived document has concepts “Trade secret” and “spying”. If we now ask a human reader to judge whether the documentis about economic espionage, he would most likely find it relevant due to the close relationships between the concepts.However, if only word-level information is used, the boolean query will ignore the document as the original query wordsnever appear.In this paper, we focus on the benefits of using concepts instead of bag-of-words in query learning and documentfiltering. As a test-bed for Wiki-ES system, we consider TREC-11 dataset with Reuters RCV1 corpus which provides a realisticexample of a multi-domain news-stream. The experiments suggest that the concept-based approach is well-fitted to be usedin conjunction with evolutionary algorithms. We observe that replacing tokens with Wikipedia’s concepts yields considerableimprovement in filtering results as measured by precision and recall. A comparison of Wiki-ES with other general documentfiltering algorithms is also drawn. The given benchmarks represent a number of paradigms. The obtained results indicatedstrong performance in terms of TREC-11 measures which motivates further research on the use of semantic information indocument retrieval.The structure of this paper is following. Section 2 summarizes the main contributions of the paper. Section 3 gives areview on IQBE model for automated query learning, and how Wikipedia can be used as a source of semantic information.Section 4 presents our framework Wikipedia-based Evolutionary Semantics (Wiki-ES). The co-evolutionary GP algorithm ispresented in Section 5. Finally, Section 6 summarizes the experimental results.2. ContributionsThe key contributions of the paper are summarized in the following points.2.1. Use of Wikipedia semantics in query learningWhen a set of documents concerning a particular topic is to be retrieved from a database, it is common for a userto generate a query composed of tokens (terms). This query is used to decide the relevance of documents in a databaseby performing a search for the tokens in those documents. However, analyzing the problem from a user point of view,it is recognized that the user is not just interested in the documents containing the exact matching tokens, rather sheis seeking all such documents which contain the concept represented by the token. This provides a motivation to worktowards generating queries composed of concepts rather than tokens. Queries composed of concepts contain wide human-and society-level knowledge, providing a better representation of the topic being searched. In this paper, we use Wikipediasemantics to convey the concept behind a token. There is no previous study to the knowledge of the authors, which utilizesthe Wikipedia semantics to construct a concept based query. The benefits of this transition from tokens to concepts, towardsretrieval of documents, has been evaluated in the paper and its significance has been established.2.2. Development of a co-evolving GPGenerating an accurate query for a search is often an iterative and tedious task to perform. However, if there is a setof documents available at hand, with each document marked relevant or irrelevant, the task of query generation can beentirely avoided by directing the documents to a genetic programming algorithm. Based on the relevance or irrelevance of\f88P. Malo et al. / Artificial Intelligence 194 (2013) 86–110the training documents, a concept based query can be learnt by the algorithm, saving the user from a monotonous task.The paper contributes towards development of a co-evolving evolutionary algorithm specialize",
            {
                "entities": [
                    [
                        3758,
                        3786,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1041–1053Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputer-aided proofs of Arrow’s and other impossibility theorems ✩Pingzhong Tang∗, Fangzhen LinDepartment of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Konga r t i c l ei n f oa b s t r a c tArrow’s impossibility theorem is one of the landmark results in social choice theory. Overthe years since the theorem was proved in 1950, quite a few alternative proofs have beenput forward. In this paper, we propose yet another alternative proof of the theorem. Thebasic idea is to use induction to reduce the theorem to the base case with 3 alternativesand 2 agents and then use computers to verify the base case. This turns out to be aneffective approach for proving other impossibility theorems such as Muller–Satterthwaiteand Sen’s theorems as well. Motivated by the insights of the proof, we discover a newtheorem with the help of computer programs. We believe this new proof opens an excitingprospect of using computers to discover similar impossibility or even possibility results.© 2009 Elsevier B.V. All rights reserved.Article history:Received 20 October 2008Received in revised form 13 February 2009Accepted 24 February 2009Available online 4 March 2009Keywords:Social choice theoryArrow’s theoremMuller–Satterthwaite theoremSen’s theoremKnowledge representationComputer-aided theorem proving1. IntroductionRecently, there has been much interest and work in applying economics models such as those from social choice theoryto computer science problems as well as computational techniques to solving problems in social choice theory. In this paper,we consider a different application of AI to economics: using computers to help prove and discover theorems in social choicetheory.The particular theorems that we are interested in are the impossibility theorems such as those by Arrow [3], Sen [20],and Muller and Satterthwaite [15] in social choice theory [2], an area concerning about how individual preferences canbe aggregated to form a collective preference in a society. Social choice theory has sometimes been called “a science ofthe impossible” because of the many famous impossibility theorems that have been proved in it. Among them, Arrow’stheorem [3] on the non-existence of rational social welfare function is without doubt the most famous one. It shows thenon-existence of the collective social preference (called social welfare function) even when some minimal standards such asPareto efficiency and non-dictatorship are imposed. Arrow’s original proof of this result is relatively complex, and over theyears, quite a few alternative proofs have been advanced (see e.g. [4,7,8,21]).In this paper, we propose yet another alternative proof of this result, with the help of computers. Briefly, Arrow’s the-orem says that in a society with at least three possible outcomes (alternatives) for each agent, it is impossible to have asocial welfare function that satisfies the following three conditions: unanimity (Pareto efficiency), independent of irrelevantalternatives (IIA), and non-dictatorship. We shall show by induction that this result holds if and only if it holds for the basecase when there are exactly two agents and three alternatives (the single agent case is trivial). For the base case, we verifyit using computers in two ways. One views the problem as a constraint satisfaction problem (CSP), and uses a depth-firstsearch algorithm to generate all social welfare functions that satisfy the first two conditions, and then verifies that all of✩An earlier version of this paper appeared in Proceedings of AAAI’08.* Corresponding author.E-mail addresses: kenshin@cse.ust.hk (P. Tang), flin@cse.ust.hk (F. Lin).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.02.005\f1042P. Tang, F. Lin / Artificial Intelligence 173 (2009) 1041–1053them are dictatorial. The other translates these conditions to a logical theory and uses a SAT solver to verify that the re-sulting logical theory is not satisfiable. Either way, it took less than one second on an AMD Opteron-based server (with 41.8 GHz CPUs and 8 GB RAM) for the base case to be verified.As it turns out, this strategy works not just for proving Arrow’s theorem. The same inductive proof can be adaptedalmost directly for proving other impossibility results such as Sen’s and Muller–Satterthwaite theorems. We have used it toprove Gibbard–Satterthwaite theorem [9,19] as well, but we leave its proof to another paper.As a byproduct of our proof of Arrow’s theorem, the social welfare functions that satisfies IIA only in the base case canall be generated by our program. To our surprise, the number of such functions is so small that we are able to look at themone by one. By doing so, we form an interesting conjecture and then prove it using the same techniques as in the previousproofs. We then demonstrate the powerfulness of the newly proved theorem by showing that it subsumes both Arrow’s andWilson’s theorems.These proofs suggest that many of the impossibility results in social choice theory are all rooted in some small basecases. Thus an interesting thing to do is to use computers to explore these small base cases to try to come up with newconjectures automatically, and to understand the boundary between impossibility and possibility results. This is what wethink the long term implication of our new proofs of Arrow’s and other impossibility theorems lies, and the main reasonwhy we want to formulate the conditions in these theorems in a logical language and use a SAT solver to check theirconsistency.The rest of the paper is organized as follows. In Sections 2 and 3, we review Arrow’s theorem and then describe ournew inductive proof of this result. We then describe in Sections 4 and 5 how this proof can be adapted to prove Muller–Satterthwaite theorem and Sen’s theorem. In Section 6, We describe the idea of making use of computer programs todiscover new theorems in social choice theory and a theorem discovered this way. We then propose in Section 7 a logicallanguage for social choice theory and describe how it can be used to axiomatize Arrow’s theorem and how the base case inour inductive proof of Arrow’s theorem can be checked using a SAT solver. Finally, we conclude this paper with a summaryof our results and an outlook on future research.2. Arrow’s theoremA voting model is a tuple (N, O ), where N is a finite set of individuals (agents) and O a finite set of outcomes (alterna-tives). An agent’s preference ordering is a linear ordering of O , and a preference profile > of (N, O ) is a tuple (>1, . . . , >n),where >i is agent i’s preference ordering, and n the size of N. In the following, when N is clear from the context, we alsocall > a preference profile of O . Similarly, when O is clear from the context, we also call it a preference profile of N.Definition 1. Given a voting model (N, O ), a social welfare function is a function W : Ln → L, where L is the set of linearordering of O , and n the size of N.A social welfare function defines a social ordering for each preference profile. If we consider the social ordering givenby a social welfare function as the aggregates of the preference orderings of the individuals in the society, it is natural toimpose some conditions on it. For instance, it should not be dictatorial in that the aggregated societal preference orderingalways is the same as a particular individual’s preference. Arrow showed that a seemingly minimal set of such conditionsturns out to be inconsistent.In the following, given a preference profile > = (>1, . . . , >n), we sometimes write >W for W (>). Thus both a >W b anda W (>) b mean the same thing: the alternative a is preferred over the alternative b according to the societal preferenceordering W (>).Definition 2. A social welfare function W is unanimous (Pareto efficient) if for all alternatives a1 and a2, we have that ifa1 >i a2 for every agent i, then a1 >W a2In words, if everyone ranks alternative a1 above a2, then a1 must be ranked above a2 socially.Definition 3. A social welfare function W is independent of irrelevant alternatives (IIA) if for all alternatives a1 and a2, and allpreference profiles >(cid:4), we have that ∀i a1 >(cid:4)i a2 implies that a1 >(cid:4)W a2 iff a1 >(cid:4)(cid:4)i a2 iff a1 >(cid:4)(cid:4)and >(cid:4)(cid:4)W a2.Literally, IIA means that the relative social ordering of two alternatives depends only on their relative orderings given byeach agent and has nothing to do with other alternatives.Definition 4. An agent i is a dictator in a social welfare function W if for all alternatives a1 and a2, a1 >W a2 iff a1 >i a2. Ifthere is a dictator in W , then it is said to be dictatorial. Otherwise, W is said to be non-dictatorial.It is easy to see that if there are at least two alternatives, then there can be at most one dictator in any social welfarefunction.\fP. Tang, F. Lin / Artificial Intelligence 173 (2009) 1041–10531043Theorem 1 (Arrow’s theorem [3]). For any voting model (N, O ), if |O | (cid:2) 3, then any social welfare function that is unanimous and IIAis also dictatorial.Arrow’s original proof of this result is somewhat complicated, and there are several alternative proofs by others, e.g.[4,7,8]. We now give yet another one using induction.3. An inductive proof of Arrow’s theoremFor ease of presentation, we assume the following notations.• For any set S, we use S−a to denote S \\ {a}, i.e. the result of deleting a in S.• We extend the above notation to tuples as well: if t = (t1, . . . , tn), then we use t−i to denote the tuple (t1, . . . , ti−1,ti+1, . . . , tn). Furthermore, we use (t−i, s) to denote the result of replacing ith item in t by s: (t−i, s) = (t1, . . . , ti−1,s, ti+1, . . . , tn). We use t−{i, j} to denote (t−i)− j .• If > is a linear ordering of O , and a ∈ O , then we",
            {
                "entities": [
                    [
                        3902,
                        3930,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 208 (2014) 41–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintWeighted synergy graphs for effective team formation withheterogeneous ad hoc agentsSomchaya Liemhetcharat∗, Manuela VelosoSchool of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 12 September 2012Received in revised form 12 December 2013Accepted 17 December 2013Available online 19 December 2013Keywords:Multi-agentMulti-robotHeterogeneousCapabilitySynergyAd hocTeam formation1. IntroductionPrevious approaches to select agents to form a team rely on single-agent capabilities,and team performance is treated as a sum of such known capabilities. Motivatedby complex team formation situations, we address the problem where both single-agent capabilities may not be known upfront, e.g., as in ad hoc teams, and whereteam performance goes beyond single-agent capabilities and depends on the specificsynergy among agents. We formally introduce a novel weighted synergy graph model tocapture new interactions among agents. Agents are represented as vertices in the graph,and their capabilities are represented as Normally-distributed variables. The edges of theweighted graph represent how well the agents work together,i.e., their synergy in ateam. We contribute a learning algorithm that learns the weighted synergy graph usingobservations of performance of teams of only two and three agents. Further, we contributetwo team formation algorithms, one that finds the optimal team in exponential time,and one that approximates the optimal team in polynomial time. We extensively evaluateour learning algorithm, and demonstrate the expressiveness of the weighted synergy graphin a variety of problems. We show our approach in a rich ad hoc team formation problemcapturing a rescue domain, namely the RoboCup Rescue domain, where simulated robotsrescue civilians and put out fires in a simulated urban disaster. We show that the weightedsynergy graph outperforms a competing algorithm, thus illustrating the efficacy of ourmodel and algorithms.© 2013 Elsevier B.V. All rights reserved.Heterogeneous agents have varying capabilities that affect their task performance. We research on teams of such hetero-geneous agents and how the performance of a team at a task relates to the composition of the team. Team performancehas previously been computed as the sum of individual agent capabilities, e.g., the amount of resources an agent pos-sesses [38,6]. In this work, we are interested in a model of team performance that goes beyond the sum of single-agentcapabilities. We understand that there is synergy among the agents in the team, where team performance at a particu-lar task depends not only on the individual agents’ capabilities, but also on the composition of the team itself. Specificagents may have or acquire a high task-based relationship that allows them to perform better as a team than other agentswith equivalent individual capabilities but a low task-based relationship. There are many illustrations of such synergy inreal human teams, basically for any task. An example is an all-star sports team comprised of top players from around the* Corresponding author. Somchaya Liemhetcharat has graduated from Carnegie Mellon University and is now at the Institute for Infocomm Research (I2R),Singapore. Tel.: +65 6408 2000, fax: +65 6776 1378.E-mail addresses: som@ri.cmu.edu (S. Liemhetcharat), veloso@cs.cmu.edu (M. Veloso).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.12.002\f42S. Liemhetcharat, M. Veloso / Artificial Intelligence 208 (2014) 41–65world, hence individual agents with high capabilities, who may have a lower synergy as a team and perform worse than awell-trained team of individuals with lower capabilities but much higher synergy.To model task-based relationships, we introduce a connected weighted graph structure, where the vertices representthe agents, and the edges represent the task-based relationships. In such graphs, we define the level of synergy of a setof agents, as a function of the shortest path between agents. We further devise a non-binary metric of team performancebased on a Gaussian model of the individual agent capabilities. Such probabilistic variables allow us to capture the inherentvariability in team performance in a dynamic world. We show that our formulation of team performance captures manyinteresting characteristics, such as the effects of including new agents into the team.Most existing team formation approaches assume that the agent capabilities are known a priori (e.g., [48]). We aremotivated by research in ad hoc agents, that learn to collaborate with previously unknown teammates [40]. An ad hoc teamis one where the agents in the team have not collaborated with each other. Assuming an ad hoc team, we address the teamsynergy learning question as: given a set of agents with unknown capabilities, how do we model and learn the capabilitiesand synergy of the agents through observations, in order to form an effective team, i.e., a subset of the agents? A solutionto this problem will enable ad hoc teams to be applied to a variety of problems in the real world, where effective teamsneed to be composed from agents who may not have previously worked together.A motivating scenario is the urban search-and-rescue (USAR) domain. Many USAR robots have been developed by dif-ferent research groups, with a variety of hardware capabilities. When a disaster occurs, researchers from around the worldarrive with their USAR robots. Due to safety and space constraints, only a subset of these robots may be able to be deployedto the site. Since many of these researchers have not collaborated in the past, selecting an effective team is an ad hocproblem, where the agent capabilities and synergy are initially unknown. Some of these robots may have been designedto work well with other robots developed by the same group, and in some cases, robots from different sources may havesynergy in a team, e.g., a robot that clears rubble quickly so that another robot can search. Thus, it is necessary to modeland learn the synergy of these robots and select the best team of robots to be deployed.We contribute a learning algorithm that uses only observations of the performance of teams of two and three agents,in order to learn the agent capabilities and weighted graph structure of the weighted synergy graph. The learning algorithmiterates through weighted graph structures, and computes the agent capabilities using the observations. We also contributetwo team formation algorithms that uses the learned weighted synergy graph to find an effective team that solves the task.Our approach does not make many assumptions about the agents, only that observations of their performance is available,and as such our approach is applicable to many multi-agent domains.We perform extensive experiments to demonstrate that our learning algorithm effectively learns the structure of repre-sentative graph types and agent capabilities. We compare the weighted synergy graph to the unweighted synergy graph thatwe previously introduced [26], and demonstrate that the weighted synergy graph is more expressive and hence applicable tomore domains. We apply the weighted synergy graph model to the RoboCup Rescue domain (that simulates rescue robots ina USAR scenario), and show that the learned weighted synergy graph is used to form a near-optimal team, and outperformsIQ-ASyMTRe [48], a competing algorithm.In summary, the contributions of this work are:1. A novel model of multi-agent team performance, the weighted synergy graph model, where agents are vertices in a con-nected weighted graph, edges represent how well agents work together, and agent capabilities are Normally-distributedvariables;2. The definition of the synergy of a multi-robot team as a function of the weighted synergy graph model;3. A team formation algorithm that forms the optimal team in exponential time;4. A team formation algorithm that approximates the optimal team in polynomial time;5. A learning algorithm that learns a weighted synergy graph using only observations of agent teams comprising two andthree agents;6. Extensive experiments that evaluate our model and algorithms using synthetic data;7. Application of the weighted synergy graph model to the RoboCup Rescue domain.The article is organized as follows: Section 2 discusses related research in multi-robot task allocation, coalition formation,team formation, and ad hoc teams, and how it compares to our work. In Section 3, we formally define the weighted synergygraph model and our team formation algorithms. Section 4 contributes the synergy graph learning algorithm, while Section 5presents extensive learning experiments. Section 6 compares the expressiveness of the weighted and unweighted synergygraph models. Section 7 details the experiments in the RoboCup Rescue domain, and Section 8 draws conclusions.2. Related workThis section presents a review of related work, discussing the relevant domains of task allocation, coalition formation,ad hoc coordination and team formation.\fS. Liemhetcharat, M. Veloso / Artificial Intelligence 208 (2014) 41–65432.1. Multi-robot task allocationMulti-robot task allocation (MRTA) is focused on the problem of allocating a set of tasks to a group of robots so as tomaximize a utility function. The MRTA problem is categorized along three axes: single-task robots (ST) versus multi-taskrobots (MT), single-robot tasks (SR) versus multi-robot tasks (MR), and instantaneous assignment (IA) versus time-extendedassignment (TA) [17].Multi-robot teams have been used for many tasks, such as in the RoboCup Rescue Simulation League [20]. A city issimulated to have had a disaster, necessitating rescue robots to help to mitigate the crisis. Civilians are located aroundthe city that ha",
            {
                "entities": [
                    [
                        3639,
                        3667,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 234 (2016) 120–151Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the expressivity of inconsistency measuresMatthias ThimmInstitute for Web Science and Technologies, Universität Koblenz-Landau, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 19 June 2015Received in revised form 26 January 2016Accepted 28 January 2016Available online 29 January 2016Keywords:Inconsistency measuresInconsistency managementWe survey recent approaches to inconsistency measurement in propositional logic and provide a comparative analysis in terms of their expressivity. For that, we introduce four different expressivity characteristics that quantitatively assess the number of different knowledge bases that a measure can distinguish. Our approach aims at complementing ongoing discussions on rationality postulates for inconsistency measures by considering expressivity as a desirable property. We evaluate 16 different measures on the proposed characteristics and conclude that the distance-based measure I(cid:2)dalal from Grant and Hunter (2013) [8] and the proof-based measure IPm from Jabbour and Raddaoui (2013) [16]have maximal expressivity along all considered characteristics. In our study, we discovered several interesting relationships of inconsistency measurement to e.g. set theory and Boolean functions and we also report these findings.© 2016 Elsevier B.V. All rights reserved.1. IntroductionInconsistency measurement is about the quantitative assessment of the severity of inconsistencies in knowledge bases. Consider the following two knowledge bases K1 and K2 formalized in propositional logic:K1 = {a, b ∨ c, ¬a ∧ ¬b, d}K2 = {a, ¬a, b, ¬b}Both knowledge bases are classically inconsistent as for K1 we have {a, ¬a ∧ ¬b} |(cid:4)⊥ and for K2 we have, e.g., {a, ¬a} |(cid:4)⊥. These inconsistencies render the whole knowledge bases useless for reasoning if one wants to use classical reasoning tech-niques. In order to make the knowledge bases useful again, one can either rely on non-monotonic/paraconsistent reasoning techniques [23,27] or one revises the knowledge bases appropriately to make them consistent [9]. Looking at the knowledge bases K1 and K2 one can observe that the severity of their inconsistency is different. In K1, only two out of four formulas (a and ¬a ∧ ¬b) are “participating” in making K1 inconsistent while for K2 all formulas contribute to its inconsistency. Furthermore, for K1 only two propositions (a and b) are conflicting and using e.g. paraconsistent reasoning one could still infer meaningful statements about c and d. For K2 no such statement can be made. This leads to the assessment that K2should be regarded more inconsistent than K1.Inconsistency measures can be used to analyze inconsistencies and to provide insights on how to repair them. An incon-sistency measure I is a function on knowledge bases, such that the larger the value I(K) the more severe the inconsistency in K. A lot of different approaches of inconsistency measures have been proposed, mostly for classical propositional logic [10,12,13,22,25,32,7,8,24,15], but also for classical first-order logic [6], description logics [21,33], default logics [5], and prob-abilistic and other weighted logics [19,30,26]. Due to this plethora of inconsistency measures it is hard to determine which E-mail address: thimm@uni-koblenz.de.http://dx.doi.org/10.1016/j.artint.2016.01.0130004-3702/© 2016 Elsevier B.V. All rights reserved.\fM. Thimm / Artificial Intelligence 234 (2016) 120–151121measure to use for an application and which measure is meaningful. Rationality postulates have been proposed that ad-dress the issue of assessing the quality of a measure—see e.g. [11,25]—but many of these properties have been criticized to address only a specific point of view, see [2] for a recent discussion on this topic.In this paper, we take a different perspective on the evaluation of inconsistency measures by considering a quantitativeanalysis of their expressivity, that is, we study how many different (inconsistent) knowledge bases can be distinguished by a given inconsistency measure. By the term expressivity we here refer to the property of a semantical concept—here, an inconsistency measure—and its capability to distinguish syntactical constructs—here, knowledge bases—, similarly as it has been done for the analysis of expressivity of semantics for other logical languages, see e.g. skepticism relations for formal argumentation [1]. Our analysis is meant to complement the study on rationality postulates and is, of course, not meaningful on its own as the compliance of measures with the basic intuitions behind inconsistency measures can only be assessed by rationality postulates. However, we introduce expressivity of inconsistency measures as an additional method to evaluate their quality. In particular, we propose four different expressivity characteristics that quantify the relation between the number of different values of an inconsistency measure wrt. different notions of the size of the knowledge base, such as number of formulas or number of propositions. We conduct a thorough comparative analysis of 16 different inconsistency measures from the literature [12,13,7,17,31,8,25,16,32,5] and classify these measures in a hierarchy of expressivity. In our study, we made several interesting observations, such as the relation between the measure IMI [7] and Sperner families [28]and of the measure Ifrom Grant and Hunter [8] and the proof-based measure IPm from Jabbour and Raddaoui [16] have maximal expressivity along all considered characteristics.MIC [7] with profiles of Boolean functions. One of our results is that the distance-based measure I(cid:2)dalalIn summary, the contributions of this paper are as follows:1. We conduct a focused survey of 16 inconsistency measures from the recent literature (Section 3).2. We propose four different expressivity characteristics, evaluate the considered inconsistency measures wrt. these char-acteristics, and study our findings (Section 4).3. We classify the evaluated measures into hierarchies of expressivity and thus provide a means to quantitatively compare different measures (Section 5).We give necessary preliminaries in Section 2 and provide a summary in Section 6. Appendix A contains proofs of technical results and Appendix B lists all example knowledge bases and families of knowledge bases used in the paper. All incon-sistency measures discussed in this paper have been implemented and an online interface to try out these measures is available.12. PreliminariesLet At be some fixed propositional signature, i.e., a (possibly infinite) set of propositions, and let L(At) be the corre-sponding propositional language constructed using the usual connectives ∧ (and), ∨ (or), and ¬ (negation).Definition 1. A knowledge base K is a finite set of formulas K ⊆ L(At). Let K be the set of all knowledge bases.If X is a formula or a set of formulas we write At( X) to denote the set of propositions appearing in X . Semantics to a propositional language is given by interpretations and an interpretation ω on At is a function ω : At → {true, false}. Let (cid:4)(At)denote the set of all interpretations for At. An interpretation ω satisfies (or is a model of) a proposition a ∈ At, denoted by ω |(cid:4) a, if and only if ω(a) = true. The satisfaction relation |(cid:4) is extended to formulas in the usual way.As an abbreviation we sometimes identify an interpretation ω with its complete conjunction, i.e., if a1, . . . , an ∈ At are those propositions that are assigned true by ω and an+1, . . . , am ∈ At are those propositions that are assigned false by ω we identify ω by a1 . . . anan+1 . . . am (or any permutation of this). For example, the interpretation ω1 on {a, b, c} with ω(a) = ω(c) = true and ω(b) = false is abbreviated by abc.For (cid:5) ⊆ L(At) we also define ω |(cid:4) (cid:5) if and only if ω |(cid:4) φ for every φ ∈ (cid:5). Define furthermore the set of models Mod( X) = {ω ∈ (cid:4)(At) | ω |(cid:4) X} for every formula or set of formulas X . If Mod( X) = ∅ we also write X |(cid:4)⊥ and say that X is inconsistent.3. Inconsistency measuresLet R∞≥0 be the set of non-negative real values including ∞. Inconsistency measures are functions I : K → R∞≥0 that aim at assessing the severity of the inconsistency in a knowledge base K, cf. [7]. The basic idea is that the larger the inconsistency in K the larger the value I(K) and I(K) = 0 if and only if K is consistent. However, inconsistency is a concept that is not easily quantified and there have been a couple of proposals for inconsistency measures so far, in particular for1 http://tweetyproject.org/w/incmes/.\f122M. Thimm / Artificial Intelligence 234 (2016) 120–151Table 1Definitions of the considered inconsistency measures.Id(K) =(cid:2)1 if K |(cid:4)⊥0 otherwiseIMI(K) = |MI(K)|MIC (K) =I(cid:3)M∈MI(K)1|M|Iη(K) = 1 − max{ξ | ∃P ∈ P(At) : ∀α ∈ K : P (α) ≥ ξ }Ic(K) = min{|υ−1(B)| | υ |(cid:4)3 K}IL Pm (K) = Ic(K)/|At(K)|Imc(K) = |MC(K)| + |SC(K)| − 1Ip(K) = |(cid:4)M|M∈MI(K)Ihs(K) = min{|H| | H is a hitting set of K} − 1dalal(K) = min{I(cid:2)(cid:3)α∈Kdalal(K) = min{maxI maxα∈Kdd(Mod(α), ω) | ω ∈ (cid:4)(At)}dd(Mod(α), ω) | ω ∈ (cid:4)(At)}dalal(K) = min{|{α ∈ K | dd(Mod(α), ω) > 0}| | ω ∈ (cid:4)(At)}I hitID f (K) = 1 − (cid:11)|K|i=1(1 − R i(K)/i)(cid:3)a∈At(cid:5)|IPm (K) =Imv (K) =|PKm (a)| · |PKm (¬a)|M∈MI(K) At(M)||At(K)|Inc(K) = |K| − max{n | ∀K(cid:14) ⊆ K : |K(cid:14)| = n ⇒ K(cid:14) (cid:16)|(cid:4)⊥}classical propositional logic, see e.g. [2,24,15,14] for some recent works. We selected 16 inconsistency measures from the literature in order to conduct our analysis on expressivity, taken from [12,13,7,17,31,8,25,16,32,5]. We briefly introduce these measures in this section for the sake of completeness, but we refer for a detailed explanation to the corresponding original papers.To illustrate the different in",
            {
                "entities": [
                    [
                        3446,
                        3474,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 1–18www.elsevier.com/locate/artintRCC8 binary constraint network can be consistentlyextended ✩Sanjiang Li a,∗, Huaiqing Wang ba State Key Laboratory of Intelligent Technology and Systems,Department of Computer Science and Technology, Tsinghua University, Beijing 100084, Chinab Department of Information Systems, City University of Hong Kong, Hong Kong, ChinaReceived 31 May 2004; received in revised form 17 August 2005; accepted 24 August 2005Available online 29 September 2005AbstractThe RCC8 constraint language developed by Randell et al. has been popularly adopted by theQualitative Spatial Reasoning and GIS communities. The recent observation that RCC8 composi-tion table describes only weak composition instead of composition raises questions about Renz andNebel’s maximality results about the computational complexity of reasoning with RCC8.This paper shows that any consistent RCC8 binary constraint network (RCC8 network for short)can be consistently extended. Given Θ, an RCC8 network, and z, a fresh variable, suppose xTy ∈ Θand T is contained in the weak composition of R and S. This means that we can add two newconstraints xRz and zSy to Θ without changing the consistency of the network. The result guaranteesthe applicability to RCC8 of one key technique, (Theorem 5) of [J. Renz, B. Nebel, On the complexityof qualitative spatial reasoning: A maximal tractable fragment of the Region Connection Calculus.Artificial Intelligence 108 (1999) 69–123], which allows the transfer of tractability of a set of RCC8relations to its closure under composition, intersection, and converse. 2005 Elsevier B.V. All rights reserved.Keywords: Qualitative spatial reasoning; Computational complexity; Region connection calculus; Binaryconstraint network; Extensionality; Path-consistency✩ This work was partly supported the National Foundation of Natural Science of China (60305005, 60321002,60496321) and by a Hong Kong CERG Grant No. CityU 1234/03E.* Corresponding author.E-mail addresses: lisanjiang@tsinghua.edu.cn (S. Li), iswang@cityu.edu.hk (H. Wang).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.08.003\f2S. Li, H. Wang / Artificial Intelligence 170 (2006) 1–181. IntroductionConstraint Satisfaction Problems (CSPs) have played a significant role in many areas ofArtificial Intelligence such as vision, resource allocation in scheduling, and temporal andspatial reasoning [5,24]. Ladkin and Maddux formulate binary CSP concepts and methodsusing relation algebra, and this “clarifies the mathematics of binary constraint satisfactionmethods, and allows problems with finite or potentially infinite domains to be handled in auniform way”. [10]When formulating a problem as a binary CSP, we usually (implicitly) assume that theunderlying relation algebra is a proper relation algebra [10] for the universe of the problem.For example, the well-known interval algebra [1] and point algebra [25] used in temporalreasoning are both proper relation algebras for the corresponding universe. This meansthat operations in these algebras, e.g., converse, intersection, composition, coincide withthe usual set-theoretical operations.The situation, however, is different in qualitative spatial reasoning (QSR), where a com-position table usually describes only weak composition. Given a universe U , supposeA = {R1, R2, . . . , Rn} is a collection of jointly exhaustive and pairwise disjoint (JEPD)relations on U . For two relations Ri, Rj , the weak composition [6] of Ri and Rj is a subsetof A, written as Ri; Rj , such that for any 1 (cid:1) k (cid:1) n, Rk ∈ Ri; Rj iff there exist a, b, c ∈ Usuch that aRib, bRj c and aRkc hold. Summarizing all weak compositions in an n × ntable, we obtain the weak composition table of A. If Rk ∈ Ri; Rj , we call (cid:3)Ri, Rk, Rj (cid:4)a composition triad, and a composition triad (cid:3)Ri, Rk, Rj (cid:4) is said to be extensional on Uif Rk ⊆ Ri ◦ Rj , that is, for any two a, c ∈ U with aRkc we have a region b in U suchthat aRib and bRj c hold, where ◦ is the set-theoretical relational composition on U . If allcomposition triads are extensional on U , then the weak composition table describes indeedcomposition, and we say it is extensional.This paper is mainly concerned with the RCC8 constraint language, which was devel-oped by Randell, Cohn, and Cui [4,17,18], and has now been popularly adopted by theQSR and GIS communities (see [21] for more information). Intuitively, spatial regions inRCC8 can be interpreted as nonempty regular closed subsets of some topological space.The composition table of RCC8 base relations has been independently established by Cui,Cohn, Randell [4] and Egenhofer [8]. This composition table, known as RCC8 compositiontable, however, is only a weak one. This is because spatial regions in RCC need not be one-piece and without holes [12,13]. For instance, given three disconnected regions o, p, q, leta be the union of o and p, and c the union of o and q. Then a partially overlaps c. Ac-cording to the RCC8 composition table, PO (partially overlap) is in the cell specified byEC (externally connected) and NTPP (non-tangential proper part). But it is easy to seethat there is no region b such that EC(a, b) and NTPP(b, c) hold at the same time. Thissuggests that PO (cid:7)⊆ EC ◦ NTPP. As a matter of fact, Li and Ying [13] identify altogether35 such non-extensional composition triads.The above observation raises questions about Renz and Nebel’s maximality resultsabout the computational complexity of reasoning with RCC8 [20,22]. Indeed, if U , theuniverse of an RCC8 binary constraint network (RCC8 network or simply network forshort), is the collection of nonempty regular closed subsets of some topological space (ornon-zero elements in a GRCC model [14]), consistent base networks are even not nec-\fS. Li, H. Wang / Artificial Intelligence 170 (2006) 1–183essarily path-consistent! For example, the RCC8 network Θ = {xECy, yNTPPz, xPOy}clearly has a solution in U , but it is not path-consistent since PO (cid:7)⊆ EC ◦ NTPP. Düntschexpresses the following concern:In the light of this it seems that some of the results in [76-78] [here [20,22]] are validonly in extensional interpretations of the weak RCC8 table such as the closed circles orareas bounded by closed Jordan curves, and not for RCC models. [5, footnote 1]More important, the applicability of one key technique used in [20,22] to RCC8 be-comes questionable now. To show that reasoning with RCC8 relations is in general NP-complete and to identify the boundary between tractability and NP-hardness, Renz andNebel [20,22] use the following theorem to transfer tractability of a set of RCC8 relationsS to its closure, (cid:1)S, under composition, intersection, and converse, where RSAT(S) is theproblem of deciding consistency of networks over S.Theorem 5 [22]. Let C be a set of binary relations that is closed under composition, inter-section, and converse. Then for any subset S ⊆ C that contains the universal relation andthe identity relation,1 the problem RSAT( (cid:1)S) can be polynomially reduced to RSAT(S).This theorem suggests that, if S is a subset of C that contains the universal relation andthe identity relation, then for any T ⊆ C with S ⊆ T ⊆ (cid:1)S, RSAT(S) is tractable if and onlyif RSAT(T ) is. Renz and Nebel establish this reduction by constructing for each networkΘ over (cid:1)S a network Θ (cid:8) over S, such that Θ (cid:8) is consistent iff Θ is. This approach doesnot work for some calculi that use weak compositions (see Example 7.1 of this paper).Now since RCC8 uses weak composition instead of composition, its applicability to RCC8becomes questionable.This paper intends to remove all these doubts. To begin with, we address the ambiguityof the concept “path-consistency”. This concept is usually defined as follows [22, p. 73, lastparagraph]: A binary constraint network is path-consistent if and only if for any consistentinstantiation of any two variables, there exists an instantiation of any third variable suchthat the three values taken together are consistent.Note that this definition closely depends on the choice of universe. There is, however,another definition of path-consistency that is independent of the choice of universe. Thisdefinition is given by Ladkin and Maddux [10] in a more general manner using relationalgebras. By this definition, a binary constraint network Θ = {xiRij xj : Rij ∈ A, 1 (cid:1) i, j (cid:1)n} over an atomic relation algebra A is path-consistent if and only if for any 1 (cid:1) i, j, k (cid:1) n,Rii (cid:1) 1(cid:8), Rij = R∼j i and Rij (cid:1) Rik; Rkj , where 1(cid:8), ∼ and ; are, respectively, the identity, theconverse, and the composition of A. Under this interpretation, a consistent RCC8 networknecessarily contains a path-consistent refinement (see Lemma 4.1 of this paper).To show that Theorem 5 in [22] really holds for RCC8 relations, we show that each con-sistent RCC8 network can be further extended at least one-shot. Suppose Θ is a consistent1 The reason that S should contain the identity relation is because we require any two spatial variables to beconstrained by one and only one relation in a binary CSP (see [16]).\f4S. Li, H. Wang / Artificial Intelligence 170 (2006) 1–18RCC8 network. This means, for any three RCC8 relations R, S, T with T = R; S and anyconstraint xiTxj ∈ Θ, the RCC8 network Θ (cid:8) = Θ ∪ {xiRz, zSxj } is also consistent, wherez is a fresh variable. This result guarantees the validity of the reduction method given inthe proof of [22, Theorem 5] for RCC8.Our proof of this statement is by construction. In an earlier paper, Li [11] gives anO(n3) algorithm to generate a realization in certain topological space for every path-consistent RCC8 base network. This construction can be further simplified and adaptedfor the present purpose. Indeed, we shall construct a canonical RCC8 model and show thatevery path-consistent RCC8 netwo",
            {
                "entities": [
                    [
                        2173,
                        2201,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1–18www.elsevier.com/locate/artintIterated belief revision, revised ✩Yi Jin 1, Michael Thielscher ∗Department of Computer Science, Dresden University of Technology, GermanyReceived 8 September 2005; received in revised form 1 November 2006; accepted 9 November 2006Available online 13 December 2006AbstractThe AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide widely acceptedcriteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulatesalone, however, are too permissive: They support operators by which all newly acquired information is canceled as soon as an agentlearns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the standardpostulates alone, and we show how to solve the problem by an additional postulate of independence. We give a representationtheorem for this postulate and prove that it is compatible with AGM and DP.© 2006 Elsevier B.V. All rights reserved.Keywords: Iterated belief revision; Implicit dependence; Conditional beliefs1. IntroductionThe capability of gathering information about the world and revising its beliefs based on the new informationis crucial for an intelligent agent. Belief revision therefore is a central topic in Artificial Intelligence. Technically,belief revision is the process of changing the beliefs of an agent to accommodate new, more precise, or more reliableevidence that is possibly inconsistent with the existing beliefs.The formal study of belief revision took as starting point the work of Alchourrón, Gärdenfors, and Makinson(AGM) during the first half of the 1980s [1–3]. The AGM framework studies idealized mathematical models of beliefrevision. Given an underlying logic language L, the beliefs of an agent are represented by a set of sentences in L(known as belief set) which is closed under logical consequence. New evidence is also a sentence in L, and a beliefrevision operator incorporates the new evidence into the current belief set to obtain a revised belief set. The authors ofthe original AGM framework have developed their theory under two basic assumptions regarding the new evidence:it is intended to describe facts of the static world; and it is more reliable (hence prioritized in the revision process)than the prior beliefs. The latter assumption is often referred to as primacy of update. The necessity and ideas ofdistinguishing belief revision from belief update (suitable for a situation where the new evidence describes a change✩ This article is a substantial extension of the conference paper [Y. Jin, M. Thielscher, Iterated belief revision, revised, in: Proceedings of theInternational Joint Conference on Artificial Intelligence (IJCAI), Edinburgh, Scotland, August 2005, pp. 478–483].* Corresponding author.E-mail addresses: yijin@inf.tu-dresden.de (Y. Jin), mit@inf.tu-dresden.de (M. Thielscher).1 The first author is funded by the Deutsche Forschungsgemeinschaft under grant no. Gr 334/3.0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.11.002\f2Y. Jin, M. Thielscher / Artificial Intelligence 171 (2007) 1–18of the world) was first noticed by Keller and Winslett [24] and later on formalized in [22]. Belief revision where thenew evidence is not prioritized, is a relatively recent topic studied by many researchers [5,10,12,18]. In this paper, wewill concentrate on the problem of prioritized belief revision where iterations are necessary.In situations where the new evidence is consistent with the existing beliefs, the two can just be merged; we call thismild revision. More interesting and complicated are situations where the evidence conflicts with the prior beliefs, inwhich case the agent needs to remove some of its currently held beliefs in order to accommodate the new evidence.This kind of revision is referred to as severe revision [13]. To provide general design criteria for belief revisionoperators, a set of postulates has been developed [3]. As first argued by the AGM trio and later frequently repeatedby others [9,13], the guiding principle of the AGM postulates is that of economy of information, or minimal changeof belief sets, which means not to give up currently held beliefs and not to generate new beliefs unless necessary.However, Rott [33,34] has recently pointed out that “it is a pure myth that minimal change principles are the foundationof existing theories of belief revision, at least as far as the AGM tradition is concerned”. His argument is mainly basedon the fact that so-called full meet revision [1] discards all prior beliefs in a severe revision and at the same timesatisfies all AGM postulates. This implies that the AGM postulates are too weak to capture the principle of minimalchange.For the incremental adaptation of beliefs, the AGM postulates proved to be overly weak, too [8,9]. This has led tothe development of additional postulates for iterated belief revision by Darwiche and Pearl (DP), among others (e.g.,[6,13,27]).Still, however, the AGM and DP postulates together are too permissive in that they support belief revision operatorswhich assume arbitrary dependencies among the pieces of information which an agent acquires along its way. Theseoperators have a drastic effect when the agent makes an observation which contradicts its currently held beliefs: Theagent is forced to cancel everything it has learned up to this point [28,30]. In this paper, we first give a formal analysisof this problem of implicit dependence, and then we present, as a solution, an Independence postulate for iterated beliefrevision. We give a representation theorem for our new postulate and prove its consistency by defining a concrete beliefrevision operator. We also contrast the Independence postulate to the so-called Recalcitrance postulate of [28,30] andargue that the latter is too strict in that it rejects reasonable belief revision operators.The rest of the paper is organized as follows. In the next section, we recall the classical AGM approach in apropositional setting as formulated by [23], followed by the approach of [8] for iterated belief revision. In Section 3,we formally analyze the problem of the DP postulates to be overly permissive. In Section 4, we present an additionalpostulate to overcome this deficiency, and we give a representation theorem for the postulate along with a concreterevision operator. We conclude in Section 5 with a detailed comparison to related work. Proofs of the main results canbe found in Appendix A.2. BackgroundIn this paper, we will deal with a propositional language L generated from a finite set P of atomic propositions.The language is that of classical propositional logic, i.e., with the classical consequence relation (cid:3). We say thattwo sentences α and β are logically equivalent, written as α ≡ β, iff α (cid:3) β and β (cid:3) α. As usual, a propositionalinterpretation (world) is a mapping from P to {(cid:5), ⊥}. The set of all interpretations is denoted by W. If an interpretationw truth-functionally maps a sentence μ to (cid:5), then w is called a model of μ (denoted by w |= μ). Given a sentence μ,we denote by Mods(μ) the set of all models of μ.A total pre-order (cid:2) (possibly indexed) is a reflexive, transitive binary relation s.t., either α (cid:2) β or β (cid:2) α holds forany α, β. The strict part of (cid:2) is denoted by <, that is, α < β iff α (cid:2) β and β (cid:7)(cid:2) α. As usual, α = β abbreviates α (cid:2) βand β (cid:2) α. Given any set S and total pre-order (cid:2), we denote by min(S, (cid:2)) the set of minimal elements of S wrt (cid:2).2.1. KM postulatesKatsuno and Mendelzon (KM) rephrased the AGM postulates for the propositional setting [23]. The beliefs of anagent are represented by a sentence ψ in L.2 Any new evidence is a sentence μ in L, and the result of revising ψ2 As L is assumed finite, any belief set can be represented as a sentence (modulo logical consequence). In this paper, we therefore do notdistinguish belief sets from sentences.\fY. Jin, M. Thielscher / Artificial Intelligence 171 (2007) 1–183with μ is also a sentence (denoted by ψ ∗ μ) which belongs to L. This is then the reformulation of the original AGMpostulates:(KM1) ψ ∗ μ (cid:3) μ.(KM2) If ψ ∧ μ is consistent, then ψ ∗ μ ≡ ψ ∧ μ.(KM3) If μ is consistent, then ψ ∗ μ is also consistent.(KM4) If ψ1 ≡ ψ2 and μ1 ≡ μ2, then ψ1 ∗ μ1 ≡ ψ2 ∗ μ2.(KM5) (ψ ∗ μ) ∧ φ (cid:3) ψ ∗ (μ ∧ φ).(KM6) If (ψ ∗ μ) ∧ φ is satisfiable, then ψ ∗ (μ ∧ φ) (cid:3) (ψ ∗ μ) ∧ φ.Readers are referred to [14] for the motivation and interpretation of these postulates.Katsuno and Mendelzon have given a representation theorem for Postulates (KM1)–(KM6) wrt a revision mecha-nism based on total pre-orders over possible world:Definition 1. A function that maps each belief set ψ to a total pre-order (cid:2)ψ on W is called a faithful assignment overbelief sets iff• If w1, w2 |= ψ , then w1 =ψ w2.• If w1 |= ψ and w2 (cid:7)|= ψ, then w1 <ψ w2.• If ψ ≡ φ, then (cid:2)ψ = (cid:2)φ.The intuitive meaning of w1 (cid:2)ψ w2 is that w1 is at least as plausible as w2 from the viewpoint of the agent whopossesses the belief set ψ. The total pre-order (cid:2)ψ is also called a faithful ranking wrt ψ.We particularly note that the last condition in Definition 1 says that faithful rankings of logically equivalent beliefsets must be identical. This essentially prohibits the possibility that in different situations the agent has the same beliefset but with different preferences among the beliefs.Theorem 1. [23] A revision operator ∗ satisfies Postulates (KM1)–(KM6) iff there exists a faithful assignment thatmaps a belief set ψ to a total pre-order (cid:2)ψ s.t.,Mods(ψ ∗ μ) = min(cid:2)Mods(μ), (cid:2)ψ(cid:3)Although the KM postulates were meant to be a reformulation of the AGM postulates for propositional logics,there is a",
            {
                "entities": [
                    [
                        3187,
                        3215,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 305 (2022) 103661Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLMMS reloaded: Transformer-based sense embeddings for disambiguation and beyondDaniel Loureiro a,∗a LIAAD - INESC TEC, Dept. of Computer Science, FCUP, University of Porto, Portugalb School of Computer Science and Informatics, Cardiff University, United Kingdom, Alípio Mário Jorge a, Jose Camacho-Collados ba r t i c l e i n f oa b s t r a c tArticle history:Received 20 May 2021Received in revised form 20 December 2021Accepted 3 January 2022Available online 5 January 2022Keywords:Semantic representationsNeural language modelsDistributional semantics based on neural approaches is a cornerstone of Natural Language Processing, with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self-supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM’s meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionLexical ambiguity is prevalent across different languages and plays an important role in improving communication ef-ficiency [87]. Word Sense Disambiguation (WSD) is a long-standing challenge in the field of Natural Language Processing (NLP), and Artificial Intelligence more generally, with an extended history of research in computational linguistics [75].Interestingly, both computational and psychological accounts of meaning representation have converged on high-dimensional vectors within semantic spaces.From the computational perspective, there is a rich line of work on learning word embeddings based on statistical regularities from unlabeled corpora, following the well-established Distributional Hypothesis [41,35, DH]. The first type of distributional word representations relied on count-based methods, initially popularized by LSA [27], and later refined with GloVe [82]. Before GloVe, word embeddings learned with neural networks, first introduced by Bengio et al. [7], gained wide adoption with word2vec [72] and, afterwards, culminated with fastText [12]. The development and improvement of word embeddings has been a major contributor to the progress of NLP in the last decade [38].* Corresponding author.E-mail addresses: daniel.b.loureiro@inesctec.pt (D. Loureiro), amjorge@fc.up.pt (A. Mário Jorge), camachocolladosj@cardiff.ac.uk (J. Camacho-Collados).https://doi.org/10.1016/j.artint.2022.1036610004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fD. Loureiro, A. Mário Jorge and J. Camacho-ColladosArtificial Intelligence 305 (2022) 103661From the psychological perspective, there is also ample behavioral evidence in support of distributional representations of word meaning. Similarly to word embeddings, these representations are related according to the degree of shared features within semantic spaces, which translates into proximity in vector-space [97,48]. Understandably, the nature of the features making up this psychological account of semantic space, among other aspects (e.g., learning method), is not as clear as we find in the computational account. Nevertheless, contextual co-occurrence is among the most informative factors for meaning representation as well [67,32,91]. There are even use cases in neurobiology motivating research into accurate dis-tributional representations of word meaning. In Pereira et al. [83], word embeddings have proven useful for decoding words and sentences from brain activity, after learning a mapping between corpus-based embeddings (i.e., GloVe and word2vec) and fMRI activation.The current understanding of how humans perform disambiguation attributes major relevance to sentential context, and other linguistic and paralinguistic cue’s (e.g., speaker accent) to a lesser extent [97,14]. However, the previously mentioned computational approaches are not designed for sense-level representation due to the Meaning Conflation Deficiency [15], as they converge different senses into the same word-level representation. Some works have explored variations on the word2vec method for sense-level embeddings [99,45,90,65], but the dynamic word-level interactions composing sentential context were not targeted by those works.The works of Melamud et al. [68], Yuan et al. [126], Peters et al. [84] were among the first to propose Neural Language Models (NLMs) featuring dynamic word embeddings conditioned on sentential context (i.e., contextual embeddings). These works showed that NLMs (trained exclusively on language modeling objectives) can produce contextual embeddings for word forms that are sensitive to the word’s usage in particular sentences. Furthermore, these works also addressed WSD tasks with a simple nearest neighbors solution (k-NN) based on proximity between contextual embeddings. Their results rivaled systems trained specifically for WSD (i.e., with additional modeling objectives), highlighting the accuracy of these contextual embeddings.However, it was not until the development of Transformer-based NLMs, namely BERT [29], that contextual embeddings from NLMs showed clearly better performance on WSD tasks than previous systems trained specifically for WSD (LMMS, Loureiro & Jorge [61]).In this earlier work, we explored how to further take advantage of the representational power of NLMs through propa-gation strategies and encoding sense definitions. Besides pushing the state-of-the-art of WSD, in Loureiro & Jorge [61] we created sense embeddings for every entry in the Princeton WordNet v3.0 (200k word senses, [34]), so that the semantic space being represented is granular and expansive enough to encompass general knowledge domains for various parts-of-speech of the English language. With this fully populated semantic space at our disposal we suggested strategies for uncovering biases and world knowledge represented by NLMs.Since our work on LMMS, others have shown additional performance gains for WSD with fine-tuning or classification approaches that make better usage of sense definitions [44,11], semantic relations from external resources [104,9], or alto-gether different approaches to WSD [5].However, there are several questions still standing regarding how to leverage NLMs for creating accurate and versatile sense embeddings, beyond optimizing for WSD benchmarks only. Given that semantic spaces with distributional represen-tations of word meanings feature prominently in both the conventional computational and psychological accounts of word disambiguation, these questions warrant further exploration.Contributions. In this extension of LMMS, we broaden our scope to more recent Transformer-based models in addition to BERT [124,59,52] (14 model variants in total), verify whether they exhibit similar proficiency at sense representation, and explore how performance variation can be attributed to particular differences in these models. Striving for a principled approach to sense representation with NLMs, we also introduce a new layer pooling method, inspired by recent findings of layer specialization [95], which we show is crucial to effectively use these new NLMs for sense representation. Most importantly, in this article we provide a general framework for learning sense embeddings with Transformers and perform an extensive evaluation of such sense embeddings from different NLMs on various sense-related tasks, emphasizing the versatility of these representations.Outline. This work is organized as follows. We first provide some background information on the main topics of this re-search: Vector Semantics (§2.1), Neural Language Modeling (§2.2) and Sense Inventories (§2.3). Next, we describe related work on Sense Embeddings (§3.1), WSD (§3.2) and Probing NLMs (§3.3).The method used to produce this work’s sense embeddings is described in Section 4, covering aspects of the method introduced in Loureiro & Jorge [61] (from §4.1 to §4.3), as well as our new layer pooling method in Section 4.4.In Section 5 we describe our experimental setting, providing relevant details about our choice of NLMs (§5.1) and anno-tated corpora used to learn sense embeddings (§5.2).The layer pooling methodology described in Section 4.4 requires validating performance under two distinct modes of ap-plication. Consequently, in Section 6 we report on performance variation per layer across NLMs (§6.1), highlight differences between disambiguation and matching profiles (§6.2), and present the rationale for choosing particular profiles for each task (§6.3).In Section 7, we tackle several sense-related tasks using our proposed sense embeddings and compare results against the state-of-the-art, namely: WSD (§7.1), Uninformed Sense Matching (§7",
            {
                "entities": [
                    [
                        3613,
                        3641,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 202 (2013) 52–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPOMDP-based control of workflows for crowdsourcingPeng Dai∗, Christopher H. Lin, Mausam, Daniel S. WeldDepartment of Computer Science and Engineering, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 20 December 2011Received in revised form 8 June 2013Accepted 9 June 2013Available online 20 June 2013Keywords:Partially-Observable Markov DecisionProcessPOMDPPlanning under uncertaintyCrowdsourcing1. IntroductionCrowdsourcing, outsourcing of tasks to a crowd of unknown people (“workers”) in anopen call, is rapidly rising in popularity. It is already being heavily used by numerousemployers (“requesters”) for solving a wide variety of tasks, such as audio transcription,content screening, and labeling training data for machine learning. However, quality controlof such tasks continues to be a key challenge because of the high variability in workerquality. In this paper we show the value of decision-theoretic techniques for the problemof optimizing workflows used in crowdsourcing. In particular, we design AI agents that useBayesian network learning and inference in combination with Partially-Observable MarkovDecision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs.We use these techniques for three distinct crowdsourcing scenarios: (1) control of votingto answer a binary-choice question, (2) control of an iterative improvement workflow,and (3) control of switching between alternate workflows for a task. In each scenario,we design a Bayes net model that relates worker competency, task difficulty and workerresponse quality. We also design a POMDP for each task, whose solution provides thedynamic control policy. We demonstrate the usefulness of our models and agents in liveexperiments on Amazon Mechanical Turk. We consistently achieve superior quality resultsthan non-adaptive controllers, while incurring equal or less cost.© 2013 Elsevier B.V. All rights reserved.The ready availability of the Internet across the world has had far-reaching consequences. Not only has widespread onlineconnectivity revolutionized communication, politics, entertainment, and other aspects of everyday life, it has enabled theability to easily unite large groups of people around the world (a crowd) for a common purpose. This ability to crowdsourcehas in turn opened up radical new possibilities and resulted in novel successes, like Wikipedia1 – a whole encyclopediawritten by the crowd, and platforms that are rapidly impacting the world’s laborforce by bringing them together in onlinemarketplaces that provide work on-demand.We believe that Crowdsourcing, “the act of taking tasks traditionally performed by an employee or contractor, and out-sourcing them to a group (crowd) of people or community in the form of an open call,”2 has the potential to revolutionizeinformation-processing services by coupling human workers with intelligent machines in productive workflows [21].* Corresponding author. Current affiliation: Google Inc., 1600 Amphitheater Pkwy, Mountain View, CA 94043.E-mail addresses: daipeng@cs.washington.edu (P. Dai), chrislin@cs.washington.edu (C.H. Lin), mausam@cs.washington.edu (Mausam),weld@cs.washington.edu (D.S. Weld).1 http://en.wikipedia.org.2 http://en.wikipedia.org/wiki/Crowdsourcing.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.06.002\fP. Dai et al. / Artificial Intelligence 202 (2013) 52–8553Fig. 1. A handwriting recognition task (almost) successfully solved on Mechanical Turk using an iterative-improvement workflow. Workers were shown thetext written by a human and in a few iterations they deduced the message (with minimal errors highlighted). Figure adapted from [37].While the word “crowdsourcing” was only coined in 2006, the area has grown rapidly in economic significance with theemergence of general-purpose platforms such as Amazon’s Mechanical Turk,3 task-specific sites for call centers,4 program-ming jobs5 and more [37,4,7,33,24].Crowdsourced workers are motivated by a variety of incentives. Common incentives include entertainment, e.g., in thecontext of playing games with a purpose [63,10], contribution to science,6 a sense of community, and monetary rewards.While our work is applicable to several crowdsourcing scenarios, we focus on financially motivated micro-crowdsourcing –crowdsourcing of small jobs in exchange for monetary payments. Labor markets, like oDesk, handle medium and large-sizedtasks requiring a diverse range of skills and micro-crowdsourcing has become very popular with requesters, who use aconcert of small-sized jobs to handle a wide variety of higher-level tasks, such as audio transcription, language translation,calorie counting [42], and helping blind people navigate unknown surroundings [7]. It has also been immensely popularwith workers in both developed and developing countries [49].On popular micro-crowdsourcing platforms, like Mechanical Turk, requesters often use workflows, a series of steps, tocomplete tasks. For instance, for a simple image classification task (e.g. “Is there a lion in this picture?”), a workflow assimple as asking several workers the same binary-choice question will suffice. For a more difficult task like the handwritingrecognition task shown in Fig. 1, a requester might create a more complicated workflow like iterative improvement, in whichworkers incrementally refine each others’ solutions until no further improvement is necessary [37]. A plethora of researchshows that for simple binary classification workflows, micro-crowdsourcing can achieve high-quality results [58,60]. Simi-larly, iterative improvement, find–fix–verify [3] and other workflows have been shown to yield excellent output even whenindividual workers err.But the use of these workflows raises many important questions. For example, when designing a workflow to handleproblems like the handwriting recognition task shown in Fig. 1, we do not know answers to questions like: (1) What is theoptimal number of iterations for such a task? (2) How many ballots should be used for voting? (3) How do these answerschange depending on workers’ skill levels?Our paper offers answers to these questions by constructing AI agents for workflow optimization and control. We studythree distinct crowdsourcing scenarios. We start by considering the problem of dynamically controlling the aggregation ofthe simplest possible workflow: binary classification. Next, we extend our model to control the significantly more complexiterative improvement workflow. Finally, we show how our model can be used to dynamically switch between alternativeworkflows for a given task.We use a shared toolbox of techniques on each of these crowdsourcing scenarios; there are two key components. First, wepropose a probabilistic model for worker responses. This model relates worker ability, task difficulty and worker responsequality by means of a Bayesian network. Second, we view the problem of workflow control as a problem of decision-theoretic planning and execution, and cast it as a Partially-Observable Markov Decision Process (POMDP) [6]. The Bayesnet provides the model for the POMDP, and the POMDP policy controls the workflow to obtain a high-quality output in acost-efficient manner.We make several important contributions. First, we provide a principled solution to dynamically decide the numberof votes for a task based on the exact history of workers who worked on a task instance, their answers and a notion of3 http://mturk.com.4 http://liveops.com.5 http://topcoder.com.6 http://galaxyzoo.org, Audubon Christmas Bird Count, etc.\f54P. Dai et al. / Artificial Intelligence 202 (2013) 52–85varying problem difficulty. We also provide a framework for answering more complex questions in larger workflows (e.g. thenumber of iterations in an iterative improvement workflow). The commonality of approaches in these diverse tasks suggestsan underlying abstraction, which may be exploited for optimizing and controlling many different kinds of workflows. Ourexperiments consistently outperform best known baselines by large margins, e.g., obtaining 50% error reduction in thescenario of multiple workflows, or 30% cost savings for iterative improvement.Moreover, our work reveals some surprising discoveries. First, for the iterative improvement scenario, our AI agentproposes a rather unexpected voting policy, which was not predicted by any human expert (see Section 4). Second, wedemonstrate that judiciously using alternative workflows for a task is much better than using a single “best” workflow.While the base idea is not novel, the fact that we can do this dynamic switching between workflows automatically toobtain high-quality results is a surprising discovery.The rest of the paper is structured as follows. Section 2 formally defines Markov Decision Processes and Partially-Observable Markov Decision Processes (POMDP). Then we review and propose planning algorithms for solving POMDPs.Section 3 details how we model and control the aggregation of a simple binary classification workflow using our firstagent, TurKontrol0. Section 4 extends our model and agent to iterative improvement workflows to create our secondagent, TurKontrol. We present some simulation-based investigation of the performance of TurKontrol, illustrate howto learn the model parameters, and finally demonstrate the usefulness of TurKontrol on Mechanical Turk, with realtasks. Section 5 details how we model the availability of multiple workflows and the design of our third agent, Agen-tHunt, which dynamically selects the next best workflow to use. We illustrate how to learn model parameters and thendemonstrate the usefulness of AgentHunt in simulation and on Mechanical Turk. Finally, we present related work, proposefuture work, and m",
            {
                "entities": [
                    [
                        3541,
                        3569,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 186 (2012) 157–173Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAugmenting tractable fragments of abstract argumentation ✩,✩✩Wolfgang Dvoˇrák, Sebastian Ordyniak, Stefan Szeider∗Institute of Information Systems, Vienna University of Technology, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 19 August 2011Received in revised form 12 January 2012Accepted 7 March 2012Available online 8 March 2012Keywords:Abstract argumentationBackdoorsComputational complexityParameterized complexityFixed-parameter tractability1. IntroductionWe present a new approach to the efficient solution of important computational problemsthat arise in the context of abstract argumentation. Our approach makes known algorithmsdefined for restricted fragments generally applicable, at a computational cost that scaleswith the distance from the fragment. Thus, in a certain sense, we gradually augmenttractable fragments. Surprisingly, it turns out that some tractable fragments admit suchan augmentation and that others do not.More specifically, we show that the problems of Credulous and Skeptical Acceptance arefixed-parameter tractable when parameterized by the distance from the fragment of acyclicargumentation frameworks—for most semantics. Other tractable fragments such as thefragments of symmetrical and bipartite frameworks seem to prohibit an augmentation:the acceptance problems are already intractable for frameworks at distance 1 from thefragments.For our study we use a broad setting and consider several different semantics. For thealgorithmic results we utilize recent advances in fixed-parameter tractability.© 2012 Elsevier B.V. All rights reserved.The study of arguments as abstract entities and their interaction in form of attacks as introduced by Dung [13] hasbecome one of the most active research branches within Artificial Intelligence, Logic and Reasoning [3,4,35]. Argumentationhandles possible conflicts between arguments in form of attacks. Arguments may either originate from a dialogue betweenseveral agents or from the pieces of information available to a single agent, this information may even contain contradic-tions. A main issue for any argumentation system is the selection of acceptable sets of arguments, called extensions, wherean acceptable set of arguments must be in some sense coherent and be able to defend itself against all attacking argu-ments. Abstract argumentation provides suitable concepts and formalisms to study, represent, and process various reasoningproblems most prominently in defeasible reasoning (see, e.g., [5,34]) and agent interaction (see, e.g., [33]).Unfortunately, important computational problems such as determining whether an argument belongs to some extension(Credulous Acceptance) or to all extensions (Skeptical Acceptance), are intractable (see, e.g., [11,16]). In order to solve theseproblems on medium or large-sized real world instances, it is significant to identify efficient algorithms. However, a fewtractable fragments are known where the acceptance problems can be efficiently solved: the fragments of acyclic [13],symmetric [10], bipartite [14], and—for most semantics—noeven [16] argumentation frameworks.✩Ordyniak and Szeider’s research has been funded by the European Research Council, grant reference 239962 (COMPLEX REASON). Dvoˇrák’s research hasbeen funded by the Vienna Science and Technology Fund (WWTF) through project ICT08-028.✩✩A preliminary and shortened version of this paper appeared in IJCAI 2011.* Corresponding author.E-mail address: stefan@szeider.net (S. Szeider).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.03.002\f158W. Dvoˇrák et al. / Artificial Intelligence 186 (2012) 157–173Table 1Complexity of acceptance problems, parameterized by the distance from a fragment.FragmentAcycNoevenBipSymadmCAFPTXPhardhardcomCAFPTXPhardhardprfCA/SAFPTXPhardhardsemCA/SAFPTXPhardhardstbCA/SAFPTXPhardhardstgCA/SAhardhardhardhardIt seems unlikely that an argumentation framework originating from a real-world application belongs to one of theknown tractable fragments, but it might be “close” to a tractable fragment.In this paper we study the natural and significant question of whether we can solve the relevant problems efficiently forargumentation frameworks that are of small distance to a tractable fragment. As the distance we take the smallest number ofarguments that must be deleted to put the framework into the tractable fragment under consideration. One would certainlyhave to pay some extra computational cost that increases with the distance from the tractable fragment, but ideally thisextra cost should scale gradually with the distance. To get a broad picture of the complexity landscape we take severalpopular semantics into consideration, namely the semantics introduced by Dung [13], i.e., admissible, complete, preferred,and stable semantics, and further semi-stable [6,7,40], and stage [40] semantics (see [2] for a survey). Our approach isinspired by the notion of “backdoors” which originates from the area of propositional satisfiability (see, e.g., [28,39,42]),and has been successfully used in other problem areas, including quantified Boolean formulas and nonmonotonic reasoning[24,38].Results. On the positive side we show that for all the considered semantics, except for stage semantics, the fragments ofacyclic and noeven argumentation frameworks admit an augmentation. In particular, we show that we can solve Credulousand Skeptical Acceptance in polynomial time for argumentation frameworks that are of bounded distance from either ofthe two fragments. We further show that with respect to the acyclic fragment, the order of the polynomial time boundis independent of the distance, which means that both acceptance problems are fixed-parameter tractable (see [12]) whenparameterized by the distance from the acyclic fragment. To obtain these results we introduce the new notion of partiallabelings of argumentation frameworks and apply recent results from fixed-parameter theory. We use partial labelings tocapture and propagate the acceptance state of certain key arguments (forming a backdoor) of the argumentation framework.On the negative side, we show that the fragments of bipartite and symmetric argumentation frameworks do not admitan augmentation. In particular, we show that the problems Credulous and Skeptical Acceptance are already intractable forargumentation frameworks at distance 1 from either of the two fragments. We also show that the acyclic and noevenfragments do not admit an augmentation with respect to the stage semantics, in contrast to the other five consideredsemantics. In particular, we show that the acceptability problems for the stage semantics are already intractable for noevenargumentation frameworks, and for argumentation frameworks at distance 1 from the acyclic fragment.To put our tractability results into context, we compare the parameters “distance to the acyclic fragment” and “distanceto the noeven fragment” with other parameters that, if bounded, make acceptance problems tractable. We show that ourdistance-based parameters are incomparable with the previously considered parameters treewidth and clique-width [14,23].Hence our augmentation approach provides an efficient solution for instances that are hard for other known methods.Table 1 summarizes our results for the different semantics and fragments. The table can be read as follows: A columnmarked CA concerns Credulous Acceptance, and a column marked CA/SA concerns both Credulous and Skeptical Acceptance,each with respect to a particular semantics as indicated. For the admissible and complete semantics we omit SkepticalAcceptance because the corresponding problems are already tractable for arbitrary frameworks [10,13]. An entry “XP”means that acceptance can be decided in polynomial time for argumentation frameworks whose distance to the fragmentis bounded by a constant (the order of the polynomial may depend on the distance); an entry “FPT” means that the accep-tance problem is fixed-parameter tractable, parameterized by the distance from the fragment; an entry “hard” means thatCredulous or Skeptical Acceptance are at least NP-hard or coNP-hard, respectively, even for instances of distance 1 from thefragment.The reminder of the paper is organized as follows. In Section 2 we provide basic definitions and preliminaries. In Sec-tion 3 we introduce the important concept of partial labelings that will be an important tool to obtain our tractabilityresults. In Section 4 we give efficient algorithms for the augmentation of the acyclic and noeven fragments. In Section 5 weestablish intractability for the bipartite and symmetric fragments. In Section 6 we strengthen the tractability results fromSection 4 with the help of strong backdoors. In Section 7 we compare our newly found parameters with already knownstructural parameters such as treewidth and clique-width. We close in Section 8 with concluding remarks. Some proofs oftechnical lemmas and theorems are given in Appendix A.2. PreliminariesAn abstract argumentation system or argumentation framework (AF, for short) is a pair ( X, A) where X is a (possiblyinfinite) set of elements called arguments and A ⊆ X × X is a binary relation called attack relation. In this paper we will\fW. Dvoˇrák et al. / Artificial Intelligence 186 (2012) 157–173159Fig. 1. Left: the AF F from Example 1. Right: indicated in gray the only non-empty complete extension of F .restrict ourselves to finite AFs, i.e., to AFs for which X is a finite set. If (x, y) ∈ A we say that x attacks y and that x is anattacker of y.An AF F = ( X, A) can be considered as a directed graph, and therefore it is convenient to borrow notions and notationfrom graph theory. For a set of arguments Y ⊆ X we denote by F [Y ] the AF (Y , {(x, y) ∈ A | x, y ∈ Y }) and by F − Y the AFF [ X \\ Y ].Example",
            {
                "entities": [
                    [
                        3724,
                        3752,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 72–104Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAn AGM-style belief revision mechanism for probabilistic spatio-temporallogicsJohn Grant a,c, Francesco Parisi b, Austin Parker c, V.S. Subrahmanian c,∗a Towson University, Towson, MD 21252, USAb Università della Calabria, 87036 Rende (CS), Italyc University of Maryland, College Park, MD 20742, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 21 September2009Accepted 6 October 2009Available online 14 October 2009Keywords:Belief revisionReasoning about motionSpatio-temporal logicsUncertainty managementThere is now extensive interest in reasoning about moving objects. A probabilistic spatio-temporal (PST) knowledge base (KB) contains atomic statements of the form “Object ois/was/will be in region r at time t with probability in the interval [(cid:2), u]”. In this paper,we study mechanisms for belief revision in PST KBs. We propose multiple methods forrevising PST KBs. These methods involve finding maximally consistent subsets and maximalcardinality consistent subsets. In addition, there may be applications where the user hasdoubts about the accuracy of the spatial information, or the temporal aspects, or aboutthe ability to recognize objects in such statements. We study belief revision mechanismsthat allow changes to the KB in each of these three components. Finally, there may bedoubts about the assignment of probabilities in the KB. Allowing changes to the probabilityof statements in the KB yields another belief revision mechanism. Each of these beliefrevision methods may be epistemically desirable for some applications, but not for others.We show that some of these approaches cannot satisfy AGM-style axioms for belief revisionunder certain conditions. We also perform a detailed complexity analysis of each of theseapproaches. Simply put, all belief revision methods proposed that satisfy AGM-style axiomsturn out to be intractable with the exception of the method that revises beliefs by changingthe probabilities (minimally) in the KB. We also propose two hybrids of these basicapproaches to revision and analyze the complexity of these hybrid methods.© 2009 Elsevier B.V. All rights reserved.1. IntroductionThere are numerous applications where we need to reason about probabilistic spatio-temporal applications. A shippingcompany may be interested in continuously tracking the locations of its vehicles. As RFID tags become ever more common,companies (pharma, automotive, electronics) are interested in tracking supply items and in understanding where these itemsare now, and where they might be in the future. Military agencies are interested in tracking where vehicles might be — nowand in the future. Cell phone companies are interested in when and where cell phones might be in the future in order todetermine how best to balance load on cell towers. Moreover, all these applications have an essential component involvinguncertainty. Predicting where a cell phone might be in the future may be derived probabilistically from past logs showingthe phones’ location. Likewise, predicting where and when an RFID tag will be is subject to uncertainty. Where and when aship will reach a given geolocation is also subject to many forces that cannot be accurately specified, even when a scheduleis available.* Corresponding author.E-mail addresses: jgrant@towson.edu (J. Grant), fparisi@deis.unical.it (F. Parisi), austinjp@cs.umd.edu (A. Parker), vs@cs.umd.edu (V.S. Subrahmanian).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.10.002\fJ. Grant et al. / Artificial Intelligence 174 (2010) 72–10473Methods to reason about probabilistic spatio-temporal (PST) information have emerged in recent years, both in databases[20] and in AI [5,18]. In this paper, we build upon the results of [20]. Our PST knowledge base contains a set of facts of theform loc(id, r, t)[(cid:2), u] which informally states that “Object o is somewhere in region r at time t with a probability between(cid:2) and u (inclusive)”. A more formal description will be provided shortly in the paper.One important aspect of applications such as those mentioned above is that there is continuous change. As objects move,they encounter unexpected situations, leading to a continuous revision of estimates of where they might be in the future, aswell as a revision of where they might have been in the past. Surprisingly, to date, we are not aware of any effort to handlerevisions to such PST knowledge bases. A PST knowledge base K can be revised in many different ways. Clearly, when theinsertion of a fact ra into the knowledge base leads to no inconsistency, i.e. K ∪ {ra} is consistent, then ra can just be addedto K. However, when K ∪ {ra} is inconsistent, then many different belief revision operations are possible.In this paper, we focus on several different ways in which to revise K based on various epistemic intuitions.• Following on much work in classical reasoning about inconsistency in AI, our revision could try to find a maximal (w.r.t.either subset inclusion or cardinality) subset K(cid:4)of K that is consistent with ra — in this case, the revision of K w.r.t.the update ra is K(cid:4) ∪ {ra}. We study these two revision strategies, show that they satisfy AGM-style axioms (defined inSection 2), and that they lead to computational intractability.• It is also possible to revise K when ra is inserted by minimally modifying the spatial, temporal, or object componentsin K.– We first propose a revision mechanism based on just modifying the object ids in a PST KB. An application user ordeveloper may wish to use this strategy for an application when there is reason to believe that the object ids arelikely to be incorrect. This may occur, for instance, when the PST KB is generated using an image processing program(e.g. a car license plate reader) that may be “off”.– We also propose a revision mechanism based on just modifying the temporal component in a PST KB. An applicationuser or developer may wish to use this strategy for an application when there is reason to believe that the timesreported are “off”. This may be due to historical skepticism such as the belief that the clocks used to automaticallygenerate PS KBs in the application are flawed.– We also propose a revision mechanism based on just modifying the spatial component in a PST KB. An applicationuser or developer may wish to use this strategy for an application when there is reason to believe that the regionsare inaccurate. This may be due to the fact that GPS transponders exhibited errors previously.We develop all these revision mechanisms. We show that spatial revisions may not satisfy AGM-style axioms and thatthe other mechanisms — though they satisfy AGM-style axioms — are computationally intractable.• We also propose three revision mechanisms based on revising the probability intervals in a PST KB. In one, only thelower bound is modified, in another, only the upper bound is modified, and in the third, both may be simultaneouslymodified. We show that the last mechanism not only satisfies AGM-style axioms, but that there is a polynomial timealgorithm to compute this update mechanism. An end user may use this mechanism when there is reason to believethat the probabilities in a PST KB are likely to be incorrect.• We also propose a revision mechanism that allows simultaneous changes to each of the spatial, temporal, object, andprobability components in PST KBs. The user can specify how unlikely each of these mechanisms may be wrong bysetting appropriate weights.Fig. 1 summarizes the types of revision methods proposed in this paper — it also states whether the method satisfies AGM-style axioms or not, and the computational complexity involved. As probabilistic revision is polynomial, we spend a fairamount of time focusing on speeding this up via the use of a suite of heuristics.Fig. 1. A summary of this paper’s results. Unless otherwise stated, all results assume that T is finite.\f74J. Grant et al. / Artificial Intelligence 174 (2010) 72–104This paper builds on some of our previous work on representing and reasoning about probabilistic spatio temporal (PST)knowledge bases [23]. Section 2 formalizes the notion of a PST KB from some of our past work, overviews AGM axiomsfor updating logical theories, and provides a linear programming based algorithm to check the consistency of PST KBs.Section 3 provides many possible ways of revising a PST KB and shows which of these methods satisfy AGM-style axioms,and also analyzes the computational complexity of implementing these methods. Section 4 provides two hybrid methods torevise PST KBs based on the basic methods proposed previously. We study whether these hybrid methods satisfy AGM-styleaxioms, as well as the computational complexity of these methods. Section 5 identifies a partitioning strategy that may beused to more quickly find an approximate solution to probabilistic revision problems. Section 6 compares our work withrelated work in the scientific literature. At the end, Section 7 identifies directions for future work on reasoning about PSTKBs.All proofs not given in the text are given in Appendices A and B.2. Background: Formal model[20,21] proposes a framework for probabilistic spatio-temporal reasoning in which we can reason about statementsof the form “Object o is/was/will be in region r at time t with a probability within the interval [(cid:2), u]”. We assume theexistence of some finite set ID of object ids. We generally assume a finite convex set S of points in a 2-dimensional space1;however, in some cases the 2-dimensionality of space is irrelevant and we simply deal with a set of points, |S| > 1. We usedistance(p, q) to represent the Euclidean distance between p and q. We assume that time, T , is represented by the set of allnon-negative integers. How",
            {
                "entities": [
                    [
                        3676,
                        3704,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 935–981Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDialogue games that agents play within a societyNishan C. Karunatillake a,∗, Nicholas R. Jennings a, Iyad Rahwan b,c, Peter McBurney da School of Electronics and Computer Science, University of Southampton, SO17 1BJ, United Kingdomb (Fellow) School of Informatics, University of Edinburgh, Edinburgh, EH8 9LE, United Kingdomc Faculty of Informatics, The British University in Dubai, PO Box 502216 Dubai, United Arab Emiratesd Department of Computer Science, University of Liverpool, Liverpool, L69 7ZF, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 21 December 2007Received in revised form 19 January 2009Accepted 3 February 2009Available online 21 February 2009Keywords:Dialogue game protocolsMulti-agent negotiationSocial conflict resolutionArgument schemesHuman societies have long used the capability of argumentation and dialogue to overcomeand resolve conflicts that may arise within their communities. Today, there is an increasinglevel of interest in the application of such dialogue games within artificial agent societies.In particular, within the field of multi-agent systems, this theory of argumentation anddialogue games has become instrumental in designing rich interaction protocols and inproviding agents with a means to manage and resolve conflicts. However, to date, much ofthe existing literature focuses on formulating theoretically sound and complete models formulti-agent systems. Nonetheless, in so doing, it has tended to overlook the computationalimplications of applying such models in agent societies, especially ones with complexsocial structures. Furthermore, the systemic impact of using argumentation in multi-agent societies and its interplay with other forms of social influences (such as those thatemanate from the roles and relationships of a society) within such contexts has alsoreceived comparatively little attention. To this end, this paper presents a significant steptowards bridging these gaps for one of the most important dialogue game types; namelyargumentation-based negotiation (ABN). The contributions are three fold. First, we presenta both theoretically grounded and computationally tractable ABN framework that allowsagents to argue, negotiate, and resolve conflicts relating to their social influences within amulti-agent society. In particular, the model encapsulates four fundamental elements: (i) ascheme that captures the stereotypical pattern of reasoning about rights and obligationsin an agent society, (ii) a mechanism to use this scheme to systematically identify socialarguments to use in such contexts, (iii) a language and a protocol to govern the agentinteractions, and (iv) a set of decision functions to enable agents to participate in suchdialogues. Second, we use this framework to devise a series of concrete algorithms that giveagents a set of ABN strategies to argue and resolve conflicts in a multi-agent task allocationscenario. In so doing, we exemplify the versatility of our framework and its ability tofacilitate complex argumentation dialogues within artificial agent societies. Finally, we carryout a series of experiments to identify how and when argumentation can be useful foragent societies. In particular, our results show: a clear inverse correlation between thebenefit of arguing and the resources available within the context; that when agents operatewith imperfect knowledge, an arguing approach allows them to perform more effectivelythan a non-arguing one; that arguing earlier in an ABN interaction presents a more efficientmethod than arguing later in the interaction; and that allowing agents to negotiate theirsocial influences presents both an effective and an efficient method that enhances theirperformance within a society.© 2009 Elsevier B.V. All rights reserved.* Corresponding author.E-mail addresses: nnc@ecs.soton.ac.uk (N.C. Karunatillake), nrj@ecs.soton.ac.uk (N.R. Jennings), irahwan@acm.org (I. Rahwan), mcburney@liverpool.ac.uk(P. McBurney).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.02.002\f936N.C. Karunatillake et al. / Artificial Intelligence 173 (2009) 935–9811. IntroductionAutonomous agents usually exist within a multi-agent community, performing actions within a shared social contextto achieve their individual and collective objectives [81]. In such situations, the actions of these individual agents are in-fluenced via two broad forms of motivations. First, the internal influences reflect the intrinsic motivations that drive theindividual agent to achieve its own internal objectives. Second, as agents reside and operate within a social community, thesocial context itself influences their actions. For instance, when agents function within a society that has an organisationalstructure, they may assume certain specific roles or be part of certain relationships. These, in turn, may influence the actionsthat an agent may perform. Here, we categorise such external forms of motivations as social influences.Now, in many cases, both these forms of influence are present and they may give conflicting motivations to the individualagent. For instance, an agent may be internally motivated to perform a specific action. However, at the same time, it mayalso be subject to an external social influence (via the role it is assuming or the relationship that it is part of) not todo so. To illustrate this more clearly, let us consider an example relationship that exists between the two roles supervisorand student.1 Assume that, as a result of this supervisor-student relationship, any agent who assumes the role of studentis socially influenced to produce and hand over his thesis to his supervisor in a timely manner. Therefore, if an agentnamed Andy assumes the role of the student and another named Ben assumes the role of his supervisor, Andy will besocially influenced by Ben to hand over the thesis in time. However, if Andy also has a certain internal motivation to usethat limited time on some other activity (i.e., finish some programming work), a conflict will arise between Andy’s socialinfluence and his internal influence. In such a case, if Andy decides to pursue his internal motivation at the expense ofhis social influence, this may, in turn, manifest itself as a conflict between the two agents since Ben may well have aninterest in Andy abiding by his social influence and hand over his thesis in time. Also an agent may face situations wheredifferent social influences motivate it in a contradictory manner (one to perform a specific action and the other a differentconflicting action). For instance, if Andy is also part of a project, his project manager (Cindy) may socially influence Andyto use his time integrating some software component. Similar to above, in such an event, if the agent decides to abide by acertain social influence and forgo the other, it may also lead to a conflict between that agent and the agent that exerts theneglected social influence.In addition to such disparate motivations, due to the complexity and dynamism usually present within multi-agent sys-tems, in many cases, agents have to carry out their actions with imperfect knowledge about their environment. Specifically,when agents operate within a social context, they may not have complete knowledge about the capabilities, roles, or rela-tionships that they and their counterparts are deemed to assume within the society. Thus, in such instances, an agent maynot be aware of the existence of all the social influences that could or indeed should affect its actions. For instance, Andymay not be aware that Cindy was appointed as the new project manager. Thus, he may not believe that he is required toperform any integration work that Cindy may demand of him. Moreover, agents may also lack the knowledge of certainspecific social and internal influences that motivate other agents’ actions within the community. For instance, Andy may notbe aware of the fact that the university will incur a large penalty if the project integration is not completed in time. Thus,due to the absence of this knowledge, he may chose to write his thesis believing it is more important than the integrationwork. As can be seen, therefore, the lack of knowledge about social influences can also lead to conflicts between agents.From the above discussion, it can be seen that when agents operate in a society with incomplete information and withdiverse and conflicting influences, they may, in certain instances, lack the knowledge, the motivation and/or the capacityto abide by all their social influences. However, to function as a coherent society it is important for these agents to havea means to resolve such conflicts, manage their internal and social influences, and, thus, come to a mutual understandingabout their actions.In searching for a solution to this problem, we observe that when individuals operate within a human society, theyencounter similar forms of conflicts in their day to day life. For instance, when carrying out their actions humans encounterinfluences from different elements within the society, some of which are in conflict with one another. Furthermore, theyalso perform their actions in the presence of incomplete information about their social context. Thus, they also face conflictsdue to their lack of knowledge about certain influences within the society. However, mainly due to their skill in language,dialogue, and debate, human beings have adapted to use different forms of complex interactions to manage and resolve suchconflicts. To this end, researchers and philosophers from different branches of AI, linguistics, dialogue theory, and logic havelong been inspired by this human social ability and have tried to capture and model such behaviour [53,75]. Such studieshave given birth to a number of different dialogue models [80]",
            {
                "entities": [
                    [
                        4191,
                        4219,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 300–324www.elsevier.com/locate/artintAutomatic scoring of short handwritten essays in readingcomprehension testsSargur Srihari ∗, Jim Collins, Rohini Srihari, Harish Srinivasan, Shravya Shetty,Janina Brutt-GrifflerCenter of Excellence for Document Analysis and Recognition (CEDAR) University at Buffalo, State University of New York,Amherst, NY 14228, USAReceived 14 September 2006; received in revised form 27 June 2007; accepted 29 June 2007Available online 24 July 2007AbstractReading comprehension is largely tested in schools using handwritten responses. The paper describes computational methods ofscoring such responses using handwriting recognition and automatic essay scoring technologies. The goal is to assign to each hand-written response a score which is comparable to that of a human scorer even though machine handwriting recognition methods havehigh transcription error rates. The approaches are based on coupling methods of document image analysis and recognition togetherwith those of automated essay scoring. Document image-level operations include: removal of pre-printed matter, segmentationof handwritten text lines and extraction of words. Handwriting recognition is based on a fusion of analytic and holistic methodstogether with contextual processing based on trigrams. The lexicons to recognize handwritten words are derived from the read-ing passage, the testing prompt, answer rubric and student responses. Recognition methods utilize children’s handwriting styles.Heuristics derived from reading comprehension research are employed to obtain additional scoring features. Results with two meth-ods of essay scoring—both of which are based on learning from a human-scored set—are described. The first is based on latentsemantic analysis (LSA), which requires a reasonable level of handwriting recognition performance. The second uses an artificialneural network (ANN) which is based on features extracted from the handwriting image. LSA requires the use of a large lexiconfor recognizing the entire response whereas ANN only requires a small lexicon to populate its features thereby making it practicalwith current word recognition technology. A test-bed of essays written in response to prompts in statewide reading comprehensiontests and scored by humans is used to train and evaluate the methods. End-to-end performance results are not far from automaticscoring based on perfect manual transcription, thereby demonstrating that handwritten essay scoring has practical potential.© 2007 Elsevier B.V. All rights reserved.Keywords: Automatic essay scoring; Contextual handwriting recognition; Reading comprehension; Latent semantic analysis; Artificial neuralnetworks1. IntroductionReading comprehension is an important component of learning in schools. Tasks that require students to writeabout texts are ubiquitous at all levels of schooling and assessment, and low-performing writers have difficulty with* Corresponding author.E-mail address: srihari@cedar.buffalo.edu (S. Srihari).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.06.005\fS. Srihari et al. / Artificial Intelligence 172 (2008) 300–324301such tasks. For example, a recent New York State assessment of fourth grade English language arts asked studentsto write after reading an essay and a poem about whales, and the prompt clearly specified that students should useinformation from the texts they had read in their responses. The test prompt and two responses were as follows.Test Prompt:Do you think that fishing boats should be allowed in waters where whales swim? Why or why not? Use detailsfrom BOTH the article and the poem to support your answer. In your answer, be sure to– state your opinion,– explain your reasons for this opinion,– support your opinion using information from BOTH the article and the poem.Low Scoring Response:“They should not be a loud where whale are. Because whale need to swim or they will die”.High Scoring Response:“I think fishing boats should not be allowed where whales are because the people might hurt the whale or get it inthe fishing net and the whale might eat the fish in the fishing net and the people might throw a spear at it. Theymight even go and kill the whale for no reason what so ever. They might even hurt the whale with the boat and itmight get killed that way. That is why I think that fishing boats and not allowed where whales are”.Whereas the second writer presents a relatively full, logically connected, and error free response, the first writeruses information minimally, far from the extent necessary to form a skilled argument.While electronically written responses are becoming the standard for college level entrance testing, handwrittenresponses are the principal means in state-wide testing in schools. This is due to issues such as how early to introducekey-boarding skills, academic integrity with closely spaced test stations, network down-time during testing, etc. Sincethe approach of using handwritten essays in reading comprehension evaluation is efficient and reliable it is likely toremain a key component of learning.Writing done by hand is the primary means of testing students on state assessments. Consider as an example theNew York State English Language Assessment (ELA) administered statewide in grades 5 and 8. In the reading partof the test the student is asked to read a passage such as that given in Fig. 1, which is a grade 8 example, and respondto several prompts in writing. An example prompt is: “How was Martha Washington’s role as First Lady differentfrom that of Eleanor Roosevelt? Use information from American First Ladies in your answer”. The completed answersheets of three different students to the prompt are given in Fig. 2. The responses are scored by human assessors on aseven-point scale of 0–6. A rubric for the scoring is given in Table 1. This is referred to as a holistic rubric—which isin contrast to an analytic rubric that captures several writing traits.Assessing large numbers of handwritten responses is a relatively time-consuming and monotonous task. At thesame time there is an intense need to speed up and enhance the process of rating handwritten responses, while main-taining cost effectiveness. The assessment can also be used as a source of timely, relatively inexpensive and responsiblefeedback about writing. The paper describes a first attempt at designing a system for reading, scoring and analyzinghandwritten essays from large scale assessments to provide assessment results and feedback. Success in designingsuch a system will not only allow timely feedback to students but also can provide feedback to education researchersand educators.There is significant practical and pedagogical value in computer-assisted evaluation of such tests. The task ofscoring and reporting the results of these assessments in a timely manner is difficult and relatively expensive. Thereis also an intense need to test later in the year for the purpose of capturing the most student growth and at the sametime meet the requirement to report student scores before summer break. The biggest challenge is that of reading andscoring the handwritten portions of large-scale assessments.From the research viewpoint an automated solution will allow studying patterns among handwritten essays thatmay be otherwise laborious or impossible. For instance metrics can be obtained for identifying difficulties strugglingstudents are having, for measuring repetition of sections from the original passage, for identifying language constructsspecific to the population, etc.The assessment problem is a well-defined problem whose solution will push forward existing technologies ofhandwriting recognition and automatic essay scoring. A grand challenge of artificial intelligence (AI) is that of a\f302S. Srihari et al. / Artificial Intelligence 172 (2008) 300–324Fig. 1. Text passage to be read. From the New York English Language Arts assessment for Grade 8, 2001—two of three pages of the story “AmericanFirst Ladies” are shown.Fig. 2. Sample answer sheets of three students (a)–(c) based on the reading comprehension passage of Fig. 1. The human assigned scores for theseessays, on a scale of 0–6, were 2, 4 and 4 respectively.computer program to read a chapter in a freshman physics textbook and answer prompts at the end of the chapter [27].Our challenge is go the other way to evaluate student responses which are handwritten. Much of AI research hasprogressed in the quest for solutions for specific problems, and this problem promises to be an exciting one both in\fS. Srihari et al. / Artificial Intelligence 172 (2008) 300–324303Table 1Holistic rubric chart for the prompt “How was Martha Washington’s role as First Lady different from that of Eleanor Roosevelt?”6Understandingof textUnderstanding ofsimilarities anddifferencesamong the rolesCharacteristicsof first ladiesComplete,accurate andinsightfulFocused,fluent andengaging5Understandingroles offirst ladiesOrganized4Logicaland accurateOnly literalunderstandingof article3PartialUnderstandingDrawingconclusionsabout roles offirst ladies2Readable1BriefNot logicalRepetitiveNot thoroughlyelaborateOrganizedSketchyLimitedunderstandingUnderstoodonly sectionsToogeneralizedWeakFacts withoutsynchronizationterms of the task and its use. Solving the problem also promises to reduce costs and raise efficiency of large-scaleassessments.This is an interdisciplinary project involving three distinct knowledge areas: optical handwriting recognition(OHR), automatic essay scoring (AES) and reading comprehension studies. OHR may first be viewed as largely anengineering enterprise concerning data input. However the challenges posed in deciphering handwriting, particularlythat of children, makes it a truly difficult AI task. AES is a topic involving computational linguistics which has prac-tical solutions, however dealing with very noisy textual input calls for new methods",
            {
                "entities": [
                    [
                        3123,
                        3151,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 441–456Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRevenue monotonicity in deterministic, dominant-strategy combinatorialauctionsBaharak Rastegari∗, Anne Condon, Kevin Leyton-BrownDepartment of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver, B.C., Canada, V6T 1Z4a r t i c l ei n f oa b s t r a c tArticle history:Available online 15 September 2010Keywords:Mechanism designCombinatorial auctionsRevenue1. IntroductionIn combinatorial auctions using VCG, a seller can sometimes increase revenue bydropping bidders. In this paper we investigate the extent to which this counterintuitivephenomenon can also occur under other deterministic, dominant-strategy combinatorialauction mechanisms. Our main result is that such failures of “revenue monotonicity” canoccur under any such mechanism that is weakly maximal—meaning roughly that it choosesallocations that cannot be augmented to cause a losing bidder to win without hurtingwinning bidders—and that allows bidders to express arbitrary known single-mindedpreferences. We also give a set of other impossibility results as corollaries, concerningrevenue when the set of goods changes, false-name-proofness, and the core.1Crown Copyright © 2010 Published by Elsevier B.V. All rights reserved.In combinatorial auctions (CAs), multiple goods are sold simultaneously and bidders are allowed to place bids on bun-dles, rather than just on individual goods. These auctions are interesting in settings where bidders have non-additive—andparticularly, superadditive—values for goods. (For an introduction, see Cramton et al. [12].) As with other applications ofmechanism design, the design of combinatorial auctions has tended to focus on the theoretical properties that a givendesign can guarantee.It is often desired for an auction mechanism to offer bidders the dominant strategy of truthfully revealing their privateinformation to the mechanism. (By the revelation principle, the assumption that bidders declare truthfully is without lossof generality; however, not all mechanisms offer dominant strategies.) Another useful property is revenue monotonicity, theguarantee that the seller’s revenue weakly increases as the number of bidders grows. Revenue monotonicity is importantbecause, without it the auctioneer has an incentive to disqualify bidders to increase revenue. Similarly, in such auctions abidder might find it profitable to place pseudonymous bids in order to reduce the seller’s revenue.We begin with a discussion of related work in the literature concerning dominant strategy truthfulness and revenuemonotonicity.1.1. Dominant strategy implementationConsiderable research has characterized the space of social choice functions that can be implemented in dominant strate-gies. A classic result of Roberts [26] showed that for bidders with unrestricted quasilinear valuations, affine maximizers are* Corresponding author.E-mail addresses: baharak@cs.ubc.ca (B. Rastegari), condon@cs.ubc.ca (A. Condon), kevinlb@cs.ubc.ca (K. Leyton-Brown).1 We previously published a six-page preliminary version of our main result at a conference (Rastegari et al., 2007) [24]. Among other differences, thiswork considered a very limited version of our weak maximality condition that can be understood as requiring Pareto efficiency with respect to biddervaluations (i.e., ignoring payments).0004-3702/$ – see front matter Crown Copyright © 2010 Published by Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.08.005\f442B. Rastegari et al. / Artificial Intelligence 175 (2011) 441–456the only dominant-strategy-implementable social choice functions. Subsequent work has focused mainly on restricted classesof preferences [27,17,9,29,11].The VCG mechanism [31,10,16] has gained substantial attention in mechanism design literature because of its strongtheoretical properties. In particular, it offers dominant strategies and achieves efficiency. Indeed, no substantially different(technically, no non-Groves) mechanism can guarantee these properties for agents with general quasilinear valuations [15].VCG is computationally intractable,2 thus, there have been many attempts to design feasible dominant strategy truthfulmechanisms, even if for restricted classes of valuations. Archer and Tardos [2], Andelman and Mansour [1] and Mu’alem andNisan [19] studied the design of dominant strategy truthful mechanisms for combinatorial settings with single-parameteragents: agents whose private information can be encoded in a single positive real number. Babaioff et al. [6,7] studied CAdesign in single-value domains under the further assumption that each agent has the same value for all desired outcomes.Yokoo et al. [34,35,33] studied the design of dominant strategy truthful mechanisms for settings in which bidders maysubmit multiple bids using pseudonyms.1.2. Revenue monotonicityA main concern for auctioneers is an auction’s revenue. In this paper we focus on a particular revenue-related property:that a seller’s revenue from an auction is guaranteed weakly to increase as the number of bidders grows. Ausubel andMilgrom [4] dubbed this property bidder monotonicity. In order to emphasize that we are concerned with monotonicity ofrevenue—as compared to some other auction property—we prefer the term bidder revenue monotonicity. This can be con-trasted with e.g., good revenue monotonicity, the property that a seller’s revenue from an auction is guaranteed to weaklyincrease as the number of goods at the auction grows. We are primarily interested in the former property; thus, as ashorthand we abbreviate bidder revenue monotonicity simply as revenue monotonicity.It is easy to see that even VCG is not (bidder) revenue monotonic. Following an example due to Ausubel and Milgrom [5],consider an auction with three bidders and two goods for sale. Suppose that bidder 2 values the bundle of both goods at $2billion whereas bidder 1 and bidder 3 value the first and the second goods at $2 billion respectively. The VCG mechanismawards the goods to bidders 1 and 3 for the price of zero, yielding the seller zero revenue. However, in the absence ofeither bidder 1 or bidder 3, the auction would generate $2 billion in revenue.∗S(cid:2) V∗S∪{i} − V∗S(cid:3)∪{i} − V∗S(cid:3) , where VDifferent approaches have been proposed for understanding the extent of revenue non-monotonicity problems. One ap-proach has considered VCG’s performance under restricted valuation classes. Say that the combined valuation of bidders satisfiesbidder submodularity if and only if for any bidder i and any two sets of bidders S and S, it is the case that∗VS is the maximum social welfare achievable under S. Ausubel and Milgrom [4] showedthat if the combined valuation of bidders satisfies bidder submodularity then VCG is guaranteed to be revenue monotonic.Bidder submodularity is implied by the goods are substitutes condition (see, e.g., Ausubel and Milgrom [4] for a definition).However, in many application domains for which combinatorial auctions have been proposed, goods are not substitutesand bidders’ valuations exhibit complementarity. We therefore wish to investigate revenue monotonicity in domains wherearbitrary complementarity may exist. The simplest such domain is that of known single-minded bidders. Roughly speaking,a known single-minded bidder desires only a specific, known bundle, valuing that bundle and all its supersets at the sameamount and any other bundle at zero. Note that VCG is not revenue monotonic in this domain, as demonstrated in theabove example.with S ⊆ S(cid:3)(cid:3)Day and Milgrom [13] showed that, under the assumption that bidders follow a so-called “best-response truncationstrategy,” auctions that always select an outcome that is in the core with respect to declared valuations (so-called core-selecting auctions) are revenue monotonic when they select a core outcome that minimizes the seller’s revenue. (A precursorto this result also appeared in Ausubel and Milgrom [4].) Thus, the ascending proxy auction proposed by Ausubel andMilgrom [4] and the clock-proxy auction proposed by Ausubel et al. [3] are both revenue monotonic when agents playsuch a best-response strategy, but do not offer dominant strategies. Other mechanisms that have been proposed for use inpractice similarly lack dominant strategies (see, e.g., Bernheim and Whinston [8], Rassenti et al. [23] and Porter et al. [22]);we are not aware of any result in the literature that shows whether or not they are revenue monotonic.While revenue monotonicity is a feature of some auction mechanisms that have been deployed in practice, dominantstrategies are (perhaps surprisingly) uncommon. This fact underscores the practical importance of revenue properties likerevenue monotonicity, while pointing out that auctioneers are willing to sacrifice the strategic simplicity of dominant strate-gies.1.3. Overview of our workIn our work, we ask whether there exists a combinatorial auction mechanism that allows bidders to express arbitraryknown single-minded preferences and that is both dominant strategy truthful and revenue monotonic.If dominant strategy truthfulness and revenue monotonicity are the only conditions we require, it is easy to answerthe above question in the affirmative. Specifically, we can offer all goods as one indivisible bundle using a second-price2 Indeed, VCG has a host of other drawbacks too; see, e.g., Rothkopf [28].\fB. Rastegari et al. / Artificial Intelligence 175 (2011) 441–456443sealed-bid auction. However, this mechanism is unappealing, because it is combinatorial only in a degenerate sense. If wewant to require the mechanism to allocate the goods more sensibly than through a static pre-bundling, we must ask forsome further property. Very restrictively, we could require efficiency. In this work, we exchange efficiency for the muchmore inclusive notion of weak maximality. While efficiency requires",
            {
                "entities": [
                    [
                        3552,
                        3580,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 897–921www.elsevier.com/locate/artintLaying the foundations for aWorld Wide Argument WebIyad Rahwan a,∗,1, Fouad Zablith a, Chris Reed ba Institute of Informatics, British University in Dubai, United Arab Emiratesb School of Computing, University of Dundee, UKReceived 8 November 2006; received in revised form 4 April 2007; accepted 4 April 2007Available online 10 May 2007AbstractThis paper lays theoretical and software foundations for a World Wide Argument Web (WWAW): a large-scale Web of inter-connected arguments posted by individuals to express their opinions in a structured manner. First, we extend the recently proposedArgument Interchange Format (AIF) to express arguments with a structure based on Walton’s theory of argumentation schemes.Then, we describe an implementation of this ontology using the RDF Schema Semantic Web-based ontology language, and demon-strate how our ontology enables the representation of networks of arguments on the Semantic Web. Finally, we present a pilotSemantic Web-based system, ArgDF, through which users can create arguments using different argumentation schemes and canquery arguments using a Semantic Web query language. Manipulation of existing arguments is also handled in ArgDF: users canattack or support parts of existing arguments, or use existing parts of an argument in the creation of new arguments. ArgDF alsoenables users to create new argumentation schemes. As such, ArgDF is an open platform not only for representing arguments, butalso for building interlinked and dynamic argument networks on the Semantic Web. This initial public-domain tool is intended toseed a variety of future applications for authoring, linking, navigating, searching, and evaluating arguments on the Web.© 2007 Elsevier B.V. All rights reserved.Keywords: Argument schemes; Argumentation; Tools; E-democracy; Argument interchange format; Semantic web1. IntroductionArgumentation can be defined as a verbal and social activity of reason aimed at increasing (or decreasing) theacceptability of a controversial standpoint for the listener or reader, by putting forward a constellation of propositions(i.e. arguments) intended to justify (or refute) the standpoint before a rational judge [53, page 5]. The theory of argu-mentation is a rich, interdisciplinary area of research encompassing but not exclusive to philosophy, communicationstudies, linguistics, and psychology.* Corresponding author.E-mail addresses: irahwan@acm.org (I. Rahwan), fouad@zablith.org (F. Zablith), chris.reed@computing.dundee.ac.uk (C. Reed).URLs: http://homepages.inf.ed.ac.uk/irahwan/ (I. Rahwan), http://fouad.zablith.org (F. Zablith),http://www.computing.dundee.ac.uk/staff/creed/ (C. Reed).1 (Fellow) School of Informatics, University of Edinburgh, UK.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.015\f898I. Rahwan et al. / Artificial Intelligence 171 (2007) 897–921A variety of opinions and arguments are presented every day on the Web, in discussion forums, blogs,2 newssites, etc. As such, the Web acts as an enabler of large-scale argumentation, where different views are presented,challenged, and evaluated by contributors and readers. However, these methods do not capture the explicit structureof argumentative viewpoints. This makes the task of evaluating, comparing and identifying the relationships amongarguments difficult.First, let us outline our long-term vision through a scenario. You query the Web (e.g. through an appropriate formthat generates a formal query) by asking a question like ‘List all arguments that support the War on Iraq on the basisof expert assessment that Iraq has Weapons of Mass Destruction (WMDs).’ You are presented with various argumentsordered by strength (calculated using the number and quality of its supporting and attacking arguments). One of thesearguments is a blog entry, with a semantic link to a CIA report claiming the presence of WMDs. You inspect thecounterarguments to the CIA reports and find an argument that attacks them by stating that ‘CIA experts are biased.’You inspect this attacking argument and you find a link to a BBC article discussing various historical examples of theCIA’s alignment with government policies, and so on.Motivated by the above vision, we lay theoretical and software foundations of a World Wide Argument Web(WWAW): a large-scale Web of inter-connected arguments posted by individuals on the World Wide Web in a struc-tured manner. The theoretical foundation is an ontology of arguments, extending the recently proposed ArgumentInterchange Format [11], and capturing Walton’s general theoretical account of argumentation schemes [57]. For thesoftware foundation, we build on the strengths and potential of the Semantic Web [4] and implement the ontology us-ing the RDF Schema Semantic Web ontology language. We then present a pilot Semantic Web-based system, ArgDF,through which users can create arguments using different argumentation schemes and can query arguments using aSemantic Web query language. Manipulation of existing arguments is also handled in ArgDF: users can attack orsupport parts of existing arguments, or use existing parts of an argument in the creation of new arguments. ArgDFalso offers flexible features, such as the ability to create new argumentation schemes from the user interface. As such,ArgDF is an open platform not only for representing arguments, but also for building interlinked and dynamic argu-ment networks on the Semantic Web. This initial public-domain tool is intended to seed what it is hoped will becomea rich suite of sophisticated applications for authoring, linking, navigating, searching, and evaluating arguments onthe Web.This paper advances the state of the art in computational modelling of argumentation in three ways. First, it presentsthe first Semantic Web-based system for argument annotation, navigation and manipulation. Second, the paper pro-vides the first highly scalable yet highly-structured argument representation capability on the Web. This contrasts withcurrent group argumentation support systems, which are either scalable but weakly-structured, or highly-structured buttheory-dependent and only applicable to small numbers of participants. Finally, the paper contributes to the recentlyproposed Argument Interchange Format (AIF) ontology [11] by extending it to capture Walton’s argument schemes[57] and providing a complete implementation of the AIF in a Semantic Web language.3 If successful, the WWAWwill be the largest argumentation support system ever built because its construction is not centralised, but distributedacross contributors and software developers in the model of many emerging Web 2.0 applications.4The rest of the paper is organised as follows. In the next section, we discuss the different enabling componentsof large-scale argumentation. In Section 3, we present an overview of the current state of the Argument InterchangeFormat. We present our extensions to the AIF in Section 4 and discuss its RDFS implementation in Section 5. Wethen present the pilot system ArgDF in Section 6. We conclude the paper and discuss future potential applications inSection 7.2. Enablers of large-scale argumentationArgumentation-based techniques and results have found a wide range of applications in both theoretical and prac-tical branches of artificial intelligence and computer science [43] ranging from non-monotonic reasoning [10,37] to2 A blog (short for Web-log) is a user-generated website where entries (e.g. commentaries, news, diary items) are presented in journal style anddisplayed in a reverse chronological order.3 To our knowledge, the only other representation of the AIF using Semantic Web languages is a preliminary attempt by the first author [40].4 Web 2.0 is a term that has become widely used to refer to second-generation Web services that emphasise user collaboration, such as socialnetworking sites, collaborative tagging sites (for so called folksonomy meta-data generation), mass collaborative editing (through wikis [28]), etc.\fI. Rahwan et al. / Artificial Intelligence 171 (2007) 897–921899knowledge engineering [8], to multi-agent systems’ communication and negotiation [38,39]. Another area that haswitnessed significant growth is argumentation-support systems [25]. Our interest here is mainly in the latter, and par-ticularly in large-scale argumentation support in a Web environment. By argumentation support, we mean tools thatenable users to browse, visualise, search, and manipulate arguments and argument structures. There is a great diversityof resources that can be drawn upon in trying to build the foundation for the WWAW, including tools for interactionand visualisation, and, first and foremost, arguments themselves.2.1. ArgumentsThe first important component of large-scale argumentation are the arguments themselves. In this sub-section,we discuss the availability of argument corpora, which may be used as a basis for providing argument search andnavigation capabilities.Currently, the largest corpus of analysed arguments is the AraucariaDB corpus from the University of Dundee[41]. It has around 500 arguments, produced by expert analysts, and drawn from newspapers, magazines, judicialreports, parliamentary records and online discussion groups from various countries and in different domains. Anothersignificant analysis effort has been carried out at McMaster [22], and takes a smaller set of academic arguments asa sample upon which to evaluate aspects of theories of argument. Globalargument5 is taking a different approach—that of encouraging many research groups to apply different analysis techniques to a common body of arguments. Atthe time of writing, the Globalargument community has managed several very detailed analyses of a single extendedargument. Apart from these, no other academic effort at systematic analysis of arguments is known. Investigations suchas t",
            {
                "entities": [
                    [
                        2880,
                        2908,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 229 (2015) 105–125Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVariable symmetry breaking in numerical constraint problems ✩Alexandre Goldsztejn a, Christophe Jermann b,∗Carme Torras ca IRCCyN, CNRS, Nantes, Franceb LINA, Université de Nantes/CNRS, Nantes, Francec Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain, Vicente Ruiz de Angulo c, a r t i c l e i n f oa b s t r a c tArticle history:Received 10 December 2014Received in revised form 6 August 2015Accepted 16 August 2015Available online 20 August 2015Keywords:Constraint programmingSymmetriesNumerical constraintsVariable symmetriesSymmetry breaking has been a hot topic of research in the past years, leading to many theoretical developments as well as strong scaling strategies for dealing with hard applications. Most of the research has however focused on discrete, combinatorial, problems, and only few considered also continuous, numerical, problems. While part of the theory applies in both contexts, numerical problems have specificities that make most of the technical developments inadequate.In this paper, we present the rlex constraints, partial symmetry-breaking inequalities corresponding to a relaxation of the famous lex constraints extensively studied in the discrete case. They allow (partially) breaking any variable symmetry and can be generated in polynomial time. Contrarily to lex constraints that are impractical in general (due to their overwhelming number) and inappropriate in the continuous context (due to their form), rlex constraints can be efficiently handled natively by numerical constraint solvers. Moreover, we demonstrate their pruning power on continuous domains is almost as strong as that of lex constraints, and they subsume several previous work on breaking specific symmetry classes for continuous problems. Their experimental behavior is assessed on a collection of standard numerical problems and the factors influencing their impact are studied. The results confirm rlex constraints are a dependable counterpart to lexconstraints for numerical problems.© 2015 Elsevier B.V. All rights reserved.1. IntroductionNumerical constraint solvers are nowadays beginning to be competitive and even to outperform, in some cases, classical methods for solving systems of equations and inequalities over the reals. As a consequence, their application has raised interest in fields as diverse as neurophysiology and economics [2], biochemistry, crystallography, robotics [3] and, more generally, in those related to global optimization [4]. Symmetries naturally occur in many of these applications, and it is advisable to exploit them in order to reduce the search space and, thus, to increase the efficiency of the solvers.E-mail addresses: alexandre.goldsztejn@irccyn.ec-nantes.fr (A. Goldsztejn), christophe.jermann@univ-nantes.fr (C. Jermann), ruiz@iri.upc.edu✩This paper is an extended version of [1] presented at the conference CP 2011.* Corresponding author.(V. Ruiz de Angulo), torras@iri.upc.edu (C. Torras).http://dx.doi.org/10.1016/j.artint.2015.08.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\f106A. Goldsztejn et al. / Artificial Intelligence 229 (2015) 105–125Numerical solvers follow the Branch&Prune scheme, similarly to discrete constraint solvers: At each iteration, a sub-domain is selected, pruned according to the constraints, and then split into several sub-domains to be further explored. The main differences with discrete solvers are that (sub)domains being continuous only their boundaries are contracted, and that a sub-domain is declared to be a solution whenever it reaches some prescribed computational precision. Because of the resemblance of the solving processes, it is tempting to port symmetry breaking methods designed for discrete Constraint Satisfaction Problems (CSPs) to numerical ones.Considerable work on symmetry breaking has been done for discrete CSPs in the last decades [5–7]. Two main symmetry-breaking strategies have been pursued: 1) to devise specialized search algorithms that avoid symmetric portions of the search space [8,9]; and 2) to add symmetry-breaking constraints (SBCs) that filter out redundant subspaces [10,11]. Contrarily, there exists very little work on symmetry breaking for numerical problems. For cyclic variables permutations, an approach divides the initial space into boxes and eliminates symmetric ones before the solving starts [12]. SBCs have also been pro-posed, but only for either specific problems [13,14] or specific symmetry classes [15–17], and often only partially breaking the considered symmetries.In this paper, we propose the first general SBCs for numerical constraint problems that (partially) break any variable symmetry. These SBCs take the form of simple binary inequalities of the form xi ≤ x j where xi and x j are two distinct variables of the problem and i < j. Thus, at most n(n−1)inequalities are generated to deal with any symmetry. They can be generated in polynomial time knowing a generator of the symmetry group, using classical group theory algorithms. Moreover we demonstrate that these SBCs are suitable and optimal for numerical problems, i.e., they enclose tightly an asymmetric search subspace and thus have a better, or similar, pruning power than other SBCs.2The outline of the paper is as follows: Section 2 provides the necessary background on numerical problems and sym-metries; Section 3 introduces our SBCs as a relaxation of the lexicographic-ordering based SBCs [18] widely used by the discrete CSP community, and it also establishes the good properties of this relaxation; Section 4 introduces the state-of-the-art and compares our SBCs to existing alternatives; Section 5 assesses the practical interest of our SBCs on a benchmark of standard problems and analyzes the factors influencing their impact. Section 6 concludes the paper with future research directions.2. Principles of variable symmetry breakingA CSP is defined as a triple (cid:4)x, d, c(cid:5), where x = (x1, . . . , xn) is a list of variables, d = (d1, . . . , dn) is a list of domains for the variables, and c = (c1, . . . , cm) is a list of constraints. The focus of this paper is on numerical CSPs (NCSPs), whose variables are continuous, and thus domains are subsets of R, typically represented as a set of intervals (box) x. To conform mathematical notations in use for numerical problems, the same symbols are used for variables and their valuations, i.e., x will often denote a point in Rn. For the same reason, we adopt a functional notation for the evaluation of a constraint ci : Rn → {true, false} and for the evaluation of the conjunction of the constraints c : Rn → {true, false}. Hence a solution of a NCSP is a point x ∈ x that satisfies c(x), and its solution set is χ = {x ∈ x : c(x)}.A bijective function s : Rn → Rn is a symmetry of a (N)CSP if it maps solutions to solutions,1 i.e., for any x ∈ x such that c(x) = true, s(x) ∈ x and c(s(x)) = true. We say x and s(x) are symmetric points and, in case they are solutions, symmetric solutions. The symmetries of a (N)CSP form a group for the composition law. This symmetry group is denoted (cid:3) in the following. Though the identity function is forcibly part of (cid:3), since it is a trivial symmetry of any CSP, it is not considered in the following as it is irrelevant to break.In this paper, we consider only symmetries that are permutations of variables. Let Sn be the set of all permutations of {1, . . . , n}. The image of i by a permutation σ is denoted by iσ . Any permutation σ is completely defined by the image of each integer in {1, . . . , n}, and it is usually described as a vector [1σ , 2σ , . . . , nσ ]. A symmetry s is a variable symmetry iff there is a permutation σ ∈ Sn such that for any point x ∈ x, s(x) = (x1σ , . . . , xnσ ). We identify such symmetries with their associated permutations and denote both by σ in the following. Consequently, the group of variable symmetries of a CSP is isomorphic to a permutation subgroup of Sn, which are both identified and denoted by (cid:3) in the following. The application of a variable symmetry σ to a point x is denoted by xσ , this notation being extended to sets (discrete or continuous) of points X ⊆ x by X σ = {xσ : x ∈ X}.Example 1. The 3-cyclic roots problem consists in finding all (x1, x2, x3) ∈ R3 satisfying (x1 + x2 + x3 = 0) ∧ (x1x2 + x2x3 +x3x1 = 0) ∧ (x1x2x3 = 1). This problem has six variable symmetries (including identity):(cid:3) = {[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]},(1)i.e., (cid:3) = S3. Indeed, all the variables are syntactically interchangeable within all the constraints by the commutativity laws of product and sum.1 Nothing is required for non-solution points, i.e., we consider only solution symmetries [19].\fA. Goldsztejn et al. / Artificial Intelligence 229 (2015) 105–125107We can define the symmetry class of any point x ∈ x as the set of the images s(x) for all the symmetries s of the problem. In the case of variable symmetries, it can be noted x(cid:3) = {xσ : σ ∈ (cid:3)}. Provided that the domain satisfy the symmetries, i.e. x = xσ for all σ ∈ (cid:3), being in the same class is an equivalence relation and thus the symmetry classes form a partition of x.The symmetries of a (N)CSP are broken when a single representative in each symmetry class is retained. To this end, it is possible to add symmetry-breaking constraints (SBCs) which exclude all but a single representative in each symmetry class [5,7,20]. Crawford et al. [18] proposed lexicographic ordering constraints (lex) to address variable symmetry breaking. Recall that given x and y in Rn, the lexicographic order is defined inductively as:for n = 1,for n > 1,x (cid:10)lex y ≡ (x1 ≤ y1)x (cid:10)lex y ≡ (x1 < y1) ∨(cid:2)(cid:3)(x1 = y1) ∧ (x2:n (cid:10)lex y2:n)where, given a list z = (z1, z2, . . . , zn), zi: j denotes the sublist",
            {
                "entities": [
                    [
                        3124,
                        3152,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 268 (2019) 96–114Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing a small agreeable set of indivisible items ✩Pasin Manurangsi a, Warut Suksompong ba Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USAb Department of Computer Science, University of Oxford, UKa r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2018Received in revised form 12 August 2018Accepted 13 October 2018Available online 18 December 2018Keywords:AgreeabilityIndivisible itemsResource allocationSocial choiceWe study the problem of assigning a small subset of indivisible items to a group of agents so that the subset is agreeable to all agents, meaning that all agents value the subset as least as much as its complement. For an arbitrary number of agents and items, we derive a tight worst-case bound on the number of items that may need to be included in such a set. We then present polynomial-time algorithms that find an agreeable set whose size matches the worst-case bound when there are two or three agents. We also show that finding small agreeable sets is possible even when we only have access to the agents’ preferences on single items. Furthermore, we investigate the problem of efficiently computing an agreeable set whose size approximates the size of the smallest agreeable set for any given instance. We consider two well-known models for representing the preferences of the agents—the value oracle model and additive utilities—and establish tight bounds on the approximation ratio that can be obtained by algorithms running in polynomial time in each of these models.© 2018 Elsevier B.V. All rights reserved.1. IntroductionA typical resource allocation problem involves dividing a set of resources among interested agents. We are often con-cerned with the efficiency of the allocation, e.g., achieving high social welfare or ensuring that no other allocation would make every agent better off than the current allocation. Another important issue is the fairness of the allocation. For exam-ple, we might want the resulting allocation to be envy-free, meaning that every agent regards her bundle as the best among all bundles in the allocation [23,55], or proportional, meaning that every agent obtains at least her proportionally fair share [51]. A common feature of such problems is that one agent’s gain is another agent’s loss: The setting inherently puts the agents in conflict with one another, and our task is to try to resolve this conflict as best we can according to our objectives. Resource allocation problems constitute a major area of study in artificial intelligence.We study in this work a variant of the resource allocation problem where instead of the agents being pitted against one another, they belong to one and the same group. We will collectively allocate a subset of items to this group; our goal is to make this subset “agreeable” to all agents. Agreeability can be thought of as a minimal desirability condition: While an agent may be able to find other subsets of items that she personally prefers, the current subset is still acceptable for her, and she can agree with its allocation to the group. In other words, if the agreeability condition is not met for some This paper unifies and expands earlier versions that appeared in Proceedings of the 25th International Joint Conference on Artificial Intelligence [52]✩and Proceedings of the 26th International Joint Conference on Artificial Intelligence [40]. In particular, Theorems 5, 10, and 11 are new to this version, and Theorems 4, 6, and 7 improve corresponding results in the earlier versions. These additions lead to asymptotically tight bounds in Sections 3.3 and 4.1.E-mail address: warut.suksompong@cs.ox.ac.uk (W. Suksompong).https://doi.org/10.1016/j.artint.2018.10.0010004-3702/© 2018 Elsevier B.V. All rights reserved.\fP. Manurangsi, W. Suksompong / Artificial Intelligence 268 (2019) 96–11497Table 1Summary of the upper bounds on the size of the smallest agreeable set, presented in Section 3.n = 2n ≥ 3Full preferences(cid:2) m2min(cid:3) + 1 (Theorem 1)(cid:3)(cid:4)(cid:2)(cid:5)m+n2, m(Theorem 1)Ordinal preferences(cid:2)(cid:3)+ 1 (Theorem 2)m2+ (cid:2)(log m) for constant n (Theorems 4, 5)m2agent, then the agent will be unsatisfied and tempted to leave the group. We consider a notion of agreeability based on the fairness notion of envy-freeness: a subset of items is said to be agreeable to an agent if the agent likes it at least as much as the complement set. Agreeability, or minor variants thereof, has been considered in the context of fair division, where each group consists of a single agent [7,13,16]. For example, Brams et al. [16] calls the property “worth at least 50 percent”. An appealing aspect of agreeability is that it can be defined for arbitrary ordinal preferences, which constitutes a considerably larger class of preferences than those represented by additive cardinal utility functions [5,15,17,39,53]. Indeed, for most of this work we only assume that the agents’ preferences are monotonic, meaning that an agent always values a set of items at least as much as any of its subsets. Since in a large majority of resource allocation settings agents can simply ignore items that yield negative value to them, the monotonicity assumption is usually made without loss of generality.As applications of our agreeability notion, one could imagine that the agents are going together on a trip and agreeing on the set of items to put in a shared luggage, or choosing a subset of items as prizes from a team competition that they won together. Without further constraints, the problem described so far would be trivial, since we could simply allocate the entire set of items to the agents. We therefore impose a constraint that the allocated subset should be as small as possible. This constraint on size is reasonable in a variety of settings, including in the two given examples. Indeed, in the first example a luggage has limited space, and in the second example the organizers may want some items to be left as prizes for the losing teams, perhaps so that the allocation seems fair to an outsider. Similar cardinality constraints have been considered in the context of fair division [11]. In the example of agents going together on a trip, a subset of items that they take is agreeable if they like it no less than the complement subset of items left at home. Put differently, based on the set of items chosen, every agent would rather go on the trip than stay at home. Similarly, for agents taking items as prizes from a team competition, if the competition is between two teams and a subset of items is not agreeable to some agent in the winning team, we will have an undesirable situation where the agent envies the losing team that takes the remaining items.While our study is based on the framework of resource allocation, agreeability is also relevant in other areas of social choice theory and artificial intelligence. In particular, one could think of choosing an agreeable set of items as an election of a committee from a set of candidates, where the committee size is unspecified but perhaps should be minimized. The theory of committee elections provides a number of specific ways to instantiate the notion of agreeability. For example, if one uses approval elections, where every agent either approves or disapproves each candidate and approves a committee if it contains at least one of her approved candidates, an agreeable committee according to our notion corresponds to one where every agent has an approved candidate in the committee. In general, the preferences of the agents for various committees can be quite complex, and several variants of committee elections have been investigated in the literature [6,50]. We see our work as a starting point that deals with a particularly simple and natural agreeability notion, and our hope is that this work will lay a foundation for studying different notions that may be appropriate for other applications.1.1. Our resultsIn this work, we initiate the study of agreeability in resource allocation. First, in Section 3, we establish upper bounds on the size of the smallest agreeable set, both when the algorithm has access to the agents’ full preferences and when the algorithm only has access to the agents’ preferences on single items. In addition, we present algorithms that compute agree-able sets whose size matches the worst-case bounds under both assumptions. Our results in this section are summarized in Table 1.In Section 3.1, we derive a tight upper bound on the number of items that may need to be included in an agreeable set, for any number of agents and items. Remarkably, even though agents may have vastly differing and perhaps conflicting preferences, the number of extra items that we might need to choose in order to accommodate all of them is surprisingly small, i.e., half an item per additional agent (Theorem 1). Our result holds under a very weak assumption that preferences are monotonic, meaning that an agent cannot be worse off whenever an item is added to her set. Interestingly, to establish this result we make use of Kneser’s conjecture, a combinatorial result whose proof by Lovász [37] gave rise to the field of topological combinatorics.In Section 3.2, we turn our attention to the question of whether we can efficiently compute an agreeable set whose size matches the worst-case bound given in Section 3.1. We answer the question in the affirmative for the cases of two and three agents. To this end, we make the assumption that preferences are responsive, meaning that an agent cannot be worse off when an item is added to her set or replaced by another item that she weakly prefers to the original item. While responsiveness is stronger than monotonicity, it is still a generalization of additivity, a very common assumption on prefere",
            {
                "entities": [
                    [
                        3868,
                        3896,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 71–92Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFair assignment of indivisible objects under ordinal preferencesHaris Aziz∗, Serge Gaspers, Simon Mackenzie, Toby WalshNICTA and University of New South Wales, Sydney 2052, Australiaa r t i c l e i n f oa b s t r a c tArticle history:Received 28 June 2014Received in revised form 7 June 2015Accepted 14 June 2015Available online 18 June 2015Keywords:Fair divisionResource allocationEnvy-freenessProportionalityWe consider the discrete assignment problem in which agents express ordinal preferences over objects and these objects are allocated to the agents in a fair manner. We use the stochastic dominance relation between fractional or randomized allocations to systematically define varying notions of proportionality and envy-freeness for discrete assignments. The computational complexity of checking whether a fair assignment exists is studied for these fairness notions. We also characterize the conditions under which a fair assignment is guaranteed to exist. For a number of fairness concepts, polynomial-time algorithms are presented to check whether a fair assignment exists. Our algorithmic results also extend to the case of unequal entitlements of agents. Our NP-hardness result, which holds for several variants of envy-freeness, answers an open question posed by Bouveret, Endriss, and Lang (ECAI 2010). We also propose fairness concepts that always suggest a non-empty set of assignments with meaningful fairness properties. Among these concepts, optimal proportionality and optimal weak proportionality appear to be desirable fairness concepts.© 2015 Elsevier B.V. All rights reserved.1. IntroductionA basic yet widely applicable problem in computer science and economics is to allocate discrete objects to agents given the preferences of the agents over the objects. The setting is referred to as the assignment problem or the house allocation problem (see, e.g., [1,8,28,32,40,50,51]). In this setting, there is a set of agents N = {1, . . . , n}, a set of objects O = {o1, . . . , om}with each agent i ∈ N expressing ordinal preferences (cid:2)i over O . The goal is to allocate the objects among the agents in a fair or optimal manner without allowing transfer of money. The assignment problem is a fundamental setting within the wider domain of fair division or multiagent resource allocation [23]. The model is applicable to many resource allocation or fair division settings where the objects may be public houses, school seats, course enrollments, kidneys for transplant, car park spaces, chores, joint assets of a divorcing couple, or time slots in schedules. Fair division has become a major area in AI research in the last decade, and especially the last few years (see, e.g., [3,12–15,18,23,25,29,37,44]).In this paper, we consider the fair assignment of indivisible objects. Two of the most fundamental concepts of fairness are envy-freeness and proportionality. Envy-freeness requires that no agent considers that another agent’s allocation would give him more utility than his own. Proportionality requires that each agent should get an allocation that gives him at least 1/n of the utility that he would get if he was allocated all the objects. When agents’ ordinal preferences are known but * Corresponding author.E-mail addresses: haris.aziz@nicta.com.au (H. Aziz), sergeg@cse.unsw.edu.au (S. Gaspers), simon.mackenzie@nicta.com.au (S. Mackenzie), toby.walsh@nicta.com.au (T. Walsh).http://dx.doi.org/10.1016/j.artint.2015.06.0020004-3702/© 2015 Elsevier B.V. All rights reserved.\f72H. Aziz et al. / Artificial Intelligence 227 (2015) 71–92Fig. 1. Inclusion relationships between fairness concepts. Envy-freeness is abbreviated as EF and Proportionality is abbreviated as Prop. Possible completion is abbreviated as PC. Necessary completion is abbreviated as NC. An arrow represents inclusion. For example, every SD envy-free outcome is also SD proportional. Double lines represent equivalence. For example, SD EF and Necessary EF are equivalent.utility functions are not given, then ordinal notions of envy-freeness and proportionality need to be formulated. We consider a number of ordinal fairness concepts. Most of these concepts are based on the stochastic dominance (SD) relation which is a standard way of comparing fractional/randomized allocations. An agent prefers one allocation over another with respect to the SD relation if he gets at least as much utility from the former allocation as the latter for all cardinal utilities consistent with the ordinal preferences. Although this paper is restricted to discrete assignments, using stochastic dominance to define fairness concepts for discrete assignments turns out to be fruitful. The fairness concepts we study include SD envy-freeness, weak SD envy-freeness, possible envy-freeness, SD proportionality, and weak SD proportionality. We consider the problems of computing a discrete assignment that satisfies some ordinal notion of fairness if one exists, and the problems of verifying whether a given assignment satisfies the fairness notions.Contributions We present a systematic way of formulating fairness properties in the context of the assignment problem. The logical relationships between the properties are proved. Interestingly, our framework leads to new solution concepts such as weak SD proportionality that have not been studied before. The motivation to study a range of fairness properties is that, depending on the situation, only some of them are achievable. In addition, only some of them can be computed efficiently. In order to find fairest achievable assignment, one can start by checking whether there exists a fair assignment for the strongest notion of fairness. If not, one can try the next fairness concept that is weaker than the one already checked (Fig. 1).We present a comprehensive study of the computational complexity of computing fair assignments under ordinal prefer-ences. In particular, we present a polynomial-time algorithm to check whether an SD proportional exists even when agents may express indifferences. The algorithm generalizes the main result of [46] (Theorem 1) who focused on strict preferences. For the case of two agents, we obtain a polynomial-time algorithm to check whether an SD envy-free assignment exist. The result generalizes Proposition 2 in [12] in which preferences over objects were assumed to be strict. For a constant number of agents, we propose a polynomial-time algorithm to check whether a weak SD proportional assignment exists. As a corol-lary, for two agents, we obtain a polynomial-time algorithm to check whether a weak SD envy-free or a possible envy-free assignment exists. Even for an unbounded number of agents, if the preferences are strict, we characterize the conditions under which a weak SD proportional assignment exists. We show that the problems of checking whether possible envy-free, SD envy-free, or weak SD envy-free assignments exist are NP-complete. The result for possible envy-freeness answers an open problem posed in [12]. Our computational results are summarized in Table 1.We show that our two main algorithms can be extended to the case where agents have different entitlements over the objects or if we additionally require the assignment to be Pareto optimal. Our study highlights the impacts of the following settings: i) randomized/fractional versus discrete assignments, ii) strict versus non-strict preferences, and iii) multiple objects per agent versus a single object per agent.Since the fairness concepts we introduce may not be guaranteed to exist, we suggest possible ways to extend the fair-ness concepts. Firstly, we consider the problem of maximizing the number of agents for whom the corresponding fairness constraint is satisfied. A criticism of this approach is that there can still be agents who are completely dissatisfied. We then consider an alternative approach in which the proportionality constraints is weakened in a natural and gradual manner. We refer to the concepts as optimal proportionality and optimal weak proportionality. The fairness concepts are not only at-tractive but we show that an optimal proportional assignment can be computed in polynomial time and an optimal weak proportional assignment can be computed in polynomial time for a constant number of agents.2. Related workProportionality and envy-freeness are two of the most established fairness concepts. Proportionality dates back to at least the work of Steinhaus [48] in the context of cake-cutting. It is also referred to as fair share guarantee in the literature [41]. A formal study of envy-freeness in microeconomics can be traced back to the work of Foley [31].\fH. Aziz et al. / Artificial Intelligence 227 (2015) 71–9273Table 1Complexity of checking the existence of a fair assignment of indivisible goods for n agents and m objects. The results in bold are from this paper.Weak SD proportionalin P for strict preferences (Theorem 7)in P for constant n (Theorem 8)SD proportionalin P (Theorem 6)Weak SD envy-freePossible envy-freeNP-complete (Theorem 11)in P for strict preferences [12]in P for n = 2 (Corollary 2)NP-complete (Theorem 11)in P for strict preferencesin P for n = 2 (Corollary 2)SD envy-freeNP-complete even for strict preferences [12]in P for n = 2 (Corollary 1)The computation of fair discrete assignments has been intensely studied in the last decade within computer science. In many of the papers considered, agents express cardinal utilities for the objects and the goal is to compute fair assignments (see, e.g., [9,13,15,28,35,39,42,45]). A prominent paper is that of Lipton et al. [39] in which algorithms for approximately envy-free assignments are discussed. It follows from [39] that even when two agents express cardinal utilities, checking whether there exists a proportional or envy-free assignment is NP-complete. A closely relat",
            {
                "entities": [
                    [
                        3571,
                        3599,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 228 (2015) 129–152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConfidence-based reasoning in stochastic constraint programming ✩Roberto Rossi a,∗a Business School, University of Edinburgh, United Kingdomb Department of Computer Science, Taif University, Taif, Saudi Arabiac Department of Management, Cankaya University, Ankara, Turkeyd Insight Centre for Data Analytics, University College Cork, Ireland, Brahim Hnich b, S. Armagan Tarim c,d,1, Steven Prestwich d,1a r t i c l e i n f oa b s t r a c tArticle history:Received 7 November 2014Received in revised form 5 July 2015Accepted 8 July 2015Available online 15 July 2015Keywords:Confidence-based reasoningStochastic constraint programmingSampled SCSP(α, ϑ)-solution(α, ϑ)-solution setConfidence interval analysisGlobal chance constraint1. IntroductionIn this work we introduce a novel approach, based on sampling, for finding assignments that are likely to be solutions to stochastic constraint satisfaction problems and constraint optimisation problems. Our approach reduces the size of the original problem being analysed; by solving this reduced problem, with a given confidence probability, we obtain assignments that satisfy the chance constraints in the original model within prescribed error tolerance thresholds. To achieve this, we blend concepts from stochastic constraint programming and statistics. We discuss both exact and approximate variants of our method. The framework we introduce can be immediately employed in concert with existing approaches for solving stochastic constraint programs. A thorough computational study on a number of stochastic combinatorial optimisation problems demonstrates the effectiveness of our approach.© 2015 Elsevier B.V. All rights reserved.The stochastic constraint satisfaction/optimisation framework introduced in [2,3] constitutes an expressive declarative formalism for modelling problems of decision making under uncertainty. A stochastic constraint satisfaction problem (SCSP), alongside decision variables, features random variables, which follow some probability distribution and can be used to model uncertainty. Relationships over subsets of random and decision variables can be expressed in a declarative manner via stochastic constraints. The fact that a given relationship over subsets of random and decision variables should be satisfied according to a prescribed probability can be expressed by means of chance constraints. Finally, since problems of decision making under uncertainly are sequential in nature, the modeller can define a stage structure, that is a sequence of decision stages, in each of which a subset of all possible decisions are taken and a subset of all possible random variables are observed. A solution to an SCSP can be represented in general by means of a policy tree, which records feasible or optimal decisions associated with each possible set of random variable realisations.✩This work is an extended version of [1].* Corresponding author at: Business School, University of Edinburgh, 29 Buccleuch place, EH8 9JS, Edinburgh, UK. Tel.: +44 (0)131 6515239; fax: +44 (0)131 650 8077.E-mail addresses: roberto.rossi@ed.ac.uk (R. Rossi), hnich.brahim@gmail.com (B. Hnich), armtar@yahoo.com (S.A. Tarim), s.prestwich@cs.ucc.ie(S. Prestwich).1 This publication has emanated from research supported in part by a research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289.http://dx.doi.org/10.1016/j.artint.2015.07.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\f130R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152As shown in [3, Theorem 1], solving SCSPs is a computationally hard task. Even trivial instances with a dozen of decision and random variables require a computational effort out of reach even for the most advanced hardware/software combina-tion. This is due to the fact that the size of the policy tree grows exponentially in the number of random variables in the model and in the size of their support. Furthermore, a major limitation of all existing complete SCSPs solution methods, such as [3] and [4], is the fact that they assume the support of random variables is finite, otherwise a solution cannot be expressed as a finite policy tree. In practice, however, it is often the case that random variables either range over continu-ous supports or have a very large number (possibly infinite) of values in their domain. To date, no general purpose method exists for solving large-scale SCSPs, or SCSPs featuring random variables with continuous or discrete infinite support; for the sake of brevity we shall name this latter class of SCSPs “infinite SCSPs.”The main contribution of this paper is to propose a framework for solving large-scale or infinite SCSPs. More specifically, we argue that in solving large-scale or infinite SCSPs, one should not consider the ultimate feasible/optimal solution, which in some cases may even be impossible to represent; rather, the decision maker should aim for a solution that she “suffi-ciently trusts,” which she may claim to be optimal or feasible with a given confidence level, and for which a certain degree of error may be tolerated. In order to obtain such a solution, the decision maker should only look at a possibly limited number of samples drawn from the random variables in the model. In other words, she should try to “estimate” the quality of this solution.Our approach has several analogies with established techniques in statistics. When a survey is conducted on a sample population — e.g. an electoral poll — a statistician typically associates a certain confidence level with the results obtained from the chosen sample population. For instance, one may claim that there is a 90% chance that the actual mean being estimated is within a given interval. We argue that the very same approach may be adopted in stochastic decision making. If the infinite or large-scale m-stage SCSP does not admit any closed form solution and is complex enough to rule out any chance of obtaining an exact solution, we suggest that — as is done in statistics — one may introduce a confidence level α and a tolerated estimation error ±ϑ . The decision maker, instead of looking for an exact solution, may then aim to “estimate” — according to the chosen α and ϑ — whether the actual satisfaction probability guaranteed by an assignment is greater than or equal to the given target value for each of the chance constraints in the model. By choosing given values for α and ϑ the set of solutions may vary. For this reason we will introduce a new notion of solution that is parameterised by these two parameters and that we call an (α, ϑ)-solution. Intuitively, as α tends to 1 and ϑ tends to 0 the set of (α, ϑ)-solutions will converge to the set of actual solutions to the original stochastic constraint satisfaction problem, which we therefore rename (1, 0)-solutions. One should note that an approach of this kind has been recently advocated in [5, Chap. 4].In this work, we make the following contributions to the stochastic constraint programming literature:• we discuss how to obtain compact instances of infinite or large-scale stochastic constraint programs via sampling: we call these instances “sampled SCSPs;”• we introduce the concepts of (α, ϑ)-solution and of (α, ϑ)-solution set; and show how to compute a priori the mini-mum sample size that guarantees the attainment of such classes of solutions;• we show how the above tools can be employed in order to find approximate solutions to infinite or large-scale stochas-tic constraint satisfaction/optimisation problems that cannot be solved by existing exact approaches in the stochastic constraint programming literature;• we conduct a thorough computational study on three well-known stochastic combinatorial problems to validate our theoretical framework and assess its effectiveness, efficiency, and scalability.This work is structured as follows: in Section 2 we introduce the relevant formal background in constraint programming, stochastic constraint programming, and confidence interval analysis; in Section 3 we introduce sampled SCSPs; in Section 4we discuss properties of the solutions of sampled SCSPs and formally introduce (α, ϑ)-solutions; in Section 5 we introduce (α, ϑ)-solution sets; in Section 6 we extend our discussion to stochastic constraint optimisation problems; in Section 7 we discuss connections with established techniques in statistics; in Section 8 we present our computational study; in Section 9we discuss related works; finally, in Section 10 we draw conclusions and discuss future research directions.2. Formal backgroundWe now introduce the relevant background in constraint programming, stochastic constraint programming, and confi-dence interval analysis.2.1. Constraint programmingA Constraint Satisfaction Problem (CSP) [6] consists of a set of decision variables, each with a finite domain of values, and a set of constraints specifying allowed combinations of values for some variables. A solution to a CSP is an assignment of variables to values in their respective domains such that all of the constraints are satisfied. Constraint solvers typically explore partial assignments enforcing a local consistency property. A constraint c is generalised arc consistent (GAC) if and only if when a variable is assigned any of the values in its domain, there exist compatible values in the domains of all the \fR. Rossi et al. / Artificial Intelligence 228 (2015) 129–152131other variables of c. In order to enforce a local consistency property on a constraint c during search, we employ filtering algorithms that remove inconsistent values from the domains of the variables of c. These filtering algorithms are repeatedly called until no more values are pruned. This process is called constraint propagation.2.2. Stochastic constraint programmingThe following definitions are based on [4",
            {
                "entities": [
                    [
                        3531,
                        3559,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 491–513www.elsevier.com/locate/artintOn the design of coordination diagnosis algorithms forteams of situated agentsMeir Kalech ∗, Gal A. KaminkaThe MAVERICK group, Department of Computer Science, Bar Ilan University, IsraelReceived 5 September 2005; received in revised form 12 March 2007; accepted 16 March 2007Available online 24 March 2007AbstractTeamwork demands agreement among team-members in order to collaborate and coordinate effectively. When a disagreementbetween teammates occurs (due to failures), team-members should ideally diagnose its causes, to resolve the disagreement. Suchdiagnosis of social failures can be expensive in communication and computation, challenges which previous work has not ad-dressed. We present a novel design space of diagnosis algorithms, distinguishing several phases in the diagnosis process, andproviding alternative algorithms for each phase. We then combine these algorithms in different ways to empirically explore spe-cific design choices in a complex domain, on thousands of failure cases. The results show that different phases of diagnosis affectcommunication and computation overhead. In particular, centralizing the diagnosis disambiguation process is a key factor in re-ducing communications, while runtime is affected mainly by the amount of reasoning about other agents. These results contrastwith previous work in disagreement detection (without diagnosis), in which distributed algorithms reduce communications.© 2007 Elsevier B.V. All rights reserved.Keywords: Diagnosis; Multi-agent systems; Situated agents1. IntroductionWith increasing deployment of robotic and agent teams in complex, dynamic settings, there is an increasing need toalso be able to respond to failures that occur in teamwork [1,7,23,33]. One type of failure in teamwork is disagreement,where agents come to disagree on salient aspects of their joint task. There is thus a particular need to be able to detectand diagnose the causes for disagreements that may occur, in order to facilitate recovery and reestablishment ofcollaboration, e.g., by negotiations [19]. This type of diagnosis is called social diagnosis, since it focuses on findingcauses for failures to maintain social relationships [17], i.e., coordination failures.For instance, suppose a team of four robotic porters carry a table, when suddenly one of the robots puts the tabledown on the floor, while its teammates are still holding the table up. Team-members can easily identify a disagreement,but they also need to determine its causes, e.g., that the robot believed the table reached the goal location, while itsteammates did not. Given this diagnosis, the robots can negotiate in order to resolve the disagreement.* Corresponding author.E-mail addresses: kalechm@cs.biu.ac.il (M. Kalech), galk@cs.biu.ac.il (G.A. Kaminka).URLs: http://www.cs.biu.ac.il/~kalechm/ (M. Kalech), http://www.cs.biu.ac.il/~galk/ (G.A. Kaminka).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.03.005\f492M. Kalech, G.A. Kaminka / Artificial Intelligence 171 (2007) 491–513Unfortunately, while the problem of detection has been addressed in the literature e.g., [16,18,24], social diagnosisremains an open challenge. Naive implementations of social diagnosis processes can require significant computationand communications, which prohibits them from being effective as the number of agents is scaled up, or the numberof failures to diagnose increases. Previous work did not rigorously address this concern: Kaminka and Tambe [17]guarantee disagreement detection without communications, but their heuristic-based diagnosis often fails. Dellarocasand Klein as well as Horling et al. [4,9] do not explicitly address communication complexity. Fröhlich et al. and laterRoos et al. [6,27,29,30] assume fixed communication links, an assumption which does not hold in dynamic teams inwhich agents may choose their communication partners dynamically (see Section 2 for details).We seek to examine in depth the communication and computation requirements of social diagnosis. We distinguishtwo phases of social diagnosis: (i) selection of the diagnosing agents; and (ii) diagnosis of the team state (by theselected agents). We provide alternative algorithms for these phases, and combine them in different ways, to presentsix diagnosis methods, corresponding to different design decisions. We then examine the runtime and communicationcomplexity and empirically evaluate these parameters in diagnosing thousands of systematically-generated failurecases, occurring in a team of behavior-based agents in two different complex domains.We draw general lessons about the design of social diagnosis algorithms from the empirical results. Specifically, theresults show that centralizing the disambiguation process is a key factor in dramatically improving communicationsefficiency, but is not a determining factor in runtime efficiency. On the other hand, explicit reasoning about other agentsis a key factor in determining runtime: Agents that reason explicitly about others incur significant computational costs,though they are sometimes able to reduce the amount of communications. These results contrast with previous workin disagreement detection, in which distributed algorithms reduce communications (and to some extent, runtime) byreasoning about other agents.The paper is organized as follows: Section 2 motivates the research and discusses related work. Section 3 presentsthe architecture of behavior-based agents. Section 4 presents the disambiguating diagnosis hypotheses phase andSection 5 presents the diagnosing agent selection phase. Section 6 specifies diagnosis methods which combine thealgorithms in the previous two sections in different ways, and Section 7 evaluates them empirically. Section 8 con-cludes.2. Motivation and related workAgreement (e.g., on a joint plan or goal) is the key to the establishment and maintenance of teamwork [1,7,10,33].The Joint Intentions framework [1] focuses on agreement (mutual belief) in a team’s joint goal. The SharedPlansframework [7] relies on an intentional attitude, in which an individual agent’s intention is directed towards a group’sjoint action. This includes mutual belief and agreement among the teammates in a complete recipe including manyactions. Similarly, the Joint Responsibility model [10] establishes the team-members mutual belief in a specific recipeas a corner-stone for their collaboration.There exist several architectures for building agents, using ideas from teamwork theories; agreement on specificfeatures of the agents’ internal state plays a critical role in all. GRATE∗ implements the joint responsibility model [10]in industrial agent systems. STEAM [33] and TEAMCORE [25] use ideas from both Joint Intentions and SharedPlans,and add reactive team plans which are selected or deselected by a team or sub-team. BITE [14,15] follows in thistradition, and additionally allows for a variety of agreement-synchronization protocols to be used interchangeably, incontrolling physical robots.However, teamwork sometimes fails, causing disagreements—agreement failures—among team-members [4,16,17]. This may be due to sensing failures, or different interpretations of sensor readings. The function of a diagnosisprocess is to go from disagreement detection (where an alarm is raised when a fault—disagreement—occurs), to faultidentification, where the causes for the disagreement are discovered, in terms of the differences in beliefs between theagents that lead to the disagreement. Such differences in beliefs may be a result of differences in sensor readings orinterpretation, in sensor malfunctions, or communication difficulties.While diagnosis of a single-agent system is relatively well understood, and known to be computationally difficult[8], social diagnosis—diagnosis of coordination failures such as disagreements—remains an open area of research.In particular, to our best knowledge, there has not been an in-depth exploration of disagreement diagnosis algorithms.Our work takes first steps to understand disagreement diagnosis algorithms in terms of their design choices, and theeffects of these on computation and communications.\fM. Kalech, G.A. Kaminka / Artificial Intelligence 171 (2007) 491–513493The most closely-related work to ours is reported in [16,17]. This previous investigation provides guarantees ondetection of disagreements, but only presented a heuristic approach to diagnosis, which indeed does not always suc-ceed. The algorithms we present here succeed in the same examples where the previous heuristic approaches havefailed.Dellarocas and Klein [4,18] report on a system of domain-independent exceptions handling services. The firstcomponent contains a knowledge base of generic exceptions. The second contains a decision tree of diagnoses; thediagnosing process is done by traversing down the tree by asking queries about the relevant problem. The thirdcomponent is responsible to seek for a solution for the exception, based on a resolution knowledge base. This approachtransfers the failure-handling responsibility from the agent to an external system, to alleviate the load on each agentdesigner (which would now be freed of the responsibility of implementing an exception-handling system in eachagent). However, in contrast to our work, communication and runtime concerns are not addressed. In their systemsentinel agents monitor the agents in the multi-agent system and pro-actively query agents about their status. They donot mention the monitoring method and when a querying is necessary, but both of those actions have a large influenceon communication and computation complexity.Similarly, Horling et al. [9] uses a fault-model of failures and diagnoses to detect and respond to multi-agentfailures. In this model, a set of pre-defined diagnoses are stored in acyclic graph’s nodes. When a fault is detected asuitable node is tri",
            {
                "entities": [
                    [
                        3033,
                        3061,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1194–1203Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRational choice and AGM belief revisionGiacomo Bonanno 1Department of Economics, University of California, Davis, CA 95616-8578, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 24 October 2008Received in revised form 8 May 2009Accepted 11 May 2009Available online 30 May 2009Keywords:Rational choiceRevealed preferenceBelief revisionPartial belief revision functionChoice functionArrow’s axiom1. IntroductionWe establish a correspondence between the rationalizability of choice studied in therevealed preference literature and the notion of minimal belief revision captured by theAGM postulates. A choice frame consists of a set of alternatives Ω, a collection E ofsubsets of Ω (representing possible choice sets) and a function f : E → 2Ω (representingchoices made). A choice frame is rationalizable if there exists a total pre-order R on Ωsuch that, for every E ∈ E,f (E) coincides with the best elements of E relative to R.We re-interpret choice structures in terms of belief revision. An interpretation is obtainedby adding a valuation V that assigns to every atom p the subset of Ω at which p istrue. Associated with an interpretation is an initial belief set and a partial belief revisionfunction. A choice frame is AGM-consistent if, for every interpretation of it, the associatedpartial belief revision function can be extended to a full-domain belief revision functionthat satisfies the AGM postulates. It is shown that a finite choice frame is AGM-consistentif and only if it is rationalizable.© 2009 Elsevier B.V. All rights reserved.The dominant theory of belief revision is due to Alchourrón, Gärdenfors and Makinson [1] and is known as the AGMtheory. In their approach beliefs are modeled syntactically as sets of formulas and belief revision is construed as an operationthat associates with every deductively closed set of formulas K (thought of as the initial beliefs) and formula φ (thought ofas new information) a new set of formulas B K (φ) representing the new beliefs after revising by φ.We establish a correspondence between the AGM theory and the set-theoretic structures studied in rational choice theory(also known as revealed preference theory; see, for example, [22] and [24]). Rational choice theory considers structures(cid:4)Ω, E, f (cid:5) consisting of a set of alternatives Ω , a collection E of subsets of Ω (representing possible choice sets) and afunction f from E into the set of subsets of Ω , representing choices made. The main objective of rational choice theory isto investigate the conditions under which the function f can be rationalized by a total pre-order R on Ω in the sense that,for every E ∈ E , f (E) coincides with the best elements of E relative to R.We re-interpret choice structures in terms of belief revision. The set Ω is now interpreted as a set of states. A modelbased on (or an interpretation of) a choice structure is obtained by adding to it a valuation V that assigns to every atomicformula p the set of states at which p is true. Truth of an arbitrary formula at a state is then obtained as usual. Given amodel (cid:4)Ω, E, f , V (cid:5) we define the initial beliefs as the set of formulas φ such that f (Ω) is a subset of the truth set of φ,denoted by (cid:6)φ(cid:6). Hence f (Ω) is interpreted as the set of states that are initially considered possible. We then interpret thecollection of events (sets of states) E as a set of possible items of information. If φ is a formula such that (cid:6)φ(cid:6) ∈ E , we definethe revised beliefs upon learning that φ as the set of formulas ψ such that f ((cid:6)φ(cid:6)) ⊆ (cid:6)ψ(cid:6). Thus the event f ((cid:6)φ(cid:6)) is interpretedas the set of states that are considered possible after learning that φ is the case. Hence associated with every model is aE-mail address: gfbonanno@ucdavis.edu.1 I am grateful to three anonymous reviewers for helpful and constructive comments.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.05.001\fG. Bonanno / Artificial Intelligence 173 (2009) 1194–12031195partial belief revision function (partial because, in general, it is not the case that, for every formula φ, (cid:6)φ(cid:6) ∈ E , that is, notevery piece of information is potentially available or contemplated). We say that a choice frame (cid:4)Ω, E, f (cid:5) is AGM-consistentif, for every model based on it, the associated partial belief revision function can be extended to a full-domain belief revisionfunction that satisfies the AGM postulates. We show that, when the set of states is finite, the properties of AGM-consistencyand rationalizability are equivalent.In the next section we review the notion of belief function and the AGM postulates. In Section 3 we develop the corre-spondence between AGM belief revision and rational choice. Section 4 contains a brief discussion of related literature andconcluding remarks.2. Belief revision functionsLet Φ be the set of formulas of a propositional language based on a countable set A of atomic formulas.2 Given a subsetK ⊆ Φ, its PL-deductive closure [K ]P L (where ‘PL’ stands for Propositional Logic) is defined as follows: ψ ∈ [K ]P L if and onlyif there exist φ1, . . . , φn ∈ K (with n (cid:2) 0) such that (φ1 ∧ · · · ∧ φn) → ψ is a tautology (that is, a theorem of PropositionalLogic). A set K ⊆ Φ is consistent if [K ]P L (cid:9)= Φ (equivalently, if there is no formula φ such that both φ and ¬φ belong to[K ]P L ). A set K ⊆ Φ is deductively closed if K = [K ]P L . A belief set is a set K ⊆ Φ which is deductively closed.Let K be a consistent belief set representing the agent’s initial beliefs and let Ψ ⊆ Φ be a set of formulas representingpossible items of information. A belief revision function based on K is a function B K : Ψ → 2Φ (where 2Φ denotes the set ofsubsets of Φ) that associates with every formula φ ∈ Ψ (thought of as new information) a set B K (φ) ⊆ Φ (thought of as therevised beliefs).3 If Ψ (cid:9)= Φ then B K is called a partial belief revision function, while if Ψ = Φ then B K is called a full beliefrevision function.Definition 1. Let B K : Ψ → 2Φ be a (partial) belief revision function and Bthat BK is an extension of B K if, for every φ ∈ Ψ , BK (φ) = B K (φ).∗∗∗K: Φ → 2Φ a full belief revision function. We sayA full belief revision function is called an AGM function if it satisfies the following properties, known as the AGM postu-lates: ∀φ, ψ ∈ Φ,(AGM1) B K (φ) = [B K (φ)]P L ,(AGM2) φ ∈ B K (φ),(AGM3) B K (φ) ⊆ [K ∪ {φ}]P L ,(AGM4) if ¬φ /∈ K , then [K ∪ {φ}]P L ⊆ B K (φ),(AGM5) B K (φ) = Φ if and only if φ is a contradiction,(AGM6) if φ ↔ ψ is a tautology then B K (φ) = B K (ψ),(AGM7) B K (φ ∧ ψ) ⊆ [B K (φ) ∪ {ψ}]P L ,(AGM8) if ¬ψ /∈ B K (φ), then [B K (φ) ∪ {ψ}]P L ⊆ B K (φ ∧ ψ).AGM1 requires the revised belief set to be deductively closed. AGM2 requires that the information be believed. AGM3says that beliefs should be revised minimally, in the sense that no new formula should be added unless it can be deducedfrom the information received and the initial beliefs.4 AGM4 says that if the information received is compatible with theinitial beliefs, then any formula that can be deduced from the information and the initial beliefs should be part of therevised beliefs. AGM5 requires the revised beliefs to be consistent, unless the information φ is a contradiction (that is, ¬φis a tautology). AGM6 requires that if φ is propositionally equivalent to ψ then the result of revising by φ be identical tothe result of revising by ψ . AGM7 and AGM8 are a generalization of AGM3 and AGM4 that“applies to iterated changes of belief. The idea is that if B K (φ) is a revision of K [prompted by φ] and B K (φ) is to bechanged by adding further sentences, such a change should be made by using expansions of B K (φ) whenever possible.More generally, the minimal change of K to include both φ and ψ (that is, B K (φ ∧ ψ)) ought to be the same as theexpansion of B K (φ) by ψ , so long as ψ does not contradict the beliefs in B K (φ)” (Gärdenfors [12], p. 55; notationchanged to match ours).5We now turn to a semantics for belief revision, using structures that are known in rational choice theory as choicefunctions. We shall call them choice frames.2 Thus Φ is defined recursively as follows: if p ∈ A then p ∈ Φ and if φ, ψ ∈ Φ then ¬φ ∈ Φ and (φ ∨ ψ) ∈ Φ.∗φ or K ∗ φ instead of B K (φ), but for our purposes the latter notation is clearer.3 In the literature it is common to use the notation K4 For every formula ψ , ψ ∈ [K ∪ {φ}]P L if and only if (φ → ψ) ∈ K (since, by hypothesis, K = [K ]P L ).5 The expansion of B K (φ) by ψ is [B K (φ) ∪ {ψ}]P L . Note, again, that, for every formula χ , χ ∈ [B K (φ) ∪ {ψ}]P L if and only if (ψ → χ ) ∈ B K (φ) (since,by AGM1, B K (φ) = [B K (φ)]P L ).\f1196G. Bonanno / Artificial Intelligence 173 (2009) 1194–12033. Choice frames and AGM belief revisionDefinition 2. A choice frame is a triple (cid:4)Ω, E, f (cid:5) whereΩ is a non-empty set of states (or possible worlds); subsets of Ω are called events.E ⊆ 2Ω is a collection of events (2Ω denotes the set of subsets of Ω ) such that ∅ /∈ E and Ω ∈ E .f : E → 2Ω is a function that associates with every event E ∈ E an event f (E) satisfying the following properties:(1) f (E) ⊆ E and (2) f (E) (cid:9)= ∅.In rational choice theory a set E ∈ E is interpreted as a set of available alternatives and f (E) is interpreted as the subsetof E which consists of the chosen alternatives (see, for example, [22] and [24]). In our case, we think of the elements ofE as possible items of information and the interpretation of f (E) is that, if informed that event E has occurred, the agentconsiders as possible all and only the states in f (E). The set f (Ω) is interpreted as the states that are initially consideredpossible.6In order to interpret a choice frame (cid:4)Ω, E, f (cid:5) in t",
            {
                "entities": [
                    [
                        4125,
                        4153,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 1–27Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAn SMT-based approach to weak controllability for disjunctive temporal problems with uncertainty ✩Alessandro Cimatti a, Andrea Micheli a,b,∗a Fondazione Bruno Kessler, Istituto per la Ricerca Scientifica e Tecnologica, Via Sommarive 18, 38123 Povo, Trento, Italyb Doctoral School in Information and Communication Technology, University of Trento, Via Sommarive 9, 38123 Povo, Trento, Italy, Marco Roveri aa r t i c l e i n f oa b s t r a c tArticle history:Received 11 November 2013Received in revised form 27 February 2015Accepted 5 March 2015Available online 12 March 2015Keywords:Weak controllabilityTemporal problemsSatisfiability modulo theoryStrategy synthesisThe framework of temporal problems with uncertainty (TPU) is useful to express temporal constraints over a set of activities subject to uncertain (and uncontrollable) duration. In this work, we focus on the most general class of TPU, namely disjunctive TPU (DTPU), and consider the case of weak controllability, that allows one to model problems arising in practical scenarios (e.g. on-line scheduling).We first tackle the decision problem, i.e. whether there exists a schedule of the activities that, depending on the uncertainty, satisfies all the constraints. We propose a logical approach, based on the reduction to a problem of Satisfiability Modulo Theories (SMT), in the theory of Linear Real Arithmetic with Quantifiers. This results in the first implemented solver for weak controllability of DTPUs.Then, we tackle the problem of synthesizing control strategies for scheduling the activities. We focus on strategies that are amenable for efficient execution. We prove that linear strategies are not always sufficient, even in the sub-case of simple TPU (STPU), while piecewise-linear strategies, that are multiple conditionally-applied linear strategies, are always sufficient. We present several algorithms for the synthesis of linear and piecewise-linear strategies, in case of STPU and of DTPU.All the algorithms are implemented on top of SMT solvers. We provide experimental evidence of the scalability of the proposed techniques, with dramatic speed-ups in strategy execution compared to on-line reasoning.© 2015 Elsevier B.V. All rights reserved.1. IntroductionMany practical settings, such as planning and scheduling, require the solution of sets of constraints over time points, that typically represent the time at which activities begin and end. For example, constraints may represent a bound on the overall time span, or lower/upper bounds on the distance between two activities.The Temporal Problem (TP) [18,36] is a well studied formalism to model such temporal constraints. In the basic form of TP, also referred to as TP without uncertainty, the durations of activities are assumed to be controllable by the executor. This means that the executor assumes to have the possibility of choosing any duration that it may want. A solution is an assignment to all the time points (i.e., the beginning time and the end time of the activities), that satisfies the constraints. ✩This paper is an extended version of [10] published at AAAI 2012, Toronto, Canada.* Corresponding author.E-mail addresses: cimatti@fbk.eu (A. Cimatti), amicheli@fbk.eu (A. Micheli), roveri@fbk.eu (M. Roveri).http://dx.doi.org/10.1016/j.artint.2015.03.0020004-3702/© 2015 Elsevier B.V. All rights reserved.\f2A. Cimatti et al. / Artificial Intelligence 224 (2015) 1–27Depending on the structure of the constraints, TPs range from simple temporal problems (STP) [18], to temporal constraint satisfaction problems (TCSP) [18], to disjunctive temporal problems (DTP) [36].In practice, activities may also have uncertain (and uncontrollable) durations. For example, it may be impossible to know precisely the time taken by a drilling or locomotion procedure; yet, the production of an overall schedule must be able to take this uncertainty into account. The formal framework of TPs has been extended with uncertainty (TPU), thus obtaining STPU, TCSPU, and DTPU [38,32,37]. Because of uncertainty, TPUs are much more complicated than TPs without uncertainty. In fact, they can be thought in terms of games, where the scheduler/executor must play against an “adversarial” envi-ronment. Intuitively, the variables representing the time points are separated into controllable ones (that are existentially quantified), and uncontrollable ones (universally quantified).Within this setting, several degrees of solution have been identified for TPUs [38]. In strong controllability, a solution is a fixed, unconditioned assignment to each controllable time point, that will satisfy the constraints regardless of the uncontrollable duration of the activities. This corresponds to devising a time-triggered program, where activities are started at fixed times.In dynamic controllability, a solution is a strategy where the values of controllable variables may depend on the values of the uncontrollable ones, as long as they can be observed, i.e. they occur in the past. The corresponding execution must deal with branching, and may interleave the start of activities with the observation of the uncontrollable (but observable) “end of activity” events.In this paper we focus on weak controllability, that is concerned with the existence of a strategy that associates values to the controllable starting points of each activity, as a function of the uncontrollable durations. The values for the uncon-trollable durations are not known at the moment of solving the problem; however, the executor is given the actual value of such durations just before the execution starts.There are several reasons for studying weak controllability. From the temporal problems perspective, weak controllabil-ity is a conceptually interesting dual of the strong controllability problem. In addition, deciding whether a given TPU is weakly controllable may serve as a pre-check for more complex problems such as dynamic controllability. In fact, weak controllability is a necessary condition for dynamic controllability [38].From the practical standpoint, weak controllability allows for the modeling of a setting where a number of tasks is to be repeatedly executed, but with modalities that depend on some environmental parameters that become available just prior to execution. For example, an automated production line may be required to perform a set of activities, whose duration functionally depends on the measured size of the objects to be manipulated. The duration of the activities is unknown a priori, except for an upper and lower bound, but it becomes precise once the actual objects materialize. Similarly, in a multi-core processor, the power management may dynamically control the actual clock speeds, thus affecting the duration of jobs. An on-line scheduler may be required to decide the appropriate allocation based on information that may be made available by the power management unit. Another example of application is given in the setting of remote systems (such as space exploration rovers or satellites), where the degradation due to use causes many activities to change duration over time. For example, the movement speed of many components may decrease with the age of the system. These domains share the fact that the tasks may be repeated multiple times, on platforms of limited capacity, and in conditions that can be estimated prior to execution. As such, they can be encoded as weak controllability problems.In this paper, we tackle weak controllability for DTPUs (i.e. in its most general form), making the following contributions. First, we propose a general decision procedure for the problem of weak controllability for DTPUs. Our approach makes use of the framework of Satisfiability Modulo Theory (SMT) [4], a formal framework that allows for the analysis of problems in decidable fragments of First Order Logic. The decision procedure is based on a reduction to an SMT problem for the theory of Quantified Linear Real Arithmetic (LRA). The encoding can be thought as working by refutation: we state the existence of an assignment to uncontrollable time points that cannot be countered by any controllable assignment. This means that the SMT problem is satisfiable if and only if the TPU is not weakly controllable. The problem can thus be directly provided to an efficient SMT solver. This approach accounts for the first implemented decision procedure for weak controllability of DTPUs.Then, we investigate the problem of on-line strategy execution, i.e. given a weakly controllable DTPU, how to repeatedly produce a suitable schedule for the controllable time points as a function of a valuation to the uncontrollable ones. We propose an approach, referred to as implicit strategy execution, based on the run-time execution of a solver for TP without uncertainty: any valuation to the uncontrollable durations removes the uncertainty from the problem, and thus transforms the TPU at hand into a TP. The solver is then invoked to solve the consistency problem yielding an assignment to the controllable time points. Unfortunately, this solution imposes strong requirements on the run-time: most notably, the control platform must support the execution of a solver; in addition, at each iteration it is required to solve an NP-hard problem, i.e. a DTP (without uncertainty).This motivates the investigation of efficient run-time execution for weakly controllable TPUs. We analyze the spectrum of explicit strategies, expressed in a form that does not require reasoning, and can thus be directly evaluated. We consider linear strategies, that are strategies in which the values for the controllable time points are a linear function of the uncontrollable ones; and piecewise-linear strategies, that are combinations of different linear strategies, each associated with an activation condition defined over",
            {
                "entities": [
                    [
                        3418,
                        3446,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 245 (2017) 115–133Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAn initial study of time complexity in infinite-domain constraint satisfactionPeter Jonsson a, Victor Lagerkvist b,∗a Department of Computer and Information Science, Linköping University, SE-581 83 Linköping, Swedenb Institut für Algebra, TU Dresden, 01069 Dresden, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 6 November 2015Received in revised form 9 January 2017Accepted 25 January 2017Available online 27 January 2017Keywords:Constraint satisfactionInfinite domainTime complexityThe constraint satisfaction problem (CSP) is a widely studied problem with numerous applications in computer science and artificial intelligence. For infinite-domain CSPs, there are many results separating tractable and NP-hard cases while upper and lower bounds on the time complexity of hard cases are virtually unexplored. Hence, we initiate a study of the worst-case time complexity of such CSPs. We analyze backtracking algorithms and determine upper bounds on their time complexity. We present asymptotically faster algorithms based on enumeration techniques and we show that these algorithms are applicable to well-studied problems in, for instance, temporal reasoning. Finally, we prove non-trivial lower bounds applicable to many interesting CSPs, under the assumption that certain complexity-theoretic assumptions hold. The gap between upper and lower bounds is in many cases surprisingly small, which suggests that our upper bounds cannot be significantly improved.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThis introductory section is divided into three parts: we begin by motivating our work, continue by discussing the problems that we study, and finally briefly present our results.1.1. MotivationThe constraint satisfaction problem over a constraint language (cid:2) (CSP((cid:2))) is the problem of finding a variable assignment which satisfies a set of constraints, where each constraint is constructed from a relation in (cid:2). This problem is a widely studied computational problem and it can be used to model many classical problems such as k-coloring and the Boolean satisfiability problem, in a natural and uniform way. In the context of artificial intelligence, CSPs have been used for for-malizing a wide range of problems, cf. Rossi et al. [55]. Efficient algorithms for CSP problems are hence of great practical interest. If the domain D is finite, then a CSP((cid:2)) instance I with variable set V can be solved in O (|D||V | · poly((cid:3)I(cid:3))) time by enumerating all possible assignments. Hence, we have an obvious upper bound on the time complexity. This bound can, in many cases, be improved if additional information about (cid:2) is known, cf. the survey by Woeginger [65] or the textbook by Gaspers [29]. There is also a growing body of literature concerning lower bounds [34,39,42,61].* Corresponding author.E-mail addresses: peter.jonsson@liu.se (P. Jonsson), victor.lagerqvist@tu-dresden.de (V. Lagerkvist).http://dx.doi.org/10.1016/j.artint.2017.01.0050004-3702/© 2017 Elsevier B.V. All rights reserved.\f116P. Jonsson, V. Lagerkvist / Artificial Intelligence 245 (2017) 115–133When it comes to CSPs over infinite domains, there is a large number of results that identify polynomial-time solvable cases, cf. Ligozat [45] or Rossi et al. [55]. However, almost nothing is known about the time complexity of solving NP-hard CSP problems. One may conjecture that a large number of practically relevant CSP problems do not fall into the tractable cases, and this motivates a closer study of the time complexity of hard problems. Thus, we initiate such a study in this article.1.2. Computational problemsAssume that we are given an instance of CSP((cid:2)) where (cid:2) is a constraint language over an infinite domain. Which upper bounds can we provide for CSP((cid:2))? Clearly, the method for finite-domain CSPs, based on enumerating all possible variable assignments, no longer work since the domain is infinite. In fact, infinite-domain CSPs are in general undecidable [7]. A first step is therefore to only consider decidable infinite-domain CSPs. However, even for such problems, for every recursive function, one can find a decidable CSP problem which cannot be solved faster than this [4]. Hence, we first need to fix a class of constraint languages X such that CSP((cid:2)) is included in a reasonable complexity class for every (cid:2) ∈ X . Througout this article we exclusively study the case when CSP((cid:2)) is included in NP, since this is a natural and well-studied class of problems. However, when considering CSPs over infinite domains, representational issues also become highly important. A relation in a finite-domain CSP problem is easy to represent by simply listing the allowed tuples. When considering infinite-domain CSPs, the relations need to be implicitly represented. A natural way is to consider disjunctive formulas over a finite set of basic relations. Let B denote some finite set of basic relations such that CSP(B) is tractable. Let B∨ω denote the closure of B under finitary disjunctions, and let B∨k be the subset of B∨ω containing only disjunctions of length at most k. We first consider a finite-domain example for illustrative purposes: let D = {true, false} and let B = {B 1, B2} where B1 = {true} and B2 = {false}. In other words a unary constraint of the form B 1(x) forces the variable x to be mapped to true, and B2( y) forces the variable y to be mapped to false. It is then easy to see that CSP(B∨ω) corresponds to the Boolean SAT problem while CSP(B∨k) corresponds to the k-SAT problem. Early examples of disjunctive constraints over infinite-domains can be found in, for instance, temporal reasoning [43,37,58], reasoning about action and change [26], and deductive databases [41]. More recent examples include interactive graphics [48], rule-based reasoning [46], and set constraints (with applications in descriptive logics) [10]. There are also works studying disjunctive constraints from a general point of view [16,21] but they are only concerned with the separation of polynomial cases from NP-hard cases, and do not further investigate the time complexity of the hard cases.There is also an important connection to constraint languages containing first-order definable relations (see Section 2.2for details). Assume (cid:2) is a finite constraint language containing relations that are first-order definable in B, and that the first order theory of B admits quantifier elimination. Then, upper bounds on CSP((cid:2)) can be inferred from results such as those that will be presented in Sections 3 and 4. This indicates that studying the time complexity of CSP(B∨ω) is worthwhile, especially since our understanding of first-order definable constraint languages is rapidly increasing [8].CSPs in certain AI applications are often based on binary basic relations and unions of them (instead of free disjunctive formulas). This is the predominant way of representing constraints in, for instance, spatial reasoning. Clearly, such relations are a subset of the relations in B∨k and we let B∨=denote this set of relations. We do not explicitly bound the length of disjunctions since they are bounded by |B|. The literature on such CSPs is voluminous and we refer the reader to Renz and Nebel [54] for an introduction. We remark that there exists examples of undecidable CSP problems over constraint languages of the form B∨=[32]. Hence, even for such restricted problems it is impossible to give general upper bounds, unless additional restrictions are imposed on the set B of basic relations.1.3. Our resultsThroughout the article, we primarily measure time complexity in the number of variables. Historically, this has been the most common way of measuring time complexity: the vast majority of work concerning finite-domain CSPs concentrates on the number of variables. One reason for this is that an instance may be massively larger than the number of variables — a SAT instance I = (V , C) (where V is the set of variables and C is the set of clauses) may contain up to 22|V |distinct clauses if repeated literals are disallowed — and measuring in the instance size may give far too optimistic figures. This may be quite detrimental since naturally appearing test examples tend to contain a moderate number of constraints. In light of |V | · poly((cid:3)I(cid:3))) time (where (cid:3)I(cid:3) denotes the total this, it is much more informative to know that SAT can be solved in O (2(cid:3)I(cid:3) · poly((cid:3)I(cid:3))) time (which number of bits needed for representing I ) instead of merely knowing that it is solvable in O (2|V | · poly((cid:3)I(cid:3))) that increasing of course is true since |V | ≤ (cid:3)I(cid:3)). For instance, we immediately conclude from the bound O (2the number of variables increases the run time much more rapidly than increasing the number of clauses. This is something (cid:3)I(cid:3) · poly((cid:3)I(cid:3))).that one cannot immediately infer from the bound O (2Let us now turn to the time complexity of solving infinite-domain CSPs. To solve such problems in practice, backtracking algorithms are usually employed. The literature on heuristically guided backtracking algorithm and empirical analyses of such algorithms is huge: we refer the reader to any good textbook (such as Dechter [24] or the handbook edited by Rossi et al. [55]) on constraint satisfaction for more information about this. What we find lacking in the literature are analyses of the asymptotical performance of such algorithms, i.e. their worst-case behavior. Unfortunately, we show in Section 3that they can be highly inefficient in the worst case. Let p denote the maximum arity of the relations in the set of basic \fP. Jonsson, V. Lagerkvist / Artificial Intelligence 245 (2017) 115–133117relations B, let m = |B|, and let |V | d",
            {
                "entities": [
                    [
                        3128,
                        3156,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1429–1469Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMaintenance goals of agents in a dynamic environment: Formulation andpolicy construction ✩Chitta Baral a,∗, Thomas Eiter c, Marcus Bjäreland b, Mutsumi Nakamura aa Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287, USAb AstraZeneca R&D, S-43183 Mölndal, Swedenc Institute of Information Systems, Vienna University of Technology, A-1040 Vienna, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 25 September 2005Received in revised form 3 March 2008Accepted 18 March 2008Available online 3 April 2008Keywords:Maintenance goalsk-maintainabilityAgent controlComputational complexity of agent designAnswer set programmingHorn theoriesSAT solvingDiscrete event dynamic systemsSelf-stabilizationThe notion of maintenance often appears in the AI literature in the context of agentbehavior and planning. In this paper, we argue that earlier characterizations of the notionof maintenance are not intuitive to characterize the maintenance behavior of certain agentsin a dynamic environment. We propose a different characterization of maintenance anddistinguish it from earlier notions such as stabilizability. Our notion of maintenance is moresensitive to a good-natured agent which struggles with an “adversary” environment, whichhinders her by unforeseeable events to reach her goals (not in principle, but in case). It hasa parameter k, referring to the length of non-interference (from exogenous events) neededto maintain a goal; we refer to this notion as k-maintainability. We demonstrate the notionon examples, and address the important but non-trivial issue of efficient constructionof maintainability control functions. We present an algorithm which in polynomial timeconstructs a k-maintainable control function, if one exists, or tells that no such controlis possible. Our algorithm is based on SAT Solving, and employs a suitable formulationof the existence of k-maintainable control in a fragment of SAT which is tractable. Forsmall k (bounded by a constant), our algorithm is linear time. We then give a logicprogramming implementation of our algorithm and use it to give a standard proceduralalgorithm, and analyze the complexity of constructing k-maintainable controls, underdifferent assumptions such as k = 1, and states described by variables. On the one hand,our work provides new concepts and algorithms for maintenance in dynamic environment,and on the other hand, a very fruitful application of computational logic tools. We compareour work with earlier works on control synthesis from temporal logic specification andrelate our work to Dijkstra’s notion of self-stabilization and related notions in distributedcomputing.© 2008 Elsevier B.V. All rights reserved.✩A preliminary version of the formulation part, entitled “A formal characterization of maintenance goals”, has been presented at AAAI’00, and apreliminary version of the algorithm part entitled “A polynomial time algorithm for constructing k-maintainable policies” has been presented at ICAPS’04.The current version revises and combines both of them with additional elaborations, examples, results, and proofs. The major part of the algorithms wasdone when Chitta Baral was visiting Vienna University of Technology in 2003. Marcus Bjäreland carried out the major part of his work while he was withthe Department of Computer and Information Science of Linkoping University.* Corresponding author.E-mail addresses: chitta@asu.edu (C. Baral), eiter@kr.tuwien.ac.at (T. Eiter), marcus.bjareland@astrazeneca.com (M. Bjäreland), mutsumi@asu.edu(M. Nakamura).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.005\f1430C. Baral et al. / Artificial Intelligence 172 (2008) 1429–14691. Introduction and motivationFor an agent situated in a static environment, the goal is often to reach one out of several states where certain conditionsare satisfied. Such a goal is usually expressed by a formula in propositional or first-order logic. Sometimes the goal requiresconstraining the path taken to reach one of the states. In that case, the goal can be expressed by a formula in temporallogic [3,7,54].Our concern in this paper is about agents in a dynamic environment. In that case, things are more complex since thestate of the world can change through both actions of the agent and of the environment. The agent’s goal in a dynamicenvironment is then often more than just achieving a desired state, as after the agent has successfully acted to reach adesired state, the environment may change that state. In such a case, a common goal of an agent is to ‘maintain’ rather thanjust ‘achieve’ certain conditions. The goal of maintaining certain conditions (or a set of states that satisfy these conditions)is referred to as maintenance goals. Maintenance goals are well-known in the AI literature, e.g., [3,27,41,55,67], and havecounterparts in other areas such as in stability theory of discrete event dynamic systems [56,58,61,62,66] and in activedatabases [17,51]. However, as we argue in this paper, earlier characterizations of maintenance goals are not adequate underall circumstances.To see what is wrong with earlier definition of maintenance goals, suppose an agent’s goal is to maintain a fluent f ,i.e., the proposition f should be true. A straightforward attempt1 to express it using temporal operators is the formula(cid:2) f , where (cid:2) is the temporal operator “Always” and (cid:2) f means that fis true in all the future states of the world. This istoo strong a condition, as maintaining inherently means that things go out of shape and they have to be maintained backto shape. A better temporal logic representation of this goal is thus the formula (cid:2)(cid:3) f , where (cid:3) is the temporal operator“Eventually”. Intuitively, the formula (cid:2)(cid:3) fis satisfied by an infinite trajectory of states of the form s0, s1, s2, . . . , if at anystage i (cid:2) 0, there exists some stage j (cid:2) i such that fis true in s j . An agent’s control is said to satisfy (cid:2)(cid:3) f if all trajectoriesthat characterize the evolution of the world due to the environment and the agent’s control satisfy (cid:2)(cid:3) f . At first glance the formula(cid:2)(cid:3) f seems to express the goal of maintaining f , as it encodes that if f becomes f alse in any state in the trajectory thenit becomes true in a later state.We consider (cid:2)(cid:3) f to be also too strong a specification—in many situations—to express the intuitive notion of ‘main-taining f ’, if we take on a more refined view of the (sometimes nasty) part which the environment might play, which weillustrate by some examples. Suppose f denotes the condition that the Inbox of a customer service department be empty.Here the environment makes f false by adding new requests to the Inbox while the agent tries to make f true by process-ing the messages in the Inbox and removing them from it. If the agent is diligent in processing the message in the Inboxand makes it empty every chance the agent gets, we would then like to say that agent maintains the Inbox empty. But sucha control does not satisfy the formula (cid:2)(cid:3) f under all circumstances, because there will be trajectories where the agent isoverwhelmed by the environment (flooding the Inbox) and f never becomes true.Another example in support of our intuition behind maintainability is the notion of maintaining the consistency of adatabase [17,51,68]. When direct updates are made to a database, maintaining the consistency of the database entails thetriggering of additional updates that may bring about additional changes to the database so that in the final state (after thetriggering is done) the database reaches a consistent state. This does not mean that the database will reach consistency ifcontinuous updates are made to it and it is not given a chance to recover. In fact, if continuous update requests are madewe may have something similar to denial of service attacks. In this case we can not fault the triggers saying that they donot maintain the consistency of the database. They do. It is just that they need to be given a window of opportunity or arespite from continuous harassment from the environment to bring about the additional changes which are necessary torestore database consistency. The same holds for maintaining a room clean; we can not fault the cleaning person if he orshe is continually sent away because the room is being continuously used.Another example is a mobile robot [15,47] which is asked to ‘maintain’ a state where there are no obstacles in front of it.Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot, there is no way for the robotto reach a state with no obstacle in front of it. But often we will be satisfied if the robot avoids obstacles in its front whenit is not continually harassed. Of course, we would rather have the robot take a path that does not have such an adversary,but in the absence of such a path, it would be acceptable if it takes an available path and ‘maintains’ states where there areno obstacles in front.The inadequacy of the expression (cid:2)(cid:3) fis defined ontrajectories which do not distinguish between transitions due to agent actions and environment actions. Thus we can notdistinguish the casesin expressing our intuition about ‘maintaining f ’ is because (cid:2)(cid:3) f(i) where the agent does its best to maintain f (and is sometimes thwarted by the environment) and can indeed make ftrue in some (say, k) steps if there is no interference from the environment during those steps; and(ii) where the agent really does not even try.1 All through the paper we consider the evaluation of linear temporal formulas with respect to all ‘valid’ trajectories. An alternative approach would beto use a va",
            {
                "entities": [
                    [
                        3798,
                        3826,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 204 (2013) 30–55Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintType Extension Trees for feature construction and learningin relational domainsManfred Jaeger a,∗, Marco Lippi b, Andrea Passerini c, Paolo Frasconi da Institut for Datalogi, Aalborg Universitet, Denmarkb Dipartimento di Ingegneria dell’Informazione e Scienze Matematiche, Università degli Studi di Siena, Italyc Dipartimento di Ingegneria e Scienza dell’Informazione, Università degli Studi di Trento, Italyd Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Firenze, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 23 October 2012Received in revised form 31 July 2013Accepted 8 August 2013Available online 20 August 2013Keywords:Statistical relational learningInductive logic programmingFeature discovery1. IntroductionType Extension Trees are a powerful representation language for “count-of-count” featurescharacterizing the combinatorial structure of neighborhoods of entities in relationaldomains. In this paper we present a learning algorithm for Type Extension Trees (TET)that discovers informative count-of-count features in the supervised learning setting.Experiments on bibliographic data show that TET-learning is able to discover the count-of-count feature underlying the definition of the h-index, and the inverse document frequencyfeature commonly used in information retrieval. We also introduce a metric on TET featurevalues. This metric is defined as a recursive application of the Wasserstein–Kantorovichmetric. Experiments with a k-NN classifier show that exploiting the recursive count-of-count statistics encoded in TET values improves classification accuracy over alternativemethods based on simple count statistics.© 2013 Elsevier B.V. All rights reserved.Probabilistic logical (or relational) models provide models for properties and relationships of entities in domains witha relational structure, such as graphs, networks, or, generally, any kind of structure found in a relational database. Theprevalence of this type of structured data, and the challenges posed by it for traditional machine learning methods basedon simple attribute-value data models has led to an increasing interest over the past 10 years in probabilistic logical models,and associated statistical-relational learning techniques [10,6].When modeling entities embedded in a relational domain a key question is what features of the entities are relevantto model and predict properties of interest. Apart from using attributes of the given entities themselves, one has in rela-tional learning the ability to construct new features by considering the relational neighborhood of an entity. Taking intoconsideration related entities and their attributes, one obtains a basically unlimited supply of potential features.A word on terminology here may be in order: by an attribute we mean a formal representation in a dataset of a propertyof individual entities by a data column. The color property of a flower, for example, could be formalized by attributessuch as color ∈ {red, green, blue, orange, . . .}, or three distinct attributes RGB_red, RGB_green, RGB_blue ∈ {0, . . . , 255}. Thevalue space of an attribute will typically be a simple data type like Boolean, enumeration, or numeric. In classic attribute-value data, feature is often a synonym for attribute. By contrast, we use feature to denote formalized properties in a muchbroader sense. First, a feature may only be implicit in the data as a function of explicit data. For example, brightnessas a function of RGB_red, RGB_green, and RGB_blue is a feature for an attribute-value dataset containing the attributes* Corresponding author.E-mail addresses: jaeger@cs.aau.dk (M. Jaeger), lippi@diism.unisi.it (M. Lippi), passerini@disi.unitn.it (A. Passerini), paolo.frasconi@unifi.it (P. Frasconi).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.08.002\fM. Jaeger et al. / Artificial Intelligence 204 (2013) 30–5531Fig. 1. Bibliographic data fragment and count-of-count feature.RGB_red, RGB_green, RGB_blue; the “number of friends older than 22” is a feature (of a person entity) in a relational social-network dataset. Second, for relational data, a feature can also represent a property relating multiple entities. Thus, “titleshaving more than 3 words in common” would be a feature for a pair of paper entities in a bibliographic database. Third,unlike other common frameworks in statistical learning (like for example kernel methods), in this paper we are not in-terested in simple numerical features but will focus on features whose values are complex combinatorial data structuresrepresenting what we loosely will call counts-of-counts. In all cases, however, we require that a feature has a well-definedformal specification and value space. The language available for the formal specifications defines the feature space.Relational learning frameworks differ widely to what extent they are linked to a clearly defined feature space, and towhat extent feature selection or feature construction is integrated into the model learning process. On the one hand, thereare techniques that only require the availability of features of a simple data type. The features construction is not part of thelearning framework, and usually requires an application-dependent data pre-processing [42]. Propositionalization approachesalso maintain a strict separation between feature construction and learning, but specific frameworks and representationlanguages for feature specification are a crucial ingredient [22].On the other extreme there are approaches in which feature construction and model learning are tightly integrated,and, in fact, the learned model essentially consists of a list of features represented in a formal specification language. Tothis category belong most frameworks that are based on predicate logic as the feature representation language [3,20,21]. Inbetween, there are approaches where feature construction is an integral part of the learning process, but the exact featurespace accessible to the learner is less clearly delimited [1,18].A key component in the design of relational features is given by the tools that are available for constructing features fromproperties of entities that are related to the entity of interest by chains of one or several relations. Since the number ofentities that are reached by such “slotchains” [8] varies from instance to instance, this feature construction usually involvesa form of combination or aggregation of the properties of multiple related entities.In non-probabilistic inductive logic programming approaches, such an aggregation is usually based purely on existentialquantification, i.e., a feature only determines whether or not a related entity with certain attributes exists. So, for example,for an “author” entity in a bibliographic database one could define a Boolean feature saying whether there exists a paperciting a paper of this author. A number of frameworks that are more closely linked to relational databases [31,13] constructfeatures based on aggregation operators. Here, it would be possible, for example, to construct a feature that represents theaverage count of citations that papers of an author have received, or a feature that represents the average price of itemspurchased by a customer. Recently approaches that define probability distributions over entire structures based on purecount features have become quite popular [36,43]. Here the probability of a relational structure (over a given domain ofentities) is determined by the count of entity tuples that satisfy some relational constraints, typically expressed as a logicalclause.All these approaches are based on features that only represent relatively simple summary statistics about quantitativeproperties of an entity’s relational neighborhood. However, for many prediction tasks, a more detailed picture of combi-natorial count-of-count features may be relevant. Consider the tiny bibliographic dataset shown in Fig. 1, for instance. Itrepresents 5 different authors, 10 different papers by these authors, and citation links between the papers. Simple summaryfeatures for an author a could be the number of a’s papers, or his/her total or average citation count. However, a currentlyimportant attribute for an author is the h-index [14]. To predict the h-index (or another attribute closely linked to theh-index – like receiving a professional award, or a large research grant) one may need to consider the more detailed featureof the count of papers with given counts of citations. In Fig. 1, the values for the 5 authors of this count-of-count featureare shown on the right (an expression k : l meaning that there are l papers with k citations).As another example for count of count features consider the Internet Movie Database (IMDB), a quite popular objectof investigation in relational machine learning. Here one may be interested in predicting some attribute of a movie, e.g.,whether it will be a box-office success (e.g. [38,31]). For this prediction one may consider the cast of the movie, for examplein terms of its size, the count of actors in the cast who have previously received an award nomination, the total number ofaward nominations shared by the actors, etc. Again, a more detailed count-of-count feature can be more informative thanonly flat counts: it will make a difference, perhaps, whether there is a single actor in the cast with many award nominations(perhaps a single box office draw actor, but maybe beyond the peak of his/her career?), or whether there are many actorswith one or two nominations each (perhaps a young all-star cast?).In information retrieval, relevance measures for a document d given a query q are often based on counting terms ap-pearing both in d and q. These counts will usually be weighted by a term weight such",
            {
                "entities": [
                    [
                        4012,
                        4040,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1481–1497Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiagnosing multiple intermittent failures using maximum likelihoodestimation ✩Rui Abreu a,∗, Arjan J.C. van Gemund ba Department of Informatics Engineering, Faculty of Engineering, University of Porto, Portugalb Embedded Software Group, Delft University of Technology, Faculty of Electrical Eng., Math., and CS, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 14 September 2009Received in revised form 8 September 2010Accepted 8 September 2010Available online 25 September 2010Keywords:Fault diagnosisBayesian reasoningMaximum likelihood estimationIn fault diagnosis intermittent failure models are an important tool to adequately deal withrealistic failure behavior. Current model-based diagnosis approaches account for the factthat a component c j may fail intermittently by introducing a parameter g j that expressesthe probability the component exhibits correct behavior. This component parameter g j , inconjunction with a priori fault probability, is used in a Bayesian framework to compute theposterior fault candidate probabilities. Usually, information on g j is not known a priori.While proper estimation of g j can be critical to diagnostic accuracy, at present, onlyapproximations have been proposed. We present a novel framework, coined Barinel, thatcomputes estimations of the g j as integral part of the posterior candidate probabilitycomputation using a maximum likelihood estimation approach. Barinel’s diagnosticperformance is evaluated for both synthetic systems, the Siemens software diagnosisbenchmark, as well as for real-world programs. Our results show that our approach issuperior to reasoning approaches based on classical persistent failure models, as well aspreviously proposed intermittent failure models.© 2010 Elsevier B.V. All rights reserved.1. IntroductionIn model-based fault diagnosis (MBD) faults are typically assumed to be persistent. In many practical situations, however,faults exhibit intermittent failure behavior, such as in copiers where sometimes sheets may be blank, or where a worn rollersometimes slips and causes a paper jam [12]. Intermittent failure is also relevant in software fault diagnosis, which is theprimary context of this paper. Although software is supposed to be inherently deterministic, intermittent failure modelsare often essential. This can be due to non-determinism (e.g., race conditions) caused by design faults related to properlydealing with concurrency. A more compelling reason is the modeling abstraction applied when reasoning about softwarecomponents. In our reasoning approach the input and output values are abstracted to binary “correctness” values. Consider,the integer division x/10 where 10 is a fault that should have been 15. Consider two input values x = 15, and x = 20,respectively. In the first case, the component produces a correct output, whereas in the second case the component fails. Ifboth inputs were modeled as correct (e.g., because they were produced by other, nominal, components) the division com-ponent exhibits intermittent failure behavior. Although a weak fault model (that does not stipulate particular fault behavior)admits any output behavior, modeling inconsistently failing (software) components merely in terms of weak models resultsin degraded diagnostic performance [4].✩This work has been carried out as part of the TRADER project under the responsibility of the Embedded Systems Institute. This project is partiallysupported by the Netherlands Ministry of Economic Affairs under the BSIK03021 program.* Corresponding author.E-mail addresses: rui@computer.org (R. Abreu), a.j.c.vangemung@tudelft.nl (A.J.C. van Gemund).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.09.003\f1482R. Abreu, A.J.C. van Gemund / Artificial Intelligence 174 (2010) 1481–1497A model for intermittent failure behavior [9] was introduced as an extension of the GDE framework [11,13]. Essentially,next to the prior probability p j that a component c j is at fault, a parameter g j is used to express the probability that a faultycomponent exhibits correct (good, hence g) behavior (g j = 0 = for persistently failing, g j = 1 = effectively ok, 0 < g j <1 = intermittently failing). The model is incorporated into the standard, Bayesian framework that computes the posteriorprobability of diagnosis candidates based on observations [8,13].The intermittent failure model has been shown to yield significantly better results (e.g., in the diagnosis and replanningof paper sheet paths in copiers with intermittent component failures [23], and in software fault diagnosis [4]), compared toan approach based on a classical, persistent failure model. An important problem in using the intermittent failure model,however, is the estimation of g j , as calibration data on correct and incorrect component behavior is typically not available.Estimating g j for each component c j would be straightforward when (sufficient) system observations are available whereonly that single, intermittently failing component is involved [9]. However, in a multiple-fault context usually only systemobservations are available in which multiple faulty components are involved. Consequently, isolating to what extent eachindividual component contributes to the observed, intermittent failure behavior is not trivial. However, as the influence ofg j in the computation of the posterior probability of each diagnostic candidate is significant, exact knowledge of each g jcan be critical to overall diagnostic accuracy.In [12] as well as in [4,5] strategies have been proposed to estimate the g j in a multiple-fault context. However, theapproaches are essentially based on an approximation. In this paper, we present a novel approach to compute the g j , inconjunction with a new approach towards the computation of the posterior candidate probabilities using an intermittentfailure model that generalizes over classical, persistent MBD approaches. The approach represents a departure from thecurrent Bayesian framework as used in current diagnosis approaches (e.g., [4] and [12]) in the sense that (1) the resulting g jare maximum likelihood estimators instead of approximations, and (2) the computation of the posterior candidate probabilitiesis an integral product of the g j estimation procedure.Apart from diagnosis accuracy, in this paper we also address diagnosis efficiency. The weak (intermittent) modelingapproach, in combination with the large systems we consider (in the order of tens of thousands of components) leads to ahuge diagnostic candidate space. In this paper we present a minimal hitting set algorithm that features a novel, diagnosis-specific heuristic that directs the search to generate candidates in order of decreasing posterior probability, even withinequal-cardinality groups. This feature allows the candidate generation process to be truncated to a very limited number ofcandidates (merely 100 in our experiments), yet effectively capturing all posterior probability mass. This tailored algorithmenables us to apply our diagnosis technique to very large systems.This paper makes the following contributions:• We present our new approach for the candidate probability computation which features a maximum likelihood estima-tion algorithm to compute the g j of all components involved in the diagnosis. The approach is coined Barinel,1 whichis the name of the software implementation of our method;• We present a new algorithm to compute the minimal hitting set from a set of conflicts, called Staccato,2 and derive itstime and space complexity;• We compare the accuracy and complexity of Barinel (including Staccato) to the current approaches in [4] and [12] forsynthetically generated observation series based on injected faults with known g j setpoints;• We describe the application of our approach to software multiple-fault diagnosis and evaluate its diagnostic perfor-mance using the well-known Siemens suite of benchmark programs (extended for multiple faults) as well as real-worldprograms (space, sed, gzip).The results from the synthetic experiments, as well as from the application to real software systems, confirm that ournew approach has superior diagnostic performance to all Bayesian approaches to intermittently failing systems known todate, at very limited computation cost.The paper is organized as follows. In the next section we describe the current Bayesian approach to persistent andintermittent failure models. In Sections 3 and 4 we describe our new approach to candidate generation, and posteriorprobability computation, respectively. Sections 5 and 6 present experimental results for synthetic observations, and realprogram codes, respectively. Section 7 describes related work, while Section 8 concludes the paper.2. PreliminariesIn this section we describe the state-of-the-art in MBD involving intermittent failures.1 Barinel stands for Bayesian AppRoach to dIagnose iNtErmittent fauLts. A barinel is a type of caravel used by the Portuguese sailors during theirdiscoveries.2 Staccato is an acronym for STAtistiCs-direCted minimAl hiTing set algOrithm.\fR. Abreu, A.J.C. van Gemund / Artificial Intelligence 174 (2010) 1481–149714832.1. Basic definitionsDefinition. A diagnostic system DS is defined as the triple DS = (cid:3)SD, COMPS, OBS(cid:4), where SD is a propositional theory de-scribing the behavior of the system, COMPS = {c1, . . . , cM } is a set of components in SD, and OBS is a set of observablevariables in SD.With each component c j ∈ COMPS we associate a health variable h j which denotes component health. The health statesof a component are either healthy (h j true) or faulty (h j false).Definition. An h-literal is h j or ¬h j for c j ∈ COMPS.Definition. An h-clause is a disjunction of h-literals containing no complementary pair of h-liter",
            {
                "entities": [
                    [
                        3876,
                        3904,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 164 (2005) 1–22www.elsevier.com/locate/artintA formal analysis of why heuristic functions workB. John Oommen a,∗,1, Luis G. Rueda b,2a Senior Member, IEEE. School of Computer Science, Carleton University, 1125 Colonel By Dr.,Ottawa, ON, K1S 5B6, Canadab School of Computer Science, University of Windsor, 401 Sunset Ave., Windsor, ON, N9B 3P4, CanadaReceived 10 May 2001AbstractMany optimization problems in computer science have been proven to be NP-hard, and it is un-likely that polynomial-time algorithms that solve these problems exist unless P = NP. Alternatively,they are solved using heuristics algorithms, which provide a sub-optimal solution that, hopefully,is arbitrarily close to the optimal. Such problems are found in a wide range of applications, in-cluding artificial intelligence, game theory, graph partitioning, database query optimization, etc.Consider a heuristic algorithm, A. Suppose that A could invoke one of two possible heuristic func-tions. The question of determining which heuristic function is superior, has typically demanded ayes/no answer—one which is often substantiated by empirical evidence. In this paper, by using Pat-tern Classification Techniques (PCT), we propose a formal, rigorous theoretical model that providesa stochastic answer to this problem. We prove that given a heuristic algorithm, A, that could utilizeeither of two heuristic functions H1 or H2 used to find the solution to a particular problem, if theaccuracy of evaluating the cost of the optimal solution by using H1 is greater than the accuracy ofevaluating the cost using H2, then H1 has a higher probability than H2 of leading to the optimal solu-tion. This unproven conjecture has been the basis for designing numerous algorithms such as the A*algorithm, and its variants. Apart from formally proving the result, we also address the correspond-ing database query optimization problem that has been open for at least two decades. To validateour proofs, we report empirical results on database query optimization techniques involving a fewwell-known histogram estimation methods. 2005 Elsevier B.V. All rights reserved.* Corresponding author.E-mail addresses: oommen@scs.carleton.ca (B.J. Oommen), lrueda@scs.carleton.ca (L.G. Rueda).1 Partially supported by NSERC, the Natural Science and Engineering Research Council of Canada. Fellow ofthe IEEE.2 This work was partially supported by Departamento de Informática, Universidad Nacional de San Juan,Argentina, and by NSERC. Member of the IEEE.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2002.02.001\f2B.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–22Keywords: A* algorithms; Heuristic algorithms; Pattern recognition; Optimization1. Introduction1.1. OverviewThe area of computer science has still quite a few open, unsolved problems. In thispaper, we are concerned with one such problems, namely that of using heuristics to solveoptimization problems.Any arbitrary optimization problem3 is typically defined in terms of instances which aredrawn from a (finite) set, X , an objective function, and some feasibility functions. The aimis to find an (and hopefully, the unique) instance of X , which leads to the maximum (or theminimum) value of the objective function subject to the feasibility constraints. A formaldefinition of an optimization problem can be found in [10]. But to be more specific, con-sider the well-known Traveling Salesman Problem (TSP), in which the cities are numberedfrom 1 to n, and the salesman starts from city 1, visits every other city once, and returnsto city 1. An instance of X is a permutation of the cities, for example, 1 4 3 2 5, if weare considering a world consisting of five cities. The objective function for that instance,f (1 4 3 2 5) is obtained by performing the summation of the inter-city distances: 1 → 4,4 → 3, 3 → 2, 2 → 5, and 5 → 1. The optimal solution is the instance that minimizes thevalue of f .A heuristic algorithm is an algorithm that attempts to find a certain instance of X thatmaximizes f (or the profit) by iteratively invoking a heuristic function. The instance thatmaximizes f will be the optimal solution4 to the optimization problem. A heuristic is amethod that performs one or more modifications to a given solution or instance, in order toobtain a different solution which is either superior, or which leads to a superior solution.The heuristic, in turn, invokes a heuristic function, which estimates (or measures) the costof the solution at the particular state in the search process. This is the context in which weuse these terms.Many heuristic algorithms and heuristic functions have been reported in the literature,where the former include the alpha-beta search [11], backtracking, hill-climbing [10], sim-ulated annealing [1], genetic algorithms [13], tabu search [7], learning automata [15], etc.The issue of how heuristic functions are used in such heuristic algorithms in searching,game playing, etc., can be found in [16,24] and is, indeed, an enormous field of study initself. This question is not addressed here.To clarify issues, let us consider the classical n-puzzle problem [16]. This problem con-sists of a square board containing n square tiles and an empty position called the “blank”.The aim is to rearrange the tiles from some pre-defined (usually random) initial configura-tion into a pre-determined goal configuration, by sliding any tile adjacent to the blank into3 Every optimization problem can also be formulated as a decision problem [6].4 We use the term “solution” to refer to an element x ∈ X , and the term “profit” to refer to the value of f (x).In minimization problems, f (.) will be a cost function.\fB.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–223the blank position. A heuristic algorithm solves this problem by examining, using a heuris-tic function, some of the possible valid movements. Viewed from the perspective of theunderlying state graph, the possible states encountered at the next level form the childrennodes of the current node in the search structure. Other variants of heuristic algorithmsinvolve the examination of lower levels as well. The breadth-first search and depth-firstsearch schemes are examples of heuristic algorithms, useful in any such problem solvingstrategy. An example of a heuristic function, however, is the measurement (or estimate) ofthe number of tiles that are out of place. Another measure is the sum of the depth of thenode and the number of tiles that are out of place.One of the better-known solutions to the n-puzzle problem is the A* algorithm. Thisalgorithm is a graph search algorithm that is used to find the path of minimum cost betweentwo nodes, the start node and the goal node. The A* maintains a tree which stores the pathsthat are already explored. Using these paths, a measure, f , of the potential advantage ofchoosing each path is calculated. The value of f , which is the cost of traversing the graphbetween two nodes, can be calculated by using different heuristic functions. A heuristic issaid to be admissible, and the A* converges to the correct result, if the heuristic function isan upper bound of the true cost from all nodes to the goal node.In general, for any arbitrary problem, the question of how useful a heuristic functionis, in determining the cost of traversing from one node to another, has no known analyticsolution—it has traditionally been empirically analyzed. In this paper, we present a formalanalysis that provides a stochastically positive answer to the question of comparing therelative advantages of potential heuristic functions.The A* algorithm and its variants (like the A+ algorithm) have also been success-fully applied to other problems, such as object recognition using deformable templates[16,26,28]. Various solutions to optimization problems using different heuristic functionsare found in [28]; we shall use this paper, [28], to highlight the difference between theheuristic algorithms, and the effect of the same algorithm using various potential heuristicfunctions. The authors of [28] address the problem of tracking roads in satellite imagesusing the twenty-question search paradigm, and the A+ algorithm, a “cousin” of the A*algorithm. Using these algorithms the roads can be represented in terms of straight-linesegments. The various paths are expanded by the application of an ensemble of heuristicfunctions. One such heuristic function is the one based on the conditional entropy mea-surements of the branches, which are used to choose the most “promising” path. Whilethe paper discusses other heuristic functions, the question of how one can compare thesolutions obtained using the various heuristic functions is achieved by comparing the em-pirical simulation results. We hope that our formal analysis can be a tool to achieve a morerigorous comparison of these heuristic functions in [28], and other similar scenarios.5The tools we propose to use are drawn from the well-established theory of PatternRecognition (PR) [5,27]—a prominent field of machine intelligence. Broadly speaking, PRinvolves decision-making, based on a priori and learned knowledge of the classes and ob-jects being recognized. More specifically, the system learns information about the features5 The model presented here has some limitations when investigating the quality of solutions yielded by anA*-like algorithm. These limitations will be discussed in a later sub-section.\f4B.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–22of a set of classes. Subsequently, given an object of unknown identity, and this informa-tion, the system attempts to recognize the unknown object as belonging to one of the knownclasses with some arbitrary accuracy. Necessarily, our overview of PR is brief!There are many applications of PR, including face and speech recognition, fingerprintidentification, character recognition, medical diagnosis, etc. I",
            {
                "entities": [
                    [
                        2604,
                        2632,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 193 (2012) 186–216Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcurrent forward bounding for distributed constraint optimizationproblemsArnon Netzer, Alon Grubshtein∗, Amnon MeiselsDept. of Computer Science, Ben Gurion University of the Negev, P.O. Box 653, Be’er Sheva 84105, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 6 November 2011Received in revised form 28 August 2012Accepted 4 September 2012Available online 7 September 2012Keywords:Distributed constraint optimizationproblemsAlgorithmsConcFBA distributed search algorithm for solving Distributed Constraints Optimization Problems(DCOPs) is presented. The new algorithm scans the search space by using multiple searchprocesses (SPs) that run on all agents concurrently. SPs search in non-intersecting parts ofthe global search space and perform Branch & Bound search. Each search process (SP) usesthe mechanism of forward bounding (FB) to prune efficiently its part of the global searchspace. The Concurrent Forward-Bounding (ConcFB) algorithm enables all SPs to share theirupper bound across all parts of the global search space. The number of concurrent SPs iscontrolled dynamically by the ConcFB algorithm, by performing dynamic splitting. Withineach SP a dynamic variable ordering is employed in order to help control the balanceof computational load among all agents and across different SPs. The ConcFB algorithmis evaluated experimentally and compared to all state of the art DCOP algorithms. Thenumber of Non-Concurrent Logical Operations, Non-Concurrent Steps, the total number ofmessages sent and CPU time are used as performance metrics. The evaluation procedureconsiders different DCOP problem types with a varying number of agents and differentconstraint graphs. As problems become larger and denser, ConcFB is shown to outperformall other evaluated algorithms by 2–3 orders of magnitude in all performance measures.Further evaluations comparing different variants of ConcFB provide important insights intothe working of the algorithm and reveals the contribution of its different components.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe field of Distributed Constraint Reasoning provides a widely accepted framework for representing and solving Multi-Agent Systems (MAS) problems. In a distributed constraint problem each agent holds a set of variables representing its state.These variables take values from a finite domain and are subject to constraints. A distributed constraint algorithm definesan interaction protocol for coordinating a joint assignment of variables. Optimally solving constraint problems is NP-Hard inthe general case [6].Distributed Constraint Reasoning provide an elegant model for many everyday combinatorial problems that are dis-tributed by nature. In these problems, independent computational entities, or agents, have partial knowledge of the problem.The distributed setting assumes that the agents are either incapable of disclosing private information or reluctant to do so[14,2]. Distributed Constraint Optimization Problems (DCOPs) were successfully applied to various MAS problems – coordi-nating mobile sensors [14,25], meeting and task scheduling [16], synchronization of traffic lights [13] and many others.Recent years have seen a large number of different and interesting algorithms for optimally solving DCOPs. These includeSynchronous Branch and Bound (SBB) [12], NCBB[4] , ADOPT [21], ODPOP[23] , BnB-ADOPT [26], OptAPO [10] and AFB [9].* Corresponding author. Tel.: +972 54 7706194; fax: +972 8 6477650.E-mail addresses: netzerar@cs.bgu.ac.il (A. Netzer), alongrub@cs.bgu.ac.il (A. Grubshtein), am@cs.bgu.ac.il (A. Meisels).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.09.002\fA. Netzer et al. / Artificial Intelligence 193 (2012) 186–216187Some algorithms use pseudo trees [21,23,26] (introduced in Section 2.2) and some attempt to asynchronously prune thesearch space [9]. The OptAPO algorithm partially centralizes the problem [10] and DPOP uses Dynamic Programming [23].Despite these differences, all algorithms share two important properties: they all attempt to increase efficiency by increasingcomputational concurrency and they all attempt to promptly obtain good bounds to reduce the number of states visited inthe search space.The present paper presents a new approach towards finding an optimal solution to DCOPs. The proposed algorithmpartitions the search space into non-intersecting subproblems somewhat similar to those described for DCSPs in [31]. Eachsubproblem involves all agents and is solved by the Synchronous Forward Bounding (SFB) algorithm. This choice of SFBstems from its synchronous nature and its powerful pruning abilities.The agents take part in solving all independent subproblems concurrently by assigning unique identifiers and separatedata structures to each subproblem. In this form, information from different areas of the search space can be used to achievebounds faster. The Concurrent Forward Bounding (ConcFB) algorithm has the following important properties:• High degree of concurrency. Much of the computational effort is performed in parallel and the algorithm terminatesfaster. Moreover, as is shown in Section 3, ConcFB controls the number of running concurrent search processes bydynamically splitting the remaining parts of the problem.• Improves on former methods of Forward Bounding by sharing information between disjoint parts of the search space.• Controls work load balancing by employing dynamic ordering heuristics. This is useful when computational effort iseither costly or slow (weak mobile devices).The efficiency of ConcFB is extensively evaluated against the state of the art algorithms where the number of Non-Concurrent Logical Operations, Non-Concurrent Steps, total number of messages sent and CPU time are used as performancemetrics. An additional concurrent algorithm which combines multiple instances of SBB is introduced and its implementationis evaluated to provide further insights on the impact of concurrent algorithms.The evaluation procedure considers different DCOP problem types with a varying number of agents and different con-straint graphs. As problems become larger and denser, ConcFB is shown to outperform all other evaluated algorithms by2–3 orders of magnitude in all performance metrics. Further evaluations comparing different variants of ConcFB provide im-portant insights into the working of the algorithm and reveals the contribution of its different components.The remainder of this paper is structured as follows: Section 2 formally defines DCOPs and introduces some leadingDCOP algorithms. Section 3 presents ConcFB in detail and Section 4 presents correctness and completeness proof for ConcFB.Section 5 describes enhancements to the basic ConcFB algorithm. The experimental evaluation and a discussion of the resultsis in Section 6. The conclusions are summarized in Section 7.2. Distributed constraint optimization2.1. Distributed Constraint Optimization Problem (DCOP)Formally, a DCOP is a tuple (cid:3)A, X , D, C(cid:4) where:1. A is a finite set of agents A1, A2, . . . , An.2. X is a finite set of variables X1, X2, . . . , Xm. Each variable is held by a single agent but an agent may hold more thanone variable.3. D is a set of domains D1, D2, . . . , Dm. Each domain D i contains a finite set of values which can be assigned to thevariable Xi .4. C is a set of constraints. Each constraint c ∈ C defines a non-negative cost for every possible value combination of a setof variables, and is of the form:C : D i1× D i2× · · · × D ik→ R+A binary constraint is a constraint involving exactly two variables which takes the following formCi j : D i × D j → R+A binary DCOP is a DCOP in which all constraints are binary.We say that a constraint c is applicable to a joint (partial or full) assignment a, if all variables involved in c take valuein a.To facilitate understanding, we make the following assumptions on the structure of DCOPs:1. Each agent holds a single variable (the terms variable and agent will be used interchangeably).2. DCOPs are assumed to be binary.These are common assumptions in the DCOP literature (cf. [21,19,3,26]).\f188A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 1. A simple DCOP example with four agents.Fig. 2. The OR search tree of the DCOP depicted in Fig. 1.Relations between interacting agents of a DCOP are often represented by graphs. Each node corresponds to an agentwhile an edge represents a constraint between two agents. The nature of these constraints is specified by a set of valuescorresponding to the agents’ joint assignments. It is worth noting that unless explicitly stated otherwise, it is commonto assume that the constraint structure of a DCOP does not limit communication between agents [27]. Thus agents cancommunicate with other agents and add links [29,27], agree on an ordering between them [30] or broadcast importantinformation to other agents which are not directly connected to them via a constraint [9]. Fig. 1 presents a simple DCOPproblem with four agents. The cost of each value combination is specified on the right hand side of the figure.A DCOP algorithm proceeds by sending out messages and by adding or changing assignments to variables. An assignmentis a (cid:3)variable, value(cid:4) pair. A set of assignments, in which each variable appears at most once, is called a partial assignment.The cost of a partial assignment, PA, is the aggregated constraint cost of all variables constituting the assignment PA. Forexample, the cost of the partial assignment (cid:3)a1, 3(cid:4)(cid:3)a2, 2(cid:4) with respect to the DCOP of Fig. 1, is exactly 1. Afull assignmentis a partial assignment that includes all variables, and a solution is a full assignment of minimal cost. The solution to theabove DCOP is (cid:3",
            {
                "entities": [
                    [
                        3851,
                        3879,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 220 (2015) 1–27Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSTR3: A path-optimal filtering algorithm for table constraints ✩Christophe Lecoutre a, Chavalit Likitvivatanavong b,∗a CRIL-CNRS UMR 8188, Université d’Artois, F-62307 Lens, Franceb School of Computing, National University of Singapore, 13 Computing Drive, Singapore 117417, Singapore, Roland H.C. Yap ba r t i c l e i n f oa b s t r a c tArticle history:Received 27 August 2014Received in revised form 3 December 2014Accepted 9 December 2014Available online 16 December 2014Keywords:Constraint satisfaction problemsGeneralized arc consistencyNon-binary constraintsBacktracking searchConstraint propagation is a key to the success of Constraint Programming (CP). The principle is that filtering algorithms associated with constraints are executed in sequence until quiescence is reached. Many such algorithms have been proposed over the years to enforce the property called Generalized Arc Consistency (GAC) on many types of constraints, including table constraints that are defined extensionally. Recent advances in GAC algorithms for extensional constraints rely on directly manipulating tables during search. This is the case with a simple approach called Simple Tabular Reduction (STR), which systematically maintains tables of constraints to their relevant lists of tuples. In particular, STR2, a refined STR variant is among the most efficient GAC algorithms for positive table constraints. In this paper, we revisit this approach by proposing a new GAC algorithm called STR3 that is specifically designed to enforce GAC during backtrack search. By indexing tables and reasoning from deleted values, we show that STR3 can avoid systematically iterating over the full set of current tuples, contrary to STR2. An important property of STR3 is that it can completely avoid unnecessary traversal of tables, making it optimal along any path of the search tree. We also study a variant of STR3, based on an optimal circular way for traversing tables, and discuss the relationship of STR3 with two other optimal GAC algorithms introduced in the literature, namely, GAC4 and AC5TC-Tr. Finally, we demonstrate experimentally how STR3 is competitive with the state-of-the-art. In particular, our extensive experiments show that STR3 is generally faster than STR2 when the average size of tables is not reduced too drastically during search, making STR3 complementary to STR2.© 2014 Elsevier B.V. All rights reserved.1. IntroductionAlgorithms that establish Generalized Arc Consistency (GAC) on constraint problems (networks) filter out inconsistent values from variable domains in order to reduce the combinatorial search spaces of such problems. They have been a staple of Constraint Programming (CP) since its origin in the field of Artificial Intelligence (AI) in the seventies, with for example the introduction of algorithms (G)AC3 [2] and (G)AC4 [3,4]. Typically, GAC is enforced at each step of a complete backtrack ✩This is an expansion of the article which previously appeared in ECAI-12 [1].* Corresponding author.E-mail addresses: lecoutre@cril.fr (C. Lecoutre), likitchav@gmail.com (C. Likitvivatanavong), ryap@comp.nus.edu.sg (R.H.C. Yap).http://dx.doi.org/10.1016/j.artint.2014.12.0020004-3702/© 2014 Elsevier B.V. All rights reserved.\f2C. Lecoutre et al. / Artificial Intelligence 220 (2015) 1–27Fig. 1. Standard and dual representations of the relation of a ternary constraint C with scope { X, Y , Z }.search, leading to the so-called MAC, Maintaining (generalized) Arc Consistency, algorithm [5]. This paper introduces a new GAC algorithm, called STR3, that works with positive table constraints. Furthermore, unlike most GAC algorithms, STR3 is specifically conceived to be used within MAC rather than being standalone.A table is just a relation, as in classical relational database, and a positive table constraint contains (in a table) all permit-ted combinations of values for a subset of variables (whereas a negative table constraint contains all forbidden combinations of values). Table constraints have been well studied in the artificial intelligence literature and arise naturally in many ap-plication areas. For example, in configuration and databases, they are introduced to model the problem no matter whatever the domain is. Besides, table constraints can be viewed as the universal mechanism for representing constraints, provided that space requirements can be controlled. The importance of table constraints makes them commonly implemented in all major constraint solvers that we are aware of (e.g., Choco, GeCode, JaCoP, OR-Tools).For table constraints, many classical filtering algorithms that reduce search through inference (such as [6–9]) work with constraints that stay unaltered while running. However, recent developments suggested that reducing the amount of traversal by discarding irrelevant tuples from tables can lead to faster algorithms. Simple Tabular Reduction (STR) and its improvements [10,11] fall into this category and have been shown to be among the best GAC algorithms for positive table constraints.The main idea behind simple tabular reduction is to remove invalid tuples from tables as soon as possible in a systematic fashion. STR3 is based on the same principle as STR1 [10] and STR2 [11] but employs a different representation of table constraints. Similarly to a few other algorithms (e.g., GAC-allowed [6] and GAC-va [8]), STR3 provides an index for each constraint table, enabling a tuple sought with respect to a domain value to be found without visiting irrelevant tuples, thus reducing time complexity. Fig. 1 shows an example for a ternary constraint. Importantly, for each constraint relation, STR3 maintains some specific data structures designed so that no constraint tuple is processed more than once along any path, through the search tree, going from the root to a leaf.Most of the GAC algorithms for table constraints previously introduced in the literature suffer from repeatedly traversing the same tables or related data structures during search [11,12]. In contrast, STR3 avoids such repetition and is path-optimal: each element of a table is examined at most once along any path of the search tree. An important feature of STR3 is that it is designed specifically to be interleaved with backtracking search, where the main goal is to maintain the consistency while minimizing the cost of backtracking. As such, unlike most other GAC algorithms, STR3 is only applicable within the context of search: STR3 maintains GAC, but before commencement of search, GAC must be enforced by some other algorithm, such as STR2 for example.We also investigated a promising circular manner for traversing tables in STR3. Although this seemed attractive at first because the circular approach described in [13] has an optimal run time per branch when amortized across a search tree, our experiments found that it was not really effective for STR3 in practice. To conclude our theoretical analysis, we discuss the relationships between STR3 and two other optimal GAC algorithms for table constraints, namely, GAC4 [4] and AC5TC-Tr [14].We present an extensive experimental study that demonstrates that STR3 is competitive with state-of-the-art algorithms. In particular, our experiments show that STR3 is rather complementary to STR2. STR2 is faster than STR3 where simple tab-ular reduction can eliminate so many tuples from the tables that they become largely empty. STR3, by contrast, outperforms STR2 when constraint relations do not shrink very much during search (this is when STR2 is the more costly). Hence, STR3 is complementary to STR2.This paper is organized as follows. Technical background is provided in Section 2. In Section 3, the concept of STR3 is explained together with its algorithm. A detailed example of STR3’s step-by-step execution is given in Section 4. Sec-tion 5 analyzes the relationships among STR’s data structures in greater detail. Theoretical analysis of STR3 is carried out in Sections 6 and 7. A variant of STR3 is studied in Section 8. Previous works related to STR3 are discussed in Section 9. Experimental results are reported in Section 10. The paper concludes in Section 11.\fC. Lecoutre et al. / Artificial Intelligence 220 (2015) 1–2732. PreliminariesIn this section, we introduce some technical background concerning the constraint satisfaction problem, and we recall the operation of a data structure called sparse set, which is key to STR3’s optimality.2.1. Constraint satisfaction problemA finite constraint network P is a pair (X , C ) where X is a finite set of n variables and C is a finite set of e constraints. Each variable X ∈ X has an initial domain, denoted by D( X), which is the set of values that can be assigned to X . Each constraint C ∈ C involves an ordered subset of variables of X , denoted by scp(C), that is called the scope of C . The arityof a constraint C is the number of variables involved in C , i.e., |scp(C)|. A binary constraint involves two variables whereas a non-binary constraint involves strictly more than two variables. The semantics of a constraint C is given by a relation, (cid:2)denoted by rel(C); if scp(C) = { X1, . . . , Xr}, then rel(C) ⊆ri=1 D( Xi) represents the set of satisfying combinations of values, called allowed tuples, for the variables in scp(C).A solution to a constraint network is an assignment of a value to every variable such that every constraint is satisfied. A constraint network is satisfiable iff at least a solution exists. The Constraint Satisfaction Problem (CSP) is the NP-complete task of determining whether a given constraint network is satisfiable or not. Thus, a CSP instance is defined by a constraint network, which is solved either by finding a solution or by proving that no solution exists. Solving a CSP instance usually involves a complete backtrack search that is interleaved",
            {
                "entities": [
                    [
                        3299,
                        3327,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1053–1091Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputational techniques for a simple theory of conditional preferencesNic Wilson∗Cork Constraint Computation Centre, Department of Computer Science, University College Cork, Cork, Irelanda r t i c l ei n f oa b s t r a c tA simple logic of conditional preferences is defined, with a language that allows thecompact representation of certain kinds of conditional preference statements, a semanticsand a proof theory. CP-nets and TCP-nets can be mapped into this logic, and the semanticsand proof theory generalise those of CP-nets and TCP-nets. The system can also expresspreferences of a lexicographic kind. The paper derives various sufficient conditions for a setof conditional preferences to be consistent, along with algorithmic techniques for checkingsuch conditions and hence confirming consistency. These techniques can also be used fortotally ordering outcomes in a way that is consistent with the set of preferences, and theyare further developed to give an approach to the problem of constrained optimisation forconditional preferences.© 2010 Elsevier B.V. All rights reserved.Article history:Received 28 February 2009Received in revised form 9 August 2010Accepted 9 August 2010Available online 2 December 2010Keywords:Conditional preferencesComparative preferencesCeteris paribus preferencesCP-netsTCP-netsConstrained optimisationLexicographic preferences1. Introduction(cid:3)(cid:3), where x, xThe formalism CP-nets [3,4] is designed for compactly expressing conditional comparative preferences in multivariateproblems. A CP-net involves statements of the form: u : x > xare values of a variable X and u is an assignmentto a set of variables U (called the parents of X ). The interpretation is that, given u, x is (strictly) preferred to x, all else(cid:3)being equal (ceteris paribus); that is, for all assignments s to the other variables S, sux is preferred to sux, where e.g., suxis the outcome (complete assignment) α such that α( X) = x, α(U ) = u and α(S) = s. The statement therefore compactlyrepresents exponentially many preferences between outcomes. This is a conditional preference, since the preference betweenvalues of X is conditional on the values of other variables U . It represents comparative preferences, in that the preferencestatements relate directly to the ordering between outcomes; this is in contrast to many theories of preference whichassign some form of grade to outcomes, and outcomes are compared by comparing their grades. Comparative preferencestatements can be easier to reliably elicit: often it is easier to judge that one alternative is preferred to another than it is toallocate particular grades of preference to the alternatives.(cid:3)Another key feature of CP-nets and related languages is the ceteris paribus aspect of the interpretation. If someone tellsus they’d prefer a green car to a white car, they wouldn’t usually mean that they’d prefer any green car to any white car;a ceteris paribus interpretation, that any green car is preferred to a car which is similar except being white, seems muchmore natural. However, this will tend to lead to quite weak inferences, and a user will sometimes want to express muchstronger statements such as those of the form: x is preferred to xirrespective of the values of other variables, where the variableX is the most important variable, and, for example, xrepresents a value that should be avoided if at all possible.(cid:3)(cid:3)This paper develops a formalism along similar lines to CP-nets, but where a richer language of preference statementscan be expressed: stronger conditional preference statements as well as the usual CP-nets ceteris paribus statements. The* Tel.: +353 21 4205954, fax: +353 21 4205369.E-mail address: n.wilson@4c.ucc.ie.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.018\f1054N. Wilson / Artificial Intelligence 175 (2011) 1053–1091(cid:3)to W and assignments t to S − W , tuxw is preferred to tux(cid:3)[W ] (where W is a subset of S), which represents that for all assign-language consists of statements of the form u : x > x(cid:3)ments w, w. So, given u and any t, x is preferred to xirrespective of the values of W . CP-nets ceteris paribus statements are represented by such statements with W = ∅, and the(cid:3)[V − { X}], where V is the setstrong conditional preference statement in the previous paragraph corresponds to (cid:5) : x > xof all variables. As in CP-nets, and their extension TCP-nets [6,8], this is a compact representation: each statement typicallycorresponds to many preferences between outcomes.w(cid:3)(cid:3)The next section introduces the new formalism, which can be viewed as a simple logic of conditional preferences. A cp-theory Γ has an associated preference relation >Γ on outcomes; Γ can be considered to be a compact representation of >Γ .A semantics is given and also a complete proof theory, based on ‘swapping sequences’, which is a natural generalisation offlipping sequences in CP-nets and TCP-nets. Section 3 examines the relative expressivity of the language as compared withCP-nets. It shows how CP-net orderings (Section 3.1) and TCP-net orderings (Section 3.2) can be represented within thelanguage; however, this stronger kind of preference statement, which can be used, for example, to construct a lexicographicorder on outcomes, is not expressible within the languages of CP-nets or TCP-nets (see Sections 3.3 and 3.4). Section 3.5illustrates that the ceteris paribus statements of CP-nets tend to be rather weak, by showing how hard it is for a CP-net togenerate a total order on outcomes.Sections 4, 5, 6 and 7, are all concerned with the inter-related topics of determining consistency of a cp-theory, totallyordering sets of outcomes, and constrained optimisation. Most of the work on CP-nets and TCP-nets has assumed a verystrong acyclicity property on the variables (though see [12,11]); here we generally make much weaker assumptions, whichis desirable since natural sets of conditional preference statements can easily fail to be acyclic in this sense. A necessarycondition for consistency is derived, “local consistency” (Section 4.1), and some sufficient conditions; determining whetherthese conditions hold is much less hard than determining consistency.A cp-theory is consistent if and only if there exists a strict total order on outcomes that satisfies it. We focus on aparticular kind of strict total order: one generated by a complete search tree (or “cs-tree”, see Section 4.2), as used inbacktracking search for solutions of a constraint satisfaction problem; the associated strict total order is the order in whichoutcomes are visited by such a search tree. We derive various sufficient conditions for a cs-tree to satisfy a cp-theory. Ifwe can show that there exists a cs-tree satisfying a cp-theory Γ , then we have proved that Γ is consistent. Furthermore,we can use such a satisfying cs-tree for totally ordering sets of outcomes, and in a constrained optimisation algorithm(Section 4.4), making use of an upper approximation of the preference relation, i.e., a relation on outcomes that extends thepreference relation.For the fully acyclic case, i.e., when the graph formed by dependencies and importance is acyclic, defining a satisfyingcs-tree is straightforward, as shown in Section 5; this implies that Γ is consistent if and only if it is locally consistent,with the latter condition often being very easy to check. For more general cases, the situation is more complicated, and inSections 6 and 7 we derive more complex methods for constructing satisfying cs-trees. Section 6 considers weaker forms ofacyclicity for cp-theories, that we call strong conditional acyclicity (Section 6.1) and cuc-acyclicity (Section 6.2), and whichare sufficient conditions for a cp-theory to be consistent. A polynomial upper approximation is derived for cuc-acyclic cp-theories.Proving consistency of a cp-theory by explicitly giving a cs-tree that satisfies the cp-theory will typically not be feasible,since the cs-tree is an exponentially large object. However, cs-trees can be defined in a compact way based on implicitrepresentations of the variable and value orderings; defining the value ordering is easy, given that the cp-theory is locallyconsistent. Section 7 defines a compact computational structure and associated techniques for defining the variable order-ings of a cs-tree satisfying the cp-theory; this can be used for confirming consistency, ordering outcomes and constrainedoptimisation.Section 8 discusses related work, Section 9 concludes, and Appendix A contains most of the proofs.2. A logic of conditional preferencesIn this section, a simple logic of conditional preferences is defined, with a language, semantics and a kind of prooftheory. As we will see in Sections 3.1 and 3.2, CP-nets and TCP-nets can be expressed within this language. The logic has asomewhat restrictive language, but the restrictions entail some nice properties, generalising properties of CP-nets.After giving some basic definitions of ordering relations in Section 2.1, we define cp-theories and their associated pref-erence relations in Section 2.2. A semantics (Section 2.3) and a proof theory (Section 2.4) are defined, with a completenessresult (Theorem 1).2.1. Ordering relationsIn this section we give some basic definitions and properties of ordering relations that will be used throughout thepaper.A binary relation (cid:6) on a set Ω is defined to be a subset of Ω × Ω ; the notations “(a, b) ∈ (cid:6)” and “a (cid:6) b” are usedinterchangeably. Since binary relations are sets, we can talk about the intersection and union of them, and containment ofone by another. So, in particular, if (cid:6) and (cid:6)(cid:3)holds if and only if a (cid:6) b impliesb. We may also say in this case that (cid:6)(cid:3",
            {
                "entities": [
                    [
                        3967,
                        3995,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 457–486Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintWeighted argument systems: Basic definitions, algorithms, andcomplexity resultsPaul E. Dunne a, Anthony Hunter b, Peter McBurney a, Simon Parsons c, Michael Wooldridge a,∗a Dept. of Computer Science, University of Liverpool, Liverpool, UKb Dept. of Computer Science, University College London, London, UKc Department of Computer and Information Science, Brooklyn College, CUNY, Brooklyn, NY, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 31 July 2009Received in revised form 8 September 2010Accepted 8 September 2010Available online 25 September 2010Keywords:ArgumentationHandling inconsistencyComputational complexityWe introduce and investigate a natural extension of Dung’s well-known model of argumentsystems in which attacks are associated with a weight, indicating the relative strengthof the attack. A key concept in our framework is the notion of an inconsistency budget,which characterises how much inconsistency we are prepared to tolerate: given aninconsistency budget β, we would be prepared to disregard attacks up to a total weightof β. The key advantage of this approach is that it permits a much finer grained levelof analysis of argument systems than unweighted systems, and gives useful solutionswhen conventional (unweighted) argument systems have none. We begin by reviewingDung’s abstract argument systems, and motivating weights on attacks (as opposed tothe alternative possibility, which is to attach weights to arguments). We then presentthe framework of weighted argument systems. We investigate solutions for weightedargument systems and the complexity of computing such solutions, focussing in particularon weighted variations of grounded extensions. Finally, we relate our work to the mostrelevant examples of argumentation frameworks that incorporate strengths.© 2010 Elsevier B.V. All rights reserved.1. IntroductionInconsistency between the beliefs and/or preferences of agents is ubiquitous in everyday life, and yet coping with in-consistency remains an essentially unsolved problem in artificial intelligence [12]. One of the key aims of argumentationresearch is to provide principled techniques for handling inconsistency [13,46].Although there are several different perspectives on argumentation, a common view is that argumentation starts with acollection of statements, called arguments, which are related through the notions of support and attack. Typically, argumentα1 supporting argument α2 would be grounds for accepting α2 if one accepted α1, while argument α1 attacking argumentα2 would be grounds for not accepting α2 if one accepted α1. Now, if we allow arguments to attack one-another, then suchcollections of arguments may be inconsistent; and the key question then becomes how to obtain a rationally justifiableposition from such an inconsistent argument set. Various solutions have been proposed for this problem, such as admissiblesets, preferred extensions, and grounded extensions [19]. However, none of these solutions is without drawbacks. A commonsituation is that, while a solution may be guaranteed to give an answer, the answer may be the empty set. Conversely,several answers may be provided, with nothing to distinguish between them. These drawbacks limit the value of thesesolutions as argument analysis tools.* Corresponding author.E-mail addresses: ped@csc.liv.ac.uk (P.E. Dunne), a.hunter@cs.ucl.ac.uk (A. Hunter), mcburney@liverpool.ac.uk (P. McBurney),parsons@sci.brooklyn.cuny.edu (S. Parsons), mjw@csc.liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.09.005\f458P.E. Dunne et al. / Artificial Intelligence 175 (2011) 457–486In part to overcome these difficulties, there is a trend in the literature on formalizations of argumentation towardsconsidering the strength of arguments. In this work, which goes back at least as far as [30], it is recognized that not allarguments are equal in strength, and that this needs to be taken into account when finding extensions of a collection ofarguments and counterarguments. We review this literature in Section 2.1, and we conclude that whilst it is clear thattaking the strength of arguments into account is a valuable development, it is not just the strength of the arguments, per se,that is important. The strength of the attack that one argument (which may itself be very strong) makes on another, can beweak.In this paper, we introduce, formalise, and investigate a natural extension of Dung’s well-known model of argumentsystems [19], in which attacks between arguments are associated with a numeric weight, indicating the relative strengthof the attack, or, equivalently, how reluctant we would be to disregard the attack. For example, consider the followingarguments:• α1 = The house is in a good location, it is large enough for our family and it is affordable: we should buy it.• α2 = The house suffers from subsidence, which would be prohibitively expensive to fix: we should not buy it.These arguments are mutually attacking, and in the terminology of Dung’s abstract argument systems [19], both argumentsare credulously accepted, neither is sceptically accepted, and the grounded extension is empty. Thus the conventional anal-ysis is not very useful for this scenario. However, the representation we are using surely misses a key point: the attacksare not of equal weight. We would surely regard the attack of α2 on α1 as being much stronger than the attack of α1 onα2, though both are very strong arguments in their own right. Our framework allows us to take these differing weights ofattack into consideration. (We note that an alternative to our approach, which has to some extent already been consideredin the literature, is to attach weights to arguments, rather than attaching weights to attacks between arguments. A detaileddiscussion of the relative merits of the two possibilities is given in Section 2.)A key concept in our framework is the notion of an inconsistency budget. The inconsistency budget characterises howmuch inconsistency we are prepared to tolerate: given an inconsistency budget β, we would be prepared to disregard at-tacks up to a total weight of β. By increasing the inconsistency budget, we get progressively more solutions, and this inturn gives a preference ordering over solutions: we prefer solutions obtained with a smaller inconsistency budget. This ap-proach permits a very fine-grained level of analysis, and gives useful, non-trivial solutions when conventional (unweighted)argument systems have none.The remainder of this paper is structured as follows:• We begin by reviewing Dung’s abstract argument systems, and providing motivation for the idea of extending Dung’sframework with weights. We discuss in particular the relative merits of attaching weights to arguments versus attachingweights to attacks.• In Section 3, we present the formal model of weighted argument systems that we work with throughout the remainderof the paper. After presenting the model, we discuss the semantics of weights, i.e., how weights can be interpreted, andhow they might be derived for some different domains.• In Sections 4–6, we investigate solutions to weighted argument systems and the associated complexity of computingthese solutions, focussing in particular on weighted variations of grounded extensions. We also consider the moregeneral algorithmic and combinatorial properties of our framework.• In Section 7, we consider the relationship between our weighted argument systems and four other well-known relatedextensions of Dung’s argument framework. We show that, in a precise formal sense, our weighted argument systemsare strictly more expressive: all of the other frameworks considered can be represented as weighted argument systems,but there exist weighted argument systems that have no equivalent representation in the alternative frameworks.• We conclude with some issues for future work.2. BackgroundSince weighted argument systems and their associated solutions generalise Dung’s well-known abstract argument sys-tems model, we begin by recalling the key concepts from this model — note that further discussion of related work may befound in Section 7.Definition 1. A Dung-style abstract argument system is a pair D = (cid:3)X , A(cid:4) where X = {α1, . . . , αk} is a finite set of arguments,and A ⊆ X × X is a binary attack relation on X [19].1The next step is to define solutions for such argument systems, i.e., concepts of what constitutes a set of mutuallyX → {(cid:7), ⊥}compatible arguments from X within a system (cid:3)X , A(cid:4). Typically, such subsets are defined via predicates σ : 21 Note that Dung’s model does not assume any internal structure for arguments, nor give any concrete interpretation for them. The intended interpreta-tion of the attack relation in Dung’s model is also not completely defined, but intuitively, (α1, α2) ∈ A means that if one accepts α1, then one should notaccept α2. In other words, it would be inconsistent to accept α2 if one accepted α1.\fP.E. Dunne et al. / Artificial Intelligence 175 (2011) 457–486459in ← out ← ∅Function ge(X , A) returns a subset of X1.2. while initial((cid:3)X , A(cid:4)) (cid:12)= ∅ doin ← in ∪ initial((cid:3)X , A(cid:4))3.out ← out ∪ {α ∈ X : ∃α(cid:15) ∈ in s.t. (cid:3)α(cid:15), α(cid:4) ∈ A}4.X ← X \\ (out ∪ in)5.A ← A restricted to X6.7.8.end-whilereturn in.Fig. 1. Computing the grounded extension of an (unweighted) argument system: the function ge(. . .).so that when σ (S) holds of S ⊆ X in (cid:3)X , A(cid:4) the set S is viewed as acceptable with respect to the criteria defined by σ(see e.g., Baroni and Giacomin [8]). We review a number of proposals for such criteria in the following definition.Definition 2. Given an argument system D = (cid:3)X , A(cid:4) and a set S ⊆ X , we say that S is initial if (cid:",
            {
                "entities": [
                    [
                        3726,
                        3754,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1308–1345Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpecifying and computing preferred plans ✩Meghyn Bienvenu a, Christian Fritz b, Sheila A. McIlraith c,∗a CNRS & Université Paris-Sud, Franceb Palo Alto Research Center, USAc Department of Computer Science, University of Toronto, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 April 2009Received in revised form 30 July 2010Accepted 30 July 2010Available online 2 December 2010Keywords:Knowledge representationPreferencesPlanning with preferencesIn this paper, we address the problem of specifying and computing preferred plans usingrich, qualitative, user preferences. We propose a logical language for specifying preferencesover the evolution of states and actions associated with a plan. We provide a semantics forour first-order preference language in the situation calculus, and prove that progressionof our preference formulae preserves this semantics. This leads to the development ofPPlan, a bounded best-first search planner that computes preferred plans. Our preferencelanguage is amenable to integration with many existing planners, and beyond planning,can be used to support a diversity of dynamical reasoning tasks that employ preferences.© 2011 Elsevier B.V. All rights reserved.1. IntroductionResearch in automated planning has historically focused on classical planning – generating a sequence of actions toachieve a user-defined goal, given a specification of a domain and an initial state. However, in many real-world settingssatisficing plans are plentiful, and it is the generation of high quality plans, meeting users’ preferences and constraints, thatpresents the greatest challenge [50].In this paper we examine the problem of preference-based planning – generating a plan that not only achieves a user-defined goal, but that also conforms, where possible, to a user’s preferences over properties of the plan. To address theproblem of preference-based planning, we require a language for specifying user preferences, as well as a means of gener-ating plans that is capable of optimizing for the defined class of preferences. To this end, we propose LPP , a first-orderlanguage for specifying domain-specific, qualitative user preferences. LPP is expressive, supporting the definition of tem-porally extended preferences over the evolution of actions and states associated with a plan. LPP harnesses much of theexpressive power of first-order and linear temporal logic (LTL) [51]. We define the semantics of our first-order preferencelanguage in Reiter’s version of the situation calculus [47,53]. Leveraging this semantics, we also define an extension of LPPthat allows for the specification of preferences over the occurrence of Golog complex actions [44,53]. Golog is an Algol-inspired agent programming language that supports the construction of complex actions using programming language-likeconstructs over primitive and complex actions. Golog has proven of great utility in a diversity of agent programming appli-cations.LPP ’s situation calculus semantics enables us to reason about preferences over situations (corresponding to trajectoriesor partial plans) within the language, which is beneficial for a diversity of reasoning tasks where distinguishing a preferredsituation or trajectory is relevant. Such tasks include but are not limited to plan understanding, diagnosis of dynamical✩The majority of the work presented in this paper was performed while the authors were affiliated with the University of Toronto. Revisions of the paperwere carried out while the first author was at Université Paul Sabatier and Universität Bremen, and the second author at Information Sciences Institute.* Corresponding author.E-mail addresses: meghyn@lri.fr (M. Bienvenu), cfritz@parc.com (C. Fritz), sheila@cs.toronto.edu (S.A. McIlraith).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.021\fM. Bienvenu et al. / Artificial Intelligence 175 (2011) 1308–13451309systems, and requirements modeling within software engineering. LPP can also be used to characterize ordered defaultsand norms for default and deontic reasoning.Despite LPP ’s roots in the situation calculus, planning with LPP does not require the use of deductive plan synthesisand a theorem prover. LPP is amenable to use by any state-of-the-art planner that can take LTL-based preferences as input.Indeed, as we will discuss later, work by Baier and McIlraith [2] provides a compilation algorithm that enables preference-based planners that do not accept LTL formulae as input to plan with LPP -like LTL preferences. In this paper, we proposePPLAN, a bounded best-first search forward-chaining planner in the spirit of TLPlan [1] and TALPlanner [43]. PPLAN exploitsprogression to efficiently evaluate LTL preference satisfaction over partial plans. To guide search towards an optimal plan, wepropose an admissible evaluation function that, in concert with A* search, results in the generation of optimal plans.There is a significant body of research on preferences both within artificial intelligence (AI) and in related disciplines.A recent special issue of AI Magazine [36] provides a high-level overview of some of the latest AI research in this field,including research on planning with preferences [6]. In the last four years, there has been growing interest within theplanning community in preference-based planning. This includes study of the specification of preferences for planning (e.g.,Son and Pontelli [59,60] and Delgrande, Schaub, and Tompits [23]), and in particular an extension to the Planning DomainDefinition Language (PDDL) [48] by Gerevini and Long to include preferences (PDDL3) [33]. In 2006, the biennial Interna-tional Planning Competition (IPC-2006) included a track on planning with preferences specified in PDDL3. A number ofpreference-based planners were developed in and around this time, and subsequently (e.g., [24,25,41,61,9,10,29,3,5,35]). Wediscuss this related work in detail in Section 7.This paper is organized as follows. In Section 2 we provide a brief review of the situation calculus. Then in Section 3,we introduce the syntax and semantics of our LPP preference language for planning, illustrating its use through a moti-vating example which is carried throughout the paper. With the semantics of our preference language in hand, we returnto the general problem of planning with preferences. In Section 4, we define the notion of progression over LPP pref-erence formulae and prove that it preserves the semantics of our preferences. We also define an admissible evaluationfunction, which can be used with progression and A* search to generate optimal plans. Then, in Section 5, we describe thePPLAN algorithm, a bounded best-first forward-chaining planner that plans with preferences. We prove the correctness ofthe PPLAN algorithm and present experimental results for a proof-of-concept implementation of the algorithm in Prolog.Finally, in Section 6 we extend LPP to enable definition of preferences over Golog complex actions. We correspondinglyextend our notion of progression to include these new preference formulae. We conclude the paper with a discussion ofrelated work and a summary.2. PreliminariesThe situation calculus is a sorted, logical language with equality designed for specifying and reasoning about dynamicalsystems [53]. The signature of the language is specified in terms of three sorts: the set of action terms, A, consists ofconstants or functions mapping objects and sometimes other actions into elements of type action; the set of situation termsconsists of the constant S0, denoting the initial state of the world, and terms of the form do(a, s) where a is an actionterm and s is another situation term; finally object terms encompass everything that is neither an action nor a situation.In the situation calculus, the state of the world is expressed in terms of functions and relations (called fluents) which arerelativized to a particular situation s, e.g., F ((cid:3)x, s). In this paper, we consider only relational fluents, and we distinguishbetween the set F of fluents (e.g., isSnowing(s)), which are used to model dynamic properties of the world, and the setR of non-fluent relational formulae (e.g., meal(spaghetti)), which describe properties of the world that do not change overtime. A situation s is a history of primitive actions a ∈ A performed from the initial, distinguished situation S 0. The functiondo maps a situation s and an action a into a new situation do(a, s). The theory induces a tree of situations, rooted at S 0.states that situation s precedes situation sA basic action theory D in the situation calculus comprises four domain-independent foundational axioms and a set ofdomain-dependent axioms. The foundational axioms Σ define the situations, their branching structure and the situationpredecessor relation (cid:2). s (cid:2) sin the situation tree. Σ includes a second-orderinduction axiom. The domain-dependent axioms are strictly first-order and are of the general form described below. Thereader is also directed to Appendix A for an example axiomatization of the dinner domain, which we use throughout thispaper to illustrate concepts. Note that we follow the notational convention established by Reiter [53] and assume that freevariables in situation calculus formulae are universally quantified from the outside, unless otherwise noted. In later sections,when discussing preferences and Golog, we also adopt the convention of referring to fluents in situation-suppressed form,e.g., at(home) rather than at(home, s).(cid:5)(cid:5)• A set Dap of action precondition axioms which describe the conditions under which it is possible to execute an actionA in a situation s. An action precondition axiom for an action A takes the form(cid:2)PossA((cid:3)x), s(cid:3)≡ Π A((cid:3)x, s)where Π A((cid:3)",
            {
                "entities": [
                    [
                        3993,
                        4021,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 925–952www.elsevier.com/locate/artintGenerating and evaluating evaluative argumentsGiuseppe Carenini a,∗, Johanna D. Moore ba Computer Science Department, University of British Columbia, 2366 Main Mall, Vancouver, BC Canada V6T 1Z4b Human Communication Research Centre, University of Edinburgh, 2 Buccleuch Place, Edinburgh, United Kingdom EH8 9LWReceived 21 June 2005; received in revised form 15 May 2006; accepted 23 May 2006AbstractEvaluative arguments are pervasive in natural human communication. In countless situations people attempt to advise or persuadetheir interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). With the proliferation of on-line systemsserving as personal advisors and assistants, there is a pressing need to develop general and testable computational models forgenerating and presenting evaluative arguments. Previous research on generating evaluative arguments has been characterizedby two major limitations. First, researchers have tended to focus only on specific aspects of the generation process. Second, theproposed approaches were not empirically tested. The research presented in this paper addresses both limitations. We have designedand implemented a complete computational model for generating evaluative arguments. For content selection and organization, wedevised an argumentation strategy based on guidelines from argumentation theory. For expressing the content in natural language,we extended and integrated previous work in computational linguistics on generating evaluative arguments. The key knowledgesource for both tasks is a quantitative model of user preferences. To empirically test critical aspects of our generation model,we have devised and implemented an evaluation framework in which the effectiveness of evaluative arguments can be measuredwith real users. Within the framework, we have performed an experiment to test two basic hypotheses on which the design ofthe computational model is based; namely, that our proposal for tailoring an evaluative argument to the addressee’s preferencesincreases its effectiveness, and that differences in conciseness significantly influence argument effectiveness. The second hypothesiswas confirmed in the experiment. In contrast, the first hypothesis was only marginally confirmed. However, independent testing byother researchers has recently provided further support for this hypothesis.© 2006 Elsevier B.V. All rights reserved.Keywords: Natural language generation; User tailoring; Preferences; Empirical evaluation1. IntroductionEvaluative arguments are pervasive in natural human communication. In countless situations, people attempt toadvise or persuade their interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). For instance,doctors need to advise patients about which treatment is best for them. A teacher may need to convince a studentthat a certain course is (is not) the best choice for the student. And salespeople often need to compare similar prod-ucts, explaining why one of the products would be more to the current customer’s liking than the other(s). With the* Corresponding author.E-mail address: giuseppe.carenini@gmail.com (G. Carenini).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.003\f926G. Carenini, J.D. Moore / Artificial Intelligence 170 (2006) 925–952explosion of information available on-line and the ever-increasing availability of wireless devices, we are witnessinga proliferation of computer systems serving as personal assistants or advisors, e.g., [9,62], which aim to support orreplace humans in similar communicative settings. The success of such systems will crucially depend on their abilityto generate and present effective evaluative arguments.In the 1990s, considerable research was devoted to developing computational models for automatically generatingand presenting evaluative arguments. Several studies have investigated the process of selecting and structuring thecontent of an argument (e.g., [7,31,35,47]), and [23] developed a detailed model of how the selected content shouldbe realized in natural language. Despite the abundance of prior work on this topic, the previous research has beencharacterized by two major limitations. First, because of the complexity of generating natural language, researchershave tended to focus only on specific aspects of the generation process. Second, because of a lack of systematicevaluation, it is difficult to gauge the effectiveness, scalability and robustness of the proposed approaches.The research presented in this paper addresses these limitations. By following principles from argumentation the-ory and computational linguistics, we have developed a complete computational model for generating evaluativearguments. In our model, all aspects of the generation process are covered in a principled way, from selecting and or-ganizing the content of the argument, to expressing the selected content in natural language. For content selection andorganization, we devised an argumentation strategy based on guidelines from argumentation theory. For expressingthe content in natural language, we extended and integrated previous work on generating evaluative arguments. Thekey knowledge source for both tasks is a quantitative model of user preferences. To empirically test critical aspects ofour generation model, we have devised and implemented an evaluation framework in which the effectiveness of evalu-ative arguments can be measured with real users. The design of the evaluation framework was based on principles andtechniques from several research fields, including computational linguistics, social psychology, decision theory andhuman computer interaction. Within the framework, we have performed an experiment to test two basic hypotheseson which the design of the computational model is based; namely, that tailoring an evaluative argument to a model ofthe addressee’s preferences increases its effectiveness, and that differences in conciseness significantly influence ar-gument effectiveness. The first hypothesis was only marginally confirmed in the experiment (0.05 < p < 0.10), whilethe second one was confirmed at p < 0.05. Moreover, recent work [62], which is a direct extension of our research,provided further independent empirical support for the first hypothesis.In the next section, we focus on the problem of generating evaluative arguments tailored to a model of the user’spreferences and we describe the design and development of our Generator of Evaluative Argument (GEA). In Sec-tion 2, we describe our evaluation framework. First, we justify the design of the evaluation framework by reviewingliterature on persuasion from social psychology as well as previous work on evaluating natural language generationtechniques. Next, we introduce and motivate the user task at the core of the framework. In particular, we illustratehow, in the context of this task, the effectiveness of an argument can be assessed by measuring its effects on user’sbehaviors, beliefs and attitudes. Section 3 describes the experiment we ran within the evaluation framework and inSection 4 we discuss related work on generating and evaluating evaluative arguments.2. Generating evaluative argumentsThe generation of evaluative arguments has been extensively investigated in the past. Yet, the computational modelsdeveloped in previous work only cover sub-parts of the generation process. For instance, [35] provided a sophisticatedapproach only to content selection, while [23] was mainly limited to content realization. Furthermore, all earliermodels were not informed by argumentation theory [42], a theory, rooted in rhetoric, providing guidelines on howeffective arguments are to be generated.In this section we present GEA, the first computational model that covers all aspects of generating evaluativearguments in a principled way, by effectively integrating general principles and techniques from argumentation theoryand computational linguistics. GEA is a rather complex computational model. In this section, we describe its designand development in a top-down fashion. First, we illustrate how GEA specializes the pipeline architecture typicallyadopted in Natural Language Generation (NLG) systems and introduce the basic algorithms and knowledge structures.Then, we discuss a set of guidelines from argumentation theory on which an effective argumentation strategy can bebased. After that, we introduce the quantitative model used in GEA to represent the user’s preferences and describean argumentation strategy that tailors the content as well as structure of an evaluative argument to such a model. The\fG. Carenini, J.D. Moore / Artificial Intelligence 170 (2006) 925–952927Fig. 1. The GEA architecture as a specialization of the generic NLG pipeline architecture.section concludes with a detailed description of how GEA realizes the content selected by the argumentation strategyin natural language.2.1. The architecture of the Generator of Evaluative Arguments (GEA)Text generation involves two fundamental tasks: a process that selects and organizes the content of the text (deepgeneration), and a process that expresses the selected content in natural language (surface generation). GEA, likemost previous work in NLG, makes the assumption that deep generation should strictly precede surface generation,and adopts the resulting pipeline architecture [50]. In this architecture (see center of Fig. 1 from top to bottom) a textplanner selects and organizes content from a domain model by applying a communicative strategy to achieve a set ofcommunicative goals, which are given as input. The output of text planning is a text plan, a data structure that spec-ifies: the rhetorical structure of the text, the propositions that the text should convey and a partial order among thosepropositions. Then, a text Micro-Planner packages the selected cont",
            {
                "entities": [
                    [
                        3325,
                        3353,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 49–78Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintModular-E and the role of elaboration tolerance in solvingthe qualification problemAntonis Kakas a, Loizos Michael b, Rob Miller c,∗a University of Cyprus, P.O. Box 20537, CY-1678, Cyprusb Harvard University, Cambridge, MA 02138, USAc University College London, London WC1E 6BT, UKa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Reasoning about actionsElaboration toleranceQualification problemDefault reasoningWe describe Modular-E (ME), a specialized, model-theoretic logic for reasoning aboutactions. ME is able to represent non-deterministic domains involving concurrency, staticlaws (constraints), indirect effects (ramifications), and narrative information in the formof action occurrences and observations along a time line. We give formal results whichcharacterize ME’s high degree of modularity and elaboration tolerance, and show howthese properties help to separate out, and provide principled solutions to, differentaspects of the qualification problem. In particular, we identify the endogenous qualificationproblem as the problem of properly accounting for highly distributed, and potentiallyconflicting, causal knowledge when reasoning about the effects of actions. We show howa comprehensive solution to the endogenous qualification problem helps simplify theexogenous qualification problem — the problem of reconciling conflicts between predictionsabout what should be true at particular times and actual observations. More precisely, wedescribe how ME is able to use straightforward default reasoning techniques to solvethe exogenous qualification problem largely because its robust treatments of the frame,ramification and endogenous qualification problems combine into a particular characteristicof elaboration tolerance that we formally encapsulate as a notion of “free will”.© 2010 Elsevier B.V. All rights reserved.1. IntroductionFor half a century the seminal work of John McCarthy has been instrumental in identifying the major areas, issues anddirections for progress in Knowledge Representation and logic-based A.I. In particular, research in reasoning about actionand change (RAC), originally initiated by McCarthy and collaborators, continues to be a central topic in this field. “Classical”RAC formalisms such as the Situation, Event and Fluent Calculi [26,28,32,36], as well as their more semantically specializedcounterparts such as TAL, Dynamic Logic and the Languages A, E and C+ [5,8,10,12,15], are increasingly proving their worthnot only in traditionally related areas such as planning and cognitive robotics, but also in fields as diverse as computationalbiology, the semantic web and software engineering [27,33,38].Irrespective of the particular logic or formalism being developed, certain issues have for a long time been consideredfundamental in RAC. Foremost among these is of course the frame problem — how to succinctly and flexibly represent andreason about the non-effects of actions, avoiding such pitfalls as the infamous Hanks and McDermott problem [11]. Morerecently there has been much focus on the ramification problem — how to accommodate knowledge and inferences about the* Corresponding author.E-mail addresses: antonis@ucy.ac.cy (A. Kakas), loizos@eecs.harvard.edu (L. Michael), rsm@ucl.ac.uk (R. Miller).URLs: http://www2.cs.ucy.ac.cy/~antonis/ (A. Kakas), http://www.eecs.harvard.edu/~loizos/ (L. Michael), http://www.ucl.ac.uk/slais/rob-miller/ (R. Miller).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.008\f50A. Kakas et al. / Artificial Intelligence 175 (2011) 49–78indirect and knock-on effects of actions. Largely as a result of this, there has been a growing consensus that RAC formalismsneed to explicitly incorporate some notion of causality.However, a third fundamental issue identified by McCarthy, although generally perceived as important, has receivedrelatively little attention to date. This is the qualification problem [22,37], which, as we will see, relates to various difficultiesin adequately qualifying statements either about the executability or about the effects (both direct and indirect) of actions.One can in fact naturally cast the qualification problem in terms of McCarthy’s “Appearance and Reality” phenomenon [25].The reality in a domain, captured in the context of RAC formalisms by effect laws, is not directly observable, and theselaws are of necessity incomplete. This incompleteness leads in some cases to inconsistency, rendering the reasoning processincapable of drawing any conclusion. The qualification problem can be viewed as the problem of how to let appearancesin a domain (captured by observations, etc.) qualify our beliefs about the reality, so that the inconsistency is lifted, andmeaningful conclusions may be drawn.The qualification problem is the main focus of this paper. But, just as the ramification problem has proved to be in-timately related to the frame problem, the qualification problem is inextricably linked to both the frame and ramificationproblems, so that development of a solution to one inevitably leads to a re-examination of solutions to the other two. Hence,as a necessary preliminary to our main aim, we also present an exceptionally robust and complete solution to the frameand ramification problems combined. We also illustrate how McCarthy’s notion of elaboration tolerance [24], long considereddesirable in RAC frameworks, plays a key role in the combined solution to all three problems.1.1. Some terminologyIn order to describe the various aspects of the qualification problem, and our approach to solving them, it is convenientto first summarize some of the terminology commonly used in this research area. Time-varying properties of the world,i.e., those that can potentially be affected by actions, are usually referred to as fluents. The terms action and event are oftenused synonymously. A state is an assignment of a truth value to each fluent. Narrative-based formalisms (such as TAL, theEvent Calculus and the Language E ) employ a structure of time-points (or time intervals) that is defined independentlyfrom actions and fluents. One way or another, explicitly or implicitly, these frameworks associate a unique state with eachtime-point in each model. In such formalisms, a fluent holds at a time-point if it is true in the associated state. On theother hand, non-narrative-based formalisms (such as the Situation and Fluent Calculi and the Language A) avoid the useof an independent time structure by reasoning directly about sequences of actions. Such formalisms, one way or another,explicitly or implicitly, associate a unique state with each “allowed” action sequence in each model. The term situation issometimes used to refer to a sequence of actions and sometimes used to refer to the state associated with a sequence ofactions.There is also a common terminology as regards different types of statements or sentences within RAC formalisms. Theterms effect law, effect axiom, and causal law are sometimes used to characterize a sentence describing a specific causal effect.For example, to describe the effect of turning the ignition key of a car we may write (in the syntax of the Situation Calculus,the Event Calculus and the Language C+ respectively):Holds(EngineRunning, Do(TurnKey, s)) ← Holds(BatteryCharged, s)Initiates(TurnKey, EngineRunning, t) ← HoldsAt(BatteryCharged, t)TurnKey causes EngineRunning if BatteryChargedThe qualification BatteryCharged in this effect law is an example of a fluent precondition — although it is not necessaryfor BatteryCharged to hold in order for the TurnKey action to be successfully executed, BatteryCharged is necessary for theTurnKey action to have this particular effect on EngineRunning. In contrast to effect laws, executability laws specify conditionsunder which an action can or cannot be successfully executed, e.g. (Situation Calculus, Event Calculus and Language C+syntax respectively):Poss(TurnKey, s) ≡ Holds(HasKey, s)Impossible(TurnKey, t) ← ¬HoldsAt(HasKey, t)nonexecutable TurnKey if ¬HasKeyIn this statement the qualification HasKey is an executability or action precondition, and indeed such sentences are alsosometimes referred to as action precondition axioms.Most formalisms also allow various action-independent relationships between fluents or sets of fluents to be described.Domain constraints or state constraints are simply constraints on the set of allowed states that have to be taken into accountone way or another when constructing state transition rules from the domain description as a whole. For example, todescribe that broken cars’ engines cannot run we may write (in the Situation Calculus):¬[Holds(EngineRunning, s) ∧ Holds(EngineBroken, s)]\fA. Kakas et al. / Artificial Intelligence 175 (2011) 49–7851Exactly how a formalism should take such statements into account is of course debatable, a central issue being aboutwhether they should result in more or in less change. (In this particular example one might argue that an action thatcauses EngineBroken should therefore also cause ¬EngineRunning. But one is unlikely to argue that an action that causesEngineRunning should therefore also cause ¬EngineBroken, but rather that ¬EngineBroken should act as an extra fluentprecondition for effect laws that initiate EngineRunning.) In many formalisms the ambiguity of such statements can beavoided by re-expressing them as “unidirectional” ramification laws or indirect effect laws. For example, in the Language E wemay write:¬EngineRunning whenever {EngineBroken}to express that causing EngineBroken has the knock-on effect of causing ¬EngineRunning.Observation statements (or simply observations) are assertions that particular fluents hold or do not hold at particulartime-points or in particular states. For example, in the narrative-bas",
            {
                "entities": [
                    [
                        3668,
                        3696,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 247 (2017) 313–335Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintContinual curiosity-driven skill acquisition from high-dimensional video inputs for humanoid robotsVarun Raj Kompella∗, Marijn Stollenga, Matthew Luciw, Juergen SchmidhuberThe Swiss AI Lab IDSIA, USI & SUPSI, Galleria 2, 6928 Manno-Lugano, Switzerlanda r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 12 October 2014Accepted 2 February 2015Available online 12 February 2015Keywords:Reinforcement learningArtificial curiositySkill acquisitionSlow feature analysisContinual learningIncremental learningiCubIn the absence of external guidance, how can a robot learn to map the many raw pixels of high-dimensional visual inputs to useful action sequences? We propose here Continual Curiosity driven Skill Acquisition (CCSA). CCSA makes robots intrinsically motivated to acquire, store and reuse skills. Previous curiosity-based agents acquired skills by associating intrinsic rewards with world model improvements, and used reinforcement learning to learn how to get these intrinsic rewards. CCSA also does this, but unlike previous implementations, the world model is a set of compact low-dimensional representations of the streams of high-dimensional visual information, which are learned through incremental slow feature analysis. These representations augment the robot’s state space with new information about the environment. We show how this information can have a higher-level (compared to pixels) and useful interpretation, for example, if the robot has grasped a cup in its field of view or not. After learning a representation, large intrinsic rewards are given to the robot for performing actions that greatly change the feature output, which has the tendency otherwise to change slowly in time. We show empirically what these actions are (e.g., grasping the cup) and how they can be useful as skills. An acquired skill includes both the learned actions and the learned slow feature representation. Skills are stored and reused to generate new observations, enabling continual acquisition of complex skills. We present results of experiments with an iCub humanoid robot that uses CCSA to incrementally acquire skills to topple, grasp and pick-place a cup, driven by its intrinsic motivation from raw pixel vision.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOver the past decade, there has been a growing trend in humanoid robotics research towards robots with a large number of joints, or degrees of freedom, notably the ASIMO [1], PETMAN [2] and the iCub [3]. These robots demonstrate a high amount of dexterity and are potentially capable of carrying out complex human-like manipulation. When interacting with the real-world, these robots are faced with several challenges, not the least of which is the problem of how to solve tasks upon processing an abundance of high-dimensional sensory data.In the case of well structured environments, these robots can be carefully programmed by experts to solve a particu-lar task. But real-world environments are usually unstructured and dynamic, which makes it a daunting task to program these robots manually. This problem can be substantially alleviated by using reinforcement learning (RL; [4,5]), where a * Corresponding author.E-mail address: varun@idsia.ch (V.R. Kompella).http://dx.doi.org/10.1016/j.artint.2015.02.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f314V.R. Kompella et al. / Artificial Intelligence 247 (2017) 313–335Fig. 1. A playroom scenario for a baby humanoid-robot in a lab environment, where it is placed next to a table with a few moving objects. The robot has a limited field-of-view and encounters continuous streams of images as it holds or shifts its gaze. Figure shows three such perspectives oriented towards the moving objects. How can the robot learn to solve tasks in the absence of an external guidance?robot learns to acquire desired task-specific behaviors, by maximizing the accumulation of task-dependent external rewards through simple trial-and-error interactions with the environment.Unfortunately, for humanoid robots equipped with vision, the sensory and joint state space are so large that it is ex-tremely difficult to procure the rewards (if any exist) by random exploration. For example, if the robot receives a reward for sorting objects, it could take an extremely long time to obtain the reward for the first time. Therefore, it becomes necessary to (a) build lower-dimensional representations of the state-space to make learning tractable and (b) to explore the envi-ronment efficiently. But how can these robots learn to do this in the presence of external rewards that are typically only sparsely available?Much of the human capacity to explore and solve problems is driven by self-supervised learning [6,7], where we seek to acquire behaviors by creating novel situations and learning from them. As an example, consider a simple playroom scenario for a baby humanoid as shown in Fig. 1. Here, the robot is placed next to a table with a few moving objects. The robot has a limited field-of-view and encounters continuous streams of images as it holds or shifts its gaze. If the robot can learn compact representations and predictable behaviors (e.g., to grasp) from its interactions with the cup, then by using these learned behaviors, it can speed up the acquisition of external rewards related to some teacher-defined task, such as placing the cup at a particular location. Continually acquiring and reusing a repertoire of behaviors and representations of the world, learned through self-supervision, can therefore make the robot adept in solving many external tasks.But how can the robot (a) self-supervise its exploration, (b) build representations of the high-dimensional sensory inputs and (c) continually acquire skills that enable it to solve new tasks? These problems have individually been researched in the machine learning and robotics literature [8–29]. However, to develop a single system that addresses all these important is-sues together is a challenging open problem in artificial intelligence (AI) research. We propose an online-learning framework that addresses this open problem.In order to make the robot self-supervised or intrinsically-motivated to explore new environments, we use the theory of Artificial Curiosity (AC; [30,31]). AC mathematically describes curiosity and creativity. AC-driven agents are interested in the learnable but as-yet-unknown aspects of their environment, and are disinterested in the already learned and inherently unlearnable (noisy) aspects. Specifically, the agent receives intrinsic rewards for action sequences, and these rewards are pro-portional to the improvement of the agent’s internal model or predictor of the environment. Using RL and the self-generated intrinsic rewards derived using AC [32–36,25], the agent is motivated to explore the environment where it makes maximum learning progress.Most RL algorithms however, tend to work only if the dimensionality of the state space is small, or its structure is simple. In order to deal with massive high-dimensional streams of raw sensory information obtained, for example through vision, it is essential to reduce the input dimensionality by building low-dimensional but informative abstractions of the environment [37]. An abstraction maps the high-dimensional input to a low-dimensional output. The high-dimensional data sensed by a robot is often temporally correlated and can be greatly compressed if the temporal coherence in the data is exploited. Slow Feature Analysis (SFA; [14,38,39]) is an unsupervised learning algorithm that extracts temporal regularities from rapidly changing raw sensory inputs. SFA is based on the Slowness Principle [40–42], which states that the underlying causes of changing signals vary more slowly than the primary sensory stimulus. For example, individual retinal receptor responses or gray-scale pixel values of video may change quickly compared to latent abstract variables, such as the position of a moving object. SFA has achieved success in many problems and scenarios, e.g., extraction of driving forces of a dynam-ical system [43], nonlinear blind source separation [44], as a preprocessor for reinforcement learning [39], and learning of place-cells, head-direction cells, grid-cells, and spatial view cells from high-dimensional visual input [38].SFA techniques are not readily applicable to open-ended online learning agents, as they estimate covariance matrices from the data via batch processing. We instead use Incremental Slow Feature Analysis (IncSFA; [45,46]), which does not \fV.R. Kompella et al. / Artificial Intelligence 247 (2017) 313–335315need to store any input data or computationally expensive covariance matrix estimates. IncSFA makes it feasible to handle high-dimensional image data in an open-ended manner.IncSFA, like most online learning approaches, gradually forgets previously learned representations whenever the statistics of the input change, for example, when the robot shifts its gaze from perspective two to perspective one in Fig. 1. To ad-dress this issue, in our previous work, we proposed an algorithm called Curiosity-Driven Modular Incremental Slow Feature Analysis (Curious Dr. MISFA; [47,48]), which retains what was previously learned in the form of expert modules [29]. From a set of input video streams, Curious Dr. MISFA actively learns multiple expert modules comprising slow feature abstractions, in the order of increasing learning difficulty. The algorithm continually estimates the initially unknown learning difficulty through intrinsic rewards generated by exploring the input streams.Using Curious Dr. MISFA, the robot in Fig. 1 finds its interactions with the plastic cup more interesting (easier to encode) than the complex movements of the other objects. This results in a compact slow featur",
            {
                "entities": [
                    [
                        3424,
                        3452,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 62–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTransforming Wikipedia into a large scale multilingual concept networkVivi Nastase∗, Michael StrubeHITS gGmbH, Heidelberg, Germanya r t i c l ei n f oa b s t r a c tArticle history:Available online 26 June 2012Keywords:Knowledge baseMultilingualityKnowledge acquisition1. IntroductionA knowledge base for real-world language processing applications should consist of a largebase of facts and reasoning mechanisms that combine them to induce novel and morecomplex information. This paper describes an approach to deriving such a large scale andmultilingual resource by exploiting several facets of the on-line encyclopedia Wikipedia.We show how we can build upon Wikipedia’s existing network of categories and articles toautomatically discover new relations and their instances. Working on top of this networkallows for added information to influence the network and be propagated throughout itusing inference mechanisms that connect different pieces of existing knowledge. We thenexploit this gained information to discover new relations that refine some of those foundin the previous step. The result is a network containing approximately 3.7 million conceptswith lexicalizations in numerous languages and 49+ million relation instances. Intrinsic andextrinsic evaluations show that this is a high quality resource and beneficial to various NLPtasks.© 2012 Elsevier B.V. All rights reserved.While the availability of large amounts of data has encouraged the development of successful statistical techniques fornumerous natural language processing tasks, there is a concurrent quest for computer accessible knowledge. Knowledgeallows a system to counter data sparsity (e.g. lexical semantic knowledge), as well as make connections between entities(e.g. BARACK OBAMA president_of UNITED STATES OF AMERICA).Shortly after its launch in January 2001, the potential of Wikipedia as a large scale source of knowledge for Artificial Intel-ligence and Natural Language Processing in particular became apparent to researchers in the field. The appeal of Wikipediais that it strikes a middle ground between accurate, manually created, limited-coverage resources such as WordNet [9], Cyc[18], general purpose (SUMO, [33]) or domain-specific ontologies (Gene Ontology,1 UMLS2), dictionaries and thesauri, andautomatic, wide-coverage, but still noisy knowledge mined from the web [38].Unlike resources prepared by trained linguists, Wikipedia’s structures have arisen through the collaboration of contribu-tors and, with the exception of the category structure which was encouraged by the contribution guidelines, without priorplanning. This may bring the quality of a resource based on such underspecified criteria into question, but its usefulness in avariety of Natural Language Processing (NLP) tasks has already been shown [22]. The category structure was not intended tobe an ontology-like structure, but what has emerged is a folksonomy, mirroring the shared categorization preferences of thecontributors. The collaborative aspect has also led to the implicit encoding of much information that when made explicit,reveals millions of new bite-sized pieces of knowledge.* Corresponding author.E-mail addresses: vivi.nastase@h-its.org (V. Nastase), michael.strube@h-its.org (M. Strube).1 http://www.geneontology.org.2 http://www.nlm.nih.gov/research/umls/.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.008\fV. Nastase, M. Strube / Artificial Intelligence 194 (2013) 62–8563Wikipedia contains a wealth of multi-faceted information: articles, links between articles, categories which group articles,infoboxes, a hierarchy that organizes the categories and articles into a large directed network, cross-language links, andmore. These various types of information have been usually exploited independently from each other.This paper presents WikiNet3 – the result of jointly bootstrapping several information sources in Wikipedia to produce alarge scale, multilingual and self-contained resource. The starting point is the category and article network. The most inter-esting feature of our approach is that it works completely automatically, in that it itself discovers relations in Wikipedia’scategory names for which it then finds numerous instances based on the category structure.Building WikiNet involves three main steps. First, category names are deconstructed to retrieve the categorization crite-rion, which leads to the discovery of numerous binary relation instances. In the second step the relation instances discoveredin the first step are refined based on information in the articles’ infoboxes. In the last step the network obtained up to thispoint is formalized by merging nodes that refer to the same concept, and by adding lexicalizations for these concepts fromredirect, disambiguation and cross-language links from Wikipedia versions in different languages. The resulting resource is anetwork consisting of 3 707 718 concepts and 49 931 266 relation instances (for 454 relations),4 and covers multiple dimen-sions: multilinguality, world knowledge, lexical semantics, collocations, paraphrases, named entities. Because the processingdoes not rely on manual feedback, and both the relations and their instances in the network are automatically discoveredin Wikipedia’s categories and infoboxes, the algorithm can easily be applied to the latest Wikipedia versions to generate anupdated resource.Intrinsic evaluation of the knowledge extracted shows that combining different types of information leads to the deriva-tion of accurate facts, not overtly expressed within articles or infoboxes, and as such not to be found by processing singleaspects of Wikipedia. We contrast this approach with DBpedia [1] and YAGO [45] – the largest repositories of facts extractedfrom Wikipedia to date. We perform extrinsic evaluation through two tasks – semantic relatedness computation betweenpairs of terms, and metonymy resolution, i.e. finding the correct interpretation of terms which are not used in any of theirliteral senses (e.g. White House is often used to refer to the President of the United States). The extrinsic evaluation resultsshow that the resource is of good quality – evidenced by high correlation results with manually assigned relatedness scoreson disambiguated data – but it also has high ambiguity which cannot be solved for pairs of terms out of context. ApplyingWikiNet to the task of metonymy resolution shows consistent increase in precision and recall when using world knowledgeto find the correct interpretation of potentially metonymic words, but due to the small size of the available data theseincreases are not statistically significant.2. Building WikiNetThe starting point for building WikiNet is the category and article network from one language version of Wikipedia.This network is modified step by step as more types of information from Wikipedia are taken into account. In the finalstep the nodes in the network are considered to represent concepts. Concepts and their lexicalizations are separated, andeach concept – now represented through a language independent ID – has associated numerous lexicalizations in a varietyof languages. An overview of the processing is shown in Algorithm 1, and each step is presented in more detail in theremainder of the section.Algorithm 1 Algorithm for building a large scale multilingual knowledge network.Input:W – the English Wikipedia dumpR – a set of relational nouns{W X } – a set of additional Wikipedia dumps in different languagesOutput:WikiNet – a graph with nodes as concepts, and edges as relations between them1: R 1 = DeconstructWikipediaCategories(W , R)2: R 2 = PropagateInfoboxRelations(W , R1)3: return WikiNet = BuildConceptNetwork(R2, W , {W X })The Wikipedia dump W is the file containing all English Wikipedia articles in XML format,5 and R is a set of relationalnouns extracted from an existing resource (NOMLEX,6 Meyers et al. [23]) used for detecting one of four classes of rela-tions in Wikipedia category names. The result of the category deconstruction process – R 1 – is a set of relation instances,represented as tuples (x, r, y), where x, y are strings, some of which are Wikipedia article or category names, others arefragments of category names, and r is a relation, also derived from the category names. R2, the result of infobox relation3 This article builds upon and expands [27,29]. It expands on this previous work by using a list of relational nouns extracted from NOMLEX. Itpresents a new method for computing semantic relatedness between a pair of terms, and its evaluation with standard data sets.It presents ex-periments on embedding the resource into an NLP task, in particular metonymy resolution. WikiNet can be downloaded from http://www.h-its.org/english/research/nlp/download/wikinet.php.4 The statistics reported in this paper refer to the WikiNet built starting from the English Wikipedia dump of 2011/01/15, and adding several otherlanguage versions. Details are in Section 3.1.5 Wikipedia dumps are available from http://download.wikimedia.org/. We use the pages-article.xml.bz2 file.6 http://nlp.cs.nyu.edu/meyers/nombank/nombank.1.0/NOMLEX-plus.1.0.\f64V. Nastase, M. Strube / Artificial Intelligence 194 (2013) 62–85propagation, has the same structure as R1, with the difference that some of the previously extracted relation instances areassigned new relations. WikiNet, derived from R 2 and additional information from W and {W X }, is a graph. The nodesare concepts, which are identified through a unique numeric ID and have associated multiple lexicalizations in various lan-guages. The edges are relation instances between concepts corresponding to the tuples in R 2, after mapping the argumentsonto concepts and filtering out the tuples for which at least o",
            {
                "entities": [
                    [
                        3580,
                        3608,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 304 (2022) 103650Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExact stochastic constraint optimisation with applications in network analysisAnna L.D. Latour a,∗Holger H. Hoos a,c, Siegfried Nijssen d,∗a LIACS, Leiden University, P.O. Box 9512, 2300 RA Leiden, the Netherlandsb Polytechnique Montréal, Montréal (Québec), H3T 1J4, Canadac University of British Columbia, Vancouver (British Columbia), V6T 1Z4, Canadad ICTEAM, UCLouvain, Place Sainte-Barbe 2 bte L5.02.01, B-1348 Louvain-la-Neuve, Belgium, Behrouz Babaki b, Daniël Fokkinga a, Marie Anastacio a, a r t i c l e i n f oa b s t r a c tArticle history:Received 15 August 2020Received in revised form 8 October 2021Accepted 4 December 2021Available online 10 December 2021Keywords:Constraint programmingProbabilistic inferenceStochastic constraintsOrdered binary decision diagramsMonotonic probability distributionsGlobal constraintsAutomated algorithm configurationProbabilistic networksWe present an extensive study of methods for exactly solving stochastic constraint (optimisation) problems (SCPs) in network analysis. These problems are prevalent in science, governance and industry. The first method we study is generic and decomposes stochastic constraints into a multitude of smaller local constraints that are solved using a constraint programming (CP) or mixed-integer programming (MIP) solver. However, many SCPs are formulated on probability distributions with a monotonic property, meaning that adding a positive decision to a partial solution to the problem cannot cause a decrease in solution quality. The second method is specifically designed for solving global stochastic constraints on monotonic probability distributions (SCMDs) in CP. Both methods use knowledge compilation to obtain a decision diagram encoding of the relevant probability distributions, where we focus on ordered binary decision diagrams (OBDDs). We discuss theoretical advantages and disadvantages of these methods and evaluate them experimentally. We observed that global approaches to solving SCMDs outperform decomposition approaches from CP, and perform complementarily to MIP-based decomposition approaches, while scaling much more favourably with instance size. Both methods have many alternative design choices, as both knowledge compilation and constraint solvers are used in a single pipeline. To identify which configurations work best, we apply programming by optimisation. Specifically, we show how an automated algorithm configurator can be used to find optimised configurations of our pipeline. After configuration, our global SCMD solving pipeline outperforms its closest competitor (a MIP-based decomposition pipeline) on all test sets we considered by up to two orders of magnitude in terms of PAR10 scores.© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionIn business, governance, science as well as in our daily lives, we often have to solve problems that involve optimal decision making under constraints and uncertainty. Examples of these problems arise in planning and scheduling, but they * Corresponding authors.m.i.a.anastacio@liacs.leidenuniv.nl (M. Anastacio), hh@liacs.nl (H.H. Hoos), siegfried.nijssen@uclouvain.be (S. Nijssen).E-mail addresses: a.l.d.latour@liacs.leidenuniv.nl (A.L.D. Latour), behrouz.babaki@polymtl.ca (B. Babaki), d.b.fokkinga@umail.leidenuniv.nl (D. Fokkinga), https://doi.org/10.1016/j.artint.2021.1036500004-3702/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fA.L.D. Latour, B. Babaki, D. Fokkinga et al.Artificial Intelligence 304 (2022) 103650also occur naturally in fields such as data mining and bioinformatics. Given the abundance of relational data in these areas, many problems also involve probabilistic network data.Consider, for example, the following spread of influence problem, as studied in the data mining literature [26,41]. We are given a social network of people (vertices) that have stochastic influence relationships (edges). To promote a new product, we want to rely on word-of-mouth advertisement to turn acquaintances of people who buy our product into new customers. We start this process by ‘infecting’ a set of people in the network by giving them a free sample. The budget for this marketing campaign is limited (a constraint), so we can distribute at most k samples. Each person who is a customer can influence their friends to become a customer with a certain probability. Given the social network, which k people should we give free samples in order to maximise the expected number of eventual customers (our objective)? We note that adding a person to the set of people who receive a free product sample can never decrease the expected number of people that will eventually be infected by the viral campaign.Another example is an optimisation variant of the power transmission grid reliability problem [29]. We are given a power transmission network of power lines, power producers, power consumers and transmission stations. Natural disasters, such as earthquakes and hurricanes, may cause power lines to break, and if too many such breaks occur, households lose power. We can reinforce power lines to make them less likely to break during a natural disaster, and we are given a budget bfor these upgrades (a constraint). Which power lines do we reinforce such that we maximise the expected number of households that will still have power after a natural disaster (our objective), while not exceeding our budget? Note that adding a power line to the set of lines that are reinforced can never decrease the expected number of households that still have power after a disaster.A third example is an enumeration problem, aimed at finding sets of members of a social network who are, in ex-pectation, highly influential to certain communities in their distribution of fake news. Using again a probabilistic spread-of-influence framework similar to the one described above, we combine this framework with a frequent itemset mining (FIM) [1]approach and associated constraint. Here, we repeatedly solve a constraint satisfaction problem, to find all solutions to that problem, instead of solving an optimisation problem.These problems are instances of a general class of problems, known as stochastic constraint (optimisation) problems (SCPs). SCPs have the following characteristics:• They involve decision variables and stochastic (or random) variables.• They involve reasoning over (typically) complex probability distributions.• They involve possibly complex constraints that limit the decisions we can take.The three problems described above feature a fourth characteristic:• The probabilities and expectations are higher if more nodes or edges are selected, which makes these probability dis-tributions monotonic.We call these special cases of SCPs stochastic constraint (optimisation) problems on monotonic distributions (SCPMDs). While this fourth characteristic seems limiting, problems that have this property are plentiful in network analysis; examples include the applications mentioned above, but also a signalling-regulatory pathway inference problem described in the bioinformat-ics literature [24,52] and a variant on landscape connectivity [74]. We discuss the relation of SCPs and SCPMDs to other problems in Section 10.Both SCPs and SCPMDs are difficult to solve exactly (i.e., in a way that produces provably optimal solutions). Well-known instances of SCPMDs, such as spread of influence problems, are NP-hard [41]. Calculation of a probability in probabilistic networks requires solving a counting problem that is known to be #P-complete [62]. Exact solving requires finding an optimal solution in a search space that grows exponentially with problem size.In this work we present two main approaches for solving SCPs exactly. The first is based on decomposing hard constraints on probability distributions into a multitude of local constraints, and is applicable to SCPs in general. The second is designed for solving SCPMDs (and can only be applied to those), exploiting structures that result from monotonicity to obtain a global constraint propagation algorithm for solving those stochastic constraints. We discuss SCPs, SCPMDs and how to solve them in Section 2.The main algorithmic contributions in this work are as follows1:1. We present new versions of a constraint decomposition method for solving SCPs [43], based on ordered binary decision diagram (OBDD) [14] representations of probability distributions (Section 4).1 We presented an earlier version of this work in a conference paper [44]. This article extends this earlier publication with a more elaborate description of the propagation algorithm from [44], new proofs and additional contributions 4–6. Preliminary versions of contributions 4 and 5 were presented in a workshop paper [31]. Here, we have extended that work by including earlier approaches from Latour et al. [43] to the configuration experiments and by significantly extending the design space of our methods.2\fA.L.D. Latour, B. Babaki, D. Fokkinga et al.Artificial Intelligence 304 (2022) 1036502. We show that this decomposition approach is not generalised arc consistent (GAC), thus causing it to prune the search space insufficiently, and that a straightforward arc consistent modification of this approach does not significantly im-prove performance (Section 4.2).3. To address this inefficiency in the search, we introduce a global constraint on OBDD representations of monotonic distributions, which we call the stochastic constraint on monotonic distributions (SCMD), and introduce a GAC-by-design propagation algorithm for this constraint (Section 5).In summary, the benefits of the decomposition methods are:• They are",
            {
                "entities": [
                    [
                        3565,
                        3593,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 130–150Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEvaluating Entity Linking with WikipediaBen Hachey a,∗, Will Radford b,c, Joel Nothman b,c, Matthew Honnibal d, James R. Curran b,ca Research & Development, Thomson Reuters Corporation, St. Paul, MN 55123, USAb School of Information Technologies, University of Sydney, NSW 2006, Australiac Capital Markets CRC, 55 Harrington Street, NSW 2000, Australiad Department of Computing, Macquarie University, NSW 2109, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 23 April 2012Keywords:Named Entity LinkingDisambiguationInformation extractionWikipediaSemi-structured resources1. IntroductionNamed Entity Linking (nel) grounds entity mentions to their corresponding node in aKnowledge Base (kb). Recently, a number of systems have been proposed for linkingentity mentions in text to Wikipedia pages. Such systems typically search for candidateentities and then disambiguate them, returning either the best candidate or nil. However,comparison has focused on disambiguation accuracy, making it difficult to determine howsearch impacts performance. Furthermore, important approaches from the literature havenot been systematically compared on standard data sets.We reimplement three seminal nel systems and present a detailed evaluation of searchstrategies. Our experiments find that coreference and acronym handling lead to substantialimprovement, and search strategies account for much of the variation between systems.This is an interesting finding, because these aspects of the problem have often beenneglected in the literature, which has focused largely on complex candidate rankingalgorithms.© 2012 Elsevier B.V. All rights reserved.References to entities such as people, places and organisations are difficult to track in text, because entities can bereferred to by many mention strings, and the same mention string may be used to refer to multiple entities. For instance,David Murray might refer to either the jazz saxophonist or the Iron Maiden guitarist, who may be known by other aliasessuch as Mad Murray. These synonymy and ambiguity problems make it difficult for language processing systems to collectand exploit information about entities across documents without first linking the mentions to a knowledge base.Named Entity Linking (nel) is the task of resolving named entity mentions to entries in a structured Knowledge Base(kb). nel is useful wherever it is necessary to compute with direct reference to people, places and organisations, rather thanpotentially ambiguous or redundant character strings. In the finance domain, nel can be used to link textual informationabout companies to financial data, for example, news and share prices [34]. nel can also be used in search, where resultsfor named entity queries could include facts about an entity in addition to pages that talk about it [8].nel is similar to the widely-studied problem of word sense disambiguation (wsd, [36]), with Wikipedia articles playingthe role of WordNet synsets [20]. At core, both tasks address problems of synonymy and ambiguity in natural language.The tasks differ in terms of candidate search and nil detection. Search for wsd assumes that WordNet is a complete lexicalresource and consists of a lexical lookup to find the possible synsets for a given word. The same approach is taken inwikification, where arbitrary phrases including names and general terms are matched to Wikipedia pages [32,33,27,15].* Corresponding author.E-mail address: ben.hachey@gmail.com (B. Hachey).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.005\fB. Hachey et al. / Artificial Intelligence 194 (2013) 130–150131However, this does not provide a mechanism for dealing with objects that are not present in the database. nel, on theother hand, does not assume the kb is complete, requiring entity mentions without kb entries to be marked as nil [8,31].Furthermore, named entity mentions vary more than lexical mentions in wsd. Therefore, search for nel requires a noisiercandidate generation process, often using fuzzy matching to improve recall [48,28].Until recently, wide-coverage nel was not possible since there was no general purpose, publicly available collectionof information about entities. However, Wikipedia has emerged as an important repository of semi-structured, collectiveknowledge about notable entities. Accordingly, it has been widely used for knowledge modelling [46,6,37,42]. It has beenused for nlp tasks like automatic summarisation [45,50]. And it has also been exploited for a number of information extrac-tion tasks ranging from ner learnt from Wikipedia link structure [40] to relation extraction learnt from the nearly structuredinformation encoded in Wikipedia Infoboxes [51].The most popular data sets for nel were distributed as part of the recent Knowledge Base Population tasks at the nistText Analysis Conference (tac). The thirteen participants in the 2009 task developed systems that linked a set of 3904 entitymentions in news and web text to a knowledge base extracted from Wikipedia infoboxes. The highest accuracy achievedwas 82.2% [48] with subsequent publications reporting results as high as 86% [21].The popularity of the tac shared tasks has led to a wide range of innovative entity linking systems in the literature.However, since all participants were individually striving for the highest accuracy they could achieve, the systems all differalong multiple dimensions, so it is currently unclear which aspects of the systems are necessary for good performance andwhich aspects might be improved.In this paper, we reimplement three prominent entity linking systems from the literature to obtain a better understand-ing of the named entity linking task. Our primary question concerns the relative importance of search and disambiguation:an nel system must first search for a set of candidate entities that the mention string might refer to, before selecting a sin-gle candidate given the document. These phases have not been evaluated in isolation, and the systems from the literaturetend to differ along both dimensions.We find that the search phase is far more important than previously acknowledged. System descriptions have usuallyfocused on complicated ranking methods. However, search accounts for most of the variation between systems. Furthermore,relatively unremarked search features such as query expansion based on coreference resolution and acronym detection seemto have a much larger impact on system performance than candidate ranking.2. Review of named entity disambiguation tasks and data setsSeveral research communities have addressed the named entity ambiguity problem. It has been framed in two differentways. Within computational linguistics, the problem was first conceptualised by Bagga and Baldwin [4] as an extension ofthe coreference resolution problem. Mihalcea and Csomai [32] later used Wikipedia as a word sense disambiguation dataset by attempting to reproduce the links between pages, as link text is often ambiguous. Finally, Bunescu and Pa ¸sca [8] usedWikipedia in a similar way, but include ner as a preprocessing step and require a link or (nil) for all identified mentions. Wewill follow the terminology of these papers, and refer to the three tasks respectively as cross-document coreference resolution(cdcr), wikification, and named entity linking (nel). We use the more general term named entity disambiguation when wemust avoid referring specifically to any single task.The cdcr, wikification, and nel tasks make different assumptions about the problem, and these lead to different evalu-ation measures and slightly different techniques. The cdcr task assumes that the documents are provided as a batch, andmust be clustered according to which entities they mention. Systems are evaluated using clustering evaluation measures,such as the B3 measure [3]. The wikification task assumes the existence of a knowledge base that has high coverage overthe entities of interest, and that entities not covered by the knowledge base are relatively unimportant. And nel requiresa knowledge base but does not assume that it is complete. Systems are usually evaluated on micro-accuracy (percentageof mentions linked correctly) and macro-accuracy (percentage of entities linked correctly). In this section, we review themain data sets that have been used in cdcr and nel research. Although we make some reference to approaches used, werereserve the main description of named entity disambiguation techniques for Section 3.2.1. Early cross-document coreference datasetsThe seminal work on cross-document coreference resolution (cdcr) was performed by Bagga and Baldwin [4]. Theyperformed experiments on a set of 197 documents from the New York Times whose text matched the expressionJohn.*?Smith—where .*? is a non-greedy wildcard match up to the first instance of Smith, e.g., only John DonnelSmith would be matched in John Donnell Smith bequeathed his herbarium to the Smithsonian. The documents were manuallygrouped according to which John Smith entities they mentioned. None of the articles mentioned multiple John Smiths, sothe only annotations were at the document level.The John Smith dataset approaches the problem as one name, many people: there are many entities that are referred toby an ambiguous name such as John Smith. However, there is another side to the problem: one person, many names. Anentity known as John Smith might also be known as Jack Smith, Mr. Smith, etc. In other words, there are both synonymy andambiguity issues for named entities.\f132B. Hachey et al. / Artificial Intelligence 194 (2013) 130–150Most cdcr datasets are similarly collected by searching for a set of canonical names, ignoring non-canonical coreferentforms. For instance, Mann and Yarowsky [29] collected a data set of",
            {
                "entities": [
                    [
                        3735,
                        3763,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 320 (2023) 103919Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintReasoning about causality in gamesLewis Hammond a,∗Alessandro Abate a, Michael Wooldridge aa University of Oxford, United Kingdomb DeepMind, United Kingdom, James Fox a,∗, Tom Everitt b, Ryan Carey a, a r t i c l e i n f oa b s t r a c tArticle history:Received 17 March 2022Received in revised form 1 April 2023Accepted 2 April 2023Available online 5 April 2023Keywords:CausalityGame theoryGraphical modelsContentsCausal reasoning and game-theoretic reasoning are fundamental topics in artificial intel-ligence, among many other disciplines: this paper is concerned with their intersection. Despite their importance, a formal framework that supports both these forms of reasoning has, until now, been lacking. We offer a solution in the form of (structural) causal games, which can be seen as extending Pearl’s causal hierarchy to the game-theoretic domain, or as extending Koller and Milch’s multi-agent influence diagrams to the causal domain. We then consider three key questions:i) How can the (causal) dependencies in games – either between variables, or between strategies – be modelled in a uniform, principled manner?ii) How may causal queries be computed in causal games, and what assumptions does this require?iii) How do causal games compare to existing formalisms?To address question i), we introduce mechanised games, which encode dependencies be-tween agents’ decision rules and the distributions governing the game. In response to question ii), we present definitions of predictions, interventions, and counterfactuals, and discuss the assumptions required for each. Regarding question iii), we describe correspon-dences between causal games and other formalisms, and explain how causal games can be used to answer queries that other causal or game-theoretic models do not support. Finally, we highlight possible applications of causal games, aided by an extensive open-source Python library.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1.2.Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.1.Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.2.Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Causal models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.1.Game-theoretic models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.2.3345573. Mechanised MAIDs and relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10* Corresponding authors.E-mail addresses: lewis.hammond@cs.ox.ac.uk (L. Hammond), james.fox@cs.ox.ac.uk (J. Fox).https://doi.org/10.1016/j.artint.2023.1039190004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fL. Hammond, J. Fox, T. Everitt et al.Artificial Intelligence 320 (2023) 1039197.6.4.5.3.1. Mechanised MAIDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103.2.Relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13Causality in games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154.1.Interventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164.2.4.3.Counterfactuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17Solution concepts and subgames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21Nash equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215.1.Subgames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225.2.Equilibrium refinements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235.3.Connections to EFGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256.1.Equivalences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266.2.Causality in EFGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276.3.Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28Case study: insurance pricing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287.1.Blame, intent, incentives, and fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307.2.Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31Advantages and disadvantages of causal games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318.1.Future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328.2.Declaration of competing interest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32Data availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Appendix A.Transformations between game representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Theoretical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34Further examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42Counterfactuals using the closest possible world principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42Non-existence results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43Reasoning about existing concepts using causal games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46Codebase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48Creating MAIDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48Computing equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51B.1.B.2.B.3.Appendix B.Appendix C.A.1.A.2.C.1.C.2.8.NotationSymbolObjectAncVcRGChVDescVdodom(V )EVEEFaVGIJMM(ζk)MVmGmMNPaVPr or PPrπ or P σQRR(mM)r DAncestors of VCondensed R-Relevance GraphChildren of VDescendants of VDo OperatorDomain of VExogenous Variable for VEdgesExtensive-Form GameFamily of VGraphInterventionIntervention SetModelPerturbed ModelMec",
            {
                "entities": [
                    [
                        3552,
                        3580,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 164 (2005) 81–119www.elsevier.com/locate/artintOn the logic of cooperation and propositional controlWiebe van der Hoek ∗, Michael WooldridgeDepartment of Computer Science, University of Liverpool, Liverpool L69 7ZF, United KingdomReceived 24 August 2004Available online 5 February 2005AbstractCooperation logics have recently begun to attract attention within the multi-agent systems com-munity. Using a cooperation logic, it is possible to represent and reason about the strategic powersof agents and coalitions of agents in game-like multi-agent systems. These powers are generallyassumed to be implicitly defined within the structure of the environment, and their origin is rarelydiscussed. In this paper, we study a cooperation logic in which agents are each assumed to control aset of propositional variables—the powers of agents and coalitions then derive from the allocation ofpropositions to agents. The basic modal constructs in this Coalition Logic of Propositional Control(CL-PC) allow us to express the fact that a group of agents can cooperate to bring about a certainstate of affairs. After motivating and introducing CL-PC, we provide a complete axiom system for thelogic, investigate the issue of characterising control in CL-PC with respect to the underlying powerstructures of the logic, and formally investigate the relationship between CL-PC and Pauly’s Coali-tion Logic. We then show that the model checking and satisfiability problems for CL-PC are bothPSPACE-complete, and conclude by discussing our results and how CL-PC sits in relation to otherlogics of cooperation. 2005 Elsevier B.V. All rights reserved.Keywords: Multi-agent systems; Cooperation logic; Logics for control* Corresponding author.E-mail address: wiebe@csc.liv.ac.uk (W. van der Hoek).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.003\f82W. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–1191. IntroductionCooperation logics are logics that are intended to enable reasoning about coalitionsin multi-agent systems, and in particular, the powers that such coalitions have. Probablythe two best known examples of cooperation logics are Pauly’s Coalition Logic [36–38],and the Alternating-time Temporal Logic (ATL) of Alur, Henzinger, and Kupferman [5].Both of these systems are based upon the notion of a cooperation modality: a unary modaloperator, indexed by a set of agents, which is used to represent the fact that this set of agentscan cooperate so as to make true the state of affairs given as an argument to the operator.In Coalition Logic, for example, a formula [1, 2](p ∧ q) is used to express the fact that thecoalition {1, 2} can cooperate in such a way as to make the formula p ∧ q true. Althoughthey differ on technical details, the semantics of both logics are essentially equivalent [19]:coalition C are able to achieve ϕ if there exists a collective strategy for C such that, byfollowing this strategy, C can enforce ϕ (that is, ϕ is true in every outcome that couldarise by following the strategy). In both logics, the strategies available to a coalition, andthe outcomes consistent with these strategies, are implicitly enumerated within the logic’smodels: in the case of Coalition Logic, by means of effectivity functions (cf. [1]), and inthe case of ATL, by means of a system transition function.In this paper, we study a variant of cooperation logic that we refer to as the CoalitionLogic of Propositional Control (CL-PC). The key idea in CL-PC is that each agent is as-sumed to control a set of propositional variables. The strategies, or choices available toan agent then correspond to the different possible assignments of truth or falsity to thesepropositions. On top of that, the ability of a coalition to bring about some state of affairsderives from the propositional variables that are under the overall control of the coalition.There are at least two reasons why CL-PC is a system worthy of study in its own right:• First, and perhaps most importantly, if we are interested in building software agents,then it is extremely natural to think of the ability of these agents in terms of settingand unsetting bits in some digital control system. Indeed, this is arguably the mostfundamental kind of control that can be imagined.• Second, in implemented systems for reasoning about cooperation in game-like multi-agent scenarios, the individual powers of agents are actually specified by allocatingagents propositions that lie under their control. For example, this is exactly the ap-proach taken in the MOCHA model checking system for ATL, where the keywordcontrols is used to indicate the fact that an agent (or “module”, in the terminol-ogy of MOCHA) is uniquely able to determine the value of a propositional variable[3,6].Against this background, the present paper makes four main contributions to the study ofcooperation logics.First, although we have taken inspiration and some methodology from ATL and Coali-tion Logic, we note that the basic cooperation modalities of these logics have a ratherunusual modal flavour, which is neither wholly universal nor wholly existential. This isbecause these logics are intended to capture ∃∀-ability, or α-ability [1, pp. 11–12], the ideabeing that a coalition C have the α-ability to achieve some state of affairs ϕ if C have\fW. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–11983a collective choice such that, no matter what the agents outside C do, ϕ will hold as aconsequence of this choice. This type of ability is entirely natural when we wish to studythe circumstances under which a coalition can “reliably” bring about some state of affairs.However, the ∃∀ nature of cooperation modalities in these logics, and the fact that they areneither conventionally existential nor conventionally universal, means that (i) they are hardfor “logic users” to understand, as they have some counterintuitive properties (particularlyin their dual forms); and (ii) from a technical standpoint, the fact that they are a combina-tion of existential and universal modality makes them somewhat awkward to work with,at least compared with conventional “box” and “diamond” modalities. In CL-PC, however,the basic cooperation modalities capture contingent ability—a weaker notion of abilitythan the α-ability of Coalition Logic and ATL. Contingent ability is the ability to achievesome state of affairs under the assumption that, apart from our actions, the world remainsstatic. This is the type of ability that is implemented in classic AI planning systems such asSTRIPS [17,28]. Although contingent ability is perhaps not of great interest in its own right,it turns out that the contingent ability constructs of CL-PC are sufficient to define α-ability(as well as a related type of ability known as β-ability). Thus, although we appear to startwith a weaker notion of ability than those of Coalition Logic and ATL, it turns out that thisis in fact all we need to define these stronger types of ability. Moreover, the contingentability operators of CL-PC have the advantage of being “true modal diamonds”: they thushave a much simpler semantics than α-ability operators, and are easier to work with from atechnical point of view (for example, when using such conventional modal logic constructssuch as canonical models to prove completeness [11, pp. 59–61]).Second, although our basic cooperation modalities are conventional modal diamonds,and hence we can give them a more-or-less conventional Kripke semantics [9, p. 42], weare also able to give an alternative semantics to CL-PC, which is directly based on thepower structures that underpin the logic. We show that the two semantics are, in a precisesense, equivalent, and that we can thus move between the two semantics as we see fit. Theadvantage of this is that we can work with whichever semantics seems most appropriate tothe task at hand.Third, although complete axiomatizations are known for both ATL [19] and CoalitionLogic [36–38], we are able to provide an axiomatization for CL-PC that draws upon thesimple underlying power structures of the logic. As a consequence, our axiomatization ofCL-PC has a rather different flavour to those of Coalition Logic and ATL.Fourth, and finally, we present an analysis of control in CL-PC: when a coalition controlssome state of affairs. In particular, we show how the control that a coalition is able to exertwith respect to some state of affairs is related to the power structure underlying the logic.The remainder of this paper is structured as follows. Following a formal definition ofCL-PC, in Section 3 we present a complete axiomatization for the logic. In Section 4.1,we show how α- and β-ability modalities can be defined in terms of the basic constructsof CL-PC, and in Section 4.2, we investigate the characterisation of control in CL-PC, withparticular reference to the underlying power structures. In Section 5, we investigate thecomputational complexity of the model checking and satisfiability problems for the logic,and show that both problems are PSPACE-complete. We conclude with a discussion on theimplications of our results, and how the logic stands in relation to other similar systems.\f84W. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–1192. The coalition logic of propositional controlIn this section, we give a formal definition of CL-PC. We begin with an informal in-troduction to the main features of the logic (readers familiar with Coalition Logic or ATLmay wish to skip or skim through this section). We then formally define the syntax ofCL-PC, and give two alternative semantics. The first is a “direct” or “propositional” seman-tics, which has the advantages of being both simple and closely related to the intuitionsunderpinning the language, but has the disadvantage of being rather unconventional in themodal logic sense, and hence rather hard to work with from the point o",
            {
                "entities": [
                    [
                        1878,
                        1906,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 39–55Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTransfer learning in heterogeneous collaborative filteringdomainsWeike Pan, Qiang Yang∗Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clearwater Bay, Kowloon, Hong Konga r t i c l ei n f oa b s t r a c tArticle history:Received 6 December 2010Received in revised form 6 December 2012Accepted 12 January 2013Available online 11 February 2013Keywords:Transfer learningCollaborative filteringMissing ratingsA major challenge for collaborative filtering (CF) techniques in recommender systems isthe data sparsity that is caused by missing and noisy ratings. This problem is even moreserious for CF domains where the ratings are expressed numerically, e.g. as 5-star grades.We assume the 5-star ratings are unordered bins instead of ordinal relative preferences. Weobserve that, while we may lack the information in numerical ratings, we sometimes haveadditional auxiliary data in the form of binary ratings. This is especially true given thatusers can easily express themselves with their preferences expressed as likes or dislikesfor items. In this paper, we explore how to use these binary auxiliary preference data tohelp reduce the impact of data sparsity for CF domains expressed in numerical ratings. Wesolve this problem by transferring the rating knowledge from some auxiliary data sourcein binary form (that is, likes or dislikes), to a target numerical rating matrix.In particular, our solution is to model both the numerical ratings and ratings expressed aslike or dislike in a principled way. We present a novel framework of Transfer by CollectiveFactorization (TCF), in which we construct a shared latent space collectively and learn thedata-dependent effect separately. A major advantage of the TCF approach over the previousbilinear method of collective matrix factorization is that we are able to capture the data-dependent effect when sharing the data-independent knowledge. This allows us to increasethe overall quality of knowledge transfer. We present extensive experimental results todemonstrate the effectiveness of TCF at various sparsity levels, and show improvements ofour approach as compared to several state-of-the-art methods.© 2013 Elsevier B.V. All rights reserved.1. IntroductionData sparsity is a major challenge in collaborative filtering [23,9,43]. Sparsity refers to the fact that some observedratings, e.g. 5-star grades, in a user-item rating matrix are too few, such that overfitting can easily happen when we use aprediction model for missing values in the test data. However, we observe that, some auxiliary data of the form “like” or“dislike” may be more easily obtained, such as the favored/disfavored data in Moviepilot1 and Qiyi,2 the dig/bury data inTudou,3 the love/ban data in Last.fm,4 and the “Want to see”/“Not interested” data in Flixster.5 It is often more convenientfor users to express such preferences instead of numerical ratings. The question we ask in this paper is: how do we take* Corresponding author.E-mail addresses: weikep@cse.ust.hk (W. Pan), qyang@cse.ust.hk (Q. Yang).1 http://www.moviepilot.de.2 http://www.qiyi.com.3 http://www.tudou.com.4 http://www.last.fm.5 http://www.flixster.com.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.01.003\f40W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Table 1Matrix illustration of some related work on transfer learning in collaborative filtering. Note that SoRec, CMF, CBT and RMGM can beapplied in more general problem settings, e.g. more than two matrices, more than one types of alignments, etc.MethodsTraining dataAuxiliary dataSoRec (user side) [39]CMF (item side) [52]CBT (not aligned) [31]RMGM (not aligned) [32]R ∼ UVTKnowledge sharing: U = U1Value domain: (U, V), (U1, V1) ∈ DRDR = {(U, V) | U ∈ Rn×d, V ∈ Rm×d}R ∼ UVTKnowledge sharing: V = V2Value domain: (U, V), (U2, V2) ∈ DRDR = {(U, V) | U ∈ Rn×d, V ∈ Rm×d}R1 ∼ U1VT1R2 ∼ U2VT2R ∼ UBVTKnowledge sharing: B = B3Value domain: (U, V), (U3, V3) ∈ D{0,1}D{0,1} = {(U, V) | U ∈ {0, 1}n×d, U1 = 1, V ∈ {0, 1}m×d, V1 = 1}R3 ∼ U3B3VT3R ∼ UBVTKnowledge sharing: B = B3Value domain: (U, V), (U3, V3) ∈ D[0,1]D[0,1] = {(U, V) | U ∈ [0, 1]n×d, U1 = 1, V ∈ [0, 1]m×d, V1 = 1}R3 ∼ U3B3VT3advantage of auxiliary knowledge in the form of binary ratings to alleviate the sparsity problem in numerical ratings whenwe build a rating-prediction model?To the best of our knowledge, no previous work answered the question of how to jointly model a target data of numericalratings and an auxiliary data of binary ratings. There are some prior works on using both the numerical ratings and implicitdata of “whether rated” [28,35] or “whether purchased” [57] to help boost the prediction performance. Among the previousworks, Koren [28] uses implicit data of “rated” as offsets in a factorization model, and Liu et al. [35] adapt the collectivematrix factorization (CMF) approach [52] to integrate the implicit data of “rated.” Zhang and Nie [57] convert the implicitdata of simulated purchases to a user-brand matrix as a user-side meta data representing brand loyalty and a user-itemmatrix of “purchased.” However, none of these previous works consider how to use auxiliary data in the form of like anddislike type of binary ratings in collaborative filtering in a transfer learning framework.Most existing transfer learning methods in collaborative filtering consider auxiliary data from several perspectives, includ-ing user-side transfer [39,11,58,38,55], item-side transfer [52], or knowledge-transfer using related but not aligned data [31,32]. We illustrate the ideas of knowledge sharing from a matrix factorization view as shown in Table 1. We show fourrepresentative methods [39,52,31,32] in Table 1 and describe the details starting from a non-transfer learning method ofprobabilistic matrix factorization (PMF) [47].Probabilistic matrix factorization The PMF [47] or latent factorization model (LFM) [4] seeks an appropriate low-ranki· , where U ∈ Rn×d, V ∈ Rm×d areapproximation, R = UVT , for which any missing value can be predicted by ˆrui = U u· V Tuser-specific and item-specific latent feature matrices, respectively. The optimization problem of PMF is as follows [47,4],EI(U, V) + αR(U, V)minU,V(1)\fW. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55where EI(U, V) = 1(cid:2)2(cid:2)(cid:2)nu=1mi=1 yui(rui − U u· V Ti· )2 = 12(cid:5)Y (cid:6) (R − UVT )(cid:5)2F is the loss function, and R(U, V) = 12 ((cid:2)nu=1mi=1(cid:5)V i·(cid:5)2) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F ) is a regularization term used to avoid overfitting.41(cid:5)U u·(cid:5)2 +Social recommendation SoRec [39] is proposed to alternatively factorize the target rating matrix R and a user-side socialnetwork matrix R1 with the constraint of sharing the same user-specific latent feature matrix (see U = U1 in Table 1). Theobjective function is formalized as follows [39],EI(U, V) + EI(U, V1) + αR(U, V, V1)minU,V1,U(2)where (U, V) ∈ DR, and R(U, V, V1) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F+ (cid:5)V1(cid:5)2F ) is a regularization term on the latent variables.Collective matrix factorization CMF [52] is proposed to alternatively factorize the target rating matrix R and an item-sidecontent matrix R2 with the constraint of sharing the same item-specific latent feature matrix (see V = V2 in Table 1). Thisapproach is similar to that in SoRec [39], but with different auxiliary data. The optimization problem of CMF is stated asfollows [52],EI(U, V) + EI(U2, V) + αR(U, V, U2)minU,V,U2(3)where (U, V) ∈ DR, and R(U, V, U2) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F+ (cid:5)U2(cid:5)2F ) is again a regularization term used to avoid overfitting.Codebook transfer The CBT [31] method consists of codebook construction and expansion steps. It achieves knowledgetransfer with the assumption that both auxiliary and target data share a common cluster-level rating pattern (see B = B3 inTable 1).1. Codebook construction. Assume that (U3, V3) ∈ D{0,1} are user-specific and item-specific membership indicator matricesof the auxiliary rating matrix R3, which are obtained using co-clustering algorithms such as NMF [19]. The constructed3 R3V3]k(cid:3) denotes the summation of ratingscodebook is represented as B3 = [UTby users in a user cluster k on items in an item cluster (cid:3). [UT3 (R3 > 0)V3]k(cid:3) denotes the number of ratings from users ina user cluster k on items in an item cluster (cid:3), hence, the element-wise division (cid:7) resembles the idea of normalization,and [B3]k(cid:3) is the average rating of users in a user cluster k on items in an item cluster (cid:3).3 (R3 > 0)V3] [31], where [UT3 R3V3] (cid:7) [UT2. Codebook expansion. The codebook expansion problem is formalized as follows [31],EB(U, V)s.t.(U, V) ∈ D{0,1}minU,V(4)(cid:5)Y (cid:6) (R − UBVT )(cid:5)2where EB(U, V) = 1F is a B-regularized square loss function, and B = B3 is the codebook constructed2from the auxiliary data R3. In [31], an alternating greedy-search algorithm is proposed to solve the combinatorialoptimization problem in Eq. (4), and the choices of U uk = 1, V i(cid:3) = 1 are used to select the entry located at (k, (cid:3)) ofi· . Thus, the predicted rating ˆrui = [UBVT ]ui = [B]k(cid:3) is the average rating of users in the userB via [UBVT ]ui = U u·BV Tcluster k on items in an item cluster (cid:3) of the auxiliary data.Rating-matrix generative model RMGM [32] is derived and extended from the FMM generative model [50], and we re-write it in a matrix factorization manner,minU,V,B,U3,V3EB(U, V) + EB(U3, V3)s.t.(U, V), (U3, V3) ∈ D[0,1](5)where EB(U, V) is again a B-regularized loss function, the same as given in Eq. (4). We can see that RMGM is differentfrom CBT since it learns (U, V) and (U3, V3) alternatively and relaxes the hard membership requirement as ",
            {
                "entities": [
                    [
                        3433,
                        3461,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 187–231www.elsevier.com/locate/artintConstraint partitioning in penalty formulationsfor solving temporal planning problems ✩Benjamin W. Wah a,∗, Yixin Chen ba Department of Electrical and Computer Engineering and the Coordinated Science Laboratory,University of Illinois, Urbana-Champaign, Urbana, IL 61801, USAb Department of Computer Science, Washington University, St. Louis, MO 63130, USAReceived 25 August 2003; accepted 7 July 2005Available online 24 August 2005AbstractIn this paper, we study the partitioning of constraints in temporal planning problems formulatedas mixed-integer nonlinear programming (MINLP) problems. Constraint partitioning is attractivebecause it leads to much easier subproblems, where each is a significant relaxation of the originalproblem. Moreover, each subproblem is very similar to the original problem and can be solved byany existing solver with little or no modification. Constraint partitioning, however, introduces globalconstraints that may be violated when subproblems are evaluated independently. To reduce the over-head in resolving such global constraints, we develop in this paper new conditions and algorithmsfor limiting the search space to be backtracked in each subproblem. Using a penalty formulation ofa MINLP where the constraint functions of the MINLP are transformed into non-negative functions,we present a necessary and sufficient extended saddle-point condition (ESPC) for constrained lo-cal minimization. When the penalties are larger than some thresholds, our theory shows a one-to-onecorrespondence between a constrained local minimum of the MINLP and an extended saddle point ofthe penalty function. Hence, one way to find a constrained local minimum is to increase gradually thepenalties of those violated constraints and to look for a local minimum of the penalty function usingany existing algorithm until a solution to the constrained model is found. Next, we extend the ESPCto constraint-partitioned MINLPs and propose a partition-and-resolve strategy for resolving violated✩ Research supported by National Science Foundation Grant IIS 03-12084 and National Aeronautics and SpaceAdministration Grant NCC 2-1230.* Corresponding author.E-mail address: wah@uiuc.edu (B.W. Wah).URL: http://manip.crhc.uiuc.edu.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.07.001\f188B.W. Wah, Y. Chen / Artificial Intelligence 170 (2006) 187–231global constraints across subproblems. Using the discrete-space ASPEN and the mixed-space MIPSplanners to solve subproblems, we show significant improvements on some planning benchmarks,both in terms of the quality of the plans generated and the execution times to find them. 2005 Elsevier B.V. All rights reserved.Keywords: Constraint partitioning; Extended saddle-point condition; Penalty function; Local search; Mixedspace planning; Nonlinear constraints; Temporal planning1. IntroductionA temporal planning problem involves arranging actions and assigning resources inorder to accomplish given tasks and objectives over a period of time. It can be defined bya state space with discrete, continuous, or mixed variables; a discrete or continuous timehorizon; a set of actions defining valid state transitions; a set of effects associated with eachaction; a set of constraints to be satisfied in each state or throughout an action; and a set ofgoals to be achieved.In this paper, we formulate a planning problem as a mixed-integer nonlinear program-ming (MINLP) problem. Such a formulation allows us to develop a formal mathematicalfoundation when partitioning a large planning problem by its constraints into subproblems(stages). The MINLP formulation of the problem when partitioned into N + 1 subproblemsis as follows:J (z)(cid:2)(cid:1)z(t)(Pt ): minzsubject to h(t)and H (z) = 0, G(z) (cid:1) 0 (global constraints).(cid:2)(cid:1)z(t)= 0, g(t)(cid:1) 0, t = 0, . . . , N (local constraints),(1)1 , . . . , h(t)1 , . . . , g(t)Here, Stage t, t = 0, . . . , N , has local state vector z(t) = (z1(t), . . . , zut (t))T of ut mixedvariables; h(t) = (h(t)mt )T is a vector of mt local equality-constraint functions thatinvolve z(t); g(t) = (g(t)rt )T is a vector of rt local inequality-constraint functionsof z(t); H = (H1, . . . , Hp)T is a vector of p global equality-constraint functions that in-(cid:3)Nvolve z =i=0 z(i); and G = (G1, . . . , Gq )T is a vector of q global inequality-constraintfunctions of z. Note that z(t) includes all variables that appear in one or more of the lo-cal constraints in Stage t, and that z(0), . . . , z(N ) may overlap with each other since thepartitioning is by constraints.We assume that J is continuous and differentiable with respect to its continuous vari-ables and is lower bounded. Further, g and h can be unbounded, discontinuous, non-differentiable, and not in closed form. These assumptions are reasonable for AI planningproblems, whose constraint functions may be discontinuous and not in closed form andwhose objective functions are continuous and differentiable in the continuous subspace.A solution to Pt is a plan that involves an assignment of z and that satisfies all the con-straints.To illustrate the constrained formulation of a planning problem, consider the toy prob-lem in Fig. 1 solved by ASPEN [9]. The problem involves scheduling four activities: act_1\fB.W. Wah, Y. Chen / Artificial Intelligence 170 (2006) 187–231189Fig. 1. A toy example from ASPEN [9] whose goal is to find a valid schedule that completes 4 activities, act_1and act_2 that are instances of type A1 and act_3 and act_4 that are instances of type A2, while minimizingthe total power_resource used. Based on the initial infeasible schedule, the 19 constraints are partitioned into3 stages, {E1, E5, E9, E11}, {E2, E3, E6, E7, E10, E12, E13, E15}, and {E4, E8, E14}, and 4 global constraints{E16, E17, E18, E19}. A local constraint remains associated with a stage even when activities are rescheduled.The number of iterations to solve the problem is reduced from 16 taken by ASPEN to 12 after partitioning.and act_2 of type A1 and act_3 and act_4 of type A2, over a discrete horizon of 60 seconds.Its goal is to satisfy the nineteen constraints, E1 through E19, on positive and negative factsand preconditions and effects of actions, while minimizing the total power_resource used.Among the 19 constraints in the initial schedule in Fig. 1, E1, E2, E3, E4, E6, and E15 arenot satisfied.In a MINLP formulation of the toy example, each of the nineteen constraints in Fig. 1 istransformed into one or more equivalent constraints. We use two variables s(a) and e(a) todenote, respectively, the starting and ending times of activity a. For each state, we assign avector of state variables to denote their values indexed by time. For example, we use c(t)to denote the color_state at time t, which can be set to 0 (red), 1 (blue), or 2 (green)(c(t) = 2 means that the color_state at time t is green); p(t) to denote the power_supplyat t; and w(t) to denote the power_usage at t. The following illustrates a small portion ofthe resulting constraints encoded:(c1) w(t) (cid:1) p(t) (cid:1) 25, ∀t = 0, . . . , 60; // power_resource capacity constraint(c2) 0 (cid:1) s(act_3) − e(act_1) (cid:1) 30; // act_1 ends_before start of act_3 by [0, 30](c3) s(act_1) = t (cid:3)⇒ c(t) = 2; ∀t = 0, . . . , 60; // color_state constraint for act_1(c4) s(cc_b) = t (cid:3)⇒ c(t) = 1; ∀t = 0, . . . , 60; // color_changer cc_b effect constraintThe constraints are either equality or inequality constraints (such as (c1) and (c2)), ordeduction constraints (such as (c3) and (c4)). A deduction constraint A ⇒ B, where A and\f190B.W. Wah, Y. Chen / Artificial Intelligence 170 (2006) 187–231Fig. 2. An illustration of constraint partitioning that decomposes P into a conjunction (∧) of three subproblemsand a set of global constraints to be resolved, where the complexity of each subproblem is substantially smallerthan that of P . The set of global constraints G includes constraints in P that span across variables in multi-ple subproblems and new constraints added to maintain the consistency of shared entities and variables acrosssubproblems.B are equality or inequality constraints, can be encoded as an equivalent equality constraintH (A ⇒ B) = 0:(cid:4)H (A ⇒ B) =0numerical violation of B if A is true but B is false.if A is false, or A and B are both trueFor example, the equivalent equality constraint encoding (c3) returns 0 if s(act_1) = t isfalse; otherwise, it returns the value of (c(t) − 2).A general approach for solving a large constrained optimization problem is to se-lect iteratively a set of its variables to which values can be assigned according to thestructural characteristics of the domain, and to partition the problem into subspaces bysetting the variables selected to specific values. Systematic-search methods may set thevalues of variables in some predefined order or in an order independent of the interactionsamong variables. By considering variable interactions, intelligent backtracking employsvariable/value ordering to order the subproblems generated, pre-filters partial inconsistentassignments to eliminate infeasible subproblems, and prunes subproblems with inferiorbounds computed by relaxation or approximation. Alternatively, iterative-repair methodsoperate on the full dimensionality of the starting problem and consider the interaction ofeach assignment with all its variables. In general, it is difficult to make full use of the in-teractions among variables and subproblems in the selection and assignment of variables.In this paper, we propose a new approach called constraint partitioning that decomposesthe constraints of a problem into a conjunction (∧) of subproblems, each with local con-straints and related to others by global constraints (Fig. 2). Constraints that relate to onlyvariables in one subproblem are local constraints, whereas constraints that ",
            {
                "entities": [
                    [
                        2386,
                        2414,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1555–1569Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHybrid tractability of valued constraint problems ✩Martin C. Cooper a, Stanislav Živný b,c,∗a IRIT, University of Toulouse III, 31062 Toulouse, Franceb University College, University of Oxford, Oxford OX1 4BH, UKc Computing Laboratory, University of Oxford, Oxford OX1 3QD, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 24 August 2010Received in revised form 6 December 2010Accepted 19 February 2011Available online 24 February 2011Keywords:Constraint optimisationComputational complexityTractabilitySoft constraintsValued constraint satisfaction problemsGraphical modelsForbidden substructuresThe constraint satisfaction problem (CSP) is a central generic problem in computer scienceand artificial intelligence: it provides a common framework for many theoretical problemsas well as for many real-life applications. Valued constraint problems are a generalisation ofthe CSP which allow the user to model optimisation problems. Considerable effort has beenmade in identifying properties which ensure tractability in such problems. In this work, weinitiate the study of hybrid tractability of valued constraint problems; that is, propertieswhich guarantee tractability of the given valued constraint problem, but which do notdepend only on the underlying structure of the instance (such as being tree-structured) oronly on the types of valued constraints in the instance (such as submodularity). We presentseveral novel hybrid classes of valued constraint problems in which all unary constraintsare allowed, which include a machine scheduling problem, constraint problems of arbitraryarities with no overlapping nogoods, and the SoftAllDiff constraint with arbitrary unaryvalued constraints. An important tool in our investigation will be the notion of forbiddensubstructures.© 2011 Elsevier B.V. All rights reserved.1. IntroductionAn instance of the constraint satisfaction problem (CSP) consists of a collection of variables which must be assignedvalues subject to specified constraints. Each CSP instance has an underlying hypergraph, known as its constraint hypergraph,whose vertices are the variables of the instance and whose hyperedges are the scopes of the constraints. Such a hypergraphis also known as the structure of the instance.An important line of research on the CSP is to identify all tractable cases which are recognisable in polynomial time.Most of this work has been focused on one of the two general approaches: either identifying forms of constraint which aresufficiently restrictive to ensure tractability no matter how they are combined [1,2], or else identifying structural propertiesof constraint networks which ensure tractability no matter what forms of constraint are imposed [3].The first approach has led to identifying certain algebraic properties known as polymorphisms [4] which are necessaryfor a set of constraint types to ensure tractability. A set of constraint types which ensures tractability is called a tractableconstraint language. The second approach has been used to characterise all tractable cases of bounded-arity CSPs (such asbinary CSPs): the only class of structures which ensures tractability (subject to certain complexity theory assumptions) areessentially structures of bounded tree-width [5,6].✩A preliminary version of part of this work appeared in Proceedings of the 16th International Conference on Principles and Practice of Constraint Programming(CP), LNCS, vol. 6308, 2010, pp. 152–166. This work was supported by EPSRC grant EP/F01161X/1. Stanislav Živný was supported by Junior ResearchFellowship at University College, Oxford.* Corresponding author at: Computing Laboratory, University of Oxford, Wolfson Building, Parks Road, Oxford OX1 3QD, UK. Tel: +44 (0)1865 273884.E-mail addresses: cooper@irit.fr (M.C. Cooper), standa.zivny@comlab.ox.ac.uk (S. Živný).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.02.003\f1556M.C. Cooper, S. Živný / Artificial Intelligence 175 (2011) 1555–1569In practice, constraint satisfaction problems usually do not possess a sufficiently restricted structure or use a sufficientlyrestricted constraint language to fall into any of these tractable classes. Nevertheless, they may still have properties whichensure they can be solved efficiently, but these properties concern both the structure and the form of the constraints. Suchproperties have sometimes been called hybrid reasons for tractability [7–11].Since in practice many constraint satisfaction problems are over-constrained, and hence have no solution, or are under-constrained, and hence have many solutions, soft constraint satisfaction problems have been studied [7]. Several very generalsoft CSP frameworks have been proposed in the literature [12,13]. In this paper we focus on one of the very generalframeworks, the valued constraint satisfaction problem (VCSP) [12]. In an instance of the valued CSP, every constraint isassociated with a cost function (rather than a relation as in the CSP) which allows the user to express preferences amongdifferent partial assignments, and the goal is to find an optimal assignment (i.e. an assignment of smallest total cost).Similarly to the CSP, an important line of research on the VCSP is to identify tractable cases which are recognisable inpolynomial time. It is well known that structural reasons for tractability generalise to the VCSP [7]. In the case of languagerestrictions, only a few conditions are known to guarantee tractability of a given set of valued constraints [14–16,22].Up until now there have been very few results on hybrid tractability for the VCSP, that is, tractability of subproblems ofthe VCSP defined by properties which are not exclusively language-based or structure-based. For instance, Kumar defines aninteresting framework for hybrid tractability for the Boolean weighted CSP [10]. However, to the best of our knowledge, thisframework has so far not provided any new hybrid classes. In fact, all tractable classes presented in [10] are not hybrid andare already known.Contributions. The main contribution of the paper is the study of hybrid tractability of VCSPs and the introduction of novelhybrid tractable classes of VCSPs. As a first step, we start with binary VCSPs.We introduce the class defined by the joint-winner property (JWP). This class generalises the SoftAllDiff constraint witharbitrary unary valued constraints. Moreover, we generalise this class to a larger class of non-binary VCSPs including CSPand MAX-CSP instances with no overlapping nogoods.The rest of the paper is organised as follows. In Section 2, we define binary constraint satisfaction problems (CSPs),valued constraint satisfaction problems (VCSPs) and other necessary definitions needed throughout the paper. In Section 3,we study binary VCSPs whose only soft constraints are unary. A connection between these VCSPs and the maximum weightindependent set problem in certain graph classes leads in a straightforward manner to corresponding hybrid tractable classesof VCSPs. In Section 4, we define the joint-winner property and give several examples of studied problems that satisfy thejoint-winner property. In Section 5, we study important properties of VCSP instances satisfying the joint-winner property,which allow us, in Section 6, to present a polynomial-time algorithm for solving binary VCSPs satisfying the joint-winnerproperty. In Section 7, we prove that this new tractable class is maximal. In Section 8, we extend the class of tractable VCSPsdefined by the joint-winner property. Finally, in Section 9, we summarise our work and finish with some open problems.We remark that even though our results are formulated as valued constraint satisfaction problems, it is clear that theseresults apply to various other optimisation frameworks that are equivalent to valued constraint problems such as Gibbsenergy minimisation, Markov Random Fields and other graphical models [17,18].2. PreliminariesIn this paper we firstly focus on binary valued constraint satisfaction problems before generalising to problems with costfunctions of arbitrary arity. We denote by Q+ the set of all non-negative rational numbers. We denote Q+ = Q+ ∪ {∞} withthe standard addition operation extended so that for all a ∈ Q+, a + ∞ = ∞. Members of Q+ are called costs.A unary cost function over domain D i is a mapping ci : D i → Q+. A binary cost function over domains D i and D j is amapping ci j : D i × D j → Q+. If the range of ci (ci j respectively) lies entirely within Q+, then ci (ci j respectively) is called afinite-valued cost function.If the range of ci (ci j respectively) is {α, ∞}, for some α ∈ Q+, then ci (ci j respectively) is called a crisp cost function.Note that crisp cost functions are just relations; that is, subsets of D i (in the unary case) or D i × D j (in the binary case)corresponding to the set of finite-cost tuples. If ci (ci j respectively) is not a crisp cost function, it is called soft.A binary VCSP instance [12] consists of a set of variables (denoted as v i , where i ∈ {1, . . . , n}); for each variable v i adomain D i containing possible values for variable v i ; and a set of valued constraints. Each valued constraint is either of theform (cid:7)v i, ci(cid:8), where v i is a variable and ci is a unary cost function (constraints of this form are called unary constraints),or of the form (cid:7)(cid:7)v i, v j(cid:8), ci j(cid:8), where v i and v j are variables with i < j, the pair (cid:7)v i, v j(cid:8) is called the scope of the constraint,and ci j is a binary cost function (constraints of this form are called binary constraints). A constraint is called crisp if itsassociated cost function is crisp, and similarly a constraint is called soft if its associated cost function is soft. For notationalconvenience, throughout this paper we assu",
            {
                "entities": [
                    [
                        4053,
                        4081,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 241 (2016) 191–216Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFinding a collective set of items: From proportional multirepresentation to group recommendation ✩Piotr Skowron a,∗a University of Oxford, Oxford, UKb AGH University of Science Technology, Krakow, Polandc Université Paris-Dauphine, Paris, France, Piotr Faliszewski b, Jérôme Lang ca r t i c l e i n f oa b s t r a c tWe consider the following problem: There is a set of items (e.g., movies) and a group of agents (e.g., passengers on a plane); each agent has some intrinsic utility for each of the items. Our goal is to pick a set of K items that maximize the total derived utility of all the agents (i.e., in our example we are to pick K movies that we put on the plane’s entertainment system). However, the actual utility that an agent derives from a given item is only a fraction of its intrinsic one, and this fraction depends on how the agent ranks the item among the chosen, available, ones. We provide a formal specification of the model and provide concrete examples and settings where it is applicable. We show that the problem is hard in general, but we show a number of tractability results for its natural special cases.© 2016 Elsevier B.V. All rights reserved.Article history:Received 29 October 2015Received in revised form 3 June 2016Accepted 16 September 2016Available online 22 September 2016Keywords:Proportional representationOrdered weighted averageChamberlin–Courant ruleComputational complexityApproximationElectionsVoting1. IntroductionA number of real-world problems consist of selecting a set of items for a group of agents to jointly use. Examples of such activities include picking a set of movies to put on a plane’s entertainment system, deciding which journals a university library should subscribe to, deciding what common facilities to build, or even voting for a parliament (or other assembly of representatives). Let us consider some common features of these examples.First, there is a set of items1 and a set of agents; each agent has some intrinsic utility for each of the items (e.g., this utility can be the level of appreciation for a movie, the average number of articles one reads from a given issue of a journal, expected benefit from building a particular facility, the feeling—measured in some way—of being represented by a particular politician).Second, typically it is not possible to provide all the items to the agents and we can only pick some K of them, say (a plane’s entertainment system fits only a handful of movies, the library has a limited budget, only several sites for the facilities are available, the parliament has a fixed size).Third, the intrinsic utilities for items extend to the sets of items in such a way that the utility derived by an agent from a given item may depend on the rank of this item (from the agent’s point of view) among the selected ones. Extreme ✩The preliminary version of this paper was presented at AAAI-2015.* Corresponding author.E-mail addresses: piotr.skowron@cs.ox.ac.uk (P. Skowron), faliszew@agh.edu.pl (P. Faliszewski), lang@lamsade.dauphine.fr (J. Lang).1 We use the term ‘item’ in the most neutral possible way. Items may be candidates running for an election, or movies, or possible facilities, and so on.http://dx.doi.org/10.1016/j.artint.2016.09.0030004-3702/© 2016 Elsevier B.V. All rights reserved.\f192P. Skowron et al. / Artificial Intelligence 241 (2016) 191–216examples include the case where each agent derives utility from his or her most preferred item only (e.g., an agent will watch his or her favorite movie only, will read/use the favorite journal/favorite facility only, will feel represented by the most appropriate politician only), from his or her least preferred item only (say, the agent worries that the family will force him or her to watch the worst available movie), or derives 1/K of the utility from each of the available items (e.g., the agent chooses the item—say, a movie—at random). However, in practice one should expect much more complicated schemes (e.g., an agent watches the top movie certainly, the second one probably, the third one perhaps, etc.; or, an agent is interested in having at least some T interesting journals in the library; an agent feels represented by some top T members of the parliament, etc.).The goal of this paper is to formally define a model that captures all the above-described scenarios, provide a set of examples where the model is applicable, and provide an initial set of computational results for it in terms of efficient algorithms (exact or approximate) and computational hardness results (NP-hardness and inapproximability results).Our work builds upon, generalizes, and extends quite a number of settings that have already been studied in the litera-ture. We provide a deeper overview of this research in Section 8 and here we only mention the two most directly related lines of work. First, our model where the agents derive utility from their most preferred item among the selected ones directly corresponds to winner determination under the Chamberlin–Courant’s voting rule [18,50,7] (it is also very deeply connected to the model of budgeted social choice [41,49,42]) and is in a certain formal sense a variant of the facility location problem. Second, the case where for each item each agent derives the same fraction of the utility is, in essence, the same as K -winner range-voting (or K -winner Borda [21]); that agents enjoy equally the items they get is also a key assumption in the Santa Claus problem [6], and in the problem of designing optimal picking sequences [14,10,35].The paper is organized as follows. First, in Section 2 we discuss several important modeling choices and provide the for-mal description of our model. Then, in Section 3, we discuss the applicability of the model in various scenarios. Specifically, we show a number of examples that lead to particular parameter values of our model. We give an overview of our results in Section 4 and then, in Sections 5, 6, and 7, we present these results formally. In Section 5 we present results regarding the complexity of computing exact solutions for our model. In the next two sections we discuss the issue of computing approximate solutions. First without putting restrictions on agents’ utilities (Section 6) and, then, for what we call non-finicky utilities (Section 7). Intuitively put, under non-finicky utilities the agents are required to give relatively high utility values to a relatively large fraction of the items. We believe that the notion of non-finicky utilities is one of the important contributions of this paper. We discuss related work in Section 8 and conclude in Section 9.2. The modelIn this section we give a formal description of our model. However, before we move on to the mathematical details, let us explain and justify some high-level assumptions and choices that we have made.First, we assume that the agents have separable preferences. This means that the intrinsic utility of an object does not depend on what other objects are selected. This is very different from, for example, the case of combinatorial auctions. However, in our model the impact of an object on the global utility of an agent does depend on its rank (according to that agent) among the selected items. This distinction between the intrinsic value of an item and its value distorted by its rank is also considered in several other research fields, especially in decision theory (where it is known as “rank-dependent utility theory”) and in multicriteria decision making, from which we borrow one of the main ingredients of our approach, the ordered weighted average (OWA) operators [58] (for technical details see the work of Kacprzyk et al. [34]). OWAs were recently used in social choice in several contexts [31,3,23]; we discuss these works in detain in Section 8.Second, throughout the paper we navigate between two views of the agents’ intrinsic utilities:1. Generally, we assume that the utilities are provided explicitly in the input as numerical values, and that these values are comparable between agents. Yet, we make no further assumptions about the nature of agents’ utilities: they do not need to be normalized, they do not need to come from any particular range of values, etc. Indeed, it is possible that some agent has very strong preferences regarding the items, modeled through high, diverse utility values, whereas some other agent does not care much about the selection process and has low utility values only.2. In some parts of the paper (which will always be clearly identified), we assume that utilities are heavily constrained and are derived from non-numerical information, such as approval ballots specifying which items an agent approves (leading to approval-based utilities), or rankings over alternatives, from which utilities are derived using an agent-independent scoring vector (typically, a Borda-like vector).Formally, the latter view is a special case of the former, but we believe that it is worthwhile to consider it separately. Indeed, many multiwinner voting rules (such as the Chamberlin–Courant [18] rule or the Proportional Approval Voting rule [37]) fit the second view far more naturally, whereas for other applications the former view is more natural.Third, we take the utilitarian view and measure the social welfare of the agents as the sum of their perceived utilities. One could study other variants, such as the egalitarian variant, where the social welfare is measured as the utility of the worst-off agent. We leave this as possible future research (our preliminary attempts indicated that the egalitarian setting is computationally even harder than the utilitarian one). Very recently, Elkind and Ismaïli [23] used OWA operators to define variants of the Chamberlin–Courant rule that lay between the utilitarian and egalitarian variants, while Amanatidis et al",
            {
                "entities": [
                    [
                        3358,
                        3386,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 213 (2014) 42–59Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe price of query rewriting in ontology-based data accessGeorg Gottlob a, Stanislav Kikot b, Roman Kontchakov b, Vladimir Podolskii c,Thomas Schwentick d, Michael Zakharyaschev b,∗a Department of Computer Science, University of Oxford, UKb Department of Computer Science and Information Systems, Birkbeck, University of London, UKc Steklov Mathematical Institute, Moscow, Russiad Fakultät für Informatik, TU Dortmund, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 7 July 2013Received in revised form 13 March 2014Accepted 26 April 2014Available online 5 May 2014Keywords:OntologyDatalogConjunctive queryQuery rewritingSuccinctnessBoolean circuitMonotone complexity1. Introduction±±linear Datalogand sticky DatalogWe give a solution to the succinctness problem for the size of first-order rewritingsof conjunctive queries in ontology-based data access with ontology languages such as. We show that positive existential andOWL 2 QL,nonrecursive datalog rewritings, which do not use extra non-logical symbols (except forintensional predicates in the case of datalog rewritings), suffer an exponential blowupin the worst case, while first-order rewritings can grow superpolynomially unless NP ⊆P/poly. We also prove that nonrecursive datalog rewritings are in general exponentiallymore succinct than positive existential rewritings, while first-order rewritings can besuperpolynomially more succinct than positive existential rewritings. On the other hand,we construct polynomial-size positive existential and nonrecursive datalog rewritingsunder the assumption that any data instance contains two fixed constants.© 2014 Elsevier B.V. All rights reserved.±.Our aim in this article is to give a solution to the succinctness problem for various types of conjunctive query rewritingin ontology-based data access (OBDA) with basic ontology languages such as OWL 2 QL and fragments of DatalogThe idea of OBDA has been around since about 2005 [14,19,28,47]. In the OBDA paradigm, an ontology defines a high-level global schema and provides a vocabulary for user queries. An OBDA system rewrites these queries into the vocabularyof the data and then delegates the actual query evaluation to the data sources (which can be relational databases, triplestores, datalog engines, etc.). OBDA is often regarded as an important ingredient of the new generation of information sys-tems because it (i) gives a high-level conceptual view of the data, (ii) provides the users with a convenient vocabulary forqueries, thus isolating them from the details of the structure of data sources, (iii) allows the system to enrich incompletedata with background knowledge, and (iv) supports queries to multiple and possibly heterogeneous data sources.A key concept of OBDA is first-order (FO) rewritability. An ontology language L is said to enjoy FO-rewritability if anyconjunctive query (CQ) q over any ontology Σ , formulated in L, can be rewritten to an FO-query qsuch that, for any datainstance D, the answers to the original CQ q over the knowledge base (Σ, D) can be computed by evaluating the rewriting(cid:4)* Corresponding author.E-mail addresses: georg.gottlob@cs.ox.ac.uk (G. Gottlob), staskikotx@gmail.com (S. Kikot), roman@dcs.bbk.ac.uk (R. Kontchakov), podolskii@mi.ras.ru(V. Podolskii), thomas.schwentick@udo.edu (T. Schwentick), michael@dcs.bbk.ac.uk (M. Zakharyaschev).http://dx.doi.org/10.1016/j.artint.2014.04.0040004-3702/© 2014 Elsevier B.V. All rights reserved.\fG. Gottlob et al. / Artificial Intelligence 213 (2014) 42–5943(cid:4)(cid:4)(cid:4)over D. As qis an FO-query, the answers to qqcan be obtained using a standard relational database management system(RDBMS). Ontology languages with this property include the OWL 2 QL profile of the Web Ontology Language OWL 2, whichis based on description logics of the DL-Lite family [16,4], and fragments of Datalogsuch as linear tgds [11] (also knownas atomic-body existential rules [6]) or sticky tgds [12,13]. To illustrate, consider an OWL 2 QL-ontology Σ consisting of thefollowing tuple-generating dependencies (tgds):±(cid:2)∀x(cid:2)∀x∀x, y∀x, y(cid:2)RA(x) → ∃ yProject(x) → ∃ y(cid:2)worksOn(x, y) ∧ Project( y)(cid:3)(cid:3),(cid:2)(cid:2)isManagedBy(x, y) ∧ Professor( y)(cid:3)worksOn(x, y) → involves( y, x)(cid:3)isManagedBy(x, y) → involves(x, y),,(cid:3)(cid:3),and the CQ q(x) asking to find those who work with professors:q(x) = ∃ y, z(cid:2)(cid:3)worksOn(x, y) ∧ involves( y, z) ∧ Professor(z).A moment’s thought should convince the reader that the (positive existential) query(cid:4)q(x) = ∃ y, z(cid:4)worksOn(x, y) ∧(cid:2)(cid:3)worksOn(z, y) ∨ isManagedBy( y, z) ∨ involves( y, z)(cid:5)∧ Professor(z)(cid:5)worksOn(x, y) ∧ Project( y)(cid:4)∃ y(1)(2)(3)(4)(5)∨∨ RA(x)is an FO-rewriting of q(x) and Σ in the sense that, for any set D of ground atoms and any constant a in D, we have(Σ, D) |(cid:10) q(a)if and only if D |(cid:10) q(cid:4)(a).(In Section 2, we shall consider this example in more detail.) A number of different rewriting techniques have beenproposed and implemented for OWL 2 QL (PerfectRef [47], Presto/Prexto [55,54], Rapid [18], the combined approach [37],Ontop [51,33]) and its various extensions (Requiem/Blackout [45,46], Nyaya [25,43], Clipper [20] and [35]). However, allFO-rewritings constructed so far have, in the worst case, been exponential in the size of the query q. Thus, despite thefact that, for data complexity, CQ answering over ontologies with FO-rewritability is as complex as standard database queryevaluation (both are in AC0), rewritings can be too large for RDBMSs to cope with. It has become apparent, in both theoryand experiments, that for the OBDA paradigm to work in practice, we have to restrict attention to those ontologies and CQsthat ensure polynomial FO-rewritability (in the very least).The major open question we are going to attack in this article is whether the standard ontology languages for OBDA (inparticular, OWL 2 QL) enjoy polynomial FO-rewritability. Naturally, the answer depends on what means we can use in theof q and Σ above, we did not use any non-logical symbols other than those thatrewritings. For example, in the rewriting qoccurred in q and Σ . Such rewritings (perhaps also containing equality) may be described as ‘pure’ as they can be used withall possible databases; cf. [16]. (Note that all known rewritings apart from the one in the combined approach [37] are purein this sense.) Other important parameters are the available logical means (connectives and quantifiers) in rewritings and theway we represent them. Apart from the class of arbitrary FO-queries, we shall also consider positive existential (PE) queriesand nonrecursive datalog (NDL) queries as possible formalisms for rewritings (needless to say that pure NDL-rewritings maycontain new intensional predicates).(cid:4)At first sight, the results we obtain in this article could be divided into negative and positive. The bad news is thatthere is a sequence of CQs qn and OWL 2 QL ontologies Σn, both of size O (n), such that any pure PE- or NDL-rewritingof qn and Σn is of exponential size in n, while any pure FO-rewriting is of superpolynomial size unless NP ⊆ P/poly. Weobtain this negative result by first showing that OBDA with OWL 2 QL is powerful enough to compute monotone Booleanfunctions in NP, and that PE-rewritings correspond to monotone Boolean formulas, NDL-rewritings to monotone Booleancircuits, and FO-rewritings to arbitrary Boolean formulas. Then we use the celebrated exponential lower bounds for the sizeof monotone circuits and formulas computing the (NP-complete) Boolean function Cliquen,k ‘a graph with n nodes containsa k-clique’ [50,49]; a superpolynomial lower bound for the size of arbitrary (not necessarily monotone) Boolean formulascomputing Cliquen,k is a consequence of the assumption NP (cid:11)⊆ P/poly. We also use known separation results [49,48] formonotone Boolean functions such as ‘a bipartite graph with n vertices in each part has a perfect matching’ and ‘a givenvertex is accessible in a path accessibility system with n vertices’ to show that pure NDL-rewritings are in general exponen-tially more succinct than pure PE-rewritings, while pure FO-rewritings can be superpolynomially more succinct than purePE-rewritings.On the other hand, we have some good news as well: assuming that every data instance contains two fixed distinctindividual constants, we construct polynomial-size impure PE- and NDL-rewritings of any CQ and any ontology with the±polynomial witness property (in particular, any ontology in OWL 2 QL, linear Datalogof bounded arity). In essence, the rewriting guesses a polynomial number of ground atoms with database individuals andlabelled nulls (encoded as tuples over the two fixed constants), and checks whether these atoms satisfy the given CQand form a sequence of chase steps. We first construct a polynomial-size impure PE-rewriting and then show how itsdisjunctions can be encoded by a polynomial-size NDL-rewriting with intensional predicates of small arity. As the twoof bounded arity or sticky Datalog±\f44G. Gottlob et al. / Artificial Intelligence 213 (2014) 42–59constants in the impure PE-rewriting can be replaced with two fresh existentially quantified variables, say x and y, suchthat x (cid:11)= y, we also obtain a polynomial-size pure FO-rewriting over data instances with at least two domain elements.How to reconcile these seemingly contradictory results? To establish exponential and superpolynomial lower boundsfor the size of pure rewritings, we show that computing monotone Boolean functions in NP is polynomially reducible toanswering CQs over OWL 2 QL-ontologies and data instances with a single individual. As evaluating queries over such datainstances is tractable, pure rewritings of the CQs and ontologies computing NP-complete monotone B",
            {
                "entities": [
                    [
                        3530,
                        3558,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 220 (2015) 64–103Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBackdoors to tractable answer set programming ✩Johannes Klaus Fichte a,b, Stefan Szeider a,∗a Vienna University of Technology, Favoritenstrasse 9-11, 1040 Vienna, Austriab University of Potsdam, August-Bebel-Strasse 89, 14482 Potsdam, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 7 March 2014Received in revised form 1 December 2014Accepted 6 December 2014Available online 15 December 2014Keywords:Answer set programmingBackdoorsComputational complexityParameterized complexityKernelizationAnswer Set Programming (ASP) is an increasingly popular framework for declarative programming that admits the description of problems by means of rules and constraints that form a disjunctive logic program. In particular, many AI problems such as reasoning in a nonmonotonic setting can be directly formulated in ASP. Although the main problems of ASP are of high computational complexity, complete for the second level of the Polynomial Hierarchy, several restrictions of ASP have been identified in the literature, under which ASP problems become tractable.In this paper we use the concept of backdoors to identify new restrictions that make ASP problems tractable. Small backdoors are sets of atoms that represent “clever reasoning shortcuts” through the search space and represent a hidden structure in the problem input. The concept of backdoors is widely used in theoretical investigations in the areas of propositional satisfiability and constraint satisfaction. We show that it can be fruitfully adapted to ASP. We demonstrate how backdoors can serve as a unifying framework that accommodates several tractable restrictions of ASP known from the literature. Furthermore, we show how backdoors allow us to deploy recent algorithmic results from parameterized complexity theory to the domain of answer set programming.© 2015 Elsevier B.V. All rights reserved.1. IntroductionAnswer Set Programming (ASP) is an increasingly popular framework for declarative programming [115,122]. ASP admits the description of problems by means of rules and constraints that form a disjunctive logic program. Solutions to the program are so-called stable models or answer sets. Many important problems of AI and reasoning can be succinctly repre-sented and successfully solved within the ASP framework. It has been applied to several large industrial applications, e.g., social networks [97], match making [74], planning in a seaport [129], optimization of packaging of Linux distributions [69], and general game playing [145].The main computational problems for ASP (such as deciding whether a program has a solution, or whether a certain atom is contained in at least one or in all solutions) are complete for the second level of the Polynomial Hierarchy [41]; thus, ASP problems are “harder than NP” and have a higher worst-case complexity than CSP and SAT. In the literature, several restrictions have been identified that make ASP tractable, most prominently the Horn fragment and the stratified fragment [78,2], for a detailed trichotomy (tractable, first level, second level of PH) see [148].Fichte and Szeider’s research was supported by the European Research Council, grant reference 239962 (COMPLEX REASON). Fichte’s research was ✩partially supported by the Austrian Science Fund (FWF) project Y698.* Corresponding author.E-mail addresses: fichte@kr.tuwien.ac.at (J.K. Fichte), stefan@szeider.net (S. Szeider).http://dx.doi.org/10.1016/j.artint.2014.12.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\fJ.K. Fichte, S. Szeider / Artificial Intelligence 220 (2015) 64–103651.1. ContributionIn this paper we use the concept of backdoors to identify new restrictions that make propositional ASP problems tractable. Small backdoors are sets of atoms that represent “clever reasoning shortcuts” through the search space and represent a hidden structure in the problem input. Backdoors were originally introduced by Williams, Gomes, and Selman [152,153] as a tool to analyze the behavior of DPLL-based SAT solvers. Backdoors have been widely used in theoretical investigations in the area of propositional satisfiability [152,135,138,103] and constraint satisfaction [84], and also for abductive reasoning [125], argumentation [40], and quantified Boolean formulas [137]. A backdoor is defined with respect to some fixed target class for which the computational problem under consideration is polynomial-time tractable. The size of the backdoor can be seen as a distance measure that indicates how far the instance is from the target class.In this paper we develop a rigorous theory of backdoors for answer set programming. We show that the concept of backdoors can be fruitfully adapted for this setting, and that backdoors can serve as a unifying framework that accommodates several tractable restrictions of propositional ASP known from the literature.For a worst-case complexity analysis of various problems involving backdoors such as finding a small backdoor or using it to solve the problem, it is crucial to investigate how the running time depends on the size of the backdoor, and how well running time scales with backdoor size. Parameterized Complexity [35,55,85] provides a most suitable theoretical framework for such an analysis. It provides the key notion of fixed-parameter tractability which, in our context, means polynomial-time tractability for fixed backdoor size, where the order of the polynomial does not depend on the backdoor size. We show how backdoors allow us to deploy recent algorithmic results from parameterized complexity theory to the domain of answer set programming.Parameterized complexity provides tools for a rigorous analysis of polynomial-time preprocessing in terms of kerneliza-tion [7,58]. A kernelization is a polynomial-time self-reduction of a parameterized decision problem that outputs a decision equivalent problem instance whose size is bounded by a function f of the parameter (the kernel size). It is known that every decidable fixed-parameter tractable problem admits a kernelization, but some problems admit small kernels (of size polynomial in the parameter) and others do not. We provide upper and lower bounds for the kernel size of the prob-lems backdoor evaluation and backdoor detection for disjunctive answer set programs. These bounds provide worst case guarantees and limits for polynomial-time preprocessing for the considered problems.Several algorithms in the literature are defined for disjunction-free (i.e., normal) programs only. We introduce a general method for lifting these parameters to disjunctive programs, preserving fixed-parameter tractability under certain conditions.Although our main focus is on a theoretical evaluation, we present some experimental results where we consider the backdoor size of structured programs and random programs of varied density.1.2. Background and related workComplexity of ASP problems Answer set programming is based on the stable-model semantics for logic programs [78,79]. The computational complexity of various problems arising in answer set programming has been subject of extensive studies. Eiter and Gottlob [41] have established that the main decision problems of (disjunctive) ASP are complete for the second level of the Polynomial Hierarchy (Σ P2 -complete, respectively). Moreover, Bidoít and Froidevaux [5] and Marek and Truszczy ´nski [114] have shown that the problems are NP-complete (co-NP-complete respectively) for disjunction-free (so-called normal) programs. Several fragments of programs where the main reasoning problems are polynomial-time tractable have been identified, e.g., Horn programs [78], stratified programs [2] and programs without even cycles [156]. Dantsin et al. [27] survey the classical complexity of the main reasoning problems for various semantics of logic programming, including fragments of answer set programming.2 - or Π PASP solvers Various ASP solvers have been developed in recent years. Many of them utilize SAT solvers as black boxes or search techniques from SAT. There are solvers that deal with one or more fragments of disjunctive programs (normal, tight, or head-cycle-free), e.g., Smodels [141], Assat [111], Cmodels2 [82], and Clasp2 [71]. There are also solvers that deal with the full set of disjunctive programs, e.g., Clasp3 [37], Cmodels3 [108], DLV [107], and GnT [92]. Compilations to other problem domains and respective solvers have been considered for normal programs, e.g., propositional satisfiability [91], mixed integer programming [112], satisfiability modulo theories [93,76]. We would like to point out that these solvers use heuristics without non-trivial worst-case performance guarantees. In contrast we provide for the main reasoning problems of answer set programming theoretical worst-case time bounds that take certain hidden structures in disjunctive programs into account.Preprocessing techniques and unit propagation used in solvers might be considered in a wider sense as implicitly exploit-ing Horn fragments. Grounders like Gringo [64] already solve Horn programs simply by propagating atoms which trivially (do not) belong to the minimal model, e.g., atoms that occur in the head of rules with an empty body, atoms that occur in the head of rules where all atoms in the positive body already belong to the minimal model, atoms that cannot belong to the minimal model according to some constraint, and atoms that cannot belong to the minimal model as they occur in no head. Moreover, SAT-based solvers like Clasp [62] transform the program into a propositional formula using Clark’s completion (see e.g., [73]) where the resulting formula characterizes the classical models and necessary conditions for atoms to belong to a model. If the program contains no cycles in its positive dependency graph, unit propagation (as part of a \f66J.K. Fichte, S. Sz",
            {
                "entities": [
                    [
                        3574,
                        3602,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1390–1409Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the modelling and optimization of preferences in constraint-basedtemporal reasoning ✩Michael D. Moffitt11400 Burnet Rd., Austin, TX, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 28 February 2009Received in revised form 12 August 2010Accepted 15 September 2010Available online 8 December 2010Keywords:PreferencesOverconstrained problemsConstraint satisfactionOptimizationBranch and boundTemporal reasoningIn this paper, we consider both the modelling and optimization of preferences inproblems of constraint-based temporal reasoning. The Disjunctive Temporal Problemswith Preferences (DTPP) – a formulation that combines the rich expressive power ofthe Disjunctive Temporal Problem with the introduction of metric preference functions –is studied, and transformed into a corresponding constraint system that we name theValued DTP (VDTP). We show that for a broad family of optimization criteria, the VDTPcan express the same solution space as the DTPP, under the assumption of arbitrarypiecewise-constant preference functions. We then generalize the powerful search strategiesfrom decision-based DTP literature to accomplish the efficient optimization of temporalpreferences.In contrast to the previous state-of-the-art system (which addresses theoptimization of temporal preferences using a SAT formulation), we instead employ a meta-CSP search space that has traditionally been used to solve DTPs without preferences.Our approach supports a variety of objective functions (such as utilitarian optimalityor maximin optimality) and can accommodate any compliant valuation structure. Wealso demonstrate that key pruning techniques commonly used for temporal satisfiability(particularly, the removal of subsumed variables and semantic branching) are naturallysuited to prevent the exploration of redundant search nodes during optimization that mayotherwise be encountered when resolving a typical VDTP derived from a DTPP. Finally, wepresent empirical results showing that an implementation of our approach consistentlyoutperforms prior algorithms by orders of magnitude.© 2010 Elsevier B.V. All rights reserved.1. IntroductionThe need to accommodate preferences has increasingly become an important problem in many fields related to artificialintelligence. While the topic spans several subjects – including decision theory, planning and scheduling, and machinelearning – the area of constraint satisfaction [9,29] affords many of the greatest opportunities for both the representation andreasoning of preferences [6,28]. The application of preferences to constraint-based systems presents at least three principalchallenges. The first of these challenges is determining a means to achieve preference elicitation, either through explicitmechanisms or by indirect inference through a series of observations and interactions with a user [34,35]. Secondly, onemust address the adequate modelling of local preference values and their global aggregation; the burden of translating theknown preference values of the real world to a specific standalone representation is seldom straightforward, and, in somecases, impossible. The third challenge deals with the necessary adaptation of classical search strategies to transform thegoal of satisfaction into one of optimization, requiring the generalization of highly specialized techniques to navigate a richer✩This paper includes and extends preliminary work from Moffitt and Pollack (2005, 2006) [18,19].E-mail address: mdmoffitt@us.ibm.com.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.016\fM.D. Moffitt / Artificial Intelligence 175 (2011) 1390–14091391search space [16]. Whether optimization can be done practically depends largely on the choice of model and the choice ofsearch strategy, resulting in a well-known tradeoff between expressive power and efficient reasoning.To be sure, existing literature on classical finite-domain CSPs is rich with techniques for encoding and resolving prefer-ence criteria. Among the various formalisms proposed, two popular representations are dominant: The Valued CSP [30] andthe Semiring CSP [7]. In the Valued CSP, constraints are annotated with scalar valuations that reflect the cost of their viola-tion. In the Semiring CSP, the various relational tuples that may satisfy a constraint are themselves labeled with preferences.Aside from the unique ability of the semiring to encode a partial ordering over the solution space, the two representationsare comparable, and can be readily converted to one another [8]. Both approaches unify the expressive power of the classicalCSP and the efficient algorithms for their satisfaction under the larger scope of preference optimization.Closely related to the finite-domain CSP, the temporal CSP is a common representation for many planning and schedul-ing problems in which the relationships between events (in time) are expressed by constraining their pairwise difference.Preferences have been proposed in this framework as well, with the most common variant augmenting traditional temporalconstraints [10] with local preference functions that express how well a particular assignment satisfies the correspondingconstraint [13]. These functions might convey that a certain activity should be as long as possible, or that it is desirablefor a pair of activities to be scheduled very close to one another. While the literature-to-date has introduced representa-tions with generously expressive preference functions, they have often been applied to relatively inexpressive underlyingconstraint systems, limiting the reasoning of complex preferences to only a relatively small class of problems [14,15,20,24].As preference-based temporal models continue to become more and more commonplace in industrial constraint engines[5,4,25], modern optimization tools must be able to respond to a wider range of problem instances.The Disjunctive Temporal Problems with Preferences (DTPPs) [23], a powerful representation that subsumes many com-mon temporal formalisms, attempts to provide the best of both worlds: a rich model for complex disjunctive constraints(to handle, for instance, non-overlap conditions that commonly arise in planning and scheduling) in addition to a rich lan-guage for expressing preference profiles over their domains. Early work in this problem space focused on maximizing theminimum of such preference values, while later developments have begun to address the more challenging problem ofutilitarian optimization [26], where the sum of the individual preference values is maximized. In either case, the problemof optimization is divided from the core satisfiability engine (i.e., of the wealth of techniques used to find feasible solu-tions, relatively few are extended toward finding good solutions). This division is due, in part, to a fundamental dichotomybetween the preference model and the search space of temporal problems: preference values are attributed to grounded dif-ferences between temporal events, whereas the meta-CSP algorithms for temporal reasoning refrain from instantiating theseobject-level variables. Recent work has shown that SAT formulations can demonstrate orders of magnitude of improvementas compared to these techniques [31], suggesting that advances in SAT technology may be the key to rapid search. Hence,prior art has yet to reveal a unified approach for both the expressive modelling and efficient optimization of preferenceswithin a classic CSP framework.In this work, we consider an alternative to the DTPP – the Valued DTP (or VDTP). We show that for a broad familyof optimization criteria, the VDTP can express the same solution space as the DTPP, under the assumption of arbitrarypiecewise-constant preference functions. We furthermore argue that the valued constraint representation eliminates thedichotomy between the object-level preference model and the meta-CSP solution space, and thus offers unique advan-tages when used to guide the search strategies employed in temporal constraint satisfaction algorithms. We then generalizedecision-based DTP literature to accomplish the efficient optimization of temporal preferences. Our approach supports avariety of objective functions (such as utilitarian optimality or maximin optimality) and can accommodate any compliantvaluation structure. We also demonstrate that key pruning techniques commonly used for temporal satisfiability (partic-ularly, the removal of subsumed variables and semantic branching) are naturally suited to prevent the exploration ofredundant search nodes during optimization that may otherwise be encountered when resolving a typical VDTP derivedfrom a DTPP. Finally, we present empirical results showing that an implementation of our approach consistently outper-forms prior algorithms by orders of magnitude, including the SAT-based approach.The remainder of the paper is organized as follows. Section 2 covers background material related to classical CSPs andtheir corresponding preference models. Sections 3 and 4 cover constraint-based temporal reasoning and extensions to tem-poral preferences, respectively. In Sections 5 and 6, we present the Valued DTP, and establish its relationship with the DTPwith Preferences. In Section 7, we demonstrate how to adopt the preference model of the VDTP to construct a meta-CSPsearch framework for optimization. In Section 8, we provide an empirical evaluation of approaches. Finally, we conclude inSection 9 with a summary of our approach along with future works.2. Preference optimization in finite-domain constraint networksWe begin by briefly reviewing the formulation of classical CSPs, followed by a description of two preference models thathave been used to augment the original framework.2.1. Finite-domain constraint networksA Constraint Satisfaction Problem (or ",
            {
                "entities": [
                    [
                        3727,
                        3755,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 239 (2016) 70–96Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiffusion centrality: A paradigm to maximize spread in social networksChanhyun Kang a, Sarit Kraus b, Cristian Molinaro c,∗V.S. Subrahmanian aa Department of Computer Science, University of Maryland, USAb Department of Computer Science, Bar-Ilan University, Israelc DIMES, Università della Calabria, Italyd Department of Computer Science, Boise State University, USA, Francesca Spezzano d, a r t i c l e i n f oa b s t r a c tArticle history:Received 7 February 2015Received in revised form 21 May 2016Accepted 30 June 2016Available online 7 July 2016Keywords:Social networksDiffusion modelLogic programmingQuantitative logicWe propose Diffusion Centrality (DC) in which semantic aspects of a social network are used to characterize vertices that are influential in diffusing a property p. In contrast to classical centrality measures, diffusion centrality of vertices varies with the property p, and depends on the diffusion model describing how p spreads. We show that DC applies to most known diffusion models including tipping, cascade, and homophilic models. We present a hypergraph-based algorithm (HyperDC) with many optimizations to exactly compute DC. However, HyperDC does not scale well to huge social networks (millions of vertices, tens of millions of edges). For scaling, we develop methods to coarsen a network and propose a heuristic algorithm called “Coarsened Back and Forth” (CBAF) to compute the top-k vertices (having the highest diffusion centrality). We report on experiments comparing DC with classical centrality measures in terms of runtime and the “spread” achieved by the k most central vertices (using 7 real-world social networks and 3 different diffusion models). Our experiments show that DC produces higher quality results and is comparable to several centrality measures in terms of runtime.© 2016 Elsevier B.V. All rights reserved.1. IntroductionAn increasingly important problem in social networks (SNs) is that of assigning a “centrality” value to vertices which will reflect their importance within the SN. Well-known measures such as degree centrality [21,46], betweenness centrality [8,20], PageRank [9], closeness centrality [49,5], and eigenvector centrality [7] only take the structure of the network into account—they do not differentiate between vertices that are central w.r.t. spreading one topic or meme or sentiment vs. spreading another. A vertex that is important in spreading awareness of a mobile phone program may be very unimportant in spread-ing information about a restaurant. Likewise, most past work assumes that there is no information about properties of the vertices/edges or edge weights, but in modern social networks, at least some self-declared properties exist and, in many cases, analysis of tweets and posts can provide further information. These omissions can cause different problems as shown in the following toy example.* Corresponding author.E-mail address: cmolinaro@dimes.unical.it (C. Molinaro).http://dx.doi.org/10.1016/j.artint.2016.06.0080004-3702/© 2016 Elsevier B.V. All rights reserved.\fC. Kang et al. / Artificial Intelligence 239 (2016) 70–9671Fig. 1. A small HIV social network. Shaded vertices denote people with HIV.Example 1 (HIV). Fig. 1 shows four people a, b, c, d, where b has HIV. Solid edges denote sexual relationships, while dashed edges denote friend relationships. Both “friend” and “sexual partner” relationships can play a role in the diffusion of HIV (as friends may, unbeknownst to us, also be sexual partners). Edge weights denote the intensity of the relationships.The table below shows the centrality of a, b, c, d w.r.t. various centrality measures. Notice that the nature of the rela-tionships (i.e., friend and sexual partner) are not taken into account by these centrality measures, as they consider only the topological structure of the network.Centrality measureDegreeBetweennessPageRankClosenessEigenvectora120.3670.330.375b0.3300.1410.20.125c0.6600.2460.250.25d0.6600.2460.250.25The only person in this network capable of spreading HIV is b. However, b has the lowest centrality according to all five centrality measures mentioned above.Example 2. Consider again the same network shown in Fig. 1 and suppose the vertices denoted users on Twitter. A solid edge (u, v) denotes the fact that u and v have both retweeted at least one of the other’s tweets, while a dashed edge indicates that they are friends (i.e., u follows v and vice versa). Suppose b was the only person to have tweeted a positive opinion about a political candidate while none of the others have done so. Then, by the same reasoning as in the previous example, and given that Fig. 1 is the entire network, we can again infer that any other user (i.e., a, c, d) who tweets positively about the same candidate was either influenced by b or was influenced by some exogenous process. b should clearly get more credit for the other user’s positive tweet than anyone else, but has the lowest centrality according to classical centrality measures.Past centrality measures do not take into account (i) the property of interest w.r.t. which a vertex’s “importance” is measured, (ii) how properties (e.g., HIV in the example above) diffuse through the SN, and (iii) any semantic aspect of the network (properties of vertices and edges), solely focusing on the topological structure. Taking all of these aspects into account is crucial in determining the most central vertices. We can readily think of networks (e.g., Twitter) where person A has the highest centrality in terms of spread of support for Republicans, while person B is the central player in terms of spread of support for conserving gorillas. The network in both cases is the same (Twitter), but the most “central” person depends on the diffusive property with respect to which a vertex is considered “influential” or “central”. Taking into account diffusion models (e.g., how one person influences another) is another crucial aspect. Different ways of spreading a property (e.g., a disease) may lead to different central vertices. Furthermore, intrinsic properties of vertices (customers, patients) and the nature and strength of the relationships (edges) are important too. For instance, [45] talks about the role of nine different demographic factors in influencing online purchases across 14 product categories, showing that some demographic factors are relevant for some product types, while others are relevant for others. This paper proposes the novel notion of diffusion centrality that takes an SN, a diffusive property p, and a previously learned diffusion model (cid:2) for p, and defines centrality of vertices based on this input. We do not provide algorithms to automatically learn diffusion models—interested readers may find one such algorithm in [10].The paper’s goal is to show how diffusion centrality can be used to achieve higher spread of a diffusive property p by using diffusion models for p rather than classical centrality measures. We further show that this can be done for most diffusion models we have seen in the literature. Last but not least, our methods are shown to scale to social networks with over 2M vertices and 20M edges.Real-world diffusion models fall into three diverse categories. In cascade models, there is some probability that a vertex will spread a diffusive property p to one of its neighbors [34,36]—these include popular disease spread models such as the SIR model of disease spread [26]. Tipping models use other mathematical calculations such as cost-benefit analysis, often involving no probabilities, in order to decide whether a vertex will adopt a certain behavior. Tipping models were introduced by Nobel laureate Tom Schelling [50] to model segregation of neighborhoods, and by Granovetter [24]. In homophilic models, similarities between two vertices are considered in order to decide if the two vertices will adopt a similar behavior [42,12,3]. \f72C. Kang et al. / Artificial Intelligence 239 (2016) 70–96Homophilic models use various types of distance measures between attributes of a vertex (e.g., age, occupation, gender) and combine them via non-probabilistic measures to achieve a degree of similarity between two vertices.Because diffusion models vary dramatically, a paradigm to express them must be capable of: (i) expressing semantic properties of vertices and connections between them, (ii) representing probabilistic inferences, and (iii) expressing inferences based on non-probabilistic, quantitative reasoning. The suite of knowledge representation paradigms offers several starting points. Bayesian nets and causal inference [47] offer an obvious place to start as they can be used to express cascade models. However, it is not clear if they can be used to express generic quantitative information, which is needed to express many other real diffusion models, such as tipping and homophilic models. In contrast, the language of Generalized Annotated (logic) Programs (GAPs) [35] has been well-studied in knowledge representation and is rich enough to capture a wide variety of different forms of reasoning. It can represent both the structure of social networks (with semantics and weight annotations) as well as these diverse types of diffusion models. Indeed, as shown in [51], many existing diffusion models from all three aforementioned categories can be expressed as GAPs, including: the Susceptible–Infectious–Removed (SIR) [2]and Susceptible–Infectious–Susceptible (SIS) [26] models of disease spread; the Big Seed marketing approach [57], which is a strategy of advertising to a large group of individuals who are likely to spread the advertisement further through network effects; models of diffusion of “favorited” pictures in Flickr [13]; tipping models like the Jackson–Yariv model [28]. We also considered richer versions of GAPs, such as hy",
            {
                "entities": [
                    [
                        3124,
                        3152,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 163–188Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the adoption of abductive reasoning for time series interpretationT. Teijeiro∗, P. FélixCentro Singular de Investigación en Tecnoloxías da Información (CITIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spaina r t i c l e i n f oa b s t r a c tArticle history:Received 31 March 2017Received in revised form 10 November 2017Accepted 4 June 2018Available online 20 June 2018Keywords:AbductionInterpretationTime seriesTemporal abstractionTemporal reasoningNon-monotonic reasoningSignal abstractionTime series interpretation aims to provide an explanation of what is observed in terms of its underlying processes. The present work is based on the assumption that the common classification-based approaches to time series interpretation suffer from a set of inherent weaknesses, whose ultimate cause lies in the monotonic nature of the deductive reasoning paradigm. In this document we propose a new approach to this problem, based on the initial hypothesis that abductive reasoning properly accounts for the human ability to identify and characterize the patterns appearing in a time series. The result of this interpretation is a set of conjectures in the form of observations, organized into an abstraction hierarchy and explaining what has been observed. A knowledge-based framework and a set of algorithms for the interpretation task are provided, implementing a hypothesize-and-test cycle guided by an attentional mechanism. As a representative application domain, interpretation of the electrocardiogram allows us to highlight the strengths of the proposed approach in comparison with traditional classification-based approaches.© 2018 Elsevier B.V. All rights reserved.1. IntroductionThe interpretation and understanding of the behavior of a complex system involves the deployment of a cognitive appara-tus aimed at guessing the processes and mechanisms underlying what is observed. The human ability to recognize patterns plays a paramount role as an instrument for highlighting evidence which should require an explanation, by matching infor-mation from observations with information retrieved from memory. Classification naturally arises as a pattern recognition task, defined as the assignment of observations to categories.Let us first state precisely at this point what is the problem under consideration: we wish to interpret the behavior of a complex system by measuring a physical quantity along time. This quantity is represented as a time series.The Artificial Intelligence community has devoted a great deal of effort on different paradigms, strategies, methodologies and techniques for time series classification. Nonetheless, in spite of the wide range of proposals for building classifiers, ei-ther by eliciting domain knowledge or by induction from a set of observations, the resulting classifiers behaves as deductive system. The present work is premised on the assumption that some of the important weaknesses of this approach lie in its deductive nature, and that an abductive approach can address these shortcomings, which are described below.* Corresponding author.E-mail address: tomas.teijeiro@usc.es (T. Teijeiro).https://doi.org/10.1016/j.artint.2018.06.0050004-3702/© 2018 Elsevier B.V. All rights reserved.\f164T. Teijeiro, P. Félix / Artificial Intelligence 262 (2018) 163–188Let us remember that a deduction contains in its conclusions information that is already implicitly contained in the premises, and thus it is truth-preserving. In this sense, a classifier ultimately assigns a label or a set of labels to observations. This label can designate a process or a mechanism of the system being observed, but it is nothing more than a term that summarizes the premises implied by the observations. Conversely, abduction, or inference to the best explanation, is a form of inference that goes from data to a hypothesis that best explains or accounts for the data [21]. Abductive conclusions contain new information not contained in the premises, and are capable of predicting new evidence, although they are fallible. Abductions are thus truth-widening, and they can make the leap from the language of observations to the language of the underlying processes and mechanisms, responding to the aforementioned problem in a natural way [24]. For example, consider a simple rule stating that if a patient experiences a sudden tachycardia and a decrease in blood pressure, then we can conclude that he or she is suffering from shock due to a loss of blood volume. From a deductive perspective, loss of blood volume is just a name provided by the rule for the satisfaction of the two premises. However, from an abductive perspective, loss of blood volume is an explanatory hypothesis, a conjecture, that expands the truth contained in the premises, enabling the observer to predict additional consequences such as, for example, pallid skin, faintness, dizziness or thirst.Of course, the result of a classifier can be considered as a conjecture, but always from an external agent, since a classifier is monotonic as a logical system and its conclusions cannot be refuted from within. Classifier ensembles aim to overcome the errors of individual classifiers by combining different classification instances to obtain a better result; thus, a classifier can be amended by others in the final result of the ensemble. However, even an ensemble represents a bottom-up mapping, and classification invariably fails above a certain level of distortion within the data. The interpretation and understanding of a complex system usually unfolds along a set of abstraction layers, where at each layer the temporal granularity of the representation is reduced from below. A classification strategy provides an interpretation as the result of connecting a set of classifiers along the abstraction structure, and the monotonicity of deduction entails a propagation of errors from the first abstraction layers upwards, narrowing the capability of making a proper interpretation as new abstraction layers are successively added. Following an abductive process instead, an observation is conjectured at each abstraction layer as the best explanatory hypothesis for the data from the layer or layers below, within the context of information from above, and the non-monotonicity of abduction supports the retraction of any observation at any abstraction layer in the search for the best global explanation. Thus, bottom-up and top-down processing complement one another and provide a joint result. As a consequence, abduction can guess the underlying processes from corrupted data or even in the temporary absence of data.On the other hand, a classifier is based on the assumption that the underlying processes or mechanisms are mutually exclusive. Superpositions of two or more processes are excluded; they must be represented by a new process, corresponding to a new category which is different and usually unrelated to previous ones. Therefore, an artificial casuistry-based heuristics is adopted, increasing the complexity of the interpretation and reducing its adaptability to the variability of observations. In contrast, abduction can reach a conclusion from the availability of partial evidence, refining the result by the incremental addition of new information. This makes it possible to discern different processes just from certain distinguishable features, and at the end to infer a set of explanations as far as the available evidence does not allow us to identify the best one, and they are not incompatible with each other.In a classifier, the truth of the conclusion follows from the truth of all the premises, and missing data usually demand an imputation strategy that results in a conjecture: a sort of abducing to go on deducing. In contrast, an abductive interpretation is posed as a hypothesize-and-test cycle, in which missing data are naturally managed, since a hypothesis can be evoked by every single piece of evidence in isolation and these can be incrementally added to reasoning. This fundamental property of abduction is well suited to the time-varying requirements of the interpretation of time series, where future data can compel changes to previous conclusions, and the interpretation task may be requested to provide the current result as the best explanation at any given time.Abduction has primarily been proposed for diagnostic tasks [10,33], but also for question answering [15], language understanding [22], story comprehension [6], image understanding [36] or plan recognition [28], amongst others. Some studies have proposed that perception might rely on some form of abduction. Even though abductive reasoning has been proven to be NP-complete or worse, a compiled form of abduction based on a set of pre-stored hypotheses could narrow the generation of hypotheses [24]. The present work takes this assumption as a starting point and proposes a model-based abductive framework for time series interpretation supported on a set of temporal abstraction patterns. An abstraction pattern represents a set of constraints that must be satisfied by some evidence in order to be interpreted as the hypothetical observation of a certain process, together with an observation procedure providing a set of measurements for the features of the conjectured observation. A set of algorithms is devised in order to achieve the best explanation through a process of successive abstraction from raw data, by means of a hypothesize-and-test strategy.Some previous proposals have adopted a non-monotonic schema for time series interpretation. TrenDx system detects significant trends in time series by matching data to predefined trend patterns [19,20]. One of these patterns plays the role of the expected or normal pattern, and the other patterns are fault patterns. A matching score of each pattern is based",
            {
                "entities": [
                    [
                        3318,
                        3346,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 245–269Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConformant plans and beyond: Principles and complexityBlai BonetDepartamento de Computación, Universidad Simón Bolívar, Caracas 89000, Venezuelaa r t i c l ei n f oa b s t r a c tArticle history:Received 16 September 2008Received in revised form 29 October 2009Accepted 29 October 2009Available online 3 November 2009Keywords:PlanningComplexity of planningPartially-observable planningNon-deterministic planningModal logicConformant planning is used to refer to planning for unobservable problems whosesolutions, like classical planning, are linear sequences of operators called linear plans.The term ‘conformant’ is automatically associated with both the unobservable planningmodel and with linear plans, mainly because the only possible solutions for unobservableproblems are linear plans. In this paper we show that linear plans are not only meaningfulfor unobservable problems but also for partially-observable problems. In such case, theexecution of a linear plan generates observations from the environment which must becollected by the agent during the execution of the plan and used at the end in order todetermine whether the goal had been achieved or not; this is the typical case in problemsof diagnosis in which all the actions are knowledge-gathering actions.Thus, there are substantial differences about linear plans for the case of unobservableor fully-observable problems, and for the case of partially-observable problems: whilelinear plans for the former model must conform with properties in state space, linearplans for partially-observable problems must conform with properties in belief space.This differences surface when the problems are allowed to express epistemic goals andconditions using modal logic, and place the plan-existence decision problem in differentcomplexity classes.Linear plans is one extreme point in a discrete spectrum of solution forms for planningproblems. The other extreme point is contingent plans in which there is a branch point forevery possible observation at each time step, and thus the number of branch points is notbounded a priori. In the middle of the spectrum, there are plans with a bounded numberof branch points. Thus, linear plans are plans with zero branch points and contingent plansare plans with unbounded number of branch points.In this work, we lay down foundations and principles for the general treatment of linearplans and plans of bounded branching, and provide exact complexity results for noveldecision problems. We also show that linear plans for partially-observable problems arenot only of theoretical interest since some challenging real-life problems can be dealt withthem.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConsider the game of Mastermind which is a two-person code-breaking game played by the codemaker and the code-breaker. The game begins when the codemaker chooses a secret code, made of 4 pegs colored from 6 available colors(repetitions allowed), and the task of the codebreaker is to discover the code by questioning the codemaker and assessinghis answers. Each question, called a guess, is also a sequence of 4 colored pegs that is answered by the codemaker withtwo tokens of information: first the number of exact matches in the guess, i.e. the number of pegs of the right color andE-mail address: bonet@ldc.usb.ve.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.11.001\f246B. Bonet / Artificial Intelligence 174 (2010) 245–269Fig. 1. Optimal contingent plan for Mastermind with 3 pegs and 3 colors.in the right position, and second the number of near matches in the guess, i.e. the number of pegs of the right color butin wrong position. The codebreaker wins if he can discover the secret code in at most 10 guesses, otherwise the codemakerwins. This popular game has captivated the attention of millions of people [60] including some renowned mathematicians[14,18,37,38].The game proceeds in guess-and-answer stages in which a guess may depend on the information acquired during theprevious stages. A winning strategy for Mastermind can be depicted as a tree whose nodes are the subsets of the possiblesecret codes at a given stage. For example, the root node is the set of 64 = 1296 possible secret codes since, at the beginning,the codebreaker has no information whatsoever. Each internal node of the tree is labeled with the guess to be done in casethe game reaches that stage, and for each possible answer to the guess, there is a child node that corresponds to the subsetof secret codes compatible with the answer. The leaves of the tree are nodes that correspond to singletons since theserepresent stages of the game at which the codebreaker has discovered the secret code.Fig. 1, for example, depicts an optimal strategy for a game of Mastermind with 3 pegs and 3 colors. Although the labelson the edges that tell the possible answers to the guesses are not shown, the important thing to note is the form of thesolution, i.e. its tree structure.The game of Mastermind can be cast as a non-deterministic planning problem with partial observability, and hencesolutions can be obtained with planners that perform search in belief space. Indeed, subsets of possible states (secret codesin Mastermind) are called belief states, and solutions like Fig. 1 are called contingent plans in belief space or contingentplans with partial observability. In general, if b is a belief state in the solution graph, o is an operator applicable at b, andz1, . . . , zn are the possible observations obtainable after the application of the operator o at b, then the children of b in thesolution graph are the beliefs bz1o denotes the belief that results after applying o at b and observing zi .o where bzio , . . . , bznThere are natural variations of the game such as the ones that result by increasing the number of colors in the secretcode or the number of available colors to choose from. However, there is a more interesting variation that is known asstatic Mastermind [14,23]. In this variation, the codebreaker is asked to give ahead a linear sequence of guesses such thatthe secret code can be determined from the answers upon such guesses. For example, for a game with 3 pegs and 3 colors,the sequence(cid:3)(cid:2)guess(2, 0, 0), guess(2, 1, 0), guess(2, 2, 1)σ =is guaranteed to succeed independently of the chosen secret code. Moreover, its length is minimum among all such se-quences, and hence corresponds to an optimal sequence. Also observe that the length of σ is greater than or equal to thelength of any branch in the optimal contingent plan in Fig. 1; this is not a coincidence since the sequence σ must discoverthe secret code independently of its value.We call a sequence like σ a linear or conformant plan for a partially-observable problem. Linear plans had beenstudied before in the context of unobservable planning by the name of conformant planning [16,21,24,30,57]. Unlikepartially-observable problems like Mastermind, unobservable problems only admit linear plans as solutions, since underthe hypothesis of null observability, the decision maker has no available input on which to base his decisions. In unobserv-able problems, a linear plan generates a collection of trajectories that result from the uncertainty in the initial state and thenon-determinism in the actions of the problem. A linear plan is a valid plan when each trajectory that starts at an initialstate ends in a goal state. This is the reason for the name ‘conformant’ as it means that the trajectories generated by theplan conform with the goal of the problem.\fB. Bonet / Artificial Intelligence 174 (2010) 245–269247Until now, linear plans had been only generally considered for unobservable planning problems. However, as the ex-ample of Mastermind shows, it also makes sense to consider linear plans for problems with partial observability (andalso for problems with full observability). Hence, we think that the term ‘conformant’ has been improperly used torefer to two different things: a class of solutions, namely linear plans, and to the class of unobservable planning prob-lems.In fully-observable domains, a linear plan does not make use of the information available at each time step as the plandetermines the actions to do at each step independently of contingencies. Thus, this case is essentially the same as theunobservable one and, from now on, we treat unobservable problems as non-deterministic fully-observable problems forwhich only linear plans are acceptable. In partially-observable domains, a linear plan also dictates the actions to do ateach time step, without deviating from a unique line of execution, yet there is an important difference with respect to theformer case as now the decision maker must collect the observations generated during the application of the plan in orderto achieve the goal at the end of the plan.There are substantial differences between the cases of linear plans for fully-observable and partially-observable domains.The first important difference is about the guarantees offered by such a plan. In the former case, the agent has the guaran-tee that the last state after the application of the plan will be a goal state. In the latter case however, as illustrated in theexample of Mastermind, the agent has the guarantee that after applying the plan and collecting the observations generatedalong, he will have enough information to achieve the goal, e.g., computing the secret code in Mastermind. Hence, while con-formance in fully-observable domains is about the compliance of a set trajectories in state space, conformance for partially-observabledomains is about the compliance of a set of trajectories in belief space.The second important difference appears when studying the computational complexity of decision problems for bothnotions of conformance: ",
            {
                "entities": [
                    [
                        3540,
                        3568,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1722–1736Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms and complexity results for persuasive argumentation ✩,✩✩Eun Jung Kim a, Sebastian Ordyniak b, Stefan Szeider b,∗a AlGCo project-team, CNRS, LIRMM, Montpellier, Franceb Institute of Information Systems, Vienna University of Technology, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 1 October 2010Received in revised form 2 March 2011Accepted 4 March 2011Available online 8 March 2011Keywords:Abstract argumentationValue-based argumentation frameworksComputational complexityGraphical modelsBounded treewidthThe study of arguments as abstract entities and their interaction as introduced byDung (1995) [1] has become one of the most active research branches within ArtificialIntelligence and Reasoning. A main issue for abstract argumentation systems is theselection of acceptable sets of arguments. Value-based argumentation, as introduced byBench-Capon (2003) [8], extends Dung’s framework. It takes into account the relativestrength of arguments with respectto some ranking representing an audience: anargument is subjectively accepted if it is accepted with respect to some audience, it isobjectively accepted if it is accepted with respect to all audiences.Deciding whether an argument is subjectively or objectively accepted, respectively, arecomputationally intractable problems.In fact, the problems remain intractable understructural restrictions that render the main computational problems for non-value-basedargumentation systems tractable. In this paper we identify nontrivial classes of value-basedargumentation systems for which the acceptance problems are polynomial-time tractable.The classes are defined by means of structural restrictions in terms of the underlyinggraphical structure of the value-based system. Furthermore we show that the acceptanceproblems are intractable for two classes of value-based systems that where conjectured tobe tractable by Dunne (2007) [12].© 2011 Elsevier B.V. All rights reserved.1. IntroductionThe study of arguments as abstract entities and their interaction as introduced by Dung [1] has become one of the mostactive research branches within Artificial Intelligence and Reasoning, see, e.g., [2–4]. Argumentation handles possible con-flicts between arguments in form of attacks. The arguments may either originate from a dialogue between several agents orfrom the pieces of information at the disposal of a single agent, this information may even contain contradictions. A mainissue for any argumentation system is the selection of acceptable sets of arguments, where an acceptable set of argumentsmust be in some sense coherent and be able to defend itself against all attacking arguments. Abstract argumentation pro-vides suitable concepts and formalisms to study, represent, and process various reasoning problems most prominently indefeasible reasoning (see, e.g., [5,6]) and agent interaction (see, e.g., [7]).Extending Dung’s concept, Bench-Capon [8] introduced value-based argumentation systems that allow to compare argu-ments with respect to their relative strength such that an argument cannot successfully attack another argument that isconsidered of a higher rank. The ranking is specified by the combination of an assignment of values to arguments and an✩Ordyniak and Szeider’s research was supported by the European Research Council, grant reference 239962. Kim’s research was partially supported bythe EPSRC, grant reference EP/E034985/1.✩✩A preliminary and shortened version of this paper appeared in COMMA 2010.* Corresponding author.E-mail address: stefan@szeider.net (S. Szeider).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.001\fE.J. Kim et al. / Artificial Intelligence 175 (2011) 1722–17361723ordering of the values; the latter is called an audience [9]. As laid out by Bench-Capon, the role of arguments in this settingis to persuade rather than to prove, demonstrate or refute. Whether an argument can be accepted with respect to all possibleor at least one audience allows to formalize the notions of objective acceptance and subjective acceptance, respectively.An important limitation for using value-based argumentation systems in real-world applications is the computationalintractability of the two basic acceptance problems: deciding whether a given argument is subjectively accepted is NP-hard, deciding whether it is objectively accepted is co-NP-hard [10]. Therefore it is important to identify classes of value-based systems that are still useful and expressible but allow a polynomial-time tractable acceptance decision. However,no nontrivial tractable classes of value-based systems have been identified so far, except for systems with a tree structurewhere the degree of nodes and the number of nodes of degree exceeding 2 are bounded [11]. In fact, as pointed out byDunne [12], the acceptance problems remain intractable for value-based systems whose graphical structures form trees, instrong contrast to the main computational problems for non-value-based argumentation that are linear-time tractable fortree systems, or more generally, for systems of bounded treewidth [12].1.1. Our contributionIn this paper we introduce nontrivial classes of value-based systems for which the acceptance problems are tractable.The classes are defined in terms of the following notions:• The value-width of a value-based system is the largest number of arguments of the same value.• The extended graph structure of a value-based system has as nodes the arguments of the value-based system, two argu-ments are joined by an edge if either one attacks the other or both share the same value.• The value graph of a value-based system has as vertices the values of the system, two values v 1 and v 2 are joined by adirected edge if some argument of value v 1 attacks an argument of value v 2 [11].We show that the acceptance problems are tractable for the following classes of value-based systems:(P1) value-based systems with a bipartite graph structure where at most two arguments share the same value (i.e., systemsof value-width 2);(P2) value-based systems whose extended graph structure has bounded treewidth; and(P3) value-based systems of bounded value-width whose value graphs have bounded treewidth.In fact, we show that both acceptance problems are linear-time tractable for the classes (P2) and (P3), the latter beinga subclass of the former. Our results suggest that the extended graph structure is a suitable structural representation ofvalue-based argumentation systems. The positive results (P1)–(P3) hold for systems with unbounded number of arguments,attacks and values.We contrast our positive results with negative results that rule out classes conjectured to be tractable. We show that theacceptance problems are (co)-NP-hard for the following classes:(N1) value-based systems of value-width 2;(N2) value-based systems where the number of attacks between arguments of the same value is bounded (systems ofbounded attack-width);(N3) value-based systems with bipartite value graphs.In fact, we show that both acceptance problems are intractable for value-based systems of value-width 2 and attack-width 1.Classes (N1) and (N2) were conjectured to be tractable [12], the complexity of (N3) was stated as an open problem [11].The reminder of the paper is organized as follows. In Section 2 we provide basic definitions and preliminaries. In Sec-tion 3 we define the parameters value-width and attack-width and establish the results involving systems of value-width 2,we also discuss the relationship between systems of value-width 2 and dialogues [9]. In Section 4 we consider value-basedsystems with an extended graph structure of bounded treewidth and show linear-time tractability. We close in Section 5with concluding remarks. Some proofs of technical lemmas are given in Appendix A.The main results of this paper have been presented in preliminary and shortened form at COMMA’10 [13]. Here weprovide full proofs, examples, and additional discussions. Further new additions are the results (P3) and (N3) involvingvalue graphs, and the discussion of the relationship between systems of value-width 2 and dialogues.2. Arguments, attacks, values, and audiencesIn this section we introduce the objects of our study more formally.2.1. Abstract argumentation systemDefinition 1. An abstract argumentation system or argumentation framework is a pair ( X, A) where X is a finite set of elementscalled arguments and A ⊆ X × X is a binary relation called the attack relation. If (x, y) ∈ A we say that x attacks y.\f1724E.J. Kim et al. / Artificial Intelligence 175 (2011) 1722–1736Fig. 1. The abstract argumentation system F 0 and value-based system F of Examples 1 and 2, respectively.An abstract argumentation system F = ( X, A) can be considered as a directed graph, and therefore it is convenient toborrow notions and notation from the theory of directed graphs [14]. For example we say that a system F = ( X, A) is acyclicif ( X, A) is a DAG (a directed acyclic graph).Example 1. An abstract argumentation system F 0 = ( X, A) with arguments X = {a, b, c, d, e, f } and attacks A = {(a, d), (a, e),(b, a), (c, d), (d, b), ( f , c)} is displayed in Fig. 1.Next we define commonly used semantics of abstract argumentation systems as introduced by Dung [1]. For thediscussion of other semantics and variants, see, e.g., Baroni and Giacomin’s survey [15]. Let F = ( X, A) be an abstractargumentation system and S ⊆ X .1. S is conflict-free in F if there is no (x, y) ∈ A with x, y ∈ S.2. S is acceptable in F if for each x ∈ S and each y ∈ X with ( y, x) ∈ A there is some x3. S is admissible in F if it is conflict-free and acceptable.4. S is a preferred extension of F if S is admissible in F and there is no admissible set S(cid:5) ∈ S with (x(cid:5), y) ∈ A.(cid:5)of F that properly con",
            {
                "entities": [
                    [
                        3799,
                        3827,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 20–50Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSolving coalitional resource gamesPaul E. Dunne b, Sarit Kraus a,c,∗, Efrat Manisterski a, Michael Wooldridge ba Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900, Israelb Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UKc Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 10 April 2008Received in revised form 18 September2009Accepted 22 September 2009Available online 25 September 2009Keywords:Coalitional gamesNTU gamesSolution conceptsThe coreBargainingAlgorithmsComplexity1. IntroductionCoalitional Resource Games (crgs) are a form of Non-Transferable Utility (ntu) game, whichprovide a natural formal framework for modelling scenarios in which agents must poolscarce resources in order to achieve mutually satisfying sets of goals. Although a numberof computational questions surrounding crgs have been studied, there has to date beenno attempt to develop solution concepts for crgs, or techniques for constructing solutions.In this paper, we rectify this omission. Following a review of the crg framework and adiscussion of related work, we formalise notions of coalition structures and the core forcrgs, and investigate the complexity of questions such as determining nonemptiness of thecore. We show that, while such questions are in general computationally hard, it is possibleto check the stability of a coalition structure in time exponential in the number of goalsin the system, but polynomial in the number of agents and resources. As a consequence,checking stability is feasible for systems with small or bounded numbers of goals. Wethen consider constructive approaches to generating coalition structures. We present anegotiation protocol for crgs, give an associated negotiation strategy, and prove that thisstrategy forms a subgame perfect equilibrium. We then show that coalition structuresproduced by the protocol satisfy several desirable properties: Pareto optimality, dummyplayer, and pseudo-symmetry.© 2009 Elsevier B.V. All rights reserved.There is currently much interest in the possibility of delegating complex tasks to semi-autonomous software agents[34,37]. A highly desirable requirement for such domains is that the agents should be able to reach agreements with one-another on matters of common interest. For example, in order to accomplish the goals that they have been delegated, agentsmay need to share a scarce resource, work together to achieve a common goal, or come to a common understanding abouta disputed domain of discourse. This requirement has motivated work in automated negotiation [22,28], online auctions [11]and computational social choice theory [15].In this paper, our interest lies in domains with the following characteristics:We desire some goal to be achieved, and delegate the goal to an agent, along with some bundle of resources, which may be expendedby the agent in order to accomplish the goal. Accomplishing the goal may require resources not possessed by the agent, promptingthe need for cooperation. A group of agents will thus pool resources to accomplish a set of goals to the satisfaction of all contributors.Our primary aim is for the agent to satisfy our goal, and to this end, if it is necessary to expend all the resources we endow it with,* Corresponding author.E-mail addresses: ped@csc.liv.ac.uk (P.E. Dunne), sarit@macs.biu.ac.il (S. Kraus), mjw@csc.liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.09.005\fP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5021then this is acceptable. However, if there are multiple ways of satisfying the goal, we desire that the agent should minimize resourceusage.The formal model we use to capture such scenarios is a refinement of the Coalitional Resource Games (crgs) framework,which was introduced in [39]. In a crg, each agent has a set of goals, and is endowed with some quantity of resources;each goal requires a specified quantity of each resource in order to accomplish it. The main change to the basic crg modelthat we make here is to introduce the idea of preferring outcomes that minimize resource consumption. To capture thesepreferences, we introduce costs: the cost to an agent of a particular scenario is simply the sum of the resource quantities itcontributes in this scenario.Many important real world scenarios seem to fit within this model. Consider agents that support arranging carpoolschemes.1The idea in a carpool scheme is to encourage people who live and work close to each other to share cars to and from work, ratherthan each driving their own car. We model car pooling in our framework as follows. A possible goal of an agent is arrangingtransportation for all necessary days and times. An agent may have more than one possible goal when the transportation can beon different possible days (e.g., a worker might visit the main office on either Monday or Wednesday). The resources are places incars for specific days, origin, destination, and time. An agent would prefer that another agent provides a ride, if possible, even if heis available on that day and has the car, since this will save his resources.One characteristic of our domains is that utility is non-transferable. In cooperative games with transferable utility, thevalue of a coalition is simply a real number, corresponding to payoff that can be divided amongst coalition members in anyway they see fit [25, p. 257]. In such games, utility is transferable because it can be transferred between coalition members.Most existing work in multi-agent negotiation and resource allocation assumes transferable utility [22,28]. The rationalefor our choice is that there are domains in which utility is non transferable, which is why non-transferable utility games(ntu games) have been studied in the literature [25, p. 268]. As an example with respect to our domain, when scientistscollaborate on a joint paper, the resources they contribute include their experience and expertise. Such resources are noteasy to value or trade explicitly, and the utility that one scientist gets from publishing a paper cannot usually be transferredto those that he or she cooperated with. (We elaborate on this issue in more detail in Section 3.)We emphasise that the scenarios we consider typically require cooperation: it is not in general the case that an agentcan achieve its goals in isolation, and will need to cooperate with others in order to do so. The possible outcomes of thesecooperative games are structures in which coalitions commit to achieve certain goals, and in which members of a coalitioneach commit to contribute some part of their resource endowment. Presented with a number of different possible outcomes,we want an agent to choose one that achieves its delegated goal while minimizing the cost to itself (i.e., minimizes thequantity of resources that it contributes). Given that we are in the realm of cooperative games, a number of issues thussuggest themselves for consideration [29]: Which coalitions will form? And how will these coalitions choose an outcomefrom those that are available to them, given the different preferences that agents have over outcomes?With respect to the former question, we formalise the core for our domain, and investigate the complexity of severalquestions surrounding the core. We show that it is co-np-complete to check whether a particular outcome is in the coreof a game, while it is co-np-hard to check whether the core is non-empty, or to check whether the core is non-emptyand contains a non-trivial outcome. However, as we will see, the core may be empty even with quite strong constraints ongames, and this motivates us to consider other types of outcomes.Our second contribution is to consider a constructive, bargaining-based approach to coalition structure generation.We present a negotiation protocol for the domain, and investigate its properties. Using backward induction, we derivestrategies that are in subgame perfect equilibrium, and prove that outcomes generated will, on average, satisfy three de-sirable properties: pseudo-symmetry, dummy player, and Pareto optimality. Although n-agent bargaining for ntu gameshas been considered in the game theory literature [16], there has been little work on this in computer science/ai (seee.g., [7]).A comment on notation and proofs. The remainder of the paper makes use of much notation, and for the reader’s conve-nience, we summarise the main notations used in Appendix A. In addition, in the interests of readability, we omit all longerproofs from the main text, presenting them instead in Appendix B.1 This is not a frivolous example: car pooling is a major activity, heavily promoted by some national governments as a means of reducing road traffic(and hence pollution, etc.). See, for example:http://www.carpoolworld.com/.Carpools have already been the subject of study using coalitional games, although from a somewhat different (more abstract) perspective than the presentpaper [24].\f22P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–502. Background and related workIf we are to build computer programs that can cooperate with each other, then it is natural to ask what models havebeen previously developed to model cooperative scenarios. Game theory is a valuable source of models for multi-agentsystems in general, and cooperative game theory in particular studies cooperation, addressing itself to such problems as whowill cooperate with who (i.e., which coalitions will form), and how such coalitions will share the benefits of cooperation.Within cooperative game theory, perhaps the simplest, best-known, and most widely studied model of cooperative gamesis the coalitional game with transferable utility [2",
            {
                "entities": [
                    [
                        3713,
                        3741,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 738–771www.elsevier.com/locate/artintSolving quantified constraint satisfaction problems ✩Ian P. Gent a, Peter Nightingale a, Andrew Rowley a, Kostas Stergiou b,∗a School of Computer Science, University of St Andrews, St Andrews, Fife, KY16 9SS, UKb Department of Information and Communication Systems Engineering, University of the Aegean, GreeceReceived 15 August 2006; received in revised form 2 April 2007; accepted 5 November 2007Available online 22 November 2007AbstractWe make a number of contributions to the study of the Quantified Constraint Satisfaction Problem (QCSP). The QCSP is anextension of the constraint satisfaction problem that can be used to model combinatorial problems containing contingency oruncertainty. It allows for universally quantified variables that can model uncertain actions and events, such as the unknown weatherfor a future party, or an opponent’s next move in a game. In this paper we report significant contributions to two very differentmethods for solving QCSPs. The first approach is to implement special purpose algorithms for QCSPs; and the second is to encodeQCSPs as Quantified Boolean Formulas and then use specialized QBF solvers. The discovery of particularly effective encodingsinfluenced the design of more effective algorithms: by analyzing the properties of these encodings, we identify the features in QBFsolvers responsible for their efficiency. This enables us to devise analogues of these features in QCSPs, and implement them inspecial purpose algorithms, yielding an effective special purpose solver, QCSP-Solve. Experiments show that this solver and ahighly optimized QBF encoding are several orders of magnitude more efficient than the initially developed algorithms. A final,but significant, contribution is the identification of flaws in simple methods of generating random QCSP instances, and a means ofgenerating instances which are not known to be flawed.© 2007 Elsevier B.V. All rights reserved.Keywords: Quantified constraint satisfaction problems; Quantified Boolean formulas; Arc consistency; Search algorithms; Random problems1. IntroductionQuantified Constraint Satisfaction Problems (QCSPs) can be used to model various PSPACE-complete combina-torial problems from domains like planning under uncertainty, design, adversary game playing, and model checking.For example, in game playing we may want to determine if a consistent strategy exists for all possible moves of theopponent. In a design problem it may be required that a configuration must be possible for all possible sequences ofuser choices. As a final example, when planning in a safety critical environment, such as a nuclear station, we may✩ Parts of this paper have appeared in the conference papers [I. Gent, P. Nightingale, A. Rowley, Encoding quantified CSPs as quantified Booleanformulae, in: Proceedings of ECAI-2004, 2004, pp. 176–180; I. Gent, P. Nightingale, K. Stergiou, QCSP-Solve: A solver for quantified constraintsatisfaction problems, in: Proceedings of IJCAI-2005, 2005].* Corresponding author.E-mail addresses: ipg@dcs.st-and.ac.uk (I.P. Gent), pn@dcs.st-and.ac.uk (P. Nightingale), agdr@dcs.st-and.ac.uk (A. Rowley),konsterg@aegean.gr (K. Stergiou).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.003\fI.P. Gent et al. / Artificial Intelligence 172 (2008) 738–771739require that an action is possible for every eventuality. QCSPs extend traditional, unquantified, CSPs to deal with thekind of contingency found in the above examples.The QCSP naturally generalizes the standard CSP formalism by allowing for universally quantified variables.Universal variables are used to model actions or events which are contingent, for which we are uncertain, or justthose which are not in our control. Examples would be contingencies such as user choices in a configuration problem,uncertainties such as the weather in a plan to hold a garden party, or opponent moves in an adversary game. In aconventional CSP, all variables are existentially quantified, since all are within our control. The values in the domainof a universal variable capture all the possible outcomes of the event or action modelled by this variable. In this way,QCSPs model bounded uncertainty. In a QCSP we try to find a strategy, defining the values of the existential variablesfor all possible sequences of instantiations for the universal variables, so that all the constraints in the problem aresatisfied. Such a strategy guarantees that there is a solution whatever values the universal variables take, i.e. whateverthe outcome of the uncertain actions and events. The generalization of CSPs to QCSPs increases the expressiveness ofthe framework, but at the same time the complexity of the decision task rises from NP-complete to PSPACE-complete[8,26,38].There is already considerable interest in quantified constraint reasoning in the case of Quantified Boolean Formulae(QBF), which is the generalization of SAT that allows universal quantification (for example, [13,23,29,32,33]). Also,there is a significant body of work on quantified problems with continuous real domains (e.g. [5,41]). Ratschan givesnumerous references to papers on this subject [40]. As far as QCSPs with discrete finite non-Boolean domains areconcerned, there is recent research on theory defining the complexity of various reasoning tasks and also specifyingtractable subclasses (e.g. [8,11,15–18]). Also, various useful concepts from CSPs, such as global and local consistency,substitutability and interchangeability, have been defined for QCSPs [11,12]. However, little has been done as faras algorithms for solving QCSPs are concerned. In the few existing works, Bordeaux and Monfroy introduced aframework for implementing arc consistency and described filtering operators for certain classes of constraints [9,12]. Also, very recently, Verger and Bessière proposed a bottom-up solver for QCSPs called BlockSolve [44], whileBenedetti, Lallouet and Vautard implemented QeCode, a QCSP solver built on top of the CSP solver Gecode [4].In this paper we report the first comprehensive attempt to build effective QCSP solvers, although we limit ourselvesto the case where constraints are binary. We make contributions to two very different approaches to solving QCSPs.These are special purpose solvers for QCSPs; and encoding QCSPs as QBF instances so that existing QBF solverscan be used. In each approach we introduce novel and effective techniques. We also show how experience with theencodings directly influenced the design of better techniques for the specialized solvers.We first approach QCSPs directly by extending well-known algorithms from the standard to the quantified case.This is analogous to the approach taken at the early stages of research in QBF. We show that some of the most widelyused techniques for CSPs can be adapted to deal with quantification. We first describe a generic arc consistencyalgorithm that can be used to enforce AC in any binary QCSP. We then extend the chronological backtracking (BT),forward checking (FC), and maintaining arc consistency (MAC) algorithms so that they can handle quantification. Wealso propose modifications of FC and MAC that take advantage of the properties of QCSPs.Then we follow an orthogonal approach, based on encoding QCSPs as QBFs. A particular advantage of encod-ing one search problem as another occurs when, as here, search techniques for the target problem are more highlydeveloped than the original. In contrast to QCSP, numerous advanced solvers are available for QBF. We describe afinely-tuned encoding which can be several orders of magnitudes more efficient than the direct methods described sofar. The tuning of encodings to be effective for search is considerably more involved than in the case of SAT, whereencodings often have an elegant simplicity. A simple way of lifting CSP encodings to QCSP is very ineffective, so weexplore and implement new ideas, without analogues in SAT, that make search very effective.Apart from obtaining efficient tools for QCSP solving, we benefit from the study and development of encodings tolearn valuable lessons that can be transferred to direct algorithms. So in the third, and final, stage in the developmentof algorithms for QCSPs we analyze the advantages offered by our QBF encoding to identify the features responsi-ble for its efficiency. We identify three sophisticated techniques; conflict-based backjumping [39], solution-directedbackjumping [32], and most importantly, the pure literal rule [14], as important reasons for the success of QBF solversin solving encoded QCSP instances. We devise analogues of these features in QCSPs, and implement them on top ofdirect algorithms, to yield a specialized direct solver, called QCSP-Solve.A final issue we address in this paper is that of benchmarking, since there is naturally a distinct lack of benchmarksto compare algorithms on. This is a familiar problem that has appeared in the early stages of experimental research\f740I.P. Gent et al. / Artificial Intelligence 172 (2008) 738–771in various other areas. As was the case with CSP, SAT, and QBF, we address this problem by proposing and usingmethods to generate random instances. We show that a simple generalization of random generation models fromCSPs or QBF to QCSPs is prone to flaws, which quickly affect all generated instances. We then introduce a randomgenerator that is free from these flaws, although it remains possible that it will suffer from a currently unknown flaw.Experiments run on problems created using this generator reveal a progressive, and dramatic, improvement in theefficiency of our methods; starting with the initial direct algorithms and culminating in QCSP-Solve and a highlyoptimized QBF encoding.This paper is structured as follows. In Section 2 we give the necessary definitions and background. We then presentprogressively more efficient methods of handling",
            {
                "entities": [
                    [
                        3316,
                        3344,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1406–1423Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEncoding deductive argumentation in quantified Boolean formulaePhilippe Besnard a, Anthony Hunter b,∗, Stefan Woltran ca IRIT-CNRS, Universitè Paul Sabatier, 118 rte de Narbonne, 31062 Toulouse, Franceb Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UKc Institute for Information Systems 184/2, Technische Universität Wien, Favoritenstrasse 9-11, 1040 Vienna, Austriaa r t i c l ei n f oa b s t r a c tThere are a number of frameworks for modelling argumentation in logic. They incorporatea formal representation of individual arguments and techniques for comparing conflictingarguments. A common assumption for logic-based argumentation is that an argument is apair (cid:3)(cid:2), α(cid:4) where (cid:2) is minimal subset of the knowledge-base such that (cid:2) is consistentand (cid:2) entails the claim α. Different logics provide different definitions for consistency andentailment and hence give us different options for argumentation. Classical propositionallogic is an appealing option for argumentation but the computational viability of generatingan argument is an issue. To better explore this issue, we use quantified Boolean formulaeto characterise an approach to argumentation based on classical logic.© 2009 Elsevier B.V. All rights reserved.Article history:Received 27 January 2009Received in revised form 12 May 2009Accepted 25 June 2009Available online 27 June 2009Keywords:Argument systemsArgumentationClassical logicInconsistencyQuantified Boolean formulaeConflicting knowledge1. IntroductionArgumentation is a vital aspect of intelligent behaviour by humans. Consider diverse professionals such as politicians,journalists, clinicians, scientists, and administrators, who all need to collate and analyse information looking for pros andcons for consequences of importance when attempting to understand problems and make decisions.There is a range of proposals for logic-based formalisations of argumentation (for reviews see [8,13,31]). These proposalsallow for the representation of arguments for and against some claim, and for counterargument relationships betweenarguments.In a number of key proposals for argumentation, an argument is a pair where the first item in the pair is a consistentset (or a minimal consistent set) of formulae that proves the second item which is a formula (see for example [1,5,7,15,24,26,30]). Hence, different underlying logics provide different definitions for consistency and entailment and hence give usdifferent options for defining the notion of an argument.Since classical logic has many advantages for representing and reasoning with knowledge including syntax, proof theoryand semantics for the intuitive language incorporating negation, conjunction, disjunction and implication, it is an interestingand promising choice for the underlying logic for argumentation. However, it is computationally challenging to generatearguments from a knowledge-base using classical logic. If we consider the problem as an abduction problem, where weseek the existence of a minimal subset of a set of formulae that implies the consequent, then the problem is in the secondlevel of the polynomial hierarchy [23]. Furthermore, given a knowledge-base (cid:4) and a formula α, it has been shown thatascertaining whether there is a subset (cid:2) of (cid:4) such that (cid:3)(cid:2), α(cid:4) is an argument (i.e. (cid:2) is consistent, (cid:2) entails α, and thereis no subset of (cid:2) that entails α) is a (cid:5) p2 -complete decision problem [29].* Corresponding author.E-mail address: A.Hunter@cs.ucl.ac.uk (A. Hunter).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.006\fP. Besnard et al. / Artificial Intelligence 173 (2009) 1406–14231407Beyond these observations, there remains a range of further important computational complexity questions. So to betterunderstand the use of classical logic in argumentation, and in particular to understand its computational properties, weuse quantified Boolean formulae (QBFs) to characterise an approach to argumentation that is based on classical logic. Thischaracterisation can then be used to obtain computational complexity results in terms of upper bounds.A further reason to characterise logic-based argumentation in the form of QBFs is that we can then harness implementa-tions of QBF solvers to develop prototype implementations for logic-based argumentation. There are numerous QBF solversavailable (see, e.g, [28] and the references therein), and the encodations we present in this paper can be straightforwardlyhandled in them.2. Preliminaries2.1. Logical argumentationIn this section we review an existing proposal for logic-based argumentation [7]. We consider a classical propositionallanguage. We use α, β, γ , . . . to denote formulae and (cid:4), (cid:2), (cid:8), . . . to denote sets of formulae. Deduction in classical propo-sitional logic is denoted by the symbol (cid:5) and deductive closure by Th so that Th((cid:2)) = {α | (cid:2) (cid:5) α}.For the following definitions, we first assume a knowledge-base (cid:4) (a finite set of formulae) and use this (cid:4) throughout.We further assume that every subset of (cid:4) is given an enumeration (cid:3)α1, . . . , αn(cid:4) of its elements, which we call its canonicalenumeration. This really is not a demanding constraint: In particular, the constraint is satisfied whenever we impose anarbitrary total ordering over (cid:4). Importantly, the order has no meaning and is not meant to represent any respective impor-tance of formulae in (cid:4). It is only a convenient way to indicate the order in which we assume the formulae in any subset of(cid:4) are conjoined to make a formula logically equivalent to that subset.The paradigm for the approach is a large repository of information, represented by (cid:4), from which arguments can beconstructed for and against arbitrary claims. Apart from information being understood as declarative statements, there is noa priori restriction on the contents, and the pieces of information in the repository can be as complex as possible. Therefore,(cid:4) is not expected to be consistent. It need not even be the case that every single formula in (cid:4) is consistent.The framework adopts a very common intuitive notion of an argument. Essentially, an argument is a set of relevantformulae that can be used to classically prove some claim, together with that claim. Each claim is represented by a formula.Definition 1. An argument is a pair (cid:3)(cid:2), α(cid:4) such that: (1) (cid:2) ⊆ (cid:4); (2) (cid:2) (cid:7)(cid:5) ⊥; (3) (cid:2) (cid:5) α; and (4) there is no (cid:2)(cid:9) ⊂ (cid:2) suchthat (cid:2)(cid:9) (cid:5) α. We say that (cid:3)(cid:2), α(cid:4) is an argument for α. We call α the claim (or consequent) of the argument and (cid:2) thesupport of the argument (we also say that (cid:2) is a support for α).Example 1. Let (cid:4) = {α, α → β, γ → ¬β, γ , δ, δ → β, ¬α, ¬γ }. Some arguments are:(cid:2)(cid:2)(cid:2)(cid:2)(cid:3)(cid:3){α, α → β}, β{¬α}, ¬α{α → β}, ¬α ∨ β{¬γ }, δ → ¬γ(cid:3).(cid:3)By monotonicity of classical logic the following equivalent characterisation easily follows.Proposition 1. A pair (cid:3)(cid:2), α(cid:4) is an argument iff it satisfies (1)–(3) from Definition 1 together with (4(cid:9)) for each φ ∈ (cid:2), ((cid:2) \\ {φ}) (cid:7)(cid:5) α.Arguments are not independent. In a sense, some encompass others (possibly up to some form of equivalence). To clarifythis requires a few definitions as follows.Definition 2. An argument (cid:3)(cid:2), α(cid:4) is more conservative than an argument (cid:3)(cid:8), β(cid:4) iff (cid:2) ⊆ (cid:8) and β (cid:5) α.Example 2. (cid:3){α}, α ∨ β(cid:4) is more conservative than (cid:3){α, α → β}, β(cid:4).Definition 3. An argument (cid:3)(cid:2), α(cid:4) is strictly more conservative than an argument (cid:3)(cid:8), β(cid:4) iff (cid:2) ⊆ (cid:8), β (cid:5) α, and either (cid:8) (cid:7)⊆ (cid:2)or α (cid:7)(cid:5) β.Some arguments directly oppose the support of others, which amounts to the notion of an undercut.Definition 4. An undercut for an argument (cid:3)(cid:2), α(cid:4) is an argument (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) where {φ1, . . . , φn} ⊆ (cid:2).\f1408P. Besnard et al. / Artificial Intelligence 173 (2009) 1406–1423Example 3. Let (cid:4) = {α, α → β, γ , γ → ¬α}. Then, (cid:3){γ , γ → ¬α}, ¬(α ∧ (α → β))(cid:4) is an undercut for (cid:3){α, α → β}, β(cid:4). A lessconservative undercut for (cid:3){α, α → β}, β(cid:4) is (cid:3){γ , γ → ¬α}, ¬α(cid:4).Definition 5. (cid:3)(cid:8), β(cid:4) is a maximally conservative undercut for (cid:3)(cid:2), α(cid:4) iff (cid:3)(cid:8), β(cid:4) is an undercut for (cid:3)(cid:2), α(cid:4) such that noundercuts of (cid:3)(cid:2), α(cid:4) are strictly more conservative than (cid:3)(cid:8), β(cid:4).The value of the following definition of canonical undercut is that we only need to take the canonical undercuts intoaccount. This means we can justifiably ignore the potentially very large number of non-canonical undercuts.Definition 6. An argument (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) is a canonical undercut for (cid:3)(cid:2), α(cid:4) iff it is a maximally conservative undercutfor (cid:3)(cid:2), α(cid:4) and (cid:3)φ1, . . . , φn(cid:4) is the canonical enumeration of (cid:2).The next result is central.Proposition 2. (See Theorem 5.4 [7].) A pair (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) is a canonical undercut for (cid:3)(cid:2), α(cid:4) iff it is an undercut for (cid:3)(cid:2), α(cid:4)and (cid:3)φ1, . . . , φn(cid:4) is the canonical enumeration of (cid:2).In other words, the canonical undercuts for (cid:3)(cid:2), α(cid:4) are given by all arguments of the form (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) where(cid:3)φ1, . . . , φn(cid:4) is the canonical enumerat",
            {
                "entities": [
                    [
                        3825,
                        3853,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1460–1480Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAgent decision-making in open mixed networksYa’akov Gal a,b,∗, Barbara Grosz b, Sarit Kraus c,d, Avi Pfeffer e, Stuart Shieber ba Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israelb School of Engineering and Applied Sciences, Harvard University, USAc Computer Science Department, Bar Ilan University, Israeld Institute for Advanced Computer Studies, University of Maryland, USAe Charles River Analytics, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 14 December 2008Received in revised form 18 August 2010Accepted 27 August 2010Available online 21 September 2010Keywords:Human–Computer decision-makingNegotiationComputer systems increasingly carry out tasks in mixed networks, that is in group set-tings in which they interact both with other computer systems and with people. Partic-ipants in these heterogeneous human–computer groups vary in their capabilities, goals,and strategies; they may cooperate, collaborate, or compete. The presence of people inmixed networks raises challenges for the design and the evaluation of decision-makingstrategies for computer agents. This paper describes several new decision-making modelsthat represent, learn and adapt to various social attributes that influence people’s decision-making and presents a novel approach to evaluating such models. It identifies a range ofsocial attributes in an open-network setting that influence people’s decision-making andthus affect the performance of computer-agent strategies, and establishes the importanceof learning and adaptation to the success of such strategies. The settings vary in the ca-pabilities, goals, and strategies that people bring into their interactions. The studies deploya configurable system called Colored Trails (CT) that generates a family of games. CT isan abstract, conceptually simple but highly versatile game in which players negotiate andexchange resources to enable them to achieve their individual or group goals. It provides arealistic analogue to multi-agent task domains, while not requiring extensive domain mod-eling. It is less abstract than payoff matrices, and people exhibit less strategic and morehelpful behavior in CT than in the identical payoff matrix decision-making context. By notrequiring extensive domain modeling, CT enables agent researchers to focus their attentionon strategy design, and it provides an environment in which the influence of social factorscan be better isolated and studied.© 2010 Published by Elsevier B.V.1. IntroductionComputer systems are increasingly being deployed in group settings in which they interact with people to carry out tasks[3,46,42,44,28]. To operate effectively in such settings, computer agents need capabilities for making decisions and negoti-ating with other participants—both people and computer-based agents—about the procurement and allocation of resourcesnecessary to complete their tasks. For example, in a civil disaster like an earthquake, rescue personnel and equipment aredispersed geographically and may be under the jurisdiction of various dispatchers. Dispatchers might depend on computeragents to allocate these limited resources to affected locations quickly and to alert them about changing environmentalconditions, such as wind speed and traffic. In turn, computer agents might depend on people to provide up-to-the-minute* Corresponding author at: Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israel.E-mail address: kobig@bgu.ac.il (Y. Gal).0004-3702/$ – see front matter © 2010 Published by Elsevier B.V.doi:10.1016/j.artint.2010.09.002\fY. Gal et al. / Artificial Intelligence 174 (2010) 1460–14801461information about the availability of personnel and equipment. In another realm, in some electronic auction settings, bothpeople and computer agents (representing groups or individuals) might participate not only to acquire items of value, butalso to exchange information about the reliability of others.1First response and e-commerce are two different kinds of examples of open mixed networks. By “open” we mean that theautonomous agents in the network may be designed by or represent different individuals or organizations. By “mixed” wemean that the participants of the network may be computer agents or people. Computer agents operating in open, mixednetworks may support people in their work (e.g., collaborative human–computer interfaces [47,3]), serve as proxies forpeople or institutions (e.g., electronic commerce [25,44]), or interact with other agents to carry out tasks for which they areresponsible (e.g., robots in rescue operations [46,36]). These examples exhibit several key characteristics of mixed networksettings: (1) the participants are both human and computer-based; (2) they depend on each other to make decisions; (3)they may need to exchange resources and information; (4) they have different, complementary roles.Open mixed network settings present a range of challenges for agent designers. First, the participants in these networks—whether people or computer agents—are loosely coupled and not under the control of any single entity. Agent designersare unlikely to know a priori the strategies that people or agents designed by others will adopt, and they cannot forceothers’ agents to adopt a particular strategy. Second, people’s decision-making behavior in group settings does not followthe strategies of classical economic or game theoretic models, but is affected by such social and psychological factors ascognitive biases, social preferences, and framing effects [12,7,4]. It is difficult to measure the effects of such factors directly,and preferences are hard to elicit explicitly from people [9,35]. Third, agents may differ in their goals and plans, so agentdesigners need to develop strategies that are flexibly able to accommodate different levels of cooperation or competitiveness.For these reasons, it is at best challenging, and at worst, impossible, to construct effective agent strategies purely analytically.An alternative approach is to learn and evaluate agent strategies empirically. However, past empirical investigations ofcomputer agent strategies such as the Trading Agent Competition [1] and RoboCup soccer [2] have typically required a fullyspecified domain model. The need for extensive modeling of domain specific knowledge in such settings makes it difficultto distinguish among possible causes of agents’ failures and successes, such as the way agents model the specifics of thedomain or the way they make decisions more generally.On the other hand, completely abstract settings such as the payoff matrices or decision trees traditionally used in studiesin the behavioral sciences collapse the structure of a domain into a list of choices that does not capture the essentialrelationships among tasks, goals and resources.2 Such relationships often play an important role in decision making.The investigations in this paper were done in an environment that represents an intermediate approach. They use theCT (Colored Trails) system [20] which provides an analogue to the ways in which goals, tasks and resources interact in real-world settings, but abstracts away the complexities of real-world domains. CT supports comparisons of the performanceof different computational strategies for interacting in groups comprising people and computer agents as well as solelycomputer agents.3This paper presents several new decision-making models that represent, learn and adapt to various social attributes ofnegotiation in open, mixed-network settings. We consider in particular, social factors that influence possible negotiationdeals (e.g., joint benefit and inequality of outcome), traits of individual negotiators (e.g., altruism, trustworthiness, helpful-ness) and group structure (e.g., solidarity, hierarchy). Our results show that (1) people exhibit more helpful behavior andincrease their social welfare in CT settings than in payoff-matrix types of settings; and (2) computer agents that modeland learn the social factors that influence human negotiation strategies can outperform traditional game-theoretic equilibriastrategies when interacting with people and other computer agents in mixed networks.The contributions of the paper are four-fold: it presents new multi-agent decision-making models, ones that are ableto learn and adapt to the social attributes that affect behavior in open mixed networks; it presents a novel approach toevaluating such models; it shows empirically that agents using these models outperform traditional game-theoretic equi-libria strategies. Lastly, it describes CT more completely than before as a new environment for investigating the design andperformance for negotiation strategies in open-mixed networks. It integrates earlier reports of initial CT studies [17,16,48]and describes a broader range of experimental investigations which demonstrate the flexibility of the CT infrastructure tosupport different agent-design studies.The purpose of the work reported in this paper was not to design “plug-and-play” strategies for specific applicationssuch as first response or electronic commerce. Rather, the studies we describe show empirically that agents will be betterable to negotiate with people if they take into account social factors. In this respect, our results relate to recent work inthe social sciences that point to societal and cultural factors that people “bring into the game”, as influencing the way theybehave in negotiation settings [41,8]. Our studies differ from these in providing and evaluating computational models fordecision-making in these settings. In particular, they identify the influence of factors that have not been addressed in pasthuman–computer decision-making studies and show the influence of these factors on agent-strategy performance",
            {
                "entities": [
                    [
                        3733,
                        3761,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2061–2074Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRandomized coalition structure generationTravis Service a,∗, Julie Adams ba Vanderbilt University, 357 Jacobs Hall, 2201 West End Nashville, TN 37235-1824, USAb Vanderbilt University, 359 Jacobs Hall, 2201 West End Nashville, TN 37235-1824, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 25 December 2010Received in revised form 11 July 2011Accepted 1 August 2011Available online 9 August 2011Keywords:Coalition structure generationCoalition formationCharacteristic function game√Randomization can be employed to achieve constant factor approximations to the coalitionstructure generation problem in less time than all previous approximation algorithms. Inparticular, this manuscript presents a new randomized algorithm that can generate a 23n2.587n) time, improving upon the previous algorithm thatapproximate solution in O (√n2.83n) time to guarantee the same performance. Also, the presented newrequired O (techniques allow a 14 approximate solution to be generated in the optimal time of O (2n)and improves on the previous best approximation ratio obtainable in O (2n) time of 18 .The presented algorithms are based upon a careful analysis of the sizes and numbers ofcoalitions in the smallest optimal coalition structures.An empirical analysis of the new randomized algorithms compared to their deterministiccounterparts is provided. We find that the presented randomized algorithms generatesolutions with utility comparable to what is returned by their deterministic counterparts(in some cases producing better results on average). Moreover, a significant speedup wasfound for most approximation ratios for the randomized algorithms over the deterministicalgorithms. In particular, the randomized 12 approximate algorithm runs in approximately22.4% of the time required for the deterministic 12 approximation algorithm for problemswith between 20 and 27 agents.© 2011 Elsevier B.V. All rights reserved.1. IntroductionMany situations require partitioning the agents into disjoint teams or coalitions where each coalition cooperatively com-pletes a subgoal or subtask [1–3]. However, the process of optimally partitioning the agents into coalitions is computationallydifficult due to the fact that the number of potential coalitions scales exponentially with the number of agents.Characteristic function games, a class of cooperative games, models cooperative multi-agent situations by assigning eachcoalition a value indicating the joint utility those agents will receive if they form a coalition [1,2,4–7]. For example, thisutility may be the difference between the utility earned by completing the subtask assigned to the potential coalition andthe estimated cost incurred during task execution. Given a set of agents, N, a characteristic function game is defined by afunction ν : N → R(cid:2)0. The value ν(C), for a coalition C ⊆ N, is the joint utility the members of C will receive if C forms.A coalition structure is simply a partitioning of the agents into disjoint coalitions. The coalition structure generation problem(CSG problem) is to construct a coalition structure C S that maximizes:ν(C S) =(cid:2)C∈C Sν(C).* Corresponding author.E-mail addresses: tservice@acm.org (T. Service), julie.a.adams@vanderbilt.edu (J. Adams).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.002\f2062T. Service, J. Adams / Artificial Intelligence 175 (2011) 2061–2074The asymptotically fastest algorithm to solve the CSG problem exactly is based on dynamic programming and runs inO (3n) time [2,8]. Due to the high computational complexity of the optimal CSG algorithm, much research has focused onthe development of anytime algorithms. While these anytime algorithms can quickly return approximate solutions, in theworst case most current anytime algorithms require O (nn) time to determine the optimal solution, far worse than the O (3n)time dynamic programming algorithm. Among the current state-of-the-art is Rahwan et al’s. [1] Integer Partition algorithm.Due to the high computational complexity of constructing the optimal coalition structure, our recent work has focusedon developing approximation algorithms that return solutions with bounds on their quality in time less than O (3n) [9,10].For example, our prior algorithm was capable of returning a solution that was at least 2n2.83n) time.This paper improves upon the state-of-the-art in CSG approximation algorithms by presenting randomized algorithmsthat achieve the same approximation ratios as our prior work, but require significantly less time. For example, our newrandomized approximation algorithm is capable of generating a 2n2.59n) time. This result improvesn2.83n) time deterministic algorithm for the same approximation ratio. We also show how to gen-upon our previous O (4 approximation in the optimal time of O (2n) (i.e., any algorithm must observe the values of all 2n − 1 coalitions inerate a 1order to guarantee any approximate solution [2]).3 approximation in O (3 of the optimal in O (√√√Our methods also permit approximation ratios that are unachievable by current approximation algorithms. For example,our randomized algorithm is the first designed to guarantee a 35 approximation ratio.All of the presented approximation algorithms are probabilistic in the sense that they are guaranteed to return theirstated approximation ratio with high probability. Iteratively running the algorithms a small number of times and simplytaking the highest quality solution yields the stated approximation ratio with high probability. For example, if a givenalgorithm finds a 22 , then running the algorithm k times and taking the bestresult yields a 23 approximation ratio with probability at least 12 )k. Several of the presented algorithmic results are of the form:3 approximation with probability 1 − ( 1Algorithm A returns a coalition structure that is guaranteed to have value within a factor ofprobability greater than 12 . A runs in expected time O (g(n)).f of the optimal withThat is, the output of the algorithm (and hence the quality of the solution it presents) is a random variable, and for someof the presented algorithms, the runtime of the algorithm is also a random variable.An empirical study is presented that shows the randomized algorithms perform similarly to their deterministic coun-terparts in terms of utility and sometimes find higher quality solutions. Further, it is shown that the run time of therandomized algorithms, for most approximation guarantees, is significantly faster than the deterministic algorithms.The remainder of the paper is organized as follows. Section 2 describes the prior work on coalition structure genera-tion. Section 3 presents the new randomized algorithms for coalition structure generation. Section 4 provides an empiricalcomparison of the new randomized algorithms to their deterministic counterparts. Section 5 presents concluding remarks.2. Related workMuch algorithm research has focused on the coalition structure generation problem. The current fastest algorithm that isguaranteed to find the optimal solution is based on dynamic programming and requires O (3n) time to find an optimal coali-tion structure on n agents [7,2,8]. Given this high computational complexity, recent work has focused on the developmentof anytime and approximation algorithms.Sandholm et al. [2] developed one of the first anytime algorithms for the coalition structure generation problem. Sand-holm et al. viewed coalition structure generation as a search through the lattice of partitions of the n agents, which theyreferred to as the coalition structure graph. Sandholm et al.’s algorithm proceeded by searching through the bottom twolevels of the coalition structure graph (i.e., those coalition structures that consisted of only one or two coalitions), followedby a breadth first search from the top of the graph (i.e., examining those coalition structures that consist of i coalitionsfollowed by those coalition structures that consist of i − 1 coalitions and so on). Sandholm et al. derive guarantees on thequality of the best solution found so far based upon which levels of the coalition structure graph have been searched.Among the state-of-the-art in anytime coalition structure generation is Rahwan et al.’s [1,6] Integer Partition algorithm.As with Sandholm et al.’s algorithm, the Integer Partition algorithm searches directly through the space of coalition struc-tures. The Integer Partition algorithm groups coalition structures together into subspaces based upon the sizes of thecoalitions they contain. For example, both the coalition structures {{1, 2}, {3}, {4}} and {{3, 4}, {1}, {2}} are in the samesubspace as they both contain a coalition of size 2 and two coalitions of size 1. Rahwan et al. show how to generate upperand lower bounds on the quality of the coalition structures in each subspace. The Integer Partition algorithm uses thosebounds to perform a branch and bound search through the space of all coalition structures. Empirically, Rahwan et al. haveshown that the Integer Partition algorithm is often capable of quickly pruning many of the subspaces from considerationand performs significantly better than Sandholm et al.’s algorithm.While the Integer Partition algorithm performs well empirically on many problem distributions, it is possible to constructdistributions on which the Integer Partition algorithms performance deteriorates significantly [10]. The worst case runtimerequired to find the optimal solution of both the Integer Partition algorithm and Sandholm et al.’s algorithm is O (nn), sincein the worst case each coalition structure must be examined and there are O (nn) coalition structures.\fT. Service, J. Adams / Artificial Intelligence 175 (2011) 2061–207420632.1. Deterministic approximation algorithmsOur recent work has focused",
            {
                "entities": [
                    [
                        3471,
                        3499,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1951–1983Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintItemset mining: A constraint programming perspectiveTias Guns∗, Siegfried Nijssen, Luc De RaedtKatholieke Universiteit Leuven, Celestijnenlaan 200A, 3001 Leuven, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 May 2010Received in revised form 5 May 2011Accepted 6 May 2011Available online 11 May 2011Keywords:Data miningItemset miningConstraint programmingThe field of data mining has become accustomed to specifying constraints on patternsof interest. A large number of systems and techniques has been developed for solvingsuch constraint-based mining problems, especially for mining itemsets. The approachtaken in the field of data mining contrasts with the constraint programming principlesdeveloped within the artificial intelligence community. While most data mining researchfocuses on algorithmic issues and aims at developing highly optimized and scalableimplementations that are tailored towards specific tasks, constraint programming employsa more declarative approach. The emphasis lies on developing high-level modelinglanguages and general solvers that specify what the problem is, rather than outlining howa solution should be computed, yet are powerful enough to be used across a wide varietyof applications and application domains.This paper contributes a declarative constraint programming approach to data mining.More specifically, we show that it is possible to employ off-the-shelf constraint program-ming techniques for modeling and solving a wide variety of constraint-based itemsetmining tasks, such as frequent, closed, discriminative, and cost-based itemset mining.In particular, we develop a basic constraint programming model for specifying frequentitemsets and show that this model can easily be extended to realize the other settings. Thiscontrasts with typical procedural data mining systems where the underlying proceduresneed to be modified in order to accommodate new types of constraint, or novelcombinations thereof. Even though the performance of state-of-the-art data miningsystems outperforms that of the constraint programming approach on some standard tasks,we also show that there exist problems where the constraint programming approach leadsto significant performance improvements over state-of-the-art methods in data mining andas well as to new insights into the underlying data mining problems. Many such insightscan be obtained by relating the underlying search algorithms of data mining and constraintprogramming systems to one another. We discuss a number of interesting new researchquestions and challenges raised by the declarative constraint programming approach todata mining.© 2011 Elsevier B.V. All rights reserved.1. IntroductionItemset mining is probably the best studied problem in the data mining literature. Originally applied in a supermarketsetting, it involved finding frequent itemsets, that is, sets of items that are frequently bought together in transactions ofcustomers [1]. The introduction of a wide variety of other constraints and a range of algorithms for solving these constraint-based itemset mining problems [33,5,41,42,11,31,50,9] has enabled the application of itemset mining to numerous other* Corresponding author. Tel.: +32 16 32 75 67; fax: +32 16 32 79 96.E-mail address: tias.guns@cs.kuleuven.be (T. Guns).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.05.002\f1952T. Guns et al. / Artificial Intelligence 175 (2011) 1951–1983problems, ranging from web mining to bioinformatics [31]; for instance, whereas early itemset mining algorithms focusedon finding itemsets in unsupervised, sparse data, nowadays closed itemset mining algorithms enable the application ofitemset mining on dense data [40,43], while discriminative itemset mining algorithms allow for their application on su-pervised data [35,13]. This progress has resulted in many effective and scalable itemset mining systems and algorithms,usually optimized to specific tasks and constraints. This procedural and algorithmic focus can make it non-trivial to extendsuch systems to accommodate new constraints or combinations thereof. The need to allow user-specified combinations ofconstraints is recognized in the data mining community, as witnessed by the development of a theoretical framework basedon (anti-)monotonicity [33,41,11] and systems such as ConQueSt [9], MusicDFS [50] and Molfea [18]. These systems supporta predefined number of (anti-)monotonicity based constraints, making them well suited for a number of typical data miningtasks.These approaches contrast with those of constraint programming. Constraint programming is a general declarativemethodology for solving constraint satisfaction problems, meaning that constraint programs specify what the problem is,rather than outline how the solution should be computed; it does not focus on a particular application. Constraint program-ming systems provide declarative modeling languages in which many types of constraints can be expressed and combined;they often support a much wider range of constraints than more specialized systems such as satisfiability (SAT) and integerlinear programming (ILP) solvers [10]. To realize this, the model is separated as much as possible from the solver. In the pasttwo decades, constraint programming has developed expressive high-level modeling languages as well as solvers that arepowerful enough to be used across a wide variety of applications and domains such as scheduling and planning [45].The question that arises in this context is whether these constraint programming principles can also be applied to itemsetmining. As compared to the more traditional constraint-based mining approach, this approach would specify data miningmodels using general and declarative constraint satisfaction primitives, instead of specialized primitives; this should makeit easy to incorporate new constraints and combinations thereof as – in principle – only the model needs to be extended tospecify the problem and general purpose solvers can be used for computing solutions.The contribution of this article is that we answer the above question positively by showing that the general, off-the-shelfconstraint programming methodology can indeed be applied to the specific problems of constraint-based itemset mining.1We show how a wide variety of itemset mining problems (such as frequent, closed and cost-based) can be modeled in aconstraint programming language and that general purpose out-of-the-box constraint programming systems can effectivelydeal with these problems.While frequent, closed and cost-based itemset mining are ideal cases, for which the existing constraint programmingmodeling language used suffices to tackle the problems, this cannot be expected in all cases. Indeed, in our formulation ofdiscriminative itemset mining, we introduce a novel primitive by means of a global constraint. This is common practice inconstraint programming, and the identification and study of global constraints that can effectively solve specific subproblemshas become a branch of research on its own [6]. Here, we have exploited the ability of constraint programming to serveas an integration platform, allowing for the free combination of new primitives with existing ones. This property allowsto find closed discriminative itemsets effectively, as well as discriminative patterns adhering to any other constraint(s).Furthermore, casting the problem within a constraint programming setting also provides us with new insights in howto solve discriminative pattern mining problems that lead to important performance improvements over state-of-the-artdiscriminative data mining systems.A final contribution is that we compare the resulting declarative constraint programming framework to well-knownstate-of-the-art algorithms in data mining. It should be realized that any such comparison is difficult to perform; thisalready holds when comparing different data mining (resp. constraint programming) systems to one another. In our com-parison we focus on high-level concepts rather than on specific implementation issues. Nevertheless, we demonstrate thefeasibility of our approach using our CP4IM implementation that employs the state-of-the-art constraint programming li-brary Gecode [47], which was developed for solving general constraint satisfaction problems. While our analysis revealssome weaknesses when applying this particular library to some itemset mining problem, it also reveals that Gecode canalready outperform state-of-the-art data mining systems on some tasks. Although outside the scope of the present paper, itis an interesting topic of ongoing research [37] to optimize constraint programming systems for use in data mining.The article is organized as follows. Section 2 provides an introduction to the main principles of constraint programming.Section 3 introduces the basic problem of frequent itemset mining and discusses how this problem can be addressed us-ing constraint programming techniques. The following sections then show how alternative itemset mining constraints andproblems can be dealt with using constraint programming: Section 4 studies closed itemset mining, Section 5 considersdiscriminative itemset mining, and Section 6 shows that the typical monotonicity-based problems studied in the literaturecan also be addressed in the constraint programming framework. We also study in these sections how the search of theconstraint programming approach compares to that of the more specialized approaches. The CP4IM approach is then evalu-ated in Section 7, which provides an overview of the choices made when modeling frequent itemset mining in a concreteconstraint programming system and compares the performance of this constraint programming system to specialized datamining systems. Finally, Section 8 concludes.1",
            {
                "entities": [
                    [
                        3525,
                        3553,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 189 (2012) 1–18Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the evaluation of election outcomes under uncertaintyNoam Hazon a,∗, Yonatan Aumann a, Sarit Kraus a, Michael Wooldridge ba Department of Computer Science, Bar-Ilan University, Ramat Gan, Israelb Department of Computer Science, University of Liverpool, Liverpool, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 7 March 2010Received in revised form 18 April 2012Accepted 30 April 2012Available online 3 May 2012Keywords:Computational social choiceVoting rulesWe investigate the extent to which it is possible to compute the probability of a particularcandidate winning an election, given imperfect information about the preferences of theelectorate. We assume that for each voter, we have a probability distribution over a setof preference orderings. Thus, for each voter, we have a number of possible preferenceorderings – we do not know which of these orderings actually represents the preferencesof the voter, but for each ordering, we know the probability that it does. For the case wherethe number of candidates is a constant, we are able to give a polynomial time algorithmto compute the probability that a given candidate will win. We present experimentalresults obtained with an implementation of the algorithm, illustrating how the algorithm’sperformance in practice is better than its predicted theoretical bound. However, when thenumber of candidates is not bounded, we prove that the problem becomes #P-hard forthe Plurality, k-approval, Borda, Copeland, and Bucklin voting rules. We further show thateven evaluating if a candidate has any chance of winning is NP-complete for the Pluralityvoting rule in the case where voters may have different weights. With unweighted voters,we give a polynomial algorithm for Plurality, and show that the problem is hard for manyother voting rules. Finally, we give a Monte Carlo approximation algorithm for computingthe probability of a candidate winning in any settings, with an error that is as small asdesired.© 2012 Elsevier B.V. All rights reserved.1. IntroductionSocial choice theory is concerned with making group decisions in situations where the preferences of participants in thedecision-making process may be different [1]. The mechanism by which such a collective decision is made is typically a vot-ing procedure. In a voting procedure, participants (voters) express their preferences via votes, and the voting procedure thendefines the social outcome chosen as a function of the votes cast. A fundamental issue in the social choice literature is thedesign of voting procedures that will select a social outcome which reflects the preferences expressed by voters as closelyas possible [13]. In recent years, the computational aspects of social choice theory have been increasingly studied [20]. Froma computational perspective, perhaps the most natural question relating to voting is the following: Given the preferences/votesof all the voters, is it possible to compute efficiently the winning outcome according to a particular voting rule? Fortunately, it seemsthat relatively few widely used voting rules are hard to compute in this sense [5]. Another key computational question thathas been studied in the context of voting procedures is that of manipulation: the extent to which it is computationally easyor hard for a voter to determine how to vote so as to achieve the best outcome possible for themselves [4,15,19].As the references above indicate, the computational aspects of voting procedures have been increasingly studied inrecent years. However, many computational studies of voting procedures assume perfect information about voter preferences* Corresponding author.E-mail addresses: hazonn@cs.biu.ac.il (N. Hazon), aumann@cs.biu.ac.il (Y. Aumann), sarit@cs.biu.ac.il (S. Kraus), mjw@liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.009\f2N. Hazon et al. / Artificial Intelligence 189 (2012) 1–18or votes.1 That is, when we compute the social outcome, we are assumed to have complete and correct knowledge of thepreferences/votes of all the voters. However, there are important settings in which obtaining the complete preferences/votesof all voters is either not realistic or else not desirable:• Communication can be unreliable. Social choice theory largely ignores the possibility that preferences/votes may be lost intransit. However, if, for example, voting takes place via a communications network such as the Internet, then thisassumption is not valid. Data communications networks are inherently unreliable, and in many domains, reliablecommunication is simply impossible. In such situations, we may need to make social choices without access to thepreferences/votes of all voters.• Communication can be expensive. In some situations, the cost associated with gathering complete preferences/votes fromvoters may be unrealistically high. For example, if a decision is required very quickly, then the time required to gatherall preferences/votes in a large system may be unacceptable.For these reasons, we study the computational aspects of voting rules with an imperfect information model of prefer-ences/votes. There are of course many ways in which one could model incomplete information about voter preferences.For example, one model that has been studied in the literature is that of incomplete models of preferences [27,30]. Here itis assumed that we have a partial but nevertheless correct model of the preferences of voters. Intuitively, we know howvoters rank some of the candidates, but not all of them. One can then ask, for example, whether there is some “completion”of the preferences of voters that would lead to the election of a particular candidate.In our work, we use a different model of incomplete information; we do not claim this model is superior to thatof [27,30], but it provides an interesting alternative framework for modeling voting scenarios with incomplete information.We assume that for each voter, we have a probability distribution over a set of preference orderings. The idea is that although wedo not know a voter’s preference ordering exactly, we know that it is one of a set of possible orderings (typically a subsetof the overall set of possible preference orders), and we have a probability distribution over these. This information may,for example, be obtained from historical voting data, or by sampling. In this setting, the following fundamental questionarises: Given such an incomplete information model of voter preferences, a particular candidate, and a particular voting rule, what isthe probability that the given candidate would win using the given voting rule, assuming the given voter preference model? We referto this as the Evaluation problem. The Evaluation problem has received very little attention to date.2 Our aim is thus togain an understanding of the computational properties of this problem; and in particular, classes of problem instances forwhich Evaluation is computationally easy, and classes of problem instances for which it is computationally hard.The remainder of the paper is structured as follows. We first give some background and review some common votingrules in Section 2. We formally define theEvaluation problem in Definition 1. In Section 3, we first give a polynomialalgorithm to solve the evaluation problem if the number of candidates is a constant. While a result in [16] establishesthat Evaluation is NP-hard for several key voting procedures, even under quite stringent assumptions about probabilitydistributions, we show that this result holds only for weighted voting rules with weights that are not bounded by poly(n).We then experimentally evaluate our algorithm, showing that the actual running time and space are smaller than theasymptotic bound. Therefore, we also test how many voters the polynomial-time algorithm can handle for a given set ofcandidates. The results demonstrate that even with 6 or 7 candidates, the algorithm can handle more than 100 voters, whichsuggests that it may be used in many real-world voting scenarios. If the number of candidates is not bounded, the evaluationproblem becomes much harder: we show in Section 4 that even for the well-known Plurality, k-approval, Borda, Copeland,and Bucklin voting rules, the problem is #P-hard. We then analyze a simpler question, known as the Chance-Evaluationproblem (Definition 2). This question simply asks whether a candidate has any chance of being the winner (i.e., whetherthe probability that the candidate will win is greater than 0). Surprisingly, this problem is shown to be NP-complete (inthe strong sense) even for the Plurality voting rule, when voters do not all have equal weights. We give a polynomial timealgorithm for Plurality when all voters have equal weights, and show that the Chance-Evaluation problem is hard for manyother voting rules (including k-approval, Borda, Copeland and Bucklin). Finally, we present a Monte Carlo algorithm that isable to approximately answer even the Evaluation problem where the number of candidates is a parameter, with an erroras small as desired. We discuss related work in Section 5. Table 1 summarizes our key results (for comparison, we alsoinclude results from [16]).2. Preliminary definitionsAn election is given by a set of candidates (also referred to as alternatives) C = {c1, . . . , cm} and a set of voters V ={1, . . . , n}. Each voter i ∈ V is associated with a preference order R i , which is a total order over C . A vector R = (R1, . . . , Rn),containing a preference order for each voter, is called a preference profile.A voting rule F is a mapping from the set of all preference profiles to the set of candidates: if F (R) = c, we say thatthat could bec wins under F in R. A voting rule is said to be anonymous if F (R) = F",
            {
                "entities": [
                    [
                        4049,
                        4077,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1275–1309Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRepresenting ontologies using description logics, description graphs,and rules ✩Boris Motik a,∗, Bernardo Cuenca Grau a, Ian Horrocks a, Ulrike Sattler ba University of Oxford, UKb University of Manchester, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 20 February 2009Received in revised form 3 June 2009Accepted 9 June 2009Available online 13 June 2009Keywords:Knowledge representationDescription logicsStructured objectsOntologiesDescription logics (DLs) are a family of state-of-the-art knowledge representation languages,and their expressive power has been carefully crafted to provide useful knowledgemodeling primitives while allowing for practically effective decision procedures for thebasic reasoning problems. Recent experience with DLs, however, has shown that theirexpressivity is often insufficient to accurately describe structured objects—objects whoseparts are interconnected in arbitrary, rather than tree-like ways. DL knowledge basesdescribing structured objects are therefore usually underconstrained, which precludes theentailment of certain consequences and causes performance problems during reasoning.To address this problem, we propose an extension of DL languages with description graphs—a knowledge modeling construct that can accurately describe objects with parts connectedin arbitrary ways. Furthermore, to enable modeling the conditional aspects of structuredobjects, we also extend DLs with rules. We present an in-depth study of the computationalproperties of such a formalism. In particular, we first identify the sources of undecidabilityof the general, unrestricted formalism. Based on that analysis, we then investigate severalrestrictions of the general formalism that make reasoning decidable. We present practicalevidence that such a logic can be used to model nontrivial structured objects. Finally,we present a practical decision procedure for our formalism, as well as tight complexitybounds.© 2009 Elsevier B.V. All rights reserved.1. IntroductionThe Web Ontology Language (OWL) is a well-known language for ontology modeling in the Semantic Web [34]. TheWorld Wide Web Consortium (W3C) is currently working on a revision of OWL—called OWL 2 [10]—whose main goal is toaddress some of the limitations of OWL. The formal underpinnings of OWL and OWL 2 are provided by description logics(DLs) [3]—knowledge representation formalisms with well-understood formal properties.DLs are often used to describe structured objects—objects whose parts are interconnected in complex ways. Such objectsabound in molecular biology and the clinical sciences, and clinical ontologies such as GALEN, the Foundational Model of✩This is an extended version of two papers published at WWW 2008 [B. Motik, B. Cuenca Grau, U. Sattler, Structured objects in OWL: Representationand reasoning, in: Proc. of the 17th Int. World Wide Web Conference (WWW 2008), Beijing, China, April 21–25, 2008, ACM Press, 2008, pp. 555–564] andKR 2008 [B. Motik, B. Cuenca Grau, I. Horrocks, U. Sattler, Representing structured objects using description graphs, in: Gerhard Brewka, Jérôme Lang (Eds.),Proc. of the 11th Int. Joint Conf. on Principles of Knowledge Representation and Reasoning (KR 2008), Sydney, NSW, Australia, August 16–19, 2008, AAAIPress, 2008, pp. 296–306], respectively.* Corresponding author at: Oxford University Computing Laboratory, Wolfson Building, Parks Road, Oxford, OX1 3QD, United Kingdom.E-mail addresses: boris.motik@comlab.ox.ac.uk (B. Motik), berg@comlab.ox.ac.uk (B. Cuenca Grau), ian.horrocks@comlab.ox.ac.uk (I. Horrocks),sattler@cs.man.ac.uk (U. Sattler).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.003\f1276B. Motik et al. / Artificial Intelligence 173 (2009) 1275–1309Anatomy (FMA), and the National Cancer Institute (NCI) Thesaurus describe numerous structured objects. For example, FMAmodels the human hand as consisting of the fingers, the palm, various bones, blood vessels, and so on, all of which arehighly interconnected.Modeling structured objects poses numerous problems to DLs and the OWL family of languages. The design of DLs hasbeen driven by the desire to provide practically useful knowledge modeling primitives while ensuring decidability of thecore reasoning problems. To achieve the latter goal, the modeling constructs available in DLs are usually carefully crafted sothat the resulting language exhibits a variant of the tree-model property [39]: each satisfiable DL ontology always has at leastone model whose elements are connected in a tree-like manner. This property can be used to derive a decision procedure;however, it also prevents one from accurately describing (usually non-tree-like) structured objects since, whenever a modelexists, at least one model does not reflect the intended structure. This technical problem has severe consequences in practice[28]. In search of the “correct” way of describing structured objects, modelers often create overly complex descriptions;however, since the required expressive power is actually missing, such descriptions do not entail the consequences thatwould follow if the descriptions accurately captured the intended structure. We discuss the expressivity limitations of DLsin more detail in Section 3 and present a practically-motivated example.In order to address this lack of expressivity, in this paper we extend DLs with description graphs, which can be under-stood as schema-level descriptions of structured objects. To allow for the representation of conditional statements aboutstructured objects, we also extend DLs with first-order rules [20]. In this way, we obtain a powerful and versatile knowl-edge representation formalism. It allows us, for example, to describe the structure of the hand using description graphs,statements such as “if a bone in the hand is fractured, then the hand is fractured as well” using rules, and nonstructuralaspects of the domain such as “a medical doctor is a person with an MD degree” using DLs.Unsurprisingly, this formalism is undecidable in its unrestricted form. It is widely recognized that reasoning algorithmsare more likely to be effective in practice if the underlying logics are decidable. Therefore, we discuss the main causes ofundecidability and investigate restrictions under which the formalism becomes decidable.We have observed that structured objects can often be described by a possibly large, yet bounded number of parts. Forexample, a human body consists of organs all of which can be decomposed into smaller parts; however, further decomposi-tion will eventually lead to parts that one does not want or know how to describe any further. In this vein, FMA describesthe skeleton of the hand, but it does not describe the internal structure of the distal phalanges of the fingers. The number ofparts needed to describe the hand is therefore determined by the granularity of the hierarchical decomposition of the hand.This decomposition naturally defines an acyclic hierarchy of description graphs. For example, the fingers can be describedby description graphs that are subordinate to that of the hand; however, the description graph for the hand is not naturallysubordinate to the description graphs for the fingers. We use this observation to define a particular acyclicity restriction ondescription graphs. Acyclicity bounds the number of parts that one needs to reason with, which, provided that there are noDL axioms, can be used to obtain a decision procedure for the basic reasoning problems.If description graphs are used in combination with DL axioms, the acyclicity condition alone does not ensure decidabilitydue to possible interactions between DL axioms, graphs, and rules [26]. To ensure decidability, we limit this interaction byimposing an additional role separation condition. In particular, we separate the roles (i.e., the binary predicates) that can beused in DL axioms from the roles that can be used in rules; furthermore, depending on the expressivity of the DL beingused, we may additionally require DL axioms not to refer to the roles used in the description graphs.We present a hypertableau-based [31] reasoning algorithm that decides the satisfiability problem in the decidable cases,and that acts as a semidecision procedure for some undecidable ones. Furthermore, we present tight complexity bounds forthe decidable variants of our formalism and identify the main sources of complexity. We have implemented the reasoningalgorithm in the HermiT1 reasoner [30], and our initial experiments have shown the algorithm to be amenable to practice.Evaluation of our approach is currently difficult due to the lack of test data. We have therefore devised an algorithm thatextracts description graphs from existing OWL ontologies, and have applied it to GALEN and FMA. The resulting ontologiesshould be treated with caution; however, domain experts have confirmed that substantial parts of thus derived ontologiesagree with their intuition. Our transformation can thus be used as a starting point for a more comprehensive remodeling ofontologies using description graphs. Our experiments already allowed us to discover a modeling error in GALEN, which wetake as indication of the practical usefulness of our formalism. Furthermore, classification times for the transformed ontolo-gies are of similar orders of magnitude as for the original ontologies despite the fact that our formalism adds considerableexpressive power to DLs.We believe that description graphs can be used for modeling structured objects in a number of domains, of which welist a few next.• Anatomy. In Sections 3 and 4 we present a comprehensive example of how description graphs can be applied to modelhuman anatomy.• Chemistry. The precise description of molecules is an important problem in bioinformatics [23]. A formal ",
            {
                "entities": [
                    [
                        3824,
                        3852,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 279–300Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTogether we know how to achieve: An epistemic logic of know-howPavel Naumov a, Jia Tao b,∗a Claremont McKenna College, Claremont, CA, USAb Lafayette College, Easton, PA, USAa r t i c l e i n f oa b s t r a c tThe existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The article studies an interplay between the distributed knowledge, coalition strategies, and coalition “know-how” strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay.© 2018 Elsevier B.V. All rights reserved.Article history:Received 26 May 2017Received in revised form 24 May 2018Accepted 12 June 2018Available online 21 June 2018Keywords:StrategyGame theoryKnowledgeFormal epistemologyLogicAxiomatizationCompletenessImperfect information1. IntroductionAn agent a comes to a fork in a road. There is a sign that says that one of the two roads leads to prosperity, another to death. The agent must take the fork, but she does not know which road leads where. Does the agent have a strategy to get to prosperity? On one hand, since one of the roads leads to prosperity, such a strategy clearly exists. We denote this fact by modal formula Sa p, where statement p is a claim of future prosperity. Furthermore, agent a knows that such a strategy exists. We write this as KaSa p. Yet, the agent does not know what the strategy is and, thus, does not know how to use the strategy. We denote this by ¬Ha p, where know-how modality Ha expresses the fact that agent a knows how to achieve the goal based on the information available to her. In this article we study the interplay between modality K, representing knowledge, modality S, representing the existence of a strategy, and modality H, representing the existence of a know-how strategy. Our main result is a complete trimodal axiomatic system capturing properties of this interplay.1.1. Epistemic transition systemsIn this article we use epistemic transition systems to capture knowledge and strategic behavior. Informally, epistemic transition system is a directed labeled graph supplemented by an indistinguishability relation on vertices. For instance, our motivational example above can be captured by epistemic transition system T 1 depicted in Fig. 1. In this system state w* Corresponding author.E-mail addresses: Pavel.Naumov@ClaremontMcKenna.edu (P. Naumov), taoj@lafayette.edu (J. Tao).https://doi.org/10.1016/j.artint.2018.06.0070004-3702/© 2018 Elsevier B.V. All rights reserved.\f280P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Fig. 1. Epistemic transition system T 1.Fig. 2. Epistemic transition system T 2.Fig. 3. Epistemic transition system T 3.(cid:3)represents death. The original state is u, but it is indistinguishable by the agent arepresents the prosperity and state wfrom state v. Arrows on the diagram represent possible transitions between the states. Labels on the arrows represent the choices that the agents make during the transition. For example, if in state u agent chooses left (L) road, she will transition to the prosperity state w and if she chooses right (R) road, she will transition to the death state w. In another epistemic state v, these roads lead the other way around. States u and v are not distinguishable by agent a, which is shown by the dashed line between these two states. In state u as well as state v the agent has a strategy to transition to the state of prosperity: u (cid:2) Sa p and v (cid:2) Sa p. In the case of state u this strategy is L, in the case of state v the strategy is R. Since the agent cannot distinguish states u and v, in both of these states she does not have a know-how strategy to reach prosperity: u (cid:2) Ha p and v (cid:2) Ha p. At the same time, since formula Sa p is satisfied in all states indistinguishable to agent a from state u, we can claim that u (cid:2) KaSa p and, similarly, v (cid:2) KaSa p.As our second example, let us consider the epistemic transition system T 2 obtained from T 1 by swapping labels on transitions from v to w and from v to w, see Fig. 2. Although in system T 2 agent a still cannot distinguish states u and v, she has a know-how strategy from either of these states to reach state w. We write this as u (cid:2) Ha p and v (cid:2) Ha p. The strategy is to choose L. This strategy is know-how because it does not require to make different choices in the states that the agent cannot distinguish.(cid:3)(cid:3)1.2. Imperfect recallFor the next example, we consider a transition system T 3 obtained from system T 1 by adding a new epistemic state s. (See Fig. 3.) From state s, agent a can choose label L to reach state u or choose label R to reach state v. Since proposition q is satisfied in state u, agent a has a know-how strategy to transition from state s to a state (namely, state u) where q is satisfied. Therefore, s (cid:2) Haq.A more interesting question is whether s (cid:2) HaHa p is true. In other words, does agent a know how to transition from state s to a state in which she knows how to transition to another state in which p is satisfied? One might think that such a strategy indeed exists: in state s agent a chooses label L to transition to state u. Since there is no transition labeled by L that leads from state s to state v, upon ending the first transition the agent would know that she is in state u, where she needs to choose label L to transition to state w. This argument, however, is based on the assumption that agent a has a perfect recall. Namely, agent a in state u remembers the choice that she made in the previous state. We assume that the agents do not have a perfect recall and that an epistemic state description captures whatever memories the agent has in this state. In other words, in this article we assume that the only knowledge that an agent possesses is the knowledge captured by \fP. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300281Fig. 4. Epistemic transition system T 4.Fig. 5. Epistemic transition system T 5.the indistinguishability relation on the epistemic states. Given this assumption, upon reaching the state u (indistinguishable from state v) agent a knows that there exists a choice that she can make to transition to state in which p is satisfied: s (cid:2) HaSa p. However, she does not know which choice (L or R) it is: s (cid:2) HaHa p.1.3. Multiagent settingSo far, we have assumed that only agent a has an influence on which transition the system takes. In transition system T 4depicted in Fig. 4, we introduce another agent b and assume both agents a and b have influence on the transitions. In each state, the system takes the transition labeled D by default unless there is a consensus of agents a and b to take the transition labeled C. In such a setting, each agent has a strategy to transition system from state u into state w by voting D, but neither of them alone has a strategy to transition from state u to state wbecause such a transition requires the consensus of both agents. Thus, u (cid:2) Sa p ∧ Sb p ∧ ¬Saq ∧ ¬Sbq. Additionally, both agents know how to transition the system from state u into state w, they just need to vote D. Therefore, u (cid:2) Ha p ∧ Hb p.In Fig. 5, we show a more complicated transition system obtained from T 1 by renaming label L to D and renaming label R to C. Same as in transition system T 4, we assume that there are two agents a and b voting on the system transition. We also assume that agent a cannot distinguish states u and v while agent b can. By default, the system takes the transition labeled D unless there is a consensus to take transition labeled C. As a result, agent a has a strategy (namely, vote D) in state u to transition system to state w, but because agent a cannot distinguish state u from state v, not only does she not know how to do this, but she is not aware that such a strategy exists: u (cid:2) Sa p ∧ ¬Ha p ∧ ¬KaSa p. Agent b, however, not only has a strategy to transition the system from state u to state w, but also knows how to achieve this: u (cid:2) Hb p.(cid:3)1.4. CoalitionsWe have talked about strategies, know-hows, and knowledge of individual agents. In this article we consider knowledge, strategies, and know-how strategies of coalitions. There are several forms of group knowledge that have been studied before. The two most popular of them are common knowledge and distributed knowledge [1]. Different contexts call for different forms of group knowledge.As illustrated in the famous Two Generals’ Problem [2,3] where communication channels between the agents are unreli-able, establishing a common knowledge between agents might be essential for having a strategy.In some settings, the distinction between common and distributed knowledge is insignificant. For example, if members of a political fraction get together to share all their information and to develop a common strategy, then the distributed knowledge of the members becomes the common knowledge of the fraction during the in-person meeting.Finally, in some other situations the distributed knowledge makes more sense than the common knowledge. For example, if a panel of experts is formed to develop a strategy, then this panel achieves the best result if it relies on the combined knowledge of its members rather than on their common knowledge.In this article we focus on distributed coalition knowledge and distributed-know-how strategies. We leave the common knowledge for the future research. Establishing distributed knowledge though communication between agents might affect what is known by individual agents [4], but the communication between agents is out of the scope of this paper.To illustrate how distributed knowled",
            {
                "entities": [
                    [
                        2723,
                        2751,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 271 (2019) 74–97Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCooperative games with overlapping coalitions: Charting the tractability frontierYair Zick a,∗a School of Computing, National University of Singapore, Singaporeb School of Electronic and Computer Engineering, Technical University of Crete, Greecec Department of Computer Science, University of Oxford, UKd Department of Informatics, Athens University of Economics and Business, Greece, Georgios Chalkiadakis b, Edith Elkind c, Evangelos Markakis da r t i c l e i n f oa b s t r a c tArticle history:Received 6 July 2016Received in revised form 24 January 2018Accepted 21 November 2018Available online 30 January 2019Keywords:Cooperative gamesOverlapping coalition formationCoreTreewidthArbitration functionsThe framework of cooperative games with overlapping coalitions (OCF games), which was proposed by Chalkiadakis et al. [1], generalizes classic cooperative games to settings where agents may belong to more than one coalition. OCF games can be used to model scenarios where agents distribute resources, such as time or energy, among several tasks, and then divide the payoffs generated by these tasks in a fair and/or stable manner. As the framework of OCF games is very expressive, identifying settings that admit efficient algorithms for computing ‘good’ outcomes of OCF games is a challenging task. In this work, we put forward two approaches that lead to tractability results for OCF games. First, we propose a discretized model of overlapping coalition formation, where each agent i has a weight W i ∈ N and may allocate an integer amount of weight to any task. Within this framework, we focus on the computation of outcomes that are socially optimal and/or stable. We discover that the algorithmic complexity of this task crucially depends on the amount of resources that each agent possesses, the maximum coalition size, and the pattern of communication among the agents. We identify several constraints that lead to tractable subclasses of discrete OCF games, and supplement our tractability results by hardness proofs, which clarify the role of our constraints. Second, we introduce and analyze a natural class of (continuous) OCF games—the Linear Bottleneck Games. We show that such games always admit a stable outcome, even assuming a large space of feasible deviations, and provide an efficient algorithm for computing such outcomes.© 2019 Published by Elsevier B.V.1. IntroductionConsider the following simple market exchange. Two sellers (Alice and Bob) each own a ton of coffee beans (a divisible good), which they would like to sell to two potential buyers (Claire and Dave). Claire and Dave operate in different markets, so Alice and Bob can justifiably offer them different prices. Suppose that having agreed on a transaction schedule and payments, Alice decides that she is unhappy with her revenue from the deal with Claire; she wants to cancel the deal. However, Dave, upon hearing that Alice reneged on her deal with Claire, no longer wishes to work with Alice, canceling * Corresponding author.E-mail addresses: zick@comp.nus.edu.sg (Y. Zick), gehalk@ece.tuc.gr (G. Chalkiadakis), elkind@cs.ox.ac.uk (E. Elkind), markakis@gmail.com (E. Markakis).https://doi.org/10.1016/j.artint.2018.11.0060004-3702/© 2019 Published by Elsevier B.V.\fY. Zick et al. / Artificial Intelligence 271 (2019) 74–9775his agreement with her as well. Dave’s motivation for doing so may stem from many reasons, e.g. a potential business partnership with Claire, or market ‘best practices’.This setting features several interesting characteristics. First, an agent may sell resources to several agents, and may also buy from several other agents. In other words, agents may allocate resources to several profit-generating tasks. Second, agents may withdraw some of their resources from some agreements. For example, Alice may wish to sell less coffee to some customer, but not change her interactions with other parties. Finally, when trying to strategically change an agreement, agents must be aware of how their actions affect the contracts they still maintain with other (possibly unaffected) parties.In our example, agents must collaborate in order to generate revenue. Having generated revenue by making an exchange, agents are free to share the profits from the exchange as they see fit. Profit sharing can be done directly, if the agents jointly produce a new good using their resources, sell it, and distribute the revenue among themselves. It can also be indirect: a seller shares the profit from her transaction with a buyer by setting a price for her good. In either case, agents must identify a way to generate profits, and, subsequently, share profits among themselves in a reasonable manner. When sharing profits, agents should account for individuals or groups of agents who feel that they are underpaid. Indeed, a group of agents that can get more money by deviating from the proposed agreement may destabilize the entire market, resulting in a cascade of deviations, which may eventually produce a less desirable state (not to mention the cost of actual deviation). However, what constitutes a profitable deviation strongly depends on how non-deviators respond to the deviators’ actions.Reasoning about this system of incentives and reactions is a significant challenge. While many group interaction scenar-ios can be represented by the framework of transferable utility cooperative games (TU games), with stable profit-sharing schemes captured by the notion of the core (see, e.g., Peleg and Sudhölter [2]), the standard setting of TU games is not expressive enough to deal with agents participating in several collaborative agreements simultaneously. A few years ago, Chalkiadakis et al. [1] proposed a novel approach to modeling scenarios where agents can divide resources among several joint tasks, by introducing the framework of overlapping coalition formation games (OCF games) and defining several vari-ants of the notion of core stability for this model, which capture different reactions to deviations by non-deviating agents; these include the conservative core, the refined core, the optimistic core, and the sensitive core. Following their work, Zick et al. [3] proposed the notion of an arbitration function, which provides a general model for handling deviations in OCF games. These two works offer a comprehensive conceptual model for analyzing stability in settings where agents work on several concurrent projects and may deviate in a complex manner.In contrast, there has been a very limited amount of work on computing solution concepts for OCF games. The theory of OCF games is a generalization of classic cooperative game theory [2], where computational issues are relatively well-understood (see [4] for an overview). However, as Chalkiadakis et al. [1] show, more elaborate reactions to deviation may increase computational complexity: even if a solution concept is easy to compute for classic cooperative games, computing its OCF analogue may be NP-hard. For example, Chalkiadakis et al. [1] study a class of games called threshold task games: these are games where each agent is associated with an integer weight, and the value of a coalition is a piece-wise con-stant function of its total weight. They show that a payoff division in the core of a threshold task game can be found in pseudopolynomial time (i.e. in time polynomial in the number of agents and in the largest agent weight), if one assumes that when a set of agents deviates, no other agent will want to work with agents in this set—a reaction termed conservative, which closely approximates the setting of TU games (as explained by Zick et al. [3]). In contrast, if non-deviators agree to work with the members of the deviating set in coalitions that are unharmed by the deviation (a reaction termed refined), the same problem becomes NP-hard.It follows that, when assessing the computational complexity of finding stable outcomes in OCF games, one needs to consider not only structural properties of the characteristic function (i.e. the way agents generate profits), but also the way agents react to deviations. In our work, we study the influence of these two aspects of OCF games on the complexity of answering stability-related questions in OCF games.1.1. Our contributionThe computational complexity of any given problem depends on how the input is represented. For instance, a general TU game with n agents is represented by 2n real values: we need one number for each subset (coalition) of players. Thus, no algorithm that needs to know the value of each coalition can run in time that is polynomial in the number of agents. This issue is even more prominent for games with overlapping coalitions: to describe an OCF game, we need to specify a number for every partial coalition, i.e., agreement of the form ‘agent 1 contributes an x1 fraction of her resources, . . . , agent n contributes an xn fraction of her resources’, for every possible combination of (real) values x1, . . . , xn ∈ [0, 1]. Thus, a general OCF game cannot be described by a finite list of numbers, and hence one cannot meaningfully reason about the complexity of general OCF games. To mitigate this issue, we explore two different strategies:1. We introduce and study discrete OCF games, which place restrictions on how finely an agent can split her resources (Sections 3 to 6). In these games, each agent i is associated with an integer weight W i ∈ N and can only allocate an integer weight between 0 and W i to each task. By definition, a discrete OCF game can be represented as a finite list of numbers, and thus discrete OCF games are amenable to traditional complexity-theoretic analysis.2. We identify a large class of (standard, i.e., non-discrete) OCF games that can be succinctly represented (Section 7). Specifically, we study a rich and expressive class of games t",
            {
                "entities": [
                    [
                        3324,
                        3352,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 214 (2014) 1–25Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPotential-based bounded-cost search and AnytimeNon-Parametric ARoni Stern a,∗Ken Goldberg c, Ariel Felner a, Jur van den Berg b, Rami Puzis a, Rajat Shah c,∗a Information Systems Engineering, Ben Gurion University, Be’er Sheva, Israelb School of Computing, University of Utah, Salt Lake City, UT, USAc University of California, Berkeley, CA, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 1 May 2012Received in revised form 1 May 2014Accepted 3 May 2014Available online 10 May 2014Keywords:Heuristic searchAnytime algorithmsRobotics1. Introduction∗(APTS/ANAThis paper presents two new search algorithms: Potential Search (PTS) and Anytime∗Potential Search/Anytime Non-Parametric A). Both algorithms are based ona new evaluation function that is easy to implement and does not require user-tunedparameters. PTS is designed to solve bounded-cost search problems, which are problems∗where the task is to find as fast as possible a solution under a given cost bound. APTS/ANAis a non-parametric anytime search algorithm discovered independently by two researchgroups via two very different derivations. In this paper, co-authored by researchers fromboth groups, we present these derivations: as a sequence of calls to PTS and as a non-parametric greedy variant of Anytime Repairing AWe describe experiments that evaluate the new algorithms in the 15-puzzle, KPP-COM,robot motion planning, gridworld navigation, and multiple sequence alignment searchdomains. Our results suggest that when compared with previous anytime algorithms,∗: (1) does not require user-set parameters, (2) finds an initial solution faster,APTS/ANA(3) spends less time between solution improvements, (4) decreases the suboptimalitybound of the current-best solution more gradually, and (5) converges faster to an optimalsolution when reachable.∗.© 2014 Elsevier B.V. All rights reserved.Heuristic search algorithms are widely used to compute minimum-cost paths in graphs. Applications of heuristic searchrange from map navigation software and robot path planning to automated planning and puzzle solving. Different searchalgorithms return solutions of varying quality, which is commonly measured by a cost, where high quality solutions arethose with a low cost. Ideally, one would like to find optimal solutions, i.e., those with minimum cost. Given an admissible[2], return optimal solutions. However, many problems are veryheuristic, some search algorithms, such as Ahard to solve optimally [3] even with such algorithms.[1] or IDA∗∗In this paper we propose two algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-∗). These algorithms are especially suited for cases where an optimal solution is hard to find.Parametric APTS is designed to solve problems where any solution with cost less than C , an input to the problem, is acceptable, whilesolutions with cost ≥ C are useless. We call such problems bounded-cost search problems. Bounded-cost search problems(APTS/ANA∗* Corresponding author.http://dx.doi.org/10.1016/j.artint.2014.05.0020004-3702/© 2014 Elsevier B.V. All rights reserved.\f2R. Stern et al. / Artificial Intelligence 214 (2014) 1–25∗∗∗arise, for example, when the expense budget for a business trip is limited and the trip (e.g., flights and hotels) shouldbe planned as quickly as possible but within the budget limit. If an online travel agency such as Expedia or Priceline isplanning the trip, computational resources could be diverted to other clients once a plan is found within the budget limits(see Priceline’s “Name Your Own Price” option).∗The second algorithm we present, APTS/ANA, is an anytime search algorithm, i.e., an algorithm “whose quality of resultsimproves gradually as computation time increases” [4]. APTS/ANAcan be viewed as a translation of an anytime searchalgorithm into a sequence of bounded-cost search problems solved by PTS, or as an intelligent approach to avoid theparameter setting problem of Weighted A-based anytime search algorithms. Setting parameters to bounded-suboptimalsearch algorithms is a known problem in the heuristic search literature [5]. A key benefit of APTS/ANAis that it doesnot require users to set parameters, such as the w 0 and (cid:2)w parameters of ARA[6]. Furthermore, experiments suggestthat APTS/ANAimproves upon previous anytime search algorithms in most cases by (1) finding an initial solution faster,(2) spending less time between solution improvements, (3) decreasing the suboptimality bound of the current-best solutionmore gradually, and (4) converging faster to an optimal solution when reachable.are based on a new evaluation function u(n) = C−g(n)h(n)that was discovered independently bytwo research groups via two very different derivations. In this paper, co-authored by researchers from both groups, wepresent both derivations. The first derivation of u(·) is based on a novel concept called the potential of a node. The potentialof a node n is defined with respect to a given value C , and is the probability that a node n is part of a solution of cost lowerthan C . We prove that the node with the highest u(·) is the node with the highest potential, under certain probabilisticrelation between the heuristic function and the cost it estimates.Both PTS and APTS/ANA∗The second derivation of u(·) is based on the desire for a non-parametric version of the Anytime Repairing Aalgo-∗rithm [6]. We show that expanding the node with the highest u(·) has the same effect as setting the parameters of ARAdynamically to improve the best solution found so far as fast as possible. In addition, we show that u(·) bounds the subop-timality of the current solution.∗∗∗We compare PTS and APTS/ANAwith previous anytime algorithms on five representative search domains: the 15-puzzle,robot motion planning, gridworld navigation, Key player problem in communication (KPP-COM), and multiple sequencealignment. As mentioned above, the experimental results suggest that APTS/ANAimproves upon previous anytime searchalgorithms in terms of key metrics that determine the quality of an anytime algorithm. As a bounded-cost algorithm, ourresults suggest that PTS, which is specifically designed for bounded-cost problems, outperforms competing algorithms formost cost bounds and exhibits an overall robust behavior.∗∗This paper extends our preliminary work [7–9] by (1) providing a substantially more rigorous theoretical analysis ofthe presented algorithms, (2) extending the experimental results, (3) adding a comprehensive discussion on the relationbetween bounded-cost search and anytime search, and (4) discussing the limitations of PTS and APTS/ANA∗.The structure of this paper is as follows. First, we provide background and related work. In Section 3, we introducethe bounded-cost search problem and present Potential Search (PTS). In Section 4, we present Anytime Potential Search(APTS) [7,8] and Anytime Non-Parametric A) [9], showing that they are equivalent and discussing their theoreticalproperties. Section 5 presents experimental results comparing PTS and APTS/ANAwith previous algorithms. Finally, wediscuss a generalization of PTS (Section 6) and conclude with suggestions for future work (Section 7).(ANA∗∗∗2. Background and related workSearch algorithms find a solution by starting at the initial state and traversing the problem space graph until a goal stateis found. Various search algorithms differ by the order in which they decide to traverse the problem space graph. Traversingthe problem space graph involves generating and expanding its nodes. The term generating a node refers to creating a datastructure that represents it, while expanding a node means generating all its children.One of the most widely used search frameworks is best–first search (BFS) [10]. BFS keeps two lists of nodes: an openlist (denoted hereafter as OPEN), which contains all the generated nodes that have not been expanded yet, and a closed list(denoted hereafter as CLOSED), which contains all the nodes that have been previously expanded. Every generated node inOPEN is assigned a value by an evaluation function. The value assigned to a node is called the cost of the node. In everyiteration of BFS, the node in OPEN with the lowest cost is chosen to be expanded. This lowest-cost node is moved fromOPEN to CLOSED, and the children of this node are inserted to OPEN. The purpose of CLOSED is to avoid inserting nodes thathave already been expanded into OPEN. CLOSED is also used to help reconstruct the solution after a goal is found. Once agoal node is chosen for expansion, i.e., it is the lowest-cost node in OPEN, BFS halts and that goal is returned.1 Alternatively,BFS can be defined such that every node is assigned a value, and in every iteration the node with the highest value isexpanded.BFS is a general framework, and many well-known algorithms are special cases of it. For example, Dijkstra’s single-sourceshortest-path algorithm [12] and the Aalgorithm [1] are both special cases of BFS, differing only in their evaluationfunction.2 Dijkstra’s algorithm is BFS with an evaluation function that is g(n), which is the shortest path found so far from∗1 This is the textbook version of BFS [10]. However, there are variants of BFS where the search is halted earlier (e.g., BFS with lookaheads [11]).2 In this paper we consider Dijkstra’s algorithm in its best–first search variant, which is also known as Uniform Cost Search. It has been shown [13] thatthis variant of Dijkstra is more efficient than the implementation of Dijsktra detailed in the common algorithm textbook [14].\fR. Stern et al. / Artificial Intelligence 214 (2014) 1–253∗is BFS with an evaluation function that is f (n) = g(n) + h(n), where h(n) is a heuristicthe start of the search to node n. A∗(n) to denote the lowest-cost path fromfunction estimating the cost from state n to a goal node. We use t",
            {
                "entities": [
                    [
                        3154,
                        3182,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 160–185www.elsevier.com/locate/artintLoop formulas for circumscriptionJoohyung Lee a, Fangzhen Lin b,∗a Department of Computer Science and Engineering, Arizona State University, AZ, USAb Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay,Kowloon, Hong KongReceived 4 April 2005; received in revised form 13 September 2005; accepted 14 September 2005Available online 2 November 2005AbstractClark’s completion is a simple nonmonotonic formalism and a special case of several non-monotonic logics. Recently there has been work on extending completion with “loop formulas” sothat general cases of nonmonotonic logics such as logic programs (under the answer set seman-tics) and McCain–Turner causal logic can be characterized by propositional logic in the form of“completion + loop formulas”. In this paper, we show that the idea is applicable to McCarthy’s cir-cumscription in the propositional case, with Lifschitz’s pointwise circumscription playing the roleof completion. We also show how to embed propositional circumscription in logic programs and incausal logic, inspired by the uniform characterization of “completion + loop formulas”. 2005 Elsevier B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Commonsense reasoning; Knowledge representation; Circumscription;Clark’s completion; Loop formulas; Logic programming1. IntroductionClark’s predicate completion [5] is a simple and intuitive nonmonotonic formalism.Normally it is applicable when the knowledge base is given as a set of rules, and workswhen the rules do not yield a “cycle”.* Corresponding author.E-mail address: flin@cs.ust.hk (F. Lin).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.09.003\fJ. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185161Despite these limitations, surprisingly perhaps, predicate completion has been used tosolve many problems that were thought to require more sophisticated nonmonotonic logics.For instance, Reiter [34] showed that under certain reasonable assumptions, successor stateaxioms can be computed from action effect axioms by predicate completion, and thussolved the frame problem when there are no state constraints. For state constraints, Lin[25] argued that they should be encoded using a notion of causality, and once they areencoded this way, successor state axioms can once again be computed using predicatecompletion for a class of causal rules that includes almost all of the benchmark planningdomains [25,27].For the “definite” fragment of McCain–Turner causal logic [10,28], the problem of de-termining whether a theory is consistent can be reduced to the satisfiability problem forpropositional logic by the process of “literal completion”—a translation similar to Clark’scompletion. This idea has led to the creation of the Causal Calculator (CCALC),1 a systemfor representing commonsense knowledge about action and change. After turning a definitecausal theory into a classical propositional theory, CCALC finds the models of the latterby invoking a satisfiability solver, such as CHAFF,2 SATO3 and RELSAT,4 which in turncorrespond to the models of the given causal theory. CCALC has been successfully appliedto several challenge problems in the theory of commonsense knowledge [1,4,18,23] and tothe formalization of multi-agent computational systems [2,3].In logic programming where predicate completion is best known and commonly re-ferred to as program completion semantics, its relationships with other semantics, espe-cially the answer set semantics (also known as the stable model semantics) of Gelfondand Lifschitz [9], have been studied quite extensively. First of all, it is well known that ananswer set for a normal logic program is also a model of its completion, while the con-verse, generally, does not hold. Fages [8] showed that a certain syntactic condition, whichis now called “tightness”, is sufficient for establishing the equivalence between them. Er-dem and Lifschitz [7] generalized Fages’ theorem and extended it to programs with nestedexpressions (in the sense of [17]) in the bodies of rules.Instead of looking for conditions that will guarantee the equivalence between the com-pletion semantics and the answer set semantics, Lin and Zhao [24] considered how tostrengthen completion to make it equivalent to the answer set semantics. The idea is that,since the presence of cycles is what causes the mismatch between the models of the com-pletion and the answer sets for a program, one should address the problem raised by themdirectly. The completion semantics captures the intuition that for an atom to be true, oneof the bodies of the rules with the atom as the head must be true. Similarly, Lin and Zhaoassociated with each loop a “loop formula” that captures the intuition that for the atoms ina loop to be true, there must be a rule whose head belongs to the loop, and whose bodyis true but its positive part does not have any atom in the loop. They showed that a set ofatoms is an answer set for a nondisjunctive logic program iff it is a model of the completionand all loop formulas of the program. This idea allows SAT solvers to be used for finding1 http://www.cs.utexas.edu/users/tag/ccalc/.2 http://www.ee.princeton.edu/~chaff/.3 http://www.cs.uiowa.edu/~hzhang/sato.html.4 http://www.almaden.ibm.com/cs/people/bayardo/resources.html.\f162J. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185answer sets and thus has led to the creation of SAT-based answer set solvers ASSAT [24]and CMODELS-2 [11].As it turned out, program completion and loop formulas are not limited to nondisjunc-tive logic programs. Lee and Lifschitz [12] extended the Lin/Zhao theorem to disjunc-tive logic programs and, more generally, to arbitrary programs with nested expressions.Lee [13] showed that a similar result can be obtained for McCain and Turner causal logicand based on this, showed how to embed logic programs in causal logic.Given these results, one wonders how far this idea of “completion + loop formulas”can go. Is it general enough to capture other nonmonotonic logics? In this paper, we an-swer this question positively for circumscription [29,30] in the propositional case. Thus itis interesting to observe that these apparently different nonmonotonic formalisms have auniform view of “completion + loop formulas”. Using this idea, we show how to embedcircumscription in logic programs and in McCain–Turner causal logic.Hopefully, these results will lead to good implementations of propositional circumscrip-tion using SAT solvers and/or answer set solvers. This would be a significant progress innonmonotonic reasoning as circumscription has found applications in commonsense rea-soning, model-based diagnoses, discourse understanding, and others. While many of theseapplications in general make use of first-order circumscription, they can be solved usingpropositional circumscription when their domains are given and finite.This paper is organized as follows. In Section 2, we introduce some notations that wewill use in the rest of the paper, and recast the definition of circumscription in the propo-sitional case. In Section 3, we discuss Clark’s completion, and compare it with Lifschitz’spointwise circumscription [20], as the latter will serve as “completion” for our purpose. InSection 4, we introduce the notion of a loop via the notion of a dependency graph. Section 5contains the main technical results of the paper, which shows that circumscription can becharacterized by completion plus loop formulas. It also discusses some related work. Basedon the results in Section 5, Section 6 shows how circumscription can be embedded in logicprograms under the answer set semantics and in McCain–Turner causal logic. We concludein Section 7.2. Logical preliminariesA literal is a (propositional) atom or the negation of an atom. A (propositional) formulais formed from literals using propositional connectives. A clause is a finite set of literals.We identify a clause C with the disjunction of its elements. It is well known that anyformula can be transformed into an equivalent set of clauses.We use variables that range over 0-place connectives (cid:2) and ⊥, and quantify overthem. For instance, if A(z, p1, . . . , pk) is a propositional formula built with propo-sitional variables z, p1, . . . , pk, we write ∀zA(z, p1, . . . , pk) to denote the formulaA((cid:2), p1, . . . , pk) ∧ A(⊥, p1, . . . , pk), and similarly ∃zA(z, p1, . . . , pk) to denote the for-mula A((cid:2), p1, . . . , pk) ∨ A(⊥, p1, . . . , pk).In the following, we sometimes write a formula A as A(P ) or A(P , Q) for tuples P andQ of atoms. This way, when X is a tuple of variables and atoms of the same length as P ,we use A(X) or A(X, Q) to denote the result of simultaneously replacing all elements\fJ. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185163of P in A by the corresponding elements of X. We sometimes identify a tuple with thecorresponding set when there is no confusion.For P = (p1, . . . , pn), Q = (q1, . . . , qn),P (cid:1) Q stands forP = Q stands forP < Q stands for(cid:1)(pi ⊃ qi),1(cid:1)i(cid:1)n(cid:1)(pi ≡ qi),1(cid:1)i(cid:1)n(P (cid:1) Q) ∧ ¬(P = Q).Let P and Z be tuples of atoms, and A(P , Z) a formula. The circumscription of P inA(P , Z) ∧ ¬∃XYA(P , Z) with atoms in Z allowed to vary, is the following formula:(cid:2)A(X, Y ) ∧ X < P(cid:3).(1)The formula is denoted by CIRC[A(P , Z); P ; Z], which may also be written asCIRC[A(P ); P ] when Z is empty.The second conjunct of formula (1) is actually a propositional formula as in the follow-ing example:CIRC[p ∨ q; p] = (p ∨ q) ∧ ¬∃x(cid:4)(cid:2)= (p ∨ q) ∧ ¬(cid:3)(cid:2)(x ∨ q) ∧ (x ⊃ p) ∧ (x (cid:10)≡ p)(cid:3)((cid:2) ∨ q) ∧ ((cid:2) ⊃ p) ∧ ((cid:2) (cid:10)≡ p)(cid:2)(⊥ ∨ q) ∧ (⊥ ⊃ p) ∧ (⊥ (cid:10)≡ p)(cid:3)(cid:5)∨≡ (p ∨ q) ∧ ¬(p ∧ q).(2)The models of the circumscription are {p} and {q}.5There is a weaker noti",
            {
                "entities": [
                    [
                        1772,
                        1800,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 166 (2005) 194–253www.elsevier.com/locate/artintProcesses and continuous changein a SAT-based plannerJi-Ae Shin ∗, Ernest DavisCourant Institute, New York University, New York, NY 10012, USAReceived 27 September 2004; accepted 6 April 2005Available online 10 May 2005AbstractThe TM-LPSAT planner can construct plans in domains containing atomic actions and durativeactions; events and processes; discrete, real-valued, and interval-valued fluents; reusable resources,both numeric and interval-valued; and continuous linear change to quantities. It works in three stages.In the first stage, a representation of the domain and problem in an extended version of PDDL+ iscompiled into a system of Boolean combinations of propositional atoms and linear constraints overnumeric variables. In the second stage, a SAT-based arithmetic constraint solver, such as LPSAT orMathSAT, is used to find a solution to the system of constraints. In the third stage, a correct plan isextracted from this solution. We discuss the structure of the planner and show how planning withtime and metric quantities is compiled into a system of constraints. The proofs of soundness andcompleteness over a substantial subset of our extended version of PDDL+ are presented. 2005 Elsevier B.V. All rights reserved.Keywords: SAT-based planning; LPSAT; Continuous time; Metric quantities; Processes1. IntroductionNumeric and geometric entities that change continuously in time are central features ofmany domains, especially physical domains: the position of an object in space, the amountof gasoline in a tank, the temperature of water in a pot, and so on. Early generations of* Corresponding author.E-mail addresses: jiae@cs.nyu.edu (J. Shin), davise@cs.nyu.edu (E. Davis).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.04.001\fJ. Shin, E. Davis / Artificial Intelligence 166 (2005) 194–253195domain-independent planners did not deal with numeric quantities at all, and even nowfew planners deal with continuous change. The TM-LPSAT system described in this paperis the first planner that uses the SAT-based planning methodology to deal with continuouschange, as well as many other aspects of numeric quantities.Over the past decade, dozens of new powerful engines for propositional satisfiabilityhave become available [55] and are now being used in a broad range of applications. Onevery successful application has been the development of SAT-based propositional planning,in which a planning problem is compiled into a set of propositional constraints in such away that a solution to the constraints demarcates a valid plan [32,34,35]. Recently, a newclass of inference engines1 based on propositional satisfiability solvers has been developedfor systems of Boolean combinations of propositional atoms and linear constraints overreal-valued quantities [3,5,53].In this paper, we show how the SAT-based planning framework can be extended, usingSAT-based arithmetic constraint solvers, to deal with domains that involve continuous time,resources, and real-valued quantities.The TM-LPSAT planner constructs plans in domains with the following features:• The effects and preconditions of actions can involve discrete, real-valued, and interval-valued fluents.• An action can change the value of a real-valued fluent either continuously, as a linearfunction of time, or discretely.• An action may be either atomic or durative (taking place over an extended time inter-val).• An action may take real- or interval-valued parameters.• Actions may be concurrent.• Exogenous events may occur.• Autonomous processes can be defined in the language.• Processes that make a continuous change on the same fluent may be concurrent.• Reusable resources, both numeric and interval-valued, can be defined in the language.Fig. 1 shows the architecture of TM-LPSAT. The input to TM-LPSAT consists of adomain description and a problem specification represented in PDDL+ [24,25] (more pre-cisely, in a version of PDDL+ with certain restrictions and extensions as described inSection 3). The compiler compiles the planning problem into a set of constraints, eachof which is a disjunction of propositional atoms and linear (in)equalities over numericvariables. The set of constraints is passed to the SAT-based arithmetic constraint solverwhich finds a solution if one exists. From the solution, the decoder extracts a valid plan.The overall system is thus a powerful and elegant planner for a wide range of prob-lems.Our main contribution in TM-LPSAT has been the development of the compiler. Fromour point of view, the constraint solver can be viewed a black box, that takes as input a set of1 We will call these “SAT-based Arithmetic Constraint Solver” in this paper. They are also called “SAT-basedDecision Procedure” or “Theorem Prover” in the literature.\f196J. Shin, E. Davis / Artificial Intelligence 166 (2005) 194–253Fig. 1. Architecture of TM-LPSAT.constraints of the form described above and outputs a solution if one exists and a flag if nosolution exists. A number of different architectures for such a constraint solver are possible,at least in principle; it could be complete or heuristic, deterministic or probabilistic. Indeveloping and testing TM-LPSAT, we have used two pre-existing SAT-based constraintsolvers, LPSAT [53] and MathSAT [3,9]. In Section 2.2 we discuss their architecture. InSection 8 we will sketch a branch-and-bound architecture that would enable the solver tosolve optimization problems.Two sample problems will illustrate the power of the TM-LPSAT planner, and will helpintroduce the sample domains that we will discuss in Section 5:Problem 1.1. An agent must deliver 5 gallons of water to a location LD. Currently theagent is at a location LS 100 feet away, with two four-gallon buckets. At LS there is also atap that pours water at the rate of 0.1 gallons per second. The agent can move at 5 feet persecond.The following plan will enable the agent to achieve his goal in a total of 70 seconds:He turns on the tap and let it pours into bucket 1 for 10 seconds. Bucket 1 now holds 1gallon. The agent turns off the tap, puts bucket 2 under the tap, and turns on the tap. Then,he carries bucket 1 to LD, empties bucket 1 at LD, and returns to LS. The round trip takeshim 40 seconds, so bucket 2 now holds 4 gallons. He picks up bucket 2, carries it to LD,and empties it.If the agent can carry two buckets at once, then a simpler solution is possible: He pours3 gallons into bucket 1, 2 gallons into bucket 2, carries them both to LD, and empties them,again completing the task in 70 seconds.Problem 1.2. A computer architecture uses variable-length partitions as its memory model;that is, each job occupies a consecutive segment of RAM, which is fixed throughout thelifetime of the job. The machine has 128M of RAM. The operating system needs to sched-ule jobs with the following characteristics:\fJ. Shin, E. Davis / Artificial Intelligence 166 (2005) 194–253197JobTimeSpace----------------------ABCDEF10050120401004080M15M20M65M20M40MAssume that the jobs are I/O bound, so that the time requirement is independent of howmany jobs are currently active.The following plan completes all the jobs by time 160:JobStartEndSegment-----------------------------ACBEFD00050100120100120501501401600-8080-100100-115108-1280-4040-105This paper is organized as follows. Section 2 reviews previous and related work, in-cluding the work on SAT-based planning, SAT-based arithmetic constraint solvers, andPDDL+, which we draw on in the construction of TM-LPSAT. Section 3 discusses theextensions and restrictions we have made to PDDL+. Section 4 discusses the temporal on-tology. Section 5 presents a few sample domains and planning problems that TM-LPSATcan handle. Section 6, the core of our research, enumerates the rules for translating a prob-lem in PDDL+ into a system of constraints. (Table 1 on page 210 contains a summary ofthe constraints.) Section 7 discusses the soundness and completeness of our system. Sec-tion 8 presents our conclusions and discusses future work. Appendix A gives a completelisting of the PDDL+ definition of the “Bucket” domain and the problem described inProblem 1.1. Appendix B gives the proof that TM-LPSAT is sound and complete over asubstantial subset of our extended version of PDDL+ Level 5.2. Previous and related workThe TM-LPSAT planner builds on three foundations:• SAT-based planning: In this planning paradigm, a planning problem represented ina high-level planning language is compiled into a corresponding set of propositionalformulas. Solving the planning problem thus corresponds to solving the propositionalsatisfiability problem (SAT) over these formulas.• SAT-based arithmetic constraint solvers, constraint satisfaction engines that find solu-tions to Boolean combinations of propositional atoms and linear (in)equalities.• The PDDL+ specification language for planning domains and problems.\f198J. Shin, E. Davis / Artificial Intelligence 166 (2005) 194–253Also related, though not directly used in TM-LPSAT, are• Other planning paradigms for dealing with metric time and numeric quantities.• Other automated reasoning applications that deal with continuous change.We will discuss in turn each of these categories of previous work and their relation toTM-LPSAT.2.1. Planning as propositional satisfiabilityThe architecture of a SAT-based propositional planner is shown in Fig. 2. The idea ofSAT-based propositional planning [32,34,35] is to convert a planning problem in a domainwith discrete actions and fluents2 with discrete values into a set of propositional constraints.This is done as follows:• An upper bound N is guessed3 for the number of steps needed in the plan. Time pointsare labeled 0 . . . N.• The following propositional atoms are defined at each time point I:A. For each fluent F, for each possible value V of F, the statement that the value of Fat time I is V.B. For each action A, the ",
            {
                "entities": [
                    [
                        1843,
                        1871,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 48–69Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSkypattern mining: From pattern condensed representations to dynamic constraint satisfaction problemsWilly Ugarte a, Patrice Boizumault a, Bruno Crémilleux a,∗Samir Loudni a, Marc Plantevit c, Chedy Raïssi d, Arnaud Soulet ea GREYC (CNRS UMR 6072), University of Caen, F-14032 Caen, Franceb CERMN (UPRES EA 4258 – FR CNRS 3038 INC3M), University of Caen, F-14032 Caen, Francec Université de Lyon, CNRS, Université Lyon 1, LIRIS (UMR5205), F-69622, Franced INRIA Nancy Grand-Est, Francee LI (EA 2101), Université François Rabelais de Tours, F-41029 Blois, France, Alban Lepailleur b, a r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 7 April 2015Accepted 14 April 2015Available online 28 April 2015Keywords:SkypatternsPattern miningConstraint programmingDynamic CSPUser preferencesData mining is the study of how to extract information from data and express it as useful knowledge. One of its most important subfields, pattern mining, involves searching and enumerating interesting patterns in data. Various aspects of pattern mining are studied in the theory of computation and statistics. In the last decade, the pattern mining community has witnessed a sharp shift from efficiency-based approaches to methods which can extract more meaningful patterns. Recently, new methods adapting results from studies of economic efficiency and multi-criteria decision analyses such as Pareto efficiency, or skylines, have been studied. Within pattern mining, this novel line of research allows the easy expression of preferences according to a dominance relation. This approach is useful from a user-preference point of view and tends to promote the use of pattern mining algorithms for non-experts. We present a significant extension of our previous work [1,2] on the discovery of skyline patterns (or “skypatterns”) based on the theoretical relationships with condensed representations of patterns. We show how these relationships facilitate the computation of skypatterns and we exploit them to propose a flexible and efficient approach to mine skypatterns using a dynamic constraint satisfaction problems (CSP) framework.We present a unified methodology of our different approaches towards the same goal. This work is supported by an extensive experimental study allowing us to illustrate the strengths and weaknesses of each approach.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe process of extracting useful patterns from data, called pattern mining, is an important subfield of data mining, and has been used in a wide range of applications and domains such as bioinformatics [3], chemoinformatics [4], social network analysis [5], web mining [6] and network intrusion detection [7]. Since the key papers of Agrawal et al. [8], Mannila et al. [9], a considerable number of patterns, such as itemsets, strings, sequences, trees and graphs, have been studied and * Corresponding author.E-mail address: bruno.cremilleux@unicaen.fr (B. Crémilleux).http://dx.doi.org/10.1016/j.artint.2015.04.0030004-3702/© 2015 Elsevier B.V. All rights reserved.\fW. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6949used in real-world applications. Nowadays, many pattern extraction problems like subgroup discovery [10], discriminative pattern mining [11], and tiling [12] are understood from both theoretical and computational perspectives.Most existing pattern mining approaches enumerate patterns with respect to a given set of constraints that range from simple to complex. For instance, given a transaction database, a well-known pattern mining task is to enumerate all itemsets (i.e. sets of items) that appear in at least s transactions. However, the output of pattern mining operations can be extremely large even for moderately sized datasets. For instance, in the worst case, the number of frequent itemsets is exponential in the number of the items in the dataset.So far, the community has expended much effort on developing sophisticated algorithms which push the constraints deep into the mining process [13]. But also in on compression (i.e. reduction) techniques to limit the number of output patterns depending on the application contexts [14–16]. The pattern mining community, however, has paid less attention to combining mining constraints. In practice, many constraints entail choosing threshold values such as the well-used minimal frequency. This notion of “thresholding” has serious drawbacks. Unless specific domain knowledge is available, the choice is often arbitrary and may lead to a very large number of extracted patterns which can reduce the success of any subsequent data analysis. This drawback is even more pronounced when several thresholds have to be combined. A second drawback is the stringent enumeration aspect: a pattern is either above or below a threshold. But what about patterns that respect only some thresholds? Should they be discarded? It is often very difficult to apply subtle selection mechanisms. There are very few works such as [17,18] which propose to introduce a softness criterion into the mining process. Other studies attempt to integrate user preferences into the mining task in order to limit the number of extracted patterns such as the top-k pattern mining approaches [19,20]. By associating each pattern with a rank score, this approach returns an ordered list of the k patterns with the highest score to the user. However, combining several measures in a single scoring function is difficult and the performance of top-k approaches is often sensitive to the size of the datasets and to the threshold value, k.We present a unified methodology of two approaches that aim to make the results of pattern mining useful from a user-preference point of view. To this end, we integrate into the pattern discovery process the idea of skyline queries [21] in order to mine skyline patterns in a threshold-free manner. Such queries have attracted considerable attention due to their impor-tance in multi-criteria decision making and economics where they are usually called “Pareto efficiency or optimality queries”. Briefly, in a multidimensional space where a preference is defined for each dimension, a point a dominates another point b if a is better (i.e. more preferred) than b in at least one dimension, and a is not worse than b on every other dimen-sion. For example, a user selecting a set of patterns may prefer a pattern with a high frequency, a large length and a high confidence. In this case, we say that pattern a dominates another pattern b if a.frequency ≥ b.frequency, a.length ≥ b.length, a.confidence ≥ b.confidence, where at least one strict inequality holds. Given a set of patterns, the skyline set contains the patterns that are not dominated by any other pattern.Skyline pattern mining is interesting for several reasons. First, skyline processing does not require any threshold se-lection. In addition, for many pattern mining applications it is often difficult (or impossible) to find a reasonable global ranking function. Thus the idea of finding all optimal solutions in the pattern space with respect to multiple preferences is appealing. Second, the formal property of dominance satisfied by the skyline pattern defines a global interestingness measure with semantics easily understood by the user. These semantics are discussed at length in the economics literature, where the Pareto efficiency is applied to the selection of alternatives in resource distributions. However, while this notion of skylines has been extensively developed in engineering and database applications, it has remained unused for data mining purposes until recently [1]. Thirdly, skyline pattern mining is appealing from an efficiency and usability point of view. The authors of [22] established a loose upper-bound on the average number of skyline tuples O ((ln n)d−1) (with n tuples and |I|) (where |I| represents the d dimensions) which contrasts with the usual worst-case number of possible itemsets O (2cardinality of the set of items).Contributions and roadmap We present significant extensions of our recent papers [1,2] on the discovery of skyline patterns, or “skypatterns”. First, we detail a static method (called Aetheris) based on the theoretical relationships with condensed rep-resentations of patterns (representations which return a subset of the patterns having the same expressiveness as the whole set of patterns [23]). Second, we describe a dynamic method (called CP+Sky) which involves a continuous re-finement of the skyline constraints based on the extracted patterns. This is achieved through a dynamic CSP (Constraint Satisfaction Problems) framework (denoted by DynCSP). Third, the key notion of “skylineability” which constitutes the cor-nerstone of our two methods is explained in more detail. Finally, we present an extensive empirical study which includes a wide range of datasets and comparisons of our techniques. This enables us to draw some lessons about the strengths and weaknesses of each method and to better understand the advantages/weaknesses of the CSP machinery (see Sections 7.1.2and 7.1.3).The rest of this paper is organized as follows. Section 2 surveys the works related to skyline pattern analysis. Section 3introduces some basic definitions, the formal problem statement and an overview of our work. The key notion of sky-lineability is then studied in Section 4. Section 5 discusses the computation of condensed representation of patterns for skypattern queries. Section 6 discusses skylineability but within a DynCSP framework. We report an empirical study on several datasets and a case study from the chemoinformatics domain in Section 7. Finally, Section 8 discusses the learnt lessons.\f50W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–692. Related work2.1. Pattern miningFrequent itemset mining was first descri",
            {
                "entities": [
                    [
                        3134,
                        3162,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 103–139www.elsevier.com/locate/artintState-set branching: Leveraging BDDs for heuristic search ✩Rune M. Jensen ∗, Manuela M. Veloso, Randal E. BryantComputer Science Department, Carnegie Mellon University, 5000 Forbes Ave., Pittsburgh, PA 15213-3891, USAReceived 22 February 2006; received in revised form 30 May 2007; accepted 30 May 2007Available online 7 June 2007AbstractIn this article, we present a framework called state-set branching that combines symbolic search based on reduced ordered BinaryDecision Diagrams (BDDs) with best-first search, such as A* and greedy best-first search. The framework relies on an extensionof these algorithms from expanding a single state in each iteration to expanding a set of states. We prove that it is generallysound and optimal for two A* implementations and show how a new BDD technique called branching partitioning can be used toefficiently expand sets of states. The framework is general. It applies to any heuristic function, evaluation function, and transitioncost function defined over a finite domain. Moreover, branching partitioning applies to both disjunctive and conjunctive transitionrelation partitioning. An extensive experimental evaluation of the two A* implementations proves state-set branching to be apowerful framework. The algorithms outperform the ordinary A* algorithm in almost all domains. In addition, they can improvethe complexity of A* exponentially and often dominate both A* and blind BDD-based search by several orders of magnitude.Moreover, they have substantially better performance than BDDA*, the currently most efficient BDD-based implementation of A*.© 2007 Elsevier B.V. All rights reserved.Keywords: Heuristic search; BDD-based search; Boolean representation1. IntroductionInformed or heuristic best-first search (BFS) algorithms1 such as greedy best-first search and A* [27] are consideredimportant contributions of AI. The advantage of these algorithms, compared to uninformed or blind search algorithmssuch as depth-first search and breadth-first search, is that they use heuristics to guide the search toward the goal andin this way significantly reduce the number of visited states. The algorithms differ mainly by the way they evaluatenodes in the search tree. A* is probably the most widely known BFS algorithm. Each search node of A* is associated✩ This work is an extended version of a paper presented at AAAI-02 [R.M. Jensen, R.E. Bryant, M.M. Veloso, SetA*: An efficient BDD-basedheuristic search algorithm, in: Proceedings of 18th National Conference on Artificial Intelligence (AAAI-02), 2002, pp. 668–673]. The work wassupported in part by the Danish Research Agency and the United States Air Force under Grants Nos F30602-00-2-0549 and F30602-98-2-0135.The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the officialpolicies or endorsements, either expressed or implied, of the Defense Advanced Research Projects Agency (DARPA), the Air Force, or the USGovernment.* Corresponding author.E-mail addresses: runej@cs.cmu.edu (R.M. Jensen), mmv@cs.cmu.edu (M.M. Veloso), bryant@cs.cmu.edu (R.E. Bryant).URLs: http://www.cs.cmu.edu/~runej (R.M. Jensen), http://www.cs.cmu.edu/~mmv(M.M. Veloso), http://www.cs.cmu.edu/~bryant(R.E. Bryant).1 In this article, BFS always refers to best-first search and not breadth-first search.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.009\f104R.M. Jensen et al. / Artificial Intelligence 172 (2008) 103–139with a cost g of reaching the node and a heuristic estimate h of the remaining cost of reaching the goal. In eachiteration, A* expands a node with minimum expected completion cost f = g + h. A* can be shown to have muchbetter performance than uninformed search algorithms. However, an unresolved problem for this algorithm is that thenumber of expanded search nodes may grow exponentially even if the heuristic has only a small constant relative error[46]. Such heuristic functions are often encountered in practice, since many heuristics are derived from a relaxationof the search problem that is likely to introduce a relative error. Furthermore, in order to detect duplicate states andconstruct a solution, A* must keep all expanded nodes in memory. For this reason, the limiting factor of A* is oftenspace rather than time.In symbolic model checking [42], a quite different approach has been taken to verify systems with large state spaces.Instead of representing and manipulating sets of states explicitly, this is done implicitly using Boolean functions.2Given a bit vector encoding of states, characteristic functions are used to represent subsets of states. In a similarway, a Boolean function can be used to represent the transition relation of a domain and find successor states viaBoolean function manipulation. The approach potentially reduces both the time and space complexity exponentially.Indeed during the last decade, remarkable results have been obtained using reduced ordered Binary Decision Diagrams(BDDs [9]) as the Boolean function representation. Systems with more than 10100 states have been successfullyverified with the BDD-based model checker SMV [42]. For several reasons, however, only very limited work onusing heuristics to guide these implicit search algorithms has been carried out. First of all, the solution techniquesconsidered in formal verification often require traversal of all reachable states making search guidance irrelevant.Secondly, it is non-trivial to efficiently handle cost estimates such as the g and h-costs associated with individualstates when representing states implicitly.In this article, we present a new framework called state-set branching that combines BDD-based search and best-first search (BFS) and efficiently solves the problem of representing cost estimates. State-set branching applies toany BFS algorithm and any transition cost function, heuristic function, and node-evaluation function defined over afinite domain. The state-set branching framework consists of two independent parts. The first part extends a generalBFS algorithm to an algorithm called best-set-first search (BSFS) that expands sets of states in each iteration. Thesecond part is an efficient BDD-based implementation of BSFS using a partitioning of the transition relation of thesearch domain called branching partitioning. Branching partitioning allows sets of states to be expanded implicitlyand sorted according to their associated cost estimates. The approach applies both to disjunctive and conjunctivepartitioning [15].Two implementations of A* based on the state-set branching framework called FSETA* anf GHSETA* have beenexperimentally evaluated in 10 search domains ranging from VLSI-design with synchronous actions, to classicalAI planning problems such as the (N 2 − 1)-puzzles and problems used in the international planning competitions1998–2004 [2,29,39,40]. We apply four different families of heuristic functions ranging from the minimum Hammingdistance to the sum of Manhattan distances for the (N 2 − 1)-puzzles, and HSPr [8] for the planning problems. In thisexperimental evaluation, the two A* implementations outperform implementations of the ordinary A* algorithm inall domains except one where an efficient Boolean state encoding seems to be challenging to find.3 In addition, theresults show that they can improve the complexity of A* exponentially and that they often dominate both the ordinaryA* algorithm and blind BDD-based search by several orders of magnitude. Moreover, they have substantially betterperformance than BDDA*, the currently most efficient symbolic implementation of A*.The main limitation of the state-set branching framework is that a Boolean state encoding with a compact BDDrepresentation must be found for a target domain. In most cases this is easy, but for general domain representation lan-guages such as PDDL [24] it may be challenging to define automated encoding techniques. Another issue is whetherbranching partitionings are easy to obtain for all heuristics. The experiments in this article show that additive heuris-tics like the sum of Manhattan distances and the HSPr heuristic can be represented compactly. A recent study [32],however, shows that branching partitionings of the max-pair heuristic [28] may be prohibitively large. It is not ourimpression, though, that strong domain dependent heuristics are as combinatorial complex as the max-pair heuristic.2 By an explicit representation, we mean an enumerative representation that uses space linear in the number of represented elements. By animplicit representation, we mean a non-enumerative representation using Boolean expressions to characterize elements.3 By ordinary A* we refer to the graph-search version of A* that maintains a closed list for duplicate elimination and uses an explicit staterepresentation.\fR.M. Jensen et al. / Artificial Intelligence 172 (2008) 103–139105The remainder of this article is organized as follows. We first describe related work in Section 2. We then definesearch problems in Section 3 and describe the general BFS algorithm in Section 4. In Section 5, we extend this algo-rithm to expand sets of states and study a number of example applications of the new best-set-first search algorithm.In Section 6, we introduce branching partitioning and other BDD-based techniques to efficiently implement thesealgorithms. The experimental evaluation is described in Section 7. Finally, we conclude and discuss directions forfuture work in Section 8.2. Related workState-set branching is the first general framework for combining heuristic search and BDD-based search. All previ-ous work has been restricted to particular algorithms. BDD-based heuristic search has been investigated independentlyin symbolic model checking and AI. The pioneering work is in symbolic model checking where heuristic searc",
            {
                "entities": [
                    [
                        3518,
                        3546,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 258 (2018) 1–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExtracting mutual exclusion invariants from lifted temporal planning domainsSara Bernardini a,∗a Department of Computer Science, Royal Holloway University of London, Egham, Surrey, TW20 0EX, UKb Department of Mathematical Sciences “G. L. Lagrange”, Politecnico di Torino, Corso Duca degli Abruzzi, 24, 10129 Torino, Italyc Intelligent Systems Division, NASA Ames Research Center, Moffett Field, CA 94035, United States, Fabio Fagnani b, David E. Smith ca r t i c l e i n f oa b s t r a c tArticle history:Received 6 January 2017Received in revised form 24 January 2018Accepted 27 January 2018Available online 6 February 2018Keywords:Automated planningTemporal planningMutual exclusion invariantsAutomatic domain analysisWe present a technique for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies a set of invariant templates by inspecting the lifted representation of the domain and then checks these templates against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire temporal structure of the actions and the possible concurrent interactions between them. As a result, we construct a more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains but also a broader set of invariants for sequential domains. Our experimental results provide evidence that our domain analysis is effective at identifying a more extensive set of invariants, which results in the generation of fewer multi-valued state variables. We show that, in turn, this reduction in the number of variables reflects positively on the performance of the temporal planners that use a variable/value representation.© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionThis paper presents a technique for synthesising mutual exclusion invariants from temporal planning domains expressed in PDDL2.1 [21]. A mutual exclusion invariant over a set of ground atoms means that at most one atom in the set is true at any given moment. Mutual exclusion invariants can be expressed as multi-valued state variables by adding a special “null” value so that, at all moments, precisely one value holds. For instance, consider the Floortile domain from the 8th International Planning Competition (IPC’14 – see Appendix A). A mutual exclusion invariant for this domain states that two ground atoms that indicate the position of a robot can never be true at the same time. Intuitively, this means that a robot cannot be at two different locations simultaneously. To give a concrete case, consider a planning problem for the Floortiledomain with one robot r1 and three locations, t1, t2 and t3. We can create a state variable that indicates the position of r1 with a domain of three values: robotAt_r1_t1, robotAt_r1_t2 and robotAt_r1_t3.Although a number of approaches to invariant synthesis have been proposed so far [27,45,46,20,33], they are limited in scope because they deal with sequential domains only. Recently, Rintanen [47] has proposed a technique for temporal domains, but this technique does not scale to complex problems because it requires grounding the domain. We address * Corresponding author.E-mail addresses: sara.bernardini@rhul.ac.uk (S. Bernardini), fabio.fagnani@polito.it (F. Fagnani), david.smith@PSresearch.xyz (D.E. Smith).https://doi.org/10.1016/j.artint.2018.01.0040004-3702/© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f2S. Bernardini et al. / Artificial Intelligence 258 (2018) 1–65Table 1Examples of planners and their classification based on whether they treat time explicitly or implicitly and whether they use a Boolean propositional representation or a multi-valued state variable representation.PropositionalVariable/valueClassicalTemporalHSP [9] FF [35] YAHSP [49]LPG [25] POPF [12]FD [32] LAMA [44]TFD [18] EUROPA2 [23]both limitations. We find invariants for temporal domains by applying an algorithm that works at the lifted level of the representation and, in consequence, is very efficient and scales to large instances.Our invariant synthesis builds on Helmert [33], which presents a technique to translate the non-temporal subset of PDDL2.2 [17] into the Finite Domain Representation (FDR), a multi-valued planning task formalism used by Fast Down-ward [32]. Since finding invariants for temporal tasks is much more complex than for tasks with instantaneous actions, a simple generalisation of Helmert’s technique to temporal settings does not work. In the temporal case, simultaneity and interference between concurrent actions can occur, hence our algorithm cannot check actions individually against the invari-ance conditions, but needs to consider the entire set of actions and their possible intertwinements over time. In capturing the temporal case, we formulate invariance conditions that take into account the entire structure of the action schemas as well as the possible interactions between them. As a result, we construct a significantly more comprehensive technique that is able to find not only invariants for temporal domains, but also a broader set of invariants for sequential domains.We describe our approach in two major steps. First, we provide a general theory at the ground level and offer results that insure invariance under two types of properties: safety conditions for individual instantaneous and durative actions as well as collective conditions that prevent dangerous intertwinements between durative actions. Then, we lift these results to the level of schemas so that all checks needed for verifying invariance can be performed at this higher level, without the need for grounding the domain. The complexity of these checks are of linear or low polynomial order in terms of the number of schemas and literals appearing in the domain.1.1. MotivationsAutomated planning is a well-established field of artificial intelligence and, in the more than fifty years since its appear-ance, several paradigms have emerged. One fundamental difference between these paradigms is whether time is treated implicitly or explicitly. While classical planning focuses on the causal evolution of the world, temporal planning is concerned with the temporal properties of the world. In classical planning, actions are considered to be instantaneous, whereas in tem-poral planning actions have durations and can be executed concurrently. Another important difference between planning paradigms relates to whether the world is modelled by adopting a Boolean propositional representation or a representation based on multi-valued state variables. The majority of the work in planning has been devoted to classical planning with domains expressed using propositional languages, and in particular PDDL [41] and its successors [21], the language of the International Planning Competition (IPC). However, in parallel with the development of classical propositional planning, a number of temporal planning systems have been proposed for coping with practical problems, especially space mission op-erations [23,11,28,42,24]. Typically, these systems use variable/value representations. Table 1 shows a classification of several well-known planners based on these different characteristics.Recently, a few techniques have been proposed for translating propositional representations into variable/value represen-tations [32,5,47]. A central task of all these techniques is the generation of state variables from propositions and actions. The basic procedure to do this (which we use as the baseline in our experiments) relies on generating one state variable with two values, true and false, for each proposition. Naturally, such translation produces no performance advantage. A more sophisticated strategy, which produces more compact and optimised encodings, rests on extracting mutual exclusion invari-ants from propositional domains and using such invariants to generate multi-valued state variables. This is the focus of our work.These translation techniques are important as they allow fair testing of planners developed for variable/value repre-sentations on PDDL benchmarks (which are propositional). The practical issue is that planners that permit variable/value representation need this feature to be thoroughly exploited and perform competitively. Since translation between the two different representations can be cheaply automated, there is no reason to avoid providing the richer representations to those planners that accept them (if the translation was expensive, one might reasonably argue about the fairness of this process). As a consequence, these translation techniques are extremely useful for comparing alternative planning paradigms and for promoting cross-fertilisation of ideas between different planning communities, which is our primary motivation.However, the importance of these translation techniques goes beyond the engineering of a bridge between different input languages. In transforming propositional representations into state variable representations, they generate new domain knowledge, where new means accessible in this context. Effectively, these techniques are internal mini theorem provers since, rather than merely translating, they firstly selectively explore the deductive closure of the original theory to find theorems that permit optimising the representation, and secondly execute those optimisations. We will show that the cost of performing t",
            {
                "entities": [
                    [
                        3823,
                        3851,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 193 (2012) 45–86Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlanning as satisfiability: HeuristicsJussi RintanenInstitute for Integrated and Intelligent Systems, Griffith University, Queensland, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 June 2011Received in revised form 2 May 2012Accepted 9 August 2012Available online 5 September 2012Keywords:PlanningSATHeuristics1. IntroductionReduction to SAT is a very successful approach to solving hard combinatorial problems inArtificial Intelligence and computer science in general. Most commonly, problem instancesreduced to SAT are solved with a general-purpose SAT solver. Although there is the obviouspossibility of improving the SAT solving process with application-specific heuristics, thishas rarely been done successfully.In this work we propose a planning-specific variable selection strategy for SAT solving. Thestrategy is based on generic principles about properties of plans, and its performance withstandard planning benchmarks often substantially improves on generic variable selectionheuristics, such as VSIDS, and often lifts it to the same level with other search methodssuch as explicit state-space search with heuristic search algorithms.© 2012 Elsevier B.V. All rights reserved.Translation into SAT, the satisfiability problem of the classical propositional logic, is one of the main approaches to solvingthe planning problem in AI. The basic idea, first presented by Kautz and Selman [1], is to consider a bounded-horizonplanning problem, to represent the values of state variables at every time point as propositional variables, to representthe relation between two consecutive states as a propositional formula, and then to synthesize a propositional formulathat is satisfiable if and only if there is a plan of the given bounded length. This idea is closely related to the simulationof nondeterministic polynomial-time Turing machines in Cook’s proof of NP-hardness of SAT [2]. Kautz and Selman’s ideawas considered to be only of theoretical interest until 1996 when algorithms for SAT had developed far enough to makeplanning with SAT practical and competitive with other search methods [3]. Later, SAT and its extensions have become amajor state-space search method in computer-aided verification [4] and in many other areas.In this work we investigate SAT solving for planning with the conflict-driven clause learning (CDCL) algorithm [5,6], thecurrently leading framework for SAT solving for structured problems. Instead of using standard generic CDCL heuristics suchas VSIDS [7], we propose planning-specific heuristics which radically differ from generic CDCL heuristics and are based on asimple property all solutions to a planning problem have to satisfy. The work is motivated by the need to better understandwhy SAT solvers are successful in solving AI planning and other reachability problems, and by the need and opportunity todevelop more powerful, problem-specific heuristics for SAT.Our heuristic chooses action variables that contribute to the goals or subgoals, based on the current partial valuationof the CDCL algorithm, representing a tentative plan and a state sequence corresponding to its execution. The principle isextremely simple: for a given (sub)goal, choose an action that achieves the (sub)goal and that can be taken at the earliest time inwhich the (sub)goal can become (and remain) true. Intuitively, this principle expresses a preference for short and simple plans.After choosing an action, its preconditions become new subgoals for which supporting actions are found in the same way.The principle is easy to implement: start from a goal (or a subgoal), go backwards step by step until a time point in whichE-mail address: jussi@cecs.anu.edu.au.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.08.001\f46J. Rintanen / Artificial Intelligence 193 (2012) 45–86the goal is false, and choose any of the actions that can turn it from false to true at that time point. If such an action existedin the plan already, perform the procedure recursively with the preconditions of the action as the subgoals.Interestingly, it turns out that heuristics based on the above principle are often far more effective in finding plans thanthe sophisticated heuristics used by modern general-purpose SAT solvers. Furthermore, a naïve application of the principle –leading to a depth-first backward chaining planning algorithm inside the CDCL framework – lifts the efficiency of SAT-basedplanning close to level with the best earlier planners which use other search methods. This is a very significant result,because the currently best state-space search planners, which have their origins in the work of Bonet and Geffner [8], usefar more complex heuristics and additional pruning techniques to achieve a comparable performance.The simplicity and effectiveness of the principle immediately suggests that there are additional heuristics to obtainfurther efficiency improvements. Instead of finding motivation for such heuristics from standard benchmarks, we look atgeneric properties of planning problems and generic structural properties of the search trees generated by the principle. Wepresent heuristics for ordering the new subgoals and for choosing one of the applicable actions, as well as propose a schemethat replaces the pure depth-first backward search by a less directional form of search. For standard benchmark problemsin planning, the additional heuristics lift the performance of the new variable selection scheme still further.We view this work as a step toward developing efficient SAT-based techniques for planning and other related problemssuch as model-checking [4] and discrete-event systems diagnosis [9]. More advanced heuristics for these applications arelikely to also incorporate features from VSIDS, including the computation of weights of variables based on their occurrencein recently learned clauses. We believe that the success of the planner developed in this work with the standard planningbenchmark problems is more an indication of the simple structure of these benchmarks, and that more challenging problemswill need more complex variable selection heuristics. This observation is supported by earlier works that illustrate thescalability of typical planners in solving combinatorially hard problems [10,11].The structure of the paper is as follows. Section 2 describes the background of the work in planning with SAT. InSection 3 we present the variable selection scheme for planning, and in Section 4 we propose additional heuristics for it.Section 5 describes the implementation of a planning system that is based on the preceding two sections and our earlierworks [12]. In Section 6 we experimentally evaluate the planning system, and in Section 7 we discuss related work beforeconcluding the paper in Section 8.2. Planning as satisfiability2.1. BackgroundReduction to the SAT problem was proposed as a way of solving the planning problem in the 1992 paper by Kautz andSelman [1]. At the same time, algorithms for solving the SAT problem were progressing rapidly, and in 1996 Kautz andSelman were able to show their planning system to scale up better than Graphplan [13] and other planning systems of thetime [3]. These results were obtained with SAT solvers such as WalkSat [14,15] and Tableau [16].The reduction to SAT and the general solution method outlined by Kautz and Selman dominated the SAT approach toplanning for the next several years, and became the basis of scientifically and commercially very successful computer-aidedverification methods in the form of bounded model-checking [4]. In the planning community, however, the focus shifted toheuristic state-space search algorithms as proposed by Bonet, Loerincs and Geffner in the HSP planner starting in 1997[17,8].The decreasing interest of planning researchers in SAT at this time can be traced to two factors: the impractically largesize of the CNF formulas generated from the standard benchmark problems with the early encoding schemes, and the veryhigh computational cost of completing the satisfiability tests for horizon lengths shorter than the shortest plan.As proposed by Kautz and Selman, the planners sequentially went through horizon lengths 0, 1, 2, and so on, until theyreached a horizon length for which the formula is satisfiable, yielding a plan. Essentially, Kautz and Selman’s procedurecorresponds to breadth-first search, and these planners proved that the plan that was found had the shortest possiblehorizon. However, guaranteeing that plans have the shortest possible horizon is unimportant, as the horizon length doesnot, for commonly used notions of parallel plans, coincide with relevant plan quality measures, such as the sum of actioncosts. The notion of parallelism also does not correspond to actual temporal concurrency, but the possibility of reordering theparallel actions to a valid sequential plan [12], and therefore should be viewed as a way of inducing a smaller search space.The unsatisfiability proofs could be avoided by using parallelized search strategies [18]. These often speed up planning byorders of magnitude. At the same time, compact linear-size encodings were proposed. Earlier encodings, such as those basedon the planning graphs of Graphplan [13], had a quadratic size, due to the encoding of action mutexes in the most straight-forward way as binary clauses. The linear-size encodings largely eliminated the problem of excessive memory consumption,and also otherwise yielded substantial performance improvements [19,12]. These developments bridged the performancegap between SAT-based planning and explicit state-space search substantially (for standard benchmarks), and reduced thememory consumption so that it was not an obstacle to efficient planning.Since mid-1990s, there have also ",
            {
                "entities": [
                    [
                        3948,
                        3976,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 196 (2013) 106–142Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomatic behavior composition synthesisGiuseppe De Giacomo a, Fabio Patrizi a, Sebastian Sardiña b,∗a Dipartimento di Informatica e Sistemistica, Sapienza Università di Roma, Rome, Italyb School of Computer Science and IT, RMIT University, Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 9 February 2011Received in revised form 28 November 2012Accepted 13 December 2012Available online 2 January 2013Keywords:Knowledge representation and reasoningIntelligent agentsReasoning about actions and changeAutomated planningSynthesis of reactive systemsThe behavior composition problem amounts to realizing a virtual desired module (e.g.,a surveillance agent system) by suitably coordinating (and re-purposing) the execution of aset of available modules (e.g., a video camera, vacuum cleaner, a robot, etc.). In particular,we investigate techniques to synthesize a controller implementing a fully controllable tar-get behavior by suitably coordinating available partially controllable behaviors that are toexecute within a shared, fully observable, but partially predictable (i.e., non-deterministic),environment. Both behaviors and environment are represented as arbitrary finite state tran-sition systems. The technique we propose is directly based on the idea that the controllerjob is to coordinate the concurrent execution of the available behaviors so as to “mimic”the target behavior. To this end, we exploit a variant of the formal notion of simulationto formally capture the notion of “mimicking”, and we show that the technique proposedis sound and complete, optimal with respect to computational complexity, and robust fordifferent kind of system failures. In addition, we demonstrate that the technique is wellsuited for highly efficient implementation based on synthesis by model checking technolo-gies, by relating the problem to that of finding a winning strategy in a special safety gameand explaining how to actually solve it using an existing verification tool.© 2013 Elsevier B.V. All rights reserved.1. IntroductionIn this paper, we provide a thorough investigation—from theory to implementation—of the behavior composition prob-lem, that is, the problem of how to realize an abstract desired target behavior module by reusing and re-purposing a setof accessible modules implementing certain concrete behaviors. More concretely, we are interested in synthesizing a sort ofcontroller that coordinates the available existing behaviors in order to replicate a given desired target behavior [30,79,80].Generally speaking, a behavior stands for the logic of any artifact that is able to operate in the environment, such as devices,agents, software or hardware components, or workflows. For example, consider a painting blocks world scenario in whichblocks are painted and processed by different robotic arms; different behaviors stand for different types of arms (e.g., a grip-per, a painting arm, a cleaner arm, etc.), all acting in the same environment. The aim is to realize a desired (intelligent)virtual painting system by suitably “combining” the available arms.Behavior composition is of particular interest in agents and multi-agent settings. A (desired) intelligent system maybe built, for example, from a variety of existing different modules operating (that is, performing actions) on a commonenvironment and whose logic is only partially known. These modules may, in turn, be other agents themselves. A set ofRoboCup players with different capabilities can be put together to form an (abstract) more sophisticated “team” player. Sim-ilarly, a BDI (Belief–Desire–Intention) agent may implement a desired deterministic plan (which was probably obtained via* Corresponding author.E-mail addresses: degiacomo@dis.uniroma1.it (G. De Giacomo), patrizi@dis.uniroma1.it (F. Patrizi), sebastian.sardina@rmit.edu.au (S. Sardiña).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.001\fG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142107planning or agent communication) by appealing to the set of available user pre-defined non-deterministic plans [36,75]. Inrobot ecologies and ambient intelligence, advanced functionalities, such as a home surveillance agent, are achieved throughthe composition of many simple robotic devices, such as a vacuum cleaner, a lamp, or a video camera [76,17].Our work is really a form of process synthesis as studied in Computer Science [70,1,89,51]. However, while most litera-ture on synthesis concentrates on synthesizing a process satisfying a certain specification from scratch, behavior compositionfocuses on synthesizing a process (the controller) starting from available components [54]. This idea of composing andreusing components has been strongly put forward by Service Oriented Computing, under the name of “service com-position” [2,42,63,86]. Indeed, service composition aims at composing complex services by orchestrating (i.e., controllingand coordinating) services that are already at disposal. When service composition takes into account the behavior of thecomponent service, as in [20,84,16] for instance, it becomes intimately related to what we call here “behavior composi-tion”.When we look at behavior composition from an Artificial Intelligence perspective, the issue of actual controllability ofthe available behaviors becomes prominent. While one can instruct a behavior module to carry out an action, the actualoutcome of the action may not always be foreseen a priori, though it can possibly be observed after execution. Our workhere is based on revisiting a certain stream of work in service composition [13–15], called “Roman Model” in [42,86], butkeeping the need of dealing with partial controllability central. In particular, we consider the problem of synthesizing a fullycontrollable target behavior from a library of available partially controllable behaviors that are to execute within a shared,fully observable, but partially predictable environment [30,79].Technically, we abstract behaviors and the environment as finite state transition systems. More precisely, each availablemodule is represented as a non-deterministic transition system (to model partial controllability); the target behavior isrepresented as a deterministic transition system (to model full controllability); and the environment is represented as anon-deterministic transition system (to model partial predictability). The environment’s states are fully accessible by theother transition systems. Working with finite state transition systems allows us to leverage on research in Verification andSynthesis in Computer Science [69,87,50,3,23].Once we settle for a formal specification of the problem of concern, we develop a novel sound and complete, and optimalw.r.t. worst-case computational complexity technique to generate so-called compositions. The technique is directly based onthe idea that a composition amounts to a controller that coordinates the concurrent execution of the available modulesso as to “mimic” the desired target behavior. We capture “mimicking” through the formal notion of simulation [60,41].Obviously, we need to consider that available behaviors as well as the environment are only partially controllable (i.e.,non-deterministic), and therefore a special variant of the classical notion of simulation ought to be devised.The proposed technique has several interesting features:• The technique is sound and complete, in a very strong sense: it allows to synthesize a sort of meta-controller, calledcontroller generator, that represents all possible compositions. While the set of possible compositions is infinite (in factuncountable) in general, the controller generator is unique.• The technique gives us a very precise characterization of the sources of complexity in the problem: it allows for comput-ing the controller generator (i.e., an implicit representation of all compositions) in time exponential only in the numberof available behaviors, but not in the number of their states. Observe that checking the existence of a composition isknown to be EXPTIME-hard even for deterministic available behaviors running in a stateless environment [61].• Due to its “universality”, the controller generator can be used to generate a sort of lazy composition on-the-fly, possiblyadapting reactively based on runtime feedback.In particular, we shall argue that the composition solutions obtained are robust to behavior failures in two ways. First,they can handle (a) temporary behavior unavailability as well as (b) unexpected behavior/environment evolution in atotally reactive and on-the-fly manner—that is, without any extra effort or “re-planning” required to continue the realiza-tion of the target behavior—if at all possible, by the very nature of the composition generator. Second, the compositionsolutions can be parsimoniously refined when a module (c) becomes permanently unavailable, or (d) unexpectedly re-sumes operation.We complement the proposed technique by showing how it can be implemented by making use of model checkingtechnology applied to some special game structures developed in the context of Synthesis in Computer Science [3,47,40,69,27]. To that end, we show how to polynomially encode behavior compositions into safety games of a specific form, in whicheach strategy for winning the game corresponds to a composition (Section 5). With that reduction at hand, one is then ableto use available tools such as tlv [71] in order to actually compute the controller generator by symbolic model checking(Section 6).Most results presented in this paper appeared at an earlier stage in [30,79,15,80,26]. Here we revise, extend, and combinethem into a uniform and in-depth investigation which includes all the technical details and extended example",
            {
                "entities": [
                    [
                        4107,
                        4135,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2291–2320Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMulti-instance multi-label learningZhi-Hua Zhou∗, Min-Ling Zhang, Sheng-Jun Huang, Yu-Feng LiNational Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210046, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 29 April 2010Received in revised form 25 September2011Accepted 13 October 2011Available online 18 October 2011Keywords:Machine learningMulti-instance multi-label learningMIMLMulti-label learningMulti-instance learningIn this paper, we propose the MIML (Multi-Instance Multi-Label learning) framework wherean example is described by multiple instances and associated with multiple class labels.Compared to traditional learning frameworks, the MIML framework is more convenientand natural for representing complicated objects which have multiple semantic meanings.To learn from MIML examples, we propose the MimlBoost and MimlSvm algorithmsbased on a simple degeneration strategy, and experiments show that solving problemsinvolving complicated objects with multiple semantic meanings in the MIML frameworkcan lead to good performance. Considering that the degeneration process may loseinformation, we propose the D-MimlSvm algorithm which tackles MIML problems directlyin a regularization framework. Moreover, we show that even when we do not haveaccess to the real objects and thus cannot capture more information from real objectsby using the MIML representation, MIML is still useful. We propose the InsDif and SubCodalgorithms. InsDif works by transforming single-instances into the MIML representationfor learning, while SubCod works by transforming single-label examples into the MIMLrepresentation for learning. Experiments show that in some tasks they are able to achievebetter performance than learning the single-instances or single-label examples directly.© 2011 Elsevier B.V. All rights reserved.1. IntroductionIn traditional supervised learning, an object is represented by an instance, i.e., a feature vector, and associated with a classlabel. Formally, let X denote the instance space (or feature space) and Y the set of class labels. The task is to learn afunction f : X → Y from a given data set {(x1, y1), (x2, y2), . . . , (xm, ym)}, where xi ∈ X is an instance and yi ∈ Y is theknown label of xi . Although this formalization is prevailing and successful, there are many real-world problems which donot fit in this framework well. In particular, each object in this framework belongs to only one concept and therefore thecorresponding instance is associated with a single class label. However, many real-world objects are complicated, whichmay belong to multiple concepts simultaneously. For example, an image can belong to several classes simultaneously, e.g.,grasslands, lions, Africa, etc.; a text document can be classified to several categories if it is viewed from different aspects,e.g., scientific novel, Jules Verne’s writing or even books on traveling; a web page can be recognized as news page, sports page,soccer page, etc. In a specific real task, maybe only one of the multiple concepts is the right semantic meaning. For example,in image retrieval when a user is interested in an image with lions, s/he may be only interested in the concept lions insteadof the other concepts grasslands and Africa associated with that image. The difficulty here is caused by those objects thatinvolve multiple concepts. To choose the right semantic meaning for such objects for a specific scenario is the fundamentaldifficulty of many tasks. In contrast to starting from a large universe of all possible concepts involved in the task, it maybe helpful to get the subset of concepts associated with the concerned object at first, and then make a choice in the* Corresponding author.E-mail address: zhouzh@lamda.nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.10.002\f2292Z.-H. Zhou et al. / Artificial Intelligence 176 (2012) 2291–2320small subset later. However, getting the subset of concepts, that is, assigning proper class labels to such objects, is still achallenging task.We notice that as an alternative to representing an object by a single instance, in many cases it is possible to representa complicated object using a set of instances. For example, multiple patches can be extracted from an image where eachpatch is described by an instance, and thus the image can be represented by a set of instances; multiple sections can beextracted from a document where each section is described by an instance, and thus the document can be represented by aset of instances; multiple links can be extracted from a web page where each link is described by an instance, and thus theweb page can be represented by a set of instances. Using multiple instances to represent those complicated objects may behelpful because some inherent patterns which are closely related to some labels may become explicit and clearer. In thispaper, we propose the MIML (Multi-Instance Multi-Label learning) framework, where an example is described by multipleinstances and associated with multiple class labels.Compared to traditional learning frameworks, the MIML framework is more convenient and natural for representingcomplicated objects. To exploit the advantages of the MIML representation, new learning algorithms are needed. We proposethe MimlBoost algorithm and the MimlSvm algorithm based on a simple degeneration strategy, and experiments show thatsolving problems involving complicated objects with multiple semantic meanings under the MIML framework can lead togood performance. Considering that the degeneration process may lose information, we also propose the D-MimlSvm (i.e.,Direct MimlSvm) algorithm which tackles MIML problems directly in a regularization framework. Experiments show thatthis “direct” algorithm outperforms the “indirect” MimlSvm algorithm.In some practical tasks we do not have access to the real objects themselves such as the real images and the real webpages; instead, we are given observational data where each real object has already been represented by a single instance.Thus, in such cases we cannot capture more information from the real objects using the MIML representation. Even in thissituation, however, MIML is still useful. We propose the InsDif (i.e., INStance DIFferentiation) algorithm which transformssingle-instances into MIML examples for learning. This algorithm is able to achieve a better performance than learning thesingle-instances directly in some tasks. This is not strange because for an object associated with multiple class labels, ifit is described by only a single instance, the information corresponding to these labels are mixed and thus difficult forlearning; if we can transform the single-instance into a set of instances in some proper ways, the mixed information mightbe detached to some extent and thus less difficult for learning.MIML can also be helpful for learning single-label objects. We propose the SubCod (i.e., SUB-COncept Discovery) algo-rithm which works by discovering sub-concepts of the target concept at first and then transforming the data into MIMLexamples for learning. This algorithm is able to achieve a better performance than learning the single-label examples di-rectly in some tasks. This is also not strange because for a label corresponding to a high-level complicated concept, it maybe quite difficult to learn this concept directly since many different lower-level concepts are mixed; if we can transform thesingle-label into a set of labels corresponding to some sub-concepts, which are relatively clearer and easier for learning, wecan learn these labels at first and then derive the high-level complicated label based on them with a less difficulty.The rest of this paper is organized as follows. In Section 2, we review some related work. In Section 3, we propose theMIML framework. In Section 4 we propose the MimlBoost and MimlSvm algorithms, and apply them to tasks where theobjects are represented as MIML examples. In Section 5 we present the D-MimlSvm algorithm and compare it with the“indirect” MimlSvm algorithm. In Sections 6 and 7, we study the usefulness of MIML when we do not have access to realobjects. Concretely, in Section 6, we propose the InsDif algorithm and show that using MIML can be better than learningsingle-instances directly; in Section 7 we propose the SubCod algorithm and show that using MIML can be better thanlearning single-label examples directly. Finally, we conclude the paper in Section 8.2. Related workMuch work has been devoted to the learning of multi-label examples under the umbrella of multi-label learning. Notethat multi-label learning studies the problem where a real-world object described by one instance is associated with anumber of class labels,1 which is different from multi-class learning or multi-task learning [28]. In multi-class learning eachobject is only associated with a single label; while in multi-task learning different tasks may involve different domains anddifferent data sets. Actually, traditional two-class and multi-class problems can both be cast into multi-label problems byrestricting that each instance has only one label. The generality of multi-label problems, however, inevitably makes it moredifficult to address.One famous approach to solving multi-label problems is Schapire and Singer’s AdaBoost.MH [56], which is an extensionof AdaBoost and is the core of a successful multi-label learning system BoosTexter [56]. This approach maintains a set ofweights over both training examples and their labels in the training phase, where training examples and their correspondinglabels that are hard (easy) to predict get incrementally higher (lower) weights. Later, De Comité et al. [22] used alternatingdecision trees [30] which are more powerfu",
            {
                "entities": [
                    [
                        4024,
                        4052,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 110–146Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe complexity and generality of learning answer set programsMark Law∗, Alessandra Russo, Krysia BrodaDepartment of Computing, Imperial College London, SW7 2AZ, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 2 September 2016Received in revised form 20 February 2018Accepted 15 March 2018Available online 21 March 2018Keywords:Non-monotonic logic-based learningAnswer Set ProgrammingComplexity of non-monotonic learningTraditionally most of the work in the field of Inductive Logic Programming (ILP) has ad-dressed the problem of learning Prolog programs. On the other hand, Answer Set Program-ming is increasingly being used as a powerful language for knowledge representation and reasoning, and is also gaining increasing attention in industry. Consequently, the research activity in ILP has widened to the area of Answer Set Programming, witnessing the pro-posal of several new learning frameworks that have extended ILP to learning answer set programs. In this paper, we investigate the theoretical properties of these existing frame-works for learning programs under the answer set semantics. Specifically, we present a detailed analysis of the computational complexity of each of these frameworks with re-spect to the two decision problems of deciding whether a hypothesis is a solution of a learning task and deciding whether a learning task has any solutions. We introduce a new notion of generality of a learning framework, which enables us to define a framework to be more general than another in terms of being able to distinguish one ASP hypothesis solution from a set of incorrect ASP programs. Based on this notion, we formally prove a generality relation over the set of existing frameworks for learning programs under answer set se-mantics. In particular, we show that our recently proposed framework, Context-dependent Learning from Ordered Answer Sets, is more general than brave induction, induction of stable models, and cautious induction, and maintains the same complexity as cautious induction, which has the highest complexity of these frameworks.© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionOver the last two decades there has been a growing interest in Inductive Logic Programming (ILP) [1], where the goal is to learn a logic program called a hypothesis, which together with a given background knowledge base, explains a set of examples. The main advantage that ILP has over traditional statistical machine learning approaches is that the learned hypotheses can be easily expressed in plain English and explained to a human user, so facilitating a closer interaction be-tween humans and machines. Traditional ILP frameworks have focused on learning definite logic programs [1–6] and normal logic programs [7,8]. On the other hand, Answer Set Programming [9] is a powerful language for knowledge representation and reasoning. ASP is closely related to other declarative paradigms such as SAT, SMT and Constraint Programming, which have each been used for inductive reasoning [10–12]. Compared with these other paradigms, due to its non-monotonicity, ASP is particularly suited for common-sense reasoning [13–15]. Because of its expressiveness and efficient solving, ASP is * Corresponding author at: Department of Computing, Huxley Building, 180 Queen’s Gate, Imperial College London, London, SW7 2AZ, United Kingdom.E-mail address: mark.law09 @imperial .ac .uk (M. Law).https://doi.org/10.1016/j.artint.2018.03.0050004-3702/© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM. Law et al. / Artificial Intelligence 259 (2018) 110–146111also increasingly gaining attention in industry [16]; for example, in decision support systems [17], in e-tourism [18] and in product configuration [19]. Consequently, the scope of ILP has recently been extended to learning answer set programs from examples of partial solutions of a given problem, with the intention being to provide algorithms that support automated learning of complex declarative knowledge. Learning ASP programs allows us to learn a variety of declarative non-monotonic, common-sense theories, including for instance Event Calculus [20] theories [21] and theories for scheduling problems and agents’ preference models, both from real user data [22] and from synthetic data [23,24].Learning ASP programs has several advantages when compared to learning Prolog programs. Firstly, when learning Prolog programs, the goal directed SLDNF procedure of Prolog must be taken into account. Specifically, when learning programs with negation, it must be ensured that the programs are stratified, or otherwise the learned program may loop under certain queries. As ASP is declarative, no such consideration need be taken into account when learning ASP programs. A second, more fundamental advantage of learning ASP programs, is that the theory learned can be expressed using extra types of rules that are not available in Prolog, such as choice rules and weak constraints. Learning choice rules allows us to learn non-deterministic concepts; for instance, we may learn that a coin may non-deterministically land on either heads or tails, but never both. This could be achieved by learning the simple choice rule 1{heads, tails}1. Learning choice rules is different from probabilistic ILP settings such as [25–27] where, in similar coins problems the focus would be on learning the probabilities of the two outcomes of are coin. Learning weak constraints enables a natural extension of ILP to preference learning [23], which has resulted to be effective in problem domains such as learning preference models for scheduling [23]and for urban mobility [24].Several algorithms, aimed at learning under the answer set semantics, and different frameworks for learning ASP pro-grams have been recently introduced in the literature. [28] presented the notions of brave induction (I L P b) and cautious induction (I L P c ), based respectively on the well established notions of entailment under the answer set semantics [13,29]of brave entailment (when an atom is true in at least one answer set) and cautious entailment (when and an atom is true in all answer sets). In brave induction, at least one answer set must cover the examples, whereas in cautious induction, every answer set must cover the examples. Brave induction is actually a special case of an earlier learning framework, called in-duction of stable models (I L P sm) [30], in which examples are partial interpretations. A hypothesis is a solution of an induction of stable models task if for each of the example partial interpretations, there is an answer set of the hypothesis combined with the background knowledge, that covers that partial interpretation. Brave induction is equivalent to induction of stable models with exactly one (partial interpretation) example.Each of the above frameworks for learning ASP programs is unable to learn some types of ASP programs [31]; for exam-ple, brave induction alone cannot learn programs containing hard constraints. In [31], we presented a learning framework, called Learning from Answer Sets (I L P L A S ), which unifies brave and cautious induction and is able to learn ASP programs containing normal rules, choice rules and hard constraints. In spite of the increased expressivity, none of the above ap-proaches can learn weak constraints, which are able to capture preference learning. Informally, learning weak constraints consists on identifying conditions for ordering answer sets. The learning task in this case would require examples of or-derings over partial interpretations. To tackle this aspect of learning ASP programs, we have extended the Learning from Answer Sets framework to Learning from Ordered Answer Sets (I L P L O A S ) [23] and demonstrated that our algorithm1 is able to learn preferences in a scheduling domain. More recently, we have extended the I L P L O A S framework to I L P contextL O A S , with context-dependent examples, which come together with extra contextual information [24].In this paper, we explore both the expressive power and the computational complexity of each framework. The former is important, as it allows us to identify the class of problems that each framework can solve, whereas the latter gives an indication of the price paid for using each framework. We characterise the expressive power of a framework in terms of new notions called one-to-one-distinguishability, one-to-many-distinguishability and many-to-many-distinguishability. The intuition of one-to-one-distinguishability is that, given some fixed background knowledge B and sufficient examples, the framework should be able to distinguish a target hypotheses H 1 from another, unwanted, hypotheses H 2. This means that there should be at least one task T (of the given framework) with background knowledge B, such that H 1 is a solution 1(F )) as the set of of T , and H2 is not. We characterise the one-to-one-distinguishability class of a framework F (written D1tuples (cid:3)B, H1, H2(cid:4) for such B’s, H1’s and H2’s, and state that a framework F1 is more D11 -general than another F2 if F2’s one-to-one-distinguishability class is a strict subset of F1’s one-to-one-distinguishability class.One-to-many-distinguishability relates to the task of finding a single target hypothesis from within a set of possi-ble hypotheses. It upgrades the notion of one-to-one-distinguishability classes to one-to-many-distinguishability classes. These are tuples of the form (cid:3)B, H, S(cid:4) for which a framework has at least one task that includes H and none of the (unwanted) hypotheses in S as an inductive solution. Many",
            {
                "entities": [
                    [
                        3694,
                        3722,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 191–192 (2012) 42–60Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn minimal constraint networks ✩Georg GottlobDepartment of Computer Science and Oxford Man Institute, University of Oxford, Oxford OX1 3QD, UKa r t i c l ei n f oa b s t r a c tIn a minimal binary constraint network, every tuple of a constraint relation can beextended to a solution. The tractability or intractability of computing a solution tosuch a minimal network was a long standing open question. Dechter conjectured thiscomputation problem to be NP-hard. We prove this conjecture. We also prove a conjectureby Dechter and Pearl stating that for k (cid:2) 2 it is NP-hard to decide whether a singleconstraint can be decomposed into an equivalent k-ary constraint network. We showthat this holds even in case of bi-valued constraints where k (cid:2) 3, which proves anotherconjecture of Dechter and Pearl. Finally, we establish the tractability frontier for thisproblem with respect to the domain cardinality and the parameter k.© 2012 Elsevier B.V. All rights reserved.Article history:Received 12 May 2012Received in revised form 26 July 2012Accepted 28 July 2012Available online 31 July 2012Keywords:ConstraintsMinimal networkComplexityJoin decompositionStructure identificationDatabase theoryKnowledge compilation1. IntroductionThis paper deals with problems related to minimal constraint networks. First, the complexity of computing a solution toa minimal network is determined. Then, the problems of recognizing network minimality and network-decomposability arestudied.1.1. Minimal constraint networksIn his seminal 1974 paper [26], Montanari introduced the concept of a minimal constraint network. Roughly, a minimalnetwork is a constraint network where each partial instantiation corresponding to a tuple of a constraint relation can beextended to a solution. Each arbitrary binary network N having variables { X1, . . . , X v } can be transformed into an equivalentbinary minimal network M(N) by computing the set sol(N) of all solutions to N and creating for 1 (cid:2) i < j (cid:2) v a constraintci j whose scope is ( Xi, X j) and whose constraint relation consists of the projection of sol(N) to ( Xi, X j), and for 1 (cid:2) i (cid:2) va unary constraint ci whose scope is ( Xi) and whose constraint relation is the projection of sol(N) over ( Xi). The minimalnetwork M(N) is unique, and its solutions are exactly those of the original network, i.e., sol(N) = sol(M(N)).An example of a binary constraint network N is given in Fig. 1(a). This network has four variables X1, . . . , X4 which,for simplicity, all range over the same numerical domain {1, 2, 3, 4, 5}. Its solution, sol(N), which is the join of all relationsof N, is shown in Fig. 1(b). The minimal network M(N) is shown in Fig. 1(c).Obviously, M(N), which can be regarded as an optimally pruned version of N, is hard to compute. But computing M(N)may result in a quite useful knowledge compilation [21,5]. In fact, with M(N) at hand, we can answer a number of queries✩This paper is a significantly extended version of a paper with the same title presented at the 17th International Conference on Principles and Practiceof Constraint Programming (Gottlob, 2011, [17]). The present paper contains new results in addition to those of Gottlob (2011) [17]. Possible future updateswill be made available on CORR at http://arxiv.org/abs/1103.1604.E-mail address: georg.gottlob@cs.ox.ac.uk.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.006\fG. Gottlob / Artificial Intelligence 191–192 (2012) 42–6043Fig. 1. A binary constraint network N, it solution sol(N), and its minimal network M(N).in polynomial time that would otherwise be NP-hard. Typically, these are queries that involve one or two variables only,for example, the queries “is there a solution for which X4 (cid:2) 3?” or “does N have a solution for which X2 < X1?” are affirmativelyanswered by a simple lookup in the relevant tables of M(N). For the latter query, for example, one just has to look intothe first relation table of M(N), whose tuple (cid:2)2, 1(cid:3) constitutes a witness. In contrast, in our example, the query “is therea solution for which X1 < X4?” is immediately recognized to have a negative answer, as the fourth relation of M(N) hasno tuple witnessing this inequality. An example of a slightly more involved non-Boolean two-variable query that can bepolynomially answered using M(N) is: “what is the maximal value of X2 such that X4 is minimum over all solutions?”. Again, onecan just “read off” the answer from the single relation of M(N) whose variables are those of the query. In our example inFig. 1, it is the penultimate relation of M(N), that can be easily used to deduce that the answer is 2.1.2. Computing solutions to minimal constraint networksIn applications such as computer-supported interactive product configuration, such queries arise frequently, but it wouldbe useful to be able to exhibit at the same time a full solution together with the query answer, that is, an assignment ofvalues to all variables witnessing this answer. However, it was even unclear whether the following problem is tractable:Given a non-empty minimal network M(N), compute an arbitrary solution to it. Gaur [11] formulated this as an openproblem. He showed that a stronger version of the problem, where solutions restricted by specific value assignments to apair of variables are sought, is NP-hard, but speculated that finding arbitrary solutions could be tractable. However, since theintroduction of minimal networks in 1974, no one came up with a polynomial-time algorithm for this task. This led Dechterto conjecture that this problem is hard [8]. Note that this problem deviates in two ways from classical decision problems:First, it is a search problem rather than a decision problem, and second, it is a promise problem, where it is “promised” that\f44G. Gottlob / Artificial Intelligence 191–192 (2012) 42–60the input networks, which constitute our problem instances, are indeed minimal – a promise whose verification is itselfNP-hard (see Section 4.1). We therefore have to clarify what NP-hardness means, when referring to such problems. Thesimplest and probably cleanest definition is the following: The problem is NP-hard if any polynomial algorithms solving itwould imply the existence of a polynomial-time algorithm for NP-hard decision problems, and would thus imply P = NP. Inthe light of this, Dechter’s conjecture reads as follows:Conjecture 1.1. (See Dechter [8].) Unless P = NP, computing a single solution to a non-empty minimal constraint network cannot bedone in polynomial time.While the problem has interested a number of researchers, it has not been solved until recently. Some progress was madeby Bessiere in 2006. In his well-known handbook article “Constraint Propagation” [4], he used results of Cros [6] to showthat no backtrack-free algorithm for computing a solution from a minimal network can exist unless the Polynomial Hierarchycollapses to its second level (more precisely, unless Σ p2 ). However, this does not mean that the problem is intractable.2A backtrack-free algorithm according to Bessiere must be able to recognize each partial assignment that is extensible toa solution. In a sense, such an algorithm, even if it computes only one solution, must have the potential to compute allsolutions just by changing the choices of the variable-instantiations made at the different steps. In more colloquial terms,backtrack-free algorithms according to Bessiere must be fair to all solutions. Bessiere’s result does not preclude the existenceof a less general algorithm that computes just one solution, while being unable to recognize all partial assignments, andthus being unfair to some solutions.= Π pThe simple example in Fig. 1, by the way, shows that the following naïve backtrack-free strategy is doomed to fail: Pickan arbitrary tuple from the first relation of M(N), expand it by a suitable tuple of the second relation, and so on. In fact,if we just picked the first tuple (cid:2)1, 1(cid:3) of the first relation, we could combine it with the first tuple (cid:2)1, 1(cid:3) of the secondrelation and obtain the partial instantiation X1 = X2 = X3 = 1. However, this partial instantiation is not part of a solution,as it cannot be expanded to match any tuple of the third relation. While this naïve strategy fails, one may still imagine theexistence of a more sophisticated backtrack-free strategy, that pre-computes in polynomial time some helpful data structurebefore embarking on choices. However, as we show in this paper, such a strategy cannot exist unless NP = P.In the first part of this paper, we prove Dechter’s conjecture by showing that every polynomial-time search algorithm A∗that computes a single solution to a minimal network can be transformed into a polynomial-time decision algorithm Afor the classical satisfiability problem 3SAT. The proof is carried-out in Section 3. We first show that each SAT instance canbe transformed in polynomial time into an equivalent one that is highly symmetric (Section 3.1). Such symmetric instances,which we call k-supersymmetric, are then polynomially reduced to the problem of computing a solution to a minimal binaryconstraint network (Section 3.2). We further consider the case of bounded domains, that is, when the input instances aresuch that the cardinality of the overall domain of all values that may appear in the constraint relation is bounded by somefixed constant c. By a simple modification of the proof of the general case, it is easily seen that even in the bounded domaincase, the problem of computing a single solution remains NP-hard (Section 3.3).Our hardness results for computing relations can be reformulated in terms of database theory. Every constraint net-work N can be seen as a relational database instance,",
            {
                "entities": [
                    [
                        3600,
                        3628,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1873–1896Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the completeness of orientation rules for causal discoveryin the presence of latent confounders and selection biasJiji Zhang a,ba Division of the Humanities and Social Sciences, California Institute of Technology, USAb Department of Philosophy, Lingnan University, Hong Konga r t i c l ei n f oa b s t r a c tArticle history:Received 28 October 2007Received in revised form 30 June 2008Accepted 6 August 2008Available online 14 August 2008Keywords:Ancestral graphsAutomated causal discoveryBayesian networksCausal modelsMarkov equivalenceLatent variables1. IntroductionCausal discovery becomes especially challenging when the possibility of latent confoundingand/or selection bias is not assumed away. For this task, ancestral graph models areparticularly usefulin that they can represent the presence of latent confounding andselection effect, without explicitly invoking unobserved variables. Based on the machineryof ancestral graphs, there is a provably sound causal discovery algorithm, known asthe FCI algorithm, that allows the possibility of latent confounders and selection bias.However, the orientation rules used in the algorithm are not complete. In this paper, weprovide additional orientation rules, augmented by which the FCI algorithm is shown tobe complete, in the sense that it can, under standard assumptions, discover all aspectsof the causal structure that are uniquely determined by facts of probabilistic dependenceand independence. The result is useful for developing any causal discovery and reasoningsystem based on ancestral graph models.© 2008 Elsevier B.V. All rights reserved.Directed acyclic graphs (DAGs) are now widely used both as statistical models and as causal models. This double in-terpretation of DAGs, better known as (causal) Bayesian networks in the AI literature, is the springboard for much of theresearch on automated causal discovery and reasoning [12,20,25]. Given a set of variables V, if the causal structure of Vcan be properly represented by a DAG, one can try to learn the causal structure from data by exploiting the statisticalimplications DAGs have as statistical models. In general the causal structure is underdetermined, as multiple DAGs may beequally compatible with the correlational pattern suggested by data. But these DAGs usually share common features, whichconstitute the aspects of the causal structure that are not underdetermined and are in principle learnable from observationaldata. To develop algorithms for inferring these learnable causal features from correlational patterns is an important goal inthe project of automated causal discovery.Assuming no confounding or selection effect due to unobserved variables, there are causal discovery algorithms that areprovably sound and complete, under some plausible assumptions relating causal structure to probability distribution [7,17,25,32]. However, the assumption of no latent confounding or selection effect is seldom appropriate, and it is desirable andeven necessary in many situations to relax it. Unfortunately, the problem becomes much more difficult when we drop theassumption, due to the fact that the causal structure may not be properly representable by a DAG unless latent variables areexplicitly invoked. Not only are DAG models with latent variables hard to handle statistically [5,11], they make an infinitesearch space unless we seriously constrain the number of latent variables or the topology of the unknown causal network.E-mail address: jiji@hss.caltech.edu.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.001\f1874J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 1. A causal mechanism with latent and selection variables.One way around this is to represent such models without explicitly introducing latent variables, especially if we arenot interested in the latent variables per se. A class of graphical models developed for this purpose is known as ancestralgraph models [23]. As we will describe in more detail, a major virtue of ancestral graphs is that for any DAG with latentconfounding and selection variables, there is a unique maximal ancestral graph (MAG) over the observed variables alonethat represents the conditional independence relations and causal relations entailed by the original DAG. Instead of directlytargeting the causal DAG, which for all we know might involve any number of latent variables, a more tractable goal forcausal discovery is to learn as many features of the causal MAG as possible.There is a provably sound procedure for this purpose, known as the FCI algorithm [26].1 Whether it is complete—thatis, whether it can in principle discover all causal information that is not underdetermined—has been an open problem[18,25].2 In fact, as we will explain later, the algorithm is not complete as it stands. In this paper, we provide additionalorientation rules (i.e., rules for inferring edge marks), and show that the augmented FCI algorithm is complete. The resultamounts to a constructive characterization of common features shared by an equivalence class of MAGs, which should beuseful in any system of causal discovery and reasoning based on ancestral graph models. In this regard, our result generalizesMeek’s characterization of commonalities shared by Markov equivalent DAGs [17], and builds directly on some earlier resultsestablished in [2].Causal discovery aside, this paper should be of interest to anyone interested in ancestral graph models, which havedrawn attention from both statisticians and computer scientists [1,2,9,10,23,30,37]. We also suspect that the results of thispaper (and especially some lemmas in Appendix A) will be useful in providing a characterization of equivalence classes ofMAGs in the style of Andersson et al.’s characterization of equivalence classes of DAGs [4].The rest of the paper is organized as follows. Section 2 introduces the relevant background on ancestral graphs. InSection 3, we describe the FCI algorithm and report an important step made in [2] towards the completeness result. Wethen present additional orientation rules in Section 4, with which we show that the augmented FCI algorithm is complete.We conclude in Section 5. Most proofs are postponed to the appendices.2. Ancestral graphs and their interpretationsThe following example attributed to Chris Meek in [22] illustrates nicely the primary motivation behind ancestral graphs:The graph [Fig. 1] represents a randomized trial of an ineffective drug with unpleasant side-effects. Patients arerandomly assigned to the treatment or control group ( A). Those in the treatment group suffer unpleasant side-effects(Ef ), the severity of which is influenced by the patient’s general level of health (H ), with sicker patients sufferingworse side-effects. Those patients who suffer sufficiently severe side-effects are likely to drop out of the study. Theselection variable (Sel) records whether or not a patient remains in the study, thus for all those remaining in thestudy Sel = StayIn. Since unhealthy patients who are taking the drug are more likely to drop out, those patients in thetreatment group who remain in the study tend to be healthier than those in the control group. Finally health status(H ) influences how rapidly the patient recovers (R) [22, p. 234].This simple case shows how the presence of latent confounders and selection variables matters. The variables of primaryinterest, A and R, are observed to be correlated, even though the supposed causal mechanism entails independence betweenthem. This correlation is not due to sample variation, but rather corresponds to genuine probabilistic association induced bydesign—only the subjects that eventually stay in the study are considered. The observed correlation is in effect a correlationconditional on the selection variable Sel, a canonical example of selection effect. On the other hand, H is a familiar latentconfounder that contributes to “spurious correlation”.1 FCI stands for fast causal inference, which is probably an overly optimistic name.2 These authors raised the problem with regard to an older version of the algorithm designed based on a representation called inducing path graphs. Thereis a very close relationship between inducing path graphs and MAGs, which is explained in detail in the appendix of [34]. It suffices to note here that thecompleteness problem addressed in this paper is an even harder problem than the completeness problem formulated in terms of inducing path graphs.Also, the FCI algorithm is sometimes claimed to be complete [28], but only in a much weaker sense than what we consider in this paper.\fJ. Zhang / Artificial Intelligence 172 (2008) 1873–18961875A main attraction of ancestral graphs is that, without explicitly including latent variables, they can represent conditionalindependence relations and causal relations among observed variables when the underlying data generating process involveslatent confounders and/or selection variables. This of course requires a richer syntax than that of DAGs.2.1. Ancestral graphsA mixed graph is a vertex-edge graph that can contain three kinds of edges: directed (→), bi-directed (↔) and undi-rected (—), and at most one edge between any two vertices. The two ends of an edge we call marks or orientations. Thetwo marks of a bi-directed edge are both arrowheads (>), the two marks of an undirected edge are both tails (−), and adirected edge has one of each. We say an edge is into (or out of) a vertex if the edge mark at the vertex is an arrowhead(or a tail).Two vertices are said to be adjacent in a mixed graph if there is an edge (of any kind) between them. Given a mixedgraph G and two adjacent vertices A, B therein, A is a parent of B and B is a child of A if A → B is in G; A is called aspouse of B (and B a spouse of A) if A ↔ B is in G; ",
            {
                "entities": [
                    [
                        3719,
                        3747,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2198–2222Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecision-theoretic planning with generalized first-order decisiondiagramsSaket Joshi a, Kristian Kersting b, Roni Khardon c,∗a School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR 97331, USAb Knowledge Discovery Department, Fraunhofer IAIS, 53754, Sankt Augustin, Germanyc Department of Computer Science, Tufts University, Medford, MA 02155, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 19 February 2010Received in revised form 9 September 2011Accepted 11 September 2011Available online 16 September 2011Keywords:Knowledge representationAutomated reasoningFirst order logicModel checkingMarkov decision processDynamic programmingDecision theoretic planningMany tasks in AI require representation and manipulation of complex functions. First-OrderDecision Diagrams (FODD) are a compact knowledge representation expressing functionsover relational structures. They represent numerical functions that, when constrained tothe Boolean range, use only existential quantification. Previous work has developed a setof operations for composition and for removing redundancies in FODDs, thus keeping themcompact, and showed how to successfully employ FODDs for solving large-scale stochasticplanning problems through the formalism of relational Markov decision processes (RMDP).In this paper, we introduce several new ideas enhancing the applicability of FODDs. Morespecifically, we first introduce Generalized FODDs (GFODD) and composition operationsfor them, generalizing FODDs to arbitrary quantification. Second, we develop a novelapproach for reducing (G)FODDs using model checking. This yields – for the first time –a reduction that maximally reduces the diagram for the FODD case and provides a soundreduction procedure for GFODDs. Finally we show how GFODDs can be used in principleto solve RMDPs with arbitrary quantification, and develop a complete solution for the casewhere the reward function is specified using an arbitrary number of existential quantifiersfollowed by an arbitrary number of universal quantifiers.© 2011 Elsevier B.V. All rights reserved.1. IntroductionThe problem of an autonomous agent acting optimally in an environment is central to Artificial Intelligence. There aremany variants of this problem. For the case where the stochastic dynamics of the environment are known and the objectivecan be described by a reward function, Markov decision processes (MDP) have become the standard model [1,2]. Classicaldynamic programming algorithms for solving MDPs [3,4], however, require explicit state enumeration. This is often imprac-tical as the number of states grows very quickly with the number of domain objects and relations. For example in a domainwith predicate on( X, Y ), and n objects that can be substituted for X and Y , we have at least n2 ground propositions and 2n2potential states. Classical solutions require enumeration of these 2n2states. In other words, classical dynamic programmingsolutions to MDPs do not scale to bigger problems because the size of the state space is too large.One potential solution to this problem is the use of structure in representing state and action spaces. Many problems arenaturally described by referring to objects and relations among them. Relational representations naturally factor the statespace and they can capture parameterized functions over the state space. The past few years have seen the successes of thisapproach in the field of Statistical Relational Learning [5] which combines expressive knowledge representation formalisms* Corresponding author.E-mail address: roni@cs.tufts.edu (R. Khardon).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.09.001\fS. Joshi et al. / Artificial Intelligence 175 (2011) 2198–22222199with statistical approaches to perform probabilistic inference and learning in relational domains. MDPs enhanced with suchrepresentations are known as relational or first-order MDPs.Recently, Boutilier et al. [6] have shown how algorithms for relational MDPs (RMDP) can be used to solve stochasticplanning problems. Inspired by this seminal work, several authors have developed different representation schemes and al-gorithms implementing this idea [7–10]. In particular, Wang et al. [9] and Joshi and Khardon [11] introduced the First-OrderDecision Diagram (FODD) representation, showed how RMDPs can be solved using FODDs, and provided a prototype imple-mentation that performs well on problems from the International Planning Competition. The use of FODDs to date, however,has two main limitations. The first is representation power. FODDs (roughly speaking) represent existential statements butdo not allow universal quantification. This excludes some basic planning tasks. For example, a company that has to plan aphysical meeting of all employees requires that they are all in a single location thus requiring a quantifier prefix ∃∀ for thegoal; the goal can be expressed as “there exists a location such that all employees are in that location”. The second is thatmanipulation algorithms for FODDs require special reductions to ensure that their size is small. Such reductions have beenintroduced but they are not complete, i.e., they may not yield a small FODD although one exists.In this article, we show how one can overcome these limitations. Specifically, we make the following three contributions.First, we introduce Generalized FODDs (GFODD), a novel FODD variant that allows for arbitrary quantification as well asmore general aggregations of values. Basic algorithms that allow us to perform operations over functions represented byGFODDs are developed. Second, we show how GFODDs can be used to solve RMDPs with arbitrary quantification. Finally, weprovide a novel reduction approach based on model checking. This provides the first reduction for FODDs that guaranteesthat the resulting FODD is “maximally reduced” in a sense which is defined precisely in the technical section. This isa significantly stronger reduction than ones that existed previously for FODDs. In addition we develop model checkingreductions for the ∃∗∀∗quantifier setting of GFODDs, where a finite number of existential quantifiers is followed by afinite number of universal quantifiers. We show that this enables solutions for RMDPs with reward functions given by ∃∗∀∗statements, where all intermediate constructs in the algorithm are maintained in this form. The new representations andalgorithms developed form a significant extension of the scope of the FODD approach to decision-theoretic planning and asignificant improvement of our understanding of their reductions.The new reductions presented in the paper have a relatively high complexity and are not likely to be efficient in practicefor large diagrams. However, they provide the basis for easy-to-implement heuristic reductions for FODDs. In recent work[12] we developed such heuristic reductions as well as heuristics for generating the models from problem descriptions. Thenew reductions provide significant speedup in planning time, over an implementation using theorem proving reductions,while maintaining state-of-the-art performance on problems from the international planning competition. Model checkingreductions are therefore important in expanding applicability of FODDs to decision theoretic planning. Practical implemen-tations of reductions for GFODDs will be similarly important for their applicability.Our results are also closely related to recent work on probabilistic inference with large models. In fact, the relationalvalue iteration algorithm of Boutilier et al. [6] and our implementation of this algorithm using (G)FODDs can be seen toperform some form of lifted inference in probabilistic models. Recently several algorithms that take advantage of modelstructure in inference have been proposed [13–21]. Whereas, existing approaches essentially take a single ground modeland a single ground question and calculate a numerical solution for the question, our solutions for RMDPs take a familyof models and a potentially non-ground question as input, and calculate numerical solutions for all members of the family.Of course the planning models must have some structure to make this possible and this is precisely the structure ouralgorithms take advantage of.We proceed as follows. After briefly reviewing FODDs, we present the model checking reduction operator for FODDs inSection 3. Then, in Section 4, we introduce GFODDs and their composition operations. Section 5 extends the model checkingreduction operator to GFODDs with the quantifier setting ∃∗∀∗. Finally Section 6 shows the utility of GFODDs for solvingRMDPs. To that end we devise a value iteration approach for RMDPs using GFODDs. Note that, since knowledge of RMDPsis not required for the development and algorithms for GFODDs, we have deferred the introduction of RMDPs to Section 6.2. First-order decision diagramsThis section briefly reviews previous work on FODDs [9]. We use standard terminology from first-order logic [22]. A first-order decision diagram is a labeled directed acyclic graph, where each non-leaf node has exactly 2 outgoing edges labeledtrue and false. The non-leaf nodes are labeled by atoms generated from a predetermined signature of predicates, con-stants and an enumerable set of variables. Leaf nodes have non-negative numeric values. The signature also defines a totalorder on atoms, and the FODD is ordered with every parent smaller than the child according to that order.Example 1. Two examples of FODDs are given in Fig. 1; in these and all diagrams in the paper left going edges representthe branch taken when the predicate is true and right edges are the false branches.Thus, a FODD is similar to a formula in first-order logic. Its meaning is similarly defined relative",
            {
                "entities": [
                    [
                        3861,
                        3889,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 901–934Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintReasoning about preferences in argumentation frameworksSanjay Modgil∗Department of Computer Science, Kings College London, Strand, London WC2R 2LS, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 17 December 2007Received in revised form 23 December 2008Accepted 3 February 2009Available online 7 February 2009Keywords:ArgumentationDungPreferencesNon-monotonic reasoningLogic programmingThe abstract nature of Dung’s seminal theory of argumentation accounts for its widespreadapplication as a general framework for various species of non-monotonic reasoning, and,more generally, reasoning in the presence of conflict. A Dung argumentation frameworkis instantiated by arguments and a binary conflict based attack relation, defined by someunderlying logical theory. The justified arguments under different extensional semanticsare then evaluated, and the claims of these arguments define the inferences of theunderlying theory. To determine a unique set of justified arguments often requires apreference relation on arguments to determine the success of attacks between arguments.However, preference information is often itself defeasible, conflicting and so subjectin this paper we extend Dung’s theory to accommodateto argumentation. Hence,arguments that claim preferences between other arguments, thus incorporating meta-level argumentation based reasoning about preferences in the object level. We then defineand study application of the full range of Dung’s extensional semantics to the extendedframework, and study special classes of the extended framework. The extended theorypreserves the abstract nature of Dung’s approach, thus aiming at a general framework fornon-monotonic formalisms that accommodate defeasible reasoning about as well as withpreference information. We illustrate by formalising argument based logic programmingwith defeasible priorities in the extended theory.© 2009 Elsevier B.V. All rights reserved.1. Introduction1.1. BackgroundThe formal study of argumentation has come to be increasingly central as a core study within Artificial Intelligence [12].Logic based models of argumentation are being applied to formalisation of defeasible reasoning and conflict resolutionover beliefs and goals, and to decision making over actions [1,8,24,25,35]. The inherently dialectical nature of these modelshave provided foundations for formalisation of argumentation-based dialogues [5], where, for example, one agent seeksto persuade another to adopt a belief it does not already hold to be true [33], or when agents deliberate about whatactions to execute [21], or negotiate over resources [4]. Furthermore, recent major research projects [6,7] are developinggeneral models of argumentation based inference, decision making and dialogue, and implementations of these models fordeployment in agent and semantic grid applications.Many of the above theoretical and practical developments build on Dung’s seminal theory of argumentation [19]. A Dungargumentation framework is a directed graph consisting of a set of arguments Args and a binary conflict based attack re-lation R on Args. The extensions, and so justified arguments of a framework are then defined under different semantics,* Tel.: +44 (0)207 8481631.E-mail address: sanjay.modgil@kcl.ac.uk.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.02.001\f902S. Modgil / Artificial Intelligence 173 (2009) 901–934where the choice of semantics equates with varying degrees of scepticism or credulousness. Extensions are defined throughapplication of an ‘acceptability calculus’, whereby an argument X ∈ Args is said to be acceptable with respect to S ⊆ Args iffany argument Y that attacks X is itself attacked by some argument Z in S (intuitively, any such Z is said to reinstate X ).For example, if S is a maximal (under set inclusion) set such that all its contained arguments are acceptable with respectto S, then S is said to be an extension under the preferred semantics.Recent years have witnessed intensive formal study, development and application of Dungs ideas in various directions.This can be attributed to the abstract nature of a Dung argumentation framework, and the encoding of intuitive, genericprinciples of commonsense reasoning through application of the acceptability calculus. The underlying logic, and defini-tion of the logic’s constructed arguments Args and attack relation R is left unspecified, thus enabling instantiation of aframework by various logical formalisms. A theory’s inferences can then be defined in terms of the claims of the justifiedarguments constructed from the theory (an argument essentially being a proof of a candidate inference – the argument’sclaim – in the underlying logic). Dung’s theory can therefore be understood as a semantics for non-monotonic reasoning. Inthis view, what appropriately accounts for the correctness of an inference is that it can be shown to rationally prevail in theface of opposing inferences, where it is application of the acceptability calculus that encodes logic neutral, rational meansfor establishing such standards of correctness. Indeed, many logic programming formalisms and non-monotonic logics (e.g.default, auto-epistemic, defeasible, non-monotonic modal logics and certain instances of circumscription) have been shownto conform to Dung’s semantics [13,18–20].Dung’s extensional semantics may yield multiple extensions. The sceptically justified arguments are those that appearin every extension. However, one may then be faced with the problem of how to choose between conflicting credulouslyjustified arguments that belong to at least one, but not all extensions. To illustrate, consider two individuals P and Qexchanging arguments A, B . . . about the weather forecast:P1: “Today will be dry in London since the BBC forecast sunshine” = A.Q1: “Today will be wet in London since CNN forecast rain” = B.A and B claim contradictory conclusions and so attack each other (symmetrically attack). Under Dung’s preferred semantics,there are two extensions: { A} and {B}. Neither argument is sceptically justified. One solution is to provide some means forpreferring one argument to another. Some works (e.g., [32,34]) formalise the role of preferences in the underlying logicalformalisms that instantiate a Dung framework. For example, in [32], if X undercuts Y (where ‘undercut’ denotes a certaintype of conflict based interaction), then XRY if Y is not stronger than (preferred to) X . Other approaches formalise therole of preferences at an abstract level. In Amgoud and Cayrol’s Preference based Argumentation Frameworks [3], a Dungframework is augmented with a preference ordering on Args, so that an attack by X on Y is successful only if Y is notpreferred to X . In Bench-Capon’s Value based Argumentation Frameworks (VAFs) [11], a Dung framework is augmented withvalues and value orderings, so that an attack by X on Y is successful only if the value promoted by Y is not ranked higherthan the value promoted by X according to a given ordering on values.Examining the role of preferences in the above weather example, one might reason that A is preferred to B because theBBC are deemed more trustworthy than CNN. Hence B does not successfully attack A, and so this attack can be removedand we are only left with the successful attack from A to B. Thus only { A} will be a preferred extension; A is scepticallyjustified. This example illustrates resolution of an argumentation framework obtained by replacing symmetric attacks withasymmetric attacks. Properties relating frameworks and their resolutions have been studied in [9] and [26]. Properties offrameworks obtained through removal of asymmetric attacks have also been studied in the context of VAFs.1.2. Overview of paperInformation required to determine the success of an attack is often assumed pre-specified, as a given preference or valueordering. However, preference information may be contradictory, given that preferences may vary according to context, anddistinct sources may valuate the strengths of arguments using different criteria, or indeed assign different valuations for anygiven criterion. Thus, one often needs to reason, and indeed argue about, as well as with, defeasible and possibly conflictingpreference information. To illustrate, consider continuation of the above dialogue about the weather:P2: “But the BBC are more trustworthy than CNN” = C .Q2: “However, statistically CNN are more accurate forecasters than the BBC” = CQ3: “And basing a comparison on statistics is more rigorous and rational than basing a comparison on your instinctsabout their relative trustworthiness” = E..(cid:5)(cid:5)expresses a preference for B over A. C and C(cid:5)Argument C is not an argument that attacks B; rather it is an argument expressing a preference for A over B. However,attack each other since they express contradictory preferences. Finally,Csuccessfully attacks C . We thus have a sceptically justifiedargument E claims that Cargument Cclaiming that B is preferred to A, and so B is sceptically justified.is preferred to C , and so only C(cid:5)(cid:5)(cid:5)\fS. Modgil / Artificial Intelligence 173 (2009) 901–934903In this paper we are thus motivated to extend Dung’s theory to accommodate argumentation about preferences. Thepaper is organised as follows. In Section 2 we review Dung’s theory of argumentation. In the sections that follow wedescribe our contributions to the formal study and application of argumentation:• In Sections 3 and 4, Dung’s theory of argumentation is extended to integrate ‘metalevel’ argumentation about pref-erences between arguments. The extended theory preserves the abstract nature of Dung’s approach. Arguments expressingpreferences (preference arguments) are simply nodes in a graph, and application of preferences is abstra",
            {
                "entities": [
                    [
                        3496,
                        3524,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 228 (2015) 1–44Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA new probabilistic constraint logic programming language based on a generalised distribution semantics ✩Steffen Michels a,∗a Radboud University, Institute for Computing and Information Sciences, Nijmegen, The Netherlandsb Embedded Systems Innovation by TNO, The Netherlands, Arjen Hommersom a, Peter J.F. Lucas a, Marina Velikova ba r t i c l e i n f oa b s t r a c tArticle history:Received 7 April 2014Received in revised form 2 May 2015Accepted 26 June 2015Available online 4 July 2015Keywords:Probabilistic logic programmingImprecise probabilitiesContinuous probability distributionsExact probabilistic inferenceProbabilistic logics combine the expressive power of logic with the ability to reason with uncertainty. Several probabilistic logic languages have been proposed in the past, each of them with their own features. We focus on a class of probabilistic logic based on Sato’s distribution semantics, which extends logic programming with probability distributions on binary random variables and guarantees a unique probability distribution. For many applications binary random variables are, however, not sufficient and one requires random variables with arbitrary ranges, e.g. real numbers. We tackle this problem by developing a generalised distribution semantics for a new probabilistic constraint logic programminglanguage. In order to perform exact inference, imprecise probabilities are taken as a starting point, i.e. we deal with sets of probability distributions rather than a single one. It is shown that given any continuous distribution, conditional probabilities of events can be approximated arbitrarily close to the true probability. Furthermore, for this setting an inference algorithm that is a generalisation of weighted model counting is developed, making use of SMT solvers. We show that inference has similar complexity properties as precise probabilistic inference, unlike most imprecise methods for which inference is more complex. We also experimentally confirm that our algorithm is able to exploit local structure, such as determinism, which further reduces the computational complexity.© 2015 Elsevier B.V. All rights reserved.1. IntroductionProbabilistic logics are gaining popularity as modelling and reasoning tools, since they combine the power of logic to represent knowledge with the ability of probability theory to deal with uncertainty. In addition, in the field of statistical relational learning (SRL) [1], powerful machine learning methods have been developed using probabilistic logical languages as their basis.The need for those methods emerges from the fact that in many areas more and more data become available, which does not only imply uncertainty, but often provides rich structure in terms of relations between entities. Probabilistic logics and SRL methods have been applied to a wide range of problem domains. Examples include: link and node prediction in This publication was supported by the Dutch national program COMMIT. The research work was carried out as part of the Metis project under the ✩responsibility of Embedded Systems Innovation by TNO, with Thales Nederland B.V. as the carrying industrial partner.* Corresponding author.E-mail addresses: s.michels@science.ru.nl (S. Michels), arjenh@cs.ru.nl (A. Hommersom), peterl@cs.ru.nl (P.J.F. Lucas), marina.velikova@tno.nl(M. Velikova).http://dx.doi.org/10.1016/j.artint.2015.06.0080004-3702/© 2015 Elsevier B.V. All rights reserved.\f2S. Michels et al. / Artificial Intelligence 228 (2015) 1–44metabolic networks [2], discovering interactions between genes [3], dealing with a potentially unknown number of relations between multiple objects by a robot [3] and fusing information about vessels on the North Sea by modelling relations between those objects and heterogeneous pieces of information [4].Combining logic and probability theory is challenging and involves dealing with a trade-off between expressivity and efficiency of inference. The research described in this article focuses on probabilistic logics adhering to Sato’s distribution semantics [5]. This semantics guarantees a single unambiguously defined probability distribution and supports efficient in-ference. In this semantic framework, logic programming (LP) is used to define a probability distribution over a set of binary facts. Examples of languages based on that semantics are ProbLog [6], PRISM [7], ICL [8], and CP-logic [9]. The choice for this kind of semantics is motivated by the fact that it allows one to use probabilities with local meaning, which provides the modularity needed for knowledge representation, similar to the widely used Bayesian networks [10]. Some alternatives, in particular the popular Markov Logic Networks, make use of weights that only can be interpreted in the context of the entire theory [11].For many real-world knowledge-representation problems binary random variables are not convenient or not sufficient; very often, random variables taking values within arbitrary ranges are needed, e.g. integers and real numbers. In fact, virtually all deterministic real-world models include such variables. Examples are: data models involving the age or height of persons, temporal models that use integer or real-valued time, and physical models expressing most quantities as real numbers. Since in all such domains uncertainty is present, the provision of a probabilistic representation of such models is essential. Furthermore, most domains are typically relational. An example involving relations and uncertainty, as well as real-valued variables, is inferring a map of the indoor environment based on observations by robots [12].While finite-ranged discrete random variables can be represented by sets of binary random variables, random variables with an infinite number of values, such as continuous variables, have significant impact on the semantics of probabilistic logics and the complexity of the inference problem. Some previous attempts to extend probabilistic logic programming with real-valued variables heavily restrict the use of such variables [13], such that they are not powerful enough to model many real world problems. Other approaches resort to approximate methods for inference, such as sampling [14,12]. For many problems current sampling techniques are effective, but such approaches may fail and guarantees about the result’s quality are weak. This is especially problematic for problems in which wrong decisions have a huge impact.In this article, we propose an alternative to using exact inference and sampling with some inherent advantages; we can represent distributions for which exact inference is infeasible and at the same time provide more guarantees than offered by existing approximation methods. We provide a powerful, general theoretic foundation for probabilistic logic programs, which we refer to as a generalised distribution semantics, and a practically useful language based on the semantic framework. The theory supports approximating probability distributions with arbitrarily-ranged random variables, both continuous and discrete, and is equipped with an efficient method for inference.The main contribution of our work is an expressive logical language that defines events in terms of constraints on the random variable’s values, e.g. inequalities on real-valued random variables. The logical part of the language is inspired by constraint logic programming (CLP) [15]. To allow exact computation of probabilities, we make probabilities imprecise by introducing credal sets on top of the generalised distribution semantics. Given these credal sets, it is ensured that the bounds on marginals can be computed exactly. Moreover, by virtue of the distribution semantics, this new framework also ensures that there is always at least one consistent distribution, in contrast to some other probabilistic logics with imprecisions, e.g. the probabilistic logic of Nilsson [16].Based on this semantics we introduce a new probabilistic constraint logic programming (PCLP) language, in which inde-pendent probability distributions of random variables are defined by means of a set of probability-constraint pairs. Similar to deterministic constraint logic programming (CLP) [15], PCLP is a family of languages allowing one to use arbitrary con-straint theories, unlike most formalisms which are restricted to certain kinds of random variables, e.g. finite discrete and real-valued ones. This is possible thanks to the general semantic foundation. As examples we discuss discrete constants (PCLP(D)) and real numbers (PCLP(R)). To our knowledge this is the first usable framework that combines imprecise prob-abilities with continuous variables. An earlier version of the language was already presented at a previous occasion [17]. In the present paper we place the language in the context of the general semantic foundation and provide proofs of more general properties.We finally present an inference algorithm that is a generalisation of recently emerged probabilistic inference methods based on translating inference problems to weighted model counting (WMC) problems. This has been shown to be an effi-cient inference method for propositional formalisms such as Bayesian networks [18]. In addition, it has been shown to be applicable to probabilistic logics based on distribution semantics [19]. We show that exact inference in our new language can be dealt with by a generalisation of this method.This paper also shows that inference in our framework has similar complexity characteristics as precise probabilistic inference. In fact, we show that it is in the same complexity class as precise inference, unlike most other imprecise ap-proaches. Furthermore, the complexity can be bounded in terms of the problem structure, similar to WMC. Our generalised framework can also exploit additional structur",
            {
                "entities": [
                    [
                        3507,
                        3535,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 236 (2016) 30–64Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDomain-independent planning for services in uncertain and dynamic environmentsEirini Kaldeli a,b, Alexander Lazovik b, Marco Aiello ba School of Electrical and Computer Engineering, National Technical University of Athens, Zographou Campus, 15780 Athens, Greeceb Johann Bernoulli Institute, University of Groningen, Nijenborgh 9, 9747 AG Groningen, The Netherlandsa r t i c l e i n f oa b s t r a c tArticle history:Received 12 May 2014Received in revised form 6 March 2016Accepted 9 March 2016Available online 14 March 2016Keywords:AI planningWeb service compositionResearch in automated planning provides novel insights into service composition and contributes towards the provision of automatic compositions which adapt to changing user needs and environmental conditions. Most of the existing planning approaches to aggregating services, however, suffer from one or more of the following limitations: they are not domain-independent, cannot efficiently deal with numeric-valued variables, especially sensing outcomes or operator inputs, and they disregard recovery from runtime contingencies due to erroneous service behavior or exogenous events that interfere with plan execution. We present the RuGPlanner, which models the planning task as a Constraint Satisfaction Problem. In order to address the requirements put forward by service domains, the RuGPlanner is endowed with a number of special features. These include a knowledge-level representation to model uncertainty about the initial state and the outcome of sensing actions, and efficient handling of numeric-valued variables, inputs to actions or observational effects. In addition, it generates plans with a high level of parallelism, it supports a rich declarative language for expressing extended goals, and allows for continual plan revision to deal with sensing outputs, failures, long response times or timeouts, as well as the activities of external agents. The proposed planning framework is evaluated based on a number of scenarios to demonstrate its feasibility and efficiency in several planning domains and execution circumstances which reflect concerns from different service environments.© 2016 Elsevier B.V. All rights reserved.1. IntroductionSoftware service infrastructures enable the large scale integration of heterogeneous systems and solve a number of interoperability issues. A prototypical example is that of Web Services (WS) where programmatic access to Web resources is guaranteed via standardized XML interfaces, such as those defined by the Web Service Description Language (WSDL) (www.w3.org/TR/wsdl). Automated planning can contribute to the realization of service infrastructures that go beyond basic interoperation and ad hoc process specifications, offering highly automated functionalities that are adaptable to changing user needs and environmental conditions. The goal is to compose and interact automatically with several service providers in order to offer value added functionalities. More precisely, a service composition is a combination of operations provided by different services to satisfy complex objectives which cannot be fulfilled by a single service instance. Planning is the process of “choosing and organizing actions by anticipating their expected outcomes,” with the aim of achieving a pre-stated E-mail address: kaldeli@gmail.com (E. Kaldeli).http://dx.doi.org/10.1016/j.artint.2016.03.0020004-3702/© 2016 Elsevier B.V. All rights reserved.\fE. Kaldeli et al. / Artificial Intelligence 236 (2016) 30–6431goal [42]. The analogies between the problem of Web Service composition (WSC) and automated planning are evident and have been exploited before (e.g., [1,108,98,110,15]): actions correspond to functionalities offered by different services, and the goal is derived from a user request or inferred by a situation that calls for a combination of services.The composition method advocated herein is driven by the general aim of combining services automatically and on-demand, relying solely on individual descriptions of loosely-coupled software components, and a declarative goal language. The idea is to maintain a generic and modular repository that comprises a number of atomic service operations, from book-ing flights to arranging appointments with a doctor, and that can serve a variety of objectives with minimal request-specific configuration. We use domain-independent planning and propose an extended language for expressing complex goals in a declarative fashion, detached from the particularities and interdependencies of the available services. This is unlike most previous approaches that restrict the applicability of the domain to a set of anticipated user needs, predefined in the form of some procedural template, e.g., [90,108].1.1. Characteristics of service domainsService domains are data intensive, i.e., they deal with variables ranging over very large domains, such as prices, dates, product quantities, and so on. If the behavior of a service operation is to be modeled by a planning operator, then this must quite frequently involve fluents with numeric-valued input arguments. For example, an operation to reserve an airline ticket is parametrized by data associated with the flight. Whether or not the application of such an operation has the intended effect depends on the choice of the correct value of the input parameters. One must also take into account numeric properties (e.g., the temperature must be greater than 0) both in preconditions and in the goal, and be able to apply arithmetic operations (e.g., increase an account balance by a certain amount). Things become more complicated when one considers that numeric information is very often the output of sensing operations. Due to the many operators involving variables taking values in domains with large cardinality, either as input parameters or as outputs, the number of ground operators and, as a consequence, the size of the search space can increase enormously.In a service environment, the planner must deal with uncertainty about the initial state, i.e., consider that there is a number of possibilities about the actual values of certain variables. The actual value of an unknown variable can be returned after the invocation of a sensing operator, referred to as knowledge-gathering or observational, which returns exactly one outcome out of a (possibly very large) set of choices. In fact, marketplaces consisting of services publicly available on the Web are usually dominated by services that are data sources [31], which in a planning context are modeled as sensing operators. A successful plan may be conditioned on the outcomes of such actions, e.g., the user may want to go ahead with buying a book from amazon.com if this costs less than a maximum price. In a domain-independent setting, the planning agent is required to plan for sensing; the planner should be able to identify which knowledge it lacks for satisfying the goal, and reason about how to find it, instead of relying on pre-specified queries [110,76,4]. The planner should also proactively see to the data flow of the plan, i.e., the way the service return values are used by subsequent actions. For example, a user may want to mail a parcel to someone whose address he does not already know. The plan should thus first consult a white pages service, and then give the order for posting by passing the right address value to the respective input parameter. For data intensive service domains, determining the parameters for an action can be just as difficult as determining which actions belong to the plan. Since almost all state-of-the-art planners resort to some kind of pre-processing for compiling the PDDL [87] domain into a fully grounded encoding, on-the-fly handling of runtime outputs is difficult to implement.Uncertainty applies, however, not only to the initial state and the non-determinism of the many possible values of the outputs of sensing actions. In fact, a service invocation may behave in unexpected ways: i mat return a failure, not respond at all, or even act in a way different from the one prescribed by its description. The actual outcomes of a service invocation only become visible at runtime, when the plan is exposed to the actual environmental conditions. Thus, the problem of uncertainty is directly related to the interaction between planning and execution.The state of a service domain may not only change as a result of the deliberate actions executed by the planning agent, but also due to the activity of other exogenous agents which are active in the same environment. The activity of other actors may have repercussions for the composition-plan under execution, and render it invalid, either because information own which it relies has meanwhile become obsolete, or because certain scheduled actions are no longer applicable under the new circumstances. For example, considering a partially executed composition which involves circumnavigation of a robot, if an external actor puts an obstacle in the robot’s way in the middle of execution, the robot may fall unless it revises its decisions about how to move. With a few notable exceptions [4,17,73], context dynamicity has largely been overlooked by existing planning approaches to WSC. Moreover, in many service environments, dynamicity also applies to the availability of information and services; e.g., the services offered by a mobile phone may appear and disappear depending on the location of the phone.1.2. ApproachWe choose to work directly at the schematic level of the planning domain, i.e., without performing any grounding. Following the so-called Multi-Valued Task (MPT) paradigm [53], we use state variables rather than predicates as the basic elements for describing the world. According to that view, a state is a tuple of values to variables, leading to a more",
            {
                "entities": [
                    [
                        3516,
                        3544,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1528–1554Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLocal closed world reasoning with description logics underthe well-founded semanticsMatthias Knorr a,∗, José Júlio Alferes a, Pascal Hitzler ba CENTRIA, Departamento de Informática, FCT/UNL, Quinta da Torre, 2829-516 Caparica, Portugalb Kno.e.sis Center, Department of Computer Science and Engineering, Wright State University, 3640 Colonel Glenn Hwy, Dayton, OH 45435, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 24 September 2009Received in revised form 21 January 2011Accepted 23 January 2011Available online 26 January 2011Keywords:Knowledge representationDescription logics and ontologiesNon-monotonic reasoningLogic programmingSemantic WebAn important question for the upcoming Semantic Web is how to best combine open worldontology languages, such as the OWL-based ones, with closed world rule-based languages.One of the most mature proposals for this combination is known as hybrid MKNF knowl-edge bases (Motik and Rosati, 2010 [52]), and it is based on an adaptation of the StableModel Semantics to knowledge bases consisting of ontology axioms and rules. In this paperwe propose a well-founded semantics for nondisjunctive hybrid MKNF knowledge basesthat promises to provide better efficiency of reasoning, and that is compatible with boththe OWL-based semantics and the traditional Well-Founded Semantics for logic programs.Moreover, our proposal allows for the detection of inconsistencies, possibly occurring intightly integrated ontology axioms and rules, with only little additional effort. We alsoidentify tractable fragments of the resulting language.© 2011 Elsevier B.V. All rights reserved.1. Introduction and motivationThe Semantic Web has recently become a major source of inspiration for Knowledge Representation and Reasoning (KRR).The underlying idea of the Semantic Web is to use KRR techniques to enhance data in the World Wide Web with knowledgebases, making this data available for processing by intelligent systems. Semantic Web has become a mature field of research,and industrial applications of Semantic Web technologies are on the way. Semantic Web is a topic that is clearly here tostay.However, we believe that the KRR formalisms used in the Semantic Web are not adequate for several application areaswithin the Semantic Web. We therefore motivate in this section why KRR formalisms combining open and closed worldreasoning are sometimes preferable over fragments of classical first-order logics, and we present application scenarios illus-trating the requirement for that combination. Then, we show the limitations of already existing approaches, and we statethe main contributions of our proposal.1.1. Open vs. closed world reasoningThe most prominent expressive KRR approach employed in Semantic Web research is based on Description Logics [3,27].In particular, the Web Ontology Language OWL [26] is based on the description logic SROIQ(D), and it is a recommendedstandard by the World Wide Web Consortium (W3C) for modelling Semantic Web knowledge bases (commonly known asontologies).* Corresponding author. Tel.: (+351) 21 294 8536; fax: (+351) 21 294 8541.E-mail addresses: mknorr@di.fct.unl.pt (M. Knorr), jja@di.fct.unl.pt (J.J. Alferes), pascal@pascal-hitzler.de (P. Hitzler).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.01.007\fM. Knorr et al. / Artificial Intelligence 175 (2011) 1528–15541529Description Logics (DLs), in turn, bear a first-order predicate logic semantics. DLs are monotonic and adhere to theOpen World Assumption (OWA). This means that (negative) conclusions drawn from a knowledge base must be based oninformation explicitly present in the knowledge base. Being based on classical first-order logic, DLs differ from other KRRformalisms, e.g., those studied in the non-monotonic reasoning field, that usually apply the Closed World Assumption (CWA).Under that assumption, all non-provable expressions are assumed to be false.The decision to rely on the OWA appears to be a natural one in light of the envisioned applications related to the WorldWide Web: the absence of a piece of knowledge should not generally be taken as an indication that this piece of knowledgeis false. However, there are also application scenarios where the CWA, or at least the partial closure of the knowledge base,is a more natural choice. Such scenarios can occur, e.g., if ontology-based reasoning is done in conjunction with data storedin a database. Database data is usually considered to be complete, and so statements not in the database should be takenas false.As an example where a combination of open and closed world assumption is desired, consider the large case studydescribed in [54], containing millions of assertions about matching patient records with clinical trials criteria. In this clinicaldomain, open world reasoning is needed in radiology and laboratory data. For example, unless a lab test asserts a negativefinding, no arbitrary assumptions about the results of the test can be made. That is, we can only be certain that somepatient does not have a specific kind of cancer if the corresponding test has a negative result. However, as observed in [54],the closed world assumption can and should be used with data about medical treatment to infer that a patient is not on amedication unless otherwise stated. The work of [54] applies only open world reasoning but claims that the usage of closedworld reasoning in data about medical treatment would be highly desirable and that the combination of OWA and CWA isan open problem in their work. Similar situations occur, e.g., in matchmaking using Semantic Web Services (cf. [22]), and inother scenarios in the medical domain.In fact, life sciences, including medicine, is a prominently studied application area for OWL. Several large-scale ontologieshave been developed in this area that are being used in practice, such as GALEN1 and SNOMED.2 These ontologies provideunified medical terminologies for the management and exchange of clinical information. The knowledge bases typicallyconsist of information about anatomy, diseases, procedures, drugs, etc., and their applications range from medical recordmanagement to diagnostics support. SNOMED is used, for example, in the case study described above. All of these appli-cations use ontology reasoning based on the OWA. But it is not difficult to foresee situations in these domains that wouldbenefit from local closed world reasoning. Consider, for example, that such a medical knowledge base is used to decidewhether a certain anaesthetic should be applied before surgery, depending on whether the patient is allergic to the anaes-thetic or not. This information might not be available, and it should be modelled using the CWA: in an emergency situation,unless we know explicitly about an allergy, we assume that the patient is not allergic, and we apply the anaesthetic. Otherexamples can be found if we were to model exceptions in anatomical terminology; e.g., the existence of persons whoseheart is actually on the right-hand side. Exception modelling is not directly possible in classical first-order logic (this is aproblem usually known in Artificial Intelligence as the specification problem) and so also not possible in OWL using only theOWA.All of these examples demonstrate why application developers frequently voice that it would be favourable to have localclosed world modelling as an additional feature for ontology-based systems. More precisely, it would be desirable to have aKRR formalism that allows us to interpret some parts of the knowledge base under the CWA, and others under the OWA.Such capabilities would considerably enhance the usability of OWL.1.2. Combining rules and ontologiesOntologies are a standard OWA formalism while rules usually apply the CWA. A combination of ontologies and ruleswould clearly yield a combination of the OWA and the CWA. However, combining rules and ontologies is a non-trivial task,since a naive combination of ontologies and OWA-based rules is already undecidable [32]. In fact, formalisms for rulesand formalisms for ontologies differ substantially on how decidability is achieved. For ontologies, decidability is achievedby specific syntactic restrictions on the available first-order predicates, and by restricting the way these predicates canbe related. Rules do not have such syntactic restrictions, but are usually limited in their applicability to the finitely manydifferent objects explicitly appearing in the knowledge base. An immediate effect of these differences is that some expressivefeatures of one of the approaches are not available in the other approach. Namely, rules make it possible to express: non-treeshape-like relationships [62]3 such as “an uncle is the brother of one’s father”; integrity constraints [56] to state, e.g.,that a certain piece of information is explicitly present in the database; and closed world reasoning and specification ofexceptions, as discussed above. Ontologies, on the contrary, make it possible to express open world reasoning, reason withunbounded or infinite domains, and they are thus well suited to represent many types of incomplete information andschema knowledge. For example, in rule-based formalisms one typically cannot say that “every person has a father anda mother who are both persons” without listing all the parents explicitly. Our stance is that a combination of rules and1 http://www.opengalen.org/.2 http://www.ihtsdo.org/snomed-ct/.3 The DL SROIQ [30] also provides role composition axioms, which can be used to address some, but by no means all, use cases.\f1530M. Knorr et al. / Artificial Intelligence 175 (2011) 1528–1554ontologies is not only of interest for current applications in the web, but also as a highly sophisticated means of knowledgerepresentation in general.As argued in [52],",
            {
                "entities": [
                    [
                        3453,
                        3481,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 53–85Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHierarchical semi-Markov conditional random fields for deep recursive sequential dataTruyen Tran a,∗a Center for Pattern Recognition and Data Analytics, Deakin University Geelong, Australiab Adobe Research, Adobe, USA, Dinh Phung a, Hung Bui b, Svetha Venkatesh aa r t i c l e i n f oa b s t r a c tArticle history:Received 20 January 2015Received in revised form 12 February 2017Accepted 14 February 2017Available online 24 February 2017Keywords:Deep nested sequential processesHierarchical semi-Markov conditional random fieldPartial labellingConstrained inferenceNumerical scaling1. IntroductionWe present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of linear-chain conditional random fields to model deep nested Markov processes. It is parameterised as a conditional log-linear model and has polynomial time algorithms for learning and inference. We derive algorithms for partially-supervised learning and constrained inference. We develop numerical scaling procedures that handle the overflow problem. We show that when depth is two, the HSCRF can be reduced to the semi-Markov conditional random fields. Finally, we demonstrate the HSCRF on two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. The HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.© 2017 Elsevier B.V. All rights reserved.Modelling hierarchical depth in complex stochastic processes is important in many application domains. In a deep hier-archy, each level is an abstraction of lower level details [1–4]. This paper studies recursively sequential processes, in that each level is a sequence and each node in a sequence can be decomposed further into a sub-sequence of finer grain [2].Consider, for example, a frequent activity performed by human ‘eat-breakfast’. It may include a series of more specific activities like ‘enter-kitchen’, ‘go-to-cupboard’, ‘take-cereal’, ‘wash-dishes’ and ‘leave-kitchen’. Each specific activity can be decomposed into finer details. Similarly, in natural language processing (NLP) syntax trees are inherently hierarchical. In a partial parsing task known as noun-phrase (NP) chunking [5], there are three syntactic levels: the sentence, noun-phrases and part-of-speech (POS) tags. In this setting, the sentence is a sequence of NPs and non-NPs, and each phrase is a sub-sequence of POS tags.A popular approach to deal with hierarchical data is to build a cascaded model where each level is modelled separately, and the output of the lower level is used as the input of the level right above it (e.g. see [6]). For instance, in NP chunking this approach first builds a POS tagger and then constructs a chunker that incorporates the output of the tagger. This approach is sub-optimal because the POS tagger takes no information of the NPs and the chunker is not aware of the reasoning of the tagger. In contrast, a noun-phrase is often very informative to infer the POS tags belonging to the phrase. As a result, this layered approach may suffer from the so-called cascading error problem in that errors introduced from the lower layer propagate to higher levels.* Corresponding author.E-mail address: truyen.tran@deakin.edu.au (T. Tran).http://dx.doi.org/10.1016/j.artint.2017.02.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f54T. Tran et al. / Artificial Intelligence 246 (2017) 53–85A more holistic approach is to build a joint representation of all the levels. Formally, given a data sequence z we need to model and infer about the deep, nested semantic x. The main problem is to choose an appropriate representation of xso that inference can be efficient. An important class of representation is hierarchical hidden Markov model (HHMM) [2]. An HHMM is a nested hidden Markov network (HMM) in the sense that each state is also a sub HMM. Although HMMs represent only first-order Markov processes, HHMMs offer higher-order interaction. HHMMs are generative models with joint distribution Pr(x, z), where the data generating distribution Pr(z | x) must be simplified for efficient inference about the semantic Pr(x | z). An alternative is to model the discriminative distribution Pr(x | z) directly without modelling the data Pr(z). This can be more effective since arbitrary long-range and interdependent data features can be incorporated into the model.The most popular class of probabilistic structured output methods are conditional random fields (CRFs) [7], but the early models are flat. Deep variants have been introduced the past decade, including dynamic CRFs (DCRF) [8], hierarchical CRFs [9,10]), and stacked CRFs [11]. However, these methods require a fixed pre-defined hierarchy, and thus are not suitable for problems with automatically inferred topologies.To this end, we construct a novel discriminative model called Hierarchical Semi-Markov Conditional Random Field (HSCRF).1The HSCRF offers nested semantic similar to that by the HHMM but is parameterised as an undirected log-linear model. The HSCRF generalises linear-chain CRFs [7] and semi-Markov CRFs [13].To be more concrete, let us return to the NP chunking example. The problem can be modelled as a three-level HSCRF, where the root represents the sentence, the second level the NP process, and the bottom level the POS process. The root and the two processes are conditioned on the sequence of words in the sentence. Under discriminative modelling, rich contextual information can be simply encoded as features including starting and ending of a phrase, phrase length, and distribution of words falling inside the phrase can be effectively encoded. On the other hand, such encoding is much more difficult for HHMMs.We then proceed to address important issues. First, we show how to represent HSCRFs using a dynamic graphical model (e.g. see [14]) which effectively encodes hierarchical and temporal semantics. For parameter learning, an efficient algorithm based on the Asymmetric Inside–Outside of [15] is introduced. For inference, we generalise the Viterbi algorithm to decode the semantics from an observational sequence.The common assumptions in discriminative learning and inference are that the training data in learning is fully labelled, and the test data during inference is not labelled. We propose to relax these assumptions in that training labels may only be partially available. Likewise, when some labels are given during inference, the algorithm should automatically adjust to meet the new constraints.We demonstrate the effectiveness of HSCRFs in two applications: (i) segmenting and labelling activities of daily living (ADLs) in an indoor environment and (ii) jointly modelling noun-phrases and part-of-speeches in shallow parsing. Our experimental results in the first application show that the HSCRFs are capable of learning rich, hierarchical activities with good accuracy and exhibit better performance when compared to DCRFs and flat-CRFs. Results for the partially supervised case also demonstrate that significant reduction of training labels still results in models that perform reasonably well. We also show that observing a small amount of labels can significantly increase the accuracy during decoding. In shallow parsing, the HSCRFs can achieve higher accuracy than standard CRF-based techniques and the recent DCRFs.To summarise, in this paper we claim the following contributions:• Introducing a novel Hierarchical Semi-Markov Conditional Random Field (HSCRF) to model complex hierarchical and nested Markovian processes in a discriminative framework.• Developing an efficient generalised Asymmetric Inside–Outside (AIO) algorithm for full-supervised learning.• Generalising the Viterbi algorithm for decoding the most probable semantic labels and structure given an observational sequence.• Addressing the problem of partially-supervised learning and constrained inference.• Constructing a numerical scaling algorithm to prevent numerical overflow.• Demonstration of the applicability of the HSCRFs for modelling human activities in the domain of home video surveil-lance and shallow parsing of English.The rest of the paper is organised as follows. Section 2 reviews Conditional Random Fields and Hierarchical Hidden Markov Models. Section 3 continues with the HSCRF model definition. Section 4 defines building blocks required for common in-ference tasks. Section 5 presents the generalised Viterbi algorithm. Parameterisation and estimation follow in Section 6. Learning and inference with partially available labels are addressed in Section 7. Section 8 presents a method for numerical scaling to prevent numerical overflow. Section 9 documents experimental results. Section 11 concludes the paper.1 Preliminary version was published in NIPS’08 [12].\fT. Tran et al. / Artificial Intelligence 246 (2017) 53–8555Table 1Notations used in this paper.NotationDescription(cid:3)(cid:3)xd:di: jed:di: jζ d,si: jci, j, tτ dr, s, u, v, wRd,s,zi: jπ d,su,iAd,s,zu,v,iEd,s,zu,i(cid:5) [ζ, z]Sd(cid:6)d,si: jˆ(cid:6)d,si: j(cid:7)d,si: jˆ(cid:7)d,si: jαd,si: j (u)λd,si: j (u)δ [·], I [·]ψ(·),ϕ(·)(cid:3)and starting from time i and ending at time j, inclusive(cid:3)Subset of state variables from level d down to level dSubset of ending indicators from level d down to level dSet of state variables and ending indicators of a sub model rooted at sd, level d, spanning a sub-string [i, j]Contextual cliqueTime indicesSet of all ending time indices, e.g. if i ∈ τ d then edand starting from time i and ending at time j, inclusive= 1iStateState-persistence potential of state s, level d, spanning [i, j]Initialisation potential of state s at level d, time i initialising sub-state uTransition at level d, time i from state u to v under the same pare",
            {
                "entities": [
                    [
                        3494,
                        3522,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 165–192Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIterated belief change in the situation calculus ✩Steven Shapiro a,∗, Maurice Pagnucco b, Yves Lespérance c, Hector J. Levesque aa Department of Computer Science, University of Toronto, Toronto, ON M5S 3G4, Canadab ARC Centre of Excellence for Autonomous Systems and National ICT Australia, School of Computer Science and Engineering, The University of New South Wales,Sydney, NSW 2052, Australiac Department of Computer Science and Engineering, York University, Toronto, ON M3J 1P3, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Knowledge representation and reasoningReasoning about action and changeSituation calculusBelief changeintelligenceJohn McCarthy’s situation calculus has left an enduring mark on artificialresearch. This simple yet elegant formalism for modelling and reasoning about dynamicsystems is still in common use more than forty years since it was first proposed. The abilityto reason about action and change has long been considered a necessary component forany intelligent system. The situation calculus and its numerous extensions as well as themany competing proposals that it has inspired deal with this problem to some extent. Inthis paper, we offer a new approach to belief change associated with performing actionsthat addresses some of the shortcomings of these approaches. In particular, our approach isbased on a well-developed theory of action in the situation calculus extended to deal withbelief. Moreover, by augmenting this approach with a notion of plausibility over situations,our account handles nested belief, belief introspection, mistaken belief, and handles beliefrevision and belief update together with iterated belief change.© 2010 Elsevier B.V. All rights reserved.The work of John McCarthy has had a profound and lasting effect on artificial intelligence research. One of his moreenduring contributions has been the introduction of the situation calculus [2,3]. This simple yet elegant formalism for mod-elling and reasoning about dynamic systems is still in common use more than forty years since it was first proposed. Theability to reason about action and change has long been considered a necessary component for any intelligent system. Anagent acting in its environment must be capable of reasoning about the state of its environment and keeping track of anychanges to the environment as actions are performed. Various theories have been developed to give an account of howthis can be achieved. Foremost among these are theories of belief change and theories for reasoning about action. Whileoriginating from different motivations, the two are united in their aim to have agents maintain a model of the environmentthat matches the actual environment as closely as possible given the available information. An important consideration isthe ability to deal with a succession of changes; known as the problem of iterated belief change.In this paper, we consider a new approach for modelling iterated belief change using the language of the situationcalculus [2,3]. While our approach is in some ways limited in its applicability, we feel that it is conceptually very simpleand offers a number of useful features not found in other approaches:• It is completely integrated with a well-developed theory of action in the situation calculus [4] and its extension tohandle knowledge expansion [5,6]. Specifically, the manner in which beliefs change in our account is simply a special✩An earlier version of this paper appeared in Shapiro et al. (2000) [1].* Corresponding author.E-mail addresses: steven@cs.toronto.edu (S. Shapiro), morri@cse.unsw.edu.au (M. Pagnucco), lesperan@cse.yorku.ca (Y. Lespérance), hector@ai.toronto.edu(H.J. Levesque).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.003\f166S. Shapiro et al. / Artificial Intelligence 175 (2011) 165–192case of how other fluents change as the result of actions, and thus among other things, we inherit a solution to theframe problem.• Like Scherl and Levesque [5,6], our theory accommodates both belief update and belief expansion. The former concernsbeliefs that change as the result of the realization that the world has changed; the latter concerns beliefs that changeas the result of newly acquired information.• Unlike Scherl and Levesque, however, our theory is not limited to belief expansion; rather it deals with the more generalcase of belief revision. It will be possible in our model for an agent to believe some formula φ, acquire information thatcauses it to change its mind and believe ¬φ (without believing the world has changed), and later go back to believing φagain. In Scherl and Levesque and in other approaches based on this work such as [7,8], new information that contradictsprevious beliefs cannot be consistently accommodated.• Because belief change in our model is always the result of action, our account naturally supports iterated belief change.This is simply the result of a sequence of actions. Moreover, each individual action can potentially cause both an update(by changing the world) and a revision (by providing sensing information) in a seamless way.• Like Scherl and Levesque and unlike many previous approaches to belief change, e.g., [9,10], our approach supportsbelief introspection: an agent will know what it believes and does not believe. Furthermore, it has information aboutthe past, and so will also know what it used to believe and not believe. Finally, an agent will be able to predict what itwill believe in the future after it acquires information through sensing.• Unlike Scherl and Levesque, our agents will be able to introspectively tell the difference between an update and arevision as they move from believing φ to believing ¬φ. In the former case, the agent will believe that it believed φ inthe past, and that it was correct to do so; in the latter case, it will believe that it believed φ in the past but that it wasmistaken.• One important lesson learned is that not only does our method for iterated belief change in the situation calculuspossess interesting properties but attempting to use more sophisticated schemes that involve modifying plausibilities ofpossible worlds, leads to unintuitive introspection properties when applied to situations.The rest of the paper is organized as follows: in the next section, we briefly review the situation calculus including theScherl and Levesque [5,6] model of belief expansion, and we review the most popular accounts of belief revision, beliefupdate, and iterated belief change; in Section 3, we motivate and define a new belief operator as a modification to the oneused by Scherl and Levesque; in Section 4, we prove some properties of this operator, justifying the points made above;in Section 5, we show the operator in action on a simple example, and how an agent can change its mind repeatedly;in Section 6, we analyze the extent to which our framework satisfies revision, update, and iterated revision postulates; inSection 7, we compare our framework to some of the existing approaches to belief change; and in the final section, we drawsome conclusions and discuss future work.1. BackgroundThe basis of our framework for belief change is an action theory [4] based on the situation calculus [2,3], and extendedto include a belief operator [5,6]. In this section, we begin with a brief overview of the situation calculus and follow it witha short review of belief change in sufficient detail to understand the contributions made in this paper.1.1. The situation calculusThe situation calculus is a predicate calculus language for representing dynamically changing domains. A situation repre-sents a snapshot of the domain. There is a set of initial situations corresponding to the ways the agent1 believes the domainmight be initially. The actual initial state of the domain is represented by the distinguished initial situation constant, S 0,which may or may not be among the set of initial situations believed possible by the agent. The term do(a, s) denotes theunique situation that results from the agent performing action a in situation s. Thus, the situations can be structured into aset of trees, where the root of each tree is an initial situation and the arcs are actions.Predicates and functions whose value may change from situation to situation (and whose last argument is a situation)are called fluents. For instance, we use the fluent InR1(s) to represent that the agent is in room R1 in situation s. The effectsof actions on fluents are defined using successor state axioms [4], which provide a succinct representation for both effectaxioms and frame axioms [2,3]. For example, assume that there are only two rooms, R 1 and R2, and that the action leavetakes the agent from the current room to the other room. Then, the successor state axiom for InR1 is2:(cid:2)InR1(s) ∧ a (cid:6)= leaveThis axiom asserts that the agent will be in R1 after doing some action if and only if either the agent is in R2 (¬InR1(s))and leaves it or the agent is currently in R1 and the action is anything other than leaving it.(cid:3)¬InR1(s) ∧ a = leave(cid:3)do(a, s)InR1(cid:3)(cid:3)(cid:2)(cid:2)≡∨(cid:2).1 The situation calculus can accommodate multiple agents, but for the purposes of this paper we assume that there is a single agent, and all actions areperformed by that agent.2 We adopt the convention that unbound variables are universally quantified in the widest scope.\fS. Shapiro et al. / Artificial Intelligence 175 (2011) 165–192167Moore [11] defined a possible-worlds semantics for a modal logic of knowledge in the situation calculus by treatingsituations as possible worlds. Scherl and Levesque [5,6] adapted the semantics to the action theories of Reiter [4]. The ideais to have an accessibility relation on situations, B(si",
            {
                "entities": [
                    [
                        3952,
                        3980,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1101–1132Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA probabilistic plan recognition algorithm based on plan tree grammarsChristopher W. Geib a,∗, Robert P. Goldman ba University of Edinburgh, School of Informatics 2 Buccleuch Place, Edinburgh, EH8 9LW, United Kingdomb SIFT LLC, 211 N. First St. Suite 300, Minneapolis, MN 55401, USAa r t i c l ei n f oa b s t r a c tWe present the PHATT algorithm for plan recognition. Unlike previous approaches to planrecognition, PHATT is based on a model of plan execution. We show that this clarifiesseveral difficult issues in plan recognition including the execution of multiple interleavedroot goals, partially ordered plans, and failing to observe actions. We present the PHATTalgorithm’s theoretical basis, and an implementation based on tree structures. We alsoinvestigate the algorithm’s complexity, both analytically and empirically. Finally, we presentPHATT’s integrated constraint reasoning for parametrized actions and temporal constraints.© 2009 Elsevier B.V. All rights reserved.Article history:Received 28 November 2007Received in revised form 31 October 2008Accepted 21 January 2009Available online 24 March 2009Keywords:Plan recognitionBayesian methodsProbabilistic grammarsTask trackingIntent inferenceGoal recognitionAction grammars1. IntroductionThere is an increasing need for automated systems that understand the goals and plans of their human users. Applica-tions that need such understanding include everything from assistive systems for the elderly, to computer network security,to insider threat detection, to agent based systems. As we develop such systems, we find that much of the early work onplan recognition made simplifying assumptions that are too restrictive for effective application in these domains. Some suchsimplifying assumptions include:• The observed agent is only pursuing a single plan at a time.• The observed agent’s plans are totally ordered.• Failing to observe an action means it will never be observed or the observer will see an arbitrary subset of the actualactions.• The actions within a plan have no explicit temporal relations.• The plan representation is purely propositional. That is, actions do not have parameters.1While some of these limitations have been addressed individually, our new plan recognition system, PHATT, is the firstsystem to provide a solution to all of these issues within a single framework. PHATT takes a very different approach to theproblem of intent inference2 from other systems, and it is this approach that allows it to address all of these issues at thesame time.* Corresponding author.E-mail addresses: cgeib@inf.ed.ac.uk (C.W. Geib), rpgoldman@sift.info (R.P. Goldman).1 For example, one may have an action that goes from home to the train station, and an action that goes from the train station to home, but not anaction that moves between two arbitrary locations.2 Plan recognition is sometimes also referred to as “task tracking,” “intent recognition” or “intent inference.” We will use these terms interchangeably.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.01.003\f1102C.W. Geib, R.P. Goldman / Artificial Intelligence 173 (2009) 1101–1132Most, if not all, early work on plan recognition treated plans as patterns to be matched against data, rather than asrecipes for actions to be executed. Unlike such approaches, PHATT is based on a model of plan execution, which moresimply and elegantly captures key aspects of the plan recognition problem. The critical observation behind this approachis that goal driven agents will take those actions that are consistent with their goals and are enabled by the actions theyhave already taken. We call the set of actions that the agent could execute next, given their goals and the actions they havealready performed, the pending set. Putting the execution of plans and pending sets at the center of our plan recognitionmodel, we can build a stochastic model of plan execution and from it develop a probabilistic algorithm for recognizingplans.Like much of the prior work, we will be assuming that the agents being observed are not actively deceitful. Deceitfulagents might attempt to dissemble, misdirect, or otherwise take actions to deliberately confuse an observing agent ratherthan directly to achieve goals. We will not be discussing how to address these issues here.The rest of this paper has the following structure. We first present an example domain and a short review of priorwork, with particular attention to limitations of this previous work that PHATT addresses (Sections 2 and 3). Section 4describes the intuitions behind the PHATT algorithm followed by the theoretical core of the paper in Sections 5 to 8.Section 5 formalizes plan libraries in terms of leftmost plan trees. Section 6 provides an abstract, top-down algorithm thatclosely parallels the generative model, providing a smooth transition to the probability model, and a first step to the actualimplementation. Section 7 provides a formal probability model for use with the explanations produced using the plan trees.Section 8 gives a bottom-up algorithm that approximates the top-down algorithm and then discusses its implementationand limitations.The rest of the paper covers evaluating the PHATT algorithm and extensions. Section 9 discusses the algorithm’s formalcomplexity, while Section 10 covers empirical complexity results and some studies of the algorithm’s scalability. Section 11explains PHATT’s use of variables and temporal constraints to improve its efficiency. Finally, Section 12 concludes this paperwith a discussion of topics that we think are particularly interesting areas for future work.2. BackgroundMost plan recognition algorithms require as input a plan library which implicitly specifies the set of plans that are tobe recognized. PHATT [20,22,25] is based on a model of the execution of simple hierarchical plans [16]. In this framework,plan libraries are partially ordered AND/OR trees. AND-nodes represent methods for achieving a particular task: all of thechildren of an AND-node must be performed in order to perform the parent task. The children may be further constrainedto be performed in a particular order (or one of a set of possible orders), by annotating them with pairwise orderingconstraints.As an example, Fig. 1 displays a small example plan library taken from a computer network security domain. In this case,the attacker is motivated by one of three top-level AND-node goals: bragging (Brag) (being able to boast of his/her successto other crackers); theft of information (Theft); or denial of service (DoS) (attacking a network by consuming its resourcesso that it can no longer serve its legitimate objectives). Attackers who wish to achieve bragging rights will first scan thetarget network for vulnerabilities (scan), and then attempt to gain control (get-ctrl). They are not motivated by exploitingthe control they gain. On the other hand, attackers who wish to steal information will scan for vulnerabilities, get controlof the target, and then exploit that control to steal data (get-data). Finally, an attacker who wishes to DoS the target needonly scan to identify a vulnerability, and then carry out his DoS attack (dos-attack).OR-nodes in the plan library represent places where the agent may choose one of a number of alternate methods toachieve a task. Only one of the children of an OR-node need be performed in order for the parent action to be achieved. Forthis reason, ordering constraints between the children of an OR-node are not allowed. For example, in Fig. 1 the OR-nodedos-attack has three possible children: synflood (syn-flood), bind DoS attack (bind-DoS), and the ping of Death (ping-of-death), but only one of them must be executed to perform a dos-attack. Since OR-nodes represent choices within the planwe will also refer to them as choice points for the plan, and will use these two terms interchangeably.Fig. 1. An example set of plans: In this figure, AND-nodes are represented by an undirected arc across the lines connecting the parent node to its children.OR-nodes do not have this arc. Ordering constraints in the plans are represented by directed arcs between the ordered actions. For example action scanmust be executed before get-ctrl which must be executed before get-data to perform Theft.\fC.W. Geib, R.P. Goldman / Artificial Intelligence 173 (2009) 1101–11321103Our representation of plans as partially ordered AND/OR trees is similar to the Hierarchical Task Network (HTN) represen-tation in Ghallab, Nau, and Traverso’s recent textbook [24, pp. 244–245], but does not take into account action preconditionsand postconditions. Note that our example plan library, while displaying a variety of the phenomena that we will be inter-ested in discussing, is not a full, up-to-date, or even realistic plan library for this computer security domain. This librarysimply illustrates the use of method decomposition (represented by AND-nodes), choice points (represented by OR-nodes),and ordering constraints between sibling actions. We will use this plan library as a running example throughout this article.3. Previous work in plan recognitionAttempts to perform plan recognition are almost as old as artificial intelligence itself, and over the years a large numberof methods have been applied to plan recognition. Some of the methods used include rule-based systems, parsing (bothconventional and stochastic), graph-covering, Bayesian nets, cost-based abduction, etc. Early approaches paid little atten-tion to choosing between different explanatory hypotheses. Either the problem was not isolated as a separate problem ofparticular interest (as in early rule-based approaches), or it was finessed (as in graph-covering approaches). Our Bayesianapproach addresses this issue directly (as did earlier Bayesian approaches). ",
            {
                "entities": [
                    [
                        3211,
                        3239,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 52–90Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMeasuring inconsistency with constraints for propositional knowledge basesKedian MuSchool of Mathematical Sciences, Peking University, Beijing 100871, PR Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 16 May 2016Received in revised form 12 February 2018Accepted 20 February 2018Available online 2 March 2018Keywords:InconsistencyConstraintsCausalityBipartite graphMeasuring inconsistency has been considered as a necessary starting point to understand the nature of inconsistency in a knowledge base better. For practical applications, however, we often have to face some constraints on resolving inconsistency. In this paper, we propose a graph-based approach to measuring the inconsistency for a propositional knowledge base with one or both of two typical types of constraints on modifying formulas. Here the first type of constraint, called the hard constraint, describes a pair of sets of formulas such that all the formulas in the first set should be protected from being modified on the condition that all the formulas in the second set must be modified in order to restore the consistency of that base, while the second type, called the soft constraint, describes a set of pairs of formulas that are not allowed to be modified together. At first, we use a bipartite graph to represent the relation between formulas and minimal inconsistent subsets of a knowledge base. Then we show that such a graph-based representation allows us to characterize the inconsistency with constraints in a concise way. Based on this characterization, we thus propose measures for the degree of inconsistency and for the responsibility of each formula for the inconsistency of a knowledge base with constraints, respectively. Finally, we show that these measures can be well explained based on Halpern and Pearl’s causal model and Chockler and Halpern’s notion of responsibility.© 2018 Elsevier B.V. All rights reserved.1. IntroductionInconsistency is one of the important issues in knowledge and information systems. Techniques for inconsistency han-dling have been given much attention in the community of artificial intelligence and its application domains. Recently, measuring inconsistency has been considered as a useful way of better understanding the nature of inconsistency, and then provides a promising starting point to promote the process of inconsistency handling in knowledge and information systems in many applications such as requirements engineering [22,23], network security and intrusion detection [18,19], and med-ical experts systems [29]. A growing number of inconsistency measures have been proposed so far. Hunter et al. classified these inconsistency measures into two categories, i.e., base-level measures and formula-level ones [8]. Roughly speaking, the base-level measures focus on describing how inconsistent a knowledge base is, while the formula-level ones aim to grasp the responsibility (or contribution) of each formula of a knowledge base for the inconsistency in that base.In particular, minimal inconsistent subsets of a knowledge base are attractive to measuring inconsistency in applications of syntax-based inconsistency handling [7]. Here a minimal inconsistent subset (MIS for short) refers to an inconsistent E-mail address: mukedian @math .pku .edu .cn.https://doi.org/10.1016/j.artint.2018.02.0030004-3702/© 2018 Elsevier B.V. All rights reserved.\fK. Mu / Artificial Intelligence 259 (2018) 52–9053subset without an inconsistent proper subset. Please note that minimal inconsistent subsets of a knowledge base may be considered as a natural characterization of inconsistency in that base, since we only need to remove one formula from each minimal inconsistent subset in order to restore the consistency of that base [30]. In this sense, inconsistency measures built upon minimal inconsistent subsets may help us link measuring inconsistency with resolving inconsistency in a natural way. Along this line, minimal inconsistent subsets have been used to develop base-level inconsistency measures [7,8,24,26,9] as well as formula-level measures [7,8,21,9].Theoretically, removing any formula of a minimal inconsistent subset can break the minimal inconsistent subset. Then removing a minimal part that contains at least one formula for each minimal inconsistent subset may be considered as a potential proposal for resolving the inconsistency. However, not all of such proposals for resolving inconsistency are interesting to a given practical application. For example, in requirements engineering, changing different sets of software requirements may involve different stakeholders with their own demands and benefit expectations, then a final proposal is often a trade-off between different stakeholders [22]. Generally, domain experts and users often have a good sense of which proposals are more appropriate for resolving inconsistency in that application. They may also have a sense of “conditions” for acceptable proposals for the application domain, which would rule out the proposals that they know would not be of interest. Thus, a good heuristic is to specify such intuition or expectations on resolving inconsistency as constraints to facilitate inconsistency handling in practical applications. For example, the integrity constraints in merging an inconsistent multiset of information from different sources are used to characterize the behavior that any expected merging operator has to obey [15]. In requirements engineering, essential requirements are not allowed to be involved in any feasible proposal for resolving contradictions between requirements in general case [27].Besides that such constraints can help us to select proposals we want, they may be pushed deep into the process of inconsistency handling to improve the effectiveness of related activities involved in resolving inconsistency. In particular, incorporating such constraints in measuring inconsistency can help us establish more practical relations between measuring inconsistency and resolving inconsistency.In this paper, we focus on two typical kinds of constraints on modifying formulas of a knowledge base. A constraint of the first type is a pair of sets of formulas such that all the formulas in the first set should be protected from being modified, on the condition that all the formulas in the second must be changed in resolving inconsistency. We call such a constraint a hard constraint. Generally, a hard constraint represents some partial compromise on resolving inconsistency in practical applications. In contrast, a constraint of the second type is given as a set of pairs of formulas that are not allowed to be modified together in resolving inconsistency. We call such a constraint a soft constraint.(cid:2)(cid:2)As mentioned above, minimal inconsistent subsets can be considered as a promising starting point to connect inconsis-tency measures and syntax-based inconsistency handling. However, selecting formulas that have to be modified to break minimal inconsistent subsets from their own respective perspectives does not necessarily lead to an effective proposal for resolving inconsistency. Intuitively, overlaps between minimal inconsistent subsets are often of interest to breaking all the minimal inconsistent subsets by removing as few formulas as possible. Then such two overlapping minimal inconsistent subsets should be associated with each other when we want to break them. Along this line, given a minimal inconsistent subset, any two minimal inconsistent subsets that have their own respective overlaps with the minimal inconsistent subset will be also associated with each other even if the two subsets have no overlap. More generally, two minimal inconsistent are associated with each other if there is a chain of minimal inconsistent subsets M1, M2, · · · , Mn with subsets M and MM1 = M and Mn = Msuch that Mi+1 and Mi overlap each other for all i = 1, 2, · · · , n − 1. Evidently, these associations bring a partition of the set of minimal inconsistent subsets such that only minimal inconsistent subsets in the same part (called a cluster in this paper) are associated with one another (but not necessarily overlap), moreover, they should be broken as a whole instead of from their own respective perspectives. Then we need to know how the minimal inconsistent subsets in a cluster are associated with each other in order to break them together. That is, we need to capture both the interconnection relation between minimal inconsistent subsets and formulas that play important roles in the interconnection so as to help us understand the role of each formula in causing the inconsistency from a perspective of causality. To address this, we con-struct a bipartite graph for a knowledge base, which represents both the inner structure of each minimal inconsistent subset and the interconnection between minimal inconsistent subsets due to their overlaps. Then we show that such a graph-based representation allows us to incorporate the two types of constraints in characterizing inconsistency in a concise way. Based on this incorporation, we propose approaches to measuring inconsistency with one or both of the two types of constraints, respectively. In particular, both our base-level and formula-level measures can be reduced to their respective corresponding measures presented in [21] when there is no constraint. Some intuitive logical properties and complexity issues for these inconsistency measures are also discussed, respectively.On the other hand, it is often expected that an inconsistency measure under development will be interpretable. That is, inconsistency measures may need to be tied in with some specific interpretations that can help us gain an intuitive insight into the inconsistency. Generally, causality plays an important role in analyzing and resolving inc",
            {
                "entities": [
                    [
                        3457,
                        3485,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1054–1078Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRange and Roots: Two common patterns for specifying and propagatingcounting and occurrence constraints ✩Christian Bessiere a, Emmanuel Hebrard b, Brahim Hnich c, Zeynep Kiziltan d, Toby Walsh e,∗a LIRMM, CNRS and U. Montpellier, Montpellier, Franceb 4C and UCC, Cork, Irelandc Izmir University of Economics, Izmir, Turkeyd Department of Computer Science, Univ. di Bologna, Italye NICTA and UNSW, Sydney, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 18 September 2007Received in revised form 26 February 2009Accepted 3 March 2009Available online 17 March 2009Keywords:Constraint programmingConstraint satisfactionGlobal constraintsOpen global constraintsDecompositions1. IntroductionWe propose Range and Roots which are two common patterns useful for specifying awide range of counting and occurrence constraints. We design specialised propagationalgorithms for these two patterns. Counting and occurrence constraints specified usingthese patterns thus directly inherit a propagation algorithm. To illustrate the capabilities ofthe Range and Roots constraints, we specify a number of global constraints taken from theliterature. Preliminary experiments demonstrate that propagating counting and occurrenceconstraints using these two patterns leads to a small loss in performance when comparedto specialised global constraints and is competitive with alternative decompositions usingelementary constraints.© 2009 Elsevier B.V. All rights reserved.Global constraints are central to the success of constraint programming [25]. Global constraints allow users to specifypatterns that occur in many problems, and to exploit efficient and effective propagation algorithms for pruning the searchspace. Two common types of global constraints are counting and occurrence constraints. Occurrence constraints place re-strictions on the occurrences of particular values. For instance, we may wish to ensure that no value used by one set ofvariables occurs in a second set. Counting constraints, on the other hand, restrict the number of values or variables meetingsome condition. For example, we may want to limit the number of distinct values assigned to a set of variables. Many dif-ferent counting and occurrences constraints have been proposed to help model a wide range of problems, especially thoseinvolving resources (see, for example, [22,4,23,3,5]).In this paper, we will show that many such constraints can be specified by means of two new global constraints, Rangeand Roots together with some standard elementary constraints like subset and set cardinality. These two new global con-straints capture the familiar notions of image and domain of a function. Understanding such notions does not require a strong✩This paper is a compilation and an extension of [C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The RANGE and ROOTS constraints: Specifyingcounting and occurrence problems, in: L.P. Kaelbling, A. Saffiotti (Eds.), IJCAI, Professional Book Center, 2005, pp. 60–65; C. Bessiere, E. Hebrard, B. Hnich, Z.Kiziltan, T. Walsh, The RANGE constraint: Algorithms and implementation, in: J.C. Beck, B.M. Smith (Eds.), CPAIOR, in: Lecture Notes in Computer Science,vol. 3990, Springer, 2006, pp. 59–73; C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The ROOTS constraint, in: F. Benhamou (Ed.), CP, in: LectureNotes in Computer Science, vol. 4204, Springer, 2006, pp. 75–90]. The first author was supported by the ANR project ANR-06-BLAN-0383-02.* Corresponding author.E-mail addresses: bessiere@lirmm.fr (C. Bessiere), e.hebrard@4c.ucc.ie (E. Hebrard), brahim.hnich@ieu.edu.tr (B. Hnich), zeynep@cs.unibo.it (Z. Kiziltan),tw@cse.unsw.edu.au (T. Walsh).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.001\fC. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781055background in constraint programming. A basic mathematical background is sufficient to understand these constraints anduse them to specify other global constraints. We will show, for example, that Range and Roots are versatile enough toallow specification of open global constraints, a recent kind of global constraints for which the set of variables involved isnot known in advance.Specifications made with Range and Roots constraints are executable. We show that efficient propagators can be de-signed for the Range and Roots constraints. We give an efficient algorithm for propagating the Range constraint based ona flow algorithm. We also prove that it is intractable to propagate the Roots constraint completely. We therefore proposea decomposition of the Roots constraint that can propagate it partially in linear time. This decomposition does not destroythe global nature of the Roots constraint as in many situations met in practice, it prunes all possible values. The proposedpropagators can easily be incorporated into a constraint toolkit.We show that specifying a global constraint using Range and Roots provides us with an reasonable method to propagatecounting and occurrence constraints. There are three possible situations. In the first, the global nature of the Range andRoots constraints is enough to capture the global nature of the given counting or occurrence constraint, and propagation isnot hindered. In the second situation, completely propagating the counting or occurrence constraint is NP-hard. We mustaccept some loss of propagation if propagation is to be tractable. Using Range and Roots is then one means to propagatethe counting or occurrence constraint partially. In the third situation, the global constraint can be propagated completely inpolynomial time but using Roots and Range hinders propagation. In this case, if we want to achieve full propagation, weneed to develop a specialised propagation algorithm.We also show that decomposing occurrence constraints and counting constraints using the Range and Roots constraintsperforms well in practice. Our experiments on random CSPs and a on real world problem from CSPLib demonstrate thatpropagating counting and occurrence constraints using the Range and Roots constraints leads to a small loss in performancewhen compared to specialised global constraints and is competitive with alternative decompositions into more elementaryconstraints.The rest of the paper is organised as follows. Section 2 gives the formal background. Section 3 defines the Range andRoots constraints and gives a couple of examples to illustrate how global constraints can be decomposed using these twoconstraints. In Section 4, we propose a polynomial algorithm for the Range constraint. In Section 5, we give a completetheoretical analysis of the Roots constraint and our decomposition of it, and we discuss implementation details. Section 6gives many examples of counting and occurrence constraints that can be specified using the Range and Roots constraints.Experimental results are presented in Section 7. Finally, we end with conclusions in Section 8.2. Formal backgroundA constraint satisfaction problem consists of a set of variables, each with a finite domain of values, and a set of con-straints specifying allowed combinations of values for subsets of variables. We use capitals for variables (e.g. X , Y and S),and lower case for values (e.g. v and w). We write D( X) for the domain of a variable X . A solution is an assignment ofvalues to the variables satisfying the constraints. A variable is ground when it is assigned a value. We consider both integerand set variables. A set variable S is often represented by its lower bound lb(S) which contains the definite elements (thatmust belong to the set) and an upper bound ub(S) which also contains the potential elements (that may or may not belongto the set).Constraint solvers typically explore partial assignments enforcing a local consistency property using either specialised orgeneral purpose propagation algorithms. Given a constraint C , a bound support on C is a tuple that assigns to each integervariable a value between its minimum and maximum, and to each set variable a set between its lower and upper boundswhich satisfies C . A bound support in which each integer variable is assigned a value in its domain is called a hybrid support.If C involves only integer variables, a hybrid support is a support. A value (resp. set of values) for an integer variable (resp.set variable) is bound or hybrid consistent with C iff there exists a bound or hybrid support assigning this value (resp. set ofvalues) to this variable. A constraint C is bound consistent (BC) iff for each integer variable Xi , its minimum and maximumvalues belong to a bound support, and for each set variable S j , the values in ub(S j) belong to S j in at least one boundsupport and the values in lb(S j) are those from ub(S j) that belong to S j in all bound supports. A constraint C is hybridconsistent (HC) iff for each integer variable Xi , every value in D( Xi) belongs to a hybrid support, and for each set variable S j ,the values in ub(S j) belong to S j in at least one hybrid support, and the values in lb(S j) are those from ub(S j) that belongto S j in all hybrid supports. A constraint C involving only integer variables is generalised arc consistent (GAC) iff for eachvariable Xi , every value in D( Xi) belongs to a support. If all variables in C are integer variables, hybrid consistency reducesto generalised arc consistency, and if all variables in C are set variables, hybrid consistency reduces to bound consistency.To illustrate these different concepts, consider the constraint C( X1, X2, T ) that holds iff the set variable T is assignedexactly the values used by the integer variables X1 and X2. Let D( X1) = {1, 3}, D( X2) = {2, 4}, lb(T ) = {2} and ub(T ) ={1, 2, 3, 4}. BC does not remove any value since all domains are already bound consistent (value 2 was ",
            {
                "entities": [
                    [
                        3908,
                        3936,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1172–1221Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUpdating action domain descriptions ✩Thomas Eiter a, Esra Erdem b, Michael Fink a,∗, Ján Senko aa Institute of Information Systems, Vienna University of Technology, Vienna, Austriab Faculty of Engineering and Natural Sciences, Sabancı University, Istanbul, Turkeya r t i c l ei n f oa b s t r a c tArticle history:Received 28 November 2008Received in revised form 4 June 2010Accepted 27 June 2010Available online 17 July 2010Keywords:Knowledge representationReasoning about actions and changeTheory changeAction languagesPreference-based semanticsIncorporating new information into a knowledge base is an important problem which hasbeen widely investigated. In this paper, we study this problem in a formal frameworkfor reasoning about actions and change. In this framework, action domains are describedin an action language whose semantics is based on the notion of causality. Unlikethe formalisms considered in the related work, this language allows straightforwardrepresentation of non-deterministic effects and indirect effects of (possibly concurrent)actions, as well as state constraints; therefore, the updates can be more general thanelementary statements. The expressivity of this formalism allows us to study the updateof an action domain description with a more general approach compared to related work.First of all, we consider the update of an action description with respect to furthercriteria, for instance, by ensuring that the updated description entails some observations,assertions, or general domain properties that constitute further constraints that are notexpressible in an action description in general. Moreover, our framework allows us todiscriminate amongst alternative updates of action domain descriptions and to single outa most preferable one, based on a given preference relation possibly dependent on thespecified criteria. We study semantic and computational aspects of the update problem,and establish basic properties of updates as well as a decomposition theorem that givesrise to a divide and conquer approach to updating action descriptions under certainconditions. Furthermore, we study the computational complexity of decision problemsaround computing solutions, both for the generic setting and for two particular preferencerelations, viz. set-inclusion and weight-based preference. While deciding the existence ofsolutions and recognizing solutions are PSPACE-complete problems in general, the problemsfall back into the polynomial hierarchy under restrictions on the additional constraints. Wefinally discuss methods to compute solutions and approximate solutions (which disregardpreference). Our results provide a semantic and computational basis for developing systemsthat incorporate new information into action domain descriptions in an action language, inthe presence of additional constraints.© 2010 Elsevier B.V.Open access under CC BY-NC-ND license.1. IntroductionAs we live in a world where knowledge and information is in flux, updating knowledge bases is an important issuethat has been widely studied in the area of knowledge representation and reasoning (see e.g. [67,12,20,61] and references✩This paper is a revised and significantly extended version of a preliminary paper that appeared in: Proc. 19th International Joint Conference on ArtificialIntelligence (IJCAI 2005), pp. 418–423.* Corresponding author.E-mail addresses: eiter@kr.tuwien.ac.at (T. Eiter), esraerdem@sabanciuniv.edu (E. Erdem), michael@kr.tuwien.ac.at (M. Fink), jan@kr.tuwien.ac.at(J. Senko).0004-3702 © 2010 Elsevier B.V.doi:10.1016/j.artint.2010.07.004Open access under CC BY-NC-ND license.\fT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211173therein). However, the problem is far from trivial and many different methods have been proposed to incorporate newinformation, be it affirmative or prohibitive, which are based on different formal and philosophical underpinnings, cf. [67,39,57]. It appears that there is no general purpose method that would work well in all settings, which is partly due to thefact that an update method is also dependent to some extent on the application domain.In particular, in reasoning about actions and change, the dynamicity of the world is a part of the domain theory, andrequires special attention in update methods. For various approaches to formal action theories, including the prominentsituation calculus, event calculus, and action languages that emerged from the research on non-monotonic reasoning, theproblem of change has been widely studied and different methods have been proposed (see [64] for background and refer-ences, and Section 8.1 for a more detailed discussion).To give a simple example, consider an agent having the following knowledge, K TV , about a TV with remote control:(TV1) If the power is off, pushing the power button on the TV turns the power on.(TV2) If the power is on, pushing the power button on the TV turns the power off.(TV3) The TV is on whenever the power is on.1(TV4) The TV is off whenever the power is off.Now assume that the agent does not know how a remote control works (e.g., she does not know the effect of pushing thepower button on the remote control). Suppose that later she obtains the following information, K RC , about remote controls:(RC1) If the power is on and the TV is off, pushing the power button on the remote control turns the TV on.(RC2) If the TV is on, pushing the power button on the remote control turns the TV off.The task is now to incorporate this new knowledge into the current knowledge base K TV . In this particular case, thisseems unproblematic, as upon simply adding K RC to KTV the resulting stock of knowledge is consistent; in general, however,it might be inconsistent, and a major issue is how to overcome this inconsistency.We study the incorporation problem in the context of action languages [30]. In these formalisms, actions and change aredescribed by “causal laws.” For instance, in the action language C [32], the direct effect of the action of pushing the powerbutton on the TV, stated in (TV1), is described by the causal lawcaused PowerON after PushPBTV ∧ ¬PowerON,(1)which expresses that this action, represented by PushPBTV , causes the value of the fluent PowerON to change from false totrue; the indirect effect of this action that is stated in (TV3) is described by the causal lawcaused TvON if PowerON,(2)which expresses that if the fluent PowerON is caused to be true, then the fluent TvON is caused to be true as well.Action description languages are quite expressive to easily handle non-determinism, concurrency, ramifications, qualifica-tions, etc. The meaning of an action description can be represented by a “transition diagram”—a directed graph whose nodescorrespond to states and whose edges correspond to action occurrences; Fig. 1 below (Section 2) shows an example. Thereare reasoning systems, like CCalc2 and DLVK,3 that accept domain descriptions in an action language, like C or K respec-tively, and support various kinds of reasoning tasks over these descriptions, including planning, prediction and postdictionin CCcalc and computing different kinds of plans in DLVK.As far as action languages are concerned, the update problem was studied to a remarkably little extent. For the basicaction language A (see [30]), which is far less expressive than C, the update problem has been considered, e.g., in [44,47]. Both works focused on updates that consist of elementary statements (i.e., essentially facts) over time, and presentedspecific update methods, focusing on the contents of the knowledge base. We address the update problem from a moregeneral perspective in the following ways:• We consider a richer language (i.e., a fragment of C) to study the update problem, and updates are represented interms of a set of arbitrary causal laws.• We view the update problem from a more general perspective. Sometimes, ensuring consistency is not sufficient: wemight want to ensure also that the updated action description entails some scenarios, conditions, or general properties ofthe domain that cannot be expressed by causal laws. In our update framework, such further knowledge could be taken intoaccount.For example, for the effective use of the TV system in the above scenario, the following constraint might be imposed:(C) Pushing the power button on the remote control is always possible.41 Note that the statement is wrong; its defectiveness is observed and resolved upon update.2 http://www.cs.utexas.edu/users/tag/cc/.3 http://www.dbai.tuwien.ac.at/proj/dlv/K/.4 Note the conceptual difference between (C) and (TV2): (C) expresses an executability condition, whereas (TV2) captures a causal relationship.\f1174T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221If KRC is simply added to KTV , then (C) is not satisfied by KRC ∪ KTV : when the power and the TV are on, pushing the powerbutton on the remote control is not possible, since (RC2) and (TV3) contradict. The question is then how the agent canupdate KTV by incorporating KRC relative to (C); note that (C) is not expressible by causal laws in the action language C.To represent constraints like (C), we use formulas for “queries” in action languages like in [30]; here, the formulaALWAYS executable {PushPBRC}(3)has to evaluate to true, where {PushPBRC} stands for the concrete action of pushing the power button on the remote control.Similarly, consider the following scenario that we might want the updated action description to entail:(S) Sometimes, when the power is on, pushing the power button on TV turns the power off, and after that if we push thepower button on the TV then the power is on again.This scenario cannot be expressed by means of causal laws either; however, it can be expressed by a formulaSOMETIMES evolves PowerON; {PushPBTV };¬PowerON; {PushPBTV }; PowerON.• Some",
            {
                "entities": [
                    [
                        3695,
                        3723,
                        "DOI"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 28–61Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintYAGO2: A spatially and temporally enhanced knowledge basefrom WikipediaJohannes Hoffart a,∗, Fabian M. Suchanek b, Klaus Berberich a, Gerhard Weikum aa Max Planck Institute for Informatics, Germanyb INRIA Saclay, Francea r t i c l ei n f oa b s t r a c tWe present YAGO2, an extension of the YAGO knowledge base, in which entities, facts, andevents are anchored in both time and space. YAGO2 is built automatically from Wikipedia,GeoNames, and WordNet. It contains 447 million facts about 9.8 million entities. Humanevaluation confirmed an accuracy of 95% of the facts in YAGO2. In this paper, we presentthe extraction methodology, the integration of the spatio-temporal dimension, and ourknowledge representation SPOTL, an extension of the original SPO-triple model to timeand space.© 2012 Elsevier B.V. All rights reserved.Article history:Received 8 November 2010Received in revised form 10 April 2012Accepted 16 June 2012Available online 18 June 2012Keywords:OntologiesKnowledge basesSpatio-temporal factsInformation extraction1. Introduction1.1. MotivationComprehensive knowledge bases in machine-readable representations have been an elusive goal of AI for decades.Seminal projects such as Cyc [1] and WordNet [2] manually compiled common sense and lexical (word-sense) knowl-edge, yielding high-quality repositories on intensional knowledge: general concepts, semantic classes, and relationships likehyponymy (subclass-of) and meronymy (part-of). These early forms of knowledge bases contain logical statements that song-writers are musicians, that musicians are humans and that they cannot be any other species, or that Canada is part of NorthAmerica and belongs to the British Commonwealth. However, they do not know that Bob Dylan and Leonard Cohen aresongwriters, that Cohen is born in Montreal, that Montreal is a Canadian city, or that both Dylan and Cohen have won theGrammy Award. Early resources like the original Cyc and WordNet lacked extensional knowledge about individual entitiesof this world and their relationships (or had only very sparse coverage of such facts).In the last few years, the great success of Wikipedia and algorithmic advances in information extraction have revivedinterest in large-scale knowledge bases and enabled new approaches that could overcome the prior limitations. Notableendeavors of this kind include DBpedia [3], KnowItAll [4,5], Omega [6], WikiTaxonomy [7,8], and YAGO [9,10], and mean-while there are also commercial services such as freebase.com, trueknowledge.com, or wolframalpha.com. These contain manymillions of individual entities, their mappings into semantic classes, and relationships between entities. DBpedia has har-vested facts from Wikipedia infoboxes at large scale, and also interlinks its entities to other sources in the Linked DataCloud [11]. YAGO has paid attention to inferring class memberships from Wikipedia category names, and has integratedthis information with the taxonomic backbone of WordNet. Most of these knowledge bases represent facts in the form of* Corresponding author.E-mail address: jhoffart@mpi-inf.mpg.de (J. Hoffart).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.001\fJ. Hoffart et al. / Artificial Intelligence 194 (2013) 28–6129subject–property–object triples (SPO triples) according to the RDF data model, and some provide convenient query interfacesbased on languages like SPARQL.However, current state-of-the-art knowledge bases are mostly blind to the temporal dimension. They may store birthdates and death dates of people, but they are unaware of the fact that this creates a time span that demarcates the person’sexistence and her achievements in life. They are also largely unaware of the temporal properties of events. For example,they may store that a certain person is the president of a certain country, but presidents of countries or CEOs of companieschange. Even capitals of countries or spouses are not necessarily forever. Therefore, it is crucial to capture the time periodsduring which facts of this kind actually happened. However, this kind of temporal knowledge has not yet been treatedsystematically in state-of-the-art work. A similar problem of insufficient scope can be observed for the spatial dimension.Purely entity-centric representations know locations and their located-in relations, but they do not consistently attach ageographical location to events and entities. The geographical location is a crucial property not just of physical entities suchas countries, mountains, or rivers, but also of organization headquarters, or events such as battles, fairs, or people’s births.All of these entities have a spatial dimension.If it were possible to consistently integrate the spatial and the temporal dimension into today’s knowledge bases, thiswould catapult the knowledge bases to a new level of usefulness. The knowledge base would be fully time and space aware,knowing not only that a fact is true, but also when and where it was true. The most obvious application is that it wouldbecome possible to ask for distances between places, such as organization headquarters and cities (already possible today),or even between places of events (mostly not supported today). The time-awareness would allow asking temporal queries,such as “Give me all songs that Leonard Cohen wrote after Suzanne”. Another, perhaps less obvious application is the abilityto spatially and temporally locate practically any entity that occurs in a natural language discourse. Simple examples aresentences such as “I am going to Berlin”, which could be automatically annotated with the coordinates of Berlin. We mayeven want to refer to locations by informal and vague phrases such as “the Midwest” or “the corn belt”. Likewise, the newknowledge base would be able to assign a time dimension to a sentence such as “During the era of Elizabeth I, the Englishwaged war against the Spanish”, so that this event could be temporally anchored. More subtle examples are expressionsthat have both a temporal and a spatial dimension. Take “Summer of Love” as example. This term conveys more than just atime (1967). It also conveys a place (San Francisco) and duration (a few months) [12]. A time and space aware knowledgebase could correctly locate this event on both dimensions. We could for example ask for “all musicians born in the vicinityof the Summer of Love”.1.2. ContributionWhat we need is a comprehensive anchoring of current ontologies along both the spatial and the temporal dimension.This paper presents such an endeavor: YAGO2. As the name suggests, this is a new edition of the YAGO knowledge base.However, in contrast to the original YAGO, the methodology for building YAGO2 (and also maintaining it) is systematicallydesigned top-down with the goal of integrating entity-relationship-oriented facts with the spatial and temporal dimensions.To this end, we have developed an extensible approach to fact extraction from Wikipedia and other sources, and we havetapped on specific inputs that contribute to the goal of enhancing facts with spatio-temporal scope. Moreover, we havedeveloped a new representation model, coined SPOTL tuples (SPO + Time + Location), which can co-exist with SPO triples,but provide a much more convenient way of browsing and querying the YAGO2 knowledge base. In addition, YAGO2 in-corporates carefully selected keywords and keyphrases that characterize entities; these are automatically gathered from thecontexts where facts are extracted. As no knowledge base can ever be complete, the conteXtual annotations further enhancethe capabilities for querying and interactive exploration. The full YAGO2 interface provides SPOTLX tuples to this end.Along these lines, the paper makes the following novel contributions:• an extensible framework for fact extraction that can tap on infoboxes, lists, tables, categories, and regular patterns in freetext, and allows fast and easy specification of new extraction rules;• an extension of the knowledge representation model tailored to capture time and space, as well as rules for propagatingtime and location information to all relevant facts;• methods for gathering temporal facts from Wikipedia and for seamlessly integrating spatial types and facts from GeoN-ames (http://geonames.org), in an ontologically clean manner with high accuracy;• a new SPOTL(X) representation of spatio-temporally enhanced facts, with expressive and easy-to-use querying;• exemplary demonstrations of the added value obtained by the spatio-temporal knowledge in YAGO2, by showing howthis aids in extrinsic tasks like question answering and named entity disambiguation.The result is YAGO2, available at http://www.yago-knowledge.org. It contains more than 447 million facts for 9.8 millionentities (if GeoNames entities are included). Without GeoNames entities, it still contains 124 million facts for 2.6 millionentities, extracted from Wikipedia and WordNet. Both facts and entities are properly placed on their temporal and geo-graphical dimension, thus making YAGO2 a truly time and space aware ontology. More than 30 million facts are associatedwith their occurrence time, and more than 17 million with the location of their occurrence. The time of existence is knownfor 47% of all entities, the location for 30%. Sampling-based manual assessment shows that YAGO2 has a precision (i.e.,absence of false positives) of 95 percent (with statistical significance tests).\f30J. Hoffart et al. / Artificial Intelligence 194 (2013) 28–61The rest of the paper is organized as follows. Section 2 gives a brief overview of the original YAGO knowledge base.Section 3 presents our extraction architecture. Section 4 introduces the temporal dimension in YAGO2. Section 5 introducesthe spatial dimension. Section 6 explains additional contex",
            {
                "entities": [
                    [
                        3346,
                        3374,
                        "DOI"
                    ]
                ]
            }
        ]
    ]
}