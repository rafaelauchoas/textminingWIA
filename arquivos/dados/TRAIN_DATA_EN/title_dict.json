{
    "TRAINING_DATA": [
        [
            "Artificial Intelligence 184–185 (2012) 1–16Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA complete solution to the Maximum Density Still Life Problem ✩Geoffrey Chu, Peter J. Stuckey∗NICTA Victoria Laboratory, Department of Computing and Information Systems, University of Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 17 August 2011Received in revised form 8 November 2011Accepted 8 February 2012Available online 10 February 2012Keywords:Combinatorial optimizationSearchConstraint programmingDynamic programming1. IntroductionThe Maximum Density Still Life Problem (CSPLib prob032) is to find the maximum numberof live cells that can fit in an n × n region of an infinite board, so that the board is stableunder the rules of Conway’s Game of Life. It is considered a very difficult problem andhas a raw search space of O (2n2). Previous state of the art methods could only solveup to n = 20. We give a powerful reformulation of the problem into one of minimizing“wastage” instead of maximizing the number of live cells. This reformulation allows usto compute very strong upper bounds on the number of live cells, which dramaticallyreduces the search space. It also gives us significant insights into the nature of the problem.By combining these insights with several powerful techniques: remodeling, lazy clausegeneration, bounded dynamic programming, relaxations, and custom search, we are ableto solve the Maximum Density Still Life Problem for all n. This is possible because theMaximum Density Still Life Problem is in fact well behaved mathematically for sufficientlylarge n (around n > 200) and if such very large instances can be solved, then there existways to construct provably optimal solutions for all n from a finite set of base solutions.Thus we show that the Maximum Density Still Life Problem has a closed form solution anddoes not require exponential time to solve.© 2012 Elsevier B.V. All rights reserved.The Game of Life was invented by John Horton Conway and is played on an infinite board made up of square cells. Thegame takes place through discrete time steps. Each cell c in the board is either alive or dead during each time period. Thelive/dead state of cell c at time t + 1, denoted as state(c, t + 1), can be obtained from the number l of live neighbors of c attime t and from state(c, t) as follows:state(c, t + 1) =⎧⎪⎪⎪⎨⎪⎪⎪⎩l < 2 dead [Death by isolation]l = 2 state(c, t) [Stable condition]l = 3 alive [Birth condition]l > 3 dead [Death by overcrowding]The board is said to be a still life at time t if it is stable under these rules, i.e., it is identical at t + 1. For example, anempty board is a still life. Given a finite n × n region where all cells outside must be dead, the Maximum Density Still LifeProblem is to compute the maximum density of live cells that can appear in the n × n region in a still life, or equivalently,the maximum number of live cells that can appear in the n × n region.✩This paper includes and significantly extends the earlier work (Chu et al., 2009) [1].* Corresponding author.E-mail address: peter.stuckey@nicta.com.au (P.J. Stuckey).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.02.001\f2G. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–16The raw search space of the Still Life Problem has size O (2n2) and it is extremely difficult even for small values of n.Previous search methods using integer programming (IP) [2] and constraint programming (CP) [3] could only solve upto n = 9, while a CP/IP hybrid method with symmetry breaking [3] could solve up to n = 15. An attempt using bucketelimination [4] reduced the time complexity to O (n223n) but increased the space complexity to O (n22n). This methodcould solve up to n = 14 before it ran out of memory. A subsequent improvement that combined bucket elimination withsearch [5] used less memory and was able to solve up to n = 20.In this paper, we combine some mathematical insights into the Still Life Problem with several powerful search techniquesto completely solve the problem for all n. This is possible because the Still Life Problem becomes well behaved mathemat-ically for sufficiently large n (around n > 200). The overall solution plan has four parts: (1) use complete search with amodel that propagates strongly to solve the problem for all “small” n (n (cid:2) 50), (2) use bounded dynamic programming ona relaxation of the problem to prove a closed form upper bound on live cells for all medium and large n (n > 50), (3) use acustom search to look for special form solutions to prove lower bounds on live cells for medium n (around 50 < n (cid:2) 200),(4) look for special form periodic solutions that can be tiled to construct arbitrarily large solutions to prove lower boundson live cells for large n (around n > 200). The lower and upper bounds proved in parts 2, 3 and 4 coincide, thus they are theoptimums for those n. Each of these parts require some mathematical insights into the problem as well as the appropriateapplication of search techniques. We give a brief overview of them here.Part 1. In Section 2 we give a new insightful proof that the maximum density of live cells in the infinite case (n = ∞)2 . The proof is based on counting “wastage”. Wastage is calculated by looking at each 3 × 3 pattern and seeing howis 1much space we have “wasted” by not fitting in enough live cells into the local area. This proof allows us to reformulatethe Maximum Density Still Life Problem into one of minimizing wastage rather than maximizing the number of live cells.The new model gives very tight lower bounds on wastage that dramatically increases the pruning strength of the model. InSection 3 we show how this model, coupled with a simple lookahead, allows a Lazy Clause Generation [6] solver to solvethe problem up to around n = 50 using complete search.Part 2. In Section 4, we conjecture that for sufficiently large n, all wastage which is forced to occur by the still life con-straints are forced by only the constraints near the edge of the n × n region. That is, only the boundary conditions causesuboptimality compared to the optimal density of 12 in the infinite case. If this conjecture holds, then it is possible to geta very good or optimal lower bound on the wastage (and thus upper bound on live cells) simply by relaxing the Still LifeProblem onto its boundary and solving it, i.e., ignore all constraints other than then those within the first k rows of theedge of the n × n region for some small k. This relaxed problem has the interesting property that the pathwidth of itsconstraint graph is O (k) instead of the O (n) of the original. There exist various techniques for solving such low pathwidthproblems which can reduce the complexity from O (2nk) to only O (n22k), e.g., caching [7], nogood learning [6,8], dynamicprogramming [9], variable elimination [4]. In Section 5 we show how to use bounded dynamic programming [10] to solvethe boundary relaxation. For fixed and small k, these relaxed problems can be solved in O (n) time. Furthermore, due to thetranslational symmetry in the problem, we can solve the boundary relaxation for all n using induction by examining a finitenumber of base cases. Thus we can derive a closed form expression which gives a very tight upper bound on the numberof live cells.Part 3. In Section 6, we conjecture that for sufficiently large n, there always exist optimal solutions of the following form:wastage only exists at the four 4 × 4 corners of the board, or in the one row beyond the edge of the board. Based on thisconjecture, we search for these special form solutions using a variant of limited discrepancy search with dynamic relaxationsas a lookahead. Such a search can find optimal solutions for up to n = 200 or so. We know that the solution is optimal ifthe number of live cells in the solution coincides with the upper bound on live cells proved in part 2.Part 4. The Still Life Problem becomes mathematically well behaved for sufficiently large n. This raises the possibility thatoptimal solutions can be constructed in a systematic way. In Section 7 we find optimal solutions for n ∼ 200 which areperiodic, and which satisfy certain other constraints. If such solutions are found, then they can be tiled indefinitely toproduce arbitrarily large, provably optimal solutions.We conclude the paper in Section 8.2. Wastage reformulationThe maximum density of live cells in a still life on an infinite board is known to be 12 [11]. However, this proof is quitecomplex and only applies to the infinite case. In this section we provide a much simpler proof that can easily be extendedto the finite case and gives much better insight into the possible sub-patterns that can occur in an optimal solution.Theorem 1. The maximum density of live cells in a still life on an infinite board is 12 .Proof. Consider any configuration of the board which is a still life. We show that the density of live cells in this configura-tion is (cid:2) 12 . We initially assign 2 tokens to each cell in the board. We will show below that there exists a way to redistribute\fG. Chu, P.J. Stuckey / Artificial Intelligence 184–185 (2012) 1–163Table 1Possible patterns around dead cells, showing where they donate their tokens and anywastage.Table 2Contributions to the tokens of a live cell from its Southneighbor.these tokens such that: (1) each live cell ends up with (cid:3) 4 tokens, and (2) each token either remains at the original cell towhich it was assigned, or is redistributed to one of the 4 orthogonal neighbors. If such a redistribution exists, then in anyn × n region of the infinite board, if L is the number of live cells, then: 2(n2 + 4n) (cid:3) 4L. This is because at most 2(n2 + 4n)tokens could have ended up in the n × n region after redistribution, and each live cell must have (cid:3) 4 of them. Rearranging,we get L/n2 (cid:2) 12 and t",
            {
                "entities": [
                    [
                        146,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 322 (2023) 103951Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintSpectral complexity-scaled generalisation bound of complex-valued neural networksHaowen Chen a,b,c, Fengxiang He d,b,∗a Department of Mathematics, ETH Zürich, 8092 Zürich, Switzerlandb JD Explore Academy, JD.com, Inc., Beijing, 100176, Chinac Department of Mathematics, Faculty of Science, The University of Hong Kong, Hong Kong Special Administrative Regiond Artificial Intelligence and its Applications Institute, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdome School of Computer Science, Faculty of Engineering, The University of Sydney, Darlington NSW 2008, Australia, Shiye Lei e, Dacheng Tao e,ba r t i c l e i n f oa b s t r a c tArticle history:Received 12 November 2021Received in revised form 22 May 2023Accepted 27 May 2023Available online 5 June 2023Keywords:Complex-valued neural networksGeneralisationSpectral complexityComplex-valued neural networks (CVNNs) have been widely applied in various fields, primarily in signal processing and image recognition. Few studies have focused on the generalisation of CVNNs, although it is vital to ensure the performance of CVNNs on unseen data. This study is the first to prove a generalisation bound for complex-valued neural networks. The bounds increase as the spectral complexity increases, with the dominant factor being the product of the spectral norms of the weight matrices. Furthermore, this work provides a generalisation bound for CVNNs trained on sequential data, which is also affected by the spectral complexity. Theoretically, these bounds are derived using the Maurey Sparsification Lemma and Dudley entropy integral. We conducted empirical experiments on various datasets including MNIST, ashionMNIST, CIFAR-10, CIFAR-100, Tiny ImageNet, and IMDB by training complex-valued convolutional neural networks. The Spearman rank-order correlation coefficient and the corresponding p-values on these datasets provide strong proof of the statistically significant correlation between the spectral complexity of a network and its generalisation ability, as measured by the spectral norm product of the weight matrices. The code is available at https://github .com /LeavesLei /cvnn _generalization.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons .org /licenses /by-nc -nd /4 .0/).1. IntroductionComplex-valued neural networks (CVNNs) have garnered significant attention in various fields, such as signal processing [1,2], voice processing [3], and image reconstruction [4]. To reduce complex operations, it is natural to link CVNNs to two-dimensional real-valued neural networks with fewer degrees of freedom [5,6]. A complex number consists of a real part and imaginary part, which can alternatively be expressed as amplitude and phase. When performing computations using complex numbers, distinct arithmetic operations are applied separately to the real and imaginary parts.Several recent studies endeavoured to investigate the different properties of CVNNs and built basic algorithms for their implementation. For example, Nitta [7,8,9,10] proved the orthogonality of the decision boundary of complex-valued neu-* Corresponding author at: Artificial Intelligence and its Applications Institute, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdom.E-mail address: F.He@ed.ac.uk (F. He).https://doi.org/10.1016/j.artint.2023.1039510004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons .org /licenses /by-nc -nd /4 .0/).\fH. Chen, F. He, S. Lei et al.Artificial Intelligence 322 (2023) 103951rones, addressed the redundancy problem of the parameters of CVNNs, extended the backpropagation algorithm to complex numbers, and Trabelsi et al. [11] organised the essential components of complex-valued deep neural networks, such as complex convolutions, complex batch normalisation, and complex weight initialisation. Empirical studies were conducted to examine the experimental performance of CVNNs. Hirose and Yoshida [5] used different neural networks, including CVNNs, to process signals of different coherence and Nitta [7] found that for the same computational cost, CVNNs display a higher learning speed than real-valued neural networks.Previous studies have shown satisfactory experimental performance for CVNNs. However, there is still a lack of theoretical analysis of their generalisation ability. This gap in understanding has motivated us to derive a generalisation bound for CVNNs.This is the first study to provide theoretical evidence for the generalisation performance of CVNNs. We propose novel upper bounds which positively correlate with the spectral complexity of CVNNs trained on both independent identically distributed (i.i.d.) and sequential data. The spectral complexity-scaled upper bounds suggest a direct correlation between the generalisation ability of CVNNs and the spectral norm product of their complex-valued weight matrices.From an empirical perspective, the experiments were conducted to investigate the influence of spectral complexity on the generalisation ability. Specifically, we trained CVNNs using stochastic gradient descent (SGD) on six standard datasets: CIFAR-10, CIFAR-100, MNIST, FashionMNIST, Tiny ImageNet, and IMDB. Excess risks were collected for analysis. When the training error is almost zero across all datasets, the excess risk equals the test accuracy and is informative in expressing gen-eralisation ability. In addition, because the change in the spectral norm product of the weight matrices primarily contributes to the change in spectral complexity, it is used to simulate spectral complexity. Our experimental results demonstrate a strong correlation between the spectral-norm product and excess risk, which is consistent with our theoretical analysis. The code is available at https://github .com /LeavesLei /cvnn _generalization.The remainder of this paper is organised as follows. Section 2 presents the motivation behind the research and pro-vides a review of related work. Section 3 provides an introduction to the preliminaries of complex-valued neural networks. Section 4 presents the theoretical results, while Section 5 presents the experimental results. In Section 6, a comparison is made between CVNNs and real-valued neural networks to explore the novelties and advantages of the proposed bound. In Section 7, the practical applications of the proposed theorems in spectral normalisation algorithms are discussed in detail.2. Motivation and related worksComplex values are widely adopted in different neural networks for their biological [12], computational [7,13], and representational advantages [14,15].From a biological perspective, Reichert and Serre [12] proposed that the complex-valued neuronal unit is a more ap-propriate abstraction in modelling the activity of neurones in the brain than a real-valued unit. To better process cortical information, the modelling mechanism must consider both firing rate and spike timing. In incorporating these two elements into deep neural networks, the amplitude of a complex-valued neuron represents the firing rate and the phase represents the spike timing. When two inputs of an excitatory complex-valued neuron have similar or dissimilar phase information, the magnitude of the net input may increase or decrease depending on whether the phases are similar, which correspond to synchronous and asynchronous situations, respectively. The incorporation of complex values into deep neural networks helps construct richer and more versatile representations.Regarding the computational aspect, Danihelka et al. [13] combined long short-term memory (LSTM) with the concept of holographic reduced representations and used complex values to increase the efficiency of information retrieval. Experiments showed that this method achieves a faster learning speed on multiple memorisation tasks. Nitta [7] extended the back-propagation algorithm to complex values, preserving the basic idea of real-valued back-propagation, with updates conducted on both real and imaginary parts. Through experiments, it was demonstrated that under the same time complexity, the learning speed of complex backpropagation is definitely faster than the real speed when the learning rate is low, that is, less than 0.5.Complex-valued neural networks also provide advantages over real-valued neural networks in terms of representational ability. Arjovsky et al. [14] proposed a unitary recurrent neural network (RNN) with unitary matrices as the weight matrix, to circumvent the well-studied gradient vanishing and gradient exploding issues. The unitary matrix is the generalised form of the orthogonal matrices in the complex field, and the absolute value of its eigenvalue is 1. Compared to an orthogonal matrix, a complex-valued matrix has a richer representation, particularly in applications of the discrete Fourier Transform. Wisdom et al. [15] further proposed full-capacity unitary RNNs, thereby improving the performance over unitary evolution RNN (uRNN).Given these advantages and applications of CVNNs, an increasing number of researchers have been investigating the properties of complex-valued neural networks to provide a basic framework for the implementation of CVNNs. Nitta [8]demonstrated that the decision boundary of a two-layered complex-valued network is orthogonal, and for a three-layered network, the decision boundary is nearly orthogonal. This reflects the computational power and versatility of complex values. In their work, Trabelsi et al. [11] provided the building blocks for complex-valued deep neural networks, including complex batch normalisation and complex weight initialisation strategies. They also compared the p",
            {
                "entities": [
                    [
                        153,
                        234,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 91 (1997) 131-154 Artificial Intelligence Networked bubble propagation: a polynomial-time hypothetical reasoning method for computing near-optimal solutions Yukio Ohsawa a**, Mitsuru Ishizuka b*l a Department of Systems Engineering, Osaka University l-3 Machikaneyama, Toyonaka City, Osaka 560, Japan b Department of Information and Communication Engineering, Universiry of Tokyo, 7-3-l Hongo, Bunkyo-ku, Tokyo 113, Japan Received March 1996; revised November 1996 Abstract Hypotheucal reasoning (abduction) is an important knowledge processing framework because of its theoretical basis and its usefulness for solving practical problems including diagnosis, de- sign, etc. In many cases, the most probable hypotheses set for diagnosis or the least expensive one for design is desirable. Cost-based abduction, where a numerical weight is assigned to each hypothesis and an optimal solution hypotheses set with minimal sum of element hypotheses’ weights is searched, deals with such problems. However, slow inference speed is its crucial prob- lem: cost-based abduction is NE-complete. In order to achieve a tractable inference of cost-based abduction, ‘we aim at obtaining a nearly, rather than exactly, optimal solution. For this approach, an approximate solution method exploited in mathematical programming is quite beneficial. On the other hand, from the standpoint of knowledge processing, it is also important to realize inference on a network which reflects knowledge structure. Knowledge structure is a fruitful information for an efficient inference. In this paper, we propose an inference method which works on a knowledge network, based on a mechanism similar to the pivot and complement method, an efficient approxi- mate O-1 integer programming method to find a near-optimal solution within a polynomial time of O(p) , where N is the number of variables or hypotheses. We refonnalize this method by a new type of network on which inference is executed by propagating bubbles. This method achieves an inference time of 0( N’) by executing each bubble propagation within a small sub-network, i.e., by taking aldvantage of the knowledge structure. @ 1997 Elsevier Science B.V. Keywords: Hypothetical reasoning; Knowledge network; Approximate solution method; Polynomial-time inference * Corresponding author. E-mail: osawa@sys.es.osaka-u.ac.jp. 1 E-mail: is,hizuka@miv.t.u-tokyo.ac.jp. 0004-3702/!)7/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIISOOO4-3702(96)00061-6 \f132 E Ohsawa, M. IshizukdArtifcial Intelligence 91 (1997) 131-154 1. Introduction Hypothetical reasoning (abduction) is a useful knowledge in [ 21,221, where knowledge such as diagnosis, design, etc. Its logic-based into two components, ble to many practical problems is presented ground knowledge 2 and hypothetical and facts which are always false and may contradict with others. If _Z is not sufficient i.e., what is observed and wished to be explained, hypothetical hypotheses That is, the function of hypothetical the following system framework applica- framework i.e., back- rules true, while H consists of hypotheses which may be true or for deriving a given goal G, searches for a reasoning .Z and supports G if combined with X. set h that satisfies knowledge H. 2 is composed of inference is to find a hypotheses set h 2 H, which is consistent with constraints. is divided reasoning h C H, Zuht-G, 2 U h y 0 (empty clause). (2) (3) hypotheses each hypothesis We call h a solution associating and G with a set of observed a model-based observations. Also, by associating components) connection (between designing perform a model-based diagnosis symptoms, set or simply in H with a possible by hypothetical a solution set. As an example, by in one system state of a component reasoning we can perform (h) consistent with the each hypothesis with a possible or a component and G with a given system specification, we can for finding a set of fault hypotheses [ 171. to obtain a hypotheses likely diagnosis In many cases, we wish i.e., the most is assigned set with the minimal for a design. Cost-based of the goal, solution Here, a numerical weight hypotheses of element hypotheses the greatest posterior probability probability of the corresponding for diagnosis solution system, the lowest cost product the weight of each possible hypothesis. in h. According set which for a system to each hypothesis abduction deals with this type of problem is the best explanation fault, or the least expensive solving. in H and an optimal solution cost is searched, where cost is sum of the weights set is of where p is the likely a as abduction. Also, for designing the cost of each component if each weight element hypothesis. This means to [ 41, this minimal is given as -log(p), cost hypotheses that the most is available by assigning can be obtained by cost-based However, a crucial problem of hypothetical reasoning time nonmonotonic speed. That is, consistency is the slow inference makes the computation nentially with the number of possible hypotheses has been proven many symbolic goal, like [ 161 which employs useful portion of knowledge parallel from the hypotheses, to be NP-complete for proving inference starting [ 15,271. To overcome approaches have been proposed. Top-down including (N). The computational cost-based abduction checking among possible hypotheses time to grow expo- complexity speed, from the to the and [ 111, this slow inference inference [28], can focus the search [ 61 or MGTP starting as seen in ATMS the goal. On the other hand, bottom-up and causes the inference the QSQR approach \fE Ohsawa, M. lshizuka/ArtificiaI Intelligence 91 (1997) 131-154 rank vu?-(X) = Cw(X,Si)var(Si), kl 143 (10) (11) The first row of Eq. ( 11) is the variation second to the (rank) th rows mean their boundary values (this matrix computation after Procedure 3 (see Appendix B), so that there are rank - 1 zeroes in the right-hand side of Eq. (11)). that other I nodes stays non-basic, in the value of the source node, and the i.e., stays with is possible because rank is equal to rank’ For the example is var(Sl) Eq. (11) computed by Eq. (10) as in Fig. 6, var( Sl) - var(S2) = 0. Then : var( S2) = 1 : 1, because row of ratios among all the nodes are the second the variation var( i’l ) : var( S1) : var( S2) : var( P) : var( Q) : var( R) =--$:l:l:l:l:l. (12) 51.3. The calculation of relative depths is determined The relcztive depth, denoted by depth(X), varies if the value of node X changes or increases according upper bound, the basic node X with the smallest value of Idepth( X) 1 as the destination corresponds If var(T2) # 0, this depth(X) denote indicates how much the source node’s value to its upper or lower bound. Whether X decreases is in the lower or the source value to whether region. We select the search point should be kept in the feasible node. This shift of the search point from 1 not to 2’ but to 2 in Fig. 1. is defined by Eqs. (13)-( 15>, where up(X) and Zw(X) the upper and the lower bounds of node X, respectively. to the minimum since if if if - - - > 0 then depth(X) = < 0 then depth(X) = UP(X) -X var(X) ’ /w(X) - x var(X) ’ = 0 then depth(X) = +oo. (13) (14) (1% \fZ Ohsawa, M. IshizukdArh~cial Intelligence 91 (1997) 131-154 (1) Attachment of ruling arrows before procedure 3. (2) The extracted propagation path with respect to Tl from the network of (1). + --) : mows attached while rank=1 in the procedure of Fig.8. : arrows attached when rank=2 in the procedure of Fig.8. (3) The bubble propagated from 7’1 to P. Fig. 6. An example of computing influence degrees. (14) in Eqs. indicate inequalities (13) and the value of X, respectively. Eq. ( 15) means and The that a basic node X cannot be decreasing the destination node if var( X) is 0 (the first bracket cannot be 0, because 7’1 = up( Tr ) or Iw( Z’r ) but up( 7’1) # Iw( Tt ) , since we do not count the nodes of goal or inc whose upper and lower bounds are equal, as 2’1). Also, if var(Tl) = 0, any 0 node is allowed to be selected since the source node’s bounds will never be violated. the value change of source node TI supposing In Fig. 6, consider that the bubble at the conditions for increasing Tl propagates to node P. Assume the values before the bubble propagation: (Tl,S1,S2,P,Q,R) =(0,0.1,0.7,0.7,0.3,0.5). Since Tl = up(Tl) depth(P) calculated TI propagates variables is computed as at this time and var(P)/vur(T~) is computed as 0.3 from Eq. ( 13). Similarly, as (1,0.9,0.3,0.3,0.7,0.5). (12), the relative depths of nodes are the bubble at to P, with an increase of 0.3 in the value of P. Thus the variance of the jdepth( P) ( is the smallest, < 0 according to Eq. Since \f1! Ohsawa, M. lshizuka/Artijicial Intelligence 91 (1997) 131-154 133 can avoid backtracking. There are also approaches are combined, such as the inference based on an extension forts, the inference against N. path network method of the upside-down meta-interpretation time of hypothetical reasoning in which both of the above merits [ 201 these ef- [ 121, or a method [3]. Despite remains intractable, i.e., exponential represented near-optimal intractability, for computing in propositional solution which This computational abduction problem in O-l research integer programming logic can be translated however, can be overcome has been developed (PC, hereafter), where N is the number of variables. Hence the key insight solutions in operations finds a near-optimal if we search for a near- rather than the exactly optimal one in cost-based abduction. An efficient (also NP- [2]. This method, pivot and is quite close to the in a polynomial-time method. The overall procedure of the PC method in [ 131: into problem. Then a solution set with the minimal optimal solution method complete) complement optimal solution takes time O(p), a cost-based integer programming an equivalent O-l or a near-minimal cost can be obtained quickly by the PC method one of the best among existing methods, ",
            {
                "entities": [
                    [
                        66,
                        180,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1174–1182www.elsevier.com/locate/artintFrom here to human-level AIJohn McCarthyComputer Science Department, Stanford University, Stanford, CA 94305, USAAvailable online 10 October 2007AbstractHuman-level AI will be achieved, but new ideas are almost certainly needed, so a date cannot be reliably predicted—maybe fiveyears, maybe five hundred years. I’d be inclined to bet on this 21st century.It is not surprising that human-level AI has proved difficult and progress has been slow—though there has been importantprogress. The slowness and the demand to exploit what has been discovered has led many to mistakenly redefine AI, sometimes inways that preclude human-level AI—by relegating to humans parts of the task that human-level computer programs would have todo. In the terminology of this paper, it amounts to settling for a bounded informatic situation instead of the more general commonsense informatic situation.Overcoming the “brittleness” of present AI systems and reaching human-level AI requires programs that deal with the commonsense informatic situation—in which the phenomena to be taken into account in achieving a goal are not fixed in advance.We discuss reaching human-level AI, emphasizing logical AI and especially emphasizing representation problems of informationand of reasoning. Ideas for reasoning in the common sense informatic situation include nonmonotonic reasoning, approximateconcepts, formalized contexts and introspection.© 2007 Published by Elsevier B.V.Keywords: Human-level AI; Elaboration tolerance1. What is human-level AI?The first scientific discussion of human level machine intelligence was apparently by Alan Turing in the lec-ture [35]. The notion was amplified as a goal in [34], but at least the latter paper did not say what would have to bedone to achieve the goal.Allen Newell and Herbert Simon in 1954 were the first people to make a start on programming computers forgeneral intelligence. They were over-optimistic, because their idea of what has to be done to achieve human-levelintelligence was inadequate. The General Problem Solver (GPS) took general problem solving to be the task oftransforming one expression into another using an allowed set of transformations.Many tasks that humans can do, humans cannot yet make computers do. There are two approaches to human-level AI, but each presents difficulties. It isn’t a question of deciding between them, because each should eventuallysucceed; it is more a race.E-mail address: jmc@cs.stanford.edu.URL: http://www-formal.stanford.edu/jmc/.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.10.009\fJ. McCarthy / Artificial Intelligence 171 (2007) 1174–118211751. If we understood enough about how the human intellect works, we could simulate it. However, we don’t havesufficient ability to observe ourselves or others to understand directly how our intellects work. Understanding thehuman brain well enough to imitate its function therefore requires theoretical and experimental success in psy-chology and neurophysiology.1 See [28] for the beginning of the information processing approach to psychology.2. To the extent that we understand the problems achieving goals in the world presents to intelligence we can writeintelligent programs. That’s what this article is about.Much of the public recognition of AI has been for programs with a little bit of AI and a lot of computing. Thissucceeded for chess and checkers and has so far failed for the game of go. Go requires the identification ofsubpositions that are analyzed separately first and then in interaction with each other. Human chess players alsodo this, but the chess programs don’t. The price of the much greater computation this makes necessary has beenaffordable in chess but not in go. Computer speed bypasses many other heuristics that save humans enormouscomputation.What problems does the world present to intelligence? More narrowly, we consider the problems it would presentto a human scale robot faced with the problems humans might be inclined to relegate to sufficiently intelligent ro-bots. The physical world of a robot contains middle sized objects about which its sensory apparatus can obtain onlypartial information quite inadequate to fully determine the effects of its future actions. Its mental world includes itsinteractions with people and also meta-information about the information it has or can obtain.Our approach is based on what we call the common sense informatic situation, which we contrast with the boundedinformatic situation that characterizes both formal scientific theories and almost all (maybe all) experimental work inAI done so far.A formal theory in the physical sciences deals with a bounded informatic situation. Scientists decide informally inadvance what phenomena to take into account. For example, much celestial mechanics is done within the Newtoniangravitational theory and does not take into account possible additional effects such as outgassing from a comet orelectromagnetic forces exerted by the solar wind. If more phenomena are to be considered, a person must make a newtheory. Probabilistic and fuzzy uncertainties can still fit into a bounded informatic system; it is only necessary that theset of possibilities (sample space) be bounded.Most AI formalisms also work only in a bounded informatic situation. What phenomena to take into account isdecided by a person before the formal theory is constructed. With such restrictions, much of the reasoning can bemonotonic, but such systems cannot reach human level ability. For that, the machine will have to decide for itselfwhat information is relevant. When a bounded informatic system is appropriate, the system must construct or choosea limited context containing a suitable theory whose predicates and functions connect to the machine’s inputs andoutputs in an appropriate way.2 The logical tool for bounding the informatic situation is nonmonotonic reasoning.2. The common sense informatic situationContention: The key to reaching human-level AI is making systems that operate successfully in the common senseinformatic situation.In general a thinking human is in what we call the common sense informatic situation [13]. It is more general thanany bounded informatic situation. The known facts are incomplete, and there is no a priori limitation on what facts arerelevant. It may not even be decided in advance what phenomena are to be taken into account. The consequences ofactions cannot be fully determined. The common sense informatic situation necessitates the use of approximate con-cepts that cannot be fully defined and the use of approximate theories involving them. It also requires nonmonotonicreasoning in reaching conclusions.The common sense informatic situation also includes some knowledge about the system’s mental state.1 Recent work with positron emission tomography has identified areas of the brain that consume more glucose when a person is doing mentalarithmetic. This knowledge will help build AI systems only when it becomes possible to observe what is going on in these areas during mentalarithmetic.2 The textbook [4] puts it this way. “To get human-level computational intelligence it must be the agent itself that decides how to divide up theworld, and which relationships to reason about”.\f1176J. McCarthy / Artificial Intelligence 171 (2007) 1174–1182A nice example of the common sense informatic situation is illustrated by an article in the American Journal ofPhysics some years ago. It discussed grading answers to a physics problem. The exam problem is to find the height ofa building using a barometer. The intended solution is to measure the air pressure at the top and bottom of the buildingand multiply the difference by the ratio of the density of mercury to the density of air.However, other answers may be offered. (1) Drop the barometer from the top of the building and measure the timebefore it hits the ground. (2) Measure the height and length of the shadow of the barometer and measure the lengthof the shadow of the building. (3) Rappel down the building using the barometer as a measuring rod. (4) Lower thebarometer on a string till it reaches the ground and measure the string. (5) Offer the barometer to the janitor of thebuilding in exchange for information about the height. (6) Ignore the barometer, count the stories of the building andmultiply by ten feet.Clearly it is not possible to bound in advance the common sense knowledge of the world that may be relevant tograding the problem. Grading some of the solutions requires knowledge of the formalisms of physics and the physicalfacts about the earth, e.g. the law of falling bodies or the variation of air pressure with altitude. However, in every case,the physics knowledge is embedded in common sense knowledge. Thus before one can use Galileo’s law of fallingbodies s = 12 gt 2, one needs common sense information about buildings, their shapes and their roofs.Bounded informatic situations are obtained by nonmonotonically inferring that only the phenomena that somehowappear to be relevant are relevant. In the barometer example, the student was expected to infer that the barometer wasonly to be used in the conventional way for measuring air pressure. For example, a reasoning system might do this byapplying circumscription to a predicate relevant in a formalism containing also metalinguistic information, e.g. thatthis was a problem assigned in a physics course. Formalizing relevance in a useful way promises to be more difficultthan just using existing relevance logics.Common sense facts and common sense reasoning are necessarily imprecise. The imprecision necessitated by thecommon sense informatic situation applies to computer programs as well as to people.Some kinds of imprecision can be represented numerically and have been explored with the aid of Bayesian net-works, fuzzy logic and similar formalisms. This is in a",
            {
                "entities": [
                    [
                        74,
                        101,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 25–38Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstraint propagation as information maximization ✩A. Nait Abdallah a,b, M.H. van Emden c,∗a Department of Computer Science, University of Western Ontario, Canadab INRIA Rocquencourt, Francec Department of Computer Science, University of Victoria, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 January 2012Received in revised form 11 February 2013Accepted 14 February 2013Available online 16 February 2013Keywords:Constraint-satisfaction problemsInformation partial orderIntervalsPropagationThis paper draws on diverse areas of computer science to develop a unified view ofcomputation:• Optimization in operations research, where a numerical objective function is maximizedunder constraints, is generalized from the numerical total order to a non-numericalpartial order that can be interpreted in terms of information.• Relations are generalized so that there are relations of which the constituent tuplesindexes, whereas in other relations these indexes are variables.have numericalThe distinction is essential in our definition of constraint-satisfaction problems.• Constraint-satisfaction problems are formulated in terms of semantics of conjunctions ofatomic formulas of predicate logic.• Approximation structures, which are available for severalapplied to solutions of constraint-satisfaction problems.important domains, areAs application we treat constraint-satisfaction problems over reals. These cover a large partof numerical analysis, most significantly nonlinear equations and inequalities. The chaoticalgorithm analyzed in the paper combines the efficiency of floating-point computation withthe correctness guarantees of arising from our logico-mathematical model of constraint-satisfaction problems.© 2013 Elsevier B.V. All rights reserved.1. Computation as maximization in information spaceThe early history of constraint processing is written in three MIT theses: Sutherland’s, Waltz’s, and Steele’s [16,20,14].Already in this small selection one can discern two radically different approaches. Sutherland and Steele use relaxation:starting form a guessed assignment of values to variables, constraints are successively used to adjust variables in such away as to satisfy better the constraint under consideration. These authors followed an old idea brought into prominenceunder the name of relaxation by Southwell [15].Waltz adopted a radically different approach (and was, to our knowledge, the first to do so). He associated with each ofthe problem’s variables a domain; that is, the set of all values that are not a priori impossible. Each constraint is then usedto eliminate values from the domains of one or more variables affected by the constraint that are incompatible with thatconstraint. In this paper we are concerned with the latter method, which we call the domain reduction method.✩Research Report 746, Dept. of Computer Science, University of Western Ontario, Canada.* Corresponding author.E-mail address: vanemden@cs.uvic.ca (M.H. van Emden).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.002\f26A. Nait Abdallah, M.H. van Emden / Artificial Intelligence 197 (2013) 25–38The attraction of domain reduction is its completeness for finite domains: if a solution exists, then it will be found. Thisin contrast with relaxation, which can flounder forever.1In this paper we present domain reduction as an example of the view of computation as monotonic gain of information. Thisview was pioneered by Dana Scott, who was the first to make mathematical sense [12] of a recursively defined function f .f a sequence a of partial functions. If x is such that f (x) requires aHe did this by associating with the definition ofrecursion depth is at most n, then an(x) is defined and equal to f (x); otherwise an(x) is undefined. Thus a is a sequence ofpartial functions in which each function agrees with the previous one, but is “more defined”.In general, if two partial functions g and h of the same type are such that h is defined wherever g is and such thatthey have the same value when both are defined, then Scott proposed to regard g as an approximation to h and noted thatthis notion of approximation is a partial order in the set of partial functions of the same type. Moreover Scott proposedto transfer the information concept from random variables, as it was in Shannon’s information theory, to partial functions,noting that a partial function can be regarded as containing more information than partial functions approximating it.The approach to the semantics of recursive definitions can be summarized by saying that every such definition can beregarded as the limit of a sequence of approximations each containing more information about the limit of the sequencethan the previous one.Scott was aware that it might seem somewhat far-fetched to give such an interpretation to the notion of “information”.As a justification Scott [13] gave another example of a set partially ordered by information: that of numerical intervals.Although this certainly strengthened the case, this suggestion has not, as far as we know, been followed up. In this paperwe do so, motivated by the opportunities for deeper understanding of constraint solving.In numerical applications the view of computation as monotonic gain of information is more than a theoretically in-teresting insight: it is adds an essential capability. Suppose a conventional numerical computation is stopped after 1000iterations and yields 1.912837465 and that it yields 1.912877134 when allowed to run for 10,000 iterations, what do weknow about the improvement obtained, if any? If results, intermediate and final, were expressed as intervals we would, say,have [1.911, 1.938]2 after 1000 iterations and perhaps [1.9126, 1.9283]3 after 10,000 iterations. Here we see that we knowmore about the unknown solution as a result of the additional computational work. Rephrasing “knowing more” as “gain ininformation” suggests that the effect of iteration in interval arithmetic can be described as “monotonic gain of information”.The important qualification “monotonic” is there because in interval arithmetic we never need to settle for less informationas a result of additional computational work, though we may fail to make a gain. Moreover, such a stalling of progress is auseful criterion for halting the iteration.Because of the special importance of solving constraint-satisfaction problems over the reals by means of floating-pointarithmetic, we choose our example problem from this area. Section 3 gives the needed review of interval methods; Section 4describes the example. The new view of domain reduction as monotonic information gain is used in Section 6 to developthe method from first principles. This suggests regarding the set of constraints in a constraint-satisfaction problem as aformula in predicate logic with a fixed interpretation of predicate symbols. The standard semantics only assigns meaningsto closed formulas, whereas here we have a formula with free variables. Accordingly, in Section 5 we develop the requiredextension of the semantics of predicate logic. This needs a novel treatment of relations, also in this section.2. Related workFollowing Mackworth’s AC-3 algorithm [9] there are many other papers concerned with converging fair itera-tions [1,3,17,18,11].For historical references we refer to the textbooks [7,2].We address the connections with the work of Saraswat et al. [11] in Section 7.3. Interval arithmetic and interval constraintsTo facilitate the use of information in computation we do not use interval arithmetic directly, but indirectly via aconstraint-satisfaction problem (CSP). Such problems are solved by associating with each unknown a set of possible val-ues instead of the usual single value. This is especially appropriate for real-valued unknowns. In combination with the useof floating-point arithmetic, the sets of possible values take the form of intervals with floating-point numbers as bounds.This special case of CSP solving is called interval constraints [6,1].We introduce interval constraints by means of an example. In interval arithmetic the rule for adding intervals is[a, b] + [c, d] =(cid:2)(cid:3)x + y: x ∈ [a, b] ∧ y ∈ [c, d]1 But, as one may expect, domain reduction is no cure-all. For some problems, relaxation quickly finds a solution, and domain reduction requires aninfeasible amount of time. The n-queens problem for large n is an example. Van Hentenryck and Michel [19], page 89, mention n = 10,000 as a routineexample for relaxation in combination with their search technique.2 Note the smaller number of decimals: with intervals it becomes clear that additional decimals would be meaningless.3 The smaller interval warrants another decimal.\fA. Nait Abdallah, M.H. van Emden / Artificial Intelligence 197 (2013) 25–3827so that, e.g., [0, 2] + [0, 2] = [0, 4]. The analogous operation in interval constraints starts by defining the constraintsum(x, y, z) which holds between the reals x, y, and z iff x + y = z. In other words, the formula sum(x, y, z) is true wheneverx + y = z. This leads to the following inferencesum(x, y, z)x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [−∞, +∞]x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [0, 4]We use here the conventional format for inference: the premises above the horizontal line; the conclusion below. The aboveinference coincides, in this special case, with interval arithmetic. Only the interval for z is narrowed.In interval constraints we may have a priori constraints on all variables, as insum(x, y, z)x ∈ [0, 2] ∧ y ∈ [0, 2] ∧ z ∈ [3, 5]x ∈ [1, 2] ∧ y ∈ [1, 2] ∧ z ∈ [3, 4]Here the intervals for all three variables are narrowed. As a result, the effect of the operation can no longer be exclusivelycharacterized as an addition or as its inverse: the effect is a mixture of seve",
            {
                "entities": [
                    [
                        143,
                        193,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 125 (2001) 209–226Research NoteRobust Bayes classifiersMarco Ramoni a;(cid:3), Paola Sebastiani ba Children’s Hospital Informatics Program, Harvard Medical School, 300 Longwood Avenue,Boston, MA 02115, USAb Department of Mathematics and Statistics, University of Massachusetts, Amherst, MA 01003, USAReceived 12 November 1999; received in revised form 24 October 2000AbstractNaive Bayes classifiers provide an efficient and scalable approach to supervised classificationproblems. When some entries in the training set are missing, methods exist to learn these classifiersunder some assumptions about the pattern of missing data. Unfortunately, reliable information aboutthe pattern of missing data may be not readily available and recent experimental results show thatthe enforcement of an incorrect assumption about the pattern of missing data produces a dramaticdecrease in accuracy of the classifier. This paper introduces a Robust Bayes Classifier (RBC) ableto handle incomplete databases with no assumption about the pattern of missing data. In order toavoid assumptions, the RBC bounds all the possible probability estimates within intervals using aspecialized estimation method. These intervals are then used to classify new cases by computingintervals on the posterior probability distributions over the classes given a new case and by rankingthe intervals according to some criteria. We provide two scoring methods to rank intervals and adecision theoretic approach to trade off the risk of an erroneous classification and the choice of notclassifying unequivocally a case. This decision theoretic approach can also be used to assess theopportunity of adopting assumptions about the pattern of missing data. The proposed approach isevaluated on twenty publicly available databases. (cid:211) 2001 Elsevier Science B.V. All rights reserved.Keywords: Bayes classifier; Missing data; Probability intervals1. IntroductionSupervised classification is the task of assigning a class label to unclassified casesdescribed as a set of attribute values. This task is typically performed by first traininga classifier on a set of classified cases and then using it to label unclassified cases. The* Corresponding author.E-mail addresses: marco_ramoni@harvard.edu (M. Ramoni), sebas@math.umass.edu (P. Sebastiani).0004-3702/01/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 0 0 ) 0 0 0 8 5 - 02001 Elsevier Science B.V. All rights reserved.\f210M. Ramoni, P. Sebastiani / Artificial Intelligence 125 (2001) 209–226supervisory component of this classifier resides in the training signal, which provides theclassifier with a way to assess a dependency measure between attributes and classes. NaiveBayes classifiers (NBCs) [4,11] have been among the first supervised classification methodsand, during the past few years, they have enjoyed a renewed interest and consideration [6].The training step for a NBC consists of estimating the conditional probability distributionsof each attribute given the class from a training data set. Once trained, the NBC classifiesa case by computing the posterior probability distribution over the classes via Bayes’Theorem and assigning the case to the class with the highest posterior probability.NBCs assumes that the attributes are conditionally independent given the class and thisassumption renders very efficient both training and classification. Unfortunately, when thetraining set is incomplete, that is, some attribute values or the class itself are reportedas unknown, both efficiency and accuracy of the classifier can be lost. Simple solutionsto handle missing data are either to ignore the cases including unknown entries or toascribe these entries to an ad hoc dummy state of the respective variables [15]. Both thesesolutions are known to introduce potentially dangerous biases in the estimates, see [9] for adiscussion. In order to overcome this problem, Friedman et al. [6] suggest the use of the EMalgorithm [3], gradient descent [20] or, we add, Gibbs sampling [7]. All these methods relyon the assumption that data are Missing at Random (MAR) [13], that is, the database is leftwith enough information to infer the missing entries from the recorded ones. Unfortunately,there is no way to verify that data are actually MAR in a particular database and, when thisassumption is violated, these estimation methods suffer of a dramatic decrease in accuracywith the consequence of jeopardizing the performance of the resulting classifier [21].This paper introduces a new type of NBC, called Robust Bayes Classifier (RBC), whichdoes not rely on any assumption about the missing data mechanism. The RBC is based onthe Robust Bayes Estimator (RBE) [18], an estimator that returns intervals containing allthe estimates that could be induced from all the possible completions of an incompletedatabase. The intuition behind the RBE is that, even with no information about the missingdata mechanism, an incomplete data set can still constrain the set of estimates that canbe induced from all its possible completions. However, in this situation, the estimator canonly bound the posterior probability of the classes. The first contribution of this paper isto provide a specialized closed-form, interval-based estimation procedure for NBCs, whichtakes full advantage of their conditional independence assumptions. Once trained, theseclassifiers are used to classify unlabeled cases. Unfortunately, Bayes’ Theorem cannotbe straightforwardly extended from standard point-valued probabilities to interval-valuedprobabilities. Nonetheless, the conditional independence assumptions underlying the NBCallows for a closed-form solution for the classification task, too. The second contributionof this paper is a new propagation algorithm to compute posterior probability intervalscontaining all the class posterior probabilities that could be obtained from the exactcomputation of all possible completions of the training set. These intervals are then rankedaccording to a score and a new case is assigned to the class associated with the highestranked interval. We provide two scoring methods: the first, based on the strong dominancecriterion [10], assigns a case to the class whose minimum posterior probability is higherthan the maximum posterior probability for all other classes. This criterion preserves therobustness of the classifier but may leave some cases unclassified and hence we provide aweaker criterion to improve the coverage. We also introduce a general decision-theoretic\fM. Ramoni, P. Sebastiani / Artificial Intelligence 125 (2001) 209–226211framework to select the most appropriate criterion by trading off accuracy and coverage.As a by-product, this decision-theoretic approach provides a principled way to asses theviability of the MAR assumption for a given training set. We also show that, when thedatabase is complete, the RBC estimates reduce to the standard Bayesian estimates andtherefore the RBC subsumes the standard NBC as a special case. This approach is evaluatedon twenty publicly available databases.2. Naive Bayes classifiersAn NBC is better understood if we regard the m attributes and the set of q mutuallyexclusive and exhaustive classes as discrete stochastic variables. In this way, we candepict a NBC as a Bayesian network [6]—a directed acyclic graph where nodes representstochastic variables and arcs represent dependency relationships between variables—as shown in Fig. 1. In this network, the root node represents the set C of mutuallyexclusive and exhaustive classes and each attribute is a child node Ai . Each value cjof the variable C is a class and each attribute Ai bears a set of si values Ai D ak. Asshorthand, we will denote C D cj by cj and Ai D ak by aik. The graphical structure of theBayesian network representing the NBC encodes the assumption that each attribute Ai isconditionally independent of the other attributes given the class. The classifier, therefore,is defined by the marginal probability distribution fp.cj /g of the variable C and by a setof conditional probability distributions fp.aik D cj /g of each attribute Ai given each classcj . A consequence of the independence assumption is that all these distributions can beestimated from a training set D, independently from each other, as follows.Let n.aik; cj / be the frequency of cases in the training set D in which the attribute Aiappears with value aik and the class is cj and let n.cj / be the frequency of cases in thetraining set with class cj . When the training set D is complete, the Bayesian estimates ofp.aik j cj / and p.cj / arep.aik j cj / DP(cid:11)ij k C n.aik; cj /T(cid:11)ij h C n.aih; cj /Uhand p.cj / DP(cid:11)j C n.cj /T(cid:11)l C n.cl/Ul;(1)respectively. The quantities (cid:11)ij k and (cid:11)j can be regarded as frequencies of pair aik; cj and ofthe class cj , respectively, in an imaginary sample, representing the prior information aboutthe distributions of the attributes and the classes. The size (cid:11) of this imaginary sampleis called global prior precision. Further details are in [17]. Once the classifier has beenFig. 1. A Bayesian network representing an NBC with attributes A1; : : : ; A9 and a set C of classes.\f212M. Ramoni, P. Sebastiani / Artificial Intelligence 125 (2001) 209–226trained, we can use it for the classification of new cases. If we represent a case as a setof attribute values e D fa1k; : : : ; amkg, Bayes’ theorem yields the posterior probability of aclass cj given e asp.cj j e/ DQp.cj /PqhD1 p.ch/miD1 p.aik j cj /QmiD1 p.aik j ch/(2)and the case is assigned to the class with the highest posterior probability.From the computational point of view,the training of the classifier reduces tosummarizing the whole database D into m contingency tables Ti of dimension .q (cid:2) si /,each cell .j; k/ of the table Ti collecting the frequency of the pair .aik; cj /. In this way(i) the estimation of the q probability distributions of each attribute Ai",
            {
                "entities": [
                    [
                        55,
                        79,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Available online at www.sciencedirect.comRArtificial Intelligence 155 (2004) 1–39www.elsevier.com/locate/artintA framework for linguistic modellingJonathan LawryDepartment of Engineering Mathematics, University of Bristol, Bristol BS8 1TR, UKReceived 13 November 2001; received in revised form 7 November 2003AbstractA new framework for linguistic reasoning is proposed based on a random set model of the degree ofappropriateness of a label. Labels are assumed to be chosen from a finite predefined set of labels andthe set of appropriate labels for a value is defined as a random set-valued function from a populationof individuals into the set of subsets of labels. Appropriateness degrees are then evaluated relativeto the distribution on this random set where the appropriateness degree of a label corresponds to theprobability that it is contained in the set of appropriate labels. This interpretation is referred to as labelsemantics. A natural calculus for appropriateness degrees is described which is weakly functionalwhile taking into account the logical structure of expressions. Given this framework it is shown that abayesian approach can be adopted in order to infer probability distributions on the underlying variablegiven constraints both in the form of linguistic expressions and mass assignments. In addition, twoconditional measures are introduced for evaluating the appropriateness of a linguistic expressiongiven other linguistic information. 2003 Elsevier B.V. All rights reserved.Keywords: Random sets; Linguistic constraints; Fuzzy labels; Label semantics; Bayesian inference1. IntroductionThe limitations of classical modelling techniques to effectively capture the behaviourof complex systems has become increasingly clear over recent years. This has motivatedresearch into new, alternative modelling paradigms by the artificial intelligence community(e.g., fuzzy reasoning, possibility theory, Bayesian modelling, default reasoning: see [4,8,11,28,30]). All of these approaches share an emphasis on high level qualitative descriptionsas opposed to a more traditional low level framework. The advantage of such higher-levelknowledge representation is that it allows for the fusion of expert or background knowl-E-mail address: j.lawry@bris.ac.uk (J. Lawry).0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2003.10.001\f2J. Lawry / Artificial Intelligence 155 (2004) 1–39edge and knowledge derived from data. Furthermore, it tends to provide a clearer insightinto the underlying nature of the system than can be obtained from less transparent lower-level models. Another feature shared by many of the new approaches is that they providea methodology for reasoning in the presence of uncertainty. This is no coincidence, butrather is due to the fact that uncertainty and imprecision are often inherent in complexmodelling problems. This uncertainty is not only due to lack of precision or errors in mea-sured features but is often present in the model itself since the available features may notbe sufficient to provide a complete model of the system. To illustrate this point, considerthe important area of river basin modelling for flood forecasting. For this problem it isoften necessary to model river levels at a particular time point, purely in terms of rainfalland river levels at earlier times. However, in reality so many complex features influencerunoff that it is both difficult to identify the most important and practically impossible tomeasure any but a few of them. For instance, the likelihood that a given rainfall event willproduce a flood is dramatically affected by such factors as the size of the drainage basin,the topography of the basin, the amount of urban use within the basin and so on.While the development of analytical models may be impractical for many complex sys-tems, there is often data available implicitly describing the behaviour of the system. Forexample, large companies such as supermarkets, high street stores and banks collect astream of data relating to the behaviour of their customers. Such data must be analysedto provide flexible models of customer behaviour that can be used to aid a wide varietyof decision-making processes. Hence, if a higher level modelling approach is to be trulyeffective it must provide a natural knowledge representation framework for inductive learn-ing. As such it is important that it allows for the modelling of uncertainty, imprecision andvagueness in a semantically clear manner. Indeed, we should emphasise the necessity of aclear underlying semantics for any higher-level modelling paradigm since one of the fun-damental reasons for a high level approach is to provide transparent models that can beunderstood and used by practitioners in the relevant fields. This cannot be achieved if thevalidity of the underlying concepts and inference processes are either obscured or in doubt.In the sequel we will outline a new methodology for linguistic modelling and show how itcan be applied in an inductive learning context. The approach will centre on the modellingof linguistic constraints on variables as proposed by Zadeh [37] although the underlyingsemantics will be quite different.The phrase computing with words was introduced by Zadeh [42] to capture the idea ofcomputation based not on numerical values, but on natural language terms and expressions.As a general idea this is clearly of relevance to the type of modelling described above,however, we shall propose a quite different interpretation to that given in [38–40]. Thegeneral methodology for computing with words proposed by Zadeh is that of fuzzy settheory or fuzzy logic and in particular is based on the idea of linguistic variables (see [38–40]). A linguistic variable is defined as a variable that takes natural language terms such aslarge, small, tall, medium etc. as values and where the meaning of these words is given byfuzzy sets on some underlying domain of discourse. Hence, a particular expression of theform Bill is tall can be taken as expressing the fact that the linguistic variable describingBill’s height has the value tall, and such a statement has a partial truth-value correspondingto the membership degree of Bill’s actual height in the fuzzy set representing the meaningof tall. The truth-value of compound expressions such as Bill is tall or medium is then\fJ. Lawry / Artificial Intelligence 155 (2004) 1–393evaluated according to a fuzzy set calculus based on some choice of t-norm or t-conorm(see [18] for an exposition).In our view the principal problem with the above approach is that the semanticsunderlying standard fuzzy logic or indeed the notion of membership function itself is ratherobscure. The difficulty is revealed by consideration of a fundamental question that shouldbe asked of all models of linguistic constraints. What information is conveyed regardingthe underlying variable? For instance, if someone asserts that Bill is tall exactly whatinformation about Bill’s height is conveyed by that assertion? In the case of fuzzy settheory, according to Zadeh [41], the latter provides a flexible constraint on the variablerepresenting Bill’s height. More specifically, it tells us that the possibility distribution onBill’s height corresponds to the membership function of the fuzzy set tall. However, thisassociation with possibility distributions does not, in itself, support the assumption of afully truth-functional calculus for membership degrees, as in fuzzy set theory (see [26]).Indeed, it does not really provide any insight into the behaviour of compound fuzzy sets.One possible solution to this difficulty is to accept that neither possibility distributions orfuzzy memberships are sufficiently intuitive to be treated as primitive notions and attemptto provide a lower-level model. If we are going to adopt the fuzzy logic methodology thenany such semantics should not only be intuitive but should also be consistent with a fullytruth-functional calculus based on a particular choice of t-norm and t-conorm. A numberof different models have been investigated and these are reviewed in [6,27].One of the most promising ideas is to view fuzzy memberships as being fixed pointcoverage functions of random sets, themselves representing uncertainty or variation in theunderlying crisp definition of a concept [12]. For instance, we might have a populationof different individuals each proposing their own set of heights that would qualify for thedescription tall. The associated random set would be a function from the set of individ-uals into the set of subsets of heights and the membership of a particular height, h, inthe fuzzy set tall would correspond to the probability of encountering an individual whoincluded h in their crisp set definition. This is the essence of the voting model for fuzzysets proposed originally by Black [3] and later by Gaines [10]. Clearly this interpretationis implicitly probabilistic in its nature and hence, it is not perhaps surprising that it doesnot fit well within the inference framework of fuzzy logic. One problem is that there isnot a one-to-one correspondence between fuzzy sets and random sets. The same fuzzy setcould be generated by a potentially infinite family of random sets (see Goodman [12]). Inpossibility theory this problem is overcome by making the assumption that the random setis consonant (i.e., the set of sets with non-zero mass constitutes a nested hierarchy). Lawry[20] justifies this by introducing the idea of an optimism parameter according to which themore optimistic a voter the more likely they are to include h in the extension of the concepttall. It is difficult to consolidate such an assumption with a fully truth-functional calculussince, in that case, a voter with a high optimism parameter would be required to be opti-mistic regarding both the concept and its negation. Lawry [20] suggests a weaker notionof negation to overcome this difficulty but nonetheless t",
            {
                "entities": [
                    [
                        111,
                        147,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 215 (2014) 79–119Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn influence, stable behavior, and the most influential individuals in networks: A game-theoretic approachMohammad T. Irfan a,1, Luis E. Ortiz b,∗a Department of Computer Science, Bowdoin College, Brunswick, ME 04011, United Statesb Department of Computer Science, Stony Brook University, Stony Brook, NY 11794, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 13 September 2012Received in revised form 31 May 2014Accepted 17 June 2014Available online 25 June 2014Keywords:Computational game theorySocial network analysisInfluence in social networksNash equilibriumComputational complexityWe introduce a new approach to the study of influence in strategic settings where the action of an individual depends on that of others in a network-structured way. We propose network influence games as a game-theoretic model of the behavior of a large but finite networked population. In particular, we study an instance we call linear-influence gamesthat allows both positive and negative influence factors, permitting reversals in behavioral choices. We embrace pure-strategy Nash equilibrium, an important solution concept in non-cooperative game theory, to formally define the stable outcomes of a network influence game and to predict potential outcomes without explicitly considering intricate dynamics. We address an important problem in network influence, the identification of the most influential individuals, and approach it algorithmically using pure-strategy Nash-equilibria computation. Computationally, we provide (a) complexity characterizations of various problems on linear-influence games; (b) efficient algorithms for several special cases and heuristics for hard cases; and (c) approximation algorithms, with provable guarantees, for the problem of identifying the most influential individuals. Experimentally, we evaluate our approach using both synthetic network influence games and real-world settings of general interest, each corresponding to a separate branch of the U.S. Government. Mathematically,we connect linear-influence games to important models in game theory: potential and polymatrix games.© 2014 Published by Elsevier B.V.1. IntroductionThe influence of an entity on its peers is a commonly noted phenomenon in both online and real-life social networks. In fact, there is growing scientific evidence that suggests that influence can induce behavioral changes among the entities in a network. For example, recent work in medical social sciences posits the intriguing hypothesis that much of our behavior such as smoking [16], obesity [15], and even happiness [24] is contagious within a social network.Regardless of the specific problem addressed, the underlying system studied by Christakis and Fowler exhibits several core features. First, it is often very large and complex, with the entities exhibiting different behaviors and interactions. Second, the network structure of complex interactions is central to the emergence of collective (global) behavior from individual (local) behavior. For example, in their work on obesity, individuals locally interact with their friends and relatives within their * Corresponding author. Tel.: +1 631 632 1805; fax: +1 631 632 8334.E-mail addresses: mirfan@bowdoin.edu (M.T. Irfan), leortiz@cs.stonybrook.edu (L.E. Ortiz).1 Parts of this work were done while the author was a PhD student at Stony Brook University.http://dx.doi.org/10.1016/j.artint.2014.06.0040004-3702/© 2014 Published by Elsevier B.V.\f80M.T. Irfan, L.E. Ortiz / Artificial Intelligence 215 (2014) 79–119social network. These local interactions appear to give rise to a global phenomenon, namely, the clustering of medically obese individuals [15]. Third, the directions and strengths of local influences are highlighted as very relevant to the global behavior of the system as a whole. Fourth, given that one’s behavioral choice depends on others, the individuals potentially act in a strategic way.The prevalence of systems and problems like the ones just described, combined with the obvious issue of often-limited control over individuals, raises immediate, broad, difficult, and longstanding policy questions: e.g., Can we achieve a desired goal, such as reducing the level of smoking or controlling obesity via targeted, minimal interventions in a system? How do we optimally allocate our often limited resources to achieve the largest impact in such systems?Clearly, these issues are not exclusive to obesity, smoking or happiness; similar issues arise in a large variety of settings: drug use, vaccination, crime networks, security, marketing, markets, the economy, public policy-making and regulations, and even congressional voting!2 The work reported in this paper is in large part motivated by such questions/settings and their broader implication.We begin by providing a brief and informal description of our approach to influence in networks. In the next section, we place our approach within the context of the existing literature.1.1. Overview of our model of influenceConsider a social network where each individual has a binary choice of action or behavior, denoted by −1 and 1. Let us represent this network as a directed graph, where each node represents an individual. Each node of this graph has a threshold level, which can be positive, negative, or zero; and the threshold levels of all the nodes are not required to be the same. Each arc of this graph is weighted by an influence factor, which signifies the level of direct influence the tail node of that arc has on the head node. Again, the influence factors can be positive, negative, or zero and are not required to be the same (i.e., symmetric) between two nodes.Given such a network, our model specifies the best response of a node (i.e., what action it should choose) with respect to the actions chosen by the other nodes. The best response of a node is to adopt the action 1 if the total influence on it exceeds its threshold and −1 if the opposite happens. In case of a tie, the node is indifferent between choosing 1 and −1; i.e., either would be its best response. Here, we calculate the total influence on a node as follows. First, sum up the incoming influence factors on the node from the ones who have adopted the action 1. Second, sum up those influence factors that are coming in from the ones who have adopted −1. Finally, subtract the second sum from the first to get the total influence on that node.Clearly, in a network with n nodes, there are 2n possible joint actions, resulting from the action choice of each individual node. Among all these joint actions, we call the ones where every node has chosen its best response to everyone else a pure-strategy Nash equilibria (PSNE). We use PSNE to mathematically model the stable outcomes that such a networked system could support.1.2. Overview of the most-influential-nodes problemWe formulate the most-influential-nodes problem with respect to a goal of interest. The goal of interest indirectly de-termines what we call the desired stable outcome(s). Unlike the mainstream literature on the most-influential-nodes prob-lem [49], maximizing the spread of a particular behavior is not our objective. Rather, the desired stable outcome(s) resulting from the goal of interest is what determines our computational objective. In addition, our solution concept abstracts away the dynamics and does not rely on the “diffusion” process by which such a “spread of behavior” happens.Roughly speaking, in our approach, we consider a set of individuals S in a network to be a most influential set, with respect to a particular goal of interest, if S is the most preferred subset among all those that satisfy the following condition: were the individuals in S to choose the behavior xS prescribed to them by a desired stable outcome x ≡ (xS , x−S ) which achieves the goal of interest, then the only stable outcome of the system that remains consistent with their choices xS is xitself.Said more intuitively, once the nodes in the most influential set S follow the behavior xS prescribed to them by a desired stable outcome x achieving the goal of interest, they become collectively “so influential” that their behavior “forces” every other individual to a unique choice of behavior! Our proposed concept of the most influential individuals is illustrated in Fig. 1 with a very simple example.Now, there could be many different sets S that satisfy the above condition. For example, S could consist of all the individuals, which might not be what we want. To account for this, we also specify a preference function over all subsets of individuals. While this preference function could in principle be arbitrary, a natural example would be the one that prefers a set S of minimum cardinality.2 The headline-grabbing U.S. “debt-ceiling crisis” in 2011, especially the last-minute deal to increase the debt ceiling, is evidence of influence among senators in a strategic setting. We can also view the bipartisan “gang-of-six” senators, specifically chosen to work out a solution, as an intervention as such a group would not naturally arise otherwise.\fM.T. Irfan, L.E. Ortiz / Artificial Intelligence 215 (2014) 79–11981Fig. 1. Illustration of our approach to influence in networks. Each node has a binary choice of behavior, {−1, +1}, and, in this instance, wants to behave like the majority of its neighbors (and is indifferent if there is a tie). We adopt pure-strategy Nash equilibrium (formally defined later), abbreviated as PSNE, as the notion of stable outcome. Here, (a) shows the network, and (b) shows all the PSNE, one in each row, where black denotes behavior 1, gray −1. The goal of interest or the desired outcome is to have everyone choose 1. Selecting the set of nodes {1, 2, 3} and assigning these nodes the behavior prescribed by the desired outcome (i.",
            {
                "entities": [
                    [
                        135,
                        241,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 80 (1996) 309-348 Art ifkial Intelligence Model simplification by asymptotic order of magnitude reasoning Kenneth Man-kam Yip NE 43-432, MIT AI Lab, 545 Technology Square, Cambridge, MA 02139, USA Received February 1994; revised September 1994 Abstract One of the hardest problems in reasoning about a physical system is finding an approximate model that is mathematically tractable and yet captures the essence of the problem. This paper describes an implemented program AOM which automates a powerful simplification method. AOM is based on two domain-independent ideas: self-consistent approximations and asymptotic order of magnitude reasoning. The basic operation of AOM consists of five steps: (1) assign order of magnitude estimates to terms in the equations, (2) find maximal terms of each equation, i.e., terms that are not dominated by any other terms in the same equation, (3) consider all possible n-term (4) propagate the effects of the balance assumptions, and (5) dominant balance assumptions, remove part al models based on inconsistent balance assumptions. AOM also exploits constraints among equal:ions and submodels. We demonstrate its power by showing how the program simplifies difficult flui’d models described by coupled nonlinear partial differential equations with several parameters. We believe the derivation given by AOM is more systematic and easily understandable than those given in published papers. 1. Introduction Model simplification-the derivation of simpler equations from more genera1 ones-is Few physical in many areas of science and engineering. a recurrent problem theories can be matched directly with experiments. To an experimenter wondering why a certain say, why water boils at about 1OOT under ordinary is got for a measurement, value conditions, interacting a complicated with one another with a complicated quantum reduce to a form responsive laws of is to together and interpretation. Approximate models are not just statistical mechanics would not be exactly helpful. The real problem so complex and general, with so many variables force law, governed by the fundamental system of equations describing these equations, 1O23 molecules, to analysis linked 0004.3702/96/$15.00 SSD/OOO4-3702(94)00068-9 @ 1996 Elsevier Science B.V. All rights reserved \fthem are and to the “bag constructive 310 K.M.-K. Yip/Artificial Intelligence 80 (1996) 309-348 useful; experiments they are essential. Without and assess numerical it, we cannot make predictions. With it, we can guide results. Professional scientists simplify problems by all sorts of methods. Among estimates, exploitation that beginners in a systematic, can apply directly of small parameters, are seldom articulated and order of magnitude often requires an understanding in choices of what idealizations These methods and others besides, which belong dimensional symmetry considerations. of tricks” of a skilled practitioner, manner scientist must exercise judgement make. Making such judgement the solution, knowledge of the relative eration of limiting cases. The purpose of this paper is to demonstrate knowledge model approximation The implemented the in scientific works. To simplify a model or approximations to of the gross features of importance of terms in the model, and consid- how this kind of the difficult problem of ideas: reasoning. Given order of magnitude self-consistent approximations, and a few order equations, a system of fluid equations, in the equations, AOM finds all the simplified of magnitude equations consistent with the problem specification. The spirit of the analysis is heuristic and exploratory. We will not be able to prove that the simplified equations have strict validity. Rather these equations are the only ones which could possibly be valid. program, called AOM, is based on two domain-independent such as the Navier-Stokes in a computer program in fluid dynamics. can be embodied for the variables and asymptotic to tackle estimates is a good domain Fluid dynamics First, the domain is extremely solutions of many scientific and technological drag on ship hulls, and to evolution coupled nonlinear partial differential numerical difficulties. So methods of simplification the domain important Despite to heat transfer of galaxies. Second, of that subject-has in reentering for testing simplification important. Knowledge of fluid dynamics problems-from spacecrafts, life in moving ideas for three reasons. is critical for the fluids, to to motion of air masses, systems of and are likely to have large payoff. Third, are in general the fluid equations equations, which present enormous analytical because a list of identifiable, is appropriate for the development the appearance of the program as an application of AI techniques accumulated significant over the years. approximations- to a spe- l To study the nature of scientific cialized domain, we want to stress our more general concerns reasoning as practiced that professionals for this line of research: in normal science. We would problems, like to codify some of the skills making approximations, l To solve real problems l To provide scientists with an intelligent workbench consisting of a library of pow- explaining data, and testing in an area of significance have in formulating theories. to modern science. erful heuristic and qualitative methods. Our work is thus rooted in the tradition of focusing on the problem solving behavior of articulate professionals their methods so that a computer can exhibit similar behavior on similar problems. Works with a similar (such as Slagle’s SAINT, Moses’ SIN, and intent range from the early expert systems in MIT to the engineering Dendral), [ 1,5,33], and to the recent researches problem solving project and dynamicist workbench domains and formalizing in well-structured reasoning [ 91. This work is closely related automatic model generation and order of magnitude reasoning. Raiman introduces order of magnitude scales to ex- in qualitative to the researches concerning \fK.M.-K. Yip/Artificial Intelligence 80 (1996) 309-348 311 in the context of comparative [20]. Weld explores analysis algebra tend the power of qualitative called exaggeration Stephanopo’ulos lyzing chemical processes assumptions combine numerical and symbolic order of magnitude [ 141. Raiman and Williams explore in finding dominant equilibrium behaviors of an acid-base related [ 271. Mavrovouniotis ideas in a technique and in ana- relations the use of simplifying [ 281. system from these works Our project differs in two major aspects. First, whereas all the previous works deal with either qualitative models or models specified by algebraic or (ODES), we believe AOM is one of the first programs ordinary differential equations (PDEs) . Second, we base partial differential to handle systems of nonlinear of functions, which, be- our programs on a theory of asymptotic sides being closer to algebraic equations and ODES as well as to PDEs. to what applied mathematicians order of magnitude or fluid dynamicists use, ’ applies equations The use Iof asymptotic order of magnitude [32]. The program has since been extended in particular a well-known flow, the triple-deck model, a composite model having it can reproduce in qualitative reasoning originally to deal with more substantial, appeared non- approximate model subparts. interacting the the additional capability of AOM, and greatly expands examples; in textbook, for laminar This paper demonstrates explanation of new examples and the underlying algorithm. some terminology the relatively complicated as follows. We first introduce ideas can be understood by a careful is organized the fluid domain. We then explain necessary in Section 3 the model simplification the essential in Sections 4 and 5 where we describe asymptotic order of magnitude, The paper to understand task in the context of a fluid problem. Despite the paper, examples method of dominant algorithm and 8. In Section 9, we present a detailed evaluation of the strengths and weaknesses of the program. Section 10 puts AOM magnitude this paper presents. in the context of previous works on order of advances reasoning. We finally conclude with a summary of the technical in Section 6. We show the program’s performance reading of the motivating to find self-consistent The simplification approximations. in Sections 7 is described equations and the balance in 2. Characteristics of the problem domain 2.1. Some terminology laws of motion. The basic equations and conservation Fluids obey Newton’s servation of momentum Fig. 1 are -just examples of Newton’s Second Law (F = mu), In fluid mechanics, customary the equation, Since to have the acceleration and the remaining the motion of a fluid particle can change with both time and space, the inertia consists of two parts: the local acceleration (i.e., rate of change of velocity with respect for con- in it is side of of mass. The three momentum terms written on the left-hand force terms on the right. are expressions or the inertia equations ’ The asymptotic theory is also commonly used in the analysis of algorithms. \f312 K.M.-K. fip/Artijicial Intelligence 80 (1996) 309-348 Conservation of momentum: inertia forces / lOCEll convective . ’ pWSS”E applied forces viscous !?+uF?+v~+ aw @ 1 waz = -az + G ( 2 aw+!?+$ ax2 2 ay2 . . > Conservation of mass: s+g+g=o Fig. I. Meaning of terms in the 3D incompressible Navier-Stokes equations. When the velocity is indepen- dent of time, and the w-component of the velocity is zero, the general equations reduce to the 2D steady incompressible flow. to time), gradient). and the convective acceleration (i.e., product of velocity and the velocity A steadyjow is one in which the local acceleration into two types: (1) su@zceforces, fluid can be divided include pressure and friction external pressure constant, and y is the vertical coordinate). law is expressed The mass conservation forces due to viscosity, and (2",
            {
                "entities": [
                    [
                        66,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 83 (1996) 229-239 Artificial Intelligence Off-line reasoning for on-line efficiency: knowledge bases * Yoram Moses a,*, Moshe Tennenholtz b il Department r;lf Applied Mathematics and Computer Science, The Weizmann Institute of Science, Rehovot, 76100 Israel h Faculty of Industrial Engineering and Management, Technion, Israel Institute of Technology, Haifa, 32000 Israel Received November 1993; revised July 1994 Abstract The complexity of reasoning is a fundamental issue in AI. In many cases, the fact that an intelligent system needs to perform reasoning on-line contributes to the difficulty of this reasoning. This paper considers the case in which an intelligent system computes whether a query is entailed by the system”s knowledge base. It investigates how an initial phase of off-line preprocessing and design can improve the on-line complexity considerably. The notion of an eficient basis for a query language is presented, and it is shown that off-line preprocessing can be very effective for query languages that have an efficient basis. The usefulness of this notion is illustrated by showing that a fairly expressive language has an efficient basis. A dual notion of an eficient disjunctive basis for a knowledge base is introduced, and it is shown that off-line preprocessing is worthwhile for knowledge bases that have an efficient disjunctive basis. 1. Introduction Many activities concerned with a system representation. include planning The reasoning representation the following of knowledge in the framework task: an intelligent aspect of the world), and reasoning agent has a given representation are of to this relatively efficiently. Typical examples and computing whether a query is entailed by a given knowledge base. reasoning: when an in both of these cases can be thought of as on-line Its task is to solve this problem and a problem that relates (or of a relevant * Part of the material presented in this paper appeared in Proceedings IJCAI-93 [ 91. * Corresponding author. E-mail: yoram@cs.weizmann.ac.il. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDf0004-3702(95)00015-l \f230 X Moses, M. TennenhoWArtificial Intelligence 83 (1996) 229-239 its on-line performance in a is should find a solution is given, our algorithm reason about to the problem. schemes of knowledge input instance, and should researchers often use general logic [6], then often carried out using general schemes of reasoning proving, Prolog for logic programs, etc. Consider [4], semantic networks the following question: logic programs [lo], can our agent improve the problem the system and about In order to handle such problems, such as first order representation is the reasoning for theorem etc. Moreover, such as resolution system, Intuitively, there should of the world) the complexity to this system? to this particular is not very useful invariably be special-purpose algorithms instead of using general the on-line activity. In such a case the agent should be allowed to the agent, without our providing algorithms. Our aim the problem of how an initial phase of off-line preprocessing to reduce of the agent’s on-line behavior. We are especially in systems where agents might be presented with many potential problems rather case where the system it uses (e.g., its knowledge base or representation fixed, and we know ahead of time that the agent is to be asked to solve many problems it is clear that the answer should be positive; with respect for solving given a fixed system problems with respect schemes of reasoning. This answer, however, the agent with a way in which it can obtain such special-purpose in this paper is to consider can serve interested during extensive preprocessing without Specifically, we shall investigate system knowledge base. We present show query efficient disjunctive basis for a knowledge base, and show that off-line preprocessing very effective Reactive for knowledge bases that have an efficient disjunctive basis. to planning, [ 1,2] ) . Some other works suggested [ 1 l] ). However, have been to compile suggested reactive behaviors on-line behavior does not need to concentrate only on “real” reactive behavior. On-line behavior that faces various problems might to the behavior of an agent task is to identify areas where off-line after the initialization processing for each such area. can be helpful and to suggest a particular In this work, we apply this idea to query evaluation increasing the amortized cost per solution significantly. the following central context. We consider an intelligent are entailed by its language, and for the notion of an is the notion of an eficient basis for a query in greatly in a number of works (see in advance that off-line preprocessing languages that have an efficient basis. In addition, we consider to compute whether particular improved on-line behavior of the system. The main in AI, related especially the task of improving refer more generally to problems approaches to perform that needs can result (queries) formulas (see type of solution in knowledge bases. a high-level This paper is organized as follows. Section 2 contains can be used. In Section 3 we discuss that makes preprocessing languages effective. Section 4 presents a fairly expressive query discussion of the notion of an efficient of knowledge bases for lan- in which off-line additional examples languages that has an efficient basis, and considers bases worthwhile. A fairly natural in the context of knowledge bases. In Section 5 we present a of for representing that makes preprocessing the contents for representing the desired property. Finally, Section 6 con- knowledge bases language to have is shown for useful off-line processing, and provides some concluding reasoning how off-line basis, a property of query extremely these guage preprocessing property of languages knowledge of a knowledge siders other possibilities remarks. is useful base \f( 1) Replacing that represent a model, base. (2) Decreasing The first approach retical computer expressiveness case of multi-agent I: Moses, M. Tennenholtz/Art@cial Intelligence 83 (1996) 229-239 231 2. Off-line versus on-line reasoning Consider the well-known problem of determining whether queries are entailed by a for example in some logical in [ 51. We assume knowledge base, as discussed base KB expressed concerning KB are formulated. Given a query (Y, we are interested This problem verification process might be very inefficient. There are two main approaches discussed that we have a knowledge language, and a query language QL in which queries in whether KB + a. the that are in the general case. Moreover, even for tractable queries, in the AI literature for overcoming this difficulty: is intractable problem solving by model checking [ 31: discuss knowledge bases specific models, so that a query only needs to be checked against it is logically entailed by a knowledge rather than computing whether the expressive power of the knowledge base and of the query language in order to have more tractable queries. science. The second is in fact the way in which relational databases are treated in theo- is concerned with finding good tradeoffs between (as is done in the knowledge base case by [ 51, or in the and complexity activity by [ 171). in time t where complexity but polynomial is the following. Assume t might be large but still feasible Another potential way for decreasing in the size of the knowledge base KB). The question that any (e.g., is for each amount in order to make the on-line behavior more In the next sections we illustrate how this approach can be useful. We point to specific query can be verified super-linear whether we can find a subset QL’ c QL of a feasible member LY of QL’ whether KB b a (all of this might of time), and use this off-line processing efficient. a general sel: of queries Notice However, of retrieval (off-line preprocessing will be diffe.rent from classical multiple query optimization by knowledge bases instead it is performed instead of clever retrieval of a set of queries after their arrival) in this way, and discuss specific examples. can be treated as a type of multiple query optimization. size, verify off-line take a considerable the context of our query optimization the actual way in which that can be handled from relational this approach (cf. [ 121) . databases), (entailment that and The program described above allows efficient processing of many queries made to a fixed query made with respect a fixed knowledge base. A similar approach can be used for treating a dual problem: bases. We shall processing describe a general class of knowledge bases that can be handled in this way. Although this may be somewhat to off-line processing of a query language, there are contexts where this does make good sense. to different knowledge than our approach less powerful 3. Query lamguages with an efficient basis In this section we concentrate on off-line reasoning knowledge base, and queries each query formulated in the query regarding it arrive in a dynamic language QL can be verified in the case where we have a fixed that fashion. We assume in time t (generally, \f232 Y Moses, M. TennenholtdArtQicial Intelligence 83 (1996) 229-239 t might be a function of the size of the knowledge base and of the size of the current that the knowledge base KB and every query). For ease of exposition we will assume logic. 1 query (Y E QL are formulas in the language C of propositional Let us denote the set of primitive propositions in this logic by X = {xi, x2,. . . , xn, . . .}. We use ,Ci to denote are a subset of {xi, x2, . . . ,xi}. We will associate with every query language QL an infinite sequence QL1 C QL2 C . . ., where QLi = QL n .Ci. We say that a query language QL’ is of polynomial size if there exists a fixed polynomial p, such that lQL:I < p(i), where in QLf. IQL(I denotes the set of formulas of L: whose primitive proposition",
            {
                "entities": [
                    [
                        75,
                        133,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 94 (1997) 79-97 Artificial Intelligence Negotiation and cooperation in multi-agent environments * Sarit Kraus a,bJ a Department of Mathematics and Computer Science, Bar Ilan University Ramat Can, 52900 Israel b hstith!te for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USA Abstract Automatic intel~gent agents i~abiting a shared environment must coordinate their activities. improve the performance of the individual agents or Cooperation-not merely coordination-may the overall behavior of the system they form. Research in Distributed Artificial Intelligence (DAI) addresses the problem of designing automated intelligent systems which interact effectively. DA1 is not the only field to take on the challenge of understanding cooperation and coordination. There are a variety of other multi-entity environments in which the entities coordinate their activity and cooperate. Among them are groups of people, animals, particles, and computers. We argue that in order to address the challenge of building coo~nated intelligent agents, it is beneficial to combine AI techniques with methods and techniques from a range of muIti-entity fields, such as game theory, operations research, physics and philosophy. To support this claim, we describe some of our projects, where we have successfully taken an interdisciplinary approach. the benefits in applying multi-entity methodologies and show the adaptations, We demomtrate modifications and extensions necessary for solving the DA1 problems. @ 1997 Elsevier Science B.V. and collabom~d ~ey~ur~~~ Dis~buted Artificial Intelligence; Multi-agent systems; Cooperation; Negotiation 1. Introduction One of the greatest challenges can work together. The integration of automated for computer science is building computer systems that systems has always been a challenge, *This is an extended version of a lecture presented upon receipt of the Computers and Thought Award at the 14th International Joint Conference on Artificial Intelligence in Montreal, Canada, August 1995. ’ Email: sa.rit@cs.biu.ac.il or sarit@umiacs.umd.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIISOOO4-3702(97)00025-S \f80 S. Kraus/Artijicial Intelligence 94 (1997) 79-97 have become more sophisticated, but as computers cooperation printers, disks, and CPUs, but also high-level and cooperate. have become more critical. the demands for coordination It is not only basic level components and such as complex systems that need to coordinate Examples of such intelligent l automated agents l teams of robotic systems acting l computational l distributed l intelligent for whom systems include: that monitor electricity transformation in hostile environments networks [5]; [ 321; that facilitate distributed design and engineering agents transportation agents that negotiate over meeting scheduling options on behalf of people they work [67]; and and planning [ 25,561; systems [ 541; l Internet agents In these environments, the performance form. that collaborate to provide updated information to their users. even when coordination agents or the overall behavior of the system is not required, cooperation may improve they of the individual Problems of coordination and cooperation are not unique systems, but their in a wide range of populations. People pursue and cooperation with other people or machines. Ani- cooperate with each other, and form communities. to computer language), (with limited levels of activity exist at multiple own goals through communication mals interact Particles of matter. Although most computers interaction them is generally among gotiation or other sophisticated the levels of negotiation, acterize natural coordinating research Recent interact with each other and compose different act in multicomputer types of material and phases the currently restricted, and they interact under strict rules. Ne- In general, that char- rarely occur among computers. environments, interactions interactions bidding, voting, and other sophisticated systems are absent. in Distributed Artificial power, efficiency, and flexibility of intelligent ing sophisticated techniques research, ligent agents by combining AI techniques with methods and techniques fields that study multi-entity the challenge of building coordinated for communication I have addressed behavior. Intelligence automated (DAI) systems and cooperation aims (agents) among to increase the by develop- In my intel- from various them. and collaborated is beneficial for the development of coordi- I argue that an interdisciplinary intelligent approach agents. Because is quite the contrary. nated and cooperative these fields, which study multi-entity behavior, are not concerned with agent design, one might think that they are not relevant It is true that these fields do not solve AI for DAI. Our experience problems, but they have thought about a wide range of issues that are important to the design of intelligent sometimes with proven proper- that are useful to adopt for designing agents. DAI ties or methods for their needs; researchers however, the advantages they do not need to start from scratch. In this paper, we show by example still have a lot of work left in order to adapt these methods and the challenges of building on other work. agents, and they provide for proving properties techniques, The amount of work done in the related fields is overwhelming. in taking an interdisciplinary approach is determining which technique Thus, a major to use. for techniques that influence the choice of the appropriate challenge There are several parameters a DAI application: \fS. Kraus/Artificial Intelligence 94 (1997) 79-97 81 (1) (2) (3) (4) (5) Lie level of cooperation among the agents: cooperative agents which work to- ward satisfying the same goal versus agents which are self-motivate and try to maximize their own benefits. ’ There are intermediary cases where self-motivated agents join together to work toward a joint goal. Regulations and protocols: environments where the designers of the agents can agree on regulations and protocols for the agents’ interaction versus situations with no pre-defined regulations and protocols. Number of agents: a very large number of agents (hundred or more) versus a few agents which communicate and coordinate their actions. Type of agents: systems of automated agents versus systems composed of people and automated agents. C~~~~ni~at~on and computation costs: the availability and cost of communica- tion among the agents and their computation capabilities and costs. Any DA1 task can be characterized according to these dimensions. This characteriza- tion guides the choice of the multi-entity technique that can be applied to the specific task. Consider the deveIopment of automated agents for buying and selling items on the Web, such as clothes and furniture. Suppose there are several enterprises, each with several kinds of goods which they sell to users or to other enterprises. Each enterprise has intelligent seller and buyer agents. The job of the seller agent is to sell the enterprise’s goods to other enterprises through their buyer agents or to users. The job of a buyer agent is to obtain from other enterprises the goods that are missing ffom the stock of its enterprise. Several different DA1 problems may arise in such a fr~ework: in the interaction between two automated agents belonging to different enter- prises, the agents are self-motivated, but may benefit from cooperation. The designers of the agents may agree upon regulations for the interaction, the num- ber of agents of each interaction is limited, and they can communicate and have computation capabilities. A seller agent of an enterprise may try to sell some goods to a person. In this case, the person will prefer a non-structured interaction, and it is more difficult to set regulations and protocols for the interaction in advance. Two agents of the same enterprise may work together toward the same goal: increasing the benefits of their enterprise. In this case, the agents are cooperative, regulations and protocols can be set in advance, the number of agents is limited, they are automated, and they can communicate. In each of these three cases, there is a different multi-entity technique that should be applied. In this paper, we will examine different DAI tasks and will discuss the application of game-theoretic techniques (Section 2), physics models (Section 3), operations research methods (Section 4)) and informal models of cooperation and coordination (Section 5) to DAI environments. 2 Research in DAI is divided into two basic classes: distributes Problem Solving (DPS) and belts-Agent Systems (M.4) [ 61. Cooperative agents belong to the DPS class, while self-motivated agents belong to the MA class. \f82 S. Kraus/Art@ial Intelligence 94 (1997) 79-97 2. The application of game-theoretic techniques to multi-agent environments agents which represent different Researchers in DA1 have considered problems sharing where the agents are self-motivated, o situations where airplanes belonging related to task allocation as in the following examples: and resource to different airlines need to share the limited that will give to find a mechanism resources of the same airport, and it is necessary [ 611; to planes with less fuel on board priority o an electronic market populated with automated and buy and sell (e.g., [8,17,74]); enterprises o transportation centers that deliver packages and may cooperate to reduce expenses [641; o info~ation o intelligent for whom servers that form coalitions for answering queries [ 361; and agents that negotiate over meeting scheduling options on behalf of people they work [67]. in the Introduction that in these examples the five criteria presented these examples, Using we observe and try to maximize their own benefits. The designers of the agents may agree in advance on regulations and protocols usually ",
            {
                "entities": [
                    [
                        64,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 75 (1995) 161-194 Artificial Intelligence A typed resolution principle for deduction with conditional typing theory Tie-Cheng Wang * Kestrel Institute, 3260 Hillview Avenue, Palo Alto, CA 94304, USA Received October 1992; revised March 1994 Abstract The formal reasoning involved in solving a real world problem usually consists of two parts: type reasoning associated with the type structure of the problem domain, and general reasoning associated with the kernel formulation. This paper introduces a typed resolution principle for a typed predicate calculus. This principle permits a separation of type reasoning from general reasoning even when the background typing theory shares the same language constructs with the kernel formulation. Such a typing theory is required for an accurate formulation of the type structure of a computer program which contains partial functions and predicate subtypes, and also is useful for efficiently proving certain theorems from mathematics and logic by typed (sorted) formulation and deduction. The paper presents a typed deduction procedure which employs type reasoning as a form of constraints to general reasoning for speeding up the proof discovery. The paper also discusses further refinements of the procedure by incorporating existing refinements of untyped resolution. 1. Introduction The theory of data types often plays a fundamental role in the formal reasoning involved in solving a real world problem. Type specification is indispensable both for restricting the categories, or data types, of individuals involved in the kernel specification of the problem, and for formulating the data type theories about the problem domain. Consequently, the formal reasoning usually consists of two parts: one associated with type relations, called type reasoning, and the other associated with general relations, called general reasoning. * E-mail: wang@kestrel.edu. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00027-X \f162 Tie-Cheng Wang/Art$cial Intelligence 75 (1995) 161-194 type reasoning The simplest approach to handling relations are specified by standard that it permits a direct application of all existing proof techniques The disadvantage problem mixes for which more efficient methods can be applied. In addition, type formulae. This approach has the advantage theory. to solve a special it it is inelegant: is to use predicate calculus: it uses a general method is that it is inefficient: the type calculus for first-order first-order into the deductive is hybrid knowledge to carry out inference of general reasoning. representation type reasoning, sorted reasoning and uses algorithms to the general Another approach uses specialized a form of constraints This approach programming, calculus computer programs and efficiently proving certain (sorted) constructors Particularly, we need to deal with conditional and reasoning. This approach as for speeding up the proof discovery. logic typed predicate to this approach. However, motivated by reasoning about from mathematics by typed the capability of handling type partial functions, and subtypes. and deduction, we shall emphasize and relations associated with polymorphism, includes constrained reported here belongs or order-sorted) resolution, logic, constraint type reasoning typing rules. (many-sorted formulation resolution, etc. The theorems theory and A conditional typing rule is a typing rule having a hypothetical condition on general relations. Conditional ( 1) It is needed for accurately typing rule is needed in a number of important cases. typing partial functions. For example, div( X, y) : int/ formally as a language. For example, in the next section.) subranges and enumeration y # O/x: int A y: int. (The symbols “/” and “:” will be introduced part of our typed language It is needed for specifying ventional programming and x: weekend/x E {saturday, sunday}. It is needed x: integer. It may be needed a typed formula. For example, x: string/vhf(x) It may be needed x $ Z/x: dpt (see Example 2.4). for some typing rules created naturally for typing some Skolem for specifying predicate (see Example 2.3). (2) (3) (4) (5) from normalization of functions. For example, q(x) : xpt/ types occurring in a con- i: dbid/lb < i A i 6 ub/i: integer, subtypes. For example, X: odd/-even(x)/ Due to the existence of conditional typing rules, existing techniques on many-sorted (to be addressed sorting or order-sorted predicate calculus may be inefficient, or difficult few exceptions later), most of previous studies that the underlying no hypothetical solved by our typed approach when typing the background for general language components for solving theory relations. Thus, a crucial problem type reasoning logical is how to separate theory and the kernel relations. The typed resolution principle (typing) on general is nonconditional formulation condition to apply directly. With in sorted logic assume in the sense of having that must be from general reasoning share the same is introduced principle permits a normalization this problem. resolution into two subsets of clauses. One is a set of typing of the denial of a theorem The typed being proved rules, called a typing theory, and the other is a set of typed clauses. The principle consists of two special forms of binary resolution. One is the binary resolution of two typed clauses upon their kernels, called kernel resolution. The other is the binary the type restriction of a typed clause and the head of a typing rule, called TP-resolution. Kernel resolution upon resolution \fthe completeness to reduce prove permits one typing of these clauses deduction procedures theory lie-Cheq Wang/Artificial Intelligence 7.5 (1995) 161-194 163 to deduce consequences is used formulation. TP-resolution and TP-deduction. Type-checking type restrictions consequences cannot be satisfied to the general related from the general relations is used to carry out type reasoning: contained namely, the kernel in type-checking detects those consequences in the given relations contained typing of kernel resolution whose deduces theory. TP-deduction in the typing theory. We shall prove a typed version of the Herbrand of the typed resolution principle. The typed Herbrand the proof of the unsatisfiability theorem, and based on this theorem, theorem in a of a set of typed clauses to the search for an unsatisfiable in the typing theory. It thus provides from untyped deduction. subset of untyped a basis logical consequences for developing typed to general problem solving, and demonstrate Despite the gain in the efficiency by specializing type reasoning, (sorted) deduction this problem, we shall devote a good deal of discussion main cost of proving a theorem by a typed reasoning. By noting design of typed deduction procedures which can also be efficient in general In particular, we shall define a TP-second deduction procedure, and investigate resolution. the existing improvements from general prob- Besides from program analysis, many in our typed language in a nontrivial manner, such that can be effectively applied. The paper will present some refinements of untyped theorems reasoning. its further theorems derived by incorporating in many cases the is still due to general to the lem solving can be formulated the typed deduction techniques examples which apply improvements The basic typed deduction both in the clarity of representation type reasoning idea of specializing [ 241. Since famous paper on non-resolution theorem proving then, much research Bledsoe’s typed deductive databases focused on the sorted predicate calculus Schmidt-Schauss formulate handle deduction on sort relations. This approach has demonstrated over unsorted approach in solving certain problems taxonomic (Walther [ 27 1, etc.). The sorted predicate calculus employs sorted languages relations, and uses special algorithms, mainly sorted unification, and in the efficiency of reasoning. systems dates back to in deductive [3] and Reiter’s work on in this direction has been [ 111, Frisch[ 131, and to to [ 311, Cohn a great advantage intelligence. from logic and artificial The typed predicate calculus presented here extends to appear general predicates [ 121 of Cohn allows certain to include general predicates by allowing this extension, we must mention deduction Regarding [ 381 also has the ability LLAMA However, most of these systems were produced give no answer be incorporated, whereas our typed approach emphasizes refinements of untyped resolution. Thus, our typed approach substitution transforming for systematically of the corresponding an unsorted deduction transforming to the question of how existing sorted deduction. a completeness framework system that the logic of Weidenbach in typing in the underlying typing the existing approach of sorted theory. and Ohlbach theory. The sorted prover in the sort theory. that they can of existing the incorporation is in the direction of Frisch’s in the sense resolution from scratch refinements of unsorted into a sorted one. It also provides a method into one proof for an unsorted deduction [ 13,141. Frisch’s framework provides a method of systematically limited use of general predicates Besides sorted deduction, our typed approach cation system (RQS) [ 7,8], constraint logic programming is closely related (CLP) to Btirckert’s quantifi- [ 17,161, and Stickel’s \f164 Tie-Cheng Wang/Arti$cial Intelligence 75 (1995) 161-194 [ 281. All of these systems improve on automated deduction by sep- theory resolution arating out the reasoning associated with those parts of problem solving for which more efficient knowledge representation and reasoning methods are known, or can be developed. However, both Frisch’s substitution framework and Btirckert’s RQS require the back- ground theory to use a set of predicates disjoint from the set of predicates for general relations. ’ CLP has the additional restrict",
            {
                "entities": [
                    [
                        66,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 332–360www.elsevier.com/locate/artintInductive situation calculusMarc Denecker a,∗, Eugenia Ternovska ba Department of Computer Science, KU Leuven, Belgiumb School of Computing Science, Simon Fraser University, CanadaReceived 15 November 2006; received in revised form 7 February 2007; accepted 8 February 2007Available online 20 February 2007AbstractTemporal reasoning has always been a major test case for knowledge representation formalisms. In this paper, we develop aninductive variant of the situation calculus in ID-logic, classical logic extended with inductive definitions. This logic has beenproposed recently and is an extension of classical logic. It allows for a uniform representation of various forms of definitions,including monotone inductive definitions and non-monotone forms of inductive definitions such as iterated induction and inductionover well-founded posets. We show that the role of such complex forms of definitions is not limited to mathematics but extends tocommonsense knowledge representation. In the ID-logic axiomatization of the situation calculus, fluents and causality predicatesare defined by simultaneous induction on the well-founded poset of situations. The inductive approach allows us to solve theramification problem for the situation calculus in a uniform and modular way. Our solution is among the most general solutionsfor the ramification problem in the situation calculus. Using previously developed modularity techniques, we show that the basicvariant of the inductive situation calculus without ramification rules is equivalent to Reiter-style situation calculus.© 2007 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Inductive definitions; Situation calculus1. IntroductionID-logic1 [5,8,10] is an extension of classical logic with inductive definitions (ID). In mathematical texts, inductivedefinitions are usually represented as collections of rules, which represent the base case and inductive cases. Inductiverules may be monotone or non-monotone. An example of the latter is the following rule in the definition of the truthrelation |=:I |= ¬ψ ifI (cid:3)|= ψ,which states that I satisfies ¬ψ if I does not satisfy ψ. It is well known that in general, inductive definitions cannotbe represented in first-order logic (FO). ID-logic extends classical logic with a construction that allows for a uniform* Corresponding author.E-mail address: Marc.Denecker@cs.kuleuven.be (M. Denecker).1 The term ID-logic was introduced by the first author in [5] to denote a logic of sets of classical first-order logic sentences and definitions.This logic was extended to its current definition in [8] and in [7], where it was called NMID-logic in order to emphasize that the logic deals withnon-monotone inductive definitions (NMIDs).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.002\fM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360333representation of different sorts of inductive definitions; moreover, this representation preserves the rule-based natureof definitions in mathematical texts. The semantics of this new construct is based on the well-founded semantics oflogic programming [41]. This semantics correctly formalizes the semantics of different types of definitions that canbe found in mathematics, e.g. recursion-free definitions, monotone inductive definitions, and non-monotone inductivedefinitions such as inductive definitions over well-founded orders and iterated inductive definitions [4,6].ID-logic occupies an interesting place in the spectrum of logics used in mathematics, computer science and knowl-edge representation. As an extension of classical logic with a fixpoint semantics for inductive definitions, it can beviewed as a new element in the family of fixpoint logics. Monotone fixpoint logics have their origin in the logicalstudy of monotone inductive definitions [1,28]. The contribution of ID-logic is that it formalizes two non-monotoneinductive principles (i.e., inductive definition over a well-founded order and iterated inductive definition), which differfrom the non-monotone principle based on the inflationary fixpoint studied in the inflationary fixpoint logic IFP [16].ID-logic is similar to description logics [2] in its separation of definitional and assertional knowledge, but it allowsdefinitions for n-nary predicates and non-monotone inductive definitions. In addition, ID-logic is formally an exten-sion of Logic Programming and its variants such as Abductive Logic Programming and Datalog. In this way, ID-logicinduces an alternative informal semantics for logic programming, solidly based on the mathematical principle of in-ductive definitions. As such, the study of semantical and computational aspects of ID-logic can lead to synergy andintegration of all these different areas.On the computational level, ID-logic has recently been proposed as the underlying language for a constraint pro-gramming framework [27]. This framework is based on ideas from descriptive complexity theory and is similar insome respects to Answer Set Programming [20,29]. A problem instance is a finite structure, and a problem specifica-tion is an ID-logic formula defining the relationship between an instance and its solutions. Solving a problem amountsto expanding the structure with new relations to satisfy the formula. Depending on the expressiveness allowed, theframework captures various complexity classes, including P and NP. Several ID-logic solvers have been developed[21,30].The focus of this paper is on knowledge representation and modeling in ID-logic. Although diverse forms ofinductive definitions occur frequently in mathematics, there is little awareness in the logic and KR community ofnon-monotone forms of inductive definitions and of the potential role of inductive definitions for knowledge repre-sentation. Thus, a central aim of this paper is to clarify and illustrate these types of definitions. We provide examplesof monotone definitions, definitions by induction over well-founded order and iterated inductive definitions and relatethese to other knowledge representation principles such as completion and circumscription. Moreover, we show thatthe role of these complex forms of definitions is not limited to mathematics but extends to commonsense knowledgerepresentation.A second major purpose of the paper is to illustrate the use of a “tool set” from [8,42] for analyzing definitions,consisting of different modularity theorems, totality theorems and translation theorems. Our experiment demonstratesthe effectivity of the tool set for breaking up large complex definitions into conjunctions of smaller and simplerones, for translating definitions into classical logic, and for proving consistency and correctness of ID-logic theo-ries.The domain of application selected for our study is temporal reasoning. Since the early days of AI, temporal rea-soning, in particular the situation calculus, has been a major test case for knowledge representation languages. In [25],McCarthy and Hayes exposed the famous frame problem, showing the difficulty of axiomatizing actions and causa-tion in classical logic. This problem has (partly) motivated the development of the area of non-monotonic reasoning,leading to non-monotone logics such as default logic [32] and non-monotone reasoning techniques in classical logicsuch as circumscription [23] and completion [3]. Many different temporal reasoning formalisms were developed. Cur-rently, the most widely adopted formalization of situation calculus is the one in classical logic developed by Reiter andhis collaborators in the nineties [18,31,34]. Other well-known solutions are Event calculus [35], Fluent calculus [39],non-monotonic logic approaches such as the (many extensions of) the language A [14] and non-monotonic causaltheories [15,22].We present here a formalization of situation calculus in ID-logic, which we call the inductive situation calculus.Temporal reasoning is a natural application for using inductive definitions on the set of situations. In Reiter’s situ-ation calculus for example, the description of the initial state may be viewed as the base case, and successor stateaxioms may be seen the inductive case. By axiomatizing situation calculus in ID-logic, we explicitate the definitionalstructure underlying situation calculus. The main component of the inductive situation calculus will be a definition\f334M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360of fluent and causality predicates by simultaneous, non-monotone, iterated induction in the well-founded set of situ-ations. This definition and its components are natural illustrations of each of the above mentioned types of inductivedefinitions.A first benefit in explicitating the definitional structure of situation calculus, is that we considerably gain on therepresentational level. In particular, the inductive situation calculus is more expressive and modular than Reiter’sclassical logic version. On the level of modularity, in the inductive situation calculus it is possible to represent ef-fects of specific actions on specific fluents in specific circumstances by individual effect rules. It is well-known thatincreased modularity may improve elaboration tolerance [24]. On the level of expressivity, the inductive situationcalculus can handle recursive ramifications, where an effect to one fluent may cause an effect to another fluent andvice versa. The challenge in handling such recursive ramifications is to avoid erroneous models in which the re-lated fluents “cause” each other and become true simultaneously without external cause. By interpreting effect rulesas definitional rules, such spontaneous generation of effects is avoided. As a consequence, the inductive situationcalculus currently provides the most general solution of the ramification problem. It also provides the most genera",
            {
                "entities": [
                    [
                        72,
                        100,
                        "TITLE"
                    ],
                    [
                        1545,
                        1573,
                        "TITLE"
                    ],
                    [
                        8018,
                        8046,
                        "TITLE"
                    ],
                    [
                        8467,
                        8495,
                        "TITLE"
                    ],
                    [
                        8998,
                        9026,
                        "TITLE"
                    ],
                    [
                        9131,
                        9159,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 51–71Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintGrounded fixpoints and their applications in knowledge representation ✩Bart Bogaerts a,∗a Department of Computer Science, KU Leuven, 3001 Heverlee, Belgiumb Department of Computer Science, Campus De Nayer, KU Leuven, 2860 Sint-Katelijne-Waver, Belgium, Joost Vennekens a,b, Marc Denecker aa r t i c l e i n f oa b s t r a c tArticle history:Received 21 December 2014Received in revised form 19 March 2015Accepted 21 March 2015Available online 25 March 2015Keywords:Approximation fixpoint theoryLattice operatorStable semanticsWell-founded semanticsGroundednessLogic programmingAutoepistemic logicAbstract argumentationAbstract dialectical frameworks1. IntroductionIn various domains of logic, researchers have made use of a similar intuition: that facts (or models) can be derived from the ground up. They typically phrase this intuition by saying, e.g., that the facts should be grounded, or that they should not be unfounded, or that they should be supported by cycle-free arguments, et cetera. In this paper, we formalise this intuition in the context of algebraical fixpoint theory. We define when a lattice element x ∈ L is grounded for lattice operator O : L → L. On the algebraical level, we investigate the relationship between grounded fixpoints and the various classes of fixpoints of approximation fixpoint theory, including supported, minimal, Kripke–Kleene, stable and well-founded fixpoints. On the logical level, we investigate groundedness in the context of logic programming, autoepistemic logic, default logic and argumentation frameworks. We explain what grounded points and fixpoints mean in these logics and show that this concept indeed formalises intuitions that existed in these fields. We investigate which existing semantics are grounded. We study the novel semantics for these logics that is induced by grounded fixpoints, which has some very appealing properties, not in the least its mathematical simplicity and generality. Our results unveil a remarkable uniformity in intuitions and mathematics in these fields.© 2015 Elsevier B.V. All rights reserved.Motivated by structural analogies in the semantics of several non-monotonic logics, Denecker, Marek and Truszczy ´nski (from now on abbreviated as DMT) [10] developed an algebraic fixpoint theory that defines different types of fixpoints for a so-called approximating bilattice operator, called supported, Kripke–Kleene, stable and well-founded fixpoints. In the context of logic programming, they found that Fitting’s (three- or four-valued) immediate consequence operator is an approximating operator of the two-valued immediate consequence operator and that its four different types of fixpoints correspond exactly to the four major, equally named semantics of logic programs. They also identified approximating operators for default logic (DL) and autoepistemic logic (AEL) and showed that the fixpoint theory induces all main and some new semantics in these fields [11]. Moreover, by showing that Konolige’s mapping from DL to AEL [26] preserves the approximating operator, they A short version of this paper is accepted for publication in the proceedings of the AAAI’15 conference [5]. This paper extends the previous work with ✩proofs of all propositions and applications of the theory to abstract dialectical frameworks, autoepistemic logic and default logic.* Corresponding author.E-mail addresses: bart.bogaerts@cs.kuleuven.be (B. Bogaerts), joost.vennekens@cs.kuleuven.be (J. Vennekens), marc.denecker@cs.kuleuven.be(M. Denecker).http://dx.doi.org/10.1016/j.artint.2015.03.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\f52B. Bogaerts et al. / Artificial Intelligence 224 (2015) 51–71resolved an old research question regarding the nature of these two logics: AEL and DL were essentially unified in the sense that for each semantics covered by AFT, a DL theory is equivalent with its Konolige mapping in AEL. However, the original DL and AEL semantics occupy different positions in this family and do not correspond. As such AEL and DL under their original semantics, are “just” two different dialects of autoepistemic reasoning [11,13].The study of these approximating operators called approximation fixpoint theory (AFT) was later used to define semantics of extensions of logic programs, such as logic programs with aggregates [35] and HEX logic programs [2]. Vennekens et al. [42] used AFT in an algebraical modularity study for logic programming, AEL and DL. Recently, Strass [38] showed that many semantics from Dung’s argumentation frameworks (AFs) and abstract dialectical frameworks (ADFs) can be obtained by direct applications of AFT. Bi et al. [4] extended AFT with approximators allowing for inconsistencies and used it to integrate description logics with logic programs. Bogaerts et al. [6] defined the causal logic FO(C) as an instantiation of AFT. This suggests that fixpoint theory, in ways that are difficult to explain due to its high level of abstraction, captures certain fundamental intuitions in a range of logics and sorts of human knowledge. It is this observation that provides the basic motivation for the present study.In this paper, we formally use fixpoint theory to investigate an intuition that is found in all aforementioned logic do-mains. There, researchers have made use of a similar intuition: that facts (or models) can be derived from the ground up. They typically phrase this intuition by saying that, e.g., the facts should be grounded, or that they should not be unfounded, or that they should be supported by cycle-free arguments, or by arguments that contain no vicious circles, et cetera. In several cases, great efforts were done to refine semantics which did allow ungrounded models or facts. For example, it is well-known that the completion semantics of logic programs allows ungrounded models, e.g., for the transitive closure program. The efforts to avoid these led to the development of perfect, stable and well-founded semantics. Also for AEL, it was known that Moore’s expansion semantics accepted ungrounded models, e.g., for the theory {KP ⇒ P } which has the ungrounded model in which P is known but this knowledge is self-supported. Examples like this motivated several attempts to refine Moore’s semantics, among others by Halpern and Moses [24] and Konolige [26].We formalise the intuition of groundedness in the context of algebraical fixpoint theory. We call a lattice element x ∈ Lgrounded for lattice operator O : L → L if for all v ∈ L such that O (x ∧ v) ≤ v, it holds that x ≤ v. We investigate this notion on the algebraical level in AFT and on the logical level in the context of logic programming, autoepistemic logic, default logic and abstract argumentation frameworks. We explain what grounded points and fixpoints mean in these logics and show that this concept indeed formalises intuitions that existed in these fields. We investigate which existing semantics are grounded, where we call a semantics grounded if all its models are grounded, and investigate a novel semantics for these logics that is based on grounded fixpoints. Our results unveil a remarkable uniformity in intuition and mathematics in these fields and lead to a new candidate semantics with some very appealing properties, not in the least the mathematical simplicity and generality to define it in the context of operator-based logics and logic constructs.We can summarise the main contributions of this paper as follows. We extend AFT with the notion of a grounded fixpoint, a fixpoint closely related to stable and well-founded fixpoints. We show that if the Kripke–Kleene fixpoint is exact, then it is grounded. If the well-founded fixpoint is exact, then it is the unique grounded and the unique stable fixpoint. Otherwise, stable fixpoints are grounded but not necessarily the other way around. A useful feature of grounded fixpoints that distinguishes them from stable and well-founded fixpoints is that they are determined by O and do not require the choice of an approximator. We then apply this theory to different logical research domains. In all domains, we explain the meaning of grounded fixpoints, relate them to attempts to formalise groundedness, study which semantics are grounded and finally, we explore the semantics induced by grounded fixpoints. More specifically, (i) in the context of logic programming, our theory yields an intuitive, purely two-valued, semantics that is easily extensible and that formalises well-known intuitions related to unfounded sets. (ii) We show that two of the main semantics of AFs can be characterised as grounded fixpoints of previously defined operators and discuss grounded fixpoints in the context of ADFs. (iii) Applied to autoepistemic logic and default logic, groundedness turns out to provide an alternative and improved formalisation of intuitions described by Konolige [26].2. Preliminaries2.1. Lattices and operatorsA partially ordered set (poset) (cid:8)L, ≤(cid:9) is a set L equipped with a partial order ≤, i.e., a reflexive, antisymmetric, transitive relation. As usual, we write x < y as abbreviation for x ≤ y ∧ x (cid:10)= y. If S is a subset of L, then x is an upper bound, respectively a lower bound of S if for every s ∈ S, it holds that s ≤ x respectively x ≤ s. An element x is a least upper bound, respectively greatest lower bound of S if it is an upper bound that is smaller than every other upper bound, respectively a lower bound that is greater than every other lower bound. If S has a least upper bound, respectively a greatest lower bound, we denote it lub(S), respectively glb(S). As is custom, we sometimes call a greatest lower bound a meet, and a least upper bound a S = lub(S) and x ∨ y = lub({x, y}). We call (cid:8)L, ≤(cid:9) a join and use the related notations complete lattice if every subset of L has a least upper bound a",
            {
                "entities": [
                    [
                        134,
                        203,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 77 (1995) 95-127 Artificial Intelligence Artificial intelligence: an empirical science Herbert A. Simon* Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213-3890, USA Received August 1993; revised May 1995 Abstract My initial tasks in this paper are, first, to delimit the boundaries of artificial intelligence, then, to justify calling it a science: is AI science, or is it engineering, or some combination of these? After arguing that it is (at least) a science, I will consider how it is best pursued: in particular, and theory in developing AI. the respective roles for experiment I will rely more on history than on speculation, the field has much to tell us about how we can continue and accelerate of my examples will be drawn from work with which I have been associated, speak with greater confidence about what motivated its defects) than I can about the work of others. My goal, however, through history, but to make definite proposals where relevant, in advancing that advance. Many for I can that work and its methods (and about is not to give you a trip for our future priorities, using history, for our actual experience for my views. as evidence 1. Artificial intelligence as science AI deals with some of the phenomena surrounding computers, hence is a part science [27]. It is also a part of psychology and cognitive science. It that appear when computers perform of computer deals, tasks that, if performed by people, would be regarded as requiring thinking. in particular, with the phenomena intelligence- in the 1950s as an inquiry the nature of intelligence began It used computers as a revolutionary indeed exhibit, thereby providing a means for examining it in utmost detail. “B.C.“, Artificial intelligence. intelligence, before computers, the only observable examples of intelligence were the minds of living organisms, especially human beings. Now the family of intelligent systems had been joined by a new genus, intelligent computer programs. into tool to simulate, * E-mail: has@a.gp.cs.cmu.edu. 0004-3702/95/$09.50 SSDZ 0004-3702(95)00039-9 0 1995 Elsevier Science B.V. All rights reserved \f96 H.A. Simon I Artificial intelligence 77 (1995) 95-127 1.1. The multiple goals of AI from the AI thrust, As the papers reprinted reveal, in Feigenbaum and Feldman’s classic, Computers and three- Thought, pronged. One goal was to construct computer programs (e.g., the Logic Theorist) capable of exhibiting intelligent “complex “artificial friends and foes of the activity.) systems. information intelligence”, which had become the alternative the established usage among both to begin building a theory of name for the endeavor was and thereby, (The original Carnegie-Rand its very beginnings, was at least later accepted processing”; intelligence, our group A second goal was to construct programs (e.g., GPS) that exhibited intelligence by using processes like those used by humans in the same tasks. Here the aim was intelligently. The third to achieve a theory of how the human mind can behave intelligent programs (e.g., Tonge’s assembly line balancing goal was to construct program) in performing some of the world’s work. (In the body of this paper, I will refer to systems in this the usual denotation of third category as “expert systems”, enlarging somewhat in Sections 2 and 3 of Part 1 of Computers and that name.) The systems described Thought focus upon the first of these three objectives; in Part 2, those described upon the second; and those in Sections 4-6 of Part 1 upon the third. that could supplement or complement human intelligence of the systems intelligence. Surrounding Almost from its very birth, then, AI was a multicelled organism. Its foundation intelligence, either as pure was the capability for building systems that exhibited into the nature of intelligence, explorations of the theory of human explorations tasks or explorations intelligence, requiring there gradually grew up corresponding bodies of theory. But we should not think of the programs the Logic Theorist as isolated from the theories. Quite the contrary. For example, in solving theory embodies problems likewise, is a powerful heuristic GPS embodies commonly employed by people for problem-solving a theory: requires a physical symbol system capable of heuristic search. that could perform practical these operative AI systems that achievement that means-ends intelligence analysis theory the the of of the We can extract is no more separable from such programs verbal theoretical principles, as Allen Newell and I did in our 1975 Turing Award address, but the the basic operational definitions of what the principles mean. programs provide The theory is from of the verbal statements are different theories, which exhibit different properties when the programs are run. I will have more to say later about the relation of programs I to theories and how runs of programs are used to test theories. For the moment, will simply remind you that: the mathematics of the laws of motion. Different than classical mechanics from the program implementations search. statements The moment of truth is a running program. 1.2. Social fragmentation of AZ Side by side with the growth of programs aimed at the triple objectives of the human mind and building and understanding intelligence, understanding \fH.A. Simon ! Artificial Intelligence 77 (1995) 95-127 97 rather researchers focus upon expert systems, these social structures in detail, except to mention there have grown up communities of researchers understanding concerned with these objectives. Some of the researchers are interested in more than one of the three goals, a few with all three; but social structures have formed than that emphasize and enforce their common concerns. I will not describe the separateness of the three endeavors that, in there are four, not three, principal groups; for at least two rather distinct intelligence. One the “pure” is often associated with and/or science”; some within AI groups some found mainly in computer science departments, in program verification identifies with “cognitive some of its in computer and fact, groups of subgroup, colleagues who are complexity. Another members are to be found science, miscellaneous other areas. the years, all four AI groups has gradually the distance ranging from the Ameri- increased. They attend different professional meetings, to can Psychological Society, ACM and engineering societies like IEEE. They limit their reading and citations more and more their training in different academic disciplines and subdisciplines, each passing on to the next generation to the journals published by their groups. They receive its own specialized version of the enterprise. in psychology, some the Cognitive Science Society, interested subgroup in anthropology in philosophy, in linguistics, computational the AAAI, separating through theory some Over of that, In assigning a broad definition in spite of diversity of goals, there to AI, covering all of these groups, I reveal my that makes belief I believe that each one continuing communication its goals by drawing on the of these groups can get substantial help in advancing the serious work of the others, and that disadvantages the over have been of fragmentation) whole history of AI. I believe that AAAI and the Cognitive Science Society share primary for opposing and turning back the forces of dissociation. the advantages of interaction among them highly desirable. (and demonstrated is a common core responsibility frequently response intelligence The distinction My reasons for believing in complementarity of the several goals will emerge as I would just like to state two of the reasons now, in a preliminary way. I proceed. the way in which humans achieve (I will call it “heuristic First, search”) is quite different from the way in which computers performing numerical analysis and similar tasks typically do it. (We might call the latter method, “brute is not black and white, but force disciplined by mathematics.“) obvious none the less. The human methods, I believe, are absolutely essential for ill-structured problems, hence we must under- intelligent the human mind or stand them regardless of whether our aim is to understand intelligence Programs in general. for solving inverting matrices or equations depend heavily on the size and speed of solving partial differential computers, but use algorithms based on the known, and usually rich, mathemati- the amount of search required. cal structures of their problem spaces to reduce search, but almost These always preserve to find the to any desired degree of approximation. Because of the mathematical solution reduction principles do not always optimize the property of completeness-they linear programming are guaranteed to relatively problems, search \f9x H. A. Simor~ ” Artificiul Intelligence 77 (1995) 9.5-127 solving regularity sufficiency Human of the spaces searched, and sometimes problem humans, whose computational super-computers tion, problems having of strong shrewd use of heuristics of search and optimality What I am calling “disciplined goals, poorly ill-defined and regular mathematical that it is often possible to prove theorems about the the efficiency, seldom of algorithms. shares any of these properties. Nevertheless, abilities or even PCs. are sometimes able are puny compared with to solve, with those of modern little computa- are very difficult even by computer and bounded People standards-problems spaces, problem solve such problems characterized structure. lack by the and at the expense of giving up guaranteed attained. of the solutions completeness brute force” had its origins in numerical the theory of computation, which has had some extension systems. Many of us do not believe the same that range of application force can achieve its successor, to symbolic brute and numerical disciplined attain. Unless that humans to explore r",
            {
                "entities": [
                    [
                        74,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 181–219Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLakatos-style collaborative mathematics through dialectical, structured and abstract argumentationAlison Pease a,∗Chris Reed aa Centre for Argument Technology, University of Dundee, UKb Institute of Philosophy and Sociology, Polish Academy of Sciences, Polandc Department of Computing, Goldsmiths, University of London, UKd University of Edinburgh, UK, John Lawrence a, Katarzyna Budzynska b,a, Joseph Corneli c,d, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 October 2015Received in revised form 17 February 2017Accepted 20 February 2017Available online 1 March 2017Keywords:Automated theorem provingAutomated reasoningAbstract argumentationArgumentationCollaborative intelligenceDialogue gamesLakatosMathematical argumentStructured argumentationSocial creativityPhilosophy of mathematical practiceThe simulation of mathematical reasoning has been a driving force throughout the history of Artificial Intelligence research. However, despite significant successes in computer mathematics, computers are not widely used by mathematicians apart from their quotidian applications. An oft-cited reason for this is that current computational systems cannot do mathematics in the way that humans do. We draw on two areas in which Automated Theorem Proving (ATP) is currently unlike human mathematics: firstly in a focus on soundness, rather than understandability of proof, and secondly in social aspects.Employing techniques and tools from argumentation to build a framework for mixed-initiative collaboration, we develop three complementary arcs. In the first arc – our theoretical model – we interpret the informal logic of mathematical discovery proposed by Lakatos, a philosopher of mathematics, through the lens of dialogue game theory and in particular as a dialogue game ranging over structures of argumentation. In our second arc – our abstraction level – we develop structured arguments, from which we induce abstract argumentation systems and compute the argumentation semantics to provide labelings of the acceptability status of each argument. The output from this stage corresponds to a final, or currently accepted proof artefact, which can be viewed alongside its historical development. Finally, in the third arc – our computational model – we show how each of these formal steps is available in implementation. In an appendix, we demonstrate our approach with a formal, implemented example of real-world mathematical collaboration. We conclude the paper with reflections on our mixed-initiative collaborative approach.© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionThe simulation of mathematical reasoning has been a driving force throughout the history of Artificial Intelligence re-search [58,86,87,98]. However, despite significant successes in ‘computer mathematics’ (e.g., [18,40,42,45]) computers are not widely used by mathematicians apart from their quotidian applications like running word processing tools, email pro-grams, web servers and web browsers, and (sometimes) computer algebra systems. An oft-cited reason for this is that current computational systems cannot do mathematics in the way that humans do. Despite – or perhaps because of [69] – * Corresponding author.E-mail address: a.pease@dundee.ac.uk (A. Pease).http://dx.doi.org/10.1016/j.artint.2017.02.0060004-3702/© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f182A. Pease et al. / Artificial Intelligence 246 (2017) 181–219their profound rigour, machine proofs are often thought to be unclear, uninspiring and untrustworthy, as opposed to human proofs which can be deep, elegant and explanatory [21,41]. In order to help to close the gap between machine-constructed proofs and human-constructed ones, we consider two key areas of focus: informal and social aspects of proof discovery in the human context. We propose that theories and tools from the field of argumentation can be used to more closely align AI systems with the human context in these two areas.1.1. Informal aspects of proofEvaluation metrics in the Automated Theorem Proving (ATP) community are focused on soundness, and the power of a solver to prove a wide selection of difficult problems with specific resource limits.1 Qualities of the resulting proof other than soundness are rarely considered. This stands at variance with the practices of the mathematical community, in which a lack of soundness might be forgiven if a proof is interesting or complex. Indeed, an error in a proof may be neither “perturb-ing,” nor “surprising,” if it is judged to be the right sort of error (one which is not critical to the integrity of the proof) [20].2Instead, one of the main criteria by which a proof is judged in the human context is its understandability. A well-written proof can provide insight as to why a theorem may be true, point to new conjectures, form connections between different fields and suggest solutions to open problems [44,75,106]. Fields medal winners Gowers and Thurston, respectively, have said: “We like our proofs to be explanations rather than just formal guarantees of truth” [41, p. 3], and “reliability does not primarily come from mathematicians formally checking formal arguments; it comes from mathematicians thinking carefully and critically about mathematical ideas” [94, p. 10]. Thurston emphasises that informal conversations between mathemati-cians can often convey ideas more quickly and comprehensibly than a written proof [94, p. 6]. Hersch has suggested that “The standard style of expounding mathematics purges it of the personal, the controversial, and the tentative, producing a work that acknowledges little trace of humanity, either in the creators or the consumers” [47, p. 131].Lakatos offered similar insight into proof-understanding [55]. Building on Pólya’s distinction between informal, unfinished mathematics-in-the-making and formal, finished mathematics [76], he argued that a theorem and proof which are presented in isolation from their development are “artificial and mystifyingly complicated”, analogous to a “conjuring act” [55, p. 142]. In order to make results understandable, they should be presented alongside the “struggle” and “adventure” involved in the story of their development. This insight is echoed by Ernest, who criticises the practice of presenting mathematics learners with the “sanitized outcomes of mathematical enquiry”: “The outcome may be elegant texts meant for public consumption, but they also generate learning obstacles through this reformulation and inversion” [67, p. 67]. Bundy points out that this practice also obscures understandability for research mathematicians: “Mathematicians find informal proofs more accessible and understandable [than formal proofs]” [21, p. 2].In contrast to the concerns about understandability voiced by mathematicians and philosophers of mathematics, under-standability is not traditionally a concern for ATP. A handful of exceptions have focused on making an existing machine proof more comprehensible [29,30,36]. MacKenzie [60] has argued that rather than treating machines as oracles and giving them responsibility for verifying the reliability of hardware and software, there needs to be a continued interaction between computer systems and our collective human judgement: “The finished product of formal verification – the ‘proof object’ – may thus be less important than the process of constructing it.” [61, p. 2348]. Constructing or verifying proofs which are written in a classical logical formalism does not align with mainstream mathematical activity, since proofs are typically neither constructed nor presented in this way.Accordingly, our objective to model mathematical dialogues connects closely with the theory of defeasible argument (reasoning that is rationally compelling but not deductively valid [52]). The structure of classical proof theoretic systems and formal theorisations of defeasible argument differ [99]. Defeasible argument is used during the initial construction of a proof, and as the proof is refined or changed over time to reflect conceptual changes in the underlying theory, or to rectify deductive errors discovered after a proof is commonly accepted – all themes that Lakatos emphasised [55]. In practice, we may have an argument whose conclusion states that for all x, P (x) → Q (x), whose logical validity rests on a particular interpretation of P and Q . In some cases P or Q might not be clearly defined, and can be subsequently defined in different ways by different people, sometimes rendering the initial argument invalid. Whether a consensus ever occurs and whether we could be sure that the consensus is final, is an open and somewhat contentious question.We propose that applied argumentation theory can improve the understandability of output from, and input to, ATP systems, and other computer-mediated, -moderated, or -motivated proof systems. Doing this will help to close the cultural gap between human and machine mathematics. One way to go about this is to keep track of informal proof development, presenting the errors, conflicts and deadends involved, alongside a finished or current proof artefact.1.2. The social dimension of human mathematicsThe social dimension is typically neglected in automated reasoning, which usually consists of two approaches: au-tonomous theorem proving, in which a single system proves theorems, or interactive theorem proving, in which there is one 1 “Wide”, “difficult” and “resources” are all defined appropriately: see, for instance [92].2 Indeed, Aschbacher – one of the main mathematicians involved in the development of the proof of the Classification of Fin",
            {
                "entities": [
                    [
                        136,
                        234,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 117 (2000) 255–275On conjectures in orthocomplemented lattices IEnric Trillas a;1, Susana Cubillo b;(cid:3), Elena Castiñeira b;2a Dept. de Inteligencia Artificial, Univ. Politécnica de Madrid, 28660 Boadilla del Monte, Madrid, Spainb Dept. Matemática Aplicada, Univ. Politécnica de Madrid, 28660 Boadilla del Monte, Madrid, SpainReceived 31 October 1998AbstractA mathematical model for conjectures in orthocomplemented lattices is presented. After definingwhen a conjecture is a consequence or a hypothesis, some operators of conjectures, consequences andhypotheses are introduced and some properties they show are studied. This is the case, for example,of being monotonic or non-monotonic operators.As orthocomplemented lattices contain orthomodular lattices and Boolean algebras, they offer asufficiently broad framework to obtain some general results that can be restricted to such particular,but important, lattices. This is, for example, the case of the structure’s theorem for hypotheses.Some results are illustrated by examples of mathematical or linguistic character, and an appendixon orthocomplemented lattices is included. (cid:211) 2000 Elsevier Science B.V. All rights reserved.Keywords: Orthocomplemented; Orthomodular and Boolean lattices; Conjectures; Consequences; Hypothesesand their structure1. Introduction1.1.While the capability of conjecturing is one of the essential factors for the evolution ofhumankind, orderly conjecturing seems to be essential for scientific progress; managing-conjectures and research are extraordinarily interdependent terms. Good-guesswork andrationality might even be synonyms.I This paper is supported in part by CICYT, Spain, under projects TIC96-1393-C06 and TIC98-0996-C02-02.(cid:3)Corresponding author. Email: scubillo@fi.upm.es.1 Email: etrillas@fi.upm.es.2 Email: ecastineira@fi.upm.es.0004-3702/00/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 1 0 8 - 32000 Elsevier Science B.V. All rights reserved.\f256E. Trillas et al. / Artificial Intelligence 117 (2000) 255–275Conjectures are formed from preliminary information made explicit in some way orother; from information that is usually acquired by observation or experimentation andwhich constitutes the gross material on the basis of which a conjecture can be formed. Thegross material must be debugged for it to be able to be considered as starting knowledge.The debugged knowledge is often made explicit as a set P of statements or premises and aminimum requirement, which cannot always be immediately met, is that there are no twopremises pi , pj that are contradictory, that is, the conditional statement “If pi , then not-pj ” cannot be considered true. In the other words, the set P of premises should not, ideally,be inconsistent; otherwise, the aforesaid set P can hardly be accepted as representingknowledge.Taking such a body of knowledge P , we seek to arrive at a new statement q, whereby either the knowledge P is inferred from them, they are inferred from P . In the formercase, they are explanatory conjectures and in the latter case, they are inferrable conjectures.In principle, these statements q cannot be contradictory with any or, at least some, of thepremises (in the latter case, it is necessary to consider what to do with the others). Suchstatement q is a conjecture and each one can verify:(1) The statement “if q, then all the premises” is true, and q is a hypothesis of P .(2) The statement “If all the premises, then q” is true, and q is a consequence of P .(3) Neither (1) nor (2), and q is a speculative conjecture of P , a statement that is justnot inconsistent with P .This third type of conjectures will, in turn, have various relationships to P . Any processleading from P to a conjecture q is an induction; if, in particular, q is a hypothesis, itis an abduction or retrodiction, whereas if q is a consequence, it is an inference, whichis a deduction if q can be attained by means of an algorithm or program. In this paper,we seek to formalise both a sufficiently general concept of conjecture and some particularconcepts of hypothesis and consequence. For this purpose, we use a mathematical modelwhich assumes that all the statements are elements of an orthocomplemented lattice,thus encompassing classical and quantic logical calculi. By means of the above model,a preliminary classification is attained of the conjectures and the consequences, whereasthe relationship between the consequences of both a hypothesis and the premises isanalysed. Furthermore, a characterization of the hypotheses is obtained, including anecessary and sufficient condition for their existence. This is merely a preliminary paperpresenting a quite satisfactory provisional framework, in which conjectures, hypothesesand consequences appear as mathematical objects and in which the above conceptscan be addressed as such. Questions such as the computability of the above objects,forms of aggregating preliminary information, stronger ways of defining the concept ofconsequence, or the impact of certainty factors of premises on the different types ofconjectures are not addressed here; these issues will be the subject of subsequent papersconcerning work now under way.1.2.In the following, L will be a complete orthocomplemented lattice (see Section 7),the three operations of L will be represented as (cid:1), C and 0 (intersection, union andcomplementation, respectively), the least element of L as 0 and the greatest element as 1.\fE. Trillas et al. / Artificial Intelligence 117 (2000) 255–275257VIf P is a non-empty part of L, the infimum of P will be represented as p^ Dsupremum as p_ Dthen q^ 6 p^ 6 p_ 6 q_.P and theP ; both exist as L is complete. Obviously, if P (cid:26) Q are parts of L,WThe partial order of L will be denoted by the usual sign 6, “a 6 b if and only if a (cid:1) b D aor a C b D b”, where a < b if a 6 b and a 6D b. Accordingly, 0 6 a 6 1 for every a of L,and any a for which 0 < a < 1 will be called a contingent element of L. A pair of elementsa; b of L may be comparable (a 6 b or b < a) or incomparable, denoted, if applicable, asa NC b or b NC a. Using a 66 b, we denote that there is not a 6 b and, hence, there may beb < a or a NC b; obviously, a 66 b0 is equivalent to b 66 a0.In any lattice L, a 6 b if and only if there exists x 2 L, such that a D b (cid:1) x; indeed, ifa 6 b, then a D a (cid:1) b and x D a, and if a D b (cid:1) x, a 6 b follows. Similarly, a 6 b if andonly if there exists y 2 L, such that b D a C y.Obviously, p^ D 1 is equivalent to p D 1 for any p 2 P . In quite a few results, this is notrestrictive but it is unusual; generally, although not expressly stated unless it is restrictive,p^ is assumed to be contingent. Let us denote the non-empty set of the parts P of L, suchthat p^ 6D 0, as P0.L/, L (cid:0) f0g as L0 and L0 (cid:0) f1g, that is, the set of contingent elements,as L01. We will agree that ; =2 P0.L/.P 2 P0.L/ implies that no element p of P is equal to 0 and that no pair of elementsj , as if it, then pi (cid:1) pj D 0 and p^ D 0; that is, there arepi; pj of P exists such that pi 6 p0no pairs of contradictory elements in P , P is not inconsistent.2. Basic concepts2.1.Let P 2 P0.L/. We will denote as:0gI(cid:8)_.P / D fq 2 LI p_ 66 q(cid:8)^.P / D fq 2 LI p^ 66 q 0gIC_.P / D fq 2 LI p_ 6 qgIC^.P / D fq 2 LI p^ 6 qgIH .P / D fq 2 L0I q 6 p^g:It is clear that none of these sets contains 0; the latter only by definition. With regard to1, it is in the first four, while it is in the last if and only if 1 D p^; hence the new definitionH .P / D fq 2 L01I q 6 p^g is better. We will write H (cid:3).P / D H .P / (cid:0) fp^g. Obviously, ifP D f1g then (cid:8)_.P / D (cid:8)^.P / D L0; H .P / D L01 and C_.P / D C^.P / D f1g. It is clearthat if L is not finite, even if P is, the above sets can be not finite.The choice of P 2 P0.L/ for the above definitions was not made arbitrarily; rememberthat we seek to axiomatize the concepts commonly referred to as conjectures, consequencesand hypotheses (represented initially as the sets (cid:8), C and H , respectively). Thus, thischoice is justified by the following facts:\f258E. Trillas et al. / Artificial Intelligence 117 (2000) 255–275(1) C^.P / D L if and only if p^ D 0. Indeed, if p^ D 0, as for every q 2 L is 0 6 q,then L D C^.P /. Reciprocally, if C^.P / D L, for every q of L is p^ 6 q, thereforep^ D 0.(2) (cid:8)^.P / D ; if and only if p^ D 0. Indeed, if p^ D 0, as for every q 2 L is 0 6 q 0,then q =2 (cid:8)^.P /; that is (cid:8)^.P / D ;. Reciprocally, if (cid:8)^.P / D ;, there exist noq 2 L such that p^ 66 q 0; that is, for every q 2 L, p^ 6 q 0 and hence p^ D 0.(3) H .P / D ; if and only if p^ D 0. Indeed, if H .P / D fq 2 L0I q 6 p^g D ;, then.0; p^U D ;, that is p^ D 0. The reciprocal is obvious.Therefore, the case p^ D 0 is singular. From an inconsistent set of premises, we get allconsequences but neither conjectures nor hypotheses.Note that:(cid:15) If p^ 66 q 0, then for any p 2 P is p 66 q 0, as if for one of them p 6 q 0 thenp^ 6 p 6 q 0.(cid:15) If p_ 66 q 0 for some p 2 P it is p 66 q 0, as if for all p 2 P p 6 q 0 then p_ 6 q 0.(cid:15) If p 6 q for all p 2 P , then p^ 6 q.(cid:15) If p_ 6 q, for all p 2 P is p 6 q as it is p 6 p_.Theorem 2.1. q 2 C^.P / if and only if p^ 2 H .fqg/.Proof. Immediate. 2Theorem 2.2.(a) P (cid:26) C^.P /.(b) C_.P / (cid:26) C^.P / (cid:26) (cid:8)^.P / (cid:26) (cid:8)_.P /.(c) H .P / (cid:26) (cid:8)^.P /.(d) C^.P / \\ H .P / D fp^g.(e) P (cid:26) (cid:8)^.P /.Proof. (a) If p 2 P then p^ 6 p. Hence p 2 C^.P /.(b) (1) If q 2 C_.P / then p_ 6 q, and p^ 6 q follows from p^ 6 p_; hence q 2C^.P /.(2) If q 2 C^.P /, p^ D 0 would follow from p^ 6 q 0; hence p^ 66 q 0 and q 2(cid:8)^.P /.(3) If q 2 (cid:8)^.P / then p^ 66 q 0, and if p_ 6 q 0, p^ 6 q 0 would follow fromp^ 6 p_; hence, p_ 66 q 0 and q 2 (cid:8)_.P /.(c) If q 2 H .P / then q 6 p^, and if p^ 6 q 0, q 6 q 0 and q D 0 would follow; hencep^ 66 q 0 and q 2 (ci",
            {
                "entities": [
                    [
                        42,
                        86,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1498–1507Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQualitative reasoning with directional relations ✩D. Wolter∗, J.H. LeeSFB/TR 8 Spatial Cognition, P.O. Box 330440, Universität Bremen, 28334 Bremen, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 1 September 2009Received in revised form 6 September 2010Accepted 7 September 2010Available online 25 September 2010Keywords:Qualitative spatial reasoningQualitative spatial reasoning (QSR) pursues a symbolic approach to reasoning about aspatial domain. Qualitative calculi are defined to capture domain properties in relationoperations, granting a relation algebraic approach to reasoning. QSR has two primary goals:providing a symbolic model for human common-sense level of reasoning and providingefficient means for reasoning. In this paper, we dismantle the hope for efficient reasoningabout directional information in infinite spatial domains by showing that it is inherentlyhard to decide consistency of a set of constraints that represents positions in the planeby specifying directions from reference objects. We assume that these reference objectsare not fixed but only constrained through directional relations themselves. Known QSRreasoning methods fail to handle this information.© 2010 Elsevier B.V. All rights reserved.1. IntroductionQualitative spatial reasoning (QSR) [1] is the subfield of knowledge representation and symbolic reasoning that representsknowledge about spatial domains by finite sets of named qualitative relations. One particular aim of qualitative approaches isto model human common-sense understanding of space. This makes qualitative approaches useful, for instance, in human–machine interaction. Qualitative reasoning is considered to provide efficient means for reasoning about continuous, infinitebut structured domains such as space or time.Qualitative relations state relationships of variables ranging over a spatial domain. Thus, consistency problems in qual-itative spatial reasoning are closely related to constraint-based reasoning over mostly infinite domains and so QSR sharesmuch of the terminology of constraint-based reasoning. One central task in QSR is to decide consistency of qualitative con-straint networks, i.e., constraint networks in which only qualitative relations are used as constraints. In the following werefer to this problem as the consistency problem. Deciding consistency of qualitative constraint networks differs from classi-cal constraint satisfaction problems (CSP) in that the infinite domain prevents exhaustive search. QSR techniques rely on therelation algebraic structure of qualitative calculi [2] that is captured in converse and composition tables. While reasoning infull qualitative calculi is mostly NP-complete, tractable sub-algebras have been identified for some calculi [3,4].Directional calculi consist of a set of qualitative directional relations that coarsely specify the direction in which an objectis positioned. Positions are considered to be points in the Euclidean plane and directions are given with respect to a frameof reference. Qualitative representations of directional information may involve a single, global frame of reference or theymay employ different frames of reference that are determined by reference objects. In this paper we are concerned withdirectional relations that involve different reference objects, i.e., we are not concerned with cardinal directions that usea single frame of reference and for which reasoning is known to be tractable [5]. Two important examples for reference✩This work was carried out in the framework of the Transregional Collaborative Research Center “Spatial Cognition”, financial support by the DeutscheForschungsgemeinschaft is gratefully acknowledged.* Corresponding author.E-mail addresses: dwolter@sfbtr8.uni-bremen.de (D. Wolter), jay@sfbtr8.uni-bremen.de (J.H. Lee).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.09.004\fD. Wolter, J.H. Lee / Artificial Intelligence 174 (2010) 1498–15071499objects are directed lines (establishing directions “left of” or “right of” the line, for instance) or pairs of points to determinetriangle orientations (see for example [6]). Directional calculi are important for handling knowledge that makes use ofrelative or egocentric frames of references. In particular, directional calculi draw their motivation from tasks in high-levelagent control [7] or from interpreting natural language for robot instruction [8]. In this article we show that reasoning aboutdirectional relations is inherently intractable. By reducing the problem of matroid realizability to the consistency problem weshow that reasoning with directional relations is NP-hard, NP membership being an open question. Our result has impacton reasoning with any qualitative calculus that is expressive enough to distinguish “left of” from “right of” which includesflip-flop [6,9], double cross [10,11], dipole [12], OPRA [13], TPCC [14]. For all such calculi, the existing relation algebraicapproach is too weak for deciding consistency problems and all reasonable sub-algebras remain NP-hard.This paper is organized as follows. First we give basis definitions of qualitative reasoning and discuss related work. InSection 3 we explain the principle steps of our proof. After formally introducing oriented matroids (Section 4) we givein Section 5 new intractability results for several directional calculi. In Section 6 we sketch a new approach to decidingconsistency in directional calculi. We conclude by discussion and outlook.2. Qualitative constraint-based reasoningThe basic concept of qualitative spatial reasoning is the qualitative calculus [2] which comprises a set of qualitative relationsand relation algebraic operations that for many calculi meet conditions for a relation algebra in the sense of Tarski. For thecontext of this paper, only the relations are important.Definition 1 (Qualitative relation). Let D be a non-empty set called domain and let B = {r1, r2, . . . , rn} be a set of k-aryrelations over D. B is called the set of base relations and the set of all unions of base relations R = {| b ∈ 2B } is calledthe set of qualitative relations. Commonly, a qualitative relation ri ∪ r j is denoted {ri, r j}.r∈b(cid:2)Qualitative relations express the relationship of variables ranging over the domain by base relations or disjunctionsthereof.Definition 2 (QCSP). Let R = {r1, r2, . . . , rn} be a set of k-ary qualitative relations over domain D and let X be a set ofvariables ranging over D. A qualitative constraint is a formula X1 . . . Xk−1ri Xk with variables X j ∈ X . For a valuation φ : X →D we say that a qualitative constraint X1 . . . Xk−1 r Xk is satisfied if (φ( X1), φ( X2), . . . , φ( Xk)) ∈ r holds.A qualitative constraint network is a set of variables and constraints such that for any k-tuple of variables exactly oneconstraint is defined. If constraints only involve base relations, it is called a scenario for short.The problem of deciding whether there exists a valuation satisfying all qualitative constraints over a set of qualitativerelations R is called QCSP(R).Qualitative spatial reasoning exploits the algebraic structure of qualitative relations. The consistency problem is tackledusing the algebraic closure algorithm [15], an adaption of Mackworth’s AC-3 algorithm [16] for enforcing path-consistencyin finite domain CSPs. Algebraic closure exploits the composition operation to rule out local inconsistencies in a constraintnetwork. For some calculi algebraic closure implies path-consistency and can already be a sufficient condition for consis-tency [17]. In order to apply decision procedures for the consistency problem it is commonly required that algebraic closureis applicable to decide consistency of scenarios [15,18]. For example, this is the case in the RCC calculus [19] or Allen’sinterval algebra [20]. Given that algebraic closure decides consistency for scenarios, networks involving disjunctions canthen be refined to base relations by means of a backtracking search and consistency can be decided [15]. This approachgains efficiency from exploiting maximal tractable subsets, i.e., maximal sets of relations for which algebraic closure decidesconsistency [21].To put it in a nutshell, qualitative spatial reasoning pursues a relation algebraic approach which relies on the existenceof efficient decision algorithms for consistency of scenarios such that reasoning in the full algebra (i.e., including disjunctiverelations) can still be tackled in NP.Previous research investigating the tractability of directional calculi identified intractable sub-algebras that involve dis-junctions of base relations [11,14,12]. Particularly ternary point calculi are so expressive that encoding NOT-ALL-EQUAL-3-SAT or BETWEENNESS instances is straightforward (cf. [11,22]) when using disjunctions of base relations. In this paperwe significantly refine these results by showing that directional information is inherently intractable, i.e., even decidingconsistency of scenarios is intractable.3. Proof sketchIn the following we describe the general idea of how to show NP-hardness of consistency problems that constrain apoint position to be either left of or right of a line. Essentially, we develop a reduction from a realizability problem incombinatorial geometry to a consistency problem of qualitative constraints. This is captured by the central Theorem 8 thatdirectly applies to all calculi that contain relations “left of” and “right of”. As our reductions are reversible we are also able\f1500D. Wolter, J.H. Lee / Artificial Intelligence 174 (2010) 1498–1507Fig. 1. (a) Steps in the reduction of decision problems about directional information to NP-hard matroid realizability. (b) Projective plane z = 1.to show that if the geometric realizability problem turns out to be in ",
            {
                "entities": [
                    [
                        138,
                        186,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Journal Pre-proofEntropy Estimation via UniformizationZiqiao Ao and Jinglai LiPII:DOI:S0004-3702(23)00100-5https://doi.org/10.1016/j.artint.2023.103954Reference:ARTINT 103954To appear in:Artificial IntelligenceReceived date:4 June 2022Revised date:1 June 2023Accepted date:3 June 2023Please cite this article as: Z. Ao and J. Li, Entropy Estimation via Uniformization, Artificial Intelligence, 103954,doi: https://doi.org/10.1016/j.artint.2023.103954.This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, andformatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting andreview before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that,during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journalpertain.© 2023 Published by Elsevier.\fEntropy Estimation via UniformizationSchool of Mathematics, University of Birmingham, Birmingham B15 2TT, UKZiqiao Ao, Jinglai LiAbstractEntropy estimation is of practical importance in information theory and statis-tical science. Many existing entropy estimators suffer from fast growing esti-mation bias with respect to dimensionality, rendering them unsuitable for high-dimensional problems. In this work we propose a transform-based method forhigh-dimensional entropy estimation, which consists of the following two mainingredients. Firstly, we provide a modified k-nearest neighbors (k-NN) entropyestimator that can reduce estimation bias for samples closely resembling a uni-form distribution. Second we design a normalizing flow based mapping thatpushes samples toward the uniform distribution, and the relation between theentropy of the original samples and the transformed ones is also derived. As aresult the entropy of a given set of samples is estimated by first transformingthem toward the uniform distribution and then applying the proposed estima-tor to the transformed samples. The performance of the proposed method iscompared against several existing entropy estimators, with both mathematicalexamples and real-world applications.Keywords: entropy estimation, k nearest neighbor estimator, normalizing flow,uniformization2010 MSC: 00-01, 99-001. Introduction5Entropy, a fundamental concept in information theory, has found applica-tions in various fields such as physics, statistics, signal processing, and machinelearning. For example, in the statistics and data science contexts, various ap-plications rely critically on the estimation of entropy, including goodness-of-fittesting [1, 2], sensitivity analysis [3], parameter estimation [4, 5], and Bayesianexperimental design [6, 7].In this work we focus on the continuous version of entropy that takes theform,(cid:2)H(X) = −log[px(x)]px(x)dx,(1)Email addresses: zxa029@bham.ac.uk (Ziqiao Ao), j.li.10@bham.ac.uk (Jinglai Li)Preprint submitted to Journal of LATEX TemplatesJune 7, 2023\f101520253035404550where px(x) is the probability density function (PDF) of random variable X.Despite the rather simple definition, entropy only admits an analytical expres-sion for a limited family of distributions and needs to be evaluated numericallyin general. When the distribution of interest is analytically available, in princi-ple its entropy can be estimated by numerical integration schemes such as theMonte Carlo method. However, in many real-world applications, the distribu-tion of interest is not analytically available, and one has to estimate the entropyfrom the realizations drawn from the target distribution, which makes it difficultor even impossible to directly compute the entropy via numerical integration.Entropy estimation has attracted considerable attention from various com-munities in the last a few decades, and numerous methods have been developedto directly estimate entropy from realizations. In this work we only considernon-parametric approaches which do not assume any parametric model of thetarget distribution, and those methods can be broadly classified into two cate-gories. The first class of methods, are known as the plug-in estimators, whichfirst estimate the underlying probability density, and then compute the integralin Eq. (1) using numerical integration or Monte Carlo (see [8] for a detaileddescription). Some examples of density estimation approaches that have beenstudied for plug-in methods are kernel density estimator [9, 10, 11, 12], his-togram estimator [13, 10] and field-theoretic approach [14]. A major limitationof this type of methods is that they rely on an effective density estimation, whichis a difficult problem in its own right, especially when the dimensionality of theproblem is high. A different strategy is to directly estimate the entropy from theindependent samples of the random variable. Popular methods falling in thiscategory include the sample-spacing [15] and the k-nearest neighbors (k-NN)[16, 17] based estimators. The latter is particularly appealing among the exist-ing estimation methods thanks to its theoretical and computational advantagesand has been widely used in practical problems. Efforts have been constantly de-voted to extending and improving the k-NN methods, and some recent variantsand extensions of the methods are [18, 19, 20]. It is also worth mentioning thatthere are many other types of direct entropy estimators available. For example,Ariel and Louzoun [21] decoupled the target entropy to a sum of the entropy ofmarginals, which is estimated using one-dimensional methods, and the entropyof copula, which is estimated recursively by splitting the data along statisticallydependent dimensions. Kandasamy et al.[22] suggested a leave-one-out tech-nique for the von Mises expansion based estimator [23]. We also note that incertain applications the main purpose is to minimize or maximize the quantityof entropy, and in this case entropy gradient estimation strategies [24, 25] havebeen explored to avoid direct entropy estimation.It is well known that, entropy estimation becomes increasingly more diffi-cult as the dimensionality grows, and such difficulty is mainly due to the es-timation bias, which decays very slowly with respect to sample size for high-dimensional problems. For example in many popular approaches including thek-NN method [16], the estimation bias decays at the rate of O(N −γ/d) whereN is the sample size, d is the dimensionality, and γ is a positive constant[26, 22, 27, 28]. As a result, very few, if not none, of the existing entropy2\f5560657075808590estimation methods can effectively handle high-dimensional problems withoutmaking strong assumptions about the smoothness of the underlying distribu-tion [22]. Indeed, the well-known minimax bias results (e.g., [29, 30]) indicatethat without the strong smoothness assumption [22], the curse of dimensional-ity is unavoidable. However, efforts can still be made to reduce the differencebetween the actual estimation bias and the theoretical bound.The main goal of this work is to provide an effective entropy estimationapproach which can achieve faster bias decaying rate under mild smoothnessassumption, and thus can effectively deal with high-dimensional problems. Themethod presented here consists of two main ingredients. First propose two trun-cated k-NN estimators based on those by [16] and [17] respectively, and alsoprovide the bounds of the estimation bias in these estimators. Interestingly ourtheoretical results suggest that the estimators achieve zero bias for uniform dis-tributions, while there is no such a result for any existing k-NN based estimators,according to the bias analysis available to date [27, 31, 32]. This property offersthe possibility to significantly improve the performance of entropy estimationby mapping the data points toward a uniform distribution, a procedure that werefer to as uniformization. Therefore the second main ingredient of the methodis to conduct the uniformization of the data points, with the normalizing flow(NF) technique [33, 34]. Simply speaking, NF constructs a sequence of invertibleand differentiable mappings that transform a simple base distribution such asstandard Gaussian into a more complicated distribution whose density functionmay not be available. Specifically we use the Masked Autoregressive Flow [35],a NF algorithm originally developed for density estimation, combined with theprobability integral transform, to push the original data points towards the uni-form distribution. We then estimate the entropy of the resulting near-uniformdata points with the proposed truncated k-NN estimators, and derive that ofthe original ones accordingly (by adding an entropic correction term due to thetransformation). Therefore, by combining the truncated k-NN estimators andthe normalizing flow model, we are able to decode a complex high-dimensionaldistribution represented by the realizations, and obtain an accurate estimationof its entropy.The rest of the paper is organized as follows. In Section 2, we describe thetraditional k-NN based methods of entropy estimation and their convergenceproperties. In Section 3, we introduce the truncated k-NN estimators for dis-tributions with compact support, and then show how to combine these newestimators with the NF-based uniformization procedure to estimate the entropyof general distributions. Numerical examples and applications are presented inSections 4 and Section 5 respectively to demonstrate the effectiveness of theproposed methods. Finally, in Section 6, we summarize our findings and discusssome future research directions.952. k-NN Based Entropy EstimationWe provide a brief introduction to two commonly used k-NN based entropyestimators in this section. We start with the original k-NN entropy estimator3\f100proposed in [16], where the k-th nearest neighbor is contained in the sma",
            {
                "entities": [
                    [
                        17,
                        54,
                        "TITLE"
                    ],
                    [
                        330,
                        367,
                        "TITLE"
                    ],
                    [
                        1051,
                        1088,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 134 (2002) 9–22Disjoint pattern database heuristicsRichard E. Korf a,∗, Ariel Felner ba Computer Science Department, University of California, Los Angeles, Los Angeles, CA 90095, USAb Department of Mathematics and Computer Science, Bar-Ilan University, Ramat-Gan, 52900 IsraelAbstractWe describe a new technique for designing more accurate admissible heuristic evaluationfunctions, based on pattern databases [J. Culberson, J. Schaeffer, Comput. Intelligence 14 (3)(1998) 318–334]. While many heuristics, such as Manhattan distance, compute the cost of solvingindividual subgoals independently, pattern databases consider the cost of solving multiple subgoalssimultaneously. Existing work on pattern databases allows combining values from different patterndatabases by taking their maximum. If the subgoals can be divided into disjoint subsets so that eachoperator only affects subgoals in one subset, then we can add the pattern-database values for eachsubset, resulting in a more accurate admissible heuristic function. We used this technique to improveperformance on the Fifteen Puzzle by a factor of over 2000, and to find optimal solutions to 50random instances of the Twenty-Four Puzzle.  2002 Elsevier Science B.V. All rights reserved.Keywords: Problem solving; Single-agent search; Heuristic search; Heuristic evaluation functions; Patterndatabases; Sliding-tile puzzles; Fifteen Puzzle; Twenty-Four Puzzle; Rubik’s Cube1. Introduction and overviewThe sliding-tile puzzles are a classic challenge for search algorithms in AI. The key tofinding optimal solutions to these problems is an accurate admissible heuristic function. Wedescribe a generalization of the Manhattan distance heuristic that considers the interactionsamong multiple tiles, while allowing the moves of different groups of tiles to be addedtogether without violating admissibility. This results in a much more accurate admissibleheuristic.* Corresponding author.E-mail addresses: korf@cs.ucla.edu (R.E. Korf), felner@macs.biu.ac.il (A. Felner).0004-3702/02/$ – see front matter  2002 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 0 9 2 - 3\f10R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Fig. 1. The Fifteen and Twenty-Four Puzzles in their goal states.1.1. Sliding-tile puzzlesThe 4 × 4 Fifteen, and 5 × 5 Twenty-Four Puzzles are shown in Fig. 1. A square frame isfilled with tiles, except for one empty or blank position. Any tile horizontally or verticallyadjacent to the blank can be slid into that position. The task is to rearrange the tiles froma given initial configuration into a particular goal configuration, ideally or optimally in aminimum number of moves. The state space for the Fifteen Puzzle space contains about1013 states, and the Twenty-Four Puzzle contains almost 1025 states.The Fifteen Puzzle was invented by Sam Loyd in the 1870s [13], and appeared in thescientific literature shortly thereafter [7]. The editor of the journal added the followingcomment to the paper: “The ‘15’ puzzle for the last few weeks has been prominently beforethe American public, and may safely be said to have engaged the attention of nine out often persons of both sexes and of all ages and conditions of the community”. The reason forthe Fifteen Puzzle craze was that Loyd offered a $1000 cash prize to transform a particularinitial state to a particular goal state. Johnson and Story proved that it wasn’t possible, sincethe state space was divided into even and odd permutations, with no way to transform oneinto the other by legal moves.1.2. Search algorithmsThe 3 × 3 Eight puzzle, with only 181,440 reachable states, can be solved optimally bya brute-force breadth-first search in a fraction of a second.To address the Fifteen Puzzle requires a heuristic search algorithm, such as A∗ [6]. A∗ isa best-first search in which the cost of a node n is computed as f (n) = g(n) + h(n), whereg(n) is the length of the path from the start to node n, and h(n) is a heuristic estimate ofthe length of a shortest path from node n to the goal. If h(n) is admissible, or never overes-timates distance to the goal, then A∗ is guaranteed to find a shortest solution, if one exists.The classic heuristic function for the sliding-tile puzzles is Manhattan distance. For eachtile we count the number of grid units between its current and goal locations, and sum thesevalues for all tiles. Manhattan distance is a lower bound on actual solution length, becauseevery tile must move at least its Manhattan distance, and each move only moves one tileone square.Unfortunately, A∗ cannot solve random instances of the Fifteen Puzzle, because it storesevery node generated, and exhausts the available memory in minutes on most problems.Iterative-Deepening-A∗ (IDA∗) [8] is a linear-space version of A∗. It performs a series ofdepth-first searches, pruning a path when the cost f (n) = g(n) + h(n) of the last node n on\fR.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2211the path exceeds a threshold for that iteration. The threshold is initially set to the heuristicestimate of the initial state, and increases in each iteration to the lowest cost of all nodespruned on the last iteration, until a goal node is expanded. IDA∗ also guarantees an optimalsolution if the heuristic function is admissible. Unlike A∗, however, IDA∗ only requiresmemory that is linear in the maximum search depth. IDA∗ with the Manhattan distanceheuristic was the first algorithm to find optimal solutions to random instances of the FifteenPuzzle [8]. An average of about 400 million nodes are generated per problem instance,requiring almost five hours on a DEC 2060 in 1984.1.3. OverviewOn larger problems, IDA∗ with Manhattan distance takes too long, and more accurateheuristic functions are needed. While Manhattan distance sums the cost of solving eachtile independently, we consider the costs of solving several tiles simultaneously, takinginto account the interactions between them. Our main contribution is to show how heuristicvalues for different groups of tiles can be added together, rather than taking their maximum.We first present existing heuristics, including non-additive pattern databases, using theexample of Rubik’s Cube. Next, we describe disjoint pattern databases, showing how theycan be precomputed, and combined into an admissible heuristic. We then present exper-imental results on the Fifteen and Twenty-Four puzzles, finding optimal solutions to theFifteen Puzzle 2000 times faster than with Manhattan distance, and finding optimal solu-tions to 50 random Twenty-Four Puzzles. Initial results of this work first appeared in [11].2. Existing heuristics2.1. Manhattan distanceWhere did the Manhattan distance heuristic come from? In addition to the standardanswer to this question, we present an alternative that suggests the disjoint pattern databaseextension.The standard explanation for the origin of admissible heuristic functions is that theyrepresent the cost of exact solutions to simplified versions of the original problem [15].For example, in a sliding-tile puzzle, to move a tile from position x to position y, x andy must be adjacent, and position y must be empty. If we ignore the empty constraint, weget a simplified problem where any tile can move to any adjacent position, and multipletiles can occupy the same position. In this new problem, the tiles are independent of eachother, and we can solve any instance optimally by moving each tile along a shortest path toits goal position, counting the number of moves made. The cost of an optimal solution tothis simplified problem is exactly the Manhattan distance from the initial to the goal state.Since we removed a constraint on the moves, any solution to the original problem is alsoa solution to the simplified problem, and the cost of an optimal solution to the simplifiedproblem is a lower bound on the cost of an optimal solution to the original problem. Thus,any heuristic derived in this way is admissible.Alternatively, we can derive Manhattan distance by observing that a sliding-tile puzzlecontains subproblems of getting each tile to its goal location. This suggests considering thecost of solving each subproblem independently, assuming no interactions between them.\f12R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22In other words, we could search for the minimum number of moves needed to get each tileto its goal location, ignoring the other tiles, which is the Manhattan distance of that tile.Since each move only moves one tile, we can add these individual distances together toget an admissible heuristic for the problem. While the first derivation requires a problemdescription in terms of constraints on the legal moves, the second only requires recognizinga single tile as a subproblem.The key idea here, which makes it possible to efficiently compute Manhattan distance,is the assumption that the individual tiles do not interact with one another. The reasonthe problem is difficult, and why Manhattan distance is only a lower bound on actualsolution cost, is that the tiles get in each other’s way. By taking into account some ofthese interactions, we can compute more accurate admissible heuristic functions.2.2. Non-additive pattern databasesPattern databases [1], originally applied to the Fifteen Puzzle, are one way to do this.Fig. 2 shows a subset of the Fifteen Puzzle tiles, called the fringe tiles. For a given state, theminimum number of moves needed to get the fringe tiles to their goal positions, includingrequired moves of other tiles, is a lower bound on the number of moves needed to solve theentire puzzle.This number depends on the current positions of the fringe tiles and the blank, but isindependent of the positions of the other tiles. Thus, we can precompute all these values,store them in memory, and look them up as they are needed during the search. Since thereare seven fringe tiles and one blank, and sixteen different",
            {
                "entities": [
                    [
                        39,
                        75,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 479–499Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRepresenting uncertainty on set-valued variables using belief functionsThierry Denœux∗, Zoulficar Younes, Fahed AbdallahHEUDIASYC, UTC, CNRS, Centre de Recherche de Royallieu, BP 20529, F-60205 Compiègne, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 April 2009Received in revised form 2 February 2010Accepted 3 February 2010Available online 6 February 2010Keywords:Dempster–Shafer theoryEvidence theoryConjunctive knowledgeLatticeUncertain reasoningMulti-label classification1. IntroductionA formalism is proposed for representing uncertain information on set-valued variablesusing the formalism of belief functions. A set-valued variable X on a domain Ω is a variabletaking zero, one or several values in Ω. While defining mass functions on the frame 22Ωis usually not feasible because of the double-exponential complexity involved, we proposean approach based on a definition of a restricted family of subsets of 2Ω that is closedunder intersection and has a lattice structure. Using recent results about belief functionson lattices, we show that most notions from Dempster–Shafer theory can be transposedto that particular lattice, making it possible to express rich knowledge about X with onlylimited additional complexity as compared to the single-valued case. An application tomulti-label classification (in which each learning instance can belong to several classessimultaneously) is demonstrated.© 2010 Elsevier B.V. All rights reserved.An important concept in knowledge representation is that of variable. Usually, we associate to each variable X a domain(or frame of discernment) Ω , and we assume that X takes one and only one value in Ω . For instance, in conventionalclassification problems, X denotes the class of an object, and each object is assumed to belong to one and only one classamong a set Ω of classes.There are cases, however, where it is convenient to consider a variable X taking zero, one or several values in a domainΩ . In such cases, X may be called a set-valued, or conjunctive variable [8,33]. For instance, in diagnosis problems, Ω maydenote the set of faults that can possibly occur in a system, and X the faults actually occurring at a given time. In textclassification, Ω may denote a set of topics, and X the list of topics dealt with in a given text, etc.A straightforward approach to the above problem is, of course, to consider a set-valued variable X on Ω as a single-valued variable on the power set Θ = 2Ω . However, this approach often implies working in a space of very high cardinality.If, as done in this paper, we assume Ω to be finite with size K , then the size of Θ is 2K . If we want to express impreciseinformation about X , we will have to manipulate subsets of Θ . As there are 22Kof these subsets, this approach rapidlybecomes intractable as K increases.In this paper, we consider the problem of representing partial knowledge about a set-valued variable X with domain Ωusing the Dempster–Shafer theory of belief functions [26,30]. Our approach will be based on a simple representation of aclass C(Ω) of subsets of Θ = 2Ω which, endowed with set inclusion, has a lattice structure. Using recent results about belieffunctions on lattices [14], we will be able to generalize most concepts of Dempster–Shafer theory (including the canonicaldecompositions and the cautious rule [5]) in this setting. This formalism will be shown to allow the expression of a widerange of knowledge about set-valued variables, with only a moderate increase of complexity (from 2K to 3K ) as comparedto the usual single-valued case.* Corresponding author. Fax: +33 03 44 23 44 77.E-mail address: tdenoeux@hds.utc.fr (T. Denœux).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.002\f480T. Denœux et al. / Artificial Intelligence 174 (2010) 479–499The rest of this paper is organized as follows. Background notions on belief functions in the classical setting and ingeneral lattices will first be recalled in Sections 2 and 3, respectively. Our approach will then be introduced in Section 4,and some relationships with previous work will be outlined in Section 5. An application to multi-label classification will bepresented in Section 6, and Section 7 will conclude the paper.2. Belief functionsThe basic concepts of the Dempster–Shafer theory of belief functions, as introduced in [26], will first be summarized inSection 2.1. The canonical decomposition and the cautious rule will then be recalled in Section 2.2.2.1. Basic definitionsLet Ω be a finite set. A mass function on Ω is a function m : 2Ω → [0, 1] such that(cid:2)m( A) = 1.A⊆ΩThe subsets A of Ω such that m( A) > 0 are called the focal elements of m. The set of focal elements of m will be denotedF (m). m is said to be normal if ∅ is not a focal element, and dogmatic if Ω is not a focal element.A mass function m is often used to model an agent’s beliefs about a variable X taking a single but ill-known value ω0in Ω [30]. The quantity m( A) is then interpreted as the measure of the belief that is committed exactly to the hypothesisω0 ∈ A. Full certainty corresponds to the case where m({ωk}) = 1 for some ωk ∈ Ω , while total ignorance is modeled by thevacuous mass function verifying m(Ω) = 1. Probabilistic uncertainty corresponds to the case where all focal elements aresingletons, in which case m is equivalent to a probability distribution on Ω .To each mass function m can be associated an implicability function b and a belief function bel defined as follows:(cid:2)b( A) =B⊆ Abel( A) =m(B),(cid:2)m(B) = b( A) − m(∅).(1)(2)B⊆ A,B(cid:2) AThese two functions are equal when m is normal. However, they need to be distinguished when considering non-normalmass functions. Function bel has easier interpretation, as bel( A) corresponds to a degree of belief in the proposition “The truevalue ω0 of X belongs to A”. However, function b has simpler mathematical properties. For instance, m can be recoveredfrom b asm( A) =(−1)| A\\B|b(B),(3)(cid:2)B⊆ Awhere | · | denotes cardinality. Function m is said to be the Möbius transform of b. For every function fsuch that f (Ω) = 1, the following conditions are known to be equivalent [26]:from 2Ω to [0, 1]1. The Möbius transform m of fis positive and verifies(cid:3)A⊆Ω m( A) = 1.2.fis totally monotone, i.e., for any k (cid:2) 2 and for any family A1, . . . , Ak in 2Ω ,(cid:6)(cid:2)Ai(cid:4)fk(cid:5)i=1(cid:2)(−1)|I|+1 f∅(cid:7)=I⊆{1,...,k}(cid:7) (cid:8)(cid:9)Ai.i∈IHence, b (and bel) are totally monotone.Other functions related to m are the plausibility function, defined as(cid:2)pl( A) =m(B)B∩ A(cid:7)=∅= 1 − b( A)and the commonality function (or co-Möbius transform of b) defined asq( A) =(cid:2)m(B).B⊇ Am can be recovered from q using the following relation:m( A) =(−1)|B\\ A|q(B).(cid:2)B⊇ A(4)(5)(6)(7)\fT. Denœux et al. / Artificial Intelligence 174 (2010) 479–499481Functions m, bel, b, pl and q are thus in one-to-one correspondence and can be regarded as different facets of the sameinformation.A special case of interest is that where the focal elements of m are nested: m is then said to be consonant. In this case,we havepl( A ∪ B) = max(cid:10)(cid:11)pl( A), pl(B), ∀ A, B ⊆ Ω.The plausibility function is thus a possibility measure, with corresponding possibility distribution defined by π (x) = pl({x})for all x ∈ Ω . Conversely, to each possibility distribution corresponds a unique consonant mass function [26].Let us now assume that we receive two mass functions m1 and m2 from two distinct sources of information assumed tobe reliable. Then m1 and m2 can be combined using the conjunctive sum (or unnormalized Dempster’s rule of combination)defined as follows:(m1 ∩(cid:12) m2)( A) =(cid:2)m1(B)m2(C).B∩C= A(8)This rule is commutative, associative, and admits the vacuous mass function as neutral element. It is conjunctive as theproduct of m1(B) and m2(C) is transferred to the intersection of B and C . The quantity (m1 ∩(cid:12) m2)(∅) is referred to as thedegree of conflict between m1 and m2.Let q1 ∩(cid:12) 2 denote the commonality function corresponding to m1 ∩(cid:12) m2. It can be computed from q1 and q2, the common-The normalized Dempster’s rule ⊕ [26] is defined as the conjunctive sum followed by a normalization step:ality functions associated to m1 and m2, as follows:q1 ∩(cid:12) 2( A) = q1( A) · q2( A), ∀ A ⊆ Ω.(cid:12)0(m1 ⊕ m2)( A) =(m1 ∩(cid:12) m2)( A)1−(m1 ∩(cid:12) m2)(∅)It is clear that m1 ⊕ m2 is defined as long as (m1 ∩(cid:12) m2)(∅) < 1.if A = ∅,otherwise.the choice of the union operator results in the disjunctive sum [28]:(m1 ∪(cid:12) m2)( A) =It can be shown that(cid:2)m1(B)m2(C).B∪C= Ab1 ∪(cid:12) 2( A) = b1( A) · b2( A), ∀ A ⊆ Ω,Alternatives to the conjunctive sum can be constructed by replacing ∩ by any binary set operation in (8). For instance,(9)(10)(11)(12)which is the counterpart of (9). Dubois and Prade [10] have also proposed a “hybrid” rule intermediate between the con-junctive and disjunctive sums, in which the product m1(B)m2(C) is assigned to B ∩ C whenever B ∩ C (cid:7)= ∅, and to B ∪ Cotherwise. This rule is not associative, but it usually provides a good summary of partially conflicting items of evidence.In [30], Smets proposed a two-level model in which items of evidence are quantified by mass functions and combinedat the credal level, while decisions are made at the pignistic level (from the Latin pignus meaning a bet). Once a decisionhas to be made, a mass function m is thus transformed into a pignistic probability distribution p. The pignistic transformationconsists in normalizing m (assuming that m(∅) < 1), and then distributing each normalized mass m( A)/(1 − m(∅)) equallybetween the atoms ωk ∈ A:(cid:2)p(ωk) ={ A⊆Ω,ωk∈ A}m( A)(1 − m(∅))| A|, ∀ωk ∈ Ω.(13)Other authors have suggested the so-called plausibility transformation fo",
            {
                "entities": [
                    [
                        136,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 875–896www.elsevier.com/locate/artintThe Carneades model of argument and burden of proofThomas F. Gordon a,∗, Henry Prakken b, Douglas Walton ca Fraunhofer FOKUS, Berlin, Germanyb Department of Information and Computing Sciences, Utrecht University,and Faculty of Law, University of Groningen, Utrecht and Groningen, The Netherlandsc Department of Philosophy, University of Winnipeg, Winnipeg, Manitoba, CanadaReceived 8 November 2006; received in revised form 3 April 2007; accepted 16 April 2007Available online 29 April 2007AbstractWe present a formal, mathematical model of argument structure and evaluation, taking seriously the procedural and dialogicalaspects of argumentation. The model applies proof standards to determine the acceptability of statements on an issue-by-issue basis.The model uses different types of premises (ordinary premises, assumptions and exceptions) and information about the dialecticalstatus of statements (stated, questioned, accepted or rejected) to allow the burden of proof to be allocated to the proponent or therespondent, as appropriate, for each premise separately. Our approach allows the burden of proof for a premise to be assigned to adifferent party than the one who has the burden of proving the conclusion of the argument, and also to change the burden of proofor applicable proof standard as the dialogue progresses from stage to stage. Useful for modeling legal dialogues, the burden ofproduction and burden of persuasion can be handled separately, with a different responsible party and applicable proof standard foreach. Carneades enables critical questions of argumentation schemes to be modeled as additional premises, using premise types tocapture the varying effect on the burden of proof of different kinds of questions.© 2007 Elsevier B.V. All rights reserved.Keywords: Argument structure; Argument graphs; Argument evaluation; Argumentation schemes; Burden of proof; Proof standards; Legalargument1. IntroductionThis article presents a functional model of the evaluation of commonsense arguments, taking seriously the proce-dural and dialogical aspects of argumentation. The model, called Carneades in honor of the Greek skeptic philosopherwho emphasized the importance of plausible reasoning [9, vol. 1, p. 33–34], applies proof standards [10] to determinethe acceptability of statements on an issue-by-issue basis. The model has been implemented using a functional pro-gramming language. This system, also called Carneades, supports a range of argumentation tasks, including argumentreconstruction, evaluation and visualization.Carneades is meant to overcome several limitations of current ‘mainstream’ AI work on argumentation. The main-stream approach essentially regards the problem of argument evaluation to be a question of defining the appropriate* Corresponding author.E-mail addresses: thomas.gordon@fokus.fraunhofer.de (T.F. Gordon), henry@cs.uu.nl (H. Prakken), d.walton@uwinnipeg.ca (D. Walton).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.010\f876T.F. Gordon et al. / Artificial Intelligence 171 (2007) 875–896(non-monotonic) relation between sets of statements: a statement ‘follows’ from a set of statements if an argumentfor it can be constructed that survives all attacks by counterarguments that can be constructed from the same set ofstatements. (This idea can be refined in various ways but that is not the issue here.) This ‘relational’ approach ignoresthat arguments are embedded in a procedural context, in that they can be seen as having been put forward on oneside or the other of an issue during a dialogue between (human and/or artificial) agents. This dialogical context mustbe taken into account when evaluating arguments. The information provided by a dialogue for constructing and eval-uating arguments is richer than just a set of sentences. The context can tell us whether some party has questionedor conceded a statement, or whether a decision has been taken, perhaps by a third party, to accept or reject a claim,taking into consideration the arguments which have been made. Such decisions may be taken at intermediate states ofthe dialogue, for example when some alternatives are eliminated after brainstorming during a deliberation. Moreover,the dialogue context may provide information about the allocation of the burden of proof for each statement. Legalapplications may require the burden of production and burden of persuasion to be handled separately, with a differentresponsible party and applicable proof standard for each [35]. This allocation may well change over the course of thedialogue. In the law of civil procedure, for example, the burden of proof may be allocated to the party who has thebetter access to the evidence. Finally, the proof standard may depend on the phase of the dialogue. For example, aweak proof standard may be appropriate during the brainstorming phase of a deliberation or during the pleading phaseof a legal conflict.The Carneades model has been designed to be applied in such rich dialogical contexts. The evaluation of argumentsin Carneades depends on whether statements have been questioned or decided; the allocation of the burden of proof;and the proof standard applicable to questioned statements. All these elements depend on the stage and context of thedialogue in which the arguments have been put forward.An influential classification of dialogue types is that of Walton and Krabbe [51]. For present purposes their dis-tinction between persuasion and deliberation dialogue is especially relevant. The goal of a deliberation dialogue is tosolve a problem while the goal of a persuasion dialogue is to test whether a claim is acceptable. The present versionof Carneades is meant to support persuasion dialogues. In such dialogues, two or more participants try to resolve adifference of opinion by arguing about the tenability of a claim, each trying to persuade the other participants to adopttheir point of view. Dialogue systems regulate such things as the preconditions and effects of speech acts, includingtheir effects on the commitments of the participants, as well as criteria for terminating the dialogue and determiningits outcome. Good dialogue systems regulate all this in such a way that conflicting viewpoints can be resolved in away that is both fair and effective [24].It is important to note that although Carneades has been designed to be embedded in a procedural context, itdoes not itself define a dialogue protocol. No roles, speech acts, termination criteria, or procedural rules are defined.Instead Carneades is intended to be a reusable component providing services generally needed when specifying suchargumentation protocols.In line with prior AI research, arguments in Carneades are defeasible, i.e., arguments can be defeated by counterar-guments. The Carneades model of defeasible argument is founded on Walton’s theory of argumentation schemes [48].Argumentation schemes express reasoning policies, i.e. conventional patterns of reasoning, and thus are dependent onthe norms of the community. Arguments in Carneades are designed to model instantiations of argumentation schemes.Besides being defeasible, argumentation schemes have a dialogical aspect in that they come with a set of critical ques-tions [20], which enumerate ways of challenging arguments created using the scheme. Critical questions differ withregard to their impact on the burden of proof [3,43]. For some critical questions, merely asking the question is enoughto shift the burden of proof back to the party who put forward the argument to answer the question. For other criticalquestions, the party who raised the question also has the burden of answering it. Carneades models critical questionsas additional premises of an argument, with a different type of premise, called assumptions and exceptions, for eachkind of question.1The Carneades model is the latest result of a research effort that started with the Pleadings Game [14], a com-putational model of civil pleading in Anglo-American Law. Besides a dialogue protocol, the Pleadings Game also1 In an earlier version of Carneades, as reported in [17], assumptions were called ‘presumptions’. This usage however conflicted with the meaningof ‘presumption’ in our main intended application field, the legal domain. In the law, merely questioning a legal presumption is not enough to shiftthe burden of proof to the other party; the burden of proof is on the party interested in rebutting the presumption. For example, the presumption ofinnocence in criminal cases places the burden on the prosecution to prove guilt.\fT.F. Gordon et al. / Artificial Intelligence 171 (2007) 875–896877included a component for evaluating arguments in states of a dialogue. Like Carneades, the status of statements in thedialogue state was taken into account by this evaluation. (Burden of proof and proof standards were not modeled in thePleadings Game.) Whereas statements and arguments were modeled in the Pleadings Game using a specific logicalcalculus, Geffner’s logic of Conditional Entailment [12], Carneades is designed to be an open integration frameworkfor various kinds of argumentation schemes, using whatever kind of knowledge representation is appropriate for eachkind of scheme. Thus, like Dung’s abstract model of argument [8], Carneades does not depend on a particular logicallanguage for expressing statements, inference rules or argumentation schemes.Another ancestor of Carneades is Zeno [15], an argumentation model based on Horst Rittel’s idea of an Issue-BasedInformation System (IBIS) [38]. In IBIS, issues can be raised, ideas to resolve them can be proposed and arguments proand con the various ideas can be put forward. Zeno was intended to be simple enough for use in web-based mediationsystems and targeted to support practical decisions in deliberation dialogues, about what action to take. Later versi",
            {
                "entities": [
                    [
                        72,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 619–641www.elsevier.com/locate/artintArgumentation in artificial intelligenceT.J.M. Bench-Capon, Paul E. Dunne ∗Department of Computer Science, University of Liverpool, Liverpool, United KingdomReceived 27 April 2007; received in revised form 27 April 2007; accepted 1 May 2007Available online 10 May 2007AbstractOver the last ten years, argumentation has come to be increasingly central as a core study within Artificial Intelligence (AI). Thearticles forming this volume reflect a variety of important trends, developments, and applications covering a range of current topicsrelating to the theory and applications of argumentation. Our aims in this introduction are, firstly, to place these contributions in thecontext of the historical foundations of argumentation in AI and, subsequently, to discuss a number of themes that have emergedin recent years resulting in a significant broadening of the areas in which argumentation based methods are used. We begin bypresenting a brief overview of the issues of interest within the classical study of argumentation: in particular, its relationship—in terms of both similarities and important differences—to traditional concepts of logical reasoning and mathematical proof. Wecontinue by outlining how a number of foundational contributions provided the basis for the formulation of argumentation modelsand their promotion in AI related settings and then consider a number of new themes that have emerged in recent years, many ofwhich provide the principal topics of the research presented in this volume.© 2007 Elsevier B.V. All rights reserved.Keywords: Argumentation models; Dialogue processes; Argument diagrams and schemes; Agent-based negotiation; Practical reasoning1. IntroductionIn its classical treatment within philosophy, the study of argumentation may, informally, be considered as concernedwith how assertions are proposed, discussed, and resolved in the context of issues upon which several divergingopinions may be held. Thus philosophical investigations of argumentation, from Aristotle to the present day, haveaddressed such themes as: the mechanisms by which “legitimate” argumentation in support of a claim may be dis-tinguished from “flawed” argumentation; analyses of the typical structures that constitute argument components andargumentation development; the processes by which participants engaging in debate may advance their respectivepositions and undermine contrary stances and arguments, etc; and the contexts in which these questions are decided.The importance of such philosophical theories to so-called everyday reasoning has a long and distinguished historyin AI, and contributions from contemporary philosophical analyses continue to play a major role in the evolution ofeffective computational exploitation of argumentation technology.Within the simplified overview of argumentation outlined in the preceding paragraph, one can, already, identify anumber of themes whose elements embody issues of a computational nature in the following:* Corresponding author.E-mail address: ped@csc.liv.ac.uk (P.E. Dunne).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.001\f620T.J.M. Bench-Capon, P.E. Dunne / Artificial Intelligence 171 (2007) 619–641• Defining the component parts of an argument and their interaction.• Identifying rules and protocols describing argumentation processes.• Distinguishing legitimate from invalid arguments.• Determining conditions under which further discussion is redundant.It is, of course, the case that similar issues underpin one well-established and highly-developed theory: that of formallogic and mathematical proof. It is no coincidence that much of the formal computational treatment of argumentationhas its roots in ideas developed from AI inspired contributions to logic and deductive reasoning. So one finds inmathematical proof theory core concepts such as: precisely defined means for expressing assertions (e.g. formulaein a given logical language); accepted bases on which to build theorems (e.g. collections of axioms); proceduresprescribing the means by which further theorems may be derived from existing theorems and axioms (e.g. templatesfor inference rules); and precise concepts of termination (e.g. a sentential form is derivable as a theorem, “true”; or islogically invalid, “false”).While the structural elements presented in this view of mathematical reasoning have proven to be a useful basis inthe development of argumentation-based models in AI, the formal apparatus and methods of mathematical reasoningare, ultimately, radically different in nature to those of importance when considering the concept of argumentationas it is familiar from everyday contexts, e.g. as it might occur in political debate, the discussion of ethical principles,deliberation in judicial settings, etc. While there are, of course, parallels that can be made,—e.g. that those engagedin debate have some collection of accepted premises on which there is agreement, possibly, even, some recognition ofwhen contributions to a discussion are “unreasonable” or flawed, etc.—there are, however, a number of fundamentaldistinctions between the concepts “P is a formal proof that T holds” and “P is a persuasive argument for accepting T ”.Thus, in mathematical reasoning,(a) The premises can, ultimately, be explicitly defined in terms of closed concepts, e.g. the axioms of Euclideangeometry, the Zermelo–Frankel basis for set theory (ZF). Furthermore classical mathematical reasoning is basedon an assumption that such premises are, collectively, consistent.1(b) Reasoning and analysis takes place within a closed, tightly defined context, i.e. there is no notion of “incomplete”or “uncertain” information.(c) Conclusions are final and definite: if P is a correct proof that T , then T is, ipso facto valid and this status doesnot admit subsequent qualification or amendment, let alone retraction.(d) Reasoning and conclusions are entirely objective, not susceptible to rational dispute on the basis of subjectiveviews and prejudices.2 Proof is demonstration whereas argument is persuasion.In argument and discussion as encountered in everyday contexts, it is rare that any, let alone all, of these apply:the premises upon which debates may build are often presupposed as forming part of the background assumptionscommon to all parties involved; the information and knowledge brought to bear in the course of discussion willoften be incomplete, vague, or uncertain. The remaining two aspects, in many ways, highlight the most significantdifferences between “logical proof” and “persuasive argument”. Arguments are defeasible: the reasoning that formeda persuasive case for T , in the light of changes in viewpoint or awareness of information not previously available, maysubsequently fail to convince. This defeasibility is never removed: an argument may cease to be challenged and soaccepted, but the possibility of challenge remains. Finally, the extent to which an argued case is accepted is subjective,dependent on the views, attitudes, and prejudices of the audiences to which it is directed. The same case may convincesome people but, equally, fail to convince others.1 We note that in a number of systems, consistency cannot be formally proven, cf. [95] and so, in such cases, consistency is, indeed, an assumption.2 Some clarification of this claim may be in order. Suppose (cid:2) is a derivation of ϕ within a theory (cid:3)A, R(cid:4) (with axioms A and inference rules R).Within the same theory, the proof (cid:2) admits no rational, objective basis for dispute: criticisms that “ϕ is ‘inconvenient’ or ‘counter-intuitive’ ” aresubjective, and entirely irrelevant to the status of ϕ within the theory (cid:3)A, R(cid:4). In order to give rational grounds for not accepting ϕ it is necessary toendorse an alternative theory within which ϕ cannot be derived. As a concrete example, consider the axiomatic basis ZF extended by the so-called“Axiom of Choice” (ZF + AC): although widely adopted in modern theory this conflicts with Intuitionist principles which disqualify AC as an axiomso that theorems dependent on AC are (rationally) not accepted by Intuitionists.\fT.J.M. Bench-Capon, P.E. Dunne / Artificial Intelligence 171 (2007) 619–641621One can summarise the distinction between argumentation and proof by the observation that the object of argu-mentation is to persuade (to acceptance of a given claim; to performance of a desired action, and so on). Unlike theconcept of “proof”—at the level of deriving a sentential representation of an assertion—whether an argument is “cor-rect” is not a factor, and, indeed, “correctness” may not even be sensibly defined. In contrast, mathematical reasoning,in order to have any value, must be correct where “correctness” has a strict, formal definition: beyond this requirement,however, notions of “persuasiveness” are unimportant.In summary, the importation of elements from logic and formal deductive reasoning has provided a powerful basisfor modelling and analysing argumentation in computational settings of AI. As we shall discuss later, these continueto form an important strand of contemporary work. It is also the case, however, that a number of significant direc-tions pursued in recent years, have broadened the scope and concerns of argumentation in AI beyond this earlierlogic driven motivation. As a consequence, one has a shift of emphasis within the developed treatment of argumen-tation in AI progressing from formalisms rooted in classical deductive reasoning through models handling conceptsof incomplete information and uncertainty, to precise semantics for capturing defeasibility, and, within recent work,propounding computational bases to account for subjective aspects of argumentation, often using the notion of “au-dience” introduced by Perelman [145]. One consequence of such analyses has been the growth of work dealing w",
            {
                "entities": [
                    [
                        72,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVI.ER Artificial Intelligence 83 (1996) l-58 Artificial Intelligence Measures of uncertainty in expert systems Peter Walley * Department of Mathematics, The Universiry of Western Australia, Nedlands, WA 6907, Australia Received April 1991; revised January 1995 Abstract This paper compares four measures that have been advocated as models for uncertainty in expert systems. The measures are additive probabilities (used in the Bayesian theory), coherent lower (or upper) previsions, belief functions (used in the Dempster-Shafer theory) and possibil- ity measures (fuzzy logic). Special emphasis is given to the theory of coherent lower previsions, in which upper and lower probabilities, expectations and conditional probabilities are constructed from initia I assessments through a technique of natural extension. Mathematically, all the measures can be regarded as types of coherent lower or upper previsions, and this perspective gives some insight into the properties of belief functions and possibility measures. The measures are eval- uated according to six criteria: clarity of interpretation; ability to model partial information and imprecise assessments, especially judgements expressed in natural language; rules for combining and updating uncertainty, and their justification; consistency of models and inferences; feasibility of assessment; and feasibility of computations. Each of the four measures seems to be useful in special kinds of problems, but only lower and upper previsions appear to be sufficiently general to model t.he most common types of uncertainty. Keywords: Possibility lndependerlce Inference; Decision; Prevision; Bayesian theory; Lower probability; Upper probability; theory; Dempster-Shafer theory; Belief functions; Imprecise probabilities; Conditional probability; 1. Introduction My aim in this paper tainty that can be used in expert systems. The measures probabilities, cial emplhasis lower previsions, belief functions to the theory of coherent is to compare and evaluate mathematical measures of uncer- that I will consider are Bayesian and possibility measures. Spe- as this approach has coherent is given lower previsions * E-mail: peter@maths.uwa.edu.au. 0004-3702/96/$15.00 SSDf 0004-3702(95)00009-7 @ 1996 Elsevier Science B.V. All rights reserved \f2 P Walley/ArtQicial intelligence 83 (1996) I-58 comparisons interpretation less attention in the AI literature, although level, than the others received the one that is most widely applicable. On a mathematical can be regarded as special the behavioural some illuminating For example, it is (in my view) the other measures types of lower or upper previsions. They can also be given of lower or upper previsions. This point of view leads to they use for defining, the four theories differ greatly the rules they use to define updating and combining measures of uncertainty, conditional of indepen- dence. The rules used in the theory of lower previsions, which are based on a general procedure and possibility can be applied measures, in Dempster-Shafer thus theory and possibility called natural &ension, and in the calculus especially and how they model judgements they can be compared with and expectations the rules used the theories. probabilities to belief functions between theory. to be a wide-ranging and quickly growing in expert systems. References between probability measures, belief to be a survey of the four theories from a neutral position survey of mathematical models for literature on numerical measures to the and possibility measures. in [ 8,3 1,79,86,89] The paper is not intended and it is certainly not intended uncertainty. There is a substantial of uncertainty relationships Readers can learn more about the subject by consulting and the proceedings of the annual workshops on Uncertainty shall not discuss non-numerical methods of reasoning with uncertainty of endorsements parative probability approaches can be found I take it for granted I Intelligence. such as the theory com- [59,104]. Surveys of the non-numerical [ 27,104] and modal logics [ 131, default reasoning are good introductions and nonmonotonic [ 59,63,67,68], in [47,79,86]. in Artificial the surveys [46,47,88] functions logics that most practical reasoning information, involves uncertainty, partial ignorance to formally model to make inferences and that it is often useful and decisions? These questions (a) what is the best way to model uncertainty? and incomplete or conflicting the uncertainty. This raises the questions (b) how should we assess, combine and update measures of uncertainty? should we use the measures relevant expert systems are an especially good testing-ground they aim to formalise an expert system to formulate appropriate domain experts and these assessments required to supply guide him through and (c) how are to all kinds of reasoning with uncertainty, not only in expert systems. However for theories of uncertainty because and automate as much as possible of the reasoning process. As it is possible strategies, models and patterns of reasoning which are can be assessed by in the system. A user may be but the expert system should be able to some further assessments this process. is concerned only with a narrow domain of application, to that application. Many of the relevant uncertainties special assessment can be encoded The measures of uncertainty that are combined in an expert system may come from or there may be statistical models. the frequency of a disease various sources. Some may be “objective” measures, based on relative on well established data concerning between a symptom and a disease.) Other assessments of uncertainty may be supplied by the domain expert (e.g., concerning in diagnosis, or the association between a symptom and a disease when there is little statistical data). the system. Further assessments Indeed several experts may have contributed the irrelevance of specific observations or the statistical association (In medical diagnosis, in a population, for example, frequencies in building \fI! Walley/Art@cial Intelligence 83 (1996) l-58 3 may be made by the user of the system exhibited by a patient). All the expert system patient). What, inferences to make (e.g. about the uncertainties in the symptoms these measures of uncertainty and decisions (e.g. to make a diagnosis need to be combined by for this assessments that its uncertainty the expert system as a consultant elicits others from the user, combines the user “if you accept all these judgements then, is the meaning of the combined measures of uncertainty? Whose uncer- It is the user of the system who will act on the conclusions tainties do they measure? are acceptable of the system, provided he is satisfied that supplies various models to him. One can regard and finally and assessments, informs then you should draw these con- clusions”. So the expert system constructs a single model for uncertainty which the user and as a basis for action. then considers and its rea- The expert system should be able to justify soning procedures, when requested by the user, to make its model and conclusions more convincing. and assessments It should also be able to modify some of its assumptions if requeste:d by the user. In the end, the uncertainty measures on which conclusions based mus,t be acceptable its assessments of uncertainty for his own uncertainty adopting as a model all the judgements, to the user. are 2. Criteria for evaluating measures of uncertainty In the rest of this paper I will compare measures of uncertainty according to the following broad criteria. (a) (b) to be used to guide assessment, Intl?);pretution. The measure should have a clear interpretation definite system and use them as a basis for action, and to support the rules for combining and updating measures. Imprecision. The measure should be able to model partial or complete limited or conflicting and imprecise assessments of uncertainty. that is sufficiently the conclusions to understand information, ignorance, of the (c) Culculus. There should be rules for combining measures of uncertainty, updating them to calculate other uncer- and to make decisions. Some justification must be and using them after receiving new information, tainties, to draw conclusions given conditional probabilities (d) Cortsistency. There should be methods and expectations for the rules. Special attention will be given to the rules for computing and default assumptions should ensure that the conclusions tainty assessments the calculus ments. notion of consistency In the Bayesian theory and the theory of lower previsions, is formalised in mathematical principles of coherence. from unconditional probabilities. for checking the consistency of all uncer- used by the system, and the rules of are consistent with these assess- the intuitive (e) Assessment. for a user of the system It should be practicable comfortable with) all the uncertainty system should give some guidance on how to make the assessments. able to handle judgements in natural language judgements with quantitative expressions of uncertainty such as “if A then probably B”, and to combine qualitative to make (and feel that are needed as input. The It should be assessments of uncertainty. types, including assessments of various \fP Walley/Artijicial Intelligence 83 (1996) 1-58 It should be computationally feasible for the system to derive and conclusions from the assessments. (f) Computation. inferences Readers may wish to attempt to add other desiderata to this list. It does seem for a theory of uncertainty the first four criteria, which are theoretical, to me that it to satisfy all six criteria. We might the last two, which are in the sense that one would expect an irrespective of the in the sense that they will be in some applications but not in others, depending on the type of model involved, needed, practical constraints of time and computing power, is essential distinguish practical. The first four criter",
            {
                "entities": [
                    [
                        73,
                        114,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 6–29Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMiningZinc: A declarative framework for constraint-based miningTias Guns a,∗a Department of Computer Science, KU Leuven, Belgiumb LIACS, Universiteit Leiden, Netherlandsc Faculty of IT, Monash University, National ICT Australia (NICTA), Australia, Anton Dries a, Siegfried Nijssen a,b, Guido Tack c, Luc De Raedt aa r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 17 September 2015Accepted 20 September 2015Available online 26 September 2015Keywords:Constraint-based miningItemset miningConstraint programmingDeclarative modelingPattern miningWe introduce MiningZinc, a declarative framework for constraint-based data mining. MiningZinc consists of two key components: a language component and an execution mechanism.First, the MiningZinc language allows for high-level and natural modeling of mining problems, so that MiningZinc models are similar to the mathematical definitions used in the literature. It is inspired by the Zinc family of languages and systems and supports user-defined constraints and functions.Secondly, the MiningZinc execution mechanism specifies how to compute solutions for the models. It is solver independent and supports both standard constraint solvers and specialized data mining systems. The high-level problem specification is first translated into a normalized constraint language (FlatZinc). Rewrite rules are then used to add redundant constraints or solve subproblems using specialized data mining algorithms or generic constraint programming solvers. Given a model, different execution strategies are automatically extracted that correspond to different sequences of algorithms to run. Optimized data mining algorithms, specialized processing routines and generic solvers can all be automatically combined.Thus, the MiningZinc language allows one to model constraint-based itemset mining problems in a solver independent way, and its execution mechanism can automatically chain different algorithms and solvers. This leads to a unique combination of declarative modeling with high-performance solving.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe fields of data mining and constraint programming are amongst the most successful subfields of artificial intelligence. Significant progress in the past few years has resulted in important theoretical insights as well as the development of effec-tive algorithms, techniques, and systems that have enabled numerous applications in science, society, as well as industry. In recent years, there has been an increased interest in approaches that combine or integrate principles of these two fields [1]. This paper intends to contribute towards bridging this gap.* Corresponding author.(S. Nijssen), guido.tack@monash.edu (G. Tack), luc.deraedt@cs.kuleuven.be (L. De Raedt).E-mail addresses: tias.guns@cs.kuleuven.be (T. Guns), anton.dries@cs.kuleuven.be (A. Dries), siegfried.nijssen@cs.kuleuven.be, s.nijssen@liacs.leidenuniv.nlhttp://dx.doi.org/10.1016/j.artint.2015.09.0070004-3702/© 2015 Elsevier B.V. All rights reserved.\fT. Guns et al. / Artificial Intelligence 244 (2017) 6–297It is motivated by the observation that the methodologies of constraint programming and data mining are quite dif-ferent. Constraint programming has focused on a declarative modeling and solving approach of constraint satisfaction and optimization problems. Here, a problem is specified through a so-called model consisting of the variables of interest and the possible values they can take, the constraints that need to be satisfied, and possibly an optimization function. Solutions are then computed using a general purpose solver on the model. Thus the user specifies what the problem is and the constraint programming system determines how to solve the problem. This can be summarized by the slogan constraint programming = model + solver(s).The declarative constraint programming approach contrasts with the typical procedural approach to data mining. The latter has focused on handling large and complex datasets that arise in particular applications, often focusing on special-purpose algorithms to specific problems. This typically yields complex code that is not only hard to develop but also to reuse in other applications. Data mining has devoted less attention than constraint programming to the issue of general and generic solution strategies. Today, there is only little support for formalizing a mining task and capturing a problem specification in a declarative way. Developing and implementing the algorithms is labor intensive with only limited re-use of software. The typical iterative nature of the knowledge-discovery cycle [2] further complicates this process, as the problem specification may change between iterations, which may in turn require changes to the algorithms.The aim of this paper is to contribute to bridging the methodological gap between the fields of data mining and con-straint programming by applying the model + solver approach to data mining.In constraint programming, high-level languages such as Zinc [3], Essence [4] and OPL [5] are used to model the problem while general purpose solvers are used to compute the solutions. Motivated in particular by solver-independent modeling languages, we devise a modeling language for data mining problems that can be expressed as constraint satisfaction or optimization problems. Furthermore, we contribute an accompanying framework that can infer efficient execution strategies involving both specialized mining systems, and generic constraint solvers. This should contribute to making data mining approaches more flexible and declarative, as it becomes easy to change the model and to reuse existing algorithms and solvers.As the field of data mining is diverse, we focus in this paper on one of the most popular tasks, namely, constraint-based pattern mining. Even for the restricted data type of sets and binary databases, many settings (supervised and unsuper-vised) and corresponding systems have been proposed in the literature; this makes itemset mining an ideal showcase for a declarative approach to data mining.The key contribution of this paper is the introduction of a general-purpose, declarative mining framework called Min-ingZinc. The design criteria for MiningZinc are:• to support the high-level and natural modeling of pattern mining tasks; that is, MiningZinc models should closely corre-spond to the definitions of data mining problems found in the literature;• to support user-defined constraints and criteria such that common elements and building blocks can be abstracted away, easing the formulation of existing problems and variations thereof;• to be solver-independent, such that the best execution strategy can be selected for the problem and data at hand. Supported methods should include both general purpose solvers, specialized efficient mining algorithms and combinations thereof;• to build on and extend existing constraint programming and data mining techniques, capitalizing on and extending the state-of-the-art in these fields.In data mining, to date there is no other framework that supports these four design criteria. Especially the combination of user-defined constraints and solver-independence is uncommon (we defer a detailed discussion of related work to Section 6). In the constraint programming community, however, the design of the Zinc [3,6] family of languages and frameworks is in line with the above criteria. The main question that we answer in this paper is hence how to extend this framework to support constraint-based pattern mining.We contribute:1. a novel library of functions and constraints in the MiniZinc language, to support modeling itemset mining tasks in terms of set operations and constraints;2. the ability to define the capabilities of generic solvers and specialized algorithms in terms of constraints, where the latter can solve a predefined combination of constraints over input and output variables;3. a rewrite mechanism that can be used to add redundant constraints and determine the applicability of the defined algorithms and solvers;4. and automatic composition of execution strategies involving multiple such specialized or generic solving methods.The language used is MiniZinc [7] version 2.0, extended with a library of functions and constraints tailored for pattern mining. The execution mechanism, however, is much more elaborate than that of standard MiniZinc. For a specific constraint solver, it will translate each constraint individually to a constraint supported by said solver. Our method can automatically compose execution strategies with multiple solvers.\f8T. Guns et al. / Artificial Intelligence 244 (2017) 6–29The MiningZinc framework builds on our earlier CP4IM framework [8], which showed the feasibility of constraint pro-gramming for pattern mining. This work started from the modeling experience obtained with CP4IM, but the latter contained none of the above contributions as it was tied to the Gecode solver and consisted of a low-level encoding of the constraints.The present paper extends our earlier publication on MiningZinc [9] in many respects. It considers the modeling and solving of a wider range of data mining tasks including numeric and probabilistic data, multiple databases and pattern sets. The biggest change is in the execution mechanism, which is no longer restricted to using a single algorithm or generic solver. Instead, it uses rewrite rules to automatically construct execution plans consisting of multiple solver/algorithm components. We also perform a more elaborate evaluation, including a comparison of automatically composed execution strategies on a novel combination of tasks.Structure of the text Section 2 introduces modeling in MiningZinc using the basic problem of frequent itemset mining. Section 3 illustrates how a wide range of c",
            {
                "entities": [
                    [
                        133,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "A&i&l Intelligence 75 ( 1995) 63-92 Artificial Intelligence CLIP: concept learning from inference patterns Ken’ichi Yoshida *, Hiroshi Motoda Advanced Research Laboratory. Hitachi, Ltd., Hatoyama, Saitama, 350-03 Japan Abstract A new concept-learning method called CLIP (concept learning from inference patterns) is proposed that learns new concepts from inference patterns, not from positive/negative examples that most conventional concept learning methods use. The learned concepts enable an efficient inference on a more abstract level. We use a colored digraph to represent inference patterns. The is expressive enough and enables the quantitative analysis of the inference graph representation pattern frequency. The learning process consists of the following two steps: ( 1) Convert the original inference patterns to a colored digraph, and (2) Extract a set of typical patterns which appears frequently in the digraph. The basic idea is that the smaller the digraph becomes, the smaller the amount of data to be handled becomes and, accordingly, the more efficient the inference process that uses these data. Also, we can reduce the size of the graph by replacing each frequently appearing graph pattern with a single node, and each reduced node represents a new concept. Experimentally, CLIP automatically generates multilevel representations from a given physical/single-level representation of a carry-chain circuit. These representations involve abstract descriptions of the circuit, such as mathematical and logical descriptions. 1. Introduction Human beings use various abstract concepts, such as logic and mathematics, to ac- quire new knowledge. These concepts are crucial to achieve scientific and technical breakthroughs. We also use various concepts in daily life. For example, we sometimes complain, He is too stubborn CO negotiate. In this case, stubborn represents a certain characteristic of the person, and we can deduce some conclusion, such as Find another person to discuss the problem, without considering the details. How do human beings acquire these “concepts”? * Corresponding author. OOO4-3702/95/$G9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00066-2 \f64 K. Yoshidu. H. Motodu/ArtiJiicial Intelligence 75 (1995) 63-92 Cin Fig. I. Carrychain circuit some answer to this question and representing it on a computer system is an Finding important theme in artificial this question intelligence. in more detail, we use qualitative [4] circuit simulation simulation To examine all displaying the qualitative the dependency information, among in current, voltage, etc. Note that Figs. 2(a), 2(b) them being is randomly generated, example of the concept utilization. Fig. 1 shows a carry-chain of the CPU, and Fig. 2 shows i.e., the changes the same difference each datum from other data. In Fig. 2(b), The X-axis mythical words, Fig. 2(b) uses some knowledge shown in Fig. 2(a). Fig. 2(c) also uses specific knowledge about the carry-chain here, the NOT circuit data are located circuit data are located below. traces as an [9] which is part results of its behavior, show and 2(c) the only the location of is calculated the spatial allocation of the data is selected by hand. from along with the name of the data. In other to lay out the data circuit, in the upper portion of the figure, and the NOR in the layout of the data. In Fig. 2(a), and the arrows display how a datum [4], and the Y-axis is sorted using about qualitative simulation is sorted using the data, with the simulation the time-step information causality among Which jigure is best.7 in which Fig. 2(a) imagine a situation the data dependency between is the best figure. It seems to be the best in various situations, the data or to memorize We think Fig. 2(c) to explain cannot Fig. 2 shows are for the physical behavior of circuits, such as the changes and currents, we seem to use abstract-level circuits, unnecessary and abstract-level complexity. e.g., the whole structure. We the data that in voltages concepts, such as the behavior of NOR/NOT details by giving a new concept name to understand are crucial of phenomena, figure by reducing to the aggregation this complex the figure. Here, we use abstract-level is the best to use. Although in understanding to leave out concepts concepts Based on the above introspection, we assume that A concept is something which makes inference easiel; \fK. Yoshida, H. Motoda/Ar@cial Intelligence 75 (1995) 63-92 65 (a) Naive Inference Pattern (b) Sorted by Qualitative Reasoning Knowledge (c) Sorted by Circuit Knowledge Fig. 2. Example of concept usage. \f66 K. Yoshida, H. Motoda/Artijicial Intelligence 75 (I 995) 63-92 learning this assumption, CLIP analyses that satisfy typical patterns to a new abstract concept by use of which inference and propose a new concept-learning method, concept from inference patterns (CLIP). To find new concepts inference processes and tries to extract from them. Each extracted pattern corre- sponds is made efficient due to the is that it does not require any reduced complexity. CLIP’s most important characteristic prespecified knowledge about abstract concepts. For example, CLIP analyses qualitative simulation in voltage and current) of the digital circuits, and finds the logical concepts, such as NOR and NOT, without being logic. Here, the concepts NOR and NOT are generated provided any knowledge to achieve an efficient traces of the physical behavior (i.e., the changes Another important is that it also generates a set of rules to about inference. characteristic these and of CLIP interpretation interpret new concepts, This distinguishes CLIP from conventional [ 31, which do not aim to make inference at the abstract concept level. rules enable abstract-level learning methods, inference. such as that in is organized for extracting The rest of the paper CLIP and the algorithm mental their structures with additional experimentation. future Section 6 discusses results. Section 4 analyses as follows: Section 2 outlines idea of typical patterns, and Section 3 presents experi- the factors which affect the generated concepts and related work, Then, Section 5 examines the basic issues, and Section 7 summarizes the results, 2. Concept learning based on colored digraph representation inference inference the sample to represent CLIP analyzes in such a way that the new patterns can be used to make the inference more efficient. The learning process is outlined as follows: l First, sample traces and extracts patterns to or produced by the inference, traces. Each graph node represents traces of the inference are converted into a colored digraph. We use the and the direction of the graph edge the direction of the inference. Each node has two kinds of color. The rule that is used to calculate to the value itself. In the to the circuit equation number (more the circuit rule that is used to interpret to the value of the voltage, current, etc. analysis of the inference pattern a colored digraph data referred represents tirst color corresponds the value of the data, and the second color corresponds circuit domain, precisely, equation), This graph representation frequency. the first color corresponds the identifier of the interpretation and the second color corresponds to the identifier of the inference the quantitative enables l Next, based on the frequency algorithm extracts a set of typical patterns which frequently analysis of the inference pattern, a parallel-search appear in the digraph. The basic idea is: l We can reduce the size of the graph by replacing each frequently appearing graph that appears often in an inference process pattern with a single node. Any pattern probably represents an important concept. l The size of the graph corresponds the inference engine. Accordingly, to the amount of data referred to or produced by traces as the graph converted from the inference \fK. Yoshida, H. MotodalArtijicial Intelligence 75 (1995) 63-92 67 Shallow Level Inference (OUTPUn Power [OnI Inwt~ Q1 02 a3 Q4 05 WI [Ll WI N WI Find Typical Inference Pattern Deep Level Inference (INPUT) 1 Power vcc Ql Vl (HI WI I1 a2 Vl [HI IL1 [Ll P-1 IHI WI WI [L] 13 Q4 v4 [L] 12 a3 v3 ,4 Q5 [H] [L] Fig. 3. CLIP: concept learning from inference patterns. becomes smaller, the inference becomes easier. Fig. 3 summarizes this idea. The upper left part of Fig. 3 shows a simple digital circuit, and the lower part shows the inference trace that analyzes the physical behavior of the circuit. The graph edge in the lower part shows the data dependency. The numeral in each node indicates which of the interpretation rules (see Section 3.2) is used in that node to derive the value of the variable (vi, lit Qi+ etc.) attached to the node. For example, the value of the voltage VI is calculated from the electric charge Ql using Rule 2 in Fig. 3, and the value of the current I1 is calculated from voltages Vj and V,, using Rule 3. CLIP analyzes this inference trace and extracts typical patterns, such as The rule sequence 2, 3 and 4 is frequently used befare Rule I, from the graph. CLIP’s output for this case is summarized in the upper right part of Fig. 3. Here, the new inference Rule 5 is used to calculate the electric charge Qz from Ql, and the smaller amount of data in the inference process decreases the cost of the inference. Furthermore, the correspondence of the new Rule 5 and the original rule sequence 1, 2, 3 and 4 can be used to restore the original information involved in the lower graph from the upper right graph. Note that the pattern found by CLIP corresponds to the new abstract concepts which are not explicitly represented in the original graph. In Fig. 3, the lower part of the graph represents the inference process about the physical quantities, such as the voltage and the current, and the upper right graph represents the inference process about the logical values (here, [H/L] corresponds to [True/False] ). The lower part of the graph does no",
            {
                "entities": [
                    [
                        60,
                        106,
                        "TITLE"
                    ],
                    [
                        8234,
                        8280,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 105 (1998) 209-261 Artificial Intelligence Multiple perspective dynamic decision making Tze Yun Leong ’ Medical Computing Laboratory, Department of Computer Science, School qf Computing, National University of Singapore, Lower Kent Ridge Road, Singapore 119260, Singapore Received 15 September 1997; received in revised form 17 April 1998 Abstract Decision making often involves deliberations acquisition in the same discourse. This work presents a general paradigm views support knowledge inference decision making over time and under uncertainty. Baaed on a unifying vocabulary model transparency and solution efficiency for the relevant decision problems, in current decision frameworks. and representation this new paradigm balances for multiple perspective task definition and a common the trade-off between in different perspectives. Distinct perspectives or types or stages of suitable for different language the design of DynaMoL support for the modeling The new paradigm motivates for modeling and solving dynamic decision problems. The DynaMoL inferential and representational (Dynamic decision Modeling Language), frame- a general task from the solution work differentiates or computation task. The dynamic decision grammar defines an extensible decision ontology and supports complex problem specification with multiple interfaces. The graphical presentation conven- tion governs parameter visualization as formal model analysis and admits multiple solution meth- semi-Markov decision process facilitates ods. A set of general translation is devised to manage the different perspectives and rep- resentations of the decision parameters and constraints. DynaMoL has been evaluated on a prototype implementation, via some comprehensive case studies in medicine. The results demonstrate practical promise of the framework. 0 1998 Elsevier Science B.V. All rights reserved. in multiple perspectives. The mathematical representation techniques Keywords: Decision making; Knowledge representation; Multiple perspective reasoning; Probabilistic reasoning; Temporal reasoning; Semi-Markov decision processes 1. Introduction Dynamic decision making concerns problems in which explicitly considered. For example, a common medical decision time and uncertainty are is to choose an optimal ’ Email: leongty@comp.nus.edu.sg. 0004-3702/98/$ - see front matter 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00082-4 \f210 7: K Leong /Artijicial Intelligence 105 (1998) 209-261 course of treatment common investment decision to fluctuating market factors over time. financial for a patient whose physical is to determine conditions may vary over time; a an optimal portfolio with respect Reasoning about dynamic decision problems often information from different perspectives or viewpoints. For instance, at one stage of problem delibera- states that a patient would tion, it might be essential go through; at another stage, it would be illuminating the uncertain effects of a treatment that would lead to different physiological the possible physiological to consider to estimate integrating involves states. intelligence solving, and support different Research in control theory, operations research, decision analysis, artificial techniques for formulating, has led to various (AI) and other disciplines analyzing dynamic decision problems. They adopt different assumptions, ontologies, and have different strengths and weaknesses. One major difficulty of dynamic decision making into simple, parameterized models. Many assumptions resulting models. The limited decision vocabulary contributes but obscures model transparency. Moreover, all the current perspective presentation influence diagrams [37] and decision decision problem. The respective strengths of the different different stages of decision addressed however, integrates and supports different representational factors is to fit the complex decision are implicit in the toward solution efficiency, support single frameworks to the fixed vocabulary or graphical for instance, analysis, In decision to the same frameworks are best suited for In AI, various efforts have solution, and analysis. levels of abstraction. None of these frameworks, the decision models conform framework. trees [60] provide alternate perspectives issues in reasoning at multiple of the specific and constraints formulation, convention reasoning; views. 1.1. Research objectives and approaches introduces to reason about a general for addressing a new paradigm of dynamic decision making. We present a and a that a methodology extension. Multiple in This work uniform way common vocabulary supports multiple perspective perspective different ways; it facilitates effective modeling and analysis of dynamic decision problems. through the Incremental to be use of translators; gradually expanded. class of dynamic such problems. We describe language it allows the scope of the dynamic decision problems addressed reasoning allows the modeler to visualize and examine language extension provides a framework that can be customized the same information decision problems and incremental reasoning The proposed methodology motivates a language design, called DynaMoL the trade-off between model transparency (Dynamic and for the modeling decision Modeling Language). To balance solution efficiency, requirements The relevant support for the modeling correspondences relevant support action in a well-formed model. and relationships for the solution among We evaluate DynaMoL via a prototype studies in medicine.We demonstrate the DynaMoL design differentiates task from those for the solution or computation representational and inferential task facilitates specification the decision parameters computation task accelerates task. and derivation of the and constraints; the of the optimal course of implementation with some comprehensive is expressive enough case to handle a class that DynaMoL \fI: E hong /ArtiJicial Intelligence 105 (1998) 209-261 211 of real-life dynamic decision problems. We claim that the proposed methodology general and more effective techniques. The exercise also illuminates how the proposed methodology motivates a new generation of dynamic decision making tools and techniques and how it can be put into practical use. than most existing is more 1.2. Guide to the paper This paper is organized as follows: Section 2 describes the class of dynamic decision in multiple decision dynamic reasoning addressed the main concepts and the desiderata of a multiple perspective and the decision problems the design of the DynaMoL in this work. Section 3 introduces language. Section 4 presents the domain background framework. Section 5 for a case study. Based on it examines the syntax and the semantics of the language. Section 7 discusses how the problems perspective modeling sketches the case study, Section 6 describes decision model formulation in detail in DynaMoL are translated among each other and how consistency different perspectives the solution is maintained process. Sections 8 and 9 briefly examine the design of methods and the analyses supported by the language. Section 10 illustrates a prototype in applying and documents the system to different dynamic decision problems compares It also examines research. Finally, Section 12 summarizes the methodology with related work and proposes some ideas for future research. in general AI and decision making some of our experiences in some practical domains. Section 11 and limitations of this work. of the methodology in the translation the achievements the implications for DynaMoL in DynaMoL; system 2. Dynamic decision making under uncertainty: an overview 2. I. The dynamic decision problem The general dynamic decision problem in an environment. The main distinguishing some objectives problem the action or decision points, and the objective measures are specified with respect time horizon. Fig. 1 depicts the factors involved from a static one is the explicit reference in a dynamic decision problem. to time. The environment to a that satisfies feature of a dynamic decision description, is to select a course of action This work addresses dynamic decision problems with the following properties: l The time horizon l The environment is defined as a set of discrete time points. comprises to be discrete, phenomena. A patient is either “well” or “sick” on the third day after being treated; a can that a robot is about to grasp is “full”, “half-full”, or “empty”. a finite set of discrete, or reasonably assumed l There is a finite set of discrete actions. These actions are context-dependent; have varying preconditions, A patient can only go through be carried out if the patient’s physical conditions permit. usually with respect to the environment they or time or both. three open heart surgeries, and each surgery can only l Each action has a finite set of discrete, or reasonably to be discrete, effects. is “well” again; moving from its current position, a robot “gets closer to the target position”. The a patient who was previously After a treatment, forward assumed “sick’ \f212 T E hong /Artificial Zntelligence 10.5 (1998) 209-261 ... & & & ... t ,< Objective measure at t-6 j . . . . . . . . . . . . . . . . . . . . . . . 4 \\ .\\.Objective measure at t ,: t ,,..................... i:: Objective measure at t+6 \\ ..” Fig. 1. A dynamic decision problem. nature of the effects are often uncertain. A treatment either cures a disease or leads to some undesirable the time at which the effects may occur are also uncertain. A patient who is cured of peptic ulcer may have a relapse sooner than another patient. side-effects. Moreover, l The effects of an action have measurable desirability. Such a measure can be multi- dimensional, in a hospital and being well, versus of staying staying at home and being sick, but it must be time separable, i.e., the total desirability can be calculated by summing functions over time",
            {
                "entities": [
                    [
                        67,
                        111,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1307–1322Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic-based axiomatic model of bargainingDongmo ZhangIntelligent Systems Laboratory, School of Computing and Mathematics, University of Western Sydney, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 4 October 2009Received in revised form 4 August 2010Accepted 5 August 2010Available online 12 August 2010Keywords:Bargaining solutionAxiomatic model of bargainingLogical model of negotiationOrdinal bargainingGame theory1. IntroductionThis paper introduces an axiomatic model for bargaining analysis. We describe a bargainingsituation in propositional logic and represent bargainers’ preferences in total pre-orders.Based on the concept of minimal simultaneous concessions, we propose a solution ton-person bargaining problems and prove that the solution is uniquely characterizedby five logical axioms: Consistency, Comprehensiveness, Collective rationality, Disagreement,and Contraction independence. This framework provides a naive solution to multi-person,multi-issue bargaining problems in discrete domains. Although the solution is purelyqualitative, it can also be applied to continuous bargaining problems through a procedureof discretization, in which case the solution coincides with the Kalai–Smorodinsky solution.© 2010 Elsevier B.V. All rights reserved.As one of the most fundamental models in modern economic theory, the Nash bargaining solution [23] has been de-veloped into a highly sophisticated theory with extensive applications in economics, social science, political science andmanagement science [1,13,23,24,26,40,42]. Computer scientists, especially researchers in the area of artificial intelligence(AI), have found it useful in modeling interactions among distributed computer systems and autonomous software agentssince the early 90s [12,17,30,38]. Many applications have been developed for the design and evaluation of high-level inter-action protocols among autonomous agents for task assignment, resource allocation, conflict resolution, electronic tradingand web services [16,27,30,41,48].Traditionally, a bargaining situation is modeled as a numerical game, using the language of utility. In his seminal paper,Nash [23] defined a bargaining situation as a pair (S, d), where S ⊆ (cid:3)2 represents the set of utility pairs that can be derivedfrom possible agreements and d ∈ S is the utility pair that follows disagreement.1 A solution is a rule that associates toeach bargaining situation (S, d) a feasible utility pair of S. Nash proposed a set of axioms that he thought a solution shouldsatisfy and established the existence of a unique solution satisfying all the axioms [23]. Numerous extensions and alternativesolutions have been proposed in the past sixty years after this first axiomatic model of bargaining [42]. The subsequentwork has diverged in two different directions: the cooperative models and the non-cooperative models. The former, followingNash’s approach and thus also called axiomatic models, provide an axiomatic characterization of bargaining solutions [23,42].A bargaining problem is modelled as a one-shot game and solutions are characterized by a set of axioms, such as Paretooptimality, Symmetry, and so on. The non-cooperative models, also called strategic models, establish explicit constructions ofnegotiation procedures and identify the bargaining outcome as an equilibrium [1]. The attempt to establish the relationshipbetween the two models is known as the Nash program [1,24].The Nash bargaining model provides simple and mathematically elegant solutions to bargaining problems and facilitatesquantitative analysis of bargaining situations. However, in many real-world bargaining situations, the utility of a bargainerE-mail address: d.zhang@uws.edu.au.1 (cid:3)2 represents 2-dimensional real Euclidean space.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.08.003\f1308D. Zhang / Artificial Intelligence 174 (2010) 1307–1322cannot be measured using a numeric scale, therefore the solutions that are built on the Nash model become inapplicable.2Examples of such bargaining situations can be easily found in political/legal negotiations, household bargaining, labor dis-putes and so on. For instance, it is difficult to imagine an analysis of the Six-Party Talks on North Korea’s Nuclear Programthat is based on a numerical measure of each party’s utility gains or losses from the negotiations.3An alternative method of bargaining analysis, initially suggested by Shapley and Shubik, is modeling a bargaining situa-tion in terms of bargainers’ preference orderings over possible agreements [40, p. 91]. Formally, a bargaining situation canbe represented as a tuple ( A, D, (cid:2)1, (cid:2)2), where A is a set of possible agreements (described in physical terms), D is thedisagreement, and (cid:2)1 and (cid:2)2 are preference orderings over A ∪ {D}. The interpretation is that a (cid:2)i b if and only if player ieither prefers a to b or is indifferent [26, p. 9]. This allows us to assess a bargainer’s utility through pairwise comparisonsamong the possible agreements instead of quantitative measurement. Such a model of bargaining problems is called anordinal bargaining model. A bargaining solution is ordinal if it can be built on an ordinal bargaining model. We would liketo remark that a bargaining solution built on the Nash bargaining model can also be ordinal as long as it is invariant un-der any order-preserving transformations of utilities (ordinal invariance) because such a solution can be expressed in anordinal model [31]. Therefore the judgement of whether a solution is ordinal or cardinal is not by the use of numbers butits structure. In fact, most of the existing work on ordinal bargaining solutions in the literature was built on numericalmodels [3,25,35,37].The ordinal bargaining models are of interest because ordinal information is relatively easier to obtain than cardinal util-ities [36]. Asked if they prefer coffee or tea, anyone can provide a preference. However, if asked to value their preference incardinal scale, they would find it difficult [8]. Nevertheless, Shapley observed that there is no non-trivial ordinal bargainingsolution to two-player bargaining problems [39].4 The reason is, as pointed out by many researchers, that the informationabout bargainers’ attitudes towards risk, which in fact determines the negotiation power of a bargainer, is not describable byordinal preferences [26,31,40].5 With the Nash bargaining model, bargainers’ risk attitudes, combined with the preferenceson the possible agreements, are represented by utility scales, i.e., cardinal utility, through the non-linearity or curvature ofutility functions (for an intuitive example see [44]). However, such information is lost when the model is converted to anordinal model through an order-preserving transformation. Therefore the information about bargainers’ risk attitudes is lost.This suggests that additional components have to be introduced to the ordinal bargaining models to express bargainers’ riskattitudes.Rubinstein et al. introduced a variation of the ordinal bargaining model in which the preference ordering of each playeris extended to the space of lotteries over the possible agreements and the disagreement [33]. A player can express herattitudes towards risk through her preference on the lotteries. However, an ordinal preference on the lotteries is by nomeans easier to elicit than the utility scales on the possible agreements because the space of lotteries is also a continuum.More recently, O’Neill et al. introduced an ordinal bargaining solution based on the idea of gradual bargaining [25]. Instead ofmodeling a bargaining problem as a one-shot game, they look at bargaining as a family of bargaining games, parameterizedby time. The bargaining outcome can then be viewed as the limit of a step-by-step bargaining in which the agreementof the last negotiation becomes the disagreement point for the next. Players’ risk attitudes can then be observed throughthe variations of their utilities over time. However, there is no explicit representation of players’ attitudes towards risk.Zhang and Zhang proposed a purely qualitative model of bargaining based on bargainers’ ordinal preferences [44]. Similarto but different from Rubinstein et al.’s framework, the preference ordering of each player is defined on the player’s demanditems (instead of the lotteries of possible agreements). More precisely, the physical demands of each player are expressedby logical statements. A possible agreement is a logically consistent set of demands from each player. The risk attitudes ofa player are represented based on a relative ranking of the player’s demands: a risk-lover tends to insist on conflicting demandsmore firmly than a risk-averse player and therefore may rank these conflicting demands higher, and vice versa. Bargaining then isviewed as a procedure of conflict resolution over two sets of ranked demands (for two-player bargaining). A solution conceptwas proposed based on minimal changes but no axiomatic characterization was provided [44].This paper will develop an axiomatic model of bargaining based on the ordinal preference structure proposed in [44]. Wedescribe a bargaining situation in propositional logic and represent bargainers’ preferences in total pre-orders. Following thetradition of cooperative bargaining theory, we assume that any negotiation is conducted through an impartial arbitrator whohas complete information about the negotiation [22, Chapter 8].6 The agreement of a negotiation is the outcome of a se-quence of concessions simultaneously made by all players. We assume that whenever a player has to make a concession, shealways tries to make the concession as small as possible provided it is enough to break even. Based on the assumptions, w",
            {
                "entities": [
                    [
                        138,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 300 (2021) 103546Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintKandinsky Patterns ✩Heimo Müller∗, Andreas HolzingerMedical University Graz, Austriaa r t i c l e i n f oa b s t r a c tArticle history:Received 16 September 2019Received in revised form 23 May 2021Accepted 3 June 2021Available online 9 June 2021Keywords:Explainable AIExplainabilitySynthetic test dataGround truthKandinsky Figures and Kandinsky Patterns are mathematically describable, simple, self-contained hence controllable synthetic test data sets for the development, validation and training of visual tasks and explainability in artificial intelligence (AI). Whilst Kandinsky Patterns have these computationally manageable properties, they are at the same time easily distinguishable by human observers. Consequently, controlled patterns can be described by both humans and computers. We define a Kandinsky Pattern as a set of Kandinsky Figures, where for each figure an “infallible authority” defines that the figure belongs to the Kandinsky Pattern. With this simple principle we build training and validation data sets for testing explainability, interpretability and context learning. In this paper we describe the basic idea and some underlying principles of Kandinsky Patterns. We provide a Github repository and invite the international AI research community to a challenge to experiment with our Kandinsky Patterns. The goal is to help expand and advance the field of AI, and in particular to contribute to the increasingly important field of explainable AI.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionAI is currently very successful, due to (i) advances in statistical machine learning (“deep learning”), (ii) the availability of large amounts of training data, and (iii) the available computing power [1], [2]. The high complexity, nonlinearity, and high dimensionality of such approaches make them difficult for a human to interpret, and therefore such approaches are considered “black box” models [3].Boosted by DARPA’s Explainable Artificial Intelligence Program [4], the field of explainable AI (xAI) has experienced a tremendous renaissance. Due to the imoprtance of legal and ethical considerations, explainability became enormously rel-evant and has established itself as an important concept. In roughly simplified terms, explainability technically highlights decision relevant parts of machine representations and/or parts which contributed to model accuracy in training and the xAI community has already developed a variety of successful methods. However, explainability does not refer to a human model. In certain application domains, e.g. in the medical domain, there is a need for going beyond explainability, i.e. there is a need for causability. Causability [5] is neither a typo nor a synonym for Causality [6]. The term Causa-bil-ity was intro-duced in reference to the well-known term Usa-bil-ity [7]. Causability has been defined as the measurable extent to which an explanation (resulting from an explainable AI method) to a human achieves a specified level of causal understanding ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail address: heimo.mueller@medunigraz.at (H. Müller).URL: http://human-centered.ai (H. Müller).https://doi.org/10.1016/j.artint.2021.1035460004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fH. Müller and A. HolzingerArtificial Intelligence 300 (2021) 103546measured with effectiveness, efficiency and satisfaction in a specified context of use - similar to usability. This can be mea-sured with the System Causability Scale (SCS) [8]. Consequently, causability refers to a human model and the understanding can be ensured when mapping explainability with causability. A successful mapping between the two would require new human-AI interfaces which allow domain experts to interactively ask questions and counterfactual questions to gain insight into the underlying independent explanatory factors of a result [9]. In an ideal world both human and AI statements would be identical and congruent with the ground truth, which is defined for both humans and AI equally [8]. Compared to the map metaphor, the explainability–causability mapping is about establishing connections and relations - not drawing a new map. It is about identifying the same areas in two completely different maps. For example, when explaining predictions of deep learning models we apply an explanation method, e.g. simple sensitivity analysis, to understand the prediction in terms of the input variables. The result of such an explainability method can be a heatmap. This heatmap visualization indicates which pixels need to be changed to make the image look (from the AI-systems perspective!) more or less like the predicted class [10]. On the other hand there are the corresponding human concepts, and “contextual understanding” needs effective mapping of them both [11], and is among the future grand goal of human-centered AI [12].The central motivation for this work was the lack of ground truth when testing with real data sets. Image classifiers operate on low-level features (e.g. lines, circles, etc.) rather than high-level concepts, and with domain concepts (e.g. imageswith a storefront). With our Kandinsky exploration environment we can produce Kandinsky Figures and Kandinsky Patterns along with the ground truth. With these mathematically describable, simple, and controllable synthetic test data sets we enhance the development, validation and training of visual tasks and explainability. Very important is that they are at the same time easily distinguishable by human observers.2. Kandinsky patternsWassily Kandinsky (1866–1944) was an influential Russian painter [13]. As his career progressed, Kandinsky produced increasingly abstract images. For a period from 1922 to 1933 he taught at the famous Bauhaus school in Germany, which celebrated simple colors and forms. Kandinsky was a theorist as well as an artist, and he derived profound meaning from aesthetic experiences. One of Kandinsky’s ideas was that there are certain fundamental associations between colors and shapes [14], e.g. he proposed Yellow-Triangle, Blue-Circle, and Red-Square. These associations were formulated introspec-tively, however, he did conduct his own survey at the Bauhaus in 1923 and postulated a correspondence between color and form. Subsequent empirical studies used preference judgments to test Kandinsky’s original color-form combinations, usually yielding inconsistent results. Recent findings suggest that there is no implicit association between the original color-form combinations and hence cannot be considered as a universal property of the visual system [15]. In our work we do not pursue this hypothesis any further, but take only the visual principles of Kandinsky as starting point and eponym for the following definitions.A Kandinsky Figure is a square image containing 1 to n geometric objects. Each object is characterized by its shape, color, size and position within this square. Objects do not overlap and are not cropped at the border. All objects must be easily recognizable and clearly distinguishable by a human observer.The set of all possible Kandinsky Figures k is defined by the general definition together with a specific set of values for shape, color, size, position and the number of geometric objects. In the following examples we use for shape the values circle, square and triangle; for color we use the values red, blue, yellow, and we allow arbitrary positions and size with the restriction that it is still recognizable. Furthermore, we require each Kandinsky Figure to contain exactly 4 objects in the following illustrative examples. In the demo implementation this fact is embedded in the base class “Kandinsky Universe”, and in the generator functions,1 see Fig. 1.A Statement s(k) about a Kandinsky Figure k is either a mathematical function, s(k) → B; with B(0, 1) or a natural language statement, which is either true or false.Remark: The evaluation of a natural language statement is always done in a specific context. In the followings examples we use well known concepts from human perception and linguistic theory. If s(k) is given as an algorithm, it is essential that the function is a pure function, which is a computational analogue of a mathematical function.A Kandinsky Pattern K is defined as the subset of all possible Kandinsky Figures k with s(k) → 1 or the natural language statement is true. s(k) and a natural language statement are equivalent, if and only if the resulting Kandinsky Patterns con-tains the same Kandinsky Figures. s(k) and the natural language statement are defined as the Ground Truth of a Kandinsky Pattern.In a deep learning solution classification algorithm for a visual pattern is usually represented as a highly non-linear, high-dimensional network. One aim of explainable AI is to identify areas of activation within the network structure, which correspond to concepts in the natural language statement.Problem 1: How can we explain a Kandinsky Pattern, if we do not know the Ground Truth and the membership of Kandinsky Figures to a Kandinsky Pattern is only known for a limited number of Kandinsky Figures.Problem 2: Generate a natural language statement, which is easily understandable and equivalent to the machine expla-nation (classification algorithm).1 https://github .com /human -centered -ai -lab /app -kandinsky-pattern -generator.2\fH. Müller and A. HolzingerArtificial Intelligence 300 (2021) 103546Fig. 1. A Kandinsky Figure with 4 objects. (For interpretation of the colors in the figure(s), the reader is referred to the web versi",
            {
                "entities": [
                    [
                        135,
                        153,
                        "TITLE"
                    ],
                    [
                        471,
                        489,
                        "TITLE"
                    ],
                    [
                        709,
                        727,
                        "TITLE"
                    ],
                    [
                        1307,
                        1325,
                        "TITLE"
                    ],
                    [
                        1447,
                        1465,
                        "TITLE"
                    ],
                    [
                        5646,
                        5664,
                        "TITLE"
                    ],
                    [
                        5965,
                        5983,
                        "TITLE"
                    ],
                    [
                        8905,
                        8923,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 148 (2003) 335–383www.elsevier.com/locate/artintPossibilistic instance-based learningEyke HüllermeierDepartment of Mathematics and Computer Science, University of Marburg, Marburg 35032, GermanyReceived 16 July 2001; received in revised form 9 August 2002AbstractA method of instance-based learning is introduced which makes use of possibility theory andfuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principleunderlying the instance-based learning paradigm is proposed. This version is compared to thecommonly used probabilistic approach from a methodological point of view. Moreover, aspects ofknowledge representation such as the modeling of uncertainty are discussed. Taking the possibilisticextrapolation principle as a point of departure, an instance-based learning procedure is outlined whichincludes the handling of incomplete information, methods for reducing storage requirements andthe adaptation of the influence of stored cases according to their typicality. First theoretical andexperimental results showing the efficiency of possibilistic instance-based learning are presented aswell. 2003 Elsevier B.V. All rights reserved.Keywords: Possibility theory; Fuzzy set theory; Machine learning; Instance-based learning; Nearest neighborclassification; Probability1. IntroductionA major theme in machine learning concerns the problem of induction, that is thecreation of general knowledge from particular examples or observed data. In this respect,uncertainty plays a fundamental role. To begin with, the data presented to learningalgorithms is imprecise, incomplete or noisy most of the time, a problem that can badlymislead a learning procedure. But even if observations were perfect, the generalizationbeyond that data would still be afflicted with uncertainty. For example, observed data cangenerally be explained by more than one candidate theory, which means that one can neverE-mail address: eyke@mathematik.uni-marburg.de (E. Hüllermeier).0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.doi:10.1016/S0004-3702(03)00019-5\f336E. Hüllermeier / Artificial Intelligence 148 (2003) 335–383be sure of the truth of a particular theory. Consequently, inductive reasoning—by its verynature—is inseparably connected with uncertainty [13].In fact, the insight that inductive inference can never produce ultimate truth can betraced back at least as far as Francis Bacon’s epistemology. In his Novum Organum,1 Baconadvocates a gradualist conception of inductive enquiry and proposes to set up degrees ofcertainty. Thus, from experience in the form of given data, one may at best conclude that atheory is likely to be true—not, however, that it is true with certainty. In machine learningand mathematical statistics, uncertainty of this type is generally handled by means ofprobabilistic methods. In Bayesian approaches, for example, an inference result is usuallygiven in the form of a probability distribution over the space of candidate models, that is,each model (theory) is assigned a degree of probability.In this paper, our interest concentrates on possibility theory [29] as an alternativecalculus for modeling and processing uncertainty or, more generally, partial belief.By using possibility theory for handling uncertainty in learning procedures, inductivereasoning becomes possibilistic in the sense that certain generalizations are declared moreor less plausible. In this paper, we shall employ possibility theory in the context of instance-based learning (IBL), a special approach to (supervised) machine learning. IBL relies ona kind of extrapolation principle2 expressing a commonsense rule already suggested byDavid Hume:3 “In reality, all arguments from experience are founded on the similarity,which we discover among natural objects, and by which we are induced to expect effectssimilar to those, which we have found to follow from such objects. . . . From causes,which appear similar, we expect similar effects. This is the sum of all our experimentalconclusions.” Thus, HUME suggests to extrapolate properties of one object to propertiesof similar ones. The idea of possibilistic induction, combined with this extrapolationprinciple, leads to the following inference pattern: The more similar two causes are, themore plausible it is that they have the same effects. Since possibility theory (in conjunctionwith fuzzy set theory) establishes a close connection between the concepts of similarity anduncertainty, it provides an excellent framework for translating this principle into a formalinference procedure.This paper complements recent work on the use of possibility theory and fuzzy sets ininstance-based reasoning [25–27]. The latter is more concerned with extending IBL bymeans of fuzzy set-based modeling techniques, whereas here the focus is on the learningprocess itself. More specifically, we introduce a method of possibilistic IBL, referred toas POSSIBL, which implements the above-mentioned inference pattern. Together, the twoframeworks yield a powerful methodology of instance-based reasoning in which possibilitytheory and fuzzy set-based modeling are used, respectively, for representing gradationof uncertainty and evidential support and for complementing the data-driven inferenceprocedure by means of domain-specific expert knowledge.By way of background, Section 2 recalls some important ideas of possibility theory andSection 3 gives a brief review of instance-based learning and the NEAREST NEIGHBORprinciple upon which it is based. Besides, the aspect of uncertainty in IBL is discussed1 Published in 1620.2 IBL does actually not realize induction proper, as will be discussed later.3 See, e.g., [45, p. 116].\fE. Hüllermeier / Artificial Intelligence 148 (2003) 335–383337in this section. In Section 4, a possibilistic extrapolation principle is introduced andcompared to other principles commonly used in instance-based learning. Proceeding fromthis extrapolation principle, a method of possibilistic instance-based learning is developedin Section 5. Finally, Section 6 presents experimental studies. The paper concludes with asummary in Section 7.2. Background on possibility theoryIn this section, we recall some basic concepts from possibility theory, as far as requiredfor the current paper. Possibility theory deals with “degrees of possibility”. The term“possibility” is hence employed as a graded notion, much in the same way as theterm “probability”. At first sight, this might strike as odd since “possibility” is usuallyconsidered a two-valued concept in natural language (something is possible or not).Before turning to more technical aspects, let us therefore make some brief remarks onthe semantics underlying the notion of “possibility” as used in possibility theory.Just as the concept of probability, the notion of possibility can have different semanticmeanings. To begin with, it can be used in the (physical) sense of a “degree of ease”. Onemight say, for instance, that it is more possible for Hans to have two eggs for breakfastthan eight eggs, simply because eating two eggs is more easy (feasible, practicable)than eating eight eggs [82]. However, as concerns the use in most applications, andin this paper in particular, possibility theory is considered as a means for representinguncertain knowledge, that means, for characterizing the epistemic state of an agent. Forinstance, given the information that Hans has eaten many eggs, one is clearly uncertainabout the precise number. Still, three eggs appears somewhat more plausible (possible)than two eggs, since three is more compatible with the linguistic quantifier “many” thantwo.It is important to note that a degree of possibility, as opposed to a degree of probability,is not necessarily a number. In fact, for many applications it is sufficient, and often evenmore suitable, to assume a qualitative (ordinal) scale with possibility degrees rangingfrom, e.g., “not at all” and “hardly” to “fairly” and “completely” [33,52]. Still, possibilitydegrees can also be measured on the cardinal scale [0, 1], again with different semanticinterpretations. For example, possibility theory can be related to probability theory, inwhich case a possibility degree can specify, e.g., an upper probability bound [31]. Forconvenience, possibility degrees are often coded by numbers from the unit interval evenwithin the qualitative framework of possibility theory.As a means of representing uncertain knowledge, possibility theory makes a distinctionbetween the concepts of the certainty and the plausibility of an event. As opposed toprobability theory, possibility theory does not claim that the confidence in an eventis determined by the confidence in the complement of that event and, consequently,involves non-additive measures of uncertainty. Taking the existence of two quite oppositebut complementary types of knowledge representation and information processing intoaccount, two different versions of possibility theory will be outlined in the following. Fora closer discussion refer to [34] and [24].\f338E. Hüllermeier / Artificial Intelligence 148 (2003) 335–3832.1. Possibility distributions as generalized constraintsA key idea of possibility theory as originally introduced by Zadeh [82] is to considera piece of knowledge as a (generalized) constraint that excludes some “world states”(to some extent). Let Ω be a set of worlds conceivable by an agent, including the “trueworld” ω0. With (incomplete) knowledge K about the true world one can then associate apossibility measure ΠK such that ΠK(A) measures the compatibility of K with the event(set of worlds) A ⊆ Ω, i.e., with the proposition that ω0 ∈ A. Particularly, ΠK(A) becomessmall if K excludes each world ω ∈ A and large if at least one of the worlds ω ∈ A iscompatible with K. More specifically, the finding that A is incompatible with K to somedegree corresponds to a statement of the form ΠK(A) (cid:1) p, where p is a",
            {
                "entities": [
                    [
                        72,
                        109,
                        "TITLE"
                    ],
                    [
                        1106,
                        1143,
                        "TITLE"
                    ],
                    [
                        6028,
                        6065,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 188–216Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelational linear programmingKristian Kersting a,∗a CS Department, TU Dortmund University, Germanyb LEAR-INRIA Rhone-Alpes, Montbonnot, France, Martin Mladenov a, Pavel Tokmakov ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 25 June 2015Accepted 28 June 2015Available online 2 July 2015Keywords:Machine learningOptimizationRelational logicStatistical relational learningLinear programmingSymmetry(Fractional) automorphismColor-refinementLifted probabilistic inferenceLifted linear programmingEquitable partitionsOrbit partitions1. IntroductionWe propose relational linear programming, a simple framework for combining linear programs (LPs) and logic programs. A relational linear program (RLP) is a declarative LP template defining the objective and the constraints through the logical concepts of objects, relations, and quantified variables. This allows one to express the LP objective and constraints relationally for a varying number of individuals and relations among them without enumerating them. Together with a logical knowledge base, effectively a logic program consisting of logical facts and rules, it induces a ground LP. This ground LP is solved using lifted linear programming. That is, symmetries within the ground LP are employed to reduce its dimensionality, if possible, and the reduced program is solved using any off-the-shelf LP solver. In contrast to mainstream LP template languages such as AMPL, which features a mixture of declarative and imperative programming styles, RLP’s relational nature allows a more intuitive representation of optimization problems, in particular over relational domains. We illustrate this empirically by experiments on approximate inference in Markov logic networks using LP relaxations, on solving Markov decision processes, and on collective inference using LP support vector machines.© 2015 Elsevier B.V. All rights reserved.Modern social and technological trends result in an enormous increase in the amount of accessible data, with a sig-nificant portion of the resources being interrelated in a complex way and having inherent uncertainty. Such data, which we may refer to as relational data, arises for instance in social network and media mining, natural language processing, open information extraction, the web, bioinformatics, and robotics, among others. Making this data amenable to computing machinery typically yields substantial social and/or business value. Therefore, it is not surprising that probabilistic logical languages1 are currently provoking much new AI research with tremendous theoretical and practical implications. By com-bining aspects of logic and probabilities—a dream of AI dating back to at least the late 1980’s when Nils Nilsson introduced the term probabilistic logics [5]—they help to effectively manage both complex interactions and uncertainty in the data.However, instead of looking at AI through the glasses of probabilities over possible worlds, we may also approach it using optimization. That is, we have a preference relation, i.e., some objective function over possible worlds, and we want a best possible world according to the preference. Consider for example a typical data analyst solving a machine learning problem for a given dataset. She selects a model for the underlying phenomenon to be learned (choosing a learning bias), formats * Corresponding author.E-mail addresses: kristian.kersting@cs.tu-dortmund.de (K. Kersting), martin.mladenov@cs.tu-dortmund.de (M. Mladenov), pavel.tokmakov@inria.fr(P. Tokmakov).1 We refer to e.g. [1–4] and references therein for overviews.http://dx.doi.org/10.1016/j.artint.2015.06.0090004-3702/© 2015 Elsevier B.V. All rights reserved.\fK. Kersting et al. / Artificial Intelligence 244 (2017) 188–216189the raw data according to the chosen model, tunes the model parameters by minimizing some objective function induced by the data and the model assumptions, and may iterate the last step as part of model selection and validation. This is an instance of the declarative “Model + Solver” paradigm that was and is prevalent in AI [6], natural language processing [7], machine learning [8], and data mining [9]: instead of outlining how a solution should be computed, we specify what the problem is in terms some high-level modeling language and solve it using general solvers.Unfortunately, however, today’s solvers for mathematical programs typically require that the program is presented in solver-readable form and/or offer only some very restricted modeling environment. For example, a solver may require that a set of linear constraints be presented as a system of linear inequalities Ax ≤ b. This can create severe difficulties for the user. First of all, the process of turning the intuition that defines the model “on paper” into a solver-readable form could be quite cumbersome. Consider the following example from graph isomorphism [10]. Given two graphs G and H , the LP formulation introduces a variable for every possible partial function mapping k vertices of G to k vertices in H . It is not a trivial task to come up with a convenient linear indexing of the variables, let alone expressing the resulting inequalities Ax ≤ b. It requires the user to produce and maintain complicated matrix generation code, which can be tedious and error-prone. Moreover, the reusability of such specialized code is limited, as relatively minor modifications of the equations could require large modifications of the code (for example, the user decides to switch from having variables over sets of vertices to variables over tuples of vertices). Ideally, one would like to separate the rules that generate the problem from the problem instance itself. Finally, solver-readable forms are inherently propositional. By design they cannot model domains with a variable number of individuals and relations among them without enumerating all of them. As already mentioned, however, many AI tasks and domains are best modeled in terms of individuals and relations. Agents must deal with heterogeneous information of all types. Even more important, they must often build models before they know what individuals are in the domain and, therefore, before they know what variables exist. Hence modeling should facilitate the formulation of abstract, general knowledge.To overcome these downsides and triggered by the success of probabilistic logical languages, we show that optimization is liftable to the relational level too. Specifically, we lift linear programs—the most tractable, best understood, and widely used in practice fragment of mathematical programs—by introducing relational linear programs (RLPs). They are declarative LP templates defined through the logical concepts of individuals, relations, and quantified variables, and allow the user to express LP objectives and constraints for a varying number of individuals without enumerating them. For instance, the following codesubject to {vertex(X),not source(X),not target(X)}: outflow(X)-inflow(X)=0;encodes the conservation of flows for all vertices of a graph that are not source or target. Together with a logical knowledge base (LogKB) referring to the individuals and relations (effectively a logical program consisting of logical facts and rules), it induces a ground LP that can be solved using any LP solver. However, since RLPs consist of templates that are instantiated several times to construct a ground linear model, they are also likely to induce ground models that exhibit symmetries, and we will demonstrate how to detect and exploit them. As our main technical contribution, we introduce lifted linear programming (LLP). It detects symmetries in a linear program in quasilinear time and eliminates them by reparametrizing the original linear program into a smaller one sharing optimal solutions that can be computed using any LP solver.Both contributions together result in relational linear programming, best summarized as(cid:2)(cid:3)(LP + Logic) − Symmetry+ Solver.The user describes a relational problem in a high-level, relational LP modeling language and—given a logical knowledge base (LogKB) encoding some individuals or rather data—the system automatically compiles a symmetry-reduced LP that in turn can be solved using any off-the-shelf LP solver.Our empirical illustrations on several AI tasks such as computing optimal value-functions of Markov decision pro-cesses [11], approximate inference within Markov logic networks [12] using LP relaxations, and collective classification [13]demonstrate that relational linear programming can• ease the process of turning the “modeler’s form”, i.e., the form in which the modeler understands a problem or actually a class of problems (since we can now deal with a varying number of individuals and relations among them), into a solver-readable form, and• considerably reduce the time spent to compute solutions.The present paper is a significant extension of a previously published conference paper [14]. It provides a much more concise development of LLP and the first coherent view on relational linear programming as a novel and promising way for scaling AI by developing and showcasing the first modeling language for LPs based on logic programming. One of the advantages of the language is the closeness of its syntax to the mathematical notation of LP problems while supporting language elements from logic programming such as individuals, relations, and quantified variables. This allows for a very concise and readable relational definition of linear optimization problems in a general, declarative fashion; the (relational) algebraic formulation of a model does not contain any hints how to process it.We proceed as follows. We start off by reviewing linear programming and existing LP template languages in Section 2. Then, in Section 3, we introduce re",
            {
                "entities": [
                    [
                        136,
                        165,
                        "TITLE"
                    ],
                    [
                        721,
                        750,
                        "TITLE"
                    ],
                    [
                        8056,
                        8085,
                        "TITLE"
                    ],
                    [
                        8696,
                        8725,
                        "TITLE"
                    ],
                    [
                        9224,
                        9253,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1877–1910Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the complexity of core, kernel, and bargaining set ✩Gianluigi Greco a, Enrico Malizia b, Luigi Palopoli b, Francesco Scarcello b,∗a Dipartimento di Matematica, Università della Calabria, I-87036 Rende (CS), Italyb DEIS, Università della Calabria, I-87036 Rende (CS), Italya r t i c l ei n f oa b s t r a c tArticle history:Received 4 November 2010Received in revised form 10 June 2011Accepted 13 June 2011Available online 16 June 2011Keywords:Coalitional gamesCompact representationsComputational complexitySolution conceptsBounded treewidthCoalitional games model scenarios where players can collaborate by forming coalitions inorder to obtain higher worths than by acting in isolation. A fundamental issue of coalitionalgames is to single out the most desirable outcomes in terms of worth distributions,usually called solution concepts. Since decisions taken by realistic players cannot involveunbounded resources, recent computer science literature advocated the importance ofassessing the complexity of computing with solution concepts. In this context, the paperprovides a complete picture of the complexity issues arising with three prominent solutionconcepts for coalitional games with transferable utility, namely, the core, the kernel, andthe bargaining set, whenever the game worth-function is represented in some reasonablycompact form. The starting points of the investigation are the settings of graph gamesand of marginal contribution nets, where the worth of any coalition can be computedin polynomial time in the size of the game encoding and for which various openquestions were stated in the literature. The paper answers these questions and, in addition,provides new insights on succinctly specified games, by characterizing the computationalcomplexity of the core, the kernel, and the bargaining set in relevant generalizationsand specializations of the two settings. Concerning the generalizations, the paper showsthat dealing with arbitrary polynomial-time computable worth functions—no matter ofthe specific game encoding being considered—does not provide any additional source ofcomplexity compared to graph games and marginal contribution nets. Instead, only forthe core, a slight increase in complexity is exhibited for classes of games whose worthfunctions encode NP-hard optimization problems, as in the case of certain combinatorialgames. As for specializations, the paper illustrates various tractability results on classes ofbounded treewidth graph games and marginal contribution networks.© 2011 Elsevier B.V. All rights reserved.1. IntroductionCoalitional games were introduced by von Neumann and Morgenstern [59] in order to reason about scenarios where play-ers can collaborate by forming coalitions with the aim of obtaining higher worths than by acting in isolation. In the Trans-ferable Utility (TU) setting, coalition worths can be freely distributed amongst agents, while in the Non-Transferable Utility(NTU) setting coalitions are allowed to distribute worths only in some specified configurations, called consequences [62].✩Preliminary versions of parts of this paper appeared in the Proceedings of the 20th and of the 21st International Joint Conferences on ArtificialIntelligence (Malizia et al., 2007 [53]; Greco et al., 2009 [38]).* Corresponding author.E-mail addresses: ggreco@mat.unical.it (G. Greco), emalizia@deis.unical.it (E. Malizia), palopoli@deis.unical.it (L. Palopoli), scarcello@deis.unical.it(F. Scarcello).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.06.002\f1878G. Greco et al. / Artificial Intelligence 175 (2011) 1877–1910In this paper, we consider only the classical TU setting, and thus by saying game we always mean hereafter coalitionalgame with transferable utility. Such a game can abstractly be modeled as a pair G = (cid:3)N, v(cid:4), where N is a finite set of players,and v is a function associating with each coalition S ⊆ N a certain worth v(S) ∈ R that players in S obtain by collaboratingwith each other. The outcome of G is an imputation, i.e., a vector of payoffs (xi)i∈N meant to specify the distribution of thei∈N xi = v(N), and individuallytotal worth v(N) granted to each player in N. Imputations are required to be efficient, i.e.,rational, i.e., xi (cid:2) v({i}), for each i ∈ N. In the following, the set of all imputations of G is denoted by X(G).It is easily seen that, for any given coalitional game G, the set X(G) may even contain infinitely many payoff vectors.Therefore, a fundamental problem is to single out the most desirable ones in terms of appropriate notions of worth distribu-tions, which are usually called solution concepts. Traditionally, this question was studied in economics and game theory withthe aim of providing arguments and counterarguments about why such proposals are reasonable mathematical renderingsof the intuitive concepts of fairness and stability. Well-known and widely-accepted solution concepts are the Shapley value,the core, the kernel, the bargaining set, and the nucleolus (see, e.g., [62]). Each solution concept defines a set of outcomes thatare referred to with the name of the underlying concept. For instance, the “core of a game” is the set of those outcomessatisfying the conditions associated with the concept of core.(cid:2)1.1. Coalitional games from the AI perspective: Complexity and representation issuesSolution concepts for coalitional games have been brought to the attention of the computer science community, byconsidering them from a computational point of view, in a seminal study by Megiddo [57]. There, it has been observed thatthe naïve approach of explicitly listing all associations of coalitions with their worths in the specification of coalitional gamesmakes the “game theory approach” hardly applicable in practice, due to the exponential blow-up of the input representationw.r.t. the number of involved players. In fact, Megiddo [57] showed the importance of conceiving succinct representations ofcoalitional games, and taking into consideration computational complexity issues when analyzing classical solution concepts,with the aim of exhibiting efficient algorithms for their calculation. In particular, Megiddo [57] exhibited polynomial-timealgorithms for computing the nucleolus and the Shapley value of cost allocation games over trees.Another influential study on complexity issues related to coalitional games is due to Kalai and Zemel [48], who showedpolynomial-time algorithms for computing an imputation in the core of flow games.Deng and Papadimitriou [26] took a step further to use computational complexity in the analysis of coalitional games, byarguing that decisions taken by realistic agents cannot involve unbounded resources to support reasoning, and suggesting toformally capture the bounded rationality principle [76] by assessing the amount of resources needed to compute solutionconcepts in terms of their computational complexity [26,47]. In this context, Deng and Papadimitriou [26] were interestednot only in exhibiting efficient algorithms, but also in characterizing those scenarios where such algorithms are unlikely toexist due to the inherent complexity of the solution concepts. In particular, they again noticed that computational questionsare of interest whenever worth functions are encoded in some succinct way, e.g., when they are given in terms of polyno-mially computable functions over some combinatorial structure. However, to the end of assessing the intrinsic complexityof solution concepts, calling for succinct specifications is not only motivated by the practical difficulty of explicitly listingall associations of coalitions with their worths, but also because with an explicit encoding the input sizes are so large thatcomplexity problems are trivially—and in fact artificially—easy. Coalitional games whose worth functions are encoded bymeans of some succinct representation mechanism are hereinafter called compact games.Coalitional games gained popularity in the context of multi-agent systems and artificial intelligence research since thenineties, when they had been recognized by these research communities as very natural models to understand and reasonabout cooperative action. In particular, inspired by the approach of Deng and Papadimitriou [26], the questions of findingrepresentation schemes to compactly encode worth functions and assessing over them the complexity of various solutionconcepts have motivated most of the research on coalitional games in the AI field. In fact, research works facing thesequestions can be classified into two main groups, depending on the kinds of representation schemes being adopted (cf. [1])1:1. Representation schemes that are succinct, but not complete (i.e., such that there are coalitional games that cannotbe captured by such representations). Complexity analysis have been conducted on several prominent schemes of thiskind, including graph games [26], traveling salesman games [31], flow games [24], matching games [49], facility locationgames [37], skill games [9], threshold games [5,28,30], minimum cost spanning tree games [33], combinatorial optimizationgames (see [25] and the references therein), games on combinatorial structures [12], voting games [68], games in multi-issuedomains [17], linear production games [63], bin packing games [32], permutation games [77], path disruption games [8], and(vertex) connectivity games [10].2. Representation schemes that are complete, but not succinct (i.e., such that there are coalitional games requiring ex-ponential space—in the worst case—to be encoded in such representations). Influential proposals thereof are marginalcontribution nets [44], read-once (and general) marginal contribution nets [29], games with synergies among coalitions [18],and multi-attribute games [45].1 Details o",
            {
                "entities": [
                    [
                        138,
                        191,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 115 (1999) 65–105Knowledge-based proof planningErica Melis (cid:3), Jörg Siekmann 1Universität des Saarlandes, Fachbereich Informatik and DFKI, D-66041 Saarbrücken, GermanyReceived 1 February 1999AbstractKnowledge-based proof planning is a new paradigm in automated theorem proving (ATP) whichswings the motivational pendulum back to its AI origins in that it employs and further develops manyAI principles and techniques such as hierarchical planning, knowledge representation in frames andcontrol-rules, constraint solving, tactical and meta-level reasoning. It differs from traditional search-based techniques in ATP not least with respect to its level of abstraction: the proof of a theoremis planned at an abstract level and an outline of the proof is found. This outline, i.e., the abstractproof plan, can be recursively expanded and it will thus construct a proof within a logical calculus.The plan operators represent mathematical techniques familiar to a working mathematician. Whilethe knowledge of a domain is specific to the mathematical field, the representational techniquesand reasoning procedures are general-purpose. The general-purpose planner makes use of thismathematical domain knowledge and of the guidance provided by declaratively represented control-rules which correspond to mathematical intuition about how to prove a theorem in a particularsituation. These rules provide a basis for meta-level reasoning and goal-directed behaviour. Wedemonstrate our approach for the mathematical domain of limit theorems, which was proposed as achallenge to automated theorem proving by the late Woody Bledsoe. Using the proof planner of the(cid:127)MEGA system we were able to solve all the well known challenge theorems including those thatcannot be solved by any of the existing traditional systems. (cid:211) 1999 Elsevier Science B.V. All rightsreserved.Keywords: Theorem proving; Planning; Automated proof planning; Meta-level reasoning; Integrating constraintsolvers(cid:3)Corresponding author. Email: melis@cs.uni-sb.de.1 Email: siekmann@dfki.de.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 0 7 6 - 41999 Elsevier Science B.V. All rights reserved.\f66E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105Automated theorem proving : : : is not the beautiful processwe know as mathematics. This is ‘cover your eyes withblinders and hunt through a cornfield for a diamond-shapedgrain of corn’. Mathematicians have given us a great dealof direction over the last two or three millennia. Let us payattention to it.Woody Bledsoe, 19861. IntroductionSince the early days of artificial intelligence (AI) research, two schools have existed inautomated theorem proving, the logic-oriented approaches and the rather psychologicallyoriented approaches which try to simulate people. For example, atthe DartmouthConference in 1956, two systems found wide attention and are considered ‘classic’ today:Martin Davis’ decision procedure based on Presburger’s Arithmetic [30] which is the grandancestor of logic-oriented systems and the now seminal Logic Theorist [97] that pioneeredthe second category. In 1954, Davis’ system was the first system ever to prove a theoremwith a computer (“The sum of two even numbers is even”.) and about a year later, AlanNewell and Herb Simon finished their joint system, later called the Logic Theorist, whichsucceeded in proving many theorems from Principia Mathematica [106] and sparked offthe field of artificial intelligence.Since Hao Wang’s work [121] and with the development of the resolution principle in1965 [104], the logic-oriented, search-based paradigm has by and large dominated the field,and by far the strongest systems were built within this train of thought.Other ideas were, however, never fully absent. Woody Bledsoe, among others [5,19,103], advocated automated theorem proving based on mathematical knowledge andpractice [13]. Bledsoe’s beautiful quotation above shows his scepticism for purely search-based theorem proving, and in fact he never believed that it would succeed in provingdifficult theorems even in mathematically well-understood domains. He developed a visionof the concepts and procedures necessary for automated theorem proving since he thoughtof himself as “one of the researchers working on resolution type systems who ‘made theswitch’: : : and became convinced that we were on the wrong track” [12].Traditional automated theorem proving is based on general-purpose machine-orientedlogical calculi such as the resolution calculus [104], the tableaux- [114], or the matrixmethods [3,11]. The inference rules of such a calculus span the search space and morethan thirty years of research led to a battery of refinements and strategies to traversethese large (billions of nodes) spaces. In spite of many attempts to the contrary (e.g., thehyperresolution rule), the inference steps defined by these calculi are rather small and low-level when compared with the proof steps of a trained mathematician.Traditional systems such as the MKRP system [33], OTTER [80], SETHEO [72], orSPASS [119] are essentially black boxes; after the input of a theorem and of (hopefully)exactly those axioms necessary for the proof of the theorem and after setting theappropriate parameters, the system searches blindly for a sequence of logic rules thatproves the theorem from the axioms. The search is supported by some general-purpose\fE. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–10567control, called strategies or refinements [75], that is purely syntactic in nature and hardlyreflects mathematical ways of discovering a proof.Now this approach, although far from any mathematical practice and often under attackfrom the more AI-oriented community [45,46], is not entirely unreasonable as, e.g., thechess program Deep Blue has demonstrated which also derives its strength from searchtechniques. Recent success with blind SAT-techniques seems to corroborate even morethe advantages of blind but fast and simple mechanisms over domain-dependent AI-techniques.Just like automated chess and other areas, traditional ATP systems benefit from thetechnological development of faster computers with larger storage—they can now store andsearch billions of clauses and indeed, they do. 2 Due to this improvement and to varioustechnical advances in representational techniques (see for indexing [42]), systems havegained considerable strength and they can prove nontrivial open mathematical problems,such as the Robbins Algebra Conjecture [79], whose proofs are often unintuitive andtherefore tricky for humans. In general, however, most proofs of genuinely mathematicalproblems even in well-understood domains are very much beyond the capabilities of anyof today’s systems. So, after forty years of research the time is ripe again to ask WoodyBledsoe’s question: are we on the wrong track?It appears that this situation is not unique just for automated theorem proving.Over time we become trapped in our shared vision of appropriate ways to tackleproblems, and even more trapped by our funding sources where we must constantlyjustify ourselves by making incremental progress. Sometimes it is worthwhilestepping back and taking an entirely new (or perhaps very old) look at some problemsand to think about solving them in new ways. This takes courage as we may beleading ourselves into different sorts of solutions that will for many years have poorerperformance than existing solutions. With years of perseverance we may be able toovercome initial problems with the new approaches and eventually leapfrog to betterperformance. Or we may turn out to be totally wrong. That is where the couragecomes in.(Rodney Brooks, AAAI-96)1.1. The psychology of mathematical inventionWhy can a mathematician cope with long and complex proofs and what are her strategiesfor avoiding less promising proof paths?Given the current state of knowledge about our human formal reasoning capacity, wedo not know the answer. However, at least the following three observations are generally2 The first theorem prover implemented by the second author in the mid seventies was not untypical for itsgeneration; it could search spaces of several 100,000 clauses, to generate proofs of the length of a dozen steps.Our MKRP system that was under development for almost fifteen years could search spaces of several millionclauses by the end of the eighties to find proofs of about a hundred steps. Todays systems, such as SPASS andOTTER search spaces well in the billions: “Clauses generated: about 3,000,000,000. At the end of the search,about 400,000 clauses were in use. This took 314 hours and used 433 Megabyte of RAM. I guess, for a successfulsearch the search space would be 1/4 as big”. Bill McCune on OTTER’s figures for large search spaces for anopen problem in combinatory logic. Personal communication.\f68E. Melis, J. Siekmann / Artificial Intelligence 115 (1999) 65–105accepted: first, a mathematician’s reasoning is more often than not based on some vividand concrete representation of the problem at hand [43,118]. Secondly, difficult theoremsare not shown from scratch but usually with some known proof technique such as proofby induction, the pigeon hole principle, proof by diagonalization, and so on. In fact, agood mathematician has at least several dozen (but presumably less than a thousand)proof techniques for her particular field at her disposal. Also, there surely are thousands(but probably less than a million) minor tricks of the trade such as when and how toapply a homomorphism, when to differentiate, or how to reformulate a given problem.In hindsight it seems preposterous to assume that all of this can be achieved just by blindsearch. For very difficult and open mathematical problems—usually they are open exactlybecause none of the standard attacks yields a solution—there is the need to combineand reshuffle these standard techniques and so, thirdly and fina",
            {
                "entities": [
                    [
                        41,
                        71,
                        "TITLE"
                    ],
                    [
                        228,
                        258,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 264–277Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom answer set logic programming to circumscription via logic of GKFangzhen Lin a,∗, Yi Zhou ba Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kongb School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Logic programmingAnswer set programmingLogic of GKCircumscriptionNonmonotonic reasoningKnowledge representation and reasoningWe first embed Pearce’s equilibrium logic and Ferraris’s propositional generallogicprograms in Lin and Shoham’s logic of GK, a nonmonotonic modal logic that has beenshown to include as special cases both Reiter’s default logic in the propositional case andMoore’s autoepistemic logic. From this embedding, we obtain a mapping from Ferraris’spropositional general logic programs to circumscription, and show that this mapping canbe used to check the strong equivalence between two propositional logic programs inclassical logic. We also show that Ferraris’s propositional general logic programs can beextended to the first-order case, and our mapping from Ferraris’s propositional generallogic programs to circumscription can be extended to the first-order case as well to providea semantics for these first-order general logic programs.© 2010 Elsevier B.V. All rights reserved.PrologueIt gives us great pleasure to be able to contribute this work to this special issue of Artificial Intelligence in honor of JohnMcCarthy. Like so many others, we have been influenced greatly by McCarthy and his work for as long as we have known AI.This particular work relates McCarthy’s circumscription to several other nonmonotonic logics, and obviously could not havebeen done without McCarthy’s pioneering work on nonmonotonic reasoning in general and circumscription in particular.1. IntroductionAnswer Set Programming (ASP) is a new paradigm of constraint-based programming based on logic programming withanswer set semantics [9,13,17]. It started out with normal logic programs, which are programs that can have negation butnot disjunction. Driven by the need of applications, various extensions have been proposed. These include disjunctive logicprograms [5,6], nested expressions [7], cardinality and weight constraints [16], and others. Recently, Ferraris [2] proposedto view formulas in propositional logic as logic programs and showed that they include as special cases all the abovementioned classes of logic programs. In particular, Ferraris [2] provided a stable model semantics for these formulas usinga transformation similar to the original Gelfond–Lifschitz transformation, and showed that this semantics coincides withPearce’s equilibrium logic [19].In this paper, we show that this general stable model semantics can be embedded in Lin and Shoham’s logic of GK(Grounded Knowledge) [11]. Besides showing the generality of Lin and Shoham’s logic, which was proposed as a generallogic for nonmonotonic reasoning, this embedding allows us to obtain a way to check in classical propositional logic whetherany given two logic programs are strongly equivalent in almost the same way as in [12]. It also allows us to obtain a* Corresponding author.E-mail address: flin@cs.ust.hk (F. Lin).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.001\fF. Lin, Y. Zhou / Artificial Intelligence 175 (2011) 264–277265mapping from general logic programs to propositional circumscription in the same way as Lin and Shoham [11] did formapping normal logic programs to circumscription. As it turned out, this mapping, when extended to first-order case, yieldsa semantics to first-order general logic programs that is similar to the one proposed recently by Ferraris et al. [4].We first briefly review Lin and Shoham’s logic of GK, Ferraris’s general logic programs, and Pearce’s equilibrium logic.2. Logic of GKThe language of the logic of GK is a modal propositional language with two modal operators, K , for knowledge, and A,for assumption. Given a set Atom of atoms (also called variables or primitive propositions), formulas in the logic of GK aredefined inductively below in BNF notation:F ::= ⊥ | p | K (F ) | A(F ) | ¬F | F ∧ F | F ∨ F | F → F ,where p ∈ Atom, and ⊥ is a constant standing for falsity. Formulas without modal operators are called base formulas.The semantics of the logic of GK is defined through Kripke interpretations. A Kripke interpretation M is a tuple(cid:8)W , π , R K , R A, s(cid:9), where W is a nonempty set whose elements are called possible worlds, π is a function that maps apossible world to a truth assignment on Atom, R K and R A are binary relations over W representing the accessibility re-lations for K and A, respectively, and s ∈ W , called the actual world of M. The satisfaction relation |(cid:10) between a Kripkeinterpretation M = (cid:8)W , π , R K , R A, s(cid:9) and a formula F is defined inductively as follows:• M (cid:11)|(cid:10) ⊥;• M |(cid:10) p if π (s)(p) = 1, where p ∈ Atom;• M |(cid:10) ¬F iff M (cid:11)|(cid:10) F ;• M |(cid:10) F ∧ G iff M |(cid:10) F and M |(cid:10) G;• M |(cid:10) F ∨ G iff M |(cid:10) F or M |(cid:10) G;• M |(cid:10) F → G iff M (cid:11)|(cid:10) F or M |(cid:10) G;• M |(cid:10) K (F ) iff (cid:8)W , π , R K , R A, w(cid:9) |(cid:10) F for any w ∈ W , such that (s, w) ∈ R K ;• M |(cid:10) A(F ) iff (cid:8)W , π , R K , R A, w(cid:9) |(cid:10) F for any w ∈ W , such that (s, w) ∈ R A .We say that a Kripke interpretation M is a model of a formula F if M satisfies F . In the following, given a Kripke interpre-tation M, we let(cid:2)K (M) =A(M) =(cid:2)FF(cid:3)(cid:4)(cid:3) F is a base formula and M |(cid:10) K (F )(cid:3)(cid:4)(cid:3) F is a base formula and M |(cid:10) A(F ).,Notice that K (M) and A(M) are always closed under classical logical entailment. In the following, for any set X of formulas,we let Th( X) be the logical closure of X under classical logic.Informally in GK, one assumes A(M) and minimizes K (M). When the assumed A(M) turns out to be the same as theminimal K (M), an equilibrium is reached, and the assumption is said to be “justified” or the knowledge is said to be“grounded”. Formally, GK models are defined as follows.Definition 2.1 (GK models). Given a formula F , a Kripke interpretation M is a minimal model of F if M is a model of F andthere does not exist another model M1 of F such that A(M1) = A(M) and K (M1) ⊂ K (M). We say that M is a GK model1 ifM is a minimal model of F and K (M) = A(M).Lin and Shoham showed that the logic of GK can be used to capture Reiter’s default logic [20] and Moore’s auto-epistemiclogic [15]. As a consequence, normal logic programs under stable model semantics can be captured in the logic of GK aswell. Specifically, they showed that a normal ruler ← p1, . . . , pn, not q1, . . . , not qmcan be translated into the following sentence in the logic of GK:Kp1∧ · · · ∧ Kpn∧ ¬Aq1∧ · · · ∧ ¬Aqm→ Kr.(1)They also showed that this translation extends to disjunctive logic programs.In this paper, we shall show that general logic programs proposed by Ferraris [2] can be captured in the logic of GK aswell.1 In [11], GK models are called preferred models.\f266F. Lin, Y. Zhou / Artificial Intelligence 175 (2011) 264–2773. General logic programsGiven a set Atom of atoms, general logic programs [3] are formulas defined inductively below in BNF notation:F ::= ⊥ | p | F ∧ F | F ∨ F | F → F ,where p ∈ Atom. Notice that there is no negation in the language. Instead, for any formula F , ¬F is considered to be ashorthand for F → ⊥.A set X ⊆ Atom of atoms can be considered as a truth assignment in the straightforward way:X (cid:11)|(cid:10) ⊥,X |(cid:10) p iff p ∈ X,and the usual definition for the logical connectives.The stable models of a formula (general logic program) are defined by a modified extended Gelfond–Lifschitz transforma-tion. Given a general logic program F , and a set X of atoms, the reduct of F under X [2], written F X , is the formula obtainedfrom F by replacing each maximal subformula that is not classically satisfied by X with ⊥. Thus for example,(¬F ) X =(cid:5)(cid:15), X |(cid:10) ¬F ,⊥, otherwise.Now a set X of atoms is a stable model of a general logic program F if:(i) X |(cid:10) F X ;(ii) there is no proper subset X1 of X , such that X1 |(cid:10) F X .Example 3.1. Consider the following three general logic programs.P = ¬p → q,Q = ¬p ∨ p,R = p → ¬¬p,is ¬⊥ → q, which is satisfiedwhere p, q are atoms. The maximal subformula in P that is false under {q} is p, thus Pby {q}, but not by ∅. Therefore, {q} is a stable model of P . On the other hand, Pis ⊥ → ⊥, which is satisfied by {p} aswell as its subset ∅. Therefore, {p} is not a stable model of P . It can be seen that {q} is the only stable model of P . Similarly,it can be shown that Q has two stable models, {p} and ∅, and R has exactly one stable model ∅.{p}{q}4. Pearce’s equilibrium logicPearce’s equilibrium logic [19] is based on the logic of here-and-there, a non-classical logic. Given a set Atom of atoms,formulas of Atom are exactly the same as in the case of general logic programs. Thus, negation in equilibrium logic isconsidered a shorthand as well.The semantics of the logic of here-and-there is defined in terms of HT-interpretations, which are pairs (cid:8) X, Y (cid:9) of setsof atoms such that X ⊆ Y . The HT satisfaction relation2 |(cid:10) between an HT-interpretation (cid:8) X, Y (cid:9) and a formula F is definedrecursively as follows:• For p ∈ Atom, (cid:8) X, Y (cid:9) |(cid:10) p if p ∈ X ;• (cid:8) X, Y (cid:9) (cid:11)|(cid:10) ⊥;• (cid:8) X, Y (cid:9) |(cid:10) F ∧ G if (cid:8) X, Y (cid:9) |(cid:10) F and (cid:8) X, Y (cid:9) |(cid:10) G;• (cid:8) X, Y (cid:9) |(cid:10) F ∨ G if (cid:8) X, Y (cid:9) |(cid",
            {
                "entities": [
                    [
                        136,
                        204,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 132 (2001) 39–103Computer Go: An AI oriented surveyBruno Bouzy a,∗, Tristan Cazenave ba Université René Descartes (Paris V), UFR de mathématiques et d’informatique, C.R.I.P.5, 45,rue des Saints-Pères, 75270 Paris Cedex 06, Franceb Université Paris 8, Département Informatique, Laboratoire IA 2, rue de la Liberté,93526 Saint-Denis Cedex, FranceReceived 4 May 2000; received in revised form 21 November 2000AbstractSince the beginning of AI, mind games have been studied as relevant application fields. Nowadays,some programs are better than human players in most classical games. Their results highlight theefficiency of AI methods that are now quite standard. Such methods are very useful to Go programs,but they do not enable a strong Go program to be built. The problems related to Computer Go requirenew AI problem solving methods. Given the great number of problems and the diversity of possiblesolutions, Computer Go is an attractive research domain for AI. Prospective methods of programmingthe game of Go will probably be of interest in other domains as well. The goal of this paper is topresent Computer Go by showing the links between existing studies on Computer Go and differentAI related domains: evaluation function, heuristic search, machine learning, automatic knowledgegeneration, mathematical morphology and cognitive science. In addition, this paper describes boththe practical aspects of Go programming, such as program optimization, and various theoreticalaspects such as combinatorial game theory, mathematical morphology, and Monte Carlo methods. 2001 Elsevier Science B.V. All rights reserved.Keywords: Computer Go survey; Artificial intelligence methods; Evaluation function; Heuristic search;Combinatorial game theory; Automatic knowledge acquisition; Cognitive science; Mathematical morphology;Monte Carlo methods1. IntroductionSince the beginning of AI, mind games, such as Checkers [114,115] or Chess [121],have been studied as application fields for AI. Nowadays, some programs are better than* Corresponding author.E-mail addresses: bouzy@math-info.univ-paris5.fr (B. Bouzy), cazenave@ai.univ-paris8.fr (T. Cazenave).0004-3702/01/$ – see front matter  2001 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 1 2 7 - 8\f40B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103human players in most classical games: Deep Blue in Chess [4,67], Chinook in Checkers[117,118], Logistello in Othello [25], Victoria in Go-moku [3]. These results highlight theefficiency of AI methods that are now quite standard.These methods are very useful to Go programs. However, by themselves, they donot enable the AI community to build a strong Go program. The problems related toComputer Go require new AI problem solving methods. Given the abundance of problems,and the diversity of possible solutions, Computer Go is an attractive research domainfor AI. Prospective methods of programming the game of Go will probably be of interestin other domains—for example tree search in classical games is related to AND-ORtree solving, theorem proving, and constraint satisfaction. The current cornerstone ingame programming is the Alpha-Beta algorithm. It was discovered in the early stages ofAI research, and has been regularly improved ever since. Computer Go programmers arestill looking for their cornerstone, which will certainly be more complex than for othergames. The Computer Go community has reached an agreement on some unavoidablelow level modules such as tactical modules, but specialists still disagree on some otherimportant points. Future programs will probably use the best of all the current possibilities,and link them together in a harmonious way.The goal of this paper is to present Computer Go by showing the links between existingstudies on Computer Go and different AI related domains: evaluation function, heuristicsearch, machine learning, automatic knowledge generation, mathematical morphology andcognitive science.To show where the difficulty of Go programming lies, it is first necessary to comparethe game of Go to other classical games in a conventional way. In Section 2, we showthat the combinatorial complexity is much higher in Go than in other two-player, completeinformation, games. We also point out that the evaluation of a position can be very complex.Therefore, unlike other games, Section 3 shows that Go programs have poor rankings inthe human ranking system and deals with the results obtained when computers competeagainst human players and when computers play against other computers.As usual with computer games, we introduce the architecture of a Go program. Weexamine: the evaluation function, in Section 4; move generation, in Section 5; and treesearch, in Section 6. After expounding the key concepts of the evaluation function, basedon numerous concepts and viewpoints, we focus on the relationships between tree searchand the evaluation function. Tree search is used, both to find a good move in using theevaluation function, and to perform tactical computations useful to calculate the evaluationfunction.However, the architecture of a Go program is not composed of these two parts alone.The notion of abstraction plays an important role in Go, and Go programs exhibit structureat different levels, the highest level being the strategic level, and the lowest level being thetactical level. In order to be competitive, every level of a Go program has to be optimized.Therefore Go programmers spend much of their time on optimizations. In Section 7, wepresent some examples of possible optimizations at different levels of abstraction.In Section 8, closely related with mathematics, we examine combinatorial gametheory [43], which deals with games as the sum of independent sub-games. The game ofGo is a global game that can be broken down into many local sub-games. Although localsub-games are generally dependent, this theory offers an appropriate model for the game\fB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10341of Go. More precisely, the strategic level of a program may represent each tactical gameby a combinatorial game. This theory is better applied to the end of the game, when localsub-games become independent, and it enables the calculation of the value of the very lastmoves of the endgame with greater accuracy. In some positions devised to illustrate thistheory, some programs play better than the best professional players. The major currentdifficulty in applying this theory to other sub-games of Go arises from the high dependencebetween local sub-games.A problem inherent in Computer Go is that the models with the best results use a lot ofknowledge. This need for knowledge makes machine learning, and automatic generationof knowledge, attractive. The best method to obtain an average Go program very rapidlyis undoubtedly the temporal difference method. Some symbolic approaches have alsobeen tried, in an attempt automatically to generate tactical knowledge. The two symbolicmethods which yield good results are retrograde analysis of small patterns, and logicmetaprogramming. By using them, a large number of tactical rules can be generated forthe tactical levels of a Go program. We present the different methods that automaticallygenerate Go knowledge in Section 9.In Section 10, we present a surprisingly effective technique that works quite well for Go:Monte Carlo Go. This technique uses hardly any Go knowledge. However, a very simpleprogram, using this technique, beats classical, and much more complex, programs on smallboards (9 × 9).The game of Go is a very visual game. Since the beginning of Computer Go, manymodels of influence have been set up. We provide a formalization of these models withsome classical operators of mathematical morphology, in Section 11.Go is so complex that it can be used to perform interesting cognitive experiments, withina formal setting imposed by the rules of the game. Section 12 centers on the studies carriedout on Go, using a cognitive approach.The material used in this survey is based on existing Computer Go publications andon the authors’ own experience of writing Go programs. Unfortunately, programs whoseauthors do not describe their algorithms and, furthermore, keep them secret, do notexplicitly appear in this survey. Nevertheless, for the strongest commercial programsin this category, we tried to gather some personal communications that were sent tothe Computer Go mailing list. We could then mention these programs, and give shortdescriptions of them. We also base descriptions of the main components of this surveyon our own experience of writing Go programs: Indigo [15,17,18,20,21], Gogol [28–30]and Golois [32–34]. We think that Computer Go remains a new domain for computerscience, and so far, no clear theoretical model has emerged. The domain greatly benefitsfrom studies based on practical experiments. For instance, the Evaluation Function sectionmainly refers to the Indigo program, and the Automatic Knowledge Generation section toGolois. Nevertheless, we do not limit our descriptions to these programs, and enlarge uponthem using the relevant Computer Go publications.We choose not to include the rules of the game of Go in this paper. If the reader wishesto know them, he can refer to http://www.usgo.org/resources/whatisgo.html where he willfind the definitions of “intersection”, “stone”, “string”, “liberty”, “atari”, “ko”, “group”,“eye”, “tsumego”, “life”, “death”, “territory”, “influence”, “handicap”, “kyu” and “dan”which are Go concepts used by our paper.\f42B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–1032. Other games2.1. IntroductionThis section centers on the current achievements in computer implementations of othertwo-player, complete information, and zero-sum, games, which we also call “other games”.Our aim is to show that the game of Go is more complex than these “other games”. First, wefocus on the detailed results fo",
            {
                "entities": [
                    [
                        41,
                        75,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 240 (2016) 36–64Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintNasari: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entitiesJosé Camacho-Collados a,∗a Department of Computer Science, Sapienza University of Rome, Italyb Language Technology Lab, Department of Theoretical and Applied Linguistics, University of Cambridge, United Kingdom, Mohammad Taher Pilehvar b,1, Roberto Navigli aa r t i c l e i n f oa b s t r a c tArticle history:Received 23 December 2015Received in revised form 14 July 2016Accepted 25 July 2016Available online 16 August 2016Keywords:Semantic representationLexical semanticsWord Sense DisambiguationSemantic similaritySense clusteringDomain labelingOwing to the need for a deep understanding of linguistic items, semantic representation is considered to be one of the fundamental components of several applications in Natural Language Processing and Artificial Intelligence. As a result, semantic representation has been one of the prominent research areas in lexical semantics over the past decades. However, due mainly to the lack of large sense-annotated corpora, most existing representation techniques are limited to the lexical level and thus cannot be effectively applied to individual word senses. In this paper we put forward a novel multilingual vector representation, called Nasari, which not only enables accurate representation of word senses in different languages, but it also provides two main advantages over existing approaches: (1) high coverage, including both concepts and named entities, (2) comparability across languages and linguistic levels (i.e., words, senses and concepts), thanks to the representation of linguistic items in a single unified semantic space and in a joint embedded space, respectively. Moreover, our representations are flexible, can be applied to multiple applications and are freely available at http :/ /lcl .uniroma1.it /nasari/. As evaluation benchmark, we opted for four different tasks, namely, word similarity, sense clustering, domain labeling, and Word Sense Disambiguation, for each of which we report state-of-the-art performance on several standard datasets across different languages.© 2016 Elsevier B.V. All rights reserved.1. IntroductionSemantic representation, i.e., modeling the semantics of a linguistic item2 in a mathematical or machine interpretable form, is a fundamental problem in Natural Language Processing (NLP) and Artificial Intelligence (AI). Because they represent the lowest linguistic level, word senses play a vital role in natural language understanding. Effective representations of word senses can be directly useful to Word Sense Disambiguation [93], semantic similarity [13,129,106], coarsening sense inven-tories [92,124], alignment of lexical resources [101,98,108], lexical substitution [75], and semantic priming [100]. Moreover, sense-level representation can be directly extended to applications requiring word representations, with the added bene-fit that it provides extra semantic information. Turney and Pantel [129] provide a review of some of the applications of * Corresponding author.E-mail address: collados@di.uniroma1.it (J. Camacho-Collados).1 Work mainly done at the Sapienza University of Rome.2 Throughout this article by a linguistic item we mean any kind of linguistic unit that can bear a meaning, i.e., a word sense, a word, a phrase, a sentence or a larger piece of text.http://dx.doi.org/10.1016/j.artint.2016.07.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\fJ. Camacho-Collados et al. / Artificial Intelligence 240 (2016) 36–6437word representation, including: automatic thesaurus generation [21,22], word similarity [25,128,113] and clustering [103], query expansion [140], information extraction [61], semantic role labeling [29,104], spelling correction [53], and Word Sense Disambiguation [93].The Vector Space Model (VSM) is a prominent approach for semantic representation. The model represents a linguistic item as a vector (or a point) in an n-dimensional semantic space, i.e., a mathematical space wherein each of the n dimen-sions (hence, axes of the space) denotes a single linguistic entity, such as a word. The popularity of the VSM representation is due to two main reasons. Firstly, it is straightforward to view vectors as sets of features and directly apply various ma-chine learning techniques on them. Secondly, the model enjoys support from the field of Cognitive Science wherein several studies have empirically or theoretically suggested that various aspects of human cognition accord with VSMs [36,64].However, most VSM-based techniques, whether in their conventional co-occurrence based form [119,129,63], or in their newer predictive branch [20,81,8], usually base their computation on the distributional statistics derived from text corpora. Hence, in order to be able to represent individual meanings of words (i.e., word senses), these techniques require large amounts of disambiguated text prior to modeling. Additionally, Word Sense Induction techniques [103,11,58,27] require sense-annotated data, if their induced sense clusters are to be mapped to an existing sense inventory. However, providing sense-annotated data on a large scale is a time-consuming process which has to be carried out separately for each word sense and repeated for each new language of interest, i.e., the so-called knowledge acquisition bottleneck. Importantly, the largest manual effort for providing a wide-coverage sense-annotated dataset dates back to 1993, in the case of the SemCor corpus [85]. In fact, although cheap and fast annotations could be obtained by means of Amazon Mechanical Turk [123,55], games with a purpose [133,131,56], or voluntary collaborative editing such as in Wikipedia [77], producing annotated resources manually is still an onerous task. On the other hand, the performance of Word Sense Disambiguation (WSD) techniques is still far from ideal [93], which in its turn prevents a reliable automatic sense-annotation of large text corpora that can be used for modeling individual word senses. This hinders the functionality of this group of vector space models in tasks such as WSD that require the representation of individual word senses.There have been several efforts to adapt and apply distributional approaches to the representation of word senses [103,12,114,47,68]. However, most of these techniques cannot provide representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data [48]. Recently, there have been attempts to address this issue and to obtain vectors for individual word senses by exploiting the WordNet semantic network [74,106,108,116] and its glosses [19]. These approaches, however, are either restricted to the representation of concepts defined in WordNet and to the English language only, or are designed for specific tasks.In our recent work [16], we proposed a method that exploits the structural knowledge derived from semantic networks, together with distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our approach provides two main advantages in comparison to previous VSM techniques. Firstly, it is multilingual, as it can be directly applied for the representation of concepts in dozens of languages. Secondly, each vector represents a concept, irrespective of its language, in a unified semantic space having concepts as its dimensions, permitting direct comparison of different representations across languages and hence enabling cross-lingual applications.In this article, we improve our approach, referred to as Nasari (Novel Approach to a Semantically-Aware Representation of Items) henceforth, and extend their application to a wider range of tasks in lexical semantics. Specifically, the novel contributions are as follow:1. We propose a new formulation for fast computation of lexical specificity (Section 3.1.1).2. We propose a new flexible way to get continuous embedded vector representations, with the added benefit of obtaining a semantic space shared by BabelNet synsets, words and texts (Section 3.3).3. We put forward a technique for improved computation of weights in the unified vectors and show how it can improve the accuracy and efficiency of the representations (Section 3.4).4. We compute and assign weights to individual edges in our semantic network (Section 4.1) and show by means of different experiments the advantage we gain when using this new weighted graph (Section 10).5. We release the lexical and unified vector representations for five different languages (English, French, German, Italian and Spanish) and the embedded vector representations for the English language at http :/ /lcl .uniroma1.it /nasari/.In addition to these contributions, we also devised robust frameworks that enable direct application of our representa-tions to four different tasks: Semantic Similarity (Section 6), Sense Clustering (Section 7), Domain Labeling (Section 8) and Word Sense Disambiguation (Section 9). For each of the tasks, we carried out a comprehensive set of evaluations on several datasets in order to verify the reliability and flexibility of Nasari different datasets and tasks. We provide a summary of the experiments in Section 5.The rest of this article is structured as follows. We first provide an introduction of some of the most widely used knowl-edge resources in lexical semantics, in Section 2. After which, in Section 3 we describe our methodology to convert text into lexical, embedded and unified vectors. The process to obtain vector representations for synset vectors by leveraging the knowledge resources described in Section 2, and the methodology to obtain vectors from text described in Section 3, is presented in S",
            {
                "entities": [
                    [
                        134,
                        253,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 133 (2001) 139–188Reasoning about nonlinear system identificationElizabeth Bradley a,∗,1, Matthew Easley b,1, Reinhard Stolle c,2a Department of Computer Science, University of Colorado, Campus Box 430, Boulder, CO 80309-0430, USAb Rockwell Science Center, 444 High Street, Suite 400, Palo Alto, CA 94301, USAc Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA 94304, USAReceived 19 May 2000; received in revised form 4 May 2001AbstractSystem identification is the process of deducing a mathematical model of the internal dynamics ofa system from observations of its outputs. The computer program PRET automates this process bybuilding a layer of artificial intelligence (AI) techniques around a set of traditional formal engineeringmethods. PRET takes a generate-and-test approach, using a small, powerful meta-domain theory thattailors the space of candidate models to the problem at hand. It then tests these models againstthe known behavior of the target system using a large set of more-general mathematical rules. Thecomplex interplay of heterogeneous reasoning modes that is involved in this process is orchestratedby a special first-order logic system that uses static abstraction levels, dynamic declarative metacontrol, and a simple form of truth maintenance in order to test models quickly and cheaply. Unlikeother modeling tools—most of which use libraries to model small, well-posed problems in limiteddomains and rely on their users to supply detailed descriptions of the target system—PRET workswith nonlinear systems in multiple domains and interacts directly with the real world via sensors andactuators. This approach has met with success in a variety of simulated and real applications, rangingfrom textbook systems to real-world engineering problems.  2001 Elsevier Science B.V. All rightsreserved.Keywords: Automated model building; System identification; Qualitative reasoning; Qualitative physics;Knowledge representation framework; Reasoning framework; Input-output modeling* Corresponding author.E-mail addresses: lizb@cs.colorado.edu (E. Bradley), me@rpal.rockwell.com (M. Easley),rstolle@parc.xerox.com (R. Stolle).1 Supported by NSF NYI #CCR-9357740, ONR #N00014-96-1-0720, and a Packard Fellowship in Scienceand Engineering from the David and Lucile Packard Foundation.2 Research performed while a research assistant at the University of Colorado at Boulder and during apostdoctoral fellowship at Stanford University funded by the German Academic Exchange Service (DAAD)“Gemeinsames Hochschulsonderprogramm III von Bund und Ländern”.0004-3702/01/$ – see front matter  2001 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 1 4 3 - 6\f140E. Bradley et al. / Artificial Intelligence 133 (2001) 139–1881. IntroductionOne of the most powerful analysis and design tools in existence—and often one ofthe most difficult to create—is a good model. Modeling is an essential first step in avariety of engineering problems. Faced with the task of designing a controller for arobot arm, for instance, a mechanical engineer performs a few simple experiments on thesystem, observes the resulting behavior, makes some informed guesses about what modelfragments could account for that behavior, and then combines those terms into a modeland checks it against the physical system. This model then becomes the mathematical coreof the controller. Accuracy is not the only requirement; for efficiency reasons, engineerswork hard to construct minimal models—those that ignore unimportant details and captureonly the behavior that is important for the task at hand. The subtlety of the reasoning skillsinvolved in this process, together with the intricacy of the interplay between them, has ledmany of its practitioners to classify modeling as “intuitive” and “an art” [69].The computer program PRET, the topic of this paper, formalizes these intuitions andautomates a coherent and useful part of this art. PRET is an automated tool for nonlinearsystem identification. Its inputs are a set of observations of the outputs of a target system,some optional hypotheses about the physics involved, and a set of tolerances within whicha successful model must match the observations; its output is an ordinary differentialequation (ODE) model of the internal dynamics of that system. See Fig. 1 for a blockdiagram. PRET uses a small, powerful domain theory to build models and a larger, more-general mathematical theory to test them. It is designed to work in any domain that admitsODE models; adding a new domain is simply a matter of coding one or two simple domainrules. Its architecture wraps a layer of artificial intelligence (AI) techniques around a set oftraditional formal engineering methods. This AI layer incorporates a variety of reasoningmodes: qualitative reasoning, qualitative simulation, numerical simulation, geometricreasoning, constraint propagation, resolution, reasoning with abstraction levels, declarativemeta control, and a simple form of truth maintenance. Models are represented usinga component-based modeling framework that accommodates different domains, adaptssmoothly to varying amounts of domain knowledge, and allows expert users to createmodel-building frameworks for new application domains easily. An input-output modelingsubsystem allows PRET to observe target systems actively, manipulating actuators andreading sensors to perform experiments whose results augment its knowledge in a mannerthat is useful to the modeling problem that it is trying to solve. The entire reasoning processFig. 1. PRET combines AI and formal engineering techniques to build ODE models of nonlinear dynamicalsystems. It uses domain-specific knowledge to build models and an encoded ODE theory to test them, and itinteracts directly and autonomously with target systems using sensors and actuators.\fE. Bradley et al. / Artificial Intelligence 133 (2001) 139–188141Fig. 2. The system identification (SID) process. Structural identification yields the general form of the model; inparameter estimation, values for the unknown coefficients in that model are determined. PRET automates bothphases of this process.is orchestrated by a special first-order logic inference system, which automatically chooses,invokes, and interprets the results of the techniques that are appropriate for each point inthe model-building procedure. This combination of techniques lets PRET shift fluidly backand forth between domain-specific reasoning, general mathematics, and actual physicalexperiments in order to navigate efficiently through an exponential search space of possiblemodels.In general, system identification proceeds in two interleaved phases: first, structuralidentification, in which the form of the differential equation is determined, and thenparameter estimation, in which values for the coefficients are obtained. If structuralidentification produces an incorrect ODE model, no coefficient values can make itssolutions match the sensor data. In this event, the structural identification process mustbe repeated—often using information about why the previous attempt failed—until theprocess converges to a solution, as shown diagrammatically in Fig. 2. In linear physicalsystems, structural identification and parameter estimation are fairly well understood.The difficulties—and the subtleties employed by practitioners—arise where noisy orincomplete data are involved, or where efficiency is an issue. See [59,66] for someexamples. In nonlinear systems, however, both procedures are vastly more difficult—thetype of material that is covered only in the last few pages of standard textbooks.Unlike system identification software used in the control theory community, PRET is notjust an automated parameter estimator; rather, it uses sophisticated reasoning techniques toautomate the structural phase of model building as well. The basic paradigm is “generateand test”. PRET first uses its encoded domain theory—the upper ellipse in Fig. 1—toassemble combinations of user-specified and automatically generated ODE fragments intoa candidate model. In a mechanics problem, for instance, the generate phase uses Newton’slaws to combine force terms; in electronics, it uses Kirchhoff’s laws to sum voltages in aloop or currents in a cutset. In order to test a candidate model, PRET performs a series ofinferences about the model and the observations that the model is to match. This processis guided by two important assumptions: that abstract reasoning should be chosen over\f142E. Bradley et al. / Artificial Intelligence 133 (2001) 139–188lower-level techniques, and that any model that cannot be proved wrong is right. PRET’sinference engine uses an encoded mathematical theory (the lower ellipse in Fig. 1) to searchfor contradictions in the sets of facts inferred from the model and from the observations. AnODE that is linear, for instance, cannot account for chaotic behavior; such a model shouldfail the test if the target system has been observed to be chaotic. Furthermore, establishingwhether an ODE is linear is a matter of simple symbolic algebra, so the inference engineshould not resort to a numerical integration to establish this contradiction. Like the domaintheory, PRET’s ODE theory is designed to be easily extended by an expert user.To make these ideas more concrete, consider the spring/mass system shown at the topright of Fig. 3. To instruct PRET to build a model of this system, a user would enterthe find-model call at the left of the figure. (PRET also has a GUI that leads usersthrough this interaction without subjecting them to this syntax.) The domain statementinstantiates the relevant domain theory; the next two lines inform PRET that the systemFig. 3. Modeling a simple spring/mass system. In this example call to PRET, the user first sets up the problem, thenmakes five observations about the position coordinates q1 and q2, hypothesizes nine different force terms, andfinally specifies resolution an",
            {
                "entities": [
                    [
                        42,
                        89,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 914–927Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the phase transitions of random k-constraint satisfaction problemsYun Fan a, Jing Shen a,b,∗a Department of Mathematics, Central China Normal University, Wuhan, 430079, Chinab School of Science, Naval University of Engineering, Wuhan, 430033, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 29 July 2010Received in revised form 11 November 2010Accepted 11 November 2010Available online 13 November 2010Keywords:Constraint satisfaction problemPhase transitionConstraint satisfaction has received increasing attention over the years. Intense researchhas focused on solving all kinds of constraint satisfaction problems (CSPs). In this paper,first we propose a random CSP model, named k-CSP, that guarantees the existence ofphase transitions under certain circumstances. The exact location of the phase transitionis quantified and experimental results are provided to illustrate the performance ofthe proposed model. Second, we revise the model k-CSP to a random linear CSP byincorporating certain linear structure to constraint relations. We also prove the existenceof the phase transition and exhibit its exact location for this random linear CSP model.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConstraint satisfaction problem, or CSP in short, is represented by a finite set of variables, each one of which is associatedwith a domain, and a finite set of constraints, each of which consists of a subset of the variables, called a constraint scope, anda constraint relation that restricts the values of the variables in the constraint scope can simultaneously take. The objectiveis to assign a value to each variable satisfying all the constraint relations. CSP is an important topic in the area of computerscience, especially in artificial intelligence, since the regularity in their formulation provides a common base to analyze andsolve the problems of many unrelated families. In recent years, the random CSP and the corresponding phase transitionshave attracted more and more attention since Cheeseman et al. proposed in [7] that many hard instances should be foundat the phase transition points.There have been various models for investigating the phase transitions of random CSP proposed by various academiccommunities, e.g. [2,10–12,17–19,27–29]. The initial standard models, named A, B, C and D [23,28], were proposed togenerate random binary CSP instances. Experiments showed that the standard models [23,28] all exhibit a “threshold-like”behavior. On the other hand, it has been proved theoretically by Achlioptas et al. in [1] that the random instances generatedby the standard models do not have an asymptotic threshold when the length of constraint scopes and the size of domainsare fixed.Improvement of the performance of standard models was addressed from various perspectives in numerous efforts[1,21–23,26,31]. Some new models incorporated special combinatorial structures on the constraints. In other words, theconstraints are subject to certain combinatorial restrictions and the restrictions ensure that the generated instances arearc consistent [23], path consistent [21], strongly 3-consistent [22] or weakly 4-consistent [22]. It has been proved that allthese revised models have non-trivial asymptotic behaviors. While the combinatorial structures provide the capability forproducing phase transitions, this achievement typically comes at the price of more restrictions on the constraint relationsof instances.Based on the model B [28] mentioned previously, Xu and Li [31] proposed a random CSP model, named model RB.Instead of fixing the size of domains associated with each instance as in the model B, the size of domains of the model RB* Corresponding author at: Department of Mathematics, Central China Normal University, Wuhan, 430079, China.E-mail addresses: yunfan02@yahoo.com.cn (Y. Fan), shendina@hotmail.com (J. Shen).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.004\fY. Fan, J. Shen / Artificial Intelligence 175 (2011) 914–927915is uniform for each instance and the value of the size is variant as a power function of the cardinality of the set of variables,i.e. the number of variables. On the other hand, the length of constraint scopes and the tightness of constraint relationsfor each instance of the model RB are fixed. It has been proved theoretically in [1] that model B does not have the phasetransition point over most of the parameter space. Due to incorporating uniformly variant domain size, the revised modelRB does have phase transitions and the exact phase transition points have been quantified by Xu and Li [31]. Moreover,it has been demonstrated that the model RB has a lot of hard instances existing [32] and all the instances at the phasetransition points have exponential tree-resolution complexity [30]. Compared with revised models in [21–23], the capabilityof generating instances is dramatically enhanced for the model RB due to the fact that there is no combinatorial restrictionenforced on the constraint relations of model RB. Generally speaking, it is natural and relatively easier for the model RB togenerate asymptotically non-trivial CSP instances with relatively large domain size.Another area of active research in the field of CSP is the development of k-SAT, where k denotes the length of theconstraint scopes. It is proved by Friedgut in [17] that a phase transition exists for k-SAT if k is fixed. However, for fixed kwith k (cid:2) 3, there is still no effective method to obtain the exact location of the phase transition. For example, it is alreadyderived theoretically in [24] and [14] that the best lower bound and upper bound of the phase transition for 3-SAT are3.53 and 4.506 respectively; but the exact location is still under investigation. When compared with the results for k-SATwith fixed k, it has been demonstrated that it is possible for k-SAT to ascertain the exact location of phase transitions if theparameter k is growing moderately, as detailed in [16,20].Motivated by k-SAT with growing k in [20], in this paper first we revise the model RB in [31] to propose a new randomCSP model, named model k-CSP. When comparing with the model RB in [20], instead of fixing the parameters of constraints,including both the length of constraint scopes and the tightness of constraint relations, and varying the size of domains asa power function, for the new model k-CSP we assume that the size of domains and the tightness of constraint relations arefixed and the length of constraint scopes, which is denoted by k, is variant as a function of n, where n denotes the cardinalityof the set of variables. Although similar to k-SAT, the new proposed model k-CSP has growing length of constraint scopes,the two models are essentially different from each other, more specifically, the tightness of constraint relations is variant fork-SAT while is fixed for the model k-CSP. For the new model k-CSP we theoretically prove the existence of a phase transitionwhen the parameter k grows up to a logarithm function of n, and determine the exact location of the phase transition point.Further, we experimentally demonstrate the performance of the proposed model k-CSP. The experiments we conducted onthe k-CSP not only verify the theoretical results we established, but also illustrate that the computational complexity of thek-CSP grows exponentially with n (the number of variables) and the worse-cases happen around the phase transition point.We note that, the model k-CSP can generate instances as easily as the model RB since there is no other restrictions on theconstraint relations except the fixed tightness; on the other hand, the parameter k of the model k-CSP is growing up veryslowly as a logarithm function rather than the power function appearing in the model RB. In summary, the model k-CSPcan easily and naturally generate asymptotically non-trivial CSP instances within a reasonably small range of domain sizeand constraint scope length, thus it is very suitable for testing the capability of CSP algorithms.The algebraic CSP, which employs algebraic structures to the domains and the constraint relations of CSP model, isanother popular approach to construct a CSP model. We note that the algebraic CSP approach has received considerableattention in recent years [4]. One classical example of algebraic CSPs is the linear CSP, which domains are finite fields andconstraint relations are affine subspaces of the vector spaces over the finite fields. One of the major advantages of variouslinear CSP models [3,5,6,8,9,13,15] is that they all exhibit satisfiability thresholds. This motivates our other research inconstructing a random CSP model that combines the model k-CSP mentioned above with the linear CSP model.To combine the advantages of linear CSP and the model k-CSP, we incorporate certain algebraic structure to the domainsand constraint relations of k-CSP and then introduce another type of random linear CSP model, named k-hyper-F-linearCSP. For each instance of the new proposed model, we assume that the domain could be any finite field, which is denotedby F; the constraint relations are randomly chosen from the hyperplanes of the vector space Fk, where k is the lengthof constraint scopes. Similar to the model k-CSP, the length of constraint scopes k is uniformly variant as a function of n,where n denotes the number of variables. We exhibit theoretically the exact phase transition of the model k-hyper-F-linear CSP. When comparing with the linear CSP models from [3,5,6,8,9,13], we provide a more general formulation anda new proof based on a more general argument, which make the k-hyper-F-linear CSP model more widely applicable inpractice.This paper is organized as follows. Section 2 states some preliminary definitions, introduces the random model k-CSPand ",
            {
                "entities": [
                    [
                        136,
                        205,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 210 (2014) 78–122Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe dropout learning algorithmPierre Baldi∗, Peter SadowskiDepartment of Computer Science, University of California, Irvine, CA 92697-3435, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 11 June 2013Received in revised form 18 February 2014Accepted 18 February 2014Available online 24 February 2014Keywords:Machine learningNeural networksEnsembleRegularizationStochastic neuronsStochastic gradient descentBackpropagationGeometric meanVariance minimizationSparse representationsDropout is a recently introduced algorithm for training neural networks by randomlydropping units during training to prevent their co-adaptation. A mathematical analysisof some of the static and dynamic properties of dropout is provided using Bernoulligating variables, general enough to accommodate dropout on units or connections, andwith variable rates. The framework allows a complete analysis of the ensemble averagingproperties of dropout in linear networks, which is useful to understand the non-linearcase. The ensemble averaging properties of dropout in non-linear logistic networks resultfrom three fundamental equations: (1) the approximation of the expectations of logisticfunctions by normalized geometric means, for which bounds and estimates are derived;(2) the algebraic equality between normalized geometric means of logistic functions withthe logistic of the means, which mathematically characterizes logistic functions; and (3) thelinearity of the means with respect to sums, as well as products of independent variables.The results are also extended to other classes of transfer functions, including rectifiedlinear functions. Approximation errors tend to cancel each other and do not accumulate.Dropout can also be connected to stochastic neurons and used to predict firing rates,and to backpropagation by viewing the backward propagation as ensemble averagingin a dropout linear network. Moreover, the convergence properties of dropout can beunderstood in terms of stochastic gradient descent. Finally, for the regularization propertiesof dropout, the expectation of the dropout gradient is the gradient of the correspondingapproximation ensemble, regularized by an adaptive weight decay term with a propensityfor self-consistent variance minimization and sparse representations.© 2014 The Authors. Published by Elsevier B.V.Open access under CC BY-NC-ND license.1. IntroductionDropout is a recently introduced algorithm for training neural networks [27]. In its simplest form, on each presentationof each training example, each feature detector unit is deleted randomly with probability q = 1 − p = 0.5. The remainingweights are trained by backpropagation [40]. The procedure is repeated for each example and each training epoch, shar-ing the weights at each iteration (Fig. 1.1). After the training phase is completed, predictions are produced by halving allthe weights (Fig. 1.2). The dropout procedure can also be applied to the input layer by randomly deleting some of theinput-vector components—typically an input component is deleted with a smaller probability (i.e. q = 0.2).The motivation and intuition behind the algorithm is to prevent overfitting associated with the co-adaptation of featuredetectors. By randomly dropping out neurons, the procedure prevents any neuron from relying excessively on the output ofany other neuron, forcing it instead to rely on the population behavior of its inputs. It can be viewed as an extreme form of* Corresponding author.E-mail address: pfbaldici@uci.edu (P. Baldi).http://dx.doi.org/10.1016/j.artint.2014.02.0040004-3702 © 2014 The Authors. Published by Elsevier B.V.Open access under CC BY-NC-ND license.\fP. Baldi, P. Sadowski / Artificial Intelligence 210 (2014) 78–12279Fig. 1.1. Dropout training in a simple network. For each training example, feature detector units are dropped with probability 0.5. The weights are trainedby backpropagation (BP) and shared with all the other examples.Fig. 1.2. Dropout prediction in a simple network. At prediction time, all the weights from the feature detectors to the output units are halved.bagging [17], or as a generalization of naive Bayes [23], as well as denoising autoencoders [42]. Dropout has been reportedto yield remarkable improvements on several difficult problems, for instance in speech and image recognition, using wellknown benchmark datasets, such as MNIST, TIMIT, CIFAR-10, and ImageNet [27].In [27], it is noted that for a single unit dropout performs a kind of “geometric” ensemble averaging and this propertyis conjectured to extend somehow to deep multilayer neural networks. Thus dropout is an intriguing new algorithm forshallow and deep learning, which seems to be effective, but comes with little formal understanding and raises severalinteresting questions. For instance:1. What kind of model averaging is dropout implementing, exactly or in approximation, when applied to multiple layers?2. How crucial are its parameters? For instance, is q = 0.5 necessary and what happens when other values are used? Whathappens when other transfer functions are used?3. What are the effects of different deletion randomization procedures, or different values of q for different layers? Whathappens if dropout is applied to connections rather than units?4. What are precisely the regularization and averaging properties of dropout?5. What are the convergence properties of dropout?To answer these questions, it is useful to distinguish the static and dynamic aspects of dropout. By static we refer toproperties of the network for a fixed set of weights, and by dynamic to properties related to the temporal learning process.We begin by focusing on static properties, in particular on understanding what kind of model averaging is implementedby rules like “halving all the weights”. To some extent this question can be asked for any set of weights, regardless of thelearning stage or procedure. Furthermore, it is useful to first study the effects of droupout in simple networks, in particularin linear networks. As is often the case [8,9], understanding dropout in linear networks is essential for understandingdropout in non-linear networks.Related work. Here we point out a few connections between dropout and previous literature, without any attempt at beingexhaustive, since this would require a review paper by itself. First of all, dropout is a randomization algorithm and as suchit is connected to the vast literature in computer science and mathematics, sometimes a few centuries old, on the useof randomness to derive new algorithms, improve existing ones, or prove interesting mathematical results (e.g. [22,3,33]).\f80P. Baldi, P. Sadowski / Artificial Intelligence 210 (2014) 78–122Second, and more specifically, the idea of injecting randomness into a neural network is hardly new. A simple Google searchyields dozen of references, many dating back to the 1980s (e.g. [24,25,30,34,12,6,37]). In these references, noise is typicallyinjected either in the input data or in the synaptic weights to increase robustness or regularize the network in an empiricalway. Injecting noise into the data is precisely the idea behind denoising autoencoders [42], perhaps the closest predecessorto dropout, as well as more recent variations, such as the marginalized-corrupted-features learning approach described in[29]. Finally, since the posting of [27], three articles with dropout in their title were presented at the NIPS 2013 conference:a training method based on overlaying a dropout binary belief network on top of a neural network [7]; an analysis of theadaptive regularizing properties of dropout in the shallow linear case suggesting some possible improvements [43]; and asubset of the averaging and regularization properties of dropout described primarily in Sections 8 and 11 of this article [10].2. Dropout for shallow linear networksIn order to compute expectations, we must associate well defined random variables with unit activities or connectionweights when these are dropped. Here and everywhere else we will consider that a unit activity or connection is set to 0when the unit or connection is dropped.2.1. Dropout for a single linear unit (combinatorial approach)We begin by considering a single linear unit computing a weighted sum of n inputs of the formS = S(I) =n(cid:2)i=1w i Ii(1)where I = (I1, . . . , In) is the input vector. If we delete inputs with a uniform distribution over all possible subsets of inputs,or equivalently with a probability q = 0.5 of deletion, then there are 2n possible networks, including the empty network.For a fixed I , the average output over all these networks can be written as:E(S) = 12n(cid:2)NS(N , I)(2)where N is used to index all possible sub-networks, i.e. all possible edge deletions. Note that in this simple case, deletionof input units or of edges are the same thing. The sum above can be expanded using networks of size 0, 1, 2, . . . , n in theform(cid:3)(cid:4)(cid:5)(cid:6) (cid:2)(cid:7)w i Ii + w j I j+ · · ·(cid:8)w i Ii+E(S) = 12n0 +n(cid:2)i=11(cid:2)i< j(cid:2)n(cid:7)(cid:6)n − 1n − 1= 2n−1In this expansion, the term w i Ii occurs(cid:7)(cid:7)(cid:6)(cid:6)1 +n − 11n − 12+ · · · +times. So finally the average output isE(S) = 2n−12n(cid:5)w i Ii=n(cid:2)i=1n(cid:2)i=1w i2Ii+(cid:4)(3)(4)(5)Thus in the case of a single linear unit, for any fixed input I the output obtained by halving all the weights is equal to thearithmetic mean of the outputs produced by all the possible sub-networks. This combinatorial approach can be applied toother cases (e.g. p (cid:3)= 0.5) but it is much easier to work directly with a probabilistic approach.2.2. Dropout for a single linear unit (probabilistic approach)Here we simply consider that the output is a random variable of the formS =n(cid:2)i=1w iδi Ii(6)where δi is a Bernoulli selector random variabl",
            {
                "entities": [
                    [
                        135,
                        165,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 108 (1999) 1–30Functional dependencies in Horn theoriesToshihide Ibaraki a;1, Alexander Kogan b;c;(cid:3), Kazuhisa Makino d;2a Department of Applied Mathematics and Physics, Graduate School of Informatics, Kyoto University, Kyoto,Japan 606b Department of Accounting and Information Systems, Faculty of Management, Rutgers University, Newark,NJ 07102, USAc RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway, NJ 08854-8003, USAd Department of Systems and Human Science, Graduate School of Engineering Science, Osaka University,Toyonaka, Osaka, JapanReceived 12 March 1997; received in revised form 29 July 1998AbstractThis paper studies functional dependencies in Horn theories, both when the theory is representedby its clausal form and when it is defined as the Horn envelope of a set of models. We providepolynomial algorithms for the recognition of whether a given functional dependency holds in a givenHorn theory, as well as polynomial algorithms for the generation of some representative sets offunctional dependencies. We show that some problems of inferring functional dependencies (e.g.,constructing an irredundant FD-cover) are computationally difficult. We also study the structure offunctional dependencies that hold in a Horn theory, showing that every such functional dependencyis in fact a single positive term Boolean function, and prove that for any Horn theory the set of itsminimal functional dependencies is quasi-acyclic. Finally, we consider the problem of condensinga Horn theory, prove that any Horn theory has a unique condensation, and develop an efficient(cid:211) 1999 Elsevier Science B.V. All rightspolynomial algorithm for condensing Horn theories.reserved.Keywords: Knowledge representation; Horn theory; Functional dependency; Condensation; Computationalcomplexity; Conjunctive normal form; Acyclic directed graph1. IntroductionRelational databases have been invented, studied and deployed as essential tools ofinformation storage and retrieval (see [10,33,34,42,43]). Functional dependencies have(cid:3)Corresponding author. Email: kogan@rutcor.rutgers.edu.1 Email: ibaraki@kuamp.kyoto-u.ac.jp.2 Email: makino@sys.es.osaka-u.ac.jp.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 8 ) 0 0 1 1 4 - 31999 Elsevier Science B.V. All rights reserved.\f2T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30been recognized to be one of the most important concepts in the relational databasetheory (see [1,14]). Functional dependencies state that the values of certain attributes ina relation are determined by the values of some other attributes. They are commonly usedin the logical database design to express integrity constraints, and thus to express domainknowledge. The problems of inferring functional dependencies from relations have beenstudied in [30,35]. Thorough theoretical studies of functional dependencies in relationaldatabases (see [12,14,15,28,39]) have established a close connection with Horn clauses.Horn clauses were introduced in formal logic (see [21,36]), and gained prominencein logic programming (see [13]) and artificial intelligence (see [9,11,24]). In artificialintelligence, the implementation of a knowledge base as a Horn theory is often preferred,since linear time complexity of solving Horn satisfiability problems (see [13,37]) providesthe benefits of computationally tractable reasoning, while Horn clauses have the expressivepower sufficient for many applications.A Horn theory is characterized by the condition that the intersection of any two models isagain a model. A theory can be viewed as the set of its models, and reasoning with modelshas been developed in recent AI studies (see [24,27,29]). In model-based representation, atheory is represented by a subset of its models, which are commonly called characteristicmodels [24,27,29]. From the database theory point of view, the set of models is infact a relation. This relation may have functional dependencies, which reveal importantstructural properties of the theory by describing the intrinsic determinants of values ofcertain attributes. Individual functional dependencies can provide valuable insights intohidden laws of the problem domain, and can be used by domain experts for evaluatingand verifying the theory. The inference of functional dependencies in a Horn theory canthus provide a means of its qualitative analysis, and can also be considered to be a form ofknowledge discovery.The knowledge of functional dependencies in a theory may allow to simplify thetheory by eliminating those variables whose values are determined by the values of othervariables. This “condensation” procedure will result in a theory which does not have anyfunctional dependencies, can have much fewer variables than the original theory, and canbe structurally simpler than the original theory. The computational expense of condensinga theory can be offset by the speedup of queries to the knowledge base, and thereforecondensation can provide significant computational benefits. Moreover, the condensedtheory can be viewed as the “core” of the original theory, and thus condensation can revealimportant structural information about the problem domain.Knowledge condensation represents a special type of knowledge preprocessing, whichattempts to spend some computational resources at the preliminary stage to transforma knowledge base in such a way that the transformed one can be used to reason andanswer queries with less computational effort. The computational expense of knowledgepreprocessing is quickly amortized over the large number of queries during routineoperations. A well developed type of knowledge preprocessing is known under the name ofknowledge compilation (see [25,40]), which constructs Horn upper and lower bounds of ageneral Boolean theory and attempts to use them for answering queries. For some queries,such attempts can be successful, providing fast answers which would be impossible toobtain using the original Boolean theory. If the Horn bounds do not provide an answer, thenthe original theory has to be used to answer queries. It is interesting to note that knowledge\fT. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–303compilation attempts to reduce the size of the Horn upper bound by introducing additionalvariables in the theory (see [25]), while knowledge condensation aims to simplify theproblem by eliminating redundant variables from the theory.Another well developed type of knowledge preprocessing is knowledge compression(see [6,17–20]), which shortens the length of a Horn CNF without changing the Horntheory it represents. While knowledge compilation aims to reduce an intractable problemto a tractable one, knowledge compression, similarly to knowledge condensation, isdeveloped for Horn theories, and therefore simplifies a problem which is already tractable.Such simplifications are nevertheless very important, since Horn theories used in practicalapplications can have very long representations. This is typical in many applications wherepropositional Horn theories can be generated automatically, e.g., when first-order Horntheories are instantiated over finite but large domains. In these situations, the possiblesignificant size reductions provided by knowledge compression and condensation becomeessential. Both knowledge compression and condensation can be used together withknowledge compilation to simplify the Horn bounds it produces.This paper is devoted to the studies of functional dependencies in Horn theories. Itfocuses on characterizing the combinatorial structure of such functional dependencies, andon developing efficient polynomial algorithms for recognizing, inferring and using them.We consider the problems arising when a theory is represented by its Horn clausal form,as well as when it is defined as the Horn envelope (see [26]) of a set of models (i.e., it isrepresented by characteristic models).The results of this paper reveal new properties of Horn theories, and can be used tomake knowledge representation and reasoning computationally more efficient. We providepolynomial algorithms to recognize whether a given functional dependency holds in agiven Horn theory, as well as polynomial algorithms to generate some representativesets of functional dependencies. We show that some problems of inferring functionaldependencies (e.g., constructing an irredundant FD-cover) are computationally difficult.We also study the structure of functional dependencies that hold in a Horn theory, showthat every such functional dependency is in fact a single positive term Boolean function,and prove that for any Horn theory the set of its minimal functional dependencies is quasi-acyclic.Finally, we apply the obtained structural and algorithmic results about functionaldependencies in Horn theories to the problem of condensing a Horn theory. We provethat, in contrast with the case of general Boolean theories, any Horn theory has a uniquecondensation. We show that a Horn theory can be totally condensed using a very limitednumber of functional dependencies, and develop an efficient polynomial algorithm forcondensing Horn theories. The condensation of a Horn theory represented as the Hornenvelope of a set of models always reduces the size of the representation, and thereforeis computationally advantageous. The condensation of a Horn CNF may result (in theworst case) in a moderate polynomial increase in the length of the CNF. On the otherhand, examples show that the potential reduction in the length of the CNF resultingfrom condensation can be exponential. It makes sense at the preprocessing stage toattempt condensing a Horn CNF, since in the worst case (where the size increases) only apolynomial amount of computational effort is wasted, while in the case of success (wherethe size decreases) the computational benefits will be utilized continuously over the long\f4T. Ibaraki et al. / Artificial Intelligence 108 (1999) 1–30run. Addition",
            {
                "entities": [
                    [
                        39,
                        79,
                        "TITLE"
                    ],
                    [
                        671,
                        711,
                        "TITLE"
                    ],
                    [
                        7513,
                        7553,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 656–684www.elsevier.com/locate/artintProof planning with multiple strategiesErica Melis, Andreas Meier, Jörg Siekmann ∗Universität des Saarlandes and German Research Center for Artificial Intelligence (DFKI), Saarbrücken, GermanyReceived 2 May 2006; received in revised form 13 November 2007; accepted 16 November 2007Available online 22 November 2007AbstractProof planning is a technique for theorem proving which replaces the ultra-efficient but blind search of classical theorem provingsystems by an informed knowledge-based planning process that employs mathematical knowledge at a human-oriented level ofabstraction. Standard proof planning uses methods as operators and control rules to find an abstract proof plan which can beexpanded (using tactics) down to the level of the underlying logic calculus.In this paper, we propose more flexible refinements and a modification of the proof planner with an additional strategic level ofcontrol above the previous proof planning control. This strategic control guides the cooperation of the problem solving strategiesby meta-reasoning.We present a general framework for proof planning with multiple strategies and describe its implementation in the MULTIsystem. The benefits are illustrated by several large case studies, which significantly push the limits of what can be achieved by amachine today.© 2007 Elsevier B.V. All rights reserved.Keywords: Theorem proving; Proof planning; Blackboard architecture; Planning; Meta-reasoning1. IntroductionThe control problem, i.e. how to choose one of the many potential actions an intelligent agent—man or machinealike—has at its disposal, is fundamental to all problem solving processes. It stimulated the development of manysoftware architectures in artificial intelligence, including blackboard architectures [18,19,24] and multi agent sys-tems [54].In spite of their increasing sophistication, however, many systems are still rather inflexible and employ a pre-determined and fixed control schema. In particular, this is true for most classical automated theorem proving systemswhich expand and efficiently search through very large search spaces guided by pre-fixed general-purpose filters andheuristics. A modification on the fly or a flexible combination of different heuristics to tackle sub-problems is ingeneral not possible. As a result, these systems can not recognize mathematically promising search paths as they go,and they make up for this deficiency by their sophisticated representational techniques (see Chapter VIII in [45]) and* Corresponding author.E-mail addresses: melis@dfki.de (E. Melis), meier@dacos.com (A. Meier), siekmann@dfki.de (J. Siekmann).URLs: http://www.ags.uni-sb.de/~melis (E. Melis), http://www-ags.dfki.uni-sb.de/JS/index.html (J. Siekmann).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.004\fE. Melis et al. / Artificial Intelligence 172 (2008) 656–684657general search heuristics to blindly examine a space of up to several billion nodes. The final performance of a system,however, depends on whether the pre-selected search heuristic is appropriate for the particular problem at hand.1As a reaction to these problems several remedies have been tried:(1) Different systems are competitively combined such that machine resources are allocated to the most promisingsystem at a time [2,47,51,59]. Typical meta-heuristics for system selection and resource allocation evaluate char-acteristics of the problem at hand and compare it to past experience. For instance: “in the past, the system S withheuristics H was best suited for problems with the following number and type of clauses and/or equations”.(2) Cooperation of different systems, which exchange intermediate results [15], where meta-heuristics are used todecide which results to exchange. For example: “The derived clause C is a unit clause, which could be useful inanother system and hence, should be exported”.Proof planning [7] is a technique for theorem proving in which proofs are planned at a higher level of abstraction,where individual choices can be mathematically motivated by the semantics of the domain. Thus, proof planningswings the pendulum from the desert of the blind but ultra-efficient search-based paradigm of classical automatedtheorem proving to the green grass of knowledge based systems. In particular, proof planning tackles theorems notonly using general logic based methods but also by using domain-specific and general mathematical knowledge,encoded explicitly into methods and control [39,41]. Essentially, however, proof planners like CLAM or (cid:2)MEGA, aremonolithic, in the sense that the planning algorithm is pre-defined and cannot take full advantage of the runtimeknowledge that is available during the problem solving process.Our experiments with proof planning in the past decade indicate that the search process would benefit substantiallyfrom more flexibility of choice and more usage of runtime knowledge instead of a mere competitive application ofseveral systems or the simple exchange of intermediate results. This situation has been recognized in other real-worldapplications of planning as well, see, e.g., [56].In the following, we report our results for proof planning with multiple strategies, which is built upon three generalprinciples: (1) decomposition of the monolithic search process into independent processes; (2) structuring the setof methods and the corresponding control knowledge into strategies; (3) meta-reasoning with explicitly representedcontrol knowledge at a strategic level.After more than a decade of development and experimentation this article presents our current ‘final’ stable solu-tion, introducing conceptually clean notions and notation and finally backs it all up with several large case studies.Most case studies had been published before at conferences and workshops on automated theorem proving, but step-ping back now from the presentation at the time of those particular achievements we like to present and summarizeour current more general view in this journal paper.The remainder of this paper is organized as follows. After a brief introduction to proof planning and some motivat-ing examples, we show how the three principles above are implemented in the MULTI system [32,35]. The results arethen discussed and evaluated with several case studies, which illustrate the potential of explicitly represented strategicknowledge and control and demonstrate what can be achieved with this automated reasoning system today.2. Preliminaries(cid:2)MEGA is a theorem proving environment developed at the University of Saarbrücken based on proof planning andother techniques and MULTI is now the proof planner of the current system. The (cid:2)MEGA project [48] represents one ofthe major attempts to build an all encompassing assistant tool for the working mathematician or the software engineer,which combines interactive and automated proof construction for domains with rich and well-structured mathematicalknowledge. The inference mechanism at the lowest level of abstraction is based on a higher order natural deduction(ND) variant of a soft-sorted version of Church’s simply typed λ-calculus [10]. While this represents the “machinecode” of the system the user will seldom want to see, the search for a proof is conducted at a higher level of abstractionby the proof planning process.1 The general wisdom is: no single theorem prover or heuristic is best for all problems, see contest http://www.cs.miami.edu/~tptp/CASC/.\f658E. Melis et al. / Artificial Intelligence 172 (2008) 656–684Proof planning differs from traditional search-based techniques in automated theorem proving as the proof of atheorem is planned at an abstract level, where an outline of the proof is constructed first. This outline, that is theabstract proof plan, can be recursively expanded with methods and tactics eventually down to a logical calculusproof. Most plan operators, called methods for this reason, represent mathematical techniques familiar to a workingmathematician.Knowledge-based proof planning [41] employs even more techniques from artificial intelligence such as hierar-chical planning, constraint solving and control rules, which encode the “how to solve it” knowledge for guiding thesearch at an abstract level. While the knowledge of a mathematical domain represented by operators and controlrules can be specific to the mathematical field at hand, the representational techniques and reasoning procedures aregeneral-purpose.The plan operators in mathematical proof planning are called methods. They (partially) describe changes of proofstates by pre- and postconditions which are called premises and conclusions in the following. The premises andconclusions of a method are formulae (more precisely: sequents) in a higher-order language and the conclusions areconsidered as logically inferable from the premises.Hence, a mathematical theorem proving problem is expressed as a planning problem whose initial state consistsof the proof assumptions and the goal description which is the conjecture to be shown. Proof planning searches for asequence (or a hierarchy) of instantiated methods, a solution plan, which transforms the initial state with assumptionsinto a state containing the conjecture.A proof planner can be realized by the following search procedure:• As long as there are goals, select a goal and try to apply a method to it.• If there is a goal for which no method is applicable, then backtrack to the method application, which introducedthis goal.• When all goals are closed, employ a constraint solver to instantiate the variables within the methods.The reason for the late variable instantiation is to first collect as many individual constraints as possible (as long asthere are goals) and instantiate all variables to satisfy the collected constraints only at the end.As opposed to precondition achievement planning [5",
            {
                "entities": [
                    [
                        72,
                        111,
                        "TITLE"
                    ],
                    [
                        1156,
                        1195,
                        "TITLE"
                    ],
                    [
                        5286,
                        5325,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 256 (2018) 105–129Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artint, Ewen Maclean d, Roberto Confalonieri e,c, Oliver Kutz e, A computational framework for conceptual blendingManfred Eppe a,b,∗Marco Schorlemmer c, Enric Plaza c, Kai-Uwe Kühnberger fa University of Hamburg, Germanyb International Computer Science Institute, Berkeley, USAc IIIA-CSIC, Barcelona, Catalonia, Spaind University of Edinburgh, UKe Free University of Bozen-Bolzano, Italyf University of Osnabrück, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 1 September 2016Received in revised form 3 November 2017Accepted 23 November 2017Available online 2 December 2017Keywords:Computational creativityConceptual blendingCognitive scienceAnswer set programmingWe present a computational framework for conceptual blending, a concept invention method that is advocated in cognitive science as a fundamental and uniquely human engine for creative thinking. Our framework treats a crucial part of the blending process, namely the generalisation of input concepts, as a search problem that is solved by means of modern answer set programming methods to find commonalities among input concepts. We also address the problem of pruning the space of possible blends by introducing metrics that capture most of the so-called optimality principles, described in the cognitive science literature as guidelines to produce meaningful and serendipitous blends. As a proof of concept, we demonstrate how our system invents novel concepts and theories in domains where creativity is crucial, namely mathematics and music.© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionCreativity is an inherent human capability that is crucial for the development and invention of new ideas and concepts [3]. This paper addresses a kind of creativity which Boden [3] calls combinational, and which has been studied by Fauconnier and Turner [27] in their framework of conceptual blending. In brief, conceptual blending is a process where one invents a novel concept, called the blend, by combining two familiar input concepts. For illustration, consider the classical example of blending the concepts house and boat (e.g. [34,27]). A possible result is the invention of a house-boat concept, where the medium on which a house is situated (land) becomes the medium on which boat is situated (water), and the inhabitant of the house becomes the passenger of the boat. Another possible blend is the boat-house, where the boat ‘inhabits’ the house.An inherent computational problem of conceptual blending is to find a common ground, called generic space, between the two input concepts [27]. For example, the house-boat blend has the generic space of a person being inside an object that is not situated on any medium (or that is situated on a more general medium). Once the generic space has been identified, one can develop possible blends by specialising the generic space with elements from the input concepts in a meaningful way. However, this is not trivial because the naive union of input spaces can lead to inconsistencies. For example, the medium on which an object is situated can not be land and water at the same time. Hence, before combining the input * Corresponding author at: University of Hamburg, Germany.E-mail addresses: eppe@informatik.uni-hamburg.de (M. Eppe), emaclea2@inf.ed.ac.uk (E. Maclean), roberto.confalonieri@unibz.it (R. Confalonieri).https://doi.org/10.1016/j.artint.2017.11.0050004-3702/© 2017 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\f106M. Eppe et al. / Artificial Intelligence 256 (2018) 105–129concepts, it is necessary to generalise at least one medium assignment. Another problem is the huge number of possible blends, which are often not meaningful. For example, blending house and boat such that the house becomes the passenger of the boat – imagine a house-transporting cargo vessel – is not very convincing. Consequently, one has to prune the search space by ruling out such low-quality blends.Conceptual blending is perceived as a milestone in human cultural development [27]. The main motivation behind blend-ing from an AI perspective is to find a computational interpretation of the human blending process, which could be an equally important milestone in the development of intelligent agents and autonomous systems. The value of conceptual blending for the development of creative systems has been witnessed by several works in the field of Artificial Intelligence and cognitive science, where particular implementations of this cognitive theory have been proposed [83,63,64,33,36].As we show in our survey in Sec. 5, existing approaches propose computational characterisations of conceptual blending by using different formal representations for the input spaces and different techniques for performing the blending oper-ation, and for the evaluation of the blends. For instance, Goguen and Harrell [33] logically formalise conceptual blending in terms of algebraic theories, Pereira [64] uses concept maps and frames, and rules and constraints to implement blend evaluation, while Veale and Donoghue [83] focus on the use semantic networks. The survey shows that providing a full computational account for conceptual blending is very challenging, in particular for the following two reasons:• When combining two input spaces, the generic space is of particular importance to steer possible variations of blends. However, computing the generic space is a challenging issue (e.g., [76]), especially for expressive representation lan-guages. Most existing blending frameworks are therefore not capable of computing a generic space automatically.• Having identified a generic space, there typically remains a huge number of possible combinations to generate blends. To prune this result space, blends need to be evaluated. One way to do this is to check their consistency and to apply certain quality metrics.In this paper, we address these issues and ask the following question:How can we orchestrate the blending of input concepts in a computationally efficient and feasible way, that is faithful to the cognitive theory of conceptual blending and can therefore be considered as computationally creative?To answer this question, we build a general creative computational framework for conceptual blending that allows the creation and evaluation of new blended concepts. The main contributions of this paper are as follows:• We provide a blending framework that accepts input concepts in form of semiotic systems (see Sec. 2.2). Herein, we use algebraic specifications similar to those proposed by Goguen [34, Def. 1], with the difference that we assign priorities not only to constructors, i.e., operators, but also to sorts, predicates, and axioms. This extra level of knowledge allows us to guide the generalisation search process and create meaningful generalisations of the input spaces more efficiently, and we also use it for the evaluation of blends.• We automate the discovery of generic spaces by applying amalgams, a notion known from case-based reasoning [61] (see Sec. 2.3). This process coordinates the interleaved generalisation and combination of input concepts as a non-monotonic search problem. We solve this search problem by using the declarative framework of Answer Set Programming (ASP) (e.g., [2]), as described in Sec. 3.• We evaluate blends by re-interpreting the optimality principles of Fauconnier and Turner [27] and give them a full computational account (see Sec. 2.1 and 3.6). This helps to prune the search space.• As a proof of concept, we implement our framework as an exploratory creative tool that can create interesting blends in the domain of mathematics and music. We also reproduce several blends that can be found in the literature. Finally, we show how our framework finds blends that belong to different domains (see Sec. 4).• We provide a survey to characterise existing computational blending systems (see Sec. 5) and position our own work within the state of the art.2. PreliminariesOur framework is inspired by the cognitive theory of conceptual blending as presented in Fauconnier and Turner [27], whose underlying principles are described in detail in Sec. 2.1. To realise these principles computationally, we follow the work by Goguen [34], who provides a category theoretical account of blending (see Sec. 2.2). Moreover, to make Goguen’s work computationally feasible, we implement blending as an amalgam-based workflow [61], a notion that was developed in case-based reasoning (see Sec. 2.3). The implementation framework for the amalgam-based workflow is Answer Set Program-ming (ASP), for which we provide a brief background in Sec. 2.4.2.1. Cognitive principles of blendingCreativity, understood as an unfamiliar combinations of familiar ideas, goes back to the notion of bisociation, the idea that creativity is often a result of an intersection and selective combination of rather distinct frames of reference, presented \fM. Eppe et al. / Artificial Intelligence 256 (2018) 105–129107Fig. 1. The ‘houseboat’ blend, adapted from [33].by Arthur Koestler in his book The Act of Creation in 1964 [46]. Based on these basic intuitions, within the cognitive sciences these ideas have been further developed into more concrete approaches of how to produce novel ideas (which may be concepts, theories, solutions to problems, works of art, etc.). One particular such approach, known as the theory of conceptual blending or conceptual integration has been proposed by Fauconnier and Turner [26] as a kind of primitive or fundamental cognitive operation underlying much of everyday thought and language. The process by which two concepts are ble",
            {
                "entities": [
                    [
                        195,
                        244,
                        "TITLE"
                    ],
                    [
                        827,
                        876,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 195 (2013) 291–315Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal identifiability via Chain Event GraphsPeter ThwaitesSchool of Mathematics, University of Leeds, LS2 9JT, United Kingdoma r t i c l ei n f oa b s t r a c tWe present the Chain Event Graph (CEG) as a complementary graphical model to theCausal Bayesian Network for the representation and analysis of causally manipulatedasymmetric problems. Our focus is on causal identifiability — finding conditions for whenthe effects of a manipulation can be estimated from a subset of events observable in theunmanipulated system. CEG analogues of Pearl’s Back Door and Front Door theorems arepresented, applicable to the class of singular manipulations, which includes both Pearl’sbasic Do intervention and the class of functional manipulations possible on BayesianNetworks. These theorems are shown to be more flexible than their Bayesian Networkcounterparts, both in the types of manipulation to which they can be applied, and in thenature of the conditioning sets which can be used.© 2012 Elsevier B.V. All rights reserved.Article history:Received 15 April 2011Received in revised form 6 September 2012Accepted 12 September 2012Available online 13 September 2012Keywords:Back Door theoremBayesian NetworkCausal identifiabilityCausal manipulationChain Event GraphConditional independenceFront Door theorem1. IntroductionIn this paper we consider cause and effect through the analysis of controlled models. The standard apparatus for suchan approach is the Causal Bayesian Network (CBN) [8,14,15,24]. The CBN is a version of a Bayesian Network (BN) where thedirectionality of the edges of the graph is interpreted as causal and the BN as representing a causal model.BNs are specifically designed to work with problems which have a natural product space structure, but many problemswhich we might wish to model do not have such a structure, and are asymmetric in that problem variables can have differentsets of possible outcomes given different outcomes of their parental variables, or even no possible outcomes given someoutcomes of their parents. The future development at any specific point depends on the particular history of the problemup to that point (i.e. on the outcomes of ancestral variables), and the values of a particular set of covariates at that point. Itis these types of problem that we are primarily concerned with here.So for instance, consider an infectious disease which is serious for people who have blood type O. Following a firsttreatment, patients with this blood type either die or need a second treatment; patients with other blood types either needa second treatment or make a full recovery. At the next stage of the process, patients who have died or fully recovered arenot offered a second treatment, but all other patients are given one of three possible second treatments, the choice of whichis dependent on factors such as hospital policy, consultant preference etc. Similar examples occur in many other areas (seefor example [1,3,7,12]).Context-specific variants of BNs have been developed for tackling asymmetric problems [2,13,18,20]. They can be usedfor the representation and analysis of problems whose future development at any specific point depends on the particularhistory of the problem up to that point, but their use is more circumscribed in problems where there may be no possibleoutcomes of some variables given certain histories or values of covariates. In both cases however the problems being anal-ysed are no longer fully represented by the topology of the graph — context-specific BNs require supplementary informationE-mail address: P.A.Thwaites@leeds.ac.uk.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.09.003\f292P. Thwaites / Artificial Intelligence 195 (2013) 291–315in the form of trees, or tree-like conditional probability tables attached to vertices to depict the asymmetries in the prob-lem. The Chain Event Graph (CEG) introduced in [22,25] is specifically designed for the representation and analysis of suchproblems. It is a function of an event tree [21], whose topology expresses the full collection of independence properties as-sociated with a problem. It is particularly useful when problems do not exhibit a product space structure, or when there isa lot of context-specific information present. All aspects of the model structure, including any context-specific dependenciesare represented in the topology of the graph — these are not bolted on.There have been many recent advances in CBN theory (see for example [5,6,9,16,27,28]), but little of this has madethe causal analysis of such asymmetric problems simpler. In particular, techniques such as Pearl’s Back and Front Doortheorems [14,15] have conditions which are expressed in terms of the topology of the CBN — if the structure of the problemcan no longer be expressed fully in terms of the topology of the graph, then this benefit is lost.CBNs can be used for the basic Do intervention of Pearl [15], which sets a particular variable to a particular value;and their use has been extended to functional manipulations (Do X = g(W ) for some set of variables W ), and stochasticmanipulations which assign a new probability distribution over the outcomes of the manipulated variable. The ease withwhich necessary conditions can be checked on the unmanipulated graph however vanishes very rapidly as we move awayfrom basic interventions.It can be argued [4,21,26] that causes are more naturally expressed as events rather than the values of some randomvariable. The CEG provides an ideal graphical representation given this argument. It is also a sensible representation forthe analysis of manipulations to events. By making additional assumptions concerning a CEG model we can give it a causalinterpretation, and extend its use to causal analysis in an analogous manner to that in which CBNs extend the use of BNs.Unlike analysis using CBNs, the analysis of functional and stochastic manipulations using CEGs is no more complex than theanalysis of the basic Do manipulation. In using the CEG for causal analysis we are building on the ideas of researchers whohave attempted to use trees for this purpose [19,21,24].Note also that in CBN analysis the standard methods for reducing the complexity of a manipulated probability expression(for example Pearl’s Back and Front Door theorems) rely on the use of blocking sets consisting of problem variables. WithCEG-based analysis our blocking sets are composed of events, allowing us more flexibility in their construction; so insteadof conditioning on a set of variables Z = {Z1, Z2} say, we might only need to condition on the events {patient is male, patientis female and aged below 40}.A crude version of a Back Door theorem for CEGs was introduced in [26]. Here we present a much more general BackDoor theorem as well as two alternative versions of a Front Door theorem. No knowledge of the content of [26] is assumedin this paper. The earlier paper touched briefly on some topics covered here, such as the use of CEGs for more sophisticatedmanipulations, but here we offer a comprehensive overview of causal analysis on CEGs, and look more carefully at causalidentifiability — finding conditions for when the effects of a manipulation can be estimated from a subset of events ob-servable in the idle system. Pearl’s Back and Front Door theorems give sufficient conditions for causal identifiability in BNs,and their arrival prompted a search for a complete set of conditions, using which an analyst could gauge whether or not anexpression could be estimated from a subset of observable variables [6,27,28]. This paper provides several sets of sufficientconditions for causal identifiability in CEGs. We anticipate that future work will allow us to find necessary and sufficientconditions for identifiability, expressed in terms of subsets of observable events as opposed to observable variables.As the CEG is a comparatively new structure, there have been minor modifications since [22] and [26]. In particular wehave removed the undirected edges from previous definitions so that the CEG is now a DAG. This has led to a less clutteredrepresentation and made the CEG easier to read.In Section 2 we define the CEG and manipulated CEG. Section 3 develops the Back Door theorem and the idea ofsingular manipulations. A Front Door theorem is then introduced in Section 4, and Section 5 provides a discussion of possibledirections for future research.2. Definitions and notationIn this section we define the CEG. We also provide some notation that will be used throughout the paper. We then turnour attention to what it means when we manipulate a CEG to an event, and present a definition of a manipulated CEG.The CEG is a function of an event tree [21], retaining those features of the tree which allow for the transparent repre-sentation of asymmetric problems. They are a significant extension to trees since they express within their topology a morecomplete description of the conditional independence structure of a problem.An event tree T is a directed tree with vertex set V (T ) and edge set E(T ). It has a single root vertex v 0, and a collectionof leaf vertices (see for example Fig. 1, where there are 7 leaf vertices). The root-to-leaf paths {λ} of T form the atoms ofthe event space. Events measurable with respect to this space are unions of these atoms.Let V 0(T ) denote the set of non-leaf vertices of T . Then each vertex v ∈ V 0(T ) labels a random variable X(v) whosestate space X(v) can be identified with the set of directed edges e(v, v(cid:4)(cid:3)(cid:4)(cid:3)(cid:3)) ∈ E(T ) emanating from v. For each X(v) we let(cid:5)∈ X(v)(cid:3))) are called the primitive probabilities of the tree; andΠ(v) ≡where πe(vΠ(T ) ≡(cid:2)πe(cid:3)v| e(cid:3) | vv, v(cid:3) | v) ≡ P ( X(v) = e(v, v(cid:5)Π(v)",
            {
                "entities": [
                    [
                        145,
                        190,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 179–203www.elsevier.com/locate/artintPhase transition in a random NK landscape model ✩Sung-Soon Choi a, Kyomin Jung b, Jeong Han Kim c,∗,1a School of Computer Science and Engineering, Seoul National University, Seoul, 151-742 Koreab Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA 02139, USAc Department of Mathematics, Yonsei University, Seoul, 120-749 KoreaReceived 31 March 2006; received in revised form 26 March 2007; accepted 13 June 2007Available online 27 June 2007AbstractAn analysis for the phase transition in a random NK landscape model, NK(n, k, z), is given. This model is motivated frompopulation genetics and the solubility problem for the model is equivalent to a random (k + 1)-SAT problem. Gao and Culberson[Y. Gao, J. Culberson, An analysis of phase transition in NK landscapes, Journal of Artificial Intelligence Research 17 (2002)√309–332] showed that a random instance generated by NK(n, 2, z) with z > z0 = 27−7is asymptotically insoluble. Based on4empirical results, they conjectured that the phase transition occurs around the value z = z0. We prove that an instance generatedby NK(n, 2, z) with z < z0 is soluble with positive probability by providing a polynomial time algorithm. Using branching processarguments, we prove again that an instance generated by NK(n, 2, z) with z > z0 is asymptotically insoluble. The results show thephase transition around z = z0 for NK(n, 2, z). In the course of the analysis, we introduce a generalized random 2-SAT formula,which is of self interest, and show its phase transition phenomenon.© 2007 Elsevier B.V. All rights reserved.5Keywords: NK landscape; Fitness function; Solubility; Phase transition; Satisfiability problem1. Introduction1.1. NK landscape modelsA fitness landscape is a function that assigns each genetic composition (genotype) with the fitness of the expression(phenotype) of the genetic composition in an environment. The fitness landscape sometimes refers to its graphicalrepresentation as the word “landscape” indicates. The notion of fitness landscape was first introduced by Wright [47]for the analysis of population genetics. Afterwards, mathematical models to study the evolution on fitness landscapehave been proposed by many researchers including Franklin and Lewontin [20], Lewontin [34], Ewens [17], Kauffmanand Weinberger [30], and Macken and Perelson [35]. Among them, the NK model proposed by Kauffman [28] hasattracted considerable attention. The NK model generates fitness landscapes with correlation structures in which we✩ This work was partially carried on in Microsoft Research and partially supported by a grant of Research Institute of Mathematics funded byMicrosoft Korea.* Corresponding author.E-mail addresses: sschoi@soar.snu.ac.kr (S.-S. Choi), kmjung@mit.edu (K. Jung), jehkim@yonsei.ac.kr (J.H. Kim).1 This work was partially supported by Yonsei University Research Funds 2006-1-0078 and 2007-1-0025, and by the second stage of the BrainKorea 21 Project in 2007, and by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2006-312-C00455).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.06.002\f180S.-S. Choi et al. / Artificial Intelligence 172 (2008) 179–203can control the degree of interactions between genes and so, indirectly, the ruggedness and correlation degrees of thelandscapes.An NK landscape is a real-valued function defined on the set of binary n-tuples, {0, 1}n, which is of the formf (x1, x2, . . . , xn) =(cid:3)(cid:4)xi, Π(xi).fin(cid:2)i=1It is a summation of local fitness functions fi ’s, where each fi depends on its main variable xi and the variables inthe neighborhood of xi . Here the neighborhood Π(xi) is a subset of the set {x1, x2, . . . , xn} \\ {xi} and its size |Π(xi)|is k. Two ways have been introduced to choose the variables in the neighborhood Π(xi); adjacent neighborhood andrandom neighborhood. In the NK models with adjacent neighborhood, Π(xi) consists of the closest k variables (witha certain tie-break) to the main variable xi with respect to the indices modulo n. In the NK models with randomneighborhood, Π(xi) is composed of the k variables chosen uniformly at random from {x1, x2, . . . , xn} \\ {xi}. Localfitness functions are constructed independently of each other. For each local fitness function, a random value from aprobability distribution is assigned for each input. In general, it is independently (or nearly independently) assignedfor each of 2k+1 inputs and its expectation has small absolute value. In the Kauffman’s original model, the uniformdistribution between zero and one was used as the underlying distribution for local fitness functions. Later, it has beenreplaced with various probability distributions in the contexts of analysis and applications, inducing variants of theNK model.The name, “NK landscape”, embodies two parameters n and k. In terms of biology, each variable xi is regarded asa gene. The parameter n represents the number of genes that an organism has. The local fitness function fi quantifiesthe fitness of a character that is determined (or expressed in a biological term) by the gene xi affected by k other genesin Π(xi). A genotype of an organism is the values of genes xi ’s. Strictly speaking, the phenotype corresponding toa genotype is the characters expressed by the genotype. In practice, especially in this paper, the phenotype may beregarded as an organism that has the characters.Generally, the parameter k plays a role in controlling the degree of interactions between genes. The larger the valueof k is, the more genes interact one another in constructing the fitness landscape. Consider the case that k is small.Given two genotypes (or assignments) with the identical values for most of the genes, most of fi ’s produce the samevalues for the genotypes. Since the values of fi ’s are small relatively to the overall fitness f in absolute value, the twogenotypes have similar fitnesses, which implies that the landscape has strong correlation structure. On the other hand,if k is n − 1, each fi has (nearly) independent values for the two genotypes, which induces the landscape consistingof 2n (nearly) independent random values. Through experiments in the original NK model, Kauffman suggested thatthe ruggedness of the landscape generally increases as k increases [28].Kauffman [28] further analyzed various features of adaptive walks in the original NK model. Weinberger [42] andFontana et al. [19] carried out more detailed analysis of such walks. The asymptotic properties of the global and localoptima in NK landscapes were analyzed in various random NK landscape models. The differences between models aremainly due to the underlying distributions for local fitness functions. Evans and Steinsaltz [16], Durrett and Limic [13],Skellet et al. [39], and Kaul and Jacobson [31,32] used the exponential, negative exponential, uniform, and both ofnormal and uniform distributions in their works, respectively. Weinberger [43] and, later, Wright et al. [46] studiedthe computational complexities of problems related to NK landscapes. Gao and Culberson [22] showed a treewidthresult for NK landscapes in a probabilistic way.NK models have been used in biology, physics, and so on. In biology, NK models explain evolutions of biologicalobjects including amino acid sequences [29,30,35], protein or RNA sequences [6,18,19,37,41], and molecular quasi-species [14]. NK models have been served as a reference point for understanding the properties of those biologicalobjects. In statistical physics, models of spin-glasses are investigated from the viewpoint of NK models in [42]. Theevolution of organizations in a business environment is modeled based on an NK model [33]. NK models have beenused as a benchmark for evaluating various encoding schemes and genetic operators on the evolutionary algorithmand comparing them in the evolutionary computation area [5,24,36]. They have been also served as a basis for thedesign of problem difficulty measures for evolutionary algorithms [26,40] and the design of epistasis measures [38].\fS.-S. Choi et al. / Artificial Intelligence 172 (2008) 179–2031811.2. Solubility problem and phase transition in a random NK modelOne of the most interesting questions regarding NK landscape is the solubility problem that asks whether thereexists a genotype, or an assignment of values xi ’s, that maximizes the values of all local fitness functions. In otherwords, the problem asks whether there exists an organism that perfectly fits to a given environment, which seems tobe the most natural question regarding the NK landscape. For the problem it is enough to consider binary local fitnessfunctions having only two values 0 and 1, since one may replace each local fitness function by an auxiliary binaryfitness function that is 1 if and only if the value of the local fitness function is its maximum. An NK landscape f iscalled soluble if there is such an assignment. Otherwise, it is insoluble.Weinberger [43] and Wright et al. [46] proved that the problem for the NK landscapes with arbitrary neighborhoodis NP-complete for k (cid:2) 2. To investigate the difficulties of the solubility problems for typical NK landscapes with ran-dom neighborhood, Gao and Culberson [21] proposed two random NK landscape models and provided results aboutthe phase transition in the models. A phase transition in probabilistic combinatorial theory refers to the phenomenonthat the probability of a property being satisfied in the random model rapidly changes as the order parameter changesaround a certain value. The two random models are the uniform probability model and the fixed ratio model inspiredby the two random graph models of Erd˝os-Rényi type, G(n, p) and G(n, m), respectively. In the uniform probabilitymodel, the fitness value of each input for a local fitness function is independently assigned to zero",
            {
                "entities": [
                    [
                        72,
                        119,
                        "TITLE"
                    ],
                    [
                        568,
                        615,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 132 (2001) 1–38Artificial nonmonotonic neural networksB. Boutsinas a,c,∗, M.N. Vrahatis b,ca Department of Computer Engineering and Informatics, University of Patras, GR-26500 Patras, Greeceb Department of Mathematics, University of Patras, GR-26500 Patras, Greecec University of Patras Artificial Intelligence Research Center (UPAIRC),University of Patras, GR-26500 Patras, GreeceReceived 30 August 1999; received in revised form 8 January 2001AbstractIn this paper, we introduce Artificial Nonmonotonic Neural Networks (ANNNs), a kind ofhybrid learning systems that are capable of nonmonotonic reasoning. Nonmonotonic reasoning playsan important role in the development of artificial intelligent systems that try to mimic commonsense reasoning, as exhibited by humans. On the other hand, a hybrid learning system providesan explanation capability to trained Neural Networks through acquiring symbolic knowledge of adomain, refining it using a set of classified examples along with Connectionist learning techniquesand, finally, extracting comprehensible symbolic information. Artificial Nonmonotonic NeuralNetworks acquire knowledge represented by a multiple inheritance scheme with exceptions, suchas nonmonotonic inheritance networks, and then can extract the refined knowledge in the samescheme. The key idea is to use a special cell operation during training in order to preserve thesymbolic meaning of the initial inheritance scheme. Methods for knowledge initialization, knowledgerefinement and knowledge extraction are introduced. We, also, prove that these methods addressperfectly the constraints imposed by nonmonotonicity. Finally, performance of ANNNs is comparedto other well-known hybrid systems, through extensive empirical tests.  2001 Elsevier Science B.V.All rights reserved.Keywords: Nonmonotonic reasoning; Neural networks; Hybrid systems; Inheritance networks; Unconstrainedoptimization; DNA sequence analysis* Corresponding author.E-mail address: vutsinas@ceid.upatras.gr (B. Boutsinas).0004-3702/01/$ – see front matter  2001 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 1 2 6 - 6\f2B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–381. Introduction1.1. Motivation and backgroundNonmonotonic reasoning plays an important role in the development of systems that tryto mimic common sense reasoning, as exhibited by humans. Human beings are constantlyforced to make decisions and reach conclusions in an ambiguous world. The knowledgethat can be acquired by observation is inherently incomplete and may contain conflictinginformation as well as exceptions to general rules. Many formalisms are proposed in theliterature that are capable of representing knowledge under a multiple inheritance schemewith exceptions (e.g., [3,6,9,19,26,48,50,54]). A nonmonotonic reasoner has to face thetwo general problems of knowledge-based systems, namely the strong dependency on thecorrectness of the domain knowledge and the lack of domain independent and effectivelearning algorithms. Due to the latter, the domain knowledge must be altered manually,whenever necessary. Moreover, a nonmonotonic reasoner, usually, has problems in dealingwith multiple extensions of a theory. In such situations, extensions are treated as cases ofambiguity. The way they are treated depends on whether a credulous or a skeptical viewis adopted [55]. Besides, no attempt is made to resolve possible conflicts (except for a fewcases, as in [52]).On the other hand, example-based systems, such as Artificial Neural Networks (ANNs),need a large set of training examples and they have a strong dependency on the featuresused to describe those examples. They also lack an explanation capability for the generatedoutputs and, consequently, for the decisions reached. Moreover, a longstanding problemin connectionist modelling is the representation of structured objects. Although someattempts have been made to address this problem (e.g., [47]), the proposed systems are notefficient [27]. On the contrary, an explanation capability and representation of structuredobjects can be easily provided by a knowledge-based system.Recently, significant attention has been paid to the development of hybrid systems thatare based on a neural-symbolic integration, aiming at exploring the advantages of eachconstituent paradigm. There were promising early attempts [11] toward the combination ofthe explanation capabilities and the powerful declarative knowledge representation of thesymbolic approach with the massive parallelism and the generalization capabilities of theconnectionist approach. Neural-symbolic hybrid systems use an Artificial Neural Networkas an example-based learning system and a symbolic knowledge representation scheme forthe domain knowledge. The most important contributions to this interesting field can befound in [1,8,10,12,18,22,29,30,42,56].Following McCarthy’s observation [37], most of the hybrid systems using neural net-works for inferential processing, are based on logic-based propositional knowledge repre-sentation schemes. Such logic-based formalisms may lack several important properties ofnonmonotonic reasoning [6], such as the very important property of stability (also calledcumulativity). This is generally true even for well known nonmonotonic formalisms suchas Reiter’s Default Logic [6]. Special extensions of Default Logic have been introduced inorder to tackle the stability problem, such as Cumulative Default Logic [4,34]. Moreover,it has been shown that many decision problems are intractable or even undecidable whenstated within the context of formal logic-based systems.\fB. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–383On the other hand, symbolic-connectionist systems in a nonmonotonic domain areimportance to both theory and practice. Path-based such formalisms areof greatrepresentation schemes based on semantic networks. They introduce an alternativeapproach to nonmonotonic reasoning. They try to tackle algorithmic intractability and thecorrect treatment of incomplete or contradictory knowledge. Although there exists a lot ofcriticism about the semantics of semantic networks [64], it is accepted that they can beeffectively used as a representation and inference scheme in a nonmonotonic domain [54].Inheritance networks is such a path-based formalism with widespread use in nonmonotonicreasoning systems [55].Hybrid systems are usually based on logic-based knowledge representation schemesas far as the domain knowledge is concerned. The proposed, in this paper, ArtificialNonmonotonic Neural Networks (ANNNs) are hybrid systems that use inheritancenetworks, as a nonmonotonic multiple inheritance knowledge representation scheme forthe domain knowledge, and Artificial Neural Networks as a learning mechanism. Thelatter are supported by a proper training method, which suits perfectly our approach andis applied by changing selected weights at each epoch. ANNNs are not based on energyminimization, but on the spreading activation metaphor. The input cells of the connectionistpart are externally activated, based on known facts in the domain knowledge, and thespreading of this activation forces some output cells to be either activated or deactivated. Itis the activation of output cells that guides the reasoning process.1.2. Related workIn [23] a logic-based method is presented for inserting any propositional general logicprogram P into a three-layer feedforward Artificial Neural Network with binary thresholdneurons. It is proved that if the network is transformed into a recurrent network, byconnecting output units to corresponding input units, it always falls into a unique stablestate that corresponds to the unique stable model, namely the semantics, of P . Thepotential impact of this result is that a new massively parallel computational model forlogic programming is derived.The system presented in [56] (Knowledge-Based Artificial Neural Network) is capableof inserting “if-then” rules into a neural network, refining these rules using a backpropaga-tion based learning algorithm and extracting rules from the neural network. It is empiricallyshown that the system can not only revise the domain knowledge but also can efficientlylearn new rules from examples using the domain knowledge.Following the key idea in [23], the system in [12] (Connectionist Inductive Learningand Logic Programming System) integrates inductive learning from examples anddomain knowledge with deductive learning from Logic Programming. Propositional logicprograms can be inserted into a feedforward Artificial Neural Network with bipolar semi-linear threshold neurons. The network is trained using the standard backpropagationlearning algorithm and the revised logic program can be extracted.Moreover, it is shown [40–42] that the satisfiability problem in propositional logic canbe reduced to the problem of finding a global minima of an energy function of a symmetricnetwork. The consequence of this very important result is that symmetric neural networks\f4B. Boutsinas, M.N. Vrahatis / Artificial Intelligence 132 (2001) 1–38can be applied in solving a lot of hard problems, such as optimization problems andconstraint satisfaction problems [16].There are also efforts in the direction of hybrid systems that use knowledge represen-tation schemes based on first-order logic. Unfortunately, such systems are still proposi-tional [24,25]. In [21], an automated reasoning system for first-order Horn clauses is pre-sented (Connectionist Horn Clause Logic), which is implemented in a feedforward neuralnetwork. In [24] an extension of the method in [23] is presented for inserting first-orderlogic programs into three-layer recurrent Artificial Neural Networks that correspond to anapproximation of the semantics of programs. Finally, in [43] an analogous result to [42] isshown, according to which a first-order resolution proof (although of a fixed predetermine",
            {
                "entities": [
                    [
                        39,
                        78,
                        "TITLE"
                    ],
                    [
                        505,
                        544,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 300 (2021) 103555Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHard choices in artificial intelligence, Thomas Krendl Gilbert b,∗∗Roel Dobbe a,∗a Faculty of Technology, Policy and Management, Delft University of Technology, The Netherlandsb Center for Human-Compatible AI, UC Berkeley, United States of Americac University of Wisconsin-Madison, United States of America, Yonatan Mintz c,1a r t i c l e i n f oa b s t r a c tArticle history:Received 22 June 2020Received in revised form 31 May 2021Accepted 5 July 2021Available online 14 July 2021Keywords:AI ethicsAI safetyAI governanceAI regulationPhilosophy of artificial intelligenceSociotechnical systems1. IntroductionAs AI systems are integrated into high stakes social domains, researchers now examine how to design and operate them in a safe and ethical manner. However, the criteria for identifying and diagnosing safety risks in complex social contexts remain unclear and contested. In this paper, we examine the vagueness in debates about the safety and ethical behavior of AI systems. We show how this vagueness cannot be resolved through mathematical formalism alone, instead requiring deliberation about the politics of development as well as the context of deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness in terms of distinct design challenges at key stages in AI system development. The resulting framework of Hard Choices in Artificial Intelligence(HCAI) empowers developers by 1) identifying points of overlap between design decisions and major sociotechnical challenges; 2) motivating the creation of stakeholder feedback channels so that safety issues can be exhaustively addressed. As such, HCAI contributes to a timely debate about the status of AI development in democratic societies, arguing that deliberation should be the goal of AI Safety, not just the procedure by which it is ensured.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).The rapid adoption of AI systems is reshaping many public, professional, and personal domains, providing opportunities for innovation while also generating new forms of harm. These harms are diverse, ranging from physical dangers related to new robotic systems (e.g. autonomous vehicles [1]), to economic losses related to welfare systems [2], to forms of racism and discrimination in systems that engage with biometrical data in public spaces [3,4] or with personal data on social media platforms [5,6]. These cases reveal emerging gaps between the promised beneficial outcomes of AI applications and the actual consequences of deployed systems. Ongoing risks and harms are thus a product of the sociotechnical gap, “the great divide between what we know we must support socially and what we can support technically” [7].In response, a broad spectrum of civil society initiatives have emerged to safeguard human domains from the effects of AI systems. Debates about the sociotechnical gap have taken two forms. One is the proposal of normative principles to determine how the gap should be filled or who should do it. This has led to a plethora of reports and statements [8]about how AI should be governed to respect fundamental rights [9,10], alongside a growing need to operationalize these principles [11]. For example, the OECD Principles on Artificial Intelligence “promote artificial intelligence (AI) that is inno-* Corresponding author: TU Delft - Faculty of Technology, Policy and Management, Building 31, Jaffalaan 5, 2628BX Delft, The Netherlands.** Corresponding author: UC Berkeley Graduate Division, 424 Sproul Hall, Delft, CA, 94720-5900, United States.E-mail addresses: r.i.j.dobbe@tudelft.nl (R. Dobbe), tg340@berkeley.edu (T. Krendl Gilbert).1 All authors contributed equally to this work.https://doi.org/10.1016/j.artint.2021.1035550004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fR. Dobbe, T. Krendl Gilbert and Y. MintzArtificial Intelligence 300 (2021) 103555vative and trustworthy and that respects human rights and democratic values,” and are signed by governments [12]. The European Commission recently proposed a regulatory framework to translate higher-level principles into concrete technical and legal solutions through “harmonized standards” [13]. However, it is unclear how these standards could reconcile the diverse needs of users in the context of particular systems and domains. Second is the proposal of technical tools to better fill the gap. While these efforts have generated many technical approaches related to mathematical criteria for “safety” or “fairness”, their systematic organization and prioritization remains unclear and contested [14–17].Missing from both debates is a sustained interrogation of what it means to identify, diagnose, and ultimately fill the sociotechnical gaps generated by AI systems. This entails asking deeper questions about how a given system may restructure human values and social practices, whether technical and governance criteria may be reconciled in design choices, and when or where gaps emerge across the system’s development lifecycle. Put differently, we lack a presentation of AI development as a form of machine politics: interrogating and evaluating how the choices that structure a system’s design and implementation in turn reorganize human domains. In terms of machine politics, AI development is a deliberative practice comprising how human constituencies make basic organizational choices about their status as a political community.Concretely, every AI system requires a consensus definition of what it would mean for it to be safe. But present proposals for the technical safety and governance of AI systems tend to focus on safety either as a criterion of technical design, operational conditions, or the experience of end users. This means safety criteria are marred by an underlying vagueness, the absence of unifying categories to establish whether a system’s capabilities are safe or not.This paper makes two key claims. First, AI development must be reconceived in terms of the multiple points of encounter between system capabilities and sociotechnical gaps. This requires a new vocabulary and framework to make sense of salient gaps in the context of technical design decisions, constituting a reciprocal relationship between system development and governance. Second, developers must take on new roles that are sensitive to feedback about how to manage these gaps. This requires communicative channels so that stakeholders are empowered to help shape the criteria for design decisions.Our contributions flow from these two claims. In Section 2 we supply a lexicon of terms for the problems at stake in sociotechnical gaps. In Section 3 we analyze the present landscape of proposed technical and normative solutions to particular gaps in terms of piecemeal responses to vagueness. In Section 4 we present Hard Choices in Artificial Intelligence (HCAI) as a systematic framework that maps possible gaps to particular feedback channels for designers and stakeholders to use. In Section 5 we present this framework’s implications for designers and advocates when evaluating the technical performance and governance standards of actual systems. Section 6 concludes.We emphasize that our concerns, while responding to more recent iterations of AI and computer systems, are not new. The research agenda of situated design [18] and Agre’s call for a “critical technical practice” [19] comprise classic phe-nomenological critiques of “good old-fashioned” symbolic and expert systems, in particular the need to become critical about certain formal assumptions behind intelligence and to reassess problematic metaphors for perception and action [20]. Yet much technical research today has moved beyond these critiques. Reinforcement learning (RL), for example, reflects Dreyfus’ exposition of intelligence as a learned, situated, dynamic activity developed from coping with one’s surrounding environment and embodying different strategies for action. The question is no longer what computers can or cannot do, buthow to structure computation in ways that support human values and concerns. To support this aim, we propose AI prac-titioners will need new cybernetic practices that guide how feedback may be solicited from existing and emerging political orders.We thus apply an insight to AI development that scholars in Science and Technology Studies (STS) have appreciated for over four decades: any and every technological system is political, requiring collective agency and corresponding forms of deliberation to ensure its safety for everyone affected by it [21].2. Towards a sociotechnical lexicon for AIAt present, AI research lacks a robust sociotechnical lexicon. This would include the emerging problem space of AI Safety as well as newly-relevant questions of cybernetics in the context of present and future AI governance topics. In this section we present a preliminary lexicon to reveal areas of overlap and divergence between these domains, enabling comparison between contemporary assumptions of AI development and possible alternative paradigms.As was stated in the original Dartmouth summer project proposal, research on artificial intelligence is meant to pursue “the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it” [22]. Beneath specific efforts to simulate language, brain models, and intellectual creativity, AI theorists were most interested in precision: adequately specifying the mechanisms underpinning intelligence such that they would be possible to replicate via computation and symbolic reasoning. This quest for exactness has con-tinued to",
            {
                "entities": [
                    [
                        135,
                        174,
                        "TITLE"
                    ],
                    [
                        1477,
                        1516,
                        "TITLE"
                    ],
                    [
                        7129,
                        7168,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 80 (1996) l-27 Artificial Intelligence The topology of boundaries Margaret M. Fleck* Department of Computer Science, University of Iowa, Iowa Ci& IA 5.2242, fJ,YA Received November 1990; revised May 1993 Abstract High-level representations used in reasoning distinguish a special set of boundary locations, at which function values can change abruptly and across which adjacent regions may not be connected. Standard models of space and time, based on segmenting R”, do not allow these possibilities because they have the wrong topological structure at boundaries. This mismatch has made it difficult to develop formal mathematical models for high-level reasoning algorithms. This paper shows how to modify an W” model so as to have an appropriate topological structure. It then illustrates how the new models support standard reasoning algorithms, provide simple models for previously difficult situations, and suggest interesting new analyses based on change or non-change in scene topology. 1. Introduction (including is the real line Most work in artificial language) of events intelligence robotics, and natural in space or arrangements not only “core” AI, but also peripheral involves about arrange- reasoning in time. The most popular model (R) and the most popular model for space is real Euclidean structure at object, event, topological regions need functions can display abrupt in value across region boundaries. Standard models of regions based on R” do areas such as vision, ments of objects for time space R”. However, or region boundaries. not be connected changes not allow either of these possibilities. In the symbolic models used in reasoning, to one another and otherwise continuous these models have the wrong adjacent Practical implementations in artificial intelligence can problem. An algorithm may not make extensive or sophisticated * E-mail: rnfleck@cs.uiowa.edu. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00051-4 typically work around this use of topological \f2 MM. Fleck/Artificial Intelligence 80 (1996) 1-27 concepts. Or the author may adopt an model which works in his particular application but may not work for other applications, there are only two types of regions intelligence topological mismatch between R” and what is desired for artificial pattern of difficulties when researchers come to build theoretical, mathematical of their algorithms. Thus, researchers waste time battling with inappropriate models, e.g. a robot motion planner may assume in the scene, obstacles and free space. However, time that could be better spent designing practical algorithms. that the creates a analyses theoretical some authors [2,3,19,20,22,23,36] axioms without a specific concrete model. This is mathematically their analyses on a set of risky. It is (at least) one concrete it is to extend an axiom set without a clear picture of the object that these to prove an axiom set consistent It is difficult impossible from axiom sets (cf. [ 521). And to derive possible models except by exhibiting base Alternatively, symbolic difficult model. almost axioms are intended to describe. In this paper, I will show how to modify an Rn model so it has the correct topology. subtle, I will procede straight into a review of basic structure topological and why the structure of IF in Section 4 and discuss from As the issues involved are relatively definitions topology from should be assigned within is not correct alternative models the literature, (Section 2). I will regions and across boundaries, in Section 5. Section 6 works through some extended examples to show how they would be handled then discuss what in the new model. the new model I will describe (Section 3). 2. What is topology? A satisfactory model of space and the topological ture, because practical reasoning: time must define a suitable topological structure determines two concepts of great importance struc- in are continuous, l which functions l which regions and paths are connected. the definitions I will review for additional details. In this section, topology text (e.g. [ 38,391) and of basic topological concepts. t See any 2.1. Open sets and connectivity Readers will be familiar with terms such as “connected function” from courses in calculus or analysis. Topology generalizes “continuous definitions In particular, closely ordering familiar examples, so that they can be applied to a wider range of models tied to a metric readers unfamiliar with topology may believe (e.g. the usual distance (e.g. the usual linear order on points for points function in time). Although it is not true in general. “open region”, set” and these for space and time. that topological notions are in space) and/or an this is true for some ’ I will resist the temptation groups, Euler characteristics, to describe the fascinating and knot polynomials, range of derived because topological they would distract concepts from such as the main homology point of this paper. \fMM. Fleck/Artijicial Intelligence 80 (1996) l-27 3 Two pieces of information are required to specify a particular topological space: l what points does the space contain, and l what sets of points are “open”. So, for ex,ample, in the usual topology on the real line R, the open sets are the familiar open intervals, e.g. ( 1,2), (202, co), and unions of such intervals. The real line can also be given other topologies, see [38]. Open sets can also be specified indirectly, e.g. via order relations, by cell complex constructions [ 391, or by taking a subset of isome established space such as JR”. In particular, ( -57,3), Definition 1. Let A be a subset of a topological space B. In the subspace topology on A, a subset S of A is open if and only if S = X n A, where X is some open subset of B. So, the subset A = [ 0, 1 > U ( 1,5] of lR is typically given the subset topology. The open sets of A are the intersections of A with open sets of R. To be a well-formed topological structure, the open sets must satisfy the following conditions: l the null set and the entire space are both open, l the union of any (finite or infinite) collection of open sets is open, and l the intersection of any finite collection of open sets is open. A set is said to be closed, in some specified topology, if its set complement is open. It is possible for a set to be both open and closed (e.g. the whole of R) or neither (e.g. a half-open interval of W, in the usual topology). The closure ;ii of a set A is the smallest closed set containing A. A regia’n in a topological space is said to be connected if it is not the union of two disjoint open sets. A region A is said to be path-connected if any two points n and y in A can be connected by a continuous path lying entirely in A. Formally, there must be a contmuous function p : [ 0, 1 ] -+ A, such that p(O) = x and p( 1) = y. Informal models of space do not distinguish these two notions. Fortunately, this does not matter: connectedness and path-connectedness will be equivalent for the spaces discussed in this paper. 2.2. Continuous functions The topological definition of continuity is a generalization of the familiar E-S defini- tion from calculus: Definition 2. A function f : X --) Y is continuous if and only if f-’ (U) is open for any open set U C_ Y. In order to apply this definition, we must specify a topology for both the domain and range of the function. Within a connected region, continuous functions behave as you expect them to. If, however, the domain consists of two non-connected components (e.g. the domain is [ 0,l) U ( 1,5] ), the value of a continuous function can jump abruptly as one passes between the two components. \f4 M.M. Fleck/Artificial Intelligence 80 (1996) 1-27 Continuous functions are also used to match representations topologically, from another via stretching, bending, e.g. de- and termine whether one object can be obtained deformation. Formally, we define: Definition 3. A function f : X + Y is a homeomolphism has a continuous homeomorphism inverse. X and Y are said from X onto Y. and to be homeomorphic if there exists a if f is continuous To match two complex situations, as in stereo matching (cf. [ 141)) a stronger con- straint can be useful [ 28,45,46] : Definition 4. Two subsets X and Y of R” are isotopic if there is a continuous homeomorphisms fi : X -+ IP, i E [O,l], such that fo(X) =X and fl(X) = Y. family of Two homeomorphic spaces have identical are, in addition, deformed into the other.2 embedded “the same way” topological properties. Two isotopic spaces in W”, so that one can be continuously 3. The desired topological structure Reasoning algorithms, both high-level a particular for locating boundaries and low-level, distinguish algorithms formal definition images, and events, processes, or states locations as “boundaries”. Boundaries demarcate objects in 3D space, distinctive in 2D camera Although accepted searchers as to where boundaries artificial applications space or time. However, as we shall see in this section, from interior of regions contrast, R” has the same structure at all locations. set of regions of time. in 1D representations are still flawed and there is no generally re- situations. Many for structure in the required across boundaries. By should be placed depend on having a suitable in most practical to differ greatly of a boundary, is considerable that required the structure intelligence topological consensus among seems there 3.1. Boundaries the topological and the objects, Before discussing regions, or intervals facts, we must first draw a clear distinction between boundaries two parts of the same object can fail to be locally connected. The object might consist of more than one region may double back so as to connected to your finger, they do touch itself, as illustrated not typically the boundaries of 3D objects and 2D regions need not form closed curves, as illustrated in Fig. 1. When you touch your thumb com",
            {
                "entities": [
                    [
                        72,
                        98,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 316 (2023) 103843Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintPeerNomination: A novel peer selection algorithm to handle strategic and noisy assessmentsOmer Lev a, Nicholas Mattei b, Paolo Turrini c, Stanislav Zhydkov d,∗a Department of Industrial Engineering and Management, Ben-Gurion University of the Negev, Israelb Department of Computer Science, Tulane University, USAc Department of Computer Science, University of Warwick, United Kingdomd Mathematics Institute, University of Warwick, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 30 November 2021Received in revised form 12 June 2022Accepted 21 December 2022Available online 29 December 2022Keywords:Peer selectionStrategyproofnessOptimalityNoisy opinionsReweightingIn peer selection a group of agents must choose a subset of themselves, as winners for, e.g., peer-reviewed grants or prizes. We take a Condorcet view of this aggregation problem, assuming that there is an objective ground-truth ordering over the agents. We study agents that have a noisy perception of this ground truth and give assessments that, even when truthful, can be inaccurate. Our goal is to select the best set of agents according to the underlying ground truth by looking at the potentially unreliable assessments of the peers. Besides being potentially unreliable, we also allow agents to be self-interested, attempting to influence the outcome of the decision in their favour. Hence, we are focused on tackling the problem of impartial (or strategyproof) peer selection – how do we prevent agents from manipulating their reviews while still selecting the most deserving individuals, all in the presence of noisy evaluations? We propose a novel impartial peer selection algorithm, PeerNomination, that aims to fulfil the above desiderata. We provide a comprehensive theoretical analysis of the recall of PeerNomination and prove various properties, including impartiality and monotonicity. We also provide empirical results based on computer simulations to show its effectiveness compared to the state-of-the-art impartial peer selection algorithms. We then investigate the robustness of PeerNominationto various levels of noise in the reviews. In order to maintain good performance under such conditions, we extend PeerNomination by using weights for reviewers which, informally, capture some notion of reliability of the reviewer. We show, theoretically, that the new algorithm preserves strategyproofness and, empirically, that the weights help identify the noisy reviewers and hence to increase selection performance.1© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).* Corresponding author.E-mail addresses: omerlev@bgu.ac.il (O. Lev), nsmattei@tulane.edu (N. Mattei), p.turrini@warwick.ac.uk (P. Turrini), s.zhydkov@warwick.ac.uk(S. Zhydkov).1 This paper is a significant extension of our IJCAI 2020 contribution [29], which was limited to the study of PeerNomination without noise. Besides exploring the role of weights in peer selection in the presence of noise, we also extend the unweighted version with novel theoretical and experimental results.https://doi.org/10.1016/j.artint.2022.1038430004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fO. Lev, N. Mattei, P. Turrini et al.1. IntroductionArtificial Intelligence 316 (2023) 103843Peer evaluation and selection, where agents rate others and then choose a subset of themselves for an award or a prize, is one of the pillars for quality assessment in scientific contexts and beyond. While many of the current methods rely on expert panels, ideally impartial to the selection process [7,42], there is increasing need for alternative mechanisms that keep the procedure both reliable and cheap. An important approach to achieve this goal is that of using the agents that have submitted proposals for review as the set of reviewers themselves. This is particularly relevant in open online courses [37], where hiring professional graders is prohibitively expensive. Indeed, even large AI venues such as IJCAI and NeurIPS have been implementing a portion of this system, requiring authors who submit papers to agree to be the reviewers of other papers.The importance of improving peer reviewing procedures has been brought to light by the 2014 NeurIPS experiment [24,43]: of all papers submitted to NeurIPS 2014, 10% were reviewed twice by two independent committees which, aston-ishingly, agreed on less than half of the accepted papers. Whether the outcome was due to bias, incompetence, or rather well-thought disagreement is still unclear. What had been made clear, however, is that the current solutions seem to suffer from undesirable features. The exploding number of papers at AI and general computer science venues has spurred interest in improving many aspects of the peer review process, including: assignment biases [32,25,19], review quality [48], reviewer training [46], and even the quality of reviewers’ discussions (see overview by Shah [42]). Other studies of bias in evalua-tive processes have also brought to the fore the extent and impact of inaccurate assessments in peer reviewing, for example [49,45]. Finding high quality mechanisms for peer review is a critical step in helping the review process in large conferences [4], grant reviewing [33], online courses [47], and other domains.Researchers in algorithmic game theory and computational social choice worked on the peer selection problem for at least the past decade, focusing on accurate and strategyproof algorithms, including Partition [1], Credible Subset [23] and ExactDollarPartition (EDP) [4]; we provide an overview of these algorithms and more in Section 3. All of these algorithms take a Condorcet view on this aggregation problem, i.e., that there exists an a-priori ground-truth ranking of the agents, and we wish to select as many of the top ranked agents as possible, though given only access to the agents’ own noisy reports [52]. While this raises obvious philosophical challenges – e.g., what does this ground truth represent if we cannot have direct access to it? – we follow this view as it allows for quantitative analysis of the performance of peer selection algorithms, and hence their objective comparison.Many of the existing algorithms we survey in Section 3 highlight the trade-offs forced by the pursuit of the dual goal of impartiality and optimality. Some require the set of reviewing agents to be partitioned into clusters that do not review each other [4]; while others sacrifice exactness – the ability to select a given number of agents consistently [23]. With PeerNomination, the algorithm presented in this paper, we also sacrifice exactness, but we are able to achieve a new state-of-the-art performance. Additionally, none of the existing algorithms seek to alleviate the problem of noisy inputs in a unified, strategyproof mechanism. When earlier work did engage with noisy reports, it was limited to empirical testing with relatively low noise, e.g., a Mallows model with ϕ = 0.5 [4], which yields fairly minor changes in agents’ reports (as will be shown in Section 2.3). We are instead concerned with algorithms that can handle a significant level of noise, while maintaining strategyproofness and high quality of selection, an important missing aspect in the literature.Ideally, we would like an algorithm that is capable of identifying inaccurate reviewers and reducing their influence on the final selection, using only the agents’ reports themselves as a guide. We could, for example, try and downgrade those reviewers that differ too much from others. However, there are two problems with this approach: first, the noise may be such that it is difficult to establish what the consensus actually is; and second, that this meta-level reweighting can be exploited strategically. Simple reweighting is not strategyproof: consider, for example, an agent a that is harshly reviewing agent b, with both a and b reviewing a third agent c. Agent b could benefit by reviewing agent c in a way that would present agent a as an unreliable agent, lowering the impact of the report of agent a for agent b if weights are computed based on correlations to the evaluations of others, e.g., as done by Merrifield and Saari [33]. On the other hand, if a mechanism is able to identify agent b as a source of noise, it can increase the overall quality of the selection. While one can reweight agents without maintaining strategyproofness [47,51], we wish to achieve increased selection quality and strategyproofness. The algorithm we present in this paper is able to achieve both of these tasks with state of the art performance.1.1. ContributionWe present PeerNomination, an impartial (or strategyproof) peer selection method for scenarios where n agents re-view and are each reviewed by m others, with the goal of selecting k of them. Each proposal,2 which we identify with the proposing agent, is considered independently and it is selected only if it falls in the top kn m of the majority of its reviewers’ (partial) rankings, using a probabilistic completion if such number is not an integer. Performing the selection in-dependently relaxes the exactness requirement, hence our algorithm is not guaranteed to select exactly k agents every time. However, under some mild assumptions, the algorithm does select exactly k agents in expectation. Unlike other well-known 2 For the sake of clarity, when an agent is referred to as a reviewer we will always mean in the context of reviewing others and we will use the word proposal when referring to an agent that is being reviewed.2\fO. Lev, N. Mattei, P. Turrini et al.Artificial Intelligence 316 (2023) 103843peer reviewing me",
            {
                "entities": [
                    [
                        153,
                        243,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 82 (1996) 303-330 Artificial Intelligence Stochastic modelling of Genetic Algorithms David Reynolds*, Jagannathan Gomatam Department of Mathematics, Glasgow Caledonian University, Cowcaddens Road, Glasgow G4 OBA, UK Received July 1994 Abstract throughout distinctions replacement, for convergence, via Genetic Algorithms, which has practical This paper presents stochastic models for two classes of Genetic Algorithms. We present between classes of Genetic Algorithms which sample important in terms of their search dynamics. For both classes of with and without and analyse special cases of algorithm, we derive sufficient conditions Genetic Algorithm optimisation. We also derive a long-run measure of crossover bias for to the optimisation theoretical choice of crossover operators. For a class of Genetic Algorithms, we provide the algorithms underpinning increase. For degenerate an alternative accompanies excessive crossover rates. In formulating important definitions are introduced which capture in simple form the probabilistic properties of the genetic operators, which provides models which are independent that results, by proving search as mutation probabilities that degeneration class of Genetic Algorithms, we show of a class of empirically derived of solution encoding schemes. implications with respect cost-independent to randomised, the models, 1. Introduction reasons Genetic Algorithms to a wide variety of combinatorial including many that are NP-hard [3,10]. Theoretical (GAS) are a set of heuristic search algorithms which have optimisation been applied with success into problems, those who the and analyse deterministic mathematical models for GAS 12, lo], and formulate those who investigate the application of stochastic models based on the theory of Markov Chains [4, 5, 7-9, 15, 17, 181. In this paper we shall present a number of stochastic models for GAS. this success are divided mainly investigations two camps; into for * Corresponding author. E-mail: dre@gcal.ac.uk. 0004-3702196/$15.00 SSDI 0004-3702(94)00091-3 0 1996 Elsevier Science B.V. All rights reserved \f304 D. Reynolds, .I. Gomatam I Artificial Intelligence 82 (1996) 303-330 We begin by giving a brief introduction to GAS in Section 2, making important of and there. properties [4,5,15,18], then proceed to the authors; the GA operators representation-independent of homogeneous Markov Chains the probabilistic to formulate In Section 3 we present a brief introduction from old ones by sampling with replacement, In Sections 4 and 5 we introduce new definitions large classes of GAS, those which create new populations of distinctions between and those which sample solutions to the solutions without replacement. to theory in [7] summarise current stochastic models for GAS [7-9, 171. The work reported in this paper we generalise and extend was previously unknown for the results reported these describing stochastic models for the two definitions classes of GAS mentioned. The models are to investigate various properties of GAS. We analyse special cases of optimisation via GAS, and show that, given certain choices of mutation and crossover rates, both GAS reduce to a search of the solutions where no role is played by the cost function, despite the that both GAS For of a selection operator. presence for the expected numbers of converge in one generation. We present bounds in the long run which is based optimal and other solutions within the population on the probability of creation of solutions under crossover, for the class of GAS which operate on the basis of sampling with replacement. Finally, we discuss the for further analysis of the models contained potential in this paper with respect to the long-run probability distribution of a generalised GA [7] and for obtaining their rates of convergence analysing these cases, we show this distribution. then used and use towards 2. Definitions of GAS . . , k}, and that for the formulation their behaviour. We stipulate and concepts which are necessary to describe The objective of this section is to formulate definitions for GAS, together with of various assumptions that our optimi- mathematical models sation problem has k > 0 candidate solutions, where k is an integer. We assume that we have assigned a bijective mapping from the set of solutions to the integers (1,. a well- defined cost (or fitness), J, which is restricted by 0 <A < CQ. Thus, to the set of fitness values f = solutions {fi7.. . , fk}. For the purposes of formulating the models, we merely assume to the [lo] each solution would be repre- solutions, e.g., thus, we sented in our analysis as the base 10 version of its binary representation; do not assume any particular encoding scheme for solutions. that we have assigned a natural in a binary string encoding a set of and developing s = {si , s2, . . . , sk} i s k) there corresponds to each solution labelling system corresponds i (1~ index there A GA mentioned for solving is characterised by possessing the following features finite and discrete maximisation [3, lo]: problems of the type (i) a scheme for encoding solutions to the optimisation problem to be solved (chromosomes); (ii) an evaluation function that rates each solution, assigning a positive cost, or fitness to each one: \fD. Reynolds, J. Gomatam I Artificial Intelligence 82 (1996) 303-330 305 (iii) an initialisation procedure candidate solutions; for generating an initial population of size N of (iv) a set of operators used to manipulate the genetic composition of the population between generations; (v) a set of parameter values, such as stopping-criteria, This algorithm, together with the genetic operators, has been implemented etc. in the recent there are many different to optimisation problems, the fitness evaluation/selection, representation the most common many different ways [6]. For example, schemes [6] for candidate solutions being binary strings of fixed length L. Also, in different ways mutation and crossover operators have all been implemented [7]. [6], including introduction Further, the order in which these operators are applied in order to generate new populations has also been varied [6]. However, we can divide into two classes the majority of from the current population and solutions by sampling solutions with replacement those which sample solutions then the genetic operators. A pseudo-code without is: description the genetic operators, and then implement those algorithms which form new populations for GAS which use sampling with replacement of a time-varying mutation operator of existing GAS; implementing replacement and GAIWI(N, begin s, f, fitness selection, mutation, crossover) Initialise with population of size N at generation REPEAT WHILE BEGIN ]Pop(t + l)] <N t = 0 Select (p 2 2) parent solutions with replacement from Pop(t) by fitness selection Carry out mutation of the copies of the selected parents Combine the mutant parents to form (c 3 1) child solutions by crossover Place the child solutions in the new population Pop(t + 1) END t:=t+l UNTIL stopping-criteria-reached end Here and in what follows, mutation and crossover are pre-defined operators. We shall consider fitness selection above and in what follows to be implemented roulette wheel selection the selected parent solutions for GA/WI, we shall by the common immediately after selection consider into the old population into Pop(t)), and that we subsequently operate on copies of the parents. For GAS which operate on the basis of sampling without replacement, a pseudo-code description to be replaced [lo]. Further, (i.e., is: GA/ WO(N s, f, fitness selection, mutation, crossover) begin \f306 D. Reynolds, J. Gomatam ! Artijicial Intelligence 82 (1996) 303-330 Initialise with population of size N, N even, at generation REPEAT t = 0 Select N parent solutions with replacement from Pop(t) by fitness selection, to form population Pop’(t) to each solution Carry out mutation in Pop’(t) to form population Pop “( t ) Carry out croSSover pairwise between solutions in Pop”(t) to form N new child solutions, to form population Pop”‘(t) Set Pop(t + 1) := Pop”‘(t) t=t+l UNTIL stopping-criteria-reached end although in GA/W0 to note that both algorithms contain a sampling with replacement It is important fitness selection operator, and crossover operators are implemented on the basis of sampling from the current population without the latter tions. Note that we have not described choice of solution models we formulate will be independent of in GA applica- to the [6]. The two operators without replacement the above algorithms with respect to [9], GAS which contain replacement. According scheme, of which are more common there are many of representation. implementations the mutation representation 3. Current stochastic models We present a brief introduction the current approaches to [5,15,18] for further details. to discuss to Markov Chains. We then proceed to the stochastic modelling of GAS. The reader is referred 3.1. Homogeneous Markov Chain theory Definition 3.1. A stochastic process (i.e., a sequence of random variables over i.e., if time, X(t)) if it exhibits Markov dependence, is called a Markov process Pr[X(t) <x 1 X(t,) = x,, . . . , X(to) = x,] = Pr[X(t) s x 1 X(t,) = xn] = q&,x; t,) , (3.1) (3.2) (3.3) where t>t,>+-- > t,. A realisation of X(t) over time is called a Markov Chain. The Markov Chains we shall discuss in this paper are realisations of random variables defined over discrete state-spaces and discrete time. If a Markov process is said to be homoge- has parameters which do not vary over time, the process case, the probabilities of neous, otherwise, In the homogeneous inhomogeneous. \fD. Reynolds, .I. Gomatam I Artificial Intelligence 82 (1996) 303-330 307 transiting from state i to state j between on t, - t, and are defined to be time steps t, = m and t, = n depend only PI;“.“’ = Pr[X,=j]X,=i]. (3.4) A Markov Chain is said to be irreducible o",
            {
                "entities": [
                    [
                        75,
                        117,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 239 (2016) 143–167Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBuilding knowledge maps of Web graphsValeria Fionda a, Claudio Gutierrez b, Giuseppe Pirrò c,∗a DeMaCS, University of Calabria, Italyb DCC, University of Chile, Chilec ICAR-CNR, Rende, CS, Italya r t i c l e i n f oa b s t r a c tArticle history:Received 22 May 2014Received in revised form 3 July 2016Accepted 11 July 2016Available online 18 July 2016Keywords:Maps of the webNavigationWeb of dataLinked dataSemantic web1. IntroductionWe research the problem of building knowledge maps of graph-like information. There exist well-consolidated cartographic principles and techniques for mapping physical landscapes. However, we live in the digital era and similarly to the Earth, the Web is simply too large and its interrelations too complex for anyone to grasp much of it through direct observation. Thus, the problem of applying cartographic principles also to digital landscapes is intriguing. We introduce a mathematical formalism that captures the general notion of map of a graph and enables its development and manipulation in a semi-automated way. We present an implementation of our formalism on the Web of Linked Data graph and discuss algorithms that efficiently generate and combine (via an algebra) regions and maps. We present the MaGe tool, implementing the map framework, and discuss examples of knowledge maps.© 2016 Elsevier B.V. All rights reserved.The Web can be seen as a vast space of interconnected information that users commonly access via navigation enabled by browsers. However, the Web is simply too large and its interrelations too complex for anyone to grasp much only by direct observation. Consider the task of navigating a citation network by using, for instance, Google Scholar.1 One typically starts from a seed paper. By clicking on the cited by link, one navigates towards papers that have cited the seed paper, selects those of interest (e.g., by bookmarking them) and then continues. After a while it is very hard to reconstruct the network of citations in terms of papers of interest and connections between them. Moreover, the whole process is manual. Having an automatic way of identifying the portion of the citation network of interest (i.e., papers and their connections) and then some form of abstract representation, where only salient papers (e.g., papers with certain keywords in the title) and links between them are represented, is an extremely useful support to the navigation.To cope with the huge amount of interconnected information available on the Web, we take inspiration from cartography and introduce a framework to build maps of the Web. In the physical space, the process of map making can be summarized in two main steps, that is, selection and abstraction [1]. Selection enables one to focus only on the particular pieces of information that will serve the map’s purpose; specifically, in this phase the region to be mapped is chosen. In our previous example about navigating a citation network, the region would consist in nodes (i.e., papers) and cited by links visited during the navigation. Abstraction is the fundamental property of a map, which states that a map is always smaller than the region * Corresponding author.1 http :/ /scholar.google .com.E-mail addresses: fionda@mat.unical.it (V. Fionda), cgutierr@dcc.uchile.cl (C. Gutierrez), pirro@icar.cnr.it (G. Pirrò).http://dx.doi.org/10.1016/j.artint.2016.07.0030004-3702/© 2016 Elsevier B.V. All rights reserved.\f144V. Fionda et al. / Artificial Intelligence 239 (2016) 143–167it portrays. Abstracting the region visited while navigating our citation network could be done by considering only nodes with certain properties (e.g., papers published in some specific conference) and links between them.We see Web Maps as useful navigational cues and powerful ways of conveying complex information via abstract repre-sentations; in our context abstraction is used to remove unwanted details that are out of the scope of the map’s subject. This gives Web Maps the role of navigational charts that help cope with the size of the Web (cyber) space and elude the “lost in the cyberspace” syndrome [2]. Thanks to Web Maps, users can explore complex digital territories, find routes toward destinations and discover previously unknown connections between knowledge items. Web Maps are also useful for analyz-ing information. For instance, the availability of a series of chronologically sequential maps enables complex map analysis (e.g., longitudinal analysis) for the detection and forecasting of trends in specific domains. This is useful, for instance, in the analysis of knowledge flows in scientific literature to show how the interlinking between disciplines is changing [3]. Another example are maps of social networks that can be analyzed to forecast friendship [4].Recent progress in Web technologies and languages originating from the Semantic Web proposal as well as the availability at planetary scale of structured information in the Resource Description Framework (RDF) standard data format, open new opportunities toward automating the construction of Web Maps. On one hand, interlinks between data items, encoded in RDF predicates, carry a precise semantic meaning, thus allowing for precise characterization of the nature of reachability that is crucial in extracting regions of the Web. On the other hand, maps can be given an RDF representation and then be processed not only by humans, via visual interpretations, but also by machines, due to the machine-processable nature of RDF. This will foster the exchange, combination and reuse of maps. We believe that the availability of Web Maps can help human users cope with the complexity of Web Regions in the same way as geographic maps help users cope with the complexity of large physical regions.Notions of maps for digital landscapes have been around for some time. Doemel [5] introduced the idea of Web Map as a means to capture user navigational activities. This kind of map is not a map in the cartographic sense as it misses the abstraction phase, which is the raison d’être of a map [1]. There are also many tools (partially) touching upon the problem of building maps of the Web. The most traditional and popular are bookmarks: a list of URLs specified by a user when navigating the Web. This idea has been enhanced to incorporate, for instance, social features (share, rank, tag) and/or annotations of different types of data (e.g., not only pages but also documents). Delicious,2 Diigo,3 and Google Bookmarks4are among the most popular bookmarking systems. Some systems go beyond simple bookmarks by enabling one to organize URLs to also highlight connections between the two. Results are grouped and presented in the form of a graph, which simulates the idea of a region of the Web. Examples of such systems are search engines like Tag Galaxy,5 navigational history tools (e.g., [5,6]), visual HTML site maps (for users) and atlases of the Web (e.g., [2]). More recent approaches focus on providing visual representations of information in specific domains such as publications or news (e.g., [7,8]).Existing approaches, discussed in Sections 2.1 and 6, do not comply with the idea of a map that we envision. First, even if they partially simulate the idea of capturing regions of the Web, they do not consider the abstraction of Web Regions to build maps. Second, they are designed for human visualization; hence their automatic processing, composition and reuse are not considered, which hinders the exchange, automatic combination and interpretation of maps. Third, they do not enable the declarative specification of the region (e.g., portion of interest of the Web) to be mapped thus hindering the automation of the process of creating maps. Fourth, they lack a formal mathematical model. They do not guarantee formal/provable (reachability) relations between the points in the map; formal notions of granularity and scope; and formal provable rela-tions between the map and the region it represents. These limitations obstruct the generation of formal deductions from maps.1.1. ContributionsIn this paper we formally introduce the notion of Web Map and face several challenges toward this goal. First, given a user need or a conceptual notion, provide a way to specify a region of the Web that represents or encompasses it. Second, given a region of the Web, define what is a map of it and investigate its formal properties. Third, devise algorithms and compose the procedures efficiently. The contributions of this paper are:• We provide a mathematical formalization of the notions of region and map of a graph; we discuss several types of maps, present algorithms for constructing such maps and study their complexity.• We introduce an algebra for maps and study its formal properties.• We discuss the problem of obtaining regions of the Web via graph navigational languages; to this aim we introduce a general navigational language to specify Web Regions.• We showcase an implementation of the formal map framework and navigational language on the current Web of Linked Data via a tool called MaGe (Map Generator).6• We discuss some examples of Web Maps with real data.2 http :/ /delicious .com/.3 http :/ /www.diigo .com/.4 http :/ /www.google .com /bookmarks/.5 http :/ /taggalaxy.de/.6 The tool is available at the Website http :/ /mapsforweb .wordpress .com.\fV. Fionda et al. / Artificial Intelligence 239 (2016) 143–167145An overview of the idea of Web Maps was given in Fionda et al. [9,10]. The present paper significantly extends our previous work by providing: (i) all the formal definitions (ii) a new family of maps (i.e., k-maps); (iii) all the formal proofs; (iv) algorithms and complexity; and (v) further examples of maps.1.2. Organization of the paperThe paper starts with a general overview of the problem of building Web maps and continues",
            {
                "entities": [
                    [
                        136,
                        173,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 306 (2022) 103667Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelation between prognostics predictor evaluation metrics and local interpretability SHAP valuesMarcia L. Baptista a,∗a Delft University of Technology (TU Delft), Mekelweg 5, 2628 CD Delft, the Netherlandsb Luleå University of Technology, 971 87 Luleå, Swedenc Palo Alto Research Center (PARC), Palo Alto CA 94304, USAd University of Lisbon - Instituto Superior Tecnico (IST), Av. Rovisco Pais nº1, 1049-001 Lisbon, Portugal, Kai Goebel b,c, Elsa M.P. Henriques da r t i c l e i n f oa b s t r a c tArticle history:Received 6 October 2020Received in revised form 24 December 2021Accepted 20 January 2022Available online 15 February 2022Keywords:Local interpretabilityModel-agnostic interpretabilitySHAP valuesMonotonicityTrendabilityPrognosabilityMaintenance decisions in domains such as aeronautics are becoming increasingly depen-dent on being able to predict the failure of components and systems. When data-driven techniques are used for this prognostic task, they often face headwinds due to their per-ceived lack of interpretability. To address this issue, this paper examines how features used in a data-driven prognostic approach correlate with established metrics of monotonicity, trendability, and prognosability. In particular, we use the SHAP model (SHapley Additive exPlanations) from the field of eXplainable Artificial Intelligence (XAI) to analyze the out-come of three increasingly complex algorithms: Linear Regression, Multi-Layer Perceptron, and Echo State Network. Our goal is to test the hypothesis that the prognostics metrics correlate with the SHAP model’s explanations, i.e., the SHAP values. We use baseline data from a standard data set that contains several hundred run-to-failure trajectories for jet engines. The results indicate that SHAP values track very closely with these metrics with differences observed between the models that support the assertion that model complexity is a significant factor to consider when explainability is a consideration in prognostics.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionOver the last decades, developments in storage and acquisition technologies have permitted access to large volumes of data. The continual growth in computing power, followed by a corresponding decrease in costs, has also come to meet the requirements of more advanced decision-making systems. These systems have started to revolutionize the way we think about data and modeling, but have also brought additional challenges, especially at the interpretability level. Decision systems based on machine learning are well-known for their promising results [79] but also for their complexity and lack of transparency [142,76]. An accuracy-interpretability trade-off [42] is true for almost all machine learning methods. For example, deep learning networks, an advanced form of machine learning, typically combine the activities of several hundred or even thousands of neurons. Despite each neural unit’s relative simplicity, the network’s structure can be so intricate that it may not be fully understood, even by its designer. Mostly due to this reason, neural network systems tend to be seen as black-boxes, where the user is typically only aware of input-output relationships, but not the underlying reasoning.* Corresponding author.E-mail addresses: m.lbaptista@tudelft.nl (M.L. Baptista), kgoebel@parc.com (K. Goebel), elsa.h@ist.utl.pt (E.M.P. Henriques).https://doi.org/10.1016/j.artint.2022.1036670004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM.L. Baptista, K. Goebel and E.M.P. HenriquesArtificial Intelligence 306 (2022) 103667Machine learning algorithms have already revolutionized fields such as image recognition or natural language processing [103]. However, several obstacles hinder their adoption in other fields. In highly regulated environments, strict requirements on the audit and verifiability of decisions have limited their acceptance. For example, in aerospace, certification by regulatory bodies requires the applicant to demonstrate that the system meets minimal safety criteria. Accountability and trust are essential properties in many applications. As noted by Wilkinson et al. [135], from the Federal Aviation Administration (FAA) and National Aero Space Agency (NASA), “understanding the mechanisms used (...) is essential to understanding the impact on software assurance”. The General Data Protection Regulation (GDPR) approved by the European Parliament in 2016 has also imposed restrictions on automated decision-making by establishing the human right to obtain explanations about the logic involved in algorithmic decisions that influence their lives [47,132].Recognizing the importance of interpretability to accelerate machine learning progress, the Artificial Intelligence (AI) re-search community has started to pay increasing attention to the explainability topic. Researchers from different backgrounds and experiences have started to produce a significant body of research about explanations and intelligibility. A project of note is the eXplainable AI (XAI) initiative [52] led by the Defense Advanced Research Projects Agency (DARPA) of the United States. The XAI initiative aims at creating machines that can operate in their environments while also providing explanations for their behavior.Researchers from different fields have researched interpretability, and given the complexity of the subject, there is no agreement on a single definition or taxonomy. As noted by Lipton [84], the concept of interpretability is not a monolithic one, but it reflects several distinct ideas, such as trust or transparency. Given the lack of a “formal technical meaning” [84], it is important to establish a definition for interpretability. Here, we adopt the definition of Biran and Cotton [19], as the level that an observer can understand the cause of a decision. Following the work of Miller [92], and for simplicity, we equate interpretability with explainability.As described in the work of Arrieta et al. [8], there are many approaches to interpretability. One such approach is the SHAP model (SHapley Additive exPlanations) [85]. This kind of XAI model uses Shapley values from game theory to characterize the input variables’ relative importance. The approach is model-agnostic [107] as it only requires knowing the black-box model’s output for the neighbor instances of an input sample. When using SHAP, each observed value of a feature gets its SHAP value. The focus is on explaining what the model locally depends on, instead of learning the full mapping. In other words, the goal is to achieve local interpretability [43].The technique of local interpretability contrasts with global interpretability. Global interpretability consists of all the tech-niques that are able to explain the structure of a model using a macro perspective. This type of approach is most often used for simpler methods since as the complexity of the models increases it can become gradually more difficult to understand them [93]. Global interpretability methods typically examine the black-box model’s input-output relationships to infer an equivalent logical structure that can describe or simulate the black-box model’s behavior. In other words, the goal is to build a surrogate model that is more transparent [60]. Local interpretability concerns the provision of independent explanations for individual model responses. Models such as SHAP focus on calculating the importance of the different features for a specific prediction. The goal is to isolate a single instance and build a surrogate model in the neighborhood (locally) of that instance to explain how the model processes it. Because there is typically no explicit concern in maintaining the correlation between the diverse independent local models, this work aims to understand better how the SHAP local models relate to each other.In this work, we are interested in understanding how SHAP can benefit Remaining Useful Life (RUL) estimation in aero-nautics. To this end, we study three increasingly complex prognostics models: Linear Regression (LR), Multi-Layer Perceptron (MLP), and the more recent algorithm of Echo State Network (ESN) [64,37]. The ESN is a recurrent neural network where only the connections to the output are computed, and this is done with regression instead of gradient-based methods, which simplifies and accelerates the training process. These networks have the additional capability of learning multidimensional temporal patterns. As an ESN is fed with input signals, past signals can influence new ones due to the network’s feedback loops. This kind of memory enables an ESN to capture the temporal dimension of the data explicitly. There are other archi-tectures with memory, such as Long-Short Term Memory Network (LSTM) [59] or Gated Recurrent Unit (GRU) [29]. The ESN is, however, a simple and efficient alternative that has shown promising results in prognostics [101,95,110,114,109].This paper discusses the need for XAI in prognostics by providing a comprehensive literature review and investigating the SHAP model according to the classical metrics of PHM (monotonicity, trendability, and prognosability) proposed in [32]. It is advantageous that the trajectories of explanatory values produced by SHAP exhibit these properties. Monotonic SHAP values imply that the weight associated with a given feature is changing monotonically over the unit’s lifecycle. Monotonicity is desirable as it means that sensor features exhibit either increasing or decreasing importance over time. Having fluctuating SHAP values would most likely mean that the SHAP model is unstable a",
            {
                "entities": [
                    [
                        135,
                        231,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 260 (2018) 1–35Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLearning in the machine: Random backpropagation and the deep learning channelPierre Baldi a,∗, Peter Sadowski a, Zhiqin Lu ba Department of Computer Science, University of California, Irvine, United Statesb Department of Mathematics, University of California, Irvine, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 7 December 2016Received in revised form 21 December 2017Accepted 15 March 2018Available online 3 April 2018Keywords:Deep learningNeural networksBackpropagationLocal learningRandom backpropagation (RBP) is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and learning channels. Through this connection, we derive several alternatives to RBP, including skipped RBP (SRBP), adaptive RBP (ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR-10 benchmarkdatasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results for RBP and its variants including: (1) the convergence to optimal fixed points for linear chains of arbitrary length; (2) convergence to fixed points for linear autoencoders with decorrelated data; (3) long-term existence of solutions for linear systems with a single hidden layer, and their convergence in special cases; and (4) convergence to fixed points of non-linear chains, when the derivative of the activation functions is included.© 2018 Elsevier B.V. All rights reserved.1. IntroductionOver the years, the question of the biological plausibility of the backpropagation algorithm, which implements stochastic gradient descent in neural networks, has been raised several times. The question has gained further relevance due to the numerous successes achieved by backpropagation in a variety of problems ranging from computer vision [21,31,30,14] to speech recognition [12] in engineering, and from high energy physics [7,26] to biology [8,32,1] in the natural sciences, as well to recent results on the optimality of backpropagation [6]. There are however, several well known issues facing bio-logical neural networks in relation to backpropagation, these include: (1) the continuous real-valued nature of the gradient * Corresponding author.E-mail address: pfbaldi @uci .edu (P. Baldi).https://doi.org/10.1016/j.artint.2018.03.0030004-3702/© 2018 Elsevier B.V. All rights reserved.\f2P. Baldi et al. / Artificial Intelligence 260 (2018) 1–35information and its ability to change sign, violating Dale’s Law; (2) the need for some kind of teacher’s signal to provide tar-gets; (3) the need for implementing all the linear operations involved in backpropagation; (4) the need for multiplying the backpropagated signal by the derivatives of the forward activations each time a layer is traversed; (5) the need for precise alternation between forward and backward passes; and (6) the complicated geometry of biological neurons and the problem of transmitting error signals with precision down to individual synapses. However, perhaps the most formidable obstacle is that the standard backpropagation algorithm requires propagating error signals backwards using synaptic weights that are identical to the corresponding forward weights. Furthermore, a related problem that has not been sufficiently recognized, is that this weight symmetry must be maintained at all times during learning, and not just during early neural develop-ment. It is hard to imagine mechanisms by which biological neurons could both create and maintain such perfect symmetry. However, recent simulations [24] surprisingly indicate that such symmetry may not be required after all, and that in fact backpropagation works more or less as well when random weights are used to backpropagate the errors. Our general goal here is to investigate backpropagation with random weights and better understand why it works.The foundation for better understanding random backpropagation (RBP) is provided by the concepts of local learning and deep learning channels introduced in [6]. Thus we begin by introducing the notations and connecting RBP to these concepts. In turn, this leads to the derivation of several alternatives to RBP, which we study through simulations on well known benchmark datasets before proceeding with more formal analyses.2. Setting, notations, and the learning channelThroughout this paper, we consider layered feedforward neural networks and supervised learning tasks. We will denote such an architecture byA[N0, . . . , Nh, . . . , N L](1)where N0 is the size of the input layer, Nh is the size of hidden layer h, and N L is the size of the output layer. We assume i j denote the weight connecting neuron j in layer h − 1 to neuron i in layer h. that the layers are fully connected and let whThe output O hi of neuron i in layer h is computed by:=i (Shi j O h−1whi ) where(cid:2)ShijO hi= f h(2)jThe transfer functions f hi are usually the same for most neurons, with typical exceptions for the output layer, and usually are monotonic increasing functions. The most typical functions used in artificial neural networks are the: identity, logistic, hyperbolic tangent, rectified linear, and softmax.We assume that there is a training set of M examples consisting of input and output-target pairs (I(t), T (t)), with t = 1, . . . , M. Ii(t) refers to the i-th component of the t-th input training example, and similarly for the target T i(t). In addition, there is an error function E to be minimized by the learning process. In general we will assume standard error functions such as the squared error in the case of regression and identity transfer functions in the output layer, or relative entropy in the case of classification with logistic (single class) or softmax (multi-class) units in the output layer, although this is not an essential point.While we focus on supervised learning, it is worth noting that several “unsupervised” learning algorithms for neural net-works (e.g. autoencoders, neural autoregressive distribution estimators, generative adversarial networks) come with output targets and thus fall into the framework used here.2.1. Standard backpropagation (BP)Standard backpropagation implements gradient descent on E , and can be applied in a stochastic fashion on-line (or in mini batches) or in batch form, by summing or averaging over all training examples. For a single example, omitting the tindex for simplicity, the standard backpropagation learning rule is easily obtained by applying the chain rule and given by:(cid:2)whi j= −η∂E∂ whi j= ηBhi O h−1j(3)where η is the learning rate, O h−1easy to see that the backpropagated error satisfies the recurrence relation:is the presynaptic activity, and Bhijis the backpropagated error. Using the chain rule, it is Bhi= ∂E∂ Shi(cid:3)= ( f hi )(cid:2)kk wh+1Bh+1kiwith the boundary condition:B Li= ∂Ei∂ S Li= T i − O Li(4)(5)\fP. Baldi et al. / Artificial Intelligence 260 (2018) 1–353Thus in short the errors are propagated backwards in an essentially linear fashion using the transpose of the forward ma-trices, hence the symmetry of the weights, with a multiplication by the derivative of the corresponding forward activations every time a layer is traversed.2.2. Standard random backpropagation (RBP)Standard random backpropagation operates exactly like backpropagation except that the weights used in the backward pass are completely random and fixed. Thus the learning rule becomes:(cid:2)whi j= ηRhi O h−1jwhere the randomly backpropagated error satisfies the recurrence relation:(cid:2)Rhi(cid:3)= ( f hi )Rh+1kch+1kikand the weights ch+1kiare random and fixed. The boundary condition at the top remains the same:R Li= ∂Ei∂ S Li= T i − O LiThus in RBP the weights in the top layer of the architecture are updated by gradient descent, identically to the BP case.2.3. The critical equations(6)(7)(8)Within the supervised learning framework considered here, the goal is to find an optimal set of weights whi j . The equa-tions that the weights must satisfy at any critical point are simply:∂E∂ whi j(cid:2)=ti (t)O h−1Bhj(t) = 0(9)Thus in general the optimal weights must depend on both the input and the targets, as well as the other weights in the network. And learning can be viewed as a lossy storage procedure for transferring the information contained in the training set into the weights of the architecture.The critical Equation (9) shows that all the necessary forward information about the inputs and the lower weights leading up to layer h − 1 is subsumed by the term O h−1(t). Thus in this framework a separate channel for communicating information about the inputs to the deep weights is not necessary. Thus here we focus on the feedback information about the targets, contained in the term Bhi (t) which, in a physical neural system, must be transmitted through a dedicated channel.jNote that Bhi (t) depends on the output O L(t), the target T (t), as well as all the weights in the layers above h ",
            {
                "entities": [
                    [
                        133,
                        210,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1424–1440Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStonian p-ortholattices: A new approach to the mereotopology RT0Torsten Hahmann a, Michael Winter b,∗, Michael Gruninger c✩a Department of Computer Science, University of Toronto, Canadab Department of Computer Science, Brock University, St. Catharines, Canadac Department of Mechanical and Industrial Engineering, Department of Computer Science, University of Toronto, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 22 January 2009Received in revised form 7 July 2009Accepted 7 July 2009Available online 28 July 2009Keywords:Qualitative spatial reasoning (QSR)MereotopologyRegion-based spaceStonian p-ortholatticeNon-distributive pseudocomplementedlattice1. Introduction−, RT−This paper gives an algebraic representation of the subtheories RTEC , and RT of Asherand Vieu’s first-order ontology of mereotopology RT0. It corrects and extends previous workon the representation of these mereotopologies. We develop the theory of p-ortholattices– lattices that are both orthocomplemented and pseudocomplemented – and show thattogether with the Stone identity (x · y)∗ = xor equivalent definitions the naturalclass of Stonian p-ortholattices can be defined. The main contribution of the paper consistsas Stonian p-ortholattices. Moreover, it is shown thatof a representation theorem for RT−the class of models of RTEC is isomorphic to the non-distributive Stonian p-ortholatticesand a characterization of RT is given by a set of four algebras of which one need tobe a subalgebra of the present lattice model. As corollary we obtain that Axiom (A11)– existence of two externally connected regions – is in fact a theorem of the remainingaxioms of RT.∗ + y−∗© 2009 Elsevier B.V. All rights reserved.Within AI and in particular Knowledge Representation (KR), region-based theories of space have been a prominent areaof research in the recent years. Traditionally, space has been considered in mathematics as point-based theories such asgeometric (e.g. Euclidean geometry) or topological representations (point-set topology) of space. Points are somewhat trickyto define and are far from intuitive in real-world applications. Instead, point-free theories of space such as region-basedtheories can be used to represent space in the context of (qualitative) spatial reasoning. Using regions instead of pointsas smallest units accounts more naturally for how humans conceptualize our physical world. Such commonsense spatialreasoning reflects rigid bodies or spatial regions more naturally than conventional, point-based models [19,27]. Since theearliest work of de Laguna [12] and Whitehead [30], mereotopology has been considered for building point-free theoriesof space. In AI, these theories are of importance for qualitative spatial reasoning (QSR): they focus on simple propertiesthat abstract from quantitative measurements while still being powerful enough to reason about spatial configurations andextract useful spatial knowledge, e.g. about bordering regions, intersecting regions, or the composition of regions. For anoverview of mereotopology within QSR we refer to [10].Broadly speaking, mereotopology is a composition of topological (from Greek topos, “place”) notions of connectednesswith mereological (from Greek méros, “part”) notions of parthood. Neither topology nor mereology are by themselves pow-erful enough to express part-whole relations.✩The authors gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada.* Corresponding author.E-mail addresses: torsten@cs.toronto.edu (T. Hahmann), mwinter@brocku.ca (M. Winter), gruninger@mie.utoronto.ca (M. Gruninger).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.07.001\fT. Hahmann et al. / Artificial Intelligence 173 (2009) 1424–14401425Topology can also be seen as a theory of wholeness, but has no means of expressing parthood relations. Connection doesnot imply a parthood relation between two individuals, as well as disconnection does not prevent parthood. Just considerthe example of countries – there exist many countries, e.g. the United States, that are not self-connected. Alaska should beconsidered part of the United States but is by no intuitive means connected to the other states. The same applies for Hawaii,although the kind of separation is different here: Alaska is separated by Canada from the continental US, whereas Hawaiiis solely separated by the Pacific ocean. If we consider landmass only, then Alaska and the continental US are part of aself-connected individual, namely continental North America, whereas Hawaii is separated from this landmass. On the otherhand, mereology is not powerful enough to reason about connectedness. As the previous example shows, two individualsbeing part of a common individual does not imply that this sum is self-connected. Hence, parthood is not sufficient tomodel connectedness.Consequently, to be able to reason about self-connected individuals, ways to combine mereology with topology arenecessary. Previously, Casati and Varzi [6] classified mereotopologies by how the two independent theories are merged.Other systematic treatments of mereotopology can be found in [11,16].One of the ways of building mereotopology studied in [30] takes topology as basis and defines mereology on top ofit reusing the topological primitive, thereby assuming a greater generality of topology than mereology. Clarke choose thisapproach for his seminal work in [7,8], and many later works in AI used Clarke’s work as starting point, e.g. the system RT0of Asher and Vieu [1], the Region Connection Calculus (RCC) [2,9,19,25], Gotts theory [18], and Pratt and Schoop’s polygonalmereotopology [24]. Due to the same origin all of these theories use a single primitive of connectedness (or contact)and express parthood in terms of connection, thus limiting the mereotopology to the expressiveness of the connectionprimitive.Most mereotopologies are described in terms of first-order axioms. However, many of them lack soundness and com-pleteness proofs. But even soundness and completeness proofs are insufficient, instead we aim for representation theoremsup to isomorphism (“full duality” in the tradition of Stone’s representation theorem of Boolean algebras [28], see also e.g.[13,14,26,29]) that describe the models in a uniform, mathematically well-understood formalism. Among others, for theRCC [9,25] and the framework of Pratt and Schoop [24], which is limited to planar polygonal mereotopology, there existformal proofs that actually give insight into the possible models. But to better understand the relation between differentmereotopologies, we need to identify the models of each mereotopology and compare them to each other. Algebraic conceptsand relation algebras in particular provide a mathematical sound foundation for comparing various mereotopological theo-ries. Most previous work in this direction focused on the RCC, generalizations and algebraic and topological representationsthereof. Clarke’s theory has also been characterized in terms of algebras, see [3]. Another approach relates mereotopologieswith certain lattice structures. In particular, Stell shows in [27] that models of the RCC are isomorphic to so-called Booleanconnection algebras (or Boolean contact algebras), i.e. Boolean algebras together with a binary contact relation C satisfyingcertain axioms. Since lattices and Boolean algebras in particular are well-known mathematical structures, this approach ledto an intensive study of the properties of the RCC including several topological representation theorems [13–15,26,29]. Inthis paper we want to apply a similar method to the mereotopology RT0 of Asher and Vieu [1]. We will show that the sub-−EC andtheory RTRT in terms of algebraic properties. This relationship between models of RT0 and certain lattices is the main contribution ofthis paper. It can be seen as the start of a lattice-theoretic treatment of RT0 in a similar way as [27]. The next step in thisendeavor can be found in [31]. Another interesting result is Corollary 7.3 showing that the original axiom system in [1] isnot independent.can be expressed by a certain class of lattices. Subsequently, we investigate the additional axioms of RT−Compared to the RCC, the system of Asher and Vieu [1] focuses on a larger set of regions. The standard models of RCCare made of regular closed sets only whereas the standard models of RT0 contain regions with regular closed closures andregular open interiors. Therefore, the system RT0 can be seen as a more general approach in the following sense. The closedelements in Asher and Vieu’s theory correspond to the elements in RCC. It is, therefore, not very surprising that RT0 doesnot provide the same algebraic structure as RCC models, i.e. Boolean algebras. Even though we will consider distributivity inSection 6 this is a very particular case. By requiring this property one basically forces the more general elements of Asherand Vieu, i.e. open, closed and other sets, into the framework of regular closed regions. It turns out that in this – and justin this – case the contact relation collapses to overlap similar to Clarke’s original system. A more detailed study of therelationship between RCC models and the current framework via the skeleton can be found in [31].2. The mereotopology RT 0The mereotopology RT0 proposed by Asher and Vieu [1] evolved from Clarke’s theory, addressing some of its shortcom-ings. RT0 follows the strategy “Topology as Basis for Mereology” for defining mereotopology and hence does not contain anexplicit mereology. Consequently, the parthood relation P is sufficiently defined by the extension of the primitive relation C ,which limits the expressiveness of the whole theory to that of C . As a indirect consequence of our work, it will turn outthat we could",
            {
                "entities": [
                    [
                        138,
                        202,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 314 (2023) 103804Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintWhen move acceptance selection hyper-heuristics outperform Metropolis and elitist evolutionary algorithms and when not ✩Andrei Lissovoi a, Pietro S. Oliveto a, John Alasdair Warwicker ba Department of Computer Science, University of Sheffield, UKb Institute of Operations Research, Karlsruhe Institute of Technology, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 30 April 2021Received in revised form 6 September 2022Accepted 3 October 2022Available online 4 October 2022Keywords:Hyper-heuristicsRuntime analysisNon-elitismMetropolisMove acceptance operatorsTheorySelection hyper-heuristics (HHs) are automated algorithm selection methodologies that choose between different heuristics during the optimisation process. Recently, selection HHs choosing between a collection of elitist randomised local search heuristics with different neighbourhood sizes have been shown to optimise standard unimodal benchmark functions from evolutionary computation in the optimal expected runtime achievable with the available low-level heuristics. In this paper, we extend our understanding of the performance of HHs to the domain of multimodal optimisation by considering a Move Acceptance HH (MAHH) from the literature that can switch between elitist and non-elitist heuristics during the run. In essence, MAHH is a non-elitist search heuristic that differs from other search heuristics in the source of non-elitism.We first identify the range of parameters that allow MAHH to hillclimb efficiently and prove that it can optimise the standard hillclimbing benchmark function OneMax in the best expected asymptotic time achievable by unbiased mutation-based randomised search heuristics. Afterwards, we use standard multimodal benchmark functions to highlight function characteristics where MAHH outperforms elitist evolutionary algorithms and the well-known Metropolis non-elitist algorithm by quickly escaping local optima, and ones where it does not. Since MAHH is essentially a non-elitist random local search heuristic, the paper is of independent interest to researchers in the fields of artificial intelligence and randomised search heuristics.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionSelection hyper-heuristics (HHs) are automated algorithm selection methodologies designed to choose which of a set of low-level heuristics to apply in the next steps of the optimisation process [15]. Rather than deciding in advance which heuristic and related parameter settings to apply for a problem, either by manual trial and error in preliminary experiments or using automated algorithm configurators [32,64], the aim behind HHs is to automate the process at runtime. Originally shown to effectively optimise scheduling problems, such as the scheduling of a sales summit and university timetabling [15,16], they have since been successfully applied to a variety of hard combinatorial optimisation problems (see e.g., [7,6,27,40,58,64] for surveys of results).✩An extended abstract of this manuscript has appeared at the 2019 Association for the Advancement of Artificial Intelligence Conference (AAAI 2019) [46].E-mail address: p.oliveto@sheffield.ac.uk (P.S. Oliveto).https://doi.org/10.1016/j.artint.2022.1038040004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fA. Lissovoi, P.S. Oliveto and J.A. WarwickerArtificial Intelligence 314 (2023) 103804Selection HHs consist of two separate components: (1) a heuristic selection method, often referred to as the learning mechanism, to decide which heuristic to be applied in the next step of the optimisation process, and (2) a move acceptance operator to decide whether the newly produced search points should be accepted.The majority of heuristic selection methods in the literature apply machine learning techniques that generate scores for each heuristic based on their past performance. A commonly used method for the purpose is reinforcement learning [15,50,5]. Despite their numerous successful applications, very limited rigorous theoretical understanding of their behaviour and performance is available [43,1].Recently, it has been proved that a reinforcement learning HH and a simple selection HH called Random Descent [15,16], both choosing between elitist randomised local search (RLS) heuristics with different neighbourhood sizes, can respectively optimise the standard unimodal benchmark functions OneMax and LeadingOnes in the best possible runtimes achievable (up to lower order terms), with the available low-level heuristics [22,48]. Since the Random Descent HH does not store information on the past performance of the low-level heuristics, it is necessary to run the selected low-level heuristics for a sufficient amount of time, called the learning period, to allow the HH to accurately determine how useful the chosen heuristic is at the current stage of the optimisation process. However, the optimal duration of the learning period may change during the optimisation process. Doerr et al. recently introduced a self-adjusting mechanism and rigorously proved that it allows the HH to track the optimal learning period throughout the optimisation process for LeadingOnes [25]. The optimal asymptotic performance of the same self-adjusting Random Descent HH has recently been shown also for the OneMax and Ridgeunimodal benchmark functions [47]. For a survey of the available theoretical results regarding the performance of HHs, see [51].In this paper we aim to extend the understanding of the behaviour and performance of HHs to multimodal optimisation problems. In order to evaluate their capability at escaping local optima, we consider elitist and non-elitist selection operators (called move acceptance operators) that have been used in the HH literature. Move acceptance operators (also referred to as selection operators in the classic evolutionary computation literature) are classified as either deterministic, where the same decision is made independent of the stage of the optimisation process, or non-deterministic, where different decisions for the same solutions might be made at different stages [56].Cowling et al. introduced two variants of deterministic move acceptance operators: the elitist OnlyImproving (OI) op-erator, which only accepts moves that improve the current solution, and the non-elitist AllMoves (AM) operator, which accepts any new solution independent of its quality [15,16]. Another move acceptance operator that has been considered in the literature is the ImprovingandEqual (IE) operator which, in addition to accepting improving solutions, also accepts solutions of equal quality [2,4,55]. In the mentioned works, the acceptance operator remains fixed throughout the run, with the HH only switching between different mutation operators. However, it would be more desirable that HHs are allowed to decide to change the move acceptance operator and hence, the selection pressure at different stages of the optimisation process. For instance, they may use elitist move acceptance in exploitation phases of the search, such as hillclimbing, and non-elitism for exploration, for instance to escape from local optima.Indeed, Qian et al. analysed a HH that switches between move acceptance operators in the context of multi-objective optimisation [60]. They considered a HH that selects between the elitist (IE) and the strict elitist (OI) move acceptance operators and presented a function where it is necessary to mix the two acceptance operators. Lehre and Özcan presented the only available analysis of a HH which chooses between elitist and non-elitist low level heuristics [43]. In particular, the HH uses the above described OI (strict elitist) and AM (non-elitist) acceptance operators. The considered Move Acceptance HH (MAHH) uses 1-bit flips (i.e., local mutations) as the mutation operator and selects the AM acceptance operator with probability p and the OI acceptance operator with probability 1 − p. Essentially, the algorithm is a randomised local search (RLS) algorithm that switches between strict elitism, by only accepting improvements, and extreme non-elitism, by accepting any new found solution. For the standard RoyalRoadk benchmark function from evolutionary computation, which consists of several blocks of k ≥ 2 bits each that have to be set correctly to observe a fitness improvement, they proved that it is necessary to mix the acceptance operators for MAHH to be efficient, because by only accepting improvements (i.e., p = 0) the runtime is infinite due to MAHH not being able to cross the plateaus of equal fitness while by always accepting any move (i.e., p = 1), the algorithm simply performs a random search. By choosing the value of the parameter p appropriately they provide an upper bound on the expected runtime of the HH of O (n3 · k2k−3) versus the O (n log(n) · (2k/k)) expected time required by evolutionary algorithms with standard bit mutation (i.e., each bit is flipped with probability 1/n) and with the standard selection operator that accepts new solutions if their fitness is at least as good as that of their parent [26]. In particular, just using the IE acceptance operator throughout the run leads to a better performance. Hence, the advantages of switching between selection operators rather than just using one all the time were not evident.In this paper we present a systematic analysis of the same HH considered by Lehre and Özcan [43] for multimodal optimisation problems,1 where the considerable advantages of changing the move acceptance operator during the run may be highlighted. In particular, we will increase our understanding of the behaviour ",
            {
                "entities": [
                    [
                        153,
                        271,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 137 (2002) 217–238www.elsevier.com/locate/artintA hybrid graphical model for rhythmic parsing ✩Christopher RaphaelDepartment of Mathematics and Statistics, University of Massachusetts, Amherst, MA, USAReceived 4 October 2001AbstractA method is presented for the rhythmic parsing problem: Given a sequence of observed musicalnote onset times, we simultaneously estimate the corresponding notated rhythm and tempo process.A graphical model is developed that represents the evolution of tempo and rhythm and relates thesehidden quantities to an observable performance. The rhythm variables are discrete and the tempo andobservation variables are continuous. We show how to compute the globally most likely configurationof the tempo and rhythm variables given an observation of note onset times. Experiments arepresented on both MIDI data and a data set derived from an audio signal. A generalization tocomputing MAP estimates for arbitrary conditional Gaussian distributions is outlined.  2002Elsevier Science B.V. All rights reserved.Keywords: Conditional Gaussian distribution; Rhythmic parsing; MAP estimate; Dynamic programming; Musicrecognition; Hybrid graphical model1. IntroductionRhythm is the aspect of music that deals with when events occur. Typically, rhythm inWestern music is notated in a way that expresses the position of each note as a rationalnumber, usually in terms of some relatively small common denominator. For instance, ifwe use the measure as our unit of notated position, then the sequence of measure positionsm0 = 0, m1 = 1/4, m2 = 1, . . . expresses the notion that the first note occurs at thebeginning of the 1st measure, the second note occurs 1/4 the way through the 1st measure,the third note occurs at the beginning of the 2nd measure, etc. If the music is performedwith mechanical precision then a single number, the tempo, will map the measure positions✩ This is an extended version of the paper presented at the 17th Conference on Uncertainty in ArtificialIntelligence (UAI-2001), Seattle, WA, USA. This work is supported by NSF grants IIS-0113496 and IIS-9987898.E-mail address: raphael@math.umass.edu (C. Raphael).0004-3702/02/$ – see front matter  2002 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 2 ) 0 0 1 9 2 - 3\f218C. Raphael / Artificial Intelligence 137 (2002) 217–238to actual times. For instance, if the tempo is 3 seconds per measure, then the notes wouldoccur at 0 secs, 3/4 secs, 3 secs, etc. However, such a performance would be nearlyimpossible for the human performer to create, and, moreover, would be undesirable. Muchof the expressive quality of a musical performance comes from the way in which the actualnote times deviate from what is prescribed by a literal interpretation of the printed music.In particular, there are two primary components to this expressive timing [8]. Firstly, theactual tempo is often not constant, but rather continually varied throughout the evolutionof the performance. Secondly, there are more local (note by note) distortions which can beaccidental, or can result from interpretive considerations.We focus here on a problem encountered in music information retrieval (MIR): Given asequence of measured note onset times, we wish to identify the corresponding sequence ofmeasure positions. We call this process rhythmic parsing. The time sequences formingthe input to our procedure could be estimated from an audio signal or could comedirectly from a MIDI (musical instrument digital interface) file—a sequence of time-taggedmusical events such as note beginnings and endings. For example, consider the data inthe left panel of Fig. 1 containing estimated note times from an excerpt of Schumann’s2nd Romance for Oboe and Piano (oboe part only). The actual audio file can be heardat http://fafner.math.umass.edu/rhythmic_parsing. Our goal is to assign the proper scoreposition, in measures, to each the observed times. When this is done correctly, as in Fig. 1,the observed times, in seconds, plotted against the score positions, in measures, trace out acurve whose local slope gives the player’s local tempo.Applications of rhythmic parsing are numerous. Virtually every commercial score-writing program now offers the option of creating scores by directly entering MIDIdata from a keyboard. Such programs must infer the rhythmic content from the actualtimes at which musical events occur and, hence, must address the rhythmic parsingproblem. When the input data is played with anything less than mechanical precision,the transcription degrades rapidly, due to the difficulty in computing the correct rhythmicparse. Rhythmic parsing also has applications in musicology where it could be usedto separate the inherently intertwined quantities of notated rhythm and expressivetiming. Either the rhythmic data or the timing information could be the focal pointof further study. Additionally, several applications of rhythmic parsing are related toefforts in music information retrieval, as follows. The musical world eagerly awaits thecompilation of music databases containing virtually every kind of (public domain) music,thereby facilitating the searching, studying, comparing, and understanding of music. Theconstruction of such data bases will likely involve several transcription efforts includingoptical music recognition, musical audio signal recognition, and MIDI transcription.Rhythmic parsing is an essential ingredient to the latter two efforts. Finally, the last decadehas seen a virtual explosion in music data available on the World Wide Web. Unfortunately,content-based searches analogous to those performed on text are not possible at the presenttime. However, if automated music transcription were to progress to a sufficient level,searchable descriptions of musical content could be constructed automatically. Such adevelopment would dramatically increase access to music on the web. Rhythmic parsingwill play a significant role in this endeavor too.As already mentioned, mostly commercial score-writing address the rhythmic parsingproblem. Usually these efforts attempt to quantize the observed note lengths, or more\fC. Raphael / Artificial Intelligence 137 (2002) 217–238219Fig. 1. Left: Real time (seconds) vs. Musical time (measures) for the Schumann data. Right: The actual durations(seconds) of notes grouped by the musical duration (measures).precisely inter-onset intervals (IOIs), to their closest note values (eighth note, quarternote, etc.), given a known tempo, or to quantize the observed note onset times to theclosest points in a rigid grid [24]. While such quantization schemes can work reasonablywell when the music is played with robotic precision (often a metronome is used), theyperform poorly when faced with the more expressive and less accurate playing typicallyencountered. Consider the right panel of Fig. 1 in which we have plotted the written notelengths in measures versus the actual note lengths (IOIs) in seconds from our musicalexcerpt. The large degree of overlap between the empirical distributions of each note lengthclass demonstrates the futility of assigning note lengths through note-by-note quantizationin this example. In this particular example, the overlap in empirical distributions is mostlyattributable to tempo fluctuations in the performance.In addition to the commercial systems, we are also aware of several research effortsrelated to rhythm transcription. Some of this research addresses the problem of beatinduction, or tempo tracking in which one tries to accomplish the equivalent of “foot-tapping”—estimating a sequence of times corresponding to evenly spaced rhythmicintervals (e.g., beats) for a given sequence of observed note onset times [1,3,6,9,11–14].A complementary research effort addresses the problem of assigning rhythmic values assimple integer ratios to observed note lengths without any corresponding estimation oftempo [4,8,10]. The latter two assume that beat induction has already been performed,where as the former assumes that tempo variations are not significant enough to obscurethe ratios of neighboring note lengths.In many kinds of music we believe it will be exceedingly difficult to independentlyestimate tempo and rhythm, as in the previously cited research, since the observed datais formed from a complex interplay between the two. That is, independent estimationof tempo or rhythm leads to a “chicken and egg” problem: One cannot easily estimaterhythm without knowing tempo and vice-versa. In this work we address the problem ofsimultaneous estimation of tempo and rhythm. From a problem domain point of view, thisis the most significant contrast between our work and other efforts cited.The research effort closest to ours in spirit is the recent work of Cemgil [2] whichprobabilistically models tempo and rhythm jointly and seeks globally optimal datainterpretations by computing the posterior distribution through particle filtering techniques.\f220C. Raphael / Artificial Intelligence 137 (2002) 217–238There are two significant distinctions between this work and ours. Cemgil deals withthe “chicken and egg” problem by approximating the marginal distribution on rhythm byintegrating out the tempo variables; we instead estimate tempo and rhythm jointly. Perhapsa more important distinction is that we provide a dynamic programming technique thatidentifies the globally optimal data interpretation; Cemgil’s method is approximate.The paper is organized as follows. Section 2 develops a generative graphical modelfor the simultaneous evolution of tempo and rhythm processes that incorporates both priorknowledge concerning the nature of the rhythm process and a simple and reasonable modelfor tempo evolution. This section then describes a computational scheme for identifyingthe most likely configuration, a MAP estimate, of the unobserved processes given observedmusical data. Section 3 demonstrates the application of our scheme to a several musicalexamples. S",
            {
                "entities": [
                    [
                        72,
                        117,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 442–448Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA note on minimal d-separation trees for structural learningBinghui Liu a, Jianhua Guo a,∗, Bing-Yi Jing ba Key Laboratory for Applied Statistics of MOE and School of Mathematics and Statistics, Northeast Normal University, Changchun 130024, Jilin Province, Chinab Department of Mathematics, Hong Kong University of Science and Technology, Hong Konga r t i c l ei n f oa b s t r a c tStructural learning of a Bayesian network is often decomposed into problems related to itssubgraphs, although many approaches without decomposition were proposed. In 2006, Xie,Geng and Zhao proposed using a d-separation tree to improve the power of conditionalindependence tests and the efficiency of structural learning. In our research note, we studya minimal d-separation tree under a partial ordering, by which the maximal efficiency canbe obtained. Our results demonstrate that a minimal d-separation tree of a directed acyclicgraph (DAG) can be constructed by searching for the clique tree of a minimal triangulationof the moral graph for the DAG.© 2010 Elsevier B.V. All rights reserved.Article history:Received 2 April 2009Received in revised form 19 January 2010Accepted 23 January 2010Available online 2 February 2010Keywords:Bayesian networkClique treeMinimal d-separation treeMinimal triangulationSeparation treeStructural learning1. IntroductionBayesian networks (BNs), also known as directed acyclic graphical models, are useful probabilistic graphical modelsthat can be represented by DAGs. For a Bayesian network, two components are involved. First, the DAG is the qualitativecomponent which represents dependence and independence relationships: the absence of some directed edges representsthe existence of certain conditional independence relationships between variables, and the presence of edges may representthe existence of direct dependence relationships or causal relationships [10,17]. Second, the joint probability distribution isthe quantitative component that expresses the strength of association between variables. We have special interest in thestructure recovery of DAGs. Several methods for structural learning of DAGs were considered and there are mainly two basicapproaches of structural learning [23]: constraint-based approach and search-and-score approach. We will introduce somemore constraint-based algorithms. As mentioned in [23], in a constraint-based algorithm, search for d-separators of pairs ofvariables is a major problem for orientation of edges and for structure recovery of a DAG. Here a d-separator is a subsetof variables by which the variable pairs are d-separated. Verma and Pearl [21] presented the IC algorithm and searched fora d-separator S from all possible variable subsets such that two variables u and v are conditionally independent on S. Asthe search for d-separators is often time-consuming, many algorithms were proposed to speed up the search. For example,the PC algorithm, an iterative algorithm, searched only for the d-separators contained in the variables that are adjacentto u and v in each step [19], where two variables are said to be adjacent if there is an edge between the two variables.Decomposition approaches [7,22] are also useful approaches to speed up the search. Using these approaches, the originallearning question can be decomposed into some sub-questions with smaller dimensions.For many constraint-based algorithms, there are two steps to recover DAG structures [23]. First, learn the moral graphof the target DAG applying Markov blanket learning algorithms, where the Markov blanket for a variable u is defined to* Corresponding author.E-mail addresses: liubh024@yahoo.com.cn (B. Liu), jhguo@nenu.edu.cn (J. Guo), majing@ust.hk (B.-Y. Jing).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.01.002\fB. Liu et al. / Artificial Intelligence 174 (2010) 442–448443be the set of variables composed of u’s parents, its children, and its children’s other parents [16]. Second, perform furtherindependence tests for edge orientation based on the moral graph learned in the first step. To speed up the second step,Xie, Geng and Zhao [22] proposed algorithms adopting a decomposition approach, which were supported by a useful andimportant definition of d-separation tree. They introduced this definition to depict separations and conditional independen-cies between sets of random variables, and we will describe the definition again in detail in the following section. Given ad-separation tree T , the problem of searching for d-separators in a large network can be localized to smaller subnetworks,that is, d-separators are only searched for in each node of the tree separately (see Theorem 2 in [22]). Then the number ofthe further independence tests mentioned in the second step can certainly be reduced.Different d-separation trees often carry corresponding efficiencies. The efficiency can be defined from several differentangles for different purposes. For example, if the aim is to search for the tree where the largest node has the minimumsize, the efficiency may be defined inversely proportional to the number of vertices in the largest node of the tree. Ouraim is slightly different from that one and here the efficiency is defined inversely proportional to the maximum numberof possible tests, which will be described in detail in the following section. To describe an appropriate d-separation treewith high efficiency, we first introduce the definition of minimal d-separation trees for a DAG. Our paper focuses on thecharacterization and construction of a minimal d-separation tree. Xie, Geng and Zhao (2006) already proposed a sufficientcondition for d-separation trees. Based on their work, we show that any minimal d-separation tree of a DAG is equivalentto a minimal separation tree of the moral graph for the DAG, which is in turn equivalent to a clique tree of a minimaltriangulation of the moral graph. According to these equivalences, some useful algorithms of searching for minimal trian-gulations and clique trees are available for us to construct a minimal d-separation tree, which leads to a minimal numberof the further independence tests mentioned above required for orientation of edges. The definitions, such as moral graph,clique tree and triangulation [10,12,13], will be introduced in the next section in detail.In Section 2, we introduce the notation and definitions. As our paper is mainly inspired by Xie, Geng and Zhao, wemainly follow the terminology of [22]. Section 3 discusses the characterization and construction of a minimal d-separationtree of a DAG. In Section 4, we make a conclusion for our paper.2. Notation and definitionsWe follow the terminology from [13,22], unless noted otherwise.2.1. Undirected graphs and separation treesWe consider simple and connected graphs. Let G = (V , E) denote an undirected graph, where V is the vertex set andE is the set of undirected edges. An undirected edge between two vertices u and v is denoted by (u, v). A ⊆ V induces asubgraph G A = ( A, E A), where E A = E ∩ ( A × A). A subset of V is called complete if every pair of vertices in the subset isconnected by an edge. A complete subset that is maximal w.r.t. inclusion is called a clique. A path p between two verticesu and v is a sequence of vertices w 0 = u, w 1, . . . , wn = v with (w i−1, w i) ∈ E, for 1 (cid:2) i (cid:2) n (n (cid:3) 1) and w i (cid:6)= w j for1 (cid:2) i, j (cid:2) n. A cycle is a path with w 0 = wn. A chord of the cycle is a pair of vertices w i , w j such that (w i, w j) ∈ E butj (cid:6)= i − 1, i + 1. Two subsets A, B ⊆ V with A ∩ B = ∅ are said to be separated by C ⊆ V in G if all paths from A to Bpass through C , i.e., for each vertex u ∈ A and each vertex v ∈ B, all paths from u to v intersect C at some vertices. Thepartition ( A, B, S) of V is said to be a decomposition of the undirected graph G, if (1) S separates A and B in G, and (2) Sis complete in G. Then G can be decomposed into subgraphs G A∪S and G B∪S .Hh=1 Ch = V . T denotes a tree whose node set is C and edge set is E T . Inspired by thedefinition of d-separation tree, Definition 1 in [22], here we propose a similar definition of separation tree for undirectedgraphs.Let C = {C1, . . . , C H }, such that(cid:2)Definition 1. A tree T = (C, E T ) is said to be a separation tree of an undirected graph G = (V , E) if for each edge (Ci, C j) ∈C , k = 1, 2; C 1 and C 2 are node sets ofE T , V 1\\(Ci ∩ C j) and V 2\\(Ci ∩ C j) are separated by Ci ∩ C j in G, where V k =T 1 and T 2, which are obtained by removing edge (Ci, C j) from tree T .C∈Ck(cid:2)If for each edge (Ci, C j) ∈ E T , Ci ∩ C j is complete in G, we say that T is a decomposition tree of G.A tree T = (C, E T ) is reduced if each vertex set in C is not contained in another one, that is, red{C} = C, where ‘red’stands for the operation of deleting the smaller of any two sets C1, C2 with C1 ⊆ C2.2.2. Triangulated graphs and clique treesA triangulated graph, also known as a chordal graph, is an undirected graph that contains no cycles of length (cid:3) 4 withouta chord. For any undirected graph G = (V , E) edges can be added so that the resulting graph Gt = (V , E ∪ F ), called a(cid:9)) is nottriangulation of the given graph G, is triangulated. A triangulation Gt of G is said to be minimal if Gtriangulated for every proper subset F(cid:9) = (V , E ∪ Fof F .(cid:9)\f444B. Liu et al. / Artificial Intelligence 174 (2010) 442–448Fig. 1. An undirected graph G = (V , E) (left) and a minimal triangulation Gt (right) of G.Fig. 2. A DAG G.Example 1. We see that Gt in Fig. 1 is a triangulation of the undirected graph G, because it contains no cycles of length (cid:3) 4without a chord. And Gt is a minimal triangulation, as G 1 = (V , E ∪ {(1, 4)}) and G 2 = (V , E ∪ {(4, 5)}) are not triangulated.We continue to show a graph G 3 t",
            {
                "entities": [
                    [
                        136,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 201 (2013) 1–31Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief functions on distributive lattices ✩Chunlai ZhouDepartment of Computer Science and Technology, School of Information, Renmin University, Beijing, 100872, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 18 August 2012Received in revised form 7 May 2013Accepted 10 May 2013Available online 15 May 2013Keywords:Dempster–Shafer theoryMöbius transformsDistributive latticesde Morgan latticesFirst degree entailments1. IntroductionThe Dempster–Shafer theory of belief functions is an important approach to deal withuncertainty in AI.In the theory, belief functions are defined on Boolean algebras ofevents. In many applications of belief functions in real world problems, however, theobjects that we manipulate is no more a Boolean algebra but a distributive lattice. Inthis paper, we employ Birkhoff’s representation theorem for finite distributive lattices toextend the Dempster–Shafer theory to the setting of distributive lattices, which has amathematical theory as attractive as in that of Boolean algebras. Moreover, we use thismore general theory to provide a framework for reasoning about belief functions in adeductive approach on non-classical formalisms which assume a setting of distributivelattices. As an illustration of this approach, we investigate the theory of belief functionsfor a simple epistemic logic the first-degree-entailment fragment of relevance logic R byproviding an axiomatization for reasoning about belief functions for this logic and byshowing that the complexity of the satisfiability problem of a belief formula with respectto the class of the corresponding Dempster–Shafer structures is NP-complete.© 2013 Elsevier B.V. All rights reserved.Dealing with uncertainty is a fundamental issue for Artificial Intelligence [31]. Numerous approaches have been pro-posed, including Dempster–Shafer theory of belief functions (also called Dempster–Shafer theory of evidence). Ever sincethe pioneering works by Dempster [10] and Shafer [52], belief functions were brought into a practically usable form bySmets [59] and have become a standard tool in Artificial Intelligence for knowledge representation and decision-making.Dempster–Shafer belief functions on a finite frame of discernment S are defined on the power set of S, which is aBoolean algebra. They have an attractive mathematical theory and many intuitively appealing properties. Belief functionssatisfy the three axioms which generalize the Kolmogorov axioms for probability functions. Interestingly enough, they canalso be characterized in terms of mass functions m. Intuitively, for a subset event A, m( A) measures the belief that an agentcommits exactly to A, not the total belief that an agent commits to A. Shafer [52] showed that an agent’s belief in A is thesum of the masses he has assigned to all the subsets of A. This characterization of belief functions through mass functionsis simply an example of the well-known Inclusion–Exclusion principle in Enumerative Combinatorics [61] and hence has astrong combinatorial flavor. In this theory, mass functions are recognized as Möbius transforms of belief functions.Dempster–Shafer theory of belief functions is closely related to other approaches dealing with uncertainty. It includesthe Bayesian theory [51] as a special case. The first three rules of the Bayesian theory are simply those three axioms forprobability functions. It is shown [52] that a belief function on S is Bayesian (also a probability function) if and only if✩This is an expanded and improved version of a preliminary paper with the same title that appears in Proceedings of the Twenty-Sixth AAAI Conferenceon Artificial Intelligence (AAAI-12), 1968–1975, Toronto, 2012. All the technical proofs here are not published in the AAAI paper. In some sense, the prooftechniques developed in this paper are as important as the main results. In addition, Sections 3 and 4in the conference paper are totally revised andreplaced by more comprehensive sections, and some main results there get strengthened in this paper.E-mail addresses: czhou@ruc.edu.cn, chunlai.zhou@gmail.com.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.05.003\f2C. Zhou / Artificial Intelligence 201 (2013) 1–31its corresponding mass function assigns positive weights only to singletons. So a Bayesian belief function μ is more like apoint function than a set function in its level of complexity in the sense that μ is determined by its values at singletonsrather by its values at all events (its values at other non-singletons are 0). This implies that generally Bayesian belieffunctions are simpler and easier to describe than belief functions. As Shafer pointed out in Chapter 9 of his book [52],this simplicity makes the Bayesian belief functions awkward for the representation of evidence. In practice, the Bayesianapproach is criticized for having difficulty in efficiently providing reasonable estimate of the probability of some eventsand for describing confidence by a single point rather than a range [18]. The main advantage of the Dempster–Shafertheory over the Bayesian theory is that it allows for a proper representation of ignorance under incomplete information andassigns a meaningful interval to an event as a representation of the uncertainty of the event. In this aspect, the theory ofbelief functions is equivalent to the approach adopted by Fagin and Halpern [18] dealing with uncertainty using inner andouter probability measures. In contrast with the Dempster–Shafer theory, probability theory does not assign a probabilityto every event [30] and probability measures are defined on a σ -algebra, which is a subclass of the power set of the spaceunder consideration. Non-measurable events, those without probabilities, are usually considered as meaningless in probabilitytheory. However, in modeling uncertainty in artificial intelligence, they are used to represent those events to which an agenthas insufficient information to assign probabilities. A non-measurable event E is provided with inner probability measure(outer probability measure) which is the probability of the largest measurable event contained in E (the smallest measurableone containing E). The inner (outer) measure gives a lower bound (upper bound) on the agent’s degree of beliefs in E. Soinner probability measure (together with outer probability measure) induced by probability measure assigns an intervalto every event as a representation of uncertainty of the event E, which is similar to belief/plausibility functions. Moreover,belief functions and inner probability measures are equivalent on formulas [18]. There is an immediate payoff to this view ofDempster–Shafer belief functions: a logic for reasoning about belief functions can be obtained from that for inner probabilitymeasures [19].The first investigation of mathematical properties of belief functions on more general lattices was initiated by Barthélemy[4] with the combinatorial theory on lattices by Rota [47], which was motivated by possible applications of belief functionsfor non-standard representation of knowledge. Grabisch [26] continued along this direction and showed that such propertiesas Dempster’s rule of combination and Smets’s canonical decomposition [57] in the case of Boolean algebras can be trans-posed in general lattice setting. This generalized theory has been applied to many objects in real world problems that maynot form a Boolean algebra. Let us give some examples: set-valued variables in multi-label classification [13,70], the set ofpartitions in ensemble clustering [39] and bi-capacities in cooperative game theory [29]. Because of its generality, however,Grabisch’s theory loses many intuitively appealing properties in the Dempster–Shafer theory. For example, since a latticedoes not necessarily admit a probability function [26], belief functions in general lattice settings fail to maintain a closeconnection with the Bayesian theory and therefore lack many of the desirable properties associated with this theory asin Dempster–Shafer theory [18]. Since pignistic probabilities are used for decision-making in the transferable belief modelby Smets [65,58], it would be impossible to develop decision theory for general lattice structures along a similar line. Inparticular, most non-classical formalisms1 in AI assume a setting of distributive lattices and hence it would be difficult toapply Grabisch’s theory directly to obtain a deductive approach for reasoning about belief functions over these formalismsas developed in Section 5 of this paper. Our deductive approach requires a setting of distributive lattices. Moreover, in manyreal-world problems such as evidential reasoning on fuzzy events [68,55,56,66] and bipolar belief pairs on vague proposi-tions [36] which do assume a setting of distributive lattices, belief functions are defined in totally different forms. It wouldbe desirable to establish a uniform theory for all these applications of belief functions.An optimal balance between utility and elegance of a theory of belief functions is achieved for distributive lattices, whichis the main contribution of this paper. Not only does our approach for distributive lattices yield a mathematical theoryas appealing as Dempster–Shafer theory, but also its applications extend to many non-classical formalisms of structures inArtificial Intelligence (quantum theory [67] is one of very few important exceptions). The main difficulty in the extension ishow to characterize the class of belief functions without reference to mass assignments. Birkhoff’s fundamental theorem forfinite distributive lattices solves this problem. Through this characterization, many fundamental properties of belief functionsin the Boolean case are also preserved in distributive lattices. Just as i",
            {
                "entities": [
                    [
                        142,
                        183,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 551–569Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal query complexity bounds for finding graphsSung-Soon Choi a,1, Jeong Han Kim a,b,∗,2a Department of Mathematics, Yonsei University, Seoul, 120-749, Republic of Koreab National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Koreaa r t i c l ei n f oa b s t r a c tWe consider the problem of finding an unknown graph by using queries with an additiveproperty. This problem was partially motivated by DNA shotgun sequencing and linkagediscovery problems of artificial intelligence.Given a graph, an additive query asks the number of edges in a set of vertices whilea cross-additive query asks the number of edges crossing between two disjoint sets ofvertices. The queries ask the sum of weights for weighted graphs.For a graph G with n vertices and at most m edges, we prove that there exists an algorithmto find the edges of G using O( m log n2log(m+1) ) queries of both types for all m. The bound is bestpossible up to a constant factor. For a weighted graph with a mild condition on weights, itlog m ) queries are enough provided m (cid:2) (log n)α for a sufficiently largeis shown that O( m log nconstant α, which is best possible up to a constant factor if m (cid:3) n2−ε for any constantε > 0.This settles, in particular, a conjecture of Grebinski [V. Grebinski, On the power of additivecombinatorial search model, in: Proceedings of the 4th Annual International Conferenceon Computing and Combinatorics (COCOON 1998), Taipei, Taiwan, 1998, pp. 194–203] forfinding an unweighted graph using additive queries. We also consider the problem offinding the Fourier coefficients of a certain class of pseudo-Boolean functions as well asa similar coin weighing problem.m© 2010 Elsevier B.V. All rights reserved.Article history:Received 6 August 2008Received in revised form 12 February 2010Accepted 13 February 2010Available online 21 February 2010Keywords:Combinatorial searchCombinatorial group testingGraph findingCoin weighingFourier coefficientPseudo-Boolean functionLittlewood–Offord theorem1. Introduction1.1. Graph finding problemThe problem of finding a graph is stated as follows. Suppose that a graph G has n vertices and at most m edges and thatthe edges of G are unknown. We may consider two types of queries, additive queries and cross-additive queries. An additivequery asks the number of edges in a set of vertices while a cross-additive query asks the number of edges crossing betweentwo disjoint sets of vertices. The problem is to find the edges of G by using as few queries as possible.Additive queries have been motivated by a main process in shotgun sequencing [6,20]. Shotgun sequencing is a methodto determine the whole genome sequence in an organism’s DNA. In shotgun sequencing, it is required to order decoded* Corresponding author at: National Institute for Mathematical Sciences, Daejeon, 305-340, Republic of Korea.E-mail addresses: ss.choi@yonsei.ac.kr (S.-S. Choi), jehkim@nims.re.kr (J.H. Kim).1 This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry ofEducation, Science and Technology (CRI, No. 2008-0054850).2 This work was partially supported by Yonsei University Research Funds 2006-1-0078 and 2007-1-0025, and by the second stage of the Brain Korea 21Project in 2007, and by the Korea Research Foundation Grant funded by the Korean Government (MOEHRD) (KRF-2006-312-C00455).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.003\f552S.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569fragments (called contigs) of the genome sequence. Given a set of contigs, a method called the multiplex PCR method [39]tells how many pairs of the contigs are adjacent in the original sequence. Thus, the task of ordering contigs is reduced tothe problem of finding an unknown graph, which is a Hamiltonian cycle or path, by using additive queries. See e.g., [20].Cross-additive queries have been motivated by the problem of finding the Fourier coefficients for a certain class ofpseudo-Boolean functions. A pseudo-Boolean function is a real-valued function defined on the set of binary sequences. It isk-bounded if it can be expressed as a sum of subfunctions each of which depends on at most k input bits. For example,given a 2-SAT formula, the number of clauses an assignment satisfies is a 2-bounded pseudo-Boolean function. In molecularbiology and biophysics, k-bounded functions have been used to study the evolution of a population of organisms in anenvironment [25]. Specifically, k-bounded functions with small k have received attention in modeling living systems [26]and real biological objects [17]. In evolutionary computation, k-bounded functions have been also used as a benchmark forcomparing heuristic algorithms [18,32,33,38]. Cross-additive queries are used to find the Fourier coefficients of 2-boundedfunctions. More generally, cross-additive queries for k-bounded hypergraphs can be used to find the Fourier coefficients ofk-bounded functions, where k-bounded hypergraphs are hypergraphs whose hyperedges are of size at most k.An algorithm to find an unknown graph is called non-adaptive if each query in the algorithm is independent of theanswers for the previous queries. Otherwise, it is called adaptive. Non-adaptive algorithms are preferable to adaptive onesparticularly when the number of required queries is fairly large and parallel computation is available. There have beena number of papers addressing the problem of finding a graph using additive queries. When the (unknown) graph is aHamiltonian cycle on n vertices, Grebinski and Kucherov [20] presented an adaptive algorithm using O(n) additive queries,which is the best possible up to a constant factor. Later, Grebinski and Kucherov [21] provided an extensive work for severaltypes of graphs. In particular, for graphs with maximum degree bounded by d, they proved the existence of a non-adaptivealgorithm using O(dn) additive queries. When the graph is k-degenerate, the existence of a non-adaptive algorithm usingO(kn) additive queries was shown by Grebinski [19].The fully general case that the graph has n vertices and at most m edges has been a matter of primary concern. It hasbeen conjectured by Grebinski [19] that there exists an algorithm to find the unknown graph using O(m) additive queriesprovided that m = Ω(n). The conjecture has not been settled for a decade. For general m, an adaptive algorithm usingO(m log n) additive queries by Angluin and Chen [4] is the best known to date. In fact, their algorithm uses less powerfulqueries called membership queries, which ask the oracle only about the existence of an edge in a set of vertices. (There havealso been a number of papers addressing the problem of finding a graph using membership queries [2,3,5–7].) Recently,Reyzin and Srivastava [34] presented a simpler adaptive algorithm using O(m log n) additive queries. In this paper, we provethe conjecture of Grebinski in a stronger form, namely the existence of a non-adaptive algorithm using O( m log n2queries. This bound is best possible and better than O(m) if log n2m(cid:3) log m, in particular, m > n2log(m+1) ) additivelog n .mWe shall focus on bounds for the number of required cross-additive queries. Note that cross-additive queries are lessstrong than additive queries since a cross-additive query for the disjoint sets S, T of vertices can be answered by the threeadditive queries for S ∪ T , S, and T . It can be easily shown that the converse is not true: For example, for a graph withexactly one edge, Ω(log n) cross-additive queries are required to verify that it has only one edge while one additive queryis enough to verify the same. In the rest of this paper, we state results with respect to cross-additive queries. The samestatements hold for additive queries after simple modifications if necessary.In this paper, we consider two versions of the graph finding problem. The first one isProblem 1 (Unweighted graphs).Input:Output:an unweighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edgesthe edges of GFor the query complexity of the problem, we have the following.Theorem 1.1. There is a non-adaptive algorithm that solves Problem 1 using O( m log n2mlog(m+1) ) cross-additive queries.The second is a generalized one for weighted graphs with a moderate condition on weights of edges.Problem 2 (Weighted graphs).Input:Output:a weighted graph G for which the only information given is that– G has the vertex set {1, . . . , n} and at most m edges– the weights of edges of G are between nthe edges of G−a and nb in absolute value\fS.-S. Choi, J.H. Kim / Artificial Intelligence 174 (2010) 551–569553For weighted graphs, a cross-additive query asks the sum of weights of the edges crossing between two disjoint sets ofvertices. We obtain bounds for the number of cross-additive queries required to solve the problem.Theorem 1.2. For any fixed constants a, b > 0, there are a constant α > 0 and a non-adaptive algorithm that solves Problem 2 usingO( m log nlog m ) cross-additive queries provided m (cid:2) (log n)α .This extends the result of the conference version [13] that gives the bound when m is at least a constant power of n.3Concerning the condition on weights, a remark is provided in Section 7.Notice that we focused only on query complexity of algorithms. The presented algorithms are not computationally ef-ficient and we do not try to optimize them in time complexity. In terms of query complexity, the bounds in the abovetheorems are optimal up to a constant factor for all or almost all m by the information-theoretic lower bounds. For un-weighted graphs, the bound is optimal for all m. For weighted graphs, the bound is optimal if m (cid:3) n2−ε for any constantε > ",
            {
                "entities": [
                    [
                        136,
                        186,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 110 (1999) 103–134Statics and dynamics of induced systemsMichael Freund 1Department of Mathematics, University of Orléans, F-45067 Orléans, La Source Cedex, FranceReceived 3 July 1998AbstractA collection of formulae, regarded as a set of prerequisite-free normal defaults, generates anonmonotonic inference relation through its Reiter skeptical extension. The structure of the initialset totally determines the behavior of the associated inference relation, and the aim of this paper isto investigate in two directions the link that exists between a set of defaults and its induced inferencerelation. First, we determine the structural conditions corresponding to the important property ofrationality. For this purpose, we introduce the notion of stratification for a set of defaults, and provethat stratified sets are exactly those that induce a rational inference relation. This result is shownto have interesting consequences in belief revision theory, as it can be used to define a nontrivialfull meet revision operator for belief bases. Then, we adopt a dynamic point of view and study theeffects, on the induced inference relation, of a change in the set of defaults. In this perspective, theset of defaults, considered as a knowledge base, together with its induced inference relation is treatedas an expert system. We show how to modify the original set of defaults in order to obtain as outputa rational relation. We propose a revision procedure that enables the user to incorporate a new datain the knowledge base, and we finally show what changes can be performed on the original set ofdefaults in order to take into account a particular conditional that has to retracted from or added tothe primitive induced inference relation. (cid:211) 1999 Elsevier Science B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Preferential relations; Rationality; Stratification; Conditional revision;Rationalization; Full meet base revisionIntroductionAny set of formulae D of a propositional language may be seen as a set of Reiter normalprerequisite-free defaults [16], or, equivalently, as a Poole system without constraints [14].As such, it generates an inference relation that corresponds to the Reiter extension of D.1 Email: freund@labomath.univ-orleans.fr.0004-3702/99/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 0 2 0 - X1999 Elsevier Science B.V. All rights reserved.\f104M. Freund / Artificial Intelligence 110 (1999) 103–134It was noticed in [13,15] that this induced inference relation is a preferential inferencerelation, in the sense of [11], and that it can be represented by a special kind of preferentialmodel, where the set of states coincides with the set of all worlds attached to the language.Conversely, we proved in [4] that any consistency-preserving preferential inference relationdefined on a finite language by an injective model is always induced by a set of defaults.Thus, preferential reasoning, when determined by a preferential injective model, is, in thefinite case, essentially the same as default reasoning: the logic of any agent using injectivepreferential reasoning is fully determined by a set of normal prerequisite-free defaults. Thisapplies in particular to rational reasoning, as it is known that rational inference relationsmay always be defined by means of a ranked injective model [3,11].In this paper, we investigate the link that exists between a set of defaults D and itsinduced inference relation j(cid:24)D. First, on a statics point of view, we characterize the setsof defaults for which the induced inference relation satisfies the property of rationality(postulate K (cid:3) 8 in belief revision theory). We show that a set satisfies this condition if andonly if it has a stratified structure, analogous to a logical chain of sets. This study turnsout to have interesting applications in the framework of belief revision: as an example,we show that our results may be used to construct a nontrivial base revision operator thatsatisfies the extended set of AGM postulates as well as the categorial matching principle.This solves a problem posed in [9]. After this statics study, we evoke in the second part ofthe paper the dynamics of induced systems, and examine some problems connected withchanges occurring in a given set of defaults: in this perspective, the set D is understood asrepresenting all the information available to an agent, and the inference relation j(cid:24)D thatit induces corresponds to the inferences drawn by the agent. Thus the couple .D; j(cid:24)D/ isconsidered as an expert system. In this perspective, it might be necessary to operate changesin the knowledge base D for different reasons: first, in order to improve the system, onemay require that the resulting inference process is of a rational type, so that one has toreplace D by a stratified set. Then, it might appear necessary to incorporate in D somenew information. The problem is then to revise D by this information without alteringtoo much the resulting inference process. A last problem finally is the one that occurswhen one wants to modify the set of defaults D because either it appears necessary toobtain a particular conditional that was not originally entailed by D, or, on the contrary,one wishes to remove a conditional that was part of the primitive induced relation. Forall these problems, we shall see that several solutions exist, and we shall compare theirmerits.In order to make the paper self-contained, we have recalled in Section 1 the basicdefinitions and properties of preferential inference relations. The notion of inducedinference relation is introduced in Section 2, where we give a simple proof of therepresentation theorem of faithfully representable inference relations via their associatedbasic set of defaults. In Section 3, we present a characterization of the default sets thatinduce rational inference relations and propose an application in the framework of baserevision theory. Section 4 is an introduction to the general study of the dynamics of inducedsystems. In Section 5, we discuss the problem of rationalizing an inference relation by asuitable modification of its set of defaults. In Section 6, we treat the problem of revising aset of defaults by a new information and the effect of this revision on the induced inference.Section 7 is concerned with the problem of conditional revision, which occurs when a given\fM. Freund / Artificial Intelligence 110 (1999) 103–134105conditional has to be forced in the agent’s beliefs. We conclude in Section 8. Proofs of themain results are given in Appendix A.1. BackgroundWe denote by L set of well-formed formulae over a set of atomic propositions, closedunder the classical propositional connectives :, _, ^, ! and $. When there are onlyfinitely many atomic propositions, the language is said to be logically finite. Semanticsis provided by the set W of all assignments of truth values to the propositional variables.Elements of W will be referred to as worlds, and the satisfaction relation between a worldm and a formula (cid:11) is defined as usual and written m jD (cid:11). Thus m jD (cid:11) _ (cid:12) iff m jD (cid:11) orm jD (cid:12), and m jD :(cid:11) iff it is not the case that m jD (cid:11).For any world m and any subset A of L, we denote by formA.m/ the set of formulae ofA satisfied by m. The set of worlds that satisfy A will be denoted by Mod.A/. We writem jD A iff m satisfies all the elements of A, that is iff A D formA.m/.The classical consequence operation attached to L and W will be denoted by Cn: forany subset A of L; Cn.A/ is the set of all formulae (cid:11) of L such that m jD (cid:11) for all worldsm that satisfy A. Given a subset A of L, we say that A is consistent iff Cn.A/ 6D L or,equivalently, iff there exists a world m satisfying A. The set A is said to be consistent withthe set B iff A [ B is a consistent set. We write Cn.A; B/ for Cn.A [ B/, and Cn.(cid:11)/ forCn.f(cid:11)g/. We use the notation (cid:11) ‘ (cid:12) as an abbreviation for (cid:12) 2 Cn.(cid:11)/.1.1. Preferential inference relationsFollowing Kraus et al. [11], we call preferential inference relation on L a relation j(cid:24) thatsatisfies the following rules:Reflexivity. (cid:11) j(cid:24) (cid:11).Left Logical Equivalence. If Cn.(cid:11)/ D Cn.(cid:12)/ and (cid:11) j(cid:24) (cid:13) , then (cid:12) j(cid:24) (cid:13) .Right Weakening. If (cid:12) 2 Cn.(cid:11)/ and (cid:13) j(cid:24) (cid:11), then (cid:13) j(cid:24) (cid:12).Cut. If (cid:11) ^ (cid:12) j(cid:24) (cid:13) and (cid:11) j(cid:24) (cid:12), then (cid:11) j(cid:24) (cid:13) .Or. If (cid:11) j(cid:24) (cid:13) and (cid:12) j(cid:24) (cid:13) , then (cid:11) _ (cid:12) j(cid:24) (cid:13) .Cautious Monotonicity. If (cid:11) j(cid:24) (cid:12) and (cid:11) j(cid:24) (cid:13) , then (cid:11) ^ (cid:12) j(cid:24) (cid:13) .Given such a relation, we shall denote by Cj(cid:24).(cid:11)/—or C.(cid:11)/ when there is noambiguity—the set of all consequences of a formula (cid:11), that is the set of all (cid:12)’s such that(cid:11) j(cid:24) (cid:12). We will indifferently refer to “the inference relation j(cid:24)” or to “the inference relationC”. The above rules imply that, for any preferential inference relation C, the sets C.(cid:11)/ areclosed with respect to Cn, that is CnTC.(cid:11)/U D C.(cid:11)/ for all formulae (cid:11). A formula (cid:11) isj(cid:24)-consistent, or C-consistent, iff C.(cid:11)/ 6D L. An inference relation C is said to beconsistency-preserving iff C.(cid:11)/ is a consistent set for any consistent formula (cid:11). Thusa preferential inference relation C is consistency-preserving iff C.(cid:11)/ 6D L wheneverCn.(cid:11)/ 6D L.\f106M. Freund / Artificial Intelligence 110 (1999) 103–1341.2. Preferential modelsA preferential structure is a triple M D .S; <; l/ where < is an irreflexive and transitiverelation defined on a set S (the set of “states”), and l (the “label function”) is a mapping",
            {
                "entities": [
                    [
                        42,
                        81,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 620–642www.elsevier.com/locate/artintIs real-valued minimax pathological?Mitja Luštrek a,∗, Matjaž Gams a, Ivan Bratko ba Department of Intelligent Systems, Jožef Stefan Institute, Jamova 39, 1000 Ljubljana, Sloveniab Faculty of Computer and Information Science, University of Ljubljana, Tržaška cesta 25, 1000 Ljubljana, SloveniaReceived 4 January 2005; received in revised form 9 January 2006; accepted 15 January 2006Available online 17 February 2006AbstractDeeper searches in game-playing programs relying on the minimax principle generally produce better results. Theoretical analy-ses, however, suggest that in many cases minimaxing amplifies the noise introduced by the heuristic function used to evaluate theleaves of the game tree, leading to what is known as pathological behavior, where deeper searches produce worse results. In mostminimax models analyzed in previous research, positions’ true values and sometimes also heuristic values were only losses andwins. In contrast to this, a model is proposed in this paper that uses real numbers for both true and heuristic values. This model didnot behave pathologically in the experiments performed. The mechanism that causes deeper searches to produce better evaluationsis explained. A comparison with chess is made, indicating that the model realistically reflects position evaluations in chess-playingprograms. Conditions under which the pathology might appear in a real-value model are also examined. The essential differencebetween our real-value model and the common two-value model, which causes the pathology in the two-value model, is identified.Most previous research reports that the pathology tends to disappear when there are dependences between the values of siblingnodes in a game tree. In this paper, another explanation is presented which indicates that in the two-value models the error of theheuristic evaluation was not modeled realistically. 2006 Elsevier B.V. All rights reserved.Keywords: Game playing; Minimax; Pathology; Game tree; Real value; Chess1. IntroductionThe minimax principle lies at the heart of almost every game-playing program. Programs typically choose the bestmove by searching the game tree, heuristically evaluating the leaves and then propagating their values to the root usingthe minimax principle. In practice, deeper searches generally produce better results. However, mathematical analysisindicates that under certain seemingly sensible conditions, the opposite is true: minimaxing amplifies the error ofthe heuristic evaluation [2,10]. This phenomenon is called the minimax pathology [10]. Nau [14] described this as“doing worse by working harder”. Evidently, game trees of real games must be different from game trees used in thetheoretical analyses in some way that eliminates the pathology. Several explanations of what property of game treesof real games might be responsible have been put forth: similarity of positions close to each other [3,11], presence ofstabilizing game-tree nodes with reliable estimates [4,16] etc. And while these properties can be shown to eliminate* Corresponding author.E-mail addresses: mitja.lustrek@ijs.si (M. Luštrek), matjaz.gams@ijs.si (M. Gams), bratko@fri.uni-lj.si (I. Bratko).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.006\fM. Luštrek et al. / Artificial Intelligence 170 (2006) 620–642621the pathology, the question to what extent they are actually present in game trees of real games remains. Also, themechanism by which they achieve its goal is sometimes inadequately explained.This paper attempts to address both of these problems: we model game trees in a way that we believe reflects wellthe properties of real games and we explain the mechanism that eliminates the pathology. In our game trees, positionsclose to each other are similar. But unlike most models used in previous research, in which positions’ true values, andsometimes also heuristic values, could only be losses or wins, we use real numbers for both true and heuristic values.This makes it possible to model the similarity between a position’s descendants in a more natural way, and enables amore direct comparison to game-playing programs, which typically use a sizable range of integer values. The modelcan be analyzed mathematically to explain the mechanism that makes minimax effective. Multiple types of error anddifferent experimental settings, among them the approximation of real values by a limited number of discrete values,are used to determine when exactly is the pathology present in a real-value model. Some light is also shed on thereasons for pathological behavior of the two-value models used in previous research.The paper is organized as follows. Section 2 is a short introduction to the minimax pathology with some historicaloverview. Section 3 presents our model of minimax. Section 4 gives a mathematical analysis of minimax with real-number values. Section 5 compares our model to a chess program. Section 6 explains when and how the pathologyappears in a real-value model and examines the differences between real-value and two-value models. Section 7concludes the paper and points out some areas where further research is needed.2. Related workThe minimax pathology was discovered independently by Nau [10] and Beal [2]. It was later more thoroughlyanalyzed by many authors, among them Bratko and Gams [4], whose notation we adopt. In this section, we present abasic minimax model like the one by Beal and others.A game tree consists of nodes representing game positions and edges representing moves. In the basic model,positions can be lost or won. Negamax notation is used in this section, i.e. nodes are marked as lost or won from theperspective of the side to move. Two situations are possible: a node has at least one lost descendant, in which casethe node itself is won because one can always choose the move leading to the descendant lost for the opponent; or anode has only won descendants, in which case the node itself is lost because all moves lead to positions won for theopponent. This is shown in Fig. 1; losses are marked with “−” and wins with “+”.Virtually all research on the minimax pathology assumed game trees to have a uniform branching factor b. In thebasic model, the value of each leaf is independent of other leaves’ values. Let d be the depth of search and ki theprobability of a loss at ith ply. Plies are numbered upwards: 0 for the lowest ply of search and d for the root.Since a node can only be lost if all of its descendants are won, the relation between the values of k at consecutiveplies is governed by Eq. (1).ki+1 = (1 − ki)b.(1)The goal is to calculate the probability of incorrectly evaluating the root given the probability of an incorrectevaluation at the lowest ply of search. Two types of evaluation error are possible: a loss can be mistaken for a win(false win) or a win for a loss (false loss). Let pi and qi be the probabilities of the respective types of error at ith ply.False wins occur in nodes where all descendants should be won, but at least one of them is a false loss. Therefore pi+1can be calculated according to Eq. (2).pi+1 = 1ki+1(1 − ki)b(cid:1)1 − (1 − qi)b(cid:2)= 1 − (1 − qi)b.(2)False losses occur in nodes where some descendants should be lost, but all of those are false wins instead, whileall won descendants retain their true values. Therefore qi+1 can be calculated according to Eq. (3).Fig. 1. Types of nodes.\f622M. Luštrek et al. / Artificial Intelligence 170 (2006) 620–642qi+1 =11 − ki+1b(cid:3)j =1(cid:4)(cid:5)bji (1 − ki)b−j pjkji (1 − qi)b−j= (kipi + (1 − ki)(1 − qi))b − ((1 − ki)(1 − qi))b1 − ki+1.(3)If only games where both sides have an equal chance of winning at the root of the game tree are considered, kdmust be 0.5 and Eq. (1) can be used to calculate k for other plies. Values for p0 and q0 have to be chosen and Eqs. (2)and (3) can be used to calculate pd and qd . If error at the root is defined as either pd kd + qd (1 − kd ) [4] or 1/2(pd + qd )[16], it turns out that with increasing d, the error converges towards 0.5, rendering minimax useless.First attempts to explain this phenomenon were made by Bratko and Gams [4] and Beal [3]. Both came to theconclusion that the reason minimax is effective in real games is that sibling nodes have similar values. Bratko andGams argued that this property causes the formation of subtrees with reliably evaluated roots, which have a stabilizingeffect. They did not verify whether this is indeed the case in real games. Beal showed that if a sufficient numberof nodes that have all the descendants either lost or won are present in a game tree, the pathology disappears. Hesuccessfully verified his claim on king and pawn versus king chess endgame, but his results are not conclusive becausesuch an endgame is not a typical chess situation. Nau [11,13] used a simple game designed for minimax analysis toshow that a strong dependence between a node and its descendants eliminates the pathology. Pearl [16] suspected thatreal games do not have such a strong dependence. He argued that early terminations (also called blunders), which carryreliable evaluations, are the main reason for the elimination of the pathology. Both early terminations and subtreeswith similar node values proposed by Bratko and Gams [4] result in relatively error-free nodes, so these two propertiesuse basically the same mechanism to eliminate the pathology. Pearl’s calculations show that the number of necessaryearly terminations in a game tree with b = 2 is 5%, but attempts by Luštrek and Gams [9] to verify this experimentallyindicate that 20% is needed with b = 2 and even more with larger branching factors. Schrüfer [19] showed that if theerror, particularly the probability of a false loss, is sufficiently low and certain additional conditions are satisfied, agame tree is not pathological. He did not investigate whether these condition",
            {
                "entities": [
                    [
                        72,
                        107,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 105 (1998) 77-103 Artificial Intelligence Rough computational methods for information systems ’ J.W. Guan*, D.A. Bell ’ School of Information and Software Engineering, University of Ulster at Jordanstown, Joraiznstown, BT 37 OQB Northern Ireland, UK Received 16 December 1996; received in revised form 23 December 1997 Abstract Rough set theory in circumstances which are characterized by vagueness and uncertainty. The technique called rough analysis can be applied very fruitfully in artificial intelligence and cognitive sciences. tool for use in computer applications is a relatively new mathematical Although this methodology has been shown to be successful many real-life applications, to consider practical there are still several theoretical problems issues if we want to apply the theory. in dealing with the vagueness of to be solved, and we also need It is the latter set of issues we address here, in the context of handling and analysing sets during the knowledge general problem of finding all “keys”) have been shown to be m-hard. Thus, it is important efficient computational methods for the theory. representation process. Some of the associated problems (for example, large data the to seek In rough set theory, a table called an information system or a database relation is used as a special is defined systems. The use of rough analysis does not involve the details of kind of formal as classifications of information rough set theory directly, but it uses the same basic classification syntactically. Semantically, knowledge to represent knowledge techniques. language We discuss computational methods for the rough analysis of databases. 0 1998 Elsevier Science B.V. All rights reserved. Keywords: Intelligent information systems; Database and knowledge base systems Introduction In this paper we discuss how to apply the rough analysis technique to databases. Rough techniques arising from rough set theory. It provides analysis is one of the main application * Corresponding author. Email: J.guan@ulst.ac.uk. ’ Email: DA.bell@ulst.ac.uk. 0004-3702/98/$ - see front matter 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00090-3 \f78 J.U? Gum, D.A. Bell/Artijkial Inaelligence 105 (1998) 77-103 for gaining attributes insights in databases. into properties of data, dependencies It has important applications a technique of individual and cognitive sciences, as a tool for dealing with vagueness and uncertainty of facts, and in the application of the technique by classification. The objective of this paper is to enhance designing a series of algorithms context. To study the theory itself, the reader is referred to [6]. and the significance intelligence in a knowledge representation the technique to implement to artificial A sister paper [2] complements the collection of algorithms presented here; it focuses on the use of rough set theory, per se, as a means of discovering knowledge which is latent in the form of in database relations rules, with particular attention being paid to decision (i.e., data mining or knowledge discovery in databases) tables. In this paper, we concentrate upon using rough set theory itself) for the classical database problems of checking dependencies jinding keys for a conventional a view to using the solutions appear in both papers for convenience-being to and (i.e., with no distinguished decision variables) with [l]. One or two algorithms relation in general knowledge discovery the rough analysis technique (as opposed relevant to both studies. is to use the tool for computer applications Our practical motivation in which reasoning [3,14] learning large) collections in deriving evidence are based on (often sites (e.g., near Lake Turkana of sense or other data stored [l] how evidence can be obtained in certain kinds of integrity constraints is that there are realZy two classes-the from this data to support various hypotheses, featured one, and a third class lying between is that there are 3 different classes of skull-a in systems. For example, we have and computers, and perhaps managed by database management for reasoning purposes by examining shown elsewhere (see below). the properties of data as expressed into our distant ancestors, using a set of field notes an investigation Consider in Kenya). Ultimately, we are recorded on paleontological for example, interested in the dataset. One hypothesis, based on prima facie on the classes of skulls described small, finely featured one, a indications, these two. An alternative large, coarsely small and hypothesis (there may be several) medium “classes” being the clearly distinguished female and male specimens of just one class, and the large “class” being a different species. The field data can be recorded as an is given in Example 3.1 below), and rough analysis can information from this data to see which be considered hypothesis in this if we can decide which features, example, and there is also a potential practical benefit exercise (the “core”). A related problem or attributes, are significant is to find which set of attributes or features (perhaps minimal) can be used to distinguish individual this “classical” problem the reasoning and learning applications classification the accumulation data, are clearly very important discovery of keys can also provide insights get by alternative means. exercises. The into the structure of data which are not easy to skulls from one another. This is what we mean by a “key”. The solution is best supported by the data. There is a basic need for classification least in specimens and events, and itself. The classification of evidence theory can provide important support in underpinning learning and other reasoning of (e.g., paleontological) as a possible approach to support hypotheses for deriving evidence system (an illustration in the classification from observation and experimental intelligence-not encountered in database in machine in artificial to In Section 1, we introduce information ization of a database relation. Formally, systems. An information is a general- it consists of two finite sets: one universe U and system \fJ.U! Guan. D.A. Bell /Artificial Intelligence IO5 (1998) 77-103 79 one attribute set A. The rough analysis significant attributes, and the keys-the minimal technique is applied to find the core-the set of identifying sets of attributes. for an attribute The basic tool for rough set theory is classification. In Section 2, we discuss classification for one attribute. Algorithm E with the time complexity 0( 1 U I*) to find the corresponding classification be run in parallel mode to compute concurrently attributes. Algorithm intersection between many attributes is given, where 1 U 1 is the cardinality of U. The algorithm can for many between many attributes. classification In Section 3, we discuss classification I with the time complexity O(lU 1’) to find the corresponding all corresponding intersections classifications is given. Using between dependencies (FD). We present Algorithm 0 with classification, we analyse dependencies functional 0(/U 12) to check two subsets of attributes. Section 4 discusses the time complexity subsets. (ID). We present Algorithm S with the time Section 5 discusses complexity O(lU I*) to check the identity dependency of two attribute subsets. The keys ID subsets of set A. Algorithm K with the time of an attribute set A are the minimal complexity 0(21Al IA) lUl*) to find all keys is presented in Section 6. In order to reduce the the ID significance of an attribute and ID exponential significant attribute subsets. complexity, we need to investigate identity dependencies of two attribute the functional dependency for computing An attribute x in X (& A) is significant if X and X - {x) are not ID. An attribute set if every attribute x E X is significant. Using classification, we analyse the significance measure of attribute x in X. The time is O(lX] x lUl*). Algorithm C with the time set of significant X is significant significances. Section 7 introduces complexity complexity 0(1X1* 1 VI’) attributes. Section 8 discusses keys are significant subsets. Using the significance measure, we present Algorithm A with the time complexity 0( I A I3 I U I*) to find one key. The algorithm can be run in parallel mode to compute all keys concurrently. subsets of attributes. Section 9 shows that the ID ID subsets. Thus, finding keys is equivalent to allow us to find the core-the to finding significant a significance is presented significant 1. Information systems and databases An information system 1 is a system (U, A), where: . . . . uj, . . ., ulul} (I) u = (UI,U2, is a finite non-empty set, called a universe or an object space; elements of U are called identifiers or objects; (2) A = {al,az, . . . , al,. . ., alAI) is also a finite non-empty set; elements of A are called attributes; (3) for every a E A there is a mapping a from U into some space, a : U --F a(U), and is called the domain of attribute a. system An information [6] is also called a knowledge representation attribute-value an information system. An information table (see Table 1). system can be intuitively system, or an in terms of expressed \f80 J.W Guan, D.A. Bell /Artijicial Intelligence 105 (1998) 77-103 Table 1 U\\A al a2 al alAl Ul u2 ui ,.. al&l) a2(ul) al&) . alAl al (u2) a2(u2) .,. al(u2) alAl (U2) . . . q(4) . . . . a2(Ui) C?r(Ui) alAl@i) . . . . . . . . . . UlUl al(Upl) a2(ulUl) al(ulUI) . . . alAI The time complexity system for computing thereareIUIxIAlvaluesal(ui)tobecomputed,wherei=1,2,...,IUI;1=1,2,...,IAl. an information (U, A) is (U 1 x IAl since The concept of information systems is a generalization of the concept of a reMan in databases. For relational databases, a relational scheme is a finite set of attributes A = {al, a2, . . . , its domain. . . , IA]) has a set of values, Dl, called is a subset of D1 x D2 x . . . x DIAI. A member of they are labelled by different obje",
            {
                "entities": [
                    [
                        66,
                        117,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 368–395Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAuction optimization using regression trees and linear models as integer programsSicco Verwer a, Yingqian Zhang b,∗a Intelligent Systems Department, Delft University of Technology, The Netherlandsb Department of Econometrics, Erasmus University Rotterdam, The Netherlands, Qing Chuan Ye ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 14 May 2015Accepted 21 May 2015Available online 29 May 2015Keywords:Auction designMachine learningOptimizationInteger linear programmingRegressionIn a sequential auction with multiple bidding agents, the problem of determining the ordering of the items to sell in order to maximize the expected revenue is highly challenging. The challenge is largely due to the fact that the autonomy and private information of the agents heavily influence the outcome of the auction.The main contribution of this paper is two-fold. First, we demonstrate how to apply machine learning techniques to solve the optimal ordering problem in sequential auctions. We learn regression models from historical auctions, which are subsequently used to predict the expected value of orderings for new auctions. Given the learned models, we propose two types of optimization methods: a black-box best-first search approach, and a novel white-box approach that maps learned regression models to integer linear programs (ILP), which can then be solved by any ILP-solver. Although the studied auction design problem is hard, our proposed optimization methods obtain good orderings with high revenues.Our second main contribution is the insight that the internal structure of regression models can be efficiently evaluated inside an ILP solver for optimization purposes. To this end, we provide efficient encodings of regression trees and linear regression models as ILP constraints. This new way of using learned models for optimization is promising. As the experimental results show, it significantly outperforms the black-box best-first search in nearly all settings.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOne of the main challenges of mathematical optimization is to construct a mathematical model describing the properties of a system. When the structure of a system cannot be fully determined from the knowledge at hand, machine learning and data mining techniques have been used in optimization instead of this knowledge. They have, for example, been used in order to obtain decision values [1], fitness functions [2], or model parameters [3]. Models that have been learned from data are frequently used in a black-box manner, e.g., using only the predictions of learned models but not their internal structure. It is also possible to use these models in a white-box manner, for instance in order to determine search space cuts and parameter bounds. Neural networks have in this way been used to model unknown relations in constraint programming [4]. In this paper, we develop such a white-box optimization method for regression models in integer linear programming, that is, we map these entire models to sets of variables and constraints and solve them using an off the shelf solver. * Corresponding author.E-mail addresses: S.E.Verwer@tudelft.nl (S. Verwer), yqzhang@ese.eur.nl (Y. Zhang), ye@ese.eur.nl (Q.C. Ye).http://dx.doi.org/10.1016/j.artint.2015.05.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\fS. Verwer et al. / Artificial Intelligence 244 (2017) 368–395369This white-box method together with a proposed black-box method provides a solution to an optimization problem of key interest to the artificial intelligence and operations research communities: auction design. We briefly introduce this problem domain before going into the details of our methods.1.1. Sequential auction designAuctions are becoming increasingly popular for allocating resources or items in business-to-business and business-to-customer markets. Often sequential auctions [5] are adopted in practice, where items are sold consecutively to bidders. Sequential auctions are in particular desirable when the number of items for sale is large (e.g., flower auctions [6]), or when the buyers enter and leave the auction dynamically (e.g., online auctions [7]). In a sequential auction, an auctioneer may tune several auction parameters to influence the outcome of an auction, such as reserve prices for items and in which order to sell them. In other words, (s)he can design auctions for the purpose of achieving some predefined goal. In this paper, we solve one specific auction design problem, namely, deciding the optimal ordering of items to sell in a sequential auction in order to maximize the expected revenue (OOSA in short). We assume bidders in such auctions are budget constrained. This is a highly relevant problem in today’s auctions since bidders almost always have limited budget, as seen for instance in industrial procurement [8]. Previous research has shown that with the presence of budget constraints, the revenue collected by the auctioneer is heavily dependent on the ordering of items to sell [9–11]. This holds already for a toy problem with 2 items. Let us use a simple example to illustrate the importance of ordering in such cases.Example 1. Two agents A1 and A2 take part in a sequential auction of items. For sale are items r1 and r2. Suppose the items are sold by means of first-price, English auction.1 Assume the reserve prices, which are the lowest prices at which the auctioneer is willing to sell the times, for both items are 1. The amount that agent A1 and agent A2 are willing to pay for two items are: ν1(r1) = 10, ν1(r2) = 15, ν2(r1) = 12, ν2(r2) = 10. Furthermore, the budgets of A1 and A2 are 15 and 25respectively.We assume a simple bidding strategy in this example. The agents bid myopically on each item, that is, their highest bid on one item is the lower value between the amount that they are willing to pay and their remaining budget. The auctioneer’s goal is to maximize the total sold price of the items. Consider one situation where the auctioneer sells first r2and then r1. A1 will get r2 when she just over-bids A2 with 11, and then when r1 is auctioned, A1 bids maximally 4 due to her budget limit, and A2 will win the item with the price of 5. The total revenue is 16. However, if the selling sequence is (r1, r2), A2 will win r1 with the bid 11, and then A2 will win r2 with price 11. The collected revenue is 22 in this case. (cid:2)Most of the current approaches to the ordering problem in sequential auctions assume a very restricted market environ-ment. They either study the problem of ordering two items, see [11,12], or a market with homogeneous bidders [13]. To the best of our knowledge, we are the first to consider how to order items for realistic auction settings with many hetero-geneous bidders competing for many different items. This problem is highly complex—a good design on ordering needs to take care of many uncertainties in the system. For instance, in order to evaluate the revenue given an ordering, the opti-mization algorithm needs to know the bidders’ budgets and preferences on items, which are usually private and unshared. Furthermore, the large variety of possible bidding strategies that bidders may use in auctions are unknown. This auction design problem is a typical example where the mathematical optimization model cannot be fully determined, and hence, machine learning and data mining techniques can come into play. This is exactly what our approach builds upon.1.2. Learning models for white-box and black-box optimizationNowadays more and more auctions utilize information technology, which makes it possible to automatically store de-tailed information about previous auctions along with their selling sequences and the selling price per auctioned item. Our approach to solving the problem of optimal ordering for sequential auctions starts with the historical auction data. We define and compute several relevant features and then use them to learn regression trees and linear regression models for the expected revenue. Given the models, we propose two approaches to find the optimal ordering for a new set of items: (1) a best-first search that uses the models as a black-box to evaluate different orderings of the items; and (2) a novel white-box optimization method that translates the models and the set of items into a mixed-integer program (MIP) and runs this in an ILP-solver (CPLEX). Fig. 1 displays the general framework of our approaches using these two optimization methods.Just like the traditional black-box optimization approach (see, e.g. [14,15]), our best-first search is ignorant of the internal structure of the models and only calls it to perform function evaluations, i.e., predicting the revenue of an ordering of the items. Optimization is possible by means of a search procedure that uses heuristics to produce new orderings depending on previously evaluated ones. Our best-first search makes use of dynamic programming cuts inspired by sequential decision making in order to reduce the search space.1 The English auction that we consider is the one where the starting price is the reserve price, and bidders bid openly against each other. Each subsequent bid should be higher than the previous bid, and the item is sold to the highest bidder at a price equal to her bid.\f370S. Verwer et al. / Artificial Intelligence 244 (2017) 368–395One of the main contributions of this paper is the realization that learned regression models can be evaluated efficiently inside modern mathematical optimization solvers. This evaluation includes the computation of feature values (the input to machine learning), the evaluation of these features using a learned model (the output from machine learning), and a possible feedback from such evaluations to new features. In this paper, we efficiently translat",
            {
                "entities": [
                    [
                        136,
                        217,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 52–89Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConflict-driven answer set solving: From theory to practice ✩Martin Gebser, Benjamin Kaufmann, Torsten Schaub∗Universität Potsdam, Institut für Informatik, August-Bebel-Str. 89, D-14482 Potsdam, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 19 March 2010Received in revised form 26 February 2012Accepted 5 April 2012Available online 10 April 2012Keywords:Answer set programmingLogic programmingNonmonotonic reasoningWe introduce an approach to computing answer sets of logic programs, based on conceptssuccessfully applied in Satisfiability (SAT) checking. The idea is to view inferences inAnswer Set Programming (ASP) as unit propagation on nogoods. This provides us witha uniform constraint-based framework capturing diverse inferences encountered in ASPsolving. Moreover, our approach allows us to apply advanced solving techniques from thearea of SAT. As a result, we present the first full-fledged algorithmic framework for nativeconflict-driven ASP solving. Our approach is implemented in the ASP solver clasp that hasdemonstrated its competitiveness and versatility by winning first places at various solvercontests.© 2012 Elsevier B.V. All rights reserved.1. IntroductionAnswer Set Programming (ASP; [67,94,102,66,87,6,65]) has become an attractive paradigm for knowledge representationand reasoning, due to its appealing combination of rich yet simple modeling languages1 with powerful solving engines.Albeit specialized ASP solvers have been highly optimized (cf. [119,83,15]), their performance has so far not matched theone of modern solvers for Satisfiability (SAT; [12]) checking. However, computational mechanisms of SAT and ASP solvers arenot far-off, as witnessed by the SAT-based ASP solvers assat [90] and cmodels [71]. Nonetheless, state-of-the-art look-backtechniques from SAT, or more generally, Constraint Programming (CP; [26,113]), such as backjumping and conflict-drivenlearning, were not yet established in native ASP solvers. In fact, previous approaches to adopt such techniques [126,112,91]are rather implementation-specific, i.e., they focus on describing modifications of existing ASP solving approaches, and thuslack generality.We address this deficiency by introducing a novel computational approach to ASP solving, building on Boolean con-straints. Apart from the fact that this allows us to easily integrate solving techniques from related areas like SAT, e.g.,backjumping, conflict-driven learning, restarts, etc., it also provides us with a uniform characterization of inferences fromlogic program rules, unfounded sets, and conflict conditions. As major results, we show that all inferences in ASP solv-ing can be reduced to unit propagation on nogoods, and we devise the first self-contained algorithmic framework fornative conflict-driven ASP solving. While the general outline of search is the same as in Conflict-Driven Clause Learning(CDCL; [97,127,23,96]), the state-of-the-art algorithm for industrial SAT solving, the integration of unfounded set checkingis particular to ASP and owed to its elevated expressiveness (cf. [117,76,88]). However, our approach favors “local” unitpropagation over unfounded set checks, i.e., tests whether inherent (loop) nogoods are unit or violated. We elaborate upon✩This paper combines and extends the work presented in Anger et al. (2005) [2], Gebser et al. (2007, 2007, 2009) [54,52,56].* Corresponding author. Tel.: +49 331 977 3080/3081; fax: +49 331 977 3122. Torsten Schaub is also affiliated with the School of Computing Science atSimon Fraser University, Burnaby, Canada, and the Institute for Integrated and Intelligent Systems at Griffith University, Brisbane, Australia.E-mail addresses: gebser@cs.uni-potsdam.de (M. Gebser), kaufmann@cs.uni-potsdam.de (B. Kaufmann), torsten@cs.uni-potsdam.de (T. Schaub).1 The interested reader is referred to [120,45,83] for detailed accounts of ASP’s modeling languages.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.001\fM. Gebser et al. / Artificial Intelligence 187–188 (2012) 52–8953the formal properties of our conflict-driven algorithmic framework, and we demonstrate its soundness and completenessfor ASP solving.Our approach has led to the implementation of the award-winning ASP solver clasp, taking first places at the ASP, CASC,MISC, PB, and SAT contests in 2011 (see [110] for more details). We discuss the major features of clasp and provide anempirical evaluation of its performance by comparing it to other state-of-the-art ASP solvers, using the class of NP decisionproblems from the second ASP competition [28]. Generally, clasp has become a powerful native ASP solver, offering variousreasoning modes that make it an attractive tool for knowledge representation and reasoning.2 This is witnessed by anincreasing number of applications relying on clasp (or derivatives) as reasoning engine, e.g., [99,13,80,122,75,64]. Along withthe grounder gringo [51], clasp constitutes a central component of Potassco [44], the Potsdam Answer Set Solving Collectionbundling tools for ASP developed at the University of Potsdam.The outline of this paper is as follows. After establishing the formal background, we provide in Section 3 a constraint-based specification of answer sets in terms of nogoods. Based on this uniform characterization, we develop in Section 4algorithms for ASP solving that incorporate advanced look-back techniques. In Section 5, we describe the award-winningASP solver clasp, implementing our approach. Section 6 provides a systematic empirical evaluation demonstrating the com-petitiveness of clasp. We conclude with related work and summary. Proofs for formal results are provided in Appendix A.2. BackgroundGiven an alphabet P , a (propositional normal) logic program is a finite set of rules of the formp0 ← p1, . . . , pm, not pm+1, . . . , not pn(1)where 0 (cid:2) m (cid:2) n and each pi ∈ P is an atom for 0 (cid:2) i (cid:2) n. A body literal is an atom p or its (default) negation not p. Fora rule r as in (1), let head(r) = p0 be the head of r and body(r) = {p1, . . . , pm, not pm+1, . . . , not pn} be the body of r. Theintuitive reading of r is that head(r) must be true if body(r) holds, i.e., if p1, . . . , pm are (provably) true and if pm+1, . . . , pnare (assumed to be) false. Given a set β of body literals, let β+ = {p ∈ P | p ∈ β} and β− = {p ∈ P | not p ∈ β}. For body(r),− = {pm+1, . . . , pn}. The set of atoms occurring in a logic program Πwe then have that body(r)is denoted by atom(Π), and body(Π) = {body(r) | r ∈ Π} is the set of bodies of rules in Π . For regrouping rule bodiessharing the same head p, we define bodyΠ (p) = {body(r) | r ∈ Π, head(r) = p}.A set X ⊆ P of atoms is a model of a logic program Π , if head(r) ∈ X , body(r)− ∩ X (cid:7)= ∅ holds forevery r ∈ Π . In ASP, the semantics of Π is given by its answer sets [67]. The reduct, Π X , of Π relative to X is defined by− ∩ X = ∅}. Note that Π X is a Horn program possessing a unique ⊆-minimalΠ X = {head(r) ← body(r)model (cf. [30]). Given this, X is an answer set of Π , if X itself is the ⊆-minimal model of Π X . Note that any answer setof Π is a model of Π as well, while the converse does not hold in general.+ = {p1, . . . , pm} and body(r)+ | r ∈ Π, body(r)+ (cid:2) X , or body(r)The positive dependency graph of a program Π is given by (atom(Π), (cid:2)+), where atom(Π) and (cid:2)+ = {(p, head(r)) |+} are the set of vertices and directed edges, respectively. This graph allows us to identify circularr ∈ Π, p ∈ body(r)positive dependencies among atoms. According to [90], a non-empty L ⊆ atom(Π) is a loop of Π , if for every pair p ∈ L,q ∈ L (including p = q), there is a path of non-zero length from p to q in (atom(Π), (cid:2)+) such that all vertices in thepath belong to L. We denote the set of all loops of Π by loop(Π); if loop(Π) = ∅ (or loop(Π) (cid:7)= ∅), Π is a tight (or non-tight) program. As shown in [40] and exploited in Section 3, the answer sets of a tight program Π coincide with modelsof the Clark completion of Π [21], also referred to as the supported models of Π [3]. A strongly connected component of(atom(Π), (cid:2)+) is a maximal subgraph such that any pair of vertices is connected by some path; it is non-trivial, if it containssome edge. Note that, for any loop L of Π , the atoms in L belong to the same non-trivial strongly connected component of(atom(Π), (cid:2)+). Moreover, we have that Π is tight iff (atom(Π), (cid:2)+) does not include any non-trivial strongly connectedcomponent.Example 2.1. Consider the following logic program3:(cid:3)(cid:2)Π2 =a ←b ← not a d ← not c, not ec ← a, not de ← be ← e.(2)This program has two answer sets: {a, c} and {a, d}. Note that Π2 is non-tight because its positive dependency graphcontains the non-trivial strongly connected component ({e}, {(e, e)}).In practice, propositional logic programs are usually obtained from inputs in some first-order language (cf. [120,45,83])via grounding. We do not detail grounding here, but only mention that off-the-shelf grounders, such as dlv’s groundingcomponent [105], gringo [51], and lparse [120], are available to accomplish this task. Moreover, particular classes of logic2 Beyond search for one answer set of a propositional normal logic program, detailed in this paper, clasp supports so-called extended rules [47], solutionenumeration [53,57], and optimization [48]. Due to its versatile core engine, clasp can be run as a solver for ASP, SAT, Maximum Satisfiability (MaxSAT;[85]), and Pseudo-Boolean (PB; [114]) constraint satisfaction/optimization, incorporating dedicated front-ends for diverse input formats.3 Our enumeration scheme for particular logic programs Π follows that of equations.\f54M. Gebser et al. / Artificial Intelligence 187–188 (2012) 52–89programs adm",
            {
                "entities": [
                    [
                        147,
                        206,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 221–239Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRanking gamesFelix Brandt a,∗, Felix Fischer a, Paul Harrenstein a, Yoav Shoham ba Institut für Informatik, Universität München, Oettingenstr. 67, 80538 München, Germanyb Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA 94305, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 3 January 2008Received in revised form 28 August 2008Accepted 20 October 2008Available online 29 October 2008Keywords:Multi-agent systemsGame theoryStrict competitivenessn-player gamesSolution conceptsComputational complexityThe outcomes of many strategic situations such as parlor games or competitive economicscenarios are rankings of the participants, with higher ranks generally at least as desirableas lower ranks. Here we define ranking games as a class of n-player normal-form gameswith a payoff structure reflecting the players’ von Neumann–Morgenstern preferencesover their individual ranks. We investigate the computational complexity of a variety ofcommon game-theoretic solution concepts in ranking games and deliver hardness resultsfor iterated weak dominance and mixed Nash equilibrium when there are more than twoplayers, and for pure Nash equilibrium when the number of players is unbounded but thegame is described succinctly. This dashes hope that multi-player ranking games can besolved efficiently, despite their profound structural restrictions. Based on these findings,we provide matching upper and lower bounds for three comparative ratios, each of whichrelates two different solution concepts: the price of cautiousness, the mediation value, and theenforcement value.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe situations studied by the theory of games may involve different levels of antagonism. On the one end of the spec-trum are games of pure coordination, on the other those in which the players’ interests are diametrically opposed. In thispaper, we put forward a new class of competitive multi-player games whose outcomes are rankings of the players, i.e.,orderings of the players representing how well they have done in the game relative to one another. We assume players toweakly prefer a higher rank over a lower one and to be indifferent as to the other players’ ranks. This type of situation iscommonly encountered in parlor games, competitions, patent races, competitive resource allocation domains, social choicesettings, or any other strategic situation where players are merely interested in performing optimal relative to their oppo-nents rather than in absolute measures. Formally, ranking games are defined as normal-form games in which the payofffunction represents the players’ von Neumann–Morgenstern preferences over lotteries over rankings. A noteworthy specialcase of particular relevance to game playing in AI are single-winner games where in any outcome one player wins and allothers lose.While two-player ranking games form a subclass of zero-sum games, no such relationship holds for ranking games withmore than two players. Moreover, whereas the notion of a ranking is most natural in multi-player settings, this seems tobe less so for the requirement that the sum of payoffs in all outcomes be constant, as any game can be transformed intoa constant-sum game by merely introducing an additional player (with only one action at his disposal) who absorbs thepayoffs of the other players [41].* Corresponding author. Tel.: +49 89 2180 9406; fax: +49 89 2180 9338.E-mail addresses: brandtf@tcs.ifi.lmu.de (F. Brandt), fischerf@tcs.ifi.lmu.de (F. Fischer), harrenst@tcs.ifi.lmu.de (P. Harrenstein), shoham@cs.stanford.edu(Y. Shoham).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.008\f222F. Brandt et al. / Artificial Intelligence 173 (2009) 221–239As with games in which both contrary and common interests prevail, it turns out that solving ranking games tends tobecome considerably more complicated as soon as more than two players are involved. The maximin solution does notunequivocally extend to general n-player games and numerous alternate solution concepts have been proposed to copewith this type of situation. None of them, however, seems to be as compelling as maximin is for two-player zero-sumgames. In this paper we study and compare the properties of a variety of solution concepts in ranking games. The resultsof this paper fall into two different categories. First, we investigate the complexity of a number of computational problemsrelated to common solution concepts in ranking games, particularly Nash equilibrium and iterated weak dominance. Second,we study a number of comparative ratios in ranking games, each of which relates two different solution concepts: the priceof cautiousness, the mediation value, and the enforcement value.The computational effort required to determine a solution is obviously a very important property of any solution concept.If computing a solution is intractable, the solution concept is rendered virtually useless for large problem instances that donot exhibit additional structure. The importance of this aspect has by no means escaped the attention of game theorists. Inan interview with Eric van Damme [39], Robert Aumann claimed: “My own viewpoint is that, inter alia, a solution conceptmust be calculable, otherwise you are not going to use it.” It has subsequently been argued that this still holds if onesubscribes to a purely descriptive view of solution concepts: “I believe that the complexity of equilibria is of fundamentalimportance in game theory, and not just a computer scientist’s afterthought. Intractability of an equilibrium concept wouldmake it implausible as a model of behavior” [28]. In computational complexity theory, the distinction between tractableand intractable problems is typically one between membership in the class P of problems that can be solved in timepolynomial in the size of the problem instance versus hardness for the class NP of problems a solution of which can beverified efficiently. A third class that will play an important role in the context of this paper is PPAD. Problems in PPAD areguaranteed to possess a solution, and emphasis is put on actually finding it. Given the current state of complexity theory,we cannot prove the actual intractability of most algorithmic problems, but merely give evidence for their intractability. NP-hardness of a problem is commonly regarded as very strong evidence against computational tractability because it relatesthe problem to a large class of problems for which no efficient algorithm is known, despite enormous efforts to find suchalgorithms. To some extent, the same reasoning can also be applied to PPAD-hardness.We study the computational complexity of common game-theoretic solution concepts in ranking games and deliver NP-hardness and PPAD-hardness results, respectively, for iterated weak dominance and (mixed) Nash equilibria when there aremore than two players, and an NP-hardness result for pure Nash equilibria in games with an unbounded number of players.This dashes hope that multi-player ranking games can be solved efficiently, despite their profound structural restrictions.Remarkably, all hardness results hold for arbitrary preferences over ranks, provided they meet the requirements listed above.Accordingly, even very restricted subclasses of ranking games such as single-winner games—in which players only care aboutwinning—or single-loser games—in which players merely wish not to be ranked last—are computationally hard to solve.By contrast, maximin strategies [40] as well as correlated equilibria [5] are known to be computationally easy via linearprogramming for any class of games. Against the potency of these concepts, however, other objections can be brought in.Playing a maximin strategy is extremely defensive and a player may have to forfeit a considerable amount of payoff in orderto guarantee his security level. Correlation, on the other hand, may not be feasible in all practical applications, and may failto provide an improvement of social welfare in restricted classes of games [23]. Thus, we come to consider the followingcomparative ratios in an effort to facilitate the quantitative analysis of solution concepts in ranking games:• the price of cautiousness, i.e., the ratio between an agent’s minimum payoff in a Nash equilibrium and his security level,• the mediation value, i.e., the ratio between the social welfare obtainable in the best correlated equilibrium vs. the bestNash equilibrium, and• the enforcement value, i.e., the ratio between the highest obtainable social welfare and that of the best correlated equi-librium.Each of these values obviously equals 1 in the case of two-player ranking games, as these form a subclass of constant-sumgames. Accordingly, the interesting question to ask concerns the bounds of these values for ranking games with more thantwo players.2. Introductory exampleTo illustrate the issues addressed in this paper, consider a situation in which Alice, Bob, and Charlie are to choose awinner from among themselves by means of the following protocol. Each of them is either to raise or not to raise theirhand; they are to do so simultaneously and independently of one another. Alice wins if the number of hands raised,including her own, is odd, whereas Bob is victorious if this number equals two. Should nobody raise their hand, Charliewins. The normal-form of this game is shown in Fig. 1. What course of action would you recommend to Alice? There is aNash equilibrium in which Alice raises her hand, another one in which she does not raise her hand, and still another onein which she randomizes uniformly between these two options. In the only pure, i.e., non-randomized, equilibrium of thegame, Alice does not raise her hand. If the latter were to occur, we must assume that Alice believes",
            {
                "entities": [
                    [
                        136,
                        149,
                        "TITLE"
                    ],
                    [
                        891,
                        904,
                        "TITLE"
                    ],
                    [
                        1159,
                        1172,
                        "TITLE"
                    ],
                    [
                        1435,
                        1448,
                        "TITLE"
                    ],
                    [
                        2696,
                        2709,
                        "TITLE"
                    ],
                    [
                        3029,
                        3042,
                        "TITLE"
                    ],
                    [
                        3109,
                        3122,
                        "TITLE"
                    ],
                    [
                        4017,
                        4030,
                        "TITLE"
                    ],
                    [
                        4475,
                        4488,
                        "TITLE"
                    ],
                    [
                        4664,
                        4677,
                        "TITLE"
                    ],
                    [
                        4788,
                        4801,
                        "TITLE"
                    ],
                    [
                        6923,
                        6936,
                        "TITLE"
                    ],
                    [
                        7226,
                        7239,
                        "TITLE"
                    ],
                    [
                        7487,
                        7500,
                        "TITLE"
                    ],
                    [
                        8383,
                        8396,
                        "TITLE"
                    ],
                    [
                        8864,
                        8877,
                        "TITLE"
                    ],
                    [
                        9011,
                        9024,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 392–412Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for the coalitional manipulation problem ✩Michael Zuckerman a,1, Ariel D. Procaccia b,∗,2, Jeffrey S. Rosenschein aa School of Engineering and Computer Science, The Hebrew University of Jerusalem, Jerusalem 91904, Israelb Microsoft Israel R&D Center, 13 Shenkar Street, Herzeliya 46725, Israela r t i c l ei n f oa b s t r a c tWe investigate the problem of coalitional manipulation in elections, which is known to behard in a variety of voting rules. We put forward efficient algorithms for the problem inBorda, Maximin and Plurality with Runoff, and analyze their windows of error. Specifically,given an instance on which an algorithm fails, we bound the additional power themanipulators need in order to succeed. We finally discuss the implications of our resultswith respect to the popular approach of employing computational hardness to precludemanipulation.© 2008 Elsevier B.V. All rights reserved.Article history:Received 15 December 2007Received in revised form 17 November 2008Accepted 20 November 2008Available online 24 November 2008Keywords:Computational social choiceVotingManipulationComputational complexity1. IntroductionSocial choice theory is an extremely well-studied subfield of economics. In recent years, interest in the computationalaspects of social choice, and in particular in the computational aspects of voting, has sharply increased.In an election, a set of voters submit their (linear) preferences (i.e., rankings) over a set of candidates. The winner ofthe election is designated by a voting rule, which is basically a mapping from the space of possible preference profiles intocandidates. A thorn in the side of social choice theory is formulated in the famous Gibbard–Satterthwaite Theorem [15,26].This theorem essentially states that for any voting rule that is not a dictatorship, there are elections in which at least oneof the voters would benefit by lying. A dictatorship is a voting rule where one of the voters—the dictator—single-handedlydecides the outcome of the election.Since the 1970s, when this impossibility result was established, an enormous amount of effort has been invested indiscovering ways to circumvent it. Two prominent and well-established ways are allowing payments [4,16,29], or restrictingthe voters’ preferences [20].In this paper, we wish to discuss a third path—the “path less taken”, if you will—which has been explored by computerscientists. The Gibbard–Satterthwaite Theorem implies that in theory, voters are able to manipulate elections, i.e., bend themto their advantage by lying. But in practice, deciding which lie to employ may prove to be a hard computational problem;after all, there are a superpolynomial number of possibilities of ranking the candidates.✩A significantly shorter version of this paper (with most of the proofs omitted) appeared in the Proceedings of the Nineteenth ACM–SIAM Symposiumon Discrete Algorithms (SODA-08). This work was also presented at the Dagstuhl Workshop on Computational Issues in Social Choice, October 2007.* Corresponding author.E-mail addresses: michez@cs.huji.ac.il (M. Zuckerman), arielpro@gmail.com (A.D. Procaccia), jeff@cs.huji.ac.il (J.S. Rosenschein).1 The author thanks Noam Nisan for a generous grant which supported this work.2 The author was supported in this work by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.005\fM. Zuckerman et al. / Artificial Intelligence 173 (2009) 392–412393Indeed, Bartholdi et al. [3] put forward a voting rule where manipulation is N P -hard. In another important paper,Bartholdi and Orlin [2] greatly strengthened the approach by proving that the important Single Transferable Vote (STV) ruleis hard to manipulate.This line of research has enjoyed new life in recent years thanks to the influential work of Conitzer, Sandholm, andLang [7].3 The foregoing paper studied the complexity of coalitional manipulation. In this setting, there is a coalition ofpotentially untruthful voters, attempting to coordinate their ballots so as to get their favorite candidate elected. The authorsfurther assume that the votes are weighted: some voters have more power than others. Conitzer et al. show that in avariety of prominent voting rules, coalitional manipulation is N P -hard, even if there are only a constant number of candidates(for more details, see Section 2). This work has been extended in numerous directions, by different authors [5,8,12,18,25];Elkind and Lipmaa [9], for example, strengthened the abovementioned results about coalitional manipulation by employingcryptographic techniques.In short, computational complexity is by now a well-established method of circumventing the Gibbard–SatterthwaiteTheorem. Unfortunately, a shortcoming of the results we mentioned above is that they are worst-case hardness results,and thus provide a poor obstacle against potential manipulators. Recent work regarding the frequency of manipulation hasargued that with many worst-case hard-to-manipulate voting rules, a potential manipulator may be able to compute amanipulation in typical settings [6,13]. In particular, Procaccia and Rosenschein [23,24] have established some theoreticalresults regarding the frequency of success of an algorithm for the coalitional manipulation problem. The matter was furtherdiscussed by Erdélyi et al. [11]. In spite of this, the question of the tractability of the manipulation problem, and in particularof the coalitional manipulation problem, in typical settings is still wide-open.Our approach and results We wish to convince the reader that, indeed, the coalitional manipulation problem can be effi-ciently solved in typical settings under some prominent voting rules, but our approach differs from all previous work. Wepresent efficient heuristic algorithms for the problem that provide theoretical guarantees. Indeed, we characterize smallwindows of instances on which our algorithms may fail; the algorithms are proven to succeed on all other instances.Specifically, we prove the following results regarding three of the most prominent voting rules (in which coalitionalmanipulation is known to be N P -hard even for a constant number of candidates):Theorem.1. In the Borda rule, if there exists a manipulation for an instance with certain weights, Algorithm 2 will succeed when given an extramanipulator with maximal weight.2. In the Plurality with Runoff rule, if there exists a manipulation for an instance with certain weights, Algorithm 3 will succeed whengiven an extra manipulator with maximal weight.3. In the Maximin rule, if there exists a manipulation for an instance with certain weights, Algorithm 1 will succeed when given twocopies of the set of manipulators.Significance in Artificial Intelligence The sharply increased interest in computational aspects of voting is motivated by numer-ous applications of voting techniques and paradigms to problems in Artificial Intelligence (AI). These applications includework in AI subfields as diverse as Planning [10], Automated Scheduling [17], Recommender Systems [14], Collaborative Fil-tering [22], Information Extraction [27], and Computational Linguistics [21].Unfortunately, in the application of voting to AI, some of the problems investigated in Social Choice Theory, and in par-ticular the issue of manipulation, become especially acute. Indeed, multiagent systems are often inhabited by heterogeneous,self-interested agents. Such agents, unlike human beings, can be designed to be rational, and constantly engaged in com-putations meant to increase their utility. In particular, a self-interested agent could seize the opportunity to manipulate anelection to its benefit if such an opportunity were computationally easy to recognize (unless specifically programmed notto).The agenda of circumventing the Gibbard–Satterthwaite Theorem via computational complexity is, once again, mostrelevant and compelling when the voters are software agents that populate a multiagent system, since the effective, boundedrationality of such agents is practically governed by the laws of computational complexity. This is why the agenda hasbecome a prominent one in AI, with numerous papers on the subject published in the major AI conferences over the lastfive years. As of yet, there are few papers on frequency of manipulation, rather than on its worst-case complexity. We feelthat this line of work on frequency of manipulation may influence the entire direction of the computational social choiceresearch agenda (see Section 5 for more details regarding work on frequency of manipulation).Structure of the articleIn Section 2 we describe the major voting rules and formulate the coalitional manipulation problem.In Section 3 we present and analyze our algorithms in three subsections: Borda, Plurality with Runoff, and Maximin. Weprovide some results regarding an unweighted setting in Section 4. In Section 5 we describe related work at length. Finally,we discuss our approach in Section 6.3 Historical note: although we cite the JACM 2007 paper, this work originated in a AAAI 2002 paper.\f394M. Zuckerman et al. / Artificial Intelligence 173 (2009) 392–4122. Voting rules and manipulation problemsAn election consists of a set C = {c1, . . . , cm} of candidates and a set S = {v 1, . . . , v|S|} of voters. Each voter provides atotal order on the candidates. To put it differently, each voter submits a ranking of the candidates. The voting setting alsoincludes a voting rule, which is a function from the set of all possible combinations of votes to C .We shall discuss the following voting rules (whenever the voting rule is based on scores, the candidate with the highestscore wins):• Scoring rules. Let (cid:3)α = (cid:4)α1, . . . , αm(cid:5) be a vector of non-nega",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 250 (2017) 58–79Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA progression semantics for first-order logic programsYi Zhou a,b,∗a School of Computing, Engineering and Mathematics, Western Sydney University, Sydney, Australiab School of Computer Science and Technology, TianJin University, TianJin, Chinac School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China, Yan Zhang a,ca r t i c l e i n f oa b s t r a c tArticle history:Received 21 August 2015Received in revised form 19 May 2017Accepted 6 June 2017Available online 9 June 2017Keywords:Logic programmingStable modelProgressionFirst-order1. IntroductionIn this paper, we propose a progression semantics for first-order normal logic programs, and show that it is equivalent to the well-known stable model (answer set) semantics. The progressional definition sheds new insights into Answer Set Programming (ASP), for instance, its relationships to Datalog, First-Order Logic (FOL) and Satisfiability Modulo Theories (SMT). As an example, we extend the notion of boundedness in Datalog for ASP, and show that it coincides with the notions of recursion-freeness and loop-freeness under program equivalence. In addition, we prove that boundedness precisely captures first-order definability for normal logic programs on arbitrary structures. Finally, we show that the progressional definition suggests an alternative translation from ASP to SMT, which yields a new way of implementing first-order ASP.© 2017 Elsevier B.V. All rights reserved.Answer Set Programming (ASP) has emerged as a predominant approach for nonmonotonic reasoning in the area of knowledge representation and reasoning due to its simplicity, expressive power and computational advantage [6,20,33,34]. At its beginning, the stable model (answer set) semantics for first-order logic programs is defined only on Herbrand Struc-tures by grounding into propositional programs [21,22]. In recent years, a number of approaches have been developed to release this restriction by directly defining the stable model semantics on arbitrary structures [4,5,7,10,15,18,24,26,28,31,36,38,40,42].A typical approach on this research line is to use a translation to another host language, e.g. second-order language [18] or circumscription [31]. For this purpose, second-order is inevitable as the class of the stable models of some logic programs, e.g. transitive closure, cannot be captured in first-order logic [16]. Under this backdrop, a first-order logic pro-gram (cid:2) is transformed to a corresponding second-order sentence S M((cid:2)), and the stable models of (cid:2) are defined as the models of S M((cid:2)) [18]. While this definition provides a precise mathematical representation and also generalizes the tradi-tional propositional ASP, it, however, does not reveal much information about the expressiveness of first-order answer set programming. For instance, it is unclear whether we can provide a complete characterization of first-order definability for first-order ASP.In this paper, we propose a progressional definition for first-order normal logic programs. Intuitively, this definition may be viewed as a generalization of the Gelfond–Lifschitz transformation [6] to the first-order case as well as a generalization of the progression semantics for Datalog [1,32]. Also, it shares some fundamental ideas with Reiter’s semantics for default * Corresponding author.E-mail address: yzhou@scm.uws.edu.au (Y. Zhou).http://dx.doi.org/10.1016/j.artint.2017.06.0010004-3702/© 2017 Elsevier B.V. All rights reserved.\fY. Zhou, Y. Zhang / Artificial Intelligence 250 (2017) 58–7959logic [37]. Simply enough, in the progressional definition, a first-order structure M is a stable model of a first-order normal logic program (cid:2) if and only if it is the fixed point of the progression of (cid:2) with respect to M. More precisely, M coincides with the structure obtained by recursively applying the rules in (cid:2), where the negative parts are fixed by M itself. We show that, for normal logic programs, this progressional definition is equivalent to the general stable model semantics defined by S M((cid:2)).The progressional definition sheds new insights into Answer Set Programming (ASP), for instance, its relationships to Datalog, First-Order Logic (FOL) and Satisfiability Modulo Theories (SMT). It can be further evident from the progressional definition that Datalog is exactly the monotonic counterpart of ASP, and many important Datalog techniques can be ap-plied to ASP as well. Based on the proposed progressional definition, we are able to define the notion of boundedness for first-order answer set programs, which is critical for understanding the relationship between first-order ASP and classical first-order logic.With the features of iterative and nonmonotonic reasoning, ASP is a representative rule-based formalism that is signifi-cantly different from classical logics. Nevertheless, ASP and classical logics are very closely related. Hence, the relationships between them have attracted a lot of attention in the literature [4,5,12–14,17,25,26,39]. Among them, a central topic is first-order definability, that is, what kind of answer set programs can be captured in classical first-order logic in the sense that their answer sets/stable models are exactly the classical models of a first-order sentence. Our notion of boundedness provides a complete answer for this. We prove that an answer set program is first-order definable if and only if it is bounded. Moreover, the notion of boundedness/first-order definability is also equivalent to two important syntactic notions of recursion-freeness and loop-freeness (tightness) under program equivalence. We believe that results in this aspect will establish a foundation for the further study of the expressiveness and related properties of first-order ASP.The progressional definition is not only of theoretical interest but also of practical relevance as it directly yields a new translation from first-order ASP to Satisfiability Modulo Theories (SMT). Comparing this translation to the one obtained from ordered completion [4,5], it is logically stronger as it has less models.This paper is organized as follows. Section 2 introduces necessary backgrounds. Section 3 proposes the progressional definition and shows that it is equivalent to the translational definition. Then, Section 4 extends the notion of boundedness in Datalog for ASP and shows that it is equivalent to the notions of recursion-freeness and loop-freeness under program equivalence. Section 5 further shows that boundedness exactly captures first-order definability of ASP. Section 6 reports a natural translation from first-order ASP to SMT based on the progressional definition. Finally, Section 7 discusses some related and ongoing works and Section 8 concludes the paper respectively.2. PreliminariesAiWe start with necessary logical notions and notations. We consider a second-order language without function symbols but with equality. A vocabulary τ is a set that consists of relation symbols (or predicates) including the equality symbol = and constant symbols (or constants). Each predicate is associated with a natural number, called its arity. Given a vocabulary, term, atom, substitution, (first-order and second-order) formula and (first-order and second-order) sentence are defined as usual. In particular, an atom is called an equality atom if it has the form t1 = t2, where t1 and t2 are terms. Otherwise, it is called a proper atom.A structure A of vocabulary τ (or a τ -structure) is a tuple A = ( A, ccalled the domain of A, cover A for every k-ary predicate P j in τ . Pa finite set. In this paper, we consider both finite and infinite structures.AA1 , · · · , Pn ), where A is a nonempty set A(1 ≤ j ≤ n) is a k-ary relation(1 ≤ i ≤ m) is an element in A for every constant ci in τ , and Pjis also called the interpretation of P j in A. A structure is finite if its domain is A1 , · · · , cAm , P−→x ) be an atom, η an assignment in structure A. For convenience, we also write P (Let A be a structure of τ . An assignment in A is a function η from the set of variables to A. An assignment can be , where c is an arbitrary constant. −→x )η ∈ A for the fact that . The satisfaction relation |= between a structure A and a formula φ associated with an assignment η, denoted −→x be the set of free variables occurring in a formula φ. Then, the satisfaction relation −→a ) for convenience, −→a is a tuple of elements in A. In particular, if φ is a sentence, then the satisfaction relation is independent of the −→a ), where P is a predicate −→a ), to denote extended to a corresponding function from the set of terms to A by mapping η(c) to cLet P (−→x ) ∈ Pη(by A |= φ[η], is defined as usual. Let is independent from the assignment of variables not in where assignment. In this case, we simply write A |= φ for short. A ground atom in A is of the form P (−→and a a tuple of elements that matches the arity of P . For convenience, we also use P (−→a ∈ P−→x . In this case, we also write A |= φ(−→a ) ∈ A, or A |= P (−→x /AjAAA.Given a structure A of τ , Q a predicate in τ and some ground atoms Q (−→an }.−→a1 , . . . , to denote a new structure of τ which is obtained from A by expanding the interpretation of predicate Q in A (i.e. QQA ∪ {Let A1 and A2 be two structures of τ sharing the same domain, and for each constant c in τ , cA2 . By A1 ⊆ A2, A2 . By A1 ⊂ A2, we mean that A1 ⊆ A2 but not A2 ⊆ A1. We we simply mean that for each predicate P ∈ τ , Pwrite A1 ∪ A2 to denote the structure of τ where the domain of A1 ∪ A2 is the same as A1 and A2’s domain, each constant c is interpreted in the same way as in A1 and A2, and for each predicate P in τ , PA1∪A2 = PA1 ⊆ PA1 ∪ PA1 = cA2 .−→a1 ) ,. . . , Q (−→a n), we use A ∪{Q (−→−→an )}a1 ), . . . , Q (A) to \f60Y. Zhou, Y. Zhang / Arti",
            {
                "entities": [
                    [
                        134,
                        188,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1153–1179Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecision making with multiple objectives using GAI networksC. Gonzales, P. Perny∗, J.Ph. DubusLIP6 – Université Pierre et Marie Curie, case 169, 4 place jussieu, 75005 Paris, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 28 February 2009Received in revised form 20 July 2010Accepted 15 September 2010Available online 2 December 2010Keywords:Graphical modelsGAI decomposable utilityPreference representationMultiobjective optimizationMultiagent decision makingCompromise searchFairness1. IntroductionThis paper deals with preference representation on combinatorial domains and preference-based recommendation in the context of multicriteria or multiagent decision making. Thealternatives of the decision problem are seen as elements of a product set of attributesand preferences over solutions are represented by generalized additive decomposable (GAI)utility functions modeling individual preferences or criteria. Thanks to decomposability,utility vectors attached to solutions can be compiled into a graphical structure closelyrelated to junction trees, the so-called GAI network. Using this structure, we presentpreference-based search algorithms for multicriteria or multiagent decision making.Although such models are often non-decomposable over attributes, we actually showthat GAI networks are still useful to determine the most preferred alternatives providedpreferences are compatible with Pareto dominance. We first present two algorithms for thedetermination of Pareto-optimal elements. Then the second of these algorithms is adaptedso as to directly focus on the preferred solutions. We also provide results of numerical testsshowing the practical efficiency of our procedures in various contexts such as compromisesearch and fair optimization in multicriteria or multiagent problems.© 2010 Elsevier B.V. All rights reserved.The complexity of decision problems in organizations, the importance of the issues raised and the increasing need toexplain or justify any decision has led decision makers to seek a scientific support in the preparation of their decisions. Formany years, rational decision making was understood as solving a single-objective optimization problem, the optimal deci-sion being implicitly defined as a feasible solution minimizing a cost function under some technical constraints. However,the practice of decision making in organizations has shown the limits of such formulations. First, there is some diversityand subjectivity in human preferences that requires distinguishing between the objective description of the alternatives of achoice problem and their value as perceived by individuals. In decision theory, alternatives are often seen as multiattributeitems characterized by a tuple in a product set of attributes domains, the preferences of each individual being encoded by autility function defined on the multiattribute space measuring the relative attractiveness of each tuple. Hence the objectivesof individuals take the form of multiattribute utility functions to be maximized. Typically, in a multiagent decision problem,we have to deal with several such utility functions that must be optimized simultaneously. Since individual utilities are gen-erally not commensurate, constructing an overall utility function gathering all relevant aspects is not always possible. Hencethe problem does not reduce to a classical single-objective optimization task; we have to solve a multiobjective problem.Moreover, even when there is a single decision maker, several points of views may be considered in the preferenceanalysis, leading to the definition of several criteria. Rationality in decision making is generally not only a matter of costsreduction. In practice, other significant aspects that are not reducible to costs must be included in the analysis; the outcomes* Corresponding author.E-mail addresses: kaveh@river-valley.com (C. Gonzales), patrice.perny@lip6.fr (P. Perny), cvr@river-valley.com (J.Ph. Dubus).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.020\f1154C. Gonzales et al. / Artificial Intelligence 175 (2011) 1153–1179of alternatives must be thought in a multidimensional space. This is the case in the elaboration of public policies wheredifferent aspects such as ecology and environment, education, health, security, public acceptability are considered in theevaluation process. This is also the case for individual decision of consumers. For example, when choosing a new car for afamily, an individual will look at the cost, but will also consider several multiattribute utility functions concerning security inthe car (brake system, airbags, . . . ), velocity (speed, acceleration, . . . ), space (boot size, . . . ), environmental aspects (pollution)and aesthetics (color, shape, brand, . . . ). All these observations have motivated the emergence of multicriteria methodologiesfor preference modeling and human decision support [1–4], an entire stream of research that steadily developed for fortyyears.As for human decision making, automated decision making in complex environment requires optimization proceduresinvolving multiple objectives. This is the case when computers are used for planning actions of autonomous agents or for or-ganizing the workflow in production chains. Various other examples can be mentioned such as web search [5], e-commerceand resource allocation problems. In many of them, however, a decision is actually characterized by a combination of lo-cal decisions, thus providing the set of alternatives with a combinatorial structure. This explains the growing interest formultiobjective combinatorial optimization. Besides the explicit introduction of several possibly conflicting objectives in theevaluation process, the necessity of exploring large size solution spaces is an additional source of complexity. This hasmotivated the development in the AI community of preference representation languages aiming at simplifying preferencehandling and decision making on combinatorial domains.As far as utility functions are concerned, the works on compact representation aim at exploiting preference independenceamong some attributes so as to decompose the utility of a tuple into a sum of smaller utility factors. Different decompositionmodels of utilities have been developed to model preferences. The most widely used assumes a special kind of independenceamong attributes called “mutual preferential independence”. It ensures that preferences are representable by an additivelydecomposable utility [6,7]. Such decomposability makes both the elicitation process and the query optimizations very fastand simple. However, in practice, preferential independence may fail to hold as it rules out any interaction among attributes.Generalizations have thus been proposed in the literature to significantly increase the descriptive power of additive utilities.Among them, multilinear utilities [2] and GAI (generalized additive independence) decompositions [8,9] allow quite generalinteractions between attributes [7] while preserving some decomposability. The latter has been used to endow CP nets withutilities (UCP nets) both under uncertainty [10] and under certainty [11]. GAI decomposable utilities can be compiled intographical structures closely related to junction trees, the so-called GAI networks. They can be exploited to perform classicaloptimization tasks (e.g. find a tuple with maximal utility) using a simple collect/distribute scheme essentially similar tothat used in the Bayes net community or to variable elimination algorithms in CSP [12–15]. In order to extend the useof GAI nets to multiobjective optimization tasks, we investigate the potential of GAI models for representing and solvingmultiobjective optimization problems.As soon as multiple criteria or utility functions are considered in the evaluation of a solution, the notion of optimality isnot straightforward. Among the various optimality criteria, the concept of Pareto optimality or efficiency is the most widelyused. A solution is said to be Pareto-optimal or efficient if it cannot be improved on one criterion without being depreciatedon another one. Pareto optimality is natural because it does not require any information about the relative importance ofcriteria and can be used as a preliminary filter to circumscribe the set of reasonable solutions in multiobjective problems.However, in combinatorial optimization problems, the complete enumeration of Pareto-optimal solutions is often infeasiblein practice [16–18]. For this reason, in many real applications, people facing such complexity resort to artificial simplifica-tions of the problem, either by focusing on the most important criterion (as in route planning assistants), or by performinga prior linear aggregation of the criteria to get a single objective version of the problem, or by generating samples of goodsolutions using heuristics, which in any case does not provide formal guarantees on the quality of the solutions.In this paper, we assume that each objective is represented by a GAI decomposable utility function defined on themultiattribute space describing items. In Section 2, after recalling basic definitions related to GAI nets, we show how theymake it possible to represent vector-valued utility functions in a compact form, thus facilitating preference handling inmultiobjective decision-making problems. In Section 3, we present two exact algorithms exploiting the structure of theGAI net for the determination of Pareto-optimal elements. In Section 4 we propose a refinement of the second algorithmaiming at focusing the search on specific compromise solutions within the Pareto set. We provide exact algorithms forpreference-based search with various preference models. The potential of this approach is illustrated in the",
            {
                "entities": [
                    [
                        138,
                        197,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1183–1186www.elsevier.com/locate/artintLevel-headedDrew McDermottYale University, USAAvailable online 10 October 2007AbstractI don’t believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more aboutthinking and computation, the mileposts will keep changing in ways that we can’t predict, as will the esteem we assign to pastaccomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusingon such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understandhardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus,when we can talk to machines, will we understand each other?© 2007 Published by Elsevier B.V.Keywords: Speculation; Methodology; Natural languageThe question when and how we will attain human-level artificial intelligence is hard to answer because it is soill-posed. It’s like asking a biologist in 1820 how and when Frankenstein’s monster would become a reality, replacingFrankenstein with Turing.1 The history of biology is the history of attacking and solving small technical problemsone after another, with many blind alleys. At the end, the goal of knitting parts of dead people together to make a newperson just doesn’t seem as attractive as it once did.There’s no reason to suppose AI will be any different. Although some old-timers decry our loss of the vision thefield exhibited 50 years ago, this sort of loss is exactly what we would hope for. By contrast, phrenology never turnedinto a real science, and was cranking out the same kind of broadly scoped, superficial, and unverifiable observationsat the end as it had at its start.2The phrase “human-level” subtly presupposes that we are measuring skills along one dimension. Humans standat one altitude, far above fungi and cats, and we are pushing machines up the hill as though moving pianos. Butintelligence is the ability to imagine. There are as many different kinds of intelligence as there are kinds of imagination.A computer solving a complex resource-allocation task already surpasses humans in the ability to imagine ways toallocate the resources. Computer programs will eventually have many such skills, but there will never be a time wheretheir total “equals” those of the average human.I consider it likely that as we solve one technical problem after another—and waste time on several promisingideas that go nowhere—we will eventually get a picture of how computation and thought fit together that we simplycan’t envisage. When I say “we,” I don’t mean the AI community by itself, but the entire cognitive-science commu-E-mail address: drew.mcdermott@yale.edu.1 Turing was his own Mary Shelley.2 Just spend some time with a few issues of the American Phrenological Journal, published from 1838 to 1911.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.10.013\f1184D. McDermott / Artificial Intelligence 171 (2007) 1183–1186nity, defined as all disciplines based on the working hypothesis that the important processes going on in brains arecomputational. AI gets its ideas from computer science, psychology, linguistics, neuroscience, and occasionally evenphilosophy. It gives back algorithms and empirical evidence that they work (mathematical proofs of competence beingrare in this business).It seems to me that arguments such as Kurzweil’s [1] that exponential growth in computer science is bound toproduce superhuman intelligence, and breath-takingly fast as we near that apotheosis, are flawed by the fact that wedon’t know what we’re measuring. Grant that you can fit an exponential curve to scientific output to date in anydiscipline; will it be the same curve from century to century? Whenever there is a scientific revolution, much of whatpassed for important advances suddenly becomes distracting filler. One now sees the history of that field in terms of anobscure but luminous path leading up to the new insight, which now precedes the so-called “knee” of the exponentialthat we thought we had already seen.3 This is not a rare phenomenon. In our own lifetime4 we have seen a dramaticchange in our understanding of learning. In 1950 it seemed that behaviorism was on the verge of explaining the entirehuman psyche in terms of some simple learning mechanisms. Time magazine even adopted the title “Behavior” for itssection on human psychology. A graph of the progress of learning theory measured by papers published and number ofrats explained would have shown exponential growth. Now we use learning algorithms to sift through huge masses ofdata, but they work within sharp limits set by computational learning theory. In retrospect, behaviorism didn’t even askthe right questions, including most notably: How do the rats compute the relevant properties of the current situation?A revised graph of progress in the field would sharply discount all those rat runners and display quiet exponentialgrowth leading from mathematical logic and empirical linguistics through Chomsky, Valiant, and their successors intoa profusion of applications.When people demand human-level intelligence, they often think in terms of an example such as this one:In my office I have a device for showing the day of the month. It consists of two little wooden cubes, each of whichhas a digit inscribed on each face. So there are a total of 12 faces, 6 per cube. To display today’s date, you select onecube and face for the tens digit and one for the ones digit. The same cube need not always occupy the same position;sometimes one is in the tens position, sometimes the other. Single-digit days are displayed as 0d. (The month is shownon a separate set of wooden pieces, which need not concern us.)I would be very impressed if a computer could prove that such a date-display system was impossible, by thefollowing argument: We’re going to need a 0, 1, and 2 on each cube. That’s because not all the digits from 1 to 9 willfit on one cube, and 0, 1, and 2 must appear in the tens position opposite each of them. So 0, 1, and 2 must occupy6 faces. But that leaves just 6 faces for the 7 digits above 2. “QED”In spite of this proof, I really do have such a date-display system in my office. So there must be a trick. At thispoint a person might start trying to physically construct the cube, by laying out face arrangements on paper that couldbe folded into a cube. Actually, a person would almost certainly start trying to construct the cube before going off toprove that it was impossible. The lemma that there must be two each of the digits 0, 1, and 2 would be arrived in theprocess of trying to do the construction, and the constructor would quickly realize that this posed a serious problem.Presumably, during the construction process the constructor would realize that how the sides folded up was irrel-evant. Any assignment of digits to a cube would be as good as any other, so long as there’s a 0, 1, and 2 on eachcube. On the other hand, they might keep in the mind that they’re operating in a weird zone where they “know” theenterprise is doomed, so they might reserve the right to go back and consider the physical arrangement later.In the process of writing the digits down, the person might somehow realize (don’t ask me how) that a 6 and a9 look very similar, and then realize that we can use one cube face for both, provided we pick a font in which turningthe 6 over makes it into a presentable 9. So the seven digits will fit on six faces! After that insight, it will become clearthat any assignment of the digits 3–8 to the two cubes will work.What would it take for a computer to solve this problem? One might argue that the computer would have to beembodied as a robot so that it could write the digits out and see the similarity between 6 and 9. I really don’t see whythe process wouldn’t work just as well in the mind’s eye. The important ability the machine must have is to makesimplifying assumptions away from the full physical reality of characters stamped on wood, and yet to make goodguesses about which of those assumptions to revoke when trouble arises. Two such simplifications are to think of the3 Why “knee”? It looks more like an elbow to me. Anyway, it’s an optical illusion, of course; draw the curve at a different scale and the knee willappear wherever you want it to.4 “Our” here refers to us old-timers.\fD. McDermott / Artificial Intelligence 171 (2007) 1183–11861185digits as arbitrary tokens whose only property is to represent a number between 0 and 9, and to assume that one canneglect the orientation of the visible face of a cube. What strikes one as “intelligent” about the ability to solve thisproblem is the choice of what assumption to question; it wouldn’t help to think about the position of the digits on eachface, or the possibility of using different colors for different digits, or whether the cubes could be made of cedar orpine.I did not solve the calendar problem myself; my wife5 got the little wooden gadget at an office-party gift exchange,and we don’t know who created it. Obviously, at least one person figured out how to make it, but who knows whatpercentage of the human population could? My guess is very few.6People are seldom just presented with problems like this one in cold, precise paragraphs. Instead, they must engagein conversations about them, just to get clear on what the problem is. Even if they ask no other questions, after theireureka moment they would surely ask/shout, “Is it okay to use one face to represent both the 6 and the 9?!” I willreturn to this key point below.We might suppose that we have not reached human-level intelligence until we have a program that can solve thispuzzle, and the “mutilated checkerboard” [2], and some other brain teasers. But why stop there? We could perhapsalso demand that it compo",
            {
                "entities": [
                    [
                        74,
                        86,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 437–465Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing the fault tolerance of multi-agent deployment ✩Yingqian Zhang a,∗, Efrat Manisterski b, Sarit Kraus b,c, V.S. Subrahmanian c, David Peleg da Faculty of Electrical Engineering, Mathematics, and Computer Science, Delft University of Technology, 2628 CD Delft, The Netherlandsb Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900 Israelc Department of Computer Science & UMIACS, University of Maryland, College Park, MD 20742, USAd Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot 76100, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 11 June 2007Received in revised form 12 November 2008Accepted 14 November 2008Available online 25 November 2008Keywords:Multi-agent deploymentFault toleranceAlgorithmsReplicationA deployment of a multi-agent system on a network refers to the placement of oneor more copies of each agent on network hosts, in such a manner that the memoryconstraints of each node are satisfied. Finding the deployment that is most likely totolerate faults (i.e. have at least one copy of each agent functioning and in communicationwith other agents) is a challenge.In this paper, we address the problem of findingthe probability of survival of a deployment (i.e. the probability that a deployment willtolerate faults), under the assumption that node failures are independent. We show thatthe problem of computing the survival probability of a deployment is at least NP-hard.Moreover, it is hard to approximate. We produce two algorithms to accurately compute theprobability of survival of a deployment—these algorithms are expectedly exponential. Wealso produce five heuristic algorithms to estimate survival probabilities—these algorithmswork in acceptable time frames. We report on a detailed set of experiments to determinethe conditions under which some of these algorithms perform better than the others.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThere have been tremendous advances in the last decade in the theory and implementation of massive multi-agent sys-tems. However, one major obstacle to the wider deployment of multi-agent systems (MASs) is their capability of toleratingfailures. MASs that are deployed across a network can quickly “go down” due to external factors such as power failures,network outages, malicious attacks, and other system issues. Protection against such unexpected failures that disable a nodeis critical if agents are to be used as the backbone for real world applications.Clearly, ensuring that MASs are safe and protected involves a vast range of technologies that must authenticate users andagents, ensure secure communications, identify vulnerabilities, and identify and quarantine attacks. Our goal in this paperis far more modest, and concerns the way replication can form the basis of one tool (amongst many that are needed) toprevent a MAS from succumbing to failure. By replicating agents, we hope to improve the fault tolerance of a multi-agentsystem. The faults considered in this paper are those that cause disconnection (or crash) of the nodes in the network where✩This article is the extended version of the paper which appeared in the Second IEEE Symposium on Multi-Agent Security and Survivability [Y. Zhang,E. Manister, S. Kraus, V.S. Subrahmanian, Approximation results for probabilistic survivability, in: Second IEEE Symposium on Multi-Agent Security andSurvivability, Philadelphia, USA, 2005, pp. 1–10]. This research was supported in part by the Technology Foundation STW, applied science division of NWO,and the Ministry of Economic Affairs of the Netherlands, by grant N6133906C0149, in part by ARO grant DAAD190310202, AFOSR grants FA95500610405,FA95500510298, NSF grant 0540216, NSF grant 0705587, and ISF grant 1685/07.* Corresponding author.E-mail addresses: yingqian.zhang@tudelft.nl (Y. Zhang), manister@macs.biu.ac.il (E. Manisterski), sarit@macs.biu.ac.il (S. Kraus), vs@cs.umd.edu(V.S. Subrahmanian), david.peleg@weizmann.ac.il (D. Peleg).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.007\f438Y. Zhang et al. / Artificial Intelligence 173 (2009) 437–465the MAS application resides. The fault model that we consider is one where the failure of each node in the network isrepresented by a probability. Given such a fault model, agents that locate on the nodes have different probabilities to beunavailable, and therefore the multi-agent system as a whole has some probability of being out of function. The idea ofusing replication as a fault tolerance method in our work is thus that, when facing failures, at least one copy of each agentwill continue to reside on a connected, working host computer (node), so that the MAS as a whole can function as a unifiedapplication. Furthermore, in this paper, we focus on the problem of measuring the probability that a multi-agent system willtolerate the node failure. We call this probability the survivability1 of a MAS system.For example, consider the CoAX [2,35] Coalition Agent Experiment in which a large, multinational team2 of universities,companies and government labs pieced together an experimental multi-agent application in which a set of sensory agentsdeployed in an ocean tracked enemy submarines. These sensory agents fed data to prediction agents that predicted when,where, and with what probability the submarine would be in a given location. Thereafter a whole set of decision making andvisualization agents assisted a decision maker in determining how best to proceed. All these agents were supported, in turn,by other agents such as agents assessing trustworthiness of a source, database agents, resource discovery agents, and thelike. In applications such as CoAX, it is quite likely that some nodes will “go down” or “get disconnected” from the network.Any enemy sophisticated enough to use jamming technology would also make efforts to jam the network, effectively causingsome agents to have no connectivity. Thus, critical agents such as the prediction agents and the decision making agents needto be appropriately located and replicated so that the whole multi-agent system has a high probability of functioning. Ofcourse, it is assumed that the physical hardware (sensors) are already replicated to support sensor failures—this paper doesnot address how to replicate physical devices.Likewise, consider the exhaustive set of deployed multi-agent applications listed in [36]. According to their description,Skoda—a branch of Volkswagen—deployed an agent based production planning tool for manufacturing car engines. Theirmulti-agent solution looked both at low level planning and high level planning. High levels plans are examined by a set oflow level planning agents that try to achieve a part of the high level plan and flag conflicts and inconsistencies in the highlevel plan. A back and forth process ensures, once a consensus is achieved, the production plans are sent to higher levelagents who use resource allocation mechanisms to execute these plans on the production line. It is clear that in criticalapplications such as these, any node “going down” (for whatever reason) has the potential to cause the production line tocome to a grinding halt, leading to a loss of revenue for the company.Tichy et al. [42] describe a multi-agent system for the control of several components of a ship so as to reduce man-power requirements, while still ensuring highly reliable and survivable operation of the ship. They develop a hierarchicalmulti-agent architecture in which agents are embedded within hardware controllers and higher level agents coordinate andmonitor the activities of groups of agent-enhanced hardware controllers. The agents are continuously engaged within a plancreation, plan commitment, and plan execution cycle. Here too, it is clear that when agents are in control of a physicalenvironment (the ship in this case) there is high potential that the overall environment being controlled by the MAS canbe adversely affected whenever an agent “goes down”. In any situation where hardware components exist (and certainly onships), there is a possibility that hardware components will fail—for simple reasons or for more complex reasons such asthe actual physical movement of the ship and/or the oceanographic and climactic conditions with which the ship is forcedto contend. Thus, mechanisms are needed so that MASs can be deployed in a survivable manner even if some agents godown. Furthermore, it is important to calculate the guaranteed probability that the system will survive.Fault tolerance and replication techniques have been extensively studied in distributed computing systems [4,10,20,31,43],but much less so in the multi-agent systems domain [5,16,29,33]. Building a fault tolerant distributed system is notoriouslyhard. The autonomy of agents in multi-agent systems such as CoAX makes this task even more difficult. In this paper, webuild upon the framework of [27], which defined the probability that a given deployment of a MAS3 will survive, consideredthe basic problem of deployment survivability, and proposed methods for finding most survival deployments. Zhang et al. [45]also consider the complexity of the problem of finding the most survivable deployment. That is, the complexity of finding thedeployment with the highest survival probability, given a MAS deployment.The model of [27] assumes ignorance about the dependencies between node failures. However, this assumption is notalways valid. For example, an attack on Cornell’s web site is—in all likelihood—independent of the Israeli Defence Ministry’sweb site going down. The framework proposed in [27] cannot handle this. The algorithm developed in [27] for finding themost survivable deployment of agents on the network only works under the ignorance assu",
            {
                "entities": [
                    [
                        136,
                        191,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 382–391www.elsevier.com/locate/artintPerspectives on multiagent learning ✩Tuomas SandholmCarnegie Mellon University, Computer Science Department, Pittsburgh, PA 15213, USAReceived 18 May 2006; received in revised form 27 February 2007; accepted 27 February 2007Available online 30 March 2007AbstractI lay out a slight refinement of Shoham et al.’s taxonomy of agendas that I consider sensible for multiagent learning (MAL)research. It is not intended to be rigid: senseless work can be done within these agendas and additional sensible agendas mayarise. Within each agenda, I identify issues and suggest directions. In the computational agenda, direct algorithms are often moreefficient, but MAL plays a role especially when the rules of the game are unknown or direct algorithms are not known for theclass of games. In the descriptive agenda, more emphasis should be placed on establishing what classes of learning rules actuallymodel learning by multiple humans or animals. Also, the agenda is, in a way, circular. This has a positive side too: it can be usedto verify the learning models. In the prescriptive agendas, the desiderata need to be made clear and should guide the design ofMAL algorithms. The algorithms need not mimic humans’ or animals’ learning. I discuss some worthy desiderata; some from theliterature do not seem well motivated. The learning problem is interesting both in cooperative and noncooperative settings, but theconcerns are quite different. For many, if not most, noncooperative settings, future work should increasingly consider the learningitself strategically.Lower bounds cut across the agendas. They can be derived on the computational complexity and on the number of interactionsneeded.© 2007 Elsevier B.V. All rights reserved.Keywords: Multiagent learning; Learning in games; Reinforcement learning; Game theory1. IntroductionLearning from experience is a key capability because one may not be able to devise a good strategy (a plan forall possible contingencies) in advance—even with the help of computers. In multiagent settings, learning may beneeded because the opponents’ strategies are unknown, because the rules of the game are unknown, or because it iscomputationally too complex to solve for a good strategy with other means. Multiagent learning (MAL) is complicatedby the fact that the other agents may be learning as well (or changing their exploration behavior [61]), thus makingthe environment nonstationary for a learner. MAL has been studied with different objectives as well as with differentrestrictions on the game and on what the learners can observe.✩ This work was supported by the National Science Foundation under ITR grants IIS-0121678 and IIS-0427858, and a Sloan Fellowship.E-mail address: sandholm@cs.cmu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.004\fT. Sandholm / Artificial Intelligence 171 (2007) 382–391383Fig. 1. Taxonomy of agendas for multiagent learning research.2. On agendas for multiagent learningIn their paper “If multi-agent learning is the answer, then what is the question?”, Shoham et al. make an importantcontribution by laying out five agendas of (and for) MAL. I present a refinement of that taxonomy in Fig. 1. Itis consistent with their view, but adds hierarchy (and renames the “normative” agenda as “learning algorithms inequilibrium”). In the rest of this section, I will comment on the agendas using this taxonomy.2.1. Computational agendaWhile some MAL algorithms can, at least in principle, be used for equilibrium finding, they tend to be significantlyless efficient than the best direct equilibrium-finding algorithms. For example, MAL algorithms have been able tosolve only tiny poker games while direct techniques have been able to find the exact equilibrium of poker games upto, and including, the game of Rhode Island Hold’em, which has 3.1 billion nodes in the game tree [32].If one’s goal is equilibrium finding, there seems to be little reason to use MAL algorithms. There has been tremen-dous recent progress on faster algorithms for equilibrium finding in normal form games [58,62], graphical games [42,71], sequential games of perfect information [64], and sequential games of imperfect information [31,32]. Why wouldone not want to take advantage of these efficient, direct techniques?One would, but there are settings for which efficient direct techniques are not (yet) known. For example, the bestcomputer programs for Backgammon have been developed using MAL, specifically Q-learning [69]. Also, MALalgorithms are in many cases simpler to program than the direct techniques, and are thus arguably preferable if codefor the direct algorithm is not readily available and the scalability of MAL suffices for the setting. Finally, it isconceivable that for some equilibrium-finding problems, MAL-based algorithms will turn out to be the most efficient.For example, for finding a minimax solution to a two-player zero-sum game, MAL (specifically, no-regret learning)might be an efficient alternative to linear programming if the game has a huge number of (pure) strategies but thepayoffs are small [2, page 73].Most importantly, however, MAL algorithms are needed if the agents do not know the structure (e.g., payoffs) ofthe game, or if the goal is to exploit a weak opponent more than an equilibrium strategy would exploit that oppo-nent.2.2. Descriptive agendaThe descriptive agenda of MAL grew largely out of the concern that people might not have the required rationality(reasoning capability) to act according to game-theoretic equilibrium. This in turn calls into question the descriptive\f384T. Sandholm / Artificial Intelligence 171 (2007) 382–391power of game theory. To mitigate this, economists have studied whether MAL techniques lead to equilibrium play.1If so, that is a justification of equilibrium because it is reached with learning, and thus does not require sophisticatedgame-theoretic reasoning and direct equilibrium-finding algorithms. This simplicity argument can also be used forequilibrium selection (easy-to-learn equilibria being more likely and more reasonable) and for justifying/selectingsolution concepts (concepts that can be associated with convergent learning algorithms being more descriptive). Hu-mans’ and animals’ learning other than learning that yields equilibrium is also in the scope of the descriptive MALagenda.There are, however, critical shortcomings in the descriptive MAL agenda, at least in many of the ways in which ithas been pursued to date. The most important shortcoming is that it is ill-defined what counts as a MAL algorithmunder this agenda, and the descriptive conclusions depend completely on what algorithms count. For example, elabo-rate work has been done on MAL algorithms that converge to equilibrium. However, even a trivial algorithm achievesthis goal: the players first explore each cell of the payoff matrix in order, then each of them individually computes anequilibrium (each agent using the same algorithm so as to find the same equilibrium in case of multiple equilibria), andthey play that equilibrium forever from then on. Researchers pursuing the descriptive agenda would not consider thisstraw man a MAL algorithm. Why not? Unfortunately, clear definitions of what algorithms count are usually not ar-ticulated. Instead, a variety of algorithms have been proposed, and their “naturalness” is argued based on intuition andtaste on an algorithm-by-algorithm basis. Since the descriptive conclusions hinge on what algorithms count, I thinkthere should be clear definitions of what MAL algorithms count. The definitions should preferably admit and excludeclasses of algorithms—defined by some properties of the algorithmic steps—rather than individual algorithms.What algorithms are admitted versus excluded should be guided at least by experiments on humans (or animals ifthat is the population about which descriptive conclusions are to be drawn). Unfortunately, this gives rise to a potentialcircularity in the agenda: in order to make descriptive conclusions about how humans behave, we need to start out withan understanding of how humans behave. (The circularity could also be used constructively to try to verify that theapproach is working. One could observe behavior in one setting, select learning models accordingly, test the modelsin a different setting, and check whether the descriptive conclusions align with observed behavior in that setting.)Another downside is that experimental results are context dependent.One approach is to admit in the definition algorithms that are simple (as opposed to complex to execute). Whilethis is intuitively appealing, it suffers from difficulties. First, it is not clear what is simple because human reasoningmay not coincide with the Turing machine model for which clear complexity measures have been devised. Second,some of the MAL algorithms admitted in the descriptive approach today involve numerous sophisticated calculations.Another shortcoming in the descriptive agenda is that most of that work assumes that people use the learning ruleeven if they would do better for themselves by behaving differently during the learning process. In other words, peopleare reduced, by assumption, to following a certain learning algorithm which guarantees that, if each agent follows thealgorithm, (eventually) an equilibrium will be reached. A related shortcoming is that each person is assumed to followthe learning rule even if he could, by behaving differently, drive the population to converge to a different equilibriumthat is more beneficial for himself.2.3. Prescriptive agendasIn the prescriptive agendas we are interested in how multiple agents should learn. It is thus largely irrelevantwhether the learning algorithms mimic how humans (or other animals) learn. The goal is to develop learning algo-rithms that satisfy given desiderata, that is, do well against given ",
            {
                "entities": [
                    [
                        72,
                        107,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 428–439Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMcCarthy variations in a modal keyJohan van Benthem a,b,∗a University of Amsterdam, Institute for Logic, Language and Computation (ILLC), P.O. Box 94242, Amsterdam, GE, Netherlandsb Stanford, United Statesa r t i c l ei n f oa b s t r a c tWe take a fresh look at some major strands in John McCarthy’s work from a logician’sperspective. First, we re-analyze circumscription in dynamic logics of belief change underhard and soft information. Next, we re-analyze the regression method in the SituationCalculus in terms of update axioms for dynamic–epistemic temporal logics. Finally, wedraw some general methodological comparisons between ‘Logical AI’ and practices inmodal logic, pointing at some creative tensions.© 2010 Elsevier B.V. All rights reserved.Article history:Available online 3 April 2010Keywords:CircumscriptionFixed-point logicStructural rulesBelief changeSituation CalculusTemporal logicRegression methodDynamic epistemic logic1. IntroductionJohn McCarthy is a colleague whom I have long respected and admired. He is a truly free spirit who always commu-nicates about issues in an open-minded way, away from beaten academic tracks and entrenched academic ranks. Eachencounter has been a pleasure, from being involved with his creative Ph.D. students in Logical AI (each a remarkable char-acter) to his lively presence at our CSLI workshop series on Logic, Language and Computation – and most recently, hisparticipation in the Handbook of the Philosophy of Information [1]. Interacting with John makes me see my own work andmy field in new ways, even in places where I eventually disagree. This brief note presents three illustrations. As a logician,I find John’s work intriguing because it is clearly about logic, but not in the ‘internal’ professional mode that I am usedto. True, many ideas of his have provided grist to our technical mills, and that is good. But more importantly, John’s workreminds us of broader issues: what logic should be about, and also, what methodology best suits the resulting agenda. Allthese themes play in my illustrations. In doing so, I merely give new perspectives on what exists, pointing out some newdirections: there are no new formal results.2. Circumscription, logical consequence, and logical dynamicsMy first encounter with the classic [18] introducing circumscription was when my student Wilfried Meyer Viol rushedinto my office, and said he had just seen the first truly new logical idea in years, and that: not coming from a logician!We quickly read the paper, and I was struck at once by the liberating effect of other consequence relations that retain basicstructure that makes them ‘logical’, while breaking new ground in terms of new varieties of reasoning. Ever since, I have* Address for correspondence: University of Amsterdam,Netherlands.E-mail address: johan.vanbenthem@uva.nl.URL: http://staff.science.uva.nl/~johan.Institute for Logic, Language and Computation (ILLC), P.O. Box 94242, Amsterdam, GE,0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.014\fJ. van Benthem / Artificial Intelligence 175 (2011) 428–439429been intrigued by what circumscription means, and I will tell a bit of the story up to my current somewhat iconoclasticreinterpretation.2.1. Classical consequence, circumscription, and beyondMinimal models. Classical consequence from premises P to a conclusion C says that all models of P are models for C . Themodels for P are the current range of options, encoding what we know: a logical conclusion does not add to that knowledge,but elucidates it. McCarthy [18] taught us that problem solving and planning go beyond this format, getting more out of thestated premises in special models that are most congenial to the scenario at hand. A circumscriptive consequence from P toC says thatC is true in all minimal models for P .Here, minimality refers to some relevant comparison order for models: inclusion of object domains, inclusion of denotationsfor specified predicates, and so on. The general idea is minimizing over any reflexive–transitive order of ‘relative plausi-bility’ [28].1 This is not just a trick for problem solving: circumscription seems a natural phenomenon in common sensereasoning broadly construed.Circumscription and classical logics. Circumscription quickly caught the imagination of logicians, since it raises new ques-tions about familiar systems. An example is the fine structure of second-order logic (cf. [39]). Letting the comparison orderbe inclusion of predicates over the same domain, and switching to standard notation, truth of a circumscriptive sequentϕ ⇒P C with ϕ a conjunction of premises (where the predicate P may occur in both ϕ and C ) in a first-order model M istruth of a following second-order implication:(cid:6) ⊂ P : ϕϕ(P ) ∧ ¬∃P→ C(P ).(cid:3)(cid:3)P(cid:2)(cid:2)(cid:6)Here the antecedent defines the ‘predicate minimal’ models of ϕ(P ).Thus, circumscription involves second-order logic, and high complexity is lurking. Still, basic results in [15] found specialsyntactic forms of ϕ(P ) that reduce circumscription to first-order reasoning.2 This line of analysis can be extended. [34] an-alyzes just when there exists a unique minimal predicate MIN P • ϕ(P ) satisfying a given first-order description ϕ(P ) (ϕmay also contain predicates Q that are not minimized):Definition 1. A first-order formula ϕ(P , Q ) has the Intersection Property for a predicate letter P if, in every model M ,whenever M, P i |(cid:9) ϕ(P , Q ) holds for all predicates in some family { P i | i ∈ I} (here the predicate letter P gets interpretedas the predicate P i ), then it also holds for the intersection of all these predicates, that is: M, ∩ P i |(cid:9) ϕ(P , Q ).If the formula ϕ(P , Q ) is satisfied in a model M by any predicate P at all, this ensures there is a unique smallestpredicate in M that does: and that is the earlier MIN P • ϕ(P ). A simple formula with the Intersection Property is ∀x(Q x →P x): the minimal predicate for P is just Q . A more complex example is ∀x(Q x → P x) ∧ ∀xy((P x ∧ Rxy) → P y): the minimalpredicate is the reflexive–transitive R-closure of Q in the model. These two cases suggest a syntactic format matching thesemantic Intersection Property:Definition 2. A first-order formula is a PIA form (‘positive antecedent implies atom’) if it has the syntactic format (with x afinite tuple of variables)(cid:2)∀x(cid:3)ϕ(P , Q , x) → P xwith P occurring only positively in ϕ(P , Q , x).Here is a model-theoretic preservation result connecting the two notions:Theorem 1. (See van Benthem [34].) The following assertions are equivalent for all first-order formulas ψ(P , Q ):(a) ψ(P , Q ) has the Intersection Property w.r.t. predicate P ,(b) ψ(P , Q ) is definable by a conjunction of PIA formulas.This analysis relates circumscription to well-known languages in the study of computation, with operators for smallestand greatest fixed-points:Theorem 2. (See van Benthem [34].) First-order logic with added predicate minimization over PIA-conditions has the same expressivepower as LFP(FO): first-order logic with added least fixed-point operators.1 This is much as in the Lewis semantics for conditional logic since around 1970 – an analogy which has been often noted (cf. [30]). This analogy willreturn below.2 The latter are reminiscent of ‘correspondence theory’ in modal logic [39] where we ask when modal logics whose axioms express second-order condi-tions on binary relations are already completely captured by matching first-order properties.\f430J. van Benthem / Artificial Intelligence 175 (2011) 428–439The connection between circumscription and fixed-point logic seems worth developing, but this technical strand is notmy main theme in this paper.Further travels of the idea. The next noticeable phenomenon is that circumscription, like all good ideas, has crossed overto other areas, in maybe unintended ways. Non-monotonic default reasoning is important in philosophy. [30] notes howphilosophers of science in the 1950s were quite close to it in their accounts of scientific explanation as what follows froma theory ‘under normal circumstances’.3 A more detailed account is found in [35].Circumscription made its way into linguistics as well. [30] noted also how it accounts for ‘exhaustive readings’ of answersto questions. An answer “John and Mary” to a question “Who are walking?” is usually read minimally: only John and Maryare walking. Such predicate minimizations are elaborated in [43]: the art is then finding the right model order to minimizeover for concrete semantic purposes. There is also work on linguistic formulations for McCarthy’s common sense puzzles.The innovative [12] analyzed these as a source of cues directing reasoning toward a solution.The complete travels of circumscription and related ideas remain to be chronicled, and they would also include cognitivescience and mathematics. Instead, we turn to the more general impact of circumscription in views of logic itself.The Bolzano Program: logic as a study of the varieties of consequence. By now, many styles of non-classical consequence havebeen found, with their structural properties [6,8,24], and it has been suggested that logic itself should be viewed as a studyof a plurality of consequence relations. Indeed, there is a historical precedent, if we go back to the agenda before Fregeand Boole. Logic was defined as the study of different natural styles of reasoning in the work of the great pioneer BernardBolzano, who already provided a highly original theory of sub-structural properties [29,32].But this diversity of reasoning styles also raises quite a few problems of its own. What is the nature of this diversity: dowe really ‘infer’ in many different ways, and why? Can we safely combine different styles in useful ways? And if these stylesare to refle",
            {
                "entities": [
                    [
                        136,
                        170,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 749–766Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDesigning competitions between teams of individuals ✩Pingzhong Tang a,∗, Yoav Shoham b,c, Fangzhen Lin aa Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kongb Computer Science Department, Stanford University, CA 94305, United Statesc Microsoft Israel R&D Center, Herzliya, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 15 June 2009Received in revised form 26 April 2010Accepted 26 April 2010Available online 29 April 2010Keywords:Team competitionMechanism designTruthfulnessMoral hazardDominant strategy implementation1. IntroductionWe consider a setting with two teams, each with a number of players. There is an orderingof all players that determines outcome of matches between any two players from theopposing teams. Neither the teams nor the competition designer know this ordering, buteach team knows the derived ordering of strengths among its own players. Each teamannounces an ordering of its players, and the competition designer schedules matchesaccording to the announced orderings. This setting in general allows for two types ofmanipulations by a team: Misreporting the strength ordering (lack of truthfulness), anddeliberately losing a match (moral hazard). We prove necessary and sufficient conditionsfor a set of competition rules to have the properties that truthful reporting are dominantstrategies and maximum effort in matches are Nash equilibrium strategies, and certainfairness conditions are met. Extensions of the original setting are discussed.© 2010 Elsevier B.V. All rights reserved.Once upon a time in ancient China, the emperor Qi threw down the gauntlet to his minister Tian for a horse race.The rule was that each of them would announce a ranking of his three horses and each time the two horses with thesame rankings would race. As the story goes, Tian learnt that his best horse was not as good as the emperor’s bestbut better than his second best one, and his second best one was not as good as the emperor’s second best but betterthan the emperor’s worst one. Knowing that the emperor would be confident enough to announce the true ordering,the clever minister put forward his worst horse first and his best horse second followed by his second best. As a result,while Tian’s worst horse lost badly to the emperor’s best horse in the first match, he won the second and third matchesnevertheless by taking the advantage of mismatches. Tian explained afterwards his strategy to the emperor and itspotential application in military matters and as a result, he was promoted to be the general in chief.Similar examples abound.1 A somewhat more recent example is the international team competition of table tennis. Theschedule is a modification of the horse racing one by adding two matches between the first player and the second playerfrom each team. Smart coaches can also benefit from strategically reporting the orderings. We will return to these exampleslater after we formally define the problem, which is henceforth called team competition problem.Competition among teams, each consisting of several players, presents at least two types of challenge. The first regardsthe desirable outcomes. Typically, the basic information is the relative strength of pairs of players, one from each team.✩An earlier version entitled “Team Competition” appeared in Proceedings of AAMAS’09.* Corresponding author.E-mail addresses: kenshin@cse.ust.hk (P. Tang), shoham@stanford.edu (Y. Shoham), flin@cse.ust.hk (F. Lin).1 For a related example in game theory, the Colonel Blotto game, cf. Section 7.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.025\f750P. Tang et al. / Artificial Intelligence 174 (2010) 749–766But how does this information get aggregated to decide the relative merit of the two teams? For example, should a teamwith one strong player and the rest very weak players beat a team consisting entirely of mediocre players? This amounts todefining the appropriate social-choice functions in this domain. One contribution of this paper is to establish criteria for suchfunctions; specifically, we adapted the notions of player anonymity, team anonymity, monotonicity, and Pareto efficiency tothis setting.The second challenge is that relative strengths among players are typically not common knowledge. Each team hasprivate information about its players, and the only objective way of getting this information is to play a match and observethe outcome. Playing all pairwise matches is usually not feasible, and so typically a competition among teams proceedsas follows: The teams announce a ranking of their players, and the organizer schedules individual matches based on theserankings according to a formula announced in advance. The matches then take place, and each match adds a certain scoreto the team of the winner. The team with the highest aggregate score wins the competition. But this opens the door to twoways in which teams can manipulate the outcome: It can misreport the true ordering of their players, and it can throw amatch (that is, deliberately lose). This is the problem of implementing the social-choice function, or of mechanism design(see [10,14] for introductions).Another contribution of this paper is the identification of necessary and sufficient conditions for implementing in dom-inant strategies social choice functions which satisfy the specified axioms. That is, identifying conditions under which it isbest for a given team to truthfully reveal the ordering among its players – no matter what the other team does, as wellas the conditions under which it is best for a given team to play its best in each match – knowing the other team alsoplays its best. These results are extended to a more general setting where the outcome of a match between two players isprobabilistic – decided according to a winning probability matrix [6].The remainder of the paper is organized as follows: We next formulate the team competition problem as a mechanismdesign problem, identify the basic forms of mechanisms and state the desirable properties in this domain. In Sections 4and 5, we characterize the conditions under which the mechanisms satisfy these properties. We then generalize our resultsin two directions in Section 6 and discuss related work in Section 7. Finally in Section 8, we briefly discuss future researchtopics related to team competition.2. Basic modelsWe now give the mathematic models for analyzing team competition.2.1. Team competition environmentsTeam competition environment is the setting where the designer operates.Definition 2.1. A team competition environment C is a tuple ( A, B, Θ, O , R), where• A = {a1, . . . , an} is the set of players of team A.• B = {b1, . . . , bn} is the set of players of team B.• Θ is the set of possible states, where:– Each state θ ∈ Θ uniquely defines a linear order >θ on A ∪ B. If a >θ b, then a beats b in state θ .– We denote by θ A and θB the orderings on A and B that are derived from θ respectively. θ A and θB can be seen asthe private information of A and B. We denote by Θ A and ΘB the sets of all possible θ A and θB .• O = {(s A, sB ) | s A, sB ∈ R} is the set of outcomes of the competition. s A and sB are the scores for teams A and B,respectively.• R is a preference relation over O .We consider R to be the one that team A weakly prefers (s A, sB ) to (s(cid:5)A, s(cid:5)B ) iffs A (cid:2) s(cid:5)Aand sB (cid:3) s(cid:5)B ,and team A strictly prefers (s A, sB ) to (s(cid:2)s A > s(cid:5)A and sB (cid:3) s(cid:5)B(cid:3)(cid:2)ors A (cid:2) s(cid:5)B ) iff(cid:5)A, s(cid:5)A and sB < s(cid:3).(cid:5)BTeam B has the opposite preference. We note that when s A > sis not defined.2(cid:5)A and sB > s(cid:5)B , the preference between (s A, sB ) and (s(cid:5)A, s(cid:5)B )An easy way to complete the preference defined above is to restrict a mechanism on certain set of outcomes satisfying,for each state θ , s A + sB = c, for some constant c. Such a mechanism is called a constant-sum mechanism.2 We will get back to another type of preference where each team is not so sensitive about scores but only cares about winning or losing. In this case,2 : 3 is as desirable as 3 : 4.\fP. Tang et al. / Artificial Intelligence 174 (2010) 749–7667512.2. StrategiesTypically, each team communicates with a mechanism by sending it a message. In team competition context, such amessage is confined to the form of an ordering of players of that team. A strategy of each team then specifies how tochoose among its orderings of players, given its true ordering of strengths.Definition 2.2. S A : Θ A → L A , is the set of A’s pure strategies that map A’s private information to a linear order on A,where L A is the set of all linear orders on A. Similarly for S B .When there is no restriction on Θ , both Θ A and L A denote the set of all permutations on A. We use different notationshere to clarify that Θ A is the set of private information (types) based on which A chooses an ordering in L A to report.Similarly, we can define the set of A’s mixed strategies to be σ A : Θ A → Ω(L A), where Ω(L A) is the set of probabilitydistributions over L A . We assume both teams are risk neural. As a result, when they play a mixed strategy, the outcome isequivalent to the expected score profile.2.3. Generalized round-robin mechanismsDefinition 2.3. Given a team competition environment and a message profile (L A, L B ) reported by A and B, a generalizedround-robin mechanism specifies an outcome via a matrix C , where:• Each entry ci, j in C denotes the score assigned to the match between ai and b j , where ai is the i-th player of L A andb j the j-th player of L B .• The winner of the match gets ci, j and the loser gets 0.• The total score that team A can get in state θ is s A =• Such a pair (s A, sB ) creates an",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 429–433www.elsevier.com/locate/artintThe possible and the impossible in multi-agent learningH. Peyton Young a,b,ca Johns Hopkins University, USAb University of Oxford, UKc The Brookings Institution, USAReceived 16 May 2006; received in revised form 20 October 2006; accepted 20 October 2006Available online 7 February 2007AbstractThis paper surveys recent work on learning in games and delineates the boundary between forms of learning that lead to Nashequilibrium, and forms that lead to weaker notions of equilibrium or to none at all.© 2007 Elsevier B.V. All rights reserved.Keywords: Equilibrium; Learning; DynamicsInteractive learning is inherently more complex than single-agent learning, because the act of learning changes thething to be learned. If agent A is trying to learn about agent B, A’s behavior will naturally depend on what she haslearned so far, and also on what she hopes to learn next. But A’s behavior can be observed by B, hence B’s behaviormay change as a result of A’s attempts to learn it. The same holds for B’s attempts to learn about A.This feedback loop is a central and inescapable feature of multi-agent learning situations. It suggests that methodswhich work for single-agent learning problems may fail in multi-agent settings. It even suggests that learning couldfail in general, that is, there may exist situations in which no rules allow players to learn one another’s behavior in acompletely satisfactory sense. This turns out to be the case: in the next section I formulate an uncertainty principlefor strategic interactions which states that if there is enough ex ante uncertainty about the other players’ payoffs (andtherefore their potential behaviors), there is no way that rational players can learn to predict one another’s behavior,even over an infinite number of repetitions of the game ([5]; for earlier results in the same spirit see [1] and [13,14]).Admittedly this and related impossibility theorems rest on very demanding assumptions about agents’ rationality,and what it means for them to “learn” their opponents’ behavior. Under less restrictive conditions more positive resultscan be attained, as we shall see in Section 3. Thus the purpose of this note is not to claim that multi-agent learningis impossibly difficult, but to try to identify the boundary—insofar as we now know it—between the possible and theimpossible in multi-agent learning situations. These issues are discussed in greater depth in [18].1. Model-based learningThe accompanying perspectives paper by Shoham, Powers and Grenager [17], hereafter referred to as SPG, formsmy jumping-off point. They too draw attention to the fact that multi-agent learning is inherently more complex thanE-mail address: pyoung@jhu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.10.015\f430H.P. Young / Artificial Intelligence 171 (2007) 429–433single-agent learning. They also make a useful distinction between model-based and model-free forms of learning,which I shall follow here. Using essentially their language, a model-based learning scheme has the following elements:1. Start with a model of the opponent’s strategy.2. Compute and play a best [or almost best] response.3. Observe the opponent’s play and update your model.4. Goto step 2.SPG leave the concept of “model” open, but here I shall suggest a general definition. Namely, a model-based learningmethod is a function that maps any history of play into a prediction about what one’s opponents will do next period,that is, to a probability distribution over the opponents’ actions conditional on the history so far. This definitionencompasses many forms of pattern recognition. The key feature of a model-based learning rule, however, is not whatpatterns it is able to identify in the data, but how it uses these patterns to forecast the opponents’ next moves.Many game-theoretic learning methods fall into this category. Fictitious play is a simple example: each agentpredicts that his opponent will use the distribution next period that he used cumulatively up until now. More gener-ally, Bayesian updating is a model-based learning procedure: each agent updates his beliefs about the repeated-gamestrategy of the opponents (conditional on the observed history), which leads to a prediction of their behavior nextperiod.What exactly do we mean by “learning” in this context? A natural definition is that players “learn” if they eventuallysucceed in predicting their opponents’ behavior with a high degree of accuracy [5]. This idea can be given greaterprecision as follows. Suppose that you are engaged in a two-player game. Given a history ht to time t, let pt beyour prediction of the opponent’s next-period behavior, conditional on ht . Let qt be your opponent’s actual intendedbehavior next period, conditional on ht . Notice that both pt and qt are probability distributions over the opponent’saction space (which we assume is finite). Thus pt and qt lie in an m-dimensional simplex for some nonnegative integerm. The predictive error in period t is (cid:2)pt − qt (cid:2). We could say that you learn to predict if (cid:2)pt − qt (cid:2) → 0 almost surely(cid:2)ps − qs(cid:2)2 → 0as t → ∞. A less demanding definition would be that the mean square error goes to zero: (1/t)almost surely as t → ∞. We shall say that the former is learning to predict in the strong sense and the latter is learningto predict in the weak sense.s(cid:2)t(cid:2)There is a well-known condition in statistics that guarantees that all players will learn to predict in the strong sense.Namely, it suffices that each player’s forecast of the others’ behavior, conditional on his own behavior, never excludeevents that have positive probability under their actual joint behavior. This is the absolute continuity condition [2,15].So far we have said nothing about what determines agents’ behavior, only what it means for them to learn. Ingame theory, a standard assumption is that behavior is rational: at each point in time, given what has happened todate, the players’ behavioral strategies are optimal given their forecasts of what is going to happen at all future dates.If we combine rationality with the absolute continuity condition (which guarantees good prediction), then we getconvergence to Nash equilibrium along the play path [15].Suppose, however, that each player is ignorant of his opponent’s payoff function. If the opponent is rational, hisstrategy will depend—perhaps quite intricately—on what his payoffs are. Hence the first player will have difficultyforecasting the second player’s strategy unless he can gather enough information along the play path to deduce whatthe latter is optimizing. The same holds for the second player trying to forecast the behavior of the first. This turns outto be impossible in principle when there is enough ex ante uncertainty about the payoffs.Theorem 1. (See [5].) Consider an n-person game on a finite joint action space A, where the n|A| possible payoffsdefining G are drawn i.i.d. via a continuous density f that is bounded away from zero on an open interval. G isdetermined once and for all before play begins. Assume the players are forward-looking and rational, with discountfactors less than unity, they know their own realized payoffs, and they use forecasting rules that do not depend on theopponents’ realized payoffs.There is a positive probability that: (i) at least one of the players will not learn to predict even in the weak sense;and (ii) the players’ period-by-period behaviors do not converge to any Nash equilibrium of the repeated game.Furthermore, if the support of f is a sufficiently small interval, then conclusions (i) and (ii) hold with probabilityone.\fH.P. Young / Artificial Intelligence 171 (2007) 429–433431A consequence of this result is that there exist no general, model-based procedures for multi-agent learning whenplayers are perfectly rational and they have sufficiently incomplete knowledge of their opponents’ payoff functions.A crucial condition for Theorem 1 to hold is that the unknown payoffs are distributed over some interval. If insteadthey were known to lie in a finite set, or even in a countable set, the result can fail. In this case one can tailor theforecasting rules to take account of the restricted set of payoffs that the opponent could be using, and thereby satisfyabsolute continuity. The second crucial condition for Theorem 1 is rationality: agents must optimize exactly. If insteadagents almost optimize, as in smoothed fictitious play [8], the result does not necessarily hold.In my view the first of these conditions (lack of knowledge) is more important than the second (perfect rationality).For one thing the second condition is merely an ideal statement about behavior, there is little or no empirical supportfor the notion that subjects optimize exactly. By contrast the first condition seems quite realistic: a player can hardlybe expected to know the von Neumann Morgenstern payoffs of his opponent with any precision; surely the most thatcan be hoped for is that he knows they lie within some range.I now sketch a model-based, multi-agent learning method that gets around the preceding impossibility result byrelaxing rationality a bit, while maintaining the assumption about complete lack of knowledge. The method is struc-tured along the lines of statistical hypothesis testing [6]. Assume, for the moment, that there are two players, 1 and2, with finite action spaces A1 and A2. Let Δi be the simplex of probability distributions on Ai . At time t, agent 1’smodel is that agent 2 is going to play a fixed distribution p2t ∈ Δ2 in all future periods. Given this model, agent 1chooses a smoothed best response q1t ∈ Δ1. Similarly, agent 2’s model at time t is some p1t ∈ Δ1 and her smoothedbest response is q2t ∈ Δ2. Hypothesis testing takes the following form for each player. Let s be a large positive integer(the sample size) and l",
            {
                "entities": [
                    [
                        72,
                        127,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1133–1149Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe learnability of voting rules ✩Ariel D. Procaccia a,∗,1, Aviv Zohar b,a, Yoni Peleg b, Jeffrey S. Rosenschein ba Microsoft Israel R&D Center, 13 Shenkar Street, Herzeliya 46725, Israelb School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 16 May 2008Received in revised form 25 March 2009Accepted 27 March 2009Available online 9 April 2009Keywords:Computational social choiceComputational learning theoryMultiagent systemsScoring rules and voting trees are two broad and concisely-representable classes ofvoting rules; scoring rules award points to alternatives according to their position inthe preferences of the voters, while voting trees are iterative procedures that selectan alternative based on pairwise comparisons. In this paper, we investigate the PAC-learnability of these classes of rules. We demonstrate that the class of scoring rules, asfunctions from preferences into alternatives, is efficiently learnable in the PAC model. Withrespect to voting trees, while in general a learning algorithm would require an exponentialnumber of samples, we show that if the number of leaves is polynomial in the size of theset of alternatives, then a polynomial training set suffices. We apply these results in anemerging theory: automated design of voting rules by learning.© 2009 Elsevier B.V. All rights reserved.1. IntroductionVoting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computa-tional aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].In an election, n voters express their preferences over a set of m alternatives. To be precise, each voter is assumed toreveal linear preferences—a ranking of the alternatives. The outcome of the election is determined according to a voting rule.In this paper we will consider two families of voting rules: scoring rules and voting trees.Scoring rules. The predominant—ubiquitous, even—voting rule in real-life elections is the Plurality rule. Under Plurality, eachvoter awards one point to the alternative it ranks first, i.e., its most preferred alternative. The alternative that accumulatedthe most points, summed over all voters, wins the election. Another example of a voting rule is the Veto rule: each voter“vetoes” a single alternative; the alternative that was vetoed by the fewest voters wins the election. Yet a third exampleis the Borda rule: every voter awards m − 1 points to its top-ranked alternative, m − 2 points to its second choice, and soforth—the least preferred alternative is not awarded any points. Once again, the alternative with the most points is elected.The above-mentioned three voting rules all belong to an important family of voting rules known as scoring rules. A scoringrule can be expressed by a vector of parameters (cid:3)α = (cid:4)α1, α2, . . . , αm(cid:5), where each αlis a real number and α1 (cid:2) α2 (cid:2)· · · (cid:2) αm. Each voter awards α1 points to its most-preferred alternative, α2 to its second-most-preferred alternative, etc.Predictably, the alternative with the most points wins. Under this unified framework, we can express our three rules as:✩This paper subsumes two earlier conference papers [A.D. Procaccia, A. Zohar, Y. Peleg, J.S. Rosenschein, Learning voting trees, in: Proceedings of the 22ndAAAI Conference on AI (AAAI), 2007, pp. 110–115; A.D. Procaccia, A. Zohar, J.S. Rosenschein, Automated design of scoring rules by learning from examples,in: Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2008, pp. 951–958].* Corresponding author.E-mail addresses: arielpro@gmail.com (A.D. Procaccia), avivz@cs.huji.ac.il (A. Zohar), jonip@cs.huji.ac.il (Y. Peleg), jeff@cs.huji.ac.il (J.S. Rosenschein).1 The author was supported in this work by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.003\f1134A.D. Procaccia et al. / Artificial Intelligence 173 (2009) 1133–1149Fig. 1. A binary voting tree.• Plurality: (cid:3)α = (cid:4)1, 0, . . . , 0(cid:5).• Borda: (cid:3)α = (cid:4)m − 1, m − 2, . . . , 0(cid:5).• Veto: (cid:3)α = (cid:4)1, . . . , 1, 0(cid:5).A good indication of the importance of scoring rules is given by the fact that they are exactly the family of voting rulesthat are anonymous (indifferent to the identities of the voters), neutral (indifferent to the identities of the alternatives), andconsistent (an alternative that is elected by two separate sets of voters is elected overall) [26].Voting trees. Some voting rules rely on the concept of pairwise elections: alternative a beats alternative b in the pairwiseelection between a and b if the majority2 of voters prefers a to b. Ideally, we would like to select an alternative that beatsevery other alternative in a pairwise election, but such an alternative (called a Condorcet winner) does not always exist.However, there are other prominent voting rules that rely on the concept of pairwise elections, which select an alterna-tive in a sense “close” to the Condorcet winner. In the Copeland rule, for example, the score of an alternative is the numberof alternatives it beats in a pairwise election; the alternative with the highest score wins. In the Maximin rule, the score ofan alternative is the number of votes it gets in its worst pairwise election (the least number of voters that prefer it to somealternative), and, predictably, the winner is the alternative that scores highest.When discussing such voting rules, it is possible to consider a more abstract setting. A tournament T over A is a com-plete binary asymmetric relation over A (that is, for any two alternatives a and b, aT b or bT a, but not both). Clearly, theaforementioned majority relation induces a tournament (a beats b in the pairwise election iff aT b). More generally, thisrelation can reflect a reality that goes beyond a strict voting scenario. For example, the tournament can represent a basket-ball league, where aT b if team a is expected to beat team b in a game. We denote the set of all tournaments over A byT = T ( A).So, for the moment let us look at (pairwise) voting rules as simply functions f : T → A. The most prominent class ofsuch functions is the class of binary voting trees. Each function in the class is represented by a binary tree, with the leaveslabeled by alternatives. At each node, the alternatives at the two children compete; the winner ascends to the node (soif a and b compete and aT b, a ascends). The winner-determination procedure starts at the leaves and proceeds upwardstowards the root; the alternative that survives to the root is the winner of the election.For example, assume that the alternatives are a, b, and c, and bT a, cT b, and aT c. In the tree given in Fig. 1, b beats aand is subsequently beaten by c in the right subtree, while a beats c in the left subtree. a and c ultimately compete at theroot, making a the winner of the election.Notice that we allow an alternative to appear in multiple leaves; further, some alternatives may not appear at all (so, forexample, a singleton tree is a constant function).Motivation and setting. We consider the following setting: an entity, which we refer to as the designer, has in mind a votingrule (which may reflect the ethics of a society). We assume that the designer is able, for each constellation of voters’preferences with which it is presented, to designate a winning alternative (perhaps with considerable computational effort).In particular, one can think of the designer’s representation of the voting rule as a black box that matches preference profilesto winning alternatives. This setting is relevant, for example, when a designer has in mind different properties it wants itsrule to satisfy; in this case, given a preference profile, the designer can specify a winning alternative that is compatible withthese properties.We would like to find a concise and easily understandable representation of the voting rule the designer has in mind. Werefer to this process as automated design of voting rules: given a specification of properties, or, indeed, of societal ethics, findan elegant voting rule that implements the specification. In this paper, we do so by learning from examples. The designer ispresented with different preference profiles, drawn according to a fixed distribution. For each profile, the designer answerswith the winning alternative. The number of queries presented to the designer must intuitively be as small as possible: thecomputations the designer has to carry out in order to handle each query might be complex, and communication might becostly.2 We will assume, for simplicity, an odd number of voters.\fA.D. Procaccia et al. / Artificial Intelligence 173 (2009) 1133–11491135Now, we further assume that the “target” voting rule the designer has in mind, i.e., the one given as a black box, isknown to belong to some family R of voting rules. We would like to produce a voting rule from R that is as “close” aspossible to the target rule.By “close,” we mean close with respect to the fixed distribution over preference profiles. More precisely, we would liketo construct an algorithm that receives pairs of the form (preferences, winner) drawn according to a fixed distribution Dover preferences, and outputs a rule from R, such that the probability according to D that our rule and the target rule agreeis as high as possible. We wish, in fact, to learn rules from R in the framework of the formal PAC (Probably ApproximatelyCorrect) learning model; a concise introduction to this model is given in Section 2.In this paper, we look at two options for the choic",
            {
                "entities": [
                    [
                        138,
                        170,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 103 ( 199X) l-60 Artificial Intelligence Reaching agreements through argumentation: a logical model and implementation * Sarit Kraus a,b-*, Katia Sycara ‘,‘, Amir Evenchik d,2 a Depurtment of Mathematics h Institute for Advanced Computer Studies. Uni~wsi~ of Mut&md, cmd Computer Scirncu, Bar-Ilun l/niversity, 52-900 Rumat-Gun, Israel Colle,qe Park, MD 20742, USA ’ School of Computer Science. Carnegie Mellon University, Pitt,shurgh. PA 15213. USA * Motorola Israel Ltd., 3 Krumenet.\\ki Street. E,l-A\\aiv 67899. Israel Received I9 September 1996; received in revised fhnn 7 June I998 Abstract agents self-motivated try to pursue In a multi-agent environment, where cannot be taken for granted. Cooperation must be planned for and achieved their own goals, through cooperation and negotiation. We present a logical model of the mental states of the agents based communication as an on a representation of their beliefs, desires, from exchanges among agents to persuade each other and bring about iterative process emerging and a change agreements. Using categories identified from human multi-agent negotiation, we demonstrate how the logic can be used to specify argument formulation and evaluation. We also illustrate how the developed intentions, and goals. We present argument&on in intentions. We look at argumentation logic can be used to describe different for achieving cooperation as a mechanism types of agents. Furthermore, we present a general Automated Negotiation Agent which we implemented. based on the logical model. Using this system, a user can analyze and explore different methods to negotiate for coordination exists. and argue in a noncooperative The development of negotiating agents is illustrated with an example where the agents plan, act, and resolve conflicts via negotiation in a Blocks World environment. 0 1998 Elsevier Science B.V. All rights reserved. in the framework of the Automated Negotiation Agent environment where no centralized mechanism K~ywrd~s: Automated negotiation: Argumentation: BDI model This material is based upon work supported in part by NSF Grant No. IRI-9423967. NSF grant No. IRI 9724937. NSF Grant No. IRI-9612 13 I, NSF Grant No. IRI-97 12607, ONR Grant No. N00014-96- I - 1722 and Army Research Lab under contract number DAALO197K013.5. We would like to thank Madhura Nirkhe for her contribution to the development of the formal model and to Ariel Stollman for the help in the implementation. author. Email: sarit@cs.bin.ac.il. * Corresponding ’ Email: katia@cs.cmu.edu. ’ Email: evenchik@cig.mot.com. 000+3702/98/S PII: SOOO4-3702(98)00078-2 - >ee front matter 0 1998 Elsevier Science B.V. All rights re\\ervcd. \f1. Introduction In a multi-agent environment, where self-motivated and negotiation. Negotiation often involves argumentution cannot be taken for granted. Cooperation must be planned cooperation through communication form of an exchange of messages or a dialogue. Arguments to change of negotiating self-interested cooperative. There are different arguments the intentions of another. Irrespective of what argument evaluate the argument and decide whether or not to change its intentions and actions. agents try to pursue their own goals, for and achieved in the are utterances whose aim is the context could make agents more to change is used, the recipient agent must (and consequently agents, the actions) of the listener. Within that could be used by one agent this change of intentions the intentions imagine For example, two mobile robots on Mars, each built to maximize its own utility. RI requests R2 to dig for a certain mineral. R:! refuses. RI responds with a threat: “if you do not dig for me, I will break your antenna”. RI is faced with the task of evaluating this threat. Several considerations must be taken into account, such as whether or not the threat is bounded, what RI’S credibility intact. so on and so forth. R1 may take a different approach if R2 refuses to dig, and respond with for a reward: “if you dig for me today, I will help you move your equipment a promise tomorrow”. Here, R2 needs to evaluate the promise of future reward. it is for R2 to have its antenna is, how important to bringing is essential about agreement Argumentation In about each other or the environment. when agents have such situations, to each other via the exchanged messages. Argumentation may also be called for when agents either do not have the ability or the time to make inferences. This is the case when agents have bounded systems which either may not be complete or may not be closed under inferences knowledge information incomplete impart in noncooperative situations inference [7 l,lOSl. agents In order to negotiate effectively, an agent needs the ability to (a) represent and maintain a model of its own beliefs, desires, goals, and intentions. (b) reason with other agents’ beliefs, desires, goals, and intentions, and (c) influence other agents’ beliefs, intentions, and is an iterative behavior. When agents are noncollaborative, exchange of proposals of the individual goals of the agents. towards reducing conflict and promoting the process of argumentation the achievement Arguments are used by a persuader as a means to dynamically change the preferences, to increase and actions of a persuadee, to intentions, cooperate. Over repeated encounters, agents may analyze each other’s patterns of behavior and reputation. This may to establish an analogue to the human notions of credibility influence such as the “threats” described the sending agent can update and correct its model of the recipient agent, thus refining the evaluation of arguments, later. By observing as we will see in scenarios and argumentation of the persuadee to the arguments, the willingness the reactions its planning knowledge. In this paper we develop a formal logic that forms a basis for the development of a system for argumentation. We offer a logical model of the mental formal axiomatization of their beliefs, desires, intentions and goals. states of the agents based on a representation We present argumentation as an iterative process of exchanges among agents to persuade each other and bring about a change in intentions. Our work on the formal mental model overlaps with the work of others who have developed formal models for communicative \fS. Kraus et al. /Artijcial Intelligence 104 (1998) i-69 3 agents (e.g., [16,19,64,69,86,115,129,133,138,164]) and for mental models of agents (e.g., [75,152,162]). We will discuss related work in Section 5 and point out the differences of from previous work is that our work with respect to that of others. The main difference point of view. We present a from the argumentation we have developed our formalization set of axioms that allows the agents to automatically in a multi-agent generate and evaluate arguments environment. in a simulated multi-agent a general Automated environ- Based on our formalization, we have developed and implemented Negotiation Agent (ANA) which acts and negotiates ment. In the simulation these agents is assigned an initial set of mental states and inference in every step and decision request evaluation, using arguments, and so on). Once created, if needed. Both the mental states and the different system, several ANA agents can be defined and created. Each of rules which guide it that it takes (goal seeking, argument generation and selection, its desires. the agent will try to accomplish inference its mental states according rules are based on our formal model. Each of the agents changes at the time of the change. The ability well as to define different system to test different argument agent’s negotiation most appropriate argument at any stage of the negotiation. These capabilities are illustrated through an extensive example, where agents negotiate logic to a rule which applies to define mental states for each of the agents. as allows the user of the types and to assess their impact on the effectiveness of the the capability. This also allows the user to evaluate ways of selecting in a Blocks World environment. rules for argument generation, inference The paper is organized the various argument as follows. Section 2 presents formalism and the various agent types which might be engaged describes argument appropriateness. (ANA) and its capabilities argumentation axiomatization. Section 6 presents concluding Section 4 discusses for argument generation types we have identified and how an agent can evaluate the general Automated Negotiation Agent and evaluation, based on the logical literature. logical argumentation the in argumentation. Section 3 Section 5 situates our work within the related remarks. 2. The mental model intentions, cooperative, with We have a set of agents, not necessarily messages. Their mental states are characterized desires, activities are motivated by the will to fulfill selects a consistent ascribes different degrees of importance higher importance. The set of goals motivate to exchange the notions of beliefs, goals, by using and local preferences. Each agent has a set of desires. The agent’s these desires. At any given time, an agent subset of its desires. This serves as its set of current goals. An agent to fulfill goals of to different goals. It prefers the agent’s planning process. the ability The planning process may generate several intentions. Some of these are in what we category and refer to actions that are within the would like to classify as the “intend-to-do” direct control of the agent. Others are among These are propositions not directly within the “intend-that” category the agent’s realm of control, [13,56,57,158]. that it must rely \fto modify the intention structure of another agent. the persuader wants it to do. While an agent tries to influence on other agents for satisfying. 3 Often, there is room for argumentation when intend-that is the means by which an agent, the persuader, actions are part of a plan. Argumentati",
            {
                "entities": [
                    [
                        65,
                        142,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 125 (2001) 119–153Blocks World revisitedJohn Slaney a;(cid:3);1, Sylvie Thiébaux b;2a Computer Sciences Lab, Australian National University, Canberra, Australiab CSIRO Mathematical & Information Sciences, PO Box 664, Canberra, AustraliaReceived 15 August 1999; received in revised form 14 June 2000AbstractContemporary AI shows a healthy trend away from artificial problems towards real-worldapplications. Less healthy, however, is the fashionable disparagement of “toy” domains: whenproperly approached, these domains can at the very least support meaningful systematic experiments,and allow features relevant to many kinds of reasoning to be abstracted and studied. A major reasonwhy they have fallen into disrepute is that superficial understanding of them has resulted in poorexperimental methodology and consequent failure to extract useful information. This paper presents asustained investigation of one such toy: the (in)famous Blocks World planning problem, and providesthe level of understanding required for its effective use as a benchmark. Our results include methodsfor generating random problems for systematic experimentation, the best domain-specific planningalgorithms against which AI planners can be compared, and observations establishing the averageplan quality of near-optimal methods. We also study the distribution of hard/easy instances, andidentify the structure that AI planners must be able to exploit in order to approach Blocks Worldsuccessfully. (cid:211) 2001 Elsevier Science B.V. All rights reserved.Keywords: Blocks World; Planning benchmarks; Random/hard problems; Approximation algorithms1. Introduction1.1. Blocks WorldThe Blocks World (BW) consists of a finite number of blocks stacked into towers on atable large enough to hold them all. The positioning of the towers on the table is irrelevant.* Corresponding author.E-mail addresses: John.Slaney@arp.anu.edu.au (J. Slaney), Sylvie.Thiebaux@cmis.csiro.au (S. Thiébaux).1 Some of this work was done while the author was visiting IMAG (Grenoble, France).2 This work was partly done while the author was at IRISA (Rennes, France).0004-3702/01/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 0 0 ) 0 0 0 7 9 - 52001 Elsevier Science B.V. All rights reserved.\f120J. Slaney, S. Thiébaux / Artificial Intelligence 125 (2001) 119–153Fig. 1. BW planning problem and optimal plan.The BW planning problem is to turn an initial state of the blocks into a goal state, by movingone block at a time from the top of a tower onto another tower or to the table (see Fig. 1).The optimal BW planning problem is to do so in a minimal number of moves.BW planning turns out to be tractable and optimal BW planning NP-hard [6,13,14].Further, optimal BW planning is Max-SNP hard, meaning that there exists some fixedperformance ratio under which it cannot be approximated tractably [26]. Near-optimalplanning within a ratio of 2 is tractable [14], but the question of whether a better ratiois achievable in polynomial time remains open [26]. For a number of extensions of thebasic BW above (table with a limited capacity, blocks with identical names, . . . ) similarcomplexity results can be shown [14], except for approximation within a constant ratio,which is not always tractable [26].1.2. Motivations behind this paperArtificial domains such as the Blocks World, the Traveling Salesman and the Queens,are in themselves of little practical interest. Despite this, they have remained staples of theAI literature over 30 years, because they are hard for general purpose AI systems and, atleast in principle, can support meaningful, systematic and affordable experiments. Morerecently, BW seems to have fallen into disrepute. In part, this is due to the efforts of theAI planning community to address domains of more practical relevance. More importantlyhowever, it is due to superficial understanding of the domain, leading to poor experimentalmethodology and consequent failure to extract useful results from it.Three major gaps in existing knowledge of BW prevent it from being effectively usedas a benchmark. The first is the lack of knowledge about how to construct probleminstances that are suitable for systematic experimentation: for example hard instances,or uniformly distributed random ones. This seriously lowers the value of experiments.Results are commonly obtained on isolated BW instances, often unspecified except for thenumber of blocks involved, and presumably hand-crafted to show off the good points of aparticular system (here we refrain from pointing the finger at any particular example in theliterature). Matters have started to improve with attempts to create some benchmarks forplanning. 3 In particular Kautz and Selman have introduced a series of four BW problemscalled ‘bw_large.a’ to ‘bw_large.d’, which have now attained that status [17,18]. This is3 The AIPS planning competition (http://www.cs.yale.edu/(cid:24)mcdermott.html and http://www.cs.toronto.edu/aips2000) is a symptom of the perceived need for standards.\fJ. Slaney, S. Thiébaux / Artificial Intelligence 125 (2001) 119–153121good at least in that everyone’s system is solving the same problem, but as we shall show,these problems are atypical in several respects, not least in that they have abnormallyshort plans, and are easy to solve optimally. The alternative to experimenting on particularinstances is to use random problems, but when this has been done, it has usually beendone poorly. BW optimisation problems of a given size vary so much in difficulty that“five random problems” are hardly a statistically adequate base for strong conclusions.Moreover, no attention has been paid to the distribution of the random instances, althoughit greatly affects the results. Even in the AIPS 2000 competition, perhaps the most carefullyconstructed testbed for planners, the largest BW problems are again atypical and easy tosolve optimally. We believe that problem selection will improve only when the featuresmaking instances hard, easy or average are identified, and when software for generatingrandom instances with meaningful distributions is used.The second important gap lies in the lack of knowledge about the performance in timeand solution quality of BW-specific planning methods. It was not until the 1990s that theworst-case complexity of optimal BW planning was studied by Chenoweth [6], Gupta andNau [13,14] and Selman [26], and much remains to be done. Very little is known about theaverage time complexity of optimal BW planning. No results are available about averageperformance ratios for near-optimal planning. Also, the exact time complexity of near-optimal BW planning has not been carefully analysed, [14] and [1,6] reporting respectivelycubic-time and quadratic-time upper bounds in the number of blocks. As a consequence,no proper BW “gold standard” exists, and this makes it hard to assess the effectivenessof approaches to planning on the basis of results reported in the literature. For instance,[1,2,7,18] show how specific methods for near-optimal BW planning can be fruitfullyencoded in a general system, while [17] exhibits domain-independent techniques thatdramatically improve performance for BW planning. These facts should not be interpretedas showing that these systems are really effective for domains like BW unless theymatch the best domain-specific ones, both in time complexity and in solution quality. Aslong as little is known about the behaviour of BW-specific methods, misinterpretation iseasy.Only recently have planning systems been able to deal with more than a few blocks—a fact which has hardly enhanced the reputation of the field within the wider researchcommunity. This was largely due to a third gap: ignorance of BW-specific featuresthat general systems should be able to exploit if they are to do well with the domain.The papers by Bacchus and Kabanza [1,2] clearly show that attempting to bridge thisgap greatly improves not only planner performance but also the ability to interpret theexperimental results. Indeed, without a precise understanding of which information isrelevant for a domain and which is not, the reasons why a given general techniqueperforms well on this domain cannot be adequately analysed, nor is it possible to knowwhether the domain is a suitable testbed for analysing the merits of that technique.Recent improvements notwithstanding, the performance of general planners, especiallyon optimal BW problems, remains far from comparable with domain-specific ones. Thisindicates that a more detailed examination of the structure of BW problems is likelyto reveal features which will further improve planner performance and experimentalmethodology.\f122J. Slaney, S. Thiébaux / Artificial Intelligence 125 (2001) 119–1531.3. Contributions of the paperIn this paper we undertake a sustained investigation of BW, with a view to filling allthree gaps. Much of the material presented is compiled from a series of conference papers[31,32] and technical reports [27–30] written over a number of years.In Section 2 we look at BW itself, giving expressions for the number of BW states asa function of the number of blocks and showing how to use this function to generaterandom states with uniform distribution. A supply of such states is essential to experimentson average-case behaviour, yet the problem of generating them is not trivial and has notpreviously been addressed.In Section 3 we consider algorithms both for optimal and for near-optimal BW planning.We detail several methods for finding near-optimal plans in linear time, thus closing thecomplexity question for this problem. We also outline an optimal solver capable of dealingwith arbitrary problems of up to 150 blocks. The resulting programs are offered as areference point for assessing the effectiveness of planning systems on this domain.In Section 4 we first examine the average performance of the algorithms in termsof speed and, more importantly, of solution quality.",
            {
                "entities": [
                    [
                        42,
                        64,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 103 (I 998) 2099235 Artificial Intelligence A gentle introduction to NUMERICA Pascal Van Hentenryck ’ Brown lJniver.sity, Box 1910. Providence, RI 02912, USA Abstract NUMERICA is a modeling to express these problems it possible textbooks or scientific papers. In addition, combines about correctness, convergence, and completeness. techniques language for stating and solving global optimization problems. It makes in a notation close to the way these problems are stated in algorithm of NUMERICA, which intelligence, provides many guarantees the constraint-solving from numerical analysis and artificial This paper is a gentle introduction to NUMERICA. It highlights global optimization methods. high-level, way. 0 1998 Elsevier Science B.V. All rights reserved. the essence of the constraint-solving It also presents and illustrates the functionality of NUMERIC A by contrasting some of the main difficulties of it to traditional algorithm of NUMERICA in a novel, 1. Introduction Many science and engineering applications require the user to find solutions to function includes problems, and of electrical robot kinematics, such as the modeling applications circuits, (e.g., nuclear to find all solutions of chemical reactor design). The field of constraints over real numbers or to optimize a nonlinear constraints. This processes and design problems is the study of methods systems of nonlinear to nonlinear subject chemical engineering equilibrium global optimization to systems of nonlinear constraints and all global optima to optimization problems. Nonlinear problems raise many issues from a computation if a set of polynomial constraints has a solution the problem programming problems up to, say, 20 variables. On the other hand, computing over real numbers numerical problems because of the finite nature of computers. lies in NP. Nonlinear to solve raises is NP-hard. In fact, Canny [4] and Renegar [36] have shown that can be so hard that some methods are designed only is in PSPACE and it is not known whether the problem standpoint. On the one hand, deciding problems ’ E-mail: pvh@cs.brown.edu OOO4-3702/98/$ - see front matter 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00053-8 \f210 F1 Vun Hrnrrniyk /Arrijicial Intvlligence 103 (1998) 209-235 NUMERICA 1391 is a modeling to solve nonlinear problems written in a form close to the statements textbooks and scientific papers. In addition, and contrary tools, NUMERICA provides many guarantees on its results (modulo implementation traditionally to most nonlinear programming errors): language for global optimization which makes it possible found in l Correctness: NUMERICA never produces any wrong solution; l Completeness: Under reasonable assumptions, NUMERICA is guaranteed to nonlinear equation systems and all global optima to unconstrained to isolate and all solutions constrained optimization problems; l Finiteness: NUMERICA is guaranteed l Certainty: NUMERICA can prove to converge; the existence of solutions and the absence of solutions. These functionalities should be contrasted with traditional numerical methods (e.g., quasi- local: they converge quickly when Newton methods). Traditional methods are inherently they are close to a solution or to a local optimum but it is outside the scope of these methods to find all solutions (or global optima) or to prove the existence or absence of solutions. Traditional methods may also fail to converge on hard problems. The limitations of local methods come from their inability to obtain global information functions. There on nonlinear is no way to collect global probing finitely many points. In contrast, NUMERICA has the ability to evaluate nonlinear functions over intervals, which provides global on the value of the function on any point in the intervals. The global nature of this information makes it possible bound numerical errors automatically a consequence, for nonlinear programming. to and to prune away entire regions of search space. As the use of intervals makes it possible to implement global search algorithms on a function by information information relaxation techniques intelligence Of course, computations in numerical the use of intervals is hardly new, since it from Moore’s thesis in 1966 [28] and is a very active research area (e.g., [ 12-15, algorithm of NUMERICA is the constraint-solving to obtain level, NUMERICA into discrete problems, which is exactly [lo]). Once (e.g., in integer programming to apply it is natural (e.g., [25-271) which have been originated 18,20-23,28,32,37]). What distinguishes of techniques the combination techniques effective pruning can be viewed as mapping continuous problems the opposite of traditional nonlinear programming techniques consistency applied in many areas [40]. successfully its constraint-solving problems are viewed as discrete problems, such as arc- and path-consistency from numerical analysis and artificial (for many problems). At a very abstract local the thousands of of the the robustness of the approach true for small-scale highly nonlinear problems as in chemical and electrical engineering where traditional methods are likely (a that progress methods. Local methods are extremely effective tools when they apply and are probably only way to approach large-scale nonlinear programming problems variables. However, NUMERICA are needed, either because of the nature of the application, problem simplifies those found to diverge, are unable requirement in chemical engineering there are many applications where the additional is too hard for local methods, or simply because in these problems). Gehrke and Marquardt to locate all solutions or to prove the need for these functionalities. functionalities or because does not aim at replacing the task. This is especially the absence of solutions [ 111 in fact indicate NUMERICA, and algorithm, involving increases \fI? Van Hentenryck / ArtiJcial Intelligence 103 (I 998) 209-235 211 The as follows. Section 2 discusses rest of this paper programming is organized of nonlinear problems, difficulties. Section 3 is a short tour of NUMERICA, which depicts variety of problems and contrasts level, presentation of the main constraint-solving concludes NUMERICA can be found in [38,39]. on a it to traditional methods. Section 4 is a novel, very high- algorithm used in NUMERICA. Section 5 about for further research. More information the paper and suggests directions the nature and practical its functionality theoretical limitations including 2. The nature of nonlinear programming This section discusses some of the properties of nonlinear systems and some of the limitations of traditional methods. 2.1. What is possible and what is not? Today’s computers can manipulate the solution of a nonlinear problem may be a real number that cannot be represented finite space or displayed on a screen in finite time, the best we can hope for in general point close to a solution or an interval enclosing a solution. and store only a finite amount of information. Since in is a (preferably with some guarantee on its proximity to the solution) Computer methods for solving nonlinear problems typically use floating-point real numbers. Since there are only finitely many floating-point numbers to approximate numbers, these methods are bound to make numerical errors. These errors, although probably small for in isolation, may have fundamental considered instance, Wilkinson’s problem, which consists on the results. Consider, in finding all solutions to the equation implications 20 I-I i=l (x + i) + px’” = 0 [-20.4, it has no solution. Wilkinson’s in the interval When p = 2-23, numerical have fundamental require users of numerical With this in mind, consider positive values for x; (1 < i < 10) satisfying -9.41. When p = 0, the equation obviously has 11 solutions. that a small can issues software to exercise great care when interpreting their results. the following combustion problem, which consists of finding for the results of an application. These numerical error (e.g., assume implications that p is the output of some numerical problem clearly the equations computation) indicates x~+~X~+X~+~XIO= 10P5, X3+Xs=3.10-5, xt+X3+2X5+2Xs+X9+Xto=5~10-5, x4 + 2x7 = 10P5, 0.5140437 lo-7 X5 =x;, 0.1006932 1O-6 X6 =2x;, \f212 I? Van Hentenryck /Artijicial Intelligence IO3 (19%‘) 209-235 0.7816278 0.1496236 lo-l5 x7 =x2 4> lo@ x8 =x1x3, 0.6194411 1O-7 x9 = x1x2, 0.2089296 lo-l4 xl0 =x,x;. Using (0.5, . . ,0.5) as starting point and the default setting of the system, a well-known commercial to obtain point, say b, and prints a warning desired accuracy. It is not obvious way. system produces a point, say a. In the same conditions but with the defaults set system produces another to achieve the that the machine precision in this case how to interpret the highest numerical precision, these results in a meaningful the same commercial is not sufficient It is also interesting uniqueness of solutions and Schnabel the existence or to mention is outside the scope of computer algorithms. For instance, Dennis the common belief that proving in their excellent text [8] present the three functions fl (x) =x4 -12xX+47x2-60x, f*(x) =x4 - 12x” + 47x2 - 60x + 24, .f3(x) =x4 - 12x3 + 47x* - 60x + 24.1 and state: computer routine that would tell and 5; the real roots of f*(x) are x = 1 and f3 (x) has no real roots.” that there will ever be such a routine. It would be wonder@1 if we had a general-purpose us: “The roots of fl (x) are x = 0,3,4, x 2 0.888; It is unlikely existence and uniqueness-does beyond the capabilities one can expect of algorithms In fact, we must readily admit that for any computer algorithm ,functions (injinitely continuously differentiable, the algorithm. Therefore, ull a user can be guaranteed u nonlinear problem is the answer “An approximate “No approximate solution to the problem was found solution in the allocated if you wish) perverse enough that solve ",
            {
                "entities": [
                    [
                        68,
                        101,
                        "TITLE"
                    ],
                    [
                        643,
                        676,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 302 (2022) 103602Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnalyzing Differentiable Fuzzy Logic OperatorsEmile van Krieken a,∗a Vrije Universiteit Amsterdam, Netherlandsb Civic AI Lab, Amsterdam, Netherlands, Erman Acar a,b, Frank van Harmelen aa r t i c l e i n f oa b s t r a c tArticle history:Received 10 June 2020Received in revised form 27 September 2021Accepted 28 September 2021Available online 7 October 2021Keywords:Fuzzy logicNeural-symbolic AILearning with constraintsThe AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature is weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning.We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionIn recent years, integrating symbolic and statistical approaches to Artificial Intelligence (AI) gained considerable attention [22,6]. This research line has gained further traction due to recent influential critiques on purely statistical deep learning [47,59], which has been the focus of the AI community in the last decade. While deep learning has brought many important breakthroughs in computer vision [8], natural language processing [61] and reinforcement learning [68], the concern is that progress will be halted if its shortcomings are not dealt with. Among these is the massive amounts of data that deep learning models need to learn even a simple concept. In contrast, symbolic AI can easily reuse concepts and can express domain knowledge using only a single logical statement. Finally, it is much easier to integrate background knowledge using symbolic AI.* Corresponding author.E-mail addresses: e.van.krieken@vu.nl (E. van Krieken), erman.acar@vu.nl (E. Acar), Frank.van.Harmelen@vu.nl (F. van Harmelen).https://doi.org/10.1016/j.artint.2021.1036020004-3702/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fE. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602However, symbolic AI has issues with scalability: dealing with large amounts of data while performing complex reasoning task, and is not able to deal with the noise and ambiguity of e.g. sensory data. The latter is related to the well-known symbol grounding problem which Harnad [30] defines as how “the semantic interpretation of a formal symbol system can be made intrinsic to the system, rather than just parasitic on the meanings in our heads”. In particular, symbols refer to concepts that have an intrinsic meaning to us humans, but computers manipulating these symbols cannot understand (or ground) this meaning. On the other hand, a properly trained deep learning model excels at modeling complex sensory data. These models could bridge the gap between symbolic systems and the real world. Therefore, several recent approaches [18,23,67,46,20]aim at interpreting symbols that are used in logic-based systems using deep learning models. These are among the first systems to implement “a hybrid nonsymbolic/symbolic system (...) in which the elementary symbols are grounded in (...) non-symbolic representations that pick out, from their proximal sensory projections, the distal object categories to which the elementary symbols refer.” Harnad [30].1.1. Reasoning and learning using gradient descentWe introduce Differentiable Fuzzy Logics (DFL) which aims to integrate reasoning and learning by using logical formulas expressing background knowledge. The symbols in these formulas are interpreted using a deep learning model of which the parameters are to be learned. DFL constructs differentiable loss functions based on these formulas that can be minimized using gradient descent. This ensures that the deep learning model acts in a manner that is consistent with the background knowledge as we can backpropagate towards the parameters of the deep learning model.To ensure loss functions are differentiable, DFL uses fuzzy logic semantics [41]. Predicates, functions and constants are interpreted using the deep learning model. By maximizing the degree of truth of the background knowledge using gradient descent, both learning and reasoning are performed in parallel. We can apply the loss functions constructed using DFL for more challenging machine learning tasks than purely supervised learning. These methods fall under the umbrella of weakly supervised learning [76]. For example, it can be used for semi-supervised learning [74,32] or to detect noisy or inaccurate supervision [19]. For such problems, DFL corrects the predictions of the deep learning model when it is logically inconsistent with the background knowledge.To further our understanding of such losses, we present in this paper an analysis of the choice of operators used to com-pute the logical connectives in DFL. For example, functions called t-norms are used to connect two fuzzy propositions [41]. Because they return the degree of truth of the event that both propositions are true, such t-norms generalize the classical conjunction. Similarly, a fuzzy implication generalizes the classical implication. Most of these operators are differentiable, which enable their use in DFL. Interestingly, the derivatives of these operators determine how DFL corrects the deep learn-ing model when its predictions are inconsistent with the background knowledge. We show that the qualitative properties of these derivatives are integral to both the theory and practice of DFL. We approach this problem both from the view of symbolic and of statistical approaches to AI, to bridge the conceptual gap between those views. This provides insights that otherwise would be overlooked.1.2. ContributionsThe main contribution of this article is to answer the following question: “What fuzzy logic operators for existential quan-tification, universal quantification, conjunction, disjunction and implication have convenient theoretical properties when using them in gradient descent?” We analyze both theoretically and empirically the effect of the choice of operators used to compute the logical connectives in Differentiable Fuzzy Logics on the learning behavior of a DFL system. To this end,• We introduce Differentiable Fuzzy Logics (Section 4) which combines fuzzy logic and gradient-based learning, and analyze its behavior over different choices of fuzzy logic operators (Section 3).• We analyze the theoretical properties of aggregation functions, which are used to compute the universal quantifier ∀and the existential quantifier ∃, t-norms and t-conorms which are used to compute the connectives ∧ and ∨, and fuzzy implications which are used to compute the connective →.• We introduce a new family of fuzzy implications called sigmoidal implications (Section 5) using the insights from these analyses.• We perform experiments to compare fuzzy logic operators in a semi-supervised experiment (Section 9).• We give several recommendations for choices of operators.2. Differentiable LogicsLoss functions are real-valued functions that represent a cost and must be minimized. Differentiable Logics (DL) are logics for which differentiable loss functions are constructed that compute the truth value of given formulas using the semantics of the logic. These logics use background knowledge to deduce the truth value of statements in unlabeled or poorly labeled data, allowing us to use such data during learning, possibly together with normal labeled data. This can be beneficial as unlabeled, poorly labeled and partially labeled data is cheaper and easier to come by. This approach differs from Inductive Logic Programming [54] which derives formulas from data. DL instead informs what the data could have been.2\fE. van Krieken, E. Acar and F. van HarmelenArtificial Intelligence 302 (2022) 103602Fig. 1. In this running example, we have an image with two objects on it, o1 and o2.We motivate the use of DL with the following classification scenario we consider throughout our analysis. Assume we have an agent A whose goal is to describe the scene on an image. It gets feedback from a supervisor S, who does not have an exact description of these images available. However, S does have a background knowledge base K about the concepts contained on the images. The intuition behind Differentiable Logics is that S can correct A’s descriptions of scenes when they are not consi",
            {
                "entities": [
                    [
                        135,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1539–1558Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUncertainty modelling for vague concepts: A prototype theory approachJonathan Lawry a,∗, Yongchuan Tang ba Department of Engineering Mathematics, University of Bristol, Bristol BS8 1TR, UKb College of Computer Science, Zhejiang University, Hangzhou 310027, PR Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 April 2008Received in revised form 28 July 2009Accepted 29 July 2009Available online 5 August 2009Keywords:Epistemic vaguenessPrototype theoryLabel semanticsRandom sets1. IntroductionAn epistemic model of the uncertainty associated with vague concepts is introduced.Label semantics theory is proposed as a framework for quantifying an agent’s uncertaintyconcerning what labels are appropriate to describe a given example. An interpretationof label semantics is then proposed which incorporates prototype theory by introducinguncertain thresholds on the distance between elements and prototypes for descriptionlabels. This interpretation naturally generates a functional calculus for appropriatenessmeasures. A more general model with distinct threshold variables for different labels isdiscussed and we show how different kinds of semantic dependence can be captured inthis model.© 2009 Elsevier B.V. All rights reserved.Natural language is a powerful, flexible and robust mechanism for communicating ideas, concepts and information. Yetthe meaning conveyed by even simple words is often inherently uncertain. This uncertainty is reflected in the variation andinconsistency in the use of words by different individuals. For example, Parikh [30] reports an experiment where a sampleof people are shown a chart with different coloured squares and asked to count the number of red and the number ofblue squares. The results differ significantly across the group. Similar inconsistencies in the use of colour categories are alsodescribed in the work of Belin and Kay [1] and Kintz et al. [20]. We believe that this uncertainty about the appropriate useof words arises as a natural consequence of the distributed and case-based manner by which an understanding of languageis acquired.Language is, to a large degree, learnt through the experience of our interactions with other speakers from which wecan make inferences about the implicit rules and conventions of language use [29]. Exposure to formal grammar rules andexplicit dictionary definitions comes relatively late in our education and requires a priori a basic vocabulary on the part ofthe student. It is perhaps not surprising then that such a process results in significant semantic uncertainty. We cannot real-istically expect that the boundaries of linguistic concepts, as perhaps represented by their extensions in a multi-dimensionalconceptual space [11], should be precisely and unambiguously defined by a finite set of often conflicting examples. It isour view then, that the uncertainty about word meanings which naturally result from such an empirical learning process isthe underlying source of concept vagueness. Consequently we adopt an epistemic perspective on vagueness, to some extentin accordance with the views of Williamson [37], whereby crisp concept boundaries are assumed to exist but where theirprecise definition is uncertain. Furthermore, as pointed out by Parikh [29,30], empirical learning requires extrapolation frompreviously encountered examples of word use to other new but similar cases. Hence, the notion of similarity is also funda-mental to any model of vagueness. Prototype theory [32,33] provides a powerful tool to understand the role of typicalityin concept definitions, resulting in a natural ordering on possible exemplars of concepts e.g. Bill is taller than Mary, but* Corresponding author.E-mail addresses: j.lawry@bris.ac.uk (J. Lawry), tyongchuan@gmail.com (Y. Tang).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.07.006\f1540J. Lawry, Y. Tang / Artificial Intelligence 173 (2009) 1539–1558Mary is richer than Bill. In this paper we attempt to provide a formal framework for representing the epistemic uncertaintyassociated with vague concepts, which incorporates elements of prototype theory.The modelling of concept vagueness in Artificial Intelligence has been dominated by ideas from fuzzy set theory asoriginally proposed by Zadeh [38]. In that approach the extension of a concept is represented by a fuzzy set which has agraded characteristic or membership function with values ranging between 0 and 1. This allows for intermediate membership(values in (0, 1)) in vague concepts resulting in intermediate truth values for propositions involving vague concepts (fuzzylogic). The calculus for fuzzy set theory is truth-functional which means that the full complement of Boolean laws cannot allbe satisfied [4].1 Furthermore, fuzzy set theory and fuzzy logic do not in their narrowest manifestations adopt an epistemicview of vagueness. Hájek [14], for example, argues that membership values of fuzzy categories are primitives quantifyinggradedness of membership according to which it is meaningless to refer to unknown or uncertain crisp boundaries of vagueconcepts, since such boundaries are inherently fuzzy. On the other hand, many of the proposed interpretations of fuzzy setsimplicitly adopt an epistemic position. In particular, the random set model of fuzzy sets (see [12,13] and [27]) according towhich fuzzy set membership functions correspond to single point coverage functions of a random set, inherently assumesthe existence of an uncertain but crisp set representing the extension of a vague concept. The basis of the label semanticstheory [21] outlined in this paper is also a random set model of vagueness but where the intention is to quantify uncertaintyconcerning the applicability or appropriateness of labels to describe a given example. Such a theory cannot result in a truth-functional calculus but can be functional in a weaker sense in the presence of certain assumptions concerning the semanticdependence between labels.A principal motivation for this paper is to explore the relationship between prototype theory and label semantics. Hence,there will be a focus on mathematical results demonstrating a clear link between these two theories in the case whencategorization (labeling) involves thresholding of a measure of similarity to prototypes. Furthermore, we will argue froman Artificial Intelligence perspective, that the proposed framework could be a suitable model for rational intelligent agentswho use concept labels and label expressions to describe elements of their environment with the aim of communicatinginformation to their fellow agents.An outline of the paper is as follows: Section 2 describes a variant of the epistemic theory of vagueness which providesthe philosophical underpinnings for the formal models we propose [23]. Section 3 provides an overview of label semanticsas first proposed in [21] and [22]. Section 4 discusses the relationship between prototype theory, typicality, uncertainty andvagueness. Section 5 describes a new prototype theory interpretation of label semantics and finally Section 6 gives someconclusions and possible directions for future work.2. An epistemic theory of vaguenessIn our everyday use of language we are continually faced with decisions about the best way to describe objects andinstances in order to convey the information we intend. For example, suppose you are witness to a robbery, how shouldyou describe the robber so that police on patrol in the streets will have the best chance of spotting him? You will havecertain labels that can be applied, for example tall, short, medium, fat, thin, blonde, etc., some of which you may view asinappropriate for the robber, others perhaps you think are definitely appropriate while for some labels you are uncertainwhether they are appropriate or not. On the other hand, perhaps you have some ordered preferences between labels so thattall is more appropriate than medium which is in turn more appropriate than short. Your choice of words to describe therobber should surely then be based on these judgments about the appropriateness of labels. Yet where does this knowledgecome from and more fundamentally what does it actually mean to say that a label is or is not appropriate? In the sequelwe shall propose an interpretation of vague description labels based on a particular notion of appropriateness and suggesta measure of subjective uncertainty resulting from an agent’s partial knowledge about what labels are appropriate to assert.Furthermore, we will suggest that the vagueness of these description labels lies fundamentally in the uncertainty about ifand when they are appropriate as governed by the rules and conventions of language use.‘The robber is blonde’) or to agree to a classification (e.g.It seems undeniable that humans posses some kind of mechanism for deciding whether or not to make certain assertions(e.g.‘Yes he was tall’). Furthermore, although the underlyingconcepts are often vague the decisions about assertions are, at a certain level, bivalent. That is to say for a particularexample x and description θ , you are either willing to assert that ‘x is θ ’ or not. Of course in general this decision maydepend on many factors associated with the context in which the communication is taking place. For example, you arelikely to be much more cautious in your use of language when describing a robber to the police than in describing acolleague to a close friend. Also, your motives may be much more complex than purely to communicate information. Forexample, you may have recognized the robber as a family member so that your aim when describing him is to throw thepolice off the scent. Nonetheless, there seems to be an underlying assumption that some things can be correctly assertedwhile others cannot. Exactly where t",
            {
                "entities": [
                    [
                        138,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 953–982www.elsevier.com/locate/artintBackward-chaining evolutionary algorithmsRiccardo Poli ∗, William B. LangdonDepartment of Computer Science, University of Essex, UKReceived 12 August 2005; received in revised form 11 April 2006; accepted 24 April 2006Available online 9 June 2006AbstractStarting from some simple observations on a popular selection method in Evolutionary Algorithms (EAs)—tournamentselection—we highlight a previously-unknown source of inefficiency. This leads us to rethink the order in which operations areperformed within EAs, and to suggest an algorithm—the EA with efficient macro-selection—that avoids the inefficiencies associ-ated with tournament selection. This algorithm has the same expected behaviour as the standard EA but yields considerable savingsin terms of fitness evaluations. Since fitness evaluation typically dominates the resources needed to solve any non-trivial problem,these savings translate into a reduction in computer time. Noting the connection between the algorithm and rule-based systems,we then further modify the order of operations in the EA, effectively turning the evolutionary search into an inference process op-erating in backward-chaining mode. The resulting backward-chaining EA creates and evaluates individuals recursively, backwardfrom the last generation to the first, using depth-first search and backtracking. It is even more powerful than the EA with efficientmacro-selection in that it shares all its benefits, but it also provably finds fitter solutions sooner, i.e., it is a faster algorithm. Thesealgorithms can be applied to any form of population based search, any representation, fitness function, crossover and mutation,provided they use tournament selection. We analyse their behaviour and benefits both theoretically, using Markov chain theory andspace/time complexity analysis, and empirically, by performing a variety of experiments with standard and back-ward chainingversions of genetic algorithms and genetic programming.© 2006 Elsevier B.V. All rights reserved.Keywords: Evolutionary computation; Genetic algorithm; Genetic programming; Efficient search; Backward chaining; Tournament selection1. IntroductionEvolutionary Algorithms (EAs) (see Algorithm 1) are a simple and, today, very popular form of search and opti-misation technique [1,2,6,13,21,22]. Their invention dates back many decades [11,14,18,34,40] (and see also [10]).EAs share several ingredients with mainstream AI search techniques. For example, EAs can be seen as special kindsof generate-and-test algorithms, as parallel forms of beam search, etc. (see [26] for a discussion on similarities anddifferences between EAs and other search algorithms). However, their development has been largely in parallel andindependent from AI search.Despite the simplicity of EAs, sound theoretical models of EAs and precise mathematical results have been scarceand hard to obtain, often emerging many years after the proposal of the original algorithm [7,15,16,19,24,25,28–31,* Corresponding author.E-mail addresses: rpoli@essex.ac.uk (R. Poli), wlangdon@essex.ac.uk (W.B. Langdon).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.04.003\f954R. Poli, W.B. Langdon / Artificial Intelligence 170 (2006) 953–982Select sub-population for reproductionRecombine the genes of selected parents1: Initialise population2: Evaluate population3: loop4:5:6: Mutate the offspring stochastically7:8:9: end loopEvaluate the fitness of the new populationIf stopping criterion is satisfied then exit loopAlgorithm 1. Generic evolutionary algorithm.36–39,42–44,47]. An important reason for this delay is that each algorithm, representation, set of genetic operatorsand, in some cases, fitness function requires a different theoretical model. In addition, the randomness, non-linearitiesand immense number of degrees of freedom present in a typical EA make life very hard for theoreticians.One line of theoretical research where differences in representations have not been an obstacle is the analysis ofselection algorithms (step 4 in Algorithm 1). This is because selection requires only knowledge of the fitness (orphenotype) of the individuals in the population, and so the same form of selection can be applied irrespective of therepresentation of an individual (or genotype).Different selection methods have been analysed mathematically in depth in the last decade or so. The main empha-sis of previous research has been the takeover time [12], i.e., the time required by selection to fill up the populationwith copies of the best individual in the initial generation, and the evaluation of the changes produced by selection onthe fitness distribution of the population [4,5,23]. In this second line of research, the behaviour of selection algorithmsis characterised using the loss of diversity, i.e., the proportion of individuals in a population that are not selected.These theoretical studies are very comprehensive and appeared to have completely characterised selection, funda-mentally making it a largely understood process. However, starting from some simple observations on the samplingbehaviour of perhaps the most popular selection method, tournament selection, in this paper we show that there is apossible source of inefficiency in EAs. This phenomenon, which had not been analysed in previous research, has verydeep implications, its analysis effectively leading to a completely new class of EAs which is more powerful and closerin spirit to classical AI techniques than traditional EAs.The paper is organised as follows. In Section 2 we describe tournament selection, we briefly review previousrelevant theoretical results, and then go on to describe, in Section 3, the sampling inefficiency in this form of selection.In order to remove the predicted sampling inefficiency of tournament selection, in Section 4, we rethink the orderin which operations are performed within EAs. This reveals that, embedded in EAs, is a graph-structure induced bytournament selection which connects individual samples of the search space across time. (See Fig. 1 in Section 4.)We are then able to suggest an algorithm, the EA with efficient macro-selection, that exploits this graph to remove theinefficiencies associated with tournament selection. The algorithm has the same expected behaviour as the standardEA, while providing considerable savings in terms of fitness evaluations. Furthermore, it is totally general, i.e., it canbe applied to any representation and fitness function, and can be used with any crossover and mutation.In Section 5, we note an unexpected connection between the operations of the EA with efficient macro-selectionand rule-based systems, which leads us to further modify the order of operations in the EA effectively turning theevolutionary search into an inference process operating in backward-chaining mode. The resulting algorithm, whichwe call a backward-chaining EA, creates and evaluates individuals recursively. It starts at the last generation and, usingdepth-first search and backtracking, works backwards to the first. This algorithm is even more powerful than the EAwith efficient macro-selection in that it shares all its benefits, but it provably finds fitter solutions sooner, i.e., it is afaster algorithm.We analyse theoretically the behaviour of the EA with efficient macro-selection and the backward chaining EAalgorithms in Section 6. In particular, in Section 6.1 we start analysing the sampling behaviour of tournament se-lection, focusing on its effects over one time step (a generation) of an EA. We do this by noting and exploiting thesimilarity between sampling and the coupon collection problem. We extend the one-generation analysis to full runs inSection 6.2 by inventing, and then modelling mathematically using Markov chain theory, a more complex version ofthe problem—the iterated coupon collection problem—which exactly mimics tournament selection over multiple gen-erations. This allows us to fully and exactly evaluate the effects of the sampling inefficiency of tournament selectionover entire runs and indicates that extent of the savings that could be achieved.\fR. Poli, W.B. Langdon / Artificial Intelligence 170 (2006) 953–982955We discuss the details of the practical implementation of a backward-chaining EA in Section 7 while we comparethe time and space complexity of our implementation with those for a standard EA in Section 8. In Section 9 weprovide experimental results with a Genetic Algorithm (GA) and a Genetic Programming (GP) implementation ofbackward chaining EA. We discuss our findings in Section 10 and provide our conclusions in Section 11.2. Tournament selectionTournament selection is one of the most popular forms of selection in EAs. In its simplest form, a group of nindividuals is chosen randomly uniformly from the current population, and the one with the best fitness is selected(e.g., see [2]). The parameter n is called the tournament size and can be used to vary the selection pressure exerted bythis method (the higher n the higher the pressure to select above average quality individuals).In a population of size M, the takeover time is defined as the number of generations required for selection (whenno other operator is present) to obtain a population containing M − 1 copies of the best individual in the initialgeneration [12]. In [12] the takeover time for tournament selection was estimated using the asymptotic expressiont∗ = 1ln n(cid:2)ln(M) + ln(cid:4)(cid:5)(cid:3)ln(M)where the approximation improves as the population size M → ∞.The loss of (fitness) diversity is the proportion of individuals of a population that is not selected during the selectionphase. Assuming every member of the population has a unique fitness, the loss of diversity pd for tournament selectionwas estimated in [4,5] aspd = n− 1n−1 − n− nn−1 ,and later calculated exactly in [23] as(cid:7)pd = 1MM(cid",
            {
                "entities": [
                    [
                        72,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 91 (1997) 103-130 Artificial Intelligence A new approach to quantitative and credible diagnosis for multiple faults of components and sensors T. Washio a**, M. Sakumab, M. Kitamurab a hstitute of Scientijc and Industrial Research, Osaka University, 8-l Mihogaoka, Ibaraki, Osaka 567, Japan b Nuclear Engineering Department, Faculty of Engineering, Tohoku University, Sendai, Miyagi 980, Japan Received April 1996; revised September 1996 Abstract Many practical applications of system diagnosis require the credible identification of multiple faults of nonlinear components and sensors in quantitative measures. However, the state of the art of diagnosis technique is considered to be still insufficient to meet these severe requirements. The approach of diagnosis using the traditional linear system identification theory can diagnose the disturbled parameters of a system in detail and evaluate the quantitative amplitude of the disturbance. However, it hardly provides the diagnosis of the multiple faults and the diagnosis of the components having high nonlinearity. On the other hand, some recent model-based diagnosis approaches can diagnose the multiple faults even for highly nonlinear components, though they involved in components and the do not provide the detailed diagnosis of elements indivisibly quantitative: amplitudes of the faults. The method proposed in this paper provides an efficient remedy to achieve all of the practical requirements, i.e., the credible, detailed and quantitative diagnosis of multiple faults of nonlinear components and sensors. Our study newly proposes the frameworks of optimal constraints and causal ordering of physical systems. Also, a systematic and strict theory to synthesize these frame- works together with the model-based diagnosis is provided to characterize an optimal consistency checking method in diagnosis and to evaluate quantitative amplitudes of faulty disturbances. First, the detection of faulty behaviors of an objective component is performed based on the quantitative consistency checking between observations and the optimal constraints, called as “minimal over- constraints”, consisting of first principles in the components. Second, once if some inconsistencies are detectesd, a mathematical operation of model-based diagnosis derives the candidates of faulty elements and functions even under multiple fault conditions. Third, the anomalous quantities di- rectly dishtrbed by the faulty elements are identified systematically based on causal ordering. * Corresponding author. E-mail: washio@sanken.osaka-u.ac.jp. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIISOOO4-3702(96)00060-4 \f104 T. Washio et al./Art@cial Intelligence 91 (1997) 103-130 Furthermore, the quantitative deviations of these quantities are evaluated by using the minimal over-constraints. The performance of the proposed method is demonstrated through an example to diagnose an electric water heater. The ability of this diagnosis has been confirmed for the multiple faults in nonlinear and dynamic systems. @ 1997 Elsevier Science B.V. Keywords: Model-based diagnosis; Multiple faults; Minimal over-constrained subset; Causal ordering; Assumptive structural equation; First principle; Function; Process system 1. Introduction The diagnosis of anomaly is requested applications nonlinear states is strongly needed such as nuclear power plants and air planes. The diagnosis require components The methodologies the credible, detailed and on-line and sensors of diagnosis in quantitative measures. so far can be categorized in systems where high reliability tasks in those faults of identification of multiple proaches based on the traditional approaches based on the recent theories and techniques developed gence field. The latter can be further categorized based on knowledge and pattern ecognision constraints of normal systems [ 10,16,22,32], (b.2) model-based of fault modes [28], and identification [ 7,8,10,23]. theory [ 3,9,24] in the artificial (a) ap- and (b) intelli- rules into (b. 1) synthesis of diagnostic [ 201 engine generic diagnostic checking of causal consistency proposed linear system into Generally speaking, the methods (a) can diagnose it hardly provides amplitude of a the disturbed parameters of the disturbance under a the diagnosis of the multi- having high nonlinearity. On the other faults even for highly non- on (b. 1) the methods they use a priori to di- they the multiple can also provide detailed diagnosis and sensors. However, faults, since (b.2) have an advantage of fault modes, to unpredictable the methods the detailed diagnosis of elements amplitudes of the faults. Also, many of the methods faults without using knowledge though in components (b.2) assume in a system can be probed. How- in most of process systems are initially designed and indivisibly involved that states at any point the quantitative of sensors. However, in detail and evaluate (b) can diagnose Some methods of (b.1) and parts in components system given arrangement ple faults and the diagnosis of the components hand, most of the methods linear components. disturbed parameters have limitations knowledge agnose any unexpected do not provide and the quantitative a diagnostic ever, the arrangement fixed. of their applicability of fault modes. In contrast, environment of sensors Accordingly, the state of the art does not provide an efficient remedy which addresses all of the following requirements. (i) Diagnosis of highly nonlinear (ii) diagnosis of elements (iii) diagnosis of multiple element (iv) quantitative (v) diagnosis under a given arrangement of sensors. components, involved faults including diagnosis of fault amplitudes, indivisibly in components, sensor faults, \f‘I Washio et al. /Art$cial Intelligence 91 (1997) 103-130 105 in the objective of (i) , (iv) and (v) these issues. For example, system meet the requirements Some past works tried to address the works based on the diagnosis and the use of a nonlinear quantitative model of the principle of the model-based the objective main purpose of these works is the identification the issues of (ii). The of the components the integrity of sensors other researches since the installed in some operation conditions of nuclear power reliability of sensors plants and1 air planes, where e.g., high pressure and/or mechanical vibration. However, most of the methods require some assumptions and do not solve the issue of (iii). in the field of “sensor validation” in the objective system have been reported is not maintained system and not to address to diagnose in many literatures such as integrity of some specific sensors and no faults in the components, to the severe environments, the sensors are exposed of the fault location [21,31]. However, in the granularity [ 3,9], This research proposes a generic method to overcome all of the issues previously component category of (b.2) is utilized faults of elements for diagnosis is represented in which only by and dynamic. The approach the to provide a highly credible in of and causal these an to synthesize to characterize involved indivisibly under a given arrangement theory is provided can be diagnosed the frameworks of optimal constraints and strict diagnosis of first principles which may be nonlinear to the aforementioned the multiple here belongs that the objective stated under a premise the constraints presented knowledge of the model of a normal component result. Nevertheless, diagnostic: nonlinear components and dynamic sensors. Our study newly proposes ordering of physical frameworlks optimal consistency of faulty disturbances. example problem section, demonstrated section, throughout for the demonstration tlhe theory of each reasoning mechanism the example. systems. Also, a systematic the model-based In the subsequent together with through the overview of our method and an In the third this paper are described. is is explained, and its applicability checking method in diagnosis and to evaluate quantitative amplitudes 2. Overview of method and application Fig. 1 shows the outline of the diagnosis method we propose. The knowledge in advance at the blocks of (A), is prepared reasoning in off-line manners. First, a model consisting including of the objective component type of optimum constraints [ 27,29,30]. in high resolution (C) (A), a certain in the diagnostic quired and normal condition block fault identification correspondence component quantities for physical termination derived based on the information (C) are prepared expertise is prepared. Block systematically in the objective component systems of the values of quantities [ 25-27,29,30]. of first principles its sensors is derived from the model In block (B), under is given. Then re- (B) the in to enable the knowledge of the in the objective among theory of causal ordering the orders of the de- is (A) and (B) depends on some by using an extended This knowledge [ 11,12,19]. All of the diagnostic knowledge represents of the normal component. The knowledge by off-line processing, while between a set of first principles is to derive (C) and a set of functions the knowledge of dependency \f106 T Washio et al. /Artificial Intelligence 91 (1997) 103-130 (A) knowledge of minimal over-constrained subsets (C) knowledge of causality (1) identification of faulty mechanisms based on consistency checking between observations and consUaint.s (2) identification of faulty functions through intelpretaticm of faulty tist principles (3) identification of anomalous quantities and their quantitative deviations Fig. 1. Entire procedure of a proposed diagnosis method. (A). process [ 5,7,18] checking diagnosis resolution to identify information of installed is performed faulty elements in the knowledge and the knowledge In reasoning block that the arrangement based on the quantitative is applied. The constraints the diagnosis proceeds of faults ( 1 ), (2) and the identifi",
            {
                "entities": [
                    [
                        75,
                        174,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 198 (2013) 1–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProbability and timeMarco Zaffalon a,∗, Enrique Miranda ba Istituto Dalle Molle di Studi sull’Intelligenza Artificiale (IDSIA), Galleria 2, 6928 Manno (Lugano), Switzerlandb University of Oviedo, Department of Statistics and Operations Research, C – Calvo Sotelo, s/n, 33007 Oviedo, Spaina r t i c l ei n f oa b s t r a c tArticle history:Received 18 November 2011Received in revised form 17 December 2012Accepted 23 February 2013Available online 26 February 2013Keywords:Temporal reasoningImprecise probabilitiesConditioningLower previsionsSets of desirable gamblesCoherenceConglomerabilityProbabilistic reasoning is often attributed a temporal meaning,in which conditioningis regarded as a normative rule to compute future beliefs out of current beliefs andobservations. However, the well-established ‘updating interpretation’ of conditioning is notconcerned with beliefs that evolve in time, and in particular with future beliefs. On theother hand, a temporal justification of conditioning was proposed already by De Moivre andBayes, by requiring that current and future beliefs be consistent. We reconsider the latterapproach while dealing with a generalised version of the problem, using a behaviouraltheory of imprecise probability in the form of coherent lower previsions as well as ofcoherent sets of desirable gambles, and letting the possibility space be finite or infinite. Weobtain that using conditioning is normative, in the imprecise case, only if one establishesfuture behavioural commitments at the same time of current beliefs. In this case it isalso normative that present beliefs be conglomerable, which is a result that touches on along-term controversy at the foundations of probability. In the remaining case, where onecommits to some future behaviour after establishing present beliefs, we characterise theseveral possibilities to define consistent future assessments; this shows in particular thattemporal consistency does not preclude changes of mind. And yet, our analysis does notsupport that rationality requires consistency in general, even though pursuing consistencymakes sense and is useful, at least as a way to guide and evaluate the assessment process.These considerations narrow down in the special case of precise probability, because thisformalism cannot distinguish the two different situations illustrated above: it turns out thatthe only consistent rule is conditioning and moreover that it is not rational to be willing tostick to precise probability while using a rule different from conditioning to compute futurebeliefs; rationality requires in addition the disintegrability of the present-time probability.© 2013 Elsevier B.V. All rights reserved.1. Introduction1.1. What has time to do with probability?We are interested in probability understood in the subjective tradition: as an uncertainty formalism that allows you1to express beliefs and do rational reasoning. Conditioning is an important component to reason with probability. In fact,the computation of conditional beliefs (i.e., expectations or probabilities) is taken by some researchers as ‘the’ procedureto obtain future rational beliefs out of current beliefs and observations, as if the Bayesian calculus—and Bayes’ rule inparticular—had captured the essence of the reasoning process itself through time.* Corresponding author.E-mail addresses: zaffalon@idsia.ch (M. Zaffalon), mirandaenrique@uniovi.es (E. Miranda).1 We follow Good, de Finetti and Walley in referring to ‘you’ as the subject that holds some probabilistic assessments.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.005\f2M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Is this view justified? To see whether this is the case, it is useful to go back at the foundations of probability. As ithas been well documented by Shafer [54,55], De Moivre and Bayes provided, already in the 18th century, an argument forthe temporal use of conditioning: it relies on constructing two bets, at present and future times, that jointly yield you asure loss if you do not use conditioning to compute your future beliefs. This is, in other words, a (Dutch) book argumentapplied through time. The approach is not uncontroversial2 and it may well clash with one’s intuition: in fact, from thetemporal-book argument it follows that once you have established your initial beliefs, your future rational behaviour willbe ‘mechanically’ determined. Should this be the case, should you not be allowed to change your mind?Nowadays, well-established approaches to probability seem to have taken a more cautious approach to defining the roleof conditioning; this caution de facto corresponds to eliminating time from the picture. The so-called updating interpretationof conditioning reads as follows: “your expectation of a gamble (i.e., a bounded random variable) f : Ω → R, conditional onevent B from a partition B of the possibility space Ω , represents yourcurrent beliefs about f under the assumption that Boccurs and that you obtain no other relevant information about Ω ”. The crucial word in the previous phrase is ‘current’: itmeans that under the updating interpretation, conditional beliefs are beliefs that you hold now; moreover, there is nothingin that phrase that relates your current conditional beliefs with the behaviour you will adopt once, and if, B occurs. Inthis view, Bayes’ rule loses its temporal flavor and reveals a simpler nature, that of a consistency requirement between yourcurrent conditional and unconditional beliefs: in fact, Bayes’ rule can be made to follow from the traditional book argument,the one that is applied to beliefs held at the same point in time.Yet, part of the literature has kept on exploring the relationship between probability and time, in the spirit of De Moivreand Bayes’ original intuition: this is the case, for instance, of the philosophical work on ‘dynamic coherence’ started inthe seventies with Teller (who credited David Lewis for having originated the argument, see [62, Note 1 to Section 1.3])and that continued in the eighties with a number of papers [2,3,58–60]; Shafer’s work, we have already mentioned, wasalso concerned to some degree with temporal considerations [54,55]. More recent work by Shafer et al. [56] stresses suchan aspect even more: among other things, it shows that Walley’s generalisation of Bayes’ rule to sets of probabilities [67,Section 6.4] is temporally consistent in a game-theoretic sense [57].Some other tightly connected approach is the statistical work on ‘temporal coherence’ by Goldstein [21–24], and therelated one in philosophy by van Fraassen [65,66]. In our view the aim here is different, however, as the focus does notappear to be on relating present and future behaviour, but rather on widening present beliefs so as to encompass also beliefsabout future beliefs. The field of ‘belief revision’, originated in the work of Gärdenfors and colleagues [1,18], attempts alsoto deal with temporal considerations in probability, besides logic. Its connection with the temporal-book idea is weaker,though.1.2. ContributionsWe aim at making a thorough analysis about the extent to which De Moivre and Bayes’ intuition can be made to providea firm foundation for a temporal interpretation of probabilistic reasoning. To this end, we consider a framework madeof two time points: now, and a future one determined by the occurrence of an event B ∈ B. Accordingly, we considertwo uncertainty models: one that you hold at present time, that is, your current beliefs (we also call them your currentcommitments3), and another one that you will hold after B occurs. We call the latter your future commitments.Our approach to the problem initially makes no assumptions on the relationship between current and future commit-ments. We do not even force the analysis to focus on conditional beliefs: present beliefs are allowed to be generically madeboth of conditional and unconditional information. Rather, we let the relationship between current and future assessmentsemerge by itself by characterising what it means that current and future commitments are consistent. This will also revealwhether and when it is actually rational (or normative) for you to be self-consistent in time.We shall pursue our aims within the framework of imprecise probability, and in particular start our work using Walley’sbehavioural theory of coherent lower previsions [67]: this is an extension of de Finetti’s theory [12] to sets of probabilitiesthat is close to robust Bayesianism. De Finetti’s theory is based on the concept of a (linear) prevision, which is anothername for an expectation functional; a coherent lower prevision is a lower envelope of linear previsions, which is in one-to-one correspondence with a closed and convex set of finitely additive probabilities. These tools enable us to deal uniformlywith precise and imprecise probability, as well as with any cardinality of the possibility space Ω —which is then allowed tobe infinite. Section 2 provides an introduction to the theory that is conceived to make the work as self-contained as it ispossible in a research paper. It also discusses the alternative representation of coherent lower previsions in terms of a setof desirable gambles: this is the set of gambles that you find desirable (i.e., that you would accept if they were offered toyou) as a logical consequence of your probabilistic assessments. This helps us to convey the intuition behind the conceptsand the results we present. Section 3 describes our temporal framework in detail, and introduces your uncertainty modelsin the form of two coherent lower previsions for your present and future commitments, respectively.The core of our work starts in Section 4. We define a number of consistency notions for your curren",
            {
                "entities": [
                    [
                        142,
                        162,
                        "TITLE"
                    ],
                    [
                        5946,
                        5966,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 142 (2002) 179–203www.elsevier.com/locate/artintBelieving others: Pros and consSandip SenDepartment of Mathematical and Computer Sciences, University of Tulsa, 600 South College Avenue,Tulsa, OK 74104-3189, USAReceived 13 May 2001; received in revised form 28 April 2002AbstractIn open environments there is no central control over agent behaviors. On the contrary, agents insuch systems can be assumed to be primarily driven by self interests. Under the assumption thatagents remain in the system for significant time periods, or that the agent composition changesonly slowly, we have previously presented a prescriptive strategy for promoting and sustainingcooperation among self-interested agents. The adaptive, probabilistic policy we have prescribedpromotes reciprocative cooperation that improves both individual and group performance in the longrun. In the short run, however, selfish agents could still exploit reciprocative agents. In this paper,we evaluate the hypothesis that the exploitative tendencies of selfish agents can be effectively curbedif reciprocative agents share their “opinions” of other agents. Since the true nature of agents is notknown a priori and is learned from experience, believing others can also pose its own hazards. Weprovide a learned trust-based evaluation function that is shown to resist both individual and concerteddeception on the part of selfish agents in a package delivery domain. 2002 Elsevier Science B.V. All rights reserved.Keywords: Reciprocity; Agents; Cooperation; Adaptation; Trust; Relationships1. IntroductionWith the burgeoning of agent based electronic commerce, recommender systems,personal assistant agents, etc., it is becoming increasingly clear that agent systems mustinteract with a variety of information sources in an open, heterogeneous environment [7,9,10,19,20,34]. One of the key factors for successful agent based systems (ABSs) of thefuture would be the capability to interact with other ABSs and humans in different rolecontexts and over extended periods of time. The ABSs of the future will be situated inE-mail address: sandip@ens.utulsa.edu (S. Sen).0004-3702/02/$ – see front matter  2002 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 2 ) 0 0 2 8 9 - 8\f180S. Sen / Artificial Intelligence 142 (2002) 179–203a social context, playing a variety of roles in different relationships and problem solvingsituations. Borrowing on the social cliche leveled at humans, we would like to conjecturethe following about the agents of the future: Agents must be social entities. In particular, webelieve that typical real-world environments abound in cooperation possibilities: situationswhere one agent can help another agent by sharing work such that the helping cost ofthe helper is less than the cost saving of the helped agent. Social agents can benefitfrom such cooperation possibilities by identifying and sustaining mutually beneficialrelationships.Whereas economic models can provide a basis for structuring agent interactions [24,35], research in multiagent systems involving non-monetary, social reasoning proceduresas behavioral strategies for self-interested agents has been relatively scarce. We believethat such societal approaches inspired by non-monetary mechanisms [1–3,15,27] mayprovide more effective social relationships in certain situations.1 For example, agents cantake advantage of cooperation possibilities by trading helps, where the cost incurred forhelping is the time spent in helping the other agent. One strong argument for incurring“time costs” for help rather than “monetary costs” is that time cannot be stored like money.Given a choice, it is preferable to trade non-storable resources, than storable resources andindividual agents can benefit in the long run by using their unoccupied time to developmutually beneficial relationships.Cooperative relationships not only benefit individual agents, but can also enhance thecondition of the entire society or the environment. Whereas as individual agent designers,we want to develop strategies which makes our agents profitable, as designers of entireagent systems or infrastructures, we want to maximize the performance of the entiresystem. For example, as designers of agent systems or infrastructures, we want the entiresystem to operate smoothly with little or no congestion, high throughput, balanced loadson resources, etc. Can these different viewpoints be reconciled? Put another way, arethere possible worlds where individually rational action leads both to maximizing localutility and improving system-level performance? These two goals cannot be reconciledunder all situations. Under a reasonably practical set of assumptions, which apply to asignificant set of realistic domains, however, we believe that the desired synthesis can beachieved. For example, as agent designers, we can design interaction protocols, feedbackmechanisms, etc., to create abundant cooperation possibilities, which can then be utilizedby well-designed agents. Such a scenario can produce high individual as well as systemperformance. But even though system designers provide cooperation possibilities, agent1 It is often argued that all interactions can be assigned to economic agents. If, in the future, all interactionsbetween any two computational entities on the Internet involved monetary exchanges, then either these agents ortheir owners have to decide on whether to interact or conserve its monetary allocation for some more important orurgent task that may arrive later. For example, my information gathering agent has to decide between whether toproactively search for information on the net (for which it has to pay) or reactively respond to my search requestsonce it has been allocated $X for the day. This decision making may be difficult to optimize as my requests mayvary widely over different days, and I will not take kindly to my agent who cannot process my explicit requestbecause it has already spent its allocation on proactive searches which may have generated useful information butis of less importance to me right now. Neither do I want to micro-manage this monetary allocation to my agent asthen the purpose of having an automated assistant is defeated.\fS. Sen / Artificial Intelligence 142 (2002) 179–203181designers must endow their agents with the capability of identifying and benefiting fromsuch opportunities in the environment.In this paper, we assume that real-life environments do provide sufficient cooperationpossibilities, and focus on the need to design social agents that can form cooperativerelationships with other agents to benefit from such cooperation possibilities. Butunsuspecting, naive agents, who cooperate with any agent in the environment, can beexploited by malevolent agents who receive but do not return help. We have been interestedin agent strategies for interactions with other agents that can promote cooperation in groupswhile resisting exploitation [5,27–29]. Our approach is different from other researcherswho have designed effective social laws that can be imposed on agents [8,30]. Inparticular, we have studied environments where agents can mutually benefit from sustainedinteractions. In such environments, appropriately designed agent strategies can lead toboth improved local performance for individual agents and effective global behavior forthe entire system. These are the desirable features for open systems where self-interestedagents are required to share resources.More specifically, we have developed and analyzed probabilistic reciprocity schemes asstrategies to be used by self-interested agents to decide on whether or not to help otheragents [27]. The goal of this work has been to identify procedures and environmentsunder which self-interested agents may find it beneficial to help others. By helpingwe imply incurring some local cost to benefit another agent. We claim that if thegroup composition changes only slowly, and there is sustained interaction between theagents, probabilistic reciprocity based strategies can be rational, i.e., maximize individualutilities. Probabilistic reciprocity strategies can be considerably more effective thansimple deterministic reciprocity schemes like tit-for-tat [2,13] and avoid major problemsassociated with the latter [27].In our experimental package delivery domain, an agent helps another agent by carryingout a task, i.e., by delivering a package, on behalf of the helped agent. But noneof the mechanisms presented here are limited to that particular kind of cooperation.For example, the reciprocity approach presented can also be used in domains wherecooperation implies the helping agent working together with the helped agent to reducethe latter’s workload [26]. Our experiments under a variety of environmental conditions,group composition, work estimate difference, etc. have shown that under prolongedinteraction, the probabilistic reciprocity strategy produces close to optimal individual andgroup performance [5,27–29]. Additionally, this strategy is stable against selfish intruders,i.e., in the long run, selfish agents perform worse than reciprocative agents in a mixedgroup.We now turn to the focus of the current paper. Even though probabilistic reciprocativeagents outperform selfish agents in mixed groups, they still waste some effort in helpingout selfish agents. This is because the reciprocative agents have a bias to initiate help topromote cooperative relationships in the future. A selfish agent can then benefit from thisinitial cooperative advances from each of the reciprocative agents in a mixed group. This isaided by the fact that reciprocative agents do not share their experiences or impressionsof the other agents. In other words, there is no “words of mouth” transmission of thereputation or reliability of the agents in the agent group. As a result, the reciprocativestrategy was dominant over exploitative strategies only if the agent group was sta",
            {
                "entities": [
                    [
                        72,
                        103,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 316 (2023) 103840Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintOn the robustness of sparse counterfactual explanations to adverse perturbationsMarco Virgolin a,∗a Evolutionary Intelligence Group, Centrum Wiskunde & Informatica, Science Park 123, 1098 XG Amsterdam, the Netherlandsb Department of Mathematics and Geosciences, University of Trieste, via Weiss 2, 34128 Trieste, Italy, Saverio Fracaros ba r t i c l e i n f oa b s t r a c tArticle history:Received 8 April 2022Received in revised form 25 November 2022Accepted 12 December 2022Available online 16 December 2022Keywords:Counterfactual explanationExplainable machine learningExplainable artificial intelligenceRobustnessUncertaintyCounterfactual explanations (CEs) are a powerful means for understanding how decisions made by algorithms can be changed. Researchers have proposed a number of desiderata that CEs should meet to be practically useful, such as requiring minimal effort to enact, or complying with causal models. In this paper, we consider the interplay between the desiderata of robustness (i.e., that enacting CEs remains feasible and cost-effective even if adverse events take place) and sparsity (i.e., that CEs require only a subset of the features to be changed). In particular, we study the effect of addressing robustness separately for the features that are recommended to be changed and those that are not. We provide def-initions of robustness for sparse CEs that are workable in that they can be incorporated as penalty terms in the loss functions that are used for discovering CEs. To carry out our experiments, we create and release code where five data sets (commonly used in the field of fair and explainable machine learning) have been enriched with feature-specific anno-tations that can be used to sample meaningful perturbations. Our experiments show that CEs are often not robust and, if adverse perturbations take place (even if not worst-case), the intervention they prescribe may require a much larger cost than anticipated, or even become impossible. However, accounting for robustness in the search process, which can be done rather easily, allows discovering robust CEs systematically. Robust CEs make ad-ditional intervention to contrast perturbations much less costly than non-robust CEs. We also find that robustness is easier to achieve for the features to change, posing an impor-tant point of consideration for the choice of what counterfactual explanation is best for the user. Our code is available at: https://github .com /marcovirgolin /robust -counterfactuals.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionModern Artificial Intelligence (AI) systems often rely on machine learning models such as ensembles of decision trees and deep neural networks [1–3], which contain from thousands to billions of parameters. These large models are appealing because, under proper training and regularization regimes, they are often unmatched by smaller models [4,5]. However, as large models perform myriads of computations, it can be very difficult to interpret and predict their behavior. Because of this, large models are often called black-box models, and ensuring that their use in high-stakes applications (e.g., of medicine and finance) is fair and responsible can be challenging [6,7].* Corresponding author.E-mail address: marco.virgolin@cwi.nl (M. Virgolin).https://doi.org/10.1016/j.artint.2022.1038400004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM. Virgolin and S. FracarosArtificial Intelligence 316 (2023) 103840The field of eXplainable AI (XAI) studies methods to dissect and analyze black-box models [8,9] (as well as methods to generate interpretable models when possible [10]). Famous methods of XAI include feature relevance attribution [11,12], explanation by analogy with prototypes [13,14], and, of focus in this work, counterfactual explanations. Counterfactual explanations enable to reason by contrast rather than by analogy, as they show in what ways the input given to a black-box model needs to be changed for the model to make a different decision [15,16]. A classic example of counterfactual explanation is: “Your loan request has been rejected. If your salary was 60 000$ instead of 50 000$ and your debt was 2500$ instead of 5000$, your request would have been approved.” A user who obtains an unfavorable decision can attempt to overturn it by intervening according to the counterfactual explanation.Normally, the search of counterfactual explanations is formulated as an optimization problem (see Sec. 2.1 for a formal description). Given the feature values that describe the user as starting point, we seek the minimal changes to those feature values that result in a point for which the black-box model makes a different (and oftentimes, a specific favorable) deci-sion. We wish the changes to be minimal for two reasons: one, to learn about the behavior of the black-box model for a neighborhood of data points, e.g., to assess its fairness (although this is not guaranteed in general, see e.g., [17]); two, in the hope that putting the counterfactual explanation into practice by means of real-life intervention will require minimal effort too. For counterfactual explanations to be most useful, more desiderata than requiring minimal feature changes may need to be taken into account (see Sec. 9) [18].In this paper, we consider a desideratum that can be very important for the usability of counterfactual explanations: ro-bustness to adverse perturbations. By adverse perturbations we mean changes in feature values that happen due to unforeseen circumstances beyond the user’s control, making reaching the desired outcome no longer possible, or requiring the user to put more effort than originally anticipated. These unforeseen circumstances can have various origins, e.g., time delays, mea-surement corrections, biological processes, and so on. For example, if a counterfactual explanation for improving a patient’s heart condition prescribes lowering the patient’s blood pressure, the chosen treatment may need to be employed for longer, or even turn out to be futile, if the patient has a genetic predisposition to resist that treatment (for more examples, see Sec. 5.1 and choices made in the coding of our experiments, in robust_cfe/dataproc.py).We show that, if adverse perturbations might happen, one can and should seek counterfactual explanations that are ro-bust to such perturbations. A particular novelty of our work is that we distinguish between whether perturbations impact the features that counterfactual explanations prescribe to change or keep as they are (note that some features may be irrele-vant and can be changed differently than how prescribed by a counterfactual explanation, we address this in Sec. 2.3). This is because counterfactual explanations are normally required to be sparse in terms of the intervention they prescribe (i.e., only a subset of the features should be changed), for better usability (see Sec. 2.1). As it will be shown, making this discrim-ination allows to improve the effectiveness and efficiency with which robustness can be accounted for. Consequently, one might need to consider carefully which counterfactual explanation to pursue, based on whether they are robust to features to change or keep as they are.In summary, this paper makes the following contributions:1. We propose two workable definitions of robustness of counterfactual explanations that concern, respectively, the fea-tures prescribed to be changed and those to be kept as they are;2. We release code to support further investigations, where five existing data sets are annotated with perturbations and plausibility constraints that are tailored to the features and type of user seeking recourse;3. We provide experimental evidence that accounting for robustness is important to prevent adverse perturbations from making it very hard or impossible to achieve recourse through counterfactual explanations, when adverse perturbations are sampled from a distribution (i.e., they are not necessarily worst-case ones);4. We show that robustness for the features to change is far more reliable and computationally efficient to account for than robustness for the features to keep as they are;5. Additionally, we propose a simple but effective genetic algorithm that outperforms several existing gradient-free search algorithms for the discovery of counterfactual explanations. The algorithm supports plausibility constraints and imple-ments the proposed definitions of robustness.2. PreliminariesIn the following, we introduce preliminary concepts for reasoning about robustness of counterfactual explanations in a sparse sense. In particular, we (i) describe the problem statement of searching for counterfactual explanations, (ii) present the notions of perturbation and robustness in general terms, and (iii) introduce the definitions of C and K, which are sets that partition the features of a counterfactual explanation. The following Secs. 3 and 4 will then present the main contribution of this paper: notions of robustness that are tailored to sparse counterfactual explanations, i.e., specific to Cand K.2.1. Problem statementLet us assume we are given a point x = (x1, . . . , xd), where d is the number of features. Each feature takes values either in (a subset of) R, in which case we call it a numerical feature, or in (a subset of) N, in which case we call it a categorical2\fM. Virgolin and S. FracarosArtificial Intelligence 316 (2023) 103840feature. For categorical features, we use natural numbers as a convenient way to identify their categories, but disregard ordering. For example, for the categoric",
            {
                "entities": [
                    [
                        153,
                        233,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 87 ( 1996) l-20 Artificial Intelligence Local conditioning in Bayesian networks F.J. Diez* Departamento Inteligencia Artificial, U.N.E.D., Senda de1 Rey, 28040 Madrid, Spain Received March 1993; revised February 1994 Abstract (LC) Local conditioning is an exact algorithm for computing probability in Bayesian networks, networks. A list of developed as an extension of Kim and Pearl’s algorithm to each node guarantees that only the nodes inside a loop are conditioned variables associated on the variable which breaks it. The main advantage of this algorithm is that it computes the probability directly on the original network instead of building a cluster tree, and this can save time when debugging a model and when the sparsity of evidence allows a pruning of the network. The algorithm is also advantageous when some families in the network interact through AND/OR gates. A parallel implementation of the algorithm with a processor for each node is possible even in the case of multiply-connected networks. for singly-connected 1. Introduction A Bayesian random variable, network is an acyclic directed graph in which every node represents a together with a probability distribution such that P(x,,... 9%) =J-JWilP(xi)) i (1) is just of the where xi represents a possible value ,of variable Xi and pa( xi) is an instantiation prob- the conditional parents of Xi in the graph. For a node/variable ability property of Bayesian from Eq. (1). The basic infer- networks, ence problem the a posteriori probability can be deduced from the conditional of a variable X given a certain evidence with no parents, independence its a priori probability. The essential e 3 {“Xi = Xi”,“Xj = consists of computing called d-separation probabilities [20,22], P(x\\e) * E-mail: fjdiez@dia.uned.es. WWW: http:/!www.dia.uned.es/Yjdiez 0004-3702/96/$15.00 SSDIOOO4-3702(95)00118-2 Copyright @ 1996 Elsevier Science B.V. All rights reserved \fEl. Die?/hr(jiciul Intrlli~qwcr X7 (1996) J-20 Fig. I. Evidence propagation by message passing .}. For singly-connected x,“. gorithm algorithms the appendix-while numerical values of conditional [ 4,5]. the problem is NP-hard the complexity ( I5,21 ], hut the general case is much harder: heavily depends on the structure of the network-there networks. there exists an elegant and efficient exact al- of exact in of approximate methods depends mainly on the for both exact and approximate methods, the time complexity is an example probabilities; The best-known exact methods are clustering and conditioning. A version of the [ 14, 191, has become the standard algorithm for inference former, clique-tree propagation in Bayesian networks. Conditioning, on the other hand, up until now had never been used in real expert systems. The purpose of this paper is to offer an efficient version of conditioning for practical applications. The key idea in our approach consists of conditioning specific conditioning, inside each loop. It is called local because every node has a indicated by a list of variables. exclusively suitable the remainder of this introduction as follows: is organized [ 15,211 algorithm for singly-connected The paper Kim and Pearl’s conditioning methods. Section 2 explains how to build an associated some links and assigning derives technical details algorithm known methods and, finally, variables for evidence propagation; we will in Section 4. Section 5 compares the conclusion offers suggestions a list of conditioning for a straightforward implementation. are discussed the formulas to each node, and Section 3 try to clearly explain all the The two possible versions of the local conditioning with other for future research. summarizes three tree by removing networks and reviews I. 1. Algorithm for the polytree The goal of the algorithm probability of proposition is to tind the a posteriori probability i.e., the “The value of variable X is x” given the observed evidence e. the network, an arbitrary node X divides P(xle), In a polytree, i.e., in a singly-connected into a link XY divides e into the evidence above to its causes, es, and that connected that connected evidence Similarly, it, eir. This partition of evidence propagated in the network (see Fig. I ): justifies the following definition to its effects, e;. the link, e&,, and that below of the messages \fEJ. Diez/ArtQicial Intelligence 87 (1996) I-20 7r(x) 3 P(x,exf), A(x) E P(e;lx), rX(ui) E P(&,e&X), AC(X) = P(e&IX). 3 (2) (3) (4) (5) These definitions are basically taken from [ 221, although Eqs. (2) and (4) introduced by Peot and Shachter [23] to simplify the computation follow in the modification conditioning algorithms. For a singly-connected network, d-separation results in two subsidiary properties [221>: l Two children x and Yj of a node X are independent given the value of their parent: P(YilX) = P(YilXfYj>. l A parent Ui and a child Yj of a node X are independent given the value of X: P(UilX) = P(UilX,Yj). Nevertheless, two parents of a node X, which in a polytree are always a priori independent, in general become correlated by the instantiation of X: P(UijX) Z P(UilX,Uj). These independence properties lead to recursive expressions for computing the mes- sages: P(xle) = arr(x)h(x), ll, ,.... lb, i=l j=l q(x) =4x) r-pv,(XL k#j AY,(X)=~ Yl [ A(Yj> u,,...,up 3 &=I 1 P(yjlX,ol,...,u,)~?rq(L’t) c (6) (7) (8) (9) (10) where VI, . . . , V, are the causes of q other than X, and cr = [P(e) after finding constant to be computed and A(x) . r(x) ] -’ is a normalization 1.2. An overview of three conditioning methods Because of d-separation, precisely, of a loop-more the instantiation a node whose of a node which is not at the bottom its in the loop are not both two neighbors \f4 (b) Fig. 2. A network and Its associated tree. in the sense that some correlations disappear in the loop as if it were part of a polytree. Therefore, the loop parents-breaks can be propagated tioning method break the loops in the resulting cutsets are {C}, {A.D} C-D-F-E-C. requires a structural process in the network) tree. A cutset for the network and {B,E}. {F} for finding a curser (a set of nodes and a numerical process which propagates in Fig. 2(a) is {A,E}: IS not valid because it does not break loop and evidence any condi- that evidence other possible \fRJ. Diez/Artijicial Intelligence 87 (1996) I-20 5 can be called global conditioning Pearl’s algorithm it conditions [22, pp. 204-2101 every node the network cause initializing ery evidence node to all other nodes GC is not only exponential findings. in the network on every variable the weights computes [ 281, it recursively in the network. Consequently, in the cutset size, but also proportional (GC) be- in the cutset. After from ev- transmitted the complexity of to the number of Peot and Shachter [23] introduced two important improvements in the original al- (Unfortunately, that cannot be unconnected they do not offer an algorithm gorithm. They define a knot as a portion of the network by removing one edge. knots of a graph.) Since every knot has its own cutset, conditioning with its corresponding networks consisting of more than one knot, this is a first improvement respect (see Section 1 .l ) which allows ings without having to process the worst-case multiplied the the method can be called knot (KC). For example, Fig. 2(a) consists of two knots: {A, B, C, D, E, F, G}, is the empty set. For in efficiency with in the definition of V(X) and ~x( ui) the influence of different find- for every evidence node. Therefore, cutset size the algorithm the whole network to GC. The second one is a small change is bounded by the maximum by the number of knots. the cutset for the latter of their algorithm edges, and {H}; for finding complexity to fusion the knots, applies conditioning that there tree with a list of conditioning is a specific conditioning Local conditioning (LC) , the algorithm and, instead of considering local means the term displays an associated that all the nodes conditioned depend on x. Local conditioning Shachter exponential and is much more efficient: includes in the path between introduced in this paper, goes a step further exclusively within each loop; for each node. Fig. 2(b) for every node. Observe a cutset node X and a phantom node X* are flowing along this path will by Peot and for which KC has the improvements there exist some structures introduced variables complexity while LC only requires linear time (see Section 5.1). on that variable and so every 7r- or A-message 2. Associated tree The process of building for finding cutsets, a list of conditioning and assigning algorithms both (Section 4). It consists of a depth-first detect the loops tasks at the same in the network.’ an associated tree encompasses two tasks: finding a cutset to every node. Before reviewing previous a new algorithm which performs time and can even be integrated with evidence propagation this section introduces variables search in the undirected graph as a means to 2.1. DFS, a depth-$rst search algorithm The following example shows how to transform a Bayesian network an associated tree (Fig. 2(b)). The search begins at an arbitrary pivot node-A (Fig. 2(a)) into in our ’ We assume that the network is connected, as is the case for real-world models. Otherwise, the procedure should examine every connected part separately. \f6 EJ. Diez/ArtijiciuI lntellrgence 87 (1996) I-20 travels through ignoring the network them in a list called PATH. A possible the direction of the edges, marking example-and route goes through A, the nodes and including B, G, F, H, D, and C. Backtracking from a node H with no untraversed edges removes this node from PATH, such that this list always contains a path from the pivot node to node C its the node currently value is (A,B,G,F;D,C). forward from C to A, the fact that the latter is already marked denotes and a new the presence of a loop. As a result, a phantom node A* arises the loop. Every node between A ",
            {
                "entities": [
                    [
                        73,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2270–2290Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlan recognition in exploratory domainsYa’akov Gal a,b,∗, Swapna Reddy b, Stuart M. Shieber b, Andee Rubin c, Barbara J. Grosz ba Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israelb School of Engineering and Applied Sciences, Harvard University, USAc TERC, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 1 March 2010Received in revised form 8 August 2011Accepted 11 September 2011Available online 3 October 2011Keywords:Plan recognitionUser modelingThis paper describes a challenging plan recognition problem that arises in environmentsin which agents engage widely in exploratory behavior, and presents new algorithmsfor effective plan recognition in such settings. In exploratory domains, agents’ actionsmap onto logs of behavior that include switching between activities, extraneous actions,and mistakes. Flexible pedagogical software, such as the application considered in thispaper for statistics education, is a paradigmatic example of such domains, but many othersettings exhibit similar characteristics. The paper establishes the task of plan recognitionin exploratory domains to be NP-hard and compares several approaches for recognizingplans in these domains, including new heuristic methods that vary the extent to whichthey employ backtracking, as well as a reduction to constraint-satisfaction problems. Thealgorithms were empirically evaluated on people’s interaction with flexible, open-endedstatistics education software used in schools. Data was collected from adults using thesoftware in a lab setting as well as middle school students using the software in theclassroom. The constraint satisfaction approaches were complete, but were an order ofmagnitude slower than the heuristic approaches. In addition, the heuristic approaches wereable to perform within 4% of the constraint satisfaction approaches on student data fromthe classroom, which reflects the intended user population of the software. These resultsdemonstrate that the heuristic approaches offer a good balance between performanceand computation time when recognizing people’s activities in the pedagogical domain ofinterest.© 2011 Published by Elsevier B.V.1. IntroductionIn this paper we report on the development and evaluation of algorithms for recognizing users’ plans in domains inwhich users engage in exploratory and error-prone behaviors. The challenges presented by these domains were madeevident by our work with students using open-ended computer software for learning statistics, but they arise in human–computer interaction more broadly.Indeed, developing technology is changing rote and monolithic interaction styles between computers and their users tomore flexible types of interactions that allow users to explore and interleave between different activities. Examples of theseflexible systems include interactive drawing tools [44], Integrated Development Environments (IDEs), collaborative writingassistants [4], computer games, and educational software [51].To be effective partners, these systems need to recognize the activities their users are carrying out and to use thatinformation to provide support in a way that guides users’ interactions effectively. For example, an intelligent drawing tool* Corresponding author at: School of Engineering and Applied Sciences, Harvard University, USA.E-mail address: gal@eecs.harvard.edu (Y. Gal).0004-3702/$ – see front matter © 2011 Published by Elsevier B.V.doi:10.1016/j.artint.2011.09.002\fY. Gal et al. / Artificial Intelligence 176 (2012) 2270–22902271may infer that several objects on the canvas are all representatives of the same class. When the user modifies an attributein one of the forms, the system will identify and duplicate this change in the other objects in the class. Another benefit ofrecognizing users’ activities in software is to provide assessments of user performance. Such capabilities in educational andpedagogical systems could increase teachers’ abilities to identify those students who are having difficulty.Classical approaches to plan recognition have assumed a goal-oriented agent whose activities are consistent with therecognizers’ knowledge base and who forms a single encompassing plan. In contrast, flexible systems allow users to followmultiple plans, interleave actions from different plans, and perform redundant actions; they also tolerate user mistakes.Thus, inferring users’ plans in these systems gives rise to a more complex sort of plan recognition problem.This paper presents several new algorithms for keyhole plan recognition in exploratory domains.1 The algorithms arepost-hoc, in that they infer plans from complete interaction sequences, rather than after each observed action, as in on-linerecognition [13]. The algorithms we present vary in completeness (that is, whether plans are guaranteed to be found) andcomputational complexity. We investigate the trade-off between completeness and complexity empirically, by comparingthe performance of different plan recognition algorithms on real-world data.Our empirical analysis uses an educational software system for statistics education. Educational software is increasinglydesigned to be open-ended and flexible in order to support the types of exploratory activities that facilitate students’learning experience. This gives students the resources to explore concepts in new ways, but their interactions may be erraticor unfocused, making it challenging to recognize plans. During the chaos of a lab session, it is impossible for teachers totrack each student’s progress. As a result it is difficult to adapt their teaching to their students’ work. Educational softwarethus provides an important domain for plan recognition. A well structured post-hoc representation of the plans behindstudents’ activities would enable teachers to make better pedagogical decisions in the classroom.The research we report used a commercial system called TinkerPlots, used world-wide to teach students in grades 4through 8 about statistics and mathematics [34]. Using TinkerPlots, students build stochastic models and generate pseudo-random samples to analyze the underlying probability distributions. Our study used four different problems for whichstudents interacted with TinkerPlots to model hypothetical situations and to determine the probability of events.Students’ interactions with TinkerPlots are complex. They may pursue multiple plans and interleave actions from differentplans. They may be confused about the appropriate plan to take, and they may make mistakes. These behaviors create achallenging domain for plan recognition algorithms. Any number of extraneous actions may be interleaved among thosethat are a part of a successful plan. In addition, actions that are crucial to successful plans may occur in almost any order.All of the algorithms presented in the paper compose (possibly non-contiguous) interaction sequences from users’ in-teractions into a series of interdependent tasks and sub-tasks. They infer students’ plans by comparing their interactionsequence to ideal solutions, or recipes, that were specified by domain experts. At the end of this process, the algorithmsoutput a hierarchical plan that explains the student’s strategy during the session. The algorithms separate those actions thatcontribute to solving the problem from extraneous actions and mistakes.This paper integrates and extends initial reports of past studies [23,43] and makes several contributions. First, it formallydefines the task of plan recognition in exploratory domains and provides a proof of its NP-completeness. Second, it presentsnew greedy and complete algorithms for solving the plan recognition problem in these domains, providing a formal com-plexity analysis of these algorithms and comparing them to existing methods. Third, it is the first work to evaluate planrecognition algorithms on real-world data in the domain of flexible pedagogical software.We compared two algorithmic approaches for recognizing users’ interactions. One of the approaches employed incom-plete greedy algorithms to attempt to build plans from the bottom-up. The complexity of one of these algorithms ispolynomial in the size of the interaction sequence, while the complexity of the other algorithm is exponential (in theworst case) in the size of this sequence. The second approach converts the recognition process to a Constraint SatisfactionProblem (CSP) using one of two methods. One of these methods builds a complete plan to recognize the entire interactionsequence. The other method works piecemeal in a way that uses subsets of the activity sequence to eliminate infeasibleplans before attempting to recognize the entire sequence. This second method was suggested by Quilici et al. [42] but firsttested empirically here. In contrast to the greedy approach, the constraint satisfaction approach is complete, in the sensethat if all of the recipes for solving a given TinkerPlots problem exist, and the student solved the problem, the algorithmis guaranteed to find the plan that explains the student’s interaction. The complexity of both of the complete methods isexponential in the size of both the interaction sequence and the data set containing ideal solutions.We conducted a number of empirical studies to evaluate the ability of these algorithms to recognize the plans used tosolve TinkerPlots problems. The studies involved two types of settings: adults using TinkerPlots in a lab setting, and middleschool students using TinkerPlots in a classroom setting. The results confirmed that the complete algorithms were able torecognize all plans when the relevant recipes for the TinkerPlots problems existed, and students were able to solve theproblems. However, there was a systematic difference between these two empirical settings and their effect on th",
            {
                "entities": [
                    [
                        147,
                        186,
                        "TITLE"
                    ],
                    [
                        4709,
                        4748,
                        "TITLE"
                    ],
                    [
                        7679,
                        7718,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 103 (I 998) 347-356 Artificial Intelligence Creativity and artificial intelligence Margaret A. Boden Abstract Creativity is a fundamental can be used to create new ideas in three ways: by producing novel combinations of familiar by exploring generation of previously new ideas than in automating their evaluation. 0 1998 Elsevier Science B.V. All rights reserved. feature of human intelligence, and a challenge for AI. AI techniques ideas; the the generation of transformations in modelling ideas. AI will have less difficulty the potential of conceptual spaces; and by making that enable impossible 1. Why AI must try to model creativity Creativity is a fundamental feature of human oriented AI cannot for AI. Even technologically very useful in the laboratory or the market-place. And AI-models as part of cognitive human minds to be creative. science can help psychologists intelligence, and an inescapable ignore it, for creative programs could be intended to understand how it is possible (or considered) challenge for Creativity is not a special “faculty”, nor a psychological property confined Rather, it is a feature of human intelligence such as the association of ideas, reminding, a structured problem-space, dimension linked to cultural context and personality primarily on the cognitive dimension. and reflective self-criticism. (the generation of new ideas) but also motivation in general. It is grounded perception, to a tiny elite. in everyday capacities analogical searching thinking, It involves not only a cognitive and emotion, and is closely focus factors [3]. Current AI models of creativity A creative idea is one which is novel, surprising, useful, .). But “novel” has two importantly different senses here. The idea may be novel beautiful. concerned or, so far as we with respect only to the mind of the individual know, to the whole of previous history. The ability to produce novelties of the former kind may be called P-creativity (H for historical). P-creativity is the more fundamental notion, of which H-creativity the latter H-creativity (P for psychological), is a special case. (or AI-system) and valuable (interesting, 00043702/98/$ -see front matter 0 1998 Elsevier Science B.V. All rights reserved. HI: SOOO4-3702(98)00055- 1 \f348 A4.A. Buden /Artijicial Intelli~enc-e 103 (1998) 347-356 AI should concentrate primarily on P-creativity. then artificial H-creativity will occur in some cases-indeed, to model this in a powerful manner, it already has, as we shall see. (In what follows, I shall not use the letter-prefixes: usually, it is P-creativity which is at issue.) If it manages 2. Three types of creativity There are three main types of creativity, the novel ideas. Each of the three results in surprises, but only one (the third) can lead to the “shock’ idea [2]. All types include some H-creative of surprise that greets an apparently examples, but the creators celebrated in the history books are more often valued for their achievements in respect of the third type of creativity. involving different ways of generating impossible The first type involves novel (improbable) creativity. Examples associated of familiar combinations include much poetic ideas share some two newly call this “combinational” analogy-wherein conceptual the structure. Analogies are sometimes explored and developed at some length, for purposes of an apt of rhetoric or problem-solving. analogy the similarities of structure are not only noticed but are judged in terms of their strength and depth. But even the mere generation, or appreciation, involves a (not necessarily conscious) structural mapping, whereby judicious inherent ideas. Let us imagery, and also see, however, (“ideas”) that they satisfy linked, and more similar and “transformational” the generation of novel ideas by the exploration of structured conceptual to each other than creativity. The former spaces. that are not only novel, but unexpected. One can The second and third types are closely either is to the first. They are “exploratory” involves This often results in structures concerned. immediately The latter involves of the space, so that new structures can be generated which could not have arisen before. The more the more the dimension concerned, and the more powerful the transformation, fundamental surprising the new ideas will be. These two forms of creativity shade into one another, since exploration of the space can include minimal “tweaking” of fairly superficial constraints. The distinction between a tweak and a transform is to some extent a matter of judgement, but the more well-defined of some (one or more) dimension the canons of the thinking-style the transformation the space, the clearer this distinction can be. (for example) most professional respected living out of exploratory Many human beings-including a justly inherit an accepted and jazz-musicians-make is, they and perhaps superficially But human beings sometimes removing one (or more) of its dimensions, enables impossible. transform tweak ideas to be generated which (relative style of thinking it, to explore scientists, artists, creativity. That it, their culture, and then search from its contents, boundaries, and potential. the accepted conceptual space, by altering or or by adding a new one. Such transformation space) were previously to that conceptual The more fundamental the transformation, and/or the more fundamental the dimension the more different that is transformed, of amazement that attends such (previously surprise occasioned by mere improbabilities, the newly-possible impossible) structures will be. The shock ideas is much greater than the they may be. If the however unexpected \fthe richness of human them in M.A. &den /Artificial Intelligence 103 (1998) 347-356 349 are too extreme, apparent. transformations be immediately likely rejected. Indeed, it may take some time for the relation between recognized and generally accepted. the relation between the old and new spaces will not and very the two spaces to be In such cases, the new structures will be unintelligible, 3. Computer models of creativity Computer models of creativity creativity focussed on the second that exploratory considerable domain-expertise place, and to specify procedures and transformational (exploratory) include examples of all three types. As yet, those type are the most successful. That’s not to say requires and analytic power to define the conceptual space in the first is easy to reproduce. On the contrary, it typically that enable its potential to be explored. But combinational creativity are even more elusive. The reasons for this, in brief, are the difficulty of approaching associative memory, and the difficulty of identifying our values and of expressing computational creativity. The latter difficulty attends efforts directed at any type of creativity, but is especially problematic with respect to the third (see Section 4, below). form. The former difficulty bedevils attempts to simulate combinational Combinational creativity Both of these require some sort of semantic network, or inter-linked knowledge-base, their ground. Clearly, pulling association may not be telling, or appropriate than “free association”, Ideally, every product of the combinational the originality of the various combinations is studied in AI by research on (for instance) jokes and analogy. as random associations out of such a source is simple. But an tasks other too. apt, and program should be at least minimally should be assessable by the AI-system. the nature and structure of the associative in context. For all combinational linkage is important for producing punning A recent, and relatively successful, example of AI-generated Jape, a program general sentence-forms, kind of X has Y?; What kind of X can Y?; What’s a Y? The semantic network used by the program semantics, syntax, and spelling. Different combinations in distinctly is jokes based on nine [I]. Jape produces such as: What do you get when you cross X with Y?; What the difference between an X and incorporates knowledge of phonology, of these aspects of words are used. structured ways, for generating each joke-type. (combinational) humour riddles Examples of riddles generated by Jape include: (Q) What kind of murderer has fibre? (A) A cereal killer; (Q) What do you call a strange market? (A) A bizarre bazaar; (Q) What do you call a depressed and (Q) What’s the difference between leaves and a car? (A) One you brush and rake, the other you rush and brake. These may in a relaxed social setting, one or two not send us into paroxysms of laughter-although, of them might. But they are all amusing enough to prompt wryly appreciative groans. train? (A) A low-comotive; series of psychological Binsted did a systematic tests, comparing people’s reception of Jape’s riddles with their response in joke-books. She also compared Jape’s products with “non-jokes” generated by random combinations. She found, that children, by whom such humour distinguish generally is most appreciated, Jape’s riddles) and non-jokes. Although than Jape’s, this difference vanishes for instance, reliably between jokes (including can they if Jape’s find human-originated to human-originated jokes published jokes funnier \f350 M.A. Boden /Art$cial Intelligence 103 (1998) 347-356 output is pruned, SO as to omit the items generated by the least successful schemata. The riddles published are highly selected, for only those the author finds reasonably in human joke-books funny will appear in print. Binsted had set herself a challenging that every one of Jape’s jokes research showed that although none were regarded as would be amusing. Her follow-up exceptionally funny, very few produced no response at all. This contrasts with some other Al-models of creativity, such as AM [ 161, where a high proportion of the newly generated structures are not thought interesting by human beings. task: to ensure is meant true",
            {
                "entities": [
                    [
                        77,
                        115,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 94 (1997) 139-166 Artificial Intelligence On the emergence of social conventions: modeling, analysis, and simulations * Yoav Shoham a*l, Moshe Tennenholtz bl* a Robotic? Laboratory, Department of Computer Science, Stanford University, Stanford, CA 94305, USA b Faculty of Industrial Engineering and Management, Technion-Israel Institute of Technology, Haifa 32000, Israel Abstract information in a stochastic in a standard game-theoretic in economic circles, namely framework currently popular the emergence of such conventions We define the notion of social conventions framework, and identify rationality. We setting; we do so within a that of stochastic games. This in several forms; in our setting agents interact with each other through a random reevaluate information. We introduce a simple reward (HCR) . We show a class of various criteria of consistency of such conventions with the principle of individual then investigate stylized framework comes process, and accumulate their current choice of strategy and natural strategy-selection to a rationally acceptable social convention. games in which HCR guarantees eventual convergence are achieved. the efficiency with which such social conventions Most importantly, we investigate lower bound on this rate, and then present results about how HCR works out We give an analytic in practice. Specifically, we pick one of the most basic games, namely a basic coordination game (as defined by Lewis), and through extensive computer simulations determine not only the effect of applying HCR, but also the subtle effects of various system parameters, such as the amount of memory and the frequency of update performed by all agents. @ 1997 Elsevier Science B.V. in light of the accumulated rule, called highest cumulative about the system. As they do so, they continually Keywords: Conventions; Emergent behavior; Coordination; Convergence rate *This work has been partially * Corresponding 1 Email: shoham@robotics.stanford.edu. author. Email: moshet@ie.technion.ac.il. supported by AFOSR grant AF F49620-94-l-0090. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIZSOOO4-3702(97)00028-3 \f140 Z Shoham, M. Tennenholtz/Artijicial Intelligence 94 (1997) 139-166 1. Introduction such rules even agents sufficient and services, or indirectly by sharing system resources. systems, be they human (people societies or distributed in the one case, programs or processes it is crucial them and promote cooperative behavior. Without In multi-agent different agents achieve different goals, and yet these agents must information systems among goals might become unattainable (just imagine driving allowing they do not interfere We have been computing systems, in the other) aim to interact either directly by sharing In such distributed that the agents agree on certain rules, in order to decrease conflicts the simplest by any of the agents, or at least not efficiently attainable in the absence of traflic rules). These rules strike a balance between them so that tool. Some of these rules are social rules as a design designed and agreed upon ahead of time (traffic laws are an example) ; in previous work laws. However, [21,25] we investigated not all rules can be agreed upon in advance. This is either because of the design of all the society are unknown, or because that rules in advance might be computationally the society converge on a convention this is common; this is how (e.g., software) in official regulations. some aspects of this off-line design of social in a dynamic standards emerge hard. In such cases, it is often important they change over time. In addition, too much with one another. their goals, and restricting In human societies they are enshrined the characteristics long before investigating to achieve freedom fashion. individual agents occasionally How do such conventions emerge? Roughly speaking, the process we aim to study is interact with one another, and as a result one in which gain some new information. Based on its personal accumulated each agent updates its behavior over time. The complexity of this process derives from its concurrent these nature: As one agent adapts fashion. This tends to result in complex system agents update in particle physics, population genetics, and dynamics, other areas. Each of these areas has developed to carry out the investigations; we ourselves will adopt the framework of stochastic games from the economics to the behavior of the agents of those encountered it has encountered, stylized settings their behavior information, in a similar reminiscent in which literature. terms, we will be asking In general ( 1) Under what conditions (2) How efficiently As it turns out, our results on eventual convergence will be primarily analytic, whereas results of do conventions are these conventions lower bounds and empirical eventually achieved? two types of question: include both analytic emerge? and the results on efficiency extensive computer simulations. Here is the structure of our article, explained followed by a more detailed description at two levels of granularity: that appeals a brief, to game- jargon-free theoretic description, terminology. The brief description of the article is as follows: l We give a formal definition of social laws and conventions, which are essentially to agents. the restriction of choices available l We identify individual those standpoint. laws and conventions that might be deemed rational from an \fI: Shoham, M. Tennenholh/Art$icial Intelligence 94 (1997) 139-166 141 l We dlefine a stochastic setting as a result. We define a particular update in which agents interact with one another and update that in social rule, and show to accept a rational to lead all agents it is guaranteed their behavior certain circumstances convention. l We then investigate how fast such rational conventions might emerge. We first give in a lower bound, and then investigate the actual rate of convergence an analytic particular case through extensive computer simulations. is a more detailed overview of the article, which makes to game- terms. The reader unfamiliar with game theory should just skim the following, sec- to it once all the terms have been defined in subsequent refer back reference Here theoretic and perhaps tions. l We adopt without change l Next we consider the possibility as utility maximization. We also make reference Nash equilibria, and Pareto optimal@. We make no novel contribution the notions of games, payofs matrices, and rationality to the notions of maximin values, in this part. to a subset of the original a sub-game of the original one. We call to of limiting the agents if the restriction a social constraint; leaves only one strategy strategies of a given game, thus inducing such a restriction each agent, it is called a (social) convention. Some social constraints are consistent with the principle of individual for agents In fact, we identify several senses to accept those (assuming in any reasonable are not rational of “rational sense. Both rational from types of constraints may be of interest a design to the former. As social standpoint, fall within the general area of cooperative games in economics, whatever constraints contribution we make in this part takes the form of added concreteness, a somewhat new Iperspective, and the attendant new terminology. and but we will pay special attention social behavior”. Some constraints irrational rationality, all others do as well). in the sense that it is rational l Classical that results [ 9,12]), important is known the game the assumption realistic models. One strand of recent work in which agents engage pairwise) (specifically, inspired by models of population to relax not only even in game theory make strong assumptions; they rely is devoted in genetics that the game is common at all. Specifically, in particular, on the game being common knowledge. Much recent work in economics to investigating more economics, which has been strongly tends (e.g., knowledge, but sometimes number of models have been proposed of (typically the system perhaps about the strategies used by other agents, and, if the game is not known advance, about the game). The agents may then use that information choice of strategy, and the process that the system will converge had complete information vary widely on how agents accumulate choice of strategy. One important model of evolutionary conditions novel contribution a in some process about interactions about how well each of their strategies has fared so far, in to update their to show in fact and were acting rationally. The models within economics information, their is that of stochastic games and the notion that under certain to a Nash equilibrium. We make no to a particular global state as if the players the iterated process will converge It is then sometimes possible and how they update to this work as such. stable strategies through which (ess’s), where it is shown information they gain repeats. \f142 I! Shoham. M. Tennenholtz/Artificial Intelligence 94 (1997) 139-I66 The items below constitute l We ask, in an analogous the core of our article, and are all novel. fashion, how desirable through a stochastic process. These social conventions Equilibria.2 We adopt the framework of stochastic games mentioned ever, that framework unique features tantly, we define a simple and natural strategy-selection lative reward (HCR). (Again, this rule replaces social conventions might emerge are not necessarily Nash- above. How- setting has later). Most impor- rule called highest cumu- that allows quite a few variants, and our particular for the reader familiar with ess’s, we remark (we will explain and motivate the best response rule.) these features l We show a class of stochastic games to a rational social convention. converge in which the HCR rule is guaranteed to to this last topic. We first give an analytic l We then ask how fast such social ",
            {
                "entities": [
                    [
                        66,
                        141,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 180–181 (2012) 1–19Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintManipulating the quota in weighted voting games ✩Michael Zuckerman a, Piotr Faliszewski b, Yoram Bachrach c, Edith Elkind d,∗a School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israelb AGH University of Science and Technology, Krakow, Polandc Microsoft Research Ltd., Cambridge, United Kingdomd Division of Mathematical Sciences, School of Physical and Mathematical Sciences, Nanyang Technological University, Singaporea r t i c l ei n f oa b s t r a c tArticle history:Received 27 November 2010Received in revised form 28 December 2011Accepted 31 December 2011Available online 4 January 2012Keywords:Weighted voting gamesManipulationComplexityWeighted voting games provide a simple model of decision-making in human societiesand multi-agent systems. Such games are described by a set of players, a list of players’weights, and a quota; a coalition of the players is said to be winning if the total weight ofits members meets or exceeds the quota. The power of a player in a weighted voting gameis traditionally identified with her Shapley–Shubik index or her Banzhaf index, two classicpower measures that reflect the player’s marginal contribution under different coalitionformation scenarios. In this paper, we investigate by how much one can change a player’spower, as measured by these indices, by modifying the quota. We give tight bounds on thechanges in the individual player’s power that can result from a change in quota. We thendescribe an efficient algorithm for determining whether there is a value of the quota thatmakes a given player a dummy, i.e., reduces her power (as measured by both indices) to 0.We also study how the choice of quota can affect the relative power of the players. Finally,we investigate scenarios where one’s choice in setting the quota is constrained. We showthat optimally choosing between two values of the quota is complete for the complexityclass PP, which is believed to be significantly more powerful than NP. On the other hand,we empirically demonstrate that even small changes in quota can have a significant effecton a player’s power.© 2012 Elsevier B.V. All rights reserved.1. IntroductionCooperation and joint decision-making are key aspects of many interactions among self-interested agents. In such in-teractions, the collaborating agents may have different preferences, so they need a method to agree on a common courseof action. One possible solution to this problem is to use a voting procedure, and select a plan that is supported by amajority of voters. This approach to decision-making is very common in human societies and can be naturally extended tomulti-agent systems [12].Under majority voting, all agents have the same power. However, treating all voters as equals is not always appropriate:some of the agents may be more important for the task at hand than others, or contribute a larger amount of resources toit. Similarly, in parliamentary voting, some of the legislators may represent a larger constituency, and therefore should begiven more influence over the final outcome. This issue can be addressed by employing the machinery of weighted votinggames. In such games, each agent is associated with a nonnegative weight, and a subset (coalition) of agents is deemed to✩A preliminary version of this paper was presented at the Twenty Third AAAI Conference on Artificial Intelligence (AAAI-08).* Corresponding author.E-mail addresses: michez@cs.huji.ac.il (M. Zuckerman), faliszew@agh.edu.pl (P. Faliszewski), yorambac@gmail.com (Y. Bachrach), eelkind@ntu.edu.sg(E. Elkind).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.12.003\f2M. Zuckerman et al. / Artificial Intelligence 180–181 (2012) 1–19be winning if its weight meets or exceeds a given quota. The voter’s weight reflects her relative importance in the decision-making process: more important voters are assigned a higher weight. The quota is typically set to be slightly greater thanhalf of the total weight, but other values of quota (e.g., 2/3 of the total weight) are quite common as well.Even though weights are intended to model the agents’ relative importance, an agent’s ability to influence the groupdecision is not always directly proportional to her weight. For example, if the quota is so high that the only winningcoalition is the one that involves all agents, each agent can veto the decision, and hence all agents have equal power. Thus,to measure the power, instead of using agents’ weights, one typically employs one of the so-called power indices. Perhapsthe most prominent ones among them are the Shapley–Shubik index [41] and the Banzhaf index [11,6]. Intuitively, bothof these indices measure the probability that a given agent is critical to a forming coalition, i.e., that the coalition wouldbecome winning if the agent joined in; the difference between these two power indices comes from different coalitionformation models. Besides measuring the apriori voting power, the power indices can be used to share the payoff obtainedby executing the task: a natural approach is to pay each agent in proportion to their voting power, i.e., their Shapley–Shubikindex or their Banzhaf index. Also, in politics, power indices provide very useful information to lobbyists who need to decidehow to allocate their contributions.The importance of power indices makes them a natural target for manipulators, i.e., rogue parties that want to increaseor decrease the voting power of a certain agent.1 Now, accomplishing this goal by changing an agent’s weight may requirea substantial investment on the manipulator’s part, such as, e.g., recruiting additional supporters of a political party. Incontrast, it may be relatively easy to change the quota. Indeed, such changes are not unusual in political decision-making,and can be explained by the desire to build a consensus (if the quota is increased) or simplify the passage of bills (if thequota is decreased)—for instance, a recent move by Democratic members of the U.S. Senate to change the filibuster rules [22]can be viewed as an attempt to change the quota. Therefore, the entity that determines the format of the decision-makingprocedure (in what follows, we will refer to this entity as the central authority) might be able to change the quota withoutencountering substantial resistance. However, this seemingly innocent change may have very different effects on differentvoters, and therefore the central authority can use it to advance its own goals.In some settings, the quota may have to be updated in response to other changes in the voting system, such as expansionof the system to include new players (as was the case, for instance, when the European Union expanded from 15 to 27member states) or changes to players’ weights (it is plausible that in the future the countries’ weights in the EU Councilmay have to be updated to reflect the demographic changes). In such scenarios, the central authority would normally havesome freedom in setting the quota and may pursue a variety of objectives when doing so; for a discussion of this issue inthe context of European Union enlargement, see [28,30,32].In this paper, we study the effect of quota changes on the agents’ power, as measured by the Shapley–Shubik power indexand by the Banzhaf power index. We first provide tight bounds on the change in voter’s power that can be accomplishedby modifying the quota. It turns out that there are settings where all voters except for the one with the maximum weightcan have their voting power reduced to zero by an appropriate choice of the quota, i.e., the ratio between the voter’s powerbefore and after the change of quota can be unbounded; however, for both indices, we can obtain tight worst-case boundson the difference between the values of the index before and after the change.Having established that changing the quota may have a very significant effect on the agents’ power, we focus on thealgorithmic aspects of the manipulator’s problem. The manipulator may want to either minimize or maximize the targetplayer’s power. We limit our attention to the former problem. In this case, the best that the manipulator can hope for is tomake the target player a dummy, i.e., to ensure that this player’s power (as measured by both indices) is 0. We show thatthe center can easily determine whether there is a quota value that accomplishes this. This result is somewhat surprising,since checking if a given agent is a dummy for a fixed value of the quota is well-known to be coNP-complete [37,10,35].The ranking of the agents is sometimes more important than the exact power they possess: for instance, a party inparliament may have a better negotiating position if it is among the top three most powerful players. Therefore, we alsostudy the problem of setting the quota so as to guarantee a particular relation (equality or inequality) between two agents’power-index values. We demonstrate that as long as two agents have different weights, the quota can be selected so thatthey have different voting power. A related issue that we consider is that of selecting the quota so as to ensure that allagents with different weights have different power-index values. We exhibit a family of weight vectors for which essentiallyany value of the quota has this property. In contrast, we show that if agents’ weights grow fast enough, this goal cannot beachieved.In many real-life settings, the center will only be able to change the quota by a relatively small amount, or choose amonga few acceptable quota values. It is therefore interesting to ask if the manipulator can achieve his goals when his abilityto change the quota is constrained. We provide a twofold answer to this question. First, we show that choosing the quotaoptimally from a given set is likely to be hard. Specifically,",
            {
                "entities": [
                    [
                        146,
                        193,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 315 (2023) 103825Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintStrategyproof Allocation Mechanisms with Endowments and M-convex Distributional Constraints ✩Takamasa Suzuki a, Akihisa Tamura b, Kentaro Yahiro c, Makoto Yokoo c, Yuzhe Zhang d,∗a Gifu Shotoku Gakuen University, Gifu, Japanb Keio University, Yokohama, Japanc Kyushu University, Fukuoka, Japand University of Groningen, Groningen, the Netherlandsa r t i c l e i n f oa b s t r a c tArticle history:Received 25 September 2020Received in revised form 17 April 2022Accepted 10 November 2022Available online 15 November 2022Keywords:Controlled school choiceM-convex setStrategyproofnessTop trading cyclesDeferred acceptanceDistributional constraints1. IntroductionWe consider an allocation problem of multiple types of objects to agents, where each type of object has multiple copies (e.g., multiple seats in a school), each agent is endowed with an object, and some distributional constraints are imposed on the allocation (e.g., minimum/maximum quotas). We develop two mechanisms that are strategyproof, feasible (they always satisfy distributional constraints), and individually rational, assuming the distributional constraints are represented by an M-convex set. One mechanism, based on Top Trading Cycles, is Pareto efficient; the other, which belongs to the mechanism class specified by Kojima et al. [1], satisfies a relaxed fairness requirement. The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific quotas, and distance constraints. Finally, we experimentally evaluate the performance of these mechanisms by a computer simulation.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).The objective of this paper is to develop mechanisms for allocating indivisible objects to agents without monetary trans-fers, where each individual agent has a prior claim to some object, each type of an object has multiple copies, and some distributional constraints are imposed on the allocation. Our motivation is to apply these mechanisms to controlled school choice programs for public schools, i.e., deciding the allocation of students to schools (where each school has multiple iden-tical seats) when schools offer students the opportunity to attend their preferred public school other than the one closest to where they live, under distributional constraints (e.g., the capacity limits of schools).Our mechanisms are general enough to be applied to any reallocation problem of indivisible objects with multiple sup-plies. For example, in many Japanese universities, undergraduate engineering students must be assigned to a laboratory to This paper is based on our conference paper [2]. The following are the main differences: an extended study of TTC-M’s axiomatic properties (non-✩bossiness, group strategyproofness, weak core, and the characterization of TTC-M based on weak consistency), the introduction of a fair mechanism (DA-R), and an experimental comparison of the proposed mechanisms.* Corresponding author.yokoo@inf.kyushu-u.ac.jp (M. Yokoo), yoezy.zhang@rug.nl (Y. Zhang).E-mail addresses: t.suzuki@gifu.shotoku.ac.jp (T. Suzuki), aki-tamura@math.keio.ac.jp (A. Tamura), yahiro@agent.inf.kyushu-u.ac.jp (K. Yahiro), https://doi.org/10.1016/j.artint.2022.1038250004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fT. Suzuki, A. Tamura, K. Yahiro et al.Artificial Intelligence 315 (2023) 103825conduct projects. However, some students fail to choose the laboratory of greatest interest due to limited familiarity with them. A possible remedy is to apply the following three-step procedure: (i) students are assigned to laboratories using some mechanism, (ii) they experience a certain trial period, and (iii) each student has a chance to apply to another laboratory if she changes her mind or her current laboratory fails to meet her expectations. Our new mechanisms can be used in step (iii). Naturally, no student should be mandatorily reallocated to a laboratory that is worse than her current assignment.Following a seminal work by Abdulkadiro˘glu and Sönmez [3], which formalized a school choice problem in the context of the mechanism design approach, a wide range of theoretical analysis has been conducted on the existing mechanisms used in practice.1 As the theory has been developed and applied to diverse types of environments, mechanism designers have faced a variety of forms of distributional constraints unaddressed by the standard model. For example, Biró et al. [5]was motivated by the Hungarian education system where higher education institutions can declare minimum quotas for study areas that must be satisfied to open courses. Another example is the regional maximum quotas introduced by the Japanese government to control the geographical distribution of medical residents to the country’s hospitals [6].It is well-known that in the presence of distributional constraints, a stable matching may not exist. A matching’s stability was first defined for two-sided, one-to-one matching problems [7]. In the setting of a school choice problem, stability is de-fined as the combination of individual rationality (IR), fairness, and nonwastefulness (NW) [8]. IR is a basic requirement that guarantees that a student2 can obtain a seat in a school that is at least as good as her initial endowment. Fairness ensures that when student s is not accepted by school c (which she believes to be better than her assigned school), then s is ranked lower than any student accepted by c based on c’s preference. NW is an efficiency notion that rules out incidents where a student can move unilaterally to her more preferred school without violating the underlying distributional constraints. Given the incompatibility of stability under distributional constraints, mechanism designers encounter a trade-off between fairness and efficiency. In recent literature on distributional constraints [9–16], a common approach is to weaken stability while maintaining a balance between efficiency and fairness to some extent.In this paper, we examine whether efficiency/fairness is achievable under distributional constraints while guaranteeing IR. More specifically, for efficiency, we study Pareto Efficiency (PE), a stronger welfare notion than NW, which eliminates incidents where students’ welfare can be improved without detracting from the welfare of others while satisfying distribu-tional constraints. For fairness, we study a slightly relaxed requirement such that it is compatible with IR called fairness among Non-Initial Endowment students (NIE-fairness) and examine how it is achieved without sacrificing excessive effi-ciency. It has generally remained an open question whether a Pareto Efficient (PE) mechanism (i.e., a mechanism that is guaranteed to obtain a PE matching) can satisfy some fairness property under distributional constraints [6]. Kamada and Kojima [6], one of the few studies investigating efficiency under distributional constraints, argued that PE is achievable un-der regional maximum quotas. Another study by Hamada et al. [17] develops a PE mechanism and an NIE-fair mechanism when minimum (and standard maximum) quotas are imposed on each school. As described below, the class of distributional constraints studied in this work is a strict generalization of these classes.We restrict our attention to strategyproof (SP) mechanisms, in which no student has an incentive to misreport her preference over schools. In theory, we can restrict our attention to SP mechanisms without loss of generality due to the well-known revelation principle [18]: if a certain property is achieved by a mechanism (more specifically, that property is satisfied in a dominant strategy equilibrium when using the mechanism), it can be achieved by an SP mechanism. An SP mechanism is also useful in practice since a student does not need to speculate about the actions of other students to obtain a good outcome; she only needs to truthfully report her preference.In this paper, we consider a class of distributional constraints that can be represented by an M-convex set (M stands for Matroid), a concept introduced in the field of discrete mathematics, which is a discrete counterpart of the frame-work of convex analysis [19,20]. We show that the M-convexity of the underlying distributional constraints is sufficient to guarantee the existence of mechanisms that satisfy desirable properties. The class of distributional constraints that can be represented by an M-convex set contains many situations raised from realistic matching problems, including individual minimum/maximum quotas (Fragiadakis et al. [9], Hamada et al. [17]), regional maximum quotas (Goto et al. [11], Kamada and Kojima [6]), type-specific maximum quotas (Abdulkadiro˘glu [21], Fragiadakis and Troyan [10]), and distance constraints (Kojima et al. [1]).We require an additional assumption: if every student is assigned to her initial endowment school, the underlying dis-tributional constraints are satisfied. This is an innocent requirement in the context of school choice since every student would attend her local school if there is no school choice program; assuming this default allocation satisfies distributional constraints is reasonable.Our mechanism achieving PE is based on the Top Trading Cycles (TTC) mechanism [22] developed by David Gale. TTC improves students’ welfare by trading their initial endowments. Our mechanism achieving NIE-fairness belongs to a mecha-nism class specified by Kojima et al. [1], which is a generalization of the Deferred Acceptance (DA) mechanism [7]. Both ar",
            {
                "entities": [
                    [
                        153,
                        244,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 77 (1995) 249-284 Artificial Intelligence A circumscriptive calculus of events Murray Shanahan* Imperial College, Department of Computing, 180 Queen’s Gate, London SW7 ZBZ, UK Received July 1992; revised January 1994 Abstract to the frame problem A calculus of events events with nondeterministic solution developed theorem minimisation nondeterminism. continuous for is presented in which domain constraints, concurrent events, and effects can be represented. The paper offers a nonmonotonic two of the techniques that combines for this formalism the situation is presented which guarantees this solution, Finally, calculus, namely causal and state-based minimisation. A that temporal projection will not interfere with and to cope with in domains with ramifications, the paper shows how the formalism can be extended concurrency, even in change, whilst preserving the conditions for the theorem to apply. 1. Introduction the thoughts and Hayes by McCarthy if we deploy classical The frame problem was first described in the Sixties of AI researchers ever since. In a nutshell, logic in a straightforward way to [23], and has occupied the problem is this: describe are not affected by each action, as well as those because huge in all but the most trivial domains.’ By the early Eighties, the frame problem could be solved using the newly developed formal default reasoning demonstrated counter-intuitive the effects of actions, we have to represent explicitly which properties that are. This is a problem that are not affected by an action tends to be it was thought that techniques of [8] to these results. Many authors, such as Lifschitz [13] and Shoham [37], (McCarthy the naive application [22]). However, Hanks and McDermott the number of properties techniques could lead that of * Telephone: +44 171589 5111. E-mail: rnps@doc.ic.ac.uk. 1 A particularly clear description of the frame problem is to be found in McDermott [24]. 0004-3702/95/$09.50 SSDZ 0004-3702(94)00036-Z 0 1995 Elsevier Science B.V. All rights reserved \f250 M. Shanahan I Artificial Intelligence 77 (1995) 249-284 rose to the challenge of finding solutions that yielded correct conclusions with the earlier attempts.’ examples that had undermined By the end of the Eighties, the emphasis of research on the frame problem had shifted towards providing solutions which could deal with the features of complex (which arise domains. Baker [l], for example, addressed the with domain constraints). Lin and Shoham [19], on the other hand, examined problem of concurrent is issues still need perhaps now within our grasp. However, a number of outstanding that effects, to be resolved, chief among which are actions with nondeterministic is actions whose precise effects are unknown, and continuous change. the issue of ramifications to the frame problem events. A complete solution Besides focussing on the features of complex domains such as concurrency, and continuous change, current proposals for solving the frame in another way. No longer is it to argue for the validity of a proposed solution using only a such as Hanks and McDermott’s Yale nondeterminism problem are distinguished considered acceptable small number of benchmark shooting scenario. Following Lifschitz [15], a proposal has to be mathematically justified for a substantial class of problems (see also Sandewall [32]). from their antecedents examples, for is given this formalism, This paper offers a predicate-calculus-based formalism the representation effects.” A nonmonotonic based on for representing and of concurrent events reasoning about change, which facilitates solution to the frame and events with nondeterministic the problem extensions of certain predicates using standard prioritised circumscription.4 The solution works for examples and events with nondeterministic which suggests that the solution has very general application. Another presented with facilitates the construction Finally, change, whilst preserving results. algorithms. to cope with continuous the conditions of applicability of these mathematical involving effects. A mathematical the paper shows how to extend of temporal projection (domain constraints) idea of minimising is demonstrated the formalism ramifications result result is the Unlike most of the work cited in this introduction, to the frame problem offered in this paper is not based on the situation calculus of McCarthy and Hayes [23]. Although some authors have offered hints and suggestions as to how continuous change could be formulated using the situation calculus (Gelfond the solution celebrated such as Loui [20], questioned the Yale shooting actions ’ Hanks and McDermott’s authors, this example. The task I set myself scenario Yale shooting representing ’ I will not distinguish ’ A number solutions “elaboration-tolerance” domain necessitates elaboration-tolerant theory. the complete solution, of authors, the frame problem to example has become known as the Yale shooting the assumptions in the present paper underlying Hanks and McDermott’s is to address the frame problem. scenario. Some analysis of I will use the in simply as an example of where the frame problem arises. I am not interested scenario per se. from events in this paper. notably Haas for [7], Schubert the situation [33], and Reiter calculus. Arguably, (John McCarthy’s term), because the acquisition reconstruction of the domain in which new knowledge is automatically [28], have proposed monotonic solutions these of new knowledge theory. The present paper into absorbed do not offer the about supplies an the existing \fM. Shanahan I Artificial Intelligence 77 (1995) 249-284 251 et al. [6]), it is not yet clear how this could be done. On the other hand, work event calculus of Kowalski and already exists which extends Sergot [ll] [35]), and this work, taken out of the framework of logic programming and augmented with a circumscriptive approach is the basis of the formalism presented here. to deal with continuous change (Shanahan to default reasoning, the narrative-based types, includes event initiated, negation-as-failure once a property has been The ontology of Kowalski and Sergot’s formalism time points and properties. Properties are initiated and terminated by events. In their is used formalism, to it, and this is assume that it persists by default until an event occurs to terminate how the frame problem in this paper is similar unlike Kowalski and Sergot’s in extended Horn clauses and uses negation-as- formalism, which is expressed the full expressive power of first-order that presented failure, cannot be relied on to supply predicate calculus, and therefore negation-as-failure a solution solution offered here takes advantage of the insights of several previous authors, whose work I will now briefly review. is addressed. The calculus of events presented to the frame problem. The circumscriptive respects.5 However, here exploits in many [12], Kautz [8] discovered such as Lifschitz [3] and Lifschitz [lo] and Shoham such as McCarthy’s flaws in early efforts [l, 21, Baker and Ginsberg After Hanks and McDermott to overcome [22], several authors developed more the frame problem, robust solutions, [37] who use chronological minimisation, Haugh [9] and Lifschitz [13] who use causal minimisa- [15] who use tion, and Baker state-based minimisation. The last two approaches, which were developed for the situation calculus, are based on the following simple observation. The Hanks- of McDermott minimisationP This independence in by minimising predicates whose which the frame problem In other words, of projection. extensions to be minimised if the predicates minimisation can be separated facts. For example, with express causal minimisation, true facts about the effects of actions. is independent can be achieved by designing a formalism can be overcome the outcome from projection the predicates which are minimised express problem does not arise if temporal projection do not depend on than time-varying true facts, rather timelessly timelessly the principle The difficulty with this approach of separating minimisation the formalism has sufficient expressive power that the only predicates is from projection to capture rich to ensure that to be minimised domains, whilst preserving express the existing work using causal timelessly minimisation does not cope adequately with ramifications, as shown by Baker [l]. [l]). With State-based minimisation handles state-based minimisation, timelessly true facts about the abnormality of certain actions with respect to change. These to states, whose existence and facts are timelessly true because they are relativised (Baker ramifications much better the predicates which are minimised express facts. For example, true 5 In what follows, I will use the term “event calculus” to refer to the formalism presented here, not to Kowalski and Sergot’s formalism. 6 This separation is also the basis of the more recent approach of Crawford and Etherington [4]. \f252 M. Shanahan I Ardficial Intelligence 77 (1995) 249-284 properties problem are described independent of temporal projection. The solution to the frame here uses a hybrid of causal and state-based minimisation. The paper is organised to the frame problem as follows. The event are presented calculus and the accompanying in the next of its use, without two sections, any proof of correctness. followed by Blocks World example the mathematical solution a traditional Then are developed: class of problems, algorithms. presented, illustrate examples with ramifications formalism the mathematical is extended Further results which properties of the formalism are investigated. one which suggests and another examples that to aid the the frame problem the construction of application the use of these mathematical and events with nondeterministic of the is solved of temporal formalism results. These Two results for a wide projection are then include the that e",
            {
                "entities": [
                    [
                        75,
                        111,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 95 ( 1997) l-65 Artificial Intelligence Engineering and compiling planning domain models to promote validity and efficiency T.L. McCluskey *, J.M. Porteous The School of Computing and Mathematics, The University of Huddersjield, Queensgate. Huddersjield HDI 3DH, United Kingdom ’ Received July 1996; revised May 1997 Abstract This paper postulates a rigorous method for the construction of classical planning domain models. We describe, with the help of a non-trivial example, a tool-supported method for encoding such models. The method results in an “object-centred” specification of the domain that lifts the representation from the level of the literal to the level of the object. Thus, for example, operators are defined in terms of how they change the state of objects, and planning states are defined as amalgams of the objects’ states. The method features two classes of tools: for initial capture and validation of the domain model; and for operationalising the domain model (a process we call compilation) for later planning. Here we focus on compilation tools used to generate macros and goal orders to be utilised at plan generation time. We describe them in depth, and evaluate empirically their combined benefits in plan generation speed-up. The method’s main benefit is in helping the modeller to produce a tight, valid and operational domain model. It also has the potential benefits of (i) forcing a change of emphasis in classical planning research to encompass knowledge-based aspects of target planning domains in a system- atic manner, (ii) helping to bridge the gap between the research area of theoretical but unrealistic planning on the one hand, and “scruffy” but real-world planning on the other, (iii) a commitment to a knowledge representation form which allows powerful techniques for planning domain model validation and planning algorithm speed-up can be bound up into a tool-supported environment. @ 1997 Elsevier Science B.V. Keywords: Planning; Knowledge compilation; Domain modelling * Corresponding author. Email: ’ Email: julie@zeus.hud.ac.uk. lee@zeus.hud.ac.uk. 0004.3702/97/$17,00 PII SOOO4-3702(97)00034-9 @ 1997 Elsevier Science B.V. All rights reserved \f2 ZL. McCluskey, J.M. Porteous/ArtiJicial Intelligence 95 (I 997) 1-65 1. Introduction 1.1. The problems of “knowledge sparse” planning Intelligence frameworks in Artificial structure, containing the relative performance has for decades concentrated into classical planning issues of planning algorithms. Recent work has concentrated planners of total-order versus partial-order [ 7,231, extending complexity of plan generation [25], and general, research has been dominated level of representation, on, for ex- [ 3,44,57], the expres- for planning theoretical by the use of the literal or propo- actions, as the formulae made up of these literals. Although en- action little commitment Research on theoretical ample, the inherent computational siveness of the classical model [ 311. This engines sition as the basic basic knowledge vironmental assumptions and the closed world characterise to a more elaborate knowledge structure has been made. In this paper we argue research issues edge acquisition from the syntactic “object”. Several issues have ners. that in isolation of knowl- this, there should be a move away level of the in classical planning and representation representational lines of argument and, to facilitate primitive of the literal, lead us to believe into account when making claims about Planning such as default persistence, should not be considered the classical approach, to the semantic that knowledge representational and operators instantaneous to be taken deterministic representing in general and Plan- causal planners planners. linear planners, Firstly, consider link partial-order the recent trend in AI Planning over a number of different planning research to analyse of the classical generative planner linear and partial-order suggested the computational to compare and results with Initial that they were more efficient redundancy these strategies can give wildly vary- In a similar rather total- or partial-order, we should concentrate on than match different planners for hybrid planners in different problem do- properties of different variations the efficiency tradeoffs between systematic than in part as a result of reducing results have been called into question, as fixed planning ing relative performance vein, some researchers have concluded than ponder over which is preferable, where off against each other, research [32] or different domain-independent mains the choice of optimal frameworks encodings. that even in the range of domains open to classical planning, and so we need to take advantage of domain strategy appears domain-dependent, focus on control strategies the wrong question: that we are asking strategy. So rather [ 551. We conclude to use a particular and mechanisms [3,39]. But classification for planning for domain it is best heuristics domains. research should Secondly, there is a need to fill the gap between clean [ 26,421. Researchers who are exploring of planning practical applications features of planning necessarily use simple domains intensive acquisition to the research scenario, (HCI, user and reliability issues. On the other hand real-world planning as well as planning and software experts-a in that many non-functional to be considered. issues have training. In making etc.), hardware and software constraints, to facilitate theoretically research and the abstract reasoning about search requires teams of both knowledge completely different “ball game” such as user factors time, response this system towards bridging requirements steps \fTL. McCluske)s J.M. Porteous/ArGjicial lnrelligence 95 (1997) l-65 3 gap we must be careful we keep within modelling planning step forward. that while moving away from the “knowledge the spectrum of “clean AI”. Hence we see a systematic domains, within a standard, broad representational sparse” stance to approach framework, as a Thirdly, work has shown how performance strategy of the same domain model. Some researchers have testified insignificant in performance can vary by using a fixed planning from seemingly that can result to a domain encoding. An example of this is given for the performance of the system in [ 24, p. 9161. Even results favouring one planner over another that or into some the same domain encoding may be flawed in that it is the particular encoding in the domain. Guidelines a planner, for encoding domains would at least put this encoding problem than something intrinsic rather with different encodings to the large differences changes PRODIGY/EBL using is favouring frameworks context. 1.2. Implications of introducing knowledge representation issues In introducing representational issues we have three phenomena to consider: is the and (ii), to (i), reality), software the model. to conform is supposed is supposed and validating language used to encode itself (a reality, or an imagined relational testing. Using then debugging the planning to capture a piece of reality (block to a theoretical model, or an outline algorithm, etc.), and so, unlike software, for the purposes of acceptance it with respect to be used with it. Whereas planning stacking, machine- criteria such as correctness (iii) as a framework, levels of cohesion and self-consistency in relational a real client one would need to have guidelines and in applications for this kind of construction. This is apparently not the case in AI planning their specification the domain (i) the symbolic domain model, and (ii) the representation (iii) creating Initially often as hard as debugging software domain model shop scheduling, are inappropriate one can devise guidelines for domain models databases) and metrics models and appear sparse and underdeveloped. 2 For example, [ 591, Weld equates a domain specification with a set of pre- and post condition operators, yet this form of definition alone leaves questions unanswered domain?“. More generally, one might those conditions on any valid state. Also, the way that domain models are constructed purposes of research evaluation ever given. (particularly and sufficient for the appears ad hoc as the reasons for an encoding are rarely and tests to capture like the concept and process of normalisation reasonably the closed world assumption) expect domain models to include necessary a valid initial state in the such as “what constitutes that have dominated in the literature-they incorporating languages involving (rather in In Fig. 1, we show the typical concerns of the modeller as model validation, expressive issues are also language used for interaction with the language, and ease of maintenance. Validation of the representation power of the specification to understandability linked * There has been some work in developing “realistic” planner representation languages (e.g. 1 lo] ) but not within the realms of Al planning, despite the move to more expressive languages such as ADL [ 461. \f4 T.L. McCluskey, J.M. Porteous/Art@iul Intelligence 95 (1997) I-65 s MODELLER concerns include validat expressive power and maintenance of the model of the planning algorithm SHARED concerns include plan quality Fig. I Views of the domain model. Modeller INITIAL DOMAIN MODEL Tools: e.g. syntax, type and consistency checking COMPILABLE DOMAIN MODEL Tools: e.g. goal order, macro and abstraction hierarchy generators RUNNABLE DOMAIN MODEL Tools: e.g. random task generator and planner I “PROVEN” DOMAIN MODEL maintenance Fig. 2. The development of a domain model using tool support. of the input model are that it should planner, a concern cited in [ 291. From the planning algorithm’s point of view the typical lead to efficient and effective plan requirements generation. This generally entails that it is in some that can be separated out from the planning standard, simple format, and any proce",
            {
                "entities": [
                    [
                        64,
                        147,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 215 (2014) 1–23Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFractals and RavensKeith McGreggor∗, Maithilee Kunda, Ashok GoelDesign & Intelligence Laboratory, School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA 30332, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 4 June 2013Received in revised form 14 April 2014Accepted 13 May 2014Available online 20 May 2014Keywords:AnalogyVisual reasoningFractal representationsComputational psychometrics1. IntroductionWe report a novel approach to visual analogical reasoning, one afforded expressly by fractalrepresentations. We first describe the nature of visual analogies and fractal representations.Next, we exhibit the Fractal Ravens algorithm through a detailed example, describe itsperformance on all major variants of the Raven’s Progressive Matrices tests, and discussthe implications and next steps. In addition, we illustrate the importance of consideringthe confidence of the answers, and show how ambiguity may be used as a guide for theautomatic adjustment of the problem representation. To our knowledge, this is the firstpublished account of a computational model’s attempt at the entire Raven’s test suite.© 2014 Elsevier B.V. All rights reserved.Despite references to its role as core to cognition [33,35], analogy defies a singular definition [58]. In one way, analogymay be seen as a process of transference, a mapping of knowledge from one situation to another, based upon a judgmentof the similarity between the two situations [12,19,20,22–27,37,40,57,67]. Gentner [24], for example, proposed that analo-gies entail transfer of relations from a source case to a target problem and that judgment of similarity between the targetand the source depends on the correspondence between the structure of their representations. Holyoak and Thagard [37]proposed that judgments of similarity between a source case and a target problem depend on multiple criteria: structuralcorrespondence, semantic similarity, and pragmatic constraints. Keane [40] proposed incremental mapping between thesource case and the target problem. Dunbar [19] found a paradox in that humans appear to exhibit significant spontaneoususe of analogies in their natural workflow but less so in laboratory settings. Kokinov and Petrov [42] describe several con-straints to facilitate the integration of analogue retrieval from memory and analogical transfer. Holyoak and Hummel [36]similarly examine findings for recruiting memory, reasoning and learning in the service of analogy making. Clement [12] de-scribes several processes of analogy such as the use of intermediate representations (or bridging analogies). Nersessian [57]similarly describes the use of generic mechanisms in scientific analogies. Our own work on model-based analogy [6,28] hasfocused on the use of semantic similarity and pragmatics constraints for evaluating similarity between source cases and tar-get problems, and identification and abstraction of generic mechanisms for transfer from a source case to a target problemin creative design [6,28,29].In contrast, case-based reasoning [1,43,49,63] views within-domain analogical reasoning as a memory task in whichmemory supplies a source case containing an almost correct solution to the target problem. Hammond [32], for example,describes retrieval of plans based on semantic similarity to the target problem and modification of the retrieved plan tomeet the target goal. Ashley and Rissland [3] describe the use of case-based reasoning in law. Smyth, Cunningham and Keane[65] describe hierarchical case-based reasoning, and Aha, Breslow and Munoz-Avila [2] describe conversational case-based* Corresponding author.E-mail addresses: keith.mcgreggor@gatech.edu (K. McGreggor), mkunda@gatech.edu (M. Kunda), goel@cc.gatech.edu (A. Goel).http://dx.doi.org/10.1016/j.artint.2014.05.0050004-3702/© 2014 Elsevier B.V. All rights reserved.\f2K. McGreggor et al. / Artificial Intelligence 215 (2014) 1–23Fig. 1. Problem similar to those of the Raven’s Standard Progressive Matrices test.reasoning. Our own work on case-based reasoning has focused in integration of case-based and model-based reasoning foradaptive design [30].Another line of research views analogy as a mechanism of perception, where one situation is recognized in terms ofanother [10,34,56] or as a mechanism of learning, where one situation is interpreted in terms of another [39]. Yet anotherline of research on analogy pertains to visual analogy [13–17,69,70]. In visual analogy, the source case and the targetproblem contain only modal, visual knowledge, and causality is (at most) implicit. For example, Yaner and Goel [69] describea technique for retrieving design drawings from memory that are similar to a target drawing; Davies, Goel and Yaner [16]describe the technique of constructive analogy for incrementally transferred from the source drawing to the target drawing;and Yaner and Goel [70] describe the technique of compositional modeling that builds a causal model of the target drawingby analogy to the causal model of the source drawing.Each of these schools of thought emphasizes the importance of certain aspects of analogy making, and, in turn, estab-lishes certain criteria that must be achieved by any associated methodologies through some combination of mechanismand representation. Our work concerns visual analogy, the act of forming analogies based upon purely visual perceptions,or, more formally, upon a purely visual perceptual history. We propose a new representation – the fractal representation– and corresponding mechanism for addressing a class of visual analogies that occur in computational psychometrics, andin particular, on the Raven’s Progressive Matrices test of intelligence. Although we focus our remarks on representation,visual analogy, and psychometrics, we expressly make no claims as to whether our model may be extended to provide fora cognitive account.1.1. Computational psychometricsAI research on computational psychometrics dates at least as far back as Evans’ Analogy program [21], which addressedgeometric analogy problems on the Miller Geometric Analogies test of intelligence. Bringsjord and Schimanski [7] haveproposed computational psychometrics, i.e., AI that can pass psychometric tests of intelligence, as a possible mechanism formeasuring and comparing AI.Raven’s Progressive Matrices Test suite is a set of standard and common tests of intelligence [61]. The standard versionof the test consists of 60 geometric analogy problems. Fig. 1 illustrates a problem typical to those that appear on the test.1The task in the problem is to pick one of the eight choices in the bottom of the figure for insertion in that bottom-rightelement of the 3 × 3 matrix in the top of the figure. The chosen element should best match the patterns in the rows andcolumns of the matrix.The Raven’s Progressive Matrices (RPM) test paradigm is intended to measure eductive ability, the ability to extract andprocess information from a novel situation [61]. Eductive ability stands in contrast to reproductive ability, which is theability to recall and use previously learned information.The problems from Raven’s various tests are organized into five sets. Each successive set is generally interpreted to bemore difficult than the prior set. Some of the problem sets are 2 × 2 matrices of images with six possible answers; theremaining sets are 3 × 3 matrices of images with eight possible answers.1 Throughout this paper, we use example problems that are similar to those found on Raven’s tests, due to copyright concerns and to ensure the integrityof the tests themselves. The results we report, however, are from the actual test problems.\fK. McGreggor et al. / Artificial Intelligence 215 (2014) 1–233The tests are purely visual: no verbal information accompanies the tests. The test-taker is asked to select from theavailable possible answers the single answer that best completes the matrix [61].1.2. Prior approaches to RPMOver the years, different models have proposed various combinations of representations and mechanisms for solvingRPM problems. Hunt [38] gives a theoretical account of the information processing demands of certain problems fromthe Advanced Progressive Matrices (APM), in which he proposes two qualitatively different solution algorithms—“Gestalt,”which uses visual operations on analogical representations, and “Analytic,” which uses logical operations on conceptualrepresentations.Carpenter, Just, and Shell [9] describe a computational model that simulates solving RPM problems using propositionalrepresentations. Their model is based on the traditional production system architecture, with a long-term memory contain-ing a set of hand-authored productions and a working memory containing the current state of problem solving (e.g. currentgoals). Productions are based on the relations among the entities in an RPM problem, for example, the location of the darkcomponent in a row, which might be the top half in the top row of a problem, bottom-half in the bottom row, and so on.They did not test their system on the Standard Progressive Matrices (SPM), but two different versions of their system solved23 and 32 out of 34 attempted problems on the APM.Bringsjord and Schimanski [7] used a theorem-prover to solve selected RPM problems stated in first-order logic, thoughno results from this effort were reported.Lovett, Forbus and Usher [51] describe a model that extracts qualitative spatial representations from visually segmentedrepresentations of RPM problem inputs and then uses the analogy technique of structure mapping to find solutions and,where needed to achieve better analogies, to regroup or re-segment the initial inputs to form new problem representations.Again, while visual information from the RPM problems is implicit in the final representations, the structure-mapping engineis app",
            {
                "entities": [
                    [
                        133,
                        152,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 117 (2000) 231–253Robust logics ILeslie G. Valiant 1Division of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USAReceived 14 October 1998AbstractSuppose that we wish to learn from examples and counter-examples a criterion for recognizingwhether an assembly of wooden blocks constitutes an arch. Suppose also that we have prepro-grammed recognizers for various relationships, e.g., on-top-of.x; y/, above.x; y/, etc. and believethat some possibly complex expression in terms of these base relationships should suffice to approx-imate the desired notion of an arch. How can we formulate such a relational learning problem soas to exploit the benefits that are demonstrably available in propositional learning, such as attribute-efficient learning by linear separators, and error-resilient learning?We believe that learning in a general setting that allows for multiple objects and relations in thisway is a fundamental key to resolving the following dilemma that arises in the design of intelligentsystems: Mathematical logic is an attractive language of description because it has clear semanticsand sound proof procedures. However, as a basis for large programmed systems it leads to brittlenessbecause, in practice, consistent usage of the various predicate names throughout a system cannotbe guaranteed, except in application areas such as mathematics where the viability of the axiomaticmethod has been demonstrated independently.In this paper we develop the following approach to circumventing this dilemma. We suggest thatbrittleness can be overcome by using a new kind of logic in which each statement is learnable.By allowing the system to learn rules empirically from the environment, relative to any particularprograms it may have for recognizing some base predicates, we enable the system to acquire a setof statements approximately consistent with each other and with the world, without the need for aglobally knowledgeable and consistent programmer.We illustrate this approach by describing a simple logic that has a sound and efficient proofprocedure for reasoning about instances, and that is rendered robust by having the rules learnable.The complexity and accuracy of both learning and deduction are provably polynomial bounded.(cid:211) 2000 Elsevier Science B.V. All rights reserved.I This research was supported in part by grants NSF-CCR-95-04436, NSF-CCR-98-77049, ONR-N00014-96-1-0550, and ARO-DAAL-03-92-G-0115. A preliminary version of this paper appeared in Proc. 31st ACMSymposium on Theory of Computing, Atlanta, GA, May 1999, pp. 642–651.1 Email: valiant@deas.harvard.edu.0004-3702/00/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 0 0 ) 0 0 0 0 2 - 32000 Elsevier Science B.V. All rights reserved.\f232L.G. Valiant / Artificial Intelligence 117 (2000) 231–253Keywords: Learning; Reasoning; Deduction; Soundness; Robustness; Binding problem; Learning rules;Learning relations; PAC learning; PAC semantics1. IntroductionAccording to Aristotle “every belief comes either through syllogism or from induc-tion” [3]. Computational systems that aspire to exhibit some characteristics of intelligenceneed to manipulate beliefs about the world. It is reasonable to ask, therefore, how usefulAristotle’s dictum is for the construction of such systems. Our purpose here is to arguethat the duality expressed by the dictum is fundamental. In particular, we present a for-mal system that encapsulates this duality and, we believe, offers a vehicle for studying thetheoretical basis of such systems.The history of artificial intelligence can be interpreted as having revolved around thisduality from the beginning. Since the 1950s a dominant paradigm, advocated particularlyby McCarthy [28], has been that knowledge should be programmed into systems in auniform logical language as a set of rules, and that logical inference procedures suchas syllogisms be used to draw new inferences. As far as learning, Turing had alreadyspeculated earlier in 1950 that inductive learning would be used to build machines thatthink [41]. A few years later he pointed out the computational limitations of logicalreasoning alone [42].In the last forty years much progress has been made both in machine learning aswell as in computational logic. Nevertheless, the currently dominant theories of the twophenomena of inductive learning, and of logical reasoning are largely disparate, the notableexception being the area of inductive logic programming [30].The purpose of this paper is to suggest a formal system that reconciles principleddeduction, a characteristic of logic, with robustness, a characteristic of learning. Moregenerally, it encompasses learning and reasoning in a integrated way and retains thesomewhat different but crucial benefits that each has to offer.The particular benefits of mathematical logic that we wish to retain are the existenceof a clearly defined semantics for each statement, and the existence of proof proceduresthat enable new statements to be derived. In particular, the well defined semantics makespossible proof procedures that are sound: new statements that are derived from truestatements are themselves true.The main benefits of learning that need to be retained are that it provides a mechanismby which knowledge can be acquired in fragments that may be incomplete, inconsistent orinaccurate, by a system that has no understanding either of its own current global state ofknowledge, or of a consistent language of description of the world.These benefits of learning are somewhat irreconcilable with standard logics, where therules have to be expressed in terms of a set of predicates with globally consistent meanings.Such enforced global consistency may be achievable in application areas that are knownto be amenable to axiomatization, such as much of mathematics. In other areas, such asthe world of “commonsense” knowledge, where no such axiomatizations have been found,this approach has led to systems that are “brittle”.The minimal requirements for what we shall call a robust logic are the existence of:\fL.G. Valiant / Artificial Intelligence 117 (2000) 231–253233(i) Rules to encode knowledge that allow for multiple objects and for relations amongthem.(ii) A well defined semantics for the rules.(iii) An inference procedure for applying rules to instances that is sound and polynomialtime.(iv) Polynomial time algorithms for learning the rules from examples.Standard predicate calculus suitably constrained, to Horn clauses, for example, satisfiesthe first three of these requirements. Part (iv) of our definition can be interpreted mostsimply as claiming that one can make a logic robust if one provides a means of evaluatingthe accuracy of any statement in it, independently of others, by an empirical process thathas access to raw data from the world.In this paper we describe one particular such robust logic. It arose from efforts to providetheoretical underpinnings for the neuroidal architecture that is described in a companionpaper [47]. It has some added benefits, therefore, that derive from that architecture:(v) The rules can be implemented on a fixed network that mirrors their modularitiesand dependencies, and the inference procedure can be executed naturally on thatnetwork.(vi) The classes of connective functions that are allowed include a class, namelylinear threshold functions, that has ideal learnability properties: there exist efficientlearning algorithms for it that are both attribute-efficient and also (according toexperimental evidence) error-resilient.The main departure from traditional logic is that the semantics used here is PACsemantics adopted from machine learning. This views inductive learning as a “compu-statistical” phenomenon: observations on the world provide empirical evidence about rulesthat hold generally in the world. The learner chooses from a space of possible rulesaccording to the weight of statistical evidence, while computational constraints makethis choice computationally feasible. This allows robust learning from inaccurate andinconsistent data to be accomplished and to be put on a rigorous foundation. Most basicallyit is assumed that at any instant the system has some set of primitive sensors, and that itsobservations of the world can be regarded as induced by a probability distribution D oversets of sensor readings. This distribution D may be arbitrarily complex, reflecting as it doesthe complexities of the world. In general the system will not need to know the details of Ddirectly. It will, instead, aim to deal with rules that are “simple truths” in the sense that theyhold in D, at least with high probability. A system based on this logic may be given rulesthat are false most of the time, but the system would have the capability of recognizing thisfact by making enough empirical observations.There exist alternative approaches that address aspects of learning and reasoningsimultaneously. We shall discuss some of these briefly in Section 4.The mechanisms that are needed for learning and reasoning in our particular robust logicare computationally efficient. Their complexity depends only polynomially on the numberof object variables, on the number of rules in the system, and on their length even when theyexploit recursion. The only exponential dependence is on the arity of the relations, whichwe shall assume to be bounded by a small constant. We believe that this set of requirements,which our system satisfies, is indispensable for any formal system to be viable as a basisfor computational intelligence.\f234L.G. Valiant / Artificial Intelligence 117 (2000) 231–2532. ScenesSInformally, the objects in our robust logic should be thought of as referring not directlyto entities in the world but, instead, to representations in an internal image that correspondsto the short-term or working memory of the system. The contents of this image is called ascene.Scenes are defined in terms of a pair .A; e</,",
            {
                "entities": [
                    [
                        42,
                        55,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1615–1638Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAnalogical model formulation for transfer learning in AP PhysicsMatthew Klenk∗,1, Ken ForbusQualitative Reasoning Group, Northwestern University, 2133 Sheridan Road, Evanston, IL 60208, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 29 September 2008Received in revised form 4 September 2009Accepted 18 September 2009Available online 23 September 2009Keywords:Transfer learningAnalogical reasoningModel formulationCase-based reasoningTransfer learning is the ability to apply previously learned knowledge to new problemsor domains. In qualitative reasoning, model formulation is the process of moving fromthe unruly, broad set of concepts used in everyday life to a concise, formal vocabularyof abstractions, assumptions, causal relationships, and models that support problem-solving. Approaching transfer learning from a model formulation perspective, we found thatanalogy with examples can be used to learn how to solve AP Physics style problems. Wecall this process analogical model formulation and implement it in the Companion cognitivearchitecture. A Companion begins with some basic mathematical skills, a broad commonsense ontology, and some qualitative mechanics, but no equations. The Companion usesworked solutions, explanations of example problems at the level of detail appearing intextbooks, to learn what equations are relevant, how to use them, and the assumptionsnecessary to solve physics problems. We present an experiment, conducted by theEducational Testing Service, demonstrating that analogical model formulation enables aCompanion to learn to solve AP Physics style problems. Across six different variationsof relationships between base and target problems, or transfer levels, a Companionexhibited a 63% improvement in initial performance. While already a significant result,we describe an in-depth analysis of this experiment to pinpoint the causes of failures.Interestingly, the sources offailures were primarily due to errors in the externallygenerated problem and worked solution representations as well as some domain-specificproblem-solving strategies, not analogical model formulation. To verify this, we describea second experiment which was performed after fixing these problems. In this secondexperiment, a Companion achieved a 95.8% improvement in initial performance due totransfer, which is nearly perfect. We know of no other problem-solving experiments whichdemonstrate performance of analogical learning over systematic variations of relationshipsbetween problems at this scale.© 2009 Elsevier B.V. All rights reserved.1. IntroductionTransfer learning research is motivated by the observation that people improve in their ability to learn new domainsbased on their experiences in related tasks. We focus here on the task of model formulation [10]. Given a scenario description,a domain theory of model fragments, and a question, model formulation produces a scenario model, which consists of therelevant abstractions, processes, and causal relationships useful for answering the question. An important contribution ofthe qualitative reasoning community has been formalizing this process. For example, methods have been developed toefficiently identify what levels of detail should be included and which perspectives should be taken in a scenario model* Corresponding author.E-mail address: matthew.klenk.ctr@nrl.navy.mil (M. Klenk).1 Current address: Naval Research Laboratory, 4555 Overlook Ave SW, Washington, DC 20375, USA.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.09.003\f1616M. Klenk, K. Forbus / Artificial Intelligence 173 (2009) 1615–1638Fig. 1. Example AP Physics problems of the four types used in this work.[35,42]. However, these approaches have three limitations. First, they rely on having a complete and correct domain theory.Such domain theories are difficult to construct. A more incremental, learning-oriented approach would be valuable for manyapplications, so that a system’s competence could be improved over time as needed. Second, work in model formulationtends to start with fairly abstract scenario descriptions, e.g. circuit schematics or process diagrams. While this is fine forengineering applications, the ability to create qualitative and quantitative models of everyday situations (e.g., the scenariosfound in physics problems) is one of the hallmarks of human flexibility in problem-solving. Third, also due to an emphasison engineering domains, model formulation research has largely ignored learning. We propose instead a quite differentapproach: analogical model formulation. Analogical model formulation builds scenario models of everyday situations, basedon prior experience. We believe that analogical model formulation provides a way to create systems that can incrementallylearn a domain by making effective use of what knowledge they have, even when it is incomplete.Solving physics problems provides a good example of the need for this kind of flexibility. Fig. 1 provides four examples,illustrating types of problems that our system learns to solve. (These problems will be used as examples through the paper.)We factor out natural language understanding by using predicate-calculus versions of these problems, but, unlike previoussystems such as MECHO [3] or ISAAC [36], the translation process leaves everyday concepts in place. That is, balls, buildings,astronauts, boxes, baseball bats, flying, falling, and pulling all appear in the formal problem descriptions.2 Understanding therelevant abstractions and assumptions for a physics problem stated as an everyday scenario is a difficult problem. Modelingdecisions are contextual. For example, a coin falling off a building can be considered to be a point mass. But if we weremodeling the exact same coin spinning on a table, it cannot be considered a point mass since its shape and size must beconsidered. The generalizations in any common-sense ontology are unlikely to provide much help: cats, coins, and pianoscan all be considered as point masses in particular situations, but they are not closely related in any non-trivial ontologywe are aware of. Analogical model formulation addresses the three limitations in model formulation research outlinedabove. First, since it relies on examples, analogical model formulation does not require a complete domain theory. Second,it operates directly with representations of situations drawn from a broad vocabulary of concepts. Finally, by accumulatingexamples, a system using analogical model formulation learns to formulate new models of different situations.While complex, there is ample evidence that people are able to solve physics problems stated in everyday terms. Theproblems used throughout this work were generated by the Educational Testing Service, which administers the AP Physicsexamination in the United States. The AP Physics exam tests the ability of high school students to solve physics problems.Students’ performance on this exam indicates that they do learn to categorize everyday objects in terms of domain ab-stractions, determine what equations are relevant, infer parameter values from scenarios, and assume default circumstanceswhen necessary. The problems used in this work were generated automatically, from templates. The four problems, one fromeach problem type, shown in Fig. 1 represent roughly 20% of the typical Mechanics portion of the AP Physics examination.Solving physics problems via analogical model formulation begins by retrieving an example analogous to the currentscenario. Analogical model formulation uses the explanation of this example to formulate a model of the current scenario.Finally, the system uses traditional rule based reasoning over the model to arrive at a solution for the problem. Usingexample explanations, analogical model formulation enables the system to learn from examples how to make the followingmodeling decisions necessary for solving physics problems:• Which equations are relevant and how they should be instantiated (e.g., the force exerted on the box is equal to themass of the box multiplied by the acceleration of the box).• Which assumptions to make by default (e.g., assuming that events happen on Earth).2 We used a subset of the ResearchCyc ontology, containing over 30,000 concepts. See http://research.cyc.com for details.\fM. Klenk, K. Forbus / Artificial Intelligence 173 (2009) 1615–16381617• Which assumptions about the values of specific quantities to make based on the scenario (e.g., objects at rest have0 m/s).We implement analogical model formulation using the Companion cognitive architecture [18]. A central hypothesis ofthe Companion architecture is that the flexibility and breadth of human common sense reasoning arises from analogicalreasoning and learning from experience [17]. That is, people use their experience to enable them to solve new problems, andover time, extract generalizations and heuristics. For model formulation, this is consistent with Falkenhainer’s [8] observationthat engineers often use analogy with their experience to create new models. Klenk et al. [28] showed that a Companioncan formulate models by analogy to solve everyday physical reasoning problems, such as those on the Bennett MechanicalComprehension Test [2]. This article goes beyond that result by demonstrating that analogical model formulation can beused to solve variations of AP Physics style problems, through an external evaluation involving a substantial number ofproblems over systematic variations in relationships between problems.Characterizing how well learned knowledge transfers is complex. One way involves identifying different transfer levels,each representing a particular type of relationship between a known source problem and a novel target problem. We usean externally-developed set of six transfer ",
            {
                "entities": [
                    [
                        138,
                        202,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 103 (1998) 77-93 Artificial Intelligence Object identification: a Bayesian analysis with application to traffic surveillance * Timothy Huang ’ , Stuart Russell * Computer Science Division, Univer.sity of California, Berkeley CA 94720, USA Abstract Object a fundamental identification-the that allow identity sentences when formulated as evidence task of deciding requirement in standard probability to be grounded identity, as represented by the equality operator between that two observed objects are in fact one and the for any situated agent that reasons about individuals. in predicate calculus, two terms a first-order concept. Raw sensory observations, on the other hand, are essentially theory. This paper in sensory observations, the gap. We begin by defining a physical event space over which probabilities that correspond same object-is Object is essentially propositional&especially describes patterns of reasoning thereby bridging are defined. We then introduce an identity criterion, which selects to identity between observed objects. From this, we are able to compute two objects are the same, given a stream of observations that any that the to appear at subsequent is a natural mode1 for this type of reasoning. We apply in a appearance observations given its current appearance, sites the theory large numbers freeway network, with new heuristics of objects and with online learning of appearance probability models. Despite extremely noisy observations, we are able to achieve high levels of performance. 0 1998 Elsevier Science B.V. All rights reserved. the probability of many objects. We show cars observed by cameras at widely separated which defines how an object can be expected to handle the inevitable complexity of matching to the task of recognizing those events probability, Kqword.r: Object identification; Matching; Data association; Bayesian inference; Traffic surveillance * This work was sponsored by JPL’s New Traffic Sensor Technology program, by California PATH under MOU 152/214, and by ONR Contract NOO014-97-1-0941. * Corresponding author. ’ Now at the Department of Mathematics and Computer Science, Middlebury College, Middlebury, VT 05753, USA. 00043702/98/$ PIl: SOOO4-3702(98)00067-8 -see front matter 0 1998 Elsevier Science B.V. All rights reserved \f7x 7: Hung, S. Russell /Art@d Intelligence 103 (1998) 77-93 1. Introduction Object requirement a fundamental identification-the task of deciding for any situated agent that two observed objects are in fact one and the same object-is that reasons involved about individuals. Our aim in this paper is to establish in object identification. To avoid possibly empty theorizing, we couple this investigation with a real application in freeway significance: in the context of this traffic. Each refinement of the theoretical task. Section 2 application. We begin with a general the probability of identity. Section 3 shows provides a Bayesian how this probability and Section 4 describes our implementation. domain. Related work is discussed foundation can be expressed in terms of appearance probabilities, Section 5 presents experimental the patterns of reasoning to the identification in the application for computing in Section 6. of economic identification is illustrated introduction of vehicles framework results 1. I. Conceptual and theoretical issues is central to our conceptualization The existence of individuals of the world. While object recognition deals with assigning objects to categories, such as 1988 Toyota Celicas or adult humans, object identiJication deals with recognizing such as one’s car or one’s spouse. One can have specific relations it is often or marriage. Hence, particular objects one encounters. speaking, to individuals, to be fairly certain about such as ownership the identity of the specific individuals, important Formally identity is expressed by the equality operator of first-order lot, one might be interested logic. in whether C = this becomes a question of the is always a possibility, Having detected an object C in a parking MyCar. Because mistaken probability of identity: what is identity P(C = MyCar 1 all available evidence)? the events corresponding There has been little work on this question in AI. 2 The approach we will take (Section 2) is the standard Bayesian approach: define an event space, assign a prior, condition on the evidence, and identify to the truth of the identity sentence. The key step is the last, and takes the form of an ident& criterion. Once we have a formula for that are the probability of identity, we must find a way to compute is the available appearance probability. This quantity, which covers diverse domain-specific ranging applicants, seems to be more natural and usable motion models, which require calibration against ground truth. phenomena to changes of address of credit into sensor and in the domain model. Section 3 shows that one natural quantity of interest from the effects of motion, pose, and lighting than the usual division it in terms of quantities 1.2. Application The authors are participants in Roadwatch, of wide-area freeway traffic surveillance and control a major project aimed at the automation is required [7]. Object identification * In contrast, reasoning about category membership based on evidence is the canonical task for probabilistic inference. Proposing that &Car is just a very small category misses the point. \fT Huang, S. Russell /Artificial Intelligence 103 (1998) 77-93 79 (a) (h) Fig. I Images from upstream 99 in Sacramento. California. The boxed vehicle has been identified at both cameras. (b) surveillance cameras roughly (a) and downstream vehicle report stream tracks with local IDS matching e.g. a = 2 paths with global IDS two miles apart on Highway Link travel times O/D counts tracking software system. The video streams are processed at each camera site by Fig. 2. Overall design of our traffic surveillance running on customized parallel hardware. The resulting vehicle ordered vehicle reports are sent to the TMC [Traffic Management Center). The TMC uses these reports determine when a vehicle detected at one camera has reappeared up a path for each vehicle as it travels through link travel times and O/D counts as desired. The output of the system is a traffic information display, updated real time for use by traffic operations managers or by individual drivers. to at another. These matches are used to build to compute in the freeway network. The set of paths can be queried streams of chronologically time taken actual time-the link travel total number of vehicles first, to measure two fixed points on the freeway network; (O/D) counts-the for traffic for two purposes: to provide to travel between traveling between any two origin/destination points on the network in a given time interval. The sensors used in this project are video cameras placed on poles beside the freeway (Fig. 1). The overall system design is shown a complete in Fig. 2. In addition in realistic microscopic that can be placed anywhere on traffic patterns. The simulator to the traffic the freeway network and that transmit level of management center (TMC). The reported data can be corrupted by any desired includes virtual cameras real-time freeway simulator capable of simulating system, we also implemented streams of vehicle reports several hundred vehicles to the real surveillance and second, \f80 7: Huang, S. Russell/Artijcial Inrelligence 103 (1998) 77-93 noise. We found the simulator surveillance algorithms. to be an invaluable tool for designing and debugging the reasons, bandwidth, In addition, this is not feasible. Obviously, a license-plate reader would render the vehicle identification the measurements in rainy, foggy, and night-time task trivial, but In fact, because of very restricted for political and technical the vehicle reports sent to the TMC can contain only about communication contained in the reports one hundred bytes of information. are extremely noisy, especially conditions. Thus, with thousands of vehicles passing each camera every hour, there may be many possible matches for each vehicle. This leads to a combinatorial most likely consistent to that faced in assignments in radar and sonar data association, a form of the object from the tracking. Section 6 explores heuristic for selecting data association reliable matches. This, together with a scheme for online learning of appearance models to handle changing viewing and traffic conditions, yields a system with performance good enough for practical deployment problem arising in more detail. We adopt a solution literature, but also introduce a new “leave-one-out” two large sets of vehicles-that is very similar problem-finding this connection (Section 5). identification between 2. Inferring identity from observations This section shows how the probability of identity can be defined and events. We begin with the formal framework and then illustrate in terms of physical it in the observations traffic domain. 2.1. Formal Bayesian framework Let 0 be a random variable whose domain That is, any particular value of 0 might correspond objects made by some agent: 0 = (01, . . , o,}. Let oa and ob be two specific observations made, which we may think of as having been caused by objects a and b. 3 Informally, we may write the probability of identity of a and b as P(a = b 1 0 = (01, . . , on)). 4 is the set of complete observation histories. to the complete set of observations of To make this probability evaluable, we define an event space S = (HI, , HN), where the “life history” of the kth object in the universe, each Hk is a random variable denoting and each event is an N-tuple specifying the life history of all N objects. We can think of the index k as an invisible “object identification number”. We impose a prior distribution P(S), i.e., invariant under any permutation of with the restriction that the prior is exchangeable, ’ For the",
            {
                "entities": [
                    [
                        74,
                        157,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 103 (1998) 273-294 Artificial Intelligence Applications of the situation calculus to formalizing control and strategic information: the Prolog cut operator Department of Computer Science, The Hong Kong University of Science and Technology, Clear Water Bq Kowloon, Hong Kong Fangzhen Lin ’ Abstract is a natural formalism We argue that the situation calculus and reasoning about information. As a case study, in this paper we provide a situation calculus control and strategic in Prolog. We show that semantics to this our semantics semantics, operator using cut is provably correct with respect to the stable model semantics. 0 1998 Elsevier Science B.V. All rights reserved. is well-behaved when the programs are properly stratified, and that according implementation of the negation-as-failure the central search control operator for the Prolog cut operator, the conventional for representing 1. Introduction The situation calculus reasoning about actions some reserved predicate and function that block A is initially clear, we write: (McCarthy and Hayes [Sl) is a formalism in dynamic domains. and It is a many-sorted predicate calculus with in the blocks world to say symbols. For example, for representing H(clear(A), So), where H is a reserved binary predicate symbol denoting causes on(x, y) to be true, we write: * the initial situation. As an another example, that stands for “holds”, and SO is a reserved constant to say that action stuck(x, y) H(ofi(x, Y), ~~MWx, ~1, s)), ’ E-mail: flin@cs.ust.hk. 2 In this paper, free variables in a displayed formula are assumed to be universally quantified. 0004-3702/98/$ PII: SOOO4-3702(98)00054-X - see front matter 0 1998 Elsevier Science B.V. All rights reserved \f214 E Lin /Artijcinl Intdli~mcr 103 (IWX) 27.1-294 where the reserved function do(u, s) denotes in the situation s. This is an example of how the effects of an action can be represented the situation calculus. Generally, the resulting situation of doing the action a in in the situation calculus: l situations are first-order objects that can be quantified over; l a situation carries information about its history, i.e., the sequence of actions that have been performed so far. For example, the history of the situation do(stack(A. B), do(stuck(B, C), SO)) is [stuck(B, C), stuck(A, B)], i.e., the sequence of actions in the initial situation enforce a one-to-one correspondence to reach it. As we shall see later, our foundational that have been performed axioms will between situations and sequences of actions. information in AI planning, thus isomorphic i.e., sequences of actions according to situations. So control knowledge for a plan in planning, and reasoning about control knowledge. For example, Although our long term goal is to develop a general We believe that these two features of the situation calculus make it a natural formalism representing is a sequence of actions, which often are constraints on desirable plans, becomes constraints on situations Similarly, when we talk about control to constraints on derivations, (Lin [6]). in logic programming, we are referring to (Lin and Reiter [7]). for representing and reasoning the situation calculus, our focus in this paper is the Prolog cut operator, the central search control operator in Prolog. for logic programs with cut, and show semantics We shall provide a situation calculus stratified. We also is well-behaved when the programs are properly that our semantics show that according of the negation-as- implementation the conventional to this semantics, failure operator using cut is provably correct with respect to the stable model semantics of Gelfond and Lifschitz has been shown between a declarative semantics of negation and that of cut. [3]. To the best of our knowledge, this is the first time a connection in problem solving using about control knowledge framework This paper is organized as follows. Section 2 briefly reviews Section 3 reviews the basic concepts in the situation calculus and logic programming. the situation calculus semantics of (Lin and Reiter [7]) for cut-free logic programs. For the purpose of this paper, the key property of this semantics are identified with situations. Section 4 extends this semantics to logic programs with cut. This is done by an axiom on accessible situations, are not “cut off” by cut. Section 5 shows that our semantics stratified programs. Section 6 shows that the conventional failure using cut is provably correct. Finally Section 7 concludes that is, those situations whose corresponding derivations for a class of in logic programming is that derivations is well-behaved implementation of negation-as- this paper. 2. Logical preliminaries 2.1. The situation calculus The language of the situation calculus is a many-sorted We assume propositional for everything the following sorts: situation for situations, action fluents such as clear whose truth values depend on situations, else. As we mentioned above, we assume second-order one with equality. fluent for for actions, and object that Se is a reserved constant \fE Lin / Art$cial lntelligenre IO3 ( 1998) 273-294 21s c do(la,b.cl,SO) d do([a,b,c,dl,SO) a f 0 SO do(a,SO) do(la,cl,SO) Fig. 1. A function f as required by the axiom (6). denoting in a situation, do a reserved binary function denoting addition, we assume the following the initial situation, H a reserved predicate for expressing properties about fluents the result of performing an action. In two partial orders on situations: l C: following convention, we write c in infix form. By s c s’ we mean that s’ can for from s by a sequence of actions. As usual, s C s’ will be a shorthand be obtained s c s’ v s = s’. l C: we also write c in infix form. By s c s’ we mean that s can be obtained by deleting some of its actions. Similarly, s C s’ stands for s c s’ v s = s’. from s’ We shall consider only the discrete situation calculus with the following foundational axioms: So #do@, s). do(ul, sl) = do(a2, ~2) > (al = a2 A s1 = s2), WP)[P(So) A (Vu, s>(P(s> > f’(do(a, s))) 3 (Vs)~C~)l, 7s c so, s c do(a, s’) 3 s c s’, s c s’ = s #s’ A (3f){(Vq 1 SZ>(Sl E $2 3 f@l) c f(s2)) A (‘da, sl>kW, sI) E s 3 do(a, .f@l>> C .y’)l. (1) (2) (3) (4) (5) (6) It amounts from the initial one by repeatedly applying The first two axioms are unique names assumptions for situations. The third axiom is second order induction. to the domain closure axiom that every situation has to be obtained the function do. In other words, a it says that every situation sequence of actions in the initial situation, exactly the isomorphism between situations and sequences of actions that we mentioned earlier. As can be expected, induction will play an important Axioms is either the initial situation So or the result of performing (4) and (5) define C inductively. The partial order c role in this paper. the “prefix” , . . . , a,], SO), S’ & S iff there is a 0 < k < II such is really relation: 3 Given a situation S = do([al that 5” = do([al. . . . , ak], SO). In particular, we have (Vs)So E s. Axiom (6) defines C. Informally, s C s’ iff s can be obtained of its actions. More precisely, suppose S’ = do([al , . from s’ by deleting some . a,], So). Then S C S’ iff there 3 Given a sequence of actions [al,. , a,], we use &([a~, a,], S) to denote the resulting situation of performing the sequence of actions in S. Inductively, &I([]. .s) = s and do([aJL], S) = d&L, &(a, s)). \f216 E Lin /Artificial Intelligence 10.3 (1998) 273-294 are integers 1 < il < illustrates a function . < ik < n, 0 6 k < n, such that 5’ = dO([oi, , . . . , ai,], SO). Fig. 1 f as required by axiom (6) for proving the following relation: Ma, cl, So) c doGa, 6, c. 4, So) Notice that c is a special case of C: if s c s’ then s c s’. As we shall see, the partial order c will play a crucial role in this paper. In the following, we shall denote by C the set of the above axioms (l)-(6). 2.2. Logic programs We consider definite logic programs with cut. An atom p is a fluent term F(tl , . , tn), where F is a fluent of arity objectn, and tl , . . , t, are terms of sort object. A goal G is an expression of the form 11 & ... & I, where n 3 0, and for each 1 < i < n, li is either an atom, an equality atom of the form t=t’,or !. Without loss of generality, we assume that a clause (rule) is an expression of the form F(xl,...,x,) :- G where F is a fluent of the arity objecf , x1 , . , x, are distinct variables of sort object, and G is a goal. Notice that the more common form of a clause F(tl,...,t,,) :- G. can be taken to be a shorthand for the following clause: F(xl,....x,) : - xl =tl & ... & xn =tn & G. wherext,..., xn are fresh variables not in G and tl . . , t, Finally, a (definite) program is a finite set of clauses. The dejinition of a fluent symbol F in a program P is the set of clauses in P that have F in their heads. Since a goal is not a situation calculus values. Given a goal G = 11 & . . . & In, and a situation truth value of G in the situation S, to be the situation calculus formula formulas, we need a way to refer to its truth term S, we define H(G, S), the H(ll,S)r\\...r\\ H(l,,S), where for each 1 < i 6 n: (1) If li is t = t’, then H (li , S) is li (2) If li is ! , then H (1,. S) is the tautology For example, H (x = a & parent(x, y) & ! , SO) is true. x = a A H @arent(x, y), SO) A true. 3. A logical semantics The cut operator in Prolog plays a search control operator, it prevents a Prolog two roles. As a goal, it succeeds interpreter from backtracking immediately. As past it. \fF: Lin /Arr$cial Intelligence 103 (1998) 273-294 211 to the program. The rest of this section our semantics for programs with cut will come in two stages. First, we Consequently, the “pure logical” semantics of the programs when cut is taken to be a goal that consider for immediately. For this purpose, we shall use the situation calculus semantics succeeds [7]. For our purpose here, the logic programs without cut proposed by ",
            {
                "entities": [
                    [
                        67,
                        179,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 889–909Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCausal analysis with Chain Event GraphsPeter Thwaites a,∗, Jim Q. Smith a, Eva Riccomagno ba Department of Statistics, University of Warwick, Coventry, CV4 7AL, United Kingdomb Department of Mathematics, Università degli Studi di Genova, Via Dodecaneso 35, 16146 Genova, Italya r t i c l ei n f oa b s t r a c tAs the Chain Event Graph (CEG) has a topology which represents sets of conditionalindependence statements,it becomes especially useful when problems lie naturallyin a discrete asymmetric non-product space domain, or when much context-specificinformation is present. In this paper we show that it can also be a powerful represen-tational tool for a wide variety of causal hypotheses in such domains. Furthermore, wedemonstrate that, as with Causal Bayesian Networks (CBNs), the identifiability of the effectsof causal manipulations when observations of the system are incomplete can be verifiedsimply by reference to the topology of the CEG. We close the paper with a proof of a BackDoor Theorem for CEGs, analogous to Pearl’s Back Door Theorem for CBNs.© 2010 Elsevier B.V. All rights reserved.Article history:Received 16 January 2009Received in revised form 13 May 2010Accepted 13 May 2010Available online 20 May 2010Keywords:Back Door TheoremBayesian NetworkCausal manipulationChain Event GraphConditional independenceEvent treeGraphical model1. IntroductionMuch recent work in the field of causality has focused on how cause relates to control, and the analysis of controlledmodels. Here, with the advocates of this approach we assume the existence of a background idle system which is thensubjected to some sort of intervention or manipulation.The Bayesian Network (BN) is the most commonly used graphical tool for representing complex dependency relation-ships. Interpreting the directionality of the edges of the BN as causal leads to the Causal Bayesian Network (CBN), whichuses a non-parametric representation based on structural equation models [12,19,21,30]. CBNs provide a framework forexpressing assertions about what might happen when the system under study is externally manipulated and some of itsvariables are assigned certain values.BNs and CBNs are ideal for problems which admit a natural product space structure. However many processes do nothave this — they are asymmetric in the sense that measurement variables may have different collections of possible out-comes given different vectors of values for sets of ancestral variables. For a variety of examples see [4,1,10,16,2,17,23].Context-specific variants of BNs exist [2,26,23,18], usually with tree-structured conditional probability tables annexed to thevertices of the BN to allow for the analysis of context-specific independence properties. Although these graphs allow theanalyst a greater flexibility than unmodified BNs, they are still inefficient representations of processes (such as treatmentregimes) whose unfolding depends on the state of the system at any particular point and the values of specific covariates atthat point. Similarly, they are not ideal representations of problems where no outcomes of certain variables could logicallyoccur given some vectors of values of ancestral variables.* Corresponding author.E-mail address: Peter.Thwaites@warwick.ac.uk (P. Thwaites).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.004\f890P. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909There have been major advances in CBN theory in the last decade (see [6,14,20,7,35,34], and [21] for a good review ofthese). The basic Do intervention of Pearl [19] has been extended to functional manipulations (Do X = g(Z )), and stochasticmanipulations which assign a new probability distribution to the state space of the manipulated variable. Nonetheless, atthe most primitive level a manipulation of a BN still corresponds to the setting of certain measurement variables to specificvalues, possibly following some rule or policy. However, whereas the effects of a cause can be reasonably represented by arandom variable, at times the specification of a cause as the value of a random variable can be artificial. Causes are morenaturally represented as conditioning events, and such conditioning is not elegantly expressed in the BN. An analogous caseis made by Dawid [5] who argues that causes are decisions and not decision rules.Although topologically complex, event trees (the elicitation of which often provides the first stage in the developmentof a model) explicitly acknowledge structural asymmetries — context-specific and sample space information is embeddedin the topology of the tree. Their semantics are also often closer to many verbal descriptions of the world, especially whenthose descriptions revolve around how things happen rather than how the world appears. Event trees however, cannot bereadily interrogated for the conditional independence structure of a model.Trees also have their advocates in the study of causality [27,30,25]. In the related field of decision analysis, French andInsua [11] argue that the advantages of influence diagrams over decision trees are illusory, and point out that asymmetricproblems in which a particular choice of action at a decision node makes available different choices of action at subsequent decisionnodes than those available after an alternative choice are the rule rather than the exception. Using trees we can also choosethe level of detail we include in our representation, and this can be dependent on what we intend to do to the system.We can incorporate context specific information that is informative about various causal hypotheses (see for example [8]).This is particularly useful in models of biological regulatory mechanisms, which typically contain many noisy and and orgates [28].In [28] we introduced an alternative graphical model — the Chain Event Graph (CEG), constructed from an event treetogether with a set of exchangeability assumptions. It can be seen as a generalisation of a probability graph [3,27], andtypically has many fewer nodes than the original tree. The CEG retains those characteristics of the event tree which allowfor the representation of asymmetric problems; but they are also more flexible and useful, since their nodes representintrinsic events in the problem and their edges dependencies between them. They express topologically all the conditionalindependence structure associated with a problem (this is not bolted on as with context-specific BNs), and also any samplespace information generated by the asymmetry of the problem. So in a non-causal context, CEGs provide a more expressive(if somewhat more complicated) topological framework for expressing collections of conditional independence statementsthan the discrete BN.We present here an extension of CEG models which provides a framework for causal reasoning. We believe this extensionto be as transparent and compelling as the extension from BNs to CBNs. In Section 2 we give a brief definition of the CEGand a description of how to read conditional independence properties from it. This section also contains an example of howan asymmetric problem can be depicted using such a graph. Section 3 introduces the manipulation of these graphs, and thistheory is developed in Section 4 where we address the identification of the effects of manipulations. Section 5 introduces aBack Door Theorem for CEGs, a generalisation of Pearl’s Back Door Theorem for BNs [21].2. Chain Event Graphs2.1. DefinitionWe provide here a brief definition and description of the CEG. A more comprehensive definition can be found in [28].The CEG is a function of an event tree [27], and we begin this section with a brief description of this graph. An event treeT is a directed, rooted tree, with vertex set V (T ) and edge set E(T ). The non-leaf vertices are called situations and the setof situations S(T ). The root-to-leaf paths {λ} of T form the atoms of the event space (called the path σ -algebra of T ), andlabel the different possible unfoldings of the described process. Events measurable with respect to this space are unions ofthese atoms.Each situation v serves as an index of a random variable X(v) whose values describe the next stage of possible de-velopments of the unfolding process. The state space X(v) of X(v) can be identified both with the set of directed edges(cid:3) ∈ V (T ) of these edges. For each X(v) (v ∈ S(T ))e(v, vwe let(cid:3)) ∈ E(T ) emanating from v in T and the set of end-nodes vΠ(v) ≡(cid:3)(cid:3)(cid:2)π(cid:4)(cid:4) v(cid:5) (cid:4)(cid:4) vv(cid:3) | v) ≡ P ( X(v) = v(cid:6)(cid:3) ∈ X(v)(cid:3)) are called the primitive probabilities of the tree; andwhere π (vΠ(T ) ≡(cid:2)(cid:6)Π(v)v∈S(T )A full specification of the probability model is given by (T , Π(T )).We extend Shafer’s definition of an event tree by the introduction of three further properties — coloured edges, stagesand positions.\fP. Thwaites et al. / Artificial Intelligence 174 (2010) 889–909891Definition 1. The stages, colouring and positions of an event tree are defined as follows:1. Two situations v 1 and v 2 are in the same stage u if X(v 1) and X(v 2) have the same distribution under some bijectionψ between their sample spaces. We label the set of stages of the tree T by L(T ).2. For v 1, v 2 ∈ u (for some stage u), the edges e(v 1, v 1(cid:3)) and e(v 2, v 2(cid:3)) have the same colour if e(v 1, v 1(cid:3)) maps to e(v 2, v 2(cid:3))under this bijection ψ , and π (v 2(cid:3) | v 2) = π (v 1(cid:3) | v 1).3. Two situations v 1 and v 2 are in the same position w if for each subpath emanating from v 1, the ordered sequence ofcolours is the same as that for some subpath emanating from v 2. We label the set of positions of the tree T by K (T ).So two situations are in the same stage when the immediate future evolution from both situatio",
            {
                "entities": [
                    [
                        136,
                        175,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1094–1118www.elsevier.com/locate/artintDomain permutation reduction for constraint satisfaction problemsMartin J. Green ∗, David A. CohenComputer Science Department, Royal Holloway, University of London, Egham, Surrey, TW20 0EX, UKReceived 24 January 2007; received in revised form 28 November 2007; accepted 7 December 2007Available online 15 December 2007AbstractThis paper is concerned with the Constraint Satisfaction Problem (CSP). It is well-known that the general CSP is NP-hard.However, there has been significant success in discovering subproblems which are tractable (polynomial time solvable). One ofthe most effective ways to obtain a tractable subproblem has been to force all of the constraint relations to lie in some tractablelanguage.In this paper we define a new way of identifying tractable subproblems of the CSP. Let P be an arbitrary CSP instance and Γbe any tractable language. Suppose there exists, for each variable of P , a permutation of the domain such the resultant permutedconstraint relations of P all lie in Γ . The domain permuted instance is then an instance of a tractable class and can be solved bythe polynomial time algorithm for Γ . Solutions to P can be obtained by inverting the domain permutations.The question, for a given class of instances and language Γ , whether such a set of domain permutations can be found efficientlyis the key to this method’s tractability. One of the important contributions made in this paper is the notion of a “lifted constraintinstance” which is a powerful tool to study this question.• We consider the open problem of discovering domain permutations which make instances max-closed. We show that, forbounded arity instances over a Boolean domain this problem is tractable, while for domain size three it is intractable even forbinary instances.• We give a simple proof verifying the tractability of discovering domain permutations which make instances row convex.We refute a published result by giving a simple proof of the intractability of discovering domain permutations which makeinstances, even with domain size four, connected row convex.• We demonstrate that triangulated and stable marriage instances are reducible, via domain permutations, to max-closed in-stances. This provides a simple explanation for arc consistency deciding these instances.• We verify with a simple direct proof the tractability of identification of renamable Horn instances, and the intractability offinding the largest renamable Horn subset of clauses of an instance of SAT.• We describe natural tractable classes which properly extend the maximal relational classes arising from tractable constraintlanguages.We believe that domain permutation reductions have a significant chance of being useful in practical applications.© 2008 Elsevier B.V. All rights reserved.Keywords: Complexity; Constraint satisfaction problem; CSP; NP-completeness; Renamable Horn; Stable marriage; Tractability* Corresponding author.E-mail address: M.J.Green@cs.rhul.ac.uk (M.J. Green).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.12.001\fM.J. Green, D.A. Cohen / Artificial Intelligence 172 (2008) 1094–111810951. IntroductionThe constraint satisfaction paradigm involves modelling a real-world problem as a set of variables to which wecan assign values from some domain [44]. The values that can be assigned are limited by constraints. A constraintconsists of a list of variables (its scope), and a set of tuples which are the allowed assignments to this list of variables(its relation). A solution is the assignment of a value from the domain to every variable so that all of the constraintsare satisfied.Many real-world problems are naturally represented as instances of the general constraint satisfaction problem(CSP), including planning [40], scheduling [48], image processing [44], frequency assignment [21] and natural lan-guage understanding [1].The CSP is NP-hard [43]. This motivates the search for polynomial time solvable (tractable) subproblems.The structure of a CSP instance is the hypergraph whose hyperedges are the scopes (abstracted to be sets of distinctvariables) of the constraints. The set of CSP instances whose structure is acyclic form a tractable subproblem [4].This structural tractability result has been extended by identifying tractable decompositions of hypergraphs (cycle-cutset [17], hypertree decompositions [30], hinges [22,33], tree-clustering [18], etc.). These decompositions all jointhe original constraints in sets of size at most k and project each such join to form the constraints of a new, solutionequivalent, acyclic CSP instance [15]. The value k is called the width of the decomposition. A decomposition istractable if, for any k, the set of instances with width at most k can be tractably identified and reduced to the acycliccase.It is rare that a real-world example has an acyclic structure when modelled as a CSP instance. However the possibil-ity of using these widely applicable decompositions to reduce instances to the acyclic case makes structural tractabilityuseful in practice.A constraint language is a set of allowed (constraint) relations. A relational subproblem of the CSP consists ofthose instances whose relations lie in a specified language. A language which gives a tractable relational subproblemis called tractable [34,35]. Many tractable languages have been discovered [7,46].This paper introduces a new study: reductions by domain permutations. A domain permutation reduction of an in-stance to a given subproblem of the CSP is an independent permutation of the domain of each variable that transformsthe instance to lie in that subproblem. Some preliminary results appeared in a conference paper [32].We will show that determining whether a domain permutation reduction exists for a particular instance to a rela-tional subproblem corresponds exactly to the solving of an associated instance of another CSP subproblem. When this“lifted” problem for a tractable language is itself tractable then, under certain natural assumptions, we obtain a newlarge tractable subproblem.We consider the well-known max-closed tractable languages [36]. In their original paper Jeavons and Cooper leftas an open question whether there exists an efficient algorithm that can decide, for any given instance, if a domainpermutation exists that makes the instance max-closed [36]. We answer this question in Section 5.2 for the case wherethe domain has three or more elements (it is intractable) by analysing the appropriate lifted problem.However, by more careful analysis of the lifted problem for max-closed languages we are able to properly extendthe tractable subproblem of bounded arity Boolean max-closed instances. We can also extend the tractable subprob-lem of all binary max-closed instances, which has been shown [36] to be maximal as a tractable binary relationalsubproblem of the CSP.Our theory also explains why the constraint representation of the Stable Marriage Problem (SMP) [27] is tractablysolvable. We have shown that these instances have a natural domain permutation reduction to the max-closed sub-problem.Recently, a new tractable subproblem of binary instances for which arc consistency is a decision procedure, knownas triangulated CSP instances [12], has been described. It was left as an open question to discover if some unifyingreason exists that explains why arc consistency is a decision procedure for this class. In this paper we provide just suchan explanation by showing that these instances also have natural domain permutation reductions to the max-closedsubproblem.A row convex CSP instance [49] can be transformed by a domain permutation to make a particular combinatoricproperty hold for its constraint relations. A connected row convex CSP instance [20] satisfies a slightly more restrictivecombinatoric property (without first applying a domain permutation restriction). This stronger property is preservedby projection and join. It was left as an open question as to whether we can tractably identify the instances for\f1096M.J. Green, D.A. Cohen / Artificial Intelligence 172 (2008) 1094–1118which domain permutations exist transforming them into connected row convex instances. An incorrect answer tothis question has unfortunately appeared in the literature. In this paper we give a simple and correct answer to thisquestion.We also have a natural explanation for the tractability of renamable Horn theories [3,42], since the lifted problemscan easily be shown to be contained in the tractable majority-closed relational subclass [38]. It has been shown usingad-hoc methods that it is NP-hard to find the largest renamable Horn theory which is a subset of a given set ofclauses [19]. By analysing the lifted language this result becomes a simple consequence of a well-known result in thetheory of the MAX-SAT problem [16].1.1. Outline of the paperWe give the necessary basic definitions in Section 2 and then continue in Section 3 by discussing tractable constraintlanguages.We introduce our new work in Section 4 with the concept of a domain permutation reduction to a tractable relationalsubproblem and its associated lifted problem. We show the power of the new theory with an analysis of the domainpermutation reductions to the max-closed constraint language in Section 5.We use our new theory in Section 6 to:• develop some new tractable subproblems of the CSP;• unify several disparate known tractable subproblems;• show that the main results from renamable Horn theory may be obtained directly.We conclude the paper in Section 7 with final remarks and directions for future research.2. DefinitionsIn this section we will give a formal definition of a constraint satisfaction problem instance, and the associatednotions required for the paper.2.1. Constraint satisfaction problem instancesDefinition 1. An r-ary relation, ρ, over D is a subset of Dr .For any t ∈ ρ we den",
            {
                "entities": [
                    [
                        74,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 31–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the approximability of Dodgson and Young elections ✩Ioannis Caragiannis a, Jason A. Covey b, Michal Feldman c,d, Christopher M. Homan b,Christos Kaklamanis a, Nikos Karanikolas a, Ariel D. Procaccia e,∗, Jeffrey S. Rosenschein fa Computer Technology Institute and Department of Computer Engineering and Informatics, University of Patras, 26504 Rio, Greeceb Department of Computer Science, Rochester Institute of Technology, 102 Lomb Memorial Drive, Rochester, NY 14623-5603, USAc School of Business Administration and Center for the Study of Rationality, The Hebrew University of Jerusalem, Jerusalem 91904, Israeld Microsoft Israel R&D Center, Israele School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USAf School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 18 January 2011Received in revised form 8 April 2012Accepted 10 April 2012Available online 16 April 2012Keywords:Computational social choiceApproximation algorithmsThe voting rules proposed by Dodgson and Young are both designed to find an alternativeclosest to being a Condorcet winner, according to two different notions of proximity; thescore of a given alternative is known to be hard to compute under either rule. In this paper,we put forward two algorithms for approximating the Dodgson score: a combinatorial,greedy algorithm and an LP-based algorithm, both of which yield an approximation ratio ofHm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number.We also prove that our algorithms are optimal within a factor of 2, unless problems inN P have quasi-polynomial-time algorithms. Despite the intuitive appeal of the greedyalgorithm, we argue that the LP-based algorithm has an advantage from a social choicepoint of view. Further, we demonstrate that computing any reasonable approximation ofthe ranking produced by Dodgson’s rule is N P-hard. This result provides a complexity-theoretic explanation of sharp discrepancies that have been observed in the social choicetheory literature when comparing Dodgson elections with simpler voting rules. Finally, weshow that the problem of calculating the Young score is N P-hard to approximate by anyfactor. This leads to an inapproximability result for the Young ranking.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe discipline of voting theory deals with the following setting: there is a group of n agents and each of them ranks aset of m alternatives; one alternative is to be elected. The big question is: which alternative best reflects the social good?This question is fundamental to the study of multiagent systems, because the agents of such a system often need tocombine their individual objectives into a single output or decision that best reflects the aggregate needs of all the agentsin the system. For instance, web meta-search engines [12] and recommender systems [21] have used methods based onvoting theory.Reflecting on this question, the French philosopher and mathematician Marie Jean Antoine Nicolas de Caritat, marquis deCondorcet, suggested the following intuitive criterion: the winner should be an alternative that beats every other alternative✩A preliminary version of the results in this paper appeared in the Proceedings of the 20th Annual ACM–SIAM Symposium on Discrete Algorithms (SODA’09).* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), jac8687@cs.rit.edu (J.A. Covey), mfeldman@huji.ac.il (M. Feldman), cmh@cs.rit.edu(C.M. Homan), kakl@ceid.upatras.gr (C. Kaklamanis), nkaranik@ceid.upatras.gr (N. Karanikolas), arielpro@seas.harvard.edu (A.D. Procaccia), jeff@cs.huji.ac.il(J.S. Rosenschein).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.004\f32I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51in a pairwise election, i.e., an alternative that a (strict) majority of the agents prefers over any other alternative. Sadly, it isfairly easy to see that the preferences of the majority may be cyclic, hence a Condorcet winner does not necessarily exist.This unfortunate phenomenon is known as the Condorcet paradox (see Black [5]).In order to circumvent this result, several researchers have proposed choosing an alternative that is “as close as pos-sible” to a Condorcet winner. Different notions of proximity can be considered, and yield different voting rules. One suchsuggestion was advocated by Charles Dodgson, better known by his pen name Lewis Carroll, author of “Alice’s Adventuresin Wonderland.” The Dodgson score [5] of an alternative, with respect to a given set of agents’ preferences, is the minimumnumber of exchanges between adjacent alternatives in the agents’ rankings one has to introduce in order to make the givenalternative a Condorcet winner. A Dodgson winner is any alternative with a minimum Dodgson score.Young [45] raised a second option: measuring the distance by agents. Specifically, the Young score of an alternative is thesize of the largest subset of agents such that, if only these ballots are taken into account, the given alternative becomesa Condorcet winner. A Young winner is any alternative with the maximum Young score. Alternatively, one can perceive aYoung winner as the alternative that becomes a Condorcet winner by removing the fewest agents.Though these two voting rules sound appealing and straightforward, they have been criticized because they fail to meetseveral well-studied classical fairness criteria [18,6]. However, impossibility results tell us that every voting rule likewisefails to satisfy some such criterion. Thus, there is no hope of finding a voting rule that is perfect for all situations. Instead,social choice theory has advanced our understanding of an ever-increasing body of voting rules, each of which has uniquefeatures, virtues, and vices. Practitioners can choose from this body whichever rules best apply to their particular situations.Dodgson and Young voting are two such rules, as are the two approximation algorithms introduced later in this article.A less ambiguous drawback of Dodgson and Young voting is that they are notoriously complicated to resolve. As early as1989, Bartholdi, Tovey and Trick [2] showed that the Dodgson score decision problem is N P -complete, and that pinpointinga Dodgson winner is N P -hard. This important paper was one of the first to introduce complexity-theoretic considerationsto social choice theory. Hemaspaandra et al. [23] refined the aforementioned result by showing that the Dodgson winnerdecision problem is complete for Θ p2 , the class of problems that can be solved by O(log n) queries to an N P set. Subse-quently, Rothe et al. [41] proved that the Young winner problem is also complete for Θ p2 .These complexity-theoretic results give rise to the agenda of approximately calculating an alternative’s score, under theDodgson and Young schemes. This is clearly an interesting computational problem, as an application area of algorithmictechniques.However, from the point of view of social choice theory, it is not immediately apparent that an approximation of avoting rule is satisfactory, since an “incorrect” alternative—in our case, one that is not closest to a Condorcet winner—mightbe elected. The key insight is that an approximation of a voting rule is a voting rule in its own right, and in some cases onecan argue that this new voting rule has desirable properties. We discuss this point at length, and justify our approach, inSection 7.1.1. Our resultsIn the context of approximating the Dodgson score, we devise a greedy algorithm for the Dodgson score which has anapproximation ratio of Hm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number. Wethen propose a second algorithm that is based on solving a linear programming relaxation of the Dodgson score and hasthe same approximation ratio. Although the former algorithm gives us a better intuition into the combinatorial structureof the problem, we show that the latter has the advantage of being score monotonic, which is a desirable property froma social choice point of view. We further observe that it follows from the work of McCabe-Dansted [30] that the Dodgsonscore cannot be approximated within sublogarithmic factors by polynomial-time algorithms unless P = N P . We prove amore explicit inapproximability result of (1/2 − (cid:3)) ln m, under the assumption that problems in N P do not have algorithmsrunning in quasi-polynomial time; this implies that the approximation ratio achieved by our algorithms is optimal up to afactor of 2.A number of recent papers [38,39,27–29] have established that there are sharp discrepancies between the Dodgsonranking and the rankings produced by other rank aggregation rules. Some of these rules (e.g., Borda and Copeland) arepolynomial-time computable, so the corresponding results can be viewed as negative results regarding the approximabilityof the Dodgson ranking by polynomial-time algorithms. We show that the problem of distinguishing between whether am) positions in any Dodgson ranking is N P -hard. Thisgiven alternative is the unique Dodgson winner or in the last O (theorem provides a complexity-theoretic explanation for some of the observed discrepancies, but in fact is much wider inscope as it applies to any efficiently computable rank aggregation rule.√At first glance, the problem of calculating the Young score seems simple compared with the Dodgson score (we discussin Section 6 why this seems so). Therefore, we found the following result quite surprising: it is N P -hard to approximate theYoung score within any factor. Specifically, we show that it is N P -hard to distinguish between the case where the ",
            {
                "entities": [
                    [
                        147,
                        200,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 189–221Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintReasoning about discrete and continuous noisy sensors and effectors in dynamical systemsVaishak Belle a,b,∗a University of Edinburgh, Edinburgh, United Kingdomb The Alan Turing Institute, London, United Kingdomc University of Toronto, Toronto, Canada, Hector J. Levesque ca r t i c l e i n f oa b s t r a c tAmong the many approaches for reasoning about degrees of belief in the presence of noisy sensing and acting, the logical account proposed by Bacchus, Halpern, and Levesque is perhaps the most expressive. While their formalism is quite general, it is restricted to fluents whose values are drawn from discrete finite domains, as opposed to the continuous domains seen in many robotic applications. In this work, we show how this limitation in that approach can be lifted. By dealing seamlessly with both discrete distributions and continuous densities within a rich theory of action, we provide a very general logical specification of how belief should change after acting and sensing in complex noisy domains.Crown Copyright © 2018 Published by Elsevier B.V. All rights reserved.Article history:Received 27 October 2016Received in revised form 26 March 2018Accepted 5 June 2018Available online 26 June 2018Keywords:Knowledge representationReasoning about actionReasoning about knowledgeReasoning about uncertaintyProbabilistic logical modelsCognitive robotics1. IntroductionOn numerous occasions it has been suggested that the formalism [the situation calculus] take uncertainty into account by attaching probabilities to its sentences. We agree that the formalism will eventually have to allow statements about the probabilities of events, but attaching probabilities to all statements has the following objections:1. It is not clear how to attach probabilities to statements containing quantifiers in a way that corresponds to the amount of conviction people have.2. The information necessary to assign numerical probabilities is not ordinarily available. Therefore, a formalism that required numerical probabilities would be epistemologically inadequate.− McCarthy and Hayes [1].Much of high-level AI research is concerned with the behavior of some putative agent, such as an autonomous robot, operating in an environment. Broadly speaking, an intelligent agent interacting with a dynamic and incompletely known world grapples with two special sorts of reasoning problems. First, because the world is dynamic, it will need to reason about change: how its actions affect the state of the world. Pushing an object on a table, for example, may cause it to fall on the floor, where it will remain unless picked up. Second, because the world is incompletely known, the agent will need to make do with partial specifications about what is true. As a result, the agent will often need to augment what it believes about the world by performing perceptual actions, using sensors of one form or another.* Corresponding author at: University of Edinburgh, Edinburgh, United Kingdom.E-mail addresses: vaishak@ed.ac.uk (V. Belle), hector@cs.toronto.edu (H.J. Levesque).https://doi.org/10.1016/j.artint.2018.06.0030004-3702/Crown Copyright © 2018 Published by Elsevier B.V. All rights reserved.\f190V. Belle, H.J. Levesque / Artificial Intelligence 262 (2018) 189–221Fig. 1. A simple robot.For many AI applications, and robotics in particular, these reasoning problems are more involved. Here, it is not enough to deal with incomplete knowledge, where some formula φ might be unknown. One must also know which of φ or ¬φ is the more likely, and by how much. In addition, both the sensors and the effectors that the agent uses to modify its world are often subject to uncertainty in that they are noisy.To see a very simple example, imagine a robot moving towards a wall as shown in Fig. 1, and a certain distance h from it. Suppose the robot can move towards and away from the wall, and it is equipped with a distance sensor aimed at the wall. Here, the robot may not know the true value of h but may believe that it takes values from some set, say {2, . . . , 11}. If the sensor is noisy, a reading of, say, 5 units, does not guarantee that the agent is actually 5 units from the wall, although it should serve to increase the agent’s degree of belief in that fact. Analogously, if the robot intends to move by 1 unit and the effector is noisy, it may end up moving by 0.9 units, which the agent does not get to observe. Be that as it may, the robot’s degree of belief that it is closer to the wall should increase.While many proposals have appeared in the literature to address such concerns (cf. penultimate section), very few are embedded in a general theory of action whilst supporting features like disjunction and quantification. For example, graph-ical models such as Bayesian networks can represent and reason about the probabilistic dependencies between random variables, and how that might change over time. However, it lacks first-order features and a rich account of actions. Re-lational graphical models, including Markov logic networks [2], borrow devices from first-order logic to allow the succinct modeling of relational dependencies, but ultimately they are purely syntactic extensions to graphical models, and do not attempt to address the deeper issues pertaining to the specification of probabilities in the presence of logical connectives and quantifiers. Building on first-order accounts of probabilistic reasoning [3,4], perhaps the most general formalism for dealing with degrees of beliefin formulas, and in particular, with how degrees of belief should evolve in the presence of noisy sensing and acting is the account proposed by Bacchus, Halpern, and Levesque [5], henceforth BHL. Among its many properties, the BHL model shows precisely how beliefs can be made less certain by acting with noisy effectors, but made more certain by sensing (even when the sensors themselves are noisy).The main advantage of a logical account like BHL is that it allows a specification of belief that can be partial or incom-plete, in keeping with whatever information is available about the application domain. It does not require specifying a prior distribution over some random variables from which posterior distributions are then calculated, as in Kalman filters, for example [6]. Nor does it require specifying the conditional independences among random variables and how these depen-dencies change as the result of actions, as in the temporal extensions to Bayesian networks [7]. In the BHL model, some logical constraints are imposed on the initial state of belief. These constraints may be compatible with one or very many initial distributions and sets of independence assumptions. All the properties of belief will then follow at a corresponding level of specificity.Subjective uncertainty is captured in the BHL account using a possible-world model of belief [8–10]. In classical possible-world semantics, a formula φ is believed to be true when φ holds in all possible worlds that are deemed accessible. In BHL, the degree of belief in φ is defined as a normalized sum over the possible worlds where φ is true of some nonnegative weights associated with those worlds. (Inaccessible worlds are assigned a weight of zero.) To reason about belief change, the BHL model is then embedded in a rich theory of action and sensing provided by the situation calculus [1,11,12]. The BHL account provides axioms in the situation calculus regarding how the weight associated with a possible world changes as the result of acting and sensing. The properties of belief and belief change then emerge as a direct logical consequence of the initial constraints and these changes in weights.For example, suppose h is a fluent representing the robot’s horizontal distance to the wall in Fig. 1. The fluent h would have different values in different possible worlds. In a BHL specification, each of these worlds might be given an initial weight. For example, a uniform distribution might give an equal weight of .1 to ten possible worlds where h ∈ {2, 3, . . . , 11}. The degree of belief in a formula like (h < 9) is then defined as a sum of the weights, and would lead here to a value of .7. The theory of action would then specify how these weights change as the result of acting (such as moving away or towards the wall) and sensing (such as obtaining a reading from a sonar aimed at the wall). Naturally, the logical language permits weaker specifications, involving disjunctions and quantifiers, and the appropriate behavior would still emerge.While this model of belief is widely applicable, it does have one serious drawback: it is ultimately based on the addition of weights and is therefore restricted to fluents having discrete finite values. This is in stark contrast to robotics and ma-chine learning applications [13–15], where event and observation variables are characterized by continuous distributions, or perhaps combinations of discrete and continuous ones. There is no way to say in BHL that the initial value of h is any real number drawn from a uniform distribution on the interval [2, 12]. One would again expect the belief in (h < 9) to be .7, \fV. Belle, H.J. Levesque / Artificial Intelligence 262 (2018) 189–221191but instead of being the result of summing weights, it must now be the result of integrating densities over a suitable space of values, something quite beyond the BHL approach.So, on the one hand, the BHL account and others like it can be seen as general formal theories that attempt to address important philosophical problems such as those raised by McCarthy and Hayes above. But on the other, a serious criticism leveled at this line of work, and indeed at much of the work in reasoning about action, is that the theory is far removed from the kind of probabilistic uncertainty and noise seen in typical robotic applicat",
            {
                "entities": [
                    [
                        136,
                        224,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 258–298Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpatial reasoning in a fuzzy region connection calculusSteven Schockaert∗,1, Martine De Cock, Etienne E. KerreGhent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281 – S9, 9000 Gent, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 March 2008Received in revised form 18 August 2008Accepted 29 October 2008Available online 6 November 2008Keywords:Spatial reasoningRegion connection calculusFuzzy set theoryAlthough the region connection calculus (RCC) offers an appealing framework for modellingtopological relations,its application in real-world scenarios is hampered when spatialphenomena are affected by vagueness. To cope with this, we present a generalization ofthe RCC based on fuzzy set theory, and discuss how reasoning tasks such as satisfiabilityand entailment checking can be cast into linear programming problems. We furthermorereveal that reasoning in our fuzzy RCC is NP-complete, thus preserving the computationalcomplexity of reasoning in the RCC, and we identify an important tractable subfragment.Moreover, we show how reasoning tasks in our fuzzy RCC can also be reduced to reasoningtasks in the original RCC. While this link with the RCC could be exploited in practicalreasoning algorithms, we mainly focus on the theoretical consequences. In particular, usingthis link we establish a close relationship with the Egg–Yolk calculus, and we demonstratethat satisfiable knowledge bases can be realized by fuzzy regions in any dimension.© 2008 Elsevier B.V. All rights reserved.1. IntroductionTopological relations constitute an important facet of how humans perceive spatial configurations. Consequently, a largeproportion of the spatial information conveyed in natural language discourse is related to topology: we may find, for in-stance, that a certain geographic region is adjacent to, contained in or overlapping with another. The region connectioncalculus (RCC; [39]) has been proposed as a means to model such topological relations, and to reason about available topo-logical information (e.g., if a is adjacent to b, and b is a part of c, then c cannot be a part of a, regardless of how the regionsa, b and c are defined). A core feature of this calculus, discriminating it from related approaches such as the 9-intersectionmodel [12], is its generality. Starting from an arbitrary universe U of regions, topological relations are defined in terms ofan arbitrary reflexive and symmetric relation C in U , called connection (see Table 1 in Section 2). The intuitive meaning ofsome of the RCC relations from Table 1 is illustrated in Fig. 1. In particular, note that EC (externally connected) models adja-cency, while containment is modelled by TPP (tangential proper part), NTPP (non-tangential proper part) and EQ (equality).In different applications, regions can be modelled in different ways, and connection can be defined accordingly. Typically,regions are regular closed subsets of R2 or R3 and two regions a and b are called connected iff a ∩ b (cid:4)= ∅, although, forinstance, Z2 and Z3 are often of interest as well [29]. Furthermore, due to its generality, the RCC can also be applied incontexts where space is used in a metaphorical way (e.g., [38]). Note that frequently, the RCC is restricted to eight baserelations, which have the property of being jointly exhaustive and pairwise disjoint: DC (disconnected), EC, PO (partially−1. The RCC restricted to (unions of) these eight relations is referred to as RCC-8.overlaps), EQ , TPP, NTPP, TPPWhen using the RCC in applications, it is usually assumed that regions are well-defined entities, e.g., characterizedby precise boundaries. On the other hand, many geographical regions, for instance, are inherently ill-defined. For example,−1 and NTPP* Corresponding author.E-mail addresses: Steven.Schockaert@UGent.be (S. Schockaert), Martine.DeCock@UGent.be (M. De Cock), Etienne.Kerre@UGent.be (E.E. Kerre).1 Postdoctoral Fellow of the Research Foundation – Flanders.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.009\fS. Schockaert et al. / Artificial Intelligence 173 (2009) 258–298259Fig. 1. Intuitive meaning of some RCC relations.Fig. 2. Are the regions B, C , and D contained in region A?although political regions, such as countries, states, and provinces, have officially defined—and therefore precise—boundaries,many of the places people refer to in everyday communication (i.e., vernacular places), do not (e.g., [1,2,13,15,33,57,58]).Even the names of political regions are often used in a way that is not in perfect accordance with their official definitions;a typical example are city neighborhoods, whose official boundaries, if they exist, are merely intended for administrativepurposes (e.g., electoral divisions). Vague regions occur at very different scales (Ghent’s city center, the Highlands, theMiddle East), and a variety of techniques can be used to capture their spatial semantics. Approaches based on supervaluationsemantics (e.g., [1,27,57]), for instance, associate a set of possible crisp precisifications with a vague language concept, andreason about assertions that are true in every precisification, in some precisification, etc., typically using first-order logic.They are mainly motivated by philosophical considerations about the nature of vagueness, and tend to be less suitableas workable, computational models. Particularly popular are techniques which represent a vague region as a pair of crispsets (e.g., [2,4,5]). Their main idea is that a vague region can be approximated by defining a set of locations a which aredefinitely in the vague region, as well as a set of locations a which are in the vague region to some extent (where a ⊆ a);the complement of a is then the set of locations which are definitely not in the vague region. The resulting models are veryefficient, and theoretical results (e.g., reasoning procedures) can usually be obtained relatively easily from existing resultsfor crisp regions. Note that vague regions are in this case formally equivalent to ensembles flous [18] of locations. Finally,fuzzy set theory is frequently employed to model vague regions (e.g., [15,19,22,30,31]). In this case, the spatial extent of avague region is modelled by a mapping A from locations (points) to the unit interval [0, 1], such that for any location l,A(l) reflects the degree to which l belongs to the vague region. Although the resulting models may be somewhat lessefficient than models based on pairs of crisp regions, their increased flexibility is often needed to accurately capture vagueboundaries. Moreover, a pair (a, a) of crisp regions with a ⊆ a can be seen as a special case of a fuzzy set, e.g., by assigningall points in a membership degree 1, all points in a \\ a membership degree 0.5, and all other points membership degree 0.The existence of vague regions does not, as such, present any difficulties, as the RCC makes no assumptions on therepresentation of regions. However, when some of the regions involved are vague, topological relations can be vague as well.For instance, it is not entirely clear whether the Alps are included in, overlapping with, or disjoint from Southern Europe,as each of these relations seems defensible to some extent. This observation stands in contrast with the assumption thattopological relations are defined in terms of first-order logic and a crisp relation C . Moreover, even if the regions involved arecrisp, it may be desirable to define topological relations as fuzzy relations. In particular, the traditional, strict interpretationof topological relations (e.g., using point-set topology) does not always correspond very well to the way topological relationsare used in natural language. For example, it is commonplace to say that a cabinet is located against a wall even if thereis a gap of a few millimeters between the cabinet and the wall. In traditional frameworks, the cabinet and the wall wouldbe considered disjoint, irrespective of the size of the gap. A more natural solution would be to define topological relationsas fuzzy relations in which the cabinet and the wall are considered adjacent if they are actually touching, or located veryclose to each other. Note that adjacency then becomes a vague concept because it relies on nearness. A similar observationcan be made for containment; consider, for instance, the regions depicted in Fig. 2. Clearly, B is contained in A and D isnot. However, while C is in principle not a part of A, we could intuitively think of C as being a part of A to a large extent,because C is almost contained in A.Our solution is to define C as a fuzzy relation, i.e., for each pair (u, v) of regions, C(u, v) is a degree in [0, 1] reflectingto what extent u and v are connected. Keeping the generality of the RCC, other topological relations are still defined interms of C , using fuzzy logic connectives, however, instead of classical first-order logic. Note that in this way, we make nocommitment at all of why topological relations are vague (e.g., to define relations between vague regions, to model tolerant\f260S. Schockaert et al. / Artificial Intelligence 173 (2009) 258–298natural language relations, etc.). The central aim of this paper is to investigate how this fuzzification of the RCC affectsspatial reasoning. First, Section 2 presents the relevant details of our fuzzification of the RCC. Among others, we illustratehow fuzzy RCC relations can be interpreted in terms of nearness between fuzzy sets. Next, in Section 3, we provide anumber of use cases to further motivate the need for a fuzzy RCC, as well as the need for spatial reasoning in this context.Subsequently, we review some related work in Section 4, discussing shortcomings of existing approaches to handle fuzzytopological information. In Section ",
            {
                "entities": [
                    [
                        136,
                        191,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 72 ( 1995) 139- 171 Artificial Intelligence Learning dynamics: system identification for perceptually challenged agents Kenneth Basye ‘,*, Thomas Dean b*i, Leslie Pack Kaelbling b*2 a Department of Mathematics and Computer Science, Clark Universiiy 950 Main Street, Worcester, MA 01610, USA ’ Department of Computer Science. Box 1910, Brown University, Providence, RI 02912-1910, USA Received September 1992; revised March 1993 Abstract From the perspective of an agent, the input/output behavior of the environment in which it is embedded can be described as a dynamical system. Inputs correspond to the actions executable by the agent in making transitions between states of the environment. Outputs correspond to the perceptual information available to the agent in particular states of the environment. We view dynamical system identification as inference of deterministic finite-state automata from sequences of input/output pairs. The agent can influence the sequence of input/output pairs it is presented by pursuing a strategy for exploring the environment. We identify two sorts of perceptual errors: errors in perceiving the output of a state and errors in perceiving the inputs actually carried out learning in making a transition from one state to another. We present efficient, high-probability algorithms for a number of system identification problems involving such errors. We also present the results of empirical investigations applying these algorithms to learning spatial representations. 1. Introduction System identification refers to inferring a model of the dynamics governing an agent’s For instance, we might wish to infer a model of how interaction with its environment. * Corresponding author. E-mail: kbasye@gamma.clarku.edu. ’ This work was supported in part by a National Science Foundation Presidential Young Investigator Award IRI-8957601, by the Air Force and the Advanced Research Projects Agency of the Department of Defense under Contract No. E30602-91-C-0041, and by the National Science foundation in conjunction with the Advanced Research Projects Agency of the Department of Defense under Contract No. IRI-8905436. 2 This work was supported in part by a National Science Foundation National Young Investigator Award. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDl0004-3702(94)00023-T \f140 K. Btrsy YI d./Arrijkkr/ Inrrllipxce 72 (1995) 139-I 71 fluctuations assembly in the output of a parts supplier affect production for a factory or how an robot interacts with the other devices in its work cell. rules, or a set of states and transition probabilities to a system of differential a set of for a stochastic process. the agent to predict consequences of performing spatial inference, equations, Such predictions might be used in planning, The inferred model might correspond production The model is useful insofar as it enables actions or diagnostic System reasoning. identification in its environment. has been studied in a variety of disciplines theory. We focus on learning theory, neural networks, and automata environments that can be characterized a large literature even on this restricted problem, a portion of which is summarized this paper. Our results address Our objective probability outputs complexity. that infer accurate models with high inputs and the effects of uncertainty algorithms interaction with its environment. learning time when faced with noise on computational as deterministic that determine in polynomial is to produce in observing the agent’s finite-state the including representations automata. There control of is in We are interested in how agents interact with their environments such interactions. We have chosen and, in particular, how to focus on identification in observation complicates as it appears to be critical that system system uncertainty system identification It is clear that studying which such identification in observation is annoying it is not that hard to cope with. However, any structure. Useful structure sequences of distinctive plays a supporting identification in facilitating a wide range of interactions. is a means and not an end; however, we believe in into many problems in isolation provides insight role. Our basic findings are that uncertainty and requires somewhat more bookkeeping but asymptotically lacking is hopeless landmarks or short in the form of reasonably distributed in environments learning features makes to function learning adequately relatively easy. the use of a in which having some sort of a model can is in learning space to support path planning. A dynamical model can also speed the clearest example of the utility of a model even optimally without however, [ 221 by allowing an agent to simulate there are tradeoffs involved in learning dynamical models; exactly what learning will depend on the tasks of the agent. Again, we avoid addressing in how (but see [9] ) in order to focus on basic in this paper issues its actions and the environment’s It is certainly possible model. There are environments, help enormously. Perhaps, maps of large-scale up learning plans reactions. Clearly is worth those uncertainty in observation tradeoffs affects learning. 2. Modeling dynamical systems with automata We model dynamical finite-state automata systems as deterministic graph for a DFA shows the state-transition agent’s actions and the outputs in learning interested is defined in terms of the agent’s perceptual capabilities. Discernability that, from the information in a state, the agent can uniquely but rather that there exists some sequence of actions and observations structure of real environments, where discernible does not require that state, that can be used from the DFA are the agent’s perceptual the discernible the inputs in which available identify (DFAs). Fig. 1 to the DFA are the inputs. We are \fK. Basye et al./Art$cial intelligence 72 (1995) 139-171 141 0 1 :I:i. x CJ interacting with its environment. Fig. 1. An agent Y Y 0 1 X X x by the agent to distinguish any two states. For instance, the states of an automaton might correspond to the agent being in one locations in which in an office building, of many where hallways meet. In this case, the observed outputs might correspond of hallways hallways. As another example, consider Here the states might correspond by the user, and outputs to the announcements made at each state. to various menus and services, actions for traversing the structure of a voice-mail to junctions to the number incident system. to keys pressed on a junction, correspond the inputs to actions locations learning incident and The DFA need not represent the whole of the agent’s interaction with its environment; separate models could be used for different aspects of the interaction. We assume size by careful choice of perception state space has been reduced to limit action primitives. Actions agent’s options small through equivalence abstract behaviors in a given state. The set of possible observations for response the use of perceptual apparatus experiences. relations on perceptual that act as filters, are encapsulated to a manageable that serve thereby the and the is kept introducing of a relatively that determining states. We admit requires a great deal of insight specifying only a set need not correspond the set of states of the to the cross product of the sets of values for all the state of state variables and, even if this is desirable, Historically, AI researchers have kept the state space implicit, In our view, the agent’s observations of state variables or fluents. to observations automaton need not correspond variables. We see the world as consisting distinguishable and action primitives general advice on how to obtain such primitives. We claim, however, primitives, Even in a state do not uniquely in stochastic results tions available particularly in the agent observing process output at a state or realizing one action while attempting Fig. 2 illustrates for quite extreme arises due to the fact that the observa- that state. In this paper, we are sources of uncertainty. We allow there to be a noise something other than the true to execute some other action. results apply in relatively both sorts of errors. Our polynomial-time forms of uncertainty, into the problem, and we offer no that without such small number of perceptually perception interested that occasionally but predict fairly poor performance learning will be very difficult. such state-space-reducing in the deterministic case, uncertainty performance determine \f142 K. Basye et al. /Artificial Intelligence 72 (1995) 139-171 Fig. 2. Noisy observations of inputs and outputs. benign environments. Our empirical perform much better than our current of the sort we expect robots to encounter in the real world. investigations, that our algorithms theoretical bounds predict for benign environments however, indicate 3. Formal model In order automaton; as inferring identification to model system the structure of finite-state that there are two varieties of finite-state au- tomata, we now introduce an extension of the familiar definition of finite-state automata. in both versions, output Recall follows some action, and the state reached by the action depends on the action taken and the previous state. In the Moore model, output depends only on the state reached by in the Mealy model, output depends on both the previous state and the action, whereas, the action taken. Alternatively, that depend on the current state and the previous action. In terms of system which model is appropriate depends on the nature of the agent’s sensing in particular on whether sensations depend Moore automata the same regardless of how we got to that state. systems and in some way on the previous action. We use for a given state are one may think of the Mealy model as having outputs for our model, which implies that our sensations identification, between In this model,",
            {
                "entities": [
                    [
                        68,
                        143,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 102 (1998) l-20 Artificial Intelligence On stable social laws and qualitative equilibria * Moshe Tennenholtz ’ Faculty of Industrial Engineering and Management, Technion-Israel Institute of Technology, Haifa 32000, Israel Received 6 October 1996; received in revised form 1 January 1998 Abstract This paper introduces and investigates the notion of qualitative equilibria, or stable social laws, in tbe context of qualitative decision making. Previous work in qualitative decision theory has used the maximin decision criterion for modelling qualitative decision making. When several decision-makers share a common environment, a corresponding notion of equilibrium can be defined. This notion can be associated with the concept of a stable social law. This paper initiates a basic study of stable social laws; in particular, it discusses the stability benefits one obtains from using social laws rather than simple conventions, the existence of stable social laws under various assumptions, the computation of stable social laws, and the representation of stable social laws in a graph-theoretic framework. 0 1998 Elsevier Science B.V. All rights reserved. Keywords: Social laws; Qualitative decision making 1. Introduction General coordination mechanisms are essential tools for efficient in multi- reasoning issue of study in the fields of are a major agent AI systems. Coordination mechanisms mathemati,cal economics and game theory as well. Much work in these fields concentrates on the notion of an equilibrium. An equilibrium is irrational for each agent to deviate discussed literature refers to agents which are expected utility maximizers. However, much work in AI has been concerned with In particular, work in AI has been more qualitative from that behavior. The notion of an equilibrium is a joint behavior of agents, where it in the game theory and mathematical forms of rational decision making. economics *A preliminary Knowledge Representation version of this paper appears and Reasoning. in the Proceedings of the 5th International Conference on ’ Email: moshet@ie.technion.ac.il. 0004-3702/98/$19.00 PII: SOOO4-3702(98)00033-2 0 1998 Elsevier Science B.V. All rights reserved. \f2 M. Tennenholtz /Artijicial Intelligence 102 (1998) I-20 to maximize from a decision-theoretic their worst case payoff. Although, at concerned with agents which attempt it is known perspective, first, this behavior may look questionable in the context of to capture the behavior of risk-averse agents [9,19,38], and it is appropriate qualitative decision in [9] Brafman and Tennenholtz have theory [8,15,19,59]. Moreover, shown general conditions under which an agent can be viewed as if it were a maximin agent notion (i.e., an agent which maximizes of equilibrium this notion and investigate turns out to coincide with later in this paper. For ease of exposition the notion of a stable social law, to be introduced we introduce fashion, as an extension to previous work on artificial social systems. its properties. The concept of qualitative equilibrium the notion of a stable social law in a self-contained its worst case payoff). However, the corresponding has not yet been investigated. In this paper we introduce Some work on multi-agent systems assumes that agents are controlled by a single is in time, while some other work process systems protocols that conform in multi-agent at each point their behavior to agreed-upon rational negotiation in order that irrational negotiation systems agents will protocols, but will conform resolution in decentralized to resolve the agents will systems where no global controller for decentralized multi-agent encounters. The basic exists. A significant [7,17] deals with theme of work on this subject reach states of conflict and appropriate these conflicts. The in AI follow. Work deals. Agents to deals obtained by [20,37,62].2 This differs from work in game- entity which dictates concerned with decentralized part of the theory developed conflict is that negotiation mechanisms would be needed result of the negotiation is a deal has been mostly concerned with agents may not follow following theory [25,48] where a joint strategy is considered unstable from a design perspective) The Artificial Social Systems approach totally centralized basic a social law, resolution of conflicts. consist of various restrictions on the agents’ activities which allow but at the same time constrain particular, a social the system efficiency. Notice of the social law; they will be used in situations where conflicts can’t be prevented advance. it. a to coordination. The called and on-line law may is a set of freedom on one hand, them so that they will not interfere with each other. In improves can serve as part in approach and a totally decentralized idea of the Artificial Social Systems approach from (e.g., [45,57]) exposes a spectrum between (and therefore unsatisfactory to deviate law makes certain conflicts unreachable, the need robots setting, control such a social if an agent has a rational is to add a mechanism, [56]. More generally, for both centralized that will minimize traffic constraints that mechanisms and as a result them enough for example, In a mobile for conflict resolution approach incentive a social law The motivation systems, and as such it assumes multi-agent by the designer. However, laws might be considered systems approach and approaches in multi-agent resolution of conflicts laws, but the theory of artificial social systems has neglected for the theory of artificial social systems has been the design of artificial that the agents will obey the law supplied if each agent then some irrational. Therefore, at the current stage, the artificial social the to conflict resolution are somewhat complementary; theory of social the stability of social laws in is designed by a different designer is part of a more general encounters * See [53] for a detailed discussion of this point. \fM. Tennenholtz /Artificial Intelligence 102 (1998) l-20 3 encounters. laws for multi-agent In this paper we wish to bridge part of the gap between stable social is a restriction of the set of available actions (in the encounter) the theory multi-agent encounters, in multi-agent of artificial social systems and the theory of conflict resolution encounters. A social law for a multi- by considering to a set of agent encounter from them irrational. Notice socially allowed actions. Stable social laws make deviation that a convention type of a social law; a convention determines a particular joint action for the agents to follow (e.g., keep the right of the road), while a social law is quite allows several such actions and prohibits others. As it turns out, this distinction important and useful. is a particular In particular, is to optimize encounters using a game-theoretic We will discuss social laws for multi-agent frame- in recent in most of this paper we will assume work which is tailored for assumptions made in the AI literature, and especially work on qualitative decision making. that the agents are risk-averse agents, which use the maximin decision criterion. More specifically, given a set of possible behaviors of the other agents, its worst case outcome assuming the aim of the other agents may follow an agent is appropriate where there is some ordinal any of these behaviors. This kind of behavior In such situations all that matters to agents is the order of relation on possible outcomes. is an payoffs and not their exact value. The precise conditions under which such modelling in [9]. Moreover, as we discuss in Section 4, this modeling appropriate: one are discussed to the perspective achievement of a particular user’s specification. We will require that a social law suggested to the agents a certain payoff, and that it will for a particular encounter will guarantee be stable; the agents are risk- there should be no incentive averse agents. Hence, a stable social law corresponds for risk-averse extended agents. In a later stage, we show how our discussion to other basic qualitative decision-making systems, where a payoff corresponds to a notion of qualitative equilibrium is quite natural in many multi-agent to deviate from it assuming and results can be settings. We start by introducing our framework. In particular, in Section 3 we define the notion of the basic framework, study of stable social laws; we formulate systems. Having encounters encounters for which a stable convention for which there is an appropriate stable social laws. In Section 4 we discuss the intuition and formal adequacy of maximin in Section 5 we show that the set in multi-agent exists is a strict subset of the set of multi-agent of multi-agent stable social law; however, we show that there exists situations where no stable social law exists. Then, in Section 6 we initiate a computational problem and show that the general problem of coming up with a stable computational the proof of our result sheds light on the structure of stable social social law :IS intractable; restriction on our framework under which laws; in addition, we point the synthesis of stable social laws is polynomial. We then return back to the question of the existence of stable social laws; in Section 7 we first show how this question can be terms, and then expose a class of encounters where formulated the existence of stable social laws. In Section 8 simple graph-theoretic we discuss how our ideas can be applied in other qualitative decision making contexts, and in Section ‘9 we further discuss the meaning of our study and results and the connection of our work to the existing in standard graph-theoretic the corresponding to an interesting conditions literature. imply \f4 M. Tennenholtz /ArtiJicial Intelligence 102 (1998) l-20 2. The basic framework In this section we introduce our basic framework, which is built upon a basic game- theoretic model. 2.1. The basic model In general AI planning systems,",
            {
                "entities": [
                    [
                        64,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artjficial Intelligence 83 ( 1996) 297-346 Artificial Intelligence An overview of incentive contracting * Department of Mathematics and Computer Science, Bar hn University, Ramat Gan. 52900 Israel Sarit Kraus * Received May 1994; revised January 1995 Abstract Agents me.y contract some of their tasks to other agents even when they do not share a common goal. An agent may try to contract some of the tasks that it cannot perform by itself, or that may be performed more efficiently by other agents. One self-motivated agent may convince another self-motivated agent to help it with its task, by promises of rewards, even if the agents are not assumed to be benevolent. We propose techniques that provide efficient ways for agents to make incentive contracts in varied situations: when agents have full information about the environment and each other, or when agents do not know the exact state of the world. We consider situations of repeated encounters, cases of asymmetric information, situations where the agents lack information about each other, and cases where an agent subcontracts a task to a group of agents. Situations in which there is competition among possible contractor agents or possible manager agents are also considered. In all situations we assume that the contractor can choose a level of effort when carrying out the task and we would like the contractor to carry out the task efficiently without the need of close observation by the manager. 1. Introduction Agents acting in non-collaborative environments may benefit from contracting some of their tasks to other agents. In this paper we present techniques for efficient contracting that can be used in different cases of multi-agent environments where the agents do not have a common goal and there is no globally consistent knowledge. We consider *This paper is based upon work supported by the National Science Foundation under Grants No. IRI-9423967 and the Israeli Ministry of Science and the Arts under grant 4210. and is an extension of (47 1. I would like to thank Jonathan Wilkcnfeld. Barbara Grosz and an anonymous referee for theii comments, and Sean Bngelson and Onn Sbehory for useful discussions. l E-mail: sarit@bimacs.cs.biu.ac.il. Also aftlliated with the Institute for Advanced Computer Studies, University of Maryland, College Park, MD, USA. OOC4-3702/96/$15.00 @ 19% Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00059-3 \fanother agent to the agents are 298 5’. Kraus/Art@d Intelligence 83 (1996) 297-346 situations where a self-motivated order to fulfill its own tasks may contract some of its own tasks to another self-motivated agent(s), An agent may benefit from contracting some of its tasks that it cannot perform by itself, or when the task may be performed more efficiently by other agents. agent that tries to carry out its own individual plan in The central question of this paper is how one agent can convince for it when do something not assumed agent can choose different agent would the manager prefers without manager the agents do not share a global task and to be benevolent. Furthermore, we consider situations where the contractor levels of effort when carrying out the task. The manager to carry out the task with the level of effort that the the need of close observation of the manager, enabling like the contractor agent to carry out other tasks simultaneously. There are two main ways to convince another self-motivated its own tasks: by threatening agent to perform a task to interfere with the agent carrying out in two forms: The first approach to help that is not among its own tasks, or by promising rewards by rewards which may be accomplished system, where one agent may promise for current help. However, as has long been recognized an efficient basis for cooperation, wishing the future, or one agent help in carrying out its own tasks. The second approach is developed purposes. [49]. This paper concentrates on subcontracting is a bartering in return is not environment. An agent to help it in task may not need system which for other for the provision of rewards, and which can later be utilized a task to another agent may not have the ability that can help in fulfilling in economics, bartering the other with future in a multi-agent another agent’s to subcontract is a monetary particularly tasks In this paper we present a model of automated agents where incentive contracting is beneficial, We propose for side payments allows given to the owners of the automated expected utilities Assuming to fulfill to use a monetary and rewards between system in a multi-agent that the agents, and where profits may be environment to maximize that increase with the monetary values, as will be explained below. that each agent has its own personal goals, contracting would allow the agents agents. The agents will be built their goals more efficiently as opposed The issue of incentive contracting has been investigated to working on their own. [ 2,3 1,40,56,88,9 types of contracts a firm and an employer or employers [ 91) ; a landlord and a tenant (e.g., in economics and game theory 1 ] ) . These works in economics and for different applications. Examples [ 6,7,64, (e.g., [2] >; an (e.g., ) ; a buyer and a seller [ 34,58,93,102] [ 721); stockholders [98], etc. In these situations (e.g., a government [ 70,771); [ 21); a professional and taxpayers (e.g., and a policy holder the last two decades during game theory consider different of these are contracts between: 781) ; a government insurance company (e.g., (e.g., exist. The first party action or a level of effort from a number of possibilities, of both parties. The second party (named “the principal”) prescribing principal determines party as a function of the principal’s observations. Despite applications, a rule (i.e., a contract) payoff rules. Before (called “the agent” in the economics and firms (e.g., the first party that specifies and a client they differ thereby affecting has the additional and managements two parties usually literature) must choose an the outcome function of the the fee to be paid to the other the similarity of the above that is the action, in several aspects, such as the amount of information (i.e., the agent) chooses \fS. Kraus/Arti$cial Intelligence 83 (1996) 297-346 299 to the parties, available of agents. Several concepts and techniques and game theory in the relevant economics the observations are applied literature. that are made by the principal, and the number paradigm to the principal-agent full information and techniques, information agents and bilateral in the environment. We consider varied situations of automated agent environments; situations of certainty information vs. asym- symmetric vs. partial information, situations vs. situations where there are more than two vs. uncertainty, metric automated economics mechanisms ture, that can be used for contracting these results concepts used all the situations techniques agent(s) agents that are appropriate in the various economics For each of these situations we fit appropriate litera- from the game theory or the economics of automated agents. We adjust and present all of them using uniform the different concepts i.e., translating In framework. is provided with its personal expected utilities, given the constraints of the other the paper, we use a robotics domain and an example of software introduced the contracting and game theory papers the agent that designs to the automated agents environment into a uniform the contract . Throughout to demonstrate to automated agents, that we consider, in environments to maximize techniques above. 2. Related -work in DA1 Research into two basic classes: cooperative distributed problem in cooperative distributed prob- (MA) [ 12,18,59,61,101]) in solving a in DA1 is divided solving and multi-agent systems lem solving (e.g., particular problem can be divided among a number of modules or “nodes”. The modules in a cooperative distributed problem to improve the following properties of the system considers how the work involved system are centrally designed [ 8,281. Research solving [ 81: l Performance: Concurrency may increase and may allow the system to solve large problems the speed of computation faster. and reasoning, l Reliability and stability: The modules may provide redundancy, cross-checking triangulation modules can fulfill of the results. its tasks. In case of failure of one of the modules, and the other l Modularity: Each module can be developed separately, making it easier to develop and extend the system. The modules solution include to a given problem. the development of cooperating mechanisms designed to find a Research in MA (e.g., [ 20,29,48,104,107,1 intelligent behavior among a collection of autonomous gent (possibly pre-existing) shared goals or success criteria. There among the agents. agents. lo] ) is concerned with coordinating intelli- In MA, there is no global control, and no globally for real competition is, however, a possibility (possibly heterogeneous) The MA and the cooperative distributed problem of the DA1 research. Our research the problem of a self-motivated motivated (the contractor) can choose between different agent solving falls closer systems are the two poles to the MA systems pole. We consider that tries to make another self- that the contractor the task. The main agent fulfill one of its tasks. We assume to fulfill (the manager) levels of effort when trying \f300 S. Kraus/Art@cial intelligence 83 (1996) 297-346 problem that we address is how the manager should motivate the contractor to choose a level of effort that the manager prefers. The provision of incentives is in general not essential in cooperative distributed prob- lem solving systems. It is assumed that it is in the agents’ interests to help one another. This help can take the form of sharing tasks, results, or information [ 191. In task shar- ing, an agent, which cannot fulfill a task on ",
            {
                "entities": [
                    [
                        76,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1800–1808Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA note on the correctness of the causal ordering algorithmDenver Dash a,b,∗,1, Marek J. Druzdzel c,da Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USAb Department of Biomedical Informatics, School of Medicine, University of Pittsburgh, Pittsburgh, PA 15260, USAc Decision Systems Laboratory, School of Information Sciences and Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA 15260, USAd Faculty of Computer Science, Białystok Technical University, Wiejska 45A, 15-351 Białystok, Polanda r t i c l ei n f oa b s t r a c tArticle history:Received 28 October 2005Received in revised form 16 June 2008Accepted 19 June 2008Available online 28 June 2008Keywords:CausalityStructural equation modelsIn this paper we examine in detail the algorithm of Simon [H.A. Simon, Causal orderingand identifiability, in: W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method.Cowles Commission for Research in Economics, Monograph No. 14, John Wiley & Sons, Inc.,New York, 1953, pp. 49–74, Chapter III], called the causal ordering algorithm (COA), usedfor constructing the “causal ordering” of a system given a complete specification of thesystem in terms of a set of “structural” equations that govern the variables in the system.This algorithm constructs a graphical characterization of the model in a form that we calla partial causal graph. Simon argued in [H.A. Simon, Causal ordering and identifiability, in:W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method. Cowles Commission forResearch in Economics, Monograph No. 14, John Wiley & Sons, Inc., New York, 1953, pp. 49–74, Chapter III] and subsequent papers that a graph so generated explicates causal structureamong variables in the model. We formalize this claim further by proving that any causalmodel based on a one-to-one correspondence between equations and variables must beconsistent with the COA.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThis note is concerned with a technique owing to Simon known as the causal ordering algorithm (COA). Given a self-contained system of simultaneous structural equations, COA will explicate asymmetries among variables in the system andproduce a (possibly partial) matching between variables and equations. In a classic article [24], Simon showed that COAgenerates a directed graph which we call a partial causal graph (PCG). In [24] and in subsequent writings [11,12,25,26] Simonet al. argue that if a set of equations E is self-contained and composed of causal mechanisms, COA will produce causal graphsthat are consistent with experts’ “intuitive” causal orderings. We show in this note that the COA provides a summary ofthe necessary mappings from variables to equations. That is, any one-to-one mapping from variables to equations will beconsistent with the COA. As a special case, when all clusters found by the COA contain only a single variable, then thereexists only one mapping from equations to variables and only one (acyclic) directed causal graph, which is given by COA.1.1. PreliminariesFor the purposes of this note, a causal model is defined as a set of equations together with a one-to-one mapping fromequations to variables in the model (see Fig. 1). Matching a variable to an equation is an assertion that the other variables* Corresponding author at: Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USA.E-mail addresses: denver.h.dash@intel.com (D. Dash), marek@sis.pitt.edu (M.J. Druzdzel).1 This work was performed while Denver Dash was a graduate student at the Intelligent Systems Program, University of Pittsburgh.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.005\fD. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081801Fig. 1. A causal model is specified by a set of equations and a one-to-one correspondence between equations and variables and defines a directed graphover the variables.present in that equation are causal parents of the matched variable. Such a specification of a system defines a directed graph(DiG) which is interpreted as a causal graph. This representation of causality has its roots in structural equation models inthe econometrics literature [8,10,24,30,36,37] and has been developed further within AI over the past decade [6,21,29]).It is frequently the case that we know the equations that govern a given system but we are unsure about the correctmapping from variables to equations. For example, any physical system typically has an associated set of physics equationsthat govern the processes in the system. Many socio-economic models have “laws” that are represented by equations thatmust be satisfied for a given set of assumptions. Given such a set of equations, in order to produce a causal model (asdefined in this note), one must be able to generate a one-to-one correspondence between variables in the system andequations. To do this in general requires detailed background knowledge about causal interactions in the system. In practicefor even modest systems it can become an intractable task by hand. It would thus be desirable to possess an automatedmethod by which the matching between equations and variables can be generated. Such a method would be especiallyvaluable for very large models possessing hundreds or thousands of variables. A central practical problem with such anautomated method is to ensure that the mapping generated has causal meaning.Our contributions here are to formally define a Partial Causal Graph (PCG) and define a notion of consistency between aDiG and a PCG. We then show that the mapping of equations to variables produced by COA will be consistent with any othermapping, and thus the PCG generated by COA will be consistent with any DiG that is consistent with E. By “consistent” wemean in essence that any arc present in the PCG must be present in the DiG, and any arc in the DiG must not be ruledout by the PCG. Our proof requires neither linear equations nor equations which can be solved for unique values for thevariables.We feel that this work is significant because it serves to validate decades of research which has shown COA to be apowerful tool for operating on causal models. One of the primary uses for causal graphs in general is to support the abilityto reason about the effects of manipulation on a real-world system and predict the resulting probability distribution. The Dooperator of Pearl [21] is a well-known case of an operator for modeling manipulation of a variable when such a manipula-tion breaks the connection between the variable and its parents. However, the COA has served as a generating function forall sorts of operations on causal models. For example, COA can be used to model the restructuring that occurs in a dynamiccausal system when it passes through equilibrium [2,3,11]. Yet another operation might be the replacement of some compo-nents with others that depend on qualitatively different factors, such as replacing a spring with a compressible gas piston.COA is capable of modeling manipulation when reversible mechanisms are present in the model [7]. This technique wasused in a model for strategic business planning by the administration at Carnegie Mellon University [23]. Given a library offundamental laws describing an arbitrary system, COA also provides a method to automate the process of model buildingby constructing causal graphs on the fly, depending on which devices are added to the system [16]. The validity of usingCOA for these purposes, however, rests on the existence of a proof of the correctness of COA. Thus, the key significance ofthis paper is that it converts an entire thread of research from a set of useful heuristics to provably correct techniques.1.2. Previous workMuch work on causality has been performed in the past decades in statistics and artificial intelligence. This work hasbeen concerned with representation (e.g., [13,14,19,33,34]), inference (e.g., [15,19]), causal reasoning (e.g., [20,28]), learningfrom data (e.g., [1,18,27,28]), among other topics. Most of this work has dealt with causal models that are very similar tothe type constructed with the COA; however, in their formulations, a causal model is assumed as a given or it is derivedfrom data, and the process of converting a set of equations to a causal model is not considered.Nayak [17] comes the closest to addressing the question that we pose here. He shows that all mappings between struc-tural equations and variables produce the same set of ancestor-descendant pairs. Similarly, we will show that all mappingspossess common features, but these common features will be in terms of direct causal connections rather than indirectancestral relations, and we provide the proof that COA provides a condensed representation of those necessary direct con-nections. Dash [2,3] shows that the causal interpretation of equilibrium systems is not straightforward due to the factthat underlying dynamics can lead to equilibrium independence graphs that are not causal. He terms this reason for non-causality “violation of Equilibration–Manipulation commutability.” We emphasize that the work presented here does notimply that models retrieved by COA are assured to obey the Equilibration–Manipulation commutability property. There existmany other concepts of causality that do not involve a mapping from equations to variables. Granger causality [9] uses\f1802D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808correlations across time to identify causal relations. The work by de Kleer and Brown [4] and that of Williams [35] addressthe problem of determining causality from a set of constraints by propagating disturbances on variables in the model. Thereis a debate as to whether the formalisms of de Kleer and Brown and Williams are consistent wi",
            {
                "entities": [
                    [
                        138,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 983–1016www.elsevier.com/locate/artintThe complexity of soft constraint satisfactionDavid A. Cohen a, Martin C. Cooper b, Peter G. Jeavons c,∗,Andrei A. Krokhin da Department of Computer Science, Royal Holloway, University of London, UKb IRIT, University of Toulouse III, Francec Computing Laboratory, University of Oxford, UKd Department of Computer Science, University of Durham, UKReceived 4 October 2005; received in revised form 13 February 2006; accepted 13 April 2006Available online 5 June 2006AbstractOver the past few years there has been considerable progress in methods to systematically analyse the complexity of constraintsatisfaction problems with specified constraint types. One very powerful theoretical development in this area links the complexityof a set of constraints to a corresponding set of algebraic operations, known as polymorphisms.In this paper we extend the analysis of complexity to the more general framework of combinatorial optimisation problemsexpressed using various forms of soft constraints. We launch a systematic investigation of the complexity of these problems byextending the notion of a polymorphism to a more general algebraic operation, which we call a multimorphism. We show that manytractable sets of soft constraints, both established and novel, can be characterised by the presence of particular multimorphisms. Wealso show that a simple set of NP-hard constraints has very restricted multimorphisms. Finally, we use the notion of multimorphismto give a complete classification of complexity for the Boolean case which extends several earlier classification results for particularspecial cases.© 2006 Elsevier B.V. All rights reserved.Keywords: Soft constraints; Valued constraint satisfaction; Combinatorial optimisation; Submodular functions; Tractability; Multimorphism1. IntroductionIn the standard constraint satisfaction framework [14,38] a constraint is understood to be a predicate, or relation,specifying the allowed combinations of values for some fixed subset of variables: we will refer to such constraintshere as crisp constraints. Problems with crisp constraints deal only with feasibility: no satisfying solution is consideredbetter than any other.A number of authors have suggested that the usefulness of the constraint satisfaction framework could be greatlyenhanced by extending the definition of a constraint to include also soft constraints, which allow different measuresof desirability to be associated with different combinations of values [1,2,43]. In this extended framework a constraint* Corresponding author.E-mail addresses: d.cohen@rhul.ac.uk (D.A. Cohen), cooper@irit.fr (M.C. Cooper), peter.jeavons@comlab.ox.ac.uk (P.G. Jeavons),andrei.krokhin@durham.ac.uk (A.A. Krokhin).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.04.002\f984D.A. Cohen et al. / Artificial Intelligence 170 (2006) 983–1016can be seen as a cost function defined on a fixed subset of the variables which maps each possible combination ofvalues for those variables to a measure of desirability or undesirability.Problems with soft constraints deal with optimisation as well as feasibility: the aim is to find an assignment ofvalues to all of the variables having the best possible overall combined measure of desirability. In this paper weexamine how limiting the choice of cost functions affects the complexity of this optimisation problem.Example 1.1. Consider an optimisation problem where we have to choose sites for n service stations along a motorwayof length L, subject to the following requirements:• There are r > n possible sites at distances d1, . . . , dr along the motorway.• Each pair of consecutive service stations must be separated by a distance which is no less than A and no morethan B.• The service stations should be as equally spaced as possible.One possible way to model this situation is as follows:• Introduce variables v1, v2, . . . , vn to represent the position of each service station, where each variable must be• Impose a binary constraint on each pair vi, vi+1, i = 1, . . . , n − 1, with cost function δ, where δ(x, y) = 0 ifassigned a value from the set {d1, . . . , dr }.A (cid:2) y − x (cid:2) B and ∞ otherwise.• Impose a binary constraint on each pair vi, vi+1, i = 1, . . . , n − 1, with cost function ζ , where ζ (x, y) = |x − y|2.Add a unary constraint on v1 with cost function ζ (0, x), and a unary constraint on vn, with cost function ζ (x, L).(Note that the sum of these functions is minimal when the values of these variables are equally spaced between 0and L.)We would then seek an assignment of values from the set D = {d1, . . . , dr }, to all of the variables, which minimisesthe sum of all these cost functions:n−1(cid:2)i=1δ(vi, vi+1) + ζ (0, v1) +n−1(cid:2)i=1ζ (vi, vi+1) + ζ (vn, L).The cost of allowing additional flexibility in the specification of constraints, in order to model optimisation criteriaas well as feasibility, is generally an increase in computational difficulty. For example, we establish below that theclass of problems containing only unary constraints and a soft version of the binary equality constraint is NP-hard(see Example 2.11).On the other hand, for certain types of soft constraint it is possible to solve the associated optimisation problemsefficiently. For example, we establish below that optimisation problems of the form described in Example 1.1 can besolved in polynomial time (see Example 6.13).In the case of crisp constraints there has been considerable progress in analysing the complexity of problemsinvolving different types of constraints. This work has led to the identification of a number of classes of constraintswhich are tractable, in the sense that there exists a polynomial time algorithm to determine whether or not anycollection of constraints from such a class can be simultaneously satisfied [15,26,33,40,42]. One powerful result inthis area establishes that any tractable class of constraints over a finite domain must have relations which are allpreserved by a non-trivial algebraic operation, known as a polymorphism [6,26].In the case of soft constraints there has been little detailed investigation of the tractable cases, except for certainspecial cases on a two-valued domain [10,30], and a special case involving simple temporal constraints [31]. In anearlier paper [7] we identified a particular tractable class of binary soft constraints, and showed that this class wasmaximal, in the sense that adding any other soft binary constraint which is not in the class gives rise to a class ofproblems which is NP-hard. This class has recently been used to study the complexity of the MINIMUM COST HO-MOMORPHISM problem [21], which has been used to model the “Level of Repair Analysis” problem from operationsresearch [22] (see Example 2.7).\fD.A. Cohen et al. / Artificial Intelligence 170 (2006) 983–1016985In this paper we take the first step towards a systematic analysis of the complexity of soft constraints of arbitraryarity over arbitrary finite domains. To do this we generalise the algebraic ideas used to study crisp constraints, andintroduce a new algebraic operation which we call a multimorphism. Every cost function has an associated set ofmultimorphisms, and every multimorphism has an associated set of cost functions. We show that, for several differenttypes of multimorphism, the associated collection of soft constraints is a maximal tractable class. In other words, weshow that several maximal tractable classes of soft constraints can be precisely characterised as the collection of allsoft constraints associated with a particular multimorphism. Furthermore, we show that a simple NP-hard class of softconstraints has very restricted multimorphisms.Finally, we apply the techniques developed in the paper to the two-valued domain, where we obtain a new di-chotomy theorem which classifies the complexity of any set of soft constraints over this domain (Theorem 7.1). Thisdichotomy theorem generalises several earlier results concerning the complexity of particular Boolean constraint prob-lems, including the SATISFIABILITY problem [42], the MAX-SAT problem [9], the weighted MIN-ONES problem [10,30], and the weighted MAX-ONES problem [10,30] (see Corollary 7.12).The examples given throughout the paper demonstrate that the framework we introduce here can be used to unifyisolated results about tractable problem classes from many different application areas, as well as prompting thediscovery of new tractable classes. For example, the notion of a multimorphism generalises the notion of a poly-morphism (see Proposition 4.10), and so can be used to express earlier results concerning the characterisation oftractable subproblems of many different decision problems: in the case of the SATISFIABILITY problem these includethe HORN-SAT and 2-SAT subproblems [19]; in the case of the standard crisp constraint satisfaction problem theseinclude generalisations of HORN-SAT (such as the so-called ‘max-closed’ constraints [26,29]), generalisations of 2-SAT (such as the so-called ‘0/1/all’ or ‘implicative’ constraints [8,25,32]) and systems of linear equations [26]. Thenotion of a multimorphism can also be used to characterise tractable subproblems of optimisation problems: in thecase of the optimisation problem MAX-SAT these include the ‘0-valid’, ‘1-valid’ and ‘2-monotone’ constraints [10];in the case of optimisation problems over sets these include the minimisation of submodular set functions [23,39] andbisubmodular set functions [18].2. DefinitionsSeveral alternative mathematical frameworks for soft constraints have been proposed in the literature, includingthe very general frameworks of ‘semi-ring based constraints’ and ‘valued constraints’ [1,2,43]. For simplicity, weshall adopt the valued constraint framework here (the relationship with the semi-ring framework is discussed brieflyin Section 8).In the valued c",
            {
                "entities": [
                    [
                        73,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 182–183 (2012) 1–31Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInformation-geometric approach to inferring causal directionsDominik Janzing a,∗Povilas Daniušis e, Bastian Steudel f, Bernhard Schölkopf a, Joris Mooij b, Kun Zhang a, Jan Lemeire c,d, Jakob Zscheischler a,a Max Planck Institute for Intelligent Systems, Tübingen, Germanyb Radboud University, Nijmegen, Netherlandsc Vrije Universiteit Brussel, Brussels, Belgiumd Interdisciplinary Institute for Broadband Technology, Ghent, Belgiume Vilnius University, Lithuaniaf Max Planck Institute for Mathematics in the Sciences, Leipzig, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 21 December 2010Received in revised form 10 January 2012Accepted 10 January 2012Available online 12 January 2012Keywords:Deterministic causal relationsPythagorean tripleCause–effect pairsWhile conventional approaches to causalinference are mainly based on conditional(in)dependences, recent methods also account for the shape of (conditional) distributions.The idea is that the causal hypothesis “ X causes Y ” imposes that the marginal distributionP X and the conditional distribution P Y | X represent independent mechanisms of nature.Recently it has been postulated that the shortest description of the joint distribution P X,Yshould therefore be given by separate descriptions of P X and P Y | X . Since descriptionlength in the sense of Kolmogorov complexity is uncomputable, practical implementationsrely on other notions of independence. Here we define independence via orthogonalityin information space. This way, we can explicitly describe the kind of dependence thatoccurs between P Y and P X|Y making the causal hypothesis “Y causes X” implausible.Remarkably, this asymmetry between cause and effect becomes particularly simple if Xand Y are deterministically related. We present an inference method that works in thiscase. We also discuss some theoretical results for the non-deterministic case although it isnot clear how to employ them for a more general inference method.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe problem of inferring whether X causes Y (write X → Y ) or Y causes X from observations (x1, y1), . . . , (xm, ym)that are i.i.d. drawn from P X,Y is a particularly challenging task for causal inference [1]. Although this restricted problemignores other important problems of causal inference (i.e., unobserved common causes or bidirectional influence), it isuseful for studying statistical asymmetries between cause and effect. Conventional methods for causal inference [2,3] focuson conditional independences and thus require observations from at least three variables.Extending an idea in [4,5] postulates that X → Y is only acceptable as causal hypothesis if the shortest description ofP X,Y is given by separate descriptions of P Y | X and P X . Here description length is understood in the sense of algorithmicinformation (“Kolmogorov complexity”) [6–8]. Note that the postulate is equivalent to saying that P Y | X and P X are algorith-mically independent in the sense that knowing P X does not enable a shorter description of P Y | X and vice versa. To showthat this helps in distinguishing between cause and effect for just two observed variables, [5] constructed toy models ofcausal mechanisms where the causal structure X → Y yields algorithmic dependences between P X|Y and P Y . Even though* Corresponding author.E-mail address: dominik.janzing@tuebingen.mpg.de (D. Janzing).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.01.002\f2D. Janzing et al. / Artificial Intelligence 182–183 (2012) 1–31SectionContentsSection 3Section 4Postulating independence conditions (h1)–(h3) forP cause and P effect|causeJustifying the conditionsRephrasing (h1)–(h3) as orthogonalityImplications of (h3) for deterministic causalityGeneralizing (h3) via exponential familiesInference method for deterministic case based on thegeneralized condition (h3)Main referencePostulate 1 and Definition 1Lemmas 1, 2Theorem 1Theorem 2Postulate 2Sections 4.3 and 4.4Appendix AOutlook: employing orthogonality for inferring non-deterministic relations (toy examples, negative results)Lemmas 9 and 10Fig. 1. Structure of the main results.algorithmic independence between P cause and P effect|cause is an appealing formalization of independence, practical methodsmust be based on computable criteria.[9,10] described a potential asymmetry between cause and effect where independence is meant in terms of statisticalindependence between the cause and the noise term that occurs in the causal mechanism: If Y is a function of X up to anadditive noise term that is statistically independent of X , i.e.,Y = f (X) + E with E ⊥⊥ X,(1)then there is usually (up to some exceptions like the bivariate Gaussian) no such additive noise model from Y to X . In otherwords, writing X as X = g(Y ) + ˜E with some function g will not render the residual term ˜E statistically independent of Y .[11] generalizes the model class to(cid:2)Y = hf (X) + E(cid:3)with E ⊥⊥ X,(2)and show that such a “post-nonlinear (PNL) model” also exists in at most one direction, except for some special cases. IfP X,Y is consistent with (1) or (2), respectively, in one direction but not the other, one infers that direction to be the causalone that is implied by the corresponding model. For the model (1) it has been shown [12] that this kind of reasoning isjustified by the above algorithmic independence principle.Note that these inference methods do not assume that causal relations are always of the above form. They only decidefor one of the causal directions if one and only one direction admits such a model. The idea is the following: if X → Y isthe correct model, but not of the additive noise form, it is rather unlikely that it generates a joint distribution that admitsan additive noise model in the opposite direction. The reason is that this would require rather contrived adjustmentsbetween P X (the marginal distribution of the hypothetical cause) and P Y | X (the conditional distribution of the effect, giventhe cause) [12]. This article develops an information-geometric principle that does not require the restricted class of additivenoise or post-nonlinear models. To this end, we revisit additive noise models in Section 2 and show that entropies can playa key role in describing the kind of dependences between P X|Y and P Y that can occur if X causes Y . This motivates ourinformation-geometric perspective developed in Section 3, which results in an inference method for deterministic causalrelations in Section 4, with an outlook for the non-deterministic case in Appendix A. The table in Fig. 1 shows how themain results are structured.Readers who are only interested in our inference method may focus on Section 4, with Sections 4.3 and 4.4 as its mainparts. The other sections provide a general background and describe a large class of asymmetries between cause and effectthat could be helpful for developing other information-theoretic methods in the future.2. Information-theoretic view on additive noise modelsWe consider the additive noise model (1) in the low noise regime (see Fig. 2) and show how the relationship betweenthe input distribution and the conditional one is different for both directions. We use the following notational conventions.P Y |x is the distribution of Y , given a fixed value x while P Y | X denotes the entire conditional distribution. The range ofa random variable X will be denoted by D X . S(P Y |x) denotes the (differential) Shannon entropy of P Y |x for fixed x. Thefunction x (cid:5)→ S(P Y |x) will also be called the conditional entropy function. Throughout the paper we will assume that alldistributions have densities with respect to a fixed reference measure (e.g., the Lebesgue measure for real-valued variablesor the counting measure for discrete variables). This measure will never appear explicitly and should not be confused withreference probability distributions that occur all over the article. By slightly overloading notation, P X will stand for boththe distribution and the density x (cid:5)→ P X (x). We will also write P (x) instead of P X (x) whenever this causes no confusion.· · · P (x) dx will be understood as sums by interpreting dx as dμ(x) where μFor discrete variables X , integrals of the formdenotes the counting measure.Regarding (1) we observe that E ⊥⊥ X ensures that the conditional entropy function S(P Y |x) is constant in x and coincidesS(P Y |x)P (x) dx). In studying how P Y and P X|Y are then( y)|( y) is large for those y-values where | fwith the conditional entropy S(P Y | X ) (defined by the averagerelated we first assume that P X is uniform. Then, P ( y) ≈ P X ( f−1( y)) · f−1−1(cid:4)(cid:4)(cid:7)(cid:7)\fD. Janzing et al. / Artificial Intelligence 182–183 (2012) 1–313Fig. 2. Functional relation with small noise. The conditional entropy function S(P X| y ) is high at regions with high slope of fthis point.−1( y), i.e., small slope of f atis large. At the same time, the entropy S(P X| y) is large for y-values in regions with large | f( y)| (see Fig. 2). Hence, largeentropy S(P X| y) correlates with high density P ( y), assuming that P (x) is constant on the interval under consideration. If−1( y)) are high. WeP X is not the uniform distribution, high values of P ( y) occur at points where both | fargue later that if the peaks of P (x) do not correlate with the slope of f then the qualitative argument above still holdsand S(P X| y) again correlates with P ( y). This reasoning will be formalized in Section 3.( y)| and P X ( f−1(cid:7)(cid:7)−1The first information-geometric inference principle that we are going to state in the next section no longer assumes thatthe entropy S(P Y |x) is constant in x if X → Y is the true causal direction. Instead, it postulates that regions of large S(P",
            {
                "entities": [
                    [
                        146,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 779–801www.elsevier.com/locate/artintAutomated reformulation of specifications bysafe delay of constraints ✩Marco Cadoli, Toni Mancini ∗Dipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Salaria 113, I-00198 Roma, ItalyReceived 14 September 2004; received in revised form 25 January 2006; accepted 25 January 2006AbstractIn this paper we propose a form of reasoning on specifications of combinatorial problems, with the goal of reformulating themso that they are more efficiently solvable. The reformulation technique highlights constraints that can be safely “delayed”, andsolved afterwards. Our main contribution is the characterization (with soundness proof) of safe-delay constraints with respectto a criterion on the specification, thus obtaining a mechanism for the automated reformulation of specifications applicable to agreat variety of problems, e.g., graph coloring, bin-packing, and job-shop scheduling. This is an advancement with respect to theforms of reasoning done by state-of-the-art-systems, which typically just detect linearity of specifications. Another contributionis an experimentation on the effectiveness of the proposed technique using six different solvers, which reveals promising timesavings.© 2006 Elsevier B.V. All rights reserved.Keywords: Modelling; Reformulation; Second-order logic; Propositional satisfiability; Constraint satisfaction problems1. IntroductionCurrent state-of-the-art languages and systems for constraint modelling and programming (e.g., AMPL [22],OPL [48], XPRESSMP,1 GAMS [9], DLV [31], SMODELS [39], ESRA [21], PS [18] and NP-SPEC [8]) exhibit a strongseparation between a problem specification (e.g., Graph 3-coloring) and its instance (e.g., a graph), usually adopting atwo-level architecture for finding solutions: the specification is firstly instantiated (or grounded) against the instance,and then an appropriate solver is invoked (cf. Fig. 1). Such a separation leads to several advantages: obviously declar-ativeness increases, and the solver is completely decoupled from the specification. Ideally, the programmer can focusonly on the combinatorial aspects of the problem specification, without committing a priori to a specific solver. In✩ This paper is an extended and revised version of [M. Cadoli, T. Mancini, Automated reformulation of specifications by safe delay of constraints,in: Proceedings of the Ninth International Conference on the Principles of Knowledge Representation and Reasoning (KR 2004), Whistler, BC,Canada, AAAI Press/The MIT Press 2004, pp. 388–398].* Corresponding author.E-mail addresses: cadoli@dis.uniroma1.it (M. Cadoli), tmancini@dis.uniroma1.it (T. Mancini).1 Cf. http://www.dashoptimization.com.0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.01.008\f780M. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801Fig. 1. Two-level architecture of current problem solving systems.fact, some systems, e.g., AMPL, are able to translate—at the request of the user—a specification in various formats,suitable for different solvers, e.g., among the others, CPLEX, MINOS,2 LANCELOT.3Nonetheless, many existing techniques proposed in the literature for optimizing the solution of constraint satisfac-tion problems apply after the commitment to the instance: notable examples are, e.g., symmetry detection and breaking(cf., e.g., [4,16,37]), the development of techniques for imposing various local consistency notions and of heuristicsduring search (cf., e.g., [17]), the development of algorithms that deal with dependent variables, e.g., those added toSAT instances during the clausification of non-CNF formulae [27], and with the so-called “equivalence clauses” [32].However, in many cases, properties that are amenable to be optimized derive from the problem structure, ratherthan the particular instance considered. Optimization techniques that act on the problem structure have been proposed.They include the addition of implied constraints (cf., e.g., [47]), the deletion or abstraction of some of the constraints(cf., e.g., [28]), the use of redundant models, i.e., multiple viewpoints synchronized by channelling constraints, inorder to increase constraint propagation [12,20,29].Our research follows the latter approach, with the aim of systematize the process of finding useful reformulationsby performing a symbolic reasoning on the specification. In general, for many properties, symbolic reasoning can bemore natural and effective than making such “structural” aspects emerge after instantiation, when the structure of theproblem has been hidden.An example of system that performs a sort of reasoning on the specification is OPL, which is able to automaticallychoose the most appropriate solver for a problem. However, the kind of reasoning offered is very primitive: OPL onlychecks (syntactically) whether a specification is linear, in this case invoking a linear—typically more efficient—solver,otherwise a general constraint programming one.Conversely, our research aims to the following long-term goal: the automated reformulation of a declarative con-straint problem specification, into a form that is more efficiently evaluable by the solver at hand. The ultimate goal is tohandle all properties suitable for optimization that derive from the problem structure at the specification level, leavingat the subsequent instance level the handling of the remaining ones, i.e., those that truly depend on the instance. Infact, it is worthwhile to note that focusing on the specification does not rule out the possibility of additionally applyingexisting optimization techniques at the instance level.The approach we follow is similar, in a sense, to the one used in the database research community for attackingthe query optimization problem in relational databases. A query planner, whose task is to reformulate the query posedby the user in order to improve the efficiency of the evaluation, takes into account the query and the database schemaonly, not its current content, i.e., the instance (cf., e.g., [1]).In general, reformulating a constraint problem specification is a difficult task: a specification is essentially a formulain second-order logic, and it is well known that the equivalence problem is undecidable already in the first-order case[3]. For this reason, research must focus on controlled and restricted forms of reformulation.Moreover, the effectiveness of a particular reformulation technique is expected to depend both on the problem andon the solver, even if it is possible, in principle, to find reformulations that are good for all solvers (or for solversof a certain class, e.g., linear, or SAT-based ones). To this end, in related work (cf. Section 6), we present differentreformulation strategies that have been proposed in order to speed-up the process of solving a constraint problem.2 Cf. http://www.sbsi-sol-optimize.com/.3 Cf. http://www.cse.clrc.ac.uk/nag/lancelot/lancelot.shtml.\fM. Cadoli, T. Mancini / Artificial Intelligence 170 (2006) 779–801781Fig. 2. Delaying the disjointness constraint in 3-coloring. (a) 1st stage: covering and good coloring; (b) 2nd stage: disjointness.(a)(b)In this paper, we propose a technique that allows us to select constraints in a problem specification that can beignored in a first step (regardless of the instance), and efficiently reinforced once a solution of the simplified problemhas been found. We call such constraints safe-delay. Moreover, we experimentally show how reformulating problemspecifications by safe-delay improves performances of different (but not all) solvers. On one hand, this gives evidencethat problem reformulation can be effective in many cases, and on the other, it confirms the intuition that a singlereformulation technique may have positive effects for some classes of solvers, but negative ones for others, and thata portfolio of different and complementary reformulation strategies has to be considered, in general (cf. Section 6 forrelated work).The NP-complete graph k-coloring problem offers a simple example of a safe-delay constraint. The problemamounts to find an assignment of nodes to k colors such that:• Each node has at least one color (covering);• Each node has at most one color (disjointness);• Adjacent nodes have different colors (good coloring).For each instance of the problem, if we obtain a solution neglecting the disjointness constraint, we can alwayschoose for each node one of its colors in an arbitrary way at a later stage (cf. Fig. 2). It is interesting to note that thedeletion of the disjointness constraints in graph k-coloring has been already proposed as an ad-hoc technique in [46](cf. also [42]), and implemented in, e.g., the standard DIMACS formulation in SAT of k-coloring.Of course not all constraints are safe-delay: as an example, both the covering and the good coloring constraints arenot. Intuitively, identifying the set of constraints of a specification which are safe-delay may lead to several advantages:• The instantiation phase (cf. Fig. 1) will typically be faster, since safe-delay constraints are not taken into account.As an example, let’s assume we want to use (after instantiation) a SAT solver for the solution of k-coloring ona graph with n nodes and e edges. The SAT instance encoding the k-coloring instance—in the obvious way, cf.,e.g., [25]—has n · k propositional variables, and a number of clauses which is n, n · k · (k − 1)/2, and e · k forcovering, disjointness, and good coloring, respectively. If we delay disjointness, n · k · (k − 1)/2 clauses need notto be generated.• Solving the simplified problem, i.e., the one without disjointness, might be easier than the original formulation forsome classes of solvers, since removing constraints makes the set of solutions larger. For each instance it holdsthat:{solutions of original problem} ⊆ {solutions of simplified problem}.In our experiments, using ",
            {
                "entities": [
                    [
                        2345,
                        2415,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1367–1405Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVivid: A framework for heterogeneous problem solving ✩Konstantine Arkoudas, Selmer Bringsjord∗Rensselaer AI & Reasoning (RAIR) Lab, Department of Cognitive Science, Department of Computer Science, Rensselaer Polytechnic Institute (RPI), Troy, NY 12180, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 30 June 2008Received in revised form 1 June 2009Accepted 9 June 2009Available online 13 June 2009Keywords:VividHeterogeneous reasoningProblem solvingDiagramsDPLsAssumption basesNamed system statesWorlds3-valued logic1. IntroductionWe introduce Vivid, a domain-independent framework for mechanized heterogeneous rea-soning that combines diagrammatic and symbolic representation and inference. The frame-work is presented in the form of a family of denotational proof languages (DPLs). Wepresent novel formal structures, called named system states, that are specifically designedfor modeling potentially underdetermined diagrams. These structures allow us to deal withincomplete information, a pervasive feature of heterogeneous problem solving. We intro-duce a notion of attribute interpretations that enables us to interpret first-order relationalsignatures into named system states, and develop a formal semantic framework based on3-valued logic. We extend the assumption-base semantics of DPLs to accommodate dia-grammatic reasoning by introducing general inference mechanisms for the valid extractionof information from diagrams, and for the incorporation of sentential information into dia-grams. A rigorous big-step operational semantics is given, on the basis of which we provethat the framework is sound. We present examples of particular instances of Vivid in orderto solve a series of problems, and discuss related work.© 2009 Elsevier B.V. All rights reserved.Diagrams have been recognized as valuable representational and reasoning tools at least since the days of Euclid. They areused extensively in a very wide range of fields. To note just a few examples, witness: free-body, energy-level and Feynmandiagrams in physics [60]; arrow diagrams in algebra and category theory [44]; Euler and Venn diagrams in elementaryset theory and logic; function graphs in calculus and analysis; planar figures in geometry; bar, chart, and pie graphs ineconomics; circuit, state, and timing diagrams in hardware design [32]; UML diagrams in software design [47]; higraphsin specification [25]; visual programming languages [15] and visual logic and specification languages [1,27,42]; transitiongraphs in model checking [11]; ER-diagrams and hypergraphs in databases [21]; semantic (as well as neural and belief)networks in AI [50]; icons and other pictorial devices in graphical user interfaces (GUIs) and information visualization[12,39,59,63]; and so on. Given such a list, and the power of diagrams that it suggests, it seems reasonable to hold thatif the capability of computers to work with diagrams intelligently can be further increased, human reasoning and problemsolving will be facilitated. The framework presented here, Vivid, is intended to purchase some of that increase.The representational power of diagrams stems primarily from the fact that they can have structural correspondenceswith the objects or situations they represent—they are analogical representations in the terminology of Sloman [54], orhomomorphic representations in the terminology of Barwise and Etchemendy [7]; also see Hayes [26]. To put it more plainly,✩This work was made possible by grants received from DARPA and DTO. We are indebted to Ron Brachman, David Musser, Martin Rinard, and to threeanonymous referees for insightful comments, objections, and suggestions.* Corresponding author.E-mail addresses: arkouk@rpi.edu (K. Arkoudas), selmer@rpi.edu (S. Bringsjord).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.002\f1368K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405a diagram resembles—or at any rate should resemble—what the diagram depicts, in contrast to sentential descriptions.1 Thiswas noticed at least as far back as the 19th century, when Peirce observed that a diagram is “naturally analogous to thething represented” [43, p. 316].Consider, for instance, the task of describing a human face. We could perhaps describe the face with a collection ofEnglish sentences, or with a set of sentences in some formal language. But such a description is likely to be long andcomplicated, and not particularly illuminating.2 A drawing or a picture of the face, on the other hand, will be much moreperspicuous, as well as significantly more compact than most sentential representations. Of course, some diagrams arebetter than others. A talented artist will produce a drawing that is a much more accurate depiction than the scrawlings ofa child. A digital picture will be even more accurate.3 So, as Hammer [24] observes, being an analogical or homomorphicrepresentation is not a distinguishing feature of diagrams in general, but rather a distinguishing feature of good diagrams.The utility of (good) diagrams is often thought to derive from the fact that diagrams are two-dimensional objects, andtherefore spatial relationships on the plane can directly reflect analogous relationships in the underlying domain, an obser-vation made a while back by Russell [49]. A classic example are maps. We can represent the streets of a city graphically,with a map, or sententially, e.g., by a collection of assertions expressing the various intersections and so forth. The graphicalrepresentation is doubtless a more intuitive and effective description because its spatial structure is similar to the actuallayout of the city. This analogical correspondence is lost in the sentential representation. As another example, consider amap of a lake and try to imagine a sentential description of it. Stenning and Lemon [57] trace this discrepancy to the factthat sentential languages derive from acoustic signals, which are one-dimensional and must therefore rely on a complexsyntax for representation, something that is not necessary in the case of diagrams.However, two-dimensionality by itself is neither a necessary nor a sufficient condition for being a diagram. For instance,as Hammer [24] points out, a representation of a picture by a two-dimensional array of numbers encoded under someencryption scheme does not count as a diagram; there is no structural similarity between the representation and thatwhich is being represented. And, by making sufficiently clever conventions, we can construct analogical one-dimensionaldiagrams. For example, the following string asserts that the stretch of road between Main Street/35th Street and Main/36this two-way, whereas that between Main/36th and Main/37th is one-way and proceeds from right to left:Main|35th <==> Main|36th <== Main|37thIt bears stressing that diagrams are helpful only when their visual structure is analogical or homomorphic with thesemantic structure of the information which they represent. In an era of Powerpoint and multimedia presentations, it isoften taken for granted that graphical displays of information are automatically clearer and more intuitive than text, simplyby virtue of being “visual.” That is emphatically not the case. The reason why Euler circles are efficacious, for instance, isprecisely because spatial enclosure is naturally analogous to the subset relation, spatial overlap to set-theoretic intersection,and spatial separation to set-theoretic disjointness [53]. In the absence of such structural similarities, diagrams can quicklydegenerate into what Tufte [59, p. 34] calls “chartjunk”: cluttered displays of lines, curves, arrows, bars, charts, and the like,that end up obscuring rather than clarifying information.4 Conversely, a diagram does not have to be visually arresting orelaborate in order to be superior to a sentential representation. It does not even have to be two-dimensional, as we notedabove, a point that is borne out by our Main Street example, or by Hammer’s example of an one-dimensional diagrammeant to express the relative distances between the Earth, Moon, and Mars when the Moon is aligned to fall betweenEarth and Mars:Earth–Moon————MarsThis diagram is one-dimensional: its syntax can be adequately modeled by sequences of symbols [24, p. 2].Some might be inclined to criticize such diagrams as inordinately simple and purely structural, hence suffering from in-sufficient “diagrammaticity,” the implication being that only visually elaborate diagrams qualify as truly diagrammatic. Thecriticism is at odds with the brute reality of ingenious human diagrammatic reasoning and problem solving. For example,consider the well-known example of the seating puzzle of Barwise and Etchemendy [6], which we discuss extensively inSection 8. The diagrams in that puzzle are indeed very simple (one-dimensional, small, and purely ASCII); but they are noless powerful for human reasoners as a result. In fact, their structural nature and simplicity, far from being defects, arepositively conducive to their representational power. Structure and simplicity are usually advantages of analogical represen-tations, not disadvantages.1 The terms “sentential” and “symbolic” will be used synonymously throughout.2 Fractals [37] might be able to yield compact representations for some complex shapes such as coastlines, etc., but the equations generating the fractalswould be no more analogical to the corresponding shapes than other symbolic descriptions.3 In the limiting case, the ultimate representation of an object is the object itself.4 Peter Norvig provides an amusing but compelling illustration of this point in his Powerpoint version of the Gettysburg address, where he turns “fourscores and seven years” into a gratuitous graph: www.norvig.com/Gettysburg/sld005.htm. More inf",
            {
                "entities": [
                    [
                        138,
                        190,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 237 (2016) 204–227Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHierarchical conceptual spaces for concept combinationMartha Lewis a,∗a Department of Computer Science, University of Oxford, OX1 3QD, United Kingdomb Department of Engineering Mathematics, University of Bristol, BS8 1UB, United Kingdom, Jonathan Lawry ba r t i c l e i n f oa b s t r a c tArticle history:Received 12 December 2014Received in revised form 4 January 2016Accepted 30 April 2016Available online 6 May 2016Keywords:Conceptual spacesConcept compositionRandom setsWe introduce a hierarchical framework for conjunctive concept combination based on conceptual spaces and random set theory. The model has the flexibility to account for composition of concepts at various levels of complexity. We show that the conjunctive model includes linear combination as a special case, and that the more general model can account for non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence. We investigate two further aspects of human concept use, the conjunction fallacy and the ‘guppy effect’.© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionHumans undoubtedly have the ability to form new concepts by combining existing ones. The development of effective representational models of this phenomenon could potentially shed light on human cognition. Human-like reasoning has been argued to be important to artificial intelligence for its flexibility and robustness [6,29,44]. Further, a good representa-tion of human concept use will aid us in considering problems of categorization and typicality, as argued by Freund [18]. Applications of AI that must interact with humans via natural language arguably need to be able to understand and to form for themselves novel combinations of concepts. Examples of theories proposed to account for such concept combi-nation include prototype theory together with fuzzy set theory [51], conceptual spaces [19], and quantum probability [3,9] approaches. Well-known counterexamples have been identified which suggest that fuzzy sets may not provide an ap-propriate formalisation in this context [25,27,40]. It is argued in [25] that the failure of fuzzy set theory to adequately model human concept combination results from its failure to consider the intension of concepts, i.e., the attributes that the concept possesses. In contrast, the conceptual spaces and the quantum approaches take intension into account, either by considering concepts as being comprised of a combination of properties,1 which are themselves embedded in a space of quality dimensions, or by incorporating context into the model. Our proposed approach utilises a random set interpretation of membership so as to quantify an agent’s subjective uncertainty about the extent of application of a concept. We refer to this uncertainty as semantic uncertainty [33] in order to emphasise that it concerns the definition of concepts and cate-gories. Lawry and Tang [33] combine random set theory with conceptual spaces [19] and prototype theory [43], to give a formalisation of concepts as based on a prototype and an uncertain distance threshold, located in a conceptual space. We use this account of concepts to provide a framework for conjunctive concept combination which captures the effects seen * Corresponding author.E-mail address: martha.lewis@cs.ox.ac.uk (M. Lewis).1 In the current paper, we use the terms ‘attribute’ and ‘property’ interchangeably.http://dx.doi.org/10.1016/j.artint.2016.04.0080004-3702/© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fM. Lewis, J. Lawry / Artificial Intelligence 237 (2016) 204–227205in [25], including non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence.An outline of the paper is as follows. Section 2 overviews a range of theoretical approaches to concept combination from the literature, and summarises the results from experimental studies that we aim to model. Section 3 describes a random set and prototype theory representational model for concepts within a conceptual space. This model provides the theoretical underpinning for our work. Section 4 introduces a framework for concept combination based on a hierarchy of conceptual spaces, and in which compound concepts are defined within Boolean spaces. We prove a number of results showing the properties of this framework and compare this approach to others in the literature. Section 5 provides a discussion of our results and indicates possible future directions.2. BackgroundIn this section, we describe a number of approaches to concept combination that have been proposed. We consider general set-theoretic approaches, supervaluation theory, prototype theory, fuzzy set theory, conceptual spaces theory, ap-proaches from computational linguistics and quantum cognition approaches. We further describe some results from experi-mental studies with which we compare the theory we develop.2.1. Set-theoretic approachesMontague semantics [39] takes a model-theoretic approach to concepts and sentences. Concepts are defined using no-tions from set theory, and natural language expressions are modelled as functions or relations on these sets. This gives a de-scription of how the semantics of a language interacts with the syntax, so that the meaning of a compound expression may be systematically derived from its parts. However, as discussed in [27,28], this is inadequate for modelling some types of ad-jectives. In [39], an adjective is viewed as a function from properties to properties. This allows sentences such as ‘every small elephant is small’ not to be branded as logically true, which is what we require. This enables various types of adjective to be modelled. Intersective adjectives are those where the application of that adjective may simply be viewed as an intersection of sets (such as ‘red car’). Adjectives that are not intersective may be subsective, when the adjective-noun combination is a sub-set of the noun, or non-subsective, for example privative adjectives like ‘fake’, or ‘former’. However, the theory of adjectives as a function of properties is inadequate, in particular because it doesn’t account for comparatives, i.e. the ability to say that x is A-er than y. To account for this, Kamp introduces a theory of vague models, which are viewed as a nested sequence of partial models. In a partial model, a predicate is explained as assigning a value 1 to those objects which fall under the pred-icate, 0 to those that do not fall under the predicate, and no value to those for whom the predicate is indeterminate. These partial models may be completed in various ways, and the degree of truth of a sentence is related to the probability of a par-ticular set of completions of a partial model of the sentence conditioned on all sets of completions of the model. This set of completed models forms the basis for Kamp’s supervaluation, where a sentence has truth value 1 if it is true in all comple-tions of the model, 0 if it is false in all completions of the model, and indeterminate if it is true in some and false in others.Kamp’s approach is similar to Fine’s [17], in which the questions of the correct logic for vagueness and the correct truth conditions for a vague language are considered. Fine calls the possibility that logical relations hold between indefinite sentences penumbral connection, and truths that arise from such a connection penumbral truths, and argues that no natural truth-value approach respects such truths. He argues that differences in truth-value within penumbral truths concerning two predicates are essentially a difference in the way that these predicates can be made more precise. He describes a theory of super-truth, in which a sentence is true iff it is true in all admissible and complete specifications of the sentence.Both these approaches use the idea that there are in fact precise ways of describing a concept, and that the truth value of a sentence using a vague concept is dependent on the different possible ways of making the sentence more precise. In what follows, we do not consider truth values of sentences but rather typicality of an item to a concept. However, consideration of logics using the fuzzy sets we develop would be an interesting line of future work.Interestingly, [1] argue that adjective-noun combinations can be represented purely as set intersection between the adjective and the head noun. This is achieved by the use of typed sets. These are sets in which members are assigned types. So the adjective ‘clever’ is represented in the following way:Clever = { j : human, f : pet, f : policedog} : cleverwhere the interpretation of j is ‘John’, and the interpretation of f is ‘Fido’. [1] argue that by using this type of representation the problems of privative adjectives can be circumvented. An example is as follows. From the two sentences ‘Maria is a former teacher’ and ‘Maria is a programmer’, we do not wish to infer ‘Maria is a former programmer’. The typed set representation is as follows:H uman = {m : human, ...} : humanT eacher = {m : teacher, ...} : teacherF ormer = {m : teacher, ...} : f ormerP rogrammer = {m : programmer, ...} : programmer\f206M. Lewis, J. Lawry / Artificial Intelligence 237 (2016) 204–227Then, we can infer that m ∈ F ormer ∩ T eacher, but not that m ∈ F ormer ∩ P rogrammer. This is further extended to describe differences in scope when applying multiple adjectives. The approach described is interesting, and could presumably be extended to include some ",
            {
                "entities": [
                    [
                        136,
                        190,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1897–1916Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLabel ranking by learning pairwise preferencesEyke Hüllermeier a,∗, Johannes Fürnkranz b, Weiwei Cheng a, Klaus Brinker aa Department of Mathematics and Computer Science, Philipps-Universität Marburg, Germanyb Department of Computer Science, TU Darmstadt, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 21 January 2008Received in revised form 14 July 2008Accepted 8 August 2008Available online 15 August 2008Keywords:Preference learningRankingPairwise classificationConstraint classification1. IntroductionPreference learning is an emerging topic that appears in different guises in the recentliterature. This work focuses on a particular learning scenario called label ranking, wherethe problem is to learn a mapping from instances to rankings over a finite number oflabels. Our approach for learning such a mapping, called ranking by pairwise comparison(RPC), first induces a binary preference relation from suitable training data using a naturalextension of pairwise classification. A ranking is then derived from the preference relationthus obtained by means of a ranking procedure, whereby different ranking methods canbe used for minimizing different loss functions. In particular, we show that a simple(weighted) voting strategy minimizes risk with respect to the well-known Spearman rankcorrelation. We compare RPC to existing label ranking methods, which are based on scoringindividual labels instead of comparing pairs of labels. Both empirically and theoretically, itis shown that RPC is superior in terms of computational efficiency, and at least competitivein terms of accuracy.© 2008 Elsevier B.V. All rights reserved.The topic of preferences has recently attracted considerable attention in Artificial Intelligence (AI) research, notably infields such as agents, non-monotonic reasoning, constraint satisfaction, planning, and qualitative decision theory [19].1 Pref-erences provide a means for specifying desires in a declarative way, which is a point of critical importance for AI. In fact,consider AI’s paradigm of a rationally acting (decision-theoretic) agent: The behavior of such an agent has to be driven byan underlying preference model, and an agent recommending decisions or acting on behalf of a user should clearly reflectthat user’s preferences.It is hence hardly surprising that methods for learning and predicting preferences in an automatic way are amongthe very recent research topics in disciplines such as machine learning, knowledge discovery, and recommender systems.Many approaches have been subsumed under the terms of ranking and preference learning, even though some of themare quite different and are not sufficiently well discriminated by existing terminology. We will thus start our paper with aclarification of its contribution (Section 2). The learning scenario that we will consider in this paper assumes a collectionof training examples which are associated with a finite set of decision alternatives. Following the common notation ofsupervised learning, we shall refer to the latter as labels. However, contrary to standard classification, a training example isnot assigned a single label, but a set of pairwise preferences between labels (which neither has to be complete nor entirely* Corresponding author.E-mail addresses: eyke@informatik.uni-marburg.de (E. Hüllermeier), juffi@ke.informatik.tu-darmstadt.de (J. Fürnkranz), cheng@informatik.uni-marburg.de(W. Cheng), brinker@informatik.uni-marburg.de (K. Brinker).1 The increasing activity in this area is also witnessed by several workshops that have been devoted to preference learning and related topics, such asthose at the NIPS-02, KI-03, SIGIR-03, NIPS-04, GfKl-05, IJCAI-05 and ECAI-2006 conferences (the second and fifth organized by two of the authors).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.002\f1898E. Hüllermeier et al. / Artificial Intelligence 172 (2008) 1897–1916Table 1Four different approaches to learning from preference information together withrepresentative referencesmodeling utility functionsmodeling pairwise preferencesobject rankinglabel rankingcomparison training [58]constraint classification [28]learning to order things [13]this work [24]consistent), each one expressing that one label is preferred over another. The goal is to learn to predict a total order, aranking, of all possible labels for a new training example.The ranking by pairwise comparison (RPC) algorithm, which we introduce in Section 3 of this paper, has a modular struc-ture and works in two phases. First, pairwise preferences are learned from suitable training data, using a natural extensionof so-called pairwise classification. Then, a ranking is derived from a set of such preferences by means of a ranking procedure.In Section 4, we analyze the computational complexity of the RPC algorithm. Then, in Section 5, it will be shown that, byusing suitable ranking procedures, RPC can minimize the risk for certain loss functions on rankings. Section 6 is devoted toan experimental evaluation of RPC and a comparison with alternative approaches applicable to the same learning problem.The paper closes with a discussion of related work in Section 7 and concluding remarks in Section 8. Parts of this paper arebased on [24,25,33].2. Learning from preferencesIn this section, we will motivate preference learning2 as a theoretically interesting and practically relevant subfield ofmachine learning. One can distinguish two types of preference learning problems, namely learning from object preferencesand learning from label preferences, as well as two different approaches for modeling the preferences, namely by evaluatingindividual alternatives (by means of a utility function), or by comparing (pairs of) competing alternatives (by means of apreference relation). Table 1 shows the four possible combinations thus obtained. In this section, we shall discuss theseoptions and show that our approach, label ranking by pairwise comparison, is still missing in the literature and hence anovel contribution.2.1. Learning from object preferencesThe most frequently studied problem in learning from preferences is to induce a ranking function r(·) that is able to orderany subset O of an underlying class X of objects. That is, r(·) assumes as input a subset O = {x1 . . . xn} ⊆ X of objects andreturns as output a permutation τ of {1 . . . n}. The interpretation of this permutation is that object xi is preferred to x jwhenever τ (i) < τ ( j). The objects themselves (e.g. websites) are typically characterized by a finite set of features as inconventional attribute-value learning. The training data consists of a set of exemplary pairwise preferences. This scenario,summarized in Fig. 1, is also known as “learning to order things” [13].As an example consider the problem of learning to rank query results of a search engine [35,52]. The training informationis provided implicitly by the user who clicks on some of the links in the query result and not on others. This informationcan be turned into binary preferences by assuming that the selected pages are preferred over nearby pages that are notclicked on [36].2.2. Learning from label preferencesIn this learning scenario, the problem is to predict, for any instance x (e.g., a person) from an instance space X , apreference relation (cid:4)x ⊆ L × L among a finite set L = {λ1 . . . λm} of labels or alternatives, where λi (cid:4)x λ j means thatinstance x prefers the label λi to the label λ j . More specifically, we are especially interested in the case where (cid:4)x is a totalstrict order, that is, a ranking of L. Note that a ranking (cid:4)x can be identified with a permutation τx of {1 . . . m}, e.g., thepermutation τx such that τx(i) < τx( j) whenever λi (cid:4)x λ j (τ (i) is the position of λi in the ranking). We shall denote theclass of all permutations of {1 . . . m} by Sm. Moreover, by abuse of notation, we shall sometimes employ the terms “ranking”and “permutation” synonymously.The training information consists of a set of instances for which (partial) knowledge about the associated preferencerelation is available (cf. Fig. 2). More precisely, each training instance x is associated with a subset of all pairwise preferences.Thus, even though we assume the existence of an underlying (“true”) ranking, we do not expect the training data to providefull information about that ranking. Besides, in order to increase the practical usefulness of the approach, we even allow forinconsistencies, such as pairwise preferences which are conflicting due to observation errors.2 We interpret the term “preference” not literally but in a wide sense as a kind of order relation. Thus, a (cid:4) b can indeed mean that alternative a is moreliked by a person than b, but also that a is an algorithm that outperforms b on a certain problem, that a is an event that is more probable than b, that ais a student finishing her studies before b, etc.\fE. Hüllermeier et al. / Artificial Intelligence 172 (2008) 1897–19161899Given:• a (potentially infinite) reference set of objects X(each object typically represented by a feature vector)• a finite set of pairwise preferences xi (cid:4) x j , (xi , x j ) ∈ X × XFind:• a ranking function r(·) that assumes as input a set of objects O ⊆ X andreturns a permutation (ranking) of this setFig. 1. Learning from object preferences.Given:• a set of training instances {xk | k = 1 . . . n} ⊆ X(each instance typically represented by a feature vector)• a set of labels L = {λi | i = 1 . . . m}• for each training instance xk : a set of pairwise preferences of the formλi (cid:4)xk λ jFind:• a ranking function that maps any x ∈ X to a ranking (cid:4)x of L (permutationτx ∈ Sm)Fig. 2. Learning from label preferences.As in the case of object ranking, this learning scenario has ",
            {
                "entities": [
                    [
                        138,
                        184,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 180–195Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStrong mediated equilibrium ✩Dov Monderer, Moshe Tennenholtz∗Faculty of Industrial Engineering and Management, Technion – Israel Institute of Technology, Haifa 32000, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 22 November 2007Received in revised form 5 October 2008Accepted 7 October 2008Available online 14 October 2008Keywords:Multi-agent systemsGame theoryMediatorMediated equilibriumStrong equilibriumStability against potential deviations by sets of agents is a most desired property inthe design and analysis of multi-agent systems. However, unfortunately, this property istypically not satisfied. In game-theoretic terms, a strong equilibrium, which is a strategyprofile immune to deviations by coalition, rarely exists. This paper suggests the use ofmediators in order to enrich the set of situations where we can obtain stability againstdeviations by coalitions. A mediator is defined to be a reliable entity, which can askthe agents for the right to play on their behalf, and is guaranteed to behave in a pre-specified way based on messages received from the agents. However, a mediator cannotenforce behavior; that is, agents can play in the game directly, without the mediator’shelp. A mediator generates a new game for the players, the mediated game. We provesome general results about mediators, and mainly concentrate on the notion of strongmediated equilibrium, which is just a strong equilibrium at the mediated game. We showthat desired behaviors, which are stable against deviations by coalitions, can be obtainedusing mediators in several classes of settings.© 2008 Published by Elsevier B.V.1. IntroductionWhen considering a prescribed behavior in a multi-agent system, it makes little sense to assume that an agent willstick to its part of that behavior, if deviating from it can increase its payoff. This leads to much interest in the study ofNash equilibrium in games. When agents are allowed to use mixed strategies, Nash equilibrium always exists. However,Nash equilibrium does not take into account deviations by non-singleton sets of agents. While stability against deviationsby subsets of the agents, captured by the notion of strong equilibrium [4], is a most natural requirement, it is well knownthat obtaining such stability is possible only in rare situations.1In order to tackle this issue we consider in this paper the use of mediators. A mediator is a reliable entity that can interactwith the players and perform on their behalf actions in a given game. However, a mediator cannot enforce behavior. Indeed,an agent is free to participate in the game without the help of the mediator. This notion is highly natural in a setting inwhich there exists some form of reliable party or administrator that is ready to serve as a mediator. For example, whenEbay is offering proxy services, it actually acts as a mediator and not only as an organizer. Notice that we assume that themulti-agent interaction formalized as a game is given, and that all the mediator can do is to communicate with the agents✩An extended abstract of this paper appears in the proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06). Almost allproofs are missing from the extended abstract. This version of the paper contains all of these missing proofs, and provides additional discussion and results.Furthermore, some of the definitions that appear in the extended abstract have been slightly modified. This work has been partially supported by the IsraelScience Foundations (ISF).* Corresponding author.E-mail address: moshet@ie.technion.ac.il (M. Tennenholtz).1 For example, in the context of congestion games, Holzman and Law-Yone [13] characterized the networks where strong equilibrium always exist. Theyshowed that strong equilibrium is guaranteed only in a very restricted type of networks.0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.10.005\fD. Monderer, M. Tennenholtz / Artificial Intelligence 173 (2009) 180–195181and perform actions on behalf of the agents that allow it to do so. The mediator’s behavior is pre-specified and depends onthe messages received from all agents. This natural setting is different from the one discussed in the theory of mechanismdesign, where a designer designs a new game from scratch in order to yield some desired behavior.Indeed, many markets employ very powerful forms of mediators like brokers, or routers in communication networks.2 Wefind the notion of a mediator as central to the study of multi-agent systems. Indeed, while in economic theory, the dominanttheme is that rational agents are to behave independently without any interference of a mediator, the (either explicit orimplicit) existence of a party that provides suggestions, protocols, and rules of behavior has always been fundamental in theAI context of multi-agent systems (see [9,25] for some early introductions). As a result, in this paper we develop a rigorousstudy of mediators, aiming at the study of their use in establishing stability against deviations by coalitions.A mediator for a given game is defined by sets of messages, one set for each player, and by an action function definedon vectors of messages; when a player sends a message to the mediator she gives the right to play to the mediator whowill choose an action on her behalf (possibly by randomization) by applying the action function to the vector of messagessent to him. However, the mediator cannot enforce the players to use his services. The mediator generates a new gamefor the players, which we call the mediated game. In this game every player can either send a message to the mediator orplay without the mediator. The outcome generated in the given game by an equilibrium in the mediated game is calleda mediated equilibrium. An outcome generated by a strong equilibrium at the mediated game is called a strong mediatedequilibrium. In an extreme case the message space of each player is a singleton. That is, this mediator accepts only onepossible message: “I give you the right to play on my behalf”. Such a mediator is called a minimal mediator. An importantmediator is the one already developed in [32], where the set of messages of each player is the set of possible programsin a given programming language; in this case the action function is the one that executes the programs. Hence, programequilibrium is a particular type of mediated equilibrium. We further discuss the connections between mediators and thenotion of program equilibrium in Section 10. In this paper we concentrate on the notion of strong mediated equilibrium.In order to illustrate the power of a reliable mediators as discussed in this paper, consider the following simple example:In this classical Prisoners’ dilemma game we get that in the unique equilibrium both agents will defect, yielding both ofthem a payoff of 1. However, this equilibrium, which is also a dominant strategy equilibrium, is inefficient; indeed, if bothagents deviate from defection to cooperation then both of them will improve their payoffs. Formally, mutual defection isnot a strong equilibrium.Consider a reliable minimal mediator who offers the agents the following action function: if both agents give the media-tor the right to play, he will perform cooperate on behalf of both agents. However, if only one agent agrees to give the rightto play, the mediator he will perform defect on behalf of that agent. Hence, the mediator generates the following mediatedgame:2 One interesting type of such markets is that of lottery syndicates. A lottery syndicate coordinates agents’ activities in a lottery by trying to optimizethe participants’ joint actions. Such syndicates are known to be successful in the UK. It seems, however, that they are considered illegal at the US.\f182D. Monderer, M. Tennenholtz / Artificial Intelligence 173 (2009) 180–195The mediated game has a most desirable property: it possesses a strong equilibrium; that is, an equilibrium which isstable against deviations by coalitions. In this equilibrium both agents will give the mediator the right to play, which willlead them to a payoff of 4 each! Hence, cooperation in the Prisoners’ Dilemma game is a strong mediated equilibrium.In Sections 3 and 4 we explore general properties of mediators. Given the general concept of a mediator, we prove thatmediators can indeed significantly increase the set of multi-agent encounters in which desired outcomes, which are stableagainst deviations by coalitions, can be obtained. We first prove that every two-person game possesses a strong mediatedequilibrium, which also leads to optimal surplus. For general n-person games we prove that every balanced symmetric gamepossesses a strong mediated equilibrium, which also leads to optimal surplus. The precise definition of a balanced game isgiven in Section 7.1.3 On an intuitive level, a game is balanced if there exists a profile of strategies yielding a payoff vectorwith the property that for each coalition of players their aggregate payoffs in this vector is at least as high as the aggregatepayoff they can grantee themselves in the game by using a correlated strategy. For example, the Prisoner’s Dilemma gamediscussed above is a balanced game. The profile of strategies (c, c) yields the payoff vector (4, 4); No player can guaranteesherself more than 4, and the coalition of the two players cannot guarantee itself more than 8.In between equilibrium and strong equilibrium one can naturally define k-strong equilibrium as an outcome, which isimmune to deviations of coalitions of size at most k. Indeed, if one considers the distributed computing and cryptographyliterature, it typically requires stability against deviations by up to k (typically faulty or malicious) agents, which can beviewed as a particular form of game-theoretic",
            {
                "entities": [
                    [
                        136,
                        163,
                        "TITLE"
                    ],
                    [
                        6744,
                        6771,
                        "TITLE"
                    ],
                    [
                        8368,
                        8395,
                        "TITLE"
                    ],
                    [
                        8887,
                        8914,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1540–1578Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPouring liquids: A study in commonsense physical reasoningErnest Davis 1Department of Computer Science, New York University, USAa r t i c l ei n f oa b s t r a c tThis paper presents a theory that supports commonsense, qualitative reasoning about theflow of liquid around slowly moving solid objects; specifically, inferring that liquid can bepoured from one container to another, given only qualitative information about the shapesand motions of the containers. It shows how the theory and the problem specificationcan be expressed in a first-order language; and demonstrates that this inference andother similar inferences can be justified as deductive conclusions from the theory and theproblem specification.© 2008 Elsevier B.V. All rights reserved.Article history:Received 7 August 2007Received in revised form 20 April 2008Accepted 22 April 2008Available online 30 April 2008Keywords:LiquidsQualitative physical reasoningNaive physicsQualitative spatial reasoning1. IntroductionCarrying liquids in containers and pouring or ladling liquids from one container to another are among the most commonways in which people interact with liquids in daily life. People are very familiar with these phenomena and can reasonabout them easily. In particular, people understand how the physical behavior of the liquids is largely determined by thegeometrical characteristics of the liquid, the containers, and the motions involved; they can reason about physical behaviorusing only partial knowledge of the geometry, without full geometric specifications; and they can use the same knowledgein multiple inferential directions.For instance, people know that, if a cup has a small hole through the bottom, then liquid in the cup will leak outthrough the hole, but that a dent in the bottom will not cause the liquid to leak. They can use this knowledge in manyways: prediction—given that there is a hole, predict that the liquid will leak; explanation—given that the liquid is leakingfrom the bottom, deduce that there is a hole; design—if you want the liquid to drain (e.g. you are designing a colander), puta hole in the bottom; and so on. These various forms of reasoning can be carried out without knowing or positing a preciseshape description for the cup or the hole.It is very desirable that an automated reasoner likewise be able to deal with partial geometric information. Precisegeometric information may be unavailable for a number of different reasons. It may not be possible for the agent to perceiveor measure the features accurately. The features may be inferred rather than perceived. The object may be in a preliminarystate of design, and the precise geometry may not yet have been specified. The features may be a result of a future eventwhich is not yet fully known; for instance, a reasoner may be concerned that an object may spring a leak and worry aboutthe effect on the liquid inside, without knowing where exactly the leak will be or what its shape will be. A reasoner mayneed to reason generically about classes of similar objects and similar actions rather than about a single manipulation of asingle object.The theory of fluid dynamics, of course, contains a very large body of mathematics, mathematical physics, and scientificsoftware devoted to the question of predicting the flow of fluids; and these computations can now be done with very greatE-mail address: davise@cs.nyu.edu.1 I am grateful to the reviewers for many helpful suggestions. This research was supported in part by NSF grant IIS-0534809.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.04.003\fE. Davis / Artificial Intelligence 172 (2008) 1540–15781541Fig. 1. Pouring from pitcher to pail.accuracy and speed. However, these techniques all work, either by using a fine-grained division of space and time, and bycalculating the force and flow of each small piece of liquid at small step of time; or, if the PDE’s are solved or analyzedexactly, by calculating the force and flow at literally every point and instant. The techniques deliver extremely precisepredictions of fluid flow, but they require correspondingly precise specification of the boundary conditions (the shapes ofthe solid objects in contact the liquid).As the evolution of forces and flows may be extremely variable over a range of circumstances where the overall qual-itative behavior is quite stable, there is an inherent mismatch between these techniques and the objectives of qualitativereasoning. In AI applications, precise boundary conditions are generally not known and detailed predictions are not neces-sary. Different ways of pouring from a pitcher to a pail, or different shapes of the pitcher and the pail, may give rise to flowand force patterns that are completely different; but the commonsensically important inference, that the liquid pours fromthe pitcher to the pail, remains stable.For this reason, we are looking for a characterization of the behavior of liquids that does not require calculating ofvelocity, acceleration, momentum and forces. Not that these concepts lie outside a commonsense understanding of physics—on the contrary these, or something similar, are part of a commonsense understanding—but it must often be possible for aqualitative reasoner to reason about the large scale behavior of liquids without invoking these concepts.The objective of this paper is to characterize some cases of commonsense reasoning about liquids at the knowledgelevel [28]; that is, to demonstrate that, for some types of simple qualitative reasoning about liquids, one can develop arepresentation language and a theory such that the knowledge used in the reasoning and the specifications of particularproblems can be (approximately) expressed in the language and the reasoning itself can be carried out as inference from thegeneral theory and specifications. This paper is thus part of the general programme proposed by Hayes and by McCarthy [18,24,25] of developing automated commonsense reasoners by representing commonsense knowledge in logic-based languages.(We will discuss the goals of the representation in more detail in Section 1.1.)In this paper we develop a large part, though not all, of a commonsense theory of liquid flowing around slowly movingsolid objects. We illustrate the adequacy of the theory by showing that it suffices for correct prediction in a number ofscenarios, including carrying a liquid in a closed container or in an open container, pouring a liquid from one container toanother, or ladling liquid out of a container using a spoon.The primary example we will use here is pouring from one container to another. Specifically, we consider the followingscenario (Fig. 1): There is a pitcher, partly full of liquid, and an empty pail. Both of these “hold water”. The pail remainsin a fixed position throughout the scenario. The pitcher is lifted, keeping it sufficiently upright that the liquid inside doesnot reach its spout. Once it is in position, with the spout (though not necessarily all of the pitcher) centered over the pail,the pitcher is tilted until the capacity of the part of the inside of the pitcher lower than the spout is less than the volumeof the liquid. At this point, the liquid pours out of the pitcher, and falls downward into the pail, where it remains. At theend of the scenario, the liquid is divided into a section that remains in the pitcher and a section that is in the pail. Wedemonstrate that, given qualitative characterizations of the shapes of the pitcher and the pail and of the motion of thepitcher, our theory allows us to infer the behavior of the liquid.(Note: all of the figures in this paper are cross-sections in the x–z plane. Throughout this paper, solid objects are indi-cated with diagonal lines, and liquid is indicated in grey. The fact that the pictures show liquid flowing in polygonal patternsreflects my personal limitations in using the drawing software; it is not at all a requirement of the theory.)Many aspects of the commonsense understanding of liquids are omitted from our analysis here. Some of the mostimportant of these are:• Liquids in modes that are not “bulk”, in Hayes’ [19] terminology, such as mists, wettings of surfaces, liquids absorbed insponges, and so on.• Liquids in energetic modes, again in Hayes’ terminology, such as fountains or even splashes.• Mixtures or solutions of any kind.• Interactions of liquids with the atmosphere or other gasses.\f1542E. Davis / Artificial Intelligence 172 (2008) 1540–1578• The effect of liquids on the solids with which they are in contact. We assume that the motion of the solids is given byexternal constraints. Thus, our theory does not include waterwheels or other mechanisms controlled by hydraulics, solidobjects floating on liquids, swimming, and so on. (The theory may be capable in such cases of predicting the liquid flowgiven the motion of the solid objects, but it certainly cannot predict the motion of the solid objects.)• Pressure and any consequences of pressure differences. In particular, we assume that all parts of the top surface of aliquid meet the open atmosphere and are therefore at equal height.• Viscosity, surface tension, cohesion, adhesion, absorption, and so on. We deal only with “dry water”, in von Neumann’ssardonic phrase.• Any consideration of heat, temperature, and phase transitions, such as evaporation and freezing.• The feasibility of actions by an agent. The theory developed for physical feasibility of actions on solid objects in [11]can be extended to this domain, but we will not discuss this in this paper.• The theory yields incorrect predictions for liquids flowing down a channel (Section 6). This is probably the most impor-tant gap in the theory.The paper is organized as follows. Section 1.1 discusses the various goals of this representational work i",
            {
                "entities": [
                    [
                        138,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 440–447www.elsevier.com/locate/artintA hierarchy of prescriptive goals for multiagent learningMartin Zinkevich a,∗, Amy Greenwald b, Michael L. Littman ca University of Alberta, Edmonton, AB, Canadab Brown University, Providence, RI, USAc Rutgers University, New Brunswick, NJ, USAReceived 13 May 2006; received in revised form 15 February 2007; accepted 15 February 2007Available online 30 March 2007AbstractA great deal of theoretical effort in multiagent learning involves either embracing or avoiding the inherent symmetry between theproblem and the solution. Regret minimization is an approach to the prescriptive, non-cooperative goal that explicitly breaks thissymmetry, but, since it makes no assumptions about the adversary, it achieves only limited guarantees. In this paper, we consider ahierarchy of goals that begins with the basics of regret minimization and moves towards the utility guarantees achievable by agentsthat could also guarantee converging to a game-theoretic equilibrium.© 2007 Published by Elsevier B.V.1. IntroductionThe prescriptive, non-cooperative goal set forth in Shoham et al. is to design intelligent agents that perform wellin the presence of other intelligent agents. Much of the research and analysis in this domain involves either bypassingthe circularity of this objective (as in regret minimization) or embracing it (as in equilibrium or self-play analyses).In this paper, we will try to unravel this objective by consciously breaking the symmetry between the agent, whosebehavior we can prescribe, and the environment (other players1) over which we have no control. Much of the regretminimization literature also speaks from this perspective: in fact, concepts like calibration have origins in predictingthe weather, hardly a multiagent problem!Nonetheless, without making some assumptions about an agent’s environment, there are some guarantees thatsimply cannot be achieved, such as convergence to the set of Nash or correlated equilibria. This observation hasprompted others in the past to study self-play, where the environment is assumed to exhibit the same behavior as theagent. We believe that self-play is an example of a restriction upon the environment that limits the applicability ofmany results. The fact that an agent performs well in self-play says nothing about how that agent might interact withhumans or agents designed by others.Instead, we believe a more useful focus is on characterizations of environments that can be made in an agent-independent way, as described below.* Corresponding author.E-mail addresses: maz@cs.ualberta.ca (M. Zinkevich), amy@cs.brown.edu (A. Greenwald), mlittman@cs.rutgers.edu (M.L. Littman).1 We will use player to refer to the agent or the environment.0004-3702/$ – see front matter © 2007 Published by Elsevier B.V.doi:10.1016/j.artint.2007.02.005\fM. Zinkevich et al. / Artificial Intelligence 171 (2007) 440–447441Different learning agents can be considered to be trading off between the breadth of the set of environments theywork on and how well they work on that set. Or, to focus on the set of environments apart from an agent, three relevantattributes of an environment class come to mind:• Workability: What type of guarantees can be achieved against the class? By definition, agents care about utility(although how they should go about earning utility is a matter of some debate). In this paper, for concreteness, wefocus on a particular form of utility guarantees, and then discuss the environment sets in which it is possible toachieve those guarantees.• Breadth: How broad is the class? As MAL researchers, we wish to develop agents that can achieve guarantees foras broad an environment class as possible.Consider the result that no-internal regret2 agents [2,3] (we call this set ANIR) converge (in the empirical frequencyof joint actions) to the set of correlated equilibria when playing against any environment that is no-internal regret(we call this set ENIR). An interesting question arises: what if the environment is not no-internal regret? Moreover,what if we only cared about getting the utility of a stationary correlated equilibrium instead of converging to theequilibrium itself?For instance, we could add to ENIR (although not to ANIR) those environments that play stationary Nash equilibria,and the NIR agents would still get a high utility.3 Oddly, we could not add altruistic environments that play asif their opponent’s utilities were their own and have no-internal regret: for instance, if the environment has adominant strategy, it might lead to easy cooperation, whereas both players even with identical utilities might havea difficult time making a common choice. Thus, as we expand this environment set, not only do we get a strongerguarantee, but we also learn more about what makes the original result work in the first place.• Saliency: Are there agents in the class that perform well on the class? Are there agents that could be considered in-telligent? Throughout our description of environment sets, we avoid circularity by not addressing saliency directly.However, we hope to find the environments that are ultimately derived (using the principles of workability andbreadth) to be a superset of the environments we consider intelligent, or at least to overlap significantly. Whetherthis outcome prevails or not will be the primary measure of the success of our proposed agent/environment split.Normally, when researchers formulate an environment class, they either consider the set of all environments orthey begin with some concept of saliency (such as self-play).4 Between these two extremes in multiagent learning—guarantees that can be achieved in every environment and guarantees that can be achieved in self-play—there lies ahierarchy:Definition 1. A hierarchy of prescriptive goals is:(1) A hierarchy of environment sets {S1, . . . , Sk}, each one contained in its predecessor.(2) A hierarchy of guarantees {G1, . . . , Gk},such that there exists a single agent that, for every i, satisfies Gi with every environment in Si .In the large margin structural risk-minimization literature, there is a hierarchy of hypothesis spaces, with largemargin hypotheses nearer to the top of the hierarchy and smaller margin hypotheses nearer to the bottom. Assumethat the data agrees with some hypothesis, given a supervised-learning problem. If it agrees only with a small marginhypothesis, then a large amount of training data is required for good generalization performance. This guarantee2 They are referred to as no-regret agents by Foster and Vohra [2]. We use the terminology of Greenwald and Jafari [4] to distinguish no-internaland no-external regret.3 In particular, the agents in ANIR would still CEV work with the environments that play stationary Nash equilibria (see Section 3). However,the empirical joint action frequency might no longer converge to the set of correlated equilibria. Moreover, the agents that play stationary Nashequilibria do not work with ENIR, because that the ENIR algorithms will converge to a best response to a Nash equilibrium, not a Nash equilibriumitself.4 Another popular choice is the set of stationary environments. The advantage of this set is that the stationarity assumption is made in classificationtasks, and therefore supervised-learning techniques can carry over. However, there is no reason to believe that intelligent agents should exhibitstationary behavior. They, too, should learn.\f442M. Zinkevich et al. / Artificial Intelligence 171 (2007) 440–447near the bottom of the hierarchy is weak. On the other hand, if a large margin hypothesis agrees with the data, thenthe generalization performance is excellent with only a few training examples. A single algorithm—a support-vectormachine—can achieve all of these guarantees. If one such algorithm did not exist, then this hierarchy of generalizationguarantees and hypotheses spaces could only be viewed as a collection of goals, and could not be interpreted as asingle, overarching goal. Similarly, we view our proposed hierarchy of prescriptive goals as a single, overarching goalfor multiagent learning.Our perspective is similar to the objectives specified by Bowling [1], who suggests that agents should be designedto achieve two different guarantees (convergence to Nash equilibrium and best response) against two different classesof environments (self-play and stationary). Even more closely related to what we are proposing here are two resultsabout no-internal regret agents: namely, that they minimize internal regret in an arbitrary environment and that theirempirical joint action frequency converges to the set of correlated equilibria. In this work, we will focus on theimplications upon utility of these two guarantees, and we will analyze whether a broader class of environments canbe handled at each level.It is not only the theoretical elegance of structural risk minimization that has excited machine-learning researchers;what is most impressive is its practical implications. The advantage to an empiricist of using such a technique isthat it allows her to give a soft boundary on what she expects to happen. Thus, an algorithm can use the data todecide exactly how accurate the empiricist’s assumptions are and to relax them as necessary to deal with real-worldoccurrences. Whether through regret methods or the hierarchies described here, soft assumptions which, if true, resultin a performance guarantee, but, if false, do not preclude the algorithm from performing reasonably well,5 are usefulfor developing agents that perform well in practice.2. A model of interaction: Repeated bimatrix gamesIn this paper, we restrict our attention to repeated bimatrix games, as they are sufficient to model many of thefundamental issues in multiagent learning.6 Moreover, we assume that the game, including its utility functions, isknown to both players. Although this assumption will bias our discussion, we believe",
            {
                "entities": [
                    [
                        72,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 581–606www.elsevier.com/locate/artintLinguistic quantifiers modeled by Sugeno integralsMingsheng Ying 1State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology,Tsinghua University, Beijing 100084, ChinaReceived 1 December 2004; received in revised form 3 February 2006; accepted 15 February 2006Available online 20 March 2006AbstractSince quantifiers have the ability of summarizing the properties of a class of objects without enumerating them, linguisticquantification is a very important topic in the field of high level knowledge representation and reasoning. This paper introducesa new framework for modeling quantifiers in natural languages in which each linguistic quantifier is represented by a family offuzzy measures, and the truth value of a quantified proposition is evaluated by using Sugeno’s integral. This framework allowsus to have some elegant logical properties of linguistic quantifiers. We compare carefully our new model of quantification andother approaches to linguistic quantifiers. A set of criteria for linguistic quantification was proposed in the previous literature.The relationship between these criteria and the results obtained in the present paper is clarified. Some simple applications of theSugeno’s integral semantics of quantifiers are presented. 2006 Elsevier B.V. All rights reserved.Keywords: High level knowledge representation and reasoning; Natural language understanding; Computing with words; Fuzzy logic; Quantifier;Fuzzy measure; Sugeno’s integral1. IntroductionFirst order logic increases the expressive power of propositional logic a lot through adding quantifiers. Classicalfirst order logic only possesses two quantifiers, the universal quantifier (∀) and the existential quantifier (∃). However,these quantifiers are often too limited to express some properties of certain mathematical structures and to modelcertain knowledge stated in natural languages. This leads logicians and linguists to introduce the notion of generalizedquantifiers.As early as in 1957, Mostowski [29] proposed a general notion of generalized quantifier and showed that first orderlogic with a class of generalized quantifiers are not axiomatizable. This work together with others initiated the subjectof model theoretic logics.Barwise and Cooper [2] started the studies of generalized quantifiers in natural languages. Since then, a rich varietyof generalized quantifiers in natural languages have been found, and their expressive power and logical propertieshave been thoroughly investigated from both semantic and syntactic aspects. In particular, van Benthem [36] viewedE-mail address: yingmsh@tsinghua.edu.cn (M. Ying).1 This work was partly supported by the National Foundation of Natural Sciences of China (Grant No: 60321002, 60496321) and the Key GrantProject of Chinese Ministry of Education (Grant No: 10403).0004-3702/$ – see front matter  2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.02.001\f582M. Ying / Artificial Intelligence 170 (2006) 581–606a generalized quantifier as a relation on the subsets of a universe of discourse, and systematically examined variousrelational behaviors of generalized quantifiers such as reflexivity, symmetry, transitivity, linearity and monotonicityand their roles in realizing certain inference patterns. For a recent review on the theory of generalized quantifiers innatural languages, we refer to [24].It has been clearly realized in the artificial intelligence community that natural languages are suited to high levelknowledge representation [26,33]. This is indeed one of the main motivations of computing with words [25,50,57].However, classical logic is not adequate to face the essential uncertainty, vagueness and ambiguity of human reasoningexpressed in natural languages. Consequently, the logical treatments and mathematical models of the concepts ofuncertainty, vagueness and ambiguity is of increasing importance in artificial intelligence and related researches, andmany logicians have proposed different logic systems as a formalization of reasoning under uncertainty, vaguenessand ambiguity (see, for example, [3,44–47,49], [11, Chapter III.1], or [19, Chapter 7]).Since quantifiers have the ability of summarizing the properties of a class of objects without enumerating them,linguistic quantification is a very important topic in the field of knowledge representation and reasoning. Quantifiersin natural languages are usually vague in some sense. Some representative examples of linguistic quantifiers withvagueness are [56]: several, most, much, not many, very many, not very many, few, quite a few, large number, smallnumber, close to five, approximately ten, frequently. It is clear that two-valued logic is not suited to cope with vaguequantifiers. There has been, therefore, increasing interest about logical treatment of quantifiers in human languages infuzzy logic community. Indeed, sometimes fuzzy logic permits a more precise representation of the kind of quantifiersin various natural languages.The first fuzzy set theoretic approach to linguistic quantifiers was described by Zadeh [55,56]. In his approach,linguistic quantifiers are treated as fuzzy numbers and they may be manipulated through the use of arithmetic forfuzzy numbers. The truth evaluation of a linguistically quantified statement is performed by computing the cardinalityof the fuzzy set defined by the linguistic predicate in such a statement and then by finding the degree to which thiscardinality is compatible with the involved quantifier. Since then, a considerable amount of literature [1,4–7,9,10,12,15–18,30–32,42,43,51,52] has been devoted to the studies of linguistic quantifiers in the framework of fuzzy settheory. For example, in a series of papers [39–41], Yager proposed the substitution method for evaluating quantifiedpropositions and the method based on OWA operators. For a survey, see [27,28].On the other hand, fuzzy quantification models are employed in solving a great variety of problems from manydifferent fields such as database querying [7,23], data mining and knowledge discovering [7,25], information fusion[21,25], group decision making and multiple-objective decision making [20,40], inductive learning [21], and opti-mization and control [22].This paper introduces a new framework for modeling quantifiers in natural languages. In this framework, linguisticquantifiers are represented by Sugeno’s fuzzy measures [35]. More precisely, a quantifier Q is seen as a family of fuzzymeasures indexed by nonempty sets. For each nonempty set X, the quantifier Q limited to the discourse universe Xis defined to be a fuzzy measure QX on X, and for any subset E of X, the quantity QX(E) expresses the truth valueof the quantified statement “Q Xs are As” when A is a crisp predicate and the set of elements in X satisfying A is E.As is well known, predicates in linguistically quantified statements are often vague too. In this general case, the truthvalue of a quantified proposition is then evaluated by using Sugeno’s integral [35].The advantage of this framework is that it allows us to have some elegant logical properties of linguistic quanti-fiers. For example, we are able to establish a prenex normal form theorem for linguistic quantifiers (see Corollary 34).It should be pointed out that this paper only deals with increasing quantifiers because fuzzy measures assumemonotonicity. Thus, quantifiers such as several, few, quite a few, small number, not many, not very many, close tofive, approximately ten cannot be modeled in our proposed setting.This paper is arranged as follows. For convenience of the reader, in Section 2 we review some notions and resultsfrom the theory of Sugeno’s fuzzy measures and integrals. In Section 3, (linguistic) quantifiers are formally definedin terms of fuzzy measure, and several operations of quantifiers are introduced. In Section 4, we construct a firstorder language with linguistic quantifiers and present semantics of such a logical language. In particular, the truthvaluation of quantified formulas is given by using Sugeno’s integrals. Section 5 is devoted to examine thoroughlylogical properties of linguistic quantifiers. In particular, we prove a prenex normal form theorem for logical formulaswith linguistic quantifiers. In Section 6, the notions of cardinal and numeric quantifiers are introduced so that we areable to establish a close link between the Sugeno integral semantics and the Zadeh’s cardinality-based semantics oflinguistic quantifiers. In Section 7, we present some simple applications to illustrate the utility of the results obtained\fM. Ying / Artificial Intelligence 170 (2006) 581–606583in the current paper. In Section 8, our Sugeno integral approach to evaluation of quantified statements is comparedwith others. A set of criteria for linguistic quantification was proposed in the previous literature. The relationshipbetween these criteria and the results obtained in the present paper is clarified. We draw conclusions and point outsome problems for further studies in Section 9.2. Fuzzy measures and Sugeno integralsThis is a preliminary section. In this section, we are going to review some notions and fundamental results neededin the sequel from the theory of fuzzy measures and Sugeno’s integrals. For details, we refer to [35] or [11, Chapter 5].The theory of fuzzy measures and integrals was originally proposed by Sugeno [35]. Fuzzy measure is a general-ization of the notion of measure in mathematical analysis, and it relaxes the condition of additivity for usual measureand only assume monotonicity. Thus, fuzzy measures are very general, and probability measures, Zadeh’s possibilitymeasures, Shafer’s belief functions among others [37] are shown to be special cases of fuzzy measures. Sugeno’sintegral is analogous to Lebesgue integral. The difference between them is that addition and multiplication in",
            {
                "entities": [
                    [
                        72,
                        122,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence. 98 (1998) 209-235 Artificial Intelligence Preferential reasoning in the perspective of Poole default logic Michael Freund ’ Dep,wtment of Mathematics, Universiiy of Orleans. 45067 Orleans-La Source Cedex, France Received November 1996; revised March 1997 Abstract The sceptical inference relation associated with a Poole system without constraints is known to have a simple semantic representation by means of a smooth order directly defined on the set of interpretations associated with the underlying language. Conversely, we prove in this paper that, on a finite propositional language, any preferential inference relation defined by such a model is induced by a Poole system without constraints. In the particular case of rational relations, the associated set of defaults may be chosen to be minimal; it then consists of a set of formulae, totally ordered through classical implication, with cardinality equal to the height of the given relation. This result can be applied to knowledge representation theory and corresponds, in revision theory, to Grove’s family of spheres. In the framework of conditional knowledge bases and default extensions, it implies that any rational inference relation may be considered as the rational closure of a minimal knowledge base. An immediate consequence of this is the possibility of replacing any conditional knowledge base by a minimal one that provides the same amount of information. @ 1998 Elsevier Science B.V. Keywords: Nonmonotonic reasoning; Preferential relations; Rationality; Poole systems; Default logic 1. Introduction In [ 121, a variation on Reiter’s default logic [ 141 was presented, leading to the following notion: a Poole system the set of “defaults” used the maximal to determine and the set of “constraints” of the system. Such a system may be as true subsets of A that are consistent with cy and K. As shown by Makinson of a premiss LY, assuming the nonmonotonic consequences is a pair (A, K) of sets of sentences, called respectively ’ Email: freund@labomath.univ-orleansfr. 0004-3702/!)8/$19.00 @ 1998 Elsevier Science B.V. All rights reserved. PI1 sooo4- 3702( 97) 00053-2 \f210 h4. Freund/Art@cial Intelligence 98 (1998) 209-235 inference family function” relation when the Poole system liberal conception of the “extension to a sceptical approach, providing is one “without constraints”, a i.e. is empty. Such a Poole system can be identified with a set [ 11, Section 3.31, Poole’s original associated with the pair (A, K) can be modified preferential when its set K of constraints in the sense of Reiter, and the associated preferential of prerequisite-free to the sceptical Reiter extension of A. It was noticed inference relation by Makinson relation associated with such a Poole system can be represented by a special kind of preferential model, where that the converse of the set of states is the set of all worlds. Makinson this property was not settled, and conjectured normal defaults then corresponds [ 131 that the preferential that it may hold. [ 111 and Poole [ 111 mentioned inference answer to this conjecture We shall give an affirmative that are logi- cally finite, and prove that any consistency-preserving preferential relation dejked by an injective model is the inference relation associated with a Poole system without con- injective model, straints. Thus, preferential is (at least the logic of reasoning: any agent using is fully determined by an implicit set of basic defaults. in the finite case) essentially injective preferential reasoning, when determined by a preferential the same as default for languages reasoning rational language in particular the different result holds it is minimal, sets of defaults as it is known for rational reasoning, that any consistency-preserving that rational [2]. It and two sets of defaults D and D’ may induce relations may always be defined by means of ranked injective models relation defined on a logically inference is induced by a Poole system without constraints. This Poole system the same relation, but among that induce a given rational relation, one of them, called the characteristic set of the relation, satisfies some to describe, and its elements are linearly or- relation This inference follows finite is not uniquely determined, inference inference interesting properties: dered through classical therefore appears tool for the study of this relation: we denote by Si, . . . ,a,, the elements of this set, with Si+i (classically) for i < n, the given relation Si is consistent with cx but inconsistent with CY A +“. This observation perspective Grove applications in the field of conditional we prove that any consistency-preserving as the rational closure of a minimal determine if implied by Si reads “a b p iff there exists an index i such that in the theory by thus relation may be considered inference base, and we show how to explicitly knowledge bases and default extensions: implication. The characteristic it leads to some interesting to be a most useful of Poole systems, results established [ 71 and Linstrom [ lo]. Moreover, and Rabinowicz set of a rational some classical in particular, in revision conditional this base. inference explains, rational simply simple and is organized as follows: inference in Section 2, we recall is self-contained This paper relations. Poole systems and main properties of preferential the definitions and show that, in Section 3. There, we examine Makinson’s are introduced languages. The while not true this conjecture in general, section concludes with some considerations the set of defaults of a Poole system, analyzed as a belief base, may be revised or updated, and relation. Section 4 is the central this affects part of this paper, and is devoted and their sets. Section 5 is an application of the results of Section 4 to some aspects characteristic holds on the dynamics of Poole systems: conjecture in the case of finite the behaviour of the associated to the case of rational inference inference relations \fM. Freund/Art@ial Intelligence 98 (1998) 209-235 211 of knowledge in Section 6. representation theory concerning conditional bases extension. We conclude 2. Background We denote by L: a set of well-formed connectives the classical propositional under finitely many atomic propositions, is provided by the set W of all assignments Elements of W will be referred m and a formula or m k /3, and m /= TX iff it is not the case that m j= a. the language to as worlds and the satisfaction formulae over a set of atomic propositions, 7, A, V, -+ and c--f. When is said to be logically of truth values to the propositional closed there are only finite. Semantics variables. relation between a world (Y is defined as usual and written m k a. Thus m k (Y V /? iff m + LY For every subset A of L, we write m /= A iff m satisfies all the elements of A. The set of formulae of L satisfied by a world m will be denoted by 11121. attached operation The cla.ssical consequence for any subset A of C, Cn(A) all worlds m that satisfy A. Given a subset A of C, we say that A is consisfent Cn(A) A is said to be consistent with the set B iff AU B is a consistent for Cn(A to C and W will be denoted by Cn: is the set of all formulae LY of L such that m k LY for iff iff there exists a world m such that m satisfies A. The set set. We write Cn( A, B) and (Y k /3 for p E Cn(cu). IJ B), Cn(Lu) for Cn({n}) # C or, equivalently, 2.1. Prefeirential inference relations Following Kraus, Lehmann and Magidor [ 81, we call preferential inference relation on L: a relation b that satisfies the following rules: Reflexivity. (Y k cr. Left Logical Equivalence. If Cn( a) = Cn( /3) and a k y, then /3 k y. Right Weakening. If p E Cn(cr) and y b CY, then y b p. Cut. If a A p k y and a t_ p, then LY b y. Or. If a bd y and p k y, then (Y V /I k y. Cautious Monotonicity. If LY b /3 and a k y, then a A p k y. Given set of all k-consequences that I2 k p. We will indifferently such a relation, we shall denote by Cl_ (a)-or ambiguity--the such “inference C, the sets C (cu) are closed with respect formulae cr. An inference C(a) when is no that is the set of all p’s relation k” or to the relation to Cn, that is Cn[ C( cu) ] = C (cu) for all relation C is said to be consistency-preserving iff C (cu) is a relation C”. The above rules imply that for any preferential of a formula a, to “the inference inference there refer \f212 hf. Freund/Artificial Intelligence 98 (1998) 209-235 consistent consistency-preserving set for any consistent iff C(a) formula LY. Thus a preferential # C whenever Cn(cu) # C. inference relation C is 2.2. Preferential models A preferential structure is a triple M = (S, <, I) where < relation defined on a set S (the set of “states”), is an irreflexive and and I (the “label function”) from S into the set of worlds W. For any state s, we say that s satisfies iff I(s) does, and we denote by cr* the set of all states s s k a) transitive is a mapping a formula a (written satisfying the formula LY. A preferential model, as defined in [ 81, is a preferential the following condition of smoothness: given any formula satisfies s of LY* that is not minimal This condition set of states is finite), and in particular when the underlying logically in LY*, there exists a state t minimal structure is always satisfied when the preferential finite. language A preferential model determines a preferential relation b,,, by: ( def) it FM /? iff all minimal elements of CY* satisfy p. structure (S, <, I) that (Y of C and any state in a* such that t < s. is finite (i.e. when its to be is supposed Conversely, it was shown language L (respectively (respectively in a logically [ 81 that, for any preferential relation k defined on a finite language L) , there exists a preferential model a finite preferential model) M that represents i_, i.e. is such that k=kM. The following simple result will be used in the next sections: Lemma 1. Let t- be a preferential inference re",
            {
                "entities": [
                    [
                        67,
                        131,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 143–165Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantic-based regularization for learning and inferenceMichelangelo Diligenti∗, Marco Gori, Claudio SaccàDepartment of Information Engineering and Mathematics, University of Siena, Via Roma 56, Siena, Italya r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 13 August 2015Accepted 26 August 2015Available online 1 September 2015Keywords:Learning with constraintsKernel machinesFOLThis paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThis paper presents Semantic Based Regularization (SBR), a unified framework for inference and learning that is centered around the notion of a constraint and of the parsimony principle. Semantic Based Regularization bridges the ability of machine learning techniques to learn from continuous feature-based representations with the ability of modeling arbitrary pattern relationships, typically used in Statistical Relational Learning (SRL) to model and learn from high-level semantic knowledge. In order to provide a unified context for manipulating perceptual data and prior knowledge, we propose to use the unifying concept of a constraint, which is sufficiently general to represent different kinds of sensorial data along with their relations, as well as to express abstract knowledge on the tasks. We unify continuous and discrete computational mechanisms, so as to accommodate in the same framework very different stimuli. In this paper, we focus on the kernel machine mathematical and algorithmic apparatus to learn from feature-based pattern representations and on constraints resulting from a fuzzy translation of First Order Logic (FOL) formulas, expressing the prior knowledge about the learning task at hand.More specifically, SBR builds a multi-layer architecture having kernel machines at the input layer. The output of the kernel machines is fed to the higher layers implementing a fuzzy generalization of the FOL knowledge. Thanks to the * Corresponding author.E-mail addresses: diligmic@diism.unisi.it (M. Diligenti), marco@diism.unisi.it (M. Gori), sacc@unisi.it (C. Saccà).http://dx.doi.org/10.1016/j.artint.2015.08.0110004-3702/© 2015 Elsevier B.V. All rights reserved.\f144M. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165basic properties of fuzzy FOL and kernel machines, the resulting model is continuous with respect to the feature values. Therefore, the high-level semantic inference provided by the logic can be back-propagated down to the kernel machines using any gradient-based schema. This process can be iterated during training until convergence. This is an extremely powerful technique to get advantage of the available unsupervised data, as the inference process performed on this data via the logic knowledge can be used to correct the output of the kernel machines.We substantially extend earlier studies in Diligenti et al. [10] by showing that SBR enables new fundamental tasks of learning and inference that rely on the joint informative evidence coming from real-valued features and simple pattern identifiers, along with the corresponding relations. In particular, the paper gives the following new main results, which are of fundamental importance to gain an overall view of theory and, especially, to enable a large set of applications in statistical relational learning domains:variable dimension domains and null inputs We extend the SBR framework [10] to truly hybrid domains, where real-valued feature pattern representations are integrated with pure symbolic entities (e.g. pattern identifiers). Indeed, in complex relational classification tasks, it is often the case that the entities are naturally representable by pat-tern spaces of different dimensions, including the remarkable case of “void patterns” in which only relational information is available.collective classification In this paper we propose a novel collective classification method to enforce the constraints on the test set, thus exploiting the full expressiveness of FOL, like in other statistical relational learning (SRL) ap-proaches. Once again, the distinctive feature of the solution proposed in this paper arises when considering that the collective computational scheme also naturally exploits real-valued feature pattern representations.probabilistic links We extend studies on the probabilistic interpretation of regularization networks [38] to our case of learning from constraints. From one side, this highlights connections with Markov Logic Networks (MLNs) [40], while from the other side, this interpretation clearly shows the natural integration of real-valued features and object identifiers in SBR.Furthermore, the paper presents how plain SVM, Transductive, and Laplacian SVMs can be derived as special cases of the proposed SBR framework. The paper also introduces new heuristics, connected to the ones employed in constraint satisfaction programming, to improve the quality of the found solutions. Finally, we present experimental results to show the effectiveness and generality of the approach.The paper is organized as follows: in the next section previous work in the field is reviewed. Section 3 introduces First Order Logic and its fuzzy extensions, while Section 4 discusses learning from constraints with kernel machines. Section 5presents how SBR generalizes several models commonly used in relational and transductive learning. Details on how training is performed in the SBR framework is presented in Section 6. In Section 7 a collective classification approach for SBR is presented and Section 8 presents connections between SBR and probabilistic models like Markov Logic Networks. The experimental evaluation of SBR is presented in Section 9 and, finally, Section 10 draws some conclusions.2. Previous workStatistical Relational Learning (SRL) combines robust parameter estimation in the presence of noise with learning complex relational structures. Probabilistic Relational Models (PRMs) [13] are an early SRL approach that learns a statistical model from a relational database. PRMs build a probability distribution over the attributes of the objects as an instance of a schema. A Bayesian network with one node for each attribute is built and parameters are estimated from the data. Relational Dependency Networks [34] learn a (local) conditional probability distribution for each node given its Markov blanket by using a conditional learner (like logistic regression or decision trees).Markov Logic Networks (MLNs) [40] have received a lot of attention in the SRL community and have been extensively applied in many fields like bioinformatics [28] and computer vision [46]. Markov Logic Networks generalize and combine first-order logic and probabilistic graphical models. Thanks to their flexibility, MLNs have been used to tackle all the SRL main tasks: collective classification, link prediction, link-based clustering, social network modeling, and object identification. Many papers have also studied how to learn the structure of Markov Logic Networks from data without requiring an expert to express the structure in terms of prior knowledge [23,22]. Hybrid Markov Logic Networks (HMLNs) [49] extend MLNs to deal with continuous variables.Probabilistic Soft Logic (PSL) [5] is another SRL approach, which relaxes MLNs to continuous fuzzy values in the [0, 1]interval and restricts the considered FOL formulas to the ones with conjunctive body and a single literal head. PSL weight training can be solved via a convex optimization problem, but it can face only a small subset of the tasks that are potentially solved by a MLN.One disadvantage of both MLNs and PSL in real-world applications is how they deal with entities that are associated to complex feature-based representations. Let’s take as an example the common scenario of a multi-class classification task where the patterns are represented by large vectors of numeric features. In order to perform learning and inference in this domain using classical SRL techniques, different approaches are possible:\fM. Diligenti et al. / Artificial Intelligence 244 (2017) 143–165145• the value of a feature can be correlated with one output class using one specific rule. For example, let x be a generic pattern in the domain and f be a binary feature, it is possible to express the rule HasTrueValue( f , x) ∧ BelongsTo(x, c)for each category c. The training process will estimate a weight modeling the strength of this correlation. MLNs can capture a logistic regression model using thi",
            {
                "entities": [
                    [
                        136,
                        192,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 78 ( 1995) 327-354 Artificial Intelligence Localization and homing using combinations of model views Ronen Basri av*,l, Ehud Rivlin b*2,3 a Department of Applied Mathematics, The Weizmann Institute of Science, Rehovot 76100, Israel ’ Computer Science Department, Technion, Haifa 32CO0, Israel Received August 1993; revised November 1994 Abstract identifying Navigation and honing involves recognizing the environment), positioning the current position within the the environment, (the act environment, and reaching particular positions. We present a method for localization (the act of computing the exact coordinates of a of recognizing robot in the environment), (the act of returning to a previously visited position) from visual input. The method is based on representing the scene as a set of 2D views and predicting the appearances of novel views by linear combinations of the model views. The method accurately approximates the appearance of scenes under weak-perspective projection. Analysis of this projection as well as experimental results demonstrate that in many cases this approximation is sufficient to accurately describe the scene. When weak-perspective approximation is invalid, either a larger number of models can be acquired or an iterative solution to account for the perspective distortions can be employed. The method has several advantages over other approaches. It uses relatively rich representations; the representations are 2D rather than 3D; and localization can be done from only a single 2D view without calibration. The same principal method is applied for both the localization and positioning problems, and a simple “qualitative” algorithm for homing is derived from this method. * Corresponding author. E-mail: ronen@wisdom.weizmann.ac.il. ’ This report describes research done in part at the Massachusetts Institute of Technology within the Artificial Intelligence Laboratory and the McDonnell-Pew Center for Cognitive Neuroscience. Support for the laboratory’s artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research Contract NOOO14-91-J-4038. ’ E-mail: ehudr@cs.technion.ac.iI. 3 This repolt describes research done in part at the University of Maryland within the Computer Vision Laboratory in the Center for Automation Research. The second author was suppolted in part by the Defense Advanced Research Projects Agency (ARPA Order No. 8459) and the U.S. Army Engineer Topographic Laboratories under Contract DACA76-92-C-0009. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00021-6 \f328 R. Basri, E. Rivlin /Art&k! fntelligence 78 (1995) 327-354 1. Introduction Basic tasks in autonomous robot navigation are localization, positioning, is the act of recognizing the environment, that is, assigning and homing. consistent locations, to different Localization labels the robot the sense that position place-specific previously visited position. coordinate in the environment. and positioning Positioning is the act of computing is a task complementary the coordinates of to localization, in in a is often specified to a room 911”). Homing is the task of returning (e.g., “1.5 meters northwest of table r’) system (“in A method for localization, positioning, and homing in visually-guided navigation is presented. The method, based on [ 201, represents systems images. Localization is achieved by comparing of model views. The position of the robot is computed by analyzing the linear combination solution to the homing problem using the same scheme the observed is presented. that aligns the model scenes by sets of their 2D image to linear combinations the coefficients of to the image. Also, a simple, qualitative Visually-guided navigation systems can be classified according utilized. We distinguish between that represent images of the scene a representation These invariant from representations and 3D models. Systems generate large range of transformations. projecting measurements observed straightforward way. images and comparing the image data onto a lower dimensional from the data. Localization the obtained two types of representations, to the type of scene signatures the scene using a set of signatures usually that is invariant over a relatively often are obtained by a set of from the in a subspace or by computing signatures signatures with the stored signatures is achieved by generating representations Sarachik and McDermott erates signatures Braunegg map obtained by projecting signatures [ 61 use blurred from averaged orientations [ 171 computes and stores the dimensions of the navigated offices. Engelson [ 141 gen- regions of the image. [4] recovers a depth map of the scene from which he generates an occupancy the 3D edges onto “the floor”. Hong et al. [9] generate images of the scene as signatures. Nelson of edges in different from panoramic views of the scene by projecting them onto a 1D circle. Other systems store complete 3D descriptions of the scene. To recognize that relates between the transformation [I] use a trinocular images. Ayache and Faugeras the systems must first recover incoming the 3D structure of the scene before [ 151 use a stereo system align and their positions image. Fennema images. Gray-scaled the location of these landmarks the stereo image with the model a set of landmarks the transformation the 3D models of the scene landmarks are generated are used to derive et al. [ 71) compare templates of selected to recover a depth map of the observed stereo system the scene the model and the to recover et al. to is first located by the system to the that relates to sequences of 2D from the model, and scene. In order the model is computed by means of correlation and tracking. it is compared with the model. Onoguchi The method presented rather than using explicit 3D descriptions of its 2D images. Predicting the model views. in this paper does not generate signatures of the scene. However, of the scene, the scene is represented by sets the appearances of novel views is obtained by combining Homing was recently addressed in several studies. Nelson [ 141 and Zipser [22] \fR. Basri, E. Rivlin/Artificial Intelligence 78 (1995) 327-354 329 proposed to handle this problem by generating signatures of the scene from single images and storing them along with vectors directing the robot toward the target location. At runtime whenever the robot encounters a signature similar to one or more of the stored signatures it follows the precomputed direction vectors associated with these signatures. Hong et al. [9] perform homing by comparing signatures obtained from a panoramic view of the scene with a similar signature obtained at the target location. The robot is then instructed to move so as to bring the observed signature and the target signature into alignment. The method for homing presented in this paper differs from previous algorithms by that it does not use signatures to represent the scene. Homing is achieved by moving the robot so as to align the observed images of the scene with an image taken from the target position. Like [ 91, our algorithm computes the direction of motion “on the fly”. The algorithm is qualitative in nature, and it is designed so as to gradually bring the current and the target images into alignment. The rest of the paper is organized as follows. The method for localization is presented in Section 2, where we propose a method that works accurately under weak-perspective approximation and an iterative scheme to account for perspective distortions. Positioning is addressed in Section 3, and the algorithm for homing is described in Section 4. Constraints imposed on the motion of the robot as a result of special properties of indoor environments can be used to reduce the complexity of the method presented here. This topic is covered on Section 5. Experimental results follow. 2. Localization The problem of localization is defined as follows: given P, a 2D image of a place, and M, a set of stored models, find a model M’ E M such that P matches M’. One problem a system for localization should address is the variability of images due to viewpoint changes. The inexactness of practical systems makes it difficult for a robot to return to a specified position on subsequent visits. The visual data available to the robot between visits varies in accordance with the viewing position of the robot. A localization system should be able to recognize scenes from different positions and orientations. Another problem is that of changes in the scene. At subsequent visits the same place may look different due to changes in the arrangement of the objects, the introduction of new objects, and the removal of others. In general, some objects tend to be more static than others. While chairs and books are often moved, tables, closets, and pictures tend to change their position less frequently, and walls are almost guaranteed to be static. Static cues naturally are more reliable than mobile ones. Confining the system to static cues, however, may in some cases result in failure to recognize the scene due to insufficient cues. The system should therefore attempt to rely on static cues, but should not ignore the dynamic cues. We are interested in a system that can recognize the environment from different viewing positions and that can update its representations dynamically to accommodate changes in the scene. A common approach to handling the problem of recognition from different viewpoints is by comparing the stored models to the observed environment \f330 R. Bnsri, E. Rivlin/ArfQScia/ Intelligence 78 (1995) 327-354 approach is recovered and compensated after the viewpoint is used in a number of studies of object recognition alignment system based on the “Linear Combinations” into two parts. In the first part (Section 2. I ) we describe under weak-perspective for handling to the",
            {
                "entities": [
                    [
                        67,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 203 (2013) 19–34Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComplexity issues related to propagation completenessMartin Babka, Tomáš Balyo, Ondˇrej ˇCepek, Štefan Gurský, Petr KuˇceraVáclav Vlˇcek∗,Department of Theoretical Computer Science and Mathematical Logic, Faculty of Mathematics and Physics, Charles University in Prague,Malostranské nám. 25, 118 00 Praha 1, Czech Republica r t i c l ei n f oa b s t r a c tArticle history:Received 10 July 2012Received in revised form 14 June 2013Accepted 30 July 2013Available online 7 August 2013Keywords:Boolean functionsSatisfiabilityKnowledge compilationEmpowering implicatesUnit propagationPropagation completenessKnowledge compilation is a process of adding more information to a knowledge base inorder to make it easier to deduce facts from the compiled base than from the original one.One type of knowledge compilation occurs when the knowledge in question is representedby a Boolean formula in conjunctive normal form (CNF). The goal of knowledge compilationin this case is to add clauses to the input CNF until a logically equivalent propagationcomplete CNF is obtained. A CNF is called propagation complete if after any partialsubstitution of truth values all logically entailed literals can be inferred from the resultingCNF formula by unit propagation. The key to this type of knowledge compilation is theability to generate so-called empowering clauses. A clause is empowering for a CNF if it isan implicate and for some partial substitution of truth values it enlarges the set of entailedliterals inferable by unit propagation.In this paper we study several complexity issues related to empowering implicates,propagation completeness, and its relation to resolution proofs. We show several results:(a) given a CNF and a clause it is co-NP complete to decide whether the clause is anempowering implicate of the CNF, (b) given a CNF it is NP-complete to decide whetherthere exists an empowering implicate for it and thus it is co-NP complete to decidewhether a CNF is propagation complete, and (c) there exist CNFs to which an exponentialnumber of clauses must be added to make them propagation complete.© 2013 Published by Elsevier B.V.1. IntroductionOne of the most studied problems in computer science, both theoretical and applied, is the satisfiability problem for CNFformulas (SAT). The difficulty of SAT depends on the class of CNF formulas to which the input formula belongs. There arevarious techniques and algorithms for SAT for different classes of CNF formulas ranging from linear algorithms for Horn,quadratic (2-CNF) and SLUR formulas [1,2] to the very complex variants of the exponential DPLL [3,4] and CDCL [5–8]procedures implemented in general purpose SAT solvers. Even the most complicated SAT solvers usually perform a taskcalled unit propagation [3]. The goal of unit propagation is to infer as many logically entailed literals as possible from apartial truth assignment and the input formula. Although in general unit propagation is not a complete method (it does notinfer all logically entailed literals), it is complete for the class of propagation complete (PC) CNF formulas [9].PC formulas play an important role also in constraint programming, or more specifically, in CNF encodings of globalconstraints. There is a strong connection between propagation completeness of the CNF encoding and domain consistency* Corresponding author. Tel.: +420 221 914 138; fax: +420 221 914 323.E-mail addresses: babkys@gmail.com (M. Babka), biotomas@gmail.com (T. Balyo), ondrej.cepek@mff.cuni.cz (O. ˇCepek), stevko@mail.ru (Š. Gurský),kucerap@ktiml.mff.cuni.cz (P. Kuˇcera), vlcek@ktiml.mff.cuni.cz (V. Vlˇcek).0004-3702/$ – see front matter © 2013 Published by Elsevier B.V.http://dx.doi.org/10.1016/j.artint.2013.07.006\f20M. Babka et al. / Artificial Intelligence 203 (2013) 19–34of the encoded constraint [10,11]. It has been studied for several concrete global constraints such as the AllDifferentconstraint [12], the Sequence constraint [13], Regular, Among, and Generalized Sequence [10], or theGrammar con-straints [14].Some SAT solvers try to avoid searching in the state subspaces with no solution by learning from conflicts, i.e. byperforming conflict driven clause learning (CDCL) [5–8], the name CDCL is also used for the complete algorithm solving SATproblem. It is useful to learn clauses (called empowering implicates [9,15]) that allow unit propagation to infer more logicallyentailed literals after such a clause is added to the CNF formula than it was possible to infer before the addition. Therefore,to speed up the CDCL SAT solver search for a satisfying assignment, it is often very useful to learn (generate) empoweringimplicates and add them to the input CNF formula. Let us mention that today’s most successful SAT solvers for real-worldapplications are the ones using CDCL procedure.This process of adding empowering implicates to a CNF formula can be viewed as a special type of knowledge com-pilation where both the input and the output representation of the knowledge is a CNF formula. In general, knowledgecompilation is a process of adding more information to a given knowledge representation in order to make it computa-tionally easier to infer facts from the compiled representation [16,17], or a process of transforming a given knowledgerepresentation into another knowledge representation which is more tractable with respect to fact deduction, such as trans-forming a CNF into a BDD [18]. Nevertheless, in this paper we are interested only in the very limited case of knowledgecompilation that rests in adding empowering implicates to a CNF.It has been shown in [9], along with other properties of PC formulas, that a formula ϕ is PC if and only if there isno empowering implicate for ϕ. However, several complexity issues directly connected to propagation completeness andempowering implicates are left open in [9]. A short list of such questions is the following:1. Given a CNF formula ϕ and a clause C , what is the complexity of deciding whether C is an empowering implicatefor ϕ?2. Given a CNF formula ϕ that is not PC, how difficult is it to generate an empowering implicate for ϕ by resolution,where the “level of difficulty” is measured by the length of the resolution proof?3. Given a CNF formula ϕ, what is the complexity of deciding whether there exists an empowering implicate for ϕ?4. Given a CNF formula ϕ that is not PC, how many empowering implicates is it necessary to add to ϕ in order to makeit PC?In this paper we tackle all of the above listed problems. After reviewing basic definitions and notation in Section 2, wederive several simple properties of empowering implicates in Section 3. We address the following four questions as follows:1. In Section 3 we show that the first problem is co-NP complete. This is not a very difficult result, however, to the bestof our knowledge, it was not stated in the related literature yet.2. In Section 4 we tackle the second problem. We prove that for a non-PC CNF formula with s occurrences of literalsthere always exists a resolution proof of length O (s) of some empowering implicate. On the other hand, we constructexamples of CNF formulas where a resolution proof of length Ω(s) is needed for any empowering implicate, whichmeans that Θ(s) is an asymptotically tight bound for this problem. It is important to note that the upper boundresult does not require the derived empowering implicate to be prime. We show (by a simple modification of resultsconcerning refutation proofs [19,20]) that there exist CNF formulas such that in order to derive any prime empoweringimplicate of such CNF a resolution proof of an exponential length is needed.3. Section 5 contains the main results of this paper which are connected to the third problem. It was proved in [9] thatdeciding about an existence of an empowering implicate is in (cid:5) p2 . Using the results from Section 4 we strengthen thisresult by showing that the problem belongs to (cid:5) p= NP. Given the equivalence between propagation completeness and1non-existence of empowering implicates proved in [9], this immediately implies that testing propagation completenessbelongs to co-NP. Then we proceed with the hardness proof for this problem. We present a reduction from a well-knownNP-complete 3-dimensional matching problem which proves that deciding for a CNF formula whether there exists anempowering implicate for it is NP-hard (and thus testing propagation completeness is coNP-hard).4. The fourth question is answered in Section 5 as well by showing that there exist CNF formulas where an exponentialnumber (both with respect to the number of variables and the number of clauses) of empowering implicates must beadded in order to arrive at a PC formula. This strengthens the superpolynomial bound which follows from a combinationof results in [9] and [21] using a superpolynomial lower bound for certain monotone circuits from [22]. The connectionis discussed in detail in Section 2.5.We close the paper by giving few concluding remarks in Section 6.\fM. Babka et al. / Artificial Intelligence 203 (2013) 19–34212. Definitions2.1. Basic definitionsA Boolean function of n variables is a mapping f : {0, 1}n → {0, 1}. We say that a Boolean function fis satisfiable if thereis a vector (cid:4)x ∈ {0, 1}n such that f ((cid:4)x) = 1. A literal is either a variable (x, called positive literal) or its negation (¬x or x, callednegative literal). A clause is a disjunction of literals. We assume that no clause contains both positive and negative literalsof the same variable. A clause which contains just one literal is called a unit clause. Formula ϕ is in conjunctive normal form(CNF) if it is a conjunction of clauses (we also say that ϕ is a CNF formula). We shall often treat a clause as a set of itsliterals and a CNF formula as a set of its clauses. It is a well-known fact that every Bo",
            {
                "entities": [
                    [
                        134,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 51 ( 1991 ) 179-221 Elsevier 179 Understanding complex dynamics by visual and symbolic reasoning Kenneth Man-Kam Yip Department of Computer Science, Yale University, P.O. Box 2158, Yale Station, New Haven, CT 06520, USA Abstract Yip, K.M.-K., Understanding complex dynamics by visual and symbolic reasoning, Artificial Intelligence 51 (1991) 179-221. Professional scientists and engineers routinely use nonverbal reasoning processes and graphical representations to organize their thoughts and as part of the process of solving otherwise verbally presented problems. This paper presents a computational theory and an implemented system that capture some aspects of this style of reasoning. The system, consisting of a suite of computer programs collectively known as KAM, uses numerical methods as a means to shift back and forth between symbolic and geometric methods of reasoning. The KAM program has three novel features: (1) it articulates the idea that \"visual mechanisms are useful for problem solving\" into a workable computational theory, (2) it applies the approach to a domain of great technical difficulty, the field of complex nonlinear chaotic dynamics, and (3) it demonstrates the power of the approach by solving problems of real interest to working scientists and engineers. 1. Introduction In observing professional physicists and engineers, we are often struck by how an expert's \"intuitive grasp\" of a field is hard to articulate verbally. This is perhaps indicative of the use of nonverbal reasoning processes as part of the process of solving otherwise verbally presented problems. We observe scientists, mathematicians, and engineers continually using graphical representations to organize their thoughts about a problem. This paper presents a computational theory and an implemented system that capture some aspects of this style of reasoning. The system I developed-- consisting of a suite of computer programs collectively known as KAM--uses numerical methods as a means of shifting back and forth between symbolic and geometric methods of reasoning. These programs not only draw graphs and diagrams, but look at these diagrams and hold them in their \"mind's 0004-3702/91/$ 03.50 t~) 1991--Elsevier Science Publishers B.V. All fights reserved \ft80 ~.M,-K. )Tp eye\" so that a powerful visual mechanism can be brought to bear on what otherwise would be purely symbolic problems. This style of reasoning is an example of what I call imagistic reasoning. The idea that problem solvers employing visual, analogue, or diagram- matic representations can be more effective than those relying on linguistic representations alone is not new. Even before 1960, Gelernter's 3 Geom- etry Theorem Proving Machine used diagrams to filter goals generated by forward-chaining theorem prover focused backward chaining. Nevins' 12 its forward deduction of facts on lines explicitly drawn in a diagram. Stall- man and Sussman's 16 EL program performed antecedent deductions by exploiting the finite connectivity of devices. Finally, Novak's  13 ISAAC program used diagrams to solve word problems in physics. What is new in the KAM program, however, is the demonstration that this classic AI problem-solving paradigm can be made to work in a signifi- cant way. Specifically the research reported here contributes to the field of qualitative physics in three ways: • It articulated the idea that \"visual mechanisms are useful for problem solving\", transforming it into a workable theory. • It applied the theory to an area of great technical difficulty--complex nonlinear chaotic dynamics; this is an area that has never before been addressed by the AI community. • It demonstrated that the approach is powerful enough to solve not just toy problems, but problems of real interest to working scientists and engineers. In one instance, KAM has led to previously unknown publishable results in hydrodynamics 19,23, Chapter 6. The KAM program is concerned with the automatic qualitative analysis of nonlinear Hamiltonian systems with two degrees of freedom. Such systems arise from the equations of motions of particles in conservative fields. They are of essence in dynamical astrophysics, in plasma physics, and in accelerator design; a great deal of human time is spent in exploring their behavior. Although computers can painlessly generate particular numerical solutions to such equations, understanding the qualitative content of the equations requires substantial human effort and judgement to develop only relevant numerical simulations and to interpret the numerical results in high-level, qualitative terms. KAM performs numerical simulations of Hamiltonian systems governed by their equations of motions. It automatically plans the numerical exper- iments, monitors its progress, and summarizes the numerical results in an executive summary containing information essential for dynamicists to un- derstand the behavior of the systems. Performing the numerical simulations themselves, of course, is straightforward. The trick is to decide which sets of system parameters to try, how long to run any particular simulations, and \fVisual and symbolic reasoning 181 when one has gathered enough information to deduce the essential behavior of the system. Typically, when an investigator encounters such a system, he attempts to characterize it with a consistent family of phase portraits. For each assign- ment of values of the system parameters, there is a phase portrait that shows the classes of trajectories that are possible for different initial conditions. Such a family of phase portraits can be obtained by running an immense number of expensive grid of initial conditions and system parameters, but an intelligent explorer can obtain the essential information with many fewer experiments. The reason is that although nonlinear dynamical behavior is complicated, there is structure on phase space that restricts the class of legal trajectories in one phase portrait, and provides a \"grammar\" of legal phase portraits. This research work is rooted in the tradition of focusing on the problem- solving behavior of articulate professionals in well-structured domains and formalizing their methods so that a computer can exhibit similar behavior on similar problems. The KAM program captures the knowledge and judgement ordinarily supplied by a human investigator in conducting selective numeri- cal experiments. It borrows techniques from many areas of computer science and artificial intelligence. For example, it uses numerical methods to evolve the trajectories and draws them in its mind's eye. It uses algorithms from computer vision and computational geometry to classify and recognize the relevant geometrical properties of trajectories. It uses classic AI techniques similar to Waltz's constraint analysis 20 to implement structure theorems that underly the \"grammar\" of dynamical behavior used to constrain the search and to produce summary reports. The paper is organized as follows. We first describe what it is like to interact with KAM, illustrating its capabilities. We next show the major pieces of KAM and its underlying computational structure. We then take a closer look at the technology behind the demonstration results. We finally explain why KAM works and summarize the major contributions of this research. 2. A session with KAM The following sample dialogue shows how KAM aids a scientist in ex- ploring the dynamics of the Henon map 5. KAM is written in Zetalisp, running on the Symbolics Lisp Machines. It is completely working; all the capabilities shown have been implemented and tested on many examples. The session is presented in part via an English dialogue solely for the ben- efit of the reader. KAM has no natural language capability; I have simply paraphrased KAM's output in stylized English. \f182 K.M.-K. Yip Scientist. Here are the equations for Henon map, the definition of phase space, and the range of parameter value. He types in the equations (Fig. I). He also types in range of state variables and the parameter.  Consider the phase portrait with a = 1.3284305. Show me the orbit starting at the initial state as indicated by the mouse click.  The initial state is (0. 08, O. 72). KAM. The orbit is a QUASIPERIODIC ORBIT with rotation number between 5/26 and 1/5. It took 256 iterates to reach steady state (Fig. 2 (a)). Scientist. Do the same for the new mouse click.  The initial state is (0.046, 0.011). KAM. The orbit is a QUASIPERIODI(' ORBIT with rotation number between 4/19 and 3/14. It took 256 iterates to reach steady state (Fig. 2 ( b ) ) . Scientist. Show me the entire phase portrait. KAM. KAM decides what initial states to look at. After some time, K A M  displays a phase portrait (Fig. 3), and reports its find- ings.  The portrait has an elliptic fixed point at (0.000, 0.000). Surrounding the fixed point is a regular region bounded by a KAM curve with rotation number between 1/5 and 1/4. Outside the regular region lies a chain of five islands. The island chain is bounded by a KAM curve with rotation number between 4/21 and 5/26. The outermost region is occupied by E S C A P E  orbits. Chaotic orbits occupy 62% of phase space. Scientist. Show me all the major bifurcations as the parameter c~ is varied. KAM: KAM decides what parameter values to look at. 4/ier some time, K A M  makes the following executive report. In the parameter range (0, 2.2), ICAM finds a total of 38 phase portraits. The following bifurcation patterns are observed: • Poincar6-Birkhoff bifurcation: pears at about 0.875 and the about 1.075. • Poincar6-Birkhoff bifurcation: pears at about 1.000 and the about 1.157. • Poincar6-Birkhoff bifurcation: pears at about 1.075 and the about 1.257. A pair of period-8 orbits ap- 8-island chain disappears at A pair of period-7 orbits ap- 7-island chain disappears at A pair of period-6 orbits ap- 6-island chain disappears at \fVisual and symbolic reasoning 183 HEN011 MAP z . ",
            {
                "entities": [
                    [
                        57,
                        120,
                        "TITLE"
                    ],
                    [
                        267,
                        330,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 90 ( 1997) 225-279 Artificial Intelligence Abstract argumentation systems * Gerard A.W. Vreeswijk a,b** a Department of Computer Science (F&W), University of Limburg, P.0. Box 616, 6200 MD Maastricht, Netherlands h Department of Computer Science, Washington University, Campus Box 1045, One Brook&s Drive, St. Louis, MO 63130-4899, USA Received December 1995; revised September 1996 Abstract systems. An abstract argumentation In this paper, we develop a theory of abstract argumentation system is a collection of “defeasible proofs”, called arguments, that is partially ordered by a relation expressing the difference in conclusive force. The prefix “abstract” indicates that the theory is concerned neither with a specification of the underlying language, nor with the development of a subtheory that explains the partial order. An unstructured language, without logical connectives such as negation, makes arguments not (pairwise) incompatible. Incompatibility and difference in conclusive force cause defeat among arguments. The aim of the theory is to find out which arguments eventually emerge undefeated. These arguments are considered to be in force. Several results are established. The main result is that arguments that are in force are precisely those that are in the limit of a so-called complete argumentation sequence. @ 1997 Elsevier Science B.V. inconsistent, but (groupwise) Keywords: Nonmonotonic logic; Defeasible reasoning; Argumentation *This research has been conducted at the Vrije Universiteit Amsterdam, at the Rijksuniversiteit Limburg, and at the Washington University in St. Louis. Part of this research was made possible by SION, and is financed by NW0 under contract number 612-316-019. The research at the Washington University in St. Louis is financed by the NSF under contract number 9503476. A preliminary report of this work has been presented at the First World Conference on the Fundamentals of Artificial Intelligence, Paris, July 1991, and selected at February 10, 1992 by the program committee of the WOCFAI for publication in a forthcoming issue of Studia Logica. The present document is a revised version of “Abstract Argumentation Systems”, issued in 1993 as “Technical Report IR-289”. at the Department of Mathematics and Computer Science at the Vrije Universiteit Amsterdam. This article contains fragments of Chapter 2 and Chapter 7 of the author’s dissertation “Studies in Defeasible Argumentation” ( 1993). * E-mail: vreeswijk@cs.unimaas.nl, vteeswijk@cs.wustl.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PII SOOO4-3702(96)00041-O \f226 G.A.W Vreeswijk/Art$cial Intelligence 90 (1997) 225-279 1. Introduction information. One approach theory. The idea is that argumentation logics have been proposed or uncertain Various incomplete mentation ideas to reason with incomplete or uncertain and the formalism forms of incomplete motivating thus obtained or uncertain thought behind is then used information to reason with symbolically is influenced theory contains represented by (informal) forms of argu- the right concepts and information. These insights are formalized, rule-based this is the to represent on the computer. and manipulate In a nutshell, theories of formal argument. There exist a large number of formal argumentation (1) Pollock developed philosopher systems. an argumentation (2) (3) (4) the logic” argument reasoning, arguments is defined called LDR. [ 3 l-33,35,36] called LDRl, that he shows system of defeasible and extended version of LDRl, [ 211 presented recursively q, in which a premise p is discarded ( 1985-1997). OSCAR has the possibility on the computer. * Two years later, in 1988, Nute than the antecedent of the top-rule of the second argument. system called to reason is a defeasible to infer [ 291. In that report, Nute defines a simple and is readily [ 301 presented In LDR, adjudication is done via top-rules: one argument defeats another is strictly more The American OSCAR with so-called suppositional arguments. A suppositional argument with conclusion implication p 3 q. (Cf. [ 3,401.) In 1986, the philosopher Donald Nute wrote a report, entitled “A non-monotonic logic based on conditional elegant implementable a revised among competing if and only if the antecedent of the top-rule of the first argument specific In 1987, Loui defeat directness, with Simari new defeasible analysis of both articles.) a C implementation is based on LMNOP Merrill In 1988, Horty and Thomason nonmonotonic with an important formula, and arguments in which lines of reasoning, arguments it is right on a number of crucial aspects, especially when it comes to the resolution of complicated defeat and interference for a detailed In 1991-1993, Loui et al. [24] developed NATHAN, of rules for computing defeat among arguments. NATHAN developed by Costello, Loui and ( 1993), a LISP-prototype a system of defeat among arguments, in are called “paths”. Because paths are “one-dimensional” treatment of defeasible t_ is introduced. in which specificity, together in which a [ 161 presented a theory of mixed of rules consist of exactly one in 1992, Loui presented, relations between paths. symbolic argumentation, proof nets. Inheritance and evidence. Later, reasoning [55], [ 451, a mathematical terms of preference, is not as involved are trees. Perhaps theory resembles that antecedents in consequence as a theory consequence interference, d-shortness, inheritance inheritance difference [ 24,451. operator thereof, theory (Cf. in ’ First, the program was called PROWIS (for programming with subjunctives), micro-PROLOG defeasible PROLOG). 3.1. Later ( 1988), the implementation was changed and renamed and was implemented into d-PROLOG in (for \f227 (YSP) . G.A.W Vreeswijk/Artijicial Intelligence 90 (1997) 225-279 to the Yale Shooting Problem to promote an already the other way around. By means of a the issue of what should be discussed (5) Instead, it worked formalism. YSP-Konolige [ 171 proposed a solution In 1988, Konolige Unlike most of the proposals, his treatment was not meant existing particular problem-the involved when one reasons about events. The resulting discussion clear, and an almost casual manner. Meanwhile, emerges out of the discussion. Konolige’s is based on McCarthy’s with Hypotheses) are attached (6) Lin and Shoham formalism ARGH situation (1988, 1993) developed touches upon many issues of defeasible to situations. an argument important [20] ( ARGumentation calculus, where properties is extremely in argumentation the formalism more or less automatically nonmonotonic logic, McDermott logics. Among others, and Doyle’s nonmonotonic system that cap- the authors logic I, tures a number of well-known mention: Reiter’s default Moore’s autoepistemic Lifschitz’ pointwise theory of chronological tonic responsible logics, because logic, negation by failure, McCarthy’s circumscription, circumscription, ignorance. various forms of inheritance, and Shoham’s to capture so many nonmono- It is possible the system in question does not have a component that is for the resolution of argument conflicts. (7) Recently, in 1995, the Thai researcher Dung [9] presented theory, in which an argument gumentation determined by its so-called attack relations fundamental if S attacks all attackers of that argument. is paid to the internal value judgement.) in Dung’s concept theory. An argument is an abstract entity whose role to other arguments. Acceptability a mathematical ar- is is a is accepted by S if and only theory, no special attention In Dung’s structure of the arguments. (The latter is not meant as a Why are there so many different argumentation systems? Our explanation area is relatively young. No consensus has been reached yet on essential the representation or group of researchers, large diversity of argumentation and their precise of arguments systems. has its own way to deal with these issues, which results form of interaction. Each researcher, in a is that the issues, such as There are a number of problems with existing systems. (a) A problem with OSCAR is that, in some cases, >-introduction cious arguments. These fallacious arguments unjustifiably ing that actually and illustrated with a counterexample should emerge undefeated. This problem in [55]. falla- produces defeat lines of reason- is further discussed (b) The mutual dependency relations between interfering [21], arguments it is possible are difficult to construct to a its successor. With this In Loui’s system for most systems. in which each argument defeats handle cycle of three arguments cycle it remains unclear which of the three arguments is caused by Loui’s notion of defeat, This problem short arguments tain isomorphic reason, be defeated by other long arguments, that can be defeated by longer arguments that, in turn, may con- copies of the shorter argument. These copies can, for the same a chain of suc- should remain undefeated. that makes thus constructing it possible \f228 GA. W! Vreeswijk/Art$icial Intelligence 90 (1997) 225-279 cessive defeaters. If the ends fit, such a chain can be made into a cycle of three successively defeating arguments. (c) Most systems have difficulties with a situation in which it is not clear which argument should win. One possibility is to keep up all arguments, and continue reasoning with them in different “worlds”. This approach has become known as credulous reasoning. (Cf. [42] : multiple extensions; [7] : multiple contexts; [ 271: multiple belief spaces; [ 281: clusters of worlds.) A second possibility is to do away with every argument, on the basis of the idea that the arguments neu- tralize each other. This approach has become known as skeptical reasoning. (Cf. [ 21,30,36,45] : collective defeat. Horty and Thomason [ 161 introduce a mech- anism of skeptical defeat that is slightly more refined.) A third possibility is to undefeated”, “provisionally un- introduce three classes of arguments-“",
            {
                "entities": [
                    [
                        67,
                        97,
                        "TITLE"
                    ],
                    [
                        2176,
                        2206,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 116 (2000) 17–66Proving theorems by reuseChristoph Walther (cid:3), Thomas Kolbe 1Fachbereich Informatik, Technische Universität Darmstadt, Alexanderstr. 10, D-64283 Darmstadt, GermanyReceived 22 October 1997; received in revised form 7 June 1999AbstractWe investigate the improvement of theorem proving by reusing previously computed proofs. Wehave developed and implemented the PLAGIATOR system which proves theorems by mathematicalinduction with the aid of a human advisor: If a base or step formula is submitted to the system, it triesto reuse a proof of a previously verified formula. If successful, labour is saved, because the numberof required user interactions is decreased. Otherwise the human advisor is called for providing a handcrafted proof for such a formula, which subsequently—after some (automated) preparation steps—isstored in the system’s memory, to be in stock for future reasoning problems. Besides the potentialsavings of resources, the performance of the overall system is improved, because necessary lemmatamight be speculated as the result of an attempt to reuse a proof. The success of the approach is basedon our techniques for preparing given proofs as well as by our methods for retrieval and adaptationof reuse candidates which are promising for future proof reuses. We prove the soundness of ourapproach and illustrate its performance with several examples. (cid:211)2000 Elsevier Science B.V. Allrights reserved.Keywords: Deduction and theorem proving; Machine learning; Problem solving and search; Knowledgerepresentation; Analogy; Abstraction; Reuse1. IntroductionThe improvement of problem solvers by reusing previously computed solutions isan active research area of Artificial Intelligence, emerging in the methodologies ofexplanation-based learning (EBL) [22,28,65] and analogical reasoning (AR) [14,39,68]. In EBL a problem’s solution is analyzed, yielding an explanation why the solutionsucceeds. After generalization, the explanation is used for solving (similar) new problems.(cid:3)Corresponding author. Email: chr.walther@informatik.tu-darmstadt.de. This work was supported under grantsno. Wa652/4-1,2,3 by the Deutsche Forschungsgemeinschaft as part of the focus program “Deduktion”.1 Email: kolbe@informatik.tu-darmstadt.de.0004-3702/00/$ – see front matter (cid:211)PII: S 0 0 0 4 - 3 7 0 2 ( 9 9 ) 0 0 0 9 6 - X2000 Elsevier Science B.V. All rights reserved.\f18C. Walther, T. Kolbe / Artificial Intelligence 116 (2000) 17–66In AR a problem’s solution guides the solution of (similar) new problems by suggestingcorresponding inference steps. We present an approach for reusing proofs that combinesideas of EBL and AR as well as ideas from abstraction techniques [36,69].We investigate the reuse of first-order proofs within the domain of automated mathemat-ical induction [8,11,44,46,82] where similar conjectures often have similar proofs: 2 Aninduction theorem prover either proves a conjecture by first-order inferences or otherwiseassociates the conjecture with a finite set of induction formulas whose truth entail the truthof the conjecture (by means of some induction axiom). An induction formula IH ! IC iseither a step formula or a base formula in which case IH equals TRUE. Induction formulasform new conjectures serving as input to the prover, and the original conjecture is provedif eventually only (first-order) provable induction formulas, i.e., valid formulas, remain.Such formulas are proved by modifying the induction conclusion IC using axioms and theinduction hypothesis IH until TRUE is inferred. Despite this regularity the search problemof deciding when and where to apply which axiom such that the induction hypothesis IHbecomes applicable is a main challenge in automated mathematical induction [16,42,82].We call the component of an induction theorem prover which checks the validity of aninduction formula the simplifier. This component either is implemented as a (first-order)theorem prover (tailored for proving induction formulas) or as an interface to the user incase of an interactive (first-order) system. In this paper, we aim to supplement the simplifierwith a learning component in the following way: Once the simplifier has computed a proof,this proof is analyzed and then generalized in a certain sense such that it can be reusedsubsequently. Before the simplifier is asked to prove another statement, now the systemfirst looks for a previously computed proof of a similar statement and tries to reuse it. Ifthe reuse fails, the simplifier has to compute an original proof for the new statement (as itmust without a reuse facility). Otherwise (depending on the simplifier’s implementation)either the search for a proof or user interactions are saved.2. Reusing proofs—An exampleThe success of our approach is based on our techniques for preparing given proofs (byproof analysis and generalization) as well as by our techniques for proof reuse (by retrievaland adaptation methods).We illustrate our proposal by an example. We assume that functions are defined by afinite set EQ of defining equations, and we are interested in verifying that some conjecture’ follows inductively from EQ, i.e., ’ 2 Thind.EQ/ for the inductive theory Thind.EQ/ ofthe equation set EQ. If the inductive validity of such a statement ’ is verified, we mayadd ’ to a set L of lemmata, and subsequent proofs are based on the set AX VD EQ [ L ofaxioms. Now if  2 Thind.AX/ is shown for a new conjecture , then  is an inductiveconsequence of EQ since Thind.AX/ D Thind.EQ/, and  may be also inserted into L, etc.(see, e.g., [82] for a more detailed account on induction theorem proving).2 Throughout this paper induction stands for mathematical induction and should not be confused with inductionin the sense of machine learning. The reuse of previously computed induction schemas or generalizations are notsubject of our proposal.\fC. Walther, T. Kolbe / Artificial Intelligence 116 (2000) 17–6619For proving a statement  by induction, i.e., to verify  2 Thind.EQ/, a suitableinduction axiom from Thind.EQ/ is selected by well-known automated methods, cf.,e.g., [82], from which a set of induction formulas I is computed for  such thatI (cid:18) Thind.AX/ entails  2 Thind.EQ/. For instance, let the functions plus, sum and appbe defined by the following equations where 0 and s (respectively empty and add) are theconstructors of the sort number (respectively list): 3(plus-1)(plus-2)(sum-1)(sum-2)(app-1)(app-2)plus.0; y/ (cid:17) y;plus.s.x/; y/ (cid:17) s.plus.x; y//;sum.empty/ (cid:17) 0;sum.add.n; x// (cid:17) plus.n; sum.x//;app.empty; y/ (cid:17) y;app.add.n; x/; y/ (cid:17) add.n; app.x; y//:Now, e.g., the lemma(lem-1) plus.plus.x; y/; z/ (cid:17) plus.x; plus.y; z//can be easily proved by induction and therefore may be used as an axiom like any definingequation in subsequent deductions. We aim to prove conjectures as (lem-1) by reusingpreviously computed proofs of other lemmata. For instance consider the statement’Tx; yU VD plus.sum.x/; sum.y// (cid:17) sum.app.x; y//:We prove the conjecture ’ by induction upon the list-variable x and obtain two inductionformulas, viz. the base formula ’b and the step formula ’s as’b VD ’Tempty; yU;’s VD .8u ’Tx; uU/ ! ’Tadd.n; x/; yU:The following proof of the step formula ’sconclusion ’Tadd.n; x/; yU Dis obtained by modifying the inductionplus.sum.add.n; x//; sum.y// (cid:17) sum.app.add.n; x/; y//IC3 When presenting examples, we usually omit universal quantifiers at the top level of formulas as well as thesort information for variables.\f20C. Walther, T. Kolbe / Artificial Intelligence 116 (2000) 17–66(cid:8)s VD . 8u F .G.x/; G.u// (cid:17) G.H .x; u/// !F .G.D.n; x//; G.y// (cid:17) G.H .D.n; x/; y//98>=><.1/ G.D.n; x// (cid:17) F .n; G.x//.2/ H .D.n; x/; y/ (cid:17) D.n; H .x; y//.3/ F .F .x; y/; z/ (cid:17) F .x; F .y; z//>;Cs VD>:Fig. 1. The proof shell PSs for the proof of ’s .in a backward chaining style, i.e., each statement is implied by the statement in the linebelow, where terms are underlined if they have been changed in the corresponding proofstep:plus.sum.add.n; x//; sum.y// (cid:17) sum.app.add.n; x/; y//plus.plus.n; sum.x//; sum.y// (cid:17) sum.app.add.n; x/; y//plus.plus.n; sum.x//; sum.y// (cid:17) sum.add.n; app.x; y///plus.plus.n; sum.x//; sum.y// (cid:17) plus.n; sum.app.x; y///plus.plus.n; sum.x//; sum.y// (cid:17) plus.n; plus.sum.x/; sum.y///plus.n; plus.sum.x/; sum.y/// (cid:17) plus.n; plus.sum.x/; sum.y///TRUEIC(sum-2)(app-2)(sum-2)IH(lem-1)X (cid:17) XGiven such a proof, it is analyzed to distinguish its relevant features from its irrelevantparts. Relevant features are specific to the proof and are collected in a proof catchbecause “similar” requirements must be satisfied if this proof is to be reused later on. Weconsider features like the positions where equations are applied, induction conclusions andhypotheses, general laws as X (cid:17) X, etc. as irrelevant because they can always be satisfied.So the catch of a proof is a subset of the set of leaves of the corresponding proof tree.Analysis of the above proof yields (sum-2), (app-2), and (lem-1) as the catch. For example,all we have to know about plus for proving ’s is its associativity, but not its semantics orhow plus is computed.Next the conjecture, the induction formula and the catch are generalized 4 for obtaininga proof shell which stores the essentials of the proof and serves as the base for reusing theproof subsequently. Generalization is performed by replacing function symbols by functionvariables denoted by capital letters F; G; H , etc., yielding the schematic conjecture (cid:8) VDF .G.x/; G.y// (cid:17) G.H .x; y// with the corresponding schematic induction formula (cid:8)s aswell as the schematic catch Cs for our example, cf. Fig. 1.Here we use the generalization replacement plus 7! F , sum 7! G, app 7! H , add 7! D,and therefore Eq. (1) of Cs corresponds to (sum-2), Eq. (2) to (app-2), and Eq. (3) to(lem-1).",
            {
                "entities": [
                    [
                        40,
                        65,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 100 (1998) 87-123 Artificial Intelligence Search in games with incomplete information: a case study using Bridge card play Ian Frank a,*, David Basin by’ il Cotnplex Games Lab, Electrotechnical L.aboratmy, Umezono I-l-4, Tsukuba. Ibaraki, Japan 305 h Institut ji?r Inj&matik, Univer~sitiit Freiburg, Am Flughafen 17, Freiburg, Germany Received 9 February 1996; revised 15 March 1997 Abstract We examine search algorithms in games with incomplete information, formalking a best defence model of such games based on the assumptions typically made when incomplete information problems are analysed in expert texts. We show that equilibrium point strategies for optimal play exist for this model, and define an algorithm capable of computing such strategies. Using this algorithm as a reference we then analyse search architectures that have been proposed for the incomplete information game of Bridge. These architectures select strategies by analysing some statistically significant collection of complete information sub-games. Our model allows us to clearly state the limitations of such architectures in producing expert analysis, and to precisely formalise and distinguish the problems that lead to sub-optimality. We illustrate these problems with simple game trees and with actual play situations from Bridge itself. @ 1998 Elsevier Science B.V. Keywnrds: Game tree search; Incomplete information; Game theory; Computer Bridge 1. Introduction In games with incomplete information, the actual “state of the world” is unknown; for example, be visible, or the outcome of some moves may not be known. For such games, ing often some playing pieces may be hidden, some of the playing area may not find- is for for timely play. An example of an incomplete the optimal required is typically NP-hard approach game thus a heuristic information [4] and strategy * Corresponding ’ Email: basin@informatik.uni-freiburg.de. author. Email: ianf@etl.go.jp. 0004-3702/98/$19.00 PIISOOO4-3702(97)00082-9 @ 1998 Elsevier Science B.V. All rights reserved. \f88 I. Frunk, D. Basin/Artijicial Intelligence 100 (1998) G-123 on which good heuristics demic research more solutions [ 12,231. or systems than two dozen commercial the game have yet to be found is Contract Bridge; a history of aca- of to produce capable of competing with even good novice human players [ 5,10,11,17,22,24,27,31,32] software packages [ 19,331 have failed and a proliferation in reveal instead [2,36]. The the uncertainty to each other and considering [ 3]), or by removing suits information (first suggested altogether to automating Bridge card play involve reducing the sub-problems independently their cards some researchers, architectures significant that are consistent with a player’s knowledge. They speculate The common approaches space by either considering in individual complete players prompted Bridge-playing of the worlds any given situation ing and transposition to be established promising Recently, Matt Ginsberg has produced what he claims [35] of Bridge-playing proach. the search of the card combinations over in- the situation where all the has to suggest number that in (such as alpha-beta prun- the minimax value of each possible action the most sub-problems, to be chosen by statistical evaluation based on these values. to be a “whole new standard” ap- based on such a sampling for example Levy that work by examining [ 201 and Ginsberg a statistically program with an architecture the use of search reduction latter of these approaches tables) would enable in each of these overall action techniques generated randomly [ 14,151, and information Our interest in incomplete of such a model from those found [ 8, lo], and in particular that we first had to formalise games arose from our own work in designing from investigating why this program a system to play Bridge the rea- texts. To identify in expert could produce analyses different sons for these discrepancies, we found the actual model used by human players when analysing Bridge; surprisingly, we could find no explicit the best defence model of an in- descriptions the way that experts complete of this paper. We analyse problems go on to show that an equilibrium point for the two players’ strategies is well-defined for the best defence model, and describe an algorithm, which we call exhaustive strat- egy minimisation, that identifies points. We then use our best defence formalisation against “best defence”. in authoritative Bridge texts-is we formalised by considering in the literature. Thus, as a tool to investigate the first contribution the characteristics such equilibrium of sampling game-which information algorithms such problems Whilst others have noted before that computer Bridge architectures may not “play the same way as humans”, without a formal model of the assumptions made by experts the qualitative differences when solving to describe. Our formalisation that can afflict allows us to identify sampling algorithms, these problems both theoretically, play situations the two problems of how many worlds they consider. We demonstrate using simple game trees, and in practice, using actual in play have been difficult independently from Bridge itself. to combine The first of these problems, which we name strategy fusion, affects any algorithm for particular worlds to produce an optimal strategy subset) of worlds. The flaw in this approach that the exact state imposes that attempts across all (or some statistically occurs because of the property of incomplete of the world at any given point of play may not be known games to a player. This information significant strategies \f1. Frank, D. Basin/Artificiul Intelligence 100 (1998) 87-123 89 on a player’s strategy a constraint worlds at such points; a constraint for individual worlds. that he must behave typically broken when combining the same way in all possible strategies designed clearly between such an opponent the two. Non-locality can direct play towards the portions of the game In general, determining what nodes in the worlds he expects. Thus, some positions The second problem, which we name non-locality, is more subtle than strategy fusion, occurs because an and we take care to distinguish opponent with some knowledge of the actual world state can use this to his advantage. tree In particular, that are most favoutable in the game (as the opponent may always find better may never be reached under particular worlds in the search space will be reached alternatives). the entire tree of possibilities under what worlds requires examining (since each move an to select different portions of the tree in different opponent makes gives him the chance in the sense worlds). Tree search algorithms, the best play at an internal node of a search space by analysing that they determine will not take into only account the therefore make mistakes node by erroneously in world states that are in fact of no consequence at that position notion of strategy only partial specify what actions would have been the tree. the subtree of that node. Such algorithms that under some worlds for the entire game would also have to that portion of (e.g., minimaxing) the play may never actually considering in the tree. As in strategy the problem that locally evaluates they are examining. When selecting moves, the subtrees considers in all other nodes outside incorrectly. An algorithm however, are generally strategies taken is one of handling “compositional” the possibility the complete they may strategies; payoffs fusion, reach Thus, we demonstrate exactly how the analysis of sampling this shortcoming is an issue for empirical [ 131). Our interest information is actually sufficient algorithms will differ their testing (such as that apparently being involved in is in clarifying the nature of to undermine the issues games, and in understanding from that of experts. Whether practical playing potential carried out by Matt Ginsberg finding solutions the models to incomplete implicitly used by different approaches. concepts We proceed as follows. In Section 2 we introduce preliminary these in Section 3 to games with incomplete this framework. We follow this in Section 4 by giving an algorithm from game theory and apply in particular we show how the common model of Bridge play against best defence can be formalised within for computing in our best defence model. The second half of the paper then considers optimal strategies Bridge for Bridge card in Sections 6 and 7 we use our game play based on theoretic results against best defence. Finally, Section 8 draws conclusions. to identify why such architectures yield suboptimal in Section 5 we present sampling in some detail: the minimax architectures information; framework algorithm, and 2. Game theory background In this section we introduce definitions and terminology necessary self-contained. and Lute and Raiffa [ 211. This is based largely on the work of von Neumann and Morgenstern to make the paper [ 341 \f90 I. Frank, D. Busin/Arrijicial Intelligence 100 (1998) 87-123 2.1. The extensive and the normal forms of two-player games In its extensive is a finite the branches tree in which each node corresponds to a form, a game move where a selection between is made. Each node is identified as being either a personal move or a chance move. Personal moves are made freely by one of the two-player games. players, creatively named “1” and “2”, since we will consider only Chance moves are decided by some mechanical the shuffling of a pack in accordance with definite of cards, or the tossing of a coin) the start of the game. A probabilities. There play, a, of the game node and allowing each of to choose a branch until a leaf node of the tree is reached. The the players to the outcome of a play (Y, (i.e., a leaf of the tree), value the is given by a numerical utility function K;( cu). This value is sometimes payoff and Ki a payofffunction. (or chance) that each pla",
            {
                "entities": [
                    [
                        75,
                        155,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 88 (1996) 143-161 Artificial Intelligence Propagating imprecise probabilities in Bayesian networks * Gernot D. Kleiter * Institut fiir Psychologie, Universitdt Salzburg, Hellbrunner.xtr. 34, 5020 Salzburg, Austria Received March 1995; revised February 1996 Abstract in the networks “exact” probabilities; Often experts are incapable of providing likewise, in networks are based must often be small and preliminary. the probabilities probabilities probability uncertainty about probabilities. The problem of how to propagate point probabilities network now Bayesian networks. to use beta or Dirichlet distributions samples on which the In such cases can be handled by second order the in a Bayesian in to propagate Dirichlet distributions the problem of how are imprecise. The It is convenient is transformed distributions. imprecision to express into first order probabilities It is shown that the propagation of Dirichlet distributions in Bayesian networks with incomplete and Dirichlet distributions. Ap- and their second order probability density functions are obtained are in a system of probability mixtures of beta-binomial data results proximate by stochastic discussed by the use of examples. An important property increases pruning criterion small. Thus, imprecision may be used as an Ockam’s razor in Bayesian networks. simulation. A number of properties of the propagation of imprecise probabilities is that the imprecision of inferences rapidly as new premises are added to an argument. The imprecision to keep the number of variables in an inferential argument can be used as a in a network involved 1. Introduction Bayesian belief networks represent and process probabilistic knowledge. Their rep- resentational components belong to one of two domains, a qualitative or a quantitative * Thanks are due to the Fonds zur Ferderung der wissenschaftlichen Forschung, Vienna, for the financial support. Thanks are also due to the hospitality of the Department of Psychology, Bowling Green State University, Ohio, especially to Michael E. Doherty. * E-mail: gemot.kleiter@sbg.ac.at. 0004-3702/96/$15.00 Copyright @ 1996 Elsevier Science B.V. All rights reserved. PII SOOO4-3702(96)00021-S \f144 G.D. Klerter/Art@crcd lntrlligencr RR (I 996) 143-161 Fig. I. Bayestan network: Cooper’< medical diagnosis example Table I Weight tables associated with Cooper’s example I. the numbers were choosen so that two conditions the ratios of the weights preserve the probabilities of the original version of Cooper’s example in Rg. are fullfilled: (i) and (ii) the total sum of all elementary weights is 120 (A) ytl t, 96 24 (B. A) -h h -0 77 I9 ii 5 I9 !C. A! 70 Y( c ‘)I 5 <I 19 5 (E, C) 7r Y yc 44 66 (’ 2 8 probability dependence distributions (conditional) relationships like diseases, are organized of (conditional) of the involved from a specific metastatic the associated quantitative in Fig. I and Table 1 [7,34,37]. specifications. Assume we have investigated to the nodes of the graph. The tables are not “visible” the example shown the dependencies variables and independence in the visual language of graph theory. The quantitative one. The basic qualitative between variables are expressed specifications tables and attached ical representation. Consider in Fig. 1 represents network represent clinical absent/present I contains patients suspected of suffering 24 actually have developed metastatic in which the metastatic and 77 do not, etc. These and the remaining main purpose of a Bayesian belief network patient one or more of the variables are observed and are known for certain, the probabilities ties propagate through diagnosis, prediction, or explanation Bayesian network. Bayesian belief networks belong tic models intelligence in in the graph- The in a graphical model. The nodes A-E test results, or symptoms. Table 120 form of cancer. It turns out that the total serum calcium and 5 do not. Of those patients total serum calcium in Table 1. The If for a this affects states in the graph. Evidence and updated probabili- like medical in a for tutorials and related work on uncertainty //www . auai . org page and the references given there). to the class of graphical probabilis- in artificial are special cases of propagating probabilities ( [ 6, 1 1, 15,30,43]; see the http: the network. Various kinds of probabilistic form and 96 have not. Of those having is to perform probabilistic form, 19 show increased form was not observed, 19 show increased of the neighboring the metastatic are contained frequencies inference. inference \fG.D. Kleiter/Artificial Intelligence 88 (1996) 143-161 14.5 I- 10 20 30 40 50 100 * Probability Fig. 2. The beta distribution Be(4.41.40.56) example. together with a 99% highest density interval for Cooper’s Usually, the probabilities in Bayesian networks are treated as though they were known instead. Probability precisely. In the present paper we analyse Bayesian networks are not known precisely. Experts often cannot provide exact point probabilities, intervals estimates derived small sample considered made how bounds [ 17,21,25,26,33,39,40]. from empirical data are often based on in a Bayesian network cannot be several proposals have been such as lower and upper to be precise point values. to handle in which the probabilities providing [ 8,3 1,381, and second order distributions In the literature, the probabilities In such cases in dependency of variances propagation is provided imprecision structures, [ 9,12,42], A tutorial in [ 161. sizes. function statistics the uncertain We treat probabilities that are not known precisely is attached. The distributions the distribution in the same way they are treated [ 31, as uncertain quantities to which a (second order) probability If little is known If much the distribution small. The use of a second order in Bayesian statistics and there is nothing distribution exciting about it. The procedure actually goes back to Thomas Bayes. He was probability density in Bayesian density about is known, probability especially one of the first who plotted a continuous (upside-down) function, a beta distribution is tight and its variance is a standard procedure over the unit interval. the imprecision. its variance is flat and quantity, express large. The method proposed in this paper allows the derivation of the following inferences: If of a metastatic fall into comas (-d) but suffers from severe headaches is an the probability imprecision associated with this estimate. We can be 99% sure that the true lies in the interval 0.0134 and 0.227. The standard deviation of the estimate e] = a patient does not intermittently (e), then appreciable probability is 0.0436. The imprecision may be expressed by Be( 4.41,40.56), where the brackets are used as a shorthand notation to the probability density [al+, for “the probability of a given function of the parameter the beta distribution is 0.098. However, corresponding -d and cancer there (a) \f146 G.D. Klrrter/Artijicid intelli#wcr 88 (1996) lJ.?-161 corresponds content 0.99). Further analysis the full example inference is hascd on a total sample size of 120 cases the precision e”. While to a sample size of 45 cases only. Fig. 2 shows of the present interval interval the beta distribution are that the severe headaches with probability on -d not really essential with mean 0.087 and standard alone deviation 0.0387. The precision only as compared when both D and E are instantiated. We will come back to this at first sight counterintuitive together with a 99% highest density shows the metastatic increases when D is instantiated leads to the distribution cancer. Conditioning = Be(4.50.47.44) even slightly (the shortest inferences property. [n]ld] about for 2. Basic model (nodes, variables) V and a set of directed edges E between variables) defined on V x V. The vertices and the (DAG). With each node X E V and the set of its , U,,!). If (X, I/) is If the arcs do not contain cycles, , U,,,} we associate a weight table (X, 1/t,. by a graph G = l VE). dependencies a set of vertices is a directed acyclic graph We consider (arcs, probabilistic the edges are represented graph parents pa(X) = {U,, a two-dimensional weight table. then we denote if W = (Xi, X2.. More generally, the subset { ZI , . marginal along We follow [ 141 and denote a probability and marginal distributions , X,,) is an ,I-dimensional weight table, we denote , X,l} by (X, ,X2,. . Z,,,} C {X,, the marginal of X along U by (X, (i)~‘. the . . , X,,)‘{z~....~znf~. (pdf) by brackets. Joint, respec- are written as [X, Y], [ XjY], and [Xl, is denoted by +, e.g., [X, Y] = [X/Y] * [Y] etc. The [ Xlpa( _u) ] for each variable X. We conceive in a table as the shape parameters of Dirichlet distributions. Dirichlet dis- are defined for binary cases, the beta distributions, (second order) pdfs function density and their special versions tables define conditional, tively. The product of densities weight the weights tributions as follows: Definition 1 (Dirichlet distribution). plex S’= of reals with vector is given by (VI > 0,. y,~): K, < 0, i= {(yt...., Let ( Yl, I ,.... d;Cf!,y, , XI ) be a random vector on the sim- 6 I) and (v,,.... vg) a vector I. If the density of the random , Y!) > O), where d = D - P(.YI,...,.vd) = f(Vl t~.+vf)) ,,I” ’ T(Vll . ..I’(?/“). - 1 , “,‘_I ,I ] _ -& & I’,> - I , i ,=I i (1) we say that (U, , . [Y, . . . . . Yd] =Di(v , Yd) follows a d-variate Dirichlet distribution. We use the shorthand ,,.... v~). Definition 2 (Beta distribution). density is given by Let Y be a random variable on the unit interval. If its (2) \fG.D. Kleiter/Art@cinl Intelligence 88 (1996) 143-161 147 Y is beta distributed with shape parameters VI and ~2. We write Be( vt,v2). Its mean and variance are given by for short [Y] = E(Y) = -?-- VI + v2’ var(Y) = VIP2 (VI + v2>2(v, + v2 + 1). (4) In a beta distribution we interpret available about a proposition, extensively the point probability VI /( vt + ~9",
            {
                "entities": [
                    [
                        75,
                        131,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1045–1063www.elsevier.com/locate/artintActive logic semantics for a single agent in a static worldMichael L. Anderson a,d,∗, Walid Gomaa b,e, John Grant b,c, Don Perlis a,ba Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USAb Department of Computer Science, University of Maryland, College Park, MD 20742, USAc Department of Mathematics, Towson University, Towson, MD 21252, USAd Department of Psychology, Franklin & Marshall College, Lancaster, PA 17604, USAe Department of Computer and Systems Engineering, Alexandria University, Alexandria, EgyptReceived 7 December 2006; received in revised form 14 November 2007; accepted 16 November 2007Available online 22 November 2007AbstractFor some time we have been developing, and have had significant practical success with, a time-sensitive, contradiction-tolerantlogical reasoning engine called the active logic machine (ALMA). The current paper details a semantics for a general version of theunderlying logical formalism, active logic. Central to active logic are special rules controlling the inheritance of beliefs in general(and of beliefs about the current time in particular), very tight controls on what can be derived from direct contradictions (P &¬P ),and mechanisms allowing an agent to represent and reason about its own beliefs and past reasoning. Furthermore, inspired by thenotion that until an agent notices that a set of beliefs is contradictory, that set seems consistent (and the agent therefore reasonswith it as if it were consistent), we introduce an “apperception function” that represents an agent’s limited awareness of its ownbeliefs, and serves to modify inconsistent belief sets so as to yield consistent sets. Using these ideas, we introduce a new definitionof logical consequence in the context of active logic, as well as a new definition of soundness such that, when reasoning withconsistent premises, all classically sound rules remain sound in our new sense. However, not everything that is classically soundremains sound in our sense, for by classical definitions, all rules with contradictory premises are vacuously sound, whereas in activelogic not everything follows from a contradiction.© 2007 Elsevier B.V. All rights reserved.Keywords: Logic; Active logic; Nonmonotonic logic; Paraconsistent logic; Semantics; Soundness; Brittleness; Autonomous agents; Time1. IntroductionReal agents have some important characteristics that we need to take into account when thinking about how theymight actually reason logically: (a) their reasoning takes time, meaning that agents always have only a limited, evolv-ing awareness of the consequences of their own beliefs,1 and (b) their knowledge is imperfect, meaning that someof their beliefs will need to be modified or retracted, and they will inevitably face direct contradictions and other in-* Corresponding author at: Department of Psychology, Franklin & Marshall College, P.O. Box 3003, Lancaster, PA 17604-3003, USA.E-mail addresses: michael.anderson@fandm.edu (M.L. Anderson), wgomaa@alex.edu.eg (W. Gomaa), jgrant@towson.edu (J. Grant),perlis@cs.umd.edu (D. Perlis).1 Levesque’s distinction between explicit and implicit beliefs [29] points to this same issue; however, our approach is precisely to model theevolving awareness itself, rather than trying to model the full set of (implicit) consequences of a given belief set.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.005\f1046M.L. Anderson et al. / Artificial Intelligence 172 (2008) 1045–1063consistencies. Indeed, real agents will not only often find their beliefs contradicted by experience, but will sometimesfind that their beliefs have been internally inconsistent for some time, although they are only now in a position tonotice this inconsistency, having derived a certain set of consequences that makes it apparent. The challenge from thestandpoint of classical logical formalisms is that, if an agent’s knowledge base can be inconsistent, then according toclassical logic, it is permissible to derive any formula from it.This fact about classical logics is commonly known by the Latin phrase ex contradictione quodlibet: from a con-tradiction everything follows. However, Graham Priest has coined the somewhat more vivid term explosive logics: alogic is explosive iff for all formulas A and B, (A&¬A) |= B. Priest defines a paraconsistent logic precisely as onewhich is not explosive [40–42]. Now, clearly real agents cannot tolerate the promiscuity of belief resulting from ex-plosive logics, and must somehow maintain control over their reasoning, watching for and dealing with contradictionsas they arise. The reasoning of real agents, that is, must be paraconsistent. But what sort of paraconsistent logic mightagents usefully employ, what methods might agents use to control inference and deal with contradictions, and howcan these logics (and methods) be modeled in terms of truth and consequence in structures?In the current paper we are primarily interested in the last of these questions. For some time we have been devel-oping, and have had significant practical success with a time-sensitive, contradiction-tolerant logical reasoning enginecalled the active logic machine (ALMA) [46]. Because ALMA was designed with the above challenges in mind,its underlying formalism, active logic [17,18,33,34], includes special rules controlling the inheritance of beliefs ingeneral (and of beliefs about the current time in particular), very tight controls on what can be derived from directcontradictions (P &¬P ), and mechanisms allowing an agent to represent and reason about its own beliefs and pastreasoning.Here we offer a semantics for a general version of active logic. We hope and expect it will be of interest as a specificmodel of formal reasoning for real-world agents that have to face both the relentlessness of time, and the inevitabilityof contradictions.In Sections 2–6 we will introduce the formal semantics for active logic, discuss a new definition of the conse-quence relation, and give examples of sound and unsound active logic inferences. This will be followed by some moreinformal discussion of the various properties of active logic (Section 7), a comparison of active logic with relatedapproaches (Section 8), and a discussion of the practical issues involved with the use of active logic in real-worldagents (Sections 9 and 10).2. A semantics for real-world reasoningIn this section we propose a semantics for a time-sensitive, contradiction-tolerant reasoning formalism, incorporat-ing the basic features of active logic.2.1. Starting assumptionsIn order to make the problem tractable for our first specification of the semantics, we will work under the followingassumptions concerning the agent, the world (i.e., everything apart from the agent), and their interactions:• There is only one agent a.• The agent starts its life at time t = 0 (t ∈ N) and runs indefinitely.• The world is stationary for t (cid:2) 0. Thus, changes occur only in the beliefs of the agent a.Given these assumptions, there is one and only one true complete theory of the world; however, given that theagent’s beliefs evolve over time, there is a different true complete theory of the agent for each time t.2.2. The language LIn order to express theories about such an agent-and-world, we define a sorted first-order language L. We defineit in two parts: the language Lw, a propositional language in which will be expressed facts about the world, and thelanguage La, a first-order language used to express facts about the agent, including the agent’s beliefs, for instance thatthe agent’s time is now t, that the agent believes P , or that the agent discovered a contradiction in its beliefs at a given\fM.L. Anderson et al. / Artificial Intelligence 172 (2008) 1045–10631047time. We write SnK to mean the set of sentences of any language K. We are using the complete set of connectives{¬, →} from which other connectives, such as ∧, and ∨, can be derived. We assume that double negations are removedfrom formulas. For the sentence symbols the subscripts are used to indicate different propositional sentences and, fora fixed subscript, the superscripts are used to indicate different apperceptions (see Section 4) of the agent of the sameproposition. The superscript 0 is used for the original sentence symbol (without superscript).Definition 1. Let Lw be a propositional language consisting of the following symbols:• a set S of sentence symbols (propositional or sentential variables) S = {Sji : i, j ∈ N} (N is the set of naturalnumbers)• the propositional connectives ¬ and →• left and right parentheses ( and )SnLw is the set of sentences of Lw formed in the usual way. These represent the propositional beliefs of the agent1 might mean “John is happy”. For later use we assume there is a fixed lexicographicabout the world. For instance S0ordering for the sentences in SnLw .Definition 2. Let σ, θ ∈ SnLw . We say that {σ, θ } is a direct contradiction if one of the following holds: either θ is theformula σ preceded by a negation, or σ is the formula θ preceded by a negation, that is θ = ¬σ or σ = ¬θ .Before giving the definition of the language La, we remark the following:i. In its current version La is a restricted form of first-order logic that is essentially propositional. In future work weintend to extend it to the full power of first-order logic.ii. La contains a belief predicate that captures the fact that the agent believed a certain proposition at some time t.We allow for sentences of the form: at time s the agent believed that she believed that she . . . . To allow for thisindefinite (however finite) nesting, the definition of La has to be inductive where at stage n + 1 all sentences fromthe previous levels are captured for the belief predicate.Definition 3. The language La is a sorted restricted version of first-order logic hav",
            {
                "entities": [
                    [
                        74,
                        133,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 97 ( 1997) 45-82 Artificial Intelligence A logical notion of conditional independence: properties and applications Adnan Darwiche * Department of Mathematics, American University of Beirut, PO. Box 11-236, Beirut, Lebanon Received October 1995; revised April 1996 Abstract formulations to propositional several equivalent independence with respect logic and study of the proposed notion, towards a specific application of logical reasoning such as abduction and diagnosis. a framework a independence logic database around a directed acyclic graph. This structuring explicates many of We propose a notion of conditional some of its key properties. We present each oriented We suggest propositional the independences that is not necessarily Horn. The we develop an algorithm structure and can be used for deciding entailment, algorithm computing abductions and diagnoses. The presented results are motivated by similar results in the literature on probabilistic and constraint-based reasoning. @ 1997 Elsevier Science B.V. satisfied by the underlying database. Based on these structural for a class of structured databases in the size of a database computationally by structuring independences, for utilizing is linear logical Keywords: Independence; Structure-based reasoning; Graphoids; Causal networks; Pruning knowledge bases; Relevance; Logic; Probability 1. Introduction A major factor in slowing down sider irrelevant parts of a given database when computing prompted a considerable of identifying reasoners tend to con- to queries. This has amount of research on the notion of irrelevance, with the goal so they can be avoided by logical these [ 13,15,23,24]. irrelevant parts of a database logical computations is that reasoners answers Irrelevance has also been the subject of extensive to as independence referred it is typically where research reasoning, in probabilistic [ 191. The scope of independence ’ Email: darwiche@aub.edu.lb 0004-3702/97/$17.00 PII SOOO4-3702(97)00042-8 @ 1997 Elsevier Science B.V. All rights reserved \f46 A. Danviche/Arti$cial Intelligence 97 (1997) 4.5-82 to be bigger than its scope there is a standard definition of independence in logic for at least two there in logic. This also contributes in probability, to be no agreement on a definition of irrelevance theory of logical Second, the computational irrelevance utility is perceived reasoning have not been based on irrelevance. This is contrary instead of a necessity since as a luxury reasoning where independence similar that irrelevance to the one for brings influential to is the building block of seems however, in probability, reasons. First, although seems to the lack of a comprehensive probabilistic to logical algorithms what one finds almost all state-of-the-art reasoning for logical in probabilistic independence. algorithms. Motivated by the role of independence can play a similar role in logical logic. Therefore, our definition of conditional reasoning, in probability, our goal in this paper is to show at least in the context of independence with respect independence with LCI, to of conditional Independence, resembles the definition distributions. We use Logical Conditional that independence propositional to propositional respect refer to the proposed definition. to probability databases here is not LCI per se, but rather Our contribution (a) (b) the framework we propose the various formulations ing tasks. for exploiting it computationally and of LCI that we provide with respect to different reason- for logical reasoning complexity of reasoning, We show that LCI introduces independence that conditional paradigm the computational of probabilistic clear how independence tasks. We utilize deciding abductions good example of how to use independence logical these formulations computing reasoning. The various entailment, reasoning. to propositional has introduced in which the amount of independence reasoning many of the tools and techniques to probabilistic reasoning. This includes a information decides the complexity controls just as independence of LCI formulations that we present make it can be computationally valuable to the corresponding reasoning by developing an algorithm and diagnoses. The algorithm provides information when deriving that can be used for a for algorithms In the following section, we provide a more extended notion of independence where we explain We also outline the structure of the paper in light of the results to be presented. introduction the choices we had to make in developing to the proposed it. 2. Key choices for independence When formulating a notion of independence, devote this section them. This helps in relating our approach It also provides a good opportunity to enumerating one faces a number of choice points. We some of these points and to presenting our position on to the spectrum of other existing approaches. for outlining the structure of the paper. What objects can appear sentences, dence relation a propositional in which predicates, even algorithms appear as part of an indepen- [ 131. In our proposal, four objects: database A and three sets of atomic propositions X, Y and 2. Specifi- relation? One finds proposals is a relation between in an independence atomic propositions, independence \fA. Darwiche/Art@cial Intelligence 97 (1997) 45-82 47 tally, LCI decides whether independence similar finds X independent to probabilistic of Y given Z. the holds, we write Indd (X, Z, Y) and refer to it as an LCI assertion. This is the database A finds X independent of Y given Z. When independence which tells us whether a probability distribution What decides literature on independence tions: the correctness of a definition of independence? (both probabilistic and logical), one finds In considering the two main posi- position and ( 1) A philosophical of independence ties. In most of these approaches, that is, formalizing change, [ 11,191. The probabilistic liefs on these grounds where belief ity. (2) A pragmatic position, where that starts with postulating then proposes a definition that adheres independence the irrelevance of certain notion of independence is formulated in a proposition corresponds some intuitive properties to these proper- in terms of belief to certain be- can clearly be motivated to its probabil- information one. That independence is not an absolute notion but rather is, there is no correct or incorrect definition of inde- in deciding the iden- test from A will not affect of independence may one. For example, if removed target the but rather a useful or not-very-useful test A k a, a definition of sentences in A that a task-specific pendence an entailment tification result. LCI, at least as developed provide different and equivalent a specific reasoning which are dual tasks. This computational leads in this paper, is meant formulations to be a pragmatic notion. of LCI, each explicating task. The tasks we cover are: deciding entailment abductions its usefulness and satisfiability, and diagnoses, which are also dual its of LCI that are meant to a total of four formulations tasks, and computing to explicate In fact, we to role in these different reasoning tasks. LCI, however, does have a formulation the closest one to probabilistic formulation satisfiability) and then lead into the other four formulations and Section 5 (abduction and diagnosis). based on belief change, which happens to be independence. We therefore start in Section 3 with this and in Section 4 (entailment to independence, independence be used computationally? How should approach task of interest. A very popular use of independence before attempting For example, the current practice a simpler irrelevant test A’ k LY, where A’ is obtained by removing to the test. If one is adopting a pragmatic then the usage of independence will depend on the reasoning a database for logical entailment, for reducing an entailment sentences test A t= CY into from A that are is to use independence though in testing certain computations. is in pruning Although LCI will support such usage, its main computational deciding for example, LCI will be used to decompose test A k LY into a number of local tests Al /= q, 42 k (~2, . . ., A,, k a,, where each A, is so small role is different. a global entailment entailment, test Ai b ai can be performed role of LCI, we point out that the following decom- in constant time. that its corresponding the computational To introduce In positions are generally not valid in logic: \f48 A. Danviche/Artijcial Intelligence 97 (1997) 45-82 ( 1) Entailment: Decomposing an entailment test A b a V p into two simpler tests A+aandA+p. (2) Satis$abiZity: Decomposing two tests with respect (3) Abduction: Decomposing of cy and those of p. (4) Diagnosis: Decomposing of LY and those of p. a satisfiability test with respect to A U {cr A p} into to the smaller databases A U {a} the abductions of a finding and A U {p}. (Y V /? into the abductions the diagnoses of an observation cu/\\p into the diagnoses We shall demonstrate, when certain ing in p. can be used tions. however, that each one of these decompositions independences hold between the atoms appearing becomes valid in (Y and those appear- In fact, Sections 4 and 5 provide examples of how such decompositions into a number of local computa- a global computation to decompose What is the source of independence to discover independence information Although strategy that is motivated by the following result: information ? Most existing approaches by pre-processing a given database [ 1517,231. attempt this is consistent with our utilization of independence, we advocate a different If a database A is graphically structured-that are dictated by a directed reveals many of the independences acyclic graph-then satisfied by the database. is, satisfies some conditions that the topology of the structure instead of automatically Therefore, we will propose explicating them by constructin",
            {
                "entities": [
                    [
                        74,
                        147,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 255–285www.elsevier.com/locate/artintAnyone but him: The complexity of precluding an alternative ✩Edith Hemaspaandra a, Lane A. Hemaspaandra b,∗, Jörg Rothe ca Department of Computer Science, Rochester Institute of Technology, Rochester, NY 14623, USAb Department of Computer Science, University of Rochester, Rochester, NY 14627, USAc Institut für Informatik, Heinrich-Heine-Universität Düsseldorf, 40225 Düsseldorf, GermanyReceived 1 February 2006; received in revised form 18 January 2007; accepted 29 January 2007Available online 7 February 2007AbstractPreference aggregation in a multiagent setting is a central issue in both human and computer contexts. In this paper, we studyin terms of complexity the vulnerability of preference aggregation to destructive control. In particular, we study the ability of anelection’s chair to, through such mechanisms as voter/candidate addition/suppression/partition, ensure that a particular candidate(equivalently, alternative) does not win. And we study the extent to which election systems can make it impossible, or compu-tationally costly (NP-complete), for the chair to execute such control. Among the systems we study—plurality, Condorcet, andapproval voting—we find cases where systems immune or computationally resistant to a chair choosing the winner nonethelessare vulnerable to the chair blocking a victory. Beyond that, we see that among our studied systems no one system offers the bestprotection against destructive control. Rather, the choice of a preference aggregation system will depend closely on which types ofcontrol one wishes to be protected against. We also find concrete cases where the complexity of or susceptibility to control variesdramatically based on the choice among natural tie-handling rules.© 2007 Elsevier B.V. All rights reserved.Keywords: Approval voting; Computational complexity; Computational resistance; Condorcet voting; Destructive control; Election systems;Plurality voting; Preference aggregation; Multiagent systems; Vote suppression1. IntroductionVoting provides a broad framework for collective decision-making. The literature on voting is vast and active, andspans such areas as AI, complexity, economics, operations research, and political science. As noted by Conitzer, Lang,and Sandholm [9], voting has been proposed as a mechanism for use in decision-making in various computational✩ Supported in part by grants NSF-CCR-0311021, NSF-CCF-0426761, DFG-RO-1202/9-1, and DFG-RO-1202/9-3, a Friedrich Wilhelm BesselResearch Award, and the Alexander von Humboldt Foundation’s TransCoop program. A preliminary version of this paper appeared in AAAI-05[E. Hemaspaandra, L. Hemaspaandra, J. Rothe, Anyone but him: The complexity of precluding an alternative, in: Proceedings of the 20th NationalConference on Artificial Intelligence, AAAI Press, 2005]. This work was done in part while the three authors were visiting Julius-Maximilians-Universität Würzburg, in part while the first two authors were visiting Heinrich-Heine-Universität Düsseldorf, and in part while the first author wason sabbatical at the University of Rochester.* Corresponding author.URLs: http://www.cs.rit.edu/~eh/ (E. Hemaspaandra), http://www.cs.rochester.edu/u/lane/ (L.A. Hemaspaandra),http://ccc.cs.uni-duesseldorf.de/~rothe/ (J. Rothe).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.005\f256E. Hemaspaandra et al. / Artificial Intelligence 171 (2007) 255–285settings, including planning [13,14] and collaborative filtering [29]. Voting also may be useful in many large-scalecomputer settings. Examples of much recent interest include the (web-page) rank aggregation problem, and relatedissues of reducing “spam” results in web search and improving similarity search, for which the use of voting systemshas been proposed [12,15]. In such an automated setting, it is natural to imagine decisions with thousands or millionsof “voters” and “candidates”.In Bartholdi, Tovey, and Trick’s seminal paper “How hard is it to control an election?” [3], the issue of constructivecontrol of election systems is studied: How hard is it for a chair (who knows all voters’ preferences) to—throughcontrol of the voter or candidate set or of the partition structure of an election—cause a given candidate (equivalently,alternative) to be the (unique) winner?To avoid any possible confusion, let us immediately stress that by “chair” we, following the use of Bartholdi, Tovey,and Trick [3], simply mean some entity that can carry out the given type of change to the structure of the election.Bartholdi, Tovey, and Trick probably chose to use the word “chair” because that role might typically be that of someauthority responsible for organizing the election and determining its structure. Note that the chair is not necessarilyone of the candidates, or the distinguished candidate c of our forthcoming problem specifications,1 or one of the voters(although we do not exclude these possibilities). (In particular, “chair” here does not mean “a special, designated voterwho if there is a tie is allowed to break the tie”—a meaning the term has in some other contexts, but not in this paper.)To avoid a different potential source of confusion, let us also immediately focus on the fact that in the Bartholdi,Tovey, and Trick [3] model, which is also adopted here, the chair has complete information on the voters’ preferences.This is a natural assumption in many, though certainly not all, situations.2 However, it is critical to note that since thecase where complete information is available to the chair is a special subcase of the more general setting that allowsinformation to be specified with any level of completeness, lower bounds obtained in the complete information settingare inherited by any natural incomplete information model (this point was made in this context even in the originalcontrol paper of Bartholdi, Tovey, and Trick [3]). This is worth stressing: All our NP-hardness results—obtained herein the model of complete information—are instantly inherited by any natural incomplete information model (e.g.,models in which missing preferences are filled in by an adversary of the chair; models in which missing preferencesare filled in as favorably for the chair’s goal as possible; models in which the chair must find an action that underat least k (k would be part of the input) of all possible completions of the unknown information allows the chair toobtain his/her desired outcome; models in which the chair must find an action that under at least 99 percent of allpossible completions of the unknown information allows the chair to obtain his/her desired outcome; etc.). Anotherangle to approach this from would be to note that our lower-bound results are sufficiently strong that they show thateven when the chair has all the information he or she could possibly ask for about preferences—namely, completeinformation—his/her task is nonetheless still NP-hard in many cases. Simply put, the complete-information modelis actually, as a matter of complexity-theoretic basics, a more challenging one in which to prove NP-hardness lowerbounds than a partial-information model would be (although the authors realize that this may seem counterintuitive).Bartholdi, Tovey, and Trick studied plurality and Condorcet voting, and seven natural types of control: addingcandidates, suppressing candidates, partition of candidates, run-off partition of candidates, adding voters, suppressingvoters, and partition of voters. They found that in some cases there is immunity to constructive control (if his/her1 It certainly is the case that in our model the chair will be trying to make the distinguished candidate c win. And so there will be many naturalsituations in which c and the chair coincide. However, that need not always be the case. It is possible to envision situations in which c does not wantc to win (e.g., elections for the chair of an academic department in which some faculty member out of duty would be willing to serve if electedbut would far rather someone else serve; or elections for who gets “removed from the island” on some reality TV show) or situations, even when cdoes want c to win, in which the actor working to make c win is someone other than c (e.g., in particularly bare-knuckled academic faculty hiring,a department chairperson might set a vote date when certain faculty members are out of town, as an attempt to help a certain one of the externalapplicants).2 For example, in a computer science department, after endless discussions, most people know what each person’s position is on key issues. Thisis an example of a rather small-scale, intimate, private election. Of course, one might reasonably point out that large-scale public elections amonghumans are examples where, though polling data may give some information, typically no one will know all voters’ preferences. However, we notethat, as mentioned in the paragraph to which this is a footnote, our lower-bound (NP-hardness) results for the case of complete information implyNP-hardness in the case of essentially any natural partial-information model. We also point out that large-scale elections among electronic agentsmight well have complete preference information available to the chair. (Even in cases of large-scale human elections, there are relatively broadsources of information, such as party affiliation information in voter registration records. Although this certainly isn’t perfectly predictive, it mightwell be useful in attempts, for example, to gerrymander district boundaries or even, and this is in some rough sense an example of control by addingvoters, to target get-out-the-vote drives.)\fE. Hemaspaandra et al. / Artificial Intelligence 171 (2007) 255–285257candidate was not already the3 unique winner, no action of the specified type by the chair can make the candidate theunique winner), in some cases there is (computational) res",
            {
                "entities": [
                    [
                        72,
                        131,
                        "TITLE"
                    ],
                    [
                        2724,
                        2783,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 106 (1998) 109-137 Artificial Intelligence Uncertainty measures of rough set prediction Ivo Diintsch a~b~*~2, Giinther Gediga btc* 1$2 a School of Inforrnarion and Sofbvare Engineering, University of Ulster; Newtownabbey BT 37 OQB, UK b Instirut fir Semantische Infomationsverarbeitung, Universitiit Osnabriick, 49069 Osmbriick, Germany ’ FB PsychologieMethodenlehre, 49069 Osnabriick, Germany Universitiit Osmbtick, Received 14 July 1997; received in revised form 19 March 1998 Abstract The main statistics used in rough set data analysis, the approximation quality, is of limited value when there is a choice of competing models for predicting a decision variable. In keeping within the rough set phillosophy of non-invasive data analysis, we present three model selection criteria, using information length principle. Our main in the spirit of the minimum description procedure is based on the principle of indifference combined with the maximum entropy principle, to a minimum. The applicability of the proposed method thus keeping external model assumptions is demonstrated by a comparison of its error rates with results of C4.5, using 14 published data sets. @ 1998 Elsevier Science B.V. All rights reserved. theoretic entropy Keywords: Rough set model; Minimum description length principle; Attribute prediction 1. Introduction Most of the commonly used procedures the observed phenomena, or presuppose and are subject analysis, to random influences, regression, or correlation may be applied. for data prediction require parameters outside character in order that statistical methods such as variance that the properties are of a quantitative One methiod which avoids external parameters (RSDA); it has been developed by Z. Pawlak and his co-workers since the early 1970s [15,16,20,21], and has recently received wider attention as a means of data analysis [23]. The rationale of the rough set model is the observation is rough set dutu analysis that author. Email i.duentsch@ulst.ac.uk. * Corresponding 1 Email: ggetiga@Luce.Psycho.Uni-Osnabrueck.DE. implied. 2 Equal authorship 0004-3702/98/,$ PII: SOOO4-3702(98)00091-5 - see front matter 0 1998 Elsevier Science B.V. All rights reserved. \f110 I. Diintsch, G. Gediga /Artijicial Intelligence 106 (1998) 109-137 “The imprecision granularity ambiguity information about a decision from many is usually vague because of uncertainty and . Vagueness may be caused by an of the information. Granularity may sources . . . coming of representation to explanation or prescription based on vague information” introduce [24]. In other words, the original concept behind be described “roughly”: an object has a property the model is the realization that sets can only 0 CERTAINLY, l POSSIBLY, 0 CERTAINLY NOT. function internal knowledge, This looks conspicuously logical level, we can say that the algebraic semantic of a rough set logic corresponds fuzzy logic with a three-valued membership like a fuzzy membership function, and indeed, on the algebraic- (see [8,19]). to a Rough set analysis uses only and does not rely on prior model as fuzzy set methods or probabilistic models do. In other words, instead of assumptions rough set analysis utilizes solely using external numbers or other additional parameters, the granularity structure of the given data, expressed as classes of suitable equivalence relations. Of course, this does not mean that RSDA does not have any model assumptions; for example, we indicate below that the statistical model behind RSDA is the pn’nciple of indifference. However, model assumptions ignorance of what happens within the region of indiscernibility, (see Section 2.1). given by the granularity of information are such that we admit complete The results of RSDA must be seen with this background as possible in mind: the rough set model from the structural aspects of the data, of the attribute and can serve as a valuable information and other contextual to a minimum, tries to extract as much information neglecting, domains. This keeps model assumptions indicator of the direction in its pure form, numerical into which possible further analysis can go. The relationship between RSDA and statistical modeling is quite complementary (see Table l), and we have discussed it in more detail in [lo]. Knowledge representation are a tabular form of an OBJECT -+ ATTRIBUTE VALUE relationship, databases (see Section 2.2). in the rough set model is done via information systems which similar to relational If Q is a set of predictor features and d a decision attribute, then RSDA generates rules of the form xq=mq~xd=m~Vxd=m~V~~~Vxd=m~, A qEQ where X’ is the attribute value of object n with respect to attribute r. (1.1) Table 1 RSDA versus statistical modeling RSDA Statistical models Many features/attributes, few data points Few variables, many data points Describing redundancy Top down, reducing the full attribute set Reducing uncertainty Bottom up, introducing new variables \fI. Diintsch, G. Gediga /Artijcial Intelligence 106 (1998) 109-137 111 We see that in the rough set model that on the right hand side of (1.1) we can have a proper disjunction. If there is only on term on the right hand side, we call the rule deterministic. Whereas RSDA handles rules deterministic remains unclear. the status of the indeterministic in a straightforward manner, rules can be indeterministic in the sense rules If rules are based on a few observations only, the granularity of the system is too high, and the rule may be due to chance. In order to test the significance of rules, one can use that randomization methods the null hypothesis the conditional probability of the rule, assuming to compute “objects are randomly assigned to decision classes” two simple procedures, both based on randomization is true. In [I 11 we have developed techniques, which evaluate the validity of prediction based on the principle of indifference, which Section 2.4. statistics of RSDA; is briefly described is the underlying technique this in Although randomization methods are quite useful, they are rather expensive in resources, and are only applicable as a conditional testing scheme: a though they tell us when a rule may be due to chance, they do not provide us with a metric :for the comparison of two different rules Q + d, R-+ d, let alone for different models of uncertainty. Thus, we need a different criterion for model selection: the minimum description length (MDLP) (see [27,28]) states that the best theory to explain a given phenomenon principle d is one which minimizes the sum of l the binary l the binary predictor. length of encoding a hypothesis Q and length of encoding the decision data d using the hypothesis Q as a In the sequel, we present on three different probability distributions frame M, the attractiveness of this approach rules such as (1.1) is considered the aggregate of the three different ways of model selection within RSDA, based in the spirit of the MDLP. Within each model about the uncertainty of in a context where the selection criterion H M (Q + d) is is that information l effort of coding a hypothesis Q, expressed by an entropy function H(Q), and l uncertainty to classify a randomly chosen observation given this hypothesis, expressed as a suitable entropy in terms of the optimal number of decisions of “guessing” H”(d I Q>. the basic tools of RSDA and The paper i,s organized as follows: their main properties, as well as our usage of the entropy functions. Section 3 contains our three approaches to some well known data sets. Finally, Section 5 consists of a summary and an outlook. and Section 4 applies our main approach in Section 2 we describe to uncertainty, \f112 I. Diintsch, G. Gediga /Artijicial Intelligence 106 (1998) IO%137 2. Basic tools and constructions 2. I. Approximation spaces An equivalence 8 on a set U is a transitive, reflexive, and symmetric binary relation, and we call the pair (U, 0) an approximation space. In our context, we shall sometimes call an equivalence spaces are the core mathematical of information the idea that granulation relation. relation an indiscernibility relation. Approximation can be described by classes of an indiscernibility concept of RSDA, and their usage reflects Recall that a partition P of a set U is a family of nonempty, pairwise disjoint subsets of relation 8 we associate a partition PO of U by that a, b E U are in the same class of PQ, if and only if aOb. The classes of PO U whose union is U. With each equivalence specifying have the form @a = {b E U: aeb}. By some abuse of language, we also speak of the classes of an equivalence we mean the classes of its associated partition, and call 8a the class ofa mod&o 8. relation when The interpretation only up to membership limited to the classes of 6’ and their unions. This leads to the following definition: in rough set theory is that our knowledge of the objects in U extends in the classes of 8, and our knowledge about a subset X of U is For X C U, we say that is the lower approximation or positive region of X, and XEf U{ex: x E xl is the upper approximation or possible region of X. If X C U is given by a predicate P and x E U, then (1) x E X means that x certainly has property P, (2) x E x means that x possibly has property P, (3) x E U \\ x means that x definitely does not have property P. The area of uncertainty extends over X\\X, and the area of certainty is XU-x. 2.2. Information systems Knowledge representation in RSDA is done via relational tables. An information system z = (UT a, vq, fq&? consists of: \fI. Diintsch, G. Gediga /Artificial Intelligence 106 (1998) 109-137 113 Boundary of Set X Lower approximation of X _...;:;.. .: . . . . . . . .._.. _. :.:.:/~.~..: Difference of upper and lower approximation of X Fig. 1. Rough approximation. (1) a finite set U of objects; (2) a finite set 0 of attributes; (3) for each q E i2 l a set V, of attribute values, l an information function f4 : U + V,. In the sequel ",
            {
                "entities": [
                    [
                        67,
                        111,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 220–257Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAdversarial patrolling with spatially uncertain alarm signalsNicola Basilico a,∗a Department of Computer Science, University of Milan, Milano, Italyb Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy, Giuseppe De Nittis b, Nicola Gatti ba r t i c l e i n f oa b s t r a c tArticle history:Received 15 June 2015Received in revised form 6 August 2016Accepted 26 February 2017Available online 4 March 2017Keywords:Security gamesAdversarial patrollingAlgorithmic game theoryWhen securing complex infrastructures or large environments, constant surveillance of every area is not affordable. To cope with this issue, a common countermeasure is the usage of cheap but wide-ranged sensors, able to detect suspicious events that occur in large areas, supporting patrollers to improve the effectiveness of their strategies. However, such sensors are commonly affected by uncertainty. In the present paper, we focus on spatially uncertain alarm signals. That is, the alarm system is able to detect an attack but it is uncertain on the exact position where the attack is taking place. This is common when the area to be secured is wide, such as in border patrolling and fair site surveillance. We propose, to the best of our knowledge, the first Patrolling Security Game where a Defenderis supported by a spatially uncertain alarm system, which non-deterministically generates signals once a target is under attack. We show that finding the optimal strategy is FNP-hard even in tree graphs and APX-hard in arbitrary graphs. We provide two (exponential time) exact algorithms and two (polynomial time) approximation algorithms. Finally, we show that, without false positives and missed detections, the best patrolling strategy reduces to stay in a place, wait for a signal, and respond to it at best. This strategy is optimal even with non-negligible missed detection rates, which, unfortunately, affect every commercial alarm system. We evaluate our methods in simulation, assessing both quantitative and qualitative aspects.© 2017 Elsevier B.V. All rights reserved.1. IntroductionSecurity Games model the task of protecting physical environments as a non-cooperative game between a Defender and an Attacker [1]. These games usually take place under a Stackelberg (a.k.a. leader–follower) paradigm [2], where the Defender (leader) commits to a strategy and the Attacker (follower) first observes such commitment and then best responds to it. As discussed in the seminal work [3], finding a leader–follower equilibrium is computationally tractable in games with one follower and complete information, while it becomes hard in Bayesian games with different types of Attacker. The availability of such computationally tractable aspects of Security Games led to the development of algorithms capable of scaling up to large problems, making them deployable in the security enforcing systems of several real-world applications. The first notable examples are the deployment of police checkpoints at the Los Angels International Airport [4] and the scheduling of federal air marshals over the U.S. domestic airline flights [5]. More recent case studies include the positioning of U.S. Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7]. Finally, a similar approach is being tested and evaluated in Uganda, Africa, for the * Corresponding author.E-mail address: nicola.basilico@unimi.it (N. Basilico).http://dx.doi.org/10.1016/j.artint.2017.02.0070004-3702/© 2017 Elsevier B.V. All rights reserved.\fN. Basilico et al. / Artificial Intelligence 246 (2017) 220–257221protection of wildlife [8]. Thus, Security Games emerged as an interesting game theoretical tool and then showed their on-the-field effectiveness in a number of real security scenarios.We focus on a specific class of security games, called Patrolling Security Games. These games are modeled as infinite-horizon extensive-form games in which the Defender controls one or more patrollers moving within an environment, represented as a finite graph. The Attacker, besides having knowledge of the strategy to which the Defender committed to, can observe the movements of the patrollers at any time and use such information in deciding the most convenient time and target location to attack [9]. When multiple patrollers are available, coordinating them at best is in general a hard task which, besides computational aspects, must also keep into account communication issues [10]. However, the patrolling problem is tractable, even with multiple patrollers, in border security (e.g., line and cycle graphs), when patrollers have homogeneous moving and sensing capabilities and all the vertices composing the border share the same features [11]. Scal-ing this model involved the study of how to compute patrolling strategies in scenarios where the Attacker is allowed to perform multiple attacks [12]. Similarly, coordination strategies among multiple defenders are investigated in [13]. In [14], the authors study the case in which there is a temporal discount on the targets. Extensions are discussed in [15], where coordination strategies between defenders are explored, in [16], where a resource can cover multiple targets, and in [17]where attacks can be detected at different stages with different associated utilities. Finally, some theoretical results about properties of specific patrolling settings are provided in [18]. In the present paper, we provide a new model of Patrolling Security Games in which the Defender is supported by an alarm system deployed in the environment.1.1. Motivating scenariosOften, in large environments, a constant surveillance of every area is not affordable while focused inspections triggered by alarms are more convenient. Real-world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], surveillance based on wireless sensor networks [22], and border patrolling [23]. Alarm systems are in practice affected by detection uncertainty, e.g., missed detections and false positives, and localization (a.k.a. spatial) uncertainty, e.g., the alarm system is uncertain about the exact target under attack. We summarily describe two practical security problems that can be ascribed to this category. We report them as examples, presenting features and requirements that our model can properly deal with. In the rest of the paper we will necessarily take a general stance, but we encourage the reader to keep in mind these two cases as reference applications for a real deployment of our model.1.1.1. Fight to illegal poachingPoaching is a widespread environmental crime that causes the endangerment of wildlife in several regions of the world. Its devastating impact makes the development of surveillance techniques to contrast this kind of activities one of the most important matters in national and international debates. Poaching typically takes place over vast and savage areas, making it costly and ineffective to solely rely on persistent patrol by ranger squads. To overcome this issue, recent developments have focused on providing rangers with environmental monitoring systems to better plan their inspections, concentrating them in areas with large likelihood of spotting a crime. Such systems include the use of UAVs flying over the area, alarmed fences, and on-the-field sensors trying to recognize anomalous activities.1 In all these cases, technologies are meant to work as an alarm system: once the illegal activity is recognized, a signal is sent to the rangers base station from where a response is undertaken. In the great majority of cases, a signal corresponds to a spatially uncertain localization of the illegal activity. For example, a camera-equipped UAV can spot the presence of a pickup in a forbidden area but cannot derive the actual location to which poachers are moving. In the same way, alarmed fences and sensors can only transmit the location of violated entrances or forbidden passages. In all these cases a signal implies a restricted, yet not precise, localization of the poaching activity. The use of Security Games in this particular domain is not new (see, for example, [8]). However, our model allows the computation of alarm response strategies for a given alarm system deployed on the field. This can be done by adopting a discretization of the environment, where each target corresponds to a sector, values are related to the expected population of animals in that sector, and deadlines represent the expected completion time of illegal hunts (these parameters can be derived from data, as discussed in [8]).1.1.2. Safety of fair sitesFairs are large public events attended by thousands of visitors, where the problem of guaranteeing safety for the hosting facilities can be very hard. For example, Expo 2015, the recent Universal Exposition hosted in Milan, Italy, saw an average of about 100,000 visits per day. This poses the need for carefully addressing safety risks, which can also derive from planned act of vandalism or terrorist attacks. Besides security guards patrols, fair sites are often endowed with locally installed monitoring systems. Expo 2015 employed around 200 baffle gates and 400 metal detectors at the entrance of the site. The internal area was constantly monitored by 4000 surveillance cameras and by 700 guards. Likely, when one or more of these devices/personnel identified a security breach, a signal was sent to the control room together with a circumscribed request of intervention. This approach is required because, especially in this kind of environments, detecting a security breach 1 See, for example, http :/ /wildlandsecurity.org/.\f222N. Basilico et al. / Artificial",
            {
                "entities": [
                    [
                        136,
                        197,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 865–888Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProperty persistence in the situation calculusRyan F. Kelly, Adrian R. Pearce∗Department of Computer Science and Software Engineering, The University of Melbourne, Victoria 3010, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 25 May 2009Received in revised form 6 May 2010Accepted 6 May 2010Available online 8 May 2010Keywords:Situation calculusAutomated reasoningProperty persistence1. IntroductionWe develop a new automated reasoning technique for the situation calculus that canhandle a class of queries containing universal quantification over situation terms. Althoughsuch queries arise naturally in many important reasoning tasks, they are difficult toautomate in the situation calculus due to the presence of a second-order induction axiom.We show how to reduce queries about property persistence, a common type of universally-quantified query, to an equivalent form that does not quantify over situations and so isamenable to existing reasoning techniques. Our algorithm replaces induction with a meta-level fixpoint calculation; crucially, this calculation uses only first-order reasoning with alimited set of axioms. The result is a powerful new tool for verifying sophisticated domainproperties in the situation calculus.© 2010 Elsevier B.V. All rights reserved.The situation calculus is one of the most popular and influential AI formalisms for reasoning about action and change,having found application in a wide variety of both theoretical and practical works [5,6,9,26,27,30]. A major contributorto the success of the formalism is that it combines a powerful modelling language built on first-order logic with easilyimplementable techniques for effective automated reasoning.A key challenge when working with the situation calculus is managing this balance between expressivity and effective-ness. An induction axiom is used to define the structure of situation terms, so answering arbitrary queries requires reasoningin second-order logic. While certain special cases are known to be decidable [31], such reasoning is prohibitively expensivein general [24].If queries are restricted to certain syntactic forms, it is possible to obtain much more effective reasoning procedures –for example, queries restricted to existential quantification over situations can be answered using only first-order logic [23],while queries containing only ground situation terms permit special-purpose techniques such as regression [26].However, there are many important reasoning tasks that require universal quantification over situations, for which thesituation calculus currently offers no effective reasoning tools. One simple example is the problem of goal impossibility –establishing that all possible situations fail to satisfy a goal. In this paper we study a subset of universally-quantified querieswhich we refer to as property persistence queries: under a particular situation calculus theory D, and given some formula φand situation σ , determine whether φ will hold in all situations in the future of σ :D |(cid:3) ∀s: σ (cid:5) s → φ[s]The need for second-order logic has traditionally limited automated reasoning about such queries. We introduce a newapproach to property persistence that is similar in spirit to the standard regression operator, by defining a meta-level* Corresponding author. Tel.: +613 8344 1399; fax: +613 9348 1184.E-mail addresses: rfk@csse.unimelb.edu.au (R.F. Kelly), adrianrp@unimelb.edu.au (A.R. Pearce).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.003\f866R.F. Kelly, A.R. Pearce / Artificial Intelligence 174 (2010) 865–888operator PD such that φ persists at σ if and only if PD(φ) holds at σ . We term the resulting formula the persistencecondition of φ and show how to calculate it as a fixpoint of applications of an operator based on regression; crucially, thiscalculation requires only first-order logic and a limited set of axioms. The persistence condition is also guaranteed to be ina form amenable to existing automated reasoning techniques.Importantly, our results do not require restrictions on the domain theory D – they are generally applicable to the fullfirst-order situation calculus, and are based purely on standard first-order reasoning techniques.The result is a powerful new technique for exploring sophisticated domain properties in the situation calculus. It allowssome second-order aspects of the theory to be “factored out” and handled using a special-purpose algorithm. The techniqueis always sound, and we show that it is complete for important standard variants of the situation calculus. Perhaps mostimportantly, it builds upon and integrates well with standard techniques for effective automated reasoning, so our techniqueis directly applicable to existing theories and systems based on the situation calculus.A preliminary version of this paper has previously appeared as [15]; this revised edition includes extended and additionalproofs, a more comprehensive discussion of the termination properties of our algorithm, and a detailed example of how thepersistence condition can be used to reason about goal impossibility – a deceptively simple task which is nonethelessbeyond the reach of existing reasoning techniques.The paper now proceeds with a brief review of the situation calculus, before formally defining the persistence conditionand establishing its effectiveness as a reasoning tool. Readers familiar with the situation calculus are encouraged to reviewthe background material in Sections 2 and 4, as we make several small modifications to the standard notation that greatlysimplify the development of our approach: the unique names axioms Duna are incorporated into a general backgroundtheory Dbg ; the Poss fluent is subsumed by a general class of action description predicates defined in Dad; we parameterisethe “future situations” predicate s (cid:2) s; and weuse the single-step variant of the regression operator, with corresponding definitions of regressable formulae.to assert that all intermediate actions satisfy a given predicate using s <α s(cid:7)(cid:7)2. The situation calculusThe situation calculus is a powerful formalism for describing and reasoning about dynamic worlds. It was first introducedby McCarthy and Hayes [22] and has since been significantly expanded and formalised [23,26]. We use the particular variantdue to Reiter et al. at the University of Toronto, sometimes called the “Toronto school” or “situations-as-histories” version.The formalisation below is based on the standard definitions from [16,23,25], with some simple modifications.The language Lsitcalc of the situation calculus is a many-sorted language of second-order logic with equality, containingthe following disjoint sorts:• Action terms denote individual instantaneous events that can cause the state of the world to change;• Situation terms are histories of the actions that have occurred in the world, with the initial situation represented by S 0and successive situations built using the function do : Action × Situation → Situation;• Object terms represent any other object in the domain.Fluents are predicates representing properties of the world that may change between situations, and so take a situationterm as their final argument. Predicates and functions that do not take a situation term are called rigid. We use the termprimitive fluent to describe fluents that are directly affected by actions, rather than being defined in terms of other fluents.No functions other than S0 and do produce values of sort Situation. For the sake of clarity we will not consider functionalfluents in this paper; this is a common simplifying assumption in the situation calculus literature and does not result in aloss of generality.Lsitcalc contains the standard alphabet of logical connectives, constants (cid:8) and ⊥, countably infinitely many variables ofeach sort, countably infinitely many predicates of each arity, etc.; for a complete definition, consult the foundational paperby Pirri and Reiter [23]. We follow standard naming conventions for the situation calculus: upper-case roman names indicateconstants; lower-case roman names indicate variables; Greek characters indicate meta-variables or formula templates. Allaxioms universally close over their free variables at outermost scope. The notation ¯t indicates a vector of terms of context-appropriate arity and type. The connectives ∧, ¬, ∃ are taken as primitive, with ∨, →, ≡, ∀ defined in the usual manner.Complex properties of the state of the world are represented using uniform formulae. These are basically logical combi-nations of fluents referring to a common situation term.Definition 1 (Uniform formulae). Let σ be a fixed situation term, R i an arbitrary rigid predicate, F i an arbitrary primitivefluent predicate, τi an arbitrary term that is not of sort Situation, and xi an arbitrary variable that is not of sort Situation.Then the formulae uniform in σ are the smallest set of syntactically-valid formulae satisfying:φ ::= F i( ¯τi, σ ) | R i( ¯τi) | τi = τ j | φi ∧ φ j | ¬φ | ∃xi: φWe will call a formula uniform if it is uniform in some situation. The important aspect of this definition is that theformula refers to no situation other than σ , which appears as the final argument of all fluents in the formula. In particular,uniform formulae cannot quantify over situations or compare situation terms, and cannot contain non-primitive fluents.\fR.F. Kelly, A.R. Pearce / Artificial Intelligence 174 (2010) 865–888867The meta-variable φ is used throughout to refer to an arbitrary uniform formula. The notation φ[s(cid:7)] represents a uniformformula with the particular situation sinserted into all its fluents, replacing whatever situation term was previously there.Note that this is simply a syntactic shorthand designed to",
            {
                "entities": [
                    [
                        136,
                        182,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 94 (1997) 7-56 Artificial Intelligence The independent choice logic for modelling multiple agents under uncertainty David Poole * Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver; BC, Canada V6T I24 Abstract Inspired by game theory representations, Bayesian networks, influence diagrams, structured Markov decision process models, logic programming, and work in dynamical systems, the inde- pendent choice logic (ICL) is a semantic framework that allows for independent choices (made by various agents, including nature) and a logic program that gives the consequence of choices. This representation can be used as a specification for agents that act in a world, make observa- tions of that world and have memory, as well as a modelling tool for dynamic environments with uncertainty The rules specify the consequences of an action, what can be sensed and the utility of outcomes. This paper presents a possible-worlds semantics for ICL, and shows how to embed in- fluence diagrams, structured Markov decision processes, and both the strategic (normal) form and extensive (game-tree) form of games within the ICL. It is argued that the ICL provides a natural and concise representation for multi-agent decision-making under uncertainty that allows for the representation of structured probability tables, the dynamic construction of networks (through the use of logical variables) and a way to handle uncertainty and decisions in a logical representation, @ 1997 Elsevier Science B.V. 1. Introduction This paper presents the Independent Choice Logic (ICL), agents under uncertainty. [ 7,351, representations multiple networks tured agent ma,delling and dynamical and change influence diagrams of Bayesian [ 27,45,50]. It is inspired by game theory a logic for modelling [ 17,32,53], Bayesian networks [ 22,231, probabilistic Horn abduction [ 361, struc- [ 5,7,8], [ 29,48,5 1,571 and logical modelling of action and Markov decision processes systems * Email: poole@cs.ubc.ca. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PZI s0004~-3702(97)00027-1 \f8 D. Poole/Artijcial Intelligence 94 (1997) 7-56 First we motivate ICL from a number of different perspectives, (Section of knowledge 1.3), representation the paradigms the foundations it fits within subsections we present theory (Section then build this paper presents examples of the use of the logic, including diagrams, Markov decision processes, can be represented. diagrams of the representation influence the formal definition (Section of ICL based on agents 1.4) and logic and the strategic and extensive then show how In separate 1.2), game 1.5). We (Section in Section 2. The majority of 1.1). (Section showing how influence forms of games than tests), amongst rule-based framework its parents represented probabilities representation is exponentially of independence of variables given for the conditional probability in the network. The conditional as tables, but can often be specified more compactly the rule representation, that there agents, so that not only can the knowledge base be expressed compactly [ 351 provide a useful representation are a representation for reasoning under Bayesian or belief networks uncertainty. Bayesian networks random variables. The Bayesian network model does not constrain how a variable depends on its of a variable parents, nor does it specify a representation their given parents are typically in than trees (unless terms of trees [ 71 or rules [ 361. Rules are more compact the trees can in the sense have shared structure and redundant that there are some functions larger the tree representation where the converse does not hold.’ Rules have the added advantage extension [ 361, a first-order as failure and fewer restriction on the rules paper extends the probabilistic multiple rules, but agents’ policies can also be expressed by rules. the primary but is a natural to the first-order case [ 361. This paper builds on probabilistic Horn abduction for Bayesian networks, allowing negation than in probabilistic Horn abduction. This and decisions made by to include utilities by is in AI. This to specify what because It has often been you want argued scheme must be at least as rich as the first-order predicate calculus. One of the problems with the first order predicate calculus a rather blunt reasoning under uncertainty. Rather calculus theory, uncertainty, In the ICL, we start with a logic does instead of disjunction, not include any uncertainty theory entails exactly one of p or up for all propositions p). Agents own alternatives, which are sets that it owns. of propositions. An agent gets to choose one value from each alternative Nature is a special agent; the alternatives owned by nature have a probability distribution over them. The logic gives is in to the first-order predicate and probabilistic of how it is computed representation representation and a way [42]. which would entail having both disjunctive of the choices made by nature and the and is definitive on all propositions is the way it handles uncertainty; that we should use probability and does not do justice [33] ) that any general than adding uncertainty to all of the subtleties to handle uncertainty. This involved focus of knowledge this paper proposes Logic has become all it has available the consequences to give meaning is disjunction. and decision independently [ 3,19,20,24], to compute to symbols it provides instrument a way (every (e.g., ’ As we allow negation as failure in the roles, the rules can be seen as a DNF definition of a concept Clark’s completion when converted leaf in the decision [ 111). It is known that DNF formulae to decision trees [ 461. Decision tree whose body corresponds trees can be converted to the path to the leaf. (using sometimes entail an exponential blow up in size to mles, with a role for each simply \fD. Poole/Artificial Intelligence 94 (1997) 7-56 9 agents. This allows us to have the advantages of logic, with symbols denotations, specifications lets us use the normative agent should do. of valid consequences tools of decision/game theory notions and first-order representations, that can be given but also to determine what an in systems [ 29,441) referring functions the state (see e.g., and describe a state space terms of Bayesian Models, of dynamical [ 121 or even more concisely in terms of matrices. in terms of propositions, in terms of these propositions. The state transition networks been described have traditionally treating state spaces in terms of vectors of states It is often much more convenient transition function can be stated con- [ $81 is loga- local, the in the size of the state space. The effects of actions are typically the poten- only on a few other variables. This provides of the propositional In the in terms of rules. One advantage of rules cal- to also and dynamic program- in terms of state spaces, for example and state transition to describe function cisely or rules 11401, never rithmic value of a variable depending tial ICL we specify state is that they are closer [ 3 1 ] (see culus the stage or situation make helps clarify ming. to take advantage of the compactness functions transition to the traditional AI representations [ 401) . The first-order nature of the rules, with explicit the rules perspicuous. The rule based representation state. The number of variables such as the situation the close relationship regression planning to the explicit representation. reference by trees between 1.1. Knowledge representation representation should be. There axe two different views of what a knowledge l The first is that a knowledge representation should let users state whatever knowl- this view it is not appropriate to specify how a piece of knowl- follows from the facts in a common sense manner. An example of can conclude what logically representation represen- to let us state many facts about the world, but logics have been for knowledge this tradition, edge they have in a reasonably natural way. Under for the designer of a knowledge edge should be encoded. Reasoning stated facts or can fill in missing this view is in the use of the first-order predicate calculus tation. It is a rich enough with primitive means deve:loped 21, ;!4]. Missing maximum the user can add whatever should be able to make appropriate l The second view is that a knowledge entropy or random worlds assumptions to handle uncertainty. Within to handle uncertainty facts can be inferred using default reasoning [ 41. What inferences. language they like to the knowledge base, and the representation and multiple agents making decisions [3,15,19- [ 301, or by making is that is important language representation symlbolic modelling view a knowledge guide users as to how they should and once some choices have been made, be specified. An example tool for representing specify the random variables of interest, independence representation that makes some things easier should provide a high-level this It should think about the domain, what they should say; to should specify how to model a domain. it prescribes what information to state. Under needs is Bayesian networks [ 351, which provide a modelling amongst random variables. The user needs to these variables can take, and the values \f10 D. Poole/Artificial Intelligence 94 (1997) 7-56 the dependency amongst these variables. Once these are specified the Bayesian network model prescribes what probabilities need to be specified. It is important not to confuse these, as judging a knowledge representation by the inappropriate criteria will lead to an unfair judgment. The knowledge representation in this paper should be seen as an instance of the second. We do not expect that people will be able to just throw any knowledge in. For example, missing rules have a particular meaning; if you want to assert ignorance there are specific ways to do it. 1.2. Agents An agent is somethin",
            {
                "entities": [
                    [
                        63,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1917–1939Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMechanisms for information elicitationAviv Zohar∗, Jeffrey S. RosenscheinSchool of Engineering and Computer Science, The Hebrew University of Jerusalem, Jerusalem, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 22 March 2007Received in revised form 11 July 2008Accepted 10 August 2008Available online 23 August 2008Keywords:Information elicitationMechanism designInformation tradeWe study the computational aspects of information elicitation mechanisms in which aprincipal attempts to elicit the private information of other agents using a carefullyselected payment scheme based on proper scoring rules. Scoring rules, like many othermechanisms set in a probabilistic environment, assume that all participating agents sharesome common belief about the underlying probability of events. In real-life situationshowever, the underlying distributions are not known precisely, and small differences inbeliefs of agents about these distributions may alter their behavior under the prescribedmechanism.We examine two related models for the problem. The first model assumes that agentshave a similar notion of the probabilities of events, and we show that this approach leadsto efficient design algorithms that produce mechanisms which are robust to small changesin the beliefs of agents.In the second model we provide the designer with a more precise and discrete set ofalternative beliefs that the seller of information may hold. We show that constructionof an optimal mechanism in that case is a computationally hard problem, which is evenhard to approximate up to any constant. For this model, we provide two very differentexponential-time algorithms for the design problem that have different asymptotic runningtimes. Each algorithm has a different set of cases for which it is most suitable. Finally, weexamine elicitation mechanisms that elicit the confidence rating of the seller regarding itsinformation.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe old aphorism “Knowledge is power”, stated by Sir Francis Bacon some four centuries ago, is more relevant nowthan ever. The need to make informed choices causes correct and accurate information to be a desired and highly-valuedcommodity. As intelligent automated agents take on more tasks, and need to act independently within large systems, theirneed to buy and sell information increases.Information in stochastic environments is hard to evaluate, and may be easily faked. Any novice can give a predictionregarding the behavior of tomorrow’s stock market; by pure chance, those predictions may outperform those of even themost informed financial wizard.The question that naturally arises is how to pay for information that can only be verified with some probability. Thisis especially important in cases where in order to obtain the information, the seller itself has to invest some effort. Thepayments made by the buyer must be carefully set so as to induce the seller to invest the effort into acquiring the true* Corresponding author.E-mail addresses: avivz@cs.huji.ac.il (A. Zohar), jeff@cs.huji.ac.il (J.S. Rosenschein).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.005\f1918A. Zohar, J.S. Rosenschein / Artificial Intelligence 172 (2008) 1917–1939information. Otherwise, the seller might be tempted to avoid the cost of obtaining the information, and simply make some-thing up.Most current real-world information trading is done with reliable sources of information over an extended period oftime (for example, buying the same newspaper every day). This repeated form of interaction helps motivate the providerof information to supply accurate and reliable reports (not unlike the “shadow of the future” motivating cooperation in theiterated Prisoner’s Dilemma [1]). The potential for additional interactions in the future makes the information provider’sreputation valuable, and motivates the seller to provide accurate pieces of information.However, advances in technology and infrastructure such as the internet have made a multitude of information sourcesreadily available at a moment’s notice (via web services [2], for example). These tend to be smaller and much more spe-cialized information providers, which can accurately report about a small niche in which they specialize. Interactions withthese sources are often not repeated. Since there is no central authority that governs these sources, and no single authoritycan vouch for the reliability of the information they provide, it is left up to the buyer of information to sift through theinformation that is available and decide what to use.1One approach to the problem of source reliability is the use of reputation systems [3]. These systems are mechanismsthrough which agents provide feedback about the quality of service they received from a specific vendor; this feedbackis later viewed by other potential clients. Unfortunately, solid non-manipulable reputation systems are hard to create, andmost service providers on the internet are not currently rated by any such system.We are therefore interested in other ways of obtaining correct information from a previously unknown informationsource. We will assume that there is no repeated interaction, and the incentive for providing good service must exist withinevery transaction, on its own. The overall approach we take in this work is that of mechanism design. We shall attempt tocreate the incentives for delivering accurate reports by providing payments to the agents in a way that will guarantee thema higher payment when they are behaving well, i.e., when they provide correct information.We shall assume that agents are acting rationally and that they are not intentionally trying to sabotage the buyer—any use the buyer may make of the purchased information does not affect the seller. Instead, we adopt the assumptionthat information providers are only interested in receiving a higher payment and doing the least amount of work. A trulymalicious agent that is trying to intentionally deceive, regardless of monetary loss, will not give good information regardlessof the mechanism applied, and must therefore be dealt with in other ways. Such agents are often handled using securityand encryption tools that we shall not discuss here.1.1. An example scenario for information elicitationThere are many possible scenarios for information exchange, such as reviewing papers, obtaining predictions about thestock market, buying weather information, and so on. We present here one example to which we will refer throughout thepaper.Let us assume that Bob owns a car, and wants to decide if he should upgrade his emergency road service coverage.For this purpose, he wants to evaluate the mechanical condition of the car; this will help him predict the car’s chances ofbreaking down in the near future, and will help him decide whether the extra insurance is worthwhile. Since Bob knowsvery little about cars, he turns to an independent expert, a mechanic named Alice, and asks her to take a look under thehood.Knowing that Bob is not an expert, Alice can decide not to invest any effort in checking the car, and instead make upsome list of malfunctions that threaten to disable the car at any moment, or alternatively she may just say that the car isfine (she has no vested interest in whether Bob upgrades his coverage). How will Bob know that he was told the truth?Even if Alice invests effort in checking the car and says that the car is fine, an accidental malfunction could disable it thenext day (probably making Bob feel cheated).To ensure trust, Alice can make her wages conditioned on the future: if Alice says the car is in poor shape, Bob will geta refund if his car does not break down within the next six months, while if Alice reports that the car is fine, Bob gets arefund if the car does break down within six months. What are the exact payments that will ensure that Alice does herjob? There is naturally some probability that Alice will have to refund some of Bob’s money even if she checked the car andreported the truth to Bob.There might also be a situation in which Alice knowingly lies to Bob. If the chances that a car in good condition willbreak down are too high, Alice could decide to say the car is in bad condition, and thus ensure that she does not refundBob if his car breaks down (even though it was indeed in good condition).1.2. Information elicitation vs. preference elicitationMechanism design [4,5] is the study of how to set the rules and protocols of interaction among agents in a way that willencourage rational agents to behave in a prescribed way that leads to a desired outcome. The mechanism design literature1 As an example, consider querying some foreign weather service before traveling abroad. One will only know if the weather prediction they supplied isgood after arriving at the destination. One may not be likely to require the services of that supplier again.\fA. Zohar, J.S. Rosenschein / Artificial Intelligence 172 (2008) 1917–19391919provides many successful examples of mechanisms that “battle” the agent’s self-interest and successfully achieve outcomesthat are more socially oriented, or are beneficial to the designing agent in some way.Many times, in order to decide on an outcome, a mechanism tries to elicit the preferences of participating agents. Infor-mation elicitation scenarios are slightly different from preference elicitation as it is usually understood in the mechanismdesign literature. In preference elicitation scenarios, information revelation is most often used as a means to an end (i.e., toarrive at some desirable outcome). For example, an auctioneer may want to know the valuations potential buyers have foran expensive painting so that he can award this painting to the bidder that values it highest, and in the p",
            {
                "entities": [
                    [
                        138,
                        176,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 80 (1996) 197-241 Artificial Intelligence A metatheory of a mechanized object theory Faust0 Giunchiglia a*b**, Paolo Traverso a~’ a Mechanized Reasoning Group, IRST - lstituto per lo Ricerca Scientijica e Tecnologica, 38050 Povo, Trento, Italy h Mechanized Reasoning Group, DISA. University of Trento, via Imana 5, Trento, Italy Received November 1992; revised July 1994 Abstract In this paper we propose a metatheory, MT, which represents the computation which implements its object theory, OT, and, in particular, the computation which implements deduction in OT. To theory. MT has emphasize this fact we say that MT is a metutheory of a mechanized object some “unusual” properties, e.g. it explicitly represents failure in the application of inference rules, and the fact that large amounts of the code implementing OT are partial, i.e. they work only for a limited class of inputs. These properties allow us to use MT to express and prove tactics, i.e. expressions which specify how to compose possibly failing applications of inference rules, to interpret them procedurally to assert theorems in OT, to compile them into the system implementation code, and, finally, to generate MT automatically from the system code. The definition of MT is part of a larger project which aims at the implementation of self-reflective systems, i.e. systems which are able to introspect their own code, to reason about it and, possibly, to extend or modify it. 1. A metatheory of a mechanized object theory [28], metareasoning the seminal work by Goedel topics ), in philosophical in formal reasoning. Work has been done in mathematical (e.g. Since studied research (e.g. [ 15,3,9,50] in many (e.g. are by no means exhaustive. Our interests are in theorem proving with metatheories. Similar theory OT to previous work has been one of the most logic [ 5]), planning in logic programming (e.g. in automated deduction, we have mechanized subfields of AI, such as mathematical [47] ) and so on. These citations [48] 11, programming logic (e.g. an object [ 11,541)) languages reasoning [ 41]), (e.g. * Corresponding ’ E-mail: leaF@irst.itc.it. author. E-mail: fausto@irst.itc.it. 0004-3702/96/$15.00 SSDlOOO4-?702(95)00002-X @ 1996 Elsevier Science B.V. All rights reserved \f198 F Giunchi~lk F! Tucrver.ro/Artifi’cirrl Intelligence 80 (1996) 197-241 its me&theory MT. The mechani~tion and theorem prover called GETFOL [ 171. Unlike previous work, we have defined MT to be a metatheory this fact, we say that MT is a rnetatheory of a mechanized object can be intuitively described as follows: the fact that OT is mechanized. To emphasize theory, This requirement that takes into account inside an interactive has been performed l MT represents the computation which implements OT. The words “computation” and “represent” can be formally defined, even in Section 9.6). is In particular, GETFOL is if this function in this paper in a LISP-like by representability (but see discussion programming we mean not done developed speaking, formed by a (recursive) in MT of a corresponding CONJ is the HGKM function or (CONJ A) 1ct FALSE depending structure A, is a conjunction, where --+ is the symbol CONJ is represented where “A” is the name of A if A is a conjunction false. “representing” in the implementation on whether in MT by the predicate called HGKM [ 19,49,X5]. Roughly language that for any computation which can be per- in the code implementing OT, there is a deduction formula, and vice versa. Thus, for instance, of OT such that (CONJ A) e TRUE the formula A, recorded by the data in HGKM. Then symbol Conj such that hr Conj(“A”), for computation and br +Lmj(“A”) if this is MT has also been defined to be a metatheory of provability, i.e. to be about what is provable or not provable in OT. In this perspective the above requirement becomes: o MT represents the computation which implements deduction in OT. fandi that br Tz -+B, recording “T2 +B”) implements introduction fandi such is represented fandi(“rl +A”, is the HGKM function which rj, F2 -+ A A B of OT. Then fandi for instance, rule performing the above equality holds. So far, we have considered in OT the in- in Section 5, GETFOL (GAMMAI, (GAMMA=!, B)) us (GAMMA1 GAMMA2, A AND B), where (GAMMAl, A), (GAMMAZ, conjunction a sequent version of natural deduction (as described [ 461). We have (f andi Thus, ference implements A) B), (GAMMA1 GAMMAZ, A AND B) stand for the data structures rt +A, tion symbol where “r, + A”, “r2 + B”, “r,, r2 -+A A B” are the names theorems of OT. We have the further requirement constant for which rule applications. However, only if certain preconditions tion elimination of a logic, but it is always vents solved HGKM functions, these can be applied and fail when ment fandeltac elimination) the requirement implemented them from asserting non-theorems. inside In the implementation fail for failure, the conclusion the theorems in MT by a func- = “rl, rz +A A B”, in MT of the above rz + A A B” is the unique successftd functions which can be applied to apply a conjunc- in the definition on paper It pre- of GETFOL, we have and by defining new of the rules when imple- tactics failure. For instance, left conjunction to a disjunction. This fact is left implicit is defined, and f aif otherwise. Dually, of representability, MT has a constant this problem by using a data structure these cannot be applied. Primitive returns when fandel the code of theorem provers. the total version of inference the value returned by fandel fail and new function to satisfy sym- tactics, which return are satisfied, e.g. rules by returning rules are partial it is impossible called primitive implements an explicit inference that “rt, in order (which \fE Giun~~~~ti~, fl Traver.~~~Art~~jal ln~el~i~en~e 80 (19961 191-241 199 bols, e.g. j’andeltac, with ~-M-I’ fandeltac( “r -? A A B”) = fandel( “r -+A A B”) and ~~ fandeltac( “r -+ A V B”) = fail. 2. Exploiting a metatheory of a mechanized object theory Since MT is a metatheory about deduction in a mechanized object theory, it has two main features: ( 1) We can construct ground wffs and terms whose structure there are wffs, stating respondence with the (computation) ticular, structure can be put in one to one correspondence with the computation the object tree constructed the provability of an object level proof steps which prove the theorem at the object itself, is in one to one cor- level. In par- level theorem, whose tree of (2) The symbols occurring in such ground wffs and terms have corresponding bolls in the underlying HGKM mechanization. representing symbols to fandeltac), sponds cability of inference denoting rules and primitive r~pre~nting (e.g. Conj corresponds for predicates inference rules In particular, tactics sym- this holds for function (e.g. fandeltac corre- to the appli- to CONJ), and for constants ~r~onditions symbols of the language and theorems of OT (e.g. “A” corresponds to A). content, theorems of object then asserts rules). Notice logic inference The firs{. feature makes to give tactics a procedural in a procedural metalanguage, i.e. to use them to assert object in CIT. This process of compilation from that used in most of the previous tactics, program tactics. The second tactics are programs written these latter tv express and prove tactics, where by tactics we it possible tactics (namely, possibly mean formulas of MT which specify how to compose primitive that in this paper, the word failing applications literature, e.g. in “tactic” has a different meaning [ 14,3 I, 32,441, where e.g. feature makes in ML 1341. We call level it possible (possibly proofs). This can be done in two ways. Tactics can be interpreted, theorems i.e. they c,an be given as input in OT the proved to an interpreter which theorem. Tactics can also be compiled into HGKM code which can then be executed to prove the combination to define a process, called lifting, which can be intuitively seen as the reverse of flattening, and which allows from the code implementing OT. us to generate MT (its language and axioms) a process where the metatheory tactics representing in the code. As a result, derived like the rest of the system and used to shorten subsequent proofs. at the at the theory is called fattening. Finally, it possible of the first and the second features makes is lifted from the code, and it is used to prove theorems which are then compiled down, or possibly rules can be executed Logical manipulation system in Fig, 1 (this figure was first presented efficiency nized object code writing and me&theoretic allows us to bridge advantages. From a computational theory allows us to compose level corresponds cycle, which can be iterated, represented in [4] >. This approach provides considerable point of view, a metatheory of a mecha- the output of theorem proving. From an intellectual point of view, it the gap between that is inside a real inning It has therefore been possible inside a unified environment to define and implement level. This reasoning is schematically transformation in practice, to program interpreted interesting system, starting \f200 F: Ciunchi~lia. P Traverso/Artiftcial Intelligence 80 (1996) 197-241 ‘____~___“__“______~____________.___________~____________~_~______________~______~_~__, GETFOL METATHEORY Metalevel Theorem Proving Safe System Extension I.._____________________________________~~~~_~___________~__~~_~_~__________~__________. GETFOL SYSTEM CODE Fig. I. The lifting-reasoning-flattening cycle. and the computation which systems, deduction towards “really” and thus, possibly, extend or modify, correct way. self-reflective implements i.e. systems able deduction. This seems a first step about to reason deductively in a provably strategies reasoning their underlying 3. The project structures structures as an attempt and simulation are the mechanizable system and deduction in the code of a mechanized of the FOL system, described simulation [ 541. It can",
            {
                "entities": [
                    [
                        75,
                        117,
                        "TITLE"
                    ],
                    [
                        1485,
                        1527,
                        "TITLE"
                    ],
                    [
                        5966,
                        6008,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 120–141Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA unifying action calculusMichael ThielscherSchool of Computer Science and Engineering, The University of New South Wales, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Knowledge representationReasoning about actionsSituation CalculusMcCarthy’s Situation Calculus is arguably the oldest special-purpose knowledge represen-tation formalism, designed to axiomatize knowledge of actions and their effects. Fourdecades of research in this area have led to a variety of alternative formalisms: Whilesome approaches can be considered instances or extensions of the classical Situation Cal-culus, like Reiter’s successor state axioms or the Fluent Calculus, there are also specialplanning languages like ADL and approaches based on a linear (rather than branching)time structure like the Event Calculus. The co-existence of many different calculi has twomain disadvantages: The formal relations among them is a largely open issue, and a lot oftoday’s research concerns the transfer of specific results from one approach to another. Inthis paper, we present a unifying action calculus, which encompasses (well-defined classesof) all of the aforementioned formalisms. Our calculus not only facilitates comparisons andtranslations between specific approaches, it also allows to solve interesting problems forvarious calculi at once. We exemplify this by providing a general, calculus-independent so-lution to a problem of practical relevance, which is intimately related to McCarthy’s questfor elaboration tolerant formalisms: the modularity of domain axiomatizations.© 2010 Elsevier B.V. All rights reserved.1. IntroductionJohn McCarthy’s Situation Calculus [22] is arguably the oldest special-purpose knowledge representation formalism. Theaim is to use classical logic to axiomatize knowledge of actions and their effects. This is relevant for a variety of areas in AI,including planning, intelligent agents, high-level cognitive robotics, natural language understanding, and general game play-ing. While the Situation Calculus is the classical approach for this purpose, a variety of different logic-based formalisms haveemerged in the course of the past decades, motivated mainly by the fundamental Frame Problem [25]. Besides prominentvariants of the Situation Calculus like Reiter’s successor state axioms [31] or the Fluent Calculus [41], planning languageslike STRIPS, ADL, and PDDL [5,29,26] have been developed, which allow for simple operational solutions to the Frame Prob-lem at the expense of a significantly limited expressiveness. Furthermore, the underlying branching time structure of theSituation Calculus has been replaced by a linear time structure in the Event Calculus and a number of other approaches[18,36,4,10]. The basic principles of knowledge representation for actions are also used in special-purpose formalisms likethe Game Description Language [8].The co-existence of a multitude of knowledge representation languages for actions has two significant consequences forthe research in this area. Firstly, there is a growing need both for comparative analysis of the expressiveness of differentapproaches as well as for translations from one specific language into another one. Previous studies along this line are [17,28,35,3], each of which concerns the comparison of two specific formalisms. However, a method that encompasses a widevariety of alternative formalisms at the same time may allow for a more uniform way of assessing and translating calculi.Secondly, issues of general interest need to be separately addressed within each individual language. This often leads to aE-mail address: mit@cse.unsw.edu.au.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.010\fM. Thielscher / Artificial Intelligence 175 (2011) 120–141121multiplication of research efforts. A notorious example is the Ramification Problem, that is, the problem of determining theindirect effects of actions [9], for which a variety of individual solutions have been developed for different formalisms, e.g.,[19,21,11,40,38,27]. A general method which enables a uniform treatment of problems across different calculi would help toavoid this multiplication of research efforts.In this paper, we address both of these issues at the same time by proposing a unifying action calculus, which isindependent of a specific solution to the Frame Problem and which is shown to be general enough to encompass a varietyof different action representation formalisms. Most notably, it abstracts from the underlying time structure (branching orlinear) and thus can be instantiated with both Situation Calculus-style approaches as well as Event Calculus-like languages.In so doing, our general calculus provides a uniform method for translating a variety of specific formalisms into eachother. Moreover, the unifying approach allows to abstract from specific formalisms when investigating problems of generalinterest. We exemplify this by providing a new, calculus-independent solution to a problem of practical relevance for anyaction representation language: the modularity of domain axiomatizations [13]. Our result is a contribution to McCarthy’squest for elaboration tolerant formalisms [24], since modularity is a prerequisite for elaboration tolerance: theories with avariety of dependencies among different parts may not allow for the addition of new information without disrupting theentire axiomatization [14]. We use our unifying action calculus to develop a general method for verifying that a given set ofdomain constraints, precondition axioms, and effect formulas is free of undesired, implicit dependencies. We exemplify therange of applicability of this result by instantiating it for several specific approaches, in particular the Situation-, Fluent-,and Event Calculus.The remainder of this paper is organized as follows. In the next section, we formally define an action calculus whichabstracts from a specific underlying time structure and is independent of a specific solution to the Frame Problem. Weillustrate the expressiveness of our definition by formalizing several example domains known from the literature, includingnondeterministic actions, indirect effects, and actions with duration. In Section 3, we show how our unifying calculus canbe used as an intermediary language for translations between specific languages. Specifically, we present two new results:a translation from ADL planning problems into the Event Calculus and a translation from the basic Fluent Calculus into anew extension—suitable for nondeterministic actions—of Reiter’s basic Situation Calculus. In the second part of the paper,in Section 4, we show how the unifying action calculus can be used to provide a calculus-independent solution to theproblem of implicit dependencies among domain axioms, and we again exemplify the range of applicability of this result byinstantiating it for several action formalisms. We conclude with a discussion in Section 5.2. A unifying action calculusThe purpose of this section is to develop a unifying action calculus that abstracts from a variety of existing axioma-tization techniques for describing actions and change. Logic-based action representation formalisms have in common twofundamental elements: Fluents [22] (sometimes called features [33]) represent properties of the domain that may change inresponse to the execution of actions (or events [18]). Fluents and actions are therefore basic sorts in the sorted logic languagewe are going to define. Action calculi also need to distinguish different points in time in order to axiomatize the changescaused by actions. We assume an abstract notion of time—which may be linear or branching—as the third fundamental sort.The three basic sorts are used for three fundamental predicates: The relation t1 < t2 denotes a (possibly partial) orderingon the time structure. Predicate Holds( f , t) is used to say that fluent fis true at time t. Finally, the intended meaning ofexpression Poss(a, s, t) is that it is possible to do action a beginning at time s and ending at time t. These three predicates,along with the three fundamental sorts, form the basis of a domain signature in our unifying action calculus.Definition 1. A domain signature is a finite, sorted logic language which includes the sorts fluent, action, and time alongwith the predicates<: time × timeHolds: fluent × timePoss: action × time × timeWe tacitly assume that a signature always includes the standard predicate “=”, interpreted as true equality. As usual, then,s (cid:2) t stands for s < t ∨ s = t.Throughout the paper we will denote variables of sort action by the letter a, variables of sort fluent by f and g, andvariables of sort time by s and t. We tacitly assume uniqueness-of-names [1] for all functions into fluent and action, whichis a common assumption in all standard action calculi.Next, we define the notion of a state formula, which allows to express properties of a domain at given times.Definition 2. Let (cid:3)t be a non-empty sequence of variables of sort time in a given domain signature. A state formula in (cid:3)t is afirst-order formula Φ[(cid:3)t] in which the variables in (cid:3)t occur free and such that1. for each occurrence of Holds( f , t) in Φ we have t ∈ (cid:3)t;\f122M. Thielscher / Artificial Intelligence 175 (2011) 120–1412. predicate Poss does not occur in Φ.Similar notions are used in many existing calculi but usually restricted to a single time point. As will be shown later inthis section, the more general concept is useful, for instance, when axiomatizing actions with ramifications.We are now in a position to formalize, in our calculus, three fundamental categories of domain axioms: domain con-straints, which describe state properties that hold at all times; preco",
            {
                "entities": [
                    [
                        136,
                        162,
                        "TITLE"
                    ],
                    [
                        1238,
                        1264,
                        "TITLE"
                    ],
                    [
                        4487,
                        4513,
                        "TITLE"
                    ],
                    [
                        7181,
                        7207,
                        "TITLE"
                    ],
                    [
                        7249,
                        7275,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 167 (2005) 103–136www.elsevier.com/locate/artintProtocols from perceptual observationsChris J. Needham ∗, Paulo E. Santos 1, Derek R. Magee,Vincent Devin 2, David C. Hogg, Anthony G. CohnSchool of Computing, University of Leeds, Leeds, LS2 9JT, UKReceived 28 July 2004; received in revised form 14 February 2005; accepted 14 April 2005Available online 27 July 2005AbstractThis paper presents a cognitive vision system capable of autonomously learning protocols fromperceptual observations of dynamic scenes. The work is motivated by the aim of creating a syn-thetic agent that can observe a scene containing interactions between unknown objects and agents,and learn models of these sufficient to act in accordance with the implicit protocols present in thescene. Discrete concepts (utterances and object properties), and temporal protocols involving theseconcepts, are learned in an unsupervised manner from continuous sensor input alone. Crucial to thislearning process are methods for spatio-temporal attention applied to the audio and visual sensordata. These identify subsets of the sensor data relating to discrete concepts. Clustering within contin-uous feature spaces is used to learn object property and utterance models from processed sensor data,forming a symbolic description. The PROGOL Inductive Logic Programming system is subsequentlyused to learn symbolic models of the temporal protocols presented in the presence of noise and over-representation in the symbolic data input to it. The models learned are used to drive a synthetic agentthat can interact with the world in a semi-natural way. The system has been evaluated in the domainof table-top game playing and has been shown to be successful at learning protocol behaviours insuch real-world audio-visual environments. 2005 Elsevier B.V. All rights reserved.* Corresponding author.E-mail address: chrisn@comp.leeds.ac.uk (C.J. Needham).1 Paulo Santos is now at Centro Universitario da FEI, Sao Paulo, Brazil.2 Vincent Devin is now at France Telecom R&D, Meylan, France.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.04.006\f104C.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136Keywords: Cognitive vision; Autonomous learning; Unsupervised clustering; Symbol grounding; Inductive logicprogramming; Spatio-temporal reasoning1. IntroductionThis paper presents a cognitive vision system capable of autonomously learning proto-cols involving rudimentary language and visual objects. In this system, models of visualobjects and utterances are obtained from unsupervised statistical learning algorithms. In or-der to form symbolic data for input into an inductive logic programming (ILP) system, thecontinuous perceptual observations are transformed using the models learned. Perceptualobservations are taken to be any sensory input; here acoustic and visual inputs are used.The concept of qualitative time is introduced, since only key frames are deemed to be ofimportance. The direct link between perception and action is exploited; a change in what isperceived can only be brought about by an action. The ILP system is used to construct setsof definite clauses that express rules of behaviour for the perceived actions from the sym-bolic description of the scenes. In particular, the protocols learned encode the connectionbetween utterances with visual objects that occur in the scene. This is intrinsically a solu-tion to the anchoring problem [8] which is an instance of the symbol grounding problem[15]. The sets of definite clauses obtained are further used by a synthetic agent to performactions in the world. Therefore, in this work we explore closing the loop between learn-ing the connection between perception and action via bridging the gap between computervision, pattern recognition and symbolic knowledge discovery.The framework presented below is evaluated in the domain of simple table-top games.In this domain the system was able to learn complete protocols for the rules of the games,when different verbal utterances are made and also some aspects of the dynamics involvedin playing the game (for instance, when objects should be placed on the table). The en-tire learning process is executed with minimal human intervention and assumes minimaldomain specific knowledge of the scenes or of game concepts. In earlier work [22], wedemonstrated that the same approach is capable of learning simple mathematical conceptssuch as numerical ordering and equality.1.1. The domain of table-top gamesWe have chosen to work in the domain of simple table-top games involving interactionof one or two players with a small number of visual objects and incorporating spokenutterances. The reason for choosing such scenarios is that games contain rich protocolsand their ‘complexity’ can be controlled by adding, excluding or modifying rules, actionsand/or objects in the domain. Moreover, it may be argued that many real-world social-interaction scenarios may be modelled as games [14], which suggests that our frameworkmay be relevant to the development of a fully autonomous system that could learn how tobehave in the real world.Experimental data is collected using two standard PCs, two webcams, and a microphonein the arrangement shown in Fig. 1. The games used in this work are described in greaterdetail in Section 4. Briefly, the following three games are played:\fC.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136105Fig. 1. Example of the data collection phase. A game is played on the table between two players. One camerapoints down at the table, and another captures the face of the participant to be replaced by the synthetic agent.The audio is captured by a microphone worn by this participant.(1) SNAP1. A generalised game of snap where two cards are played simultaneously, fol-lowed by an utterance dependent upon the figures on the cards. The utterances areeither “colour” (when only the colours in the figures are the same), “shape” (whenonly the shapes in the figures are the same), “same” (when shape and colour match)or “nothing” (if no feature in the figures match to each other). The cards are removed,and “play” is then uttered indicating to play the next two cards.(2) SNAP2. A variation of the above game where cards are placed one on top of anotherand the resulting utterance is dependent upon the card which is visible, and the card atthe previous time step.(3) Paper-scissors-stone (PSS). Played with two sets of three cards each depicting one ofpaper, scissors or stone. Two players simultaneously select one of the object cards andplace them on the table. When the two figures in the cards are perceived, utterances“win”, “lose” and “draw” are spoken by one of the players (the one to be simulated bythe synthetic agent). This player says “win” when its card beats the one shown by theother player—paper beats (wraps) stone, scissors beats (cuts) paper, and stone beats(blunts) scissors. A “play” is uttered when there are no cards on the table.1.2. OverviewAn overview of the framework is illustrated in Fig. 2. Firstly, attention mechanisms arenecessary to pick out salient (interesting) sounds, objects and features from the audio andvisual input streams obtained in a setup similar to that shown in Fig. 1.There are two phases of operation of our system: training and execution.• In the training (or learning) phase, the synthetic agent observes the world, withoutparticipating. In this phase, class induction is performed on the blobs and sounds thatare perceived, and class models are formed, which are used for classification of all theperceptual objects that have been seen in training. These are used to form a symbolic\f106C.J. Needham et al. / Artificial Intelligence 167 (2005) 103–136Fig. 2. Overview of the learning framework for the synthetic agent.data description of the input signals. Protocol induction is then performed on thissymbolic data stream, from which a set of protocol models (or rules) is formed.• In the execution (or play) phase, the synthetic agent participates in games using thelearned protocol models. An inference engine is used for protocol instantiation to in-fer the synthetic agent’s (vocal) response to the current symbolic description of theworld.We assume no knowledge about the type of objects or sounds presented to the sys-tem. Therefore, unsupervised clustering of both the audio and visual feature vectors isperformed. Models are learned, based on this clustering, which can classify the perceptualinputs into classes. This provides a symbolic description of the input signals.Protocol models are represented as ordered sets of definite clauses expressed in Prologsyntax. This provides the necessary flexibility to represent the relations between objectsand actions that we require. Others have previously demonstrated the utility of (subsetsof) first-order predicate logic in high-level scene interpretation (e.g., Neumann and Weiss[30]).Inductive Logic Programming (ILP) in the form of PROGOL [28] is used for protocolinduction. The reason for choosing PROGOL resides in its capability to construct theoriesfrom only (possibly noisy) positive examples. This coincides with our aim to learn proto-col behaviour from observation in an unsupervised way. Moreover, ILP enables conceptgeneralisation (e.g., to extend rules learned from observation of certain objects to unseenentities) and for the knowledge learned to be presented in a format that allows us to assessits ‘complexity’ and accuracy, besides serving as tools for further reasoning—the symbolictheories obtained are used in this work to construct equivalence classes between utterancesin order to cope with over-clustering of the utterances in the audio signal.Once learning is complete, the synthetic agent can process the perceptual inputs andinfer the appropriate action response to the state of the world in real-time. The interactiveagent grounds learned perceptual models and learn",
            {
                "entities": [
                    [
                        72,
                        110,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 140–164Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMeasuring inconsistency in probabilistic logic: rationality postulates and Dutch book interpretation∗,1, Marcelo Finger 2Glauber De BonaDepartment of Computer Science, Institute of Mathematics and Statistics, University of São Paulo, Brazila r t i c l e i n f oa b s t r a c tArticle history:Received 25 October 2014Received in revised form 13 June 2015Accepted 15 June 2015Available online 19 June 2015Keywords:Probabilistic reasoningProbabilistic logicInconsistency measuresInconsistency measures have been proposed as a way to manage inconsistent knowledge bases in the AI community. To deal with inconsistencies in the context of conditional probabilistic logics, rationality postulates and computational efficiency have driven the formulation of inconsistency measures. Independently, investigations in formal epistemol-ogy have used the betting concept of Dutch book to measure an agent’s degree of incoherence. In this paper, we show the impossibility of joint satisfiability of the proposed postulates, proposing to replace them by more suitable ones. Thus we reconcile the rationality postulates for inconsistency measures in probabilistic bases and show that several inconsistency measures suggested in the literature and computable with linear programs satisfy the reconciled postulates. Additionally, we give an interpretation for these feasible measures based on the formal epistemology concept of Dutch book, bridging the views of two so far separate communities in AI and Philosophy. In particular, we show that incoherence degrees in formal epistemology may lead to novel approaches to inconsistency measures in the AI view.© 2015 Elsevier B.V. All rights reserved.1. Introduction“when you can measure what you are speaking about, you know something about it; but when you cannot [. . .] your knowledge is of a meagre and unsatisfactory kind;”— Lord Kelvin [45]Measuring has been a prominent activity in advancing scientific and technological development. Not all measures are alike and good measures express intuitive notions in a useful way. In the field of deductive logical reasoning, one usually has an intuition expressing that one theory is more inconsistent than other, capturing the idea that the “effort” to restore consistency is greater in one case than the other. Also, no effort is required to restore the consistency of a consistent theory.Based on those intuitions, there are several proposals for measuring inconsistency in knowledge bases over purely logical languages [19]. Some of these proposals involved attaching probabilities to formulas [29], or the combination of inconsis-tency factors [20]. Some of these measures are discrete or even qualitative, while others are more like distances, but all these measures have to behave like an information measure [6]. And to adhere to certain intuitions, a series of postulates * Corresponding author.E-mail addresses: debona@ime.usp.br (G. De Bona), mfinger@ime.usp.br (M. Finger).1 Supported by CAPES grant.2 Partially supported by CNPq grant PQ 306582/2014-7.http://dx.doi.org/10.1016/j.artint.2015.06.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\fG. De Bona, M. Finger / Artificial Intelligence 227 (2015) 140–164141for inconsistency measures for purely logical knowledge bases were proposed [21,22]; for example, the consistency postulatestates that the inconsistency measure of a consistent base is 0.Purely logical bases are known to be expressively limited in representing uncertainty required for real-world applications. In this work, we are interested in measuring the inconsistency of knowledge bases over logical probabilistic languages, which combine the deductive power of logical systems with the well-founded theory of probability. This kind of extension of purely logical systems can be traced back to the work of Boole [2], but has gained attention of AI researchers since the work of Nilsson [33], and has been extended to conditional probabilistic logic [37].In AI, one of the main uses of measuring inconsistency in a knowledge base is to guide the consolidation of inconsistent pieces of information. Within propositional logic, Grant and Hunter [13] showed how inconsistency measures can be used to direct the stepwise resolution of conflicts via the weakening or the discarding of formulas.In probabilistic bases, inconsistencies are rather common, specially when knowledge is gathered from different sources. To fix these probabilistic knowledge bases, one can, for instance, delete pieces of information, or change the probabilities’ numeric values (or intervals). In this case, an inconsistency measure helps one to detect if a change approximates consis-tency or not. In other areas, inconsistency measures for probabilistic logic have found applications in merging conflicting opinions, leading to an increased predictive power [47,25], and in quantifying the incoherence of procedures from classical statistical hypothesis testing [41].Example 1.1. Consider we are devising an expert system to assist medical diagnosis. Suppose a group of experts on a disease D is required to quantify the relationship between D and its symptoms. Suppose three conditional probabilities are presented:• the probability of a patient exhibiting symptom S1 given he/she has disease D is 50%;• the probability of a patient exhibiting symptom S2 given he/she exhibits symptom S1 and has disease D is 80%;• the probability of a patient exhibiting symptom S2 given he/she has disease D is 30%.A knowledge engineer, while checking those facts, finds that they are inconsistent: according to the first two items, the probability of symptom S2, given disease D, should be at least 50% × 80% = 40%, instead of 30%. He does not even know where each probability came from, but plans to change the probabilities, since consistency is a requirement. How should he proceed? Which probabilities is the degree of inconsistency most sensitive to? Once chosen which number to change, should it be raised or lowered in order to approximate consistency? These are the kind of questions an inconsistency measure can help to answer.The issue of measuring inconsistency in probabilistic bases has more recently been tackled by Thimm [44], Muiño [31]and Potyka [34], who developed measures based on distance minimization, tailored to the probabilistic case. Potyka focused on computational aspects, looking for efficiently computable measures [34]. Muiño was driven by the CADIAG-2 knowledge base, presenting its infinitesimal inconsistency degree, however based on a different semantics [31]. Thimm [44] adapted Hunter and Konieczny’s [22] desirable properties for inconsistency measures to the probabilistic setting, developing mea-sures that satisfy a set of rationality postulates.It was Thimm [44] who realized the importance of continuity as a Postulate for the probabilistic case, namely the property that a small change in the probability associated to formula (absent in the purely logical case) should lead only to small changes in the inconsistency measure. It was just natural that, (conditional) probabilistic logic being an extension of the classical cases, the continuity postulate was simply added to the postulates defining classical inconsistency measures.In this work, we argue that continuity cannot hold together with classical postulates such as consistency and indepen-dence, and some of these postulates must be abandoned or exchanged for other ones that restore joint satisfiability. So the first contribution of this work is that we identify and fix the possible problem with the postulates proposed by Thimm [44].Another contribution lies in showing that these measures of inconsistency have a direct counterpart in formal epistemol-ogy research over the coherence of an agent’s degrees of belief. It is known that inconsistent probabilistic beliefs correspond to a set of bets with guaranteed loss to the agent, which is called a “Dutch Book” [8,27]. This agent’s incoherence has been measured by formalizing the intuition that the greater the inconsistency the greater the corresponding sure loss, and vice versa [40,43]. Thus we interpret these incoherence measures via guaranteed losses as inconsistency measures, showing that existing measures based on distance minimization correspond to guaranteed losses that quantify an agent’s incoherence. To the best of our knowledge, no clear link has been shown between these two areas.Here is a bird’s-eye view of how we achieve these goals.After introducing probabilistic knowledge bases in Section 2, this paper develops three main contributions, in three different sections, dealing closely with three other works. In the following, we overview such contributions, together with the organization of the paper and their relation to the existing literature.Inconsistency measures for probabilistic knowledge bases were analyzed via rationality postulates by Thimm [44]. In Section 3, we argue for the incompatibility of such desirable properties. Firstly, we introduce the problematic postulates: consistency, independence and continuity. The independence postulate claims that a free conditional — a (conditional) prob-ability assignment that does not belong to any minimal inconsistent set — can be rule out without changing the degree of \f142G. De Bona, M. Finger / Artificial Intelligence 227 (2015) 140–164Table 1Inconsistency measures, where they are defined and a brief description.NotationIpIεpIsumSSKImaxSSKIa,sumSSK, Ib,sumSSKIa,maxSSK, Ib,maxSSKSection4.35.15.25.25.35.3ExplanationMinimum p-norm of the vector composed by the adjustments on the probability bounds to reach consistency.Minimum p-norm of the vector composed by the violations of each restriction corresponding to a probability bound. In the unconditional case, IεMaximum sure loss in a Dutch book if the sum of the stakes’ absolute",
            {
                "entities": [
                    [
                        136,
                        236,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 162 (2005) 89–120www.elsevier.com/locate/artintCompiling problem specifications into SAT ✩Marco Cadoli a,∗, Andrea Schaerf ba Dipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”,Via Salaria 113, I-00198 Roma, Italyb Dipartimento di Ingegneria Elettrica, Gestionale e Meccanica, Università di Udine,Via delle Scienze 208, I-33100 Udine, ItalyReceived 20 November 2001; accepted 21 January 2004Available online 10 December 2004AbstractWe present a compiler that translates a problem specification into a propositional satisfiabilitytest (SAT). Problems are specified in a logic-based language, called NP-SPEC, which allows thedefinition of complex problems in a highly declarative way, and whose expressive power is such asto capture all problems which belong to the complexity class NP. The target SAT instance is solvedusing any of the various state-of-the-art solvers available from the community. The system obtainedis an executable specification language for all NP problems which shows interesting computationalproperties. The performance of the system has been tested on a few classical problems, namelygraph coloring, Hamiltonian cycle, job-shop scheduling, and on a real-world scheduling application,namely the tournament scheduling problem. 2004 Elsevier B.V. All rights reserved.Keywords: Automatic generation of problem reformulation; Executable specifications; SAT problem;NP-complete problems✩ This paper is an extended and revised version of “Compiling problem specifications into SAT”, whichappeared in Proceedings of the European Symposium on Programming (ESOP 2001), Lecture Notes in ComputerScience, vol. 2028, Springer, Berlin, 2001, pp. 387–401.* Corresponding author.E-mail addresses: cadoli@dis.uniroma1.it (M. Cadoli), schaerf@uniud.it (A. Schaerf).URLs: http://www.dis.uniroma1.it/~cadoli (M. Cadoli), http://www.diegm.uniud.it/schaerf (A. Schaerf).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.006\f90M. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–1201. IntroductionWe present a system for writing and executing specifications for search problems,which makes use of NP-SPEC, a highly declarative specification language. NP-SPEC has aDATALOG-like syntax, i.e., PROLOG with no function symbols. Its semantics is based onthe notion of model minimality, an extension of the well-known least-fixed-point seman-tics of the Horn fragment of first-order logic [1]. NP-SPEC allows the user to express everyproblem belonging to the complexity class NP [2], which includes many notorious prob-lems interesting for real-world applications. Restriction of expressiveness to NP guaranteestermination and helps to obtain efficient executions.The core of our system is the compiler, called SPEC2SAT, that translates problemspecifications written in NP-SPEC into instances of the propositional satisfiability problem(SAT). An instance π of the original problem is translated into a formula T of propositionallogic in conjunctive normal form, in such a way that T is satisfiable if and only if π has asolution. Moreover, the system constructs the solution of π from the variable assignmentsthat satisfy T .A specification S of π is a set of metarules defining the search space, plus a set of rulesdefining the admissibility function. Both metarules and rules are transformed into a set ofclauses of T encoding their semantics. The translation of rules is based on their groundinstantiation over the Herbrand universe. Our algorithm for instantiation uses complexauxiliary data structures to avoid the generation of useless clauses insofar as possible.The approach of translation into SAT is motivated by the huge amount of research de-voted to such a problem in recent years (see, e.g., [3]), and the number of fast solversavailable from the research community. Such solvers, both complete and incomplete ones,are able to solve instances of hundreds of thousands of clauses in a few seconds, a resultinconceivable only a few years ago. In addition, the community working on SAT is stillvery active, and better and better SAT solvers are expected in the future.SAT is the prototypical NP-complete problem, and every instance π of a problem inNP can be translated into an instance of SAT of polynomial size in the size of π . In prac-tice, this idea has been exploited for a number of years in problems such as planning[4–6], scheduling [7], theorem proving in finite algebra [8], generation of test patterns forcombinatorial circuits [9], and cryptography [10]. Those papers showed that translating aproblem into SAT can give good performance in the resulting system, as compared withstate-of-the-art dedicated solvers.The shortcoming of those previous works is that the translator had to be done completelyby hand for each problem. Conversely, we aim at a system that automatically translates anyNP problem into SAT using the simple and declarative language NP-SPEC.In terms of performance, NP-SPEC obviously cannot outperform state-of-the-art solversof well-studied problems. However, we believe that it is a valuable tool for developing fastprototypes for new problems, or variations of known ones for which no specific solver isavailable. Nevertheless, experimental results show that our system is able to solve medium-size instances of various classical problems in reasonable time. In addition, it works muchfaster than the original NP-SPEC engine [11] which is based on a translation of the inputspecification in the logic programming language PROLOG.\fM. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–12091The paper is organized as follows. In Section 2 we introduce the language NP-SPECand recall the state of the art on SAT technology. In Section 3 we describe the compiler.In Section 4 we illustrate the performance of the system in four problems: graph color-ing, Hamiltonian cycle, job-shop scheduling, and tournament scheduling. Related work isdiscussed in Section 5. Finally, in Section 6 we draw conclusions and discuss future work.2. Preliminaries2.1. Overview of the NP-SPEC languageAs a first example, we show an NP-SPEC program for the Hamiltonian path NP-complete problem [2, Prob. GT39, p. 199], i.e., the problem where the input is a graphand the question is whether a traversal exists that touches each node exactly once.DATABASEn = 6;edge = {(1,2),(3,1),(2,3),(6,2),(5,6),(4,5),(3,5),// no. of nodesSPECIFICATION(1,4),(4,1)};Permutation({1..n},path).fail <-- path(X,P), path(Y,P+1), NOT edge(X,Y).// H1// H2The following comments are in order:• The input graph is defined in the DATABASE section, which is generally provided in aseparate file.• In the search space declaration (metarule H1) the user declares the predicate symbolpath to be a “guessed” one, implicitly of arity 2. All other predicate symbols are,by default, not guessed. Being guessed means that we admit all extensions for thepredicate, subject to the other constraints.• path is declared to be a permutation of the finite domain {1..n}. This means that itsextension must represent a permutation of order 6. As an example, {(1, 5), (2, 3), (3, 6),(4, 2), (5, 1), (6, 4)} is a valid extension.• Comments can be inserted using the symbol “//”.• Rule H2 is the constraint that permutations must obey in order to be Hamiltonian paths:a permutation fails, i.e., it is not valid, if two nodes X and Y which are adjacent inthe permutation are not connected by an edge. X and Y are adjacent because they holdplaces P and P+1 of the permutation, respectively.Running this program on the NP-SPEC compiler produces the following output:path: (1, 1) (2, 5) (3, 6) (4, 2) (5, 3) (6, 4)which means “1 is the first node in the path, 4 is the second node in the path, . . . , 3 is thesixth node in the path”, and is indeed an Hamiltonian path.\f92M. Cadoli, A. Schaerf / Artificial Intelligence 162 (2005) 89–120More formally, an NP-SPEC program consists of a DATABASE section and a SPEC-IFICATION section (cf. Appendix A for the complete syntax). The DATABASE sectionincludes:• Definition of extensional relations of the kindr = {t1,...,tn},where r is the input relation name and each ti is a tuple of the same arity as r. Theonly constant symbols allowed in tuples are integers and strings.• Definition of constants.The SPECIFICATION section consists of two parts:• A search space declaration, which corresponds to the definition of the domain of theguessed predicates. In basic NP-SPEC it is a sequence of declarations of the form:(1) Subset(<domain>, <predicate_id>).(2) Permutation(<domain>, <predicate_id>).(3) Partition(<domain>, <predicate_id>, n).(4) IntFunc(<domain>, <predicate_id>, min..max).where <predicate_id> is the name of the guessed predicate and <domain> is afinite set defined either as an input relation, or as an enumeration, or by means of union(‘+’), intersection (‘*’), difference (‘-’), and Cartesian product (‘><’).<domain> identifies the domain upon which the extension of the predicate isguessed, and, for Subset, it must have the same arity as <predicate_id>. In theother cases <predicate_id> is a guessed predicate of arity equal to the arity aof <domain> plus 1. Such a declaration means that <predicate_id> can haveall extensions such that the first a arguments coincide with a member of <domain>,while the last one depends on the metapredicate. In particular:− For Permutation the extension of <predicate_id> must represent a bijec-tive function from <domain> to the interval {1..c}, where c is the cardinality of<domain>.− Declarations using metapredicate Partition have a further integer-valued argu-ment n that states the number of subsets in which the domain must be partitioned.The extension of <predicate_id> must represent a function from <domain>to the interval {1..n}, the last argument being any element of such an interval.Subset is indeed the special case of Partition in which n = 2, but the syn-tax is different (declaration Subset(<domain>",
            {
                "entities": [
                    [
                        71,
                        112,
                        "TITLE"
                    ],
                    [
                        1506,
                        1547,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 93 ( 1997 ) 105 167 Artificial Intelligence Dynamic reasoning with qualified syllogisms Daniel G. Schwartz’ Department of Computer Science, Florida State University, Tallahassee. FL 32306-4019, USA Received January 1996: revised January 1997 Abstract A gualij%e~ syllogism is a classical Aristoteiean syllogism that has been “qualified” through the use of fuzzy quantifiers, likelihood modifiers, and usuality modifiers, e.g., “Most birds can Ry; Tweety is a bird; therefore, it is likely that Tweety can fly.” This paper introduces a formal logic Q of such syllogisms and shows how this may be employed in a system of nonmonotonj~ reasoning. In process are defined the notions of path logic and dynamic reasoning system (DRS) The former is an adaptation of the conventional formal system which explicitly portrays reasoning as an activity that takes place in time. The latter consists of a path logic together with a multiple- inhe~tance hierarchy. The hierarchy duplicates some of the info~ation recorded in the path logic, but additionally provides an extralogical spec#icity relation. The system uses typed predicates to formally distinguish between properties and kinds of things. The effectiveness of the approach is demonstrated through analysis of several “puzzles” that have appeared previously in the literature, e.g., Tweety the Bird, Clyde the Elephant, and the Nixon Diamond. It is also outlined how the DRS particular, predicate circumscription, a framework accommodates other reasoning techniques-in “localized” version of default logic, a variant of nonmonotonic logic, and reason maintenance. Furthermore it is seen that the same framework accomodates a new formulation of the notion of unless. A concluding section discusses the relevance of these systems to the well-known fiame problem. @ 1997 Elsevier Science B.V. ic;e?‘~~rds: Default reasoning; Dynamic reasoning systems; Fuzzy likelihood; Fuzzy probabilities; Fuzzy quanti~~rs; Multiple inheritance; Nonmonotoni~ reasoning; Qualified syllogisms; The frame problem; Unless ’ E-mail: schwartz@cs.fsu.edu. 0~4.3702/97/$17.~ @ 1997 Elsevier Science E.V. All rights reserved. PIJ SOOO4-3702(97)00020-9 \f104 D.G. Sclwartz/Arfificial Intelligence 93 (1997) 103-167 1. Introduction 1.1. Background Modern logic was originated aimed in p~ticul~ the foundations of mathematics. for the mathematical that of a formal completeness, about a century ago, with its development tialIy at investigating were fo~ulated, including the associated notions of proof, consistency, so on. Several schools of thought arose concerning what one should grounding these, Intuitionism constructive mathematics putability. This in turn played a key role in the development revived anew the centuries old vision of a “thinking machine” first computers were being only for mathematical to make computers perform ever more sophisticated birth to the subdiscipline ini- In process many key concepts logical system together with syntax versus semantics, and take as a solid forth of the notion of com- of computer science, and it the not quest then gave that these could be programmed reasoning. The subsequent it was noted but also logical invented, computations, types of mental activities (as in [ 1781). When disciplines. Among led to formulations known as AI. [ 76]), which brought (see Shortly after computers were first being programmed to perform logical deductions, that the notion of formal system which had served so well for all the that of mathematics would not be adequate importance was the discovery for encoding is oftentimes nonmonotonj~ it was found the foundations however, exploring salient aspects of natural human reasoning. Of critical everyday reasoning may lead one under conditions the situation certainty; but when the available conclusions additional keeping be obtained. Since information. inferences information to go back and retract old conclusions. information in that the addition of new information of incomplete then one’s tentatively, at hand, in mind only monotonic the set of derivable reasoning activity conclusions to be expressed. (theorems), in that the acquisition of new information This style of reasoning If one has perfect knowledge in principle can is less than complete, arises regarding be drawn with absolute then one can draw should is to expand it does not allow for this newer kind of type of formal system serves generally that these may become the conventional (axioms) invalid Hence in the interests of creating machines with more human-like “intelligence”, there for identifying ensued a concerted effort to identify and formalize various aspects of this nonmonotonic [ 1041, behavior. An early work of this genre is the 1969 paper by McCarthy and Hayes now well-known the seeds of several later developments. calculus, a new kind of formalism embodying in a expressed with language admitting modal operators a set of rules specifying how a history may be grown by adding new propositions. For example, the frame problem. That work contained In particular, a history-namely, ~zormally, and probably-together a sequence of propositions it introduced the situation consistent, normally(q5), consistent( q5) t- probably( (p) says that if 4 is normally respect probably true. to the existing history), true, and 4 is consistent with what is known so far (i.e., with that 4 is then one may add to the history the assertion \fD.G. Schwartz/Artificial Intelligence 93 (1997) 103-167 105 A decade later, four separate approaches to nonmonotonicity appeared almost simul- [ 251. This provided a mechanism system truth maintenance track of logical dependencies taneously. First was Doyle’s for keeping retraced, and formerly held conclusions a resemblance conclusions but also because certain other propositions have more recently been dubbed reason maintenance is the reasons see [ 1631). for conclusions that are at issue, rather to the earlier notion of history, but also offers are held, not only because certain earlier propositions can be retracted. The resulting in such a way that derivation steps can be formalism bears that feature are held (are “in”), are not held (are “out”). Such formalisms the novel the fact that it truth (e.g., than their objective systems reflecting individuals that the only Second was McCarthy’s method of circumscription to have P. In effect, one “circumscribes” asserting conjecture” by virtue of which one assumes certain property P are those that are explicitly axioms) have P by tentatively considers affairs-it body of information. Nonmonotonicity found that also have property P. These are then added to the formalism, and conclusions (conjectures) [ 1001. This provided a “rule of x that have a of the that must that this is all there are. The kind of formalism one thus represents a snapshot of the current state of the present are that one might reasonably enters when further in circumscriptive contains the collection of individuals smaller set than before. (i.e., as a consequence all conclusions draw, given subsequently individuals reasoning required Third was Reiter’s default are redrawn, yielding a potentially logic [ 1501. This introduced derivation schemata such as Bird(x) : MCanFly( x) CanFly( x) taken to assume is a modal operator that, if x is a bird, and it is consistent that x can fly. As with circumscription, and conjectures. Given information, one concludes where M as saying infer (by default) snapshot of the current knowledge the absence of any countervailing later time, however, it is learned be expanded by adjoining redrawn based on this new, enlarged axiom set, and if there happens theorem asserting and the earlier to express “is consistent”. The rule is interpreted that x can fly, then one may the resulting is a is a bird, and in that Tweety that Tweety can fly. If at a say, then the formalism would are to be an axiom or this fact about Tweety as a new axiom. Then conclusions fly, CanFly( Tweety) now becomes inference made by default that Tweety is a penguin, that penguins inconsistent, is blocked. formalism cannot Last is the nonmonotonic spirit with Reiter’s default “is consistent”; element of the language, by the formula but the style of formalism logic of McDermott and Doyle logic, in that it too employs a modal operator M expressing is much different. Here JW is made an explicit so that the sense of the foregoing default rule is here expressed [ 1071. This is similar in Bird(x) A M[CanFly(x)] + CanFly for this system The language tics, with M being possible”. The intent is provided with a Kripke-style as roughly equivalent with interpreted is that, if the there is a possible world in which Tweety “possible worlds” seman- “is the classical modality is a bird \f106 D.G. Sclzwartz/Artijicial Intelligence 93 (1997) 103-167 to infer that Tweety can fly. But if there are further propositions that can fly, then both conditions of the above inference hold, and one can apply classical Modus Ponens asserted, e.g., to the effect that Tweety fly, then there will be no possible world in which Tweety can fly. In this case the condition M [CanFly( will fail to hold, and the inference cannot be employed. Again a snapshot of current knowledge, from that knowledge; possibly represents together with whatever conclusions may be inferred are redrawn, a smaller set of conclusions will result. is added, and conclusions and as new information the formalism and penguins is a penguin cannot A later development was McCarthy’sformula [ 1011, a generalization of the earlier version which, to avoid confusion was here renamed predicate circumscrip- tion. McCarthy attributed to “express the facts and non-monotonic the ability of birds to fly” to Marvin Minsky, and he presented numerous may be applied to create logical formalisms adequate how formula circumscription reasoning concerning circumscription the challenge to this task. illustrating examples While McCarthy and Hayes [ 1041 h",
            {
                "entities": [
                    [
                        77,
                        120,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 103 (199X) 117-132 Artificial Intelligence Role of constrained computational systems in natural language processing * Depurtment of Computer and Information Science and Institute for Research in Cognitive Science, Room 555, Moore School, UniversiQ of Pennsylvania, Philadelphia, PA 19104, USA Aravind K. Joshi ’ Abstract and discourse, The use of constrained among others, has proved formal/computational semantics, pragmatics systems just adequate for modeling various aspects to be an of language-syntax, to both effective research strategy leading to deep understanding of these aspects, with implications machine processing and human processing. This approach enables one to distinguish between the universal and stipulative constraints. This is in contrast to an approach where we start with the most the phenomena by making all constraints powerful in a sense. The use of constrained stipulative for modeling describing locality of structures and brings out the relationship between the complexity of description of primitives and local computations over them. These ideas serve to unify theoretical, computational and statistical aspects of natural languages processing productive in other domains of AI. 0 1998 Elsevier Science B.V. All rights reserved. leads to some novel ways of that this approach will be system and then model formal/computational in AI. It is expected systems Keywords: Abstract character of adjoining; Adjoining; Almost parse; Centering; Center of an utterance; Complexity of inference; Control of inference; Constrained grammars; Local computations on complex structures; Local statistical tree-adjoining grammars; Lexicalized computations; Locality of structures; Locally monadic structure; Monadic predicate; Substitution; Supertags; Supertagging; Universal and stipulative constraints formal systems; Finite state transducers; Lexicalized This paper is a somewhat expanded version of my IJCAI-97 Research Excellence lecture. It is not a survey of the field of natural Award It is not even a survey of all of my own work. I will focus on only a few topics which in a significant way. The illustrate influenced my own work an approach processing. that has language ” This work is partially supported by NSF Grant SBR8920230 ’ Email: joshi@linc.cis.upenn.edu. and AR0 Grant DAAHO404-94-GE-0426 00043702/98/$ PII: SOOO4-3702(98)00065-4 -see front matter 0 1998 Elsevier Science B.V. All rights reserved \f118 A.K. Joshi /Arti$icicd Intrlligcwce IO;1 (199X) I17-I.12 various systems set of ideas for describing as the aspects of theses efforts could best be described to starting with the most general and most that characterize formal/computational semantics, pragmatics, discourse, among others. The use of constrained is in sharp contrast systems and then making all constraints, necessary for description, particular use of constrained language-syntax, systems computational powerful computational stipulative between in a sense. The use of such systems allows one to distinguish universal and stipulative constraints. Universal constraints are properties of languages are (or claimed properties which may be languages particular are then stipulative. tries to capture On the other hand constraints a constrained is not achievable at present and perhaps may never be achievable. However, goal of the constrained in computational modeling of language and has given deep insights techniques. languages. Moreover, the that to be) universal across languages and not language particular. All other In this approach one itself. system all Ideally we want this this is the systems approach. This approach has proved to be quite successful that captures all and only the universal properties. Of course, in the approach where in the descriptions it has also led to efficient processing as properties of the constrained are stipulative by definition. the universal properties introduced system into the structure of is unconstrained the underlying system that fall under the characterization of the approach Here are five topics of my research formal/computational using constrained (1) Cascaded finite state transducers (2) Lexicalized grammars-lexicalized (3) Some aspects of bilingual processing. (4) Computation entailments. of certain classes of inferences, systems. for parsing. tree-adjoining grammars (LTAG). for example, presupposition and (5) Local structure of discourse+entering. 1 will only discuss three of these items, will serve to illustrate the main point of my talk-the systems. items 1, 2, and 5. These examples, I hope, role of constrained computational 1. Cascaded finite state transducers My first topic or example is the use of finite state transducers It also happens to be the very first work I did in natural languages processing. As far as I know this is the first use of fst’s for parsing. This work (carried out during the period 1958-1959) was part of a project called Transformations and Discourse Analysis Project (TDAP), directed by Professor Zellig Harris at the University of Pennsylvania. (fst) for parsing. ’ ‘The other participants of this project were Lila Gleitman, Bruria Kauffman, Naomi Sager, and Carol this program has been recently faithfully collaboratively with Phil Hopely. Two papers based on this work have also appeared Chomsky. By a remarkable coincidence documentation, A.K. Joshi, P. Hopely, A parser from antiquity, Natural Language Engineering 2 (4) (1997). An extended version of this paper which for example, Wall Street Journal (WSJ), IBM Computer Manuals, and ATIS (several modern parsers have been evaluated on these corpora also) will appear in: A. Kornai (Ed.), Extended Finite State Automata, Cambridge University Press, 1998. includes an evaluation of this parser on some corpora, from the OrigiIId recently- reconstructed \fA. K. Joshi /Arti$cial Inrelligence IO3 (1998) 117-132 119 The fst parser consists of a cascade of finite state transducers corresponding to the following computations: . dictionary look-up and computation clusters which behave as a single part-of-speech; of the so-called grammatical idioms, i.e., word l part-of-speech disambiguation; . computation of simple noun phrases, prepositional phrases, and verb clusters; . computation of clauses (strictly not an fst computation). Rather than describing these computations 1 will give an example. which is an actual (of [either (also) output from the original program. [We] (have found} / that [subsequent addition] (of [the second inducer]) (to proceed] + > (for [ 15 minutes]) system]) < after (allowing} {results] Here (in [increased [. .] denotes a simple noun phrase, [single induction] reproduction]) + \\ + (of [both enzymes]). (. .) denotes a simple adjunct, and (. . .} denotes a verb cluster. Both < . . > and / . . \\ denote clauses, + denotes the end of a verb and part-of- complement. After the dictionary look-up, grammatical speech disambiguation, from phrases by a left to right fst and the verb clusters by right to left, then the prepositional left to right fst. The computation of clauses is done by a pushdown store with a depth first strategy. the simple noun phrases are computed by an fst scanning idioms computation, There are several reasons for mentioning computational this very early work. First fst’s are an example fst’s are once again playing role in natural languages processing and many of the techniques used in system but, more importantly, of a constrained a very significant this early work have close connections of fst technology finite state calculi, determinization weighted fst’s. Some of the key efforts in this area are Koskenniemi (1996), Hobbs et al. (1992) and Mohri et al. (1997). ’ in natural the new techniques and, of course, techniques for handling enormous language processing and minimization, is due to our substantial knowledge of sizes of fst’s and for their stochastic and for handling et al. (1992), Karttunen to some very recent work on fst’s. This resurgence are an example of a constrained Finite state transducers an example of a computational descriptions can be complex. So it is an example (no doubt a simple one) of a computation which I call local computation on complex structures. 1 will return to this theme repeatedly. system but they also serve as system which is finite state (thus local) but where the state 2. Lexicalized tree-adjoining grammars Now I will turn to my second example-lexicalized grammars, which are also examples systems. A lexicalized grammar consists of a finite set of constrained computational ’ K. Koskenniemi, P. Tapanainen, A. Voutilainen. Compiling and using finite-state in: Proc. in Computational Linguistics, COLING-92, Vol. I, 1992, Nantes, France, pp. 156 15th International Conference for Computational 162. I,. Karttunen, Directed Linguistics, ACL-96, Santa Crua, 1996. J.R. Hobbs. D.E. Appelt. J.S. Bear, D. Israel, W.M. Tyson, FAUSTUS: a system for extracting text, Technical Note, SRI International, Menlo Park, 1992. M. Mohri. F. Pereira, M. Riley, Rational power series in text and speech processing, Lecture Notes. AT&T Laboratories, Murray Hill, 1997. in: Proc. 34th Annual Meeting of the Association from a natural language replacement, information syntactic rules, \f120 A.K. Joshi/Art$cial Intelligence 103 (199X) 117-132 Fig. 1. LTAG substitution. structures (for example, of elementary trees, or directed acyclic graphs), each strings, structure associated with a lexical anchor. Each anchor may have more than one associated structure. Further i.e., languages in a sense, grammar and lexicon independent. Thus in a lexicalized grammar, are the same thing, in other words Grammar = Lexicon. there is a finite set of composition operations, which are universal, A particular example of a lexicalized grammar 4 is the Lexicalized Tree-Adjoining (LTAG), where each each lexical item is associated with one or more elementary syntactic and semantic trees localize the domain and adjoining. long distance ",
            {
                "entities": [
                    [
                        67,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "E L S E V I E R Artificial Intelligence 107 (1999) 219-263 Artificial Intelligence Logical analysis of binary data with missing bits Endre Boros a, l, Toshihide Ibaraki b,*, Kazuhisa Makino c,2 a RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway, NJ 08854-8003, USA b Department of Applied Mathematics and Physicw, Graduate School ofb~grmatics, Kyoto UniversiO; Kyoto 606-8501, Japan c Department of Systems and Human Science, Graduate School of Engineering Science, Osaka Universi~, Toyonaka, Osaka 560-8531, Japan Received 21 November 1997 Abstract We model a given pair of sets of positive and negative examples, each of which ma~ contain missing components.as a partially defined Boolean function with missing bits (pBmb) (T, F), where T c {0, 1, ,}n and F c {0, 1, .}n, and \"*\" stands for a missing bit. Then we consider the problem of establishing a Boolean function (an extension) f : { 0 ,  1} n ~ {0, l}belonging to a given function class C, such that f is true (respectively, false) for every vector in T (respectively, in F). This is a fundamental problem, encountered in many areas such as learning theory, pattern recognition, example-based knowledge bases, logical analysis of data, knowledge discovery and data mining. In this paper, depending upon how to deal with missing bits, we formulate three types of extensions called robust, consistent and most robust extensions, for various classes of Boolean functions such as general, positive, Horn, threshold, decomposable and k-DNF. The complexity of the associated problems are then clarified; some of them are solvable in polynomial time while the others are NP- hard. © 1999 Elsevier Science B.V. All rights reserved. Keywords: Knowledge discovery; Data mining; Logical analysis of data; Boolean functions; Partially defined Boolean functions; Missing bits; NP-hardness This research was partially supported by ONR (Grants N00014-92-J-1375 and N00014-92-J-4083), and the Scientific Grants in Aid by the Ministry of Education, Science, Sports and Culture of Japan. The visit of the first author to Kyoto University was made possible by the grant (06044112) of the Ministry of Education, Science, Sports and Culture of Japan. * Corresponding author. Emaih ibaraki@kuamp.kyoto-u.ac.jp. 1 Emalh boros@rutcor.rutgers.edu. 2 Email: makino@sys.es.osaka-u.ac.jp. 0004-3702/99/$ - see fi'ont matter © 1999 Elsevier Science B.V. All rights reserved. PII: S0004-3702(98)001 10-6 \f220 E. Boros et al. /Artificial Intelligence 107 (1999) 219-263 1. Introduction In analyzing data of some phenomena from a logical viewpoint, we often encounter the following problem: Given a pair of data sets (T, F) of \"positive\" and \"negative\" examples, where T, F c {0, 1 }n, establish a Boolean function (extension) f in a specified function class C, such that f is true (respectively, false) for every vector in T (respectively, in F). A pair of sets (T, F) is called a partially d~ned Boolean function (pdBJ). For instance, a data vector x may represent the symptoms to diagnose a disease, e.g., xl denotes whether temperature is high (xj = 1) or not (Xl ----- 0), and x2 denotes whether blood pressure is high (x2 = 1) or not (x2 = 0), etc. Establishing an extension f , which is consistent with the given data set.. then amounts to finding its logical diagnostic explanation. This type of problems is studied, for example, in learning theory (e.g., 3,32,38), where it is called the consistency problem. In the process of learning, it is fundamental to find an extension of the current set of data (T, F). The learner tries to find an extension of small (i.e., polynomial) size as it leads to interesting theoretical consequences 7. In pattern recognition, a function separating two categories of data T and F is usually called a discriminant function (e.g., 28). If the data are binary, this is essentially the same as an extension of a pdBf (T, F). In example-based knowledge bases, we encounter a similar problem of establishing an extension, but in this case it is usually asked to describe the extension by rules. Finding extensions is also one of the main goals in such areas as data analysis, knowledge acquisition, knowledge discovery and data mining (e.g., 1,9,16,17, 34), which are recently receiving increasing attention. In many of the above applications, some knowledge or hypothesis about the extension f is usually available beforehand. Such knowledge may be obtained from experience or from the analysis of mechanisms that may or may not cause the phenomena under consideration. In the above example of diagnosing diseases, it would be natural to assume that we somehow know the direction of each variable that tends to cause the disease to appear. By changing the polarities of variables if necessary, therefore, the extension f(x) can be assumed to be positive (i.e., monotone increasing) in all variables. As the above observation is essential, we consider in this paper to find an extension f that belongs to a specified class of functions C. The classes of functions considered in this paper include general, positive (or monotone), Horn, threshold, decomposable and k-DNE The class of positive functions may be the most natural special class to investigate in this respect. Horn functions are important in the sense that the satisfiability problem of Horn CNF (conjunctive normal form) can be solved in polynomial time 4,19, and, for this reason, logic programs and expert systems are often built on Horn rules. If an extension is Horn, its true set (or false set, depending on the definition) can be described by a f Horn CNE Threshold functions 30 have all appealing geometrical interpretation of linear separation, and hence is a major tool to describe discriminant functions used in pattern recognition (e.g., 28). Decomposable functions 5,8,35 are important because they can provide us additional information regarding the hierarchical structure underlying the given data sets. Finally the class of k-DNF should also be included in the list, since DNF is a standard form of representation of Boolean functions. The prime implicants in DNF of an \fE. Boros et al. / Artificial Intelligence 107 (1999) 219-263 221 extension are also called \"association rules\" in data mining (e.g.,  1,29), and \"patterns\" in papers on logical analysis of data 16 and its applications 10. Unfortunately, real-world data might not be complete, adding another dimension of complication. In other words, the values of some elements xj in a given data vector x may not be available for various reasons, such as the test to measure the xj was not conducted because it takes too much time or is expensive, or the data bits are simply lost. Therefore, it is indispensable to admit incomplete data in order to be usable in practical applications. We denote the missing bits by \"*\" in this paper. A set of data (T, F), which includes missing bits, is called a partially defined Boolean function with missing bits (pBmb), where T c_ {0, 1, .}n (respectively, P c_ {0, 1, .}n) denotes the set of \"positive examples\" (respectively, \"negative examples\"). We introduce in this paper three types of extensions of a pBmb (T, F), called robust, consistent and most robust extensions, depending upon how we deal with the missing is called (i) a robust bits. More precisely, given.a pBmb (T, F), a Boolean function f extension if for every fi ~ T (respectively, fi c/~), any 0-1 vector a obtained from fi by fixing its missing bits arbitrarily satisfies .f(a) = 1 (respectively, f ( a )  = 0). It is called (ii) a consistent extension if for every fi 6 T (respectively, fi 6 F), there exists a 0-1 vector a obtained from ~ by fixing its missing bits appropriately, for which f ( a )  = 1 (respectively, f ( a )  = 0) holds. Finally, f is called (iii) a rnost robust extension if it is a robust extension of the pBmb (T', F I) obtained from (T, F) by fixing a smallest set of missing bits appropriately (the remaining missing bits in T / U F ~ are assumed to take arbitrary values). All of these extensions provide logical explanations of a given pBmb (T, F) with varied freedom given to the missing bits i,,n T and F. Let us remark that by definition,if f ~ C is a most robust extension of (T, F), then it is also consistent; furthermore, if (T, F) has a robust extension in a class C, then it also has a most robust one (and hence a consistent one, too). Let us add that the process of finding consistent and most robust extensions will also provide us with conditions on the values of missing bits, required for (T, F) to have a consistent extension in the given class C. This type of information can also be useful in analyzing incomplete data sets. In the above example of diagnosing diseases, not all medical tests are usually performed on each patient, because the tests may be painful, expensive or even dangerous. Such attributes thus naturally become missing. In this case, a robust extension provides very useful information, if it exists, since it is a diagnostic explanation of the disease under consideration regardless of the interpretation of the missing bits. That is, it says that the current data set carries enough information to derive a meaningful explanation. It may happen, however, that the data set has no robust extension. Even in this case, there may be an extension if we can supply correct interpretation of all or part of the missing bits; such an extension may help or even improve diagnostic procedures. This leads to the concepts of consistent and most robust extensions. The most robust extension is important in practice as it minimizes the number of \"corrected\" bits in order to have an extension. There are other possible treatments of missing bits appearing in the context of learning theory (see, e.g., 6,18,23,25,36,37,39). In this paper, we study the problems of deciding the existence of these extensions for various special classes of Boolean functions C, mainly from the viewpoint of their \f222 E. Boros et al. / Ar",
            {
                "entities": [
                    [
                        83,
                        132,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 320 (2023) 103922Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintGoSafeOpt: Scalable safe exploration for global optimization of dynamical systems ✩Bhavya Sukhija a,∗Sebastian Trimpe b, Dominik Baumann c,da Department of Computer Science, ETH Zürich, Switzerlandb Institute for Data Science in Mechanical Engineering, RWTH Aachen University, Germanyc Department of Electrical Engineering and Automation, Aalto University, Espoo, Finlandd Department of Information Technology, Uppsala University, Sweden, Matteo Turchetta a, David Lindner a, Andreas Krause a, a r t i c l e i n f oa b s t r a c tArticle history:Received 31 March 2022Received in revised form 12 April 2023Accepted 14 April 2023Available online 20 April 2023Keywords:Model-free learningBayesian optimizationSafe learningLearning optimal control policies directly on physical systems is challenging. Even a single failure can lead to costly hardware damage. Most existing model-free learning methods that guarantee safety, i.e., no failures, during exploration are limited to local optima. This work proposes GoSafeOpt as the first provably safe and optimal algorithm that can safely discover globally optimal policies for systems with high-dimensional state space. We demonstrate the superiority of GoSafeOpt over competing model-free safe learning methods in simulation and hardware experiments on a robot arm.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionThe increasing complexity of modern dynamical systems often makes deriving mathematical models for traditional model-based control approaches forbiddingly involved and time-consuming. Model-free reinforcement learning (RL) meth-ods [1] are a promising alternative as they learn control policies directly from data. To succeed, they need to explore the system and its environment. Without a model, this can be risky and unsafe. Since modern hardware such as robots are ex-pensive and their repairs are time-consuming, safe exploration is crucial to apply model-free RL in real-world problems. This paper proposes GoSafeOpt, a model-free learning algorithm that can search for globally optimal policies while guaranteeing safe exploration with high probability.1.1. Related workAdvances in machine learning have motivated the usage of model-free RL algorithms for obtaining control policies [2–6]. However, directly applying these methods to policy optimization presents two major challenges: (i) Machine learning algorithms often require large amounts of data. In learning control, such data is often gathered by conducting experiments ✩This paper is part of the Special Issue: “Risk-aware Autonomous Systems: Theory and Practice”.* Corresponding author.krausea@ethz.ch (A. Krause), trimpe@dsme.rwth-aachen.de (S. Trimpe), dominik.baumann@aalto.fi (D. Baumann).E-mail addresses: bhavya.sukhija@inf.ethz.ch (B. Sukhija), matteo.turchetta@inf.ethz.ch (M. Turchetta), david.lindner@inf.ethz.ch (D. Lindner), https://doi.org/10.1016/j.artint.2023.1039220004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fB. Sukhija, M. Turchetta, D. Lindner et al.Artificial Intelligence 320 (2023) 103922Fig. 1. Illustrative example with disjoint safe regions in the policy space. The blue line depicts the objective, and the orange line is the constraint function. There are two safe regions that are marked in green. SafeOpt cannot explore the global optimum if it is initialized in the left region. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)with physical systems, which is time-consuming and wears out the hardware. (ii) Learning requires exploration, which can lead to unwarranted and unsafe behaviors.Challenges (i) and (ii) can be addressed jointly by Bayesian optimization (BO) with constraints. BO [7] is a class of black-box global optimization algorithms, that has been used in a variety of works [8–11] to optimize controllers in a sample-efficient manner. In constrained BO, there are two main classes of methods. On the one hand, approaches like [12–15] find safe solutions but allow unsafe evaluations during training. Herein, we focus on approaches that guar-antee safety at all times during exploration, which is crucial when dealing with expensive hardware. SafeOpt [16] and safe learning methods that emerged from it, e.g., [17–19], guarantee safe exploration with high probability by exploiting properties of the constraint functions, e.g., regularity. Unfortunately, these methods are limited to exploring a safe set con-nected with a known initial safe policy. Therefore, they could miss the global optimum in the presence of disjoint safe regions in the policy space (see Fig. 1). Disjoint safe regions appear when learning an impedance controller for a robot arm, as we show in our experiments and in many other applications [8,20,21]. To address this limitation [21] proposesGoSafe, which can provably and safely discover the safe global optimum in the presence of disjoint safe regions under mild conditions. To achieve this, it learns safe backup policies for different states and uses them to preserve safety when evaluating policies outside of the safe set. Specifically, it switches between actively exploring local safe regions in the state and policy space and safe global exploration. However, the active exploration in the state and policy space requires a coarse discretization of the space and is infeasible for all but the simplest systems with low-dimensional state spaces, [22] argues that dimension d > 3 is already challenging. As a result, GoSafe cannot only handle most real-world dynami-cal systems, and is restricted to impractical systems with low-dimensional state spaces. The concept of switching between two exploration stages is also pursued in the stagewise safe optimization algorithm proposed in [23]. However, also [23]is restricted to an optimum connected to a safe initialization. Lastly, the general idea of learning backup policies is related to safety filters and control barrier functions [24–26]. Nevertheless, those methods require either availability or learning of a dynamics model besides learning the policy and are, therefore, model-based. In this work, we focus on a model-free approach.1.2. ContributionsThis work presents GoSafeOpt, the first model-free algorithm that can globally search optimal policies for safety-critical, real-world dynamical systems, i.e., systems with high-dimensional state spaces. GoSafeOpt does not discretize and actively explores the state space. Therefore, it overcomes the main shortcomings and restrictions of GoSafe, while still performing safe global exploration. This makes GoSafeOpt the first and only model-free safe global exploration algorithm for real-world dynamical systems. Crucially, GoSafeOpt leverages the Markov property of the system’s state to learn backup policies which it uses to guarantee safety when evaluating policies outside the safe set. This novel mechanism for learning backup policies does not depend on the dimension of the state space. We provide high-probability safety guarantees for GoSafeOpt and we prove that it recovers the safe globally optimal policy under assumptions that hold for many practical cases. Finally, we validate it in both simulated and real safety-critical path following experiments on a robotic arm (see Fig. 2), which is prohibitive for GoSafe, the only competing model-free global safe search method. Further, we show that GoSafeOpt achieves considerably better performance than SafeOpt, a state-of-the-art method for local model-free safe policy search, and its high-dimensional variants. Table 1 compares GoSafeOpt to SafeOpt and GoSafe in terms of safety guarantees, scalability, global exploration, and sample efficiency. It shows that GoSafeOpt is the only method that can perform sample-efficient global exploration in high-dimensional systems while providing safety guarantees.2\fB. Sukhija, M. Turchetta, D. Lindner et al.Artificial Intelligence 320 (2023) 103922Fig. 2. Franka Emika Panda; seven degrees of freedom robot arm used for our evaluations.Table 1Comparison of GoSafeOpt and prior work on safe exploration based on their safety guarantees, scalability, global exploration, and sample efficiency.Safe explorationSAFEOPT [18]GOSAFE [21]GOSAFEOPT (ours)✓✓✓State space with dimension d > 3✓✗✓Global explorationSample efficient✗✓✓✓✗✓2. Problem settingWe consider a Lipschitz-continuous systemdx(t) = z(x(t), u(t)) dt,(1)where z(·) represents the unknown system dynamics, x(t) ∈ X ⊂ Rs is the system state and u(t) ∈ U ⊂ Rp is the input we apply to steer the system state to follow a desired trajectory xdes(t) ∈ X for all t ≥ 0. We assume that the system starts at a known initial state x(0) = x0.The control input u(t) we apply for a given state x(t) is specified by a policy π : X × A → U , with u(t) = π (x(t), a) :=π a(x(t)). The policy is parameterized by a ∈ A ⊂ Rd, where A is a finite parameter space.1 We encode our goal of following the desired trajectory xdes(t) through an objective function, f : A → R. Note, the trajectory of a deterministic system (1)is fully determined by its initial state x0 and the control policy. Therefore, the objective is independent of the state space X . We seek for a controller parametrization a ∈ A that optimizes f for a constant initial condition x0. Since the dynamics of the system in Eq. (1) is unknown, so is the objective f . Nonetheless, we assume we obtain a noisy measurement of f (a) at any a ∈ A by running an experiment. We aim at optimizing f from these measurements in a sample-efficient way. Additionally, to avoid the deployment of harmful policies, we formulate safety",
            {
                "entities": [
                    [
                        153,
                        234,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 250 (2017) 105–124Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLatent tree models for hierarchical topic detectionPeixian Chen a, Nevin L. Zhang a,∗Zhourong Chen a, Farhan Khawar aa Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kongb Ant Financial Services Group, Shanghai, Chinac Department of Mathematics and Information Technology, The Education University of Hong Kong, Hong Kong, Tengfei Liu b, Leonard K.M. Poon c, a r t i c l e i n f oa b s t r a c tArticle history:Received 2 May 2016Received in revised form 18 June 2017Accepted 26 June 2017Available online 29 June 2017Keywords:Probabilistic graphical modelsText analysisHierarchical latent tree analysisHierarchical topic detectionWe present a novel method for hierarchical topic detection where topics are obtained by clustering documents in multiple ways. Specifically, we model document collections using a class of graphical models called hierarchical latent tree models (HLTMs). The variables at the bottom level of an HLTM are observed binary variables that represent the presence/absence of words in a document. The variables at other levels are binary latent variables that represent word co-occurrence patterns or co-occurrences of such patterns. Each latent variable gives a soft partition of the documents, and document clusters in the partitions are interpreted as topics. Latent variables at high levels of the hierarchy capture long-range word co-occurrence patterns and hence give thematically more general topics, while those at low levels of the hierarchy capture short-range word co-occurrence patterns and give thematically more specific topics. In comparison with LDA-based methods, a key advantage of the new method is that it represents co-occurrence patterns explicitly using model structures. Extensive empirical results show that the new method significantly outperforms the LDA-based methods in term of model quality and meaningfulness of topics and topic hierarchies.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThe objective of hierarchical topic detection (HTD) is, given a corpus of documents, to obtain a tree of topics with more general topics at high levels of the tree and more specific topics at low levels of the tree. It has a wide range of potential applications. For example, a topic hierarchy for posts at an online forum can provide an overview of the variety of the posts and guide readers quickly to the posts of interest. A topic hierarchy for the reviews and feedbacks on a business/product can help a company gauge customer sentiments and identify areas for improvements. A topic hierarchy for recent papers published at a conference or journal can give readers a global picture of recent trends in the field. A topic hierarchy for all the articles retrieved from PubMed on an area of medical research can help researchers get an overview of past studies in the area. In applications such as those mentioned here, the problem is not about search because the user does not know what to search for. Rather the problem is about summarization of thematic contents and topic-guided browsing.* Corresponding author.E-mail address: lzhang@cse.ust.hk (N.L. Zhang).http://dx.doi.org/10.1016/j.artint.2017.06.0040004-3702/© 2017 Elsevier B.V. All rights reserved.\f106P. Chen et al. / Artificial Intelligence 250 (2017) 105–124Several HTD methods have been proposed previously, including the nested Chinese restaurant process (nCRP) [1,2], the hierarchical Pachinko allocation model (hPAM) [3,4], and the nested hierarchical Dirichlet process (nHDP) [5]. Those methods are extensions of latent Dirichlet allocation (LDA) [6]. Hence we refer to them collectively as LDA-based methods.In this paper, we present a novel HTD method called hierarchical latent tree analysis (HLTA). Like the LDA-based methods, HLTA is a probabilistic method and it involves latent variables. However, there are fundamental differences. The first differ-ence lies in the types of variables used in the models. In the LDA-based methods, observed variables are token variables (usually denoted as W d,n), and latent variables are constructs in a hypothetical document generation process, including a list of topics (usually denoted as β), a topic distribution vector for each document (usually denoted as θd), and a topic as-signment for each token in each document (usually denoted as Zd,n ). In contrast, each observed variable in HLTA stands for a word. It is a binary variable and represents the presence/absence of the word in a document. The latent variables in HLTA are considered as unobserved attributes of the documents. If we compare whether words occur in particular documents to whether students do well in various subjects, then the latent variables correspond to latent traits such as analytical skill, literacy skill, and general intelligence.In the LDA-based methods, each token variable stands for a location in a document, and its possible values are the words in a vocabulary. Here one cannot talk about conditional independence between words because the probabilities of all words must sum to 1. On the other hand, the output of HLTA is a tree-structured graphical model, where the word variables are at the leaves and the latent variables are at the internal nodes. Two word variables are conditionally independent given any latent variable on the path between them. Words that frequently co-occur in documents tend to be located in the same “region” of the tree. This fact is conducive to the discovery of meaningful topics and topic hierarchies. A drawback of using binary word variables is that word counts are discarded.The second difference lies in the definition and characterization of topics. Topics in the LDA-based methods are prob-abilistic distributions over a vocabulary. When presented to users, a topic is characterized using a few words with the highest probabilities. In contrast, topics in HLTA are clusters of documents. More specifically, all latent variables in HTLA are assumed to be binary. Just as the concept “analytical skill” partitions a student population into two soft clusters, with one cluster consisting of people with high analytic skill and the other consisting of people with low analytic skill, a latent variable in HLTA partitions a document collection into two soft clusters of documents. The document clusters are interpreted as topics. For presentation to users, a topic is characterized using the words that not only occur with high probabilities in topic but also occur with low probabilities outside the topic. The consideration of occurrence probabilities outside the topic is important because a word that occurs with high probability in the topic might also occur with high probability outside the topic. When that happens, it is not a good choice for the characterization of the topic.HLTA also differs from the LDA-based methods in several other ways. Those differences are more technical in nature and will be explained Section 4.The rest of the paper is organized as follows. We discuss related work in Section 2 and review the basics of latent tree models in Section 3. In Section 4, we introduce hierarchical latent tree models (HLTMs) and explain how they can be used for hierarchical topic detection. The HLTA algorithm for learning HLTMs is described in Sections 5–7. In Section 8, we present the results HTLA obtains on a real-world dataset and discuss some practical issues. In Section 9, we empirically compare HLTA with the LDA-based methods. Finally, we end the paper in Section 10 with some concluding remarks and discussions of future work.2. Related workTopic detection has been one of the most active research areas in Machine Learning in the past decade. The most commonly used method is latent Dirichlet allocation (LDA) [6]. LDA assumes that documents are generated as follows: First, a list {β1, . . . , βK } of topics is drawn from a Dirichlet distribution. Then, for each document d, a topic distribution θd is drawn from another Dirichlet distribution. Each word W d,n in the document is generated by first picking a topic Zd,n according to the topic distribution θd, and then selecting a word according to the word distribution β Zd,n of the topic. Given a document collection, the generation process is reverted via statistical inference (sampling or variational inference) to determine the topics and topic compositions of the documents.LDA has been extended in various ways for additional modeling capabilities. Topic correlations are considered in [7,3]; topic evolution is modeled in [8–10]; topic structures are built in [11,3,1,4]; side information is exploited in [12,13]; supervised topic models are proposed in [14,15]; and so on. In the following, we discuss in more details three of the extensions that are more closely related to this paper than others.The hierarchical Pachinko allocation model (hPAM) [3,4] is proposed as a method for modeling correlations among topics. It introduces multiple levels of supertopics on top of the basic topics. Each supertopic is a distribution over the topics at the next level below. Hence hPAM can also be viewed as an HTD method, and the hierarchical structure needs to be predetermined. To pick a topic for a token, it first draws a top-level topic from a multinomial distribution (which in turn is drawn from a Dirichlet distribution), and then draws a topic for the next level below from the multinomial distribution associated with the top-level topic, and so on. The rest of the generation process is the same as in LDA.The nested Chinese Restaurant Process (nCRP) [2] and the nested Hierarchical Dirichlet Process (nHDP) [5] are proposed as HTD methods. They assume that there is a true topic tree behind data. A prior distribution is placed over all possible trees using nCRP and nHDP respectively. An assumption is made as to how d",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 74 ( 1995) 1-53 Artificial Intelligence Automated reasoning about machines * Andrew Gelsey * Computer Science Department, Hill Center for the Mathematical Sciences, Rutgers University, New Brunswick, NJ 08903, USA Received June 1992; revised July 1993 Abstract simulation Numerical is often used in predicting machine behavior, a basic capability for many tasks such as design and fault diagnosis. However, using simulators requires considerable human effort both to create behavioral models and to analyze and understand simulation results. I describe algorithms which automate the kinematic and dynamical analysis needed to create behavioral models and which automate the intelligent control of computational simulations needed to understand a machine’s behavior over both short and long time scales. The input is a description of a machine’s geometry and material properties, and the output is a behavioral model for the machine and a concise qualitative/quantitative prediction of the machine’s long-term behavior. My algorithms have been implemented in a working program which can predict a machine’s behavior over both short and long time periods. At present this work is limited to mechanical devices, particularly clockwork mechanisms. 1. Introduction Predicting a machine’s behavior soning about machines, machines, predicting lation behavioral models on which and redesign of existing machines. Numerical the behavior of machines for many tasks requiring is a basic capability rea- such as diagnosis of malfunctioning machines, design of new in systems. However, using simu- human effort both to create the the and other physical requires considerable is based and to analyze and understand is often used the simulation simulation to predict machine behavior *This research was supported by National Science Foundation grants IRI-8610241 and IRI-8812790 and by the Defense Advanced Research Projects Agency and the National Aeronautics and Space Administration under NASA grant NAG2-645. * E-mail: gelsey@cs.rutgers.edu. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved .SSDIOOO4-3702(94)00003-J \fA. C;elsey/Arr~ficm1 lnleliigence 74 (1995) l-53 b) Balance collides with lever @y=gf--~’ c) Escape wheel pushes lever and I balance d) Halfway through a full cycle Fig. I, Clock or watch escapement mechanism. to escape wheel are present in model but not shown in figures.) (Note: hairspring attached to balance and mainspring attached results of the simulation. Automating research in both spatial reasoning I describe this process requires basic artificial intelligence and reasoning about physical systems. The research l automated creation of behavioral models of machines directly in this article addresses two main problems: from models of their raw physical structure; l intelligent control of the computational experiments needed to reveal a machine’s long-term behavior. the algorithms Together, diction of a machine’s behavior over both short and long time periods. At present work is limited these problems allow the automated pre- this to mechanical devices, particularly clockwork mechanisms. for solving I present input All the algorithms in this article have been implemented in a working program. The is a description of the physical structure of a machine, which consists program’s primarily of a precise numerical specification of the machine’s geometry. From this input the program creates a behavioral model of the machine which it then uses to numerically the machine’s precise behavior when started from a number of intelligently simulate chosen description of the machine’s expected final output is a concise qualitative/quantitative initial conditions. The program’s long-term behavior. in Fig. 1 keeps the escape wheel, which I will present an example which gives an overview of the entire process. The escape- the average speed of a clock or watch constant by to advance is pushed clockwise by a strong spring, the motion of the to be by its attached spring. In Fig. 1 (b) the balance has hit the lever. then pushes the balance in spite of damping. Finally, ment mechanism allowing by only one escape wheel driven counterclockwise Impact both lever and balance as in Fig. 1 (c). This pushing loses to friction, so that it can act as a harmonic oscillator tooth for each oscillation of the balance. is blocked by the lever, and the balance to free the escape wheel, which the energy restores In Fig. 1 (a) is motionless the lever far enough force pushes and about \fA. Gebey/Artljkial Intelligence 74 (1995) l-53 3 in Fig. 1 (d), the escape wheel and lever are locked together again, and the balance has been brought temporarily to a halt by its spring. In this article, a behavioral model for a machine is considered to consist of two parts: l the identification of a set of stare variables: any particular state of the machine may be specified by assigning specific numerical values to each of the state variables; l a description of how the state variables change with time, usually by differential equations. The input to my program for the escapement example only specifies the shapes of the parts and their positions in space; this input does not indicate whether any of the parts are in contact or whether they impose any constraints on each other. Therefore, in order to identify a useful set of state variables, my program must use spatial reasoning to determine the kinematic properties of the escapement mechanism. The program identifies three kinematic pairs, pairs of parts which mutually constrain each other’s motion, by looking for pairs of parts having subparts with matching sym- metries in corresponding positions. For example, in the escapement, the balance has a hole in it which has rotational symmetry about a certain axis, and the frame has a shaft having rotational symmetry about the same axis. Algorithms 2 and 3 in Section 2.1.1 specify the conditions under which matching symmetries result in a kinematic pair. For the escapement, my program determines that each of the three moving parts forms a revolute pair with the frame and thus is constrained only to rotate about a fixed axis. The program then partitions the moving parts into kinematic subsystems each having a single degree of freedom, using algorithms from Section 2.1.3. In this mechanism, none of the three moving parts are connected to each other by kinematic pairs, so there are three kinematic subsystems, each consisting of a single moving part. As a result, the program concludes that a reasonable set of state variables for the escapement consists of six variables: one position variable and one velocity variable for each of the three kinematic subsystems. In order to generate the other half of the behavioral model for the escapement, the differential equations describing how the state variables change with time, the program must analyze the dynamics of the mechanism. My program can produce two separate behavioral models for a machine, based on distinctly different sets of approximations and simplifying assumptions. The user must choose between the two models: this article does not address model selection. However, the availability of at least two disparate models seems a necessary prerequisite for experimental investigation of how choices of approximations and simplifying assumptions influence the forms of behavioral models and the sorts of behavior the models predict. For the escapement mechanism, these models differ in their treatment of intermittent contacts between the moving parts, which are critical to the functioning of this mechanism. (Permanent contacts are handled with kinematic pairs, as described above.) The first model handles intermittent contacts between the moving parts of a mechanism by approximating the very small elastic distortions of the parts which give rise to contact forces. In the other model parts of the mechanism are treated as absolutely rigid bodies, and contact forces result from geometric constraints on the relative motions of parts in contact. Section 2.4 compares the two models. The other forces that must be modeled for the escapement mechanism are springs and friction, and my program uses simple linear models for both. \f4 350 ; $ 300 k 250 ; 200 - 150 6 100 ;: 50 2 g 0 -50 A. Gelsey/Artificial Intelligence 74 (1995) 1-53 2 0 -2 -4 -6 -8 -10 -12 0 0 -20 -40 -60 -80 -100 -120 -140 -160 -200 -180 5 10 15 20 25 30 35 40 _a__ rime 0 0 5 10 15 20 25 30 35 40 time 1 5 10 15 20 25 30 35 40 .‘_.. L_ /IILcz balance lever escape wheel Fig. 2. Motion of escapement mechanism. The behavioral model generated by my program may be used to numerically simulate a the second dynamic model. The two models, using to do a good job of predicting machine’s behavior. Fig. 2 shows a plot of a simulation of the behavior of the escapement mechanism though quite different, that such a mechanism would both appear actually exhibit. to from this article. Both outputs are shown in [ 151.) My Fig. 2 and is therefore omitted are presented algorithms automated modeling (As a result, simulation output from the first model looks identical in Section 2. the behavior To the human eye, the data plot in Fig. 2 clearly shows the regularity of the mech- simulation data. is not explicit trace to make the be- is though Fig. 2 shows the regular behavior of the to decide how long this even a human would need to do further analysis clear, instructions. Also, the plot shows a sufficiently ran for that length of time in the numerical the only reason long behavior the simulation though a stream of simulation data to determine when it has become In Section 3 I present algorithms for continuously long enough to anism’s behavior, but this regularity Furthermore, havioral regularity because of explicit escapement, regular behavior would continue. processing show regularities, experiments for characterizing to determine the limits of validity of a hypothesized behavioral those regular",
            {
                "entities": [
                    [
                        64,
                        98,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 321 (2023) 103936Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintPolynomial combined first-order rewritings for linear and guarded existential rules ✩Georg Gottlob a, Marco Manna b, Andreas Pieris c,d,∗a Department of Computer Science, University of Oxford, UKb Department of Mathematics and Computer Science, University of Calabria, Italyc School of Informatics, University of Edinburgh, UKd Department of Computer Science, University of Cyprus, Cyprusa r t i c l e i n f oa b s t r a c tArticle history:Received 4 May 2021Received in revised form 19 April 2023Accepted 25 April 2023Available online 2 May 2023Keywords:OntologiesExistential rulesTuple-generating dependenciesGuardednessConjunctive queriesQuery answeringQuery rewritingCombined approachWe consider the problem of ontological query answering, that is, the problem of answering a database query (typically a conjunctive query) in the presence of an ontology. This means that during the query answering process we also need to take into account the knowledge that can be inferred from the given database and ontology. Building, however, ontology-aware database systems from scratch, with sophisticated optimization techniques, is a highly non-trivial task that requires a great engineering effort. Therefore, exploiting conventional database systems is an important route towards efficient ontological query answering. Nevertheless, standard database systems are unaware of ontologies. An approach to ontological query answering that enables the use of standard database systems is the so-called polynomial combined query rewriting, originally introduced in the context of description logics: the conjunctive query q and the ontology (cid:2) are rewritten in polynomial time into a first-order query q(cid:2) (in a database-independent way), while the database D and the ontology (cid:2) are rewritten in polynomial time into a new database D(cid:2) (in a query-independent way), such that the answer to q in the presence of (cid:2) over D coincides with the answer to q(cid:2) over D(cid:2). The latter can then be computed by exploiting a conventional database system.In this work, we focus on linear and guarded existential rules, which form robust rule-based languages for modeling ontologies, and investigate the limits of polynomial combined query rewriting. In particular, we show that this type of rewriting can be successfully applied to (i) linear existential rules when the rewritten query can use the full power of first-order queries, (ii) linear existential rules when the arity of the underlying schema is fixed and the rewritten query is positive existential, namely it uses only existential quantification, conjunction, and disjunction, and (iii) guarded existential rules when the underlying schema is fixed and the rewritten query is positive existential. We can show that the above results reach the limits (under standard complexity-theoretic assumptions such as PSpace (cid:3)= ExpTime) of polynomial combined query rewriting in the case of linear and guarded existential rules.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).✩This paper is an extended and revised version of the papers [1], [2] and [3].* Corresponding author.E-mail addresses: georg.gottlob@cs.ox.ac.uk (G. Gottlob), manna@mat.unical.it (M. Manna), apieris@inf.ed.ac.uk (A. Pieris).https://doi.org/10.1016/j.artint.2023.1039360004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fG. Gottlob, M. Manna and A. PierisArtificial Intelligence 321 (2023) 1039361. IntroductionOver the past two decades we have seen a shift from a world where most data used by public and private organizations was stored in well-structured relational databases of modest size and treated as complete to a world where data is very large, heterogeneous, distributed in different sources, and incomplete. This makes the task of extracting useful information from such data by means of queries extremely tedious and complex. At the same time, not only do we have massive amounts of data, but we also have very large amounts of knowledge about the application domain of the data in the form of taxonomies, or even full-fledged ontologies. This gave rise to a new research field, recently dubbed knowledge-enriched data management [4], that lies at the intersection of data management and knowledge representation and reasoning. A major challenge for knowledge-enriched data management is to provide end users with flexible and integrated access to data by exploiting the available knowledge about the underlying application domain. This builds on the hypothesis that end users may have a deep understanding of a specific domain of interest, but are not able to formulate complex queries and understand performance implications.Ontology-based data access (OBDA) [5], also known as ontology-based data integration, has been proposed as a general paradigm for addressing the above central challenge. It facilitates access to data by separating the end user from the raw data sources. This is done by using an ontology, which models the underlying application domain and is semantically linked with the data via declarative mappings, as a mediator between the data sources and the end user. The purpose of the ontology is two-fold:1. It provides an integrated global view of the data that is very close to the conceptual model of the underlying application domain of which the end user has a good understanding. This makes the raw data accessible via database queries formulated solely in the vocabulary of the ontology, without requiring any knowledge of the actual structure of the data sources.2. It enriches the possibly incomplete data sources with domain knowledge. This allows us to infer new knowledge, not explicit in the data, enabling more complete answers to queries.The main algorithmic task underlying the OBDA paradigm is querying knowledge-enriched data, or, in other words, querying data in the presence of an ontology. This means that during the query answering process we also need to take into account the inferred knowledge. This problem is known as ontological query answering.1.1. Query rewritingBuilding ontology-aware database systems from scratch, with sophisticated optimization techniques, is a highly non-trivial task that requires a great engineering effort. An alternative route towards efficient ontological query answering is to use conventional database management systems (DBMSs). The fact that DBMSs are unaware of ontologies can be addressed by query rewriting: the database query q (typically a conjunctive query) and the ontology (cid:2) are rewritten into a new query q(cid:2), the so-called rewriting, which computes the answer to q in the presence of (cid:2) over all input databases. It is, of course, essential that q(cid:2) is expressed in a language that can be handled by standard DBMSs. The typical language is that of first-order (FO) queries.The Pure Approach. What has been described above is the so-called pure approach to FO rewritability in the sense that the FO rewriting q(cid:2) should be powerful enough to compute the correct answer to the given query q under the given ontology (cid:2) over all input databases. This essentially means that the construction of q(cid:2) should be independent of any database. The advantage of such a pure approach to FO rewritability should be clear: we can pre-compute q(cid:2) offline, and whenever the database D changes, we simply need to re-evaluate q(cid:2) over D, without having to re-compute it. This approach has been successfully applied to a range of lightweight description logics, mainly the members of the DL-Lite family [6], as well as classes of existential rules such as linear existential rules [7,8]; details on existential rules are given below. On the other hand, such a pure approach to FO rewritability comes with two inevitable shortcomings:1. Query rewriting algorithms generate from a reasonably sized conjunctive query a very large FO query, which can be prohibitive for efficient execution by a standard database system. We actually know that even for lightweight ontology languages such as DL-LiteR [6], the logical underpinning of the OWL 2 QL profile of OWL 2,1 there is no FO rewriting of polynomial size, unless the polynomial hierarchy collapses [9]. Further strong evidence for the non-existence of an FO rewriting of polynomial size in the case of DL-LiteR was given in [10]. In particular, it was shown that the existence of such an FO rewriting is equivalent to a major open problem in computational complexity such as NC1 = NP/poly.2 We also know that an exponential blow-up is provably unavoidable when the rewriting should be an existential positive FO query (i.e., an FO query that uses only existential quantification, conjunction, and disjunction) [9].1 https://www.w3 .org /TR /owl2 -profiles /#OWL _2 _QL.2 NC1 is the class of decision problems decidable by uniform Boolean circuits with a polynomial number of gates of at most two inputs and depth O (log n), whereas NP/poly is the non-uniform analogue of NP.2\fG. Gottlob, M. Manna and A. PierisArtificial Intelligence 321 (2023) 1039362. FO rewritability applies only to lightweight ontology languages for which the data complexity of ontological query answering (i.e., when the query and the ontology are considered fixed) is very low. More precisely, the problem of eval-uating a fixed FO query over an input database is known to be in AC0,3 a class that is properly contained in DLogSPace. Therefore, useful formalisms with PTime-hard (or even DLogSpace-hard) data complexity, such as the description logic EL [11], are immediately excluded.The Combined Approach. To overcome t",
            {
                "entities": [
                    [
                        153,
                        236,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 165–189Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDifferential evolution for noisy multiobjective optimizationPratyusha Rakshit∗, Amit KonarElectronics and Telecommunication Engineering Department, Jadavpur University, Kolkata 700032, Indiaa r t i c l e i n f oa b s t r a c tArticle history:Received 20 December 2013Received in revised form 15 June 2015Accepted 15 June 2015Available online 18 June 2015Keywords:NoiseDifferential evolution for multiobjective optimizationSamplingInterquartile rangeSkewnessDominance probabilityWe propose an extension of multiobjective optimization realized with the differential evolution algorithm to handle the effect of noise in objective functions. The proposed extension offers three merits with respect to its traditional counterpart. First, an adaptive selection of the sample size for the periodic fitness evaluation of a trial solution based on the fitness variance in its local neighborhood is proposed. This avoids the computational complexity associated with the unnecessary reevaluation of quality solutions without disregarding the necessary evaluations for relatively poor solutions to ensure accuracy in fitness estimates. The second strategy is concerned with determining the expected value of the noisy fitness samples on the basis of their distribution, instead of their conventional averaging, as the fitness measure of the trial solutions. Finally, a new crowding-distance-induced probabilistic selection criterion is devised to promote quality solutions from the same rank candidate pool to the next generation, ensuring the population quality and diversity in the objective spaces. Computer simulations performed on a noisy version of a well-known set of 23 benchmark functions reveal that the proposed algorithm outperforms its competitors with respect to inverted generational distance, spacing, error ratio, and hypervolume ratio metrics.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe multiobjective optimization (MOO) literature has witnessed a radically different perspective in solving real-world problems using evolutionary computing methods. A MOO is concerned with mathematical optimization problems involving two or more complex, nonlinear, conflicting objectives to be optimized simultaneously. Usually, a derivative-free single-objective optimization algorithm generates new trial solutions that are biased toward the better region of the objective space, and weeds out poor solutions using a competitive selection over iterations. However, for a nontrivial MOO problem, there exists no single solution that simultaneously optimizes each objective. To jointly optimize multiple objective functions in a MOO [1], selection of trial solutions is performed by Pareto ranking, which is concerned with judiciously identify-ing nondominated trial solutions from the rest of the population. Pareto ranking is induced by the fitness measure of all objective functions for individual trial solutions.The objectives, being functions of certain variables describing a specific problem, usually return a unique value for the variables in their argument. However, in many scientific/engineering problems, it has been observed that even though the measurements of the variables remain constant, the objective functions return different values because of noise-induced dynamic variation of the objective surfaces. This class of problem is referred to as the “noisy optimization problem.” Noise * Corresponding author. Tel.: +91 9477399645.E-mail address: pratyushar1@gmail.com (P. Rakshit).http://dx.doi.org/10.1016/j.artint.2015.06.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\f166P. Rakshit, A. Konar / Artificial Intelligence 227 (2015) 165–189creeps into the picture because of technological limitations, modeling errors, and incomplete data, leading to different results from repeated evaluations for the same set of parameter values of the objective functions. In such circumstances, a quality trial solution in a MOO may be deprived of being promoted to the next generation because of its poor (noisy) fitness estimates, while a deceptive solution with illusive good fitness may not be discarded from the current population [2,3].This paper addresses the issues of uncertainty management (regarding the selection of qualitative trial solutions) in MOO in the presence of noise by incorporating the following three policies: adaptation of the sample size of a trial solution for its periodic fitness evaluation, expected fitness estimation from the measured noisy fitness samples, and crowding-distance-induced stochastic selection. First, the sample size for periodic fitness evaluation of each trial solution is adapted by means of the fitness variance in their local neighborhood. “Sampling” refers to the periodic fitness evaluation of a trial solution to diminish the risk of promoting inferior solutions in the noisy environment. It is worth mentioning that the adaptive selection of the sample size is momentous as increasing the sample size augments the quality measure of fitness at the cost of additional runtime. Here a nonlinear form (capturing the relationship between the sample size of a trial solution and the fitness variance in its local neighborhood) induced by an exponential function is regarded to efficiently balance the trade-off between runtime complexity and computational accuracy.Second, while measuring the fitness of a trial solution, traditional methods [4–6] refer to the average fitness of the samples. However, the average fitness presumes equal probability of occurrence of all fitness samples, and thus returns a poor fitness estimate when the noise variance (in the fitness measure of the solutions) in the local neighborhood of a selected trial solution is large. This problem is circumvented here by referring to the expected value of the fitness samples as the true fitness estimate of a trial solution. The expected fitness concerned with the occurrence probability of the fitness samples seems to give a better fitness measure of a given trial solution. We introduce a novel strategy to evaluate the expected fitness of the trial solutions from the distribution of the fitness samples in the entire sample space. In the present context, a density-based nonuniform partitioning of the fitness sample space is employed to capture the uncertainty involved in the fitness measurement of the noisy fitness samples.Finally, we develop a probabilistic selection (PS) policy to encapsulate the diversity as well as the quality of the non-dominated trial solutions even in noisy fitness landscapes. It is observed that the deterministic selection scheme of the crowding-distance-based sorting (used for promoting trial solutions from the same rank candidate pool to the next gen-eration), which is employed in traditional MOO algorithms, can lead to suboptimal or misleading sets of nondominated solutions in the noisy environment even when sampling is used [7]. The selection strategy here depends not only on the density of nondominated solutions surrounding an individual in the objective space, but also on the reliability of its mea-sured fitness samples. We develop a new probabilistic measure of the reliability based on the skewness of the distribution of the fitness samples. The degree of asymmetry of the distribution of the fitness samples is captured by skewness. Con-sequently, it provides a unique approach for identifying the rare fitness samples lying in the tail of the distribution. These infrequent samples (far away from the expected fitness) are assumed to occur because of the creeping of noise in the fitness landscapes. The rarer the occurrence of the infrequent samples (i.e., the closer the fitness samples are to the expected value with small skewness of the distribution), the greater is the degree of credibility of the fitness estimates of a given trial so-lution. The trial solutions having a greater crowding distance and a high grade of reliability (assessed using the probability of occurrence of no rare samples) are given more precedence during ranking of solutions in the same front.The evolutionary component of the proposed noisy MOO algorithm has been realized here by the differential evolution for MOO (DEMO) [8] algorithm for its proven merits in global optimization. Some of the attractive features of DEMO justi-fying its selection in the design of the proposed noisy optimization algorithm include the simplicity of its structure leading to ease of coding, very few control parameters, and faster convergence [48,49] in comparison with other MOO algorithms.Performance analysis of the proposed noisy optimization algorithm realized with DEMO—referred to as “differential evolution for noisy MOO” (DENMO) henceforth—is studied using the noisy version of a set of 23 benchmark functions. Exper-iments were undertaken to compare the potency of the proposed algorithm with differential evolution for MOO with noise (DEMON) [9], nondominated sorting genetic algorithm II (NSGA-II) with α-dominance operator (NSGA-II-A) [10], confidence-based dynamic resampling (CDR) [11], simulated annealing for noisy MOO [12], elitist evolutionary multiagent system [13], multiobjective evolutionary algorithm with robust features (MOEA-RF) [14], modified NSGA-II [7], noise-tolerant strength Pareto evolutionary algorithm [15], and Pareto front-efficient global optimization [16]. In this study, the objective functions are contaminated with noise samples taken from five noise distributions—namely, Gaussian, Poisson, Rayleigh, exponential, and random (with positive and negative expeditions of the noise amplitude within ±25% of the true fitness function values). Experiments reveal that the proposed realization outperforms other algorithms for four important performance metrics—that is, inverted generational distance (IGD), spacing, error ratio (ER), and hypervol",
            {
                "entities": [
                    [
                        136,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 514–540www.elsevier.com/locate/artintDuality in permutation state spaces and the dual search algorithmUzi Zahavi a, Ariel Felner b,∗, Robert C. Holte c, Jonathan Schaeffer ca Computer Science Department, Bar-Ilan University, Ramat-Gan, Israelb Department of Information Systems Engineering, Ben-Gurion University, Israelc Computing Science Department, University of Alberta, Edmonton, Alberta, CanadaReceived 2 August 2006; received in revised form 27 June 2007; accepted 22 October 2007Available online 6 November 2007AbstractGeometrical symmetries are commonly exploited to improve the efficiency of search algorithms. A new type of symmetry inpermutation state spaces, duality, is introduced. Each state has a dual state. Both states share important attributes such as theirdistance to the goal. Given a state S, it is shown that an admissible heuristic of the dual state of S is an admissible heuristicfor S. This provides opportunities for additional heuristic evaluations. An exact definition of the class of problems where dualityexists is provided. A new search algorithm, dual search, is presented which switches between the original state and the dual statewhen it seems likely that the switch will improve the chance of reaching the goal faster. The decision of when to switch is veryimportant and several policies for doing this are investigated. Experimental results show significant improvements for a number ofapplications, for using the dual state’s heuristic evaluation and/or dual search.© 2007 Elsevier B.V. All rights reserved.Keywords: Heuristics; Search; Admissibility; Duality1. Introduction and overviewThe states of many combinatorial problems (e.g., Rubik’s cube, 15-puzzle) are defined as placements of a set ofm objects into a set of n locations (where n (cid:2) m). All the different ways to put the objects into the locations with atmost one object per location defines a state space which is called a permutation state space in this paper.1 Given twostates in a permutation state space, start and goal, and a set of operators that transform one state into another, searchalgorithms such as A∗ [8] and IDA∗ [12] can be used to find the shortest sequence of operators that transform startinto goal. These algorithms use a cost function f (n) = g(n) + h(n), where g(n) is the cost to reach state n from startand h(n) is an admissible (i.e. is always a lower bound) heuristic function estimating the cost from n to goal.* Corresponding author.E-mail addresses: zahaviu@cs.biu.ac.il (U. Zahavi), felner@bgu.ac.il (A. Felner), holte@cs.ualberta.ca (R.C. Holte), jonathan@cs.ualberta.ca(J. Schaeffer).1 Strictly speaking, a permutation would require n, the number of locations, to be exactly the same as m, the number of objects. We have relaxedthis requirement and only demand that n (cid:2) m. We use the term strict permutation state space to refer to state spaces in which the states arepermutations in the strict sense (m = n).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.10.019\fU. Zahavi et al. / Artificial Intelligence 172 (2008) 514–540515The effectiveness of the search is greatly influenced by the accuracy of h(n). When h(n) is more accurate, thenumber of nodes generated in a search decreases and the goal state is reached sooner [16]. There is a tradeoff for thisreduction, however. More accurate heuristics usually consume a larger time overhead per node generated and thereforethe percentage reduction in the actual time needed to solve a problem is smaller in practice than the percentagereduction in the total number of generated nodes. Usually, the reduction in the number of generated nodes dominatesthe constant time per node and therefore a time reduction is seen as well [4,17].In this paper a new type of symmetry is discussed—duality. It is based on the observation that in strict2 permutationstate spaces, i.e., when m = n, the roles played by objects and locations are interchangeable. By reversing these roles,a state, S, can be mapped to its dual representation, Sd . Given an admissible heuristic, h, the value h(Sd ) is a lowerbound on the distance from S to the goal. Taking the maximum of h(S) and h(Sd ) can result in a better heuristicvalue for S and, hence, less search. Further, if h(Sd ) > h(S), this can be exploited by using a search algorithm thatswitches representations when it appears likely to be beneficial. The dual search algorithm searches in the original ordual search space, switching representations to whichever has a higher heuristic value.The contributions of this paper are as follows:• A formal definition of duality is given, along with precise conditions for it to be applicable. The dual of a state, S,is another state, Sd , that is easily computed from S and shares key search-related properties with S, such as beingthe same distance from the goal. Therefore any admissible heuristic for Sd can be used as an admissible heuristicfor S.• A new type of search algorithm, dual search, is introduced. It has the unusual feature that it does not necessarilyvisit all the states on the solution path that it returns. Instead, it constructs its solution path from path segmentsthat it finds in disparate regions of the state space. The jumping from region to region is effected by choosing toexpand Sd instead of S whenever doing so improves the chances of achieving a cutoff in the search.• Using the heuristic evaluation of the dual state (h(Sd )) in the search shows a significant performance improvementfor a number of domains. Adding the dual search algorithm further improves the results. For all the domainsstudied, the results represent the best in the published literature.The idea of duality is also used in the constraint satisfaction problems (CSP) literature, where flipping the rolesof variables and constraints produces a dual version of the problem. Independent of our work, Hnich et al. discussmethods to use duality in CSP applications [9]. For example, they exploit duality by choosing to solve the variationof the problem that appears to be faster to solve. By contrast, in this paper we introduce duality ideas in the context ofheuristic state-space search.The paper is organized as follows. Sections 2 and 3 present background material. In Section 4, the notion of simpleduality is defined. Simple duality is a special case of duality that only applies to strict permutation states spaces.Section 5 discusses the properties of the dual heuristic. Section 6 presents a new search algorithm based on duality,DIDA∗ (Dual IDA∗). Section 7 provides experimental evidence for the benefits of using the heuristic evaluation of thedual state and for the dual search algorithm. Section 8 provides generalization of the duality notion to a wider varietyof permutation state spaces that are not necessarily strict. Experimental results for the general case are then providedin Section 9. A summary and suggestions for future work are provided in Section 10. Preliminary versions of thispaper appeared in [7,20].2. Problem domains and permutation state spacesThis section introduces the three application domains used in this paper and gives a formal definition of permutationstate spaces. Pattern databases, used as the heuristic evaluation function for our application domains, are described.2.1. The sliding-tile puzzlesOne of the classic examples in the AI literature of a single-agent path-finding problem is the sliding-tile puzzle.Three versions of this puzzle are the 3 × 3 8-puzzle, the 4 × 4 15-puzzle and the 5 × 5 24-puzzle. They consist of a2 We also provide generalization of this idea to permutation state spaces that are not necessarily strict.\f516U. Zahavi et al. / Artificial Intelligence 172 (2008) 514–540Fig. 1. The 8-, 15- and 24-puzzle goal states.Fig. 2. 3 × 3 × 3 Rubik’s cube.square frame containing a set of numbered square tiles, and an empty position called the blank. The legal operatorsare to slide any tile that is horizontally or vertically adjacent to the blank into the blank position. The problem isto rearrange the tiles from some random initial configuration into a particular desired goal configuration. The statespace grows exponentially in size as the number of tiles increases, and it has been shown [19] that finding optimalsolutions to the sliding tile problem is NP-complete. The 8-puzzle contains 9!/2 (181,440) reachable state, the 15-puzzle contains about 1013 reachable states, and the 24-puzzle contains almost 1025 states. The goal states of thesepuzzles are shown in Fig. 1.The classic heuristic function for the sliding-tile puzzles is called Manhattan distance. It is computed by countingthe number of grid units that each tile is displaced from its goal position, and summing these values over all tiles,excluding the blank. Since each tile must move at least its Manhattan distance to its goal position, and a legal moveonly moves one tile, the Manhattan distance is a lower bound on the minimum number of moves needed to solve aproblem instance.2.2. Rubik’s cubeRubik’s cube was invented in 1975 by Erno Rubik of Hungary. It is one of the most famous combinatorial puzzleof our time. The standard version consists of a 3 × 3 × 3 cube (Fig. 2), with different colored stickers on each of theexposed squares of the sub-cubes, or cubies. Any 3 × 3 × 1 edge plane of the cube can be rotated 90, 180, or 270degrees relative to the rest of the cube. In the goal state, all the squares on each side of the cube are the same color. Thepuzzle is scrambled by making a number of random moves, and the task is to restore the cube to its original goal state.There are about 4 × 1019 different reachable states. There are 20 movable cubies and 6 stable cubies in the center ofeach face. The movable cubies can be divided into eight corner cubies, with three faces each, and twelve edge cubies,with two faces each. Corner cubies can only move among corner positions, and edge cubi",
            {
                "entities": [
                    [
                        72,
                        137,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1064–1093www.elsevier.com/locate/artintAnalysing inconsistent first-order knowledgebasesJohn Grant a,b, Anthony Hunter c,∗a Department of Mathematics, Towson University, Towson, MD 21252, USAb Department of Computer Science, University of Maryland, College Park, MD 20742, USAc Department of Computer Science, University College London, Gower Street, London WC1E 6BT, UKReceived 31 December 2006; received in revised form 14 November 2007; accepted 14 November 2007Available online 22 November 2007AbstractIt is well-known that knowledgebases may contain inconsistencies. We provide a framework of measures, based on a first-orderfour-valued logic, to quantify the inconsistency of a knowledgebase. This allows for the comparison of the inconsistency of diverseknowledgebases that have been represented as sets of first-order logic formulae. We motivate the approach by considering someexamples of knowledgebases for representing and reasoning with ontological knowledge and with temporal knowledge. Analysingontological knowledge (including the statements about which concepts are subconcepts of other concepts, and which conceptsare disjoint) can be problematical when there is a lack of knowledge about the instances that may populate the concepts, andanalysing temporal knowledge (such as temporal integrity constraints) can be problematical when considering infinite linear timelines isomorphic to the natural numbers or the real numbers or more complex structures such as branching time lines. We addressthese difficulties by providing algebraic measures of inconsistency in first-order knowledgebases.© 2007 Elsevier B.V. All rights reserved.Keywords: Measuring inconsistency; Paraconsistent logics; Inconsistency tolerance; Analysing inconsistency; Conflict resolution1. IntroductionThe need for handling inconsistencies in knowledgebases has been well recognised in recent years. Inconsistenciesmay arise for various reasons such as when information sources are merged or in the presence of integrity constraints.The use of first-order logic becomes problematical because a single (local) inconsistency leads to the (global) incon-sistency of the entire knowledgebase. Paraconsistent logics allow for local inconsistency without global inconsistency.Paraconsistent reasoning is important in handling inconsistent information, and there have been a number of proposalsfor paraconsistent logics, such as Da Costa’s Cω logics [11], developments of C systems [9], Priest’s three-valued logicLPm [33], Belnap’s four-valued logic [5], and versions of Belnap’s four-valued logic restricted to minimal models [1],for reasoning with inconsistent information. Further approaches, such as techniques for analysing and querying incon-sistent databases and knowledgebases [2,3,12,31], techniques for merging knowledgebases [4,7,27,28], and analyticaltechniques for inconsistent software specifications [19], have been proposed (for reviews of some applications see* Corresponding author.E-mail addresses: jgrant@towson.edu (J. Grant), a.hunter@cs.ucl.ac.uk (A. Hunter).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.006\fJ. Grant, A. Hunter / Artificial Intelligence 172 (2008) 1064–10931065[6,16]). Whilst these methods provide potentially valuable ways of using inconsistent knowledgebases, they do notprovide an adequate way of summarising the nature of the inconsistencies.Our interest in this paper is in providing a measure for the inconsistency of a knowledgebase represented as a set offirst-order logic formulae. By providing such a measure we can compare different knowledgebases and evaluate theirquality of information. If given the opportunity to choose between different knowledgebases, we may try to choosethe one that is least inconsistent.Four-valued paraconsistent logics have been used as the basis of an approach to measuring inconsistency in knowl-edgebases [14,20,21]. In this, each inconsistent set of formulae is reflected in the four-valued models for the set, andthen the inconsistency is measured in the models. This approach to measuring inconsistency has already been seen asa useful tool in analysing a diverse range of information types including news reports [23], integrity constraints [14],ontologies [32], software specifications [8,30], and ecommerce protocols [10]. However, this approach of measuringinconsistency has been restricted to either a propositional language or a language with predicates but without functionsymbols.In this paper, we present a framework for measuring inconsistency for a full first-order language, together withexamples in analysing ontological and temporal knowledge. Dealing with a full first-order language is potentiallyimportant in diverse applications (such as reasoning about specifications [13]), but it does also raise issues with regardto analysing arbitrarily large, including infinite, domains. To address these issues, our framework provides algebraicmeasures of inconsistency in first-order knowledgebases.2. Overview of our approachIn this section, we provide an informal overview of our approach together with some examples to motivate andillustrate our approach. We start by recalling that many diverse applications in computer science require the ability torepresent and reason with knowledge in a form that is more expressive than propositional logic. Furthermore, in manyapplications, there is a need to analyse inconsistency arising in knowledge.To illustrate the need for systems and/or users to analyse inconsistency, consider diverse applications such as toolsfor analysing formal software specifications (where parts of the specifications may have come from different sources),systems for disambiguation in natural language processing (where there are conflicting syntactic, semantic, or prag-matic parses of the text/speech being parsed), and tools for developing ontologies based on description logics (wherethere may be multiple ontologies perhaps from multiple sources that need to be combined by an ontology engineerinto a single coherent and consistent ontology). In these examples, and in many other potential applications, there iseither the need for an automatic system to analyse the degree of inconsistency arising in the available knowledge, orthere is the need for a system to provide a user (such as a software or knowledge engineer) with an assessment of thedegree of inconsistency arising in the available knowledge. Once the system/user has access to an assessment of thedegree of inconsistency, the system/user can make a more intelligent and better informed decision on the course ofaction to take on the inconsistency.In this paper we assume a knowledgebase is a set of formulae of classical first-order logic. We impose no restrictionson this. It can include function symbols, variable symbols, and quantifier symbols. And of course, a knowledgebasecan be inconsistent, and indeed, any formula in a knowledgebase may be inconsistent.Our approach to measuring inconsistency in a knowledgebase is to consider the “four-valued models” of it. Each ofthese models is based on what we call a bistructure, which essentially is a pair of classical interpretations: One of theseinterpretations is used for the satisfaction of positive literals (i.e. the atoms), and the other is used for the satisfactionof negative literals. So in a bistructure, both an atom and its negation, or neither, can be satisfied. This gives a four-valued semantics, so that an atom may be regarded as being exactly one of “true” or “false” or “both true and false”or “neither true nor false” in a bistructure. The semantics for more complex formulae is given by a generalisation ofBelnap’s four valued logic, which is a paraconsistent logic that we call tolerant logic. For our purposes, this semanticsis simple and the set of models for any knowledgebase is always nonempty.Given a bistructure, we apply a simple measure of inconsistency, denoted Inc, that gives the proportion of the tuplesin the bistructure that are in conflict. The amount of conflict in a bistructure is the number of tuples that are both trueand false. This is normalised by the total number of tuples that are possible in the interpretations (which is a functionof the size of the domain), so we get a value in the [0, 1] interval. For example, if we have a bistructure with just onemonadic relation R and two domain objects a1 and a2, and the first classical interpretation has both (cid:3)a1(cid:4) and (cid:3)a2(cid:4) (for\f1066J. Grant, A. Hunter / Artificial Intelligence 172 (2008) 1064–1093R), and the second classical interpretation has (cid:3)a1(cid:4) (for ¬R), then there is conflict with respect to the tuple (cid:3)a1(cid:4) andso the proportion of tuples in conflict is 1/2. Note, this measure is not restricted to Herbrand interpretations.We then generalise this measure of inconsistency to sets of bistructures. In order to set up our framework, andconsider various properties, we deal with sets of bistructures in general. But in practice, if we want to analyse aknowledgebase, we consider the set of models for the knowledgebase.For a knowledgebase, since our measure of inconsistency of a model is dependent on the domain size, we considerthe models for each domain size in turn. For each domain size, we find the minimum degree of inconsistency in amodel from the models of this size, using a function denoted MicroInc, and then we summarise this value obtained foreach size in the form of a ratio of univariate polynomial functions (i.e. a rational function) where the variable is thecardinality of the domain. The polynomial that is the numerator gives the minimum number of tuples in conflict forthe models of domain size n, and the polynomial that is the denominator gives the maximum number of tuples in themodels of domain size n. By representing the degree of inconsistency in the form of such a rational function, we havea concise su",
            {
                "entities": [
                    [
                        74,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 72 (1995) 1-52 Artificial Intelligence Computational research on interaction and agency Philip E. Agre * Department of Communication, University of California, San Diego, Lo Jolla, CA 92093-0503, USA Abstract research intelligence in artificial theories of agents’ has developed computational in their environments. Although inspired by a great diversity of formalisms Recent volvements architectures, terizations of agents’ interactions with their environments design of artificial ones. This article offers a conceptual several other fields of research that hold the potential projects, and summarizes It also briefly describes a case study in these ideas-a a short-order breakfast cook. Because it inhabits, Toast can employ an extremely in- and these research projects are unified by a common concern: using principled charac- to guide analysis of living agents and surveys framework for dialogue with these new computational the principal contributions of the articles in this special double volume. computer program called Toast that acts as in the world its designers have discovered useful structures to decide what to do next. simple mechanism for such theories, 1. Introduction The papers in this special double volume illustrate an emerging way of doing research in artificial intelligence, which might be stated compactly as follows: Using principled ronments to guide explanation and design. characterizations of interactions between agents and their envi- The purpose of this introduction explore is to explain this emerging in AI and elsewhere. its relationship to other research Let us begin with a familiar example. Consider a device style of research and to (a “controller”) that must an oil the operations of an oil refinery. So far as control direct refinery that can be adjusted (the settings of various valves and burners) number of “output variables” whose values at any given moment can be determined is an enormous machine (the “plant”) with a number of “control variables” from the outside is concerned, and a from theory * E-mail: pagre@ucsd.edu. Telephone: (619) 534-6328. Fax: (619) 534-7315 0004-3702/95/$09.50 SSDfOOO4-3702(94)00054-9 @ 1995 Elsevier Science B.V. All rights reserved \f2 PE. Agre/Artijicial Intelligence 72 (1995) 1-52 the outside let us say, maintaining must adjust the valves and burners (the readings on various sensors and gauges). The task of the “controller”, around certain values while is to stabilize terms, the controller other variables within certain fixed ranges. In concrete to sustain a fixed flow of oil without the plant blowing some of the output variables up. Given a proposed design to answer the plant in isolation. for this controller, how do we know whether simply by analyzing this question It is impossible obviously, does it suffice to analyze how the controller will interact with the plant. Given any particular and supposing of plant plus controller will follow a determinate ensure way to characterize relates changes rates of change, or past values, or both) of the output variables. it will work? itself. Nor, to analyze set of initial values, system trajectory. The designer’s goal is to trajectories has certain properties. One that equation the ongoing that the entire family of these interaction is in terms of a differential this family of trajectories in the control variables to the current values that the interaction is not stochastic, (and perhaps the combined for simplicity the controller it is crucial Instead, in this example might be regarded as an agent interacting with its envi- the plant, and differential equations provide one way of characterizing theory, of course, provides only one way of thinking It is tied to a particular model of interaction has been profoundly its historical development The controller ronment, namely such interactions. Control interactions. variables), safety and conservatism matical. A principled qualities of natural ones. Indeed, we have deliberately opposed of theories of interaction. The important should allow us to address questions to, say, “formal”) characterization like these: in relatively well-behaved of interaction, to provide a useful guide to the design of artificial agents and the explanation in order to include an unforeseeable range of possible chosen the vague word “principled” thing is that our characterization (as types of interaction about (through output and control influenced by the need for systems, and it is thoroughly mathe- though, need not have any of these l What will our agent do in a given environment? l Under what conditions will it achieve its goals or maintain desired relationships with other things? l In what kinds of environments will it work? aspects of an environment, l How do particular the workings of artifacts, affect particular that have particular properties? interactions such as topography or mutability or in types of agents’ abilities to engage l What forms of interaction require an agent to employ particular elements of internal architecture, such as memory? to make any a prioti of our agents. To the contrary, l What forms of interaction permit an agent to learn particular knowledge or skills? the about in as general a and theory can in this special double volume, some is and no single To ask these questions, we do not need architecture way as possible, forms of interaction give a complete though, each provide detailed particular thus explicitly is to understand, the properties of agents, environments, examples of the analysis of interactions within in approach, advocating no single architecture among them. Of course, account of this vast topic. The papers the relationships between This special double volume domain of architectures and environments. that any single it is doubtful assumptions ecumenical the point \fPE. Agre/Art$cial Intelligence 72 (I 995) l-52 3 the shared formalism. Through of interactions, we hope that each project can benefit can benefit from the three-dimensional can offer. themes that arise within picture of research the principled characterization from the others, and that readers in this area that this approach This introduction cannot attempt a complete synthesis of research in this area, nor is it reported representing the research a definite group or movement. together with examples and conceptual discussion. as follows. Section 2 outlines research on interaction Instead, in this special double volume and technical world. It is organized that arise when doing computational it offers one perspective in the larger is situated a series between agents In so doing, the territory of research covered by this special double reported for further the individual papers in this and their to one another. Section 5 presents a case study in the ideas of the special a manifesto on how intellectual of themes and their environments, it also specifies more precisely volume. Section 3 describes here and research computational special double volume, offering comments relationships double volume. Section 6 concludes with a prophesy research. between in other fields. These connections may provide research on interaction. Section 4 summarizes and plea for interdisciplinary the research inspiration on their distinctive the conceptual contributions connections 2. Studying interaction It is far too early to assemble through and agency. of interaction have been developing computational which offered here should be understood things to formulate research reported here and through the existing it builds. Putting words to these intuitions It is possible, the progress of research though, a rulebook for research into computational to convey some of the intuitions in this area, both theories that the traditions of research upon is a hazardous matter, and the words as heuristic devices, as first passes, and as invitations through in different ways, through different metaphors. 2.1. Mapping the territory to define carefully the scope of research reported here. Let us to the number of agents involved it is necessary research on agents interacting with the world to be arrayed in a two-dimensional First imagine and field, with one axis corresponding the other axis corresponding to the degree of realism with which the world is modeled. (See Fig. 1.) A single agent interacting with a very simple world would lie toward the in to model human origin of this diagram. Any project a realistic way would lie in the upper-right the in three areas: future simple environ- in enough detail life, or the lives of most animals, corner of the diagram, and that is surely research clusters interacting with relatively are analyzed ideal of much of the field. As it is, most current in the interaction ( 1) Research single agents that explores ments, where particular aspects of the environment to bring out larger points. (2) Research on relatively complex extremely simple environments, where forms of interaction the interaction among is largely several agents symbolic in and \fFE. Agre/Arti’cial lnfelligence 72 (1995) 1-52 many Number of agents Area 3 a few Area 2 one I Area 1 IOW high Complexity of environment Fig. I. Current Al research falls mostly into three clusters. which can be contrasted according to the degree of complexity of the environments they deal with and the number of interacting agents they employ. depends the interaction. little on the agents’ bodies. The emphasis is on the logical structure of agents in slightly in some way on (3) Research on relatively simple interaction among numerous in this special double volume more complex environments, where the interaction does depend the agents being embodied. The agents may be physical and the emphasis robots or simulations, is on the emergence of order from simple forms of interaction. The papers three clusters, with the exception of the paper by Shoham and Tennenholtz, which lies in the symbolic third. As a result, numerous to an forms of interactio",
            {
                "entities": [
                    [
                        72,
                        120,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 218 (2015) 23–55Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe limits of decidability in fuzzy description logics with general concept inclusions, Rafael Peñaloza a,b,∗, Felix Distel a,∗Stefan Borgwardt a,∗a Institute for Theoretical Computer Science, Technische Universität Dresden, 01062 Dresden, Germanyb Center for Advancing Electronics Dresden, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 25 November 2013Received in revised form 11 August 2014Accepted 25 September 2014Available online 2 October 2014Keywords:Fuzzy description logicsTriangular normsOntology consistencyDecidability1. IntroductionFuzzy description logics (DLs) can be used to represent and reason with vague knowledge. This family of logical formalisms is very diverse, each member being characterized by a specific choice of constructors, axioms, and triangular norms, which are used to specify the semantics. Unfortunately, it has recently been shown that the consistency problem in many fuzzy DLs with general concept inclusion axioms is undecidable. In this paper, we present a proof framework that allows us to extend these results to cover large classes of fuzzy DLs. On the other hand, we also provide matching decidability results for most of the remaining logics. As a result, we obtain a near-universal classification of fuzzy DLs according to the decidability of their consistency problem.© 2014 Elsevier B.V. All rights reserved.Description logics (DLs) [1] are a family of knowledge representation formalisms, designed to represent the terminological knowledge of a domain in a formally well-understood way. They form the base language for many large-scale knowledge bases, like Snomed CT1 and the Gene Ontology,2 but arguably their largest success to date is the recommendation by the W3C of the DL-based language OWL as the standard ontology language for the Semantic Web.3 DLs essentially allow to state relations between concepts, which represent subsets of a specific domain containing exactly those domain elements that share certain properties. Roles correspond to binary relations that allow to state connections between concepts. For example, the concept of a human father can be expressed asHuman (cid:3) Male (cid:3) ∃hasChild.(cid:5),which describes the set of all humans that are male and have a child. Here, Human and Male are atomic concept names, whereas hasChild is a role name. Domain-specific relations between concepts can be expressed in axioms such asbob : Male,Human (cid:6) ∀hasChild.Human,* Corresponding authors. Tel.: +49 351 463 38231; fax: +49 351 463 37959.E-mail addresses: stefborg@tcs.inf.tu-dresden.de (S. Borgwardt), felix@tcs.inf.tu-dresden.de (F. Distel), penaloza@tcs.inf.tu-dresden.de (R. Peñaloza).1 http :/ /www.ihtsdo .org /snomed-ct/.2 http :/ /www.geneontology.org/.3 http :/ /www.w3 .org /TR /owl2-overview/.http://dx.doi.org/10.1016/j.artint.2014.09.0010004-3702/© 2014 Elsevier B.V. All rights reserved.\f24S. Borgwardt et al. / Artificial Intelligence 218 (2015) 23–55saying that bob is a male individual, and that every human can only have human children, respectively. The former axiom is called an assertion, the latter a general concept inclusion (GCI). In DLs, various reasoning problems over a set of such axioms, called an ontology or knowledge base, are studied. The most fundamental one is to decide whether an ontology is consistent; that is, if the restrictions expressed by its axioms can actually be realized in a model. Different sets of constructors for expressing concepts, such as conjunctions ((cid:3)) or value restrictions (∀), lead to logics of varying expressivity, resulting in differences between the computational complexity of their consistency problems. For example, in the inexpressive DL EL, consistency is trivial, whereas other reasoning problems such as subsumption have only polynomial complexity. In the more expressive ALC, consistency without GCIs is PSpace-complete, and is ExpTime-complete in the presence of GCIs. The very expressive SROIQ, the formalism underlying the OWL 2 Direct Semantics, has a 2-NExpTime-complete consistency problem.In their classical form, however, DLs are not well-suited for representing and reasoning with the vagueness and impre-cision that are endemic to many knowledge domains, e.g. in the bio-medical fields. For example, one of the most common symptoms of diseases is the presence of fever, which is characterized by a high body temperature. Clearly, it is not possible to precisely distinguish high body temperatures from non-high body temperatures. In order to appropriately represent this knowledge, it is necessary to use a formalism capable of handling imprecision. Fuzzy variants of DLs have been introduced as a means of handling imprecise terminological knowledge. This is achieved by interpreting concepts as fuzzy sets. In a nut-shell, a fuzzy set associates with every element of the universe a value from the interval [0, 1], which expresses its degree of membership to the set. This makes it possible to express, e.g. that 38 °C is a high body temperature to degree 0.7, while 39 °C belongs to the same concept with degree 1.Compared to classical DLs, fuzzy DLs have an additional degree of freedom for choosing how to interpret the logical constructors. A standard approach, inherited from mathematical fuzzy logic [2,3], is to use a continuous triangular norm (t-norm) [4] to interpret conjunction. The three most commonly used t-norms, called Gödel, Łukasiewicz, and product, have the interesting property that all other continuous t-norms can be represented by composing copies of them in a certain way. From the chosen t-norm ⊗, the semantics of all other logical constructors is determined, generalizing the properties of the classical operators. Ontologies of fuzzy DLs generalize classical ontologies by annotating each axiom with a fuzzy value that specifies the degree to which the axiom holds. For example, a fuzzy assertion like (cid:9)bob : ∃hasFever.High ≥ 0.6(cid:11) can specify that an individual (in this case bob) belongs to a fuzzy concept (∃hasFever.High) at least to a certain degree (e.g. 0.6).For the last two decades, research on fuzzy DLs has covered many different logics, from the inexpressive EL [5] to the expressive SROIQ(D) [6], from simple fuzzy semantics [7] to ones covering all continuous t-norms [8], from acyclic terminologies [9] to GCIs [10]. Fuzzy reasoning algorithms were implemented [11,12] and the use of fuzziness in practical applications was studied [13,14]. Recently, the focus in the area changed when some tableau-based algorithms for DLs allowing general concept inclusions were shown to be incorrect [15,16]. This raised doubts about the decidability of the consistency problem in these logics, and eventually led to a plethora of undecidability results for fuzzy DLs [16–19]. In particular, one does not need to go beyond the expressivity of ⊗-ALC to get undecidability [18,19].The main goal of this paper is to characterize the limits of decidability in fuzzy DLs; in other words, we want to partition the family of fuzzy DLs according to the decidability of consistency in them. For the cases where the problem is decidable, we are also interested in finding precise complexity bounds. Given the sheer number of fuzzy DLs available, identified by the set of constructors, types of axioms, and t-norm that they use, it is infeasible to study each of them independently. Instead, we develop general methods for proving (un)decidability of these logics.Most of the known undecidability results [16,17,19] focus on one specific fuzzy DL; that is, undecidability is proven for a specific set of constructors, axioms, and chosen semantics. The papers [16,17] show undecidability of (extensions of) ⊗-ALCf,≥, where ⊗ is the product t-norm, while [19] shows the same for the Łukasiewicz t-norm. The only exception is [18], where undecidability is shown for ⊗-IALf,= for all t-norms ⊗ “starting” with the product t-norm. Abstracting from the details of each specific logic, all these proofs of undecidability follow the same basic pattern. In essence, it is shown that the logic satisfies a series of properties that allows it to encode the Post Correspondence Problem [20].In the first part of this paper, we generalize these ideas and describe a set of properties that together imply undecid-ability of a fuzzy DL. We use this general framework to strengthen all previously known undecidability results to cover all continuous t-norms except the Gödel t-norm, for which the problem is decidable [21]. Additionally, we present some vari-ants on the same ideas that allow us to prove undecidability of fuzzy DLs that do not fit precisely into the main framework. For instance, we show that the fairly inexpressive fuzzy DL ⊗-IEL= is undecidable for any continuous t-norm ⊗ except the Gödel t-norm. This can be strengthened to the even less expressive ⊗-NEL if ⊗ starts with the Łukasiewicz t-norm. These logics are of interest since they correspond to fuzzy variants of the prototypical classical DL ALC. Indeed, they have the same expressivity as ALC when their semantics is restricted to the two classical truth values.In the second part of the paper, we complement these results by considering fuzzy DLs based on t-norms that do not start with the Łukasiewicz t-norm, which in particular includes the product and Gödel t-norms. Under this assumption, we show that consistency is decidable even for the very expressive logic ⊗-SROIQf,≥ if axioms are not allowed to express upper bounds. We show an even stronger result: under these conditions, an ontology is consistent w.r.t. fuzzy semantics iff it is consistent w.r.t. crisp semantics, i.e. using only the classical truth values 0 and 1. Thus, ontology consistency in ⊗-SHOI is ExpTime-complete, and in ⊗-SROIQ it is 2-NExpTime-complete. If these restrictions are not met, then the p",
            {
                "entities": [
                    [
                        134,
                        220,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 97 ( 1997) 169-193 Artificial Intelligence Defaults and relevance in model-based reasoning ’ Roni Khardon”v*, Dan Roth b-2 a Aiken Computation Laboratory, Harvard University. Cambridge, MA 02138, USA b Department of Applied Mathematics and Computer Science, Weizmann Institute of Science, Rehovot 76100, Israel Received September 1995; revised May 1996 Abstract representations Reasoning with model-based is an intuitive paradigm, which has been shown to be theoretically sound and to possess some computational advantages over reasoning with formula-based representations of knowledge. This paper studies these representations and further substantiates the claim regarding their advantages. In particular, model-based representations are shown to efficiently support reasoning in the presence of varying context information, handle efficiently fragments of Reiter’s default logic and provide a useful way to integrate learning with reasoning. Furthermore, these results are closely related to the notion of relevance. The use of relevance information is best exemplified by the filtering process involved in the algorithm developed for reasoning within context. The relation of defaults to relevance is viewed through the notion of context, where the agent has to find plausible context information by using default rules. This view yields efficient algorithms for default reasoning. Finally, it is argued that these results support an incremental view of reasoning in a natural way, and the notion of relevance to the environment, captured by the Learning to Reason framework, is discussed. @ 1997 Elsevier Science B.V. Keywords: Knowledge representation; Common-sense reasoning; Learning to reason; Reasoning with models; Context; Default reasoning * Corresponding author. Email: roni@das.harvard.edu. Research supported by AR0 under grant DAALOS- 92-G-01 15 and by ONR grant NOOOl4-96-I-0550. ’ An earlier version of the paper appears in Proceedings of the International Joint Conference on Art$icial Intelligence (IJCAI-95) ? Email: danr@wisdom.weizmann.ac.il. Research supported by the Feldman Foundation. Part of this work was done while at Harvard University, supported by NSF grant CCR-92-00884, DARPA AFOSR-F4962-92-J-0466 and ONR grant NOOO14-96-1-0550. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. P/ISOOO4-3702(97)00044-l \f170 R. Khardon, D. Roth/Artificial Intelligence 97 (1997) 169-193 1. Introduction A considerable amount of work on the theoretical foundations of artificial intelligence has been devoted to capturing some of the intuitive notions of human reasoning. An introspective view suggests that the notion of relevance is central to human reasoning. Many “common-sense” reasoning situations are characterized by the abundance of po- tentially relevant information sources. Yet, humans seem to pick up just the relevant information and ignore the irrelevant. This ability may account for the speed with which reasoning is performed in everyday situations. In this paper, relevance is viewed as a notion that can be used to reduce the computational cost of reasoning, by focusing on information that pertains to the situation or task at hand, and ignoring the information which does not bear on this situation. We study several tasks in the framework of logi- cal reasoning, and show that relevance information can indeed be useful. In particular, we show that when performing reasoning with models-namely, when reasoning is per- formed by considering examples from the world we reason about-relevance information can be used to efficiently tackle several reasoning tasks. The generally accepted framework for the study of reasoning in intelligent systems is the knowledge-based system approach. The idea is to store the knowledge in some representation language with a well defined meaning assigned to its sentences. The sentences are stored in a knowledge base (KB) which is combined with a reasoning mechanism that is used to determine what can be inferred from the sentences in the KB. Various knowledge representations can be used to represent the knowledge in a knowledge-based system. Different representation systems (e.g., a set of logical rules, a probabilistic network) are associated with corresponding reasoning mechanisms, each [ 14,181. Given a logical knowledge with its own merits and range of applications base, for example, reasoning can be abstracted as a deduction task: determine whether a sentence, assumed to capture the situation at hand, is logically implied by the knowledge base. It is also widely agreed that a large part of our everyday reasoning involves arriving that are not entailed by our “theory” of the world. Many conclusions at conclusions are derived in the absence of information that is sufficient to imply them. This type of reasoning is naturally nonmonotonic since further evidence may force us to revise our conclusions. Several formalizations trying to capture this situation have been studied, and of particular interest to us here are theories for reasoning with “defaults” (see e.g. [20] ). In this approach, the true knowledge about the world is augmented by a set of default rules that are meant to capture “typical” cases. The quest is for a reasoning system that, given a query, responds in a way that agrees with what we know about the world and (some of) the default assumptions, and at the same time supports our intuition about a plausible conclusion. Computational considerations, however, render this approach inadequate for common- sense reasoning. This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation [ 23,251. This holds in particular for various formalizations of default reasoning [ 6,17,26], where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce \fR. Khardon, D. Roth/Artificial Intelligence 97 (1997) 169-193 171 the complexity expressiveness paper we show that model-based above-mentioned results. difficulties, of reasoning. This remains true, even when we severely of the knowledge base, the default rules and the queries allowed. representations can be used to overcome and that the notion of relevance is useful in deriving restrict the In this some of the these We incorporate the notion of relevance into the study of reasoning by introducing completes this situation the task of reasoning within context. normally We model context-specific where some additional formalize is that the availability easier, by restricting performs model-based efficient constraining reasoning. reasoning It has been argued a lot of missing context by augmenting the agent’s knowledge information when answering queries that in real life situations, one [ 121. the world with task, base. We about is therefore a deduction to the knowledge information. Reasoning within context information is added this task as the problem of reasoning within a varying context. The intuition task information to reason about. As we show, if the agent can be easily used, and yields information context of additional the domain one needs should make the reasoning then context reasoning reasoning assignments, is presented, In model-based [ 5,9] examples) It is not hard to motivate a model-based as a set of models the knowledge base is represented of the world rather than a logical formula describing (satisfying the query on these it. When a query models. from a cognitive point of view and indeed most of the proponents of this approach have been cognitive [ 3,4,11 J, who have alluded psychologists from examples” on a qualitative basis. In the AI community Levesque’s notion of “vivid” frames-theory to the notion of “reasoning this approach can be seen as an example of to Minsky’s [ 151 and to some of the work in case-based [ 12,131, and is somewhat is performed by evaluating related [ lo]. to reasoning reasoning approach Given a model-based representation task of deciding whether KB implies straightforward way: Evaluate LY on all the models a model of KB which does not satisfy KB /= a. Clearly, then, by definition, But representing KB by explicitly holding all model-based approach becomes representation if the model-based this approach verifies and still support correct deduction. feasible reasoning of the knowledge base KB, and a query a, the in a cy (denoted KB /= a) can be performed If you find that all the models of KB (Y, then KB &c: a, otherwise in the representation. representation conclude contains the implication, and yields correct deduction. the possible models is not plausible. A if KB can be replaced by a small model-based The theory of model-based representations developed [ 91 (generalizing the the- ory developed languages tion. It is shown based setting, propositional efficient before. reasoning in [5] for the case of Horn expressions) the propositional for which model-based representations that in many cases the model-based variables in the domain). Thus, representation can be obtained in which deduction support efficient deduction and abduc- in the formula- in the number of setting, correct and in cases where such algorithm were not known is small in the model-based (polynomial is NP-hard When reasoning within context, our general knowledge with additional has an easy and natural constraints, those implementation that are relevant to the current when using model-based about the world is combined task The situation, This representations. in characterizes \f172 R. Khardon, D. Roth/Art@cial Intelligence 97 (1997) 169-193 simply as a background filters out models that are not consistent with the context in the representation which are not relevant to the algorithm current context, namely models information. The remaining models are used as before for reasoning with models. The filtering process can there",
            {
                "entities": [
                    [
                        76,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 82 (1996) 157-179 Artificial Intelligence Noise modelling and evaluating learning from examples Ray J. Hickey* Faculty of Informatics, University of Ulster at Coleraine, Ulster, Co. Londonderry BT52 lSA, N. Ireland, UK Received July 1993; revised July 1994 Abstract The means of evaluating, using artificial data, algorithms, such as ID3, which learn to as the method of artificial universes. from examples is enhanced and referred is treated as a dependent variable with description attributes concepts The central notions are that of a class model and its associated representations class attribute the independent using irrelevant attribute a small universe which is then altered data generated noise has a detrimental is discussed and modelled The notion of an the construction of to increase noise. Learning curves for ID3 used on from trials. These show that increasing from these universes are estimated effect on learning. variables. The nature of noise in the model is also considered. The ideas are illustrated in which a as that of majorisation. information-theoretic ideas especially functioning through 1. Introduction Supervised learning of concepts major interest. Amongst are: induction of decision [S]); instance-based Niblett artificial neural networks Goldberg and Holland Iba and Thompson the many approaches from classified examples remains a problem of that have been taken to this task rules (Clark and [9]); (see Booker, [6] and Langley, (see Aha [2] and Cost and Salzberg [26]); genetic classifiers [24]), or high-level trees (Quinlan learning (Rumelhart [4]); B y a esian classifiers (see Cheeseman [17]). the examples presented Typically to the algorithm are representative in some sense of a set of possible examples and often constitute a very small subset. Each language (often example consists of a description in an appropriate just a simple attribute-value the assigned class or concept offered by the teacher. The learning task is therefore one of induction of a general concept description from the particular cases provided. together with representation formalism) * Telephone: +44-(0)1265-44141. E-mail: rj.hickey@ulst.ac.uk 0004-3702/96/$15.00 SSDZ 0004-3702(94)00094-S 0 1996 Elsevier Science B.V. All rights reserved \f158 R.J. Hickey I Artificial Intelligence 82 (1996) 157-179 In real-world settings the task is complicated by the presence of noise of various forms such as errors attribute values or in classification by the teacher. This not only makes the work of the learning algorithm more difficult but also complicates Performance of an algorithm or comparison of several algorithms the evaluation of its performance. in recording is usually assessed by one of the following means: (1) Empirical analysis using real data. From a database of examples (such as one of the standard (Murphy learning. Further classification performance and Aha sets kept in the “Machine Learning Repository” [21])) subsets are drawn at random and used for subsets are then drawn and used for evaluation of the of the learned description. (2) Empirical analysis using artificial data. In order the effects of to simulate to a given prescription and then aspects noise, data is generated according of the example description or the class are altered using a mechanism involving known probabilities. Irrelevant attributes may be introduced. (3) Average-case analysis. Examples to a known probabilistic prescription. The expected value behaviour of the learning algorithm is then derived. are generated according (4) PAC analysis. The probably correct approximately of basis for assessing performance. A by an algorithm [31] provides a theoretical is said to be PAC-learnable Valiant if with probability concept 1 - 6 the learned concept description has a probability 1 - E of classifying the analysis is probabilistic, almost correctly on subsequent no underlying distribution is assumed and it is therefore “worst case” over all possible distributions. trials. Although for examples (PAC) theory (2) provides greater opportunity [16] argue that method than method the most well-known artificial data sets containing In the first three methods a learning curve showing performance (typically classification accuracy) against number of training examples can be derived. For methods (1) and (2) this curve is estimated from data over many trials. Kibler and for systematic Langley investigation (1) particularly with regard to the controlled adminis- tration of noise; in method (1) the naturally occurring noise cannot be quantified satisfactorily. Amongst an element of noise is the LED domain of Breiman et al. [5] where components of an LED display for digits are inverted with a small probability. Aha [l] has introduced a variation of the empirical approach by taking a database and altering it in a random (called a case) which retains In method from the essential characteristics of the original. (3) the theoretical the underlying derived Pazzani and Sarrett [22] or Langley et al. [17]. Unfortunately feasible only for simple algorithms. Analysis of more sophisticated such as ID3 appear learning curve can, mathematics permitting, be see this approach seems algorithms [26]) would setup (into which noise may be introduced); to produce a variant for experimentation [24,25]) or backpropagation (Rumelhart (Quinlan fashion to be too difficult. (l)-(3), Unlike methods performance of an algorithm the PAC approach offers very little insight into the and is overly pessimistic in typical circumstances \fR.J. Hickey I Artijicial Intelligence 82 (1996) 157-l 79 1.59 about its capabilities. Pazzani and Sarrett [22] show learning curves derived from the average case and PAC approaches. For noise modelling in the PAC approach [27]. see Valiant [32], Angluin and Laird [3] or Sakakibara 1.1. Modelling noise and extending the use of artificial data: the method of artificial universes Although, as indicated above, the introduction of noise in a systematic way can the modelling has often (2), (3) and (4), in practice in methods be undertaken been ad hoc and lacking in any underlying theory. The resulting artificial domains are then not sufficiently realistic with regard to complexity of noise. Also it may not be clear how much noise overall has been introduced. The purpose of this work (2) by introducing to measure and modify with ease the amount of noise in an artificial system. Amongst the benefits of this approach are: is to enhance theory of noise which makes the capabilities of method it possible a unified (1) a simple means of producing data sets which possess the required amount tasks for a wide range of algo- of noise and which provide challenging rithms; (2) greater clarity concerning the relative importance of different sources of noise; (3) greater insight into the nature of noise and information and how these may be explicated. The approach involves specifying a complete probabilistic model for attributes used in the example description and the class. This will be referred an artificial universe. The class model of the universe will declare between descriptions and class distributions-as The class model can be represented table to a comparatively relationships distinct from individual classes. forms from an exhaustive small set of very general rules. An artificial universe can be used to generate examples for use by any of the types of learning algorithm mentioned above and, after learning has taken place, can provide a true indication of the performance of a learned concept description. Since approximated from a series of trials involving generated examples. is a random variable in many different value behaviour its expected can be latter the the to as Noise will be modelled using the class distributions amount of noise will be manipulated principally using the majorisation which is concerned with the relative degree of inequality amongst elements in this case a vector of probabilities constituting a distribution. real vector, in the class model. The relation in a Although what (2) above is merely an extension or elaboration is proposed here it will be referred of method to as the method of artificial universes. Specifying a complete probability model for the generation of data is hardly a new idea. Many of the artificial domains in the literature such as the LED domain [5] generators offering a limited noise modelling are such models. General-purpose see, for example Lounis and Bisson [18]. In capability have also been developed; a simple yet general means of essence the contribution is to provide here \f160 R.J. Hickey I Artificial Intelligence 82 (1996) 157-179 prescribing a particular amount of noise and in a way which is largely independent of its physical source. The ideas in this paper were outlined by Hickey method was illustrated sequent experimentation trates on the underlying [14] is performed but with a much larger number of trials. the construction using ID3 on generated theory although a similar set of experiments through [14] where the use of the of a small universe and sub- examples. The paper concen- to those in 1.2. Plan of the paper The definition of an artificial universe and its class model are given in Section 2 of the class model is also in Section 3. Two and a running example is introduced. The representation discussed. The modelling of different types of irrelevant attribute role of majorisation (pure noise and redundant) in explicating noise and its relationship types of noise is addressed are defined. The to other in Section 4. This is applied to produce ideas are reviewed information-theoretic information statistics for a universe. In Section 5 the means of assessing the performance of a deterministic classifier, results obtained from using is discussed. Experimental learning, through from universes with varying degrees of noise are reported. acquired ID3 on data generated 2. Artificial universes (referred set together with An obj",
            {
                "entities": [
                    [
                        66,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 1–24Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInconsistency measures for probabilistic logicsMatthias ThimmInstitute for Web Science and Technologies, Universität Koblenz–Landau, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 23 February 2012Received in revised form 27 July 2012Accepted 4 February 2013Available online 7 February 2013Keywords:Inconsistency measuresInconsistency managementProbabilistic reasoningProbabilistic conditional logic1. IntroductionInconsistencies in knowledge bases are of major concern in knowledge representation andreasoning. In formalisms that employ model-based reasoning mechanisms inconsistenciesrender a knowledge base useless due to the non-existence of a model.In order toinconsistencies are mandatory.restore consistency an analysis and understanding ofRecently, the field of inconsistency measurement has gained some attention for knowledgerepresentation formalisms based on classical logic. An inconsistency measure is a toolthat helps the knowledge engineer in obtaining insights into inconsistencies by assessingtheir severity. In this paper, we investigate inconsistency measurement in probabilisticincorporates uncertainty and focuses on the role ofconditionalconditionals, i.e. if–then rules. We do so by extending inconsistency measures for classicallogic to the probabilistic setting. Further, we propose novel inconsistency measures that arespecifically tailored for the probabilistic case. These novel measures use distance measuresto assess the distance of a knowledge base to a consistent one and therefore takes thecrucial role of probabilities into account. We analyze the properties of the discussedmeasures and compare them using a series of rationality postulates.logic, a logic that© 2013 Elsevier B.V. All rights reserved.The field of knowledge representation and reasoning [4] is concerned with formal representations of knowledge andhow these formalizations can be used for reasoning, i.e., how new information can be automatically inferred using a formalsystem. One of the big issues in knowledge representation is accuracy. Usually, the term “knowledge” is used to describestrict or objective information that is considered to be absolutely true in the given frame of reference, i.e. the real world.The counterpart, denoted by “subjective knowledge” or “beliefs”, is used to describe information that is assumed to be true bythe individual under consideration. While strict knowledge describes—by definition—a consistent state, subjective knowledgemight be flawed in several aspects. Besides being incorrect with respect to the real world, subjective knowledge can beincomplete, uncertain, or inconsistent. That is, for some piece of information I it might be unknown whether I is true orfalse (incompleteness), I might be believed only to a certain degree (uncertainty), or I might be in conflict with anotherpiece of information Iimplies that at least(inconsistency). Note that inconsistency of two pieces of information I and Iwith the state of the real world, anone of them is incorrect. However, even without the possibility to compare I and Iinconsistency can be detected by a being capable of reasoning, which is not necessarily true for incorrect information ingeneral. In this paper, we do not consider the general problem of incorrect information and always assume that representedpieces of information are subjective. However, as some terms like knowledge base have been established in the literature weadapt those conventions.(cid:2)(cid:2)(cid:2)Within the field of knowledge representation and reasoning there are several subfields that deal with incomplete, un-certain, and/or inconsistent knowledge such as default [27] and defeasible reasoning [19], argumentation [2,26], or possibilisticE-mail address: thimm@uni-koblenz.de.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.001\f2M. Thimm / Artificial Intelligence 197 (2013) 1–24and fuzzy reasoning [33]. Among the most established logical frameworks for dealing with uncertainty is probability theory[23,25]. There have been numerous works on combining probability theory with knowledge representation. For example,Bayesian networks and Markov nets allow for derivation of uncertain beliefs from other uncertain beliefs. Especially inapplication areas such as medical diagnosis, where the user has to rely crucially on the certainty of individual recommen-dations, reasoning using probabilistic models of knowledge serves well [24].In this paper we employ probabilistic conditional logic [28] for representing uncertain knowledge. In probabilistic condi-tional logic, knowledge is represented using probabilistic conditionals (ψ | φ)[p] with the intuitive meaning “if φ is truethen ψ is true with probability p”. Probabilistic conditional logic has been studied extensively under several aspects, e.g.effective reasoning mechanisms [9], default reasoning [20], or extensions with first-order logic fragments [15,16]. Moreover,the field of information theory provides a nice solution to the problem of incomplete information in probabilistic conditionallogic. Using the principle of maximum entropy [23] one can complete uncertain and incomplete information in order togain new information that was unspecified before, see also [28,14]. The expert system SPIRIT [30] is a working system thatemploys reasoning based on the principle of maximum entropy. It has been applied to various fields of operations researchsuch as project risk management [1] and portfolio selection [29]. Though reasoning with maximum entropy can deal withincomplete and uncertain information, it is not suitable for reasoning with inconsistent information. But inconsistency is aubiquitous matter and human beings have to deal with it all the time. In knowledge engineering and expert system design itbecomes most apparent when multiple experts try to build up a common knowledge base. However, the issue of extendingreasoning with maximum entropy to inconsistent knowledge bases has been dealt with in the literature only little so far,cf. [31,8,6].In this paper, we investigate inconsistencies in probabilistic conditional logic from an analytical perspective. One wayto analyze inconsistencies is by measuring them. An inconsistency measure is a function that quantifies the severity ofinconsistencies in knowledge bases. An inconsistency value of zero indicates no inconsistency (and therefore consistency)while the larger the inconsistency value, the more severe the inconsistency. Thus, an inconsistency measure can be seen asthe counterpart to an information measure [5] for the case of inconsistent information. Recently, there has been a gain inattention to approaches for measuring inconsistency in classical logics, see e.g. [13,11]. In general, an inconsistency measurecan be used to support the knowledge engineer in building a consistent knowledge base or repairing an inconsistent one. Forexample, Grant and Hunter [11] develop an approach for stepwise inconsistency resolution of inconsistent knowledge basesthat makes use of inconsistency measures. In their approach, a knowledge base is repaired by e.g. deleting or weakeningformulas. There, inconsistency measures serve as heuristics for selecting the right formula that has to be modified, i.e. byselecting that one that maximizes consistency gain. Inconsistency measures can also be used to determine which pieces ofinformation are most responsible for producing the inconsistency. In [13,36] the Shapley value [32] is used to distributethe inconsistency value of a knowledge base among the individual formulas. In a setting where knowledge is merged fromdifferent sources this information can help in identifying the responsible contributors.However, classical approaches for inconsistency measurement do not grasp the nuances of probabilistic knowledge andallow only for a very coarse assessment of the severity of inconsistencies. In particular, those approaches do not take thecrucial role of probabilities into account and exhibit a discontinuous behavior in measuring inconsistency. That is, a slightmodification of the probability of a conditional in a knowledge base may yield a discontinuous change in the value ofthe inconsistency. Consequently, we develop novel inconsistency measures that are more apt for the probabilistic setting.We do so by continuing and largely extending previous work [34–36]. In particular, the contributions of this paper are asfollows. First, we propose and discuss a series of rationality postulates for inconsistency measures in probabilistic conditionallogic. Many of those postulates are inspired by similar properties for the classical case—see e.g. [13]—and others specificallyaddress demands arising from the use of a probabilistic logic, such as the demand for a continuous behavior with respectto changes in the knowledge base. Second, we extend several inconsistency measures that were proposed for the classicalcase to the more expressive framework of probabilistic conditional logic and investigate their properties with respect to therationality postulates. Third, we pick up an extended logical formalization [21] of the inconsistency measure proposed in[34] for probabilistic conditional logic, generalize it, and define a family of inconsistency measures based on minimizing thedistance of a knowledge base to a consistent one. We also propose a novel compound measure that solves an issue with theprevious measure. We thoroughly investigate the properties of all measures with respect to the rationality postulates anddiscuss their advantages and disadvantages with the use of examples.The rest of this paper is organized as follows. We continue in Section 2 with an overview on probabilistic conditionallogic and introduce further notation. In Section 3 we approach the problem of incons",
            {
                "entities": [
                    [
                        142,
                        189,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 104 (1998) 107-164 Artificial Intelligence Formalizing narratives using nested circumscription Chitta Baral a* *, Alfred0 Gabaldon a, I, Alessandro Provetti b,2 a Department of Computer Science, UniversiQ of Texas at El Paso, El Paso, TX 79968, USA b D.S.I., Universith di Milano, Via Come&o 39. i-20135 Milan. Italy Received 13 June 1997: received in revised form I5 June 1998 Abstract formalisms together with the ability to do hypothetical Representing and reasoning about narratives reasoning is important for agents in a dynamic world. These agents need to record their observations and action executions as a narrative and at the same time, to achieve their goals against a changing environment, they need to make plans (or re-plan) from the current situation. The early action formalisms did one or the other. For example, while the original situation calculus was meant for hypothetical reasoning the event calculus was more appropriate for narratives. Recently, there have been some and planning, attempts at developing there has also been a lot of recent that do both. Independently, research in reasoning about actions using circumscription. Of particular interest to us is the research on using high-level theories form of circumscription with blocks representation modular. (NATs)-a to allow concurrent actions, in the high-level Starting from theories reasoning. We initially to NATs that preserves both narrative and hypothetical we define a translation use the high level language L, and then extend it to allow concurrent actions. In the process, we study several knowledge representation issues such as filtering, and restricted monotonicity with respect to NATs. Finally, we compare our formalization with other approaches, and discuss how our use of NATs makes it easier to incorporate other features of action theories, such as constraints, to our formalization. 0 1998 Elsevier Science B.V. All rights reserved. languages and their logical representation language C. which is extended using nested abnormality that make knowledge Kq~ordst Narratives; Nested abnormality theories: Circumscription: Reasoning about actions: Value minimization * Corresponding author: Email: chitta@cs.utep.edu. ’ Email: alfredo@cs.utep.edu. ’ Email: provetti@dsi.unimi.it. 0004-3702/98/s - see front matter 0 1998 Elsevier Science B.V. All rights resewed PII: SOOO4-3702(98)00070-8 \f108 C. Bard et al. /Artificial Intelligence 104 (1998) 107-164 1. Introduction about incomplete A narrative is a possibly set of observations the world in terms of in the past. Initial instants [23] and Allen’s such as Kowalski and Sergot’s event calculus logic [I], were concerned about inferring values of fluents at time instants other of ’ in a possible is reasoning what actions/events occurred and the value of fluents at different formulations of narratives, temporal than those explicitly given actions not explicitly mentioned with hypothetical about values of fluents future world reached by executing a sequence of actions. Such hypothetical important normally a sequence of actions, to achieve a particular goal. from the point of view of planning, where an agent needs to construct a plan- in the narrative and also possibly “abduce” occurrences in the narrative. These formulations were not concerned and/or counterfactual reasoning The formalism of situation calculus [34] has been normally used for hypothetical reasoning about actions and forms the basis of classical planning. But in its original form it does not allow narratives; in it are about values of fluents in the initial situation. the only actual observations that can be expressed I. I. Allowing narratives with hypothetical reasoning Recently, of having researchers is necessary have realized the importance [5,19,33,35,36,39] that captures both narratives and hypothetical a reasoning about effects of actions. formalism Such a formalism to formulate planning and execution of actions of an agent in a dynamic environment, where exogenous actions may occur. The agent has to record about occurrences of actions (both its own action executions, and exogenous observations infer them. Also, the agent has to make plans happenings) or fluent values, and sometimes and more importantly may have to dynamically revise its plans or construct new ones when faced with exogenous events. These plans are not from the initial situation as in situation calculus, but from the current situation. Although the terms “dynamic planning”, “planning with execution”, formalism backbone of such planners-the and “reactive planning” have been used in the planning role situation calculus plays for classical planners. that allows both narratives and hypothetical a to form the is necessary community, reasoning contributions: both narratives and hypothetical [39] were perhaps Miller and Shanahan [35] and Pinto and Reiter the first who reasoning. Both formalisms made many to the former showed how situation calculus can be extended the concept of actual situations-those considered important incorporate narratives, that were reached by actual occurrences of actions. Still, both formalisms have several drawbacks. For example, Miller and Shanahan only allow fluent facts about the initial state, and require stated. Also, Pinto and Reiter’s [39] solution occurrences of actions that all action occurrences be explicitly from premature minimization the possible existence of new situations-those and the latter introduced i.e., while minimizing not specified as of occurrences, suffers B It was later shown that some of these formalisms can use abduction reasoning and planning. However, Reiter 1421 has argued that it is better to do hypothetical level. Besides, the action descriptions used in these formalisms were restrictive features such as constraints. in the meta-level to do hypothetical reasoning at the object in the sense that they did not allow \fC. Bard et al. /Artijicinl Intdligcwce 104 (19Y8) 107-164 I09 from it-is or not inferable part of the axiomatization being able to make plans. As a result, both approaches agent who, for instance, after making a plan of packing his suitcase and driving the airport and doing the packing, observes his car with demobilizing did not see the exogenous action that caused the damage so it cannot put a corresponding action occurrence observation ruled out. 4 This prevents them from ability of an the car to damage. The agent to its narrative, but it should be able to infer such an occurrence that the car is damaged. lack the re-planning from its 1.2. Expressiveness of ourformalism reasoning In this paper we focus on a more general and hypothetical of the earlier proposals. In particular, besides being able to express fluent values at the initial state, and effects of actions on fluents-as can also express observations and overcomes many of the limitations in A [12], the precursor of C-we that allows both narratives formalism allowed such as: fluent facts about non-initial states, - - actual occurrence constants), and of actions at different time points (labeled by actual-situation - ordering among actual situations. Given such descriptions, which includes observations, we can: - plan from the current situation by doing hypothetical _ explain observations - through inferring action occurrences infer new fluent facts (that are not in the narrative) about the various situations explain the observations or are implied by them, reasoning, (not explicitly mentioned), that - do counterfactual reasoning about action occurrences [36,39]. and hypothesis. is a hypothesis Moreover, our formalism allows a clear distinction between observations and makes it clear why the situation calculus atom ho&(,f, and not an observation. Our formulation [a 1. . , a,]) of narratives is done using a novel form of circumscription ity Theories (NATs) [24]. One important aspect of our approach earlier formalizations our formalization the first half of the paper we give a translation of descriptions theories and show their equivalence. Later, we extend L: to allow concurrent give a translation of descriptions ries. C is one of a family of high-level action languages [ 12,19,45]. called Nested Abnormal- is that unlike most of the language, language C developed by Baral et al. [7]. In actions and theo- in the literature [35,39] that were done directly in C to nested abnormality to nested abnormality recently proposed in this extended to the high-level in a logical is grounded language 1.3. High-level language upproach vs directformalization approach In general, researchers actions have normally followed that use a high level language the methodology of: to formalize reasoning about ’ Thi\\ term was coined by Reiter this drawback. The later papers of Reiter and Pinto [ 38,421 avoid this drawback but to prevent it they abandon minimization of action occurrences. We further explain “premature minimization” and do a detailed comparison of our approach with theirs in Section 11 S. in [42] where he discussed \ffairly - developing a high-level language with English-like language-a syntax that can be easily followed, but with a precise semantics (that makes common- sense assumptions used in the formulation precise), often defined using an automata and that makes it easier to incorporate notions such as the “frame”, “qualification” “ramification” that are otherwise difficult to encode in a logical language, and translations of high-level - defining correct (sometimes complete) restricted language theories into classical systems and compare different approaches within a well known setting. logic or logic programming so as to apply existing query-answering formalization formalize that directly to be given in a particular The approaches reasoning about actions in a logical also often require upptmch, form and in a restricted language approaches, where queries are also required language, the initial subset of the logical to have to be any ",
            {
                "entities": [
                    [
                        76,
                        127,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 140–178www.elsevier.com/locate/artintMEBN: A language for first-order Bayesian knowledge basesKathryn Blackmond LaskeyDepartment of Systems Engineering and Operations Research, MS4A6, George Mason University, Fairfax, VA 22030, USAReceived 1 March 2006; received in revised form 13 August 2007; accepted 10 September 2007Available online 4 October 2007AbstractAlthough classical first-order logic is the de facto standard logical foundation for artificial intelligence, the lack of a built-in,semantically grounded capability for reasoning under uncertainty renders it inadequate for many important classes of problems.Probability is the best-understood and most widely applied formalism for computational scientific reasoning under uncertainty.Increasingly expressive languages are emerging for which the fundamental logical basis is probability. This paper presents Multi-Entity Bayesian Networks (MEBN), a first-order language for specifying probabilistic knowledge bases as parameterized fragmentsof Bayesian networks. MEBN fragments (MFrags) can be instantiated and combined to form arbitrarily complex graphical prob-ability models. An MFrag represents probabilistic relationships among a conceptually meaningful group of uncertain hypotheses.Thus, MEBN facilitates representation of knowledge at a natural level of granularity. The semantics of MEBN assigns a probabil-ity distribution over interpretations of an associated classical first-order theory on a finite or countably infinite domain. Bayesianinference provides both a proof theory for combining prior knowledge with observations, and a learning theory for refining a repre-sentation as evidence accrues. A proof is given that MEBN can represent a probability distribution on interpretations of any finitelyaxiomatizable first-order theory.© 2007 Elsevier B.V. All rights reserved.Keywords: Bayesian network; Graphical probability models; Knowledge representation; Multi-entity Bayesian network; Probabilistic logic;Uncertainty in artificial intelligence1. IntroductionFirst-order logic is primary among logical systems from both a theoretical and a practical standpoint. It has beenproposed as a unifying logical foundation for defining extended logics and interchanging knowledge among applica-tions written in different languages. However, its applicability has been limited by the lack of a coherent semantics forplausible reasoning. Among the many proposed logics for plausible inference, probability is the strongest contenderas a universal standard of comparison for plausible reasoning systems. Probability has proved its worth in applicationsfrom a wide variety of problem domains, and is a rationally justified calculus for plausible inference under uncertainty(e.g., [18,36,41,69]).Application of probability to complex, open-world problems requires languages based on expressive probabilisticlogics. The development of sufficiently expressive probabilistic logics has been hindered by the lack of modularityof probabilistic reasoning, the intractability of worst-case probabilistic inference, and the difficulty of ensuring thatE-mail address: klaskey@gmu.edu.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.006\fK.B. Laskey / Artificial Intelligence 172 (2008) 140–178141probability assessments give rise to a well-defined and unique probability distribution. The number of probabilitiesrequired to express a fully general probability distribution over truth-values of a collection of assertions is exponen-tial in the number of assertions, making a brute-force approach to specification and inference infeasible for all butthe simplest problems. These difficulties have been addressed by exploiting independence relationships to achieveparsimonious representation and efficient inference [59,61]. Recent years have seen a rapid evolution of increasinglypowerful languages for computational probabilistic reasoning (e.g., [10,16,27,30,31,35,40,43,44,46,48,56,60,64,66,68,71]).This paper presents multi-entity Bayesian networks (MEBN), a language for representing first-order probabilisticknowledge bases. The fundamental unit of representation in MEBN is the MFrag, a parameterized Bayesian networkfragment that represents uncertain relationships among a small collection of related hypotheses. MFrags allow knowl-edge to be specified at a natural level of granularity. Dependence relationships and local distributions are specified forconceptually meaningful clusters of related hypotheses. An MFrag can be instantiated multiple times by binding its ar-guments to different entities. MEBN thus provides a compact language for expressing complex graphical models withrepeated structure. A MEBN theory consists of a set of MFrags that satisfies consistency conditions ensuring existenceof a unique probability distribution over its random variables. MEBN theories can be used to reason consistently aboutcomplex expressions involving nested function application, arbitrary logical formulas, and quantification.The remainder of the paper is organized as follows. Section 2 provides an overview of formalisms for knowledgerepresentation and reasoning under uncertainty. Section 3 defines the MEBN language. Section 4 defines semantics,presents results on expressive power, and discusses inference. Section 5 reviews current research on expressive first-order languages. The final section is a summary and discussion. Proofs and algorithms are given in Appendix A.2. Probability and logicDavis [17] defines a logic as a schema for defining languages to describe and reason about entities in different do-mains of application. Certain key issues in representation and inference arise across a variety of application domains.A logic encodes particular approaches to these issues in a form that can be reused across languages, domains, andtheories.By far the most commonly used, studied, and implemented logical system is first-order logic (FOL), inventedindependently by Frege and Peirce in the late nineteenth century [24,62]. First-order logic is applied by defining a setof axioms, or sentences that make assertions about a domain. The axioms, together with the set of logical consequencesof the axioms, comprise a theory of the domain. Until referents for the symbols are specified, a theory is a syntacticstructure devoid of meaning. An interpretation for a theory specifies a definition of each constant, predicate andfunction symbol in terms of the domain. Each constant symbol denotes a specific entity; each predicate denotes aset containing the entities for which the predicate holds; and each function symbol denotes a function defined on thedomain. The logical consequences of a set of axioms consist of the sentences that are true in all interpretations, alsocalled the valid sentences.Special-purpose logics built on first-order logic give pre-defined meaning to reserved constant, function and/orpredicate symbols. Such logics provide built-in constructs useful in applications. There are logics that provide con-stants, predicates, and functions for reasoning about types, space and time, parts and wholes, actions and plans, etc.When a logic is applied to reason about a particular domain, the modeler assigns meaning to additional domain-specific symbols, and provides axioms to assert important properties of their intended referents. Formal ontologies[33,70] are usually expressed in languages based on first-order logic or one of its subsets.A first-order theory implies truth-values for the valid sentences and their negations, but provides no means toevaluate the plausibility of other sentences. Plausible reasoning is fundamental to intelligence, and plausible reason-ing logics have been an active area of research in artificial intelligence. Because probability is not truth-functional,naïve attempts to generalize the standard logical connectives and quantifiers to create combining rules for probabil-ities encountered many difficulties. Graphical probability models have become popular as a parsimonious languagefor representing knowledge about uncertain phenomena, a formalism for representing probabilistic knowledge in alogically coherent manner, and an architecture to support efficient algorithms for inference, search, optimization, andlearning. A graphical probability model expresses a probability distribution over a collection of related hypotheses asa graph and a collection of local probability distributions. The graph encodes dependencies among the hypotheses.The local probability distributions specify numerical probability information. Together, the graph and the local dis-\f142K.B. Laskey / Artificial Intelligence 172 (2008) 140–178Fig. 1. Bayesian network for diagnostic task.tributions specify a joint distribution that respects the conditional independence assertions encoded in the graph, andhas marginal distributions consistent with the local distributions [14,42,50,61,75]. A Bayesian network (e.g., [42,59,61] is a graphical probability model in which the dependency graph is an acyclic directed graph. An example of aBayesian network for a diagnostic task is given in Fig. 1. This Bayesian network represents a joint distribution overthe Cartesian product of the possible values of the random variables depicted in the graph.Some authors assume that random variables in a Bayesian network have finitely many possible values. Some requireonly that each random variable have an associated function mapping values of its parents to probability distributionson its set of possible values. In an unconstrained local distribution on finite-cardinality random variables, a separateprobability is specified for each value of a random variable given each combination of values of its parents. Becausethe complexity of specifying local distributions is exponential in the number of parents, constrained families of localdistributions are often used to simplify specification and inference. E",
            {
                "entities": [
                    [
                        72,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 217 (2014) 43–75Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpatial reasoning with RCC8 and connectedness constraints in Euclidean spacesRoman Kontchakov a, Ian Pratt-Hartmann b,c,∗a Department of Computer Science and Information Systems, Birkbeck, University of London, UKb School of Computer Science, University of Manchester, UKc Institute of Mathematics and Computer Science, University of Opole, Poland, Michael Zakharyaschev aa r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2014Received in revised form 15 July 2014Accepted 31 July 2014Available online 7 August 2014Keywords:Qualitative spatial reasoningSpatial logicEuclidean spaceConnectednessSatisfiabilityComplexity◦◦The language RCC8 is a widely-studied formalism for describing topological arrangements of spatial regions. The variables of this language range over the collection of non-empty, +(Rn), and its regular closed sets of n-dimensional Euclidean space, here denoted RCnon-logical primitives allow us to specify how the interiors, exteriors and boundaries of these sets intersect. The key question is the satisfiability problem: given a finite set of atomic RCC8-constraints in m variables, determine whether there exists an m-tuple +(Rn) satisfying them. These problems are known to coincide for all of elements of RCn ≥ 1, so that RCC8-satisfiability is independent of dimension. This common satisfiability problem is NLogSpace-complete. Unfortunately, RCC8 lacks the means to say that a spatial region comprises a ‘single piece’, and the present article investigates what happens when this facility is added. We consider two extensions of RCC8: RCC8c, in which we can state that a region is connected, and RCC8c, in which we can instead state that a region has a connected interior. The satisfiability problems for both these languages are easily seen to depend on the dimension n, for n ≤ 3. Furthermore, in the case of RCC8c, we show that there exist finite sets of constraints that are satisfiable over +(R2), but only by ‘wild’ regions having no possible physical meaning. This prompts RCus to consider interpretations over the more restrictive domain of non-empty, regular +(Rn). We show that (a) the satisfiability problems for RCC8cclosed, polyhedral sets, RCP+(R) are distinct and both NP-complete; (equivalently, RCC8c+(R2) are identical and(b) the satisfiability problems for RCC8c over RC+(R2)+(R2) and RCPNP-complete; (c) the satisfiability problems for RCC8care distinct, and the latter is NP-complete. Decidability of the satisfiability problem for RCC8care not interestingly different from RCC8. We finish by answering the following question: given that a set of +(Rn), how complex is RCC8c- or RCC8cthe simplest satisfying assignment? In particular, we exhibit, for both languages, a sequence +(R2), such that the size of Φn grows polynomially of constraints Φn, satisfiable over RCPin n, while the smallest configuration of polygons satisfying Φn cuts the plane into a +(R2), RCC8cnumber of pieces that grows exponentially. We further show that, over RCagain requires exponentially large satisfying diagrams, while RCC8ccan force regions in satisfying configurations to have infinitely many components.+(R2) is open. For n ≥ 3, RCC8c and RCC8c+(R2) and RCP◦over RC-constraints is satisfiable over RC+(R) and RCP+(Rn) or RCP) over RCover RC◦◦◦◦◦© 2014 Elsevier B.V. All rights reserved.* Correspondence to: School of Computer Science, University of Manchester, UK.E-mail addresses: roman@dcs.bbk.ac.uk (R. Kontchakov), ipratt@cs.man.ac.uk (I. Pratt-Hartmann), michael@dcs.bbk.ac.uk (M. Zakharyaschev).http://dx.doi.org/10.1016/j.artint.2014.07.0120004-3702/© 2014 Elsevier B.V. All rights reserved.\f44R. Kontchakov et al. / Artificial Intelligence 217 (2014) 43–75Fig. 1. RCC8-relations over discs in R2.Fig. 2. Two arrangements of regions in the plane satisfying (1).1. IntroductionSpatial reasoning in everyday life possesses two distinctive—and related—characteristics: it is primarily concerned with extended, as opposed to point-like entities, and it typically invokes qualitative, as opposed to quantitative, concepts [1–3]. This observation has prompted consideration, within the Artificial Intelligence community, of representation languages whose variables range over some specified collection of extended spatial objects, and whose non-logical primitives are interpreted as qualitative spatial properties and relations involving those objects. As might be expected, the logical proper-ties of such languages depend on the geometry of the spaces over which they are interpreted—in most applications, two-and three-dimensional Euclidean space. The present article draws attention to some hitherto overlooked subtleties regarding this dependency.By far the best-known language for Qualitative Spatial Reasoning is RCC8, originally proposed—in essentially equivalent formulations—by Egenhofer and Franzosa [4], Egenhofer and Herring [5], Randell et al. [6] and Smith and Park [7]. This quantifier-free language allows us to specify how regions and their interiors are related to each other. It employs an infinite collection of variables r1, r2, . . . , ranging over spatial regions, together with six binary predicates: NTPP (non-tangential proper part), TPP (tangential proper part), EQ (equality), PO (partial overlap), EC (external contact) and DC (disjointness). The relations denoted by these predicates are illustrated, for closed discs in the plane, in Fig. 1. More formally: NTPP(r1, r2) if r1is included in the interior of r2; TPP(r1, r2) if r1 is included in r2 but not in its interior; PO(r1, r2) if the interiors of r1 and r2 intersect, but neither is included in the other; and EC(r1, r2) if r1 and r2 intersect, but their interiors do not. A constraintis a statement R(ri, r j), where R is one of these six predicates. For example, the constraintsEC(r1, r2), TPP(r1, r3), NTPP(r2, r4)(1)state that regions r1 and r2 are in external contact, with the former a tangential proper part of r3 and the latter a non-tangential proper part of r4. Fig. 2 shows two arrangements of regions satisfying these constraints.−1 and TPPThe RCC8-relations mentioned above were defined in [6] by means of a formalism referred to there as the Region −1, we Connection Calculus. Of these, the relations NTPP and TPP are asymmetric: counting their converses, NTPPobtain eight relations in all, hence the name RCC8. Syntactically, the original Region Connection Calculus is the language of first-order logic (with equality) over the signature consisting of a single binary predicate C , variously referred to as ‘contact’, or (confusingly) ‘connection.’ The origin of this predicate can be traced back, via Clarke [8,9], to the philosophical work of Whitehead [10] and de Laguna [11]. Semantically, one is supposed to think of C as holding between two regions just in case they share at least one point, though matters are somewhat muddied by the recurrent suggestion that this notion should be regarded as an (undefined) primitive. However, the etymology of the term RCC8 need not concern us further: it is now standardly used for the quantifier-free language featuring the six primitives illustrated in Fig. 1, and we simply follow suit. The motivation for focussing on this particular collection of primitives is not always clear. Egenhofer and Franzosa [4] and Egenhofer and Herring [5] classify relationships between regions in terms of intersections of their interiors, exteriors and boundaries and show, in particular, that only the RCC8 relations are possible between closed disc-homeomorphs in the −1 are Euclidean plane. Düntsch, Wang and McCloskey [12] observe that NTPP, TPP, EQ, PO, EC, DC, NTPPexactly the atoms of the smallest relation algebra defined on the set of closed discs in the Euclidean plane that contains the contact relation, C . In fact, Li and Ying [13] show that the set of closed disc-homeomorphs in the Euclidean planerealizes the same relation algebra. (See also Li and Li [14] for an interesting extension of this result.) In any case, the language RCC8 is by now firmly established as a basic formalism in the field of Qualitative Spatial Reasoning. In particular, −1 and TPP\fR. Kontchakov et al. / Artificial Intelligence 217 (2014) 43–7545Fig. 3. Non-regular and regular closed subsets of a) R2, and b) R3.the standard geographic query language for RDF data GeoSPARQL,1 suggested by the Open Geospatial Consortium, is based on the RCC8 relations.How are we to understand spatial reasoning in RCC8? Observe that, in (1), nothing is said about the relation between r3 and r4. What are the possibilities? A little thought suffices to convince us that DC and EC are both impossible. As we might say, the two sets of constraintsEC(r1, r2), TPP(r1, r3), NTPP(r2, r4), DC(r3, r4),EC(r1, r2), TPP(r1, r3), NTPP(r2, r4), EC(r3, r4)(2)(3)are unsatisfiable. Allowing ourselves to combine RCC8-constraints using arbitrary sentential connectives, we could express this knowledge as a formula(cid:2)(cid:3)EC(r1, r2) ∧ TPP(r1, r3) ∧ NTPP(r2, r4)(cid:2)→ ¬(cid:3)DC(r3, r4) ∨ EC(r3, r4),which we take to be true of all tuples of regions r1, . . . , r4. The validity of this formula thus represents a geometrical fact to which an agent employing RCC8 as a spatial representation language should have access. Satisfiability and validity being dual notions, it suffices, from a computational perspective, to consider only the former. And since, in this context, nothing essential is added by sentential connectives, we may confine attention in the sequel to finite sets of constraints, interpreted conjunctively. Following common practice, we refer to such a set as an RCC8-constraint network (or, simply, RCC8-network).When introducing the notion of satisfiability of RCC8-networks, we employed the term spatial region as if it needed no clarification, giving as examples the regions in Figs. 1 a",
            {
                "entities": [
                    [
                        134,
                        211,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 95 (1997) 215-255 Artificial Intelligence Qualitative and quantitative simulation: bridging the gap* Daniel Berleant a**, Benjamin J. Kuipers b,1 ’ Department of Computer Systems Engineering, University of Arkansas, Fayetteville, AR 72701, USA h Department of Computer Sciences, University of Texas, Austin, TX 78712, USA Received January 1993; revised May 1997 Abstract Shortcomings of qualitative simulation and of quantitative simulation motivate combining them to do simulations exhibiting strengths of both. The resulting class of techniques is called semi- quantitative simulation. One approach to semi-quantitative simulation is to use numeric intervals to represent incomplete quantitative information. In this research we demonstrate semi-quantitative simulation using intervals in an implemented semi-quantitative simulator called Q3. Q3 pro- gressively refines a qualitative simulation, providing increasingly specific quantitative predictions which can converge to a numerical simulation in the limit while retaining important correctness guarantees from qualitative and interval simulation techniques. Q3’s simulations are based on a technique we call step size re$nement. While a pure qualitative simulation has a very coarse step size, representing the state of a system trajectory at relatively few qualitatively distinct states, Q3 interpolates newly explicit states between distinct qualitative states, thereby representing more states which instantiate new constraints, leading to improved quantitative inferences. 93’s techniques have been used for prediction, measurement interpretation, diagnosis, and even analysis of the probabilities of qualitative behaviors. Because Q3 shares important expressive and inferential properties of both qualitative and quantitative simulation, 43 helps to bridge the gap between qualitative and quantitative simulation. @ 1997 Elsevier Science B.V. Keywords: Qualitative: Simulation; Semi-quantitative; Intervals; QSIM; Q3 *This research was supported 5207, and performed by the National Aeronautics process, or service does not constitute or imply its endorsement by any organization. in part for the Jet Propulsion Laboratory, California in part by NSF grants IRI-8905494 and IRI-8904454 and Space Administration. Reference herein to any specific commercial and NASA grant NAG sponsored product, Institute of Technology, * Corresponding ’ Email: kuipers@cs.utexas.edu. author. Email: djb@engr.uark.edu. 0004-3702/97/$17.00 PII SOOO4-3702( @ 1997 Elsevier Science B.V. All rights reserved 97)00050-7 \f216 D. Berleant, B.J. Kuipers/Art$cial Intelligence 95 (1997) 215-255 An object is fired upward fast enough to escape a gravitational field :;I (a) Gravity(t) TO=O jll T1=~ :jl (b) Velocity(f) Cc) Distance(f) Fig. I. Qualitative experienced by the object produces a negative acceleration (c), gravitation decreases. Qualitative to Earth (not shown). simulation of an object fired upward at greater than escape velocity shows that the gravitation increases in which the object falls back simulation also produces another behavior (b), As distance (a), reducing its velocity 1. Introduction through Systems trajectory predicting simulation simulation that change over time are often so complex future system states as a function of time, cannot be found. is useful determines When accurate numerical solutions, equations In those cases for prediction. Given a model of system structure and initial state, its state space. about structure and initial that analytical the system’s information simulation is available, state is available, techniques is available. When only qualitative a significant body of work describes methods simulation. But what about the many cases in which accurate numerical yet incomplete than sim- to make more provides? That question motivates for stronger predictions is available, providing traditional numerical semi-quantitative and qualitative are combined the potential a large body of numerical information about a model for qualitative information numerical pure qualitative ulation, informative is unavailable, in which numerical than either alone would make. information simulation, techniques preventing simulation inferences As an example consider a nonlinear, field that decreases with height. Compared second-order in a gravitational movement more interesting To illustrate in a gravitational field that remains constant with height, for qualitative simulation due to its nonlinear the point that qualitative and numerical system, a rocket fired straight up to the simple case of is and second-order nature. simulation have relative strengths this example and weaknesses, here is a limitation of each: l Numerical simulation cannot generally, unlike qualitative infinite values at all. infer simulation that the final height could be infinite. More infer (Fig. 1)) numerical simulations cannot simulations cannot in Fig. 1, or instead simulation, qualitative . Qualitative as shown numerical will be the one to actually occur in a given instance. combines both qualitative infer whether or not falls back simulation Semi-quantitative so as to compensate significant guarantees which semi-quantitative simulation for weaknesses and quantitative simulations in each with strengths of the other. This leads to can provide. simulation the rocket to infinity to the ground. More generally, unlike infer which qualitative behavior cannot rises \fD. Berleanf, B.J. Kuipers/Artijicial Intelligence 95 (1997) 215-255 217 l All qualitative behaviors that are consistent with available quantitative information can be found. l Each qualitative behavior can either be annotated with intervals providing quantita- to that qualitative behavior, or ruled trajectories conforming tive bounds on system out entirely. In an earlier system, Q2 [ 591, we showed how a qualitative behavior’s symbolic values their quantitative values. While Q2 provides it relies on simulations events occur, can be annotated with intervals useful results and has been used in other work [ 35,36,39,53], the few time points at which qualitatively that contain only which limits the quantitative it can provide. that bound significant inferences The present system, Q3, extends Q2 with step size refinement trajectory, adaptively constitutes niques. Step size refinement in a simulation tion. Step size refinement inferences perspective, ulations. it inherits than either qualitative and auxiliary tech- interpolates new states into an existing sequence of states the size of the time steps in the simula- it allows better because alone. From a theoretical sim- and quantitative reducing a pragmatic contribution simulation from both qualitative or quantitative important guarantees This paper significantly a proof of convergence revises and expands a preliminary for step size refinement. and stability account [ 91, and provides 2. Q3 and step size refinement the values of model variables at qualitatively simulation trajectories produced by that time points these intervals allow better predictions about model trajectories is annotated with intervals simulation (behaviors) trajectories simulation significant 43 builds on the tree of qualitative Q2 [ 591. That tree of qualitative constrain in each trajectory. While than are possible with pure qualitative qualitative behaviors, Q2 often suffered of very wide inferred intervals. simulation, from weak quantitative and better pruning of the tree of in the form inferences Somewhat better inferences might be obtained by augmenting approaches, 42’s simple constraint [78], Ql [ 7 11. However while such sophisticated methods would help, is the size of the time periods between and it is a variant of such as quantity trajectories, lattices propagation with more sophisticated [8912 or BOUNDER a critical explicitly the well known equations. issue of step size issue would still remain. This issue time points represented in the simulation in numerical simulations of ordinary differential For typical numerical models, numerical simulation results are poor when step sizes progressively more accurate as the step size of the simulation are large, becoming becomes (A large step size means as slope of one or more model variables, change significantly next.) This basic characteristic of standard numerical that qualitative smaller. features of a trajectory, such from one time point to the is a algorithms [46] simulation 2 The name Ql has no connection with the names 42 and Q3. \f218 D. Berleant, B.J. Kuipers/Artificial Intelligence 95 (1997) 215-2.55 serious problem features of qualitative to the next. Therefore so numerical for numerically simulation step sizes for qualitative annotated qualitative trajectories do change significantly simulations the qualitative from one time point and are large by definition simulations because inferences on them tend to be weak. Augmenting a 42 simulation inferences, improved quantitative reducing metic). Step size refinement theoretically the step size (within and pragmatically is our algorithm significant step sizes can so that it has smaller just as numerical to greatly can be improved by imposed by the accuracy of floating point arith- this. Q3 augments Q2 with the simulations for doing lead limits capability of smaller step sizes. inferences step size refinement via Q2. Then, better first generates qualitative is an adaptive discretization information the step size using 43 titative ducing refinement reduce numerical error a finite number of discrete points, usually pending cretization [16,17]. and auxiliary technique. Adaptive discretization a continuous behaviors via QSIM which are annotated with quan- re- algorithms. Step size techniques system at the step size de- adaptive dis- [ 46,701, and multigrid methods time points, by varying Previously status of the simulation. include adaptive step size control are obtained by progressively in simulation methods that represent the current techni",
            {
                "entities": [
                    [
                        66,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1158–1193www.elsevier.com/locate/artintTemporal reasoning about fuzzy intervalsSteven Schockaert ∗,1, Martine De CockGhent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281-S9, 9000 Gent, BelgiumReceived 7 July 2007; received in revised form 14 December 2007; accepted 4 January 2008Available online 11 January 2008AbstractTraditional approaches to temporal reasoning assume that time periods and time spans of events can be accurately represented asintervals. Real-world time periods and events, on the other hand, are often characterized by vague temporal boundaries, requiringappropriate generalizations of existing formalisms. This paper presents a framework for reasoning about qualitative and metrictemporal relations between vague time periods. In particular, we show how several interesting problems, like consistency andentailment checking, can be reduced to reasoning tasks in existing temporal reasoning frameworks. We furthermore demonstratethat all reasoning tasks of interest are NP-complete, which reveals that adding vagueness to temporal reasoning does not increaseits computational complexity. To support efficient reasoning, a large tractable subfragment is identified, among others, generalizingthe well-known ORD Horn subfragment of the Interval Algebra (extended with metric constraints).© 2008 Elsevier B.V. All rights reserved.Keywords: Temporal reasoning; Interval algebra; Fuzzy set theory1. IntroductionTime plays a key role in many application domains, ranging from scheduling and planning [2,17,19] to naturallanguage understanding [29,34], multi-document summarization [6], question answering [22,32,39] and dynamic mul-timedia presentation [3,10,18]. Starting from Allen’s seminal work on qualitative interval relations (e.g., A happenedduring B, A overlaps with B; [1]), increasingly more expressive formalisms have been proposed to reason abouttime, among others allowing to specify metric constraints between two time points (e.g., p happened 4 time unitsbefore q; [12]), to combine qualitative and metric information [25,31], to specify constraints on the (relative) durationof events [35], and to specify arbitrary disjunctions of temporal constraints [23,27]. Most reasoning tasks of interest inthese formalisms are NP-complete. To cope with this, a lot of research efforts have been directed towards identifyingsubfragments of the various calculi in which reasoning becomes tractable [13,14,28,37], as well as towards derivingefficient solution strategies for NP-complete reasoning problems [8,36,45,46].Research, however, has largely focused on reasoning about time periods, and time spans of events, which canbe accurately represented as an interval. In contrast, many real-world events and time periods are characterized by* Corresponding author.E-mail addresses: steven.schockaert@ugent.be (S. Schockaert), martine.decock@ugent.be (M. De Cock).1 Research Assistant of the Research Foundation—Flanders.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.01.001\fS. Schockaert, M. De Cock / Artificial Intelligence 172 (2008) 1158–11931159Fig. 1. Fuzzy sets defining the vague time span of Picasso’s Blue, Rose, and Cubist periods.an inherently gradual or ill-defined beginning and ending. Typical examples are large-scale historical events like theRussian Revolution, the Great Depression, the Second World War, the Cold War, and the Dotcom Bubble, or historicaltime periods like the Middle Ages, the Renaissance, the Age of Enlightenment, and the Industrial Revolution, but alsosmall-scale events like sleeping and being born. Moreover, in natural language, vague temporal markers are frequentlyfound to convey underspecified temporal information: early summer, during his childhood, in the evening, etc. Notethat the vagueness of these events and time periods is fundamentally different from the uncertainty that exists amonghistoricians about, for example, the time period during which the Mona Lisa was painted.A formal definition of the notion of an event is difficult to provide. Clearly, an event is something that happens ata particular time and a particular place (e.g., World War II); it can have parts (e.g., the Battle of the Bulge), it canbelong to a certain category (e.g., Military Conflict) and it can have consequences (e.g., the Cold War) [47]. We will,however, abstract away from any particular formalization of events, and focus on their temporal dimension only. Assuch, we will conceptually make no difference between time periods and events. Vague time periods are naturallyrepresented as fuzzy sets [48]. A vague time period is then represented as a mapping A from the real line R to the unitinterval [0, 1]. For a time instant t (t ∈ R), A(t) expresses to what extent t belongs to the time period A. When A isa crisp time period, for all t in R, A(t) is either 0 (perfect non-membership) or 1 (perfect membership). When A is avague time period, on the other hand, A will typically be gradually increasing over an interval [t1, t2] and graduallydecreasing over an interval [t3, t4], where A(t) = 1 for t in [t2, t3] and A(t) = 0 for t < t1 and t > t4. As an example,consider Picasso’s Blue, Rose and Cubist periods. Regarding the definition of the Rose period, for example, we find2So 1904 is a transitional year and belongs neither truly to the blue period, nor to the rose period.Similarly, the ending of the Rose period, as well as the beginning and ending of the Cubist period are inherentlygradual. Fig. 1 depicts a possible definition of Picasso’s Rose period, as well as the ending of his Blue period and thebeginning of his Cubist period. These definitions reflect the gradual transition to the Rose period during 1904, as wellas Picasso’s experiments with new styles from 1906 and especially from 1907, eventually leading to his Cubist period.Clearly, the definition of a fuzzy set representing a vague time period is to some extent subjective. In fact, there is noreal reason why January 1, 1907 should belong to the Rose period to degree 0.8 and not to degree 0.75 or 0.85. Whatis most important is the qualitative ordering the membership degrees impose, e.g., June 1, 1907 is more compatiblewith the Rose period than the Cubist period; March 15, 1904 is less compatible with the Rose period than June 1,1907, etc.Applications based on classical temporal reasoning algorithms, like temporal question answering or multi-document summarization, fail to work correctly when the events or time periods involved are vague. For example,when extracting information about the life and work of Picasso from web documents, inconsistencies quickly arise:(1) Bread and Fruit Dish on a Table (1909) marks the beginning of Picasso’s “Analytical” Cubism . . . 32 http://pablo-picasso.paintings.name/rose-period/, accessed May 21, 2007.3 http://www.abcgallery.com/P/picasso/picassobio.html, accessed May 21, 2007.\f1160S. Schockaert, M. De Cock / Artificial Intelligence 172 (2008) 1158–1193(2) The first stage of Picasso’s cubism is known as analytical cubism. It began in 1908 and ended in 1912, . . . 4(3) The ‘Demoiselles d’Avignon’ of 1907 mark the beginning of his [Picasso’s] Cubist period in which he exceededthe classical form.5The solution to this problem is not to discard the least reliable sources until the resulting knowledge base is consistent,but to acknowledge that some of the temporal relations expressed in the sentences above are only true to some extent:the beginning of Picasso’s Analytical Cubism coincides with the beginning of cubism to some degree λ1, Picasso’sCubist period began with “Demoiselles d’Avignon” in 1907 to some degree λ2, Picasso’s Analytical Cubism began in1908 to some degree λ3, Picasso’s Analytical Cubism began with “Bread and Fruit Dish on a Table” in 1909 to somedegree λ4. The aim of this paper is to derive algorithms for reasoning about such fuzzy temporal information, e.g.,which values of λ1, λ2, λ3, λ4 result in a consistent interpretation of the sentences above? What conclusions can weestablish given a consistent set of (fuzzy) assertions about (vague) time periods? Our primary objective is to obtain atemporal reasoning framework that is, among others, suitable for natural language applications like multi-documentsummarization or question answering when some of the time periods and events involved are vague.The structure of this paper is as follows. In the next section, we review related work on fuzzy temporal informationprocessing, while Section 3 familiarizes the reader with some important preliminaries from fuzzy set theory andtemporal reasoning. In Section 4, we introduce our framework for representing fuzzy temporal information. Next, inSection 5, we introduce an algorithm to check the consistency of a set of assertions about fuzzy time periods. Thecomputational complexity of this problem is investigated in Section 6. Section 7 discusses how new information canbe derived from given information. Finally, Section 8 presents some concluding remarks and directions for futurework.2. Related workAlthough processing fuzzy temporal information is well studied in literature, research has tended to focus on mod-elling vague temporal information about crisp events (e.g., Picasso died in the early 1970s), rather than on modellingtemporal information about vague events. For example, in [16] possibility theory is employed to represent vague dates(e.g., early summer), and vague temporal constraints (e.g., A happened about three months before B). The underlyingassumption is that all events have crisp, albeit unknown, temporal boundaries; only our knowledge about these crispboundaries is vague. Based on this possibilistic approach, [5] introduced the notion of a fuzzy temporal constraintnetwork. In this framework, temporal information is represented as fuzzy temporal constraints, i.e., fuzzy restric-tions on the possible distances between time p",
            {
                "entities": [
                    [
                        74,
                        114,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIBR Artificial Intelligence 94 (1997) 167-215 Artificial Intelligence Representations and solutions for game-theoretic problems Daphne Koller *, Avi Pfeffer * Computer Science Department, Gates Building IA. Stanford University, Stanford, CA 94305-9010, USA Abstract A system with multiple interacting agents (whether artificial or human) is often best ana- tools. Unfortunately, while the formal foundations are well-established, lyzed using game-theoretic techniques for game-theoretic reasoning are inadequate for dealing with standard computational realistic galmes. This paper describes the Gala system, an implemented system that allows the specification and efficient solution of large imperfect information games. The system contains the first implernentation of a recent algorithm, due to Koller, Megiddo and von Stengel. Experimental results from the system demonstrate that the algorithm is exponentially faster than the standard algorithm in practice, not just in theory. It therefore allows the solution of games that are orders of magnitude larger than were previously possible. The system also provides a new declarative lan- guage for compactly and naturally representing games by their rules. As a whole, the Gala system provides tbe capability for automated game-theoretic analysis of complex real-world situations. @ 1997 Elsevier Science l3.V. Keywords: Game theory; Algorithms; Imperfect information; Multi-agent systems; Game playing; Logic programming; Poker 1. Introchction When dlesigning or analyzing tant to consider and the information mally model “rational” strategies available such a situation the (often incompatible) a situation with multiple it is impor- their possible actions, to them. Game theory provides us with the tools to for- it, and to prescribe as a multi-player goals of these entities, to analyze interacting entities, game, to the different players. * Corresponding author. Email: koller@cs.stanford.edu. ’ &nail: avi@cs.stanford.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PZISOOO4-3702(97)00023-4 \f168 D. KolleK A. Pfeffer/Artijicial Intelligence 94 (1997) 167-215 Perfect information Imperfect information No chance Chance Chess Go Inspection game Battleships Backgammon Monopoly OPEC game Poker Fig. 1. Examples of games of various types. real Since incompatible theory has been fundamental microeconomic FCC auction of wavelengths government and more. Clearly, situations policy, tions. e.g., applications and resource information allocation or service involving multiple life contains many situations agents with goals, game theory has played a role in a variety of different areas. Game of (such as the design of the 1995/6 in the realm of (both strategic and tactical), biology, [ 221) . Game theory has also been applied theory and in more practical examples law, politics, military analysis [ 11, both in the theoretical in economics foundations interacting involving multiple agents also arise in computer In some applications, the agents are a mixture of computer in computer game playing, interface design, or discourse understanding. involve two or more artificial agents, e.g., network in a distributed system, coordination science applica- and human users, Other load sharing robots, and routing, of multiple transactions of game-theoretic on the internet. analysis The applicability to computer science problems has not In recent years, several such problems have been analyzed using game the work of Franklin, Galil, and include [ 281 on network routing protocols, intelligence, more of foundations results. Examples the work of Shenker [ 231 on discourse understanding. are turning to game (see, for example, [ 271 and the references for the theoretical tools, with interesting gone unnoticed. theoretic Yung [ 71 on computer security, and the work of Parikh and more multi-agent Despite researchers systems the growing popularity of game little work on providing effective automated in this area has focused almost exclusively on solution algorithms information: world. Unfortunately, concern game hidden theory as an analytic tools for game-theoretic state of the such games form a very small fraction of the class of games that that are In real life, almost all situations there has been analysis. The work for games of pe@ct games where all players have full knowledge of the current from the players. some aspects therein). tool, In artificial contain theory. theory from the possibility the lack of information It is important to distinguish moves. The former involves uncertainty situations where different players have access to different only uncertainty games may materializes. Both perfect and of chance; examples of games from all four categories are shown these are popular to model arms control of chance about the current state of the world, particularly information. The latter involves is resolved as soon as the future involve an element in Fig. 1. Most of theorists is used by game in Section 3.5. The OPEC game the future, uncertainty which information games. The inspection it is described recreational inspections; imperfect about game \fD. Kollel; A. Pfe$er/Arti$icial Intelligence 94 (1997) 167-215 169 models oil pricing by oil-producing textbook [ 251. countries; it is described in Rasmusen’s game theory As it turns out, the presence of chance elements does not necessitate major changes to solve a game. In fact, the cost of solving a used techniques information game with chance moves to the computational perfect a game with no chance moves. By contrast, greatly one player case, 2 and is even more of a problem when the different players may have access to different greater of imperfect the complexity of the problem. This increase materializes is not substantially in the multi-player the introduction information. increases than solving information even in the case, particularly (both conceptual this problem has been infrastructure and algorithmic) largely of dealing with imperfect level. ignored at the computational for dealing with such games has had several Due to the complexity games, information The lack of a computational unfortunate consequences: l Since game-theoretic the decision-maker must abstract faced with a more complex analysis must be done manually, only small simple games (as most real-life it until the results of the to the original insight, can rarely be applied directly analysis. As a consequence, the situation and simplify to manual situation can be analyzed. When situations are), it b’ecomes amenable analysis, while providing problem. l Manual game-theoretic analysis is a subtle and complicated task, which can only the tools provided by game theory are only be performed by experts. Therefore, available to the general public via specialized consultants. l The lack of practical game-theoretic algorithms has prevented the use of game- theoretic decision making directly by autonomous this paper, we take a first step towards addressing In artificial agents. this lack. We describe system, called Gala, which automates game-theoretic takes a description implemented class of games. The system for the different players which are game-theoretically strategies described. the game If desired, or more of the agents), providing arise. of a game, analyzes rational (playing a picture of the different scenarios the system can also simulate analysis an for a large it, and outputs for the situation the role of one to that are likely The Gala system is composed of two main interacting pieces. The first allows to be described complex games specification which a large game For example, Fig. 2 presents part of a Gala specification is typically described in natural language, which we also call Gala. The Gala language mimics language, by presenting for the game of Poker. clearly and concisely, using a special-purpose large game the way in its rules. such as this, .a game specification the extensive form of a game, a natural augmentation Given generates by game theorists. “Standard” game trees, as typically used in AI game-playing are inadequate information with information sets. of the Gala system of a game tree utilized systems, the agents’ game trees they do not represent this problem by augmenting for modelling state. The extensive real-life games, since the first component form addresses ’ The problem of solving a Markov decision process (MDP) is much easier than the problem of solving a partially observable Markov decision process (POMDP). See [ 101 for a survey. \f170 D. Keller; A. Pfeffer/Art@cial Intelligence 94 (1997) 167-215 gamecpoker, C players: [dealer. gambler], flow: (play_round(ante), deal, bet), ante: (money($player) gets $cash, %% each player gets his/her initial allocation of cash payC§ante, gplayer, pot)), Xii and pays the ante into the pot deal: (choose(nature, (Handl, HsndS), (dealcdeck, Ocards, Handi), dealcdeck, $cards, HandZ))), %% a pair of random hands is chosen and dealt from the deck revealcgambler, myhand(Handl)), revealcdealer, myhand(Hand;?)), %% each player's hand is revealed only to him if(beats(Hand1, HendZ), betterhsnd gets gambler, betterhand gets dealer)), XX evaluate the hands immediately, so that we only do %% it once per deal, rather than at every possible showdown bet: (choose(gambler, InitialBet, betueen(0, $money(gambler), InitialBet)), %% the player chooses his bet revealcdealer, betcgembler, InitialBet)), %% reveals it to the other player debt := InitialBet, pay(InitialBet, gambler, pot), %% and pays it into the pot take_turns(next_bet)), next-bet: (choose($player, Bet, ( % meet or raise between($debt, $money($player), Bet) ; % fold ($debt>O, Bet = O))), if(($debt>O, Bet = 01, wins($opponent), (pay(Bet, Splayer, pot), % meet or raise if($debt=O, % fold wins($betterhand), % showdown (reveal($opponent. bet($player. Bet)), debt gets Bet - $debt))))), Fig. 2. Abbreviated Gala description of poker. \fD. Keller; A. veffer/Artijcial Intelligence 94 (1",
            {
                "entities": [
                    [
                        75,
                        132,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 97 ( 1997) 9-43 Artificial Intelligence Axioms of causal relevance David Galles ‘, Judea Pearl * Cognitive Systems Laboratory, Computer Science Department, University of California, Los Angeles, CA 90024, USA Received October 1995; revised May 1996 Abstract This paper develops axioms and formal semantics for statements of the form “X is causally irrelevant to Y in context Z”, which we interpret to mean “Changing X will not affect Y once Z is held constant”. The axiomization of causal irrelevance is contrasted with the axiomization of informational irrelevance, as in “Finding X will not alter our belief in Y, once we know Z”. Two versions of causal irrelevance are analyzed: probabilistic and deterministic. We show that, unless stability is assumed, the probabilistic definition yields a very loose structure that is governed by just two trivial axioms. Under the stability assumption, probabilistic causal irrelevance is isomorphic to path interception in cyclic graphs. Under the deterministic definition, causal irrelevance complies with all of the axioms of path interception in cyclic graphs except transitivity. We compare our formalism to that of Lewis (1973) and offer a graphical method of proving theorems about causal relevance. @ 1997 Elsevier Science B.V. Keywords: Causality; Graphoids; Causal models; Counterfactuals; Actions 1. Introduction In [ IO], a set of axioms was developed for a class of relations called gruphoids. These axioms characterize the semantics of conditional a parallel set of axioms independence for causal relevance, in probability among observed events based on calculus. This paper develops to that is, the tendency of certain events informational relevance* author. Email: judea@cs.ucla.edu. * Corresponding ’ Email: galles@cs.ucla.edu. 2 “Relevance” will be used primarily will be clear from the context when “relevance” as a genetic name for the relationship of being relevant or irrelevant. to negate “irrelevance”. is intended It 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved PIISOOO4-3702(97)00047-7 \f10 D. Galles. J. Pearl/Artificial Intelligence 97 (1997) 9-43 irrelevance Informational affect the occurrence of other events reasoner. independent about X gives us no new information statements of the form “X is causally mean “Changing X will not alter the value of Y, if Z is fixed”. about Y. Causal irrelevant of Y given Z”, which means in the physical world, independent is concerned with statements irrelevance that, given the value of Z, gaining information is concerned with to Y in context Z”, which we take to of the observer- of the form “X is The notion of causal relevance has its roots in the philosophical works of Good [ 451, and Salmon relationships, Suppes cause-effect relevance. Although relevance, a given probability [ 3,5,32]. with no reference to give probabilistic [ 371, who attempted and recognized interpretations causal from statistical the need to distinguish these attempts have not produced an algorithmic definition of causal the consistency of relevance statements against the variables in themselves, and a given distribution for testing statements among temporal ordering relevance or temporal orderings. to underlying probabilities The current paper aims at axiomatizing they led to methods [ 121, to Axiomatic characterization theories of action as well as a guide of causal relevance may serve as a normative for schemes applications. For example, [6], such schemes should enable an agent to examine only direct effects of actions for a given goal and which actions cease to be analyzing (e.g., graphical models) instead of explicitly representation and to infer which actions are relevant relevant once others are implemented. for planning storing all possible effects of an action, as in STRIPS and decision-making for developing representation standard nuances example, in general Another application should assist a machine lies in the area of automatic systems, where machine-generated of causal relevance in complex diagnostic language gener- ation-for explana- tions are loaded with causal utterances. The formalization of causal relevance and causal relationships and selecting proper causes B”, linguistic “B was caused by A”, “A was the cause of B “, “B occurred despite A”, or “B would not if it were not for A” all express some form of causal relevance between have occurred A and B, yet these utterances the appropriate and making of the relation between A and B in the context choice may require careful understanding of the discussion. Axiomization of causal relevance could also be useful in causal conversations. such as “A normally are not entirely in distinguishing to experimental researchers Statements equivalent in suppose we find influence on others conditions, For example, the amount of exercise domains where exact causal models do not exist. If we know, through experimentation, that some variables have no causal determine whether other variables will exert causal experimental or may ask what additional information. growth while no effect on tumor growth while diet is kept constant. We would infer that controlling no influence changing activity, given diet is kept constant when activity in a system, we may wish to influence, perhaps under different such that a rat’s diet has no effect on tumor that exercise has to to be able to exercise) would still have is deciding whether in the cage would have an effect on the rat’s physical that temperature has no effect on activity when has no effect on (the rat’s choice of) diet temperature that we have established only diet (while paying no attention on tumor growth. A more subtle is kept constant and, conversely, inference problem is kept constant. that temperature could provide the ambient experiments like and \fD. Galles, J. Pearl/Artijicial Intelligence 97 (1997) 9-43 II set of axioms unless further assumptions are made about the underlying If we add the stability assumption (i.e., the nature of the individual processes that no irrelevance in the system), irrelevance. The probabilistic to change very weak; the probability definition, of the effect it does not support a very causal can be destroyed by the same then we obtain of causal irrelevance with inability appeal but is inferentially We provide two formal definitions which equates causal variable, has intuitive expressive model. changing set of axioms in directed graphs. The deterministic inability of axioms without our making path-interception deterministic for probabilistic irrelevance. to change axioms causal the effect variable causal as the set governing path interception irrelevance definition, which equates causal in any state of the world, allows irrelevance with for a rich set the causal model. All of the for directed graphs, with the exception of transitivity, hold for any assumptions about In Section 2, we define causal models, a formal system for interpreting In Section 3, we provide ments. determine which of the graphoid axioms hold under this definition. Finally, definition of causal we give a nonprobabilistic irrelevance. for proving of probabilistic about causal a definition irrelevance statements causal causal state- and in Section 4, and offer a graphical method irrelevance 2. Causal models A causal model given domain; namely, computation) here a definition economics. is a complete specification of the causal relationships it is a mathematical of every causal query about object the domain. Following that provides an interpretation that govern a (and [29] we will adopt and in engineering that generalizes most of the causal models used Definition 1 (Causal model). A causal model is a 3-tuple M= (YU,F), where (i) V={Xl,... (ii) U={Ui,..., disturbances, , Xn} is a set of endogenous variables determined within U,*} is a set of exogenous or background assumptions, abnormalities, variables or boundary conditions, the system, that represent and (iii) F is a set of n nontrivial functions {ft , . . . , f,,}, each having the form Xi = fi(pUi,U), i = 1,. . . ,n, (1) where pUi are the values of a set of variables PAi G V \\ Xi (connoting the direct causes of Xi. We will assume solution we can consider the causal model M. called parents), in (iii) has a unique for Xl, . . . , X,,, given any value of the background variables Ut , . . . , U,,,. Thus (I in each variable X E V to be a function XM ( U) of the background that the set of equations The uniqueness assumption is always satisfied predecessors of Xi in some order, but may be violated in recursive models, where PAi are that is, in nonrecursive systems, \f12 D. Galles, J. Pearl/Art@cial intelligence 97 (1997) 9-43 V = {X, Y} binary x=ut v ‘y U = { UI } binary y=ut AZ x X- yy Fig. 1. A valid nonrecursive causal model, with unique values for X and Y for all values of U. solutions such functions would be disallowed in nonrecursive models conveys two possible (X = 0, Y = 0)-so requirement systems with feedback. For example, consider The state U = 0 permits 1) and The uniqueness represents all relevant background in one state. Systems possessing dynamic notion of previous supplementing state, and incorporated factors, not modeled V and U [ 91. a deterministic in U. Such physical system conditions U were accounted several equilibrium for X and Y-namely, the equations x = y V u and y = x v u. (X = 1, Y = in a causal model. that F that for, such a system can only be the existence of states the into our analysis as a third kind of variables factors often can be summarized the understanding in equilibrium. if we assume indicate Indeed, by The assumption that there is a unique solution for X1, . . . , X,, while limiting 1, does not prevent the use of causal models to describe The equations do not need to be recursive the scope feedback systems to ensure uniqueness. the causal model shown in Fig. 1 dictates unique values for X and Y for of Definition in stable equilibrium. For example, UI =0 a",
            {
                "entities": [
                    [
                        64,
                        90,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 343–367Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEmpirical decision model learningMichele Lombardi a,∗a DISI, University of Bologna, Italyb DEI, University of Bologna, Italy, Michela Milano a, Andrea Bartolini ba r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 21 December 2015Accepted 10 January 2016Available online 13 January 2016Keywords:Combinatorial optimizationMachine learningComplex systemsLocal searchConstraint programmingMixed integer non-linear programmingSAT modulo theoriesArtificial neural networksDecision treesOne of the biggest challenges in the design of real-world decision support systems is coming up with a good combinatorial optimization model. Often enough, accurate predictive models (e.g. simulators) can be devised, but they are too complex or too slow to be employed in combinatorial optimization.In this paper, we propose a methodology called Empirical Model Learning (EML) that relies on Machine Learning for obtaining components of a prescriptive model, using data either extracted from a predictive model or harvested from a real system. In a way, EML can be considered as a technique to merge predictive and prescriptive analytics.All models introduce some form of approximation. Citing G.E.P. Box [1] “Essentially, all models are wrong, but some of them are useful”. In EML, models are useful if they provide adequate accuracy, and if they can be effectively exploited by solvers for finding high-quality solutions.We show how to ground EML on a case study of thermal-aware workload dispatching. We use two learning methods, namely Artificial Neural Networks and Decision Trees and we show how to encapsulate the learned model in a number of optimization techniques, namely Local Search, Constraint Programming, Mixed Integer Non-Linear Programming and SAT Modulo Theories. We demonstrate the effectiveness of the EML approach by comparing our results with those obtained using expert-designed models.© 2016 Elsevier B.V. All rights reserved.1. IntroductionAdvances in Combinatorial Optimization methods in the last decades have enabled their successful application to a broad range of industrial problems. Many of such approaches rely on the availability of some declarative system description. This typically consists of a hand-crafted mathematical model, obtained after thorough discussion with the domain experts by introducing some simplifying assumptions.Devising a good model is a complex task, especially challenging when dealing with real-world systems. A good model finds a proper balance between model complexity and model accuracy: on the one hand, excessive simplification may lead to “optimal” – but completely useless – solutions. On the other hand, incorporating too many details results in extremely hard computational issues. Despite this, a number of successful optimization approaches have been proposed in the literature and * Corresponding author.E-mail addresses: michele.lombardi2@unibo.it (M. Lombardi), michela.milano@unibo.it (M. Milano), a.bartolini@unibo.it (A. Bartolini).http://dx.doi.org/10.1016/j.artint.2016.01.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\f344M. Lombardi et al. / Artificial Intelligence 244 (2017) 343–367applied to real-life industrial problems, enabling in many cases1 huge savings in terms of resources (time, money, machines, energy).Nevertheless, many systems are still impervious to approaches such as Mixed Integer Linear Programming (MILP), Con-straint Programming (CP), or SAT (propositional SATisfiability) and this is often due to modeling issues. There are basically two kinds of “high-complexity systems” that are out-of-reach for traditional combinatorial approaches: (1) Complex Systems, which exhibit phenomena that emerge from a collection of interacting objects capable of self-organization and affected by memory or feedback; and (2) physical systems whose dynamic model is known, but its embedding in a combinatorial model is computationally intractable.A very common way for supporting decision-making in these systems is to design a predictive model (e.g., a simulator) based on real data and to use it via what-if analysis (see [2] for a recent reference). In what-if analysis, the decision maker repeatedly feeds scenarios (i.e. sets of decisions) to the predictive model to extract the values of certain observables of interest (e.g. quality measures). Inevitably, only a limited number of scenarios is investigated, and then the decision maker commits to the one showing the best behavior. In combinatorial problems the decision space might be so large that selecting scenarios manually or in isolation results in far-from-optimal choices.The aim of this paper is to bring such high-complexity systems within the reach of combinatorial decision making and optimiza-tion. The idea is to use Machine Learning (ML) to learn an approximate relation between decisions and their impact on the system. In particular, we devise a methodology, called Empirical Model Learning (EML) that: (1) learns relations be-tween decidables and observables2 from data, and (2) encapsulates these relations into components of an optimization model, namely objective functions or constraints. The training data for the learning techniques can be harvested from the real system or extracted from a predictive model (e.g. simulator). The integration into model components is not merely a matter of encoding, since in some cases an operational semantics for the efficient use of the component should be de-fined.The ability to integrate Machine Learning models in combinatorial optimization has the potential to play a major role in bridging the gap between predictive and prescriptive analytics. An EML based system may be capable of suggesting optimal decisions in a complex real-world setting, by taking advantage of recent developments in big data analysis and predictive model design.This paper provides three main contributions. First, we introduce the Empirical Model Learning approach in a general fashion. Second, we present a number of methods for embedding Machine Learning models (namely Decision Trees and Artificial Neural Networks) into several optimization techniques (Local Search, Mixed Integer Non-Linear Programming, Con-straint Programming, SAT Modulo Theories). Some of our embedding techniques have been presented in previous papers of ours [4,5]. Third, we show that despite the main idea behind EML being very simple, its application requires some care for obtaining an effective optimization approach. We highlight the main difficulties and suggest possible solutions by applying the EML approach on two practical examples.As motivating (and running) examples, we use two thermal-aware workload dispatching problems, defined over an ex-perimental multicore Intel CPU called “Single-chip Cloud Computer” (SCC, see [6]). Both problems consist in mapping a set of heterogeneous jobs on the platform cores so as to maximize some cost metric involving the platform efficiency. The efficiency of each core is affected by a number of complex factors including the thermal dynamics of the chip, the workload distribution, and the presence of low-level schedulers and thermal controllers. Although an accurate system simulator for the platform is available, it cannot be inserted into a decision model due to its high complexity and large run time. We show that EML allows considerable improvements over simpler optimization approaches either based on expert-designed heuristics, or on expert-designed models refined via function fitting.The paper is structured as follows: in Section 2 we provide a comparative analysis of related work. In Section 3 we introduce the example problems. In Section 4 we give a brief overview of the EML approach. Section 5 presents techniques for embedding Machine Learning models into Combinatorial Optimization models. Sections 6 and 7 discuss respectively how to design the core combinatorial structure of the optimization problem, and how to extract a system model from data: in both cases, our example problems are employed to present the process. We provide experimental results in Section 8 and concluding remarks in Section 9.2. Comparative analysis of related workThe EML approach combines elements of Combinatorial Optimization, Machine Learning, and Complex Systems/Simula-tion. In this section we provide a brief overview of approaches related to the integration of such research fields.Loosely related approaches Researchers have been interested for a long time in the integration of optimization techniques in Machine Learning. This is not surprising, given that training problems are fundamentally (very peculiar) optimization prob-lems. Works such as [7,8] have studied the core optimization problems in ML algorithms and proposed efficient methods 1 The reader may find some examples on the web page dedicated to the Franz Edelman Award at https :/ /www.informs .org /Recognize-Excellence /Franz-Edelman-Award.2 The names decidables and observables have been suggested by Peter Flach [3].\fM. Lombardi et al. / Artificial Intelligence 244 (2017) 343–367345for extracting knowledge from huge volumes of data. Other works (e.g. [9,10] and those presented in [11]) have applied Constraint Programming to Machine Learning tasks.In the optimization community, a substantial effort has been recently dedicated to using learning to improve a solution approach. Clustering methods have been employed for automatic algorithm selection (e.g. [12]). Several Machine Learning techniques have been used for predicting the run time of optimization algorithms, once again with the aim to perform algorithm selection (e.g. [13,14]). A few works have focused on learning customized optimization problem instances for testing new techniques (see [15]).Constraint acquisition Some papers [16–18] have focused on learning a set of constraints t",
            {
                "entities": [
                    [
                        136,
                        169,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 96 ( 1997) 42 l-449 Artificial Intelligence Reasoning with minimal models: efficient algorithms and applications 1 Rachel Ben-Eliyahu-Zohary a**, Luigi Palopoli b*2 a Mathematics and Computer Science Department, Ben-Gurion University of the Negev, Beer-Sheva 84105, Israel b DEIS, Universitd della Calabria, 87030 Rende (CS), Italy Received September 1996 Abstract Reasoning with minimal models is at the heart of many knowledge-representation systems. Yet it turns out that this task is formidable, even when very simple theories are considered. In this paper, we introduce the elimination algorithm, which performs, in linear time, minimal model finding and minimal model checking for a significant subclass of positive CNF theories which we call positive head-cycle-free (HCF) theories. We also prove that the task of minimal entailment is easier for positive HCF theories than it is for the class of all positive CNF theories. Finally, we show how variations of the elimination algorithm can be applied to allow queries posed on disjunctive deductive databases and disjunctive default theories to be answered in an efficient way. @ 1997 Published by Elsevier Science B.V. Keywords: Minimal models; Disjunctive databases; Disjunctive default logic; Disjunctive logic programs; Stable model semantics; Linear time algorithms 1. Introduction Computing minimal models is an essential ficial intelligence, including circumscription [ 29-3 11, default logic task in many reasoning systems in arti- [ 391, and minimal * Corresponding author. Email: rachel@cs.bgu.ac.il. ’ Part of this work was done while the first author was visiting the Cognitive Systems Laboratory, Computer Science Department, University of California, Los Angeles, CA, USA, and the second author was a visiting scholar at the Computer Science Department, University of California, Los Angeles, CA, USA. This is an on Principles of extended and revised version of a paper presented at the Fourth and Reasoning, Bonn, Germany, 1994. Knowledge Representation International Conference * Email: luigi@si.deis.unical.it. 0004-3702/97/$17.00 PIISOOO4-3702(97)00060-X @ 1997 Published by Elsevier Science B.V. All rights reserved. \f422 R. Ben-Eliyahu-Zohary, L. PalopoWArtficial Intelligence 96 (1997) 421-449 diagnosis semantics sumption or plausible gorithms systems. [ 121, and in answering queries posed on logic programs [4,21]) [32]). and deductive databases systems, the generalized the goal is to produce plausible In such reasoning (under (under stable model as- closed-world inferences explanations, not to compute minimal models. Nonetheless, for computing minimal models can substantially speed up inference efficient al- in these Surprisingly, and perhaps due to its inherent difficulty, reasoning with minimal models Given a propositional tasks (and others) have been consid- [ 6,9-l 1,18,26,34]. has received a formal analysis only recently CNF theory T and a literal L in T, the following ered: 3 is a minimal model for T. l Model finding. Find a minimal model l Model checking. Check whether a given interpretation l Minimal entailment. l Minimal membership. Unfortunately, for T. the results of the formal work on the complexities Is L true in all the minimal models of T? Is L true in at least one minimal model of T? minimal models are discouraging. is, when the theory has no clause are very hard to answer: model finding always have a minimal model!) 4, model checking and minimal membership entailment is II;-complete, is P NP[o(lo@)]-hard (and positive [lo] is co-NP-complete is X;-complete [ 181. It turns out that even when the theory is positive, in which all the literals are negative, of reasoning with that these questions theories [9], minimal to the positive that turns out to characterize In this paper, we exploit a basic property is head-cycle-freeness the negative a subclass of all CNF theories for which the above and related problems can be solved efficiently. The [ 71. The idea is simple. A clause 5 is viewed as having a property direction-from is made explicit in the way clauses are represented in logic programs. We then associate a dependency graph with each an arc directed and there is an arc directed positive dependency appear positive in the size of the theory. is in S, if A appears if and only if in its that in time linear graph there is no directed cycle that goes through in 6. A CNF theory will be called head-cycle-free from a clause S to an atom A if and only from an atom A to a clause 6 if and only in the same clause. Head-cycle-freeness theory: each atom and each clause if A appears negative two different atoms can be checked in the graph; this direction literals-and is a node (HCF) there We show that for positive HCF theories, the above problems are more manageable time in the size of the theory, minimal than they are in the general case: model linear minimal membership are summarized in this paper. is NP-complete. The complexity in Fig. 1. Entries without a reference number entailment is co-NP-complete results for propositional indicate in [20], and theories results presented finding and model checking can be done 3 See the next section for formal definitions of minimal model, interpretation, and IiteraZ. 4 We recall that PNP[o(las n)l is the class of decision problems that are solved by polynomial-time deterministic Turing machines making at most a logarithmic number of calls to an oracle characterization of model finding, given in terms of complexity of the complexity bounded in NR For a precise see classes of functions, [ill. 5 In this section, a clause is a disjunction of literals. In the following sections we use a different syntax. \fR. Ben-Eliyahu-Zohary, L. Palopoli/Ar@cial Intelligence 96 (1997) 421-449 423 Language CNF Model checking co-NP- complete Model finding NPMVllOptP[O(logn)]- complete [ 111 [ 91 Minimal entailment Minimal membership $-complete [ 181 8;-complete [ 181 positive HCF O(n) O(n) co-NP-complete [ 201 NP-complete Fig. 1. Complexity of computational tasks with minimal models. Our algorithms can be generalized to allow efficient computation of minimal Herbrand for a significant subclass of positive models apply our results on CNF theories disjunctive [ 441 that computes a stable model for a stratified HCF disjunctive deductive database 6 . This algorithm also can be used to answer queries posed on disjunctive default in that seemingly In addition, we that use algorithm rules. Specifically, we provide a polynomial-time to answering queries on deductive databases first-order CNF theories. data complexity form a relevant knowledge fragment of CNF theories the world about [ 16,19,27]. HCF theories represent meaningful theories is formally confirmed in [ 271, where their expressive power is precisely The rest of this paper is organized as follows. In Section 2, we present theories. they can The relevance of HCF stated. the elimina- positive HCF finding for propositional tion algorithm which performs minimal model theories, and consider entailment and minirnal rithm for the class of function-free demonstrate systems. Related work is discussed tion 6. some applications of the elimination the other tasks of minimal model checking, minimal membership, for this class. In Section 3, we generalize first-order positive HCF theories. algorithm in Section 5, and conclusions in knowledge-representation are presented in Sec- the elimination algo- In Section 4, we 2. The elimination algorithm for positive HCF theories In this section, we introduce the elimination algorithm perform minimal model We will also establish and minimal membership finding on a propositional positive HCF theory the complexity of minimal model checking, minimal (EA), which can be used to time. entailment, in linear for propositional positive HCF theories. We defilne a theory T to be a set of clauses of the form (1) the body of the clause, while where IZ, m > 0 and all the A’s and the C’s are atoms. 7 The expression -+ is called the head of the clause. We assume positive we state otherwise. to the left of to the right of --f is called that all of the Cs are distinct. A theory T is called theories, unless if, for every clause, n > 0. In this section, we deal with positive the expression 6 Stable models and srra@ied disjunctive deductive databases will be defined in the following the equivalent notation ’ Note that the syntax of (1) for a clause; usually, is a bit unusual sections. -Al V -A2 V . . V -A,,, \\I Cl V C2 V . . . V C, is used. \f424 R. Ben-Eliyahu-Zohary, L. Palopoli/Artijicial Intelligence 96 (1997) 421-449 A set of atoms satisfies the body of a clause if and only if all the atoms in the body to this set. A set of atoms violates a clause if and only if the set of the clause belong the body of the clause but none of the atoms in the head of the clause belongs satisfies to the set. A set of atoms X is a model of a theory T if none of its clauses is violated by X. A model X of a theory T is minimal if there is no Y c X that is also a model of in T. T. An interpretation for a theory T is an assignment Interpretations the value true. A literal is an atom (“positive” and models will be represented by the set of atoms being assigned literal) or a negated atom (“negative” of truth values to the atoms literal). With every theory T we associate a directed graph Gr, called the dependency graph * of T, in which (a) each atom A and each clause 6 in T is a node and (b) there is an arc from A to S if and only if A is in the body of 6 and an arc from S to A if and only if A is in the head of 6. As mentioned before, model finding is co-NP-complete, model entailment for positive theories is II;-complete, is PNPto(losn)l-hard, model and minimal membership checking is Z;-complete. problems only directed cycle involving Ci and Cj. So, for example, is not HCF, while the theory A -+ B, B + A, A V C is HCF. From the work of [ 71 and the results presented here it follows that these",
            {
                "entities": [
                    [
                        68,
                        136,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 98 (1998) 317-349 Artificial Intelligence On the knowledge requirements of tasks Ronen I. Brafman a,*, Joseph Y. Halpern b*l, Yoav Shoham c,2 a Department of Mathematics and Computer Science, Ben-Gurion University, Beer-Sheva 84105, Israel b Computer Science Department, Cornell University, Ithaca, NY 14853-7501, USA c Computer Science Department, Stanford University, Stanford, CA 94305, USA Abstract In order to successfully perform a task, a situated system requires some information about its domain. If we can understand what information the system requires, we may be able to equip it with more suitable sensors or make better use of the information available to it. These considerations have motivated roboticists to examine the issue of sensor design, and in particular, the minimal information required to perform a task. We show here that reasoning in terms of what the robot knows and needs to know to perform a task is a useful approach for analyzing these issues. We extend the formal framework for reasoning about knowledge, already used in Al and distributed c:omputing, by developing a set of basic concepts and tools for modeling and analyzing the knowledge requirements of tasks. We investigate properties of the resulting framework, and show how ii: can be applied to robotics tasks. @ 1998 Elsevier Science B.V. Keywords: Knowledge; Sensor design; Configuration programs; Knowledge complexity; Knowledge capability space; Manipulation tasks; (Skeletal) knowledge-based 1. Introduction complexity The notion of computational effect on the develop- ment of computer science. While imperfect, our ability to classify different computational problems solving in polynomial versely, when a problem in solved for its solution. Con- to be) a more such problems. Thus, when a problem can be solved or approximately on improving to be a member of (what in terms of their complexity time, we can concentrate allows us to understand has had a profound inherent difficulties is believed algorithms is shown author. Email: brafman@cs.bgu.ac.il * Corresponding ] EmaiI: halpcm@cs.comeIl.edu. 2 Email: shoham@cs.stauford.edu. 0004-3702/98/$19.00 PIISOOO4-3702(97)00061-l @ 1998 Elsevier Science B.V. All rights reserved \f318 R.I. Brajinan et al. /ArtiJicial Intelligence 98 (I 99%) 317-349 assumptions when confronting (e.g., ). However, is true primarily difficult class such as the class of NP-complete for heuristics and simplifying Some areas of robotics have benefited of certain stylized [5,17,18] This motion-planning the analog of a Turing machine, a formal device of a robotic task or the capabilities space and issues such as the sloppiness for communication This suggests information Donald between that a good model time complexity of controllers, for robotics spatially [ 71. are not the dominating from advances robotics problems, problems, we know that we must look this problem. in computational complexity. such as variants of robot the area of robotics as a whole still lacks the difficulty for this is that usually in a robotic task. Rather, of sensors, and the need factors the imprecision that faithfully quantifies of a robot. 3 The reason separated components assume major should revolve around importance. the notions of [9] and and uncertainty. Similar points have also been made by Erdmann to capture framework We propose a formal can form the basis for a general model of informational robotic [ 101, which makes use of a formal notion of knowledge. We believe terms of knowledge robots and robotic of the knowledge of the knowledge robot to perform requirements systems attack these notions, closely based on that of in aspects of in terms tasks. In our framework, required in terms they can acquire. We can therefore assess the ability of a particular to the knowledge a task by comparing in distributed tasks such as coordinated tasks can be characterized them, and robots can be characterized of the use of knowledge of the task. This the information to characterize its knowledge that reasoning is reminiscent to perform to perform capabilities needed [ 111. attained. a crucial . . .-plays is attained In a certain is eventually I. Moreover, for coordination In the coordinated that everyone knows state where everyone knows and agreement is irrelevant; task is to move an object from some These are the types of tasks discussed attack problem and other problems of coordination and agreement, it turns out that common knowledge-the that everyone role. It is, in a precise sense, a nec- knows [ 10,ll the essary and sufficient condition is that all that matters knowledge before common knowledge common knowledge important class of tasks that we consider here, which we refer to as manipulation tasks, we can say even more. The goal to a goal in a manipulation literature configuration. [ 9,141. formulas such that, if the agent knows one of these formulas at every step, then the task can be performed for the it is possible each of these tests identifies agent always the a set of configurations the distance, goal. This is essentially [9]. As we shall see, thinking tool to clarify what is going on. We illustrate in terms of knowledge gives us a high-level this point by applying our ideas analyzed by example originally Blum and Kozen initial configuration in the motion-planning find a set of propositional to know one of these conditions. for which a particular exists which would reduce from to some distance measure, of the system’s configuration (if the agent has appropriate task, we can typically [ 11; see Section 4. to a maze-searching taken by Erdmann In a manipulation and, moreover, the approach Intuitively, according transition sensors) ’ This observation was made by John Mitchell. \fR.I. Brajkan et al. /Artificial Intelligence 98 II 998) 317-349 319 - - 10 9 8 7 6 5 4 3 2 1 0 Fig. 1. The two-arm system. To provide intuition, throughout this paper we will anchor example. Although simple, the example embodies sensing, and the need to coordinate the formal develop- two impor- the actions of spatially ment in the following tant ingredients-imprecise distributed actuators. one-dimensional in feet, from 0 through 10 (for simplicity we ignore robotic arms must coor- Example 1.1. Two horizontal, perpendicular, dinate as follows. The first arm must push a hot object lengthwise across the table until the second arm is able to push it sideways so that it falls into a cooling bin. The length is marked the vertical of the table is initially placed at position 0 on the table. The second arm is coordinate). The object [ 3,7]. 4 The second arm cannot able to push the object if it is anywhere this will cause the mechanism hit the obiject while for more than an instant to jam; on the other hand, the object cannot remain motionless the second arm must move precisely when or it will burn a hole into the table. Thus, the first one stops. This setup two variants of the in Fig. 1. We consider is illustrated problem: it is pushed by the first arm, since in the region (a) The arms share a controller. The controller has access to a sensor reporting the position of the object with error no greater location is q then the reading can be anywhere than 1, i.e., if the object’s current in [q - 1, q + 1 ] . (b) Same as (a), except the error bound It is not hard to see that in case (b), is 4 rather than 1. is no protocol there that performs that deals with (a) the task, is whereas the following in case (a), (where there is. For example, a centralized protocol r is the current reading) : if I 61 4 then Move(armi) else Move(armz). 4 We use the [a, b] notation to denote the interval of natural numbers between a and b, including a and b. Thus, [3,7] ={3,4,5,6,7}. \f320 RI. Brafman et al. /AriQicial Intelligence 98 (1998) 317-349 several basic information controller this task and what information Example 1 .l illustrates the need the controller needs in order to perform to analyze issues, such as how much each in this paper. taken by the actions, and plans, we take tools for activities. a situated is capable of obtaining. These are the types of issues we consider the planning perspective This example should make apparent [ 151 and Morgenstern that, unlike [ 161 on knowledge, that can perform some given set of tasks. To use the analogy of computational the task of building that must agents representation the course of its planning that can aid in the process of designing its knowledge during It is not our goal to provide knowledge work of Moore a design perspective. an agent that reasons about Rather, we provide a set of concepts system complexity, we are not considering how to solve a particular computational which a designer could characterize problem. Although both problems assumptions, concepts, and languages are appropriate to say on this issue in our discussion of related work (Section 5). are related at some abstract problem; rather, we attempt to provide figure out tools by that soIves this level, different models, in each case. We shall have more the resources needed by a program The rest of this paper is organized as follows: In the next section, we describe to define measures of information requirements tasks, agents, and their information requirements. we take in modeling use the concept of knowledge and information these measures. of additional the problem of maze searching. We discuss Section 6 with some directions for further work. of agents, and we show some relations capabilities In Section 4, we continue with this development, tools, such as control variables and learning. We illustrate supplying related work in Section 5, and conclude the view In Section 3, we of tasks that exist among a number these tools with in 2. The basic model In this section, we describe a basic model of an agent embedded it must act. We start with an overview of our perspective in which understanding and our technical choices of which will help the reader understand the de",
            {
                "entities": [
                    [
                        75,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 991–1017www.elsevier.com/locate/artintOn propositional definability ✩Jérôme Lang a, Pierre Marquis b,∗a IRIT, CNRS / Université Paul Sabatier, 118 route de Narbonne, 31062 Toulouse, Franceb CRIL, CNRS / Université d’Artois, rue Jean Souvraz, S.P. 18, 62307 Lens, FranceReceived 21 November 2006; received in revised form 19 December 2007; accepted 28 December 2007Available online 11 January 2008AbstractIn standard propositional logic, logical definability is the ability to derive the truth value of some propositional symbols given apropositional formula and the truth values of some propositional symbols. Although appearing more or less informally in variousAI settings, a computation-oriented investigation of the notion is still lacking, and this paper aims at filling the gap. After recallingthe two definitions of definability, which are equivalent in standard propositional logic (while based on different intuitions), anddefining a number of related notions, we give several characterization results, and many complexity results for definability. We alsoshow close connections with hypothesis discriminability and with reasoning about action and change.© 2008 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Propositional logic; Computational complexity; Definability; Hypothesis discriminability; Reasoning aboutaction and change1. IntroductionWhen reasoning about knowledge represented in propositional logic, exhibiting structure can be of a great help.By “structure” we mean some relationships which exist between some sets of propositional symbols and/or formulaswithin a propositional formula (cid:2). Such relationships are known under various names, including dependency, rele-vance, novelty, controllability, and some of them have been investigated, see among others [1,2].In this paper we focus on an additional form of dependency, called definability. Definability captures two differentintuitions: implicit definability and explicit definability. A propositional symbol y can be implicitly defined in a givenformula (cid:2) in terms of a set X of propositional symbols if and only if the knowledge of the truth values of thepropositional symbols of X (whatever they are) enables concluding about the truth value of y, while y can be explicitlydefined in (cid:2) in terms of X when there exists a formula (cid:3)X built up from X only, such that (cid:3)X is equivalent to y in (cid:2).✩ This paper is an extended and revised version of some parts of two papers: “Complexity results for independence and definability inpropositional logic”, appeared in the Proceedings of the Sixth International Conference on Principles of Knowledge Representation and Reasoning(KR’98), pages 356–367; and “Two forms of dependence in propositional logic: Controllability and definability”, appeared in the Proceedings ofthe Fifteenth National Conference on Artificial Intelligence (AAAI’98), pages 268–273.* Corresponding author.E-mail addresses: lang@irit.fr (J. Lang), marquis@cril.univ-artois.fr (P. Marquis).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.12.003\f992J. Lang, P. Marquis / Artificial Intelligence 172 (2008) 991–1017Table 1The complexity of DEFINABILITYFragment CDEFINABILITYPROPPS (general case)DNNFq-HornCNFIPcoNP-cin Pin PcoNP-cDefinability is acknowledged as an important logical concept for decades. It is closely related to the Craig/Lyndoninterpolation theorem [3]. Many studies in logic are about determining whether a given logic (standard or modal,propositional or first-order) satisfies the “basic” Beth property (whenever a theory implicitly defines a symbol interms of all others, there is an explicit definition of that symbol in terms of all others), or even the (stronger) projectiveBeth property (when implicit definability and explicit definability coincide). Thus classical first-order logic satisfiesthe “basic” Beth property (this is the famous Beth’s theorem [4]), as well as the projective one, while for instancefirst-order logic on finite structures does not (see e.g., [5]).Standard propositional logic has been known to satisfy the projective Beth property. In this paper, we consider de-finability in standard propositional logic from a computational point of view. We present several characterization andcomplexity results which prove useful for several AI applications, including hypothesis discrimination and reasoningabout actions and change.From a computational point of view, our results concern both time and space complexity. As to time complexity,we mainly considered the decision problem DEFINABILITY which consists in determining whether a given formula(cid:2) defines a given symbol y (or more generally a given set Y of symbols) in terms of a given set X of symbols. Weidentify its complexity both in the general case and under restrictions induced by a number of propositional fragments(formally defined in Section 2) that proved of interest in many AI contexts (see [6–9]); the results are summarized inTable 1.While the table shows that the definability problem is intractable in the general case (unless P = NP), it also showsthat:• The main propositional fragments which are tractable for SAT are also tractable for DEFINABILITY. Indeed, DNNFcontains (among others) all DNF formulas and all OBDD “formulas”, while q-HornCNF contains all renamableHorn CNF formulas. The fact that large propositional fragments (including complete ones, i.e., fragments intowhich any propositional formula has an equivalent, as DNNF is) is of great value from a practical perspective.• Nevertheless, tractability for SAT is not enough for ensuring tractability for DEFINABILITY. Thus the Blake frag-ment IP is tractable for SAT but likely not for DEFINABILITY. We also identify some sufficient conditions (referredto as stability conditions) under which a propositional fragment is tractable for SAT if and only if it is tractable forDEFINABILITY.About space complexity, we focus on the size of definitions; we show that in the general case, the size of anyexplicit definition of a symbol y in terms of a set of symbols X in (cid:2) is not polynomially bounded in the input size. Weidentified some sufficient conditions (polytime conditioning and polytime forgetting) on propositional fragments forensuring that definitions can be computed in polynomial time (hence are of polynomial size) when such definitionsexist. Interestingly, the influential DNNF fragment satisfies them, as well as the Blake fragment IP. The result for IPshows that it can be the case that computing an explicit definition of y on X in (cid:2) is easy when one knows that such adefinition exists, while deciding whether it exists is hard.The rest of the paper is organized as follows. In Section 2, we give some necessary background about propositionallogic and computational complexity. In Section 3 the notion of definability is presented, as well as a number ofrelated notions, including the notions of minimal defining family (or base), undefinable symbol, necessary symboland relevant symbol, as well as the notion of unambiguous definability. We also show how such notions relate oneanother and are connected to previous concepts, especially variable forgetting (see [2,10]) as well as the notions ofweakest sufficient and strongest necessary conditions [11]. In Section 4, we give a number of complexity results fordefinability and the related notions. We identify a number of tractable restrictions of the decision problems underconsideration. We also report some complexity results about the size of explicit definitions and present an algorithm\fJ. Lang, P. Marquis / Artificial Intelligence 172 (2008) 991–1017993for computing a base. In Section 5, we show that definability is closely related to hypothesis discriminability. InSection 6, we explain how many important issues in reasoning about action and change can be characterized in termsof definability. In Section 7, we briefly sketch how definability can prove useful to automated reasoning. In Section 8,we relate our results to the literature. Finally, Section 9 concludes the paper.2. Formal preliminaries2.1. Propositional logicLet PS be a finite set of propositional symbols (also called variables). PROPPS is the DAG-based propositionallanguage built up from PS, the connectives ¬, ∨, ∧, ⇒, ⇔ and the Boolean constants true and false in the usual way.Subsets of PS are denoted X, Y , etc. For every X ⊆ PS, PROPX denotes the sublanguage of PROPPS generated fromthe propositional symbols of X only.From now on, (cid:2) denotes a finite set of propositional formulas from PROPPS. Var((cid:2)) is the set of propositionalsymbols appearing in (cid:2) and |(cid:2)| is the size of (cid:2), i.e., the number of symbols used to write it. Elements of PS aredenoted x, y, etc. Specific formulas from PROPPS are of interest: a literal is a symbol x of PS (positive literal) ora negated one ¬x (negative literal). x and ¬x are two complementary literals. A clause (resp. term) is a disjunction(resp. conjunction) of literals, or the constant false (resp. true). A Conjunctive Normal Form formula (for short, a CNFformula) is a conjunction of clauses. A Disjunctive Normal Form formula (for short, a DNF formula) is a disjunctionof terms. A CNF formula is Krom [12] if and only if each clause in it contains at most two literals. A Krom formulais also said to be a 2-CNF formula or a quadratic formula. A CNF formula is Horn [13] if and only if each clause init contains at most one positive literal. A CNF formula (cid:2) is renamable Horn [14] if and only if there exists a Hornrenaming for it, i.e., a set V of symbols v such that replacing every occurrence of v ∈ V (resp. ¬v) in (cid:2) by thecomplementary literal ¬v (resp. v) leads to a Horn CNF formula. A CNF formula (cid:2) has a QH-partition [6] if andonly if there exists a partition {Q, H } of Var((cid:2)) s.t. for every clause δ of (cid:2), ",
            {
                "entities": [
                    [
                        73,
                        102,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1911–1950Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIndependent natural extensionGert de Cooman a, Enrique Miranda b, Marco Zaffalon c,∗a Ghent University, SYSTeMS Research Group, Technologiepark–Zwijnaarde 914, 9052 Zwijnaarde, Belgiumb University of Oviedo, Department of Statistics and Operations Research, C-Calvo Sotelo, s/n, 33007 Oviedo, Spainc IDSIA, Galleria 2, CH-6928 Manno (Lugano), Switzerlanda r t i c l ei n f oa b s t r a c tThere is no unique extension of the standard notion of probabilistic independence to thecase where probabilities are indeterminate or imprecisely specified. Epistemic independenceis an extension that formalises the intuitive idea of mutual irrelevance between differentsources of information. This gives epistemic independence very wide scope as well asappeal: this interpretation of independence is often taken as natural also in precise-probabilistic contexts. Nevertheless, epistemic independence has received little attentionso far. This paper develops the foundations of this notion for variables assuming valuesin finite spaces. We define (epistemically) independent products of marginals (or possiblyconditionals) and show that there always is a unique least-committal such independentproduct, which we call the independent natural extension. We supply an explicit formulafor it, and study some ofits properties, such as associativity, marginalisation andexternal additivity, which are basic tools to work with the independent natural extension.Additionally, we consider a number of ways in which the standard factorisation formulafor independence can be generalised to an imprecise-probabilistic context. We show,under some mild conditions, that when the focus is on least-committal models, using theindependent natural extension is equivalent to imposing a so-called strong factorisationproperty. This is an important outcome for applications as it gives a simple tool to makesure that inferences are consistent with epistemic independence judgements. We discussthe potential of our results for applications in Artificial Intelligence by recalling recent workby some of us, where the independent natural extension was applied to graphical models.It has allowed, for the first time, the development of an exact linear-time algorithm for theimprecise probability updating of credal trees.© 2011 Elsevier B.V. All rights reserved.Article history:Received 1 October 2010Received in revised form 8 June 2011Accepted 11 June 2011Available online 15 June 2011Keywords:Epistemic irrelevanceEpistemic independenceIndependent natural extensionStrong productFactorisationCoherent lower previsions1. Introduction1.1. Background and motivationThis is a paper on the notion of independence in probability theory. Anyone interested in or familiar with uncertainreasoning or statistics knows how fundamental this notion is. But what is independence?Most of us have been taught that two variables X1 and X2 are independent when their joint probability distributionP {1,2} factorises as the product of its marginals P 1 and P 2. This is the formalist route that defines independence through amathematical property of the joint, and that has its roots in the Kolmogorovian, measure- and integral-theoretic formalisa-tion of probability theory.* Corresponding author.E-mail addresses: gert.decooman@ugent.be (G. de Cooman), mirandaenrique@uniovi.es (E. Miranda), zaffalon@idsia.ch (M. Zaffalon).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.06.001\f1912G. de Cooman et al. / Artificial Intelligence 175 (2011) 1911–1950In Artificial Intelligence (AI)—thanks to Judea Pearl in particular [27]—, but also in the tradition of subjective probability—due to a large extent to Bruno de Finetti [17]—, independence has much more often an epistemic flavour: it is a subject whoregards two variables as independent, because she judges that learning about the value of any one of them will not affecther beliefs about the other. This means that the subject assesses that her conditional beliefs equal her marginal ones:P 1(·| X2) = P 1 and P 2(·| X1) = P 2, in more mathematical parlance.That the epistemic approach has become so popular, should not be all that surprising. The formalist approach comeswith the idea that independence is something given, which might hold or not: it is just a property of the joint. On theepistemic view, however, independence is something we are (to some extent) in control of. And this control is essential inorder to aggregate simple, independent components into complex multivariate models.It might be argued that the difference between the two approaches is mostly philosophical: in fact, the two routes areknown to be formally equivalent.1 But it turns out that we lose this formal equivalence as soon as we consider probabilitiesthat may be imprecisely specified, meaning that the available information is conveniently expressed through sets of proba-bilities (sets of mass functions). In this case the two routes diverge also mathematically, as we shall see further on. This isexemplified by the existence of the different notions of strong and epistemic independence, respectively.2 Of these two, strongindependence has been most thoroughly investigated in the literature. Studies of epistemic independence are confined toa relatively small number of papers [6,10,26,29] inspired by Peter Walley’s [30, Section 9.3] seminal ideas. We mention inparticular Paolo Vicig’s interesting study [29], for the case of coherent lower probabilities (which may be defined on infinitespaces), of some of the notions considered in this paper as well.This situation is somewhat unfortunate as the scope of strong independence is relatively narrow: in fact, its justificationseems to rely on a sensitivity analysis interpretation of imprecise probabilities. On this interpretation, one assumes that thereexists some (kind of ‘ideal’ or ‘true’) precise probability P T{1,2} for the variables X1 and X2 that satisfies stochastic indepen-dence, and that, due to the lack of time or other resources, can only be partially specified or assessed. Then one considersall the precise-probabilistic models P {1,2} that are consistent with the partial assessments and that satisfy stochastic inde-pendence. Taken together, they constitute the set of probabilities for the problem under consideration. This set models asubject’s (partial) ignorance about the true model P T{1,2}.It is questionable that this sensitivity analysis interpretation is broadly applicable, for the simple reason that it hingeson the assumption of the existence of the underlying ‘true’ probability P T{1,2}. Consider the situation where we wish tomodel an expert’s beliefs: the expert usually does not know much about ideal probabilities, and what she tells us is simplythat information about one variable does not influence her beliefs about the other. Moreover, we could well argue thatexpert knowledge is inherently imprecise to some extent, no matter the resources that we employ to capture it.3 Therefore,why not take the expert at her word and model only the information she provides us about the mutual irrelevance ofthe two variables under consideration? After all, forcing a sensitivity analysis interpretation here would amount to addingunwarranted assumptions, which may lead us to draw stronger conclusions than those the expert herself might be preparedto get to.In order to model such mutual irrelevance, we need a different understanding of imprecise probability models thatdoes not (necessarily) rely on precise probability as a more primitive notion: Walley’s behavioural theory of impreciseprobability [30], which models beliefs by looking at a subject’s buying and selling prices for gambles. The perceived mutualirrelevance of two sources of information can be formalised easily in this framework: we state that the subject is not goingto change her prices for gambles that depend on one variable, when the other variable is observed. This turns out to bestill equivalent to modelling the problem through a set of precise probabilities P {1,2} but, in contradistinction with thecase of sensitivity analysis, not all those probabilities satisfy stochastic independence in general. The reason for this is thatepistemic independence is a property of the set of probabilities that cannot be explained through the properties of theprecise probabilities that make up the set. This point is not without importance, as it shows that buying and selling pricesfor gambles are actually a more primitive and fundamental notion in a theory of personal probability.This illustrates that a behavioural theory of probability and the notion of epistemic independence fit nicely together.It also indicates that epistemic independence has a very wide scope, as it needs to meet fewer requirements than strongindependence in order to be employed. That being so, why has strong independence been studied and applied much moreextensively than its epistemic counterpart, even in work based on Walley’s approach? This is probably due to a numberof concurring factors: (i) a tendency in the literature to extend stochastic independence, perhaps somewhat uncritically, ina straightforward way to imprecise probabilities; (ii) the fact that epistemic independence does not appear to be as well-behaved as strong independence, for instance with respect to the graphoid axioms [6]4; and, perhaps more importantly,(iii) the lack of formal tools for handling epistemic independence assessments. To give a telling illustration of this lastpoint: epistemically independent products have so far been given a formal definition [30, Section 9.3] only for the case of1 There may be subtleties, however, related to events of probability zero. See Refs. [6, Notes 5 and 6 in Section 3], [30, Sections 6.5 and 6.10] and [1] formore information.2 Other possible ways to defi",
            {
                "entities": [
                    [
                        138,
                        167,
                        "TITLE"
                    ],
                    [
                        1346,
                        1375,
                        "TITLE"
                    ],
                    [
                        1549,
                        1578,
                        "TITLE"
                    ],
                    [
                        1835,
                        1864,
                        "TITLE"
                    ],
                    [
                        2220,
                        2249,
                        "TITLE"
                    ],
                    [
                        2640,
                        2669,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 909–924www.elsevier.com/locate/artintAnalyzing the degree of conflict among belief functionsWeiru LiuSchool of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, BT7 1NN, UKReceived 15 March 2005; received in revised form 6 April 2006; accepted 17 May 2006This paper is dedicated to Philippe Smets who sadly passed away in November 2005Available online 30 June 2006AbstractThe study of alternative combination rules in DS theory when evidence is in conflict has emerged again recently as an interestingtopic, especially in data/information fusion applications. These studies have mainly focused on investigating which alternativewould be appropriate for which conflicting situation, under the assumption that a conflict is identified. The issue of detection(or identification) of conflict among evidence has been ignored. In this paper, we formally define when two basic belief assignmentsare in conflict. This definition deploys quantitative measures of both the mass of the combined belief assigned to the emptyset beforenormalization and the distance between betting commitments of beliefs. We argue that only when both measures are high, it is safeto say the evidence is in conflict. This definition can be served as a prerequisite for selecting appropriate combination rules.© 2006 Elsevier B.V. All rights reserved.Keywords: Dempster–Shafer theory; Dempster’s combination rule; Conflicting beliefs; Betting commitments1. IntroductionWhen the Dempster–Shafer theory of evidence (DS theory) first appeared as a mechanism to model and reasonwith uncertain information in intelligent systems, criticisms on the counterintuitive results of applying Dempster’scombination rule to conflicting beliefs soon emerged (e.g., [18,28,29]) where an almost impossible choice (with avery lower degree of belief) by both sources came up as the most possible outcome (with a very high degree of belief).Since then, alternative combination rules have been explored to recommend where the mass of the conflictingbelief from the two sources should land (e.g., [4,19,26]). Recently, due to the increasing applications of DS theory inintelligent fusion processes, Dempster’s combination rule and its alternatives have been under the microscope again(e.g., [10,13,14,21]).In [13], the three well-known alternatives, i.e., Smets’s unnormalized combination rule (known as the conjunctivecombination rule) [19], Dubois and Prade’s disjunctive combination rule [4], and Yager’s combination rule, are ex-amined and a general combination framework is proposed. This new framework has a component that re-distributesthe mass of the combined belief assigned to the emptyset (the false assumption) in a flexible way that it specifieswhich subsets can share this mass and by what proportions. In this way, the three alternatives listed above can all besubsumed by the framework.E-mail address: w.liu@qub.ac.uk (W. Liu).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.002\f910W. Liu / Artificial Intelligence 170 (2006) 909–924In [14], the weighted average is recommended in certain situations, such as, one piece of evidence contradicts withseveral other pieces of evidence which are consistent, to preserve the opinion from majority sources.While the above two papers are still circling around the well-known alternatives, the method proposed in [10] takesa different approach. A new operator called the consensus operator is proposed which reduces a basic belief assign-ment on a set of values into a basic belief assignment on a binary set (a set with only two values), the combination isthen carried out on this binary set. Three examples, two are commonly regarded as involving conflicting beliefs andone is with consistent beliefs, are examined in comparison with Dempster’s rule of combination. It was concludedthat the consensus operator could always produce a rational result for combining even conflicting beliefs. However,since this method always focuses on two elements when performing combinations, it may not be suitable for manycomplex situations where multiple values (not just two) should be preserved.Furthermore, the consensus operator approach does not provide any indication whether the evidence to be combinedmay be conflicting. As it was concluded by the author “by looking at the result only, it does not tell whether the originalbeliefs were in harmony or in conflict” [10].To justify whether original beliefs are in conflict has a big impact on selecting alternative combination rules [21].So far there are no general mechanisms to measure the degree of conflict other than using the mass of the combinedbelief assigned to the emptyset before normalization, i.e., m⊕(∅) (see its definition in Section 2). In this paper, wemainly focus on this rather ignored topic. We study quantitatively when two sources can be defined as conflict. Weargue that the conventional explanation that a high mass value of the combined belief assigned to the emptyset beforenormalization indicates a conflict among the original beliefs may not always be accurate. For example, if we havetwo distinct and totally reliable sources providing two basic belief assignments m1 and m2 as m1(si) = m2(si) = 0.2(i = 1, 2, . . . , 5), then combining these basic belief assignments with Dempster’s rule yields the mass being assignedto the emptyset as 0.8 before normalization. Under the current convention, this amount of mass would warrant averdict that these two pieces of evidence are in conflict and Dempster’s rule should not be used. In fact, these twopieces of evidence are consistent and using Dempster’s rule produces a new basic belief assignment which is identicalto either of them.In order to avoid a wrong claim made by using only m⊕(∅), we propose an alternative method to measure theconflict among beliefs using a pair of values, the mass of the combined belief allocated to the emptyset before normal-ization and the distance between betting commitments. We also investigate the effect of these measures on decidingwhen Dempster’ rule can be applied. We believe that this result is significant given that it decides subsequently whetherDempster’s rule is appropriate and if not, what other rule should be considered.The rest of the paper is organized as follows. In Section 2, we review the basic definitions in DS theory. In Section 3,we first examine the commonly accepted convention that m⊕(∅) reveals the degree of conflict among two pieces ofevidence and the deficiency associated with this convention. We then investigate the meaning of pignistic transfor-mation and define the distance between betting commitments from two pignistic transformations. A formal definitionconsisting of two measures is proposed to judge when two pieces of evidence are in conflict. We also demonstrate thatthe distance between betting commitments is consistent with the distance between two pieces of evidence measuredby the method in [11]. In Section 4, we explore the properties and behaviour of this pair of measures. In Section 5,we look at the impact of this new definition on the decision of whether Dempster’s rule should be used in general andthen discuss in particular the cases which show the difference in the decisions when using only m⊕(∅) and using bothof the measures. Section 6 concludes the main contribution of the paper and discusses the difference between conflictanalysis and independence analysis among basic belief assignments.2. Basics of the Dempster–Shafer theoryWe review a few concepts commonly used in the Dempster–Shafer theory of evidence, as well as the conjunctivecombination rule [21] and the disjunctive combination rule [4]. Let Ω be a finite set called the frame of discernment.Definition 1. [20] A basic belief assignment (bba) is a mapping m : 2Ω → [0, 1] that satisfies(cid:2)A⊆Ω m(A) = 1.In Shafer’s original definition which he called the basic probability assignment [22], condition m(∅) = 0 is re-quired in Definition 1. Recently, some of the papers on Dempster–Shafer theory, especially since the establishment\fW. Liu / Artificial Intelligence 170 (2006) 909–924911of the Transferable Belief Model (TBM) [16], condition m(∅) = 0 is often omitted. A bba with m(∅) = 0 is called anormalized bba and is also known as a mass function.Definition 2. The belief function from a bba m is defined as bel : 2Ω → [0, 1],bel(A) =(cid:3)m(B).B⊆AWhen m(A) > 0, A is called a focal element of the belief function.Definition 3. [21] A categorical belief function is a belief function where its corresponding bba m satisfies(cid:4)m(B) =1 if B = A, where A (cid:6)= ∅, A (cid:6)= Ω, B ⊆ Ω,0 otherwise.(1)A categorical belief function has only one focal element and this element is neither empty nor the whole frame. Inother words, a categorical belief function assigns the total belief to a single proper subset of the frame.Definition 4. Let m1 and m2 be two bbas defined on frame Ω which are derived from two distinct sources. Let thecombined bba be m⊕ = m1 ⊕ m2 by Dempster’s rule of combination where ⊕ represents the operator of combination.Then(cid:2)m⊕(A) =B,C⊆Ω,B∩C=A m1(B)m2(C)(cid:2)B,C⊆Ω,B∩C=∅ m1(B)m2(C)1 −,∀A ⊆ Ω, A (cid:6)= ∅(cid:2)when(cid:2)B,C⊆Ω,B∩C=∅ m1(B)m2(C) (cid:6)= 1.B,C⊆Ω,B∩C=∅ m1(B)m2(C) is the mass of the combined belief assigned to the emptyset before normalizationand we denote it as m⊕(∅). In the following, whenever we use m⊕(∅), we always associate it with this explanationunless otherwise explicitly stated.The above rule is meaningful only when m⊕(∅) (cid:6)= 1, otherwise, the rule cannot be applied.Definition 5. [21] Let m1 and m2 be two bbas defined on frame Ω. Their conjunctive combination, denoted asm ∩(cid:9) = m1 ∩(cid:9) m2, is a new bba on Ω defined as:(cid:3)m ∩(cid:9)(A) =m1(B)m2(C),B,C⊆Ω,B∩C=A∀A ⊆ Ω,where ∩(cid:9) represents the operator of combination.Definition 6. [4] Let m1 and m2 be two bbas defined on frame Ω. Th",
            {
                "entities": [
                    [
                        72,
                        127,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 85 (1996) 363-397 Artificial Intelligence The sensitivity of belief networks to imprecise probabilities: an experimental investigation Malcolm Pradhan a,b,*, Max Henrion a, Gregory Provan a, Brendan Del Favero a,c, Kurt Huang a*b a Institute for Decision Syslems Research, 4984 El Catnino Real, Suite 110, L.os Altos, CA 94022. USA h Section on Medical Informarics. Stanford University, Stanford, CA 94305, USA c Engineering-Economic Systems, Stanford University, Stanford, CA 94305, USA Received January 1995; revised October 1995 for reason- the numerical In this Abstract Bayesian belief networks are being increasingly used as a knowledge representation the practicality of obtaining for large-scale applications. need to create belief networks the probabilities affects diagnostic performance. We conducted for medical diagnosis of ( 1) varying (2) adding ing under uncertainty. Some researchers have questioned probabilities with sufficient precision work, we investigate how precise in the probabilities set of real-world belief networks the effects on diagnostic performance weights into numerical probabilities, (3) simplifying severe-to outside large amounts of noise significant that outside diseases degraded performance modestly. Overall, highly simple binary belief networks are a practical lead to only modest reductions from quatemary binary domains-absent the network. We found that even extreme differences and present, and (4) using effect of the simplification from quatemary domains imprecise to be by measuring how imprecision a series of experiments on a the mappings in liver and bile disease. We examined frequency to the numerical probabilities. from qualitative test cases mild, moderate, and that contain diseases in the probability mappings and in diagnostic performance. We found no to binary representation. We also found that even significantly, and that that these findings indicate suggest random noise for diseases and findings-absent, representations may often be adequate. These findings of robustness input probabilities may not impair diagnostic performance representation without requiring undue precision. Keywords: Probabilistic reasoning; Bayesian networks * Corresponding author. E-mail: pradhan@camis.stanford.edu 0004.3702/96/$15,00 PIISOOO4-3702(96)00002-l Copyright @ 1996 Published by Elsevier Science B.V. All rights reserved. \f364 M. Prudhm r/ trl. /Artificiul Intelli~erwe 85 (1996) 363-397 1. The tradeoff between accuracy and cost or model is, by definition, from a human expert, Each knowledge representation is derived the representation When of the expert’s perception of reality. The question accurate-it whether is s@ficietzt!\\. for which one that drives our research. is completely for the purposes the representation accurate a simplification it is a simplification of reality. even is not cannot be-but whether the model is the it is designed. This question a representation in choosing in representation The choice of a representation the accuracy with which the model represents is a balancing act. On the one hand, a richer representa- the real-world system. in inferences-for tion should improve Greater accuracy to be correct, example, that would be most effective. On the other hand, a and richer and for resources storage, and will require more effort to construct, verify, and maintain. The success of knowledge-based to find an effective systems depends critically on the knowledge engineer’s ability in a medical application, recommendations representation will require more computational tradeoff between accuracy and cost. that would be more likely lead to improved accuracy should diagnoses for inference treatment Experienced knowledge engineers generally develop useful intuitions about how to there is little theoretical or experimental complexity of alternative them. Of course. the exploration knowledge make such choices: however, available to guide computational topic of AI research. However, once we have chosen a particular such as rules, a nonmonotonic research available to guide or richness of the model Theoretical relationships important and performance, its performance the knowledge representation to affect is likely engineer between analysis role. of the generality, representations research currently and has been a major limitations, type of representation- is little in deciding how the complexity for a given application. of the experimental work must play an can be valuable here. But, due to the analytic complexity logic scheme, or Bayesian belief networks-there 1. I. Experiments on be&f networks efficient in interest techniques, representation In recent years, inference algorithms, there has been substantial growth in Bayesian belief net- 1321. There has been work on the develop- works (BNs) as a knowledge and ment of effective knowledge engineering increasing numbers of real-world applications of BNs [ 14,171. The primary goal of the work described here is to investigate how the precision of representation of BNs affects the quality of diagnosis based on the network. We view this research as a contribution an empirical and theoretical basis for guidelines towards the eventual goal of developing for knowledge engineers the level and complexity of representation that provides generated, to compare knowledge range of different characteristics-such internal nodes, or frequency of undirected cycles-we tradeoff between accuracy and cost. is based on a series of real-world BNs, rather than on the randomly research it is easy to generate BNs with a wide as ratio of arcs to nodes, ratio of source nodes to wanted to focus on BNs that have abstract knowledge bases (KBs) used in much of the experimental representations. Although to help them choose the most appropriate Our investigation \fM. Pradhan et al./Art@cial Intelligence 85 (1996) 363-397 365 the characteristics to be relevant The problem domain disorders (liver and bile diseases). of real application to other real application domains that we use in this study than artificially is medical diagnosis likely generated networks. for hepatobiliary domains. We believe such BNs are more from an early quasi-probabilistic [ 301 that uses a representation (CPCS) reference as frequency weights, specifying BNs case simulation (QMR) links, such as the relationship the experimental patient [25] and quick medical bases, causal We derived computer-based rived the Internist-l In these knowledge finding are quantified give rise to a finding or other variable, on a five-point qualitative our group developed a belief network independence and marginal probabilistic [ 231, even though some information in QMR-BN. reformulation, QMR-BN, demonstrated representation, with specific from the Internist-l independence to convert a method the chance of findings given diseases, noisy OR influences of diseases on findings, of QMR with the independence [40]. Empirical of diseases comparison comparable diagnostic performance (e.g. linkages between diseases) was not employed KB, named de- [24] expert systems. between disease and that one disease will scale. In previous work, to /QMR representation assumptions-conditional herent BN, mapping probabilities Our first task in the current work was to convert the CPCS knowledge base into a co- frequency weights into link probabilities, which are the conditional probabilities, but not caused by one of the diseases or other variable of each finding given each disease. We also had to assess additional to quantify leak that each finding, or other variable, will be present in the knowledge base, and prior the chance probabilities Bayesian to quantify representations the prevalence rate of each disease or predisposing in general, and BNs in particular, have been criticized by to from large numbers of numerical probabilities are estimated directly these probabilities they require factor. by domain experts, or some combination the fact that a conventional BN representation has a certain AI researchers because quantify uncertain data, or assessed as subjective probabilities of the two, there voracious appetite is no denying for such numbers. relationships. Whether The first question we examined is how precise such numbers need to be. The liter- that subjective are liable to consistent biases and imprecision. of subjective probabilities makes clear ature on the expert assessment probabilities achieve adequate diagnostic precision performance the reliability If it turns out that BNs, to require numerical probabilities with greater than experts can provide, BNs will be of little practical value. But, if a BN’s to probable errors, we can allay concerns about assessments. performance, turns out to be insensitive of subjective probability two experiments to examine We performed In each experiment, we assessed bilities. effect on diagnostic diagnosis averaged over a large number of diagnostic performance, measured First, we compared the standard, empirically into probabilities weights treats frequency weights as order-of-magnitude that strength. ignores differences between the numbers to two alternative mappings, the effect of the manipulations assigned as the probability the sensitivity of BNs to the expert proba- in terms of their to the correct test cases, for three different BNs. [ 151 from frequency that and the uniform mapping, links as having equal all probabilities, treating by the curvilinear mapping derived mapping \fSecond, we added random noise to the probabilities ping. In this case, we added noise separately and the prior probabilities. By examining three types of probability, we were able to differentiate effect on diagnostic performance. to the link probabilities, derived from the standard map- leak probabilities, the effect of noise separately on each of these them in terms of their among In our third experiment, we examined is. the number of values each variable can the performance of networks severe} with simplif",
            {
                "entities": [
                    [
                        66,
                        158,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 230 (2016) 134–172Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAffect control processes: Intelligent affective interaction using a partially observable Markov decision processJesse Hoey a,∗a David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, N2L 3G1, Canadab Centre for Theoretical Neuroscience, University of Waterloo, Waterloo, Ontario, N2L 3G1, Canadac Potsdam University of Applied Sciences, Institute for Urban Futures, Kiepenheuerallee 5, 14469 Potsdam, Germany, Tobias Schröder b,c, Areej Alhothali aa r t i c l e i n f oa b s t r a c tArticle history:Received 2 April 2014Received in revised form 12 August 2015Accepted 17 September 2015Available online 3 October 2015Keywords:AffectEmotionSociologyAffect control theoryMarkov decision processIntelligent tutoring systemAssistive technologyHuman–computer interactionThis paper describes a novel method for building affectively intelligent human-interactive agents. The method is based on a key sociological insight that has been developed and extensively verified over the last twenty years, but has yet to make an impact in artificial intelligence. The insight is that resource bounded humans will, by default, act to maintain affective consistency. Humans have culturally shared fundamental affective sentiments about identities, behaviours, and objects, and they act so that the transient affective sentiments created during interactions confirm the fundamental sentiments. Humans seek and create situations that confirm or are consistent with, and avoid and suppress situations that disconfirm or are inconsistent with, their culturally shared affective sentiments. This “affect control principle” has been shown to be a powerful predictor of human behaviour. In this paper, we present a probabilistic and decision-theoretic generalisation of this principle, and we demonstrate how it can be leveraged to build affectively intelligent artificial agents. The new model, called BayesAct, can maintain multiple hypotheses about sentiments simultaneously as a probability distribution, and can make use of an explicit utility function to make value-directed action choices. This allows the model to generate affectively intelligent interactions with people by learning about their identity, predicting their behaviours using the affect control principle, and taking actions that are simultaneously goal-directed and affect-sensitive. We demonstrate this generalisation with a set of simulations. We then show how our model can be used as an emotional “plug-in” for artificially intelligent systems that interact with humans in two different settings: an exam practice assistant (tutor) and an assistive device for persons with a cognitive disability.© 2015 Elsevier B.V. All rights reserved.1. IntroductionDesigners of intelligent systems have increasingly attended to theories of human emotion, in order to build software interfaces that allow users to experience naturalistic flows of communication with the computer. This endeavour requires a comprehensive mathematical representation of the relations between affective states and actions that captures, ideally, the subtle cultural rules underlying human communication and emotional experience. In this paper, we argue that Affect Control Theory (ACT), a mathematically formalized theory of the interplays between cultural representations, interactants’ * Corresponding author.E-mail addresses: jhoey@cs.uwaterloo.ca (J. Hoey), post@tobiasschroeder.de (T. Schröder), aalhothal@cs.uwaterloo.ca (A. Alhothali).http://dx.doi.org/10.1016/j.artint.2015.09.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\fJ. Hoey et al. / Artificial Intelligence 230 (2016) 134–172135identities,1 and affective experience [1], is a suitable framework for developing emotionally intelligent agents. To accomplish this, we propose a probabilistic and decision theoretic generalisation of ACT, called BayesAct, which we argue is more flexible than the original statement of the theory for the purpose of modelling human–computer interaction. BayesAct is formulated as a partially observable Markov decision process or POMDP. The key contributions of this new theory are: (1) to represent sentiments as probability distributions over a continuous affective space, thereby allowing these sentiments to be dynamic and uncertain; (2) to propose a new kind of agent based on affect control theory that has the ability to learn affective iden-tities of interactants; (3) to integrate the affective dynamics proposed by affect control theory with standard POMDP-based artificial intelligence; and (4) to introduce explicit utility functions to affect control theory that parsimoniously trade-off affective and propositional goals for a human-interactive agent. These contributions allow BayesAct to be used as an arti-ficially intelligent agent: they provide the computerised agent with a mechanism for predicting how the affective state of an interaction will progress (based on affect control theory) and how this will modify the object of the interaction (e.g. the software application being used). The agent can then select its strategy of action in order to maximize the expected values of the outcomes based both on the application state and on its affective alignment with the human.Affect control theory arises from the long tradition of symbolic interactionism that began almost three hundred years ago with the insights of Adam Smith [2] into the self as a mirror of the society in which it is embedded: the so-called looking-glass self [2]. These insights eventually led to the modern development of structural symbolic interactionism through Mead, Cooley, and Stryker [3], and culminating in Heise’s affect control theory (ACT) [1], which this paper extends. Although ACT, and symbolic interactionism in general, are very well established theories in sociology, they have had little or no impact in artificial intelligence. This paper is the first to propose affect control theory as a fundamental substrate for intelligent agents, by elaborating a POMDP-based formulation of the underlying symbolic interactionist ideas. This new theory allows ACT to be used in goal-directed human-interactive systems, and thereby allows A.I. researchers to connect to over fifty years of sociological research on cultural sentiment sharing and emotional intelligence. The theory also contributes a generalisation of affect control theory that we expect will lead to novel developments in sociology, social psychology, and in the emerging field of computational social science [4].The main contribution of this paper is therefore of a theoretical nature, which we demonstrate in simulation. We have also implemented the theory in a simple tutoring system and in an assistive technology that is designed to assist persons with dementia. We report the results of an empirical survey and demonstrative study with human participants in the case of the tutoring system. The assistive technology is further described in [5]. Therein, a prompting system delivers audio-visual cues to a person using a variety of different affective “styles”. The mapping from non-verbal behaviours of the user to the “style” of prompt is defined by BayesAct alone.1.1. Model overviewBayesAct is a partially observable Markov decision process (POMDP, see Fig. 1(a) and Section 2.2) model of an agent interacting with an environment. The environment is modelled, as usual in a POMDP, with a set of states, X. A BayesAct agent has actions, A, available to it, and these actions change the state of the environment according to a stochastic transition function. The environment model (states) are not assumed to be observable (they are latent), but the agent has access to a set of observations (cid:2)x, from which it can infer the state of the environment by using Bayes’ rule and a stochastic observation function that relates states to observations. Finally, a utility function, R, describes the preferences of the agent on a numerical scale. The utility function can be used by a Bayesian (sequential) decision maker to optimize decisions (action choices) in the long term.BayesAct is modelling the case where the environment contains humans (or other BayesAct agents) who are partially responsible for the state dynamics. BayesAct therefore includes a latent user model as part of its state space (shown as factor Y in Fig. 1(a)). The user model describes the identity (see footnote 1) of the agent and of the human it is interacting with, and conditions (stochastically) the dynamics of the state.The identities are modelled as four concurrently evolving discrete-time non-linear dynamical systems over a three di-mensional continuous affective space. The three dimensions are: evaluation (how good/bad something is), potency (how strong/weak), and activity (how active/passive). The space is referred to as “EPA” space, and it has been found by soci-ologists to capture over 80% of the variance in affective meanings ascribed by humans across cultures and languages [6], and is in some sense “fundamental” to human emotion (see Section 2.1). It has also been used by other works in affective computing (where it is referred to as “PAD” space or Pleasure–Arousal–Dominance, see Section 2.3).BayesAct departs from other works on affective computing because it also includes the dynamics of identities in the EPA space. These dynamics are learned from datasets of human sentiments about events, measured during decades of research by sociologists in different cultures around the world, and forming part of a sociological theory called affect control theory (ACT) ([1]; see Section 2.1). As the EPA space, the dynamics are found to be culturally stable and consistent [7]. The dynamics form part of the transition function (for the identities, Y) in the POMDP (see Section 3.2). The dynamics relate an agent’s stable (through tim",
            {
                "entities": [
                    [
                        136,
                        248,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 76 (1995) 481-526 Artificial Intelligence A multivalued logic approach to integrating planning and control Alessandro Saffiotti *, Kurt Konolige, Enrique H. Ruspini ArtQicial Intelligence Centec SRI International, Menlo Park, CA 94025, USA Received 15 July 1993; revised 18 March 1994 Abstract Intelligent agents embedded in a dynamic, uncertain environment should incorporate capabilities for both planned and reactive behavior. Many current solutions to this dual need focus on one aspect, and treat the other one as secondary. We propose an approach for integrating planning and control based on behavior schemas, which link physical movements to abstract action descriptions. Behavior schemas describe behaviors of an agent, expressed as trajectories of control actions in an environment, and goals can be defined as predicates on these trajectories. Goals and behaviors can be combined to produce conjoint goals and complex controls. The ability of multivalued logics to represent graded preferences allows us to formulate tradeoffs in the combination. Two theorems relate complex controls to complex goals, and provide the key to using composition standard knowledge-based deliberation techniques to generate complex controllers. We report experiments in planning and execution on a mobile robot platform, Flakey. 1. Introduction Mobile increasingly sophisticated and autonomous, robots are becoming and we de- mand more intelligent behavior from them in complex environments. To meet these expectations, we must address a set of problems associated with real-world environ- ments: knowledge of the environment is partial and approximate; sensing is partial and noisy; the dynamics of the environment can be only partially predicted; and an agent’s hardware execution is not completely reliable. Classical AI planning approaches to these problems are inadequate, especially in providing realtime decision-making and control for the robot. On the other hand, purely reactive systems of control (e.g., [ 6,9,13,17] ) , * Corresponding author. Current address: IRIDIA, Universitk Libre de Braxelles, 50 av. Roosevelt CP 194/6, B-1050 Brussels, Belgium. E-mail: asaffio@ulb.ac.be. 0004-3702/95/.$09.50 SSDI 0004-3702(94)00088-3 @ 1995 Elsevier Science B.V. All rights reserved \f482 A. sajiotti et al./Artijicial Intelligence 76 (1995) 481-526 immediate while providing tally substitute not to carry an oil lantern downstairs response for planned behavior to unpredicted in solving complex environmental situations, cannot to- tasks (for example, by d&ding to look for a gas leak [ 131.) One solution and reactivity to the dual need for planning at the lower level, a complex controller achieves is to adopt a two-level model: at the upper level, a planner decides a sequence of abstract goals to be achieved, these based on the available knowledge; goals while dealing with the environmental ). The (e.g., satisfy strategic goals controller is “complex” because it must be able to simultaneously and low-level “innate” (e.g., going to the end of the corridor), coming job to produce physical goals (e.g., avoiding obstacles on the way). It is the controller’s movements the two main challenges are trading off between multiple goals, and bridging these goals to the highest degree possible. Thus, specified goals and physical movements. that satisfy to developing the gap between abstractly a complex controller from the planner [ 3,10,14,27,30] contingencies approach implements the problem A reasonable is to decompose to complex control [ 2,6 1. In the psychological type of physical movement one specific motor skill, and results into small in a the concept of activity directed at a particular goal has been given the name schema Arbib and for behavior of frogs. Each of these two task-level the frog; the combination the prey and away from by Lyons units of control, each of which certain coordinated and his colleagues have exploited robot control. For example, Arbib and House [ l] describe how schemas can account the prey-seeking goals is represented of the fields describes obstacles. Further extensions of this idea to robot control were investigated and Arbib field attracting or repelling of the frog towards and obstacle-avoidance as a potential to model brain functioning the schema concept the movements literature, [ 241, Overton [ 291, and Arkin Arbib’s motor schemas give an answer [ 31 under the name motor schema. to trading off among multiple goals, by pro- of complex control problems. They do not, however, symbolically above, of bridging the gap between approach viding a modular decomposition try to answer the second challenge specified goals and low-level physical movements. positional directly connects of our approach proach as a mathematically-motivated of multivalued l Behaviors to higher-level planning are very close logic. The advantages to those of Arbib’s. reconstruction to this formalization are described to behavior, based on the mathematics in terms of preferences can be composed mathematically In this paper, we develop a com- that and deliberation processes. The starting point In fact, one can view our ap- the tools of motor schemas, using of multivalued logic, are the following. among control actions. Hence, mul- as a means of trading off between form of coordination than the linear superposition used tiple behaviors their goals -a more powerful in motor schemas. l The concept of a goal as a predicate on the trajectory produced by the controller arises naturally, descriptions of action. and bridges the gap between physical movements and more abstract . Complex goals can be achieved by composing such as goal-regression their respective behaviors. Thus, stan- planning, can be used to generate dard deliberation procedures, complex controllers. \fA. Sajjiotti et al./Ariifcial Intelligence 76 (1995) 481-526 483 I. 1. Outline of the approach We develop the following the theory of behavior levels of abstraction: in a bottom-up fashion, describing movements at bodily movement + execution =+ goal satisfaction in a specific environment straighten elbow joint put arm out car window signal left turn This way of connecting movements, the work of Israel et al. [ 161. Formally, we use the framework of multivalued [ 23,321, which allows us to express partial preferences logical operators actions and achievements and to combine inspired by logics them by using has been [ 5,351. The basic units of control, control schemas, are descriptions of types of movements. capabilities, schemas define the camera the agent’s basic movement Control aiming to the right. Like classical controllers, states to effector commands. However, control schemas are less committal controllers over the space of all possible commands. The idea here is that different commands generate, are represented by predicates like making a step or control schemas relate internal than classical in that they map each state to a measure of preference, or desirabilityfunction, can functions to a greater or lesser extent, the same type of movement. Desirability in a multivalued We compose control schemas by combining logic. the corresponding desirability functions satisfy the desirability to functions of that will, under some conditions, a corridor, an obstacle avoidance logics. For instance, we can compose control schemas via the operators of multivalued obtain a movement both behaviors. Care must be taken, however, when the control schemas are conflicting, if a robot is facing an obstacle that is, they have no common preferences. For example, blocking corridor following schema with its own context of applicability: corridor following cannot be used, and its preferences contextual truth of these formulae combination, for control schemas. control schema may want to stop, while a schema may want to go forward. In general, we associate each control is blocked, plain should be disregarded. We express logic; and use the degrees of schemas. This weighted called context-depending blending, is the main coordination mechanism by using formulae of a multivalued the preferences of different e.g., when the corridor to weight conditions Control schemas operate with respect to the agent’s internal state, including its sensor rep- these two into the controller, of objects that contain action descriptions in the world, e.g., picking up block “A”. To reconcile readings. Planners, on the other hand, manipulate resentations levels of abstraction, we insert some parts of the planner’s model e.g., the expected size and position of the intended block. These object models, or de- scriptors, are then used as input to control schemas, “lifting” to the level of abstraction used by the planner. To maintain a closed-loop keep track of these objects during execution, by polling perceptual the descriptors anchored to their real-world with a set of object descriptors and a contextual condition, Behaviors play the role of situated actions: formed under which circumstances the effects of the controller response, we to keep together into a behavior. should be per- and with respect to which objects. Behaviors bridge routines correspondent. A control schema, they indicate which movement is packaged \f484 A. S@otti et al. /Art@cial Intelligence 76 (1995) 481-526 the gap between abstract action descriptions and physical control. They are inherently movement-oriented, since their control schema induces a preference on control actions; but they also incorporate elements of abstract action: the objects that the action operates on, and the preconditions for the success of the action. Our final step is to link the local notions of sensing and control embodied in behaviors to the global notion of satisfaction of goals. To do this, we adapt some ideas from dynamic logic to our multivalued framework. We define the meaning of a behavior to be the (fuzzy) set of all possible executions that it can produce, expressed as trajectorie",
            {
                "entities": [
                    [
                        75,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 156–192Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMagic Sets for disjunctive Datalog programs ✩Mario Alviano, Wolfgang Faber∗, Gianluigi Greco, Nicola LeoneDepartment of Mathematics, University of Calabria, 87036 Rende, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 13 January 2011Received in revised form 20 April 2012Accepted 24 April 2012Available online 26 April 2012Keywords:Logic programmingStable modelsMagic SetsAnswer set programmingData integrationIn this paper, a new technique for the optimization of (partially) bound queries overdisjunctive Datalog programs with stratified negation is presented. The technique exploitsthe propagation of query bindings and extends the Magic Set optimization technique(originally defined for non-disjunctive programs).An important feature of disjunctive Datalog programs is non-monotonicity, which callsfor non-deterministic implementations, such as backtracking search. A distinguishingcharacteristic of the new method is that the optimization can be exploited also duringthe non-deterministic phase. In particular, after some assumptions have been made duringthe computation, parts of the program may become irrelevant to a query under theseassumptions. This allows for dynamic pruning of the search space. In contrast, the effectof the previously defined Magic Set methods for disjunctive Datalog is limited to thedeterministic portion of the process. In this way, the potential performance gain by usingthe proposed method can be exponential, as could be observed empirically.The correctness of the method is established and proved in a formal way thanks to astrong relationship between Magic Sets and unfounded sets that has not been studied inthe literature before. This knowledge allows for extending the method and the correctnessproof also to programs with stratified negation in a natural way.The proposed method has been implemented in the DLV system and various experimentson synthetic as well as on real-world data have been conducted. The experimental resultson synthetic data confirm the utility of Magic Sets for disjunctive Datalog, and theyhighlight the computational gain that may be obtained by the new method with respectto the previously proposed Magic Set method for disjunctive Datalog programs. Furtherexperiments on data taken from a real-life application show the benefits of the MagicSet method within an application scenario that has received considerable attention inrecent years, the problem of answering user queries over possibly inconsistent databasesoriginating from integration of autonomous sources of information.© 2012 Elsevier B.V. All rights reserved.1. IntroductionDisjunctive Datalog is a language that has been proposed for modeling incomplete data [48]. Together with a lightversion of negation, in this paper stratified negation, this language can in fact express any query of the complexity class2 (i.e., NPNP) [22], under the stable model semantics. It turns out that disjunctive Datalog with stratified negation isΣ Pstrictly more expressive (unless the polynomial hierarchy collapses to its first level) than normal logic programming (i.e.,non-disjunctive Datalog with unstratified negation), as the latter can express “only” queries in NP. As shown in [22], the✩Preliminary portions of this paper appeared in the proceedings of the 20th International Conference on Logic Programming (ICLP’04).* Corresponding author.E-mail addresses: alviano@mat.unical.it (M. Alviano), faber@mat.unical.it (W. Faber), ggreco@mat.unical.it (G. Greco), leone@mat.unical.it (N. Leone).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.008\fM. Alviano et al. / Artificial Intelligence 187–188 (2012) 156–192157high expressive power of disjunctive Datalog has also some positive practical implications in terms of modeling knowledge,since many problems in NP can be represented more simply and naturally in stratified disjunctive Datalog than in normallogic programming. For this reason, it is not surprising that disjunctive Datalog has found several real-world applications[42,49,50,57,58], also encouraged by the availability of some efficient inference engines, such as DLV [43], GnT [37], Cmodels[46], or ClaspD [21]. As a matter of fact, these systems are continuously enhanced to support novel optimization strategies,enabling them to be effective over increasingly larger application domains. In this paper, we contribute to this developmentby providing a novel optimization technique, inspired by deductive database optimization techniques, in particular the MagicSet method [6,9,63].The goal of the original Magic Set method (defined for non-disjunctive Datalog programs) is to exploit the presenceof constants in a query for restricting the possible search space by considering only a subset of a hypothetical programinstantiation that is sufficient to answer the query in question. In order to do this, a top–down computation for answeringthe query is simulated in an abstract way. This top–down simulation is then encoded by means of rules, defining new MagicSet predicates. The extensions of these predicates (sets of ground atoms) will contain the tuples that are calculated duringa top–down computation. These predicates are inserted into the original program rules and can then be used by bottom–upcomputations to narrow the computation to what is needed for answering the query.Extending these ideas to disjunctive Datalog faces a major challenge: While non-disjunctive Datalog programs are deter-ministic, which in terms of the stable model semantics means that any non-disjunctive Datalog program has exactly onestable model, disjunctive Datalog programs are non-deterministic in the sense that they may have multiple stable models.Of course, the main goal is still isolating a subset of a hypothetical program instantiation, upon which the considered querywill be evaluated in an equivalent way. There are two basic possibilities how this non-determinism can be dealt with inthe context of Magic Sets: The first is to consider static Magic Sets, in the sense that the definition of the Magic Sets is stilldeterministic, and therefore the extension of the Magic Set predicates is equal in each stable model. This static behavior isautomatic for Magic Sets of non-disjunctive Datalog programs. The second possibility is to allow dynamic Magic Sets, whichalso introduce non-deterministic definitions of Magic Sets. This means that the extension of the Magic Set predicates maydiffer in various stable models, and thus can be viewed as being specialized for each stable model.While the nature of dynamic Magic Sets intuitively seems to be more fitting for disjunctive Datalog than static MagicSets, considering the architecture of modern reasoning systems for disjunctive Datalog substantiates this intuition: Thesesystems work in two phases, which may be considered as a deterministic (grounding) and a non-deterministic (modelsearch) part. The interface between these two is by means of a ground program, which is produced by the deterministicphase. Static Magic Sets will almost exclusively have an impact on the grounding phase, while dynamic Magic Sets alsohave the possibility to influence the model search phase. In particular, some assumptions made during the model searchmay render parts of the program irrelevant to the query, which may be captured by dynamic Magic Sets, but not (or onlyunder very specific circumstances) by static Magic Sets.In the literature, apart from our own work in [20], there is only one previous attempt for defining a Magic Set methodfor disjunctive Datalog, reported in [32,33], which will be referred to as Static Magic Sets (SMS) in this work. The basic ideaof SMS is that bindings need to be propagated not only from rule heads to rule bodies (as in traditional Magic Sets), but alsofrom one head predicate to other head predicates. In addition to producing definitions for the predicates defining Magic Sets,the method also introduces additional auxiliary predicates called collecting predicates. These collecting predicates howeverhave a peculiar effect: Their use keeps the Magic Sets static. Indeed, both magic and collecting predicates are guaranteedto have deterministic definitions, which implies that disjunctive Datalog systems can exploit the Magic Sets only during thegrounding phase. Most systems will actually produce a ground program which does contain neither magic nor collectingpredicates.In this article, we propose a dynamic Magic Set method for disjunctive Datalog with stratified negation under the stablemodel semantics, provide an implementation of it in the system dlv, and report on an extensive experimental evaluation.In more detail, the contributions are:(cid:2)(cid:2)(cid:2)(cid:2)We present a dynamic Magic Set method for disjunctive Datalog programs with stratified negation, referred to asDynamic Magic Sets (DMS). Different from the previously proposed static method SMS, existing systems can exploitthe information provided by the Magic Sets also during their non-deterministic model search phase. This featureallows for potentially exponential performance gains with respect to the previously proposed static method.We formally establish the correctness of DMS. In particular, we prove that the program obtained by the transfor-mation DMS is query-equivalent to the original program. This result holds for both brave and cautious reasoning.We highlight a strong relationship between Magic Sets and unfounded sets, which characterize stable models. Wecan show that the atoms which are relevant for answering a query are either true or form an unfounded set,which eventually allows us to prove the query-equivalence results.Our results hold for a disjunctive Datalog language with stratified negation under the stable model semantics. Inthe literat",
            {
                "entities": [
                    [
                        149,
                        192,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 295 (2021) 103458Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA review of possible effects of cognitive biases on interpretation of rule-based machine learning models ✩Tomáš Kliegr a,∗a Prague University of Economics and Business, Department of Information and Knowledge Engineering, Czech Republicb The Prague College of Psychosocial Studies, Czech Republicc Johannes Kepler University, Department of Computer Science, Linz, Austria, Štˇepán Bahník b, Johannes Fürnkranz ca r t i c l e i n f oa b s t r a c tArticle history:Received 3 October 2019Received in revised form 7 December 2020Accepted 20 January 2021Available online 26 January 2021Keywords:Cognitive biasCognitive illusionInterpretabilityMachine learningRule induction1. IntroductionWhile the interpretability of machine learning models is often equated with their mere syntactic comprehensibility, we think that interpretability goes beyond that, and that human interpretability should also be investigated from the point of view of cognitive science. The goal of this paper is to discuss to what extent cognitive biases may affect human understanding of interpretable machine learning models, in particular of logical rules discovered from data. Twenty cognitive biases are covered, as are possible debiasing techniques that can be adopted by designers of machine learning algorithms and software. Our review transfers results obtained in cognitive psychology to the domain of machine learning, aiming to bridge the current gap between these two areas. It needs to be followed by empirical studies specifically focused on the machine learning domain.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).This paper aims to investigate the possible effects of cognitive biases on human understanding of machine learning models, in particular inductively learned rules. We use the term “cognitive bias” as a representative for various cognitive phenomena that materialize themselves in the form of occasionally irrational reasoning patterns, which are thought to allow humans to make fast judgments and decisions.Their cumulative effect on human reasoning should not be underestimated as “cognitive biases seem reliable, systematic, and difficult to eliminate” [83]. The effect of some cognitive biases is more pronounced when people do not have well-articulated preferences [168], which is often the case in explorative data analysis.Previous works have analyzed the impact of cognitive biases on multiple types of human behavior and decision making. A specific example is the seminal book “Social cognition” by Kunda [90], which is concerned with the impact of cognitive biases on social interaction. Another, more recent work by Serfas [147] focused on the context of capital investment. Closer to the domain of machine learning, in their article “Psychology of Prediction”, Kahneman and Tversky [84] warned that cog-nitive biases can lead to violations of the Bayes theorem when people make fact-based predictions under uncertainty. These results directly relate to inductively learned rules, since these are associated with measures such as confidence and support expressing the (un)certainty of the prediction they make. Despite some early work [104,105] showing the importance of study of cognitive phenomena for rule induction and machine learning in general, there has been a paucity of follow-up ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail addresses: tomas.kliegr@vse.cz (T. Kliegr), bahniks@seznam.cz (Š. Bahník), juffi@faw.jku.at (J. Fürnkranz).https://doi.org/10.1016/j.artint.2021.1034580004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fT. Kliegr, Š. Bahník and J. FürnkranzArtificial Intelligence 295 (2021) 103458research. In previous work [53], we have evaluated a selection of cognitive biases in the very specific context of whether minimizing the complexity or length of a rule will also lead to increased interpretability, which is often taken for granted in machine learning research.In this paper, we attempt to systematically relate cognitive biases to the interpretation of machine learning results. We anchor our discussion on inductively learned rules, but note in passing that a deeper understanding of human cognitive bi-ases is important for all areas of combined human-machine decision making. We focus primarily on symbolic rules because they are generally considered to belong to the class of interpretable models, so that there is little general awareness that different ways of presenting or formulating them may have an important impact on the perceived trustworthiness, safety, or fairness of an AI system. In principle, our discussion also applies to rules that have been inferred by deduction, where, however, such concerns are maybe somewhat alleviated by the proved correctness of the resulting rules. To further our goal, we review twenty cognitive biases and judgmental heuristics whose misapplication can lead to biases that can distort the interpretation of inductively learned rules. The review is intended to help to answer questions such as: How do cognitive biases affect the human understanding of symbolic machine learning models? What could help as a “debiasing antidote”?This paper is organized as follows. Section 2 provides a brief review of related work published at the intersection of rule learning and psychology. Section 3 motivates our study by showing an example of a learnt rule and discussing sample cognitive biases that can affect its plausibility. Section 4 describes the criteria that we applied to select a subset of cognitive biases into our review, which eventually resulted in twenty biases. These biases and their respective effects and causes are covered in detail in Section 5. Section 6 provides a concise set of recommendations aimed at developers of rule learning algorithms and user interfaces. In Section 7 we state the limitations of our review and outline directions for future work. The conclusions summarize the contributions of the paper.2. Background and related workWe selected individual rules as learnt by many machine learning algorithms as the object of our study. Focusing on simple artefacts—individual rules—as opposed to entire models such as rule sets or rule lists allows a deeper, more focused analysis since a rule is a small self-contained item of knowledge. Making a small change in one rule, such as adding a new condition, allows to test the effect of an individual factor. In this section, we first motivate our work by putting it into the context of prior research on related topics. Then, we proceed by a brief introduction to inductive rule learning (Section 2.2) and a brief recapitulation of previous work in cognitive science on the subject of decision rules (Section 2.3). Finally, we introduce cognitive biases (Section 2.4) and rule plausibility (Section 2.5), which is a measure of rule comprehension.2.1. MotivationIn the following three paragraphs, we discuss our motivation for this review, and summarize why we think this work is relevant to the larger artificial intelligence community.Rules as interpretable models Given that neural networks and ensembles of decision trees are increasingly becoming the prevalent type of representation used in machine learning, it might be at first surprising that our review focuses almost exclusively on decision rules. The reason is that rules are widely used as a means for communicating explanations of a variety of machine learning approaches. In fact, quite some work has been devoted to explaining black-box models, such as neural networks, support vector machines and tree ensembles with interpretable surrogate models, such as rules and decision trees (for a survey on this line of work we refer, e.g., to [69]). As such a conversion typically also goes hand-in-hand with a corresponding reduction in the accuracy of the model, this approach has also been criticized [142], and the interest in directly learning rule-based models has recently renewed (see, e.g., [52,176,110,173]).Embedding cognitive biases to learning algorithms The applications of cognitive biases go beyond explaining existing machine learning models. For example, Taniguchi et al. [159] demonstrate how a cognitive bias can be embedded in a machine learn-ing algorithm, achieving superior performance on small datasets compared to commonly used machine learning algorithms with “generic” inductive bias.Paucity of research on cognitive biases in artificial intelligence Several recent position and review papers on explainability in Artificial Intelligence (xAI) recognize that cognitive biases play an important role in explainability research [106,126]. To our knowledge, the only systematic treatment of psychological phenomena applicable to machine learning is provided by the review of Miller [106], which focuses on reasons and thought processes that people apply during explanation selection, such as causality, abnormality and the use of counterfactuals. This authoritative review observes that there are currently no studies that look at cognitive biases in the context of selecting explanations. Because of the paucity of applicable research focusing on machine learning, the review of Miller [106]—like the present paper—takes the first step of applying influential psychological studies to explanation in the xAI context without accompanying experimental validation specific to machine learning. While Miller [106] summarizes the main reasoning processes that drive generation and understanding of explana-tions, our review focuses specifically on cognitive biases as psychological phenomena that can distort the interpretation of machine learning models if not prope",
            {
                "entities": [
                    [
                        135,
                        239,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 191–192 (2012) 20–41Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn truth-gaps, bipolar belief and the assertability of vague propositionsJonathan Lawry a,∗, Yongchuan Tang ba Intelligent Systems Laboratory, University of Bristol, Bristol BS8 1UB, UKb College of Computer Science, Zhejiang University, Hangzhou 310027, PR Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 September 2011Received in revised form 12 July 2012Accepted 18 July 2012Available online 1 August 2012Keywords:VaguenessTruth-gapsValuation pairsSemantic uncertaintyIntegrated uncertaintyBipolar belief measuresThis paper proposes an integrated approach to indeterminacy and epistemic uncertaintyin order to model an intelligent agent’s decision making about the assertability ofvague statements. Initially, valuation pairs are introduced as a model of truth-gaps forpropositional logic sentences. These take the form of lower and upper truth-valuationsrepresenting absolutely true and not absolutely false respectively. In particular, we considervaluation pairs based on supervaluationist principles and also on Kleene’s three-valuedlogic. The relationship between Kleene valuation pairs and supervaluation pairs is thenexplored in some detail with particular reference to a natural ordering on semanticprecision. In the second part of the paper we extend this approach by proposing bipolarbelief pairs as an integrated model combining epistemic uncertainty and indeterminacy.These comprise of lower and upper belief measures on propositional sentences, defined bya probability distribution on a finite set of possible valuation pairs. The properties of thesemeasures are investigated together with their relationship to different types of uncertaintymeasure. Finally, we apply bipolar belief measures in a preliminary decision theoretic studyso as to begin to understand how the use of vague expressions can help to mitigate therisk associated with making forecasts or promises. This then has potential applications tonatural language generation systems.© 2012 Elsevier B.V. All rights reserved.1. IntroductionA defining feature of vague concepts is that they admit borderline cases which neither definitely satisfy the conceptnor its negation. For example, there are some height values which would neither be definitely classified as being short nornot short. For propositions involving vague concepts this naturally results in truth-gaps. In other words, there are cases inwhich a proposition is neither absolutely true nor absolutely false. If Ethel’s height lies in a certain intermediate range then theproposition ‘Ethel is short’ may be inherently borderline. Such truth-gaps suggest that a non-Tarskian notion of truth may berequired to capture this aspect of vagueness even in a simple propositional framework. There has been a number of differentpossibilities proposed in the literature for this alternative model of truth including three-valued logics and supervaluations.In the sequel we will discuss and relate two different models of truth-gaps, supervaluationism and Kleene’s strong three-valued logic, in the context of a new framework for bipolar valuations. In particular, we will investigate propositionaltruth-models taking the form of a lower and an upper truth valuation on the sentences of the language. The underlyingidea is that, given such a valuation pair, the lower truth valuation represents the strong criterion of being absolutely true,while the upper valuation represents the weaker criterion of being not absolutely false. In this context, borderline statementsare those for which there is a difference between the lower and upper valuations (i.e. a truth-gap).* Corresponding author.E-mail addresses: j.lawry@bris.ac.uk (J. Lawry), tyongchuan@gmail.com (Y. Tang).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.07.004\fJ. Lawry, Y. Tang / Artificial Intelligence 191–192 (2012) 20–4121A different perspective on borderline cases relates to the notion of assertability. Here we take the view that conceptdefinitions are to a large extent determined by linguistic convention, and according to such conventions a statement may ormay not be assertable given a particular state of the world. Interestingly, a case can be made that assertability is inherentlybipolar, a phenomenon which manifests itself in a distinction between those propositions which convention would deemdefinitely assertable, and those which convention would not classify as incorrect, or perhaps even dishonest, to assert. Parikh[27] observes that:Certain sentences are assertible in the sense that we might ourselves assert them and other cases of sentences whichare non-assertible in the sense that we ourselves (and many others) would reproach someone who used them. But therewill also be the intermediate kind of sentences, where we might allow their use.For example, consider a witness in a court of law describing a suspect as being short. Depending on the actual heightof the suspect this statement may be deemed as clearly true or clearly false, in which latter case the witness could beaccused of perjury. However, there will also be an intermediate height range for which, while there may be doubt anddiffering opinions concerning the use of the description short, it would not be deemed as definitely inappropriate and hencethe witness would not be viewed as committing perjury. In other words, for certain height values of the suspect, it maybe acceptable to assert the statement ‘the suspect was short’, even though this statement would not be viewed as beingabsolutely true. Clearly there is a natural connection between this bipolar aspect of assertability and the idea of truth-gapsfor borderline cases outlined above. If a statement θ is absolutely true, a judgment which is of course dependent both onthe state of the world and on how linguistic convention defines the relevant concepts, then θ would be definitely assertable.On the other hand, provided that θ is not absolutely false then θ would be deemed acceptable to assert. The bipolarityof assertability would seem to be a special case of what Dubois and Prade [7] refer to as symmetric bivariate unipolarity,whereby judgments are made according to two distinct evaluations on unipolar scales, i.e. distinct evaluations about theassertability of a sentence and its negation. In the current context, we have a strong and a weak evaluation criterion wherethe former corresponds to definite assertability and the latter to acceptable assertability. As with many examples of thistype of bipolarity there is a natural duality between the two evaluation criteria in that a proposition is definitely assertableif and only if it is not acceptable to assert its negation.The adequate representation of epistemic uncertainty is of central importance in any effective model of belief. Typicallywe think of uncertainty as arising because of insufficient information about the state of the world. However, in the presenceof vagueness there may also be semantic uncertainty due to our having only partial knowledge of language conventions.For example, consider the proposition ‘Ethel is short’. Here an agent with certain knowledge of Ethel’s height may stillbe uncertain as to the truth of this proposition due to uncertainty about the conventions governing the definition of theconcept short. Such uncertainty may naturally arise from the distributed manner in which language is learnt across apopulation of communicating agents. Semantic uncertainty often occurs in conjunction with a lack of knowledge concerningthe underlying state of the world. In our example, the agent may also be uncertain as to the precise value of Ethel’s height.In the sequel then we propose an integrated model of semantic and stochastic uncertainty in the context of languageconventions which admit borderline cases. Here we view truth as a function of both the state of the world, e.g. Ethel’sheight, and language convention, e.g. the interpretation of the concept short in terms of height values. An integrated modelof epistemic uncertainty and truth-gaps can then take the form of a probability distribution on the cross product of the setof possible world states and the set of possible language conventions. Furthermore, if a convention maps each state of theworld to a valuation pair, then this naturally results in a probability distribution on possible valuation pairs. Given such adistribution we can immediately define lower and upper measures by evaluating the probabilities of those valuation pairsin which a given sentence is absolutely true and of those in which it is not absolutely false respectively. We refer to theselower and upper measures on the sentences of the language as a bipolar belief pair.We argue that valuation pairs are one of the most straight-forward representations of truth-gaps in natural languagepropositions. Hence, by taking a probability distribution over a set of possible valuation pairs for the language we generatea very natural integrated model of belief for propositions and sentences which involve vague concepts and about whichthere is inherent uncertainty. As such, the proposed framework provides an ideal platform from which we can begin toexplore issues concerning the utility of vagueness in communication. Certainly there are many potential applications ofsuch a study including in natural language generation [39], consensus modelling [24] and multi-agent dialogues [22]. In thispaper we shall focus mainly on the first of these application areas.A fundamental open problem in natural language generation is that of understanding why individuals often chooseto make vague assertions rather than semantically similar crisp (non-vague) ones. In particular, what are the practicaladvantages of such a decision from the perspective of an asserting agent? One approach is ",
            {
                "entities": [
                    [
                        147,
                        220,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 32–51Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal defense against election control by deleting voter groupsYue Yin a,∗a Key Lab of Intelligent Information Processing, ICT, CAS, University of Chinese Academy of Sciences, Beijing, Chinab Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United Statesc School of Computer Science and Engineering, Nanyang Technological University, Singapored Dept. of Computer Science, Ariel University, Israel, Yevgeniy Vorobeychik b,∗∗, Bo An c, Noam Hazon da r t i c l e i n f oa b s t r a c tArticle history:Received 5 June 2017Received in revised form 7 February 2018Accepted 15 February 2018Available online 21 February 2018Keywords:Election controlProtecting electionsSecurity gamesElection control encompasses attempts from an external agent to alter the structure of an election in order to change its outcome. This problem is both a fundamental theoretical problem in social choice, and a major practical concern for democratic institutions. Consequently, this issue has received considerable attention, particularly as it pertains to different voting rules. In contrast, the problem of how election control can be prevented or deterred has been largely ignored. We introduce the problem of optimal defense against election control, including destructive and constructive control, where manipulation is allowed at the granularity of groups of voters (e.g., voting locations) through a denial-of-service attack, and the defender allocates limited protection resources to prevent control. We consider plurality voting, and show that it is computationally hard to prevent both types of control, though destructive control itself can be performed in polynomial time. For defense against destructive control, we present a double-oracle framework for computing an optimal prevention strategy. We show that both defender and attacker best response subproblems are NP-complete, and develop exact mixed-integer linear programming approaches for solving these, as well as fast heuristic methods. We then extend this general approach to develop effective algorithmic solutions for defense against constructive control. Finally, we generalize the model and algorithmic approaches to consider uncertainty about voter preferences. Experiments conducted on both synthetic and real data demonstrate that the proposed computational framework can scale to realistic problem instances.1© 2018 Elsevier B.V. All rights reserved.* Principle corresponding author.** Corresponding author.E-mail addresses: melody1235813 @gmail .com (Y. Yin), yevgeniy.vorobeychik @vanderbilt .edu (Y. Vorobeychik), boan @ntu .edu .sg (B. An), noamh @ariel .ac .il(N. Hazon).1 A preliminary version of this work appeared in the Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI-16) [68]. There are several major advances in this article: (i) Whereas the earlier work considered only defense against destructive control, we extended the model to consider defense against constructive control as well. (ii) We analyzed the time complexity of preventing constructive control, and proposed a heuristic algorithm which computes the defense strategy to prevent constructive control in polynomial time (under certain circumstances). (iii) We proposed a mixed integer linear programming approach to compute a strong Stackelberg equilibrium of the game of defense against constructive control, and a more scalable approximation algorithm. (iv) We performed detailed experiments to evaluate the proposed algorithms.https://doi.org/10.1016/j.artint.2018.02.0010004-3702/© 2018 Elsevier B.V. All rights reserved.\fY. Yin et al. / Artificial Intelligence 259 (2018) 32–51331. IntroductionDemocratic institutions rely on the integrity of the voting process. A major threat to this integrity is the possibility that the process can be subverted by malicious parties for their own ends. Indeed, actual incidents of demonstrated and real attempts at vote manipulation and control bear out this concern. For example, the 2013 election in Pakistan was marred by a series of election-day bombings and shootings, resulting in over 150 people dead or injured, in an attempt to subvert the voting process [57], and the 2010 Sri Lanka election exhibited 84 major and 202 minor incidents of poll-related violence [7]. With the dawn of electronic and Internet voting, the additional threat of election control and manipulation through cyber attacks on electronic and Internet voting systems has emerged, with a number of documented demonstration attacks [3,62]. While recent allegations in the U.S. of deliberate cyber attacks aimed at influencing election outcomes have not been specifically against electronic voting systems [61], the collective evidence suggests that these are vulnerable, and may well become targets in the near future. Consequently, cyber security experts have repeatedly urged deployment of better auditing systems for electronic voting systems used in the U.S. elections, arguing that elections can be successfully manipulated through targeted attacks at voting machines and polling places, for example, in battleground states [56]. However, auditing all such systems is laborious and expensive, and few systematic methods for selective auditing have been deployed to date [33].We consider the general problem of protecting elections against malicious subversion, for example, through deployment of enhanced physical security at voting locations, or strategies for choosing which electronic voting machines or voting districts to audit. We model attacks on elections as targeting voter groups, such as voting machines or precincts, in order to change the identity of the election winner, a problem commonly known in prior literature as election control.The study of the computational complexity of election control was initiated by Bartholdi et al. [4], who considered the problem from the perspective of computational complexity. Since then it has received considerable attention in prior liter-ature (see Section 2). In this literature, a voting rule is viewed as resistant if control is NP-hard, and vulnerable otherwise. Many voting rules were shown to be resistant to several types of control, while plurality—which is widely used—can be controlled through voter deletion in polynomial time [4,27]. However, control is usually studied at the granularity of indi-vidual voters, and protection, when considered, is about designing voting rules which are NP-hard to control [19,28]. While these considerations are crucial if one is to understand vulnerability of elections, they are also limited in several respects. First, as the incidents of control described above attest, control can be exercised for groups of voters through a single at-tack, such as a denial-of-service attack on a voting station or a polling center (of which bombing is an extreme example). Second, NP-hardness of control is insufficient evidence for resistance: it is often possible to solve large instances of NP-hard problems in practice (see, e.g., [64] in the case of SAT). Resistance to election control in the broader sense, such as through allocation of limited protection resources to prevent attacks on specific voter groups, has, to our knowledge, neither been modeled nor investigated to date.To address these limitations, we consider the problem of optimally protecting elections against control. We model control as a denial-of-service (deletion) attack on a subset of voter groups, which may represent polling places or electronic vot-ing stations, with the goal of preventing the original winner from winning (destructive control) or making another candidate win (constructive control). We focus on plurality voting. Erdélyi et al. [18] show that constructive control by adding, deleting, and partitioning voters in this model is NP-hard, and recently Maushagen and Rothe [45] have shown NP-completeness of constructive and destructive control by partitioning voter groups for each non-trivial pure scoring rule. In contrast, we show that destructive control can be decided in polynomial time. We then consider the problem of defense against both types of control, modeling it as a Stackelberg game in which an outside party deploys limited protection resources to protect a collection of voter groups, allowing for randomization, and the adversary responds by attempting to subvert (control) the election. Specifically, defense against destructive control is modeled as a zero-sum game, while defense against constructive control is modeled as a nonzero-sum game. Protection resources may represent actual physical security for polling centers or voting stations, or resources devoted to auditing of specific electronic voting systems or electoral districts. We assume that the defender’s goal is to ensure that the same candidate wins with or without an election control attack. We show that the problem of choosing the minimal set of resources to guarantee that an election cannot be controlled is computation-ally hard for both destructive and constructive control. For general cases of defense against destructive control, we propose a double-oracle framework to compute an optimal protection. We prove that both the defender and attacker oracles are NP-complete when randomized strategies are allowed. On the positive side, we develop novel mixed-integer linear pro-gramming formulations for both oracles that enable us to compute a provably optimal solution for protecting elections from destructive control. Moreover, we develop heuristic defender and attacker oracles which significantly speed up computation in the framework. Our experiments demonstrate the effectiveness and scalability of our algorithmic approach.For defense against constructive control, we first introduce a heuristic algorithm which can compute the optimal defender",
            {
                "entities": [
                    [
                        134,
                        199,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1673–1699Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA linear approximation method for the Shapley valueShaheen S. Fatima a,∗, Michael Wooldridge b, Nicholas R. Jennings ca Department of Computer Science, Loughborough University, Loughborough LE11 3TU, UKb Department of Computer Science, University of Liverpool, Liverpool L69 3BX, UKc School of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 2 December 2007Received in revised form 22 May 2008Accepted 27 May 2008Available online 7 July 2008Keywords:Coalitional game theoryShapley valueApproximation methodThe Shapley value is a key solution concept for coalitional games in general and votinggames in particular. Its main advantage is that it provides a unique and fair solution, butits main drawback is the complexity of computing it (e.g., for voting games this complexityis #p-complete). However, given the importance of the Shapley value and voting games,a number of approximation methods have been developed to overcome this complexity.Among these, Owen’s multi-linear extension method is the most time efficient, being linearin the number of players. Now,in addition to speed, the other key criterion for anapproximation algorithm is its approximation error. On this dimension, the multi-linearextension method is less impressive. Against this background, this paper presents a newapproximation algorithm, based on randomization, for computing the Shapley value ofvoting games. This method has time complexity linear in the number of players, but has anapproximation error that is, on average, lower than Owen’s. In addition to this comparativestudy, we empirically evaluate the error for our method and show how the differentparameters of the voting game affect it. Specifically, we show the following effects. First, asthe number of players in a voting game increases, the average percentage error decreases.Second, as the quota increases, the average percentage error decreases. Third, the erroris different for players with different weights; players with weight closer to the meanweight have a lower error than those with weight further away. We then extend ourapproximation to the more general k-majority voting games and show that, for n players,the method has time complexity O(k2n) and the upper bound on its approximation erroris O(k2/n).√© 2008 Elsevier B.V. All rights reserved.1. IntroductionCoalition formation is a key form of interaction in multi-agent systems. It is the process of bringing together two ormore agents so as to achieve goals that individuals on their own cannot, or to achieve them more efficiently [2,18,22,23].Often, in such situations, there is more than one possible coalition and a player’s payoff depends on which one he joins.Given this, there are two key problems in this area. First, to ensure that none of the parties in a coalition has any incentiveto break away from it and join another coalition. Second, to determine how the players split the gains from cooperationbetween themselves.In this context, cooperative game theory deals with the problem of coalition formation and offers a number of solutionconcepts that possess desirable properties like stability, fair division of joint gains, and uniqueness [23,27]. Cooperative gametheory differs from its non-cooperative counterpart, in that, it allows the players to form binding agreements, and so there is* Corresponding author.E-mail addresses: S.S.Fatima@lboro.ac.uk (S.S. Fatima), M.J.Wooldridge@csc.liv.ac.uk (M. Wooldridge), nrj@ecs.soton.ac.uk (N.R. Jennings).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.05.003\f1674S.S. Fatima et al. / Artificial Intelligence 172 (2008) 1673–1699often an incentive to work together to receive the largest total payoff. Also, unlike non-cooperative game theory, cooperativegames are not specified through a description of the strategic environment (including the order of the players’ moves andthe set of actions at each move) and the resulting payoffs. Instead, cooperative game theory reduces this collection of datato the coalitional form, where each coalition is represented by a single real number. In short, there are no actions, moves, orindividual payoffs. The chief advantage of this approach, at least in multiple agent environments, is its practical usefulness.Specifically, it allows the abstraction of dealing with groups, rather than the individuals, and so much larger problems canbe handled.In more detail, cooperative game theory offers a number of solution concepts (such as the core, kernel, and Shap-ley value [23]) and a number of multi-agent systems researchers have used and extended these to facilitate automatedcoalition formation [26,31,33,34]. In so doing, a key challenge, from the multi-agent systems perspective, is to study thecomputational aspects of the solutions that game theory provides. This is important because many of these solutions arecomputationally hard to find and so of limited use in building actual systems. For example, computing the core is oftennp-complete [10], while computing the Shapley value is often #p-complete [12].To this end, this paper is concerned with efficiently computing the Shapley value [32]. In more detail, a player’s Shapleyvalue reflects how much that player contributes to a coalition—that is, how much value the agent adds to a coalition. Anagent who never adds much has a small Shapley value, while an agent that always makes a significant contribution has ahigh Shapley value. Now, the main advantage of the Shapley value, over solution concepts such as the core and the kernel, isthat it provides a solution that is both unique and fair. The former is desirable because it leaves no ambiguity; there is onlyone possible solution for a game and so the players know what they will gain from playing it. The latter property relates tohow the gains from cooperation are split between coalition members. In this case, a player’s Shapley value is proportionalto the contribution he makes as a member of a coalition; the greater the contribution, the higher its value. Thus, from aplayer’s perspective, both uniqueness and fairness are desirable properties.However, while uniqueness and fairness are both desirable properties, the Shapley value has one major drawback: formany coalitional games, it cannot be determined in polynomial time. One of the most common coalitional games is thevoting game (which is a means for the players to reach a consensus) and for this game, finding the Shapley value is #p-complete [12] (meaning that it is as hard as counting satisfying assignments of propositional logic formulae [25, p. 442]).Since #p-completeness subsumes np-completeness, this implies that computing the Shapley value for the voting game willbe intractable in general. In other words, it is practically infeasible to try to compute the exact Shapley value. However, thevoting game has practical relevance not only in the context of multi-agent systems [28,34], but also in human settings, as itis an important means of reaching consensus between multiple parties.Against this background, a number of approximation methods have been developed in order to overcome the problem ofcomputational hardness of finding the exact Shapley value (see Section 3 for details). These methods vary in terms of theirtime complexities. Among these, however, Owen’s multi-linear extension method [24] for a weighted voting game is one ofthe most time efficient, requiring time linear in the number of players. However, the accuracy with which it approximatesthe real value can be an issue in some cases (the method works well for those games for which all the players havesmall weights). To combat this, this paper presents a new approximation algorithm for computing the Shapley value for aweighted voting game. Our method is based on the technique of randomization and has time complexity that is linear inthe number of players, but has a lower approximation error than Owen’s method. In addition to this comparative study, weempirically evaluate the error for our method in a range of environments and show how the different parameters of thevoting game affect the error. We then extend our approximation method (for a weighted voting game) to the more generalk-majority voting games. For this, we show that for n players, the time complexity of our extended method is O(k2n) andthe upper bound on its approximation error is O(k2/n).√By undertaking this work, this paper makes a number of important contributions to the state of the art. First, and mostimportantly, it presents a new computationally efficient approximation algorithm for the Shapley value for weighted vot-ing games. The proposed method has linear time complexity, and is better than Owen’s method in terms of its error ofapproximation. Second, we extend our approximation method for a weighted voting game to the more general k-majorityvoting games. This is the first such method for this game. Finally, we provide a comprehensive error analysis of our approx-imation method. As mentioned earlier, we not only consider the worst case and obtain the upper bound on the error, butwe also consider a general case and show how the different parameters of the voting game affect this error. This analysisdistinguishes our work from the existing literature on approximation methods in that these have no error analysis1 (neitherfor the worst, nor the general case). Nevertheless, we believe such analysis is essential because it enables us to present acomplete picture of our method’s performance in terms of how far the approximation can be from the exact Shapley valueand how the different parameters of the voting game affect it.The remainder of the paper is organized as follows. Section 2 defines the Shapley value more formally and deta",
            {
                "entities": [
                    [
                        138,
                        189,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1079–1100Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintContractor programmingGilles Chabert a,∗, Luc Jaulin ba Ecole des Mines de Nantes LINA CNRS UMR 6241, 4, rue Alfred Kastler, 44300 Nantes, Franceb ENSIETA, 2, rue Fran cois Verny, 29806 Brest Cedex 9, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 22 February 2008Received in revised form 11 March 2009Accepted 15 March 2009Available online 18 March 2009Keywords:Constraint processingInterval methodsSolver designProgramming languagesThis paper describes a solver programming method, called contractor programming, thatcopes with two issues related to constraint processing over the reals. First, continuousconstraints involve an inevitable step of solver design. Existing softwares provide aninsufficient answer by restricting users to choose among a list of fixed strategies. Ourfirst contribution is to give more freedom in solver design by introducing programmingconcepts where only configuration parameters were previously available. Programmingconsists in applying operators (intersection, composition, etc.) on algorithms calledcontractors that are somehow similar to propagators.Second, many problems with real variables cannot be cast as the search for vectorssimultaneously satisfying the set of constraints, but a large variety of different outputsmay be demanded from a set of constraints (e.g., a paving with boxes inside and outside ofthe solution set). These outputs can actually be viewed as the result of different contractorsworking concurrently on the same search space, with a bisection procedure intervening incase of deadlock. Such algorithms (which are not strictly speaking solvers) will be madeeasy to build thanks to a new branch & prune system, called paver.Thus, this paper gives a way to deal harmoniously with a larger set of problems whilegiving a fine control on the solving mechanisms. The contractor formalism and the paversystem are the two contributions. The approach is motivated and justified through differentcases of study. An implementation of this framework named Quimper is also presented.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConstraint programming is a simple and efficient paradigm to handle a large class of combinatorial problems [40,10,44].In the presence of real-valued variables, constraint propagation algorithms combined with interval analysis [16,22,27,19,9]are also particularly well-suited, included for real-world applications (see, e.g., [33,21]). We shall refer to this interval variantof constraint programming as interval programming. Even then, interval programming has had only moderate success. In ouropinion, the reason is a lack of clear and unified formalism describing how solvers and derived programs are built. Thispaper is an attempt to fill this gap.We propose a framework that allows one to build a continuous solver with a few lines, in a high-level syntax. More thanjust another tuning language, a programming framework is proposed.1.1. MotivationThree reasons justify the introduction of a solver programming framework in presence of real variables.* Corresponding author.E-mail addresses: gilles.chabert@emn.fr (G. Chabert), luc.jaulin@ensieta.fr (L. Jaulin).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.002\f1080G. Chabert, L. Jaulin / Artificial Intelligence 173 (2009) 1079–11001. Constraint programming is a declarative paradigm which means that a programmer should spend most of the effort inmodeling conveniently the problem. This effort may involve breaking symmetries, introducing global or soft constraints,etc.. All these concepts are related to modeling and represent, by the way, very active fields of research. In theory, thesolver is a black box of which a programmer could ignore the details.Despite of this, there is always a need at some point to control the solver, as it is with all declarative languages (considerfor instance Prolog cuts that allow ruling out choices in the search). We can say that the overall efficiency one gets isthe combined result of efforts made on both aspects: modeling and solver control.With real variables, modeling languages are limited.1 Constraints can usually be nothing but equations which meansthat mathematics is de facto the ultimate modeling language.2 The consequence is that solver control becomes aninevitable step if one is to improve efficiency.2. Continuous solvers have a two-layered structure, namely interval analysis and constraint programming, The lower layerincludes interval arithmetics and interval numerical algorithms (e.g., an interval variant of the Newton iteration) withround-off considerations. The upper layer includes branch & prune algorithms for describing sets of reals defined byconstraints (or optimizing a criterion under constraints). Since these layers correspond to quite different scientific com-munities, there is a need more than ever for an interface between them. In concrete words, it would be useful to givea constraint programmer the ability to develop a continuous solver without digging into details of interval analysis.3. The last and possibly main point is related to the output of constraint solvers. With discrete domains, the output isalways the set of solutions (or a subset optimizing some criteria). But in continuous domains, there may be a largevariety of different outputs. First, one may look for a sub-paving (a set of boxes) encompassing the solutions and thisis precisely what most of the existing solvers provide. They act as root finders. Next, in case of a solution set witha non-null volume, several sub-pavings are expected, each satisfying a different property, basically: “may contain asolution”, “does contain a solution” or “contains only solutions”. Such solvers rather act as set describers. Actually, wewill see through the examples of Section 2 that the semantics behind the sub-pavings may completely change from oneproblem to the other.3 As we will show, neither a root finder nor a set describer is adapted for solving these problems. Ofcourse, ad-hoc solutions always exist, but the purpose is precisely to avoid a multiplicity of programs where a single onewould be enough. In practice, when people are facing a specific constraint problem that requires a specific algorithm,they have to reverse-engineer the code of an existing solver. Often, they redevelop it from scratch.1.2. ContributionWe propose a formalism and an algorithm, called paver.In the formalism, the different interval routines (evaluations, projections, existence tests, etc.) are all wrapped in thevery same object called contractor (see Section 3). Of course, the concept of contractor is not a novelty on its own. Our(first) contribution is to redefine various constraint programming techniques (propagation, shaving, parameter splitting, etc.)as operations over contractors that yield new contractors (Section 4). Syntactically, the contractor is then the unique atom,whence a certain simplicity. A solver can then be programed, rather than configured, by combining different contractors(examples are given in Sections 4.2, 4.3, 5.1 and 5.5).The paver algorithm is a generic solver. It takes a list of contractors, an initial box and follows a classical recursion: thecontractors are successively called on the current box until either it gets empty or no more contraction could be done. Inthe latter case, the box is bisected and contractors are called back again.The fact that different contractors work concurrently allows solving problems of quite different nature (see next section).This is our second contribution.Hence, contractor programming consists in two distinct steps: contractor design and paver design. The former refers to thedesign of the most possible efficient contractor for a given set (constraint) and shall be discussed in Section 4. The latterrefers to the selection of contractors that yield the desired output, regardless of efficiency.This framework is already supported by a real system named Quimper that will be introduced in Section 6.Thinking of contractor programming as an extension of constraint programming is valid to the extent that contractorshelp in modeling the output of a problem. But, fundamentally, there is not such an extension since constraints basically tellthe “what” whereas contractors tell the “how”.Note that branching will not be covered in this paper but one has to keep in mind that this part of the paver should becustomizable as well. Only plain bisection will be used in the examples (variable are selected with a round-robin heuristic).1 This limitation holds for numerical systems involving analytic expressions, which cover most of the mathematical models of physics problems. Butmodeling languages as such are not limited with real variables any more than with discrete ones (one may introduce table of constraints, piecewiseconstraints, etc.).2 There is still a notable exception: geometrical constraints. Geometry represents a semantic level above algebra; as an example, the “intersection of threespheres” can be introduced as a global constraints instead of three equivalent distance equations [1]. But, except in such cases, no improvement has to beexpected from the modeling side.3 We can say that no modeling language dedicated to the output exists so far, and this is another important distinction with discrete problems wherethis modeling aspect is not as ubiquitous (solvers using explanations are counter-examples).\fG. Chabert, L. Jaulin / Artificial Intelligence 173 (2009) 1079–110010811.3. Power of contractor programmingAs for every programming language, the power of contractor programming, i.e., the class of problems that can be solvedusing this paradigm would require the setting of computability theory to be described formally. Pavings obtained in ourframework are the results of algorithms that recur",
            {
                "entities": [
                    [
                        138,
                        160,
                        "TITLE"
                    ],
                    [
                        648,
                        670,
                        "TITLE"
                    ],
                    [
                        7741,
                        7763,
                        "TITLE"
                    ],
                    [
                        8192,
                        8214,
                        "TITLE"
                    ],
                    [
                        9691,
                        9713,
                        "TITLE"
                    ],
                    [
                        9761,
                        9783,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 95 ( 1997) 409-438 Artificial Intelligence Representing action: indeterminacy and ramifications Enrico Giunchiglia ‘, G. Neelakantan Kartha b, Vladimir Lifschitz ‘,* a DIST-University of Genoa, 16145 Genoa, Italy h i2 Technologies, 1603 L&l Freeway, Suite 780, Dallas, TX 75234, USA c University of Texas at Austin, Austin, 7X 78712, USA Abstract We define and study a high-level language for describing actions, more expressive than the action language A introduced by Gelfond and Lifschitz. The new language, A’R, allows us to describe actions with indirect effects (ramifications), nondeterministic actions, and actions that may be impossible to execute. It has symbols for nonpropositional fluents and for the fluents that are exempt from the commonsense law of inertia. Temporal projection problems specified using the language JR can be represented as nested abnormality theories based on the situation calculus. @ 1997 Elsevier Science B.V. Keywords: Action languages; Circumscription; Nested abnormality Ramification problem theories; Nondeterministic actions; 1. Introduction Mary jumped Common into the lake, then got out of the water and put her hat on. sense allows us to answer some questions about the outcome of this series of events. l Is Mary in the lake? Of course not. She just got out of it. l Does she have the hut on? Of course she does. She just put it on. l Is she wet? Of course she is. She just got out of the lake. These are examples of reasoning this reasoning has long been considered one of the central problems their effects. Formalizing about actions and form of commonsense * Corresponding author. Email: vl@cs.utexas.edu 0004-3702/97/$17.00 PIISOOO4-3702(97)00037-4 @ 1997 Elsevier Science B.V. All rights reserved \f410 E. Giunchiglia et al. /Art$cial Intelligence 95 (I 997) 409-438 of Artificial or branching used (classical details of the formalization etc.). logic, Intelligence. Existing approaches differ by their temporal ontologies time, time points or intervals, situations, events or histories), its nonmonotonic extensions, logic programming), (which objects are reified, how circumscription (linear by the logic and by other is applied, Properties of actions can be conveniently described in specialized “action the background in the examples of commonsense for instance, languages”, knowledge reasoning [7]. Consider, such as the language A from about the effects of actions into the lake (J), getting out of the above. Mary has performed lake (G) and putting her hat on (P). We are interested in the effect of each of these actions on whether or not Mary is in the lake (L). In the language A, the effects of the actions J and G on L can be described by the propositions that is involved three actions: jumping J causes L, G causes TL. is no need There incorporates assumed by default the “commonsense to remain the same. to specify that P has no effect on L, because law of inertia”: when an action is performed, the semantics of A things are The language d has been used as a tool for investigating actions. For instance, for describing between for in [ 251 and [ 26 J , as well as the use of the relationship in [ 111, the methods in classical logic developed in [ I], are described as translations from d, and each of the translations to be sound and complete relative that can be represented to the semantics of A. These theorems show in A, the three formalization methods actions several other techniques formalizing circumscription is found that, for the action domains results. produce equivalent In this paper, we introduce a new action language, AR, which is in several ways more expressive than A. ( 1) In AR, actions may have indirect effects, or rumijications. Consider, for instance, into the lake has on Mary being wet ( W). In d, it can the effect that jumping be described by the proposition J causes W We would prefer, however, effect on L. Any action Mary walks her boyfriend, can be described to treat the effect of J on W as a ramification of its true will make W true also: if into the lake by she will get wet all the same. This relationship between L and W into the lake, or is thrown that causes L to become into the lake, or crawls language by writing in the new action always L 3 W (2) Actions described in AR can be nondeterministic. into the lake then maybe she will lose her hat, or maybe not. In If Mary jumps while having her hat on (H) this indeterminacy AR, can be described by the proposition J possibly changes H if H. \fE. Giunchiglia et al. /Artijicial Intelligence 95 (1997) 409-438 411 (3) In AR, an action can be impossible cannot get out of the lake if she is already on the shore. We will write this as to execute in some states. For instance, Mary impossible G if 4 In fact, this will be treated as an abbreviation for the proposition G causes False if ?L. (4) The language AR has symbols for nonpropositionalj7uents. [ 241 is something in the lake), W (being wet) and H (having can be false or true depending of these fluents are the truth values of propositional formalization, we might wish to introduce elaborate representing Mary’s current symbol Location, Generally, a “fluent” that depends on the state of the world. For instance, L (being the hat on) are fluents, because each situation. The possible values logic, F and T. In a more fluent the nonpropositional location. AR allows us to write on the particular Location is Luke (5) instead of L, and to use other location symbols, such as Shore, Home or Library, in place of Lake. In AR, a fluent can be classified as noninertial, which makes law of inertia. For instance, the commonsense clouds later, no matter what Mary will be doing during noninertial. Noninertial (Section 4.3). from the that this will be still the case a minute this time. The fluent C is fluents are needed also for expressing explicit definitions (C), but there is no guarantee the sun may be now behind it exempt to the action the verification of several properties of the language The next two sections of the paper describe language A from the syntax and semantics of AR and relate [ 71. Our work on the “debugging” of the that in and of this language semantics of AR has involved to hold for action languages; can be naturally expected Section 4. In Section 5, we define the syntax and semantics of “initial conditions” “value propositions”. This allows us to express formally involving actions described problems of this kind can be expressed called nested abnormality connection with recent advances The relation of this paper to earlier work on action relegated temporal projection problems In Section 6 we show how temporal projection [22] in [ 3,6]. reasoning in Section 7. Proofs are in terms of the version of circumscription [ 181. Reductions of this kind are of special interest in the automation of circumscriptive these properties are discussed to the appendix. is discussed theories in AR. Preliminary reports on this work are published symbols the language AR0 described not include instead of possibly changes, out to be less satisfactory preliminary AR, and their use is restricted problems. publications in the first of these papers for nonpropositional fluents the construct it used (see Section 4.1) . Furthermore, in that “value propositions” as [ 141 and [ 81. d72 differs from in two ways. First, AT& did (see the end of Section 4.4). Second, turned this paper differs from both are not treated here as part of releases, whose semantics to the conceptually simpler case of temporal projection \f412 E. Giunclzigliu et al. /Artificial Intelligence 95 (1997) 409-438 2. Syntax To be precise, AR is not a single language, but rather a family of languages. A particular language in this group set of symbols is characterized by that are called Jluent names, l a nonempty l a function, associating with every fluent name F a nonempty set RngF of symbols that is called the range of F, l a subset of fluent names l a nonempty set of symbols that are called inertial, that are called action names. 2.1. Formulas, propositions and action descriptions An atomic formula is an expression of the form (F is V) where F is a fluent name, and V E RngF. A formula atomic formulas. is a propositional combination of There are three types of propositions in AR-constraints, effect propositions. A constraint sitions, and indeterminate always C determinate effect propo- is an expression of the form (1) where C is a formula. A determinate effect proposition is an expression of the form A causes C if P (2) where A is an action name, and C, P are formulas. An indeterminate is an expression of the form effect proposition A possibly changes F if P (3) where A is an action name, F an inertial fluent name, and P a formula (“precondition”). An action description is a set of propositions. 2.2. Notational conventions In formulas, we will omit some parentheses, logic. We will formula by True, and TTrue by False. A determinate as customary in classical denote some fixed tautological effect proposition (2) will be written as A causes C if P is True, and as impossible A if P if C is False. An indeterminate effect proposition (3) will be written as A possibly changes F \fE. Giunchiglia et al. /Art@d Intelligence 95 (I 997) 409-438 413 if its precondition P is True. For any action name A and formula C, A initiates C stands for the pair of propositions A causes C, impossible A if C. A fluent name F is propositional if RngF = {F,T}. If F is a propositional fluent name, we will abbreviate the atomic formula F is T by F, and the atomic formula F is F by 7. Using these notational conventions, we can formalize the example from the Introduc- tion as follows: always L 3 W; J initiates L, J possibly changes H if H, G initiates -L, P initiates H. (4) Here L, W, H are inertial propositional lhtent names, and J, G, P are action names. 3. Semantics The meaning of an action description D is represented by the corresponding function, Re",
            {
                "entities": [
                    [
                        76,
                        128,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1290–1307Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDemocratic approximation of lexicographic preference modelsFusun Yaman a,∗, Thomas J. Walsh b, Michael L. Littman c, Marie desJardins da BBN Technologies, 10 Moulton St., Cambridge, MA 02138, USAb University of Arizona, Department of Computer Science, Tucson, AZ 85721, USAc Rutgers University, Department of Computer Science, Piscataway, NJ 08854, USAd University of Maryland Baltimore County, Computer Science and Electrical Engineering Department, Baltimore, MD 21250, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 27 February 2009Received in revised form 5 August 2010Accepted 5 August 2010Available online 2 December 2010Keywords:Lexicographic modelsPreference learningBayesian methods1. IntroductionLexicographic preference models (LPMs) are an intuitive representation that corresponds tomany real-world preferences exhibited by human decision makers. Previous algorithms forlearning LPMs produce a “best guess” LPM that is consistent with the observations. Ourapproach is more democratic: we do not commit to a single LPM. Instead, we approximatethe target using the votes of a collection of consistent LPMs. We present two variations ofthis method—variable voting and model voting—and empirically show that these democraticalgorithms outperform the existing methods. Versions of these democratic algorithms arepresented in both the case where the preferred values of attributes are known and the casewhere they are unknown. We also introduce an intuitive yet powerful form of backgroundknowledge to prune some of the possible LPMs. We demonstrate how this backgroundknowledge can be incorporated into variable and model voting and show that doing soimproves performance significantly, especially when the number of observations is small.© 2010 Elsevier B.V. All rights reserved.Lexicographic preference models (LPMs) are one of the simplest yet most intuitive preference representations. An LPMdefines an order of importance on the variables that describe the objects in a domain and uses this order to make preferencedecisions. For example, the meal preference of a vegetarian with a weak stomach could be represented by an LPM such thata vegetarian dish is always preferred over a non-vegetarian dish, and among vegetarian or non-vegetarian items, mild dishesare preferred to spicy ones.Despite the simplicity of lexicographic LPMs, several studies on human decision making [4,20,9] experimentally demon-strate that humans often make decisions using lexicographic reasoning instead of mathematically more sophisticated meth-ods such as linear additive value maximization [6].Previous work on learning LPMs from a set of preference observations has been limited to autocratic approaches: oneof many possible consistent LPMs is picked heuristically and used for future decisions. However, it is highly likely thatautocratic methods will produce poor approximations of the target when there are few observations.In this paper, we present a democratic approach to LPM learning, which does not commit to a single LPM. Instead,we approximate a target preference using the votes of a collection of consistent LPMs. We present two variations of thismethod: variable voting and model voting. Variable voting operates at the variable level and samples the consistent LPMsimplicitly. The learning algorithm based on variable voting learns a weak order on the variables, such that each linearizationcorresponds to an LPM that is consistent with the observations. Model voting explicitly samples the consistent LPMs and* Corresponding author.E-mail addresses: fusun@bbn.com (F. Yaman), twalsh@cs.arizona.edu (T.J. Walsh), mlittman@cs.rutgers.edu (M.L. Littman), mariedj@cs.umbc.edu(M. desJardins).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.012\fF. Yaman et al. / Artificial Intelligence 175 (2011) 1290–13071291employs a weighted vote, where the weights are computed using Bayesian priors. The additional complexity of voting-basedalgorithms (compared to autocratic methods) is tolerable: both algorithms have low-order polynomial time complexity. Ourexperiments show that these democratic algorithms outperform both the average and worst-case performance of the state-of-the-art autocratic algorithm.We also investigate the effect of imperfect data on the learning algorithms. We consider two kinds of imperfections:faulty observations (noise) and hidden ties (ties that are broken arbitrarily). Our empirical evaluation demonstrates that all ofthe algorithms we consider are robust in the presence of hidden ties. However, even a small number of faulty observationssignificantly reduce the performance of the voting algorithms. On the other hand, the greedy algorithm is resilient: that is,the performance decline is proportional to the amount of noise in the data. We take a lesson from this, and adapting thevoting methods to consider the amount of noise in an environment, we empirically show the resulting heuristic is on parwith the greedy approach in the case of noisy observations.To further improve the performance of the learning algorithms when the number of observations is small, we introducean intuitive yet powerful form of background knowledge. The background knowledge defines equivalence classes on thevariables, indicating the most important set of variables, the second most important set, and so on. This representationpermits a user or designer to provide partial information about an LPM (or a class of LPMs) that can be used by the learnerto reduce the search space. We demonstrate how this background knowledge can be used with variable and model votingand show that doing so improves performance significantly, especially when the number of observations is small.In the rest of the paper, we give some background on LPMs (Section 2), then describe our voting-based methods (Sec-tion 3). After introducing these methods in the case where the preferred values of all attributes are known, we presentextensions of these algorithms to the case where preferred values are not known a priori (Section 4). We then introduce ourbackground knowledge representation, show how we can generalize the voting methods to exploit this background knowl-edge (Section 5), present an approach for handling noisy data (Section 6), and present experimental results of this work(Section 7). Finally, we present related work (Section 8) and discuss our future work and conclusions (Section 9).2. Lexicographic preference modelsIn this section, we briefly introduce the lexicographic preference model (LPM) and summarize previous results on learn-ing LPMs. In this work, we only consider binary variables whose domain is {0, 1}.1 For clarity in the introduction of ouralgorithms, we assume for now that the preferred value of each variable is known. This assumption will be removed inSection 4. Without loss of generality, we will assume that 1 is always preferred to 0.Given a set of variables, X = { X1, . . . , Xn}, an object A over X is a vector of the form [x1, . . . , xn]. We use the notationA( Xi) to refer the value of Xi in the object A. A lexicographic preference model L on X is a total order on a subset R of X .We denote this total order with (cid:2)L. Any variable in R is relevant with respect to L; similarly, any variable in I = X − Ris irrelevant with respect to L. If a variable A appears earlier in this total order than B ( A < B), then A is said to be moreimportant or to have a smaller rank than B.If A and B are two objects, then the preferred object given L is determined as follows:• Find the smallest (most important) variable X∗in (cid:2)L such that X∗has different values in A and B. The object that hasthe value 1 for Xis the most preferred.∗• If all relevant variables in L have the same value in A and B, then the objects are equally preferred (a tie).Example 1. Suppose X1 < X2 < X3 is the total order defined by an LPM L, and consider objects A = [1, 0, 1, 1], B =[0, 1, 0, 0], C = [0, 0, 1, 1], and D = [0, 0, 1, 0]. A is preferred over B because A( X1) = 1, and X1 is the most importantvariable in L. B is preferred over C because B( X2) = 1 and both objects have the same value for X1. Finally, C and D areequally preferred because they have the same values for the relevant variables.An observation o = ( A, B) is an ordered pair of objects, connoting that A is preferred to B. In many practical applications,however, preference observations are gathered from demonstration of an expert who breaks ties arbitrarily. That is, whenpresented with a situation in which a decision or choice must be made, if the expert judges the two alternatives to beequally good, the expert will in fact be indifferent, and will therefore be equally likely to choose either alternative. Thus, forsome observations, A and B may actually be tied in the preference order, although we cannot determine this directly fromthe observations. Therefore, an LPM L is said to be consistent with an observation ( A, B) iff L implies that A is preferredto B or that A and B are equally preferred.The problem of learning an LPM is defined as follows. Given a set of observations, find an LPM L that is consistent withthe observations. Previous work on learning LPMs was limited to the case where all variables are relevant. This assumptionentails that, in every observation ( A, B), A is strictly preferred to B, since ties can only happen when there are irrelevantattributes.1 The representation can easily be generalized to monotonic preferences with ordinal variables, such that 1 corresponds to a preference on the values inincreasing order, and 0 to a decreasing order, as shown by Yaman and desJardins [21] for conditional preference networks (CP-nets).\f1292F. Yaman et al. / Artificial Intelligence 175 (2011) 1290–1307Algorithm 1 greedyPermutationRequire: A set of variable",
            {
                "entities": [
                    [
                        138,
                        197,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 84 (1996) 113-150 Artificial Intelligence Default reasoning using classical logic * Rachel Ben-Eliyahu ay*, Rina Dechter b~l a Matirematics and Computer Science Department, Ben-Gurion University of the Negev, Beer-Sheva 84105. Israel b Information & Computer Science, University of Calqornia, Irvine, CA 92717. USA Received December 1993; revised May 1995 Abstract In this paper we show how propositional default theories can be characterized by classical propo- sitional theories: for each finite default theory, we show a classical propositional theory such that there is a one-to-one correspondence between models for the latter and extensions of the former. This means that computing extensions and answering queries about coherence, set-membership and set-entailment are reducible to propositional satisfiability. The general transformation is expo- superset of network default theories and nential but tractable for a subset which we call Z-DT-a default theories. Consequently, coherence and set-membership for the class 2-DT disjunction-free is NP-complete and set-entailment is co-NP-complete. This work paves the way for the application of decades of research on efficient algorithms for the satisfiability problem to default reasoning. For example, since propositional satisfiability can be regarded as a constraint satisfaction problem (CSP), this work enables us to use CSP techniques for default reasoning. To illustrate this point we use the taxonomy of tractable CSPs to identify new tractable subsets for Reiter’s default logic. Our procedures allow also for computing stable models of extended logic programs. 1. Introduction in artificial Researchers it widely and have used areas, including diagnostic intelligence for declarative reasoning have found Reiter’s default logic [ 291 2 attractive in a variety of representations of problems [ 301, theory of speech acts [ 281, natural language *Most of this work was done while the first author was a graduate student at the Cognitive Systems Laboratory, Computer Science Department, University of California, Los Angeles, CA, USA. * Corresponding author. E-mail: rachelQcs.bgu.ac.il. ’ E-mail: dechter@ics.uci.edu. * In this paper, when we mention “default logic” we mean “Reiter’s default logic”. OOO4-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00095-X \fI14 R. Ben-Eliyuhu. R. Dechter/Ariijiciul Intelligence 84 (1996) Il3-150 concept of extension shown, there Recent research default propositional [ 251, and inheritance processing it has been shown default” can be embedded very naturally for logic programs semantics However, while knowledge [ 4,161. can be specified hierarchies with exceptions [ II]. Most importantly, that logic programs with classical negation and with “negation by in default logic, and thus default logic provides in a natural way in default as presented by Reiter is quite that computes extensions is no procedure tricky. Moreover, of an arbitrary default indicates that the complexity of answering basic queries on propositional the logic, as Reiter has theory. [ 17,34]), and that even for very simple logic is very high (X;- or II;-complete theories, In this paper we show how we can confront the problem default is NP-hard [ 19,331. into classical propositional theories a class of theories for which we have effective ways of computing set-membership logic. default and to the identification theories. Our approach and set-entailment, these difficulties by translating leads to the identification default of extensions and testing of new tractable subsets for functions We introduce rather than to logical symbols-and the concept of nzeta-interpretations-truth that assign truth val- is ues to clauses the properties of these models enables us to a model for a given default into a classical proposi- show that any finite propositional tional theory such that there is a one-to-one between models of the clas- sical theory and extensions of the default theory. Queries about coherence and entailment logic. in default logic to in propositional in default define when such a truth function default theory can be compiled is that it reduces computation to queries about satisfiability logic are thus reducible theory. Studying correspondence The main advantage of this mapping satisfiability, algorithm a deterministic there is a significant introduces default for computing theory, while previous algorithms 3 (e.g. propositional our method propositional an extension only for certain subsets of all default theories. Our translation in general. However, (2-DT), for which our translation theories-the rzetwork default the class of disjunction-free forbidden. embed extended former. Therefore, for computing a task that has already been explored extensively. Moreover, extensions of any finite ) produce is exponential theories the so-called [ 1 l] and are theories can logic programs; answer sets of the latter coincide with extensions of the for finding extensions default [ 161 that the class of disjunction-free logic version of inheritance in which sublanguage which we call 2-default is tractable. The class 2-DT formulas with disjunction logic programs as well. for 2-DT are applicable techniques developed It has been shown [ 11,18,19,33] networks theories, includes default default As a by-product of our translation, we learn that the coherence problem and the for the class 2-DT is NP-complete and that the set-entailment for the class 2-DT is co-NP-complete. 4 The translation additional NP-complete subclasses. Note that in general also provides a general these problem set-membership problem framework problems are Xc- or II;-hard. for identifying 3 Of course there also exists the brute-force algorithm, according clauses, whether or not it is an extension of the theory. Though finite number of such subsets, 4 See Section 5. I for details. this brute-force algorithm is extremely expensive. to which you check for every subset of to consider a it is clear that it is sufficient \fR. Ben-Eliyahu, R. Dechter/Arti&ial Intelligence 84 (1996) 113-150 115 Once a default theory is expressed as a propositional theory, we may apply many existing heuristics and algorithms on propositional satisfiability. In particular, we show how topological considerations can be used to identify new tractable subsets, and how constraint satisfaction techniques can be effectively applied to tasks of default reason- ing. The rest of the introduction is organized as follows: in the following section we discuss the connections between default logic, logic programming, and inheritance networks, to demonstrate that the work presented here has a direct influence on computational issues in these fields as well. In Section 1.2 we will then give an introductory discussion about the basic ideas and contributions of this paper and explain its organization. 1.1. Default logic, inheritance networks, and logic programs 1.1.1. Reiter’s default logic We begin with a brief introduction to Reiter’s default logic [ 291. Let C be a first-order language over a countable alphabet. A default theory is a pair A = (D, W), where D is a set of defaults and W is a set of closed well-formed formulas (wffs) in C. A default is a rule of the form cr:p1,...,p, Y ’ where Q,PI,...,& and y are formulas in C. 5 (1) A default IS can also be written using the syntax LY : pi,. (Y is called the prerequisite (notation: pre( 6) ) ; PI, . . . , P,, are the justifications (notation: just( 8)); and y is the conclusion (notation: concl( 6)). The intuition behind a default can be stated as “if I believe cy and I have no reason to believe that one of the pi is false, then I can believe y”. A default (Y : P/y is normal if y = /3. A default is semi-normal if it is in the form LY : /I A y/y. A default theory is closed if all the first-order formulas in D and W are closed. . . , &/y. The set of defaults D induces an extension on W. Intuitively, an extension is a maximal set of formulas that is deducible from W using the defaults in D. Let E* denote the logical closure of E in C. We use the following definition of an extension: Definition 1.1 (Extension and let (D, W) be a closed default theory. Define [ 29, Theorem 2.11). Let E G C be a set of closed wffs, (1) Eo= W, and (2) fori~O,Ei+l=Ei”U{yIa:pl,...,P,/yEDwhereaEEiand-pl,..., -Pn $ El. E is an extension for A iff for some ordering E = Uz Ei. (Note the appearance of E in the formula for Ei+l.) Many tasks on a default theory A may be formulated using one of the following queries: 5 Empty justifications are equivalent to the identically true proposition true [ 3 11. \f116 R. Ben-Eliyahu. R. Dechter/Artijicial Intelligence 84 (1996) 113-150 l Coherence: Does A have an extension? a Set-membership: Given a set of clauses T, is T contained l Set-entailment: Given a set of clauses T, is T contained In Section 6 we will also consider a special case of set-membership which we call in every extension of A? in some extension of A? If so, find one. clause-membership, where the set T is a single clause. In this paper we focus on propositional default logic. It has been shown is X;-complete theories for this class and remains so even [ 17,341. Membership and entailment that the if restricted for the class of default theories were shown even if T is restricted to contain a single to be X;-complete literal [ 17,341. and @-complete, In this paper we for which these tasks are easier. 6 that the subclass 2-DT of all default networks and logic programs. The following theories is powerful enough two subsections default problem coherence to semi-normal normal propositional respectively, will show subclasses It has been shown to embed both inheritance elaborate on this. 1.1.2. Inheritance networks and network default theories An inheritance network is a knowledge representation thus allowing scheme in which the knowledge representational hierarchy, in a taxonomic is organized share a group of co",
            {
                "entities": [
                    [
                        66,
                        105,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 248 (2017) 123–157Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFrom model checking to equilibrium checking: Reactive modules for rational verificationJulian Gutierrez, Paul Harrenstein, Michael Wooldridge∗Department of Computer Science, University of Oxford, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 2 July 2015Received in revised form 2 April 2017Accepted 8 April 2017Available online 12 April 2017Keywords:Complexity of equilibriaReactive modulesTemporal logicModel checking is the best-known and most successful approach to formally verifying that systems satisfy specifications, expressed as temporal logic formulae. In this article, we develop the theory of equilibrium checking, a related but distinct problem. Equilibrium checking is relevant for multi-agent systems in which system components (agents) are assumed to be acting rationally in pursuit of delegated goals, and is concerned with understanding what temporal properties hold of such systems under the assumption that agents select strategies in equilibrium. The formal framework we use to study this problem assumes agents are modelled using Reactive Modules, a system modelling language that is used in a range of practical model checking systems. Each agent (or player) in a Reactive Modules game is specified as a nondeterministic guarded command program, and each player’s goal is specified with a temporal logic formula that the player desires to see satisfied. A strategy for a player in a Reactive Modules game defines how that player selects enabled guarded commands for execution over successive rounds of the game. For this general setting, we investigate games in which players have goals specified in Linear Temporal Logic (in which case it is assumed that players choose deterministic strategies) and in Computation Tree Logic (in which case players select nondeterministic strategies). For each of these cases, after formally defining the game setting, we characterise the complexity of a range of problems relating to Nash equilibria (e.g., the computation or the verification of existence of a Nash equilibrium or checking whether a given temporal formula is satisfied on some Nash equilibrium). We then go on to show how the model we present can be used to encode, for example, games in which the choices available to players are specified using STRIPS planning operators.© 2017 Elsevier B.V. All rights reserved.1. IntroductionOur main interest in this paper is in the analysis of concurrent systems composed of multiple non-deterministic computer programs, in which at run-time each program resolves its non-determinism rationally and strategically in pursuit of an individual goal, specified as a formula of temporal logic. Since the programs are assumed to be acting strategically, game theory provides a natural collection of analytical concepts for such systems [53]. If we apply game-theoretic analysis to such systems, then the main questions to be answered about such systems are not just “what computations might the system produce?”, but rather, “what computations might the system produce if the constituent programs act rationally?” If we interpret acting rationally to mean choosing strategies (for resolving non-determinism) that are in Nash equilibrium, then * Corresponding author.E-mail address: mjw@cs.ox.ac.uk (M. Wooldridge).http://dx.doi.org/10.1016/j.artint.2017.04.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f124J. Gutierrez et al. / Artificial Intelligence 248 (2017) 123–157this question amounts to asking “which of the possible computations of the system will be produced in equilibrium?” Further, if we use temporal logic as the language for expressing properties of our multi-agent and concurrent system (as is standard in the computer aided verification community [20]), then we can also interpret this question as “which temporal logic formulae are satisfied by computations arising from the selection of strategies in equilibrium?” We refer to this general problem as equilibrium checking [75].Related questions have previously been considered within computer science and artificial intelligence – see e.g., [14,23,29,30,51,13,8]. However, a common feature in this previous work is that the computational models used as the basis for analysis are highly abstract, and in particular are not directly based on real-world programming models or languages. For example, in [29] the authors define and investigate iterated Boolean games (iBG), a generalisation of Boolean games [36,37], in which each agent exercises unique control over a set of Boolean variables, and system execution proceeds in an infinite sequence of rounds, with each agent selecting a valuation for the variables under their control in each round. Each player has a goal, specified as a formula of Linear Temporal Logic (LTL), which it desires to see achieved. The iterated Boolean games model is simple and natural, and provides a compelling framework with which to pose questions relating to strategic multi-agent interaction in settings where agents have goals specified as logical formulae. However, this model is arguably rather abstract, and is some distance from realistic programming languages and system modelling languages; we discuss such work in more detail in the related work section towards the end of this article.In brief, our main aim is to study a framework without these limitations. Specifically, we study game-like systems in which players are specified using (a subset of) the Reactive Modules language [2], which is widely used as a system modelling language in practical model checking systems such as mocha [4] and Prism [43]. Reactive Modules is intended to support the succinct, high-level specification of concurrent and multi-agent systems. As we will see, Reactive Modulescan readily be used to encode other frameworks for modelling multi-agent systems (such as multi-agent STRIPS planning systems [10]).The remainder of the article is structured as follows:• We begin in the following section by motivating our work in detail, in particular by arguing that the classical notion of system correctness is of limited value in multi-agent systems, and introducing the idea of equilibrium checking as representing a more appropriate framework through which to understand the behaviour of such systems.• We then survey the logics LTL and CTL, and their semantic basis on Kripke structures, present srml – a sublanguage ofReactive Modules that we use throughout the article – and then develop a formal semantics for it.• We then introduce Reactive Modules games, in which the structure of the game (what we call the “arena”) is specified using Reactive Modules, and the preferences of players are specified by associating a temporal (LTL or CTL) goal formula with each player, which defines runs or computation trees that would satisfy the player’s goal.• We then investigate the complexity of various game-theoretic questions in Reactive Modules games, for both the LTL and the CTL settings, and conclude by discussing the complexity and expressiveness of our new framework against the most relevant related work. Table 2 at the end of the paper summarises our findings.• Finally, to demonstrate the wider applicability of our framework, we show how it can be used to capture propositional STRIPS games (cf. [22,12,25]), such as the MA-STRIPS model of Brafman and Domshlak [10].Although largely self-contained, our technical presentation is necessarily terse, and readers may find it useful to have some familiarity with temporal logics [20,18], model checking [16], complexity theory [54], and basic concepts of non-cooperative game theory [53].2. MotivationOur aim in this section is to motivate and introduce the idea of equilibrium checking as a multi-agent systems counter-part to the standard notion of verification and model checking. (Many readers will be familiar with much of this material – we beg their indulgence so that we can tell the story in its entirety.)Correctness and formal verification The correctness problem has been one of the most widely studied problems in computer science over the past fifty years, and remains a topic of fundamental concern to the present day [9]. Broadly speaking, the correctness problem is concerned with checking that computer systems behave as their designer intends. Probably the most important problem studied within the correctness domain is that of formal verification. Formal verification is the problem of checking that a given computer program or system P is correct with respect to a given formal (i.e., mathematical) specification ϕ. We understand ϕ as a description of system behaviours that the designer judges to be acceptable – a program that guarantees to generate a behaviour as described in ϕ is deemed to correctly implement the specification ϕ.A key insight, due to Amir Pnueli, is that temporal logic can be a useful language with which to express formal specifica-tions of system behaviour [56]. Pnueli proposed the use of Linear Temporal Logic (LTL) for expressing desirable properties of computations. LTL extends classical logic with tense operators X (“in the next state. . . ”), F (“eventually. . . ”), G (“always. . . ”), and U (“. . . until . . . ”) [20]. For example, the requirement that a system never enters a “crash” state can naturally be ex-pressed in LTL by a formula G¬crash. If we let (cid:2)P (cid:3) denote the set of all possible computations that may be produced by the program P , and let (cid:2)ϕ(cid:3) denote the set of state sequences that satisfy the LTL formula ϕ, then verification of LTL properties \fJ. Gutierrez et al. / Artificial Intelligence 248 (2017) 123–157125Fig. 1. Model checking. A model checker takes as input a model, representing a finite state abstraction of a system, together with a claim about the system behaviour, expressed in temporal logic. It the",
            {
                "entities": [
                    [
                        136,
                        223,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 351–391www.elsevier.com/locate/artintRepresentation of occurrences for road vehicle trafficR. Gerber, H.-H. Nagel ∗Institut für Algorithmen und Kognitive Systeme, Universität Karlsruhe (TH), 76128 Karlsruhe, GermanyReceived 28 June 2004; received in revised form 17 July 2007; accepted 19 July 2007Available online 27 July 2007AbstractOur 3D-model-based Computer Vision subsystem extracts vehicle trajectories from monocular digitized videos recording roadvehicles in inner-city traffic. Steps are documented which import these quantitative geometrical results into a conceptual repre-sentation based on a Fuzzy Metric-Temporal Horn Logic (FMTHL, see [K.H. Schäfer, Unscharfe zeitlogische Modellierung vonSituationen und Handlungen in Bildfolgenauswertung und Robotik, Dissertation, 1996]). The facts created by this import stepcan be understood as verb phrases which describe elementary actions of vehicles in image sequences of road traffic scenes. Thecurrent contribution suggests a complete conceptual representation of elementary vehicle actions and reports results obtained byan implementation of this approach from real-world traffic videos.© 2007 Elsevier B.V. All rights reserved.Keywords: Computer vision; Knowledge representation; Temporal reasoning; Reasoning about actions and change; Fuzzy metric-temporal logic1. IntroductionAn adult is expected to be able to write down—not necessarily with style and precision—what he sees. Concedingsimilar, but appropriately adapted reservations, what is required to have a computer perform an analogous task?Obviously, an analogue to human seeing could be Computer Vision. The notion of an automatic report generator,too, is no longer considered as science fiction. It most likely turns into a challenge, however, to imagine the detailedcommunication between a computer vision (sub)system and an algorithmic report generator. What looks like the meredefinition of an interface will turn out to require the design of a system-internal logic-based conceptual representationof a text in combination with the design of an entire set of processes operating on this representation.Investigations to be discussed in the sequel address an important step towards the algorithmic transformation ofvideo signals into a natural language text which describes the recorded scene, in particular its temporal development.The presentation will first sketch an overall system concept in order to provide a framework for the subsequentdiscussion which will then concentrate on the conversion of geometric tracking results into elementary conceptualrepresentations of relevant aspects of the (short-term) development in the recorded scene. A preliminary version ofthis approach has been partially outlined in [10].* Corresponding author.E-mail address: nagel@iaks.uni-karlsruhe.de (H.-H. Nagel).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.07.001\f352R. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391Fig. 1. In the upper left panel, the image plane projection of a polyhedral model for a fastback has been overlaid to frame number 340 from an imagesequence recorded at a gas station. In addition, one can see the trajectory segment obtained by automatic model-based tracking of this vehicle whichwill be referred to as object_1. Frames 635, 1180, and 2131 show snapshots of various maneuvers of another vehicle (object_4), with analogousoverlays of a projected polyhedral model and the trajectory for this vehicle (see Section 1 for more explanations). The sketch in the bottom rowillustrates the maneuvers of object_4 in this sequence.Fig. 1 illustrates a coherent source of examples for different stages of such a transformation. The first frame1 #340in the upper left panel shows a snapshot where a fastback has already stopped at the second petrol pump on thefilling lane (see Fig. 2) closer to the observer (subsequently referred to as the ‘lower filling lane’). A second fastback(subsequently referred to as ‘object_1’) had just entered the gas station and selected the filling lane on the other side1 Based on special derivative operators which suitably interpolate between digitizations in even and odd scanlines of interlaced video (see, e.g.,[32]), actually each half-frame—or field in video-coding terminology—is evaluated in its own right, resulting in a temporal sampling rate of20 msec. This aspect reduces the approximation errors by the Extended Kalman-Filter used and thus improves the tracking quality. Beyond thisfact, however, it does not influence the conversion of geometric results to natural language concepts. In order to simplify the presentation, we shalluse the term frame henceforth without further qualifications.\fR. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391353Fig. 2. Groundplan sketch of the gas station.of the petrol pumps (‘upper filling lane’) in order to stop next to the second petrol pump, too. About 300 frames—i.e. 6 seconds—later, a third vehicle, a sedan (‘object_4’), entered the gas station and headed towards a passing lanebetween the upper filling lane and the gas station building. It passed object_1, changed back to the upper filling lane,stopped there and backed up slowly until it eventually stood next to the third petrol pump, immediately in front ofobject_1, around frame-time 1180. About 1000 frames (20 secs) later, after the fastback on the lower filling lanehad already left the gas station, object_1 started to move backwards to gain space in order to change to the passinglane. Object_1 then passed object_4 and headed towards the exit of the gas station. About three quarters of a minutelater around frame-time 4600, object_4 started to move forward and headed towards the exit, too. Examples will refermostly to the sequence of maneuvers performed by object_4 and object_1 during the period while this image sequencehad been recorded.The derivation of conceptual representations and textual descriptions of agent behavior from visual input hasbecome a research topic of constantly growing interest in the last few years. Such research has to deal with theuncertainties related to the geometric results estimated from video sequences and with bridging the semantic gapbetween (mainly geometric) computer vision results and (mainly conceptual) action descriptions. This contributionaddresses a basic topic related to the second aspect, namely isolatable agent activities or occurrences for non-humanagents, in particular rigid vehicles in videos recorded from road traffic. A discussion of relevant prior publications willbe postponed to the concluding sections because similarities and differences can be stated there more succinctly withrespect to what will be reported in the sequel.2. System outlineAlgorithmic text generation based on a recorded video sequence has to be concerned with at least two disciplines,namely computer vision and computational linguistics. Each of these two disciplines already covers several subdis-\f354R. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391Fig. 3. Coarse layer structure of the overall system (from [28]; ©2000 IEEE, by permission). The layers with light gray background constitute thecore Computer Vision subsystem for the extraction of a (mostly geometric) 3-D scene representation. The Conceptual Representation subsystemhas a medium gray background, the text generation is incorporated into the Natural Language Level with background in dark gray (see, too, thetext or [29]).ciplines. Any system for video-to-text transformation will thus be complex and, therefore, difficult to present and toanalyse. The following subsection provides an overview of our entire system approach, thereby setting the frame for amore detailed outline of steps in video-based text generation proper. More information about the development of thissystem concept during past decades can be found in [29], with recent developments being discussed in [2].2.1. Overall system structureThe transformation of video signals into a text describing the recorded temporal development within the depictedscene can be subdivided into three groups of processes—see Fig. 3:(1) The subsystem which controls the video recording and the subsequent processing steps up to and including theextraction of 3-D time-dependent geometric descriptions of the scene and, in particular, of visibly moving bodies.This subsystem comprises the layers devoted to the following subtasks:(a) Control of the recording equipment including actuators required, for example, to change pan and tilt of videocamera heads, zoom of camera lenses, etc.—the Sensor-Actuator-Level (SAL).(b) The Image-Signal-Level (ISL) devoted to image processing operations on the recorded video signal.(c) The Picture-Domain-Level (PDL) where information extracted from the image signal is aggregated intoPicture-Domain-Descriptors in the 2-D image plane.(d) The Scene-Domain-Level (SDL) which combines Picture-Domain-Descriptors with knowledge about thecamera and about the scene in order to obtain a three-dimensional representation of (at least) the geometryof temporal developments in the recorded scene.In the particular example illustrated by Fig. 1, this information comprises the 3-D vehicle status together withthe 3-D model of those vehicles which have been detected, initialized, and tracked. The vehicle status comprisesthe scene ground plane coordinates (x, y) of the model reference point, the vehicle orientation θ , speed v, and\fR. Gerber, H.-H. Nagel / Artificial Intelligence 172 (2008) 351–391355steering angle2 ψ. The vehicle status is updated at each frame time point, i.e. every 20 msec, by a Kalman-Filterincorporated into a model-based tracking process—see [14,19,23].3(2) The quantitative 3-D spatio-temporal information provided by the model-based vehicle tracking subsystem isconverted into an elementary conceptual representation at the interface between the Scene-D",
            {
                "entities": [
                    [
                        72,
                        126,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 81 ( 1996) 17-29 Artificial Intelligence Generating hard satisfiability problems * Bart Selman a,*, David G. Mitchell b*l, Hector J. Levesque bv2 a AI Principles Research Department, AT&T Bell Laboratories, Murray Hill, NJ 07974, USA b Department of Computer Science, Vniversiry of Toronto, Toronto, Canada M5S IA4 Received May 1993; revised May 1995 Abstract We report results from large-scale experiments in satisfiability testing. As has been observed by others, testing the satisfiability of random formulas often appears surprisingly easy. Here we show that by using the right distribution of instances, and appropriate parameter values, it is possible to generate random formulas that are hard, that is, for which satisfiability testing is quite difficult. Our results provide a benchmark for the evaluation of satisfiability testing procedures. Keywords: Satisfiability; Random problems: Phase transitions; 4.3; Benchmarks; Empirical study 1. Introduction Many computational tasks of interest to AI, to the extent that they can be precisely characterized at all, can be shown to be NP-hard in their most general form. However, there is fundamental disagreement, at least within the AI community, about the impli- cations of this. It is claimed on the one hand that since the performance of algorithms designed to solve NP-hard tasks degrades rapidly with small increases in input size, something will need to be given up to obtain acceptable behavior. On the other hand, it is argued that this analysis is irrelevant to AI since it is based on worst-case scenarios, * An earlier version of this paper * Corresponding ’ Work carried out while visiting AT&T Bell Laboratories. author. Telephone: [ 291 was presented at AAAI-92. (908) 582-2221. E-mail: selman@research.att.com. E-mail: mitchell@ai.toronto.edu. 2 Fellow of the Canadian Institute for Advanced Research. Supported in part by a grant from the Natural Sciences and Engineering Research Council of Canada. E-mail: hector@ai.toronto.edu. 0004-3702/96/.$15.00 SSDIOOO4-3702(9.5)00045-3 @ 1996 Elsevier Science B.V. All rights reserved \f18 B. Sehan et al./Art$cial Intelligence 81 (1996) 17-29 and that what is really needed is a better understanding “on average”. of how these procedures perform The first computational task shown to be NP-hard, by Cook [9], was propositional that makes tasks have been shown to be NP-hard by proving true according the formula for SAT. Unlike many other NP-hard or SAT: Given a formula of the propositional to its variables Subsequent satisfiability assignment interpretation. least as hard as SAT. Roughly, a task is NP-hard a good algorithm SAT is of special concern (i.e., given a collection of base facts 2, a sentence not satisfiable). Many other forms of reasoning, planning these usually fact that SAT is a fundamental is essential. in AI applications require much more than the propositional and image interpretation, to AI because of its direct relationship calculus, decide if there is an to the usual rules of they are at for it would entail tasks (see [ 171 for a catalogue) , to deductive reasoning if a good algorithm (Y may be deduced iff .Z U {TX} is including default reasoning, diagnosis, also make direct appeal to satisfiability. The fact that the calculus that work well task, and that developing SAT procedures simply highlights We might ask when it is reasonable and when we should settle for something always a result of strange encodings in answering on the expected difficulty of SAT (although time being, we must rely largely on empirical such questions tailored to use a sound and complete procedure for SAT, less. Do hard cases come up often, or are they for some specific purpose? One difficulty results It seems that, at least for the is that there appear to be few applicable analytical see below). results. A number of papers (some discussed below) have claimed that the difficulty of SAT on randomly generated problems result by Goldberg polynomial in practice, but at first blush worst cases. [20] suggests in that SAT can be readily time. This does not settle the question of how well the methods will work to AI than contrived solved “on average” to be more relevant it does appear is not so daunting. For example, an often-quoted of instances. the Goldberg The big problem assume a distribution [ 141 refuted choice of distribution. is easy, but that he had used a distribution with a preponderance is, from the space of all problem no hard cases. Nevertheless, is that to examine how well a procedure does on average one must Indeed, as we will discuss below, Franc0 and Paul1 of the It is not that Goldberg had a clever algorithm, or that the problem of easy instances. That in a way that produced almost that it was a direct consequence to appear purporting result by showing papers continue to empirically they sampled instances, efficacy of some new procedure, presenting propositional given using easy problems the danger of biasing (even data suggesting variables-can just that very large satisfiability be solved. How are we to evaluate the sample if unwittingly)? to suit the procedure but using this distribution problems-with (e.g., the demonstrate [22,241), or thousands of results, in question, or of simply these empirical In this paper, we present empirical results showing that random fiability can be generated particular SAT procedure, robustness of the procedures we develop, we will want to consider on a wide spectrum of examples. While in such a way that easy and hard sets of instances anyway) are predictable in advance. the easy cases we have found can be s01ved by their performance instances of satis- (for a the If we care about \fB. Selman et al./Artificial Intelligence 81 (1996) 17-29 19 Procedure DP Given a set of clauses 2 defined over a set of variables V: If 2 contains a unit clause C, assign to the variable men- the truth value which satisfies C, and return the result of calling DP on If .E is empty, return “satisfiable”. If _E contains an empty clause, return “unsatisfiable”. Unit-Clause Rule: tioned the simplified Splitting Rule: Select from V a variable u which has not been assigned a truth If this call formula. value. Assign returns “satisfiable”, set u to the opposite value, and return it a value, and call DP on the simplified then return “satisfiable”. Otherwise, the result of calling DP on the re-simplified formula. formula. Fig. 1. The DP procedure. almost any reasonable method, from the losers. Thus, our data is presented as challenging of SAT procedures for example). The SAT procedure we used for our tests is the Davis-Putnam (see Selman et al. [ 3 1,32,34], it is the hard cases ultimately that separate test material the winners for developers procedure, which we [ 16,351, case of resolution the most widely used general this was a good choice for two reasons: First, it is equivalent reasoning in AI; second, until recently, almost all empirical work on SAT testing has used that describe below. We believe to a particular method one or another refinement of this method, which facilitates comparison. We suspect our results on hard and easy areas generalize is an extension remain [29]. The primary observations This paper larger sample sizes (10,000 and arguments formulas per point, rather than 500), which eliminates most of the sampling error and so gives a clearer picture of the behaviors of interest. We have added data in Section 3 on the average cost than just one), truth assignments. We have also improved our and have data comparing formula models been extended or clarified, and some updated references have been added, especially to theoretical the median number of satisfying different the same, but we have used much (Section 4). Some discussions to all SAT procedures. to find all satisfying truth assignments of a previous random results. (rather report is organized as follows. In Section 2 we describe the Davis- in Section 3 we study its performance on one distribution of it produces computationally the fixed clause length model. We show that with the right choice of parameter In Section 4 we consider challenging SAT instances. in the testing procedures. We briefly review related work in Section the constant density model, and argue that it is not useful The rest of the paper and Putnam procedure formulas, values, a second distribution, evaluation of satisfiability 5, and summarize our results in Section 6. 2. The Davis-Putnam procedure One of the most widely used methods is the [ 121. Our procedure, which we refer to as DP, is the splitting for propositional satisfiability testing Davis-Putnam procedure \f20 B. Selman et al./Art$cial Intelligence 81 (1996) 17-29 variant of the Davis-Putnam procedure as described in [ 111, but without the pure literal rule. (The pure literal rule is: if a literal p occurs in a formula, but its negation does not, then p can be immediately assigned the value true.) DP is sketched in Fig. 1. It takes as input a set of clauses _Z over a set of variables Y and returns either “satisfiable” or “unsatisfiable.” (A clause is a disjunction of literals. A set of clauses represents a conjunction of disjunctions, i.e., a formula in conjunctive normal form (CNF) .) DP performs a backtracking depth-first search in the space of all truth assignments, incrementally assigning truth values to variables and simplifying the formula. If no new variable can be assigned a value without producing an empty clause, it backtracks by changing a previously made variable assignment. In our implementation, variables are given an arbitrary ordering, and in the “splitting” step we choose the next variable according to this ordering, and set it first to true. The performance of simple backtracking is greatly improved by employing the unit clause rule: Whenever a clause containing a single literal arises, the variable occurring in that clause is immediately assigned the appropriate truth value. The formula is then ",
            {
                "entities": [
                    [
                        65,
                        104,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 310 (2022) 103751Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConjure: Automatic Generation of Constraint Models from Problem SpecificationsÖzgür Akgün a,∗Ian Miguel a, Peter Nightingale ba School of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, UKb Department of Computer Science, University of York, Deramore Lane, Heslington, York YO10 5GH, UK, Alan M. Frisch b, Ian P. Gent a, Christopher Jefferson a, a r t i c l e i n f oa b s t r a c tArticle history:Received 22 November 2021Received in revised form 23 May 2022Accepted 6 June 2022Available online 9 June 2022Keywords:Constraint modellingConstraint programmingCombinatorial optimizationConstraint satisfaction problemWhen solving a combinatorial problem, the formulation or model of the problem is critical to the efficiency of the solver. Automating the modelling process has long been of interest because of the expertise and time required to produce an effective model of a given problem. We describe a method to automatically produce constraint models from a problem specification written in the abstract constraint specification language Essence. Our approach is to incrementally refine the specification into a concrete model by applying a chosen refinement rule at each step. Any non-trivial specification may be refined in multiple ways, creating a space of models to choose from.The handling of symmetries is a particularly important aspect of automated modelling. Many combinatorial optimisation problems contain symmetry, which can lead to redundant search. If a partial assignment is shown to be invalid, we are wasting time if we ever consider a symmetric equivalent of it. A particularly important class of symmetries are those introduced by the constraint modelling process: modelling symmetries. We show how modelling symmetries may be broken automatically as they enter a model during refinement, obviating the need for an expensive symmetry detection step following model formulation.Our approach is implemented in a system called Conjure. We compare the models produced by Conjure to constraint models from the literature that are known to be effective. Our empirical results confirm that Conjure can reproduce successfully the kernels of the constraint models of 42 benchmark problems found in the literature.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionEfficient decision-making is of central importance to a modern society. It is natural to represent and reason about decision-making problems in terms of constraints. For example, in scheduling a football league many constraints occur, such as: every team has to play every other, home and away; every match must be assigned a set of officials, and no official or team can be in two places at once; no team should be scheduled to play more than, say, four consecutive away games. Constraint programming [1] offers a means by which solutions to such problems can be found automatically. Constraint * Corresponding author.caj21@st-andrews.ac.uk (C. Jefferson), ijm@st-andrews.ac.uk (I. Miguel), peter.nightingale@york.ac.uk (P. Nightingale).E-mail addresses: ozgur.akgun@st-andrews.ac.uk (Ö. Akgün), alan.frisch@york.ac.uk (A.M. Frisch), ian.gent@st-andrews.ac.uk (I.P. Gent), https://doi.org/10.1016/j.artint.2022.1037510004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fÖ. Akgün, A.M. Frisch, I.P. Gent et al.Artificial Intelligence 310 (2022) 103751123456789language Essence 1.3given w, g, s : int(1..)letting Golfers be new type of size g * sfind sched : set (size w) ofpartition (regular, numParts g, partSize s)from Golferssuch thatforAll g1, g2 : Golfers, g1 < g2 .(sum week in sched . toInt(together({g1, g2}, week))) <= 1Fig. 1. An Essence problem specification of the Social Golfers Problem (Problem 10 at CSPLib.org). In a golf club there are a number of golfers who wish to play together in g groups of size s. Find a schedule of play for w weeks such that no pair of golfers play together more than once.solving of a given problem proceeds in two phases. First, the problem is modelled as a set of decision variables, and a set of constraints on those variables that a solution must satisfy. A decision variable represents a choice that must be made in order to solve the problem. The domain of potential values associated with each decision variable corresponds to the options for that choice. In our football league example, one might have two decision variables per match to represent each of the home and away teams. The second phase consists of using a constraint solver to find solutions to the model: assignments of values to decision variables satisfying all constraints.There are typically many possible models for a given problem, and the model chosen can dramatically affect the efficiency of constraint solving. This presents a serious obstacle for non-expert users, who have difficulty in formulating a good (or even correct) model from among the many possible alternatives. Modelling is therefore a critical bottleneck in the process of constraint solving, considered to be one of the key challenges facing the constraints field [2].It is desirable, therefore, to automate constraint modelling as far as possible. Several approaches have been taken to automate aspects of constraint modelling. Some approaches learn models from, variously, natural language [3], positive or negative examples [4–6], membership queries, equivalence queries, partial queries [7,8], generalisation queries [9] or ar-guments [10]. Other approaches include: automated transformation of medium-level solver-independent constraint models [11–17]; deriving implied constraints from a constraint model [18–22]; case-based reasoning [23]; and refinement of ab-stract constraint specifications [24] in languages such as ESRA [25], Essence [26], F [27] or Zinc [28–30]. We focus herein on the refinement approach, where a user writes a constraint specification describing a problem above the level of abstrac-tion at which modelling decisions are made. In Section 8 we discuss in more detail alternative approaches to automated constraint modelling by this method.This paper presents the automated constraint modelling system Conjure, which serves to demonstrate the efficacy of the refinement-based approach. A problem is input to Conjure in Essence, an abstract constraint specification language.Essence’s support for abstract decision variables with types such as set, multiset, relation and function, as well as nested types, such as set of sets and multiset of relations allows a problem to be specified without committing to constraint modelling decisions. To illustrate, consider the fragment of the Essence specification of the Social Golfers Problem [31]presented in Fig. 1. Given a number of weeks (w), a number of groups (g) and a group size (s), the problem is to find a schedule of play over the w weeks for the g × s golfers divided into g groups of size s, subject to a socialisation constraint among the golfers that stipulates that no pair of golfers play together more than once. The Social Golfers Problem is naturally conceived as finding a set of partitions of golfers subject to some constraints, which can be specified in Essence via a singleabstract decision variable, as presented in the figure where the variable is sched.Since these abstract types are not supported directly by constraint solvers,1 an Essence specification must be transformed (refined) into a constraint model. Automating this process presents a considerable challenge and the contributions of this work are in meeting that challenge. Principal among these is a carefully designed rule-based architecture implemented inConjure to refine an Essence specification into a constraint model. One key contribution is that Conjure can refine nested types without resorting to enumerating the values of the inner type (for example, refining a set of sets of integers without enumerating all possible values of the inner set). This capability is vital to refining many of the Essence specifications that we use in the evaluation. As we will demonstrate, different rule application pathways produce different constraint models, supporting an automated model selection process among the many possible alternatives. This approach also facilitates the automated production of channelled constraint models [32], in which a single abstract decision variable is refined in multiple ways. Channelling constraints are elegantly generated for an abstract decision variable A by creating the equality A = A and refining it with two different representations of A, thus ensuring the two representations take the same abstract value in all solutions. Channelled models have previously been created manually by experts, typically in an effort to simplify the statement of the problem constraints so as to strengthen the inference of the constraint solver and reduce search.A further important contribution of our rule-based architecture is in the treatment of symmetry, a structure-preserving transformation. In the context of a constraint problem, given a solution to a problem instance we can obtain another symmetric solution. Symmetry can lead to redundant search: if the constraint solver reaches a dead end in its search for a 1 Set variables are a notable exception, which are widely supported. However, the solvers that support set variables do not offer a choice as to the underlying representation of the set, and do not support nested sets.2\fÖ. Akgün, A.M. Frisch, I.P. Gent et al.Artificial Intelligence 310 (2022) 103751solution, we are wasting time if we ever consider a symmetric equivalent of it. A particularly important class of symmetries are those introduce",
            {
                "entities": [
                    [
                        135,
                        213,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 75 ( 1995) 297-345 Artificial Intelligence Multiagent negotiation under time constraints * Sarit Kraus a,l, Jonathan Wilkenfeld b12, Gilad Zlotkin ‘y3 a Department of Mathematics and Computer Science, Bar Ilan University, Ramat Gan, 52900 Israel b Department of Government and Politics, CJniversify of Maryland, College Park, MD 20742, USA ’ Center of Coordination Science, Sloan School of Management, Massachusetts Institute of Technology, I Amherst St., E40-I 79, Cambridge, MA 02139, USA Received November 1992; revised January 1994 Abstract Research in distributed artificial intelligence (DAI) is concerned with how automated agents can be designed to interact effectively. Negotiation is proposed as a means for agents to communicate and compromise to reach mutually beneficial agreements. The paper examines the problems of resource allocation and task distribution among autonomous agents which can benefit from sharing a common resource or distributing a set of common tasks. We propose a strategic model of negotiation that takes the passage of time during the negotiation process itself into account. A distributed negotiation mechanism is introduced that is simple, efficient, stable, and flexible in various situations. The model considers situations characterized by complete as well as incomplete information, and ones in which some agents lose over time while others gain over time. Using this negotiation mechanism autonomous agents have simple and stable negotiation strategies that result in efficient agreements without delays even when there are dynamic changes in the environment. 1. Introduction Research in distributed artificial intelligence (DAI) agents can be designed to interact effectively. One important capability is concerned with how automated that could aid *This material 9123460. Some material for her comments. is based upon work supported by the National Science Foundation under Grant No. IRI- in this paper appeared in preliminary form in [26,27]. We thank Karen Lochbaum ’ E-mail: sarit@bimacs.cs.biu.ac.il. Also affiliated with the Institute for Advanced Computer Studies, University of Maryland, College Park. ‘E-mail: s E-mail: gilad@mit.edu. jwilkenf@bss2.umd.edu. This research was done while the author was at the Computer Science Department in the Hebrew University and was supported by Leibniz Center for Research in Computer Science. 0004-3702/95/$09.50 SSDlOOO4-3702(94)00021-R @ 1995 Elsevier Science B.V. All rights reserved \f298 S. Kraus et al./Artificial Intelligence 75 (1995) 297-345 cooperation inter-agent their respective desires and compromise One of the presumed difficulties is negotiation; agents could be built that are able to communicate to reach mutually beneficial agreements. is that negotiation the overhead of coordination benefit may increase planning be either about job sharing or resource allocation. agents from spending timetables and negotiation for satisfying their goals. too much in using negotiation is a costly and time-consuming as a way of reaching mutual it process and, consequently, (see [ 1 ] ) . In the presence of time constraints, time should be taken into consideration. The negotiation may the to their In both cases we want to prevent and therefore not keeping time on negotiation (MA) Research in DA1 is divided and Multi-Agent Systems 1.5 below). Research problem can be divided among a number of modules or “nodes”. The modules system are centrally reliability. They include solution into two basic classes: Distributed Problem Solving (DPS) [ 1 ] (see discussion of previous work in DA1 in Section in solving a particular in a DPS and/or to find a stability, modularity, of cooperation mechanisms designed in DPS considers how the work involved to improve performance, to a given problem. the development designed Research in MA is concerned with coordinating (possibly heterogeneous) tion of autonomous In MA, shared goals or success criteria. There agents. intelligent (possibly pre-existing) intelligent behavior among a collec- agents. and no globally the among for real competition is a possibility there is no global control, no globally consistent knowledge, These classes are actually falls “closer” the two extreme poles in the DA1 research spectrum. Our self- to the MA pole since rational and autonomous research motivated, that the agents may share a common goal, although even in such situations, are self-motivated has its own utility utility. agents. However, we also deal with the possibility the agents that each agent expected to their interests. We assume and that rational behavior and act only according involves maximizing it deals with interactions function, among allocation of resource We examine the problems task distribution agents. resource In some domains, (e.g., among au- resources must share a agents, due roads, bridges, clean air). and to limited tonomous In other domains, when resources common resource since are unlimited, a set of com- resources may be expensive are symmetrical. In mon tasks. Both problems resource, with each the resource problem where agent seeking a larger share of the resource. agents have a common goal, several tasks need to be performed to fulfill the goal. Each agent would like the common goal to be achieved with the least amount of effort on its part. This cooperative case also has a competitive element. Each agent wants to perform a smaller part of the job (task). agents may still mutually benefit from sharing a common (e.g., printers, satellites), or from distributing sharing and task distribution) for a valuable In the task distribution there is competition sharing problem (resource In this paper we suggest a strategic model of negotiation the negotiation process over time during preferences the agreements agreements can be avoided. We will examine time will change they are willing itself their strategies into consideration. Changes that takes the passage of in the agents’ and, as a result, in reaching the following possible situations where the in the negotiation to reach. This model will show that delays \fstrategic model (1, S. Kraus et al./Art$cial Intelligence 75 (1995) 297-345 299 is applicable: is reached time need information (Section 3). that lose over leave the negotiations to satisfy a common information the negotiations lose over time need to share a common about until an agreement to cooperate goal. about the other agent. The agents can resource. Each agent the other agent. They have no alternative, Two agents that knows all relevant but to continue Two agents Each agent knows all relevant unilaterally (Section 4). Two agents need to share a resource. One of the agents already has access to the It is gaining over time. resource and is using to use the resource and loses over time. Both agents The other agent is waiting have full information leave the negotiations Similar other (Section 6). Several agents need to cooperate over time, have full information negotiations to satisfy a common goal. All of them are losing leave the about each other and can unilaterally and can unilaterally to case (3)) but the agents do not have complete the negotiation process. (Section 7). (Section 5). about each information it during (2) (3) (4) (5) 1.1. The resource allocation problem A set of agents shares a joint resource. The joint agent at a time. Agreement resource. An agreement agents. 4 is sought so that all the agents will be able resource can only be used by one to use the the the usage of the resource among is a schedule that divides Examples of joint road fresh water, clean air, etc. (Other work in the DAI community dealing with the lines, printers, disks, bridges, resources are: communication junctions, resource allocation problem negotiation protocol arising [ 331 address mechanism [ 231 propose [ 41 proposes includes, for example, that is useful for cooperatively in distributed networks of semi-autonomous [ 6,301 which present a multistage resolving resource allocation conflicts problem solving nodes. Lesser et al. and develop a for resource allocation based on the criticality of tasks; Kornfeld and Hewitt and real-time performance, in resource allocation tradeoff resource allocation using specialist resource allocation via resource pricing.) “sponsor” agents; and Chandrasekan A communications cost of its launching get access competing project. satellite and maintenance. is a good example of a shared resource, due to the high In many cases can is by sharing one with other companies. Even in such a joint to participate satellite it mutually the only way a company beneficial to a communications companies may find Sharing a common resource requires a coordination mechanism that will manage usage of the resource. Discussion may even conclude) about the coordination mechanism will begin before discussion of other technical aspects of the joint project. the (and A coordination mechanism it can be an on-line negotiation mechanism can be a static division of frequencies or time slots. On resolves that dynamically the other hand, 40ur model is also applicable in the case where agents. This case does not differ significantly the resource the from the case where only the resource usage time can be divided. itself can actually be divided between \f300 S. Kraus et al. /Artificial Intelligence 75 (1995) 297-345 local conflicts over the usage of the common of the coordination mechanism tion mechanisms schedules. that generate agreements spectrum. On this spectrum on long resource. These are the two extreme poles there are also coordina- term (an hour, a day, . . .) global This paper addresses the kinds of attributes a coordination mechanism a negotiation mechanism is eficiency. The coordination mechanism resource. Efficiency and presents tribute usage of the common instantaneously As in the case of the communications (i.e., a local conflict should be resolved without delay). resources common satellite, that satis",
            {
                "entities": [
                    [
                        76,
                        121,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 448–452www.elsevier.com/locate/artintLearning equilibrium as a generalization of learning to optimize ✩Dov Monderer ∗, Moshe TennenholtzFaculty of Industrial Engineering and Management, Technion – Israel Institute of Technology, Haifa 32000, IsraelReceived 15 May 2006; received in revised form 20 October 2006; accepted 21 December 2006Available online 26 January 2007AbstractWe argue that learning equilibrium is an appropriate generalization to multi-agent systems of the concept of learning to optimizein single-agent setting. We further define and discuss the concept of weak learning equilibrium.© 2007 Elsevier B.V. All rights reserved.Keywords: Learning; Machine learning; Learning equilibrium1. PrefaceIn [16], Shoham, Powers, and Grenager (SPG) present five distinct agendas in multi-agent learning. In this man-uscript we discuss their third agenda—the normative approach. SPG mention that the requirement that learningalgorithms would be an equilibrium may serve as a synonyms to this approach. We claim that the equilibrium ap-proach is indeed the right one if the question is: what should a mediator who makes recommendations to all players,recommend. The equilibrium property seems to be a necessary ingredient in such recommendations. As economistsdo not tend to consider mediators (competing firms do not go to a central mediator to determine their, say, pricingpolicy)1 it is of no surprise that the equilibrium agenda is not a major issue in the learning literature in economics.However, when, say eBay provides the participants a proxy service, then it actually plays the role of a mediator (andnot only of an organizer).The theory of learning in multi-agent systems inherits all the conceptual and practical difficulties of learning insingle-agent settings, as well as all difficulties of analyzing behavior in multi-agent settings. Therefore, in order todefine and understand the equilibrium approach to learning in multi-agent systems we phrase it as an extension ofwork on learning in single-agent systems.22. Learning in single-agent systemsRoughly speaking, one could partition work on learning in single-agent systems into two major but not necessarilyindependent categories:✩ Both authors thank the Israeli Science Foundation and the Fund for the Promotion of Research at the Technion for the support of their research.* Corresponding author.E-mail address: dov@ie.technion.ac.il (D. Monderer).1 Some well-known exceptions to this statement can be found in the literature on correlated equilibrium [4], and on communication equilibrium[8,15]. However, the general theme in economics is that there is no mediator in the system that recommends behavior to the agents.2 For the sake of exposition we introduce all notations in this paper with pure strategies.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.002\fD. Monderer, M. Tennenholtz / Artificial Intelligence 171 (2007) 448–452449• Descriptive theory-prediction: Given examples of past behavior of a system, and some background information,we would like to predict the future behavior of the system. Classical work in statistics, inductive inference andsupervised learning in AI fit into this category, as well as much work in data mining and the classification ofsubjects in psychology.• Normative theory-optimization: Given partial information about a system, our aim is to devise algorithms foroptimizing an agent’s behavior in the system. Typically, the interleaving of exploration and exploitation is needed.Work on reinforcement learning in AI, as well bandits problems fit into this category.We only discuss our view about the extension to multi-agent systems of the normative approach. That is, we usethe word learning in a single-agent setting as a synonym for optimization in dynamic situations with incompleteinformation.Consider a single agent facing a dynamic decision problem with incomplete information, D, defined by a set ofdynamic decision problems Dω with a parameter ω ∈ Ω. Each ω ∈ Ω is called a state of nature. Nature chooses ω, butthe agent does not know ω. However, he possesses some initial information about the state of nature, and he acquiresadditional partial information after every stage. For example, every Dω can be a Markov decision problem. If we havea prior probability distribution over the set Ω we call the problem a Bayesian dynamic decision problem. If we wantto stress the fact that such a prior probability does not exist we call the problem a Pre-Bayesian dynamic decisionproblem.3A strategy of the decision maker at each Dω is called a policy. A strategy of the agent in the decision problem withincomplete information, D, is called in this paper an algorithm. We assume that had the agent known ω he would havechosen an optimal policy, which would have given him the long-run value, v(ω), of Dω. More precisely, let Uω be thelong-run reward function of the problem Dω, and let S(ω) be the set of possible policies for this problem. A policyf ω ∈ S(ω) is an optimal policy at Dω ifmaxgω∈S(ω)Uω(gω) = Uω(f ω).The value of Dω is the real-valued function v defined on Ω as follows:v(ω) = maxgω∈S(ω)Uω(gω) ∀ω ∈ Ω.(1)(2)Ideally, in a dynamic decision problem with incomplete information an optimizing agent would use an algorithmthat guarantees v(ω) for every ω. This approach is mainly taken in machine learning. We accept this view; in ourview the right notion for a learning-to-optimize algorithm for a decision problem with incomplete information is thefollowing: It is an algorithm that yields an optimal policy at every ω.4 More precisely:Let f be an algorithm for D. For every ω we denote by fω, the policy induced by f on Dω.f is a learning-to-optimize algorithmin D if for every w, fω is an optimal algorithm in Dω, that ismaxgω∈S(ω)Uω(gω) = Uω(fω) ∀ω ∈ Ω.(3)An equivalent definition will be useful in the sequel.The set of all algorithms for D is denoted by S. For every f ∈ S and for every ω ∈ Ω define U (ω, f ) = Uω(fω).Obviously, f is a learning-to-optimize algorithm in D if and only ifU (ω, g) = U (ω, f ) ∀ω ∈ Ω.maxg∈S(4)Unfortunately, there exist dynamic decision problems for which a learning-to-optimize algorithms do not exist.In Bayesian dynamic decision problems it is customary to look for algorithms that maximize the long-run expectedreward of the agent. Such algorithms generally exist. We call such an algorithm an optimal Bayesian algorithm.3 In economics, it is customary to relate to a Bayesian model as a model with incomplete information. Until recently, a model without priors wasnot given a special name. Recently, such games have received several titles in various papers. In this paper we follow the terminology of [11], andwe refer to such games as pre-Bayesian.4 Practically, the definition would be more elaborate, and would refer to various accuracy parameters. Notice that we refer here to the long-runvalue mentioned above.\f450D. Monderer, M. Tennenholtz / Artificial Intelligence 171 (2007) 448–452That is, f is an optimal Bayesian algorithm if(cid:2)(cid:2)maxg∈SΩU (ω, g) dμ(ω) =U (ω, f ) dμ(ω),Ωwhere μ is the prior probability on Ω.5(5)It is important to note that in a Bayesian dynamic decision problem, every learning-to-optimize algorithm is alsoan optimal Bayesian algorithm, but the converse does not necessarily hold.63. Learning in multi-agent settingsWe take the position of a mediator who is about to assign algorithms to a set of selfish agents, N = {1, 2, . . . , n} whoare engaged in a multistage game with incomplete information, G.7 This game, G is defined by a set of multi-stagegames with complete information, Gω with a parameter ω ∈ Ω. Nature chooses a state of nature ω, but the agents donot know ω. However, each agent possesses some initial private information about the state of nature, and he acquiresadditional partial information after every stage. For example, every Gω can be a repeated game. If we have a priorprobability distribution over the set Ω we say that G is a Bayesian multi-stage game. If we want to stress the factthat such a prior probability does not exist we call G a pre-Bayesian multi-stage game. In the complete informationcase, when dealing with the multi-agent setting, the term policy used in the single agent setting is replaced by the termstrategy. As in the single agent setting, a strategy of an agent in G is called an algorithm.The first question is what is the analogous concept of an “optimal policy” in the single-agent setup in the game Gω,in which the agents know ω. This is one of the most important conceptual issues dealt with in game theory. We take theposition that in the presence of a mediator, optimality means equilibrium. That is, the strategy given to every agent i isoptimal if all other agents are using their strategies in the profile.8 Hence, the analogous definition to an optimal policyin the single agent decision problem with complete information is: A profile of strategies, f ω = (f ωn ) isan equilibrium profile in Gω ifi (gωU ωi (f ω) = maxU ω∈Si (ω)−i) ∀i ∈ N.2 , . . . , f ω1 , f ωi , f ω(6)gωiNote, however, that except for two-person zero-sum games, the concept of a value function does not have a well-defined meaning in the multi-agent model.It is important to stress again the existence of a mediator in order to understand our approach. We do not claimthat economic agents play in equilibrium. We do not claim that an agent who is facing a multi-agent decision problemshould use an equilibrium strategy; This is because we cannot be sure that other agents would use an equilibriumstrategy, and even if they do they may stick to another equilibrium. However, a reliable mediator who provides allagents with algorithms can expect players to use the algorithms only if the profile of algorithms is in equilibrium.Hence, we assume that had the agents known ω they would have chosen an optimal profile of strategies, i.e. theywould have behaved according to",
            {
                "entities": [
                    [
                        72,
                        136,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 257 (2018) 1–23Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstants and finite unary relations in qualitative constraint reasoningPeter JonssonDepartment of Computer and Information Science, Linköping University, SE-581 83 Linköping, Swedena r t i c l e i n f oa b s t r a c tArticle history:Received 30 May 2017Received in revised form 1 December 2017Accepted 13 December 2017Available online 20 December 2017Keywords:Constraint satisfactionQualitative reasoningComputational complexityExtending qualitative CSPs with the ability of restricting selected variables to finite sets of possible values has been proposed as an interesting research direction with important applications, cf. “Qualitative constraint satisfaction problems: an extended framework with landmarks” by Li, Liu, and Wang (2013) [48]. Previously presented complexity results for this kind of extended formalisms have typically focused on concrete examples and not on general principles. We propose three general methods. The first two methods are based on analysing the given CSP from a model-theoretical perspective, while the third method is based on directly analysing the growth of the representation of solutions. We exemplify the methods on temporal and spatial formalisms including Allen’s algebra and RCC-5.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThis introductory section is divided into two parts where we first discuss the background of this article and thereafter describe our results.1.1. BackgroundQualitative reasoning has a long history in artificial intelligence and the combination of qualitative reasoning and con-straint reasoning has been a very productive field. A large number of constraint-based formalisms for qualitative reasoning have been invented, most notably within temporal and spatial reasoning, and they have been investigated from many dif-ferent angles. It has been noted that a particular extension to qualitative CSPs is highly relevant: Cohn and Renz [25, p. 578]observe the followingOne problem with this [constraint-based] approach is that spatial entities are treated as variables which have to be instantiated using values of an infinite domain. How to integrate this with settings where some spatial entities are known or can only be from a small domain is still unknown and is one of the main future challenges of constraint-based spatial reasoning.and Li, Liu, and Wang [48, p. 33] writeE-mail address: peter.jonsson@liu.se.https://doi.org/10.1016/j.artint.2017.12.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f2P. Jonsson / Artificial Intelligence 257 (2018) 1–23There is a growing consensus, however, that breakthroughs are necessary to bring spatial/temporal reasoning theory closer to practical applications. One reason might be that the current qualitative reasoning scheme uses a rather re-stricted constraint language: constraints in a qualitative CSP are always taken from the same calculus and only relate variables from the same infinite domain. This is highly undesirable, as constraints involving restricted variables and/or multiple aspects of information frequently appear in practical tasks such as urban planning and spatial query processing.That is, they regard the question of how to extend constraint formalisms with constants and other unary relations1as being very important; the same observation has been made in a wider context by Kreutzmann and Wolter [44]. An interesting recent example where such extensions of qualitative formalisms are necessary is the article on spatial query processing by Nikolaou and Koubarakis [56].(cid:3) ⊆ D | DGiven a (finite or infinite) set of values D, we let Dc = {{d} | d ∈ D} (i.e. the set of constant relations over D) and is finite} (i.e. the set of finite unary relations over D). Let us consider finite-domain CSPs for a moment. D f = {DFor every finite constraint language (cid:2) over D, the computational complexity of CSP((cid:2) ∪ D f ) is known due to results by Bulatov [17]. This is an important complexity result in finite-domain constraint satisfaction and it has been reproven several times using different methods [2,18]. Very recently, the complexity of CSP((cid:2) ∪ Dc) and CSP((cid:2)) has also been determined [19,63].(cid:3)The situation is radically different when considering infinite-domain CSPs where similar powerful results are not known. This can, at least partly, be attributed to the fact that infinite-domain CSPs constitute a much richer class of problems than finite-domain CSPs: for every computational problem X , there is an infinite-domain constraint language (cid:2) X such that Xand CSP((cid:2) X ) are polynomial-time Turing equivalent [9]. Finite domain CSPs are, on the other hand, always members of NP. Hence, the majority of computational problems cannot be captured by finite-domain CSPs.Nevertheless, there exist concrete examples where interesting qualitative and/or infinite-domain CSPs have been ex-tended with finite unary relations and/or constant relations. A very early example is the article by Jonsson and Bäck-ström [38] (see also Koubarakis [43]) where several temporal formalisms (including the point algebra and Allen’s algebra) are extended by unary relations (and also other relations). A more recent example is the article by Li et al. [48] where the point algebra and Allen’s algebra are once again considered. Li et al. also study several other formalisms including the cardinal relation algebra and RCC-5 and RCC-8 over two-dimensional regions and where constants are assumed to be polyg-onal regions. The results for the temporal formalisms by Jonsson and Bäckström are not completely comparable with the results by Li et al.: Jonsson and Bäckström’s approach is based on linear programming while Li et al. use methods based on enforcing consistency and computational geometry. Consistency-enforcing methods have certain advantages such as lower time complexity and easier integration with existing constraint solving methods. At the same time, the linear programming method allows for more expressive extensions with retained tractability. Both consistency-based and LP-based methods have attracted attention lately, cf. Giannakopoulou et al. [30] and Kreutzmann and Wolter [44], respectively, and generalisations of the basic concepts have been proposed and analysed by de Leng and Heintz [26].We see that this line of research has to a large extent been based on analysing concrete examples. The approach in this article will be different: instead of studying concrete examples, we study basic principles and aim at providing methods that are applicable to many different constraint formalisms.1.2. Our resultsWe present three different methods. The first two methods are based on analysing the given CSP from a model-theoretical perspective. The third method is more of a toolbox for proving that the size of solutions (i.e., the number of bits needed for representing a solution) grows in a controlled way, and that problems consequently are in NP. We will now describe these methods in slightly more detail.Method I. The first method is based on exploiting ω-categoricity. This is a model-theoretical property of constraint languages and other mathematical structures that have gained a lot of attention in the literature. Briefly speaking, a constraint language (cid:2) is ω-categorical if (cid:2) is the unique countable model (up to isomorphism) of the set of all first-order sentences that are true in (cid:2). One of the interesting aspects of ω-categorical constraint languages is that they in some respects resemble constraint languages over finite domains: this is expressed by a famous result proved by Engeler, Ryll-Nardzewski, and Svenonius (see Theorem 11). From a model-theoretical point of view, ω-categoricity is a very strong assumption. Nevertheless, many interesting CSP problems can be formulated using ω-categorical constraint languages: examples include the point algebra, RCC-5, RCC-8, and Allen’s algebra. Among the ω-categorical constraint languages, the model-complete cores are particularly interesting. Such constraint languages allow us to define gadgets that can be used for simulating constants. This method is applicable to a wide selection of CSP((cid:2)) problems when (cid:2) is ω-categorical. The drawback with the method is that it may be difficult to compute the gadgets used for simulating constants. Given that (cid:2) is an ω-categorical model-complete core and that the gadgets can be computed efficiently, we verify (based on results by Bodirsky [5]) that CSP((cid:2)) is polynomial-time equivalent to CSP((cid:2) ∪ Dc). To demonstrate the strength of this method, we apply it to an extended version of Allen’s algebra. 1 Finite unary relations are sometimes referred to as landmarks in the AI literature. We will use the standard mathematical term throughout the article.\fP. Jonsson / Artificial Intelligence 257 (2018) 1–233This exercise shows, for example, that relations with higher arity than two does not pose any particular problem. This is an important observation since previous work (such as Li et al. [48]) has mostly focused on binary relations.Method II. The second method is based on homogeneity. This is a property of relational structures that has been studied for a long time in mathematics and logic. Some machinery is needed for the formal definition so we refrain from giving it here. However, we note that homogeneous relational structures have many interesting properties: for instance, they allow quantifier elimination and they are ω-categorical whenever the structure contains a finite number of relation symbols and the domain is countably infinite. Even though homogeneity is a very strong property of relational structures, there are many well-known examples within AI and computer science. An early example was provided by Hirsch [33] who proved that Allen’s algebra (with the st",
            {
                "entities": [
                    [
                        133,
                        205,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 186 (2012) 123–156Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for strategyproof classificationReshef Meir a,∗, Ariel D. Procaccia b, Jeffrey S. Rosenschein a,1a School of Engineering and Computer Science, Hebrew University, Jerusalem 91904, Israelb Computer Science Department, Carnegie Mellon University, 5000 Forbes, Pittsburgh, PA 15213, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 25 September 2011Received in revised form 12 March 2012Accepted 26 March 2012Available online 27 March 2012Keywords:Mechanism designClassificationGame theoryApproximationThe strategyproof classification problem deals with a setting where a decision maker mustclassify a set of input points with binary labels, while minimizing the expected error. Thelabels of the input points are reported by self-interested agents, who might lie in order toobtain a classifier that more closely matches their own labels, thereby creating a bias inthe data; this motivates the design of truthful mechanisms that discourage false reports.In this paper we give strategyproof mechanisms for the classification problem in tworestricted settings: (i) there are only two classifiers, and (ii) all agents are interested in ashared set of input points. We show that these plausible assumptions lead to strong positiveresults. In particular, we demonstrate that variations of a random dictator mechanism, thatare truthful, can guarantee approximately optimal outcomes with respect to any family ofclassifiers. Moreover, these results are tight in the sense that they match the best possibleapproximation ratio that can be guaranteed by any truthful mechanism.We further show how our mechanisms can be used for learning classifiers from sampleddata, and provide PAC-style generalization bounds on their expected error. Interestingly,our results can be applied to problems in the context of various fields beyond classification,including facility location and judgment aggregation.© 2012 Elsevier B.V. All rights reserved.1. IntroductionConsider a learning algorithm, which takes a labeled set of samples (“training data”) as input, and outputs a binary clas-sifier. The training data, typically hand-constructed by human experts, is supposed to reflect the knowledge of the expertson the current domain. The basic requirement from such an algorithm is to guarantee that the output classifier minimizesthe number of classification errors with respect to the ‘truth’ (according to the domain experts). Standard machine-learningliterature studies the performance of such algorithms given various distributions and concept classes (e.g., linear classifiers),sparse or noisy data, etc.However in many real-life situations, the experts have a personal interest in the outcome of the algorithm, and thereforethey cannot be assumed to be truthful. If an expert can bias the learned classifier in her favor by lying, then the reportedtraining data will no longer reflect the properties of the domain (or even the properties of the real training data). Optimizinga classifier based on such corrupted data may result in a very poor classifier, regardless of the guarantees supplied bylearning theory (which assumes truthfulness).We consider two interrelated settings. The first setting is decision-theoretic; a decision must be made based on datareported by multiple self-interested agents. The agents are concerned with the binary labels of a set of input points. Put* Corresponding author. Tel.: +972 2 6585188.E-mail addresses: reshef.meir@mail.huji.ac.il (R. Meir), arielpro@cs.cmu.edu (A.D. Procaccia), jeff@cs.huji.ac.il (J.S. Rosenschein).1 Tel.: +972 2 6585353.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.03.008\f124R. Meir et al. / Artificial Intelligence 186 (2012) 123–156another way, the agents may disagree on the labels of the points of the input space, and we do not assume any underlyingdistribution. The utility of an agent with respect to a given decision (i.e., a given classifier) is the number of points onwhich the label provided by the classifier agrees with the agent’s own label. The goal of the decision maker is to choose aclassifier that maximizes the social welfare—the sum of utilities. As we will see, results in this setting can also be appliedto problems in the context of various other fields, including facility location and judgment aggregation.The second setting is learning-theoretic, a variation of the standard Supervised Classification problem. Samples are drawnfrom some distribution over the input space, and are then labeled by experts. A classification mechanism receives thesampled data as input, and outputs a classifier. Unlike the standard setting in machine learning (but similarly to our firstsetting), the experts are assumed to be self-interested agents, and may lie in order to increase their utility. This settingmay seem far more involved than the first, as it deals with generalization from partial data (the dataset) to the underlyingdistribution. However, we show that under the standard assumptions of learning theory, the learning problem effectivelyreduces to finding a classifier that best fits the available data (i.e., to the first setting, above).In both settings the decision maker (or mechanism, or learning algorithm) aims to find a classifier that classifies theavailable data as well as possible. However, the agents may misreport their labels in an attempt to influence the finaldecision in their favor. The result of a decision making process based on such biased data may be completely unexpectedand difficult to analyze. A truthful learning mechanism eliminates any such bias and allows the decision maker to select aclassifier that best fits the reported data, without having to take into account the hidden interests of the agents. In otherwords, once we guarantee that agents are telling the truth, we may concentrate on the more standard goal of minimizingthe error. In order to obtain truthfulness, however, we may need to trade off optimality. Our goal is to provide mechanismsthat are both truthful and approximately optimal in terms of social welfare.1.1. Restrictions on the domainIn recent work [29] we showed that in an unrestricted domain, it is effectively impossible to design truthful mechanismsthat are close to optimal. This motivates the investigation of restricted domains. In this paper we consider several suchrestrictions, described below.1.1.1. Restricting the concept class: two functionsA seemingly simple case is when the concept class contains only two functions. This is equivalent to a (binary) decisionthat has to be made based on data points that are controlled by multiple (possibly) selfish agents, where the decisionaffects all the agents. The decision maker would like to make a decision which is consistent, as much as possible, with allthe available data. However, in our strategic setting the agents might misreport their data in an attempt to influence thefinal decision in their favor.As a motivating example, consider a decision that has to be made by the Workers’ committee of the TAs in the HebrewUniversity, regarding an ongoing strike. Each member of the committee (who represents one department) announces howmany TAs in his/her department support the strike, and how many oppose it. A final decision is made based on totalsupport for the strike. Suppose that 60% of the economics department opposes the strike. However, the representative ofthe economics department majors in game theory. She therefore knows that for the benefit of the majority of TAs in herdepartment, it would be better to state that everybody objects to the strike.21.1.2. Restricting the dataset: shared inputsOur main conceptual contribution in this paper, which leads to strong positive results, is the assumption of shared inputs.In the decision-theoretic setting, this means that the agents share the same set of input points, and only disagree on thelabels of these points. In the learning-theoretic setting, the shared inputs assumption implies that the agents are interestedin a common distribution over the input space, but, once again, differ with respect to the labels.The first restriction we described did not address the issue of shared inputs. However, as the two possible classifiersare constant, the identity of the input points (i.e., their location) is irrelevant—only their labels matter. Hence, the firstrestriction is in fact a very special case of the latter (see also footnote 17).As the shared inputs assumption is a weaker restriction than assuming two functions, the guarantees are also somewhatweaker. Nevertheless, they hold with respect to any concept class. We believe that in many environments the requirement ofshared inputs is satisfied. As an example, consider a large organization that is trying to fight congestion in an internal emailsystem by designing a smart spam filter. In order to train the system, managers are asked to review the last 1000 emailssent to the “all employees” mailing list (hence, shared inputs) and classify them as either “work-related” (positive label) or“spam” (negative label). Whereas the managers will likely agree on the classification of some of the messages (e.g., “BuyViagra now!!!” or “Christmas Bonus for all employees”), it is likely that others (e.g., “Joe from the Sales department goes ona lunch break”) would not be unanimously classified. Moreover, as each manager is interested in filtering most of what hesees as spam, a manager might try to compensate for the “mistakes” of his colleagues by misreporting his real opinion with2 In an attempt to avoid such misrepresentation, major decisions usually require a gathering of all TAs, and the use of a standard voting procedure.However, most decisions are taken with a much narrower quorum.\fR. Meir et al. / Artificial Intelligence 186 (2012",
            {
                "entities": [
                    [
                        145,
                        188,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 185–196www.elsevier.com/locate/artintDetermining the consistency of partial tree descriptionsManuel Bodirsky a,∗, Martin Kutz ba Humboldt-Universität zu Berlin, Germanyb Max-Planck-Institut für Informatik, Saarbrücken, GermanyReceived 1 June 2006; received in revised form 27 November 2006; accepted 15 December 2006Available online 22 December 2006AbstractWe present an efficient algorithm that decides the consistency of partial descriptions of ordered trees. The constraint languageof these descriptions was introduced by Cornell in computational linguistics; the constraints specify for pairs of nodes sets ofadmissible relative positions in an ordered tree. Cornell asked for an algorithm to find a tree structure satisfying these constraints.This computational problem generalizes the common-supertree problem studied in phylogenetic analysis, and also generalizes thenetwork consistency problem of the so-called left-linear point algebra. We present the first polynomial time algorithm for Cornell’sproblem, which runs in time O(mn), where m is the number of constraints and n the number of variables in the constraint.© 2006 Elsevier B.V. All rights reserved.Keywords: Tree descriptions; Constraint satisfaction problems; Graph algorithms; Left-linear point algebra1. IntroductionTree description languages became an important tool in computational linguistics over the last twenty years. Gram-mar formalisms have been proposed that derive logical descriptions of trees representing the syntax of a string [15,23,26]. Membership in a language is then equivalent to the satisfiability of the corresponding logical formula. In se-mantics, the paradigm of underspecification aims at manipulating the partial description of tree-structured semanticrepresentations of a sentence rather than at manipulating the representations themselves [17,25]. One of the key issuesin both constraint-based grammar and constraint-based semantic formalisms is to collect partial descriptions of treesand to solve them, i.e., to find a tree structure that satisfies all constraints.Cornell [13] introduced a simple but powerful tree description language, which contains constraints for dominance,precedence, and equality between nodes, and disjunctive combinations of these (a formal definition is given is Sec-tion 2). Cornell also gave a saturation algorithm based on local propagations, which turned out to be incomplete. Foran example of a tree description that shows this, see Section 3.4 in [3].In this article we present the first polynomial-time algorithm that tests satisfiability of a tree description from Cor-nell’s tree description language and directly constructs a solution to the problem instance, if one exists. A predecessorof this algorithm, which applies to a restricted language, was presented in [4]. The present algorithm, which solves the* Corresponding author.E-mail addresses: bodirsky@informatik.hu-berlin.de (M. Bodirsky), mkutz@mpi-inf.mpg.de (M. Kutz).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.12.004\f186M. Bodirsky, M. Kutz / Artificial Intelligence 171 (2007) 185–196general problem of Cornell’s full tree description language, runs in time O(nm), where n is the number of variablesand m the number of constraints in the input. The performance is achieved by a recursive strategy that works directlyon the constraint graph, and avoids local consistency techniques a la [14,19] that are frequently used in constraintsatisfaction.Significance of the results. Computational linguistics is not the only area in computer science and artificial intelli-gence where partial tree descriptions become relevant. In fact, a fragment of Cornell’s language has been introducedindependently in [12] (also see [16,21]), and is known there as the left-linear point algebra. The best known algorithmfor the so-called network satisfaction problem for the left-linear point algebra has a running time which is in O(n5),where n denotes the size of the input [21]. Since the left-linear point algebra is a fragment of Cornell’s language, ourquadratic time algorithm also yields a new and asymptotically faster algorithm for the left-linear point algebra. Detailsof this connection will be given in Section 3.1.The consistency problem we study can also be posed as a constraint satisfaction problem (CSP), as formalizedin e.g. [8]. The catch here is that the variables might take values from an infinite domain (it can be shown that theproblem cannot be modeled as a CSP with a finite domain); see also Section 3. One important direction of research inthis area is to systematically identify constraint languages that can be solved in polynomial time. In this context, ouralgorithmic result is interesting because it is neither based on group-theoretic techniques such as Gaussian elimination,nor on Datalog and local consistency techniques. This is in contrast to CSPs with finite domains, where all knownalgorithms for polynomial-time solvable algorithms involve at least one of the above two techniques [9,18].In computational biology, phylogenetic analysis is a field where we have to deal with partial information aboutevolutionary trees. An evolutionary tree for a set of species is a rooted tree where the leaves are bijectively labeledwith the species from the set. Constructing evolutionary trees from biological data is a difficult problem for a varietyof reasons (see [20]). Many approaches assume that the evolutionary tree is built from a set of taxa based on thecomparison of a single protein or a single position in aligned protein sequences, but very often the resulting tree willbe different depending on which particular protein or position is used. Several trees, each from a different protein orposition, must be built and be shown to be “generally consistent” before the implied evolutionary history is consideredreliable. The question whether such consistency tests can be automated motivates the so-called common-supertreeproblem [20]. We will describe in Section 3.2 how the common-supertree problem can be modeled in (a fragment of)Cornell’s tree description language. Therefore, the algorithm presented here also yields a new algorithm for (and anew perspective on) the common-supertree problem.Outline. In Section 2, we introduce standard terminology for rooted trees and define Cornell’s tree description lan-guage. This allows us to clearly describe in Section 3 the relationship between our results and results in qualitativetemporal reasoning in artificial intelligence, phylogenetic analysis in computational biology, the left-linear point al-gebra in the theory of relation algebras, and the general framework of constraint satisfaction problems. In Section 5,we introduce an algorithm for a small fragment of Cornell’s language. This fragment is already expressive enough tocapture the common-supertree problem mentioned above. The corresponding consistency-problem is non-trivial in thesense that the algorithm proposed by Cornell is inconsistent already for this fragment (see [3]). However, the simplic-ity of the language allows for a smaller and simpler description of an algorithm that decides consistency. Discussingthis language first will be instructive to deal with the consistency problem for the full language, which is far moreinvolved. For the full language, we first reduce the problem to a simpler tree description language (Section 5), provefundamental results for constraint-graphs that are associated to a partial tree description (Section 6), and finally usethese results to present our algorithm and prove its correctness (Section 7). Section 8 summarizes and poses questionsfor future research.2. Tree descriptionsThe trees considered here are always rooted, and we consider the edges as directed, pointing away from the root.By an ordered tree we mean a rooted tree with a linear order on the children of each vertex and we use the terms leftand right to compare them.We follow the notation of [2]. The set of vertices of a tree T is denoted by VT , and the vertices are usually calledu, v, or w. The expression u (cid:3) v denotes that u is the father of v and u (cid:3)∗ v (and v ∗(cid:4) u) means that u dominates v, i.e.,u is an ancestor of v in the tree (including u = v). We write u (cid:3)+ v (and v +(cid:4) u) if u (cid:3)∗ v and u (cid:5)= v. If for two verticesu and v neither u (cid:3)∗ v nor v (cid:3)∗ u, we say that u and v are disjoint, in symbols u ⊥ v. In this situation we distinguish\fM. Bodirsky, M. Kutz / Artificial Intelligence 171 (2007) 185–196187Fig. 1. The translation of the partial tree description of Fig. 1 into the restricted language.two cases: either u precedes or succeeds v. A vertex u precedes a vertex v (and v succeeds u), in symbols u ≺+ v(and v +(cid:8) u), if there is a common ancestor of u and v in the tree that has two children w1 and w2 with w1 (cid:3)∗ u andw2 (cid:3)∗ v and such that u is to the left of v. We write u ≺∗ v if either u ≺+ v or u = v.The right picture in Fig. 1 shows an example of a rooted tree with root α(x). In pictures we indicate the orderingof the children of a vertex by distinguishing between left and right. Here, α(v) ≺+ α(w) and α(y) ≺+ α(v), andα(x) (cid:3)+ α(w), for example.In an ordered tree, for every pair u, v of vertices exactly one of the following relations holds:+(cid:8) v,+(cid:4) v,u = v.u ≺+u (cid:3)+v,v,uuIt is important to note that the union of the relations (cid:3)+ and ≺+ forms a strict linear order on the set of all verticesof an ordered tree, which is easily seen to be the pre-order that results from a (recursive) tree traversal that lists eachnode before its descendants.We now define partial tree descriptions, due to Cornell [13], that allow to partially describe the structure of anordered tree using arbitrary disjunctions of these five cases. To distinguish clearly between equality in this languageand the common usage of the symbol ‘=’, we de",
            {
                "entities": [
                    [
                        72,
                        128,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 246 (2017) 22–33Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInfinitary equilibrium logic and strongly equivalent logic programs ✩Amelia Harrison a,∗a University of Texas, Austin, TX, USAb Universidad Politécnica de Madrid, Madrid, Spainc University of Málaga, Málaga, Spain, Vladimir Lifschitz a,∗, David Pearce b, Agustín Valverde ca r t i c l e i n f oa b s t r a c tArticle history:Received 20 January 2016Received in revised form 9 November 2016Accepted 8 February 2017Available online 21 February 2017Keywords:Answer set programmingStrong equivalenceLogic of here-and-thereStrong equivalence is an important concept in the theory of answer set programming. Informally speaking, two sets of rules are strongly equivalent if they have the same meaning in any context. Equilibrium logic was used to prove that sets of rules expressed as propositional formulas are strongly equivalent if and only if they are equivalent in the logic of here-and-there. We extend this line of work to formulas with infinitely long conjunctions and disjunctions, show that the infinitary logic of here-and-there characterizes strong equivalence of infinitary formulas, and give an axiomatization of that logic. This is useful because of the relationship between infinitary formulas and logic programs with local variables.© 2017 Elsevier B.V. All rights reserved.1. IntroductionAnswer set programming (ASP) is a form of declarative programming based on the stable model semantics of logic programs [1–7]. The concept of strong equivalence plays an important role in the theory of ASP. Informally speaking, two sets of rules are strongly equivalent if they have the same meaning in any context.Compare, for instance, the rulesq(X, Z ) ← q(X, Y ), q(Y , Z ), p(X), p(Y ), p(Z )and← q(X, Y ), q(Y , Z ), not q(X, Z ), p(X), p(Y ), p(Z ).(1)(2)Both rules express the idea that relation q is transitive on domain p. But in many contexts these rules do not have the same meaning: the effect of adding (1) to a logic program describing p and q is, in general, not the same as the effect of adding (2). The first rule allows us to derive new facts about q; adding it to a program turns relation q into its transitive closure. The second rule is a constraint; adding it weeds out the stable models in which q is not transitive.✩This paper is an invited revision of a paper which first appeared at the 13th International Conference on Logic Programming and Non-monotonic Reasoning.* Corresponding author.E-mail addresses: ameliaj@cs.utexas.edu (A. Harrison), vl@cs.utexas.edu (V. Lifschitz), david.pearce@upm.es (D. Pearce), a_valverde@ctima.uma.es(A. Valverde).http://dx.doi.org/10.1016/j.artint.2017.02.0020004-3702/© 2017 Elsevier B.V. All rights reserved.\fA. Harrison et al. / Artificial Intelligence 246 (2017) 22–33The situation is different, however, if the program to which we add rules (1) and (2) contains the choice rule{q(X, Y )} ← p(X), p(Y )23(3)(“for any X , Y from p, decide arbitrarily whether to include q( X, Y ) in the stable model”). The set consisting of rules (1)and (3) is strongly equivalent to the set consisting of (2) and (3). Consequently, in the presence of choice rule (3), the program obtained by adding (1) has the same stable models as the program obtained by adding (2).According to Lifschitz et al. [8], strong equivalence is closely related to the 3-valued logic called the logic of here-and-there, which was introduced by Arend Heyting [9] long before the invention of computer programming.1 Consider the ground instances of rules (1)–(3):q(t1, t3) ← q(t1, t2), q(t2, t3), p(t1), p(t2), p(t3),← q(t1, t2), q(t2, t3), not q(t1, t3), p(t1), p(t2), p(t3),{q(t1, t2)} ← p(t1), p(t2)(t1, t2, t3 are arbitrary ground terms) and rewrite these ground rules as propositional combinations of ground atoms in the following way:q(t1, t2) ∧ q(t2, t3) ∧ p(t1) ∧ p(t2) ∧ p(t3) → q(t1, t3),¬(q(t1, t2) ∧ q(t2, t3) ∧ ¬q(t1, t3) ∧ p(t1) ∧ p(t2) ∧ p(t3)),p(t1) ∧ p(t2) → q(t1, t2) ∨ ¬q(t1, t2).(4)(5)(6)Formulas (4) and (5) are equivalent to each other in classical logic. But this fact cannot be established in the logic of here-and-there, which is weaker than classical logic. Formula (6) is a tautology; this fact cannot be established in the logic of here-and-there either. On the other hand, the equivalence between the set consisting of formulas of forms (4) and (6)and the set consisting of formulas of forms (5) and (6) can be proved even in this weaker logic. This example illustrates a general fact: two sets of rules written as propositional formulas are strongly equivalent if and only if they are equivalent in the logic of here-and-there [8, Theorem 1].In view of this relationship, proving strong equivalence can be often reduced to reasoning in a system of axioms and inference rules that is sound and complete with respect to the logic of here-and-there. Such formal systems have been known for a long time; see Section 5.1.The proof of the theorem relating strong equivalence to the logic of here-and-there is based on the characterization of stable models in terms of equilibrium logic [10]—a nonmonotonic counterpart of the logic of here-and-there.The statement of the theorem is not restricted to finite sets of formulas. This is important because a single rule with variables has infinitely many ground instances if we allow function symbols (or symbols for arbitrary integers) in ground terms. But some rules found in ASP programs can be represented by sets of propositional formulas only if we allow formulas themselves to be infinite; infinite sets of finite formulas do not suffice. Consider, for instance, the ruleq ← count{ X : p(X)} = 0.(7)The aggregate expression in the body means, informally speaking, that set p is empty. This rule can be thought of as an implication with an infinite conjunction in the body:(cid:2)t¬p(t) → q.Here t ranges over ground terms. The need for infinite conjunctions and disjunctions is common when rules contain local variables, such as X in the example above. Many ASP programs, in particular many programs in the input language of the grounder gringo and its subset, the ASP Core language [11], can be represented by formulas of this type [12].In many cases, first-order formulas can also be used to capture the meaning of ASP programs. For example, rule (7) can be represented using the first-order formula∀x¬p(x) → q.But possibilities of this approach are more limited. For instance, if count in (7) is replaced with sum, or 0 is replaced by a variable, the resulting rule cannot be represented using a first-order formula.In this paper, on the basis of the definition of a stable model for infinitary propositional formulas proposed by Miroslaw Truszczy ´nski [13], we extend to such formulas some definitions and theorems of the theory of strong equivalence and equilibrium logic. Our goals are1 The name “here-and-there” is appropriate in view of the fact that this logic can be described in terms of Kripke frames with two worlds, “Here” and “There.” It is known also as “the logic of present and future” or “the Smetanich logic.”\f24A. Harrison et al. / Artificial Intelligence 246 (2017) 22–33(i) to define the infinitary version of the logic of here-and-there,(ii) to define its nonmonotonic counterpart—the infinitary version of equilibrium logic,(iii) to verify that stable models of infinitary formulas in the sense of Truszczy ´nski can be characterized in terms of infinitary equilibrium logic,(iv) to verify that infinitary propositional formulas are strongly equivalent to each other iff they are equivalent in the infinitary logic of here-and-there,(v) to find an axiomatization of that logic.We will see that achieving goals (i)–(iv) is straightforward, given the work done earlier for finite formulas. Goal (v) is more challenging.A preliminary version of this paper was presented at the 2015 Conference on Logic Programming and Nonmonotonic Reasoning [14]. The material in Sections 2.4 and 5.3 is new to this version.2. Stable models and equilibrium logic in the infinitary setting2.1. Review: infinitary formulasLet (cid:2) be a propositional signature, that is, a set of propositional atoms. The syntax of infinitary formulas defined by Truszczy ´nski [13] can be described as follows. For every nonnegative integer r, (infinitary propositional) formulas (over (cid:2)) of rank r are defined recursively, as follows:• every atom from (cid:2) is a formula of rank 0,• if H is a set of formulas, and r is the smallest nonnegative integer that is greater than the ranks of all elements of H, • if F and G are formulas, and r is the smallest nonnegative integer that is greater than the ranks of F and G, then then H∧and H∨are formulas of rank r,F → G is a formula of rank r.(cid:2)as F ∨ G. The symbols (cid:8) and ⊥ will be understood as abbreviations for ∅∧respectively; ¬F stands for F → ⊥, and F ↔ G stands for (F → G) ∧ (G → F ). These conventions allow us to view We will write {F , G}∧and ∅∨finite propositional formulas over (cid:2) as a special case of infinitary formulas.as F ∧ G, and {F , G}∨A set or family of formulas is bounded if the ranks of its members are bounded from above. For any bounded family (cid:3)(Fα)α∈ A of formulas, we denote the formula {Fα : α ∈ A}∧by α∈ A Fα , and similarly for disjunctions.(cid:3)For example, if p1, p2, . . . and q are atoms then each ¬pi is a formula of rank 1, ¬pi is a formula of rank 2, andi¬pi → q(8)iis a formula of rank 3.Subsets of a signature (cid:2) will be also called interpretations of (cid:2). The satisfaction relation between an interpretation and a formula is defined recursively, as follows:• For every atom p from (cid:2), I |= p if p ∈ I .• I |= H∧• I |= H∨• I |= F → G if I (cid:13)|= F or I |= G.if for every formula F in H, I |= F .if there is a formula F in H such that I |= F .A model of a set H of infinitary formulas is an interpretation that satisfies all formulas in H. ",
            {
                "entities": [
                    [
                        134,
                        201,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 319 (2023) 103915Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintAutomated streamliner portfolios for constraint satisfaction problemsPatrick Spracklen, Nguyen Dang, Özgür Akgün∗, Ian MiguelSchool of Computer Science, University of St Andrews, St Andrews, Fife, KY16 9SX, UKa r t i c l e i n f oa b s t r a c tArticle history:Received 22 January 2022Received in revised form 20 March 2023Accepted 24 March 2023Available online 29 March 2023Keywords:Constraint programmingConstraint modellingConstraint satisfaction problemAlgorithm selectionConstraint Programming (CP) is a powerful technique for solving large-scale combinatorial problems. Solving a problem proceeds in two distinct phases: modelling and solving. Effec-tive modelling has a huge impact on the performance of the solving process. Even with the advance of modern automated modelling tools, search spaces involved can be so vast that problems can still be difficult to solve. To further constrain the model, a more aggressive step that can be taken is the addition of streamliner constraints, which are not guaranteed to be sound but are designed to focus effort on a highly restricted but promising portion of the search space. Previously, producing effective streamlined models was a manual, difficult and time-consuming task. This paper presents a completely automated process to the gen-eration, search and selection of streamliner portfolios to produce a substantial reduction in search effort across a diverse range of problems. The results demonstrate a marked im-provement in performance for both Chuffed, a CP solver with clause learning, and lingeling, a modern SAT solver.© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionChallenging combinatorial problems, from domains such as planning, scheduling, packing or configuration, often form problem classes: families of problem instances related by a shared high-level specification, with a common set of free pa-rameters. Constraint Programming (CP) and Propositional Satisfiability solving (SAT) offer powerful, complementary means to solve these problem classes. For either formalism, a model must be formulated, which describes the problem class in a format suitable for input to the intended solver. Since the search spaces involved can be vast, however, sometimes the model initially formulated for a problem class may give instances where it is too difficult for the solver to find a solution in a timely mannerIn response, a natural step is to constrain the model further in order to strengthen the inferences the solver can make, therefore detecting dead ends in the search earlier and reducing overall search effort. One approach is to add im-plied constraints, which can be inferred from the initial model and are therefore guaranteed to be sound. Manual [1,2]and automated [3–5] approaches to generating implied constraints have been successful. Other approaches include adding symmetry-breaking [6–9] and dominance-breaking constraints [10–12], both of which rule out members of equivalence classes of solutions while preserving at least one member of each such class.* Corresponding author.E-mail addresses: jlps@st-andrews.ac.uk (P. Spracklen), nttd@st-andrews.ac.uk (N. Dang), ozgur.akgun@st-andrews.ac.uk (Ö. Akgün), ijm@st-andrews.ac.uk (I. Miguel).https://doi.org/10.1016/j.artint.2023.1039150004-3702/© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fP. Spracklen, N. Dang, Ö. Akgün et al.Artificial Intelligence 319 (2023) 103915Fig. 1. Essence specification of the Car Sequencing Problem [14], shown to be NP-complete [15]. A number of cars (n_cars) are to be produced; they are not identical, because different classes (n_classes) are available (quantity) as variants on the basic model. The assembly line has different stations which install the various options (n_options) such as air conditioning and sun roof (each class of cars requires certain options, represented by usage). A maximum number of cars (maxcars) requiring a certain option can be sequenced within a consecutive subsequence block (blksize), otherwise the station will not be able to cope.If these techniques are inapplicable, or improve performance insufficiently, for satisfiable problems a more aggressive step is to add streamliner constraints [13], which are not guaranteed to be sound but are designed to focus effort on a highly restricted but promising portion of the search space. Streamliners trade the completeness (i.e. failing to find a solution when there is one) offered by implied, symmetry-breaking and dominance-breaking constraints for potentially much greater search reduction.Previously, producing effective streamlined models was a difficult and time-consuming task. It involved manually in-specting the solutions of small instances of the problem class in question to identify patterns to use as the basis for streamliners [13,16–18]. For example, Gomes and Sellmann [13] added a streamliner requiring a Latin Square structure when searching for diagonally ordered magic squares.The principal contribution of this paper is to demonstrate how a powerful range of streamliners can be generated and applied automatically. Our approach is situated in the automated constraint modelling system Conjure [19–21]. This system takes as input a specification in the abstract constraint specification language Essence [22,23]. Fig. 1 presents an example specifi-cation, which asks us to sequence cars on a production line so as not to exceed the capacity of any station along the line, each of which installs an option such as sun roof. Essence supports a powerful set of type constructors, such as set, multi set, function and relation, hence Essence specifications are concise and highly structured. Existing constraint solvers do not support these abstract decision variables directly. Therefore we use Conjure to refine abstract constraint specifications into concrete constraint models, using constrained collections of primitive variables (e.g. integer, boolean) to represent the abstract structure. The constraint modelling assistant tool Savile Row [24,25] is then used for producing solver dependent input. Savile Row supports several solving paradigms, including CP, SAT and SMT (satisfiability modulo theories).Our method exploits the structure in an Essence specification to produce streamlined models automatically, for example by imposing streamlining constraints on the function present in the specification in Fig. 1. The modified specification is refined automatically into a streamlined constraint model by Conjure. Identifying and adding the streamlining constraints at this level of abstraction is considerably easier than working directly with the constraint model, which would involve first recognising (for example) that a certain collection of primitive variables and constraints together represent a function – a potentially very costly process. Moreover, recovering high-level information from a low-level model expressed in a lower level constraint modelling language like OPL [26], MiniZinc [27] or Essence Prime [28] would be brittle with respect to the exact heuristics and modelling reformulations used inside Conjure and Savile Row. As with automated symmetry breaking during modelling [29,20], automated streamlining therefore motivates the adoption of a higher level language such as Essence and letting automated tools work out the best compilation – just as has happened in general programming languages.Our streamlining system completely automates the original manual process defined by Gomes and Sellmann [13]. As per their method, it does require an initial investment in generating and testing streamliners for the problem class at hand, but this effort is repaid in two ways. First, we assume a context common across automated algorithm selection [30] and machine learning in general: we expect to solve a large number of instances of the problem class, and so the effort made to formulate the best model that we can is amortised over that substantial solving effort. Second, successful streamlining can result in a vast reduction in search effort, allowing us to solve much harder instances than would otherwise be practically feasible. Our work significantly expands previous work on automated streamliner generation from high-level problem specifications [31]and automatic selection of streamlining constraints [32].2\fP. Spracklen, N. Dang, Ö. Akgün et al.Artificial Intelligence 319 (2023) 103915Fig. 2. Solving a problem instance using a streamlined Essence specification. Conjure is run once for a streamlined model, whereas Savile Row and the selected solver is run once per instance. The streamliner that is provided as input to Conjure is generated by a separate call to Conjure as part of Phase 1(Candidate Streamliner Generation).We demonstrate the effectiveness of our approach on both the CP and SAT solving paradigms, choosing representa-tive solvers for each. For CP, we use the learning solver chuffed [33], and for SAT, we use lingeling [34]. As presented in Section 8, our method can often produce a substantial reduction in search effort across a diverse range of problems. The automated streamlining system, Essence problem specifications and all the data used in this work for computational evaluation are available at https://www.github .com /stacs -cp /automated -streamliner-portfolios (see [35]).2. Architecture overviewWe begin with an overview of the architecture of our system, before explaining each of its components in detail in the subsequent sections. Given a problem class of interest, our streamlining approach proceeds in three main phases. Firstly, candidate streamliners are generated",
            {
                "entities": [
                    [
                        153,
                        222,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 99 (1998) 73-119 Artificial Intelligence Geometric construction by assembling solved subfigures ’ Jean-Fraqois Dufourd *, Pascal Mathis *, Pascal Schreck 3 Laboratoire ties Sciences de l’ltnage, de l’lnformatique et de la T&ditection (L.S.i.I.T, URA CNRS 1871), Universite Luuis Pasteur, 7, rue Rene’ Descartes, 67084 Strasbourg, France Received June 1996 Abstract Among thle expected contributions of Artificial Intelligence to Computer-Aided Design is the possibility of constructing a geometric object, the description of which is given by a system of topological and dimensional constraints. This paper presents the theoretical foundations of an original approach to formal geometric construction of rigid bodies in the Euclidian plane, based on invariance under displacements and relaxation of positional constraints. This general idea allows to explain in greater detail several methods proposed in the literature. One of the advantages of this approach is its ability to efficiently generalize and join together different methods for local solving. The paper also describes the main features of a powerful and extensible operational prototype based on these ideas, which can be viewed as a simple multi-agent system with a blackboard. Finally, some significant examples solved by this prototype are presented. @ 1998 Elsevier Science B.V. Keywords: Geometric solving; Assembling formal construction; System of geometric constraints; Computer-aided of figures; Multi-agent system; Blackboard design; Local 1. Introduction Following Intelligence * Corresponding ’ This research the seminal work of Sutherland to Computer-Aided Design [ 521, an expected contribution is the possibility (CAD) of building of Artificial a 3D author. Email: dufourdadpt-info.u-strasbg.fr. is supported by the GDR-PRC de Programmation and GDR-PRC Algorithmique. Mod2les et Infographie (French CNRS) * Email: mathis@dpt-info.u-strasbg.fr. 3 Email: schreck@dpt-info.u-strasbg.fr. 0004-3702/98r’$19.00 PlISOOO4-3’102(97)00070-2 @ 1998 Elsevier Science B.V. All rights reserved. \f14 J.-E Dufourd et al. /Artificial Intelligence 99 (1998) 73-119 for its topology and rigid object defined by a system of geometric constraints [45] embedding. The and adjacency constraints topological tools hide the setting of these constraints express of the object, namely incidence relationships its vertices, edges and faces. Usually, the components drawing composition of the object. The embedding of the object. The designer gives them as a system of dimensions constraining ponents of a sketch. The problem constraints. When between in CAD, functional de- the form and the metrics the com- is then to build components which satisfy all these into real number equations, we come upon the so-called constraints translating express during them or transcendental solving a system of polynomial ally been approached using graphs Newton-Raphson and drawbacks of such an approach have often been described [ 28,44,54]. in a purely numerical way, sometimes the method initial [ 35,391 or the homotopy-based method into subsystems. That to split system the problem of equations. Such a question has gener- often the after preprocessing, is the case with [ 301. Advantages in the literature, e.g. in interpretation As stated in [ 1,2], to tackle this question it seems to us interesting in two phases. The first phase is a solving process yielding a formal construction plan, and the second one is a numerical several numerical of approximation the formal expression of a geometric construction corresponding Formally of the construction plan. This way, the possibility of producing errors and failures can be fairly diagnosed. Moreover, the solutions are not propagated is preserved, problems of convergence is a powerful means of rendering object generic. are eliminated, solving systems of geometric constraints as encountered constructions [ 11,18,46-481. to the ones encountered In CAI, one wants area and studied in the plane has many similarities in education So, dimensioning in a sketch graphi- in high-school mathematics. to obtain all the solutions in the Instruction with solving geometric Computer-Aided cally sets a constraint The aims, however, are quite different. and discuss general case the most plausible (CAI) system similar solution. them, even in degenerate cases, while, in CAD, one expects to obtain Formal solving appears in some CAD knowledge-based in common with geometric mechanical systems, e.g. [ 1,8,16]. Such provers based efficient methods like constraint graph decomposition [22]. Moreover, systems have several aspects on axiomatics [ 27,4 1 ] or progressive a two-phase and cannot be applied easily figure rigid$cation treatment. But these methods are restricted to any geometric universe. [ 50,5 1,54,55] could be reconsidered using types of constraints to specific This question has also been solving [ 15,561. Restrictions tackled by computer algebra systems is quite similar For to automatic proving based on formal or size of the solved criticisms of this approach. algebra as well as with solving, one must work with systems of equations whose variables are the formal such systems, polynomial reasoning systems and the tedious calculation But surely, numerical coordinates involved are common is that both with computer of the geometric objects rather than the geometric objects the main drawback on the generality themselves. [ 19,20,32]. In this paper, we present a general constraints as encountered in CAD formal to specify framework rigid body. We propose for systems of geometric an original \fJ.-E Dufourd et al. /Artijicial Intelligence 99 (1998) 73-l I9 75 in in [7], literature [7,30,41,50,51], under displacements and proposed invariance for a solving process based on specifies the methodological in particular by formalizing approach solving of parts. This framework the systems and computed metric constraints, its use of two used ilar to ours. There are however considerable the content of the two levels, and the numerical over, besides proach ical tion. local foundation in the assembling of sub- using what we call a border. The approach looks sim- concepts, than formal character. More- of our ap- including ones based on numer- It has great solving power and wide applica- local and global, in its underlying to encompass different methods, differences rather for common problems, one of the advantages levels of construction, and computer its efficiency is its ability iterations algebra. Next, we present the current implementation of our framework, a prototype which works by using assembling employing differ- in the plane using and local solving tactics. We describe ent strateg.ies and two phases, one formal and one interpretative, methods. These methods are two knowledge-based and use method is closely of methods, [ 131. Finally, related we give several examples of significant problems which have been solved by the proto- on the general characteristics rather than on technical details. We show that our CAD prototype [ 35,391. We focus here on assembling, systems and the Newton-Raphson systems with a blackboard Intelligence multi-agent to .4rtificial type. The structure of the paper is as follows. Section 2 gives an example of an easy to universe solved using our method. Section 3 outlines and systems of constraints. understand problem the formal framework for the geometric the formal solving method and the assembling, of workable to make this framework effective. Sec- the prototype. Section 7 shows on three examples how they can tion 6 briejly presents be used. Section 8 compares our propositions with other works, and Section 9 concludes our discussion. strategies with local solving methods together. Section 5 presents Section 4 defines indications some 2. An example of geometric construction with assembling Our method allows us to build step by step geometric constructions in the Euclidian solving parts of the system of constraints and assembling the principles of this approach in the example them by illustrated by plane by locally displacements. We examine the constraint system of Fig. 1. Fig. 1 represents a dimensional part where characteristic points, curves and numerical values are respectively named a, . . . , g, r and kl , . . . , k5, (~1, . . . ~y3, in order to specify constraints. double-arrow differs according In the example, kl corresponds lines. to a constraint of distance between points a and b, and k5 to a constraint of distance between point e and oriented In the technical drawing area, the meaning of a dimensional to the positions of the joined line fg. Fig. 1 specifies all the constraints imposed on our sketch, point b. Some constraints constraints of tangency, are drawn in the figure by dimensions, are implicit. The question of transforming the hexagon cdefga with like into explicit and others, them \f16 J.-E Dufourd et al. /ArtQicial Intelligence 99 (1998) 73-119 Fig. 1. A constraint system. the scope of this paper. We thus consider in the following that we constraints have a problem is beyond textually set by: distance distance distance distance distance distance from point LL to point b = kl from point a to point g = k2 from point c to point d = k3 from point d to point e = k4 from point e to oriented from point f to point g = k6 line dc to oriented line fe to oriented line ba to oriented angle from oriented angle from oriented angle from oriented line fg = k5 line de = al line fg = a2 line bc = ~3 points a, b, g are collinear is a circular arc curve r oriented oriented line ab is tangent line bc is tangent to r at a to r at c It must be completed by topological constraints coming lines and points-circles produce neither a drawing nor numerical values us, a solution must have the form of a simple program of construction, being implicitly given, it is impossible from the drawing, e.g. points- to to solve the system of constraints. For that we call a incidence. Dimens",
            {
                "entities": [
                    [
                        65,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1407–1429Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintImplementing logical connectives in constraint programmingChristopher Jefferson b, Neil C.A. Moore b, Peter Nightingale b,∗, Karen E. Petrie aa School of Computing, University of Dundee, Dundee DD1 4HN, UKb School of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 31 July 2009Received in revised form 30 June 2010Accepted 2 July 2010Keywords:Constraint programmingConstraint satisfaction problemsPropagation algorithmsLogical connectivesCombining constraints using logical connectives such as disjunction is ubiquitous inconstraint programming, because it adds considerable expressive power to a constraintlanguage. We explore the solver architecture needed to propagate such combinations ofconstraints efficiently. In particular we describe two new features named satisfying sets andconstraint trees. We also make use of movable triggers (Gent et al., 2006) [1], and with thesethree complementary features we are able to make considerable efficiency gains.A key reason for the success of Boolean Satisfiability (SAT) solvers is their ability topropagate Or constraints efficiently, making use of movable triggers. We successfullygeneralise this approach to an Or of an arbitrary set of constraints, maintaining the crucialproperty that at most two constraints are active at any time, and no computation at allis done on the others. We also give an And propagator within our framework, whichmay be embedded within the Or. Using this approach, we demonstrate speedups of over10,000 times in some cases, compared to traditional constraint programming approaches.We also prove that the Or algorithm enforces generalised arc consistency (GAC) when allits child constraints have a GAC propagator, and no variables are shared between children.By extending the Or propagator, we present a propagator for AtLeastK, which expressesthat at least k of its child constraints are satisfied in any solution.Some logical expressions (e.g. exclusive-or) cannot be compactly expressed using And, Orand AtLeastK. Therefore we investigate reification of constraints. We present a fast genericalgorithm for reification using satisfying sets and movable triggers.© 2010 Published by Elsevier B.V.1. IntroductionProblems often consist of choices. Making an optimal choice which is compatible with all other choices made is difficult.Constraint programming (CP) is a branch of Artificial Intelligence, where computers help users to make these choices. Con-straint programming is a multidisciplinary technology combining computer science, operations research and mathematics.Constraints are a powerful and natural means of knowledge representation and inference in many areas of industry andacademia, arising in design and configuration; planning and scheduling; diagnosis and testing; and in many other contexts.A constraint satisfaction problem (CSP [2]) is a set of decision variables, each with an associated domain of potential values,and a set of constraints. For example, the problem might be to fit components (values) to circuit boards (decision variables),subject to the constraint that no two components can be overlapping. An assignment maps a variable to a value from itsdomain. Each constraint specifies allowed combinations of assignments of values to a subset of the variables. A solution to a* Corresponding author.E-mail addresses: caj@cs.st-andrews.ac.uk (C. Jefferson), ncam@cs.st-andrews.ac.uk (N.C.A. Moore), pn@cs.st-andrews.ac.uk (P. Nightingale),kpetrie@computing.dundee.ac.uk (K.E. Petrie).0004-3702/$ – see front matter © 2010 Published by Elsevier B.V.doi:10.1016/j.artint.2010.07.001\f1408C. Jefferson et al. / Artificial Intelligence 174 (2010) 1407–1429CSP is an assignment to all the variables which satisfies all the constraints. In this paper we consider solving CSPs throughbacktrack search with an inference step at each node [2].Modelling is the process of representing a problem as a CSP. To allow natural modelling of some problems, the logicalconnectives of And and Or are required between constraints. For example, in a school timetabling problem you may haveeither Teacher1 Or (Teacher2 And Teacher3) taking a particular class. It is also sometimes useful to be able to apply Not toa constraint, this is often done in CSP by means of reification. The reification of a constraint C produces another constraintCr , such that Cr has an extra Boolean variable r in its variable set, and (in any solution) r is set to true if and only if theoriginal constraint C is satisfied. In this paper we discuss the neglected area of how to efficiently implement these logicalconnectives across constraints, which are the fundamental building blocks of CSP models [3] (Chapter 11).During the search for a solution of a CSP, constraint propagation algorithms are used. These propagators make inferences,recorded as domain reductions, based on the domains of the variables constrained. If at any point these inferences result inany variable having an empty domain then search backtracks and a new branch is considered. Propagators and generalisedarc consistency (GAC) are important concepts in this paper. When considering a single constraint C , GAC is the strongestpossible consistency that a propagation algorithm can enforce. Enforcing GAC removes all domain values which are notcompatible with any solution of C . In [3] (Chapter 3), Bessiere defines GAC and discusses the complexity of enforcing it.In this paper we consider propagating logical combinations of constraints. For example, for constraints C1, C2, C3, C4 wemay wish to post the following expression and propagate it efficiently.(C1 ∧ C2) ⇒ (C3 ∨ C4)It is desirable to make use of existing propagators for C1, C2, C3 and C4 since these may be highly efficient specialisedpropagators.1.1. A traditional approachA traditional approach (probably the most common) is to individually create reified propagators for the four constraints.These introduce an additional Boolean variable representing the truth of the constraint (e.g. the reified form of C1 is theconstraint r1 ⇔ C1, so in any solution r1 is True if and only if C1 is satisfied). A logical expression can be enforced on theadditional Boolean variables to obtain the desired combination. The example above translates into the following collectionof constraints1:r1 ⇔ C1,(r1 ∧ r2) ⇒ (r3 ∨ r4)r3 ⇔ C3,r2 ⇔ C2,r4 ⇔ C4,This scheme has three major disadvantages. First, it can be very inefficient because every reified constraint is propagatedall the time. For example consider an Or of a set of n constraints. As we will demonstrate in Section 4, at most twoconstraints need to be actively checked at any time. However, a reification approach will propagate all n reified constraintsat all times. Second, developing reified propagators individually for each constraint is a major effort. Third, when a variableoccurs multiple times in an expression, the reified decomposition may propagate poorly. In this paper we address the firsttwo issues but not the third: we achieve the same level of consistency as the reified decomposition.1.2. Two vital features of a solver for a new approachThe key finding of this work is that two vital features of the solver must be combined to achieve efficient propagationof logical connectives. If either feature is not available, then the other is of limited benefit. The two features are constrainttrees, which allow a parent constraint to control the propagation of its children, and movable triggers which allow a constraintto change the events [3] (Chapter 14) it is interested in during search.Consider an Or of n constraints over disjoint variable sets. We will show that at most two of the constraints need to beconsidered at any time, because if two of the constraints are satisfiable then no propagation can occur. Once two satisfiableconstraints have been identified, all other constraints are presently irrelevant and no computation time should be wastedon them. This is essential to efficiency when n is large.Constraint trees allow us to stop checking irrelevant constraints. However, this is not enough to achieve zero cost forirrelevant constraints: there is a cost to generate trigger events for the constraints. It is necessary to remove triggers notcurrently of interest, hence movable triggers are also required.The following table summarises the costs caused by irrelevant constraints.ReificationConstraint treesStatic triggersAll reified constraintspropagated at all timesTrigger events received forall constraints at all timesMovable triggersAll reified constraintspropagated at all timesIrrelevant constraintscause no cost1 In some solvers it would be necessary to further decompose (r1 ∧ r2) ⇒ (r3 ∨ r4).\fC. Jefferson et al. / Artificial Intelligence 174 (2010) 1407–14291409Our implementations are in the Minion solver [4], though the presentation is not specific to Minion.1.3. OverviewThere are a number of solver architecture decisions which impinge on propagating logical combinations of constraints.In Section 3 we describe three architecture features which are key to the new algorithms presented in this paper. Satisfyingsets (Section 3.3) are novel to the best of our knowledge. We also provide the first implementation of constraint trees(Section 3.2). Movable triggers [1] are also described in Section 3.1 to aid understanding of the rest of the paper.In Section 4, we present a propagator for the constraint AtLeastK, which ensures that at least k of a set of constraintsare satisfied in any solution. Both And and Or are special cases of AtLeastK. Via the constraint trees framework, AtLeastKconstraints may be nested to any depth, and also may be reified using the algorithms given in Section 5. The AtLeastKpropagator maintains the crucial property that only k + 1 constraints are ",
            {
                "entities": [
                    [
                        138,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 220–235Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDealing with logical omniscience: Expressiveness and pragmatics ✩Joseph Y. Halpern a, Riccardo Pucella b,∗a Cornell University, Ithaca, NY 14853, USAb Northeastern University, Boston, MA 02115, USAa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:LogicKnowledgeLogical omniscienceAwarenessImpossible worldsProbability1. IntroductionWe examine four approaches for dealing with the logical omniscience problem and theirpotential applicability: the syntactic approach, awareness, algorithmic knowledge, and im-possible possible worlds. Although in some settings these approaches are equi-expressiveand can capture all epistemic states, in other settings of interest (especially with proba-bility in the picture), we show that they are not equi-expressive. We then consider thepragmatics of dealing with logical omniscience—how to choose an approach and constructan appropriate model.© 2010 Elsevier B.V. All rights reserved.John McCarthy was a pioneer in the use of reasoning about knowledge in AI. His notion of what “any fool” knows, oneof the earliest uses of common knowledge, goes back to roughly 1970; it first appears in a published paper in [21]. It thusseems particularly appropriate for a paper on logics of knowledge to appear in this special issue of Artificial Intelligencededicated to John McCarthy and his work.Like most authors, McCarthy gave “possible-worlds” style semantics to knowledge. Logics of knowledge based onpossible-worlds semantics have been shown to be useful in many areas of knowledge representation and reasoning, rangingfrom security to distributed computing to game theory. In these models, an agent is said to know a fact ϕ if ϕ is true inall the worlds she considers possible. While reasoning about knowledge with this semantics has proved useful, as is wellknown, it suffers from what is known in the literature as the logical omniscience problem: under possible-world semantics,agents know all tautologies and know the logical consequences of their knowledge.While logical omniscience is certainly not always an issue, in many applications it is. For example, in the context ofdistributed computing, we are interested in polynomial-time algorithms, although in some cases the knowledge neededto perform optimally may require calculations that cannot be performed in polynomial time (unless P = NP) [26]; in thecontext of security, we may want to reason about computationally bounded adversaries who cannot factor a large compositenumber, and thus cannot be logically omniscient; in game theory, we may be interested in the impact of computationalresources on solution concepts (for example, what will agents do if computing a Nash equilibrium is difficult).Not surprisingly, many approaches for dealing with the logical omniscience problem have been suggested (see [10, Chap-ter 9] and [25]). A far from exhaustive list of approaches includes:• syntactic approaches [5,24,18], where an agent’s knowledge is represented by a set of formulas (intuitively, the set offormulas she knows);• awareness [7], where an agent knows ϕ if she is aware of ϕ and ϕ is true in all the worlds she considers possible;✩A preliminary version of this paper appeared in the Proceedings of the 11th Conference on Theoretical Aspects of Rationality and Knowledge, 2007, pp. 169–176.* Corresponding author.E-mail addresses: halpern@cs.cornell.edu (J.Y. Halpern), riccardo@ccs.neu.edu (R. Pucella).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.009\fJ.Y. Halpern, R. Pucella / Artificial Intelligence 175 (2011) 220–235221• algorithmic knowledge [12] where, roughly speaking, an agent knows ϕ if her knowledge algorithm returns “Yes” on a• impossible worlds [29], where the agent may consider possible worlds that are logically inconsistent (for example, wherequery of ϕ; andp and ¬p may both be true).Which approach is best to use, of course, depends on the application. One goal of this paper is to elucidate the aspectsof the application that make a logic more or less appropriate. We start by considering the expressive power of theseapproaches. In Section 3, we examine the expressiveness of the approaches for a general epistemic logic. It may seemthat there is not much to say with regard to expressiveness, since it has been shown that all these approaches are equi-expressive and, indeed, can capture all epistemic states (see [31,10] and Section 2). However, this result holds only if weallow an agent to consider no worlds possible. As we show, this equivalence no longer holds in contexts where agents mustconsider some worlds possible.This difference in expressive power is particularly relevant once we have probability in the picture. In Section 4, weexamine the logical omniscience problem in the context of an epistemic logic that can talk explicitly about probability, withformulas of the form K ((cid:3)(Primen) = 1/3), read “the agent knows that the probability that Primen is true is 1/3”. We showthat in the presence of probabilities, the approaches to dealing with logical omniscience that make sense in this setting arenot equi-expressive.But expressive power is only part of the story. We consider here (mainly by example) the pragmatics of dealing withlogical omniscience—an issue that has largely been ignored: how to choose an approach and construct an appropriatemodel. In Section 5, we examine the four main approaches to logical omniscience, and identify some guiding principles forchoosing an approach to model a situation, based on the source of the lack of logical omniscience in that situation. Comingup with an appropriate structure can be nontrivial. As a specific contribution, we illustrate a general approach to deriving animpossible-worlds structure based on an implicit description of the situation, which seems to be appropriate for a numberof situations of interest.2. The four approaches: a reviewWe now review the standard possible-worlds approach and the four approaches to dealing with logical omnisciencediscussed in the introduction. For ease of exposition we focus on the single-agent propositional case. While in many appli-cations it is important to consider more than one agent and to allow first-order features (indeed, this is true in some ofour examples), the issues that arise in dealing with multiple agents and first-order features are largely orthogonal to thoseinvolved in dealing with logical omniscience. Thus, we do not discuss these extensions here.2.1. The standard approachWe define a propositional language LK of knowledge. Starting with a set Φ of primitive propositions, we close off underconjunction (∧), negation (¬), and the K operator. As usual, we consider ϕ ∨ ψ to be an abbreviation for ¬(¬ϕ ∧ ¬ψ), andϕ ⇒ ψ to be an abbreviation for ¬ϕ ∨ ψ . K ϕ will usually be read as “the agent knows ϕ”, but because K ϕ ⇒ ϕ will notalways hold in our models, K ϕ will sometimes have a more natural reading as “the agent believes ϕ”. None of our resultsdepend on the reading of the operator.We give semantics to LK formulas using Kripke structures. For simplicity, we focus on approaches that satisfy the K45(cid:6), π ), where W is a nonemptyaxioms (as well as KD45 and S5).1 In this case, a K45 Kripke structure is a triple (W , W(cid:6) ⊆ W is the set of worlds that the agent considers possible, and π is anset of possible worlds (or worlds, for short), Winterpretation that associates with each world a truth assignment π (w) to the primitive propositions in Φ. Note that theagent need not consider every possible world (that is, each world in W ) possible. Then we have(M, w) |(cid:8) p iff π (w)(p) = true, where p ∈ Φ.(M, w) |(cid:8) ¬ϕ iff (M, w) (cid:10)|(cid:8) ϕ.(M, w) |(cid:8) ϕ ∧ ψ iff (M, w) |(cid:8) ϕ and (M, w) |(cid:8) ψ .(M, w) |(cid:8) K ϕ iff (M, w(cid:6)) |(cid:8) ϕ for all w(cid:6) ∈ W.(cid:6)This semantics suffers from the logical omniscience problem. In particular, one sound axiom is(cid:2)(cid:3)K ϕ ∧ K (ϕ ⇒ ψ)⇒ K ψ,which says that an agent’s knowledge is closed under implication. In addition, the knowledge generalization inference rule issound:From ϕ infer K ϕ.1 We could extend the investigation in this paper to more general structures satisfying weaker axioms, but consider the more standard setting sufficesfor the points we want to make. We expect similar results to the ones we obtain here to hold for more general structures, but have not checked the details.\f222J.Y. Halpern, R. Pucella / Artificial Intelligence 175 (2011) 220–235Thus, agents know all tautologies. As is well known, two other axioms are sound in K45 Kripke structures:K ϕ ⇒ K K ϕand¬K ϕ ⇒ K ¬K ϕ.These are known respectively as the positive and negative introspection axioms. (These properties characterize K45.)In the structures we consider, we allow Wto be empty, in which case the agent does not consider any worlds possible.(cid:6), π ) where(cid:6) (cid:10)= ∅. Thus, in a KD45 Kripke structure, the agent always considers at least one world possible. In KD45 Kripke structures,In such structures, K ϕ is true for all ϕ, including false. A KD45 Kripke structure is a K45 Kripke structure (W , WWthe axiom(cid:6)¬K (false)is sound, which implies that the agent cannot know inconsistent facts. The logic KD45 results when we add this axiom toK45. S5 Kripke structures are KD45 Kripke structures where W = W; that is, the agent considers all worlds in W possible.In S5 Kripke structures, the axiom(cid:6)K ϕ ⇒ ϕ,which says that the agent can know only true facts, is sound. Adding this axiom to the KD45 axioms gives us the logic S5.2.2. The syntactic approachThe intuition behind the syntactic approach for dealing with logical omniscience is simply to explicitly list, at every pos-(cid:6), π , C), where(cid:6), π ) is a K45 Kripke structure and C associates a set of formulas C(w",
            {
                "entities": [
                    [
                        136,
                        199,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER. Artificial Intelligence 83 ( 1996) 267-295 Artificial intelligence Relation algebras of intervals Robin Hirsch ’ Department of Computer Science, University College, London WCIE 6BX UK Received February 1994; revised March 1995 Abstract If the representation happens to be complete, homogeneous Given a representation of a relation algebra we construct relation algebras of pairs and of then intervals. the pair and interval algebras can be constructed direct from the relation algebra. If, further, the original relation algebra is w-categorical we show that the interval algebra is too. The complexity of relation algebras is studied and it is shown that every pair algebra with infinite representations is intractable. Applications include constructing an interval algebra that combines metric and interval expressivity. and fully universal 1. Introduction interest systems to describe in reasoning for temporal that can handle There has been considerable reasoning. For many applications intervals, it turns out that formalisms particularly lack the expressive power required the situation adequately. based on points instead of points as the basic entities significantly increases the expressive Using intervals power but., in general, involves a loss of tractability. Interval reasoning is important in all those applications that involve interfering processors, multi-agents or interactions with the environment. The application might require us to say that “one process takes place while another property holds” or “two actions have disjoint duration”. One of the most powerful algebraic tools for temporal reasoning is relation algebra. This has given some very general results about the decidability and completeness of systems of binary relations (for a good survey see [ 251, see also ) and might also be useful for considering questions of complexity. A background knowledge in relation algebra is certainly an advantage when reading this paper, though terms are defined as [ 3,4,10,19,20,24] ’ Supported by SERC grant reference: GR/H46343. Many thanks to Ian Hodkinson and Mark Reynolds for their contribution to this work. E-mail: R.Hirsch@cs.ucl.ac.uk. 0004-3702/96/$15.00 SSDIOOO4-3702(95)00042-9 @ 1996 Elsevier Science B.V. All rights reserved \f268 R. Hir.wh/Art@cial Intelligence 83 (1996) 267-295 they are introduced. Background others, study of relation algebras may be found the previously reading in [ 221. cited works and [ 5,9,11,12,15,21,26]. in relation algebra includes, amongst many A good history of the The idea in this paper is to see how relation algebras can be used to handle interval reasoning. Section 2 gives the basic definitions for relation algebras and their representations to consist of binary together with some properties of representations. relation algebra-intended interval algebras from w-categorical pair algebras are intractable. A number of concepts construction, Although like homogeneity it has a somewhat if the original point algebra it. In Section 5 it is shown theoretical relations on points-and In Section 4 we show how to take a build pair and is all theory are used in this that a pair or interval algebra is. In Section 6 we show that virtually from model flavour, this work is very applicable. A number of attempts have been made reasoning with quantitative metric expressivity. Section 7 starts from a point-based metric system and gives a con- struction of an interval algebra which achieves and has some advantage over its competitors. to combine qualitative that combination interval and universality, but they are defined in the text. 2. Basics Definitions the boolean operations, l A proper relation algebra is a set of binary relations over some domain D, closed the identity (the top element of the boolean the whole square D x D, though is under relation. Let 1 denote algebra). Note it turns out that 1 is always an equivalence always relative relation over D. Complementation that 1 does not have converse, composition the biggest binary and containing to equal relation (A, V, -, l,O, l’,” , ; ) which obeys the Tarski to the top element. l A relation algebra A is a tuple [ 1 I]. That is axioms (1) (1 is the universal element), (A, V, -,O, 1) is a Boolean algebra ; is an associative binary operator on A, (a”)” = a, (2) (3) (4) 1’; a = a; 1’ = a, (5) a; (b v c) = a; b V a; c, (6) (7) (8) (9) (avb)“=a-vb-, (a-6)“=a--b-, (u;b)- (a; b) A c- = 0 H (b; c) A a” = 0 [triangle axiom]. = b-;a-, l A relation algebra is equivalent algebra can be decomposed to saying is called simple if it has no nontrivial congruence relations. This that for all 0 # a E A we have 1; a; 1 = 1. Any relation as a subalgebra of a direct product of simple ones. l An integral relation algebra satisfies 1; a = a; 1 = 1 for all non-zero a E A. l A representation X of A is an isomorphism from A to a proper relation algebra. is the {(d, d): d E D} (D The element 1’ must be mapped to the identity \fR. Hirsch/Artificial Intelligence 83 (1996) 267-295 269 thus x E X means that A is simple by noting in the domain of the representation. and the domain of the representation, - and ; are interpreted as converse and composition the unit 1 always gets represented as a sum of disjoint, there is no confusion we use the same letter X to stand for the that x is a domain of the representation), respectively. When isomorphism point For a simple relation algebra complete graphs each of which on its own. In this paper we is a representation only consider simple relation algebras and assume that a representation consists of a single component, i.e., for any pair of points the unit is called square. We justify them. Such a representation relation holds between the assumption is relation representable are representable. if all its simple components Let a E A and x, y E X. The notation X, (x, y) k a is used as an alternative (x, y) C: X(a). Where no confusion An atomic representation has the further property the domain of the representation them. It can be proved complete-i.e., finite relation algebras every representation An atomic d-network N is a finite directed graph with each edge (m, n) labelled by an atom N( m, n) of A, and transitively closed: for any three nodes 1, m, n of N we have that for any two points x1, x:! in there is a unique atom from A that holds between if it is is atomic [ 81. For arbitrary unions are preserved, wherever is a complete arises we may simply write (x, y) b a. they are defined representation. that a square representation in the representation that an arbitrary if and only if and only algebra to N(Z,m); N(m,n) 2 N(Z,n). A general d-network edge is labelled with a single atomic relation.2 is defined similarly, but it is no longer assumed that each Fact. Not every relation algebra has a representation set of axioms which characterises the representable [ 191 and indeed there is no finite relation algebras [ 241. all the relations, .?, J in the representation, isomorphism h of a representation An automorphism 0 of the representation X is a permuation of the representation preserving i.e., Vx, y E X,Va E A (x, y) b a H (x0, ~0) C_ a. A local tuples pair of points. A reprlzsentation a full automorphism A representation X is called universal if it has the following property: networks N if N embeds embed atomic d-networks is a finite map h : R -+ J for some that hold between each of A then it embeds it is called fully universal. is said to be homogeneous if every local isomorphism in any representation in the representation preserving all the relations for all atomic in N. If all of the representation. extends to 2 It is possible A and a first-order to a certain sentence is consistent with Th( A). to constmct a first-order language L(A) with one binary relation symbol for each element of theory Th(d) whose models are exactly the representations of A. A network first-order existential sentence and a network embeds in some representation is equivalent if the if and only \f270 R. Hirsch/Artijcial Intelligence 83 (1996) 267-295 Definition. A representation homogeneous. if and only amalgamation if its atomic networks is not needed here. it is shown In [7] is normal if it is square, complete, fully universal and that a relation algebra has a normal representation form an amalgamation class but the concept of Examples l Let P be the “point algebra” consisting of three atoms l’, < and > with <“= > and representation composition table that any representation So any countable ordering. This representation be any local isomorphism, Use a back and forth construction fully universal follows finite linear order and therefore embeds defined by <; < = < and <; > = 1. It follows from this composition of P must be a dense linear order without endpoints. their usual let p partial map from Q to Q. to extend p to a full automorphism. That Q is a turns out to be normal. To show homogeneity, from the fact that any atomic P-network i.e., a finite order-preserving to the rationals with is isomorphic is effectively in Q. l The Allen interval algebra Z has thirteen atoms I’, <, meets, overlaps, starts, during, table can be found in [ 11. namely ordered pairs turns out to be also ends plus the converses of the last six. The composition We will see later that it has only one countable of rationals (p.q) with p less normal. representation than q. This representation is R([O,O]), complement is W[p,ql) where i is a real interval with rational endpoints identity l The metric point system M of [ 61 consists of finite unions of basic relations R(i) (open, closed or semi-open). The V - = R( [ -4, -p] ) and composition R( [p, q] ); on if i. The representation based on the reals is not atomic as the pair (0, r) are not related by any atom, but the of M can be constructed (a, b) E R(i) the real numbers or the rationals by letting = R( [p + r, q + s] ). A representation R((q,co)), mverse W[rtJl) either b - a belongs (equivalently representation to the interval not complet",
            {
                "entities": [
                    [
                        77,
                        107,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 255 (2018) 43–70Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFixpoint semantics for active integrity constraintsBart Bogaerts a,∗, Luís Cruz-Filipe ba KU Leuven, Department of Computer Science, Celestijnenlaan 200A, Leuven, Belgiumb University of Southern Denmark, Department of Mathematics and Computer Science, Campusvej 55, Odense, Denmarka r t i c l e i n f oa b s t r a c tArticle history:Received 4 July 2017Received in revised form 2 October 2017Accepted 18 November 2017Available online 23 November 2017Keywords:Active integrity constraintsApproximation fixpoint theoryActive integrity constraints (AICs) constitute a formalism to associate with a database not just the constraints it should adhere to, but also how to fix the database in case one or more of these constraints are violated. The intuitions regarding which repairs are “good” given such a description are closely related to intuitions that live in various areas of non-monotonic reasoning, such as logic programming and autoepistemic logic.In this paper, we apply approximation fixpoint theory, an abstract, algebraic framework designed to unify semantics of non-monotonic logics, to the field of AICs. This results in a new family of semantics for AICs. We study properties of our new semantics and relationships to existing semantics. In particular, we argue that two of the newly defined semantics stand out. Grounded repairs have a simple definition that is purely based on semantic principles that semantics for AICs should adhere to. And, as we show, they coincide with the intended interpretation of AICs on many examples. The second semantics of interest is the AFT-well-founded semantics: it is a computationally cheap semantics that provides upper and lower bounds for many other classes of repairs.© 2017 Elsevier B.V. All rights reserved.1. IntroductionOne of the key components of modern-day databases are integrity constraints: logical formulas that specify semantic relationships between the data being modeled that have to be satisfied at all times. When the database is changed (typically due to updating), it is necessary to check if its integrity constraints still hold; in the negative case, the database must be repaired.The problem of database repair has been an important topic of research for more than thirty years [1]. There are two major problems when deciding how to repair an inconsistent database: finding possible repairs and choosing which one to apply. Indeed, there are typically several ways to fix an inconsistent database, and several criteria to choose the “best” one have been proposed over the years. Among the most widely accepted criteria are minimality of change [45,25] – change as little as possible – and the common-sense law of inertia (discussed in, e.g., [33]) – do not change anything unless there is a reason for the change.A typical implementation of integrity constraints in database systems is by means of event–condition–action (ECA) rules [38,44], which specify update actions to be performed when a particular event (a trigger) occurs and specific con-ditions hold. ECA rules are widely used in practice, as they are simple to implement and their individual semantics is easy * Corresponding author.E-mail addresses: bart.bogaerts@cs.kuleuven.be (B. Bogaerts), lcfilipe@gmail.com (L. Cruz-Filipe).https://doi.org/10.1016/j.artint.2017.11.0030004-3702/© 2017 Elsevier B.V. All rights reserved.\f44B. Bogaerts, L. Cruz-Filipe / Artificial Intelligence 255 (2018) 43–70to understand. However, the lack of declarative semantics for ECA rules makes their interaction complex to analyze and their joint behavior hard to understand.The formalism of active integrity constraints (AICs) [27] was inspired by a similar idea. AICs express database dependen-cies through logic programming-style rules that include update actions in their heads. They come with a set of declarative semantics that identifies several progressively more restricted classes of repairs, which can be used as criteria to select a preferred repair [13]. These repairs can be computed directly by means of tree algorithms [17], which have been imple-mented as a prototype [16].Example 1.1. We motivate the use of AICs in practice by means of a simple example. Consider a company’s database, including tables employee and dept (relating employees to the department where they work). In particular, each employee is assigned to a unique department; if an employee is listed as working in two different departments, then the database is inconsistent, and this inconsistency must be fixed by removing one of those entries.We can write this requirement as the following AIC.∀x, y, z : employee(x), dept(x, y), dept(x, z), y (cid:4)= z ⊃ −dept(x, y)The intended meaning of this rule is: if all the literals in the lefthandside (body) of the rule are true in some state of the database, for particular values of x, y and z, then the database is inconsistent, and this inconsistency can be solved by performing the action on the right.Suppose that the database isDB = {employee(john), dept(john, finance), dept(john, hr)} .This database is inconsistent, and applying our AIC with x = john, y = finance and z = hr gives us a possible fix consisting of the action “remove dept(john, finance)”. Observe, however, that the instantiation x = john, y = hr and z = finance detects the same inconsistency, but proposes instead the fix “remove dept(john, hr)”: in general, there can be several different ways to repair inconsistencies.AICs may also interact with each other. Suppose that we add the constraint∀x, y, z : supervisor(x, y), dept(x, z), ¬dept( y, z) ⊃ +dept( y, z)(1)stating that employees can only supervise people from their own department, and that whenever this constraint is violated, the department of the supervisee needs to be updated (i.e., the supervisor table and the department of the supervisor are deemed correct). If the database is nowDB = {employee(john), employee(ann), dept(john, finance), dept(ann, hr), supervisor(ann, john)}then this AIC detects an inconsistency, and suggests that it be fixed by adding the entry dept(john, hr). The database is still inconsistent, though, since there are now two entries for John in the dept table; restoring inconsistency would also require removing the entry dept(john, finance).An alternative repair of the integrity constraint that the supervisee and supervisor should belong to the same department would be to change the department information associated with ann. By using active integrity constraints, we discard this solution: rule (1) only allows to insert a new department for the supervisee. If we additionally also want to allow changing ann’s department, we need an extra constraint. (cid:2)It is striking that many intuitions about what “good” repairs are, such as minimality of change, are similar to intuitions that surfaced in other domains of non-monotonic reasoning, such as logic programming [39] and default logic [34]. Still, it has been hard to find satisfying semantics for AICs. As shown by Cruz-Filipe et al. [17], the semantics of so-called founded repairs [12] unexpectedly fails to respect the common-sense law of inertia, while the more restricted semantics of justified repairs [13] forbids natural repairs in some cases. That work proposed the operational semantics of well-founded repairs, which however is not modular [14] and is therefore severely restricted in its practical applicability.In this work, we begin by defining a new semantics for AICs that avoids these problems: grounded repairs. Grounded repairs are natural counterparts to existing semantics in various non-monotonic reasoning domains such as logic program-ming; we discuss how they relate to other semantics for AICs. We also argue that grounded repairs match our intuitions regarding AICs on a broad set of examples.We then give a more abstract characterization of the different semantics for AICs by associating with each set of AICs ηa semantic operator Tη. This operator immediately induces several semantics:(i) weak repairs are fixpoints of Tη;(ii) repairs are minimal fixpoints of Tη;(iii) grounded repairs are grounded fixpoints [7] of Tη.The first two semantics are pre-existing semantics for AICs that we recover in an operator-based fashion.\fB. Bogaerts, L. Cruz-Filipe / Artificial Intelligence 255 (2018) 43–7045Next, we define a three-valued variant of Tη . In the terminology of approximation fixpoint theory (AFT) [19] our three-valued operator is an approximator of the original semantic operator. Given such an approximator Tη, AFT induces a few more semantics:(iv) the Kripke–Kleene repair is the Kripke–Kleene fixpoint of Tη;(v) the AFT-well-founded repair is the well-founded fixpoint of Tη;(vi) (partial) stable repairs are (partial) stable fixpoints of Tη;(vii) partial grounded repairs are partial grounded fixpoints of Tη.We again study properties of these new semantics and study how they compare to existing semantics. Furthermore, we argue that, from a practical point of view, the AFT-style well-founded semantics is very valuable. Indeed, we show that the AFT-well-founded repair can be computed in polynomial time, and that, on a broad set of practical examples, it corresponds to the intuitions underlying database repairs, providing natural upper and lower bounds on the set of acceptable repairs (formally: the AFT-style well-founded model approximates all justified, stable and grounded repairs).All our semantics are defined within the framework of approximation fixpoint theory, a general algebraic framework for studying logics with a fixpoint semantics. This framework was initially developed by Denecker, Marek and Truszczy ´nski, henceforth referred to as DMT [20], after identifying analogies in the semantics of logic programming [39], autoepistemic logic (AEL) [32] and default logic, hereafter abbreviated to DL [34]. The theory defi",
            {
                "entities": [
                    [
                        134,
                        185,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 78 ( 1995) 45-86 Artificial Intelligence 3-D motion estimation from motion field* Naresh C. Gupta a,b, Laveen N. Kanal ayb a Department of Computer Science, University of Maryland, College Park, MD, USA b L.N.K. Corporation, Inc., Riverdale. MD, USA Received October 1993; revised January 1995 Abstract Several experiments suggest that the first stage of motion perception is the measurement of visual motion. The result of this stage is called the motionJield, which assigns a velocity vector to each point in the image plane. The second stage involves interpreting the motion field in terms of objects and motion in the three-dimensional world. Recovering 3-D motion of the object from the motion field has been difficult owing to the nonlinear system of equations involved, and the sensitivity of the system to noise. The need for the stability of the system is essential as only the optical flow field can be recovered from a sequence of images, which is at best a crude approximation to the motion field. We define two sets of “basic” parameters, which can be recovered from the motion field by solving a linear system of equations. The relationship between the basic parameters and the motion parameter being one-to-one and linear, we obtain a closed form solution for the 3- D motion parameter by solving a system of linear equations only. We prove the correctness, completeness and robustness of the approach and in that sense the problem of recovering the motion parameter from the motion field may be said to be “solved”. We present the results of extensive experimentation with real and simulated image sequences. 1. Introduction two-dimensional image provides only (3-D) world, as the 3-D information A single dimensional the image formation. However, recover the lost 3-D information is provided by the relative motion of elements the three- is lost during there are several cues in the images which enable us to to a certain extent. A valuable source of 3-D information (Z-D) (depth and motion) in the changing 2-D image. Several information about * Supported by NSF Research Grant # IRI 8802419 and in part by LNK Corporation. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00031-3 \f46 N.C. Gupu. L.N. KanaUArtificial Intelligence 78 (1995) 45-86 the remarkable have demonstrated experiments reliably extract 3-D structure and motion other cue. A particularly present observers with apparent motion sequences of a random dot surface undergoing motion to in the absence of any is to compelling method of demonstrating ability of the human visual system from an image sequence this phenomenon in space. There are several experiments which indicate is the measurement which assigns a velocity vector the motion involves dimensional world. In this paper we present a solution sequence parameter of a rigid object undergoing that the first stage of motion perception of visual motion. The result of this stage is called the motion field, in the image plane. The second stage in the three- for the second stage of the image the 3-D motion problem. We present an algorithm in terms of objects and surfaces to each point field a general motion. interpretation interpreting to recover interpretation Image sequence In Section 3, we discuss the reasons and underline has been an active area of research for the last two to recover 3-D motion from a sequence in Section 2. Though image the associated difficulties In Section 4 we define two sets of parameters which can be recovered field via solving a linear system of equations; we also show that the decades. Several algorithms have been proposed of images. We present a brief overview of the previous efforts many algorithms have been proposed, none works well for the noisy, real-world sequences. with the problem. from the motion 3-D motion parameter sections we look at the correctness, relationship. robustness of the approach and in that sense these sections represent difference between solution using nonlocal details of our extensive experimentation. of this work are presented the theorem. We then present and the relevance this work and previous efforts. In the next section we stabilize to these basic parameters via a linear and one-to-one and the most significant Some general observations and Green’s divergence In the subsequent in the concluding completeness constraints is related section. 2. Literature review Gibson hypothesized [4-61 recover a unique, physically then numerous information. These algorithms algorithms have been proposed can be grouped correct that there is sufficient interpretation information in the flow field to of 3-D motion and structure. Since field for the 3-D to interpret into six main categories. the motion 2.1. Closed form solution from flow jields Koenderink and van Doorn [ 191 proposed an algorithm properties of motion and surface shape by using the local deformations (e.g., divergence, built on their work and obtained a closed form solution flow derivatives. A serious problem with these approaches the flow field. curl, shear). Longuet-Higgins and Prazdny to measure the invariant in the flow field [ 381 [24] and Waxman for the flow field in terms of to noise in is their sensitivity \fN.C. Gupta, L.N. KanaUArtijicial Intelligence 78 (1995) 45-i-86 47 2.2. Least squares methods a global approach Bruss and Horn 121 proposed in the entire visual field to choose the 3-D motion and structure that fits the flow field best in the least squares sense. The cases when there is only translation or only rotation are simple and stable closed form solutions iterative techniques were used for the translational parameter. Adiv In the case of a general motion, system of equations to solve a nonlinear that combines are derived. information the same residual [ l] minimizes way. The flow field is divided for each patch under direction, each patch. Patches having similar motion are merged. an error measure the assumption is computed, into patches and motion parameters function as Horn and Bruss, but in a different are then estimated of planarity. For each patch and each translation from which a best translation is selected for Other researchers have also proposed function over a discretely residual the focus of expansion of a translating field is decomposed which the velocity rotational motion flow field. is hypothesized techniques that pick solutions by minimizing sampled solution space. Lawton camera. Prazdny into rotational and translational is estimated and the best translation [ 311 proposed an approach a [ 211 used it to obtain in components. The for the remaining Heegar and Jepson [ 121 minimize the same residual depth and the rotation parameters function of the translation. The error function for a large number of patches translation direction which is selected from which a translation for most patches are eliminated function as Horn and Bruss. The to arrive at a measure of error as a is evaluated for each candidate translation is selected is chosen for each patch. The to be the translation. 2.3. Subdividing the problem Several researchers have proposed splitting the problem of structure and motion esti- into several subproblems. The idea is to eliminate one set of motion parameters only mation and get a constraint value of that set of parameters, which proposed of smooth only. first for the rotational solving in rotation or translation. Solving is then used to estimate component of motion. Under that constraint gives the other. Prazdny the [ 3 1 ] the assumption in terms of rotation surfaces, he derived a system of nonlinear equations Helmholz image point, same expansion. Reiger and Lawton focus of expansion is the noise sensitivity the difference pointed out that if two points at different depths are projected onto the the focus of the from local flow-vector differences. The problem with this approach in the image velocities points [ 321 proposed an approximate to estimate algorithm towards in computing the flow difference. 2.4. Direct methods Negahdaripour and Horn 3-D motion parameters. They substituted to get a constraint constraint, [29] proposed several direct methods field equations in terms of 3-D parameters and image the motion the for recovering in the optical flow intensity gradients. \f48 N.C. Gupta, L.N. Kanal/Artijicial Intelligence 78 (199.5) 45-M to avoid Several algorithms were proposed being Hanna directly [lo] from the image proposed an iterative algorithm intensity. the computation of the optical the motivation for special cases of object motion; has proved flow-which to be difficult. the motion of the camera that estimates 2.5. Long sequence Several algorithms have been proposed which use a sequence of flow fields to estimate [27] used a precise dynamical model for the motion parameters. Matthies and Kanade temporal changes of their approach motion may only be translation Kalman and parallel filter per pixel to recover a dense depth map. in depth to recover structure from a sequence of images. The limitation is the need to know the camera motion as well as the restriction to the image plane. Heel that [ 131 used one 2.6. Linear methods Tsai and Huang [35] proposed are recovered are determined a linear algorithm of eight “pure parameters” motion and structure parameters a sixth order polynomial. general curved object eight feature point correspondence. Motion parameters are then recovered by taking SVD of the essential parameter matrix E. The E-matrix and efficient. But they are highly sensitive coordinates. One of the reasons for this is that the linear constraint than the rigid body motion constraint. for a planar patch. First, a set by solving a set of linear equations. The from these “pure parameters” by solving for a from the are quite simple of image they utilize is weaker later [22,36] in motion. The “essential” parameters were first recovered linear algorithms were proposed to noise, especially to perturbations a",
            {
                "entities": [
                    [
                        65,
                        104,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1245–1284www.elsevier.com/locate/artintWhat makes propositional abduction tractableGustav Nordh a,∗,1, Bruno Zanuttini ba LIX, École Polytechnique, Route de Saclay, F-91 128 Palaiseau, Franceb GREYC, UMR CNRS 6072, Université de Caen, Bd. du Maréchal Juin, F-14 032 Caen Cedex, FranceReceived 10 April 2007; received in revised form 28 January 2008; accepted 5 February 2008Available online 12 February 2008AbstractAbduction is a fundamental form of nonmonotonic reasoning that aims at finding explanations for observed manifestations. Thisprocess underlies many applications, from car configuration to medical diagnosis. We study here the computational complexity ofdeciding whether an explanation exists in the case when the application domain is described by a propositional knowledge base.Building on previous results, we classify the complexity for local restrictions on the knowledge base and under various restrictionson hypotheses and manifestations. In comparison to the many previous studies on the complexity of abduction we are able to givea much more detailed picture for the complexity of the basic problem of deciding the existence of an explanation. It turns out thatdepending on the restrictions, the problem in this framework is always polynomial-time solvable, NP-complete, coNP-complete,or (cid:2)PBased on these results, we give an a posteriori justification of what makes propositional abduction hard even for some classesof knowledge bases which allow for efficient satisfiability testing and deduction. This justification is very simple and intuitive, butit reveals that no nontrivial class of abduction problems is tractable. Indeed, tractability essentially requires that the language forknowledge bases is unable to express both causal links and conflicts between hypotheses. This generalizes a similar observation byBylander et al. for set-covering abduction.© 2008 Elsevier B.V. All rights reserved.2 -complete.Keywords: Abduction; Propositional logic; Computational complexity1. IntroductionAbduction is the fundamental reasoning process which consists of explaining observations by plausible causestaken from a given set of hypotheses. For instance, it is an abduction problem to try to derive diseases from ob-served symptoms, according to known rules relating both. This process was extensively studied by Peirce [6], and itsimportance to Artificial Intelligence was first emphasized by Morgan [38] and Pople [41].From the application point of view, abduction has demonstrated its importance. It has been applied in particular toexplanation-based diagnosis (e.g., medical diagnosis [7]), to text interpretation [29], and to planning [28]. It is alsothe fundamental process underlying ATMSs [13].* Corresponding author.E-mail addresses: nordh@lix.polytechnique.fr (G. Nordh), zanutti@info.unicaen.fr (B. Zanuttini).1 Partially supported by the Swedish–French Foundation and the National Graduate School in Computer Science (CUGS), Sweden.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.02.001\f1246G. Nordh, B. Zanuttini / Artificial Intelligence 172 (2008) 1245–1284The formalization and resolution of abduction problems have been studied in numerous formalisms, among whichset-covering [7], default logic [22], logic programming [21,36]. We are interested here in its resolution in classicalpropositional logic.We adopt a complexity-theoretic point of view. More precisely, we are interested in the complexity of decidingwhether an abduction problem has a solution when the underlying knowledge base is propositional. Thus our studyfollows Selman and Levesque’s [48] and Eiter and Gottlob’s [20] seminal papers. We also build on two classificationspreviously obtained in our framework [12,40].Even in the simple setting of propositional logic, deciding whether an abduction problem has a solution is in general(cid:2)P2 -complete. Consequently, like for most hard computational problems, several approaches have been studied forsolving it efficiently: Exhibiting tractable classes obtained by restrictions over the knowledge base [12,16,20,24,51];heuristic approaches, in particular through computation of prime implicates [14,15,37,49] and through reducing theproblem to QBF and using generic QBF solvers [19]; compilation [8,35]; and approximation [31,50].In this paper we adopt the approach consisting of trying to find tractable restrictions over the knowledge base. Ourcontribution is twofold.First, we identify the complexity of abduction, with varying restrictions over the representations of manifestationsand hypotheses, for every constraint language and every clausal or equational language restricting the (propositional)knowledge base, under reasonable assumptions on the representation of the constraints. Concerning manifestations,we study the restrictions where they are expressed as a positive, negative, or unrestricted literal, clause, term, or CNF.Concerning hypotheses, we study the restrictions where they are expressed by a set of literals which is positive, neg-ative, closed under complement, or unrestricted. To that aim, we use the now well-known Schaefer’s framework [46]and Post’s lattice [42]. Precisely, we proceed as follows.• We first prove a relatively small number of tractability and hardness results for particular constraint languages.• Using Post’s classification and these results, we then derive the complexity of abduction for any constraint lan-guage.• In a similar manner, and at the same time, we obtain the complexity of abduction for any clausal or equationallanguage.We exhibit new polynomial and new hard restrictions. We also discover that abduction is always either in P,NP-complete, coNP-complete, or (cid:2)P2 -complete, depending on the restrictions. Such a result could not be taken forgranted, due to Ladner’s result stating that if P (cid:3)= NP, then there exist problems in NP that are neither in P nor NP-complete [33]. Moreover, the fact that some restrictions yield NP-complete, and others coNP-complete problems issurprising at first sight. It reveals in particular that abduction is a very rich problem in terms of completeness resultsin different complexity classes. Thus our results can be used as starting points for establishing complexity results forother problems, in particular in nonmonotonic reasoning.From the application point of view, our tables of complexity allow the designers of knowledge-based agents orexpert systems to choose the appropriate knowledge representation language, according to the tradeoff between theexpressiveness required and the constraints on resolution of abduction problems. Moreover, when a representationlanguage that is hard for abduction must be used, the precise complexity of the corresponding problem allows tochoose heuristic approaches for solving it. For instance, with an appropriate reduction an NP-complete problem canbe solved by a satisfiability solver, while a (cid:2)P2 -complete one cannot; a more generic QBF solver (or a specializedQBF∃,2-solver) must be used.Our second contribution is to identify a simple set of minimal conditions yielding NP-completeness for languageswhich allow for efficient deduction (and are thus good candidates for knowledge representation). For instance, whenterms have to be explained, we discover that abduction is NP-hard exactly when the language for knowledge bases canboth express causal links from hypotheses to individual manifestations and forbid some combinations of hypotheses.This generalizes similar observations by Bylander et al. [7] about set-covering abduction.From this condition it follows that tractability can occur only in very restricted cases, i.e., when there can be nocausal dependency at all or when causes can all be assumed together. For instance, in medical diagnosis this meansthat diseases must not rule each other out for the task to be tractable. We also argue that these conditions give intuitionsabout results beyond Schaefer’s framework of constraint languages, and we revisit some previously known results inthat manner. In this spirit, our observations allow to adopt a unified point of view on the results exhibited with manydifferent restrictions in the literature.\fG. Nordh, B. Zanuttini / Artificial Intelligence 172 (2008) 1245–12841247The use of Post’s lattice and Schaefer’s framework for studying the complexity of reasoning problems is sometimesconsidered to be overlimitating. For instance, it does not encompass the class of all Horn formulas; this is because Hornclauses can be arbitrarily long. In this study, we adopt these powerful tools coming from complexity-theory and showhow to overcome some of these limitations. Indeed, we use them to show results about infinite constraint languagesas well as about finite ones, and we formulate the former in terms of classes of CNF formulas. These extensions aredirectly motivated by AI-applications where it is common to model the knowledge base using an infinite constraintlanguage represented in terms of classes of CNF formulas.To put our results in context, we briefly discuss the results from the literature on the complexity of abduction thatare most relevant to our present study. Our starting point is Selman and Levesque’s [48], and Eiter and Gottlob’s [20]classical results. Selman and Levesque [48] proved that deciding whether an abduction problem over a Horn knowl-edge base has an explanation is NP-complete, even when the hypotheses are given as a set of positive literals andthe manifestation is a single positive literal. Similarly, Eiter and Gottlob [20] proved that when the knowledge baseis given by a general propositional formula, the problem becomes (cid:2)P2 -complete. Moreover they note that when theknowledge base is given by a definite Horn formula, the hypotheses are positive literals, and the manifestations aregiven by a positive term, then the problem is in P.From these results it is clear that the c",
            {
                "entities": [
                    [
                        74,
                        118,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 92 ( 1997) 91-129 Artificial Intelligence Proving properties of continuous systems: qualitative simulation and temporal logic * Benjamin Shults a,‘, Benjamin J. Kuipers b,* B Department of Mathematics, University of Texas at Austin, Austin, TX 78712. USA h Computer Science Department, University of Texas at Austin, Taylor Hall, Austin, 7x 78712, USA Received February 1996; revised September 1996 Abstract temporal We demonstrate an automated method about solutions for proving to ordinary differential equations (ODES), even in the face of an incomplete specification of the ODE. The method combines an implemented, on-the-fly, model checking algorithm for statements in the temporal logic CTL* with the output of the qualitative simulation algorithm QSIM. Based on the QSIM Guaranteed Coverage Theorem, we prove that for certain CTL* statements, @, if @ is true for the temporal structure produced by QSIM, then a corresponding temporal statement, di’, holds for the solution of any ODE consistent with the qualitative differential equation (QDE) that QSIM used to generate the temporal structure. @ 1997 Elsevier Science B.V. logic statements Keywords: Temporal logic; Qualitative simulation; Model checking; Differential equations 1. Introduction The world is continuous about reliably to reason range of cases by using qualitative to describe model to check the validity of statements the behaviors of the continuous it. We demonstrate and dynamic, but we want to use discrete symbolic means this for a significant to generate a finite structure guaranteed for doing simulation a method then interpreting that structure as a The main theorem of this paper can be stated is a QSIM behavior tree generated from the qualitative differential as follows. Suppose A4 equation C. If M system, in temporal logic. informally *This work has been supported Electric Power Research * Corresponding ’ E-mail: bshults@math.utexas.edu. Institute. A preliminary author. E-mail: kuipers@cs.utexas.edu. in part by the National Science Foundation (grant IRI-9216584) and by the report on this work appeared as [ 171. 0004-3702/97/$17,00 /WS0004-3702(96)00050-l @ 1997 Elsevier Science B.V. All rights reserved \f92 B. Shuks, B.J. Kuipers/Artifrcial Intelligence 92 (1997) 91-129 logic formula, to C. Of course, we will formalize all of these relationships then the formula describes every solution to for a temporal is a model every ODE which abstracts carefully in this paper. In many applications initial conditions in which ordinary differential or the specific relationship equations are used, information between a pair of quantities between quantities information is not about completely known. In some cases constants are only known to lie in a certain range or the relationship allows this which abstracts differential about the solution system. reasoning to any ODE information. We call such an abstract ODE a qualitative (or QDE) . In many such applications we want to draw conclusions to any ODE consistent with the limited to be monotonic. Qualitative information we have about a to generate descriptions is only known to the known of solutions to be used equation there are a number of applications inference about time-ordered system. Since applications Furthermore, profit from reliable of a continuous design must often cope with conditions reasoning temporal or semi-quantitative connection checking. between over the possible behaviors of a system described by a qualitative valuable. Our program, TL, makes a formal model logic model solutions to real differential and temporal is particularly equations reasoning of model-based that can events over the set of possible behaviors and to do knowledge, the ability diagnosis such as control, monitoring, of incomplete A qualitative simulator, the possible behaviors consistent with the qualitative differential [ 13,141. This set of behaviors to the QSIM algorithm state input is guaranteed represent initial as a finite structure of qualitative ture real-valued abstracts “soundness” Theorem. function which to contain to the QDE under circumstances this property of QSIM, and such as QSIM, constructs a tree-like structure whose branches equation and is expressed this struc- extended- equation which to be described. We call this property the is the content of the Guaranteed Coverage state descriptions. a branch which describes In the case of QSIM, any “reasonable” is a solution of an ordinary differential temporal Since the output of the QSIM algorithm is a structure whose paths describe reasonable, temporal questions and have those questions answered. This is accomplished it describes logic model checking. A model checking functions, we would like to be able to formulate extended-real-valued about the system using logic formula and a tree-like structure and determines whether temporal a model for the formula. Temporal (in propositional eventually, and until. Modal worlds the logical sense of the word) logic with temporal operators on time-varying (i.e., alternate behaviors or paths), logic adds operators for truth values takes as input a is the structure logic augments truth values, such as always, in alternate possible such as necessarily and possibly. algorithm We have chosen to use the branching time temporal logic CTL* which is described by Emerson and Clarke [ 7,8]. Because QSIM is sound, for any CTL* statement @ which is “universal” in a sense we if Cp is modeled by the structure produced by QSIM, will define, theorem holds for the solution of any ordinary differential QDE that generated temporal logic about continuous systems can be proved by qualitative the QSIM structure. Therefore, at least for universals, equation consistent with the in statements simulation. This then a corresponding \fB. Slzults, B.J. Kuipers/Art@cial Intelligence 92 (1997) 91-129 93 allows a hybrid reasoning reasoning about dynamical to prove common-sense system systems. statements and to do expert We also provide a limited completeness result: by QSIM describe differential which are not universal may be used to prove properties of the system. extended-real-valued equations consistent with the QDE input to QSIM, then even CTL* formulas reasonable, in case all paths in the structure output to functions which are solutions The propositional part of the temporal the construction conjunction with [ 121 -in of formulas the numerical containing extensions order to prove numerical properties of physical systems. to QSIM-Q2 language numerical includes propositions which allow in information. [ 161, Q3 [2] and NSIM This can be used In Section 2 we describe and define language CTL* and present some basic definitions theorem. The reader already familiar with CTL* may want to read only Section 2.1 to learn about our notation conventions and Section 2.4 to see the standard results from the literature which we will be using. and facts which will be needed the temporal in our main logic In Section 3 we describe the QSIM framework and prove the Guaranteed Coverage Theorem. Even readers familiar with QSIM should read most of Section 3 since we use an updated and add some new terminology. formalization Section 4 begins to show how the QSIM framework and the underlying differential equations explain how formulas reasonable are related to the theory of temporal the output of the QSIM algorithm logic and CTL* formulas. There we is used as a structure over which formulas describe in CTL* can be interpreted. We also show how CTL* real-valued functions. In Section 5 we introduce the last hypothesis theorem. We also prove some useful special cases and a completeness also discusses some issues concerning the implementation. to the main theorem and prove the main result. Section 5 In Section 6 we describe model checking with qualitative some applications simulation. of the combination of temporal logic Sections 2-4 lay the groundwork theorem in the main for the statement of the main increasing degrees of formality theorem. We will the as we develop be stating terminology. 2. CTL* Computational is a branching is summarized by Emerson logics [ 81. We will customize CTL* slightly time temporal tree logic (CTL and its extension CTL*) in The logic. The theory of branching time temporal in Handbook of TheoreticaE Computer Science systems a state may have order to allow states with no successors because infinity or if the value of some variable crosses a no successor boundary of its range). In this section, we define the syntax and semantics of the CTL* language and, in Section 2.4, give some basic results and definitions which will be used by our main from the presentation in the notation we use. We use this notation as a convenience theorems. The presentation of the language in [8] except for our implementation. of CTL* here does not differ significantly if time reaches in continuous (e.g. \f94 B. Shults, B.J. Kuipers/Artificial Intelligence 92 (1997) 91-129 A model checking algorithm formula and determines whether word) for the formula. examines the structure a temporal is a model structure (in and a temporal logic the logical sense of the Our implementation to terminate with (TL) of a model checking algorithm for CTL* is an “on-the-fly” [ 31. On-the- model checker based on the algorithm of Bhat, Cleaveland and Grumberg fly algorithms have the advantage over the more common “global” algorithms of being able large structure. the complexity for CTL model checking. Our implementation systems about continuous then is the same as the best known algorithms statements If the formula happens of this on-the-fly to be in the sublanguage CTL of CTL* result before constructing the entire exponentially (see Section 4). for expressing is customized the correct algorithm 2.1. Terminology and notation We interpret a CTL* formula over a temporal structure M = (S, X, L) where 0 S is a set of states, l X is a set of fullpaths, l L:SxAP+{T,F} proposition 4 E AP and ass",
            {
                "entities": [
                    [
                        75,
                        158,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 197 (2013) 56–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the succinctness of some modal logicsTim French a, Wiebe van der Hoek b,∗, Petar Iliev b, Barteld Kooi ca School of Computer Science and Software Engineering, University of Western Australia, Australiab Department of Computer Science, University of Liverpool, UKc Faculty of Philosophy, University of Groningen, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 24 February 2012Received in revised form 12 February 2013Accepted 16 February 2013Available online 18 February 2013Keywords:Knowledge representationModal logicSuccinctnessEpistemic logicFinite model theory of modal logicDescription logicsBoolean modal logicOne way of comparing knowledge representation formalisms that has attracted attentioni.e., we can ask whether one ofrecently is in terms of representational succinctness,the formalisms allows for a more ‘economical’ encoding of information than the other.Proving that one logic is more succinct than another becomes harder when the underlyingsemantics is stronger. We propose to use Formula Size Games (as put forward by Adlerand Immerman (2003) [1], but we present them as games for one player, called Spoiler),games that are played on two sets of models, and that directly link the length of a playin which Spoiler wins the game with the size of a formula, i.e., a formula that is true inthe first set of models but false in all models of the second set. Using formula size games,we prove the following succinctness results for m-dimensional modal logic, where one hasa set I = {i1, . . . , im} of indices for m modalities: (1) on general Kripke models (and alsoon binary trees), a definition [∀Γ ]ϕ =[i]ϕ (with Γ ⊆ I) makes the resulting logicexponentially more succinct for m > 1; (2) several modal logics use such abbreviations[∀Γ ]ϕ, e.g., in description logics the construct corresponds to adding role disjunctions,and an epistemic interpretation of it is ‘everybody in Γ knows’. Indeed, we show that onepistemic models (i.e., S5-models), the logic with [∀Γ ]ϕ becomes more succinct for m > 3;(3) the results for the logic with ‘everybody knows’ also hold for a logic with ‘somebodyknows’, and (4) on epistemic models, Public Announcement Logic is exponentially moresuccinct than epistemic logic, if m > 3. The latter settles an open problem raised by Lutz(2006) [18].i∈Γ(cid:2)© 2013 Elsevier B.V. All rights reserved.1. IntroductionThe study of the expressive power of logics is one of the major topics in mathematical logic and computer science. Thegeneral framework for such investigations can be described as follows. We begin with the question of whether a particularformalism can express some property on some class of models or not. The intuitive notion of property is given a formalexpression through the concept of query and, therefore, the formal version of our initial question is whether a particularquery is definable in some logic under investigation. Such questions are of great theoretical interest. However, it has beenargued in [10] that, as far as knowledge representation formalisms are concerned, the comparison of two such formalisms,L1 and L2, cannot be meaningfully accomplished just in terms of expressive power or the computational complexity of theirinference problems. This is due to the fact that often we have the following situation:1. L1 and L2 are equally expressive, and/or2. L1 and L2 have the same complexity of the satisfiability problem, or* Corresponding author.E-mail addresses: tim@csse.uwa.edu.au (T. French), wiebe@csc.liv.ac.uk (W. van der Hoek), pvi@liverpool.ac.uk (P. Iliev), B.P.Kooi@rug.nl (B. Kooi).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.003\fT. French et al. / Artificial Intelligence 197 (2013) 56–85573. The complexities of L1 and L2 are different but so high that it cannot be honestly claimed to be of any practicalrelevance.Therefore, the authors of [10] suggest that a better comparison criterion is the representational succinctness of such for-malisms. Intuitively, if we are interested in some particular query Q that is expressible with formulae ϕ1 and ϕ2 fromL1 and L2 respectively, we can ask if there is a significant difference in the lengths of ϕ1 and ϕ2. Hence, the notion ofsuccinctness is a refinement of the notion of expressivity.In this paper we present a number of succinctness results related to three well-known extensions of multimodal logic(ML) which have a popular epistemic and knowledge representation interpretation. A brief overview of our main theoremsis as follows.(cid:2)Adding formulae of the form [∀Γ ]ϕ to ML results in exponential succinctness on the well-known class of equivalencemodels S5, the typical semantics for epistemic logic. Intuitively, a formula [∀Γ ]ϕ is best thought of as an abbreviation[i]ϕ. Such an abbreviation arises naturally in many branches of modal logic. For example, inof the ML-formulaepistemic logic [6,25], [∀Γ ] is called the ‘everybody knows’-modality. In boolean modal logic [9], [∀Γ ] corresponds to amodality of the form [i1 ∪ · · · ∪ in], where {i1, . . . , in} = Γ ; in the parlance of Description logics [2], [∀Γ ] corresponds toadding role disjunctions to the description logic ALC (as in ‘sibling’ being defined as the role disjunction of ‘brother’and ‘sister’). Finally, in dynamic logic [11], [∀Γ ]ϕ expresses that after every execution of any program from Γ , ϕ holds(demonic non-determinism).i∈Γ(cid:3)Similarly, adding formulae of the form [∃Γ ]ϕ to ML results in exponential succinctness on S5. A formula [∃Γ ]ϕ can be[i]ϕ. Again, such formulae arise naturally in epistemic logic wherethought of as an abbreviation of the ML-formulathe modality [∃Γ ] is called the ‘somebody knows’ modality. In Dynamic logic, this modality would represent angelicnon-determinism: there is choice of a program from Γ , such that ϕ will hold after every execution of it.Finally, adding formulae of the form [ψ]ϕ to ML again results in exponential succinctness on S5, which answers aquestion left open in [18]. The modal operator [ψ] was introduced in [21] as a means for formalising the intuitive notionof ‘public announcement’. Intuitively, a formula [ψ]ϕ is evaluated at a point w in a Kripke model by first discarding allpoints that do not satisfy ψ and then, if w has survived this procedure, we see whether ϕ is true at w in the newlyobtained model.i∈ΓThe first of the above results can be explained in the following way. We show that for every natural number n, thereis a set of S5 models Mn and a property P of these models such that there is formula of the form [∀Γ ]ϕ, whose lengthis linear in n, that expresses P but every equivalent formula from ML has length exponential in n. Similarly for the secondand third results. This highlights the crucial importance of the class of models we use in our proofs. Intuitively, provingsuch a result with respect to a set of models N for which we have no special requirements for the nature of the relationsseems easier than when we impose additional conditions on the models. This is so, because the more conditions we imposeon our models, the greater the chance to find a formula of sub-exponential length equivalent to [∀Γ ]ϕ. Later we will seethat such results depend not only on the class of models used but on the number of variables and relation symbols in thelanguage, too.The paper is organised as follows. In Section 2, we briefly introduce some classes of functions needed to define thenotion of succinctness, or, better what it means that one logic is exponentially more succinct than another. We also providea lemma (Lemma 1) which offers a sufficient condition to decide this: all our proofs of succinctness rely on this lemma. Inthis section, we also define the four modal languages ML, [∀Γ ]ML, [∃Γ ]ML and [ϕ]ML that we deal with in this paper. Howdo we demonstrate that any formula equivalent to ψ ∈ L2 must have at least a certain length? In Section 2.3, we proposeto use (an adaptation of) Formula Size Games (FSGs) introduced in [1]. FSGs establish a direct link between the number ofmoves needed for one player to win a game, and the length of formulae associated with the game (Theorem 1). We alsoprove the principle of diverging pairs (Theorem 2), which guarantees under which condition the number of moves neededto win certain sub-games, contribute to the number of moves to win the overall-game.Then, Section 3 presents our succinctness results. In particular, in Section 3.1, we employ FSGs to show that both [∀Γ ]MLand [∃Γ ]ML are exponentially more succinct than ML, on the general class of Kripke models K (Theorem 3). The theorem alsoestablishes this for [ϕ]ML, but the proof for this is in [18]. Finally, Theorem 4 generalises this result of succinctness of thesethree modal languages to the class of models S5, i.e., models where the underlying accessibility relations are equivalences.We conclude in Section 4, stating some open problems and conjectures.The present paper is a greatly extended version of [8].2. Preliminaries2.1. Defining succinctnessWhen studying succinctness, we want to say that, in order to express a certain sequence of properties, the length offormulae in one language grows faster than in another language. To reason about relative growth of functions, one oftenuses either the so-called o-notation (also called asymptotic analysis), or a notation based on limits: both approaches are\f58T. French et al. / Artificial Intelligence 197 (2013) 56–85equivalent (see e.g., [5]). We feel that the latter notation is often intuitively more clear, but on the other hand the o-nota-tion enables us to prove Lemma 1. (The latter lemma provides a sufficient condition for proving succinctness: the readerinterested in our succinctness results may start reading Lemma 1 and use that as a working definition of succi",
            {
                "entities": [
                    [
                        143,
                        183,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 219 (2015) 67–91Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintIntegrating representation learning and skill learning in a human-like intelligent agent∗Nan Li, Noboru Matsuda, William W. Cohen, Kenneth R. Koedinger5000 Forbes Ave, Pittsburgh, PA 15232, USAa r t i c l e i n f oa b s t r a c tArticle history:Received 18 April 2012Received in revised form 2 July 2014Accepted 5 November 2014Available online 4 December 2014Keywords:Agent learningRepresentation learningStudent modelingBuilding an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of “deep features”, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning “deep features” reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system’s instructional strategy.© 2014 Elsevier B.V. All rights reserved.1. IntroductionOne of the fundamental goals of artificial intelligence is to understand and develop intelligent agents that simulate human-like intelligence. A considerable amount of effort [1–3] has been put toward this challenging task. Further, education in the 21st century will be increasingly about helping students not just learn content but to become better learners. Thus, we have a second goal of improving our understanding of how humans acquire knowledge and how students vary in their abilities to learn.* Corresponding author.E-mail addresses: nli1@cs.cmu.edu (N. Li), Noboru.Matsuda@cs.cmu.edu (N. Matsuda), wcohen@cs.cmu.edu (W.W. Cohen), koedinger@cmu.edu(K.R. Koedinger).http://dx.doi.org/10.1016/j.artint.2014.11.0020004-3702/© 2014 Elsevier B.V. All rights reserved.\f68N. Li et al. / Artificial Intelligence 219 (2015) 67–91To contribute to both goals, there have been recent efforts [4–7] in developing intelligent agents that model human learning of math, science, or a second language. Although such agents produce intelligent behavior with less human knowl-edge engineering than before, there remains a non-trivial element of knowledge engineering in the encoding of the prior domain knowledge given to the simulated student agent at the start of the learning process. For example, to build an algebra learning agent, the agent developer needs to provide prior knowledge by coding functions that describe, for instance, how to extract a coefficient or how to add two algebraic terms. Such manual encoding of prior knowledge can be time-consuming and the constructed prior knowledge may not naturally correspond with a human student’s prior knowledge.Since real students entering a course do not usually have substantial domain-specific or domain-relevant prior knowl-edge, it is not realistic in a model of human learning to assume this knowledge is given rather than learned. For example, for students learning about algebra, we cannot assume that they all know beforehand what a coefficient is, or what the dif-ference between a variable term and a constant term is. An intelligent system that models automatic knowledge acquisition with a small amount of prior knowledge could be helpful both in reducing the effort in knowledge engineering intelligent systems and in advancing the cognitive science of human learning.Previous work in cognitive science [8,9] showed that one of the key factors that differentiates experts and novices in a field is their different prior knowledge of world state representation. Experts view the world in terms of deep functional fea-tures (e.g., coefficient and constant in algebra), while novices only view in terms of shallow perceptual features (e.g., integer in an expression). Deep features are often domain-specific, whereas shallow perceptual features are domain-independent. Having the correct representation of the deep features aids the process of solving the domain task. For example, in algebra, students need to learn to encode equation input into “terms” and “coefficients”. A shallow feature encoding of a coefficient (e.g., of the “5” in “5x”) is as a number before a letter. A deep feature encoding requires the learner to develop knowl-edge, which may include implicit perceptual processing capabilities, to recognize coefficients more generally such as the “-5” in “-5x”, the “a” in “ax”, the “3” in “3(x+2)”, the “-1” in “-x”. In general, experts develop deep feature knowledge that allows them to see the world in the way novices do not – expert readers see “run” as a word whereas novices see letters or just lines, experts in physics see force contact points whereas novices see blocks and inclined planes, chess experts see configurations of pieces like a knight fork whereas novices see pieces. Such deep feature perception knowledge is learned for specific domains, perhaps as much by implicit experience as by explicit instruction. In algebra, students learn to see terms and coefficients in equations building upon more general prior knowledge of numbers. That prior knowledge may be the basis for initial shallow feature encoding as in the example above. In general, we consider deep features as part of rep-resentation knowledge. Representation knowledge organizes low-level perceptual input into a structured form that assists the agent to understand and solve problems in a particular domain. Even if the same perceptual input was given, for dif-ferent problem solving tasks in different domains, the ideal representation of the world can be different for different tasks. Deep features can be viewed as the key features that differentiate a well-structured representation from a poorly-structured representation.Deep feature learning is a major component of human expertise acquisition, but has not received much attention in AI. Learning deep features changes the representation on which future learning is based and, by doing so, improves future learning. However, how these deep features are acquired is not clear. Therefore, we have recently developed a learning algorithm that acquires deep features automatically with only domain-independent knowledge (e.g., what is an integer) as input [10]. We evaluated the effectiveness of the algorithm in learning deep features, but not its impact on future skill learner.In order to evaluate how the deep feature learner could affect future learning of an intelligent agent, in this paper, we integrated this deep feature learning algorithm into SimStudent [11], an agent that learns problem-solving skills by example and by feedback on performance. The original SimStudent relies on a hand-engineered representation that encodes an expert representation given as prior knowledge. This limits its ability to model novice students. The extended SimStudent first acquires the representation of the problems using the deep feature learner. Then, it makes use of the learned representation to acquire skill knowledge in later tasks. Integrating the deep feature learner into the original SimStudent both reduces the amount of engineering effort and builds a better model of student learning.We show that the extended SimStudent with better representation learning performs much better than the original Sim-Student when neither of them are given domain-specific knowledge. Furthermore, we also show that even compared to the original SimStudent with the domain-specific knowledge, the extended SimStudent is able to learn nearly as well without being given domain-specific knowledge. For the sake of simplicity, we only report experiment results in the algebra domain in this paper, but similar results are also observed in other domains [12]. In addition, we use the extended SimStudent to automatically discover models of real students, and show that the discovered models are better student models than human-generated models [13]. Although not reported here, we further use the extended SimStudent to better understand how problem orders affect learning effectiveness by inspecting SimStudent’s learning processes and learning outcomes, which are not easily obtainable from human subjects [14].To summarize, the main contributions of this paper are two-fold. By integrating representation learning into skill learn-ing, 1) we reduce the amount of knowledge engineering effort required in constructing an intelligent agent; 2) we get a better model of human behavior.In the following sections, we start with a brief review of SimStudent. We then present the deep feature learning algo-rithm together with its evaluation results. Next, we ",
            {
                "entities": [
                    [
                        134,
                        222,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 73 (1995) 149-173 Artificial Intelligence A situated view of representation and control Stanley J. Rosenschein ‘, Leslie Pack Kaelbling *v2 hnputer Science Departntent, Box 1910, Brown Universiiy Providence, RI 02912-1910, USA Received December 1993; revised September 1994 Abstract Intelligent agents are systems that have a complex, ongoing interaction with an environment that is dynamic and imperfectly predictable. Agents are typically difficult to program because the correctness of a program depends on the details of how the agent is situated in its environ- ment. In this paper, we present a methodology for the design of situated agents that is based on theory. This approach allows designers to describe the informational content of situated-automata an agent’s computational states in a semantically rigorous way without requiring a commitment to conventional run-time symbolic processing. We start by outlining this situated view of repre- sentation, then show how it contributes to design methodologies for building systems that track perceptual conditions and take purposeful actions in their environments. 1. Introduction Humans, delivery robots, and automated factories are all systems that have an in- telligent, ongoing interaction with environments that are dynamic and imperfectly pre- dictable. Such systems are often called situated agents. They constitute an important class of systems that are very difficult to program because of their close interaction with the environment in which they are situated. Specifications of correctness for situated agents amount to specifications of their interactions with the environment: what action should the agent take when the environment is in a particular configuration? Programs * Corresponding author. E-mail: lpk@cs.brown.edu. ’ Work on this paper was suppolted in part by the National Aeronautics and Space Administration under contract NAS2-13326 and by the Defense Advanced Research Projects Agency under NASA contract NASZ- 13229 and under TEC contract DATA76-93-C-0017. * Work on this paper was supported in pm by National Science Foundation National Young Investigator Award IRI-9257592 and in part by ONR Contract NOOO14-91-4052, ARPA Order 8225. OOO4-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00056-5 \f150 S.J. Rosenschein. LJ? Kuelbling/Artificial Intelligence 73 (I 995) 149-I 73 for situated agents must allow them to respond appropriately situations. to diverse, rapidly changing is an important theories of representation The emphasis on an agent’s connection to its environment and control. based on situated-automata symbolic the symbolic from that of traditional an informal overview of a particular methodology This methodology, to use high-level without requiring folk wisdom our view, this is not at all the case, and we feel there is much to gain from analyzing the semantics of representations outlining methodologies actions change In this paper, we present for the design of situated agents. [ 14,161, allows system designers content of agents in the agent. It has become In In this spirit, we start by to design and take purposeful that “situated agents” and “representation” this situated view of representation, that track perceptual conditions then show how it contributes from a situated perspective. in their environments. to be implemented the informational are incompatible for building to describe languages structures concepts. systems theory 2. Situated representation and building situated agents, is, at each moment Our ultimate aim, in designing is to have them perform that that are a rich set of tasks correctly; and goals. In order to specify correct behavior, and then to their situations appropriate to show that a particular program will satisfy that specification, we need to make precise the relationship Once behavior the internal states of an agent and conditions is made precise, we can give clear specifications states of the agent that satisfies for an agent in an environment and then generate a program to carry out actions those specifications. in its environment. this relationship for manipulating of desired between internal For example, suppose we are designing an agent whose task it is to water a plant and only if it is dry. From the outset, we must take into account the agent and the environment: about the agent, water the plant, and a statement about the environment, when it is dry. In order to design such a controller, we must have a systematic way of talking about the relationship the agent and its environment. of our problem contains the specification between if the interaction between a statement 2.1. Existing approaches There has been a variety of approaches to describing the relationship between agents and their environments. Many simple embedded systems are designed according little internal that describe variables in parametric theory. These systems usually have very of estimates of a set of real-valued directly quantities estimate actions well when upon which correct control those quantities the agent’s responses depend, inside the agent based on incoming to then designs machinery sensory signals. The control taken by the agent depend on the estimates of the quantities. This approach works can be described by simple interaction with the environment form. The designer of the control system chooses state, which to the principles of control consists typically the state of the environment the real-world \fS.J. Rosenschein, L.P. Kaelbling/Artificial Intelligence 73 (1995) 149-I 73 151 functions continuous fairly directly. As agents and their environments information will have to be represented, the quantities and when In the artificial intelligence community, represented is typically environment the system’s designer, the agent’s memory is applicable complex world, but it can be computationally to arbitrarily including to the propositions that must be estimated can be sensed become more complex, more abstract and this approach will no longer suffice. an intended about semantics information an agent’s symbolically. A formal language that relates sentences the state of its is developed by in about the world that they denote. This approach states of the agent and the such a representation. relationships intractable between to maintain to provide ascriptional stored it useful have found in the world to a thermostat, speaks of attributing accounts of the re- researchers between in order for that agent’s actions states of an agent and states of the environment. McCarthy knowledge of the temperature [lo], and [ 121 gives a definition of knowledge of an agent in terms of what would have (in service of Many lationship for example, Newell to be true some goal). More formal notions of an agent’s having knowledge about its environment are found the knowledge of one agent about another’s knowledge tions, for example. Halpem and Moses knowledge tion protocols and Moses for specifying effective way of describing to model for the purpose of asking ques- [2] provide a concrete computational model of of communica- to that of Halpern to be an systems. We use an approach agents, finding similar the concept of knowledge in their applications in distributed in the work on epistemic logic: Moore between agent and environment. logic to the formalization [ 1 I] uses epistemic the relationship to be rational of epistemic embedded logic 2.2. The situated-automata model Traditional theories of computation putation of a function. The inputs are presented for some amount of time, then generates question and only one answer; of course, tially be changed. are based on the notion of computation process, to the computational as com- it works the answer and terminates. There is only one the question can be arbitrarily complex, poten- it cannot has started, including many simple questions, but once the computation 2.2.1. Interaction model It is more appropriate to think of an agent embedded in an environment from the environment For the purposes of this work, we model a transduction. It has a stream of inputs of outputs or actions to the environment. coupling between operating alternating then synchronous we require synchronously with one another; the agent generating turns, with interaction an output the agent In the transduction model, from inputs the agent and the environment as that of a pair of automata the world generating an input (or “perception”) that is, their interaction (or “action”) to the world. In order to make a plausible model of interacting with a dynamic environment, to generate actions, without fail, at strictly timed intervals. then, an agent is viewed as an automaton that generates a as performing and generates a stream the that are can be seen as taking to the agent, this mapping of the agent and its environment. We note in passing to outputs, mediated by its internal state. Fig. 1 shows the coupling there is only one agent that although \f152 S.J. Rosenschein, L.l? Kaelbling/Art@cial Intelligence 73 (1995) 149-I 73 Fig. I. Interaction between agent and environment. interesting in this model, most perspective of this model, however, all of the other agents, whether robotic or biological, are taken the properties of a single agent from its perspective. to be part of the environment. This gives us a way to discuss have large numbers of agents. From environments the 2.2.2. Correlational deJnition of information tasks are often specified then the agent should take action A. This specification if the agent had direct access immediately that is not the case. Because an agent’s actions in the form: when P is true of the state of the Agent could only be environment, to arbitrary properties of the implemented in reality can only world. In general, depend on its inputs and internal state, agent programs must ultimately be expressed in the form: when P’ is true of the state of the agent, then the agent shoul",
            {
                "entities": [
                    [
                        75,
                        120,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 694–729Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSampleSearch: Importance sampling in presence of determinismVibhav Gogate a,∗,1, Rina Dechter ba Computer Science & Engineering, University of Washington, Seattle, WA 98195, USAb Donald Bren School of Information and Computer Sciences, University of California, Irvine, Irvine, CA 92697, USAa r t i c l ei n f oa b s t r a c tThe paper focuses on developing effective importance sampling algorithms for mixedprobabilistic and deterministic graphical models. The use ofimportance sampling insuch graphical models is problematic because it generates many useless zero weightsamples which are rejected yielding an inefficient sampling process. To address thisrejection problem, we propose the SampleSearch scheme that augments sampling withsystematic constraint-based backtracking search. We characterize the bias introduced bythe combination of search with sampling, and derive a weighting scheme which yields anunbiased estimate of the desired statistics (e.g., probability of evidence). When computingthe weights exactly is too complex, we propose an approximation which has a weakerguarantee of asymptotic unbiasedness. We present results of an extensive empiricalevaluation demonstrating that SampleSearch outperforms other schemes in presence ofsignificant amount of determinism.© 2010 Elsevier B.V. All rights reserved.Article history:Received 31 July 2009Received in revised form 1 October 2010Accepted 21 October 2010Available online 5 November 2010Keywords:Probabilistic inferenceApproximate inferenceImportance samplingMarkov chain Monte CarloBayesian networksMarkov networksSatisfiabilityModel countingConstraint satisfaction1. IntroductionThe paper investigates importance sampling algorithms for answering weighted counting and marginal queries over mixedprobabilistic and deterministic networks [1–4]. The mixed networks framework treats probabilistic graphical models such asBayesian and Markov networks [5], and deterministic graphical models such as constraint networks [6] as a single graphicalmodel. Weighted counts express the probability of evidence of a Bayesian network, the partition function of a Markovnetwork and the number of solutions of a constraint network. Marginals seek the marginal distribution of each variable,also called belief updating or posterior estimation in a Bayesian or Markov network.It is straightforward to design importance sampling algorithms [7–9] for approximately answering counting and marginalqueries because both are variants of summation problems for which importance sampling was designed. Weighted counts isthe sum of a function over some domain while a marginal is a ratio between two sums. The main idea is to transform asummation into an expectation using a special distribution called the proposal (or importance) distribution from which itwould be easy to sample. Importance sampling then generates samples from the proposal distribution and approximates theexpectation (also called the true average or the true mean) by a weighted average over the samples (also called the sampleaverage or the sample mean). The sample mean can be shown to be an unbiased estimate of the original summation, andtherefore importance sampling yields an unbiased estimate of the weighted counts. For marginals, importance sampling hasto compute a ratio of two unbiased estimates yielding an asymptotically unbiased estimate only.* Corresponding author.E-mail addresses: vgogate@cs.washington.edu (V. Gogate), dechter@ics.uci.edu (R. Dechter).1 This work was done when the author was a graduate student at University of California, Irvine.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.009\fV. Gogate, R. Dechter / Artificial Intelligence 175 (2011) 694–729695In presence of hard constraints or zero probabilities, however, importance sampling may suffer from the rejection prob-lem. The rejection problem occurs when the proposal distribution does not faithfully capture the constraints in the mixednetwork. Consequently, many samples generated from the proposal distribution may have zero weight and would not con-tribute to the sample mean. In extreme cases, the probability of generating a rejected sample can be arbitrarily close to oneyielding completely wrong estimates.In this paper, we propose a sampling scheme called SampleSearch to remedy the rejection problem. SampleSearch com-bines systematic backtracking search with Monte Carlo sampling. In this scheme, when a sample is supposed to be rejected,the algorithm continues instead with randomized backtracking search until a sample with non-zero weight is found. Thisproblem of generating a non-zero weight sample is equivalent to the problem of finding a solution to a satisfiability (SAT)or a constraint satisfaction problem (CSP). SAT and CSPs are NP-complete problems and therefore the idea of generatingjust one sample by solving an NP-complete problem may seem inefficient. However, recently SAT/CSP solvers have achievedunprecedented success and are able to solve some large industrial problems having as many as a million variables within afew seconds.2 Therefore, solving a constant number of NP-complete problems to approximate a #P-complete problem suchas weighted counting is no longer unreasonable.We show that SampleSearch generates samples from a modification of the proposal distribution which is backtrack-free.The backtrack-free distribution can be obtained by removing all partial assignments which lead to a zero weight sample. Inparticular, the backtrack-free distribution is zero whenever the target distribution from which we wish to sample is zero.We propose two schemes to compute the backtrack-free probability of the generated samples which is required for com-puting the sample weights. The first is a computationally intensive method which involves invoking a CSP or a SAT solverO (n × d) times where n is the number of variables and d is the maximum domain size. The second scheme approximatesthe backtrack-free probability by consulting information gathered during SampleSearch’s operation. This latter scheme hasseveral desirable properties: (i) it runs in linear time, (ii) it yields an asymptotically unbiased estimate, and (iii) it canprovide upper and lower bounds on the exact backtrack-free probability.Finally, we present empirical evaluation demonstrating the power of SampleSearch. We implemented SampleSearch ontop of IJGP-wc-IS [10], a powerful importance sampling technique which uses a generalized belief propagation algorithm [11]called Iterative Join Graph Propagation (IJGP) [12,13] to construct a proposal distribution and w-cutset (Rao-Blackwellised)sampling [14] to reduce the variance. The search was implemented using the minisat SAT solver [15]. We conducted ex-periments on three tasks: (a) counting models of a SAT formula, (b) computing the probability of evidence in a Bayesiannetwork and the partition function of a Markov network, and (c) computing posterior marginals in Bayesian and Markovnetworks.For model counting, we compared against three approximate algorithms: ApproxCount [16], SampleCount [17] and Rel-sat [18] as well as with IJGP-wc-IS, our vanilla importance sampling scheme on three classes of benchmark instances. Ourexperiments show that on most instances, given the same time-bound SampleSearch yields solution counts which are closerto the true counts by a few orders of magnitude compared with the other schemes. It is clearly better than IJGP-wc-ISwhich failed on all benchmark SAT instances and was unable to generate a single non-zero weight sample in ten hours ofCPU time.For the problem of computing the probability of evidence in a Bayesian network, we compared SampleSearch withVariable Elimination and Conditioning (VEC) [19], an advanced generalized belief propagation scheme called Edge DeletionBelief Propagation (EDBP) [20] as well as with IJGP-wc-IS on linkage analysis [21] and relational [22] benchmarks. Ourexperiments show that on most instances the estimates output by SampleSearch are more accurate than those output byEDBP and IJGP-wc-IS. VEC solved some instances exactly, however on the remaining instances it was substantially inferior.For the posterior marginal task, we experimented with linkage analysis benchmarks, with partially deterministic gridbenchmarks, with relational benchmarks and with logistics planning benchmarks. Here, we compared the accuracy ofSampleSearch against three other schemes: the two generalized belief propagation schemes of Iterative Join Graph Prop-agation [12,13] and Edge Deletion Belief Propagation [20] and an adaptive importance sampling scheme called EvidencePre-propagated Importance Sampling (EPIS) [23]. Again, we found that except for the grid instances, SampleSearch consis-tently yields estimates having smaller error than the other schemes.Based on this large scale experimental evaluation, we conclude that SampleSearch consistently yields very good approxi-mations. In particular, on large instances which have a substantial amount of determinism, SampleSearch yields an order ofmagnitude improvement over state-of-the-art schemes.The paper is based on earlier conference papers [24,25]. The present article contains more detailed and general analysis,full proofs, new bounding approximations (described in Section 4.2.1), as well as new experimental results.The rest of the paper is organized as follows. In Section 2, we present notation and preliminaries on graphical models andimportance sampling. In Section 3, we present the rejection problem and show how to overcome it using the backtrack-freedistribution. Section 4 describes the SampleSearch scheme and various improvements. In Section 5, we present experimentalresults and we conclude in Section 6.2 See results of SAT competitions available at http://www.satcompetition.org/.\f696V. Gogate, R.",
            {
                "entities": [
                    [
                        136,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 70–94Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstrained clustering by constraint programmingThi-Bich-Hanh Dao∗, Khanh-Chuong Duong, Christel VrainUniv. Orléans, INSA Centre Val de Loire, LIFO, EA 4022, F-45067, Orléans, Francea r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 12 May 2015Accepted 23 May 2015Available online 29 May 2015Keywords:Constrained clusteringBi-criterion clusteringConstraint programmingModelingGlobal optimization constraintFiltering algorithmConstrained Clustering allows to make the clustering task more accurate by integrating user constraints, which can be instance-level or cluster-level constraints. Few works consider the integration of different kinds of constraints, they are usually based on declarative frameworks and they are often exact methods, which either enumerate all the solutions satisfying the user constraints, or find a global optimum when an optimization criterion is specified. In a previous work, we have proposed a model for Constrained Clustering based on a Constraint Programming framework. It is declarative, allowing a user to integrate user constraints and to choose an optimization criterion among several ones. In this article we present a new and substantially improved model for Constrained Clustering, still based on a Constraint Programming framework. It differs from our earlier model in the way partitions are represented by means of variables and constraints. It is also more flexible since the number of clusters does not need to be set beforehand; only a lower and an upper bound on the number of clusters have to be provided. In order to make the model-based approach more efficient, we propose new global optimization constraints with dedicated filtering algorithms. We show that such a framework can easily be embedded in a more general process and we illustrate this on the problem of finding the optimal Pareto front of a bi-criterion constrained clustering task. We compare our approach with existing exact approaches, based either on a branch-and-bound approach or on graph coloring on twelve datasets. Experiments show that the model outperforms exact approaches in most cases.© 2015 Elsevier B.V. All rights reserved.1. IntroductionConstrained Clustering has received much attention this last decade. It allows to make the clustering task more accurate by integrating user constraints. Several kinds of constraints can be considered. First, constraints may be used to limit the size or the diameter of clusters; second, they can enforce expert knowledge instances that must be or cannot be in the same cluster (must-link or cannot-link constraints). Much work has focused on instance-based constraints and has adapted classi-cal clustering methods to handle must-link or cannot-link constraints. A small number of earlier studies have considered the integration of different kinds of constraints. These studies are based on declarative frameworks and offer exact methods that either enumerate all the solutions satisfying the user constraints, or find a global optimum when an optimization criterion is given. For instance, in [1] a SAT based framework for constrained clustering has been proposed, integrating many kinds of user constraints but limited to clustering tasks into two clusters. A framework for conceptual clustering based on Integer Linear Programming has also been proposed in [2]. In [3], we have presented a model based on Constraint Programming for * Corresponding author.E-mail addresses: thi-bich-hanh.dao@univ-orleans.fr (T.-B.-H. Dao), khanh-chuong.duong@univ-orleans.fr (K.-C. Duong), christel.vrain@univ-orleans.fr(C. Vrain).http://dx.doi.org/10.1016/j.artint.2015.05.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\fT.-B.-H. Dao et al. / Artificial Intelligence 244 (2017) 70–9471constrained clustering. This model allows to choose one among different optimization criteria and to integrate various kinds of user constraints. As far as we know, the approach we propose is the only one able to handle different optimization crite-ria and all popular constraints, for any number of clusters. It is based on Constraint Programming (CP): in such a paradigm, a constraint optimization problem or a constraint satisfaction problem is modeled by defining variables with their domains and by expressing constraints on these variables. Solving a CP problem relies on two operations: constraint propagation that reduces the domain of the variables by removing inconsistent values and branching that divides the problem in subprob-lems, by taking an unassigned variable and by splitting its domain into several parts. It is important to notice that modeling a task in Constraint Programming implies several choices, which have a high impact on the efficiency of the approach: the choice of the variables and the choice of the constraints for the model, the development of filtering algorithms dedicated to the task and the use of adapted search strategies for solving the model. A point in favor of CP is that the requirement of getting an exact solution can be relaxed by using metaheuristics or local search methods. For the time being, we have fully investigated exact methods, to push the efficiency of the framework as far as possible. Approximate search strategies could be integrated in the future.In this paper, we propose a new model for Constrained Clustering, still based on Constraint Programming, but signifi-cantly improved compared to the previous model [3]. In the previous model, two sets of variables were introduced, namely a variable for each cluster identifying a cluster by one of its points and a variable for each point expressing its assignment to a cluster. The number of clusters had to be set beforehand. The new model we present here contains only a variable for each point, giving the index of the cluster the point belongs to. As a result, the constraints enforcing the solution to be a partition and breaking symmetries are entirely different. The new model is lighter in terms of the number of variables. It also enables to remove the restriction on the number of clusters; only bounds on the number of clusters are required. Moreover, in order to make this model efficient, we have developed dedicated global constraints for three optimization criteria: minimizing the maximal diameter, maximizing the split between clusters, and minimizing the within-cluster sum of dissimilarities.The approach we propose may be easily embedded in a general process for the task of Constrained Clustering. Consider-ing Data Mining as an iterative and interactive process composed of the classical steps of task formulation, data preparation, application of a tool, thus requiring to set parameters, and validation of the results, a user can specify the task at hand including or not some constraints and decide to change the settings according to the results. He/she may decide to change the constraints, removing or relaxing some constraints, adding or hardening other constraints. The modularity and declara-tivity of our model allow this easily. In this paper, we illustrate the integration of our model in a more complex process by considering a bi-criterion clustering problem, namely finding the Pareto front when minimizing the maximal diameter and maximizing the minimal split. To achieve this, our framework is integrated in an algorithm, which alternatively calls our model to minimize the maximal diameter and then to maximize the split between clusters with adapted constraints.Our contributions are as follows.• We propose a new model based on Constraint Programming, allowing to find an optimal solution for clustering under constraints, given an optimization criterion. This new model improves substantially the previous one, it is more modular (each criterion is implemented by a global constraint) and it is much more efficient.• We show that such a framework can easily be embedded in a more general process and we illustrate this on the problem of finding the optimal Pareto front of a bi-criterion constrained clustering task. As far as we know, this is the first approach to handle bi-criterion clustering in presence of user-constraints.• We propose new global optimization constraints with dedicated filtering algorithms, thus allowing to make the model more efficient.• We compare this model with existing exact approaches, based either on a branch-and-bound approach [4] or on graph coloring [5] on twelve datasets. Experiments show that the model we propose is generally more efficient. Moreover we compare the two models based on CP that we have developed and we show that the different changes (search strategy and development of global constraints) allow to improve the model.The paper is organized as follows. Section 2 is dedicated to preliminaries on Constrained Clustering and Constraint Programming. Related work is presented in Section 3. Section 4 is devoted to the presentation of both CP models, the first one presented in [3] and the new one. The filtering algorithms for the optimization criteria are presented in Section 5. We show in Section 6 how our framework can be easily integrated for solving a bi-criterion constrained clustering task. Experiments are presented in Section 7, showing the performance and the flexibility of our approach.2. Preliminaries2.1. Constrained clusteringCluster analysis is a Data Mining task that aims at partitioning a given set of objects into homogeneous and/or well-separated subsets, called classes or clusters. It is often formulated as the search for a partition such that the objects inside the same cluster are similar, while being different from the objects belonging to other clusters. These requirements are usually expressed by an optimization criterion and the clustering task is usually defined as finding a partition of objects \f72T.-B.-H. Dao et al. / Artificial Intelligenc",
            {
                "entities": [
                    [
                        134,
                        182,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 890–913Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLoop-separable programs and their first-order definabilityYin Chen a,∗, Fangzhen Lin b, Yan Zhang c, Yi Zhou ca Department of Computer Science, South China Normal University, Guangzhou, Guangdong, Chinab Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kongc Intelligent Systems Lab, School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiaa r t i c l ei n f oa b s t r a c tAn answer set program with variables is first-order definable on finite structures if the setof its finite answer sets can be captured by a first-order sentence. Characterizing classesof programs that are first-order definable on finite structures is theoretically challengingand of practical relevance to answer set programming. In this paper, we identify a non-trivial class of answer set programs called loop-separable programs and show that they arefirst-order definable on finite structures.© 2010 Elsevier B.V. All rights reserved.Article history:Received 23 December 2009Received in revised form 18 December 2010Accepted 18 December 2010Available online 22 December 2010Keywords:Answer set programmingFirst-order definabilityKnowledge representationNonmonotonic reasoning1. IntroductionThis work is about answer set programming (ASP), a constraint-based programming paradigm that has been foundapplications in a wide range of areas including bioinformatics [9,12,29] and the semantic web [11,27]. Currently in ASPapplications, a program normally has two parts: a finite set of rules with variables, and a finite set of ground facts. Theformer represents general domain knowledge and the latter the specific instance of the problem that one wants to solve.Since current ASP solvers can only deal with rules without variables [14,20,22,28], the latter is used to ground the formerinto a set of propositional rules, and together they are given to an ASP solver.Recently there has been work on extending answer set semantics to programs with variables [4,13,23,25], and to considerthe possibility of constructing an ASP solver that can deal with rules with variables [4]. Against this backdrop, in this paperwe consider the problem of first-order definability of answer set programs with variables. This is a problem because ingeneral, the answer sets of a program with variables correspond to a second-order sentence [13,23] or an infinite set offirst-order sentences [4].The study on non-grounding based method for computing answer sets/stable models has been carried out by someresearchers [10,16]. The motivation of developing this approach is to avoid large sets of facts after grounding a programcontaining variables. By introducing concepts such as constrained non-ground stables [10] and covers/anticovers [16], usingthis approach we can derive some kind of compact representations of the stable models of the original program, so thatstable models may be partially pre-computed at compile-time.Although both the approach mentioned above and the first-order definability of logic programs address non-groundinglogic programs, the foundation of these two topics are actually quite different. In this paper, our study will be based on thefirst-order stable model semantics and identify a class of programs that is first-order definable on finite structures, whilethe non-ground approach only provided an alternative method to compute stable models of a propositional logic program.* Corresponding author.E-mail addresses: ychen@scnu.edu.cn (Y. Chen), flin@cse.ust.hk (F. Lin), yan@scm.uws.edu.au (Y. Zhang), yzhou@scm.uws.edu.au (Y. Zhou).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.12.001\fY. Chen et al. / Artificial Intelligence 175 (2011) 890–913891While our work presented in this paper is the first in-deep study on the first-order definability of answer set programswith variables, we should mention that the related problem has been addressed in propositional case. In particular, Dungand Kanchanasut have shown that every propositional logic program Π can be transformed into a propositional theory T Πsuch that the set of stable models of Π is exactly the set of models of T Π [8]. More recently, Lin and Zhao proved a similarresult by using loop-formulas [22].Studying the first-order definability of answer set programs has both theoretical and practical values. Firstly, since thesemantics of first-order answer set programs is defined based on second-order logic, it becomes an immediate issue tounderstand the expressive power of first-order answer set programs. Results of the first-order definability will providepartial answers to this issue and help us to achieve a better understanding on the difference between first-order answer setprograms and classical first-order logic. Results in this aspect will provide an important theoretical foundation for first-orderanswer set programming.Secondly, as evident from the work in Datalog and finite model theory, proving first-order definability results are usuallyhighly challenging. Very often, new proof techniques have to be developed, which may also be useful for other problemsolving. For instance, as it will be shown in this paper, in order to prove our first-order definability result, we extend theexpansion tree concept in Datalog [3] to ASP and apply it to loop-separable programs. We believe that both the notion ofloop-separable programs and the new expansion tree concept proposed in this paper may be useful for other related studiesin first-order answer set programming.Finally, knowing that a program is first-order definable is certainly helpful if one wants to construct an ASP solver forfirst-order answer set programs. It initiates the possibility of exploiting first-order inference tools, e.g. model generators andtheorem provers, to reason on programs that are first-order reducible. Also, it can be helpful for SAT-based propositionalASP solvers. This is because current SAT-based ASP solvers compute loop formulas incrementally as needed. If we know thatthe given program can be captured by a first-order sentence, then it may be more effective to bypass loop formulas andjust instantiate the first-order sentence on a given instance directly.In this paper, we show that if a program is so-called loop-separable, then it is first-order definable on finite structures.Furthermore, it is decidable whether a program is loop-separable. As we shall see, the notion of loop-separable programsdepends on a careful study of how rules interacts with first-order loops introduced in [4]. It also includes all first-orderdefinable classes of programs that we knew of, like the class of program with finite set of complete loops.The rest of the paper is organized as follows. Section 2 presents basic logic concepts and notions which will be usedin our following study. Section 3 introduces the notion of first-order definability, and Section 4 defines a class of programscalled loop-separable program. Section 5 contains the detailed proof that loop-separable programs are first-order definable.Section 6 considers some special subclasses of loop-separable programs and discusses some related work. Finally, Section 7concludes this paper with some discussions.2. First-order answer set programs with extensional databases2.1. PreliminariesWe consider a second-order language with equality but without function symbols. A vocabulary consists of a finite setof constant symbols and a finite non-empty set of relation symbols including equality =. Given a vocabulary τ , we denote byC(τ ) the sets of constant symbols in τ , and by P(τ ) the set of relation symbols. The notions of term, atom, (first-order orsecond-order) formula and (first-order or second-order) sentence are defined as usual. An atom is called an equality atomif it is an atom of the form t1 = t2, and a proper atom otherwise. We use Var(O) to denote the set of variables occurringin O, which can be a term, atom, formula, sentence or other expressions. Given a vocabulary τ , the unique name assumption(or UNA for short) on τ , denoted by Σuna(τ ) (or Σuna when τ is obvious from the context), is the conjunction of ci (cid:3)= c j forany two different constant ci, c j in C(τ ).¬∀x(Q (x) ⊃ P (x)). For the given tuples of relation symbols P = (P 1, . . . , P k) and P (cid:7) = (P(1 (cid:2) i (cid:2) k) have the same arity, we use P < P (cid:7)Let P and Q be two relation symbols or variables of the same arity. P < Q stands for the formula ∀x(P (x) ⊃ Q (x)) ∧(cid:7)(cid:7)(cid:7)1, . . . , Pk), where all P i and P(cid:2)iki=1(cid:2)ki=1AAAn ), where A is a finite set called the domain of A,A finite structure A of vocabulary τ is a tuple ( A, cm , R1 , . . . , cAA(the interpretation of a k-ary relation symbol R i ) (1 (cid:2) i (cid:2) n),∈ A (the interpretation of constant ci ) (1 (cid:2) i (cid:2) m), and Rciia k-ary relation on A. In the following, we use Dom(A) to denote the domain of structure A. Unless stated otherwise, thedomains of all structures are assumed to be finite in this paper.(cid:7)i(x) ⊃ P i(x)).to denote the formulaGiven two tuples s = (s1, . . . , sn) and ¯t = (t1, . . . , tn) of the same length, we use s = ¯t to denote the formulai=1 si = ti ,and s (cid:3)= ¯t the formula ¬(s = ¯t). A binding is an expression of the form x/t, where x is a variable, and t a term, and asubstitution is a set of bindings containing at most one binding for each variable. If ϕ is a first-order formula (term, tuple ofterms, etc.), and θ a substitution, we denote by ϕθ the result of replacing every free variable in ϕ according to θ .∀x(P i(x) ⊃ P(cid:7)i(x)) ∧ ¬A1 , . . . , R∀x(PGiven a set of variables or relation variables V and a structure A, an assignment σ on V over A is function that assignseach variable in V to a domain element in Dom(A",
            {
                "entities": [
                    [
                        136,
                        194,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 81 ( 1996) 59-80 Artificial Intelligence The satisfiability constraint gap Ian l? Gent a,*, Toby Walsh b*c*l a Department of AI, Universiv of Edinburgh, 80 South Bridge, Edinburgh, UK h Mechanized Reasoning Group, IRSZ Lx. Pant6 di Povo, Trento, Italy c DISZ University of Genoa, Genoa, Italy Received May 1994; revised March 1995 Abstract We describe an experimental investigation of the satisfiability phase transition for several dif- ferent classes of randomly generated problems. We show that the “conventional” picture of easy- hard-easy problem difficulty is inadequate. In particular, there is a region of very variable problem difficulty where problems are typically underconstrained and satisfiable. Within this region, prob- lems can be orders of magnitude harder than problems in the middle of the satisfiability phase transition. These extraordinarily hard problems appear to be associated with a “constraint gap”. That is, a region where search is a maximum as the amount of constraint propagation is a min- imum. We show that the position and shape of this constraint gap change little with problem size. Unlike hard problems in the middle of the satisfiability phase transition, hard problems in the variable region are not critically constrained between satisfiability and unsatisfiability. Indeed, hard problems in the variable region often contain a small and unique minimal unsatisfiable subset or reduce at an early stage in search to a hard unsatisfiable subproblem with a small and unique minimal unsatisfiable subset. The difficulty in solving such problems is thus in identifying the minimal unsatisfiable subset from the many irrelevant clauses. The existence of a constraint gap greatly hinders our ability to find such minimal unsatisfiable subsets. However, it remains open whether these problems remain hard for more intelligent backtracking procedures. We conjecture that these results will generalize both to other SAT problem classes, and to the phase transitions of other NP-hard problems. Keywords: Search phase transitions; Satisfiability; Constraint propagation; Hard problems *Current address: Department of Computer Science, University of Strathclyde, Glasgow Gl IXH, UK. E-mail: ipg@cs.strath.ac.uk. ’ E-mail: toby@irst.it. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00047-X \f60 1.P Gent, lY Walsh/Artijcial Intelligence 81 (19%) 59-80 1. Introduction Many randomly generated NP-hard problems display a phase transition as some pa- rameter is varied, and as the problems go from being almost always soluble to being [ 31. This phase transition is often associated with problems almost always insoluble which are typically hard to solve. In this paper, we show that with several different classes of satisfiability problems including random 3-SAT, the phase transition is indeed associated with problems which are typically hard but there are also regions of very vari- able problem difficulty in which problems are usually easy but sometimes extraordinarily hard. We identify the cause of this behaviour and show that it does not disappear with better algorithms or heuristics. We predict that similar regions of very variable problem difficulty will be found with many other NP-hard problems besides satisfiability. The extraordinarily hard problems found in these regions may be of use in analysing and comparing the performance of algorithms for NP-hard problems. 2. Satisfiability Propositional satisfiability (or SAT) is the problem of deciding if there is an assign- ment of truth values for the variables in a propositional formula that makes the formula true using the standard interpretation for logical connectives. We will consider SAT problems in conjunctive normal form (CNF) ; a formula, 2, in CNF is a conjunction of clauses, where a clause is a disjunction of literals, and a literal is a negated or un-negated variable. A standard procedure for determining satisfiability is due to Davis, Putnam, Logemann, and Loveland [ 5,6]. We call this the “Davis-Putnam procedure”. * See Fig. 1. procedure DP( 2) if .Z is empty then return satisfiable if 2 contains an empty clause then return unsatisfiable (Tautology) if 2 contains a tautologous clause c then return DP( 2 - c) (Unit propagation) if 2 contains a unit clause (1) then return DP( 2 simplified by assigning 2 to True) (Pure literal deletion) if 2 contains a literal I but not the negation of 1 then return DP( 2 simplified by assigning 1 to True) (Split) if DP( 2 simplified by assigning a literal 1 to True) is satisfiable then returu satisfiable else return DP( 2 simplified by assigning the negation of 1 to True) Fig. 1. The Davis-Putnam procedure. 2 We follow recent nomenclature [ 8,141. Davis and F’utnam [ 61 introduced the unit and pure rules, while it was Davis, Logemann, and Loveland [5] who introduced the split rule and the use of backtracking. The latter authors modestly presented the difference as merely one of implementation. in this, for example \f1.P. Gent, T Walsh/Artificial Intelligence 81 (19%) 59-80 61 An empty clause contains no literals, a unit clause contains just a single literal, and a tautologous clause contains both a literal and its negation. To simplify a set of clauses by the assignment of the literal I to True, we delete every clause that contains 1 and delete the negation of 1 whenever it occurs in the remaining clauses. Note that the Davis-Putnam procedure is non-deterministic since the literal used by the split rule is unspecified. As in previous studies (e.g. [ 8,14]), we will split upon the first literal in the first clause. We call this variant of the Davis-Putnam procedure “DP”. With good heuristics for choosing the literal to split on, an efficient implementation of the Davis-Putnam procedure is still the best complete procedure for satisfiability [ 71. 3. Constant probability model The constant probability model of randomly generated problems has been the subject of considerable theoretical and experimental attention. In this model, given N variables and L clauses, each clause is generated so that it contains each of the 2N different literals with probability p. Our experiments use a variant of the constant probability model proposed in [ 111 and since used in other experimental studies [ 8,9,14]. In this problem class, if an empty or unit clause is generated, it is discarded and another clause generated in its place. This is because the inclusion of empty or unit clauses typically makes problems easier. We shall call this the “CP” model. In all our experiments, as in [ 8,9], we choose p so that 2Np = 3 and the mean clause length remains approximately constant as N varies. In [ 141, it is shown that there is a phase transition between satisfiability and unsatisfiability for CP as the ratio of clauses to variables, L/N, is varied. If 2Np is kept constant, then this phase transition occurs at L/N M 2.80 as N--too [9]. The satisfiability phase transition is of computational importance since there is an easy-hard-easy pattern in problem difficulty as we cross the phase transition with the hardest instances occurring in the phase transition [ 141. When the ratio of clauses to variables is large, problems are usually overconstrained, and thus easily shown to be unsatisfiable. When the ratio is small, problems are usually underconstrained, and a satisfying assignment can be “guessed” quickly. The hard instances tend to occur in the phase transition where the problems are neither overconstrained nor underconstrained. In [ 81, we showed that whilst median problem difficulty has a simple easy-hard- easy pattern, there is also a region of very variable and sometimes exceptionally hard problem difficulty at a high-percentage satisfiability. The worst-case problems in this region can be orders of magnitude harder than those in the middle of the satisfiability phase transition. These extraordinary problems can easily dominate the mean problem difficulty. Similar behaviour has been observed by Hogg and Williams for randomly generated 3-colourability problems [ lo]. Fig. 2(a) gives the mean and median number of branches used by DP for 1000 problems from the CP model at N = 100 with L/N from 0.1 to 6.0 in intervals of 0.1. The number of branches is the number of leaf nodes in the search tree. It pro- vides a good indication of problem difficulty and run time. The dotted line indicates the observed probability that problems were satisfiable. There is a very considerable differ- \f62 I.F! Gent, 1: Walsh/Artificial Intelligence 81 (1996) 59-80 i.. 0.6 i.. 0.2 i.. 0 4 5 6 L/N 2 Pmb(sat) :- , i.. 0.8 i__ 0.6 ;_. 0.4 :.. 0.2 ;.. 0 5 L/N (b) ;hO,OOO p:oblems Fig. 2. CP problems tested using DP, N = 100. Mean and median branches. ence between mean and median performance. The worst-case mean of 62.5 branches occurs at L/N = 2.4 in a mostly satisfiable region, whilst the worst-case median of just 9 branches occurs at L/N = 3.9 in the middle of the satisfiability phase transi- tion. Despite testing 1000 problems at each point, there is a large amount of noise in the mean, especially in the region of L/N from about 2 to 4, and despite the use of a logarithmic scale. In Fig. 2(b), we therefore tested 100,000 problems per point. Due to the large cost of testing this number of problems, we restricted our attention to the region L/N = 1.5 to 5.0. Although the noise is reduced considerably by taking 100,000 problems, there is still a large difference between mean and median perfor- mance. The greatest difference is in the region that was previously noisy and where median performance is only 1 or 2 branches. There is a secondary peak in mean prob- lem difficulty of 24.3 branches at L/N = 3.0. The worst-case mean of 35.0 branches occurs at L/N = 3.6, close to the worst-case median of 9 branches in the middle of the satisfiability phase transition. The variable behaviour in the satisfiable region increases rapidly wit",
            {
                "entities": [
                    [
                        65,
                        98,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 243 (2017) 26–44Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCCEHC: An efficient local search algorithm for weighted partial maximum satisfiabilityChuan Luo a,b, Shaowei Cai c,∗a Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, Chinab State Key Laboratory of Mathematical Engineering and Advanced Computing, Wuxi 214125, Chinac State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing 100190, Chinad College of Information Science and Technology, Jinan University, Guangzhou 510632, Chinae Institute for Integrated and Intelligent Systems, Griffith University, Brisbane 4111, Australiaf Department of Material Science and Engineering, Massachusetts Institute of Technology, MA 02139, USA, Kaile Su d,e, Wenxuan Huang fa r t i c l e i n f oa b s t r a c tArticle history:Received 13 May 2015Received in revised form 19 October 2016Accepted 14 November 2016Available online 17 November 2016Keywords:Local searchWeighted partial maximum satisfiabilityEmphasis on hard clauses1. IntroductionWeighted maximum satisfiability and (unweighted) partial maximum satisfiability (PMS) are two significant generalizations of maximum satisfiability (MAX-SAT), and weighted partial maximum satisfiability (WPMS) is the combination of the two, with more important applications in practice. Recently, great breakthroughs have been made on stochastic local search (SLS) for weighted MAX-SAT and PMS, resulting in several state-of-the-art SLS algorithms CCLS, Dist and DistUP. However, compared to the great progress of SLS on weighted MAX-SAT and PMS, the performance of SLS on WPMS lags far behind. In this paper, we present a new SLS algorithm named CCEHC for WPMS. CCEHC employs an extended framework of CCLS with a heuristic emphasizing hard clauses, called EHC. With strong accents on hard clauses, EHC has three components: a variable selection mechanism focusing on configuration checking based only on hard clauses, a weighting scheme for hard clauses, and a biased random walk component. Extensive experiments demonstrate that CCEHC significantly outperforms its state-of-the-art SLS competitors. Further experimental results on comparing CCEHC with a state-of-the-art complete solver show the effectiveness of CCEHC on a number of application WPMS instances, and indicate that CCEHC might be beneficial in practice. Also, empirical analyses confirm the effectiveness of each component underlying the EHC heuristic.© 2016 Elsevier B.V. All rights reserved.The maximum satisfiability (MAX-SAT) problem is the optimization version of the Boolean satisfiability (SAT) problem, which is a prototypical NP-complete problem and is of great importance in a variety of fields of computer science, mathe-matical logic and artificial intelligence. In the context of the SAT and MAX-SAT problems, a propositional formula F is usually (cid:3)expressed in conjunctive normal form (CNF) [1], i.e., F =j lij, where each lij is a literal, which is either a Boolean vari-able or its negation. A CNF formula can be expressed as a set of clauses, where a clause is a disjunction of literals, and each CNF formula is a conjunction of clauses.(cid:2)i* Corresponding author.E-mail addresses: chuanluosaber@gmail.com (C. Luo), shaoweicai.cs@gmail.com (S. Cai), k.su@griffith.edu.au (K. Su), key01027@mit.edu (W. Huang).http://dx.doi.org/10.1016/j.artint.2016.11.0010004-3702/© 2016 Elsevier B.V. All rights reserved.\fC. Luo et al. / Artificial Intelligence 243 (2017) 26–4427Given a propositional formula in conjunctive normal form (CNF), the SAT problem is to decide whether an assignment exists such that all clauses in this CNF formula are satisfied; the MAX-SAT problem is to seek out an assignment that maximizes the number of satisfied clauses in the CNF formula; the weighted MAX-SAT problem, where each clause is associated with a positive integer as its weight, is to find an assignment that maximizes the total weight of satisfied clauses, and is an important generalization of MAX-SAT; the (unweighted) partial maximum satisfiability (PMS) problem, where clauses are divided into hard ones and soft ones, is to find an assignment that satisfies all hard clauses and maximizes the number of satisfied soft clauses, and is also an important generalization of MAX-SAT. The weighted partial maximum satisfiability (WPMS) problem is the combination of both weighted MAX-SAT and PMS, and is a significant generalization of MAX-SAT: Given a CNF formula, the WPMS problem, where clauses are divided into hard ones and soft ones, and each soft clause is associated with a positive integer as its weight, is to seek out an assignment that satisfies all hard clauses and maximizes the total weight of satisfied soft clauses. In theory, MAX-SAT and its generalizations (i.e., weighted MAX-SAT, PMS and WPMS), are typically NP-hard problems, and it is well known that optimal solutions to these problems are hard to approximate [2]. Thus, it is very interesting to explore high-performance heuristic procedures to solve these hard problems. In this paper, our focus is on the WPMS problem.In practice, as many combinatorial problems in real-world applications usually contain hard and soft constraints [3] and also soft constraints often have different priorities, encoding such real-world problems into the WPMS problem is more natural and direct than encoding them into SAT, MAX-SAT, weighted MAX-SAT or PMS. In fact, many important realistic problems in a wide range of real-world applications, such as computational protein design [4,5], set covering [6], coalition structure generation [7] and so on, can be encoded and solved as WPMS instances.There are two popular categories of practical algorithms for solving MAX-SAT: complete algorithms and stochastic local search (SLS) algorithms. Complete algorithms are able to prove the optimality of the solution, but they may not return a good-quality solution for large-sized instances within reasonable time [8]. Complete algorithms can be classified into two main classes: branch and bound MAX-SAT algorithms [9–11] which are based on DPLL procedures [12,13], and SAT based algorithms [14–16] which successively call an efficient CDCL (Conflict-Driven Clause Learning) SAT solver [17,18]. Although SLS algorithms are typically incomplete, i.e., they do not guarantee the optimality of the solutions they find, SLS algorithms are often able to find good-quality solutions within a reasonable time frame [19,3]. SLS algorithms are usually evolving out of GSAT [20] and WalkSAT [21]. However, there is little work on SLS algorithms for solving WPMS, and almost all of the existing solvers for solving WPMS are complete ones.Recently, significant breakthroughs have been achieved on SLS algorithms for solving weighted MAX-SAT and PMS, re-sulting in state-of-the-art SLS algorithms namely CCLS [22] and Dist [3] as well as Dist’s improvement DistUP [23]. The CCLSalgorithm makes great progress in solving weighted MAX-SAT. CCLS won several categories in the incomplete solver track of the MAX-SAT Evaluations 2013 and 2014, thanks to the configuration checking strategy [24], which has been successfully applied to SAT [25] and minimum vertex cover [26]. The CCLS algorithm can be used to solve WPMS by translating WPMS into weighted MAX-SAT, as the translation can be very straightforward via setting the weight of each hard clause to the total weight of all soft clauses plus 1. However, when it comes to the WPMS problem, CCLS loses its power and shows ineffec-tiveness, as can be seen from the competition results of the incomplete solver track of the MAX-SAT Evaluation 2014.1 The Dist algorithm shows great success on solving PMS, and won several categories in the incomplete solver track of the MAX-SAT Evaluation 2014, and also competes well with state-of-the-art complete algorithms on some classes of PMS application instances, such as advanced encryption standard and protein [3]. Dist can also be adapted to solve WPMS, and is indeed the current best SLS algorithm for solving WPMS, winning the random WPMS category and the crafted WPMS category in the incomplete solver track of the MAX-SAT Evaluation 2014. Particularly, the competition results of the MAX-SAT Evaluation 2014 show that Dist performs better than several state-of-the-art complete algorithms on the crafted WPMS benchmark. The DistUP algorithm, an improvement of Dist by using unit propagation as its initialization procedure, shows improvement over Dist on industrial instances. However, CCLS, Dist and DistUP are not dedicated to solving WPMS specifically, and their performance for solving WPMS could be further improved. Compared to the great progress of SLS algorithms on solving weighted MAX-SAT and PMS, the performance of SLS algorithms on solving WPMS lags far behind. This motivates us to design a more efficient SLS algorithm for solving WPMS. Inspired by the success of Dist as well as DistUP, our ambition is to solve more classes of structured problems and real-world ones.In this work, we present a new SLS algorithm named CCEHC (Configuration Checking with Emphasis on Hard Clauses) for solving WPMS. Our CCEHC algorithm employs an extended framework of CCLS with a heuristic emphasizing hard clauses, called EHC. With strong focus on hard clauses, the EHC heuristic has three components: a variable selection mechanism focusing on a forbidding mechanism of configuration checking based only on hard clauses, a weighting scheme for hard clauses, and an approach of biased random walk. Our main contributions in this paper are summarized as follows.Firstly, we identify an efficient algorithm framework for solving WPMS. It is surprising that our algorithm framework is based on CCLS instead of Dist, though CCLS shows worse performance on solving WPMS compared to Dist.Secondly, we propose a new variable selection mechanism focusing on a ",
            {
                "entities": [
                    [
                        134,
                        220,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 252 (2017) 267–294Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe first international competition on computational models of argumentation: Results and analysis ✩Matthias Thimm a,∗a Institute for Web Science and Technologies, Universität Koblenz–Landau, Germanyb Université Côte d’Azur, CNRS, Inria, I3S, France, Serena Villata ba r t i c l e i n f oa b s t r a c tArticle history:Received 14 June 2016Received in revised form 15 June 2017Accepted 18 August 2017Available online 30 August 2017Keywords:Formal argumentationAlgorithmsWe report on the First International Competition on Computational Models of Argumenta-tion (ICCMA’15) which took place in the first half of 2015 and focused on reasoning tasks in abstract argumentation frameworks. Performance of submitted solvers was evaluated on four computational problems wrt. four different semantics relating to the verification of the acceptance status of arguments, and computing jointly acceptable sets of arguments. In this paper, we describe the technical setup of the competition, and give an overview on the submitted solvers. Moreover, we report on the results and discuss our findings.© 2017 Elsevier B.V. All rights reserved.1. IntroductionArgumentation is a core technique for humans to reach conclusions in the presence of conflicting information and mul-tiple alternatives. It is used both as a means for persuasion in dialogues as well as one owns deliberation mechanism. An argument can be regarded as some concise set of pieces of information that supports a certain conclusion, such as “As Tweety is a bird and birds usually fly, Tweety supposedly flies”. Arguments may support contradicting conclusions—consider e.g. “As Tweety is a penguin and penguins do not fly, Tweety does not fly despite the fact that he is a bird”—and the pro-cess of argumentation aims at comparing and weighing arguments and counterarguments and ultimately deciding which arguments prevail. While the field of argumentation theory [96] studies the structure and interaction of arguments from a philosophical perspective, within artificial intelligence, the field of computational models of argumentation [6,8] has gained some attention in recent years. In general, this field is concerned with logical formalizations of models of argumentation that can be used by automatic reasoning systems to cope with uncertainty and inconsistency. Thus, these models are closely related to approaches to non-monotonic reasoning and offer a novel perspective on those. After some earlier works of e.g. Pollock [82] and Simari & Louie [87], abstract argumentation frameworks have been proposed by Dung [35] as a general and abstract formalism to represent arguments and their interactions and have, since then, been most influential. In abstract ar-gumentation frameworks, arguments are represented as vertices in a directed graph and an arc from a vertex A to a vertex B means that A is a counterargument for B or that A “attacks” B. Thus, this model abstracts from most issues of argu-mentation scenarios—including the inner structure of arguments—and provides a clean formal view on the issue of conflict between arguments. Given an abstract argumentation framework the central question is to decide whether arguments are acceptable, i.e., whether they “survive” the attacks of their counterarguments due to backing by other arguments. A set of jointly acceptable arguments is then also called extension.✩This paper was submitted to the Competition Section of the journal.* Corresponding author.E-mail address: thimm@uni-koblenz.de (M. Thimm).http://dx.doi.org/10.1016/j.artint.2017.08.0060004-3702/© 2017 Elsevier B.V. All rights reserved.\f268M. Thimm, S. Villata / Artificial Intelligence 252 (2017) 267–294Abstract argumentation provides a nice framework to discuss issues of non-monotonic reasoning in general as many other non-monotonic formalisms such as default theory and logic programs under the stable model semantics can be cast into abstract argumentation frameworks, cf. [35]. On the other hand, the multitude of different semantics and extensions go beyond the expressivity of previous formalisms and provide a novel general approach to non-monotonic reasoning, cf. e.g. [39]. This makes abstract argumentation frameworks a versatile knowledge representation formalism. Many research topics have been spawned around these frameworks including, among others, semantical issues [4], extensions on support [31], quantitative approaches [38,90,65], and in particular algorithms [30]. The computational challenges of various reasoning problems are vast and range up to the second level of the polynomial hierarchy for certain semantics [40,44]. Among the first implementations for reasoning with abstract argumentation frameworks—which appeared around 2008—were Dungine [88] and ASPARTIX [47]. More followed in the years after and, starting from 2013 up till now, a number of comparative analyses among argumentation solvers have been conducted, e.g., [42,10,43,95,11,12,14,27], in order to address a systematic performance comparison. Following the tradition of the communities of other approaches to knowledge representation and reasoning, such as the SAT and the Answer Set Programming (ASP) communities, a public competition for solver evaluation was planned soon after.This paper reports on the First International Competition on Computational Models of Argumentation (ICCMA’15) which took place in the first half of 2015. The results of the competition had been officially presented at the International Work-shop on Theory and Applications of Formal Argument (TAFA’15) which was co-located with the 24th International Joint Conference on Artificial Intelligence (IJCAI’15) in Buenos Aires, Argentina. The competition called for solvers on four classical computational problems in abstract argumentation frameworks wrt. the four classical semantics proposed in [35], includ-ing enumerating all extensions of a particular semantics and deciding whether a certain argument is contained in all of them. Submitted solvers were evaluated wrt. their runtime performance on these tasks on a series of artificially generated argumentation frameworks.Abstract argumentation frameworks are arguably the most investigated formalism for formal argumentation. However, there are also formalisms for structured argumentation, such as deductive argumentation [8] and defeasible logic program-ming [55]. In structured argumentation, arguments are a set of (e.g. propositional) formulas (the support of an argument) that derive a certain conclusion (the claim of an argument). The attack relation between arguments is then derived from logical inconsistency. For ICCMA’15 only problems of abstract argumentation have been considered as this is simple and well-understood formalism for representing computational argumentation. However, considering tracks on structured argu-mentation may be a worthwhile endeavor for future competitions.The competition received 18 solvers from research groups in Austria, China, Cyprus, Finland, France, Germany, Italy, Romania, and the UK. The solvers were based on different approaches and algorithmic design patterns to solve problems, ranging from reductions to SAT or ASP problems to novel heuristic algorithms. This paper gives an overview on the setup of the competition, the submitted solvers, and the results. More specifically, the remainder of this paper is organized as follows. In Section 2 we provide some necessary background on abstract argumentation and give an overview on the computational tasks considered in the competition. In Section 3 we describe the technical setup of the competition, including the approach for benchmark generation, the used evaluation methodology, and the technical interface requirements. In Section 4 we give an overview on the submitted solvers. Afterwards, we present and analyze the results of the competition in Section 5 and we discuss the lessons learned from this first experience in Section 6. We conclude with a summary in Section 7. Appendix Aprovides pseudo code of the graph generators used for creating the benchmark graphs of the competition. Appendix B gives detailed graph-theoretic statistics on the benchmark graphs.2. Background and competition overviewIn the following, we give a brief overview on abstract argumentation, the computational problems considered in the competition, and some brief overviews on answer set programming and satisfiability solving. The latter are intended to provide some formal background on the inner workings of solvers based on reductions to those.2.1. Abstract argumentationAbstract argumentation frameworks [35] take a very simple view on argumentation as they do not presuppose any internal structure of an argument. Abstract argumentation frameworks only consider the interactions of arguments by means of an attack relation between arguments.Definition 1 (Abstract argumentation framework). An abstract argumentation framework AF is a tuple AF = (Arg, →) where Argis a set of arguments and → is a relation → ⊆ Arg × Arg.For two arguments A, B ∈ Arg the relation A → B means that argument A attacks argument B. Abstract argumentation frameworks can be concisely represented by directed graphs, where arguments are represented as nodes and edges model the attack relation. Note that we only consider finite argumentation frameworks here, i.e., argumentation frameworks with a finite number of arguments.\fM. Thimm, S. Villata / Artificial Intelligence 252 (2017) 267–294269Fig. 1. A simple argumentation framework.Example 1. Consider the abstract argumentation framework AF = (Arg,→) depicted in Fig. 1. Here it is Arg = {A1, A2, A3,A4, A5} and → = {(A2, A1), (A2, A3), (A3, A4), (A4, A5), (A5, A4), (A5, A3), (A5, A6), (A6, A6)}.Semantics are usually given to abstract argumentation frameworks by means of extensions [35]. An extension E of an argumentatio",
            {
                "entities": [
                    [
                        136,
                        234,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 84 (1996) 177-208 Artificial Intelligence PALO: a probabilistic hill-climbing algorithm * Russell Greiner * Siemens Corporate Research, 755 College Road East, Princeton, NJ 08540-6632, USA Received April 1994; revised May 1995 Abstract Many learning systems search through a space of possible performance elements, seeking an element whose expected utility, over the distribution of problems, is high. As the task of finding the globally optimal element is often intractable, many practical learning systems instead hill- climb to a local optimum. Unfortunately, even this is problematic as the learner typically does not know the underlying distribution of problems, which it needs to determine an element’s expected search when the utility utility. This paper addresses function can only be estimated by sampling. We present a general algorithm, PALO, that returns an element find the generality of this algorithm by presenting an element whose efficiency, accuracy or completeness is nearly optimal. These results suggest learning, the multiple extension approaches to solving the utility problem from explanation-based problem from nonmonotonic tradeoff problem from knowledge representation. that is, with provably high probability, essentially a local optimum. We then demonstrate reasoning and the tractability/completeness three distinct applications the task of approximating this hill-climbing that respectively Keywords: Computational learning theory; Hill-climbing; Speed-up learning; Utility problem; Knowledge compilation; Theory revision; Prioritized default theories 1. Introduction Many learning mance elements examples, inductive seeking an element tasks can be viewed as a search through a space of possible perfor- that is optimal, based on some utility measure. As are optimally accurate, systems seek classifiers whose classifications * This paper expands the short article, “Probabilistic hill-climbing: theory and applications” that was awarded the “Artificial Intelligence Journal Best Paper Award” at the Ninth Canadian Conference on Artificial Intelligence (CSCSI-92), in Vancouver, in May 1992. * E-mail: greiner@scr.siemens.com. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved KYDI0004-3702(95)00040-2 \f178 K. Gretner/Artificiurl htelligence 84 (I 996) 177-208 learning that are optimally and many explanation-based solvers used to compare as the expected value of a particular (or goals, queries, problems, samples the different elements efficient [ 30,591. [ 17,601 and chunking 1551 systems seek problem function In each of these cases, the utility is defined of function, averaged over the distribution (e.g., classifiers or problem solvers) scoring .) that will be seen [38,42]. There are at least two problems with implementing to determine which element such a learning system: First, we is optimal; unfor- is usually unknown. There are, of course, standard statistical and techniques. For example, that is, systems have incorporated [78] use these estimates to identify an element information; the needed to estimate these This of samples that use the set of observed samples this information to the second problem: systems approximately need to know the distribution tunately, techniques several classes of learning many “PAC-learning” with high probability, leads ally optimal element, many spaces of elements climbs BACKPROP 1441, genetic algorithms speedup learning methods; guarantee that each hill-climbing ment is not always even superior of elements. Moreover, the learning has reached a point of diminishing fewer systems [30,42]. A common see especially even given towards a lncuf optimum. Many well-known a global optimum. unfortunately, the correct distribution response is intractable the task of identifying the glob- for information, that hill- is to build a system inductive including learning systems, [ 681, use this approach, as do many systems the final ele- in the space to determine when few existing 1281. Unfortunately, step is even an improvement, meaning to the initial one, much less an optimum include a stopping criterion [ 6) and ~4.5 returns. The work presented here draws ideas from both of these themes: in particular, it learning produces a general algorithm, I - 6, &-local optimal. describes using a utility measure 0, PALO efficiently at least incremental the effects of the sample order. Moreover. [ 621, passively gathering element PALO’s hill-climbing, very minor. solve problems to “batched”) the statistics (as opposed relevant over PALO, that hill-climbs to a local optimum, that is estimated by sampling. Given any parameters an element whose expected utility E,C? > is, with probability ’ As PALO processes one sample at a time, learner, which uses statistical it is an tests to mollify this system can often work unobtrusively a performance it needs by simply watching to a user’s applications. Here, the incremental problems, the cost of simply solving performance cost of can be elements. Section 4 then defines the use of “expected utility” as a quality measure Section 2 first compares and contrasts our approach with others from the literature. for comparing the general PALO algorithm, which deals that, with high of the final the statistical is better than the rigorous the generality of our its Section 3 motivates performance sequentially with a series of performance each @;+I is an improvement confidence, O,, is a local optimum the result of a proposed modification tool used to determine whether original performance this version of Minton’s “utility analysis” approach by presenting tool can be viewed as a mathematically . , O,, such the performance elements 01,. over Oi and of the PALO system, each using in the space being searched. [ 591. Section 5 demonstrates three different applications It also describes element; ’ Theorem I below defines both OUT sense of efticiency, and “~-local optimality”. \fR. Greiner/Art$cial Intelligence 84 (1996) 177-208 179 own set of transformations performance completeness, behavior limitations, paper. in a particular respectively. to find a near-optimal elements, where optimality is defined It also summarizes situation. Section 6 discusses its particular set of element within in terms of efficiency, accuracy or study, to illustrate PALO’S and in the several variations, contains proofs of the claims made an empirical extensions of our approach. The Appendix 2. Related results Finding an element with the best average performance techniques that use statistical [ 581 describe a system There are several other projects element whose average performance must evaluate each of N performance Moore set of elements, meaning explicitly. Their “Hoeffding Race” approach element-sample by removing evaluations that this element will not be the optimum. to find a performance system for each of k training samples. Maron and small, and explicit, can be performed the total number of clear that works when there is a relatively evaluations” to reduce an element as soon as it is statistically In general, each such learning the N x k “element-sample is optimal. elements attempts [ 221 presents a different, more mathematically Fong of reducing ment should deal with each sample. The resulting “Y-W tE system the number of element-sample evaluations, [50]. rigorous, solution to the problem by specifying which single ele- framework extends Kaelbling’s Combinatorial space + hill-climbing These approaches work when there is an explicit representation of all possible perfor- In many cases, however, there are an implicitly defined combinatorial to the set of its neighbors system mance elements. number of elements. Here, it makes sense to impose a “structure” on the space by con- (which form a small subset of the space), necting each element from the “current element” and then use a hill-climbing to one of its neighbors. There are, of course, a huge number of such hill-climbing sys- as well as almost every other field of computer tems used throughout machine element science. Each such system must evaluate is easily against computed. This is not true in our case, as our quality measure is the expected value of the element’s is not known as it depends on the unknown distribution the currently proposed performance “quality” its neighbors. This comparison score on an instance, which to climb successively if each element’s of instances. is trivial learning, classifiers As mentioned is optimal; see for example above, many learning systems attempt to address this challenge, of find- the learning proce- [ 61. [68], neural nets [44] and genetic algorithms the distribution, then to another. Most sys- and heuristically. By contrast, our PALO system performs an is ing an element whose expected behavior dures used by symbolic Each of these systems uses a set of training uses this information tems do this implicitly, explicit statistical superior samples to determine when one element test to determine, with prescribed corzjdence, when one element to estimate is superior to another. \f180 R. Grelner/Art@cicrI lntelli~ence 84 (I 996) 177-208 As such, it is very similar samples when hill-climbing. By contrast, PALO will stop and return is in the statistical criteria used: While PALO’s to the COMPOSER system of Gratch, DeJong and Chien element 0 if none of O’s neighbors appears significantly [ 27- 291. COMPOSER differs from PALO in two significant ways. First, COMPOSER will use the all available bet- currently best performance returns”. ter than O-which means PALO will stop on reaching a point of “diminishing test (based on The second difference Hoeffding’s of sam- that the samples are ples, COMPOSER’S is standard, and drawn empirically see Section 6.2. effective system, COMPOSER also Moreover, it does not make PALO’s conserva- makes other simplifying that the errors on successive hill-climbs tive (but mathematically will add. * in the interest of producing an empirically assumptions",
            {
                "entities": [
                    [
                        75,
                        120,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "EISEVIER Artificial Intelligence 80 (1996) 171-191 Artificial Intelligence Response to my critics Hubert L. Dreyfus* Philosophy Department, Universify of California at Berkeley, Berkeley, CA 94720, USA Received June 1995 It to testing action” intelligent is dedicated to understanding reading my critics and talking I think that my characterization to many present and former AI re- After of what John Haugeland calls Good searchers, research program pursued only by Old-Fashioned AI (GOFAI) as a degenerating rather a few “die-bards” was inaccurate. There are really at least three different is a contribution diffuse research programs. The first, and so far most important, in Newell and Simon’s deservedly to cognitive science which found its expression the famous paper on Physical Symbol Systems. that “A physical symbol system has the necessary and sufficient means hypothesis [15, pp. 41 and 491. But this is not a unified for general research program. There are several programs dedicated the human mind as a physical symbol system: Newell’s group at Carnegie-Mellon with SOAR, Minsky at MIT with frames, and John McCarthy at Stanford with his logic-based models, to name a few. Each group thinks, or at least until recently that their program was on the most promising track. But none has made thought, to convince anybody outside their school or group to join them. enough progress to making machines behave Then at specific tasks regardless of how human being do it. As Jerry intelligently talk here at Berkeley: “AI no longer does Cognitive Feldman put it in a recent in search of practical problems.” Finally, for Modeling. to many, symbolic problem work on and action. This approach solving with connectionist models of perception for being preserves being a physical symbol system as a necessary condition but abandons is intelligent since it is not clear how the part of the system solving problems using problematic symbolic representations to talk to the other parts of the system. As Haugeland points out, the very idea that the intellect sends symbolic instructions th.e work in GOFAI has shifted away from the Newell/Simon program it as a sufficient condition. But the AI engineers dedicated It is a bunch of techniques that combine high-level, this approach architectures is supposed integrated there are * E-mail: clreyfus@cogsci.berkeley.edu. 0004-3702/96/$15.00 0 1996 Elsevier Science B.V. All rights reserved SSDI 0004-3702(95)00088-7 \f172 H.L. Dreyfus I Artificial Intelligence 80 (1996) 171-191 there is a rival to the world. representation these orders may well be a mistaken way of and graduate students, neural networking modeling. There the relation of intelligence to symbolic to the body which then executes conceiving Now that has attracted many researchers is some from symbolic AI is, because neural confusion about how radical this departure nets can be simulated with algorithms on digital computers and in a loose sense in the GOFAI project were not just algorithms use symbols, but the symbols strings of bits that represented to in the world. Of course, the be semantically neural networks are still representations in some sense, but they represent by way of the weights on the connections between simulated neurons and these do not symbols. Even Newell have acknowledges some state of the computer but were supposed context-independent the properties as representing interpretable of precise, features that: You can, in one sense, say that connectionist systems are systems that are nonsymbolic and see how far you can go when you push them to do the same tasks that have been done with symbol manipulation without their becoming the physical symbolic systems. There symbol system hypothesis and connectionism. is certainly an opposition between [16, p. 1531 Daniel Dennett spells out clearly what this means: . . some of them seem to If you look at the nodes in a connectionist network. have careers, suggesting that they are particular symbols. This is the symbol this is the symbol for “dog.” It seems likely to say that whenever for “cat,” if cats are the topic, that symbol is active; otherwise cat identification the mistake of a simple you make symbol and dog symbol-this it turns out that you can disable this node, and the system can go right on thinking about cats. if you keep the cat and dog nodes going and disable some of the Moreover, that seem the system will not work. The other nodes competence of all its of the whole system depends on the cooperation elements, some of which are very much like symbols. . . . At the same time, to those symbols one can recognize that some of the things that happen at the symbol cannot be correctly and adequately described or predicted level. [5, pp. 63-641 it is not. Nevertheless, of these nodes-as does not work. Because to be just noisy, Paul Smolensky gives a detailed argument level and are related Newtonian physics [20]. to symbolic systems as quantum physics that networks work on a subsymbolic to is related Whether the shift to network research continues will depend on whether those defending GOFAI are making slow but steady progress as McCarthy claims-and presumably workers on SOAR claim too-or whether what now looks like slow that show one is trying to progress comes to look like the diminishing returns solve the wrong problem. Right now, whether one calls the current situation in research program left to the die-hards or a winnowing out GOFAI a degenerating is largely a of the faint-hearted so that only the courageous visionaries remain \fH.L. Dreyfus I Artificial Intelligence 80 (1996) 171-191 173 question of rhetoric and, as some of the responses Do show, generates more heat than light. to What Computers Still Can’t to be an and I take commonsense, Simon, McCarthy to GOFAI, unfortunately For the. answer finally to become clear, what certainly should be avoided on both sides; is the unscientific ploy of never admitting failure even when one fails to for giving a achieve one’s research goals. Douglas Lenat, whose Cyc project computer important still follows the old approach of rewriting contribution his goals and his time-table so as to be able to claim that his research project is to succeed. Eleven years ago Lenat predicted right on schedule and just about that in 10 years Cyc would cope with novelty by recognizing analogies and would then be able to teach itself by reading the newspapers. Time is up and he seems to least I have seen no published account of have made no progress on this front-at those Cyc “noticing patterns and regularities patterns [12, p. 357 (my rueful new analogies, dependencies, to this problem Lenat tells us italics)] as promised. But rather than call attention that “After target. The CNL is still on the Cyc project subsystem is developing synergisti- (Cyc-based NL understanding cally with the Cyc KB, and we expect a sort of crossover to occur in the next two years, by which we mean that most of the knowledge entry will take place by semiautomated NL understanding, with humans able to take the role of tutors talk of rather analogies and the two additional years will be up in one year. For reasons given in to my book, I do not think the analogy program will work since it the new preface presupposes having solved the problem of relevance. But the important thing is to just what has been accomplished and what has turned out to be be told clearly harder instance, be bad news for Simon, who is basing his current optimism on Lenat’s success. In a recently published the commonsense knowledge problem by saying: in the data, and drawing and generalizations” and why. That might, for to a question concerning [8, pp. 127-1421. There interview, he responds than brain surgeons.” almost a decade, than anticipated and generation) is no further from Douglas Lenat has a ten-year program of building a huge semantic memory (CYC). Then we will see. . . . When people start to build programs at that magnitude and they still cannot do what they are supposed to, then we will start worrying. [19, p. 2391 Seeing Simon worried would, in itself, be a kind of progress. In the meantime turn to the substantive issues raised by my critics. I’ll I am grateful to Harry Collins for his detailed reading and his open minded and original critique. His new arguments both for and against the possibility of AI bring a breath of fresh air into a stale debate. Also he touches upon most of the issues raised by the other reviewers so I will deal with his comments in detail. As I see it, Collins raises three problems are with a preview of my response my work on Heidegger and Wittgenstein, that there is no way reality is in itself independent of our social constructions of it. that it is a mistake to read Heidegger I note for the exegetical they to each. First, Collins claims that, since I base I should follow them in acknowledging for my overall approach. Here record, however, \f174 H.L. Dreyfus I Artificial Intelligence 80 (1996) 171-191 activity in them can be automated and Wittgenstein as social constructivists. Second, even if all domains are social constructs, does it follow, as Collins claims, that the structure of these domains is up to society and that therefore if society so language, although clearly chooses? independent socially constituted, of to my preferring how society happens I will defend my neural networks representations. taxonomy of domains of human activity, distinguishing those that are amenable to the techniques of Symbolic AI and those that are not, as well as my claim that this taxonomy does not apply to simulated neural networks. I will seek to show that chess and natural have, once constituted, to interpret intrinsic structures them. Third, Collins objects In response, to symbolic that First, relevant includes is directly The question is independent itself.” to interest certainly the correspondence by physics is indeed nature is not whether even if they were, all domains of objects are s",
            {
                "entities": [
                    [
                        75,
                        97,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 204–233www.elsevier.com/locate/artintA logical approach to efficient Max-SAT solving ✩Javier Larrosa a,∗, Federico Heras a, Simon de Givry ba Universitat Politecnica de Catalunya, Barcelona, Spainb INRA, Toulouse, FranceReceived 2 August 2006; received in revised form 11 May 2007; accepted 15 May 2007Available online 29 May 2007AbstractWeighted Max-SAT is the optimization version of SAT and many important problems can be naturally encoded as such. Solvingweighted Max-SAT is an important problem from both a theoretical and a practical point of view. In recent years, there has beenconsiderable interest in finding efficient solving techniques. Most of this work focuses on the computation of good quality lowerbounds to be used within a branch and bound DPLL-like algorithm. Most often, these lower bounds are described in a proceduralway. Because of that, it is difficult to realize the logic that is behind.In this paper we introduce an original framework for Max-SAT that stresses the parallelism with classical SAT. Then, we extendthe two basic SAT solving techniques: search and inference. We show that many algorithmic tricks used in state-of-the-art Max-SATsolvers are easily expressible in logical terms in a unified manner, using our framework.We also introduce an original search algorithm that performs a restricted amount of weighted resolution at each visited node. Weempirically compare our algorithm with a variety of solving alternatives on several benchmarks. Our experiments, which constituteto the best of our knowledge the most comprehensive Max-SAT evaluation ever reported, demonstrate the practical usability of ourapproach.© 2007 Elsevier B.V. All rights reserved.Keywords: Max-SAT; Search; Inference1. IntroductionWeighted Max-SAT is the optimization version of the SAT problem and many important problems can be naturallyexpressed as such. They include academic problems such as Max-Cut or Max-Clique, as well as real problems indomains like routing [3], bioinformatics [4], scheduling [5], probabilistic reasoning [6] and electronic markets [7].In recent years, there has been a considerable effort in finding efficient exact algorithms. These works can be dividedinto theoretical [8–10] and empirical [11–15]. A common drawback of all these algorithms is that in spite of theclose relationship between SAT and Max-SAT, they cannot be easily described with logic terminology. For instance,✩ This paper includes and extends preliminary work from [J. Larrosa, F. Heras, Resolution in Max-SAT and its relation to local consistency forweighted CSPs, in: Proc. of the 19th IJCAI, Edinburgh, UK, 2005, pp. 193–198; J. Larrosa, F. Heras, New inference rules for efficient Max-SATsolving, in: Proc. of AAAI-06, Boston, MA, 2006].* Corresponding author.E-mail addresses: larrosa@lsi.upc.edu (J. Larrosa), fheras@lsi.upc.edu (F. Heras), degivry@toulouse.inra.fr (S. de Givry).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.006\fJ. Larrosa et al. / Artificial Intelligence 172 (2008) 204–233205the contributions of [11–14] are good quality lower bounds to be incorporated into a depth-first branch and boundprocedure. These lower bounds are mostly defined in a procedural way and it is very difficult to see the logic that isbehind the execution of the procedure. This is in contrast with SAT algorithms where the solving process can be easilydecomposed into atomic logical steps.In this paper we introduce an original framework for (weighted) Max-SAT in which the notions of upper andlower bound are incorporated into the problem definition. Under this framework classical SAT is just a particularcase of Max-SAT, and the main SAT solving techniques can be naturally extended. In particular, we extend the basicsimplification rules (for example, idempotency, absorption, unit clause reduction, etc.) and introduce a new one,hardening, that does not make sense in the SAT context. We also extend the two fundamental SAT algorithms: DPLL(based on search) and DP (based on inference). We also show that the complexity of the extension of DP is exponentialon the formula’s induced width (which is hardly a surprise, since this is also the case of other inference algorithms forgraphical models [16,17]). Interestingly, our resolution rule includes, as special cases, many techniques spread overthe recent Max-SAT literature. One merit of our framework is that it allows to see all these techniques as inferencerules that transform the problem into an equivalent simpler one, as it is customary in the SAT context.The second contribution of this paper is more practical. We introduce an original search algorithm that incorporatesthree different forms of resolution at each visited node: neighborhood resolution, chain resolution and cycle resolution.Our experimental results on a variety of domains indicate that our algorithm is generally much more efficient than itscompetitors. This is especially true as the ratio between the number of clauses and the number of variables increases.Note that these are typically the hardest instances for Max-SAT. Our experiments include random weighted andunweighted Max-SAT, Max-One, Max-Cut, Max-Clique, and combinatorial auctions.The structure of the paper is as follows: In Section 2 we review SAT terminology. In Section 3 we present Max-SAT and introduce our framework. In Section 4 we extend the essential solving techniques from SAT to Max-SAT.Section 5 summarizes in a unified way several specialized forms of resolution that can be used to simplify Max-SATformula. Section 6 describes our solver. Section 7 reports our experimental work, which corroborate the efficiency ofour solver compared to other state-of-the-art solving alternatives. Section 8 discusses related work. Finally, Section 9concludes and points out directions of future work.2. Preliminaries on SATIn the sequel X = {x1, x2, . . . , xn} is a set of Boolean variables. A literal is either a variable xi or its negation ¯xi .The variable to which literal l refers is noted var(l) (namely, var(xi) = var( ¯xi) = xi ). If variable xi is assigned totrue literal xi is satisfied and literal ¯xi is falsified. Similarly, if variable xi is instantiated to false, literal ¯xi is satisfiedand literal xi is falsified. An assignment is complete if it gives values to all the variables in X (otherwise it is partial).A clause C = l1 ∨ l2 ∨ · · · ∨ lk is a disjunction of literals such that ∀1(cid:2)i,j (cid:2)k, i(cid:5)=j var(li) (cid:5)= var(lj ). It is customaryto think of a clause as a set of literals, which allows to use the usual set operations. If x ∈ C (resp. ¯x ∈ C) we saythat x appears in the clause with positive (resp. negative) sign. The size of a clause, noted |C|, is the number ofliterals that it has. var(C) is the set of variables that appear in C (namely, var(C) = {var(l) | l ∈ C}). An assignmentsatisfies a clause if and only if it satisfies one or more of its literals. Consequently, the empty clause, noted (cid:2), cannotbe satisfied. Conversely, a clause which contains the negation of the empty clause, noted ¬(cid:2), is always satisfiedand can be discarded. Sometimes it is convenient to think of clause C as its equivalent C ∨ (cid:2). A logical formulaF in conjunctive normal form (CNF) is a conjunction of different clauses, normally expressed as a set. A satisfyingcomplete assignment is called a model of the formula. Given a CNF formula, the SAT problem consists in determiningwhether there is any model for it or not. The empty formula, noted ∅, is trivially satisfiable. A formula containing theempty clause is trivially unsatisfiable and we say that it contains an explicit contradiction.2.1. Graph concepts [18]The structure of a CNF formula F can be described by its interaction graph G(F) containing one vertex associatedto each Boolean variable. There is an edge for each pair of vertices that correspond to variables appearing in the sameclause. Given a graph G and an ordering of its vertices d, the parents of a node xi is the set of vertices connected toxi that precede xi in the ordering. The width of xi along d is the number of parents that it has. The width of the graphalong d, denoted wd , is the maximum width among the vertices.\f206J. Larrosa et al. / Artificial Intelligence 172 (2008) 204–233Fig. 1. On the left, a graph G. On the right, the induced graph G∗d where d is the lexicographic order.The induced graph of G(F) along d, denoted G∗d (F), is obtained as follows: The vertices of G are processedfrom last to first along d. When processing vertex xi , we connect every pair of unconnected parents. The inducedwidth of G along d, denoted w∗d , is the width of the induced graph. The induced width (also known as tree-width,k-tree number or the dimension of the graph) is a measure of how far a graph is from acyclicity and it is a fundamentalstructural parameter in the characterization of many combinatorial algorithms. Computing the ordering d that providesthe minimum induced width is an NP-hard problem [19].Example 1. Consider the formula F = { ¯x1 ∨ x4, x1 ∨ x4, x2 ∨ x3, x2 ∨ x4, x2 ∨ ¯x5, x4 ∨ x5}. Its interaction graph G(F)is depicted in Fig. 1(a). The induced graph G∗d along the lexicographical order is depicted in Fig. 1(b). Dotted edge(x1, x2) is the only new edge with respect to the original graph. When processing node x5, no new edges are added,because the parents x2 and x4 of x5 are already connected. When processing node x4, the edge connecting x2 and x1 isadded because both variables are parents of x4 and they were not connected. When processing x3, x2 and x1, no newedges are added. The induced width w∗d is 2 because nodes x5 and x4 have width 2 (namely, they have two parents) inthe induced graph.2.2. SAT algorithmsCNF formulas can be simplified using equivalences or reductions. Well known equivalences are idempotencyC ∧ C ≡ C, absorption C ∧ (C ∨ B) ≡ C and unit clause reduction l ∧ (¯l ∨ C)",
            {
                "entities": [
                    [
                        72,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 619–637Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPanlingual lexical translation via probabilistic inference∗MausamMarcus Sammer, Jeff Bilmes, Stephen Soderland, Oren Etzioni, Daniel S. Weld, Kobi Reiter 1, Michael Skinner 1,Department of Computer Science and Engineering, Box 352350, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 23 June 2009Received in revised form 8 April 2010Accepted 8 April 2010Available online 10 April 2010Keywords:Lexical translationMultilingualityThis paper introduces a novel approach to the task of lexical translation between languagesfor which no translation dictionaries are available. We build a massive translation graph,automatically constructed from over 630 machine-readable dictionaries and Wiktionaries.In this graph each node denotes a word in some language and each edge (v i, v j) denotesa word sense shared by v i and v j . Our current graph contains over 10,000,000 nodes andexpresses more than 60,000,000 pairwise translations.The composition of multiple translation dictionaries leads to a transitive inference problem:if word A translates to word B which in turn translates to word C , what is the probabilitythat C is a translation of A? The paper describes a series of probabilistic inferencealgorithms that solve this problem at varying precision and recall levels. All algorithmsenable us to quantify our confidence in a translation derived from the graph, and thustrade precision for recall.We compile the results of our best inference algorithm to yield PanDictionary, a novelmultilingual dictionary. PanDictionary contains more than four times as many translationsas in the largest Wiktionary at precision 0.90 and over 200,000,000 pairwise translationsin over 200,000 language pairs at precision 0.8.© 2010 Elsevier B.V. All rights reserved.1. IntroductionIn the era of globalization, inter-lingual communication is becoming increasingly important. Nearly 7000 languages are inuse today [18] necessitating machine translation (MT) systems between about 49 million language-pairs. In contrast popularMT systems like Google Translate handle only on the order of a thousand language pairs. It is difficult to see how statisticalMachine Translation (MT) methods can scale to this large number of language pairs, since they depend on aligned corpora,which are very expensive to generate, and are available at the requisite scale for only a tiny number of language pairs[5,28,33,30,7].This paper considers scaling MT in the context of a far easier task: lexical translation. Lexical translation is the task oftranslating individual words or phrases (e.g., “sweet potato”) from one language to another. Because lexical translation doesnot require aligned corpora as input, it is feasible for a much broader set of languages than statistical MT. While lexicaltranslation has a long history (cf. [24,20,9,23]), interest in it peaked in the 1990s. Yet, as this paper shows, the proliferationof Machine-Readable Dictionaries (MRDs) and the rapid growth of multilingual Wiktionaries offers the opportunity to scalelexical translation to an unprecedented number of languages.* Corresponding author. Tel.: +1 206 685 1964; fax: +1 206 543 2969.E-mail address: mausam@cs.washington.edu (Mausam).1 Current address: Google Inc., 651 N 34th St., Seattle, WA 98105, USA.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.020\f620Mausam et al. / Artificial Intelligence 174 (2010) 619–637Fig. 1. A fragment of the translation graph for two senses of the English word ‘spring’. Edges labeled ‘1’ and ‘3’ are for spring in the sense of a season, and‘2’ and ‘4’ are for the flexible coil sense. The graph shows translation entries from an English dictionary merged with ones from a French dictionary.Of course, lexical translation cannot replace statistical MT, but it is useful for several applications, including the trans-lation of search-engine queries, meta-data tags,2 library classifications and recent applications like cross-lingual imagesearch [11] of http://www.panimages.org, and enhancement of multilingual Wikipedias [1]. Also, lexical translation is a valu-able component in knowledge-based Machine Translation (MT) systems, e.g., [4,6]. The increasing international adoption ofthe Web yields opportunities for new applications of lexical translation systems.The fundamental contribution of this paper is a novel approach to lexical translation, which automatically compilesvarious machine-readable multilingual and bilingual dictionaries available on the Web into a unique translation graph. A nodev in the translation graph represents a word in a particular language. An edge (v i, v j) denotes a word sense shared by v iand v j . Fig. 1 shows a snippet of the translation graph. We demonstrate that inference over this translation graph can yielda massive, multilingual dictionary with coverage superior to the union of input dictionaries at comparable precision.Inference over the translation graph necessitates matching word senses across multiple, independently-authored dictio-naries. For example, if one dictionary says that ‘udaherri’ and ‘printemps’ translate ‘spring’ another says that ‘koanga’ and‘spring’ are translations of ‘printemps’, then we need to infer whether the two dictionaries are referring to the same sense –resulting in ‘udaherri’ a translation of ‘koanga’, or not (see Fig. 1). Because of the millions of translations in the dictionaries,a feasible solution to this sense matching problem has to be scalable; because sense matches are imperfect and uncertain, thesolution has to be probabilistic. The key technical contribution of this paper is a set of methods that perform probabilisticsense matching to infer lexical translations between two languages that do not share a translation dictionary. For example,our algorithm can conclude that the Basque word ‘udaherri’ is a translation of the Maori word ‘koanga’.We presentthree differenttechniques for probabilistic inference – TransGraph, unpruned SenseUniformPaths(uSenseUniformPaths) and SenseUniformPaths. TransGraph uses heuristic-based formulae for inference, while the second,uSenseUniformPaths, reasons about graph topology via random walks and probabilistic graph sampling. SenseUniform-Paths adds constraints based on the graph topology on uSenseUniformPaths that improve precision.We use SenseUniformPaths to construct PanDictionary – a novel lexical resource that spans over 200 million pairwisetranslations in over 200,000 language pairs at 0.8 precision, a four-fold increase when compared to the union of its inputtranslation dictionaries.This paper combines and extends our previous two papers [11,31] and overall, makes the following contributions:1. We introduce a novel approach to the task of lexical translation, which compiles a large number of machine readabledictionaries in a single resource called a translation graph. We employ probabilistic reasoning and inference over thetranslation graph to infer translations that are not expressed by any of the input dictionaries.2. We develop three inference algorithms: TransGraph, unpruned SenseUniformPaths, and SenseUniformPaths. All thesealgorithms return new translations with associated confidence values, so we can trade precision for recall. We empiri-cally compare the three algorithms and find that SenseUniformPaths outperforms the others by returning many moretranslations at high precisions.3. We use SenseUniformPaths to compile PanDictionary – a massive, sense-distinguished multilingual dictionary. Ourempirical evaluations show that depending on the desired precision PanDictionary is 4.5 to 24 times larger than theEnglish Wiktionary (http://en.wiktionary.org). Moreover, it expresses about 4 times the number of pairwise translationscompared to the union of its input dictionaries (at precision 0.8).The remainder of the paper is organized as follows. Section 2 introduces the construction of the translation graph. Wedescribe the three methods for inference and compare them in Section 3. Section 4 describes the compilation of PanDic-2 Meta-data tags appear in community Web sites such as http://flickr.com and http://del.icio.us.\fMausam et al. / Artificial Intelligence 174 (2010) 619–637621tionary and compares its coverage with the English Wiktionary. Section 5 considers related work on lexical translation. Thepaper concludes in Sections 7 and 6 with conclusions and directions for future work.2. The translation graphThis section describes the properties of translation graph and its construction from multiple dictionaries. The translationgraph is an undirected graph defined as a triple (cid:3)V, E, Ψ (cid:4).V and E denote the usual sets of vertices and edges. Each vertex v ∈ V in the graph is an ordered pair (w, l) where w isa word in a language l. Undirected edges in the graph denote translations between words: an edge e ∈ E between (w 1, l1)and (w 2, l2) represents the belief that w 1 and w 2 share at least one word sense. Additionally, an edge is labeled by aninteger denoting an ID for the word sense. Ψ is a set of inequality constraints between sense IDs. It is a set of pairs of senseIDs, such that if the pair (cid:3)id1, id2(cid:4) ∈ Ψ then the senses represented by the IDs are known to be distinct, i.e., they representdifferent word senses.Fig. 1 shows a fragment of a translation graph, which was constructed from two sets of translations for the word ‘spring’from an English Wiktionary, and two corresponding entries from a French Wiktionary for ‘printemps’ (spring season) and‘ressort’ (flexible spring). Translations of the season ‘spring’ have edges labeled with sense ID = 1, the flexible coil sense hasID = 2, translations of ‘printemps’ have ID = 3, and so forth. For this fragment Ψ = {(cid:3)1, 2(cid:4), (cid:3)3, 4(cid:4)}.Note that s",
            {
                "entities": [
                    [
                        136,
                        194,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 586–614Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe extended global cardinality constraint: An empirical surveyPeter NightingaleSchool of Computer Science, University of St Andrews, St Andrews, Fife KY16 9SX, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 1 March 2010Received in revised form 18 October 2010Accepted 18 October 2010Available online 21 October 2010Keywords:Global cardinality constraintConstraint programmingGlobal constraintsPropagation algorithmsThe Extended Global Cardinality Constraint (EGCC) is a vital component of constraint solv-ing systems, since it is very widely used to model diverse problems. The literature containsmany different versions of this constraint, which trade strength of inference against compu-tational cost. In this paper, I focus on the highest strength of inference usually considered,enforcing generalized arc consistency (GAC) on the target variables. This work is an exten-sive empirical survey of algorithms and optimizations, considering both GAC on the targetvariables, and tightening the bounds of the cardinality variables. I evaluate a number of keytechniques from the literature, and report important implementation details of those tech-niques, which have often not been described in published papers. Two new optimizationsare proposed for EGCC. One of the novel optimizations (dynamic partitioning, generalizedfrom AllDifferent) was found to speed up search by 5.6 times in the best case and 1.56times on average, while exploring the same search tree. The empirical work represents byfar the most extensive set of experiments on variants of algorithms for EGCC. Overall, thebest combination of optimizations gives a mean speedup of 4.11 times compared to thesame implementation without the optimizations.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConstraint programming is a powerful and flexible means of solving combinatorial problems. Constraint solving of acombinatorial problem proceeds in two phases. First, the problem is modelled as a set of decision variables, and a set ofconstraints on those variables that a solution must satisfy. A decision variable represents a choice that must be made inorder to solve the problem. The domain of potential values associated with each decision variable corresponds to the optionsfor that choice.Consider a sports scheduling problem, where each team plays every other team exactly once in a season. No team canplay two or more matches at the same time. Each team plays in a particular stadium at most twice during the season. Inthis example one might have two decision variables per match, representing the two teams. For a set of matches played inthe same stadium, a global cardinality constraint [24] could be used to ensure no more than two occurrences of each team.The second phase consists of using a constraint solver to search for solutions: assignments of values to decision variablessatisfying all constraints. The simplicity and generality of this approach is fundamental to the successful application ofconstraint solving to a wide variety of disciplines such as scheduling, industrial design and combinatorial mathematics [34,11].The Global Cardinality Constraint (GCC) is a very important global constraint, present in various constraint solving toolk-its, solvers and languages. It restricts the number of occurrences of values assigned to a set of variables. In the originalversion of the constraint [24], each value is given a lower bound and upper bound. In any solution, the number of occur-rences of the value must fall within the bounds. The literature contains many propagation algorithms for this constraint,E-mail address: pn@cs.st-andrews.ac.uk.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.10.005\fP. Nightingale / Artificial Intelligence 175 (2011) 586–614587which trade strength of inference against computational cost, for example bound consistency [13,19], range consistency [18],and generalized arc-consistency (GAC) [24,18]. GCC is widely used in a variety of constraint models, for diverse problemssuch as routing and wavelength assignment [30], car sequencing [25], and combinatorial mathematics [11].Returning to the sports scheduling example, GCC can be used to express the stadium constraint (that a team plays in aparticular stadium at most twice during the season). Each value (representing a team) is given the bounds (0, 2), and thevariables are all slots at a particular stadium.GCC has been generalized by replacing the fixed bounds on values with cardinality variables [18], where each cardinalityvariable represents the number of occurrences of a value. To avoid confusion, I refer to this as the Extended Global Cardi-nality Constraint (EGCC). Thus an EGCC constraint has target variables (where the number of occurrences of some values areconstrained) and cardinality variables.In this paper, I focus on the highest strength of inference (enforcing GAC) on the target variables. This allows the study ofvarious methods in great depth, and leads to some surprising conclusions. I also survey methods for pruning the cardinalityvariables in depth. The main contributions of the paper are as follows.• A literature survey of GAC propagation algorithms for the target variables, and their optimizations, in Section 3.• Discussion of important implementation decisions in Section 3 that are frequently omitted from original papers, perhapsdue to lack of space. For example, how to find augmenting paths for Régin’s algorithm [24].• The proposal of two new optimizations in Section 3.4. One of these is based on modifying the flow network of Régin’salgorithm for greater efficiency, and the other is a novel generalization of the dynamic partitioning optimization ofAllDifferent [6].• A careful description of three concrete algorithms for pruning the cardinality variables in Section 4.• Easily the largest empirical study of GAC propagation methods for the target variables of EGCC, in Section 5. Thisinvolves two basic algorithms and seven optimizations.• Experimental conclusions and implementation advice for GAC for the target variables, in Section 6.• An empirical study of pruning the cardinality variables, comparing the three methods, in Section 5.8, leading to experi-mental conclusions in Section 6.• It is shown that an appropriate combination of optimizations is over 4 times faster on average than a careful butunoptimized implementation of Régin’s algorithm (Section 5.10), for our benchmark set.• A fast variant of EGCC is typically orders of magnitude better than a set of occurrence constraints. Even when EGCCpropagation was least effective, it slowed the solver down by only 1.66 times or less in our experiments (Section 5.10).2. Background2.1. PreliminariesFor CSP P = (cid:2)X , D, C(cid:3), a constraint Ck ∈ C consists of a sequence of m > 0 variables Xk = (cid:2)xk1 , . . . , xkmA CSP P = (cid:2)X , D, C(cid:3) is defined as a set of n variables X = (cid:2)x1, . . . , xn(cid:3), a set of domains D = (cid:2)D(x1), . . . , D(xn)(cid:3) whereD(xi) (cid:2) Z, |D(xi)| < ∞ is the finite set of all potential values of xi , and a conjunction C = C1 ∧ C2 ∧ · · · ∧ Ce of constraints.(cid:3) with domainsDk = (cid:2)D(xk1 ), . . . , D(xkm )(cid:3) s.t. Xk is a subsequence1 of X , Dk is a subsequence of D, and each variable xki and domainD(xki ) matches a variable x j and domain D(x j) in P . Ck has an associated set C S⊆ D(xk1 ) × · · · × D(xkm ) of tuples whichspecify allowed combinations of values for the variables in Xk.Although I define a constraint Ck to have scope (cid:2)xk1 , . . . , xkm(cid:3), when discussing a particular constraint I frequently omitkthe k subscript, and refer to the variables as (cid:2)x1, . . . , xm(cid:3), and to the domains as (cid:2)D(x1), . . . , D(xm)(cid:3).A literal is defined as a variable-value pair, xi (cid:8)→ j such that xi ∈ X and j ∈ Z. To prune a literal is to remove the valuek , andj from the domain D(xi). In the context of a constraint Ck, I refer to a tuple τ of values as being acceptable iff τ ∈ C Svalid iff |τ | = m and ∀ j: τ [ j] ∈ D(xk j ) (i.e. each value in the tuple is in its respective domain).A solution to a CSP P = (cid:2)X , D, C(cid:3) is a tuple τ of size | X| where ∀i: τ [i] ∈ D(xi) (τ represents an assignment to allisvariables), and all constraints are satisfied by τ : for each constraint Ck in C with scope (cid:2)xk1 , . . . , xkmk (τ (cid:11)constructed where ∀ j: τ (cid:11)[ j] = τ [k j], and τ (cid:11) ∈ C SGeneralized Arc-Consistency (GAC) for constraint Ck is defined as a function from domains Dk to a set of literals P . Notek is defined in terms of Dk. A literal xi (cid:8)→ j where j ∈ D(xi) is in P iff it is not present in any tuple in C Sk :k : τ [i] = j. Literals in P are not part of any acceptable and valid tuple of the constraint, therefore they can be prunedthat the set C S(cid:3)τ ∈ C Swithout reducing the set of solutions of the CSP P .(cid:3), a new tuple τ (cid:11)is acceptable).2.1.1. Graph theoryRégin’s algorithm [24] and Quimper’s algorithm [18] for pruning EGCC make use of network flow and bipartite matchingtheory [2] as well as strongly connected components [31]. Similarly, Régin’s AllDifferent algorithm [23] makes use of resultsfrom graph theory, in particular maximum bipartite matching [1] and strongly connected components.1 I use subsequence in the sense that (cid:2)1, 3(cid:3) is a subsequence of (cid:2)1, 2, 3, 4(cid:3).\f588P. Nightingale / Artificial Intelligence 175 (2011) 586–614A bipartite graph G = (cid:2)V , E(cid:3) is defined as a set of vertices V and a set of edges E ⊆ V × V , where the edges areinterpreted as having no direction and the vertices can be partitioned into two sets V 1 and V 2 such that no two elementsin the same set are adjacent.A digraph G = (cid:2)V , E(cid:3) is defined as a set of vert",
            {
                "entities": [
                    [
                        136,
                        199,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 25–41www.elsevier.com/locate/artintA Real generalization of discrete AdaBoost ✩Richard Nock a,∗, Frank Nielsen ba Université des Antilles-Guyane, UFR DSE—Ceregmia, Campus de Schoelcher, BP 7209, 97275 Schoelcher, Martinique, Franceb SONY CS Labs (FRL), 3-14-13 Higashi Gotanda, Shinagawa-Ku, Tokyo 141-0022, JapanReceived 1 June 2006; received in revised form 16 October 2006; accepted 16 October 2006Available online 21 November 2006AbstractScaling discrete AdaBoost to handle real-valued weak hypotheses has often been done under the auspices of convex optimization,but little is generally known from the original boosting model standpoint. We introduce a novel generalization of discrete AdaBoostwhich departs from this mainstream of algorithms. From the theoretical standpoint, it formally displays the original boostingproperty, as it brings fast improvements of the accuracy of a weak learner up to arbitrary high levels; furthermore, it bringsinteresting computational and numerical improvements that make it significantly easier to handle “as is”. Conceptually speaking,it provides a new and appealing scaling to R of some well known facts about discrete (ada)boosting. Perhaps the most popularis an iterative weight modification mechanism, according to which examples have their weights decreased iff they receive theright class by the current discrete weak hypothesis. In our generalization, this property does not hold anymore, as examples thatreceive the right class can still be reweighted higher with real-valued weak hypotheses. From the experimental standpoint, ourgeneralization displays the ability to produce low error formulas with particular cumulative margin distribution graphs, and itprovides a nice handling of those noisy domains that represent Achilles’ heel for common Adaptive Boosting algorithms.© 2006 Elsevier B.V. All rights reserved.Keywords: AdaBoost; Boosting; Ensemble learning1. IntroductionIn supervised learning, it is hard to exaggerate the importance of boosting algorithms. Loosely speaking, a boostingalgorithm repeatedly trains a moderately accurate learner, gets its weak hypotheses, combines them, to finally outputa strong classifier which boosts the accuracy up to arbitrary high levels [14,15]. (Discrete) Adaboost, undoubtfullythe most popular provable boosting algorithm [7], uses weak hypotheses with outputs restricted to the discrete setof classes that it combines via leveraging coefficients in a linear vote. Strong theoretical issues have motivated theextension of this discrete AdaBoost [8] to handle real-valued weak hypotheses as well [8,17,26,29]. Even when onlyfew of them are true generalizations of discrete AdaBoost [17,29], virtually all share a strong background in convex✩ Extends the paper from the same name that was awarded the Best Paper Award at the 17th European Conference on Artificial Intelligence(2006).* Corresponding author. Fax: (+596) 596 72 74 03.E-mail addresses: Richard.Nock@martinique.univ-ag.fr (R. Nock), Nielsen@csl.sony.co.jp (F. Nielsen).URLs: http://www.univ-ag.fr/~rnock (R. Nock), http://www.csl.sony.co.jp/person/nielsen/ (F. Nielsen).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.10.014\f26R. Nock, F. Nielsen / Artificial Intelligence 171 (2007) 25–41optimization originally rooted in a “key” to boosting in AdaBoost: a strictly convex exponential loss integrated intoa weight update rule for the examples, loss which upperbounds the error and approximates the expected binomiallog-likelihood. However, very little is often known for these algorithms from the seminal boosting model standpoint[14,15,27], a model which roughly requires convergence to reduced true risk under very weak assumptions (with highprobability).In this paper, we propose a new real AdaBoost, a generalization of discrete AdaBoost that handles arbitrary real-valued weak hypotheses. With respect to former real AdaBoosts, the weight update is fundamentally different as itdoes not integrate anymore the convex exponential loss; also, the leveraging coefficients for the weak hypothesesdiffer in the output; finally, these leveraging coefficients are given in closed form and their computation can noweasily be delayed until the end of boosting, which is not the case for conventional real AdaBoosts [8,17,29]. The majortheoretical key feature of this algorithm is that it is a provable boosting algorithm in the original sense. Another point isthat it saves computation time with respect to previous generalizations of discrete AdaBoost, that need to approximatethe solution of a convex minimization problem at each boosting iteration [17,29]. From the experimental standpoint,the weight update rule, which does not require anymore the approximation of logarithms or exponentials, is less proneto numerical errors. Finally, it prevents or reduces some numerical instabilities that previous generalizations [17,29]face when the weak hypotheses reach perfect, or perfectly wrong, classification. This might explain why experimentsclearly display that our algorithm handles noise more efficiently than discrete or real AdaBoosts. Noise handling hassoon be described as AdaBoost’s potential main problem, see [2].As a matter of fact, it is quite interesting that our algorithm is indeed a generalization of discrete AdaBoost, as whenthe weak hypotheses have outputs constrained to the set of classes, both algorithms coincide. From this standpoint,our paper also brings a relevant conceptual contribution to boosting. Indeed, we give a complete generalization to R ofpopular (discrete) boosting properties, and this is sometimes clearly not trivial. For example, discrete AdaBoost is veryoften presented as an algorithm that reweights lower the examples that have received the right class. Scaled to R, thisis not true anymore. Roughly speaking, provided a so-called Weak Learning Assumption holds (which states that theclassifier is slightly different from random), lower reweighting occurs only for examples that receive the right class,and on which a measure of the classifier’s confidence exceeds a measure of its average confidence (over all examples,known as a margin). Only on the discrete prediction framework do these two properties coincide. Furthermore, thisscaling property does not hold for previous real AdaBoosts [8,17,26,29].Section 2 presents some definitions, followed by a section on our generalization of discrete AdaBoost. Section 4presents and discusses experimental results, and a last section concludes the paper.2. Definitions and related workOur framework is rooted into the original weak/strong learning and boosting frameworks, and Valiant’s PAC (Prob-ably Approximately Correct) model of learnability [7,15,30]. We have access to a domain X of observations, whichcould be {0, 1}n, Rn, etc. Here, n is the number of description variables. More precisely, we collect examples, that is,couples (observation, class) written (x, y) ∈ X × {−1, +1}. “+1” is called the positive class (or label), and “−1” thenegative class. In this paper, we deal only with the two-classes case. Well known transformations exist that allow itsextension to multiclass, multilabel frameworks [29]. In this paper, boldfaces such as x denote n-dimensional vectors,calligraphic faces such as X denote sets and blackboard faces such as S denote subsets of R, the set of real numbers.Unless explicitely stated, sets are enumerated following their lower-case, such as {xi: i = 1, 2, . . .} for vector sets,and {xi: i = 1, 2, . . .} for other sets (and for vector entries). We make the assumption that examples are sampled inde-pendently, following an unknown but fixed distribution D over X × {−1, +1}. Our objective is to induce a classifieror hypothesis H : X → R, that matches the best possible the examples drawn according to D.For this objective, we define a strong learner as an algorithm which is given two parameters 0 < ε, δ < 1, samplesaccording to D a set S of m examples, and returns a classifier or hypothesis H : X → R such that with probability(cid:2) 1 − δ, its true risk (cid:4)D,H is bounded as follows:(cid:4)(cid:3)H (x)(1)Here, sign(a) is +1 iff a (cid:2) 0, and −1 otherwise. The time complexity of the algorithm is required to be polynomial inrelevant parameters, among which 1/ε, 1/δ, n. To be rigorous, the original models [15,30] also mention dependenceson concepts that label the examples. Examples are indeed supposed to be labeled by a so-called target concept,= (cid:4)D,H (cid:3) ε.Pr(x,y)∼D(cid:2)sign(cid:6)= y(cid:5)\fR. Nock, F. Nielsen / Artificial Intelligence 171 (2007) 25–4127Input: sample S = {(xi , yi ), xi ∈ X , yi ∈ {−1, +1}}w1 ← u;for t = 1, 2, . . . , T doGet (ht : X → S) ← WL(S, wt );Find αt ∈ R;Update: ∀1 (cid:3) i (cid:3) m,wt+1,i ← wt,i × exp(−αt yi ht (xi ))/Zt ; (2)endOutput: HT (x) =(cid:6)Tt=1 αt ht (x)Fig. 1. An abstraction of AdaBoost.which is unknown but fixed. Distribution D is in fact used to retrieve the examples from this target concept, andthe time complexity of the algorithm is also required to be polynomial in its size. Hereafter, we shall omit for thesake of clarity this notion of target concept, which is not important for our purpose, since our analysis may also befit to handle it as well. A weak learner (WL) has basically the same constraints, with two notable exceptions: (i) theweak hypotheses it delivers have outputs that can be restricted to a subset S ⊆ R, and (ii) (1) is only required tohold with ε = 1/2 − γ for some γ > 0 a constant or inverse polynomial in relevant parameters (this still has tobe verified regardless of D). Since predicting the classes at random, such as with an unbiased coin, would yieldPr(x,y)∼D[sign(random(x)) (cid:6)= y] = 1/2, ∀D, it comes that a weak learner is only required to perform slightly betterthan random prediction. In the original models, it is even assumed that δ is also an inverse polynomial in relevantparameters, whi",
            {
                "entities": [
                    [
                        70,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 240 (2016) 19–35Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintH-index manipulation by merging articles: Models, theory, and experiments ✩René van Bevern a,b,d,∗Manuel Sorge d, Toby Walsh d,e,fa Novosibirsk State University, Novosibirsk, Russian Federationb Sobolev Institute of Mathematics, Siberian Branch of the Russian Academy of Sciences, Novosibirsk, Russian Federationc Institut für Informatik, Friedrich-Schiller-Universität Jena, Germanyd Institut für Softwaretechnik und Theoretische Informatik, TU Berlin, Germanye University of New South Wales, Sydney, Australiaf Data61, Sydney, Australia, Christian Komusiewicz c,d, Rolf Niedermeier d, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 March 2016Received in revised form 26 July 2016Accepted 5 August 2016Available online 10 August 2016Keywords:Citation indexHirsch indexParameterized complexityExact algorithmsAI’s 10 to watch1. IntroductionAn author’s profile on Google Scholar consists of indexed articles and associated data, such as the number of citations and the H-index. The author is allowed to merge articles; this may affect the H-index. We analyze the (parameterized) computational complexity of maximizing the H-index using article merges. Herein, to model realistic manipulation scenarios, we define a compatibility graph whose edges correspond to plausible merges. Moreover, we consider several different measures for computing the citation count of a merged article. For the measure used by Google Scholar, we give an algorithm that maximizes the H-index in linear time if the compatibility graph has constant-size connected components. In contrast, if we allow to merge arbitrary articles (that is, for compatibility graphs that are cliques), then already increasing the H-index by one is NP-hard. Experiments on Google Scholar profiles of AI researchers show that the H-index can be manipulated substantially only if one merges articles with highly dissimilar titles.© 2016 Elsevier B.V. All rights reserved.The H-index is a widely used measure for estimating the productivity and impact of researchers, journals, and institu-tions. Hirsch [22] defined the index as follows: a researcher has H-index h if h of the researcher’s articles have at least hcitations and all other articles have at most h citations. Several publicly accessible databases such as AMiner, Google Scholar, Scopus, and Web of Science compute the H-index of researchers. Such metrics are therefore visible to hiring committees and funding agencies when comparing researchers and proposals.1✩An extended abstract of this article appeared at IJCAI 2015 [4]. This version provides full proof details, new kernelization results, as well as additional E-mail addresses: rvb@nsu.ru (R. van Bevern), christian.komusiewicz@uni-jena.de (C. Komusiewicz), rolf.niedermeier@tu-berlin.de (R. Niedermeier), experiments.* Corresponding author at: Novosibirsk State University, ul. Pirogova 2, 630090 Novosibirsk, Russian Federation.manuel.sorge@tu-berlin.de (M. Sorge), toby.walsh@nicta.com.au (T. Walsh).1 Our study on H-index manipulation is not meant to endorse or discourage the use of the H-index as an evaluation tool. In this regard, we merely aim to raise awareness for the various possibilities for manipulation.http://dx.doi.org/10.1016/j.artint.2016.08.0010004-3702/© 2016 Elsevier B.V. All rights reserved.\f20R. van Bevern et al. / Artificial Intelligence 240 (2016) 19–35Although the H-index of Google Scholar profiles is computed automatically, profile owners can still affect their H-index by merging articles in their profile. The intention of providing the option to merge articles is to enable researchers to identify different versions of the same article. For example, a researcher may want to merge a journal version and a version on arXiv.org, which are found as two different articles by Google’s web crawlers. This may decrease a researcher’s H-index if both articles counted towards it before merging, or increase the H-index since the merged article may have more citations than each of the individual articles. Since the Google Scholar interface permits to merge arbitrary pairs of articles, this leaves the H-index of Google Scholar profiles vulnerable to manipulation by insincere authors.In extreme cases, the merging operation may yield an arbitrarily large H-index even if each single article is cited only a few times: If the author has, for example, h2 articles that are cited once, each by a distinct article from another author, then the H-index of the profile is 1. Creating h merged articles, each consisting of h original articles, gives a profile with H-index h. This is the maximum H-index achievable with h2 citations.Increasing the H-index even by small values could be tempting in particular for young researchers, who are scrutinized more often than established researchers.2 Hirsch [22] estimates that, for the field of physics, the H-index of a successful researcher increases by roughly one per year of activity. Hence, an insincere author might try to save years of research work with the push of a few buttons.H-index manipulation by article merging has been studied by de Keijzer and Apt [9]. In their model, each article in a profile comes with a number of citations. Merging two articles, one with x and one with y citations, replaces these articles by a new article with x + y citations. The obtained article may then be merged with further articles to obtain articles with even higher citation numbers. In this model, one can determine in polynomial time whether it is possible to improve the H-index by merging, but maximizing the H-index by merging is strongly NP-hard [9]. We extend the results of de Keijzer and Apt [9] as follows.1. We propose two further ways of measuring the number of citations of a merged article. One of them seems to be the measure used by Google Scholar.2. We propose a model for restricting the set of allowed merge operations. Although Google Scholar allows merges be-tween arbitrary articles, such a restriction is well motivated: An insincere author may try to merge only similar articles in order to conceal the manipulation.3. We consider the variant of H-index manipulation in which only a limited number of merges may be applied in order to achieve a desired H-index. This is again motivated by the fact that an insincere author may try to conceal the manipulation by performing only few changes to her or his own profile.4. We analyze each problem variant presented here within the framework of parameterized computational complexity [8,12,19,25]. That is, we identify parameters p—properties of the input measured in integers—and aim to design fixed-parameter algorithms, which have running time f (p) · n O (1) for a computable function findependent of the input size n. In some cases, this allows us to give efficient algorithms for realistic problem instances despite the NP-hardness of the problems in general. We also show parameters that presumably cannot lead to fixed-parameter algorithms by showing some problem variants to be W[1]-hard for these parameters.5. We evaluate our theoretical findings by performing experiments with real-world data based on the publication profiles of AI researchers. In particular, we use profiles of some young and up-and-coming researchers from the 2011 and 2013 editions of the IEEE “AI’s 10 to watch” list [1,33].Related work Using the models introduced here, Elkind and Pavlou [27] recently studied manipulation for two alternatives to the H-index: the i10-index, the number of articles with at least ten citations, and the g-index [14], which is the largest number g such that the g most-cited articles are cited at least g times on average. They also considered the scenario where merging articles can influence the profiles of other authors. In a follow-up work to our findings, we analyzed the complex-ity of unmerging already merged articles so to manipulate the H-index with respect to the citation measures introduced here [5]. Notably, in the model corresponding to Google Scholar, the complexity is much lower for unmerging rather than for merging articles.A different way of manipulating the H-index is by strategic self-citations [10,28]; Bartneck and Kokkelmans [3] consider approaches to detect these. Strategic self-citations take some effort and are irreversible. Thus, they can permanently damage an author’s reputation. In comparison, article merging is easy, reversible and usually justified.Bodlaender and van Kreveld [6] showed that, in a previous version of the Google Scholar interface, which only allowed merges of articles displayed together on one page, it was NP-hard to decide whether a given set of articles can be merged at all.The problem of maximizing the H-index in the model of de Keijzer and Apt [9] is essentially a special case of the scheduling problems Bin Covering [2,7] and Machine Covering [20,29].A considerable body of work on manipulation can be found in the computational social choice literature [15,16]. If we view citations as articles voting on other articles, then the problem we consider here is somewhat analogous to strategic candidacy [13].2 In fact, for senior researchers with many citations, the H-index is barely more expressive than the total citation count [32].\fR. van Bevern et al. / Artificial Intelligence 240 (2016) 19–3521Fig. 1. Vertices represent articles in our profile W , arrows represent citations, numbers are citation counts (note that, in general, there may be articles in V \\ W , which are not in our profile and not displayed here). The articles on a gray background in (a) have been merged in (b)–(d), and citation counts are given according to the measures sumCite, unionCite, and fusionCite, respectively. The arrows represent the citations counted by the corresponding measure.1.1. Our modelsWe propose two new models for the merging of articles. These mode",
            {
                "entities": [
                    [
                        134,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 422–439www.elsevier.com/locate/artintDecomposition of structural learning about directed acyclic graphsXianchao Xie a, Zhi Geng a,∗, Qiang Zhao a,ba School of Mathematical Sciences, LMAM, Peking University, Beijing 100871, Chinab Institute of Population Research, Peking University, Beijing 100871, ChinaReceived 8 February 2005; received in revised form 21 November 2005; accepted 16 December 2005Available online 3 February 2006AbstractIn this paper, we propose that structural learning of a directed acyclic graph can be decomposed into problems related to itsdecomposed subgraphs. The decomposition of structural learning requires conditional independencies, but it does not requirethat separators are complete undirected subgraphs. Domain or prior knowledge of conditional independencies can be utilized tofacilitate the decomposition of structural learning. By decomposition, search for d-separators in a large network is localized to smallsubnetworks. Thus both the efficiency of structural learning and the power of conditional independence tests can be improved. 2005 Elsevier B.V. All rights reserved.Keywords: Bayesian network; Conditional independence; Decomposition; Directed acyclic graph; Junction tree; Structural learning; Undirectedgraph1. IntroductionDirected acyclic graphs (DAGs) are widely used to represent independencies, conditional independencies andcausal relationships among variables [5,6,8,15,18,19,24]. Structure recovery of DAGs has been discussed by manyauthors [5,12,19,24,27]. Search for d-separators of vertex pairs is a key issue for orientation of directed edges and forrecovering DAG structures and causal relations among variables. To recover structure of DAGs, Verma and Pearl [27]presented the inductive causation (IC) algorithm which searches for a d-separator S from all possible variable subsetssuch that two variables u and v are independent conditional on S. A systematic way of searching for d-separatorsin increasing order of cardinality was proposed in [23,24]. The PC algorithm limits possible d-separators to verticesthat are adjacent to u and v [19,24]. A decomposition approach of searching for d-separators was presented in [11].To decompose a graph into two subgraphs, the approach in [11] needs a moral graph and it requires two conditions:(i) variable sets in two subgraphs are independent conditional on their separator and (ii) the separator must be acomplete subgraph in the moral graph. The two conditions are often used to define decomposition of an undirectedgraph, see Definitions 2.1 and 2.2 in [15].In this paper, we present a decomposition approach for recovering structures of DAGs. The ultimate use of the con-structed DAGs is to interpret association and causal relationships among variables. Decomposition in our approach* Corresponding author.E-mail addresses: xie1981@water.pku.edu.cn (X.C. Xie), zgeng@math.pku.edu.cn (Z. Geng), zhq@math.pku.edu.cn (Q. Zhao).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.12.004\fX.C. Xie et al. / Artificial Intelligence 170 (2006) 422–439423only needs an undirected independence graph which may not be a moral graph and may have extra edges added tothe moral graph, and further it only requires condition (i) of conditional independencies but it does not require condi-tion (ii) of complete separators. Thus the decomposition is weaker than the weak decomposition defined in [15] andalso than that proposed in [11]. Deleting condition (ii) from decomposition conditions is important since it is difficultwith domain or prior knowledge to judge whether a separator is complete or not. In many practical applications, con-dition (i) of conditional independencies can be judged with domain or prior knowledge or with incompletely observeddata patterns, such as Markov chain, chain graphical models, dynamic or temporal models, file-matching for largedatabases and split questionnaire survey sampling [6,16,20].Section 2 gives notation and definitions. In Section 3, we show a condition for decomposing structural learningof DAGs. Construction of d-separation trees to be used for decomposition is discussed in Section 4. We propose themain algorithm and then give an example in Section 5 to illustrate our approach for recovering the global structureof a DAG. Section 6 discusses the complexity and advantages of the proposed algorithms. Conclusions are given inSection 7. The proofs of our main results and algorithms are given in Appendix A.2. Notation and definitions2.1. Directed acyclic graphs and undirected graphsLet (cid:2)GV = (V , (cid:2)EV ) denote a DAG where V = {X1, . . . , Xn} is the vertex set and (cid:2)EV the set of directed edges.A directed edge from a vertex u to a vertex v is denoted by (cid:3)u, v(cid:4). We assume that there is no directed loop in (cid:2)GV . Wesay that u is a parent of v and v is a child of u if there is a directed edge (cid:3)u, v(cid:4), and denote the set of all parents of avertex v by pa(v). We say that two vertices u and v are adjacent in (cid:2)GV if there is an edge connecting them. A path lbetween two distinct vertices u and v is a sequence of distinct vertices in which the first vertex is u, the last one is vand two consecutive vertices are connected by an edge, that is, l = (c0 = u, c1, . . . , cm−1, cm = v) where (cid:3)ci−1, ci(cid:4) or(cid:3)ci, ci−1(cid:4) is contained in (cid:2)EV for i = 1, . . . , m (m (cid:1) 1), and ci (cid:5)= cj for all i (cid:5)= j . We say that u is an ancestor of v and vis a descendant of u if there is a path between u and v in (cid:2)GV and all edges on this path point at the direction toward v.The set of ancestors of v is denoted as an(v), and define An(v) = an(v) ∪ {v}. A path l is said to be d-separated bya set of vertices Z if and only if(1) l contains a ‘chain’: u → v → w or a ‘fork’ u ← v → w such that the middle vertex v is in Z, or(2) l contains a ‘collider’ u → v ← w such that the middle vertex v is not in Z and no descendant of v is in Z.Two distinct sets X and Y of vertices are d-separated by a set Z if Z d-separates every path from any vertex in X toany vertex in Y ; We call Z a d-separator of X and Y . In a DAG (cid:2)GV , a collider u → v ← w is called a v-structure if uand w are non-adjacent in (cid:2)GV .Let ¯GV = (V , ¯EV ) denote an undirected graph where ¯EV is a set of undirected edges. An undirected edge betweentwo vertices u and v is denoted by (u, v). For a subset A of V , let ¯GA = (A, ¯EA) be the subgraph induced by Aand ¯EA = {e ∈ ¯EV | e ∈ A × A} = ¯EV ∩ (A × A). An undirected graph is called complete if any pair of vertices isconnected by an edge. For an undirected graph, we say that vertices u and v are separated by a set of vertices Z ifeach path between u and v passes through Z. We say that two distinct vertex sets X and Y are separated by Z if andonly if Z separates every pair of vertices u and v for any u ∈ X and v ∈ Y . We say that an undirected graph ¯GV isan undirected independence graph for a DAG (cid:2)GV if the fact that a set Z separates X and Y in ¯GV implies that Zd-separates X and Y in (cid:2)GV . We say that ¯GV can be decomposed into subgraphs ¯GA and ¯GB if(1) A ∪ B = V , and(2) C = A ∩ B separates A \\ B and B \\ A in ¯GV .The above decomposition does not require that the separator C is complete, which is required for weak decompositiondefined in [15] and for decomposition of search for v-structures proposed in [11]. In the next section, we show that aproblem of structural learning of a DAG can also be decomposed into problems for its decomposed subgraphs even ifthe separator is not complete.\f424X.C. Xie et al. / Artificial Intelligence 170 (2006) 422–439(a)(b)Fig. 1. A directed graph, a moral graph and a triangulated graph. (a) The DAG (cid:2)GV . (b) The moral graph (cid:2)GmV . (c) A triangulated graph (cid:2)GtV .(c)Define a moral graph (cid:2)GmA triangulated graph is an undirected graph whose every cycle of length (cid:1) 4 possesses a chord [15]. For anundirected graph ¯GV which is not triangulated, we can add extra edges to it such that it becomes to be a triangulatedgraph, denoted by ¯GtV .V for a DAG (cid:2)GV to be an undirected graph ¯GV = (V , ¯EV ) whose vertex set is V andwhose edge set is constructed by marrying parents and dropping directions, that is, ¯EV = {(u, v): (cid:3)u, v(cid:4) or (cid:3)v, u(cid:4) ∈(cid:2)EV } ∪ {(u, v): (u, w, v) forms a v-structure} [15]. An undirected edge added for marrying parents is called a moraledge. The moral graph (cid:2)GmV is an undirected independence graph for (cid:2)GV [15].Example 1. Consider a DAG (cid:2)GV in Fig. 1(a). 2 → 4 ← 3 and 4 → 7 ← 6 are two v-structures. A path l = (2, 1, 5)is d-separated by vertex 1, and another path l(cid:11) = (2, 4, 7, 6, 5) is d-separated by an empty set since 4 → 7 ← 6 is acollider. Vertices 2 and 5 are d-separated by vertex 1. an(4) = {1, 2, 3} and An(4) = {1, 2, 3, 4}. The moral graph (cid:2)GmVis shown in Fig. 1(b), whose edges (2, 3) and (4, 6) are moral edges. Set {2, 3, 5} separates {1} and {4, 6, 7}, and thus(cid:2)GmV can be decomposed into two undirected subgraphs over {1, 2, 3, 5} and {2, . . . , 7}. An undirected independencegraph for (cid:2)GV may have extra undirected edges added to the moral graph, say edges (1, 4) and (1, 6) added to (cid:2)GmV , seedashed edges in Fig. 1(c). The graph in Fig. 1(c) is a triangulated graph of (cid:2)GmV .Given a DAG (cid:2)GV , a joint distribution or density of variables X1, . . . , Xn isP (x1, . . . , xn) =n(cid:1)i=1P (xi | pai),where P (xi | pai) is the conditional probability or density of Xi given pa(Xi) = pai . The DAG (cid:2)GV and the distributionP are said to be compatible [19] and P obeys the global directed Markov property of (cid:2)GV [15]. Let X Y denotethe independence of X and Y , and X Y | Z the conditional independence of X and Y given Z. If sets X and Y ared-separated by Z, then X is independent of Y conditional on",
            {
                "entities": [
                    [
                        72,
                        138,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 850–864Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAllDifferent-based filtering for subgraph isomorphismChristine SolnonUniversité de Lyon, Université Lyon 1, LIRIS, UMR5205 CNRS, F-69622, Francea r t i c l ei n f oa b s t r a c tThe subgraph isomorphism problem involves deciding if there exists a copy of a patterngraph in a target graph. This problem may be solved by a complete tree search combinedwith filtering techniques that aim at pruning branches that do not contain solutions. Weintroduce a new filtering algorithm based on local all different constraints. We show thatthis filtering is stronger than other existing filterings — i.e., it prunes more branches — andthat it is also more efficient — i.e., it allows one to solve more instances quicker.© 2010 Elsevier B.V. All rights reserved.Article history:Received 24 December 2009Received in revised form 3 May 2010Accepted 3 May 2010Available online 6 May 2010Keywords:Subgraph isomorphismConstraint programmingAll different constraint1. IntroductionGraphs are widely used in real-life applications to represent structured objects such as, for example, molecules, images,or biological networks. In many of these applications, one looks for a copy of a pattern graph into a target graph [4]. Thisproblem, known as subgraph isomorphism, is NP-complete in the general case [6].Subgraph isomorphism problems may be solved by a systematic exploration of the search space composed of all possibleinjective matchings from the set of pattern nodes to the set of target nodes: starting from an empty matching, one incre-mentally extends a partial matching by matching a non-matched pattern node to a non-matched target node until eithersome edges are not matched by the current matching (the search must backtrack to a previous choice point and go onwith another extension) or all pattern nodes have been matched (a solution has been found). To reduce the search space,this exhaustive exploration is combined with filtering techniques that aim at removing candidate couples of non-matchedpattern-target nodes. Different levels of filtering may be considered; some are stronger than others (they remove morenodes), but also have higher time complexities.In this paper, we describe and compare existing filtering algorithms for the subgraph isomorphism problem, and weintroduce a new filtering algorithm which is stronger. We experimentally evaluate this new filtering algorithm on a widebenchmark of instances, and we show that it is much more efficient on many instances.2. Definitions and notationsA graph G = (N, E) consists of a node set N and an edge set E ⊆ N × N, where an edge (u, uThe set of neighbors of a node u is denoted adj(u) and is defined by adj(u) = {uconsider non-directed graphs, such that (u, uin Section 5.(cid:3)) ∈ E ⇔ (u(cid:3)) is a couple of nodes.(cid:3)) ∈ E}. In this paper, we implicitly(cid:3), u) ∈ E. The extension of our work to directed graphs is discussed(cid:3) | (u, uA subgraph isomorphism problem between a pattern graph G p = (N p, E p) and a target graph Gt = (Nt, Et) consists indeciding whether G p is isomorphic to some subgraph of Gt . More precisely, one should find an injective matching f : N p →Nt , that associates a different target node to each pattern node, and that preserves pattern edges, i.e.,E-mail address: christine.solnon@liris.cnrs.fr.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.05.002\fC. Solnon / Artificial Intelligence 174 (2010) 850–864851(cid:2)∀u, u(cid:3)(cid:3)∈ E p,(cid:2)f (u), f(cid:3)(cid:3)(cid:2)(cid:3)u∈ EtThe function fis called a subisomorphism function.Note that the subgraph is not necessarily induced so that two pattern nodes that are not linked by an edge may bematched to two target nodes which are linked by an edge. This problem is also called subgraph monomorphism or subgraphmatching in the literature.In the following, we assume G p = (N p, E p) and Gt = (Nt, Et) to be the underlying instance of subgraph isomorphism) nodes of G pproblem, and we assume without loss of generality that N p ∩ Nt = ∅. We usually denote u or u(resp. Gt ).(resp. v or vWe denote #S the cardinality of a set S. We also define N = N p ∪ Nt , E = E p ∪ Et , np = #N p , nt = #Nt , e p = #E p ,(cid:3)(cid:3)et = #Et , and dp and dt the maximal degrees of the graphs G p and Gt .3. Filtering for subgraph isomorphismSubgraph isomorphism problems may be modeled as constraint satisfaction problems in a very straightforward way.In this section, we first show how to model and solve subgraph isomorphism problems within a constraint satisfactionframework. Then, we describe different filtering algorithms for subgraph isomorphism in Sections 3.3 to 3.6, and we comparethem in Section 3.7.3.1. Modeling and solving subgraph isomorphism by means of constraintsA constraint satisfaction problem (CSP) is defined by a set of variables, such that each variable is associated with adomain (i.e., the set of values that it may be assigned to), and a set of constraints (i.e., relations that restrict the set ofvalues that may be assigned to some variables simultaneously). Solving a CSP involves finding an assignment of values toall variables such that all constraints are satisfied.A subgraph isomorphism problem may be modeled as a CSP by associating a variable (denoted xu ) with every patternnode u. The domain of a variable xu (denoted D u ) contains the set of target nodes that may be matched to u. Intuitively,assigning a variable xu to a value v corresponds to matching the pattern node u to the target node v. The domain D u isusually reduced to the set of target nodes the degree of which is higher or equal to the degree of u as node u may bematched to node v only if #adj(u) (cid:2) #adj(v).Constraints ensure that the assignment of variables to values corresponds to a subisomorphism function. There are twokinds of constraints:• edge constraints ensure that pattern edges are preserved, i.e.,(cid:2)∀u, u(cid:3)(cid:3)∈ E p,(xu, xu(cid:3) ) ∈ Et• difference constraints ensure that the assignment corresponds to an injective function, i.e.,(cid:2)∀u, u(cid:3)(cid:3)∈ N 2p,u (cid:11)= u(cid:3) ⇒ xu (cid:11)= xu(cid:3)Within this framework, solving a subgraph isomorphism problem involves finding an assignment of the variables that sat-isfies all constraints. We shall consider that a variable is assigned whenever its domain is reduced to a singleton, i.e.,D u = {v} ⇔ xu = v.Subgraph isomorphism problems modeled as CSPs may be solved by building a search tree that explores all possiblevariable assignments until finding a solution. The size of this search tree may be reduced by using filtering techniqueswhich propagate constraints to remove values from domains.We briefly recall some basic principles of constraint propagation in Section 3.2. Then, we describe different filteringtechniques that may be used to solve subgraph isomorphism problems in Sections 3.3 to 3.6. Note that some of thesefilterings (i.e., FC(Diff ), GAC(AllDiff ), FC(Edges), and AC(Edges)) are generic constraint propagation techniques that may beused to solve any CSP whereas some others (i.e., LV2002 and ILF(k)) are dedicated to the subgraph isomorphism problem.3.2. Recalls on constraint propagationConstraint propagation aims at filtering variable domains by removing inconsistent values, that is, values that do notbelong to any solution. This constraint propagation step may be done at each choice point of the search. If it removes allvalues in the domain of a variable, then the search can backtrack to a previous choice.A pioneering work for constraint propagation has been done in 1972 by Waltz for a scene drawing application [19].Since then, many different constraint propagation algorithms have been proposed. These algorithms achieve different partialconsistencies and also have different time and space complexities. In this section, we do not aim at describing all existingpropagation algorithms. We only briefly describe two basic and well-known generic techniques, that is, forward-checking andmaintaining arc-consistency. The reader may refer to [17,10] for more information.\f852C. Solnon / Artificial Intelligence 174 (2010) 850–864Forward-checking The basic idea of forward-checking is to propagate all constraints involving a variable just after its as-signment in order to remove from the domains of the non-assigned variables any value which is not consistent with thisassignment. More precisely, after the assignment of xi to v i , one propagates binary constraints between xi and any non-assigned variable x j by removing from the domain of x j any value v j such that the assignment {(xi, v i), (x j, v j)} violatesthe constraint holding between xi and x j . When constraints have arities greater than two, one may propagate constraintssuch that all variables but one are assigned.Maintaining arc-consistency A stronger filtering, but also a more expensive one, is obtained by maintaining arc-consistency,also called 2-consistency. Roughly speaking, a binary CSP is arc-consistent if each value v i in the domain of a variable xihas at least one support in the domain of every other variable, thus ensuring that if xi is assigned to v i then each othervariable still has at least one consistent value in its domain. More precisely, given a variable xi ∈ X and a value v i ∈ D(xi),a support of (xi, v i) for a variable x j is a value v j ∈ D(x j) such that the partial assignment {(xi, v i), (x j, v j)} is consistent.A binary CSP ( X, D, C) is arc-consistent if every value in every domain has at least one support in the domain of each othervariable.To maintain arc-consistency while constructing a partial assignment A, we filter variable domains after each variableassignment by removing non-supported values. Such a filtering must be repeated until no more domain is reduced: as soonas a value is removed, we must chec",
            {
                "entities": [
                    [
                        136,
                        189,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 92 ( 1997) 13 l- 167 Artificial Intelligence How to progress a database * Fangzhen Lin ‘, Ray Reiter * Department of Computer Science, University of Toronto, Toronto, Ont., Canada M5S 3H5 Received March 1996; revised October 1996 Abstract One way to think about a STRIPS operator is as a mapping from databases to databases, in the following sense: suppose we want to know what the world would be like if an action, represented by the STRIPS operator (Y, were done in some world, represented by the STRIPS database Do. To find out, simply perform the operator (Y on DO (by applying (Y’S elementary add and delete to DO). We describe this process as progressing the database 230 in response revision operators to the action (Y. In this paper, we consider the general problem of progressing an initial database in response to a given sequence of actions. We appeal to the situation calculus and an axiomatization of actions which addresses the frame problem (Reiter ( 1991) ). This setting is considerably more general than STRIPS. Our results concerning progression are mixed. The (surprising) bad news is that, in general, to characterize a progressed database we must appeal to second-order logic. The good news is that there are many useful special cases for which we can compute the progressed database in first-order logic; not only that, we can do so efficiently. Finally, we relate these results about progression to STRIPS-like systems by providing a se- mantics for such systems in terms of a purely declarative situation calculus axiomatization for actions and their effects. On our view, STRIPS operators provide a mechanism for computing the progression of an initial situation calculus database under the effects of an action. We illustrate this idea by describing two different STRIPS mechanisms, and proving their correctness with respect to their situation calculus specifications. @ 1997 Elsevier Science B.V. Keywords: Situation calculus; Theories of actions; Regression; Progression; STRIPS; Strongest postconditions *This paper revises, and combines, (and why) 1. Logical database foundations” results that first appeared [ 121 and “How to progress a database in E Lin and R. Reiter’s “How to progress a II. The STRIPS connection” 1151. * Corresponding author. E-mail: reiter@ai.toronto.edu. Fellow of the Canadian Institute for Advanced Research. ’ E-mail: fl@ai.toronto.edu. 0004-3702/97/$17.00 PII SOOO4-3702( @ 1997 Elsevier Science B.V. All rights reserved 96)00044-6 \f132 F Lin, R. Reiter/Art@cial Intelligence 92 (1997) 131-167 1. Introduction represented from databases is as a mapping by the STRIPS operator One way to think about STRIPS operators to databases, in the following sense: suppose we want to know what the world would be like if an (Y, were done action, by the STRIPS database 2%~. To find out, simply perform add and delete revision operators applying LY’S elementary process as progressing the database Do in response [ 251 and Pednault the world represented by the initial database. 2 However, or even possible initial world description. As we shall see in this paper, once we go beyond STRIPS-like systems, progression in some world, represented the operator cx on Do (by this to Do). We describe the effects of actions as a simple process of progressing [ 161). The resulting database describes to the action CY (cf. Rosenschein it may not always be convenient the effects of the action on becomes surprisingly to describe an In this paper, we consider of actions which addresses to a given sequence of actions. We appeal in response an axiomatization and Reiter concerning characterize is that there are many useful special cases for which we can compute database [ 131). This setting progression bad news a progressed database we must appeal to second-order is considerably more general (surprising) the frame problem are mixed. The logic; not only in first-order to the situation (Reiter an initial database and calculus [ 211, Lin than STRIPS. Our results is that, to logic. The good news the progressed in general, Finally, we relate these results about progression for such systems in terms of a purely declarative that, we can do so efficiently. to STRIPS-like complicated. the general problem of progressing ing a semantics axiomatization anism for computing the effects of an action. We illustrate mechanisms, and proving ifications. for actions and their effects. On our view, a STRIPS operator of an initial this idea by describing the progression situation their correctness with respect to their situation calculus situation systems by provid- calculus is a mech- calculus database under two different STRIPS spec- The need to progress a database arises for us in a robotics setting. In our approach a robot [ 8, lo], we must address the so-called projection problem: answer controlling query Q( do( A, SO) ) , where do( A, So) denotes from performing the sequence of actions A beginning with the initial situation SO. This can be done using [ 211) to reduce the projection [ 281, Pednault regression about from problem the initial situation SO. Unfortunately, in this application: 1. After the initial database, consisting regression suffers from a number of drawbacks to one of entailment the robot has been for a long period, [ 171, and Reiter (cf. Waldinger of sentences the situation functioning resulting to the it has performed since the sequence A, con- the initial situation, has become long, and regressing over such a sequence becomes computationally sisting of all the actions extremely expensive. 2 This is also the way that database practitioners think about database updates the STRIPS action and the database update paradigms as much about database updates as it is about STRIPS actions and their generalizations. database perspective, are essentially see Reiter [ 231. (Abiteboul the same. Accordingly, [ 11). In fact, this paper is For more on the \fE Lin, R. Reiter/Art$icial Intelligence 92 (1997) 131-167 133 2. Similarly, after a long while, the initial world state often becomes that significantly many final steps of the regression become SXY. so rearranged unneces- entirely 3. Most significantly, for robotics, perceptual actions [ 261) lead to new facts being added to the database. But such facts are true in the current situation-the the other about databases containing mixed (old) database facts-facts and we very complicated, know of no satisfactory way to do this. the current and initial situations-is facts are true in SO. Reasoning the perceptual action-whereas (Scherl and Levesque one immediately following about Our way of addressing robot’s database. sion of the database, database. We envisage line, during about. these problems with regression action every perceptual In particular, is to periodically is accompanied coupled with the addition of the perceived that these database progression computations progress the by a progres- fact to the resulting can be done off- like moving the time when the robot is busy performing physical actions, 2. Logical preliminaries The language L: of the situation calculus action function do( a, s) denoting is first order, many sorted, with sorts situation for everything else. It has the following a constant SO of sort situation denoting from that for actions, and object predicates and functions: independent situation; a binary the action a in the situation for situations, domain the initial performing the action a is possible situation. s < s’ means We assume a finite number of situation a finite number of situation and a finite number ofpuents which are predicate n 2 0. We denote by .C2 the second-order the situation calculus will be in ,C2 (Lin and Reiter [ 221) . on situations s; a binary predicate Poss( a, s) meaning in situation s; and a binary predicate <: situationx (executable) that s’ can be reached from s by a sequence of executable actions. independent predicates with arity object”, n > 0, functions with arity object” --+ object, n 3 0, symbols of arity object” x situation, for extension of ,C. Our foundational [ 13]), because we need induction the situation independent resulting axioms (Reiter the situation calculus Often, we must restrict is a finite set of sentences situation. For example, any situation the initial database for any situation terms except SO, and do not mention Poss and <. For this purpose, term st, we define ,C,, to be the subset of L that does not mention any other situation terms except st, does not quantify over situation variables, and does not mention Poss or <. Formally, in C that do not mention to a particular it is the smallest set satisfying: I. cp E L,Y, provided cp E C does not mention any situation 2. F(t1,... term. , t,, st) E Lc,, provided F is a fluent of the right arity, and tl , . . , t, are terms of the right sort. 3. If (o and C$ are in 13,,, so are 7Q9 40 v 40’9 9 A $0’7 cp 2 40’9 ‘p = q’, (V-x)$? (3x) P, (Va) q, and (3a) 9, where x and a are variables of sort object and action, respectively. \f134 F: Lin, R. ReiterIArtificial Intelligence 92 (1997) 131-167 We remark here that according This may seem odd when we want sentences Fortunately, we shall use C,, only when sf is either a ground of sort situation. to this definition, (Vu) F( do( a, Se) ) will be in C~oCn,soj. about situation st. in ,C,, to be propositions term or a simple variable (3~) (V’x) (3s).p(x, We shall use ,C$ to denote the second-order of arity object”, n > 0. So the second-order is in CzO, but over a predicate variable of arity object x situation. Formally, satisfying: 1. 2. in C,, is also in Cz,. s) z F(x, SO) is not, since extension of ,C,, by predicate variables z F(x, So) sentence the latter quantifies (3~) (tlx).p(x) ,Cz, is the smallest set , t,,) E C$ provided p is a predicate variable of arity objecf, n 3 0, and Every formula p(t1,... t1,. . . , t, are terms of sort object. If (p and 9’ are in l:,, (V’a)p, (Vp)p, (31) 9, action, respectively, 3. so are X+T",
            {
                "entities": [
                    [
                        69,
                        95,
                        "TITLE"
                    ],
                    [
                        2176,
                        2202,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 265–299www.elsevier.com/locate/artintRedundancy in logic II: 2CNF and Horn propositional formulaePaolo LiberatoreDipartimento di Informatica e Sistemistica, Università di Roma “La Sapienza”, Via Ariosto 25, 00185 Roma, ItalyReceived 9 August 2006; received in revised form 4 June 2007; accepted 15 June 2007Available online 27 June 2007AbstractWe report results about the redundancy of formulae in 2CNF form. In particular, we give a slight improvement over the trivialredundancy algorithm and give some complexity results about some problems related to finding Irredundant Equivalent Subsets(I.E.S.) of 2CNF formulae. The problems of checking whether a 2CNF formula has a unique I.E.S. and checking whether a clausein is all its I.E.S.’s are polynomial. Checking whether a 2CNF formula has an I.E.S. of a given size and checking whether a clauseis in some I.E.S.’s of a 2CNF formula are polynomial or NP-complete depending on whether the formula is cyclic. Some resultsabout Horn formulae are also reported.© 2007 Elsevier B.V. All rights reserved.Keywords: Propositional logic; Computational complexity; Redundancy1. IntroductionProblems related to redundancy in logic and similar fields has been investigated by a number of authors. Ginsberg[9] and Schmolze and Snyder [25] studied the problem of redundancy of production rules. Several authors investi-gated the problem of minimizing a formula, with particular emphasis on Horn formulae [1,11,12,19,20,28]. Gottloband Fermüller [10] gave results about the redundancy of a literal in a first-order clause. Liberatore [17,18] providedcomplexity results for the CNF case and for some non-classical logics. Büning and Zhao [3] studied the problems ofequivalence and extension-equivalence of irredundant formulae. Various authors have studied the problem of minimalunsatisfiability [2,7,21].In this article, we report about the complexity of some problems related to the redundancy of formulae in 2CNF andHorn form. In particular, the considered problems are that of checking whether a formula is redundant, establishingthe minimal size of an Irredundant Equivalent Subset (I.E.S.) of a formula, and checking whether a clause is in someI.E.S.’s of a formula. The first problem is polynomial due to the polynomiality of consistency checking for 2CNF andHorn formulae, but a slight improvement over the trivial algorithm exists. For the two other problems, complexity isshown to be polynomial or NP-complete depending on the structure of the formula.There are several reasons for checking redundancy of a formula and for finding an irredundant and equivalentsubset of it. Most of these reasons apply to all kind of formulae, regardless of whether they are general propositionalE-mail address: paolo@liberatore.org.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.06.003\f266P. Liberatore / Artificial Intelligence 172 (2008) 265–299formulae, 2CNF, Horn, or formulae of non-classical logics. Some are peculiar to tractable restrictions such as 2CNFand Horn.Generally, a logic formula may come either from a user directly encoding a domain of interest or from an automatedtranslation from some formal language. In the first case, the presence of a redundant part of a formula may indicate thatsome aspects of the domain are either of particular importance or not sufficiently understood. Intentional redundancyof information about a particular part of a domain may indicate a will or need to be sure that part of the domainis correctly encoded. On the other hand, an unintentional redundancy may indicate undetected problems with theencoding, such as multiple people using the same names for expressing different concepts. Simplifying a formulaby removing redundancy shows which parts are really needed; this may result in error detection if redundancy wasunintentional, and in a confirmation of correctness if it was intentional.If a formula results from a translation, its redundancy may give the same indications on the information in thelanguage it was originally expressed. However, it may also highlight problems that are introduced by the translationitself. As an example, while each of a set of formulae may be correct by itself, their merging may result in an incon-sistent formula because of the different meaning of the variables in different formulae [16]. The same problem mayhowever also generate redundancy. Depending on the particular scenario, redundancy may also results from severalsources providing the same information. Either way, detecting redundancy tells something significant.On the technical side, redundancy has been sometimes intentionally added to formulae to speed-up consistencyand entailment solving. Removing redundancy is a way to make such formulae easier to understand to humans.On the other hand, increasing the size of formulae generally makes solving harder. This is particular important forthose cases where consistency and entailment are polynomial problems, such as 2CNF and Horn. If a set of clausesoriginally contains a large number of redundant clauses, removing some redundant ones may provide a speedup dueto the reduction in size of the original formula. This gain is useful when the same formula is for example checkedfor consistency with or entailment to several different formulae, because the cost of redundancy removal is amortizedamong several consistency or entailment tests.The results presented in this paper differ from previous work in either the settings or in the specific analyzedproblems, or both. Related work regarding different settings are those by Ginsberg [9] and Schmolze and Snyder [25],as they are about production rules and not propositional formulae. Gottlob and Fermüller [10] also worked in adifferent logic, the first-order one, but also studied a different problem, that or redundancy within a single clauserather than the redundancy of a clause within a set of clauses. Liberatore [18] investigated redundancy for somenon-classical logics.Related work regarding propositional logic can be roughly divided into three classes. First, we have the investiga-tions into making a propositional formula as small as possible while preserving equivalence. This problem originatesfrom the article where the polynomial hierarchy has been introduced [20], and has been then subject of a number ofother studies [1,11,12,19,28]; emphasis is often of Horn formulae. These results differ from the ones in the presentarticle because they are about a different problem. Minimizing a formula means producing an equivalent formula ofminimal size; such formula can be syntactically very different from the original one, to the point of not sharing anyrecognizable part with it. Minimization and redundancy elimination are therefore different tasks, and they serve dif-ferent purposes: minimization produces a formulae of strictly minimal size; redundancy elimination is not required toreduce size as much as possible, but preserves the structure of the original formula by not adding any new part to it.The other two classes of related work are about the problems where irredundancy is a restriction over the alloweddata and about subproblems of irredundancy. In the first class falls the work of Büning and Zhao [3], who studiedproblems under the restriction that the involved formulae are irredundant. In the second class we have the problem ofminimal unsatisfiability [2,7,21]; this problem can be considered as the subcase of irredundancy when the consideredformula is assumed to be unsatisfiable. In this article, we also work in this settings by showing results for 2CNFunsatisfiable formulae.Liberatore [17] provided complexity results for the CNF case. The present article contains a similar study, butfor the 2CNF and Horn case. These special cases are generally considered of importance because consistency andentailment is polynomial, rather than NP-complete, in them. While the Horn case is generally considered the mostimportant of these two subcases, attention to the 2CNF case has also been given, as shown by a number of recentarticles on the subject [4,5,13,26,27,29].The rest of the paper is organized as follows. In the next section, we give a technical overview of the presentedresults. We then give some general theorems that will be used for proving those results. In the following four sections,\fP. Liberatore / Artificial Intelligence 172 (2008) 265–299267results will be shown for the problems of redundancy checking and Irredundant Equivalent Subsets (I.E.S.). In partic-ular, Section 4 contains result about redundancy checking; Section 5 contains the easiest results about I.E.S.’s; Section6 is about the size of I.E.S.’s; and Section 7 is about the problem of checking whether a clause is in some I.E.S.’s of agiven formula. Section 8 contains some results about Horn formulae. Technical lemmas and proofs are moved to theappendix for ease of reading.2. Overview of resultsThe first problem we consider is that of checking the redundancy of a 2CNF formula. Since a formula is redundantif and only if it is equivalent to one of its subsets and checking equivalence for 2CNF formulae is polynomial, theproblem is polynomial. We slightly improve over the trivial algorithm by showing that redundancy can be checked intime O(nm), where n is the number of variables and m is the number of clauses of the formula.The other problems we consider are about the irredundant equivalent subsets (I.E.S.) of a formula. In particular, thefollowing problems are easily shown to be polynomial for formulae in 2CNF: check whether a formula is an I.E.S. ofanother one; check whether a clause is in all I.E.S.’s of a formula; and check whether a formula has an unique I.E.S..The last two problems are polynomial thanks to the following results [17]: a clause γ is in all I.E.S.’s of a formula Πif and only if Π\\{γ } |= γ ; a formula Π has an unique I.E.S. if and only if {γ ∈ Π | Π\\{γ } (cid:3)|= γ } |=",
            {
                "entities": [
                    [
                        72,
                        132,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 98 (1998) I-47 Artificial Intelligence Schema induction for logic program synthesis Nancy Lynn Tinkham ’ Computer Science Department, Rowan University, 201 Mullica Hill Road, Glassboro, NJ 08028, USA Received February 1993; revised August 1997 Abstract Prolog program synthesis can be made more efficient by using schemata which capture similar- ities in previously-seen programs. Such schemata narrow the search involved in the synthesis of a new program. We define a generalization operator for forming schemata from programs and a downward refinement operator for constructing programs from schemata. These operators define schema-hierarchy graphs which can be used to aid in the synthesis of new programs. Algorithms are presented for efficiently obtaining least generalizations of schemata, for adding new schemata to a schema-hierarchy graph, and for using schemata to construct new programs. @ 1998 Elsevier Science KV. Keywords: Inductive logic programming; Inductive inference; Automatic programming; Learning 1. Introduction When writing computer programs, people often find it useful to draw on the knowledge of other ‘programs that have been written before. An experienced programmer may, when presented with a new problem, recall solving a similar problem on an earlier occasion; a novice programmer may use examples from the classroom or textbook to guide problem- solving. This observation motivates the following hypothesis: One way for machines to syn- thesize programs is ( 1) to see examples of programs, (2) to form generalizations which capture -information about the forms of programs, and then (3) to use these general- izations in writing future programs. This paper will describe a language for expressing generalizations of programs, an algorithm for deriving generalizations, and an algorithm for synthesizing a program from a generalization. ’ Email: nlt@rowau.edu. 0004-3702/98/$19.00 @ 1998 Elsevier Science B.V. All rights reserved. HI SOOO4-3702(97)00055-6 \f2 N.L. Tinkhatn/Art@cial Intelligence 98 (1998) l-47 an As illustration, the sujix(Su.List, List), which succeeds amples of the intended behavior of the su#ix predicate: task if SufJixist consider of synthesizing predicate the Prolog is a suffix of List, given some ex- positive examples: wm([cl7 [GhCl), &w[Y~ql~ LLY,41) negative examples: sufJix( [a, b] , [a, b, c] ) , sufJix( [z I, [w, x] ) Our task becomes easier if we have knowledge of the similar predicates pre@( PrejixList, List), ITW. Pwx[ pre$.d[XIYl,[XIZl) :-pyWI:Z). which succeeds if PrefixList is a prefix of List, and member(Element, List), member( Y [ VI W] ) . member( X, [ YlZ] ) :- member( X, Z). which succeeds which is a generalization if Element is a member of List. The first step is to derive a schema of prejix and member. One such schema is the following: Q(K [XIYI) :- QtZ Y>. This schema expresses as the base of the recursion, Further, we have the recursive call involves information the tail of that list. the structure of a recursive clause together with a clause serving in Prolog programs. the that one of the arguments a structure which is very common is a list, and that Taking this schema as a starting point, we search for a program which is a special- ization of the schema and which succeeds on all of the positive examples but none of the negative examples; eventually, the search finds wfJix(w v. su&(X, [YIZ]) :- su&(X, Z). The process, a generalization about each of these programs; information, examples. a program which then, has of a set of programs and captures some of the structural two major components: (1) to derive a schema which information (2) to derive from a schema, making use of this structural is consistent with a given set of positive and negative is I. I. Background Inductive inference, tions, including grammatical the process of learning inference, from examples, covers a range of applica- structures inference of logic formulas, learning \fN.L. i%kham/Art@cial Intelligence 98 (1998) 1-47 3 encoded in semantic nets, hypothesizing mathematical theorems, and automatic pro- gramming. . Gold 1: 161 introduced identification in the limit as a model for the inference of a langua,ge from examples. Learning, in Gold’s paper, is performed by enumerative is, algorithms that in some systematic way consider all machines in a algorithms-that given class until a machine for the target language is found. The main advantage of an enumerauve algorithm is its thoroughness, which often makes it possible to prove which classes of languages can and cannot be identified by the algorithm. This thoroughness is also the main disadvantage of an enumerative approach, in that the vast number of possibilities examined makes the search extremely slow. One o-F the improvements to enumerative algorithms is the introduction of refinement operators, which prune the search without sacrificing theoretical power. Refinement op- [ 30-321, who used them for refining discarded erators were introduced by Shapiro hypotheses. The mathematics of refinement operators in themselves were studied by Laird [ 19,201, who described both “downward” refinement (of which Shapiro’s op- erators were examples) and “upward” refinement. We will return to refinement op- erators in Section 2.2, defining some operators for generalizing and specializing pro- grams. Concept learning has also been studied by Valiant [ 401, Angluin and Laird [ 11, Mitchell [ 251, Michalski [ 241, and Winston [41]. Early work on finding least gener- alization,s of literals and clauses was done by Popplestone [2S], Reynolds [29], and Plotkin [26,27]. A survey of inductive inference systems is given by Angluin and Smith [ 21, and work in grammatical inference is surveyed by Biermann and Feldman [61. Automatic programming systems have been designed to work with LISP, Prolog, and other languages, and the input to these systems variously includes input/output example:s (as in [ 371)) input/output specifications [ 4,7,23,34], and computation traces (e.g., [ 51). The use of transformation rules to construct or improve programs has been studied by Burstall and Darlington [ 81 and Dershowitz [ 11,121. Logic program [ 131, Gilbert and Hogger [ 151, synthesis has been studied by Flener and Deville Sterling and Kirschenbaum [ 351, Lau and Prestwich [ 211, Bergadano and Gunetti [ 31, Grobelnik [ 171, Johansson [ 181, and others. 1.2. Prcject overview This paper describes a project which applies the idea of refinement operators to the problem of using known programs to aid in the synthesis of a new program to fit a set of positive and negative examples. It defines an upward refinement operator and an algorithm for using this operator efficiently to find generalizations of programs, called schemat.a. The paper then shows how these schemata can be used to narrow the search involved in program synthesis. These ideas have been implemented as a Prolog system which repeatedly adds new schemata to its knowledge base so that the system becomes increasingly more efficient at synthesizing new programs. This implemented system will be described at the end of the paper. \f4 N.L. linkham/Artijcial Intelligence 98 (1998) l-47 2. Language and operator definitions Prolog has been chosen in this paper as the basis for the language in which to express programs and schemata. Programs will be represented as multisets of Prolog-like clauses; the clauses will differ from the standard Prolog form in that the right hand side of a clause will be regarded as a multiset * rather than a sequence of literals. We will restrict our attention to programs defining only a single predicate. Hence, one example of a program is: Jrafl4[RISl, [m) .@~W[[WlIW9X> :- {atom(R),\\==(R, [ ]),jLmw(S,T)}, :- Cfratten([U~Vl,Y),Jlatten(U!Z),uppend(I:Z,X)}) Observe that this program would continue to be a correct definition of J&ten even if the sequence of literals or clauses were different; we are specifically choosing to study order-independent programs. This enables us to view programs more directly as logic expressions, without involving the extra-logical concept of order of computation. It is also more in keeping with a philosophy of Prolog programming which favors writing, where possible, programs which do not depend on the order of execution for correctness. A schema will have a representation like that of a program, except that a schema may contain predicate variables and may contain the symbol Cl (empty clause). The special symbols 0 and {Cl} will be used to represent the most specific and most general schemata, respectively. We will use “program” as the special case of “schema” in which no predicate variables or empty clauses occur; hence, a program is a schema, but a schema may or may not be a program. For an overview of the Prolog programming language, see [ 101 and [ 361. 2.1. Language deJinitions terminology must be introduced here for describing programs and schemata. Some A term is an individual-variable, an individual-constant, or a function symbol with its arguments. In the flatten program, X, [ 1, and [ RIS] are all terms. A literal is a predicate symbol with its arguments; atom(R) is an example of a literal. A clause is either 0 (representing the empty clause), a single literal, or an expression of the form where Ai, . . . , A,, are literals, and {AZ, . . . , An} is a multiset of liter&. The literal in a single-literal clause and the literal on the left-hand side of a multi-literal clause (Ai ) are positive literals; the literals on the right-hand side of a clause (AZ, . . . , A,) are negative literals. As an example, one of the clauses in thehtten program is * A multiset is a collection of objects in which repetition is significant, but, as in a set, order is not significant. The operations U (union), n (intersection), C (subset), c (proper subset), + (sum), and - (difference) on literals within clauses and on clauses within schemata will be multiset operations. For a definitio",
            {
                "entities": [
                    [
                        63,
                        107,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 814–847Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic for reasoning about counterfactual emotions ✩Emiliano Lorini∗, François SchwarzentruberInstitut de Recherche en Informatique de Toulouse (IRIT), 118 route de Narbonne, 31062 Toulouse Cedex, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 20 December 2009Received in revised form 22 November 2010Accepted 22 November 2010Available online 2 December 2010Keywords:Modal logicEmotionsSTITThe aim of this work is to propose a logical framework for the specification of cognitiveemotions that are based on counterfactual reasoning about agents’ choices. The prototypicalcounterfactual emotion is regret. In order to meet this objective, we exploit the well-knownSTIT logic (Belnap et al. (2001) [9], Horty (2001) [30], Horty and Belnap (1995) [31]). STITlogic has been proposed in the domain of formal philosophy in the nineties and, morerecently, it has been imported into the field of theoretical computer science where itsformal relationships with other logics for multi-agent systems such as ATL and CoalitionLogic (CL) have been studied. STIT is a very suitable formalism to reason about choices andcapabilities of agents and groups of agents. Unfortunately, the version of STIT with agentsand groups has been recently proved to be undecidable and not finitely axiomatizable. Inthis work we study a decidable and finitely axiomatizable fragment of STIT with agentsand groups which is sufficiently expressive for our purpose of formalizing counterfactualemotions. We call df STIT our STIT fragment. After having extended df STIT with knowledgemodalities, in the second part of article, we exploit it in order to formalize four typesof counterfactual emotions: regret, rejoicing, disappointment, and elation. At the end ofthe article we present an application of our formalization of counterfactual emotions to aconcrete example.© 2010 Elsevier B.V. All rights reserved.1. IntroductionA major objective of AI is to develop interactive cognitive systems which are more attractive and closer to the users andthat can be considered as believable interlocutors [8]. In this perspective, a challenge for AI is to build artificial agents whichare capable of: reasoning about emotions, showing their affective states and personalities, ascribing emotions to humans,predicting the effects of their actions on emotions of humans, and adapting their behaviors accordingly. With the aim ofcreating a new generation of emotional interaction systems, the study of affective phenomena has become a “hot” topic inAI where the domain of Affective Computing [44] has emerged in the last few years.Recently, some researchers have been interested in developing logical frameworks for the formal analysis of emotions(see, e.g., [39,40,58,20]). Their main concern is to exploit logical methods in order to provide a rigorous specification ofhow emotions should be implemented in an artificial agent. The design of agent-based systems where agents are capable ofreasoning about and of displaying some kind of emotions can indeed benefit from the accuracy of logical methods. Theselogical frameworks for the specification of emotions are based on the so-called BDI logics (see e.g. [17,41]). BDI logics allowto model agents’ mental states such as beliefs, desires, intentions, ideals, values, etc., which are the cognitive constituentsof emotions.✩This work is an extended and improved version of the article “A logic for reasoning about counterfactual emotions” appeared in the Proceedings of theTwenty-first International Joint Conference on Artificial Intelligence (IJCAI’09), pp. 867–872.* Corresponding author. Tel.: +33 0561556447; fax: +33 561556258.E-mail addresses: lorini@irit.fr (E. Lorini), schwarze@irit.fr (F. Schwarzentruber).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.022\fE. Lorini, F. Schwarzentruber / Artificial Intelligence 175 (2011) 814–847815Although the application of logical methods to the formal specification of emotions has been quite successful, there isstill much work to be done in the field of computational and logical modeling of ‘counterfactual emotions’. In line withpsychological theories of ‘counterfactual emotions’, we use this term to denote those emotions such as regret which ariseduring ‘counterfactual thinking’, that is, when “[. . . ] reality is compared to an imagined view of what might have been” [33,p. 136]. In other terms, counterfactual emotions are based on an agent’s alteration of a factual situation and in the agent’simagination of an alternative situation that could have realized if something different was done [49].The aim of our work is to advance the state of the art on computational modeling of affective phenomena by providinga logic which supports reasoning about this kind of emotions. Our major concern here is to find a fair trade off betweenexpressivity and complexity of the formalism. We want a logic which is sufficiently expressive to capture the fundamentalconstituents of counterfactual emotions and, at the same time, with good mathematical properties in terms of decidabilityand complexity. To this aim, we exploit a well-known logic called STIT [9,30]. STIT logic has been proposed in the domainof formal philosophy in the nineties and, more recently, it has been imported into the field of theoretical computer sciencewhere its formal relationships with other logics for multi-agent systems have been studied (see, e.g., [12]). It is a verysuitable formalism to reason about counterfactual choices of agents and of groups. Unfortunately, the version of STIT withagents and groups proposed by Horty [30] has been recently proved to be undecidable and not finitely axiomatizable [29].In this work we study a decidable and finitely axiomatizable fragment of this logic which is sufficiently expressive for ourpurpose of formalizing counterfactual emotions.The paper is organized as follows. In Section 2 we introduce one of the most influential research approach to emotions:appraisal theory. We provide a general overview of existing models of emotions proposed in this area by devoting spe-cial attention to appraisal models of counterfactual emotions. We discuss how counterfactual emotions such as regret anddisappointment are defined in these models.Section 3 is the first step in developing a representation language for the formalization of counterfactual emotions. Weintroduce a fragment of the version of STIT logic with agents and groups proposed by Horty [30]. We call df STIT our STITfragment. Differently from Horty’s logic, we prove that our fragment is decidable and finitely axiomatizable.In Section 4, we exploit the STIT fragment df STIT in order to formalize counterfactual statements of the form “group J(or agent i) could have prevented χ to be true”. These statements are indeed basic constituents of counterfactual emotionsand will be fundamental for the formalization of counterfactual emotions given in Section 6.In Section 5, we extend the STIT fragment df STIT studied in Section 3 with knowledge operators. This is a necessarystep in order to capture the subjective dimension of the affective phenomena we intend to analyze in our work. We providedecidability results and a complete axiomatization for our epistemic extension of df STIT. We decided to present first theSTIT fragment without knowledge and then the extension with knowledge operators rather than to present a direct versionof a STIT fragment with knowledge operators for several reasons. The first one is because the STIT fragment withoutknowledge studied in Section 3 is interesting in itself since it already allows to express counterfactual statements which arean interesting component of counterfactual emotions. The second one is because the proof of decidability and the proof ofcompleteness of the STIT fragment with knowledge become much simpler after having studied the STIT fragment withoutknowledge.In Section 6, the logical framework of Section 5, is finally applied to the formalization of counterfactual emotions. Weprovide a formalization of four types of counterfactual emotions: regret and its positive counterpart rejoicing, disappointmentand its positive counterpart elation. The formal definitions of these four emotions will be based on the psychological modelsof counterfactual emotions discussed in Section 2. Section 7 presents an application of our logical formalization of counter-factual emotions to a concrete example. Before concluding we discuss in Section 8 some related works in the area of logicalmodeling of emotions and affective agents.Proofs of the main theorems are collected in the annex at the end of the article.2. Emotion theoriesOur general objective in this work is to provide a formal model of emotions which can be used as an abstract speci-fication for the design of artificial agents interacting with humans. To ensure the accuracy of a such a formal model, it isimportant to consider how emotions have been defined in the psychological literature. Indeed, in order to build artificialagents with the capability of recognizing the emotions of a human user, of anticipating the emotional effects of their actionson the human, of affecting the user’s emotions by the performance of actions directed to his emotions (e.g. actions aimedat reducing the human’s stress due to his negative emotions, actions aimed at inducing positive emotions in the human),we must endow such agents with an adequate model of human emotions.There exist several theoretical approaches to emotions in psychology. We here consider one of the most influential calledappraisal theory (see [53] for a broad introduction to the developments in appraisal theory).In Section 2.1, we provide a general introduction to appraisal theory by reviewing some of the most popular modelsproposed in this area. Then, in Sectio",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ],
                    [
                        3546,
                        3597,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 86 (1996) l-41 Artificial Intelligence Variable and value ordering heuristics for the job shop scheduling constraint satisfaction problem * Norman Sadehav*, Mark S. Fox b~l a School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213-3891, USA ’ Department of Industrial Engineering, University of Toronto, 4 Taddle Creek Road, Toronto, Ont., Canada M5S IA4 Received April 1992; revised August 1995 Abstract Practical constraint satisfaction problems (CSPs) such as design of integrated circuits or scheduling generally entail large search spaces with hundreds or even thousands of variables, each with hundreds or thousands of possible values. Often, only a very tiny fraction of all these possible assignments participates in a satisfactory solution. This article discusses techniques that aim at reducing the effective size of the search space to be explored in order to find a satisfactory solution by judiciously selecting the order in which variables are instantiated and the sequence in which possible values are tried for each variable. In the CSP literature, these techniques are commonly referred to as variable and value ordering heuristics. Our investigation is conducted in the job shop scheduling domain. We show that, in contrast with problems studied earlier in the CSP literature, generic variable and value heuristics do not perform well in this domain. This is attributed to the difficulty of these heuristics to properly account for the tightness of constraints and/or the connectiviv of the constraint graphs induced by job shop scheduling CSPs. A new probabilistic framework is introduced that better captures these key aspects of the job shop scheduling search space. Empirical results show that variable and value ordering heuris- tics derived within this probabilistic framework often yield significant improvements in search efficiency and significant reductions in the search time required to obtain a satisfactory solution. The research reported in this article was the first one, along with the work of Keng and Yun ( 1989), to use the CSP problem solving paradigm to solve job shop scheduling problems. The suite of benchmark problems it introduced has been used since then by a number of other *This research was supported, in part, by the Advanced Research Projects Agency under contract #F30602- 88-C-0001 and Digital Equipment Corporation. from McDonnell Aircraft Company and #F30602-91-F-0016, and in part by grants * Corresponding I E-mail: msf@ie.utoronto.ca. author. E-mail: sadeh@cs.cmu.edu. 0004-3702/96/$15.00 SSDI0004-3702(95)00098-4 Copyright @ 1996 Elsevier Science B.V. All rights reserved. \f2 N. Sudeh, M.S. Fh/Artijiicial Intelligence 86 (I 996) l-41 to evaluate alternative for the job shop scheduling CSP The article briefly researchers reviews some of these more recent efforts and shows that our variable and value ordering heuristics remain quite competitive. techniques 1. Introduction (e.g. ( CSPs) (e.g. [ 10,39,52] Practical constraint satisfaction problems such as design problems [ 3 1, 491) or scheduling problems ) generally entail large search spaces with hundreds or even thousands of variables, each with several hundred or thousand possible values. Often, only a very tiny fraction of all these possible assignments in amounts of search before one a satisfactory the such solution that aim at reducing effective in selecting in which possible values are tried which variables to as these techniques In the CSP literature, for each variable. variable and value ordering heuristics. Our investigation in the job shop scheduling domain solution, potentially can be found. This article discusses are commonly is conducted to be explored by judiciously size of the search space requiring prohibitive and the sequence are instantiated [ 2, 12,261. participates techniques the order referred Specifically, we study a class of job shop scheduling problems in which operations [ 11,39,42,44]. time windows factory scheduling problems, We refer to satisfaction problem or job shop CSP. in which some oper- scheduling have to be performed within non-relaxable this class of problems as the job shop constraint Examples of job shop CSPs include ations have to be performed within one or several shifts, spacecraft mission problems, in which time windows are determined by astronomical factory rescheduling have no control, to be rescheduled without disturbing a job shop CSP, the objective a schedule where each operation no resource adapted reduce to relaxable due dates events over which we in which a small set of operations need problems, the schedule of other operations, etc. When solving is to find as quickly as possible a feasible schedule, namely is performed within one of its legal time windows and in this paper have also been is to the sum of tardiness and inventory costs of a set of jobs to be processed subject job shop scheduling problems, where The techniques presented to solve just-in-time is oversubscribed. the objective [ 39,401. The job shop CSP can easily be shown of any procedure enforcing mechanisms worst-case complexity nential. At the time we started consistency to yield ported different CSPs determine such as those found important [ 6,9, 11,13, 17,23,29,37,5 increases this study, CSP techniques to be NP-complete to solve this problem [ 141. Accordingly, is expected that interleave the to be expo- search with ordering heuristics had been re- to a number of 11. One of the objectives of our study was to and variable/value in search efficiency when applied if similar results could be obtained on large-scale tightly connected problems in the job shop scheduling domain. In this article, we first review generic variable and value ordering heuristics that have to perform well on other classes of CSPs. We explain why these heuristics like job shop to perform as well on large-scale for In particular, we show that these heuristics been reported are unlikely scheduling. tightly connected CSPs fail to adequately account \fN. Sadeh, M.S. Fox/Artificial Intelligence 86 (1996) 1-41 3 operations). solving paradigm indicate that attempt to better account a probabilistic are defined framework, within which new variable the tightness of constraints and/or induced by the high connectivity for the interactions of the constraint graphs characteristic of job shop CSPs. 2 The second part of this paper and value ordering introduces heuristics interactions. Empirical results more specialized heuristics [ 201. Our study suggests ability of the probabilistic on the availability reliance of an operation on the availability between variables measures of resource contention between unscheduled that our new heuristics outperform both generic CSP heuristics as well as CSPs for resource- and time-constrained these more powerful heuristics lies in the to provide estimates of the reliance of a variable the in job shop scheduling, and measures of contention framework of one of its remaining recently developed that a key to defining (e.g., of a reservation) values (e.g., in job shop scheduling, for the allocation of incompatible for these values that the CSP problem While our work shows large-scale domains considered does scale up to that benchmark complex problems of this and probably in earlier CSP studies are not representative other classes of complex CSPs. We hope that this research will prompt others in the field to evaluate to revisit earlier studies and look for more challenging their techniques. such as the job shop CSP, it also suggests problems on which is organized in Section 7. Empirical The balance of this paper as follows. Section 2 provides a formal defi- the backtrack search procedure nition of the job shop scheduling CSP Section 3 details in Sec- used in our study. Generic variable and value ordering heuristics are reviewed tions 4 and 5 respectively. Section 6 describes new variable and value ordering heuristics based on a probabilistic model of the search space. The complexity of these heuristics our new heuristics with other is discussed heuristics discussed in this article was the first one, along with that of Keng and Yun [ 201, to use the CSP prob- lem solving paradigm to solve job shop scheduling problems. The suite of benchmark to problems it introduced evaluate alternative re- views some of these more recent efforts and shows that our variable and value ordering heuristics Section 9 provides a summary of the paper and further discusses then been used by a number of other researchers for the job shop scheduling CSl? Section 8 briefly in Section 8. The work reported in this paper are presented remain quite competitive. results comparing techniques has since of this study. the implications Earlier variations of the techniques presented in this paper are discussed in [ 11,38, 39,41-441. 2. The job shop constraint satisfaction problem The job shop CSP requires a set of jobs .I = {jt , . . . , j,,} on a set of physical 0’ = {O{,.. resources RES = {RI, scheduling . . . , R,}. Each job according . , Of,,} to be scheduled to a process routing that specifies a j, consists of a set of operations * Constraint graphs are graphical representations of binary CSPs (i.e. CSPs with binary constraints) each variable Other graphical is represented representations by a node, and binary constraints also exist for non-binary CSPs. are represented by arcs between in which two nodes. \f4 N. Sadeh. M.S. Fkr/Art$ciui lntellrpwce 86 (I 996) I-41 j, j, 0: 0: 0: Fig. I. Examples of tree-like process routings. these operations partial ordering among shop CSPs with tree-like process routings. A tree-like process routing of precedence situation, especially paper to more general forms a tree (see Fig. 1). This job is one whose graph is by far the most common in this in factory scheduling. Extensions of the techniques presented types of process routings will be briefly discussed as well. (e.g. 0; B",
            {
                "entities": [
                    [
                        72,
                        170,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 203–221Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintWikipedia-based WSD for multilingual frame annotationSara Tonelli∗, Claudio Giuliano, Kateryna TymoshenkoFondazione Bruno Kessler, via Sommarive 18, I-38100 Trento, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 11 November 2010Received in revised form 9 May 2012Accepted 16 June 2012Available online 18 June 2012Keywords:Frame annotationMultilingual FrameNetsWord sense disambiguationFrameNet–Wikipedia mapping1. IntroductionMany applications in the context of natural language processing have been proven toachieve a significant performance when exploiting semantic information extracted fromhigh-quality annotated resources. However, the practical use of such resources is oftenbiased by their limited coverage. Furthermore, they are generally available only for Englishand few other languages.We propose a novel methodology that, starting from the mapping between FrameNetlexical units and Wikipedia pages, automatically leverages from Wikipedia new lexical unitsand example sentences. The goal is to build a reference data set for the semi-automaticdevelopment of new FrameNets. In addition, this methodology can be adapted to performframe identification in any language available in Wikipedia.Our approach relies on a state-of-the-art word sense disambiguation system that is firsttrained on English Wikipedia to assign a page to the lexical units in a frame. Then, thismapping is further exploited to perform frame identification in English or in any otherlanguage available in Wikipedia. Our approach shows a high potentialin multilingualsettings, because it can be applied to languages for which other lexical resources suchas WordNet or thesauri are not available.© 2012 Elsevier B.V. All rights reserved.The FrameNet database [1,2] is an English lexical resource based on the description of some prototypical situations, theframes, and the frame-evoking words or expressions associated to them, the lexical units. Every frame corresponds to ascenario involving a set of participants, the frame elements, that are typically the semantic arguments shared by all lexicalunits in a frame. Given the rich semantic information provided by frames, there have been several attempts to exploit thisknowledge to improve diverse natural language processing (NLP) tasks, from question answering [3] to relation extraction[4], and entailment rules generation [5]. The integration of this semantic paradigm in existing NLP tools, however, has beenhindered by difficulties in creating systems for frame semantic parsing. Some attempts have been made, using FrameNetdata for training [6–8]. Since large amounts of data with high-quality annotation are currently available only in English [1]and German [9], however, the applicability of supervised approaches has been limited to these two languages. Alternativeapproaches based on systems that are not trained directly of FrameNet have been only partially explored by investigatingthe integration between FrameNet and WordNet [10–12] and the use of distributional approaches [13,14].In this article, Wikipedia is used as an extensive, multilingual repository of frame information in order to achieve twomain goals: first, to devise a novel approach to multilingual frame identification, a subtask of frame semantic parsing, withouttraining a system directly on FrameNet. Then, to retrieve a large amount of frame example sentences in different languages.* Corresponding author. Tel.: +39 0461 314 542; fax: +39 0461 314 591.E-mail addresses: satonelli@fbk.eu (S. Tonelli), giuliano@fbk.eu (C. Giuliano), tymoshenko@fbk.eu (K. Tymoshenko).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.002\f204S. Tonelli et al. / Artificial Intelligence 194 (2013) 203–221We rely on Wikipedia because of several reasons. First of all, it is the largest existing repository of encyclopedicknowledge, freely available in 282 languages. It combines free-form natural language content with structural informa-tion, represented by intra- and inter-language links. Furthermore, it generally shows high editorial quality, especially theWikipedia versions of widely used languages.In order to exploit Wikipedia to perform frame annotation, a strategy to link this resource to FrameNet has been pro-posed. However, we are aware that inter-operability between FrameNet and Wikipedia may be hindered by the differentstructure, granularity and extension of the two resources. Therefore, three main research questions are addressed in thisarticle: (i) Is it possible to link FrameNet and Wikipedia and to exploit the outcome of this mapping for frame identifica-tion? (ii) Which strategy can be chosen to devise a frame identification system that is not directly trained on FrameNetexamples? And how does it compare with state-of-the-art systems? (iii) Can the same strategy be employed to support thedevelopment of non-English FrameNets? To which extent?The first question has been partially addressed in the preliminary work by Tonelli and Giuliano [15], in which the idea touse Wikipedia as a multilingual repository of frame information was first presented. The second problem, instead, has notbeen tackled before. We address it by comparing our approach with a state-of-the-art frame semantic parser for English.As for multilingual frame annotation, the acquisition of frame example sentences from Italian Wikipedia was introducedby [15], although it was only marginally evaluated. On the contrary, a methodology to use the same frame identifica-tion approach for different languages is presented for the first time in this article, and is evaluated by comparing it withWordNet-based strategies [11].This article is structured as follows. We introduce FrameNet and Wikipedia in Section 2. We present past research workrelated to our approach in Section 3. A general description of our methodology is provided in Section 4. The Wikipedia-based disambiguation system is described and compared with the state of the art in Section 5. The methodology for mappingframe–lexical unit pairs with Wikipedia pages is described and evaluated in Section 6, in which the first of our researchquestions is addressed (see items above). Then, in Section 7 a new frame identification approach is described and applied toEnglish lexical units. A thorough evaluation and a comparison with the state-of-the-art SEMAFOR system [8] are reported,addressing our second research topic. Section 8 is devoted to our third research question and details a two-fold strategyfor the creation of multilingual FrameNets: first, example sentences and lexical units in a new language are extracted fromWikipedia, and then the word sense disambiguation (WSD) system is used for multilingual frame identification. Finally, wedraw some conclusions and discuss future work in Section 9.2. FrameNet and Wikipedia: description and terminologyFrameNet [1,2] is a lexical resource for English, based on frame semantics [16], that is being created in the context of theBerkeley FrameNet project.1 Its aim is to collect the range of semantic and syntactic combinatorial possibilities of each wordin each of its senses through the annotation of example sentences. The conceptual model is based on three main elements:• Semantic frames: Cognitive schemata or scenarios necessary to understand the meaning of words. They describe situa-tions, objects and events and the participants involved in them.• Lexical units (LUs): Words, multiwords, idiomatic expressions evoking a frame.• Frame elements (FEs): Semantic roles involved in the situation or event expressed by a frame. They apply to all LUs inthe same frame.FrameNet 1.3, released in 2006, is comprised of more than 10,195 lexical units, 6000 of which are fully annotated, andnearly 800 semantic frames with hierarchical relations. An essential element of the FrameNet database is the corpus-basedevidence, i.e., every lexical has to be instantiated by at least one example sentence. In FrameNet 1.3, more than 135,000sentences have been manually annotated with frame information.As an example, we report in Table 1 the FrameNet entry for the Wearing frame.In the first row, the frame definition in natural language is reported, while the second includes the list of the coreframe elements. The third row contains part of the LU list including all frame-evoking predicates, while in the fourth a fewexample sentences are reported. All LUs are printed in bold, while the phrases bearing a FE label are reported betweensquare brackets, followed by the role label.In the remainder of this article, we call frame semantic annotation the annotation of sentences with both frame and FE(or role) information, as performed by frame-semantic parsers (e.g. [6] and [8]). The sub-task of assigning a frame label toa lexical unit in a sentence is called frame identification. This concerns both lexical units that are listed in FrameNet, theso-called seen LUs, and those that are not present in the resource, the unseen LUs. When frame identification is applied tounseen LUs, and leads to the acquisition of new LUs, it is also known as LU induction [13].The second resource we take into account in this work is Wikipedia, the largest online repository of encyclopedic knowl-edge. At the moment of writing, there are 20 million articles in 282 languages (over 3.82 million in English alone) written1 http://framenet.icsi.berkeley.edu/index.php.\fS. Tonelli et al. / Artificial Intelligence 194 (2013) 203–221205Table 1Wearing frame.Frame: WearingDef.FEsLUsEx.The words in this frame refer to what clothing a wearer (or a specific body_part of the wearer) has on.body_partclothingwearerThe body part of the wearer which is covered by the clothing.This FE identifies the clothing that the wearer wears.The person whose clothing is under discussion.attired.",
            {
                "entities": [
                    [
                        145,
                        198,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 78 ( 1995) 289-326 Artificial Intelligence Recognition of object classes from range data I.D. Reid*, J.M. Brady Department of Engineering Science, lJniversi@ of Oxford, Oxford OXI 3PJ, UK Received September 1993; revised October 1994 Abstract We develop techniques for recognizing instances of 3D object classes (which may consist of multiple and/or repeated sub-parts with internal degrees of freedom, linked by parameterized transformations), from sets of 3D feature observations. Recognition of a class instance is structured as a search of an interpretation tree in which geometric constraints on pairs of sensed features not only prune the tree, but are used to determine upper and lower bounds on the model parameter values of the instance. A real-valued constraint propagation network unifies the representations of the model parameters, model constraints and feature constraints, and provides a simple and effective mechanism for accessing and updating parameter values. Recognition of objects with multiple internal degrees of freedom, including non-uniform scaling and stretching, articulations, and sub-part repetitions, is demonstrated and analysed for two differ- ent types of real range data: 3D edge fragments from a stereo vision system, and position/surface normal data derived from planar patches extracted from a range image. Keywords: Object recognition; Parametric objects; Range data; Stereo 1. Introduction Consider a robot performing a task in an unknown or partially known environment. If it is to react to that environment in other than a haphazard “trial-and-error” fashion, the robot must learn about its surroundings using sensed data. Perhaps the simplest requirement is to avoid obstacles; for this task the robot need know nothing more about obstacles than roughly their positions and extents. A considerably more complicated task involves finding and manipulating a specific object in the environment. In this case the robot must not only locate an object, but also recognize it. Recognition demands the use of both sensed data and prior knowledge about the object in order to detect its * Telephone: +44-1865 273168. Fax: +44-1865 273908. E-mail: ian@uk.ac.ox.robots. 0004-3702/95/$09.50 SSDIOOO4-3702(95)00062-3 @ 1995 Elsevier Science B.V. All rights reserved \f290 I.D. Reid, J.M. Rrud.v/Artijbal Intelligence 7X (1995) 289-326 Fig. I Two typical pallets. The one the left is considerably pallet has five slats and three struts. larger and has six slats and four struts. The smaller presence, and to determine model-based vision paradigm addresses just this problem. its pose (position and orientation) relative to the sensor. The Model-based vision embraces a class of techniques which achieve object recognition by encoding objects’ observable “best interpretation” lates the problem as one of finding or edges), determining tween a transformation sensor(s). Such a formulation involves The paradigm those of representation, uncertainty. these features and object high-level prior knowledge about objects properties, of a scene, given and comparing the sensed data. A common in models which describe the the models with sensed data to find a formu- in sensory data (such as surfaces be- to certain matching constraints) approach low-level features correspondences (subject represented features tits into a class known as constraint some of the major research problems search strategies, interpretation in a model, and then computing to the reference frame of the satisfaction problems. intelligence; of sensory data, and handling in artificial from a model-centred reference frame fixed objects systems built to date-whether range data-have The vast majority of recognition views of objects, or three-dimensional they use single to (e.g. [ 8, 15,22,24] ) or objects with only a few intensity operate with geometrically internal degrees of freedom applied involve cannot be defined a priori. A good example of such, and which has motivated research we report, is the use of a mobile vehicle Fig. 1 depicts two such items, clearly showing [ 14, 19,401. While such systems have been successfully tasks, many other applications for which a fixed geometry the to locate and acquire industrial pallets. to the same they belong that although to a number of useful the need to recognize members of object classes robotic and automation been designed \fI.D. Reid, J.M. Brady/Art$icial Intelligence 78 (1995) 289-326 291 they vary considerably object class, they have. Such object classes are common, particularly Most of the systems mentioned necessitate a separate model. are unsuitable in size, shape, and in the number of slats and struts in man-made environments. since each variation within a class would To address system for recognizing this deficiency we develop a 3D recognition poly- hedral objects which may have multiple and repeated sub-parts which may move relative free parameters. Our system to one another, each of which may have multiple either 3D line segment data (from, takes as input a set of primitive (for for example, example, a laser range triangulation the pose of an instance of a model class, at the same time placing upper and lower bounds on the parameter values noise and occlusion. Furthermore, of the instance, between different an additional instances of the same class. a stereo vision system) or surface patch data from a range the presence of significant allows level of competence features-currently to distinguish system)-and the system determines internal despite finder The system is based on three techniques, well established in their own right in the literature: tree search l interpretation l binary geometric constraints l a continuous-valued [ 171; [20] ; constraint propagation network [ 141. The use of the first two items ticularly (or assignments) with those already viewpoint-invariant and bounds on these measurements in [ 20 1. Interpretations-branches features of observed in the interpretation. measurements in recognition systems has been well documented, par- grown by adding matches to model features which are pairwise consistent of the tree-are Pairwise consistency (such as angles and distances) precomputed from a model. is defined using a set of on pairs of features, Our system is designed to use either surface patch data normal or straight 3D edge fragments. For either a pair of surface patches or a pair consisting of one angle and in in our system are given invariants, The sets of invariants used there exist four independent (position/surface points) of edge fragments, three distance measurements. Appendix A. through the combination [ 61, who, in the ACRONYM constraints. So-called SUP/INF is a powerful way of representing The novelty of our system comes for object recognition. A set of inequality of the first two items and solving sets of networks were developed by Fisher and Orr above with the third item, which inequality [ 14 3 based on the work of Brooks of 3D models from 2D images, was the first to introduce satisfaction the viewing parameters was solved symbolically to give the pose and internal parameters of an instance of a parametric object class. Fisher and Orr’s development was to show how much of the work involved can be performed off-line constraint propagation network. by compiling They used the resulting networks internal in performance over the transformations purely symbolic system for recognition the idea of symbolic constraint constraints on the model and on in such symbolic manipulation into a real-valued such as articulations, approach of ACRONYM. to solve for object pose and some (limited) gaining an improvement the symbolic constraints For linear constraints, the SUP/INF method is guaranteed However the major weakness of both the Brooks and the Fisher/Orr to give a correct solution. is that approaches \f292 I.D. Reid, J.M. Brady/Artijicial Intelligence 78 (1995) 289-326 H W Fig. 2. A model class of equal volume boxes: (a) a parametecization and constraints; (b) model surfaces. on object pose result constraints poor (sometimes useless) bounds on the pose transformation work Orr et al. have argued uncertainty than in order to obtain more realistic pose computations for a probabilistic in complex nonlinear rather inequalities which often lead to in later of Indeed representation parameters. interval [ 301. In our method, the pose computation are separated. and internal parameter estimation is used to store internal model parameter values (upper and lower and define relations between parameters, which are updated and propagated as The constraint network bounds) an interpretation grows. This parameter as we show in later sections. However using a two-stage which rotation the benefits of the SUP/INF [ 111 followed by a best-fit is performed is ideally suited to the application, representation the network is not used for pose computation, least-squares method by first finding a best-fit [ 151. This trade-off makes full use of from its major drawback. translation network without suffering Prior to give the reader an intuitive in order the general principles by example. Consider by to detailed description, feel for the system’s operation, we illustrate the class its three of equal volume boxes depicted free parameters, H, W and D, the height, width and depth of the box. Here, the angles the surfaces are constant values, independent of the model parameters. However, between the distance d of a point on the top surface from the plane defined by the for example, (invariant fi for surfaces, surf-dist-1, is constrained by front surface 0 6 d < 0, where D is the depth of the box, initially unknown. in Fig. 2. This class in Appendix A) is characterized We draw two major insights from this, which form the basis for the remainder of this work. These are: is a symbolic bound. Algorithms less efficiently exist for solving sets of than numeric ones; we exploit one such symbolic l d E [0, DJ equations, method",
            {
                "entities": [
                    [
                        67,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 92 (1997) l-23 Artificial Intelligence Defeasible inheritance on cyclic networks * Gian Aldo Antonelli * Department of Philosophy, Stanford University, Stanford, CA 94305-2155, USA Received June 1993; revised December 1996 Abstract In this paper, we are going to present a new notion of “extension” for defeasible inheritance networks that allows us to deal with cyclic nets. Horty has shown that cyclic nets need not have extensions in the sense of Touretzky. This paper presents a generalization of that notion of extension that can be applied to cyclic nets. The present proposal is inspired by a somewhat unexpected analogy between cyclic nets and “semantically closed” languages, i.e., languages containing their own truth predicate. Accordingly, this approach to defeasible inheritance networks with cycles shows similarities to the solution of semantic paradoxes put forth by Kripke. @ 1997 Elsevier Science B.V. Keywords: Cyclic networks; Defeasible inheritance; Theories of truth 1. Background and motivation Defeasible inheritance networks were originally ematical understanding taxonomic This paper information with exceptions is concerned with direct theories of inheritance of the way developed store, to gain a sound math- access, and manipulate inheritance systems (a survey can be found in terms of the net itself. Alternatively, in Thomason [ 211). that define a notion of con- an indirect networks by embedding al- semantics. For instance, an indirect approach was them in a language networks, by Hayes [6] (via an embedding inheritance networks by Etherington the direct approach logic). However, networks for inheritance sequence theory assigns meaning to inheritance ready quipped with a well-understood pursued, into first-order and Reiter [4] first introduced by Touretzky in the case of strict inheritance logic), and in the case of defeasible into default (using an embedding [23] has now become standard. * Originally submitted as a Research Note. * E-mail: aldo@csli.stanford.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved PII SOOO4-3702(96)00053-7 \f2 G.A. Antonelli/Artijicial Intelligence 92 (1997) 1-23 Grey 0 0 Royal o African 0 Clyde Fig. 1. The standard example of pre-emption. An inheritance network can be identified with a collection of signed links (positive or items the network in the net. Nodes are labelled by lexical is to be interpreted defeasibly, a link 1z1 + n2 represents is a sequence of links from r at most the last one of which over a set of nodes. Links are of the form nt -+ n2 or IZI f, 122 respectively, negative) referring where nt and n2 are nodes convenience we will identify nodes with their labels. to categories of individuals-for When the fact that objects of category nt tend to be of category n2, whereas a link of the form nt f, nz the fact that objects of category nt tend YKX to be of category n2. A path over represents a net r to be negative. So both nt + n2 + n3 and nt --+ n2 f, n3 are paths, while nl ft n2 + ng is not. A path is positive or negative according as its last link is positive or negative. found rely on the three notions speaking, a path is constructible of constructibility, links from r. A path conjlicts another relative path containing if the first has the same endpoints but opposite sign as the second. So n1 -+ n + rz2 is conflicted by nl + n’ ft n2, and conversely. But is that of pre-emption. Pre- perhaps emption gives us a way to resolve conflicts between paths, based on the intuition that should override more generic more specific to a net I’ if it can be obtained by chaining conflict, and pre-emption. Roughly Theories of defeasible at least two links, idea in defeasible in the literature information is allowed inheritance inheritance the most important and Boutilier Touretzky and is used [ 21; and ofS-path pre-emption of Sandewall [ 81, and Stein [ 18,191. The latter has come to be prominent in this paper. Consider for instance information. on-path pre-emption of Touretzky [23] and in the literature, the standard example of pre-emption [ 151, Horty, Thomason There are two ways to define pre-emption: \fG.A. Antonelli/Artijicial Intelligence 92 (1997) l-23 Twee ty Penguin Bird Flies 0-------f0~0~0 Fig. 2. Another example of pre-emption. I is an African in Fig. 1 (the example elephant and Royal elephants over a net represented us that Clyde both African elephants grey. Here the usual notion of off-path pre-emption is grey, since concerning topological properties of the network of on-path pre-emption elephants. The notion of pre-emption information is due to Sandewall). The network tells and also that it is a Royal elephant. Of course, are elephants, but Royal elephants are not that Clyde the conclusion precludes concerning Royal elephants is more specific than information itself. It should be noted, however, captures this formally, using only that the notion is grey. As another example, consider does not block the conclusion that Clyde the network of Fig. 2. On this net, both on-path and give the same results. Indeed, although we are told that Tweety is are birds, and birds fly, the conclusion we naturally draw is that to as to about whether birds fly, and thus that Tweety flies is pre-empted by information are a kind of birds, than information information off-path pre-emption a penguin, penguins Tweety does not fly. The conclusion the effect that penguins don’t fly. Since penguins whether penguins overrides Once the notions of constructibility, fly is more specific it. We conclude that Tweety does not fly. the latter might be preferable on conceptual the definition set of paths to define extensions: [ 8,17]), have been Intuitively, conflict, and especially pre-emption of the extensions of a net r. that are supported by the net. There are (see credulous grounds to define, and [ 71 [23] ) and skeptical and computational simpler to Horty’s excellent survey is somewhat the former (see in this paper. The reader is referred two kinds of extensions. An extension if it is a maximal conflict-free set of paths over r for a net r is credulous, in which no path two ways defined, we can proceed with an extension is a conflict-free essentially [ 81) . Although (as argued, among others, therefore is adopted for details on these roughly is pre-empted. Extensions speaking, in need not be unique. However, then extensions of their sign) r contains no cycles, a path u over r, define links (irrespective this notion of degree makes sense only acyclic nets it is possible in which paths are considered treatment of inheritance Things are different on acyclic nets). it is well known that if the underlying net always exist. This can be seen as follows. Given the degree of u to be the length of the longest sequence of the same endpoints as u. It is clear that in the case of exist by means of an iterative process (see [7] for a unified in ascending order of their degrees if r contains no cycles. Then, to show that extensions from r having in the case of networks with cycles. Such nets arise naturally many situations, (see Fig. 3 for an example). for instance whenever there are two mutually overlapping In such nets, the presence of cycles is a cause in categories for the \f4 G.A. Antonelli/Artijcial Intelligence 92 (1997) 1-23 Weal thy Fig. 3. A network with cycles. o-o a - b 0-o C d Fig. 4. A network with no credulous extension. in the literature.) Then, as long as the net is acyclic, global character of the notion of specificity. For the purposes of the present discussion, let us say that a node nt is more specific than a node n2 (relative there is a (positive) can be found specific extended. however, nl might be more specific to a net r’ extending nl). path from nt to n2 but not vice versa. (Other notions of specificity if a node nt is more is is a local property of nodes. Once cycles are allowed, to a certain net r, but not relative path back from n2 to introduce a (positive) is a global property of cyclic nets. is preserved no matter how the network In this sense, specificity In this sense, specificity than node n2, then to a given network), than n2 relative this character r’ might (because if r This appears in the standard to be connected with the fact that cyclic networks need not have ex- sense of [ 71, as it was discovered by Horty. Consider the net tensions this net cannot have any of Fig. 4. According for the net. Then, clearly, suppose extensions: either the path a -+ b -+ c is in @ or it isn’t. If it is, then @ must contain also the path to inheritance, that @ is an extension to the usual approaches for contradiction \fG.A. Anlmelli/Artijicial Intelligence 92 (1997) 1-23 5 links, to block the there is nothing than b (because if @ is an extension. of CT) ; but then u + b --+ c would be pre-empted (since nodes d, e, and b have no incoming negative construction a node e, that is more specific telling us that e’s are not c’s. This is impossible is not in @ then u can’t be in Cp either, SO that a -+ b -+ c would not be pre-empted in @ and so CD cannot be an extension (because constructible affairs seems segments. This it would fail to contain a path that is but neither conflicted nor pre-empted for this state of to be that the path a + b ----) c -+ d + e 4 b pre-empts one of its initial in @, since @J contains link If a + b + c the path u is in CD), and a direct is a peculiar phenomenon, which bears a resemblance paradox. This paradox, as is well known, arises when considering A: “A is not true”. It is then Philosophers one semantics can be expressed), instance) a fixpoint construction. its own truth predicate provided we give up bivulence; provided, and logicians have developed is relevant here. Kripke setting. The desired semantics for a language containing to the so-called Liar the following sentence that A is true. to the paradox, but to provide a (and therefore A that is, that we switch (for is then achieved by means of a number of sol",
            {
                "entities": [
                    [
                        72,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1180–1193Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRelational preference rules for control ✩Ronen I. BrafmanDepartment of Computer Science, Ben-Gurion University, PO Box 653, Beer-Sheva 84105, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 28 February 2009Received in revised form 4 July 2010Accepted 4 July 2010Available online 1 December 2010Keywords:Preference modelsPreference rulesRelational modelsRule-based systemsCommand and control automationValue functions are defined over a fixed set of outcomes. In work on preference handlingin AI, these outcomes are usually a set of assignments over a fixed set of state variables.If the set of variables changes, a new value function must be elicited. Given that inmost applications the state variables are properties (attributes) of objects in the world,this implies that the introduction of new objects requires re-elicitation of preferences.However, often, the user has in mind preferential information that is much more generic,and which is relevant to a given type of domain regardless of the precise number ofobjects of each kind and their properties. Such information requires the introduction ofrelational models. Following in the footsteps of work on probabilistic relational models(PRMs), we suggest in this work a rule-based, relational language of preferences. Thislanguage extends regular rule-based languages and leads to a much more flexible approachfor specifying control rules for autonomous systems. It also extends standard generalized-additive value functions to handle a dynamic universe of objects. Given any specific set ofobjects this specification induces a generalized-additive value function over assignments tothe controllable attributes associated with these objects. We then describe a prototype of adecision support system for command and control centers we developed to illustrate andstudy the use of these rules.© 2010 Elsevier B.V. All rights reserved.1. IntroductionMuch of the work in AI on preference handling has focused on tools for modeling preferences of lay users, often inapplications related to electronic commerce, such as support for online selection of goods [29,12,10,4], tools for prefer-ence elicitation in combinatorial auctions [33], recommender systems [12], etc. Some work also targets the more classicaldecision-analysis setting which is usually mediated by an expert decision analyst, supporting the elicitation process of thedetailed classical structures used there, namely utility functions (e.g., [11,17]). However, much less work considers the useof preferences as a key tool in the design of complex systems.The idea of using preferences to design autonomous systems is quite intuitive. Autonomous systems make many decisionsduring their run-time, and ideally, their choices should be the ones maximally preferred among available choices at thecurrent context. A preference-based design explicitly models the designer’s preferences for different choices in differentcontexts, and uses a generic mechanism for selecting a preferred feasible choice at run-time.A preference-based design can provide a uniform declarative and modular approach for the design and specificationof certain autonomous systems. It is naturally amenable to customization, both before and during deployment, either byproviding additional information about the context, or allowing for additional user-specific preferences. Compared withelectronic commerce-based applications which deal with users who usually spend little time with the system and require✩A preliminary version of this paper appears in the Proceedings of the International Conference on Knowledge Representation and Reasoning, 2008 [9].E-mail address: brafman@cs.bgu.ac.il.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.010\fR.I. Brafman / Artificial Intelligence 175 (2011) 1180–11931181an interface that is immediately intuitive, the design context allows for more sophisticated and rich methods. A systemdesigner is likely to be willing to spend more than a few minutes on her system, and she can be expected to spend timelearning how to effectively specify her preference. On the other hand, the designer’s willingness to adopt a new tool islikely to depend greatly on the convenience and intuitive appeal of this tool, and on the amount of learning required touse it effectively without expert assistance. This puts the system design context somewhere between the end-user contextand the decision analysis context, and motivates the need for formalisms that address this setting. These formalisms mustprovide sufficient expressiveness while remaining intuitive.Decision-theoretic agent design is not a new paradigm. It pervades the classic text of [32], and recent work in roboticsshows that it can be very successful [24]. A full-fledged decision-theoretic approach requires maintaining a probabilisticstate estimate and a utility function. The main drawback of using classical, propositional probability distributions and utilityfunctions is that they limit the agent’s knowledge to a fixed set of propositions or objects. Thus, more generic knowledgeabout certain classes of objects, or relationships, cannot be captured. This limits the applicability of these systems to asingle fixed, static domain. On the probabilistic side, relational and object-oriented probabilistic models provide tools thatallow designers to describe generic probabilistic models that can then be used in diverse contexts in which the number andproperties of concrete object instances may be quite different. On the preference side, we are not there yet, although theneed to model preferences may be more pressing, as they are harder to learn from data because of their subjective nature.This need for preference representation tools that support the system design and control context and provide the abilityto express relational preferences in an intuitive manner that system designers can easily grasp, motivates this paper. Its maincontribution is the introduction of a simple relational preference formalism whose semantics generalizes that of generalizedadditive value functions. In addition, it explains how optimal choices can be computed given such a specification usingstandard techniques, such as variable elimination, but also, how this problem can be reduced to the problem of computingthe most probable explanation given a probabilistic relational model (PRM), leveraging existing algorithms for these models.Finally, we describe a concrete application domain, which is of independent interest, which serves to motivate this type offormalism and illustrate its possible application.Relational Preference Rules (RPRs) specify preferences for systems that act in dynamic environments where both the setof objects and their state change constantly. They combine ideas from rule-based systems and earlier preference formalismsleading to a simple rule-based syntax with weights attached to different choices. The basic idea is very simple: for everyvalue of a controllable attribute, specify what conditions affect its desirability, and how happy we would be to see this valuein this context. The syntax is simple:(cid:2)(Condition on attributes other than v) → v :(cid:4)(cid:3)list of (weight,value of v) pairsReaders familiar with formalisms such CP-nets [6] and especially UCP-nets [5] will see the clear resemblance to theconditional preference/utility tables used there, with one main difference: the conditions expressed in those formalisms arepropositional, whereas here we have conditions over relations. Indeed, given any concrete set of objects, these rules inducea concrete value function, which is induced by all possible groundings of these rules. Like rule-based systems, preferencerules-based systems can be used in process and decision control applications in which rule-based systems are currentlyused. They retain the natural form of rule-based systems, but are much more flexible because their conclusions are notbased on rigid deduction, but rather on optimization.Preference rules bare certain resemblance to soft constraint logic programs (SCLP) [2], though their semantics is different.They are also closely related to generalized-additive value functions [16,1], as each ground rule is a factor in the inducedvalue function. They can also be viewed as specifying a linear value function where the basis functions correspond to therules. Similar rules have been suggested as a formalism to specify the behavior of a multi-agent system. And of course,these rules were motivated by PRMs, of which Markov Logic is the most similar, semantically [31]. We will discuss theserelations in more depth in Section 4.The rest of this paper is structured as follows: In Section 2 we describe and discuss the syntax and semantics of pref-erence rules. Section 3 discusses the complexity of inference and how these rules can be transformed into Markov Logictheories. In Section 4 we discuss related work. In Section 5 we describe a system prototype we built using the methodol-ogy described in this paper. This system shows how preference rules can be used to select which information to displayto decision makers in a real-time command and control center. We conclude with a discussion of future challenges inSection 6.2. Preference rulesWe introduce the syntax and semantics of preference rules, and follow up with a discussion of some of our choices.2.1. The languageWe adopt an object-oriented world model. Objects are instances of certain object classes. A set of attributes is associatedwith every instance of every class. The value of these attributes may be a simple type, such as integers, reals, strings, or anobject class. Object-valued attributes capture binary relations between objects, and, in principle, any n-ary relation can be\f1182R.I. Brafman / Artificial Intelligence ",
            {
                "entities": [
                    [
                        138,
                        177,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1011–1038www.elsevier.com/locate/artintBounded model checking for knowledge and real timeAlessio Lomuscio a,1, Wojciech Penczek b,c,2, Bo˙zena Wo´zna d,∗,3a Department of Computing, Imperial College London, 180 Queen’s Gate, London SW7 2BZ, United Kingdomb Institute of Computer Science, PAS, Ordona 21, 01-237 Warsaw, Polandc Institute of Informatics, Podlasie Academy, Sienkiewicza 51, Siedlce, Polandd Institute of Mathematics and Computer Science, Jan Dlugosz University, Armii Krajowej 13/15, 42-200 Cz¸estochowa, PolandReceived 23 August 2006; received in revised form 2 April 2007; accepted 11 May 2007Available online 24 May 2007AbstractWe present TECTLK, a logic to specify knowledge and real time in multi-agent systems. We show that the TECTLK modelchecking problem is decidable, and we present an algorithm for bounded model checking based on a discretisation method. Weexemplify the use of the technique by means of the “Railroad Crossing System”, a popular example in the multi-agent systemsliterature.© 2007 Elsevier B.V. All rights reserved.Keywords: Temporal epistemic logics; Model checking; Interpreted systems; Real time systems1. IntroductionReasoning about knowledge [9] has always been a core concern in artificial intelligence. This is hardly surprisinggiven that knowledge is a key concept to model intelligent, rational activities, human or artificial. A plethora offormalisms have been proposed and refined over the years, many of them based on formal logic. One of the mostwidely studied is based on variants of modal logics and is commonly referred to as temporal epistemic logic [9].Rather than providing a computational engine for artificial agents’ reasoning, epistemic logic, at least in this line, isseen as a specification language for modelling and reasoning about systems, much in common with formal methodsin computer science. Formal properties of the logics such as completeness, decidability and complexity have beenexplored [10,12,13,20].Specification languages are most useful when they can be verified automatically. In this effort both theorem provingand model checking techniques as well as tools for epistemic logic have been developed. In the model checkingapproach the question of whether or not a system of agents S satisfies a property P is tackled by trying to establish* Corresponding author.E-mail addresses: A.Lomuscio@imperial.ac.uk (A. Lomuscio), penczek@ipipan.waw.pl (W. Penczek), b.wozna@ajd.czest.pl (B. Wo´zna).1 The author acknowledges partial support from the EPSRC (grant GR/S49353).2 The author acknowledges partial support from the Royal Society (grant ESEP 2004/R3-EU).3 The research presented here was conducted while B. Wo´zna was supported by EPSRC (grant GR/S49353). The author also acknowledgespartial support from the Ministry of Science and Information Society Technologies under grant number 3 T11C 011 28.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.005\f1012A. Lomuscio et al. / Artificial Intelligence 171 (2007) 1011–1038whether or not MS |= φP , where MS is a suitable model for S and φP is an appropriate logical formula representingP ; we refer to [8] for more details.In particular, for what concerns temporal epistemic logic, model checking techniques based on BDD [26,29],bounded model checking [23], unbounded model checking [16] have been developed and their implementation eitherpublicly released [11,26] or made available via a web-interface [22].While, one could now argue that verification via model checking of temporal epistemic logic has now become ofage, in many respects the area is still lacking support for many essential functionalities. One of these is real-time.While the formalisms above deal with discrete sequence of events, it is often of both theoretical and practical interestto refer to a temporal model that assumes a dense sequence of events and uses operators able to represent densetemporal intervals. The aim of this work is to make a first step in this direction. In particular, recent contributionshave focused on extending model checking techniques and tools [14,23,25,26,28,32], to adapt them to the needs ofmulti-agent systems (MAS) formalisms [6,9,14,15].Specifically, we make two contributions: first we present a logic, that we call TECTLK, to reason about realtime and knowledge in MAS; second, we present a bounded model checking technique for verifying automaticallyproperties of multi-agent systems expressed in this logic.The rest of the paper is organised as follows. The next section defines Real Time Interpreted Systems, the semanticson which we work with throughout the paper. In Section 3 the logic TECTLK is introduced. Section 4 deals withthe discretisation process necessary for the bounded model checking algorithm, discussed in Section 5. Section 6shows how this method can be applied to the “railroad crossing system”, a typical multi-agent system example of timedependent systems. We conclude in Section 7 by discussing some related work.2. Real Time Interpreted SystemsIn this section we briefly recall the concept of timed automata, which were introduced in [2], and define Real TimeInterpreted Systems.2.1. Timed automataLet R = [0, ∞) be a set of non-negative real numbers, R+ = (0, ∞) a set of positive real numbers, N = {0, 1, . . .}a set of natural numbers, X a finite set of real variables, called clocks, x ∈ X , c ∈ N, and ∼ ∈ {(cid:2), <, =, >, (cid:3)}. Theclock constraints over X are defined by the following grammar:cc := true | x ∼ c | cc ∧ cc.The set of all the clock constraints over X is denoted by C(X ). Note that inequalities involving differences of clocksare not in C(X ).A clock valuation on X is a tuple v ∈ R|X |. The value of the clock x in v is denoted by v(x). For a valuation v andδ ∈ R, v + δ denotes the valuation v(cid:7) such that for all x ∈ X , v(cid:7)(x) = v(x) + δ. For a subset of clocks X ⊆ X , v[X := 0]denotes the valuation v(cid:7) such that v(cid:7)(x) = 0 for all x ∈ X, and v(cid:7)(x) = v(x) for all x ∈ X \\ X. The satisfaction relation|= for a clock constraint cc ∈ C(X ) and v ∈ R|X | is defined inductively as follows:v |= true,v |= (x ∼ c) iff v(x) ∼ c,(cid:7)v |= (cc ∧ cc(cid:7)) iff v |= cc iff v |= cc.For a clock constraint cc ∈ C(X ), by (cid:2)cc(cid:3) we denote the set of all the clock valuations satisfying cc, i.e., (cid:2)cc(cid:3) ={v ∈ R|X | | v |= cc}.Definition 1 (Timed automaton). A timed automaton is a tuple T A = (Z, L, l0, E, X , I), where Z is a finite set ofactions, L is a finite set of locations, l0 ∈ L is an initial location, X is a finite set of clocks, E ⊆ L×Z×C(X )×2X ×Lis a transition relation, and I : L → C(X ) is a location invariant function, assigning to each location l ∈ L a clockconstraint defining the conditions under which T A may stay in l.Each element e of E is denoted by l a,cc,X−−−−→ l(cid:7), where l is the source location, l(cid:7) is the target location, a is an action,cc is the enabling condition for e, and X ⊆ X is the set of clocks reset when performing e.\fA. Lomuscio et al. / Artificial Intelligence 171 (2007) 1011–10381013Fig. 1. A timed automaton.The clocks of a timed automaton are used to express its timing conditions. We differentiate between enablingconditions and invariant conditions. An enabling condition is a temporal constraint which must be satisfied for thetransition to occur. An invariant condition I(l) specifies the temporal constraint that must be satisfied for the automatonto remain in l.in,x(cid:2)300,∅−−−−−−−→ t2, t2out,true,∅−−−−−→ t3, and t3Example 1. Fig. 1 shows a timed automaton consisting of four locations: t0, t1, t2, and t3, where t0 is the initial loca-approach,true,{x}−−−−−−−−−−→ t1,tion, one clock x, the set of actions Z = {approach, in, out, exit}, and the following transitions: t0exit,x(cid:3)500,∅−−−−−−−−→ t0. The invariant of the location t0 is true, whereas all the otherst1locations are labelled with the invariant x (cid:2) 500. Intuitively, the example models a system starting from t0 and movingto t1 by the action “approach” thereby causing the clock to be reset. The automaton must then execute the action “in”between the clock values of 300 and 500, thereby reaching location t2. From t2 the action “out” must be performedbefore the clock reaches the value of 500 resulting in t3. From t3 the action “exit” must be performed before the clockreaches the value of 500 resulting in t0. Note that the enabling condition in t3 is in this case redundant.We take a timed-automaton as a fine-grained model of a real-time agent. A (real-time) multi-agent system will bedefined as a set of communicating timed automata combined via parallel composition into a global timed automaton.In the composition the transitions not corresponding to a shared action are interleaved, whereas the transitions labelledwith a shared action are synchronised. Several definitions of parallel composition exist. Here we use multi-way syn-chronisation [27], i.e., we require that each component with a communication transition (labelled by a shared action)has to perform this action when the global transition occurs.Formally, let T Ai = (Zi, Li, l0i , Ei, Xi, Ii) be a timed automaton for i = 1, . . . , m, Li ∩ Lj = ∅ for all i, j ∈{1, . . . , m} and i (cid:12)= j , and let Z(a) = {1 (cid:2) i (cid:2) m | a ∈ Zi} denote the set of indices of the timed automata whose setsof actions contain the action a. The parallel composition is defined as follows.Definition 2 (Parallel composition). A parallel composition of m timed automata T Ai is a timed automaton T A =m(Z, L, l0, E, X, I), where Z =i=1 Ii(li).Each global transition is such thatXi , I(l1, . . . , lm) =mi=1 Li , l0 = (l0mi=1 Zi , L =m), X =1 , . . . , l0mi=1(cid:2)(cid:4)(cid:3)(cid:2)((l1, . . . , lm), a, cc, X, (l(cid:5)cci, X =cc =(cid:7)1, . . . , l(cid:6)(cid:7)m)) ∈ E iff (∀i ∈ Z(a))(li, a, cci, Xi, lXi, and (∀j ∈ {1, . . . , m} \\ Z(a)) l(cid:7)i) ∈ Ei,= l",
            {
                "entities": [
                    [
                        74,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 82 (1996) 21-44 Artificial Intelligence Probably approximately optimal satisficing strategies * Russell Greiner a-*, Pekka Orponen b ’ Siemens Corporate Research, 75.5 College Road, East Princeton, NJ 08540, USA h Department of Computer Science, University of Helsinki, PO. Box 26, FIN-00014 Helsinki, Finland Received September 1990; revised December 1992 Abstract A satis$cirzg search problem consists of a set of probabilistic of successes configuration experiments to be performed and failures. The expected cost and on the order of the individual experiments, the experiments strategy, which specifies that minimizes that compute optimal strategies in some order, seeking a satisfying of the search depends both on the success probabilities are to be performed. the search in which the expected cost is optimal. Earlier work has provided “optimizing A strategy functions” from the success for certain classes of search problems probabilities of the individual experiments. We extend those results by providing a general model optimal strategy when of such strategies, and an algorithm PA0 first estimates the probability values are not known. The algorithm from a number of trials of each undetermined and then uses these estimates, and the proper experiment, to identify a strategy whose cost is, with high probability, close to optimal. optimizing the PA0 We also show algorithm can also “learn while doing”, the search. that if the search problem can be formulated that identifies an approximately statistics while performing the relevant probabilities as an and-or the necessary i.e. gather tree, then function, * Some of this work was performed while the authors were at the University of Toronto, supported by an operating grant Academy of Finland. The authors useful comments on earlier versions of this paper. Preliminary versions of parts of the work have appeared the conference the National Science and Engineering Research Council of Canada, and by the referees for their in thank Dale Schuurmans, Tom Hancock and the anonymous [ 191 and [ IO]. respectively reports from * Corresponding author. E-mail: greiner@scr.siemens.com. 0004-3702/96/$15.00 SSD10004-3702(95)00010-0 @ 1996 Elsevier Science B.V. All rights reserved \f22 R. Greinec P. OrponedArtificial Intelligence 82 (1996) 21-44 1. Introduction Consider the following situation: there are two reliable tests for deciding whether an the blood to obtain a diagnosis. Using strategy 01 = (blood, individual has hepatitis; one involves a blood test and the other a liver biopsy. Assuming a doctor there can be false negatives but no false positives, first can follow perform If liver, and conclude his diagnosis based on the not, he would the patient’s performs result of that biopsy. The doctor’s other option, strategy 02 = (liver, these tests in the other order-first the blood test. blood), if necessary, the liver test and then, only there are two “strategies” the patient has hepatitis if that test is positive. test and conclude then examine he would liver), is a strategy Which strategy is better? Our goal the measurement, we assume that will perform well in practice. that the to evaluate. We can then define a strategy’s expected cost as the to perform To quantify doctor will be asked average cost required patients. Assuming, for now, that these tests (blood strategy 01 is clearly better if the probability of a positive blood test (pi) liver test (pi); the probability these tests, averaged over the distribution of anticipated have the same cost, and liver) is larger than strategy 02 is preferable. is a distribution of a positive of patients otherwise, there Earlier research on this decision making model has produced a number of “optimizing that each identify a strategy optimal for a specific values of the relevant experiments is that the probability [ 6,7,18,21,22]. values are in practice testing situation, given the A limitation of typically not that are to identify the number of trials of each experiment to obtain estimates of these probability values that are good enough strategy, with high confidence. It also addresses the complexities of from the doctor’s situation and defines strategies, the PA0 algorithm, trials of each experiment approximately to identify optimal. The algorithm presumes for the class of search structures and-or trees, the PA0 and optimal strategies, a general process to a general class of for these that uses a is, with the existence of an considered. When dealing with can “learn while a strategy whose cost algorithm An extended version of this paper, available statistics while solving relevant performance tasks. report of the basic algorithm presented here. as a technical [ 1 I], discusses techniques, functions” success probability these known a priori. This paper specifies required a nearly-optimal observing however, this many Section 2 below trials. first generalizes structures” “decision arbitrary structures. Section 3 then specifies set of observed high probability, optimizing certain doing”, search structures, i.e. gather the necessary function notably several variants and applications 2. Framework 2.1. Decision structures The doctor’s task presented (term due to Simon and Kadane problem configuration of events: in Section 1 is a simple example of a satisjcing search [ 2 1 ] ) , as his goal is to find a single satisfactory of test results. Other combination in this case, an informative \fR. Greiner; l? Orlmnen/Arrijicial Intelligence 82 (1996) 21-44 23 [ Patient has hepatitis] f- el f e2 --l Fig. I An and-or tree representation of a decision structure GI examples whether a product a position treasure chests general, can constraints. involve of such problems specimen include, is satisfactory [6], competing for prizes at a quiz show [ 211, and performing inference [ 61, screening employment [6], mining in simple expert systems e.g., performing a sequence of tests such tasks may involve searching through general “decision an arbitrary number of experiments, constrained candidates to decide for in In structures”, which by various precedence for gold buried [ 10,221. and the arcs encode the precedence trees: More general versions of this diagnostic task can be represented trees, such as G1 in Fig. 1. Here, the nodes {A, el, . . . , eg} correspond the doctor cannot serum) and found that el succeeds. The experiment associated with the A node is formally from a given line, e.g., the graph in Fig. 1 states that the relationships-e.g., the patient’s blood reacts with a particular the e2-e5 arc to the e2-e6 arc). Hence, to succeed. The set of arcs descending to draw blood from the patient) (here indicated by a horizontal i.e. it is guaranteed el (attempted e3 (test whether experiment And-or decision by and-or decision to experiments, perform experiment until he has performed moreover, degenerate, node can be either disjunctive, connecting patient has hepatitis holds. The number near each arc designates costs units incremental arcs that must be traversed. “collapsed” reduce el cost of performing the top eo node to e3 (test I unit to further iff the condition or conjunctive to simpler to reduce two-level to the el subgoal the cost of traversing it and 2 more and so forth. The is the sum of the costs of the additional (This cost specification means such trees cannot always be the blood against serum-A), each experiment that arc-hence (draw blood), [ el A (e3 V e4) ] V [ e2 A e5 A e6] on the experiments trees.) trees: The general class of decision than and-or trees. First, and-or structures we shall consider trees can encode only simple Beyond and-or strictly more general mulae, which can include each experiment only once, and whose connections “and”s and “or”s. In general, we may want to express more complicated ships of the experiments; experiments”. ships; some complicated Third, and-or of performing performed. can only be performed if has succeeded or failed. cost have been In general, we may want the cost to depend also on whether e, and/or vari- interrelation- or “at least 3 of 5 specified relation- simple precedence e.g., the XOR of m experiments, relatively e can depend only on which other experiments that an experiment of other experiments in general, we may want to specify in which the incremental is for- are only form of cost function, trees use a restricted boolean combination trees only permit Second, and-or experiment \f24 R. Greiner: I? OrponedArtijicial Intelligence 82 (1996) 21-44 ous prior experiments, more complicated ways of computing experiment; see the extended paper [ 111. have been successful. There are also situations which require yet a particular cost of performing the incremental these extensions, we define a more general class of “decision structure involve an arbitrary can constraints To accommodate tures”. A decision with general precedence formed until after certain other specified experiments (success or failure) specified can correspond has hepatitis) failures of any subset of these experiments, of experiments “decision structures” defined below. can be given by an arbitrary nondecreasing result. The overall to an arbitrary boolean combination test result have been performed with struc- set of experiments W = {ei}y=l, from being per- the the patient of the successes and a sequence function. This leads to the (e.g., whether that can prevent an experiment and the costs of performing Notation: Given two sequences, (T = (al,. formed by concatenating CT and r-i.e. is extended to the sequence The definition manner. A sequence all i = 1, . . . , II, for some monotonically is trivially a subsequence of any sequence u. (T is a subsequence of sequence CT. r = (al,. . . , a,) and Q- = (71,. . . , T,,), let g. 7 refer . . , cnr 71,. . . , r,,). in the obvious (T r r, if Ci = rh(i) for () function h. The empty sequence r, denoted increasing to the case where u or r are single elements Definition 1 (Decision where struct",
            {
                "entities": [
                    [
                        73,
                        126,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1655–1671Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVoting almost maximizes social welfare despite limited communication ✩Ioannis Caragiannis a, Ariel D. Procaccia b,∗a Research Academic Computer Technology Institute & Department of Computer Engineering and Informatics, University of Patras, Greeceb School of Engineering and Applied Sciences, Harvard University, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 7 December 2010Received in revised form 14 March 2011Accepted 23 March 2011Available online 5 April 2011Keywords:Computational social choiceIn cooperative multiagent systems an alternative that maximizes the social welfare—the sumof utilities—can only be selected if each agent reports its full utility function. This may beinfeasible in environments where communication is restricted. Employing a voting rule tochoose an alternative greatly reduces the communication burden, but leads to a possiblegap between the social welfare of the optimal alternative and the social welfare of theone that is ultimately elected. Procaccia and Rosenschein (2006) [13] have introduced theconcept of distortion to quantify this gap.In this paper, we present the notion of embeddings into voting rules: functions that receivean agent’s utility function and return the agent’s vote. We establish that very low distortioncan be obtained using randomized embeddings, especially when the number of agents islarge compared to the number of alternatives. We investigate our ideas in the contextof three prominent voting rules with low communication costs: Plurality, Approval, andVeto. Our results arguably provide a compelling reason for employing voting in cooperativemultiagent systems.© 2011 Elsevier B.V. All rights reserved.1. IntroductionA major challenge that arises in the design and implementation of multiagent systems is the aggregation of the pref-erences of the agents. Voting theory provides a neat solution by giving extremely well-studied methods of preferenceaggregation. In recent years the theoretical aspects of computational voting have been enthusiastically investigated, es-pecially within the AI community (see, e.g., [15, Chapter 1] and the many references therein). Moreover, voting has beenapplied for preference aggregation in areas as diverse as Planning, Scheduling, Recommender Systems, Collaborative Filtering,Information Extraction, and Computational Linguistics (see, e.g., [7,12,16]).While the appeal of voting in the context of heterogeneous, competitive multiagent systems is apparent, some multiagentsystems are centrally designed and fully cooperative (e.g., systems for planning and scheduling, recommender systems, collab-orative filtering, and so on). We believe that, to date, the benefit of employing voting in such domains was unclear. Indeed,agents are normally assumed to compute a utility for every possible alternative. If the agents are cooperative then they cansimply communicate their utilities for the different alternatives, and subsequently select an alternative that maximizes thesocial welfare, i.e., the sum of utilities.However, accurately conveying an agent’s utility function for each alternative may be very costly in terms of commu-nication. This could prove to be a serious obstacle in domains where communication is restricted. Communication maybe limited by the physical properties of the system (e.g., slow or error-prone transmitters, systems with low energy con-✩A preliminary version of the paper appeared in the Proceedings of AAAI’10.* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), arielpro@seas.harvard.edu (A.D. Procaccia).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.005\f1656I. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–1671sumption requirements, etc.) or the representation of the full utility functions may require a huge amount of information.Blumrosen et al. [1] outline additional persuasive reasons why communication should be restricted in multiagent settings.Fortunately, some prominent voting rules—functions that select an alternative given the preferences of the agents—imposea very small communication burden [5], and are moreover resistant to errors in communication [14].For example, consider the paradigmatic cooperative multiagent system domain: scanning an area on Mars with multiplerovers (which are known to have limited communication capabilities). Suppose the rovers must select or update their jointplan (this may happen very often), and there are one million alternatives. Moreover, suppose each rover computes a utilityfor each alternative on a scale of one to one million (this is, in fact, a very coarse scale). A rover would need to communicate106 · log(106) ≈ 20 · 106 bits in order to report its utility function. In contrast, under the Plurality voting rule, where eachagent votes for a single alternative and the alternative with most votes wins, a rover only needs to transmit twenty bits. Eventhough current applications may involve a small number of rovers, the research in wireless communication systems alreadyenvisages large-scale applications (e.g., for environment monitoring, disaster relief, battlefield operations and surveillance)with many ultra-small, possibly mobile, wireless devices such as sensors or mini-robots that cooperate towards a commongoal. Such devices are expected to be fully autonomous, a property that calls for low energy consumption and, consequently,for low communication requirements. The Harvard Micro Air Vehicles Project1 provides a concrete example of such a system.In this paper we shall argue that, in some cooperative multiagent systems, exact maximization of the social welfare canbe replaced by very simple voting rules (given an extra ingredient that we present below). The benefit is a huge reductionin the communication burden, whereas the cost, a deterioration in the social welfare of the outcome, will be shown to bealmost negligible in some settings. This arguably provides a pivotal reason for employing voting in cooperative multiagentsystems, and in AI in general.1.1. Our approachThe degree to which the social welfare of the outcome can decrease when voting is used is captured by the notionof distortion, introduced by Procaccia and Rosenschein [13]. They focus on voting rules that receive as input a ranking ofthe alternatives, and, crucially, assume that each agent reports a ranking such that the alternative that is ranked in thekth place has the kth highest utility. Under this assumption, they define the distortion of a voting rule to be the worst-caseratio between the maximum social welfare over all the alternatives, and the social welfare of the winner of the election; theworst-case is taken over all the possible utility functions of the agents. After proving some impossibility results, Procacciaand Rosenschein further restrict the structure of the utility functions. Even under this additional (very strong) assumption,they show that the distortion of most prominent voting rules is linear in the number of alternatives. The approach ofProcaccia and Rosenschein is descriptive: they propose to use the notion of distortion as a criterion in the comparison ofdifferent voting rules.Our main conceptual contribution is the consideration of embeddings into voting rules. An embedding is a set of instruc-tions that inform each agent how to vote, based only on the agent’s own utility function, that is, without any communicationor coordination between different agents. More accurately, an embedding into a specific voting rule is a function from utilityfunctions to votes that are valid under the voting rule. For instance, consider the simple Plurality rule described above. Givena utility function, an embedding into Plurality returns the alternative that the agent votes for. Procaccia and Rosenscheinimplicitly use one specific embedding, but many different embeddings exist. In this sense, our approach is algorithmic: wewish to design embeddings in a way that minimizes the distortion.We redefine the notion of distortion to take embeddings into account. The distortion of an embedding into a voting rule isstill the worst-case ratio between the maximum social welfare and the social welfare of the winner, but now the winnerdepends both on the voting rule and on the embedding, that is, on the way the utilities of the agents are translated intovotes. The worst-case is taken over all possible utilities; we do not make any assumption regarding the utilities, except thatthey are normalized.We take the idea of embeddings into voting rules one step further by allowing randomized embeddings. A randomizedembedding randomly chooses the agent’s vote, according to some probability distribution. The distortion is defined similarly,by taking into account the expected social welfare of the winner of the election. As we shall see, randomization gives usgreat power and flexibility, and ultimately provides us with the tools to design truly low-distortion embeddings.We wish to design low-distortion embeddings into voting rules with low communication complexity. Indeed, given thateach of our cooperative agents votes according to the instructions provided by the embedding (in a fully decentralized way),then an alternative with social welfare close to optimal may be elected in the face of restricted communication. We find theexistence of low-distortion embeddings rather striking, as the social welfare is a centralized concept.1.2. Our resultsWe study the distortion of embeddings into three voting rules: Plurality, Approval (each agent approves a subset ofalternatives), and Veto (each agent gives a “negative point” to one alternative). Plurality and Veto have the smallest com-1 http://robobees.seas.harvard.edu.\fI. Caragiannis, A.D. Procaccia / Artificial Intelligence 175 (2011) 1655–16711657m",
            {
                "entities": [
                    [
                        138,
                        206,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 249 (2017) 19–46Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConstrained coalition formation on valuation structures: Formal framework, applications, and islands of tractabilityGianluigi Greco a,∗a Department of Mathematics and Computer Science, University of Calabria, Italyb DIMES Department, University of Calabria, Italy, Antonella Guzzo ba r t i c l e i n f oa b s t r a c tArticle history:Received 20 September 2016Received in revised form 5 April 2017Accepted 17 April 2017Available online 21 April 2017Keywords:Coalitional gamesSolution conceptsComputational complexityTreewidthMarginal contribution networksCoalition structure generation is the problem of partitioning the agents of a given environment into disjoint and exhaustive coalitions so that the whole available worth is maximized. While this problem has been classically studied in settings where all coalitions are allowed to form, it has been recently reconsidered in the literature moving from the observation that environments often forbid the formation of certain coalitions. By following this latter perspective, a model for coalition structure generation is proposed where constraints of two different kinds can be expressed simultaneously. Indeed, the model is based on the concept of valuation structure, which consists of a set of pivotalagents that are pairwise incompatible, plus an interaction graph prescribing that a coalition C can form only if the subgraph induced over the nodes/agents in C is connected.It is shown that valuation structures can be used to model a number of relevant problems arising in real-world application domains. Then, the complexity of coalition structure generation over valuation structures is studied, by assuming that the functions associating each coalition with its worth are given as input according to some compact encoding—rather than explicitly listing all exponentially-many associations. In particular, islands of tractability are identified based on the topological properties of the underlying interaction graphs and on suitable algebraic properties of the given worth functions. Finally, stability issues over valuation structures are studied too, by considering the core as the prototypical solution concept.© 2017 Elsevier B.V. All rights reserved.1. Introduction1.1. Constrained coalition structure generationCoalition structure generation is a fundamental problem in the study of coalition formation processes for multi-agent systems, which naturally occurs whenever agents can benefit form working together by forming coalitions (see, e.g., [59,31]). The problem is defined over a pair (cid:3)N, v(cid:4), referred to as a coalitional game, where N = {a1, . . . , an} is a set of agents and where v is a valuation function that, for each coalition C , i.e., non-empty set C ⊆ N of agents, returns a real number v(C)meant to express the worth that the members of C can jointly achieve by cooperating (see, e.g., [71,53]). The goal is to find * Corresponding author.E-mail addresses: ggreco@mat.unical.it (G. Greco), antonella.guzzo@unical.it (A. Guzzo).http://dx.doi.org/10.1016/j.artint.2017.04.0050004-3702/© 2017 Elsevier B.V. All rights reserved.\f20G. Greco, A. Guzzo / Artificial Intelligence 249 (2017) 19–46Fig. 1. Interaction graph in Example 1.2, with optimal coalition structures for the basic setting (left), and when a1 and a2 are pivotal agents (right).an optimal coalition structure, i.e., a partition {C1, . . . , Ck} of the agents into disjoint and exhaustive coalitions whose total value (cid:2)ki=1 v(Ci) is maximized.Example 1.1. Consider the coalitional game (cid:3)N, v(cid:4) where N = {a1, a2, a3} and where v is the valuation function such that:⎧⎨⎩v({a3}) = 0v({a1}) = v({a2}) = v({a2, a3}) = v({a1, a3}) = 1v({a1, a2}) = v({a1, a2, a3}) = 3Note that the optimal coalition structures are {{a1, a2, a3}} and {{a1, a2}, {a3}}. Their associated value is v({a1, a2, a3}) =v({a1, a2}) + v({a3}) = 3. (cid:2)While coalition structure generation has been classically studied in the literature by assuming that all coalitions are allowed to form, in real-world applications it is often the case that some coalition structures are inadmissible, because they violate a number of constraints induced by the specific semantics of the application at hand (see, e.g., [59]).Constraints on the coalition structures that are allowed naturally emerge in those settings where cooperation is guided by an underlying structure reflecting, for instance, physical limitation, legal banishments, and social relationships. In these cases, it is natural to assume that if two disconnected agents are not connected by intermediaries in a given coalition, then they might not be able to cooperate at all. In particular, following Myerson’s influential work [51], this intuition has been often formalized (see, e.g., [15,70,9]) by equipping each coalitional game (cid:3)N, v(cid:4) with an undirected graph G = (N, E), called interaction graph, defined over the set of the agents, and by considering a coalition C as a feasible one, only if the subgraph of G induced over the nodes in C is connected.In fact, in addition to the “topological” constraints induced by the underlying interaction graphs, other kinds of con-straints might occur in concrete domains when dealing with the coalition structure generation problem. For instance, the formation of certain coalitions might be prohibited by anti-trust laws or it might be subject to constraints on the coalition sizes. Settings of this kind have been also studied in the literature [26,65,56] and a general and unifying framework of these works has been proposed too [58]. In that framework, a coalitional game is equipped with two sets, N and P , of “negative” and “positive” constraints respectively. A negative constraint n ∈ N is a set of agents, and it prescribes that no coalition C such that C ⊇ n can be formed. Positive constraints are again formalized as set of agents, and they prescribe that for each feasible coalition C , there must exist a constraint p ∈ P such that C ⊇ p. As a matter of fact, however, the framework of [58] does not support the definition of interaction graphs and, despite its generality, it cannot simulate the topological constraints that are induced by them.Example 1.2. Consider again the setting of Example 1.1 and the interaction graph reported on the left of Fig. 1. Note, for instance, that coalition {a1, a3} is not allowed to form. Then, we claim that this simple scenario cannot be modeled via positive and negative constraints. Indeed, if a negative constraint n = {a1, a3} is considered, then the coalition {a1, a2, a3}would be not feasible precisely because of n. More generally, because of the feasibility of {a1, a2, a3} and by the monotone semantics of negative constraints, no negative constraint can be defined at all.Consider now the use of positive constraints. We know that {a1} is feasible and, hence, it must occur as a positive constraint. However, in absence of negative constraints, this immediately entails that {a1, a3} is feasible, too. (cid:2)As a matter of fact, topological constraints and positive/negative constraints have been separate worlds, so far. In the paper, we move from this observation and we propose to study a setting for coalition structure generation based on the concept of valuation structure, which basically consists of an interaction graph associated with certain kinds of negative constraints. In a nutshell, a set S of pairwise “incompatible” (pivotal) agents can be defined, so that every coalition C must satisfy the condition |S ∩ C| ≤ 1 in order to be a feasible one. Indeed, note that this is equivalent to having a negative constraint S, for each subset S(cid:10) ⊆ S with |S(cid:10)| = 2.(cid:10)Example 1.3. Assume that a1 and a2 are two pivotal agents in the setting of Example 1.1. Then, the feasible coalitions are further reduced to {a1}, {a2}, {a3}, and {a2, a3}, because the coalitions {a1, a2, a3} and {a1, a2} would be no longer allowed to form. In this scenario, which is graphically illustrated on the right of Fig. 1, an optimal coalition structure is {{a1}, {a2, a3}}whose associated value is a2. Hence, the incompatibility of a1 and a2 leads to reduce the total available worth. (cid:2)\fG. Greco, A. Guzzo / Artificial Intelligence 249 (2017) 19–46211.2. ContributionThe intuition underlying our formalization is that pivotal agents in S possess some specific properties differentiating themselves from the remaining agents in N \\ S. As an extreme case, a pivotal agent might well be an abstraction for some given parameter/object involved in the problem, i.e., it is not necessarily a “true” agent of the system. For instance, S might model a set of competing facilities to which the agents in N \\ S have to be connected. In fact, as the starting point of our analysis,(1) We define a framework for equipping coalitional games with valuation structures and we show that constraints induced by pivotal agents, combined with the underlying interaction graphs, are capable of expressing a number of relevant problems arising in a number of real application scenarios.Motivated by their relevance from the knowledge representation viewpoint, the paper then embarks on a systematic study of algorithmic and complexity issues arising with them. Prior to detailing these technical contributions, however, it is appropriate to recall that there is an extensive literature studying computational issues and proposing efficient solution algorithms for coalition structure generation, which we can partition in two groups based on the kinds of game encoding considered in the research.Classically, valuation functions are viewed as “black boxes” that, on input a coalition C , return the value v(C). In partic-ular, encoding and representation issues are not taken into account. In this context, exact solution approaches or algorithms with wor",
            {
                "entities": [
                    [
                        134,
                        250,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 503–535Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcise finite-domain representations for PDDL planning tasks ✩Malte HelmertInstitut für Informatik, Albert-Ludwigs-Universität Freiburg, Georges-Köhler-Allee 052, 79110 Freiburg, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 16 November 2007Received in revised form 22 October 2008Accepted 29 October 2008Available online 25 November 2008Keywords:Automated planningProblem reformulationPDDL+SASWe introduce an efficient method for translating planning tasks specified in the standardPDDL formalism into a concise grounded representation that uses finite-domain statevariables instead of the straight-forward propositional encoding.Translation is performed in four stages. Firstly, we transform the input task into anequivalent normalform expressed in a restricted fragment of PDDL. Secondly, wesynthesize invariants of the planning task that identify groups of mutually exclusivepropositions which can be represented by a single finite-domain variable. Thirdly, weperform an efficient relaxed reachability analysis using logic programming techniques toobtain a grounded representation of the input. Finally, we combine the results of the thirdand fourth stage to generate the final grounded finite-domain representation.The presented approach has originally been implemented as part of the Fast Downwardplanning system for the 4th International Planning Competition (IPC4). Since then, it hasbeen used in a number of other contexts with considerable success, and the use of concisefinite-domain representations has become a common feature of state-of-the-art planners.© 2008 Elsevier B.V. All rights reserved.1. IntroductionConsider the transportation planning task illustrated in Fig. 1. There are three cars, a train, and two parcels, located intwo cities comprising several locations each. The cars may move along a network of roads within their respective city oforigin, while the train moves along a single railway link that connects the two cities. Parcels may be loaded into any vehiclethat is present at the same location, and parcels carried by a vehicle may be unloaded to the current location of that vehicleat any time. The objective is to move each parcel to a designated goal location.1.1. PDDL representationsIn order to find a plan for this example task using a general-purpose planning system, we must first represent it in away that such a system can reason about. Since its inception in 1998 [38], the Planning Domain Definition Language (PDDL)has become the de-facto standard language for representing classical planning tasks. The original PDDL formalism, as usedin the first two International Planning Competitions, was purely logic-based and can be considered a syntactic variant ofthe earlier ADL language [39] (excluding the support for functional fluents, which are present in ADL). Since then, thelanguage has been extended to more easily express additional aspects of real-world planning tasks, such as numbers anddurations [21], state variables whose values are derived from the values of other state variables [18], and most recently planconstraints and preferences [24].✩This work was partly supported by the German Research Council (DFG) as part of the Transregional Collaborative Research Center “AutomaticVerification and Analysis of Complex Systems” (SFB/TR 14 AVACS). See www.avacs.org for more information.E-mail address: helmert@informatik.uni-freiburg.de.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.10.013\f504M. Helmert / Artificial Intelligence 173 (2009) 503–535Fig. 1. A transportation planning task. Deliver parcel p1 from C to G and parcel p2 from F to E, using the cars c1, c2, c3 and train t. The cars may only useroads (thin edges), the train may only use the railway (thick edge).In PDDL, planning tasks are described in terms of objects of the world (cars, locations, parcels), predicates that describestatic or dynamic relations that hold between these objects (whether or not two given locations are connected by a road,whether or not a given parcel is currently inside a given vehicle), operators that manipulate these relations (moving a carfrom one location to another, unloading a parcel), an initial state that describes the situation before plan execution, and agoal specification describing the objectives that solution plans must achieve.While PDDL itself is a (restricted) first-order formalism, all state-of-the-art planning systems compile the input specifi-cation into a propositional representation at an early stage by grounding predicates, operators and goal specifications. Manyplanners go even further and transform the grounded task into a particularly simple syntactic form called propositionalSTRIPS, where states of the world can be represented as sets of (satisfied) atomic propositions and operators are representedin terms of which propositions must be true for the operator to be applicable (preconditions), which propositions the op-erator makes true (add effects), and which propositions it makes false (delete effects). The example task can be naturallymodelled in propositional STRIPS; (part of) such a representation is shown in Fig. 2.PDDL- or STRIPS-based representations of planning tasks have a number of desirable features. Due to the close rela-tionship to first-order logic (for ungrounded PDDL) and propositional logic (for grounded PDDL), the semantics are easy tounderstand for researchers and practitioners with a background in formal logics. Moreover, representing all properties of aworld state in terms of truth values has the appeal of simplicity. There is a certain mathematical elegance to the formalism,and it clearly achieves the language designers’ maxim of describing planning tasks in terms of their “physics, not advice”[38].1.2. Finite-domain representationsThe absence of any form of “advice” from the PDDL representation is appropriate for a language designed for generalproblem solvers, but it comes at a price, to be paid by planning algorithms that have to reason about the represented task.In particular, the state space induced by a propositional representation such as the one shown in Fig. 2 is very unstructured.A priori, a proposition like at-p1-a (stating that the first parcel is at location A) bears no closer relationship to at-p1-b(stating that the first parcel is at location B) than to, say, in-p2-t (stating that the second parcel is currently inside thetrain). However, if we take into account their intended meaning, propositions that represent potential locations of the sameparcel are clearly more closely related to each other than to ones that encode properties of the other parcel. In particular,only one of the propositions of the form at-p1-x can be true at the same time in any feasible world state. To the planner,there appear to be as many as 235 ≈ 3.4 · 1010 feasible world states in the example task, corresponding to all valuationsof the 35 propositional state variables, yet in truth the number of relevant states is only 11616 ≈ 1.2 · 104, as all othervaluations are not reachable from the given initial state.An alternative representation of the example task is shown in Fig. 3. This representation uses general finite-domainvariables, not just binary ones, to represent the state of the world. For example, a single variable p1 with a domain of11 values completely encodes the state of the first parcel, subsuming the information of all propositions at-p1-x andin-p1- y from the STRIPS encoding. Using this representation, the set of feasible world states coincides with the set ofsyntactically legal ones.In this article, we present an efficient algorithm for translating planning tasks specified in PDDL 2.2 into a compactfinite-domain representation. The algorithm has been implemented as part of the Fast Downward planner [29] and used bya number of other planning algorithms [3,27,31,48,49]. It extends an earlier algorithm by Edelkamp and Helmert [15] whichalso translates PDDL tasks to finite-domain representations, but is limited to a much smaller language fragment (STRIPS, notyping, no domain constants in operator definitions).As far as we know, no other algorithms for this problem have been described in the literature, so the main contributionof this article is the first description of a method to generate concise finite-domain representations from arbitrary (non-\fM. Helmert / Artificial Intelligence 173 (2009) 503–535505Fig. 2. Propositional STRIPS representation of the transportation planning task.numeric, non-temporal) PDDL tasks. From a high-level perspective, our approach follows very similar ideas to the algorithmof Edelkamp and Helmert, but the generalization beyond STRIPS requires significant extensions to the core components ofthe translation algorithm, invariant synthesis (Section 5) and grounding (Section 6). (Indeed, even though the emphasis in thisarticle is on the overall goal of transforming PDDL tasks into a concise finite-domain representation, we believe that theinvariant synthesis and grounding algorithms we present are also useful for planning algorithms that work on traditionalPDDL representations, so the algorithms presented in Sections 5 and 6 may be seen as additional contributions of thispaper.)1.3. Why finite-domain representations?Before diving into more technical matters, let us briefly discuss why compact finite-domain representations might bedesirable. We already noted that in the STRIPS representation, unlike the finite-domain representation, there is a vastlylarger number of syntactically valid states than feasible (reachable) states in the planning task. This is not necessarilyproblematic – for example, a planning algorithm based on forward search, such as Hoffmann and Nebel’s FF [33], will neverencounter any of the infeasible states, so there is no obvious advantage",
            {
                "entities": [
                    [
                        136,
                        197,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence ELSEVIER Artificial Intelligence 79 (1995) 161-182 Response Modelling creativity: reply to reviewers Margaret A. Boden University of Sussex, School of Cognitive and Computing Sciences, Brighton BNl 9QH, UK The reviewers of The Creative Mind (henceforth KM) interesting points. Most fall into seven groups: and P-creativity; distinction between H-creativity the mechanisms used for modelling creativity; AI-models as aids to creativity; and the treatment of music in TCM. I shall group my replies accordingly. have raised a host of the the role of the social context; specific computational the definition of creativity; role of evaluation; four Lovelace questions; the 1. Definition of creativity creativity. disagreement to considerable this was unavoidable: in Chapter 3 and Mozart spaces is often, and understandably, “exploratory”, I did not make Most of the reviewers point out, quite rightly, that my definition of creativity and “transformational” it sufficiently clear (despite my examples of of in Chapter 10) that mere exploration in TCM was vague. To some extent, the notion of positive value or interest, which is essential to the concept of creativity, cannot be given any general definition and is open in individual cases. But I should have been clearer about the differences between what I called “combinational”, instance, For Dickens conceptual of a space (conceptual or terrestrial) previously unsuspected, offer surprises comparable ty. Not all exploration does this, of course. But even simple induction-which, Roger Schank points out, explore a space with sometimes surprising (and valuable) results (TCM, Chapter 8). Most current AI-programs their conceptual spaces, but even so they may come up with apparently David Perkins remarks, however, creative process that were lying in surprising places. In short, it can creativi- as creative surprises. As the term applies in its richest sense with the involves changing the rules, not just working within them. to the surprises provided by transformational is the antithesis of transformational can sometimes show us regions counted as creative. Exploration and boundaries creativity+an transform explore rather than Also, I often used the distinction between a (superficial) (fundamental) transformation in a way that was intuitive 0004-3702/95/$09.50 SSDZ 0004-3702(95)00074-7 0 1995 Elsevier Science B.V. All rights reserved tweaking and a than analytic. rather \fthat from specializing transformed for granted the relevant to rings comprising I described Kekule’s move in aromatic and and pyridine. Thus change the (later) move A chemist ring-molecules instance) “place” tion patterns, within my scheme. Distinguishing not conceptual structured requires spaces but also on nature specific AI-processes. us to distinguish straightforward, this styles. such spaces, styles within individuating it depends of many benzene since conceptual space more string-molecules to ring-molecules fundamentally as a than five atoms. not all of which need be carbon. taking (for to compounds might see things differently, seeing In general. such as Schank’s the basic gulf as not it would lying between always be easy explana- heuristics tweaking for tweaking from not only on defining them. Because transformation the dimensions of the hierarchically is of is not a cut-and-dried matter, but 4, for example, space, which I described took several post-Renaissance centuries to explore Western music as a and which was Likewise. transformed of a number In Chapter single conceptual eventually consists (Bach. Vivaldi). contain many hierarchical ceptual work interest) those who discuss creativity it. is itself necessary theories fashion. spaces is highlighted jazz) and as chemistry) by the move of sub-spaces into atonal music. But (baroque music, this space undeniably sub-sub-spaces a scientific space (such or hypotheses, only some of which are The difficulty by work of judging the boundaries in the history of art and science, the novelty the creativity (both This difficulty of definition in general. including AI-workers who seek linked of distinct will usually in a clear con- yet such the and all bedevils to model to help us judge of the ideas under consideration. guilty, 1 plead problematic. However. stress on the hypothesis 4). I do not claim that precondition spaces. that animals happens play appears skilled behaviour. general: bead-game, without the piano). But to be essential as Kenneth only it. says true. The Turner restructuring, often scientific Grandpa’s scious problem-solving ideas in general, then. to the complaint I do not accept Scott Turner’s of representational redescription, that my definition charge of creativity was that I lay too much or RR (TCM, Chapter for the construction, In a recent publication it is the sole factor underlying and herself exploration, Karmiloff-Smith they (I cite relevant lack RR evidence because lack creativity in children says as much, [13]. Nor do I claim in adults learning creativity, transformation rather it is a that of conceptual the point is that it appears if the child Self-mapping of conceptual is to be flexible spaces form if we remarks, will be more fruitful in all children, imaginative to happen and is necessary follow and if we played than for creativity a map of in the the game Haase our explorations and claims that RR to read, or it and in his/her that creativity but to conscious, is not due to a “singular” process of conceptual incremental problem-solving processes. problem-solving types of example Turner modelled jokes? And Coleridge’s by Herb Simon These imagery? and his colleagues are not generated has in mind presumably processes. are produced I agree with Turner everyday by normal they, that processes: That include is the [14]. But by con- and creative is what that \fM.A. Boden I Artificial Intelligence 79 (1995) 161-182 163 conscious) change is not a question of a sudden Gestalt-switch, Chapter 10 (and much of Chapters 5 and 6) is about. In my account, conceptual restructuring but a focussed (sometimes in one or more dimensions of the pre-existing structure. So KekulC, for instance, did not “discard” his previous space: on the it into another, closely related, one. As I argue in TCM, contrary, he transformed if we were to discard our conceptual thinking something new, the novel would be neither valued nor preserved. thoughts would be unintelligible-so spaces whenever Turner says that my definition of creativity if we are to orient ourselves even in being dropped or negated: This leads me to hesitate also over Haase’s description of a radical conceptual change as one which throws out the lines and landmarks of the previous map and them with new ones. This may be very largely true, but some aspects of replaces intelligibly. the previous space need to be retained the obvious (Some aspects may be “retained” absence of an expected dimension can act as a reminder of it.) lays me open to the devil of to determinism. But he does not refer to Chapter 9, which was wholly addressed that my this problem. And he and Ashwin Ram ideas definition of transformational I explain in TCM (Chapter 1) that to say that leads to inconsistency. However, the idea before can be sensibly asserted only someone “could not” have produced to the space. If we try to apply this notion to a specific conceptual by reference entire resources of the person’s mind (or the computer’s program), of course we get an inconsistency. (and colleagues) in terms of apparently impossible complain creativity The same applies to computer programs. A program which uses (for example) heuristics [15], is changing its genetic algorithms, or AM’s concept-transforming the algorithms provided by space in significant ways. It could not do so without a set people-need the programmer; of general computational spaces that they deal with, to which we must implicitly refer when we speak of creativity. One might want to argue that some of these processes are domain-specific, so should be counted itself. This recalls Schank’s comment that the distinction between rules and meta-rules but that is just to say that computers-like is highly problematic. the domain-specific processes besides as lying within the conceptual space in Section 4 (below), in turn means Schank sees my definition as implying that creativity is a matter of degree. I am is not an all or none matter. But, very happy with that, if it means that creativity is multi- to say that creativity I prefer as explained dimensional-which to be the relevant dimensions need that specified in any argument about the “degree” of creativity of a given idea. For the is too same reasons, coarse in complex generative that the single distinction “creative” I agree with Haase inter-representational relations involved the computational not sufficiently assume representation, that my definition of creativity presupposes a particular account of mental life is perhaps prompted by the fact that I did In fact, I stress either exploratory creativity. and many different types of that new methods of inference are involved. And Ram’s comment types of process, or combinational that many different to describe systems. Ram’s complaint \fis well-taken. (such as those used for case-based enough reasoning) to enable At present, most cannot do so: they explore, can also lead to creative computer It representations. is difficult programs to their conceptual spaces. My hunch to come up with novel-and rather it will be even more of inference is that fruitful-forms control. to enable them note term (in minds or programs) But the enable generation, too. They “enabling” limit what structures are not mere here: Ram rightly notes that can be generated-but prohibitions, but positive their transform, and control novelty change than difficult and constraints they guidelines. on creative from ideas (leading me to ask how a resources the conceptual review, broadens related least Whereas",
            {
                "entities": [
                    [
                        84,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 256 (2018) 160–180Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief revision, minimal change and relaxation: A general framework based on satisfaction systems, and applications to description logicsMarc Aiguier a, Jamal Atif b,∗a MICS, Centrale Supelec, Université Paris-Saclay, Franceb Université Paris-Dauphine, PSL Research University, CNRS, UMR 7243, LAMSADE, 75016 Paris, Francec LTCI, Télécom ParisTech, Université Paris-Saclay, Paris, France, Isabelle Bloch c, Céline Hudelot aa r t i c l e i n f oa b s t r a c tArticle history:Received 13 November 2015Received in revised form 7 July 2017Accepted 11 December 2017Available online 17 December 2017Keywords:Abstract belief revisionRelaxationAGM theorySatisfaction systemsDescription logicsBelief revision of knowledge bases represented by a set of sentences in a given logic has been extensively studied but for specific logics, mainly propositional, and also recently Horn and description logics. Here, we propose to generalize this operation from a model-theoretic point of view, by defining revision in the abstract model theory of satisfaction systems. In this framework, we generalize to any satisfaction system the characterization of the AGM postulates given by Katsuno and Mendelzon for propositional logic in terms of minimal change among interpretations. In this generalization, the constraint on syntax independence is partially relaxed. Moreover, we study how to define revision, satisfying these weakened AGM postulates, from relaxation notions that have been first introduced in description logics to define dissimilarity measures between concepts, and the consequence of which is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. We show how the proposed general framework can be instantiated in different logics such as propositional, first-order, description and Horn logics. In particular for description logics, we introduce several concrete relaxation operators tailored for the description logic ALC and its fragments EL and ELU , discuss their properties and provide some illustrative examples.© 2018 Elsevier B.V. All rights reserved.1. IntroductionBelief change, the process that makes an agent’s beliefs evolve with newly acquired knowledge, is one of the classical but still challenging problems in artificial intelligence. It is gaining more and more interest these days, due to the emergence of new logical-based knowledge representation frameworks enjoying good complexity properties, allowing them to tackle large scale knowledge bases, and to reason on massive datasets. Among these logical frameworks, one can mention Description Logics (DLs) and Horn Clause theories. Description logics, for instance, are now pervasive in many knowledge-based repre-sentation systems such as ontological reasoning, semantic web, scene understanding, cognitive robotics, to mention a few. In all these domains, the expert knowledge is not fixed, but rather a flux evolving over time, hence requiring the definition of rational change operators.* Corresponding author.E-mail addresses: marc.aiguier@centralesupelec.fr (M. Aiguier), jamal.atif@dauphine.fr (J. Atif), isabelle.bloch@telecom-paristech.fr (I. Bloch), celine.hudelot@centralesupelec.fr (C. Hudelot).https://doi.org/10.1016/j.artint.2017.12.0020004-3702/© 2018 Elsevier B.V. All rights reserved.\fM. Aiguier et al. / Artificial Intelligence 256 (2018) 160–180161Studying the rationality of belief change operators, when knowledge bases are logical theories, i.e. sets of sentences in a given logic, goes back to the seminal work of Alchourròn, Gardenfors and Makinson [1], that gave birth to what is now known as AGM theory. Three change operations are studied within this framework, expansion, contraction and revision. Belief expansion consists in adding new knowledge without checking consistency, while both contraction and revision consist in consistently removing and adding new knowledge, respectively. We focus in this paper on belief revision.Although defined in the abstract framework of logics given by Tarski [40] (so called Tarskian logics), postulates of the AGM theory make strong assumptions on the considered logics. Indeed, in [1] the considered logics have to be closed under the standard propositional connectives in {∧, ∨, ¬, ⇒}, to be compact (i.e. inference depends on a finite set of axioms), and to satisfy the deduction theorem (i.e. entailment and implication are equivalent). While compactness is a standard property of logics, to be closed under the standard propositional connectives is more questionable. Indeed, many logics (called hereafter non-classical logics) such as description logics, equational logic or Horn clause logic, widely used for various modern applications in computing science, do not satisfy such a constraint. Recently, in many works, belief change has been studied in such non-classical logics [12,17,34,35]. For instance, Ribeiro et al. in [35] studied contraction at the abstract level of Tarskian logics, and recently Zhuang et al. in [42] proposed an extension of AGM contraction to arbitrary logics. The adaptation of the AGM postulates for revision for non-classical logics has been studied but only for specific logics, mainly description logics [16,17,28,29,31,33,41] and Horn logics [11,43]. The reason is that revision can be abstractly defined in terms of expansion and retraction following the Levi identity [23], but this requires the use of negation, which rules out some non-classical logics that do not consider this connective [34].The AGM postulates were interpreted in terms of minimal change in [22], in the sense that the models of the revision should be as close as possible, according to some metric, to the models of the initial knowledge set. However, to the best of our knowledge, the generalization of the AGM theory with minimality criteria on the set of models of knowledge bases has never been proposed. The reason is that semantics is not explicit in the abstract framework of logics defined by Tarski.We propose here to generalize AGM revision but in the abstract model theory of satisfaction systems, which formalizes the intuitive notion of logical systems, including syntax, semantics and the satisfaction relation. This notion was introduced in [18] under the name of “rooms”, and then of “satisfaction systems” in [38]. See also [26]. Then, we propose to generalize to any satisfaction system the approach developed in [22] for propositional logic and in [30] for description logics. In this abstract framework, we will also show how to define revision operators from the relaxation notion that has been introduced in description logics to define dissimilarity measures between concepts [14,15]. The main idea is to relax the set of models of the old belief until it becomes consistent with the new pieces of knowledge. This notion of relaxation, defined in an abstract way through a set of properties, turns out to generalize several revision operators introduced in different contexts e.g. [9,20,25,29]. This is another key contribution of our work.To concretize our abstract framework, we provide examples of relaxations in propositional logics, first order logics, and Horn logic. The case of description logics (DLs) is more detailed. This is motivated, as mentioned above, by their broad scope of applications, including reasoning on large web data.The paper is organized as follows. Section 2 reviews some concepts, notations and terminology about satisfaction systems which are used in this work. In Section 3, we adapt the AGM theory in the framework of satisfaction systems, and then give an abstract model-theoretic rewriting of the AGM postulates. We then show in Section 3.2 that any revision operator satis-fying such postulates accomplishes an update with minimal change to the set of models of knowledge bases. In Section 3.3, we introduce a general framework of relaxation-based revision operators and show that our revision operators lead to faith-ful assignments and then also satisfy the AGM postulates. In Section 4, we illustrate our abstract approach by providing revision operators in different logics, including classical logics (propositional and first order logics) and non-classical ones (Horn and description logics). The case of DL is further developed in Section 4.4, with several examples. Finally, Section 5 is dedicated to related works.2. Satisfaction systemsSatisfaction systems [26] generalize Tarski’s classical “semantic definition of truth” [39] and Barwise’s “Translation Ax-iom” [4]. For the sake of generalization, sentences are simply required to form a set. All other contingencies such as inductive definition of sentences are not considered. Similarly, models are simply seen as elements of a class, i.e. no particular struc-ture is imposed on them.2.1. Definition and examplesDefinition 1 (Satisfaction system). A satisfaction system R = (Sen, Mod, |=) consists of• a set Sen of sentences,• a class Mod of models, and• a satisfaction relation |=⊆ Mod × Sen.\f162M. Aiguier et al. / Artificial Intelligence 256 (2018) 160–180Let us note that the non-logical vocabulary, so-called signature, over which sentences and models are built, is not speci-fied in Definition 1.1 Actually, it is left implicit. Hence, as we will see in the examples developed in the paper, a satisfaction system always depends on a signature.Example 1. The following examples of satisfaction systems are of particular importance in computer science and in the remainder of this paper.Propositional Logic (PL) Given a set of propositional variables (cid:2), we can define the satisfaction system R(cid:2) = (Sen, Mod,|=) where Sen is the least set of sentences finitely built over propositional variables in (cid:2) and Boolean connectives in {¬, ∨}, Mod contains all the mappings ν : (cid:2) → {0, 1} (0 and 1 are the usual tr",
            {
                "entities": [
                    [
                        136,
                        273,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 196 (2013) 26–52Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPhysical search problems with probabilistic knowledge ✩Noam Hazon a,∗,1, Yonatan Aumann b, Sarit Kraus b, David Sarne ba Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USAb Department of Computer Science, Bar-Ilan University, Ramat Gan, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 31 August 2011Received in revised form 30 September2012Accepted 24 December 2012Available online 3 January 2013Keywords:Graph searchEconomic searchThis paper considers the problem of an agent or a team of agents searching for a resourceor tangible good in a physical environment, where the resource or good may possiblybe obtained at one of several locations. The cost of acquiring the resource or good ata given location is uncertain (a priori), and the agents can observe the true cost onlywhen physically arriving at this location. Sample applications include agents in explorationand patrol missions (e.g., an agent seeking to find the best location to deploy sensingequipment along its path). The uniqueness of these settings is in that the cost of observinga new location is determined by distance from the current one, impacting the considerationfor the optimal search order. Although this model captures many real world scenarios, ithas not been investigated so far.We analyze three variants of the problem, differing in their objective: minimizing the totalexpected cost, maximizing the success probability given an initial budget, and minimizingthe budget necessary to obtain a given success probability. For each variant, we firstintroduce and analyze the problem with a single agent, either providing a polynomialsolution to the problem or proving it is NP-complete. We also introduce a fully polynomialtime approximation scheme algorithm for the minimum budget variant. In the multi-agentcase, we analyze two models for managing resources, shared and private budget models.We present polynomial algorithms that work for any fixed number of agents, in the sharedor private budget model. For non-communicating agents in the private budget model, wepresent a polynomial algorithm that is suitable for any number of agents. We also analyzethe difference between homogeneous and heterogeneous agents, both with respect to theirallotted resources and with respect to their capabilities. Finally, we define our problem inan environment with self-interested agents. We show how to find a Nash equilibrium inpolynomial time, and prove that the bound on the performance of our algorithms, withrespect to the social welfare, is tight.© 2013 Elsevier B.V. All rights reserved.1. IntroductionFrequently, in order to successfully complete its task, an agent may need to explore (i.e., search) its environment andchoose among different available options. For example, an agent seeking to purchase a product over the Internet needs toquery several electronic merchants in order to learn their posted prices; a robot searching for a resource or a tangible goodneeds to travel to possible locations where the resource is available and learn the configuration in which it is available, as✩This paper extends two earlier conference papers (Aumann et al., 2008 [6]; Hazon et al., 2009 [31]).* Corresponding author.E-mail addresses: noamh@cs.cmu.edu (N. Hazon), aumann@cs.biu.ac.il (Y. Aumann), sarit@cs.biu.ac.il (S. Kraus), sarned@cs.biu.ac.il (D. Sarne).1 This work was done while the author was at Bar-Ilan University.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.003\fN. Hazon et al. / Artificial Intelligence 196 (2013) 26–5227well as the difficulty of obtaining it there. In these environments, the benefit associated with an opportunity is revealedonly upon observing it. The only knowledge available to the agent prior to observing the opportunity is the probabilityassociated with each possible value of each prospect.While in virtual environments the exploration can sometimes be considered costless, in physical environments travelingand observing typically entails a cost. Furthermore, traveling to a new location may increase or decrease the distance toother locations, so the cost associated with exploring other unexplored locations changes. For example, consider a Roverrobot with the goal of mining a certain mineral. Potential mining locations may be identified based on satellite imaging,each location associated with some uncertainty regarding the difficulty of mining there. In order to assess the amount ofbattery power required for mining at a specific location, the robot needs to physically visit there. The robot’s battery isthus used not only for mining the mineral but also for traveling from one potential location to another. Consequently, anagent’s strategy in an environment associated with search costs should maximize the overall benefit resulting from thesearch process, defined as the value of the option eventually used, minus the costs accumulated along the process, ratherthan merely finding the best valued option.In physical environments, it is common to use a team of agents rather than a single agent. Extending the single agentsolution to multi-agent strategy may require subdividing the search space among the different agents. However, if agentshave means of communication, then they may not wish to become too distant, as they can call upon each other for assis-tance. For example, even if a Rover does not have sufficient battery power for mining at a given location, it may be usefulfor it to travel to the site in order to determine the exact mining cost, and call for other robots that do have the necessarybattery power. In this case, the scheduling of the robots’ travel times is key, and must be carefully planned. If the agents arenot fully cooperative, a selfish behavior should also be considered. Each one of the agents will try to minimize its travelingcosts while still achieving the group’s goal.Finally, agents may be of different types, or with different amounts of resources. For example, Rover robots may beentering the mission with differing initial battery charges. They may also differ in their capabilities, like a team of Rovers inwhich some were specifically designed for mining missions, and thus require less battery power for the same mining task.This paper aims at taking the first steps in understanding the characteristics of such physical search environments, bothfor the single and multi agent cases, and developing efficient exploration strategies for the like. Our main focus is on the casewhere the opportunities are aligned along a path, as in the case of perimeter patrol [60,19,2,3]. We note that many singleand multi-agent coverage algorithms convert their complex environment into a simple long path [52,25,32]. Furthermore,we show that the problem in more general metric spaces is NP-complete, even for a tree graphs. For exposition purposes,in the remainder of the paper we use the classical procurement application where the goal of the search is purchasing aproduct and the value of each observed opportunity represents a price. Of course, this is only one example of the generalsetting of exploration in a physical environment, and the discussion and results of this paper are relevant to any suchsetting, provided that exploration and fulfilling the task consume the same type of resource.We consider three variants of the problem, differing in their objective. The first (Min-Expected-Cost) is the problem ofan agent that aims to minimize the expected total cost of completing its task. The second (Max-Probability) considers anagent that is given a budget for the task (which it cannot exceed) and aims to maximize the probability it will completethe task (e.g., reach at least one opportunity with a budget large enough to successfully buy the product). In the last variant(Min-Budget) the agent is required to guarantee a pre-defined probability of completing the task, and aims to minimize theoverall budget that will be required to achieve the said success probability. We also consider the multi-agent extensionsof these variants. While the first variant fits mostly product procurement applications, the two latter variants fit well intoapplications of robots engaged in remote exploration, operating with a limited amount of battery power (i.e., a budget).1.1. Summary of resultsWe first consider the single agent case. We prove that in general metric spaces all three problem variants are NP-hard.Thus, as mentioned, we focus on the setting where all locations are located along a path. For this setting we provide poly-nomial algorithms for the Min-Expected-Cost problem. We show the other two problems (Min-Budget and Max-Probability)to be NP-complete even for the path. Thus, we consider further restrictions and also provide an approximation scheme. Weshow that both problems are polynomial if the number of possible prices is constant. Even with this restriction, we showthat these problems are NP-complete on a tree graph. For the Min-Budget problem, we provide an FPTAS (fully-polynomial-time-approximation-scheme), that provides a (1 + (cid:2)) approximation for any (cid:2) > 0, in time O (poly(n(cid:2)−1)), where n is thesize of the input.For the multi-agent case, we first analyze a shared budget model, where all the resources and costs are shared amongall the agents. We show that if the number of agents is fixed, then all of the single-agent algorithms extend to k-agents,with the time bounds growing exponentially in k. Therefore the computation of the agents’ strategies can be performedwhenever the number of agents is relatively moderate, a common scenario in many physical environments where severalagents cooperate in exploration and search. If the number of agents is part of the input then the multi-agent versions ofMin-Budget and Max-Probability ar",
            {
                "entities": [
                    [
                        143,
                        196,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1570–1603Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintInconsistent heuristics in theory and practiceAriel Felner a,∗Zhifu Zhang c, Uzi Zahavi b, Robert Holte c, Jonathan Schaeffer c, Nathan Sturtevant c,a Department of Information Systems Engineering, Ben-Gurion University of the Negev, Beer-Sheva 85104, Israelb Department of Computer Science, Bar-Ilan University, Ramat-Gan 52900, Israelc Department of Computing Science, University of Alberta, Edmonton, Alberta, T6G2E8, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 26 July 2010Received in revised form 10 February 2011Accepted 10 February 2011Available online 18 February 2011Keywords:Heuristic searchAdmissible heuristicsInconsistent heuristics∗AIDA∗1. Introduction and overview.In the field of heuristic search it is usually assumed that admissible heuristics areconsistent,implying that consistency is a desirable attribute. The term “inconsistentheuristic” has, at times, been portrayed negatively, as something to be avoided. Part of thisis historical: early research discovered that inconsistency can lead to poor performance∗(nodes might be re-expanded many times). However, the issue has never been fullyfor A∗investigated, and was not re-considered after the invention of IDAThis paper shows that many of the preconceived notions about inconsistent heuristicsare outdated. The worst-case exponential time of inconsistent heuristics is shown to onlyoccur on contrived graphs with edge weights that are exponential in the size of the graph.Furthermore, the paper shows that rather than being something to be avoided, inconsistentheuristics often add a diversity of heuristic values into a search which can lead to areduction in the number of node expansions. Inconsistent heuristics are easy to create,contrary to the common perception in the AI literature. To demonstrate this, a number ofmethods for achieving effective inconsistent heuristics are presented.Pathmax is a way of propagating inconsistent heuristic values in the search from parentto children. This technique is generalized into bidirectional pathmax (BPMX) whichpropagates values from a parent to a child node, and vice versa. BPMX can be integrated∗. When inconsistent heuristics are used with BPMX, experimental resultsinto IDA. Positive results are alsoshow a large reduction in the search effort required by IDApresented for Asearches.and A∗∗∗© 2011 Elsevier B.V. All rights reserved.Heuristic search algorithms such as A[22] are guided by the cost function f (n) = g(n) + h(n), where g(n)is the cost of the current path from the start node to node n and h(n) is a heuristic function estimating the cost from n toa goal node. If h(n) is admissible (i.e., is always a lower bound) these algorithms are guaranteed to find optimal paths.∗[15] and IDA∗The Aalgorithm is guaranteed to return an optimal solution only if an admissible heuristic is used. There is no re-quirement that the heuristic be consistent.1 It is usually assumed that admissible heuristics are consistent. In their popularAI textbook Artificial Intelligence: A Modern Approach, Russell and Norvig write that “one has to work quite hard to concoct∗* Corresponding author.E-mail addresses: felner@bgu.ac.il (A. Felner), zahaviu@biu.ac.il (U. Zahavi), holte@cs.ualberta.ca (R. Holte), jonathan@cs.ualberta.ca (J. Schaeffer),nathanst@cs.ualberta.ca (N. Sturtevant), zhang@cs.ualberta.ca (Z. Zhang).1 A heuristic is consistent if for every two states x and y, h(x) (cid:2) c(x, y) + h( y) where c(x, y) is the cost of the shortest path between x and y. Derivationsand definitions of consistent and inconsistent heuristics are provided in Section 3.0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.02.001\fA. Felner et al. / Artificial Intelligence 175 (2011) 1570–16031571heuristics that are admissible but not consistent” [38]. Many researchers work under the assumption that “almost all admis-sible heuristics are consistent” [25]. Some algorithms require that the heuristic be consistent (such as Frontier A[30], whichsearches without the closed list).2 The term “inconsistent heuristic” has, at times, been portrayed negatively, as somethingthat should be avoided. Part of this is historical: early research discovered that inconsistency can lead to poor performance∗for A. However, the issue of inconsistent heuristics has never been fully investigated or re-considered after the invention of∗IDA. This paper argues that these perceptions about inconsistent heuristics are wrong. We show that inconsistent heuris-tics have many benefits. Further, they can be used in practice for many search domains. We observe that many recentlydeveloped heuristics are inconsistent.∗A known problem with inconsistent heuristics is that they may cause algorithms like Ato find shorter paths to nodesthat were previously expanded and inserted into the closed list. If this happens, then these nodes must be moved back tothe open list, where they might be chosen for expansion again. This phenomenon is known as node re-expansion. Awith aninconsistent heuristic may perform an exponential number of node re-expansions [32]. We present insights into this phe-nomenon, showing that the exponential time behavior only appears in contrived graphs where edge weights and heuristicvalues grow exponentially with the graph size. For IDA, it is important to note that node re-expansion is inevitable due tothe algorithm’s depth-first search. The use of an inconsistent heuristic does not exacerbate this. Because no history of pre-whether the heuristic is consistentvious searches is maintained, each separate path to the node will be examined by IDAor not.∗∗∗∗Inconsistent heuristics often add a diversity of heuristic values into a search. We show that these values can be used toescape heuristic depressions (regions of the search space with low heuristic values), and can lead to a large reduction in thesearch effort. Part of this is achieved by our generalization of pathmax into bidirectional pathmax. The idea of pathmax wasintroduced by Mero [34] as a method for propagating inconsistent values in the search from a parent node to its children.Pathmax causes the f -values of nodes to be monotonic non-decreasing along any path in the search tree. The pathmax ideafor undirected state spaces is generalized into bidirectional pathmax (BPMX). BPMX propagates values in a similar mannerto pathmax, but does this in both directions (parent to child, and child to parent). BPMX turns out to be more effective∗than pathmax in practice. It can easily be integrated into IDA. Using BPMX, thepropagation of inconsistent values allows a search to escape from heuristic depressions more quickly.and, with slightly more effort, into A∗Trivially, one can create an inconsistent heuristics by taking a consistent heuristic and degrading some of its values. Theresulting heuristic will be less informed. Contrary to the perception in the literature, informed inconsistent heuristics areeasy to create. General guidelines as well as a number of simple methods for creating effective inconsistent heuristics areprovided. The characteristics of inconsistent heuristics are analyzed to provide insights into how to effectively use them tofurther reduce the search effort.Finally, experimental results show that using inconsistent heuristics with BPMX yields a significant reduction in the-based search applications. The application domains used are the sliding-tile∗search effort required for many IDApuzzle, Pancake problem, Rubik’s cube, TopSpin and pathfinding in maps.∗- and AThe paper is organized as follows. In Section 2 we provide background material. Section 3 defines consistent and in-consistent heuristics. Section 4 presents a study of the behavior of Awith inconsistent heuristics. BPMX is introduced inSection 5 and its attributes when used with inconsistent heuristics are studied. Methods for creating inconsistent heuristicsare discussed in Section 6. Extensive experimental results for IDAare provided in Sections 7 and 8, respectively.Finally we provide our conclusions in Section 9.∗and for A∗∗Portions of this work have been previously published [14,21,44–47]. This paper summarizes this line of work and tiestogether all the results. In addition new experimental results are provided.2. Terminology and backgroundThis section presents terminology and background material used for this research.2.1. TerminologyThroughout the paper the following terminology is used. A state space is a graph whose vertices are called states. Theexecution of a search algorithm (e.g., A) from an initial state creates a search graph. A search tree spans that graphaccording to the progress of the search algorithm. The term node is used throughout this paper to refer to the nodes of thesearch tree. Each node in the search tree corresponds to some state in the state space. The search tree may contain nodesthat correspond to the same state (via different paths). These are called duplicates.∗and IDA∗The fundamental operation in a search algorithm is to expand a node (i.e., to compute or generate the node’s successorsin the search tree). We assume that each node expansion takes the same amount of time. This allows us to measure thetime complexity of the algorithms in terms of the total number of node expansions performed by the algorithm in solving∗2 The breadth-first heuristic search algorithm [49], a competitor to Frontier A, does not have this requirement and works with inconsistent heuristicstoo.\f1572A. Felner et al. / Artificial Intelligence 175 (2011) 1570–1603Fig. 1. 3 × 3 × 3 Rubik’s cube.a given problem.3 The space complexity of a search algorithm is measured in terms of the number of nodes that need tobe stored simultaneously.A second measure of interest is the number of unique states that are expanded at least once during the search. Thephrase num",
            {
                "entities": [
                    [
                        138,
                        184,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 214 (2014) 66–88Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLogical characterizations of regular equivalence in weighted social networks ✩Tuan-Fang Fan a, Churn-Jung Liau b,∗a Department of Computer Science and Information Engineering, National Penghu University of Science and Technology, Penghu 880, Taiwanb Institute of Information Science, Academia Sinica, Taipei 115, Taiwana r t i c l e i n f oa b s t r a c tArticle history:Received 4 August 2013Received in revised form 21 May 2014Accepted 24 May 2014Available online 28 May 2014Keywords:Weighted social networkMany-valued modal logicRegular equivalenceBisimulationReasoning under uncertainty or imprecisionSocial network analysis is a methodology used extensively in social science. Classical social networks can only represent the qualitative relationships between actors, but weighted social networks can describe the degrees of connection between actors. In a classical social network, regular equivalence is used to capture the similarity between actors based on their links to other actors. Specifically, two actors are deemed regularly equivalent if they are equally related to equivalent others. The definition of regular equivalence has been extended to weighted social networks in two ways. The first definition, called regular similarity, considers regular equivalence as an equivalence relation that commutes with the underlying graph edges; while the second definition, called generalized regular equivalence, is based on the notion of role assignment or coloring. A role assignment (resp. coloring) is a mapping from the set of actors to a set of roles (resp. colors). The mapping is regular if actors assigned to the same role have the same roles in their neighborhoods. Recently, it was shown that social positions based on regular equivalence can be syntactically expressed as well-formed formulas in a kind of modal logic. Thus, actors occupying the same social position based on regular equivalence will satisfy the same set of modal formulas. In this paper, we present analogous results for regular similarity and generalized regular equivalence based on many-valued modal logics.© 2014 Elsevier B.V. All rights reserved.1. IntroductionSocial network analysis (SNA) is a methodology used extensively in social and behavioral sciences, as well as in political science, economics, organization theory, and industrial engineering [58,34,64]. Positional analysis of a social network tries to find similarities between nodes in the network [6,9,25,45,65]. While many traditional clustering methods are based on the attributes of the individual nodes, SNA is more concerned with the structural similarity between the nodes. In SNA, a category, called a social role or social position, is defined in terms of the similarities of the patterns of relations between the nodes, rather than the attributes of the nodes. For example, one useful way to think about the social role “husband” is to consider it as a set of patterned interactions with a member or members of some other social categories, such as “wife” and “child” (and probably others) [34]. One of the most widely studied notions in the positional analysis of social networks is called regular equivalence [6,20,56,57]. According to Borgatti and Everett [6], two actors are regularly equivalent if they are equally related to equivalent others.✩This is a significantly extended version of [26].* Corresponding author.E-mail addresses: dffan@npu.edu.tw (T.-F. Fan), liaucj@iis.sinica.edu.tw (C.-J. Liau).http://dx.doi.org/10.1016/j.artint.2014.05.0070004-3702/© 2014 Elsevier B.V. All rights reserved.\fT.-F. Fan, C.-J. Liau / Artificial Intelligence 214 (2014) 66–8867Interestingly, Marx and Masush [51] showed that social positions based on regular equivalence can be syntactically expressed as well-formed formulas in a kind of modal logic. Thus, actors that have the same social position based on regular equivalence will satisfy the same set of modal formulas. Traditionally, modal logic has been considered the logic for reasoning about modalities, such as necessity, possibility, time, actions, beliefs, knowledge, and obligations. However, semantically, it is essentially a language for describing relational structures [3]. A relational structure is simply a collection of relations on a given universe; therefore, social networks can be represented by relational structures in mathematics. The logical characterization of social positions implies that modal formulas are semantically invariant with respect to regular equivalence.In recent years, weighted social networks have also received considerable attention because they can represent both the qualitative relationships and the degrees of connection between nodes [2,27,28,43,54,63]. The notion of regular equivalence is extended to weighted social networks based on two alternative definitions of regular equivalence [28]. While the two definitions are equivalent for ordinary networks, they induce different generalizations for weighted networks. The first generalization, called regular similarity, is based on the definition of regular equivalence as an equivalence relation that commutes with the underlying graph edges [9]. By the definition, regular similarity is a fuzzy relation that describes the degree of similarity between actors in the network. The second generalization, called generalized regular equivalence, is based on the definition of role assignment or coloring [45]. A role assignment (resp. coloring) is a mapping from the set of actors to a set of roles (resp. colors). The mapping is regular if actors assigned to the same role have the same roles in their neighborhoods. Consequently, generalized regular equivalence is an equivalence relation that can determine the role partition of actors in a weighted social network.Because of the importance of weighted social networks, we explore the logical characterizations of regular similarity and generalized regular equivalence. In this paper, we use many-valued modal logics to characterize the two kinds of relations. On one hand, we show that the truth values of many-valued modal logic formulas are invariant with respect to generalized regular equivalence. On the other hand, we demonstrate that the maximum regular similarity between any two actors is equal to the minimum equivalence between degrees of the two actors satisfying many-valued modal logic formulas.The remainder of this paper is organized as follows. In Section 2, we review some basic concepts about social networks, fuzzy relations, and positional analysis. In Sections 3 and 4, we present the logical characterizations of regular similar-ity and generalized regular equivalence respectively. In Section 5, we discuss issues related to further generalizations and applications of the logical characterizations. Section 6 contains our concluding remarks.2. Preliminaries2.1. Social networksSocial networks are defined by actors and relations (or nodes and edges in terms of graph theory) [34]. Generally, a social network is defined as a relational structure N = (U , (R i)i∈I ), where U is the set of nodes; I is an index set; and for each i ∈ I , R i ⊆ U ki is a ki -ary relation on the domain U , where ki is a positive integer. If ki = 1, then R i is called an attribute or a property. In practice, most SNA methods only consider a simplified version of a social network with binary relations. For ease of presentation, we focus on a social network with unary and/or binary relations. Thus, the social network considered in this paper is a structure N = (U , (P i)i∈I , (R j) j∈ J ), where the universe U is a finite set of actors; P i ⊆ U for all i ∈ I ; and R j ⊆ U × U for all j ∈ J . Although practical social networks are always concerned with finite sets of attributes and relations, our results do not rely on the finitary assumptions about attributes and relations. Therefore, we only assume that the set of actors is finite and do not impose additional restrictions on the index sets I and J . In terms of graph theory, N is a labeled graph, where U is a set of nodes labeled with subsets of I , and each R j denotes a set of (labeled) edges. For each x ∈ U , the out-neighborhood and in-neighborhood of x with respect to a binary relation R, denoted respectively by Rx and Rx, are defined as follows:−(cid:2)Rx =−Rx =y ∈ U(cid:2)y ∈ U(cid:4)(cid:3)(cid:3) (x, y) ∈ R,(cid:3)(cid:4)(cid:3) ( y, x) ∈ R.(1)(2)If E is an equivalence relation on U and x is an actor, the E-equivalence class of x is equal to its neighborhood, i.e., x. Note that the latter equality holds because of the symmetry of E. For any X ⊆ U , we use [ X]E to denote [x]E = Ex = Ethe set {[x]E | x ∈ X}.−Several equivalence relations have been proposed for exploring the structural similarity between actors. Among them, regular equivalence has been studied extensively [6,9,25,45,65]. Although there are several definitions of regular equivalence, we only consider two of them in this paper. The first, proposed by Boyd and Everett [9], states that an equivalence relation E is a regular equivalence with respect to a binary relation R if it commutes with R; i.e.,E · R = R · E,(3)where E · R = {(x, y) | ∃z ∈ U , (x, z) ∈ E ∧ (z, y) ∈ R} is the composition of E and R. By this definition, if E is a regular equivalence with respect to R and (x, y) ∈ E, then for each z ∈ Rx (resp. Ry) such (cid:7) ∈ R y (resp. Rx), there exists z−−\f68T.-F. Fan, C.-J. Liau / Artificial Intelligence 214 (2014) 66–88(cid:7)) ∈ E. The property leads naturally to the second definition of regular equivalence, which is based on role as-that (z, zsignment [45]. It states that an equivalence relation E is a regular equivalence with respect to a binary relation R if for x, y ∈ U ,(x, y) ∈ E ⇒(cid:5)[Rx]E = [R y]E and(cid:6)(cid:7)x−R(cid:6)−Ry(cid:7)(cid:8).E=E(4)According to this definition, if x and y are regularly ",
            {
                "entities": [
                    [
                        134,
                        210,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 319 (2023) 103918Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintThe first AI4TSP competition: Learning to solve stochastic routing problems ✩Yingqian Zhang a,∗,1, Laurens Bliek a,1, Paulo da Costa a,1, Reza Refaei Afshar a,1, Robbert Reijnen a,1, Tom Catshoek b,1, Daniël Vos b,1, Sicco Verwer b,1, Fynn Schmitt-Ulms c,2, André Hottung d,2, Tapan Shah e,2, Meinolf Sellmann f,2, Kevin Tierney d,2, Carl Perreault-Lafleur g,2, Caroline Leboeuf g,2, Federico Bobbio g,2, Justine Pepin g,2, Warley Almeida Silva g,2, Ricardo Gama h,2, Hugo L. Fernandes i,2, Martin Zaefferer l,2, Manuel López-Ibáñez j,2, Ekhine Irurozki k,2a Eindhoven University of Technology, Netherlandsb Delft University of Technology, Netherlandsc McGill University, Canadad Bielefeld University, Germanye General Electric, USAf InsideOpt, USAg Université de Montréal, Canadah Polytechnic Institute of Viseu, Portugali Rockets of Awesome, New York City, USAj University of Manchester, UKk Telecom Paris, Francel DHBW Ravensburg, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 25 January 2022Received in revised form 31 October 2022Accepted 31 March 2023Available online 3 April 2023Keywords:AI for TSP competitionTravelling salesman problemRouting problemStochastic combinatorial optimizationSurrogate-based optimizationDeep reinforcement learningThis paper reports on the first international competition on AI for the traveling salesman problem (TSP) at the International Joint Conference on Artificial Intelligence 2021 (IJCAI-21). The TSP is one of the classical combinatorial optimization problems, with many variants inspired by real-world applications. This first competition asked the participants to develop algorithms to solve an orienteering problem with stochastic weights and time windows (OPSWTW). It focused on two learning approaches: surrogate-based optimization and deep reinforcement learning. In this paper, we describe the problem, the competition setup, and the winning methods, and give an overview of the results. The winning methods described in this work have advanced the state-of-the-art in using AI for stochastic routing problems. Overall, by organizing this competition we have introduced routing problems as an interesting problem setting for AI researchers. The simulator of the problem has been made open-source and can be used by other researchers as a benchmark for new ✩This paper was submitted to the Competition Section of the journal.* Corresponding author.E-mail address: yqzhang@tue.nl (Y. Zhang).1 The organization team.2 The winning teams.https://doi.org/10.1016/j.artint.2023.1039180004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fY. Zhang, L. Bliek, P. da Costa et al.Artificial Intelligence 319 (2023) 103918learning-based methods. The instances and code for the competition are available at https://github .com /paulorocosta /ai -for-tsp -competition.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1. IntroductionMany real-world optimization problems are combinatorial optimization problems (COPs) with the objective to find an op-timal solution among a finite set of possible solutions. COPs are proven to be NP-Complete, thus solving them to optimality is computationally expensive and mostly impractical for large instances. COPs have been studied extensively in various re-search communities, including discrete mathematics, theoretical computer science, and operations research. An efficient way of finding acceptable solutions for COPs is through heuristic approaches. The time complexity of heuristics is mainly poly-nomial, although they may provide solutions that are far from optimal. Besides, these approaches must be redesigned if the problem assumption and settings are changed. Recent years have seen rapidly growing interest in using machine learning (ML) to dynamically learn heuristics and find close-to-optimal solutions for COPs [1]. Among COPs, routing problems such as the traveling salesman problem (TSP) are well-known, and they emerge in many real-life applications. The TSP has several variants that include uncertainty, making the problem challenging for traditional exact and heuristic algorithms. TSP and its variants are some of the most well-studied COPs in the ML literature. Previous works on deep neural network approaches for routing problems have focused on learning to construct good tours [2–13] and on learning to search for good solu-tions [14–27], leveraging supervised and deep reinforcement learning (DRL). Other approaches considered surrogate-based optimization (SBO) [28–33], using ML models to guide the search for good tours.In this competition, the participants solve a variant of TSP using ML methods. The selected variant of TSP contains stochastic weights, where the cost of traveling between two nodes is stochastic. Each node also has a prize, and collecting the prize depends on the arrival time of an agent. These assumptions make this variant of TSP similar to real-life problems. For example, in real life, the required time to travel from one city to another depends on road construction work and traffic jams. Moreover, visiting a location is usually assigned with time bounds that must be respected. To solve this problem variant, the participants must use one of two ML methods: SBO or DRL. Both of these methods have shown considerable promise in generating solutions for routing problems in previous works.We emphasize that the primary goal of this competition is to bring new surrogate-based and DRL-based approaches into practice for solving a difficult variant of TSP. This is done by attracting ML researchers and challenging them to solve this difficult routing problem. The solutions may be built upon existing work adapted for the particular TSP variant. Although some previous work has focused on prize collecting (orienteering) problems or stochastic weights, few researchers take the combination of these assumptions into account. This motivates us to establish a platform that provides the opportunity for AI researchers to develop SBO and DRL approaches for solving a well-known routing problem. As a byproduct, the competition provides several winning methods and a simulator for generating problem instances that researchers can use to benchmark their ML-based approaches. In summary, the objective of organizing this competition is threefold: (1) to introduce routing problems as an interesting problem setting for ML researchers; (2) to advance the state-of-the-art in using ML for routing problems; and (3) to provide a challenging problem and a simulator for researchers to benchmark their ML-based approaches.We divide the competition into two tracks, each requiring different knowledge from sub-fields of AI:• Track 1 (SBO): Given one instance, previously tried tours, and the total reward (sum of the prizes collected in a tour) for those tours, the goal is to learn a model predicting the reward for a new tour. Then an optimizer finds the tour that gives the best reward according to that model, and that tour is evaluated, giving a new data point. Then the model is updated, and this iterative procedure continues for a fixed number of steps. Over time, the model becomes more accurate, giving better and better tours. This procedure is used in SBO algorithms such as Bayesian optimization [34].• Track 2 (DRL): We consider an environment (simulator) that can generate a set of multiple instances I following the same generating distribution. We expect as output (partial) solutions containing the order in which the nodes should be visited. The environment returns general instance features and the stochastic travel time for traversing the last edge in a given solution. The goal is to maximize the prizes collected while respecting time-related constraints over multiple samples of selected test instances. This procedure is related to neural combinatorial optimization [4].The first competition, named the AI4TSP competition, was an IJCAI-21 (International Joint Conference on Artificial Intel-ligence) competition. It ran from May 27 to July 12, 2021, and was organized by the Delft University of Technology and the Eindhoven University of Technology. By the deadline of the final test phase, we had received four submissions in the SBO track and three submissions in the DRL track. The submissions are tested on up to 1, 000 problem instances with up to 200nodes, and the winners are determined by ranking the total quality of their solutions. The results of the competition have been officially announced in the Data Science Meets Optimization (DSO) workshop, which was co-located with IJCAI-21.2\fY. Zhang, L. Bliek, P. da Costa et al.Artificial Intelligence 319 (2023) 1039182. Problem description and methodologyBoth tracks look at the orienteering problem with stochastic weights and time windows (OPSWTW), which is a simplified version of the time-dependent OPSWTW [35]. This problem is similar to the traveling salesman problem (TSP), where nodes need to be visited while respecting a maximum tour time and opening and closing times of the nodes in order to maximize some measure of rewards. We detail the problem in the section below.2.1. OPSWTWIn the TSP, the goal is to find the tour with the smallest cost that visits all locations (customers) in a network exactly once. However, in practical applications, one rarely knows all the travel costs between locations precisely. Moreover, there could be specific time windows at which customers need to be served, and certain customers can be more valuable than others. Lastly, the salesman is often constrained by a maximum capacity or travel time, representing a limiting factor in the number of nod",
            {
                "entities": [
                    [
                        153,
                        228,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 95 ( 1997) 3 17-356 Artificial Intelligence Qualitative representation of positional information Eliseo Clementini ‘,*, Paolino Di Felice a,‘, Daniel Herntidez b,2 a Dip. di Ing. Elettrica, Universitd di L’Aquila, 67040 Poggio di Roio, Italy h Fakultiit ftir Informatik, Technische Universitiit Miinchen, 80290 Munich, Germany Received August 1996; revised March 1997 Abstract A framework for the qualitative representation of positional information in a two-dimensional space is presented. Qualitative representations use discrete quantity spaces, where a particular distinction is introduced only if it is relevant to the context being modeled. This allows us to build a flexible framework that accommodates various levels of granularity and scales of reasoning. Knowledge about position in large-scale space is commonly represented by a combination of orientation and distance relations, which we express in a particular frame of reference between a primary object and a reference object. While the representation of orientation comes out to be more straightforward, the model for distances requires that qualitative distance symbols be mapped to geometric intervals in order to be compared; this is done by defining structure relations that are able to handle, among others, order of magnitude relations; the frame of reference with its three components (distance system, scale, and type) captures the inherent context dependency of qualitative distances. The principal aim of the qualitative representation is to perform spatial reasoning: as a basic inference technique, algorithms for the composition of positional relations are developed with respect to same and different frames of reference. The model presented in this paper has potential applications in areas as diverse as Geographical Information Systems (GIS), Computer Aided Design (CAD), and Document Recognition. @ 1997 Elsevier Science B.V. Keywords: Spatial reasoning; Qualitative representation; Distance; Orientation; Position; Frame of reference 1. Introduction Qualitative the contrary, information it can be more efficient and provide more meaning is often mistaken to be vague or inexact, but it is not. On than pure quantitative author. Email: eliseo@ing.univaq.it. * Corresponding ’ Email: pdifelice@aquila.infn.it. 2 Email: danher@informatik.tu-muenchen.de. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved PIISOOO4-3702(97)00046-5 \f318 E. Clementini et ul. /Artificial Intelligence 95 (I 997) 317-356 saying that Alaska is 1.5 18.800km2 about size and distances in Alaska, but very to the spatial knowledge of the average that Alaska alone is bigger than all the states of the East coast is cognitively more immediate. Comparative information is the key in this example. Therefore, qualitative than quantitative ones and in most cases information from quantitative data, since the quality of things likely is sufficiently exact it is not listener. On the other from in a familiar answers arc often it is not obvious is to Florida For example, information in relation information. quantitative meaningful hand, saying Maine frame of reference cognitively more eloquent how to infer qualitative context-dependent. A qualitative answer is on purpose in a certain context and eliminates unnecessary limited uses a discrete quantity interest representation associated with it and for which qualitative 671. Qualitative to space, which spatial reasoning reasoning seems unlikely higher-dimensional Recent work [ 10, 11,3 11, The delay for spatial domains manipulations” in qualitative techniques that such inference spatial to the kind of distinctions that are of space which has normally arithmetic algebras have been devised details. Therefore, a qualitative a natural ordering [66, to scalar quantities and only recently rise to the subfield of qualitative of qualitative models and that “it full for tasks that require to the convincement in the development is partly due schemes will be useful [ 20, p. 4271. representations reasoning has been applied mainly is multidimensional in nature, giving application of quantity spaces in more than one dimension information In fact, several aspects of spatial general, the description of a scene of objects an expression both in terms of inherent characteristics of other objects. The inherent characteristics separations) and its extension topological, orientation, and distance are currently being investigated in space involves spatial aspects has made more evident can lead to promising that the results. [ 111. In that have of each object and in the context (holes and to other objects, of an object are its topology (size and shape), while, with respect relations have to be considered. representation of positional The aim of this study is the qualitative which is one of the basic cognitive spatial concepts and thus important domains of spatial knowledge. For objects their extension positional information has an obvious correspondence be expressed using polar coordinates: the radius and a reference axis. that can be modeled to the distances and distance is determined by the orientation in quantitative can be disregarded with respect terms, where positional the distance [ 151. This can from the origin and the angle between information information, in all application as points (because that are involved), relations from experience in other spatial domains Knowledge about locations in large-scale space are learned not only representations to be represented formats, which can be suitably modeled that spatial knowledge motoric experience of the domain, but also from symbolic and from facts inferred in space are likely sitional been suggested [ 8,301. People have too little short-term memory Therefore, relations. There are mainly Route knowledge two kinds of spatial knowledge: through senso- such as maps, [ 61. Thus, positions in a mixture of imaginal and propo- It has in the human mind to support a whole map “in the head”. features and route and survey knowledge. between and it is made up of order information in terms of qualitative concepts. from the representation is more elementary spatial knowledge is hierarchically in the mind is inferred organized of global \fE. Clementini et d/Artificial Intelligence 95 (1997) 317-356 319 of (relative landmarks lost when from getting as we intend and geocentric to distinguished it in this paper, and, thus, keeps people landmarks. Survey knowledge information, and distance of spatial knowledge distinguishes allocentric to coordinated from above” on a spatial situation. That (relative system of reference is more elaborate and has the characteristics is, it is independent route. Another common categorization (centered on observer), known of a particular a “view they leave order of visited be- a known reference tween egocentric frames) views structures), [ 301. Positional is survey knowledge made relations, which depending on scale can be egocentric, up of orientation and distance might depend on many other allocentric to express factors, frames of reference them in terms of isolated relations. We shall rather need to introduce studies to take into account [46]. For example, when someone show the existence of multiple to enter a local street emerges is also crucially network, dependent on scale. For example, the meaning of close in a statement “A is close to B” depends not only on the actual relative position of both objects but also their relative sizes and other scale-dependent from a subway there is a sudden change sizes, point of view, etc., so that it is not enough system or a driver gets off a highway in the frame of reference. Distance or geocentric. Both orientation internal and external factors. Furthermore, frames of reference like the objects’ cognitive factors. those In previous work, the qualitative description of space has been mostly linear rotation, [9,18,57]. independent of the objects and orientation of the position relations to common alone, being to provide a full description of a scene. Orientation rubber sheeting) involved to topological relations. Topological aspects of the scene which are invariant with respect (translation, characteristics relations sufficient objects are placed concepts: orientation as it is determined orientation useful scale environments relations the primary object, of the primary object by transformations and therefore provide a description of important topological in the scene However, and extension of objects, are not relations describe where in terms of three basic the frame of reference. The to the reference object and of topological that is mainly [ 3 1,601. For large- space, however, we must also consider distance to one another, and can be defined the reference object, and the frame of reference. The combination is then expressed with respect relations provides a restricted for describing positions. such as “the objects such as geographic form of positional in small-scale environments in a room” information relative framework and distance for orientation In this paper, we build a unified to a reference object. As mentioned to determine what we mean by, e.g., front relations. the position of a primary object by a pair of distance and orientation above, we introduce frames in the case of orientation, in the case of distance. 3 The they can i.e., We represent relations with respect of reference and the range of what we consider frames of reference are in general different be influenced means with spatial relations is, given “A, rI , B” and “B, t-2, C”, to find the relation “A, r3, C”. from what is already known. The basic step in reasoning for distance and orientation, since capabilities, factors. The framework to find new information to be close or far, by different reasoning features ’ In other words, the concept of distance varying with the scale of reasoning is embedded in the frame of reference. restricted are able to describe all \f320 E. C",
            {
                "entities": [
                    [
                        68,
                        120,
                        "TITLE"
                    ],
                    [
                        421,
                        473,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 434–439www.elsevier.com/locate/artintNo regrets about no-regretYu-Han ChangIntelligent Systems Division, USC Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, USAReceived 16 May 2006; received in revised form 26 October 2006; accepted 13 December 2006Available online 13 February 2007AbstractNo-regret is described as one framework that game theorists and computer scientists have converged upon for designing andevaluating multi-agent learning algorithms. However, Shoham, Powers, and Grenager also point out that the framework has seriousdeficiencies, such as behaving sub-optimally against certain reactive opponents. But all is not lost. With some simple modifications,regret-minimizing algorithms can perform in many of the ways we wish multi-agent learning algorithms to perform, providingsafety and adaptability against reactive opponents. We argue that the research community should have no regrets about no-regretmethods.© 2007 Elsevier B.V. All rights reserved.Keywords: Multi-agent learning; Regret-minimization; Game theory1. IntroductionTraditional no-regret algorithms sometimes perform sub-optimally because the regret criterion only compares thealgorithm’s performance to the possible alternate outcomes in the individual stage games of a repeated game, assumingthe opponent’s action stays fixed. For example, a typical no-regret agent playing Prisoner’s Dilemma would end upalways defecting, since this minimizes the algorithm’s regret relative to the other possible action of cooperating, giventhe observed sequence of opponent actions. However, it is relatively simple to extend standard no-regret approachesto handle and avoid these suboptimal cases. In fact, I would argue that such modified no-regret algorithms hold muchpromise for the future direction of multi-agent learning.Regret minimization methods, sometimes also referred to as experts algorithms or hedging algorithms, provide theclearest method for evaluating agent performance in general multi-agent settings. Since we would often like to assumethat the opponent in multi-agent learning problems is unknown, it is usually difficult to evaluate agent performance,which depends on the type of opponent the agent ends up playing against. Regret-minimization approaches circumventthis problem by defining performance in terms of a comparison class of possible strategies that the agent itself iscapable of executing. Thus, no assumptions need to be made about the opponent’s strategy. Furthermore, as Shohamet al. have stated, many regret-minimizing algorithms can also guarantee safety in addition to universal consistency.These benefits can be extended to the case where the agent faces reactive opponents as well. Instead of consideringsingle actions at each time step, our modified regret framework considers multi-period strategies by dividing up theE-mail address: ychang@ISI.EDU.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.12.007\fY.-H. Chang / Artificial Intelligence 171 (2007) 434–439435sequence of games into intervals. The regret criterion can now take into account reactive strategies such as “Tit-for-Tat”. Two issues arise from this setup: 1) an action’s potential reward can no longer be observed unless that action isactually played, since the reward depends on the opponent’s current reactive strategy, which cannot be observed, and2) computational complexity grows exponentially as we consider longer intervals and a larger set of more complexstrategies. The first issue can be resolved by using a no-regret algorithm such as Auer, Cesa-Bianchi, Freund, andSchapire’s EXP3 algorithm [1], which extends Freund and Schapire’s multiplicative weight algorithm [6] to the caseof partial information. We propose to alleviate the second issue by choosing the set of possible strategies carefully andby incorporating learning algorithms as experts in a modified version of the EXP3 algorithm [4].2. Mathematical backgroundFor most of this article, we will focus our attention on repeated games, though the techniques described can po-tentially be extended to stochastic games. The repeated game setting already captures much of the complexity of themulti-agent learning problem, where we need to focus on our ability to learn about and react to the opponent. In astochastic game, we also need to learn about and adapt to the external environment. Here we will focus on modelingthe states of the opponent and set aside the problem of additionally modeling the states of the external environment atthe same time.During each stage game of the repeated game, each player simultaneously chooses to play a particular actionai ∈ Ai and receives reward based on the joint action taken. We use the terms policy and strategy interchangeably.While Nash equilibrium is the accepted solution concept for a single stage game, in repeated game and stochastic gamesettings, modern game theory often takes a more general view of optimality, a view that has also gained acceptancein the machine learning community [3,5]. The key difference is the treatment of the history of actions taken in thegame. Here we define a behavioral strategy β : H → Ai , where H =t H t and H t is the set of all possible histories oflength t. Histories are observations of joint actions, ht = (ai, a−i, ht−1). For simplicity, we will assume A = A1 = A2.(cid:2)Definition 1. A τ -length behavioral strategy βτ : H τ → A is a mapping from the set of all possible histories H τ toactions a ∈ A. Let Bτ be the set of all possible τ -length behavioral strategies βτ .We note that |Bτ | = |A||A|2τ. In the case where we take H t = H , we could even consider learning algorithmsthemselves to be a possible “behavioral strategy” for playing a repeated game.This definition of our strategy space is clearly more powerful, and allows us to define a much larger set of potentialequilibria. However, when the opponent is not rational, it is no longer advantageous to find and play an equilibriumstrategy. In fact, given an arbitrary opponent, the Nash equilibrium strategy may return a lower payoff than some otheraction. Indeed, the payoff may be worse than the original Nash equilibrium value. Thus, we turn to regret minimizationalgorithms.2.1. Regret-minimizationIn repeated games, the standard regret minimization framework enables us to perform almost as well as the bestaction, if that single best action were played in every time period. We will frequently refer to the EXP3 algorithm (andits variants) explored by Auer et al. [1] as an example of this type of algorithm. In the original formulation of EXP3,we choose single actions to play, but we do not get to observe the rewards we would have received if we had chosendifferent actions.We need to be a bit more precise about the definition of regret here. Auer et al. consider an adversarial settingwhere the reward function is actually a sequence of reward functions that change at each time period. We denote thecumulative reward for executing an algorithm H for T time periods by RH , and this is compared with the cumulativereward the agent could have received had it chosen to execute a fixed action a for all T time periods, Rmax = maxa Ra.Since the algorithm H is randomized, we will be discussing expected regret Rmax − E[RH ]. The authors show thatT K ln K, where K is the number of actionthe performance of EXP3 exhibits an expected regret bound of 2choices, and T is the number of rounds we play the game. In situations where the rewards for all possible actions areobserved at each period, this upper bound on the expected regret can be reduced to O(T ln K ).e − 1√√√\f436Y.-H. Chang / Artificial Intelligence 171 (2007) 434–439Generally speaking, these regret-minimizing algorithms hedge between possible actions by keeping a weight foreach action that is updated according to the action’s historical performance. The probability of playing an action isthen its fraction of the total weights mixed with the uniform distribution. Intuitively, better experts perform better, getassigned higher weight, and are played more often. Sometimes these algorithms are called experts algorithms, since wecan think of the actions as being recommended by a set of experts. This set is also referred to as our comparison class.This comparison class provides a clear means of evaluating our algorithm’s performance by pegging this evaluationmetric on a set of strategies and assumptions that we know how to execute.It is important to note that most of these existing methods only compare our performance against strategies that arebest responses to what are often called oblivious or myopic opponents. That is, the opponent does not learn or react toour actions, instead playing a pre-selected, but possibly arbitrary, fixed string of actions. Under most circumstances,however, we might expect an intelligent opponent to change their strategy as they observe our own sequence of plays.For example, consider the game of repeated Prisoner’s Dilemma. If we follow the oblivious opponent assumption,then the best choice of action on hindsight would always be to defect, since we’re assuming that the oblivious opponentwill not change his next action in response to our defection. This approach would assign low scores (high regret) tocooperative strategies, and thus miss out on the chance to earn higher rewards by cooperating with opponents such asa Tit-for-Tat opponent, which cooperates with us as long as we also cooperate. These opponents can be called reactiveopponents.Our extension of the regret framework deals with reactive opponents by expanding our comparison class of strate-gies to include reactive, or behavioral, strategies. Now, instead of only comparing against the best action from thestage game assuming that the opponent’s action stays fixed, we can also compare our performance against strategiessuch as “Tit-for-Tat” with the assumption that the opponent chooses i",
            {
                "entities": [
                    [
                        72,
                        98,
                        "TITLE"
                    ],
                    [
                        959,
                        985,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 225 (2015) 51–76Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn redundant topological constraintsSanjiang Li a,b,∗a Centre for Quantum Computation & Intelligent Systems, University of Technology Sydney, Sydney, Australiab Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, Chinac Baidu (China) Co., Ltd., Shanghai, Chinad Department of Infrastructure Engineering, University of Melbourne, Melbourne, Australia, Zhiguo Long a, Weiming Liu c, Matt Duckham d, Alan Both da r t i c l e i n f oa b s t r a c tArticle history:Received 13 May 2014Received in revised form 26 March 2015Accepted 29 March 2015Available online 2 April 2015Keywords:Qualitative spatial reasoningRegion connection calculusRedundancyPrime subnetworkDistributive subalgebraRedundancy checking is an important task in the research of knowledge representation and reasoning. In this paper, we consider redundant qualitative constraints. For a set (cid:2)of qualitative constraints, we say a constraint (xR y) in (cid:2) is redundant if it is entailed by the rest of (cid:2). A prime subnetwork of (cid:2) is a subset of (cid:2) which contains no redundant constraints and has the same solution set as (cid:2). It is natural to ask how to compute such a prime subnetwork, and when it is unique. We show that this problem is in general intractable, but becomes tractable if (cid:2) is over a tractable subalgebra S of a qualitative calculus. Furthermore, if S is a subalgebra of the Region Connection Calculus RCC8 in which weak composition distributes over nonempty intersections, then (cid:2) has a unique prime subnetwork, which can be obtained in cubic time by removing all redundant constraints simultaneously from (cid:2). As a by-product, we show that any path-consistent network over such a distributive subalgebra is minimal and globally consistent in a qualitative sense. A thorough empirical analysis of the prime subnetwork upon real geographical data sets demonstrates the approach is able to identify significantly more redundant constraints than previously proposed algorithms, especially in constraint networks with larger proportions of partial overlap relations.© 2015 Elsevier B.V. All rights reserved.1. IntroductionQualitative spatial reasoning is a common subfield of artificial intelligence and geographical information science, and has applications ranging from natural language understanding [13], robot navigation [46], geographic information systems (GISs) [18], sea navigation [54], to high level interpretation of video data [48].Typically, the qualitative approach represents spatial information by introducing a relation model on a domain of spatial entities, which could be points, line segments, rectangles, or arbitrary regions. In the literature, such a relation model is often called a qualitative calculus [34]. In the past three decades, dozens of spatial (as well as temporal) qualitative calculi have been proposed in the literature (cf. [11]). Among these, Interval Algebra (IA) [1] and the RCC8 algebra [41] are widely known as the most influential qualitative calculi for representing qualitative temporal and, respectively, spatial information. Other well-known qualitative calculi include Point Algebra (PA) [51], Cardinal Relation Algebra (CRA) [33], Rectangle Algebra (RA) [24], the RCC5 algebra [41], etc.* Corresponding author at: Centre for Quantum Computation & Intelligent Systems, University of Technology Sydney, Sydney, Australia.(M. Duckham), aboth@student.unimelb.edu.au (A. Both).E-mail addresses: sanjiang.li@uts.edu.au (S. Li), zhiguo.long@student.uts.edu.au (Z. Long), liuweiming@baidu.com (W. Liu), matt@duckham.orghttp://dx.doi.org/10.1016/j.artint.2015.03.0100004-3702/© 2015 Elsevier B.V. All rights reserved.\f52S. Li et al. / Artificial Intelligence 225 (2015) 51–76Using a qualitative calculus M, we represent spatial or temporal information in terms of relations in M, and formulate a spatial or temporal problem as a set of qualitative constraints (called a qualitative constraint network). A qualitative constraint has the form (xR y), which specifies that the two variables x, y are related by the relation R. The consistency problemis to decide whether a set of qualitative constraints can be satisfied simultaneously. The consistency problem has been investigated in depth for many qualitative calculi in the literature, see e.g., [51,50,33,40,39,43,42,14,55,37,28,35,45,30].In this paper, we consider the important problem of redundant qualitative constraints. Given a set (cid:2) of qualitative constraints, we say a constraint (xR y) in (cid:2) is redundant if it is entailed by the rest of (cid:2), i.e., removing (xR y) from (cid:2) will not change the solution set of (cid:2). It is natural to ask when a network contains redundant constraints and how to get a non-redundant subset without changing the solution set. We call a subset of (cid:2) a prime subnetwork of (cid:2) if it contains no redundant constraints and has the same solution set as (cid:2).The redundancy problem (i.e., the problem of determining if a constraint is redundant in a network) is related to the minimal label problem (cf. [38,8,20,36,3]). A qualitative constraint network (cid:2) is called minimal if for each constraint (xR y)in (cid:2), R is the minimal (i.e., the strongest) relation between x, y that is entailed by (cid:2). Roughly speaking, the minimal network removes ‘redundant’ or ‘unnecessary’ basic relations from each constraint, while the redundancy problem removes ‘redundant’ or ‘unnecessary’ constraints from the constraint network.We show in this paper that it is in general co-NP hard to determine if a constraint is redundant in a qualitative constraint network. But if all constraints in (cid:2) are taken from a tractable subclass1 S then a prime subnetwork can be found in poly-nomial time. For example, if S is a tractable subclass of RCC5 or RCC8 that contains all basic relations, then we can find a prime subnetwork in O (n5) time. Furthermore, if S is a subalgebra of RCC5 or RCC8 in which weak composition distributes over nonempty intersections, then (cid:2) has a unique prime subnetwork, which is obtained by removing all redundant con-straints from (cid:2). We also devise a cubic time algorithm for computing this unique prime subnetwork, which has the same time complexity as the two approximate algorithms of Wallgrün [52].As a by-product, we identify an important class of subalgebras of qualitative calculi, called distributive subalgebras. A sub-algebra D of a qualitative calculus M is called distributive if weak composition distributes over nonempty intersections in D. We show that any path-consistent network over a distributive subalgebra is weakly globally consistent and minimal, where weakly global consistency is a notion similar to but weaker than the well-known notion of global consistency (cf. Definition 5). For RCC8, we identify two maximal distributive subalgebras which are not contained in any other distributive subalgebras, one contains 41 relations and the other contains 64. The 41 relations contained in the first subalgebra are exactly the convex RCC8 relations identified in [8].In this paper, we are mainly interested in topological constraints, as these are the most important kind of qualitative spatial information. A large part of our results can easily be transplanted to other qualitative calculi like PA, IA, CRA and RA. In particular, let M be one of PA, IA, CRA and RA and S a distributive subalgebra of M over which path-consistency implies consistency. Then we can show that any path-consistent network over S is globally consistent and minimal.2 For ease of presentation, we state and prove these results only for RCC5 and RCC8, but indicate in Table 5 which result is applicable to which calculus.1.1. MotivationAs in the case of propositional logic formulas [32], redundancy of qualitative constraints “often leads to unnecessary computation, wasted storage, and may obscure the structure of the problem” [5].3 Finding a prime subnetwork can be useful in at least the following aspects: a) computing and storing the relationships between spatial objects and hence saving space for storage and communication; b) facilitating comparison (or measure the distance) between different constraint networks; c) unveiling the essential network structure of a network (e.g., being a tree or a graph with a bounded tree-width); and d) adjusting geometrical objects to meet topological constraints [52].To further motivate our discussion, we focus on one specific application to illustrate the application area a. and briefly explain how redundancy checking or finding a prime subnetwork helps to solve the application areas b–d.Fig. 1 gives a small example of a set of spatial regions formed by the geographic “footprints” associated with placenames in the Southampton area of the UK. The footprints are derived from crowd-sourced data, formed from the convex hull of the sets of coordinate locations at which individuals used the placenames on social media (cf. [25]). Communicating and reasoning with the qualitative aspects of such data may require the storage and manipulation of large numbers of complex geometries with millions of vertices or large constraint networks with millions of relations.Even for the small example in Fig. 1, the 84 footprints then require 84 ∗ 83/2 = 3486 stored relations. The moderate-sized footprint data set from which Fig. 1 is adapted contains a total of 3443 footprints which leads to a constraint network with 5,925,403 relations. Similarly, a moderate-sized geographic data set of only 1559 statistical areas in Tasmania, explored further in later sections, contains in total 3,093,551 vertices. In the case of both footprints and statistical areas, many of the relationships can be inferred, and computing the prime subnetwork can potentially reduce the number of",
            {
                "entities": [
                    [
                        134,
                        170,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 248 (2017) 46–84Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCommonsense reasoning about containers using radically incomplete informationErnest Davis a,∗a Computer Science Dept., New York University, 251 Mercer St., New York, NY 10012, USAb Psychology and Neural Science Depts., New York University, New York, NY 10012, USAc College of Arts and Science, New York University, New York, NY 10012, USA, Gary Marcus b, Noah Frazier-Logue ca r t i c l e i n f oa b s t r a c tArticle history:Received 3 January 2016Received in revised form 30 January 2017Accepted 29 March 2017Available online 4 April 2017Keywords:Commonsense reasoningPhysical reasoningSpatial reasoningContainersIn physical reasoning, humans are often able to carry out useful reasoning based on radically incomplete information. One physical domain that is ubiquitous both in everyday interactions and in many kinds of scientific applications, where reasoning from incomplete information is very common, is the interaction of containers and their contents. We have developed a preliminary knowledge base for qualitative reasoning about containers, expressed in a sorted first-order language of time, geometry, objects, histories, and actions. We have demonstrated that the knowledge suffices to justify a number of commonsense physical inferences, based on very incomplete knowledge.© 2017 Elsevier B.V. All rights reserved.1. Physical reasoning based on radically incomplete informationIn physical reasoning, humans, unlike programs for scientific computation, are often able to carry out useful reasoning based on radically incomplete information. If AI systems are to achieve human levels of reasoning, they must likewise have this ability. The challenges of radically incomplete information are often far beyond the scope of existing automated reasoners based on simulation [11]; rather they require alternative reasoning techniques specifically designed for incomplete information.As a vivid example, consider the human capacity to reason about containers — boxes, bottles, cups, pails, bags, and so on — and the interactions of containers with their contents. For instance, you can reason that you can carry groceries in a grocery bag and that they will remain in the bag with only very weak specifications of the shape and material of the groceries being carried, the shape and material of the bag, and the trajectory of motion. Containers are ubiquitous in everyday life, and children start to learn how containers work at a very early age [21] (Fig. 1).1Containers likewise are central in a wide range of applications and domains.2 For example, in a separate study we have recently begun of the reasoning needed to understand a biology textbook [36], we find that physical containers of many different kinds and scales appear in domains relevant to biology. Some examples:* Corresponding author.E-mail addresses: davise@cs.nyu.edu (E. Davis), gary.marcus@nyu.edu (G. Marcus), N.Frazier.logue@nyu.edu (N. Frazier-Logue).1 Ironically, the working of a baby bottle nipple is beyond the scope of this paper.2 Containment is also often used metaphorically. For instance, Lakoff and Johnson [25] and Reddy [35] discuss the use of containment as a metaphor for the relation between a linguistic expression and its meaning; e.g. “Your argument has no content”. Similarly, in the context of computers, the relation between a memory location such as a variable and its value is often conceptualized as containment.http://dx.doi.org/10.1016/j.artint.2017.03.0040004-3702/© 2017 Elsevier B.V. All rights reserved.\fE. Davis et al. / Artificial Intelligence 248 (2017) 46–8447Fig. 1. Infant learning about containers.Fig. 2. A lake divides into two lakes when the water level falls.• The membrane of a cell is a container that holds the contents of the cell. Many of the primary processes in the cell are concerned with bringing material into the container and expelling material from the container.• The skin or other outer layer of an animal is a container for the animal. Again, many of the central life processes — eating, breathing, excreting — deal with transporting material into and out of the container.• In a discussion of speciation (p. 493), it is mentioned that a subpopulations of a water creature can be isolated if the water level of a lake falls, dividing it into two lakes. Here the container is the lake bed, and the phenomenon depends on the somewhat non-obvious fact that a liquid container that bounds a single connected region at one level may bound two regions at a lower level (Fig. 2).In this paper we describe the initial stages of development of a knowledge-based system for reasoning about manipu-lating containers, in which knowledge of geometry and physics and problem specifications are represented by propositions. Below, we outline the system, and show that this approach suffices to justify a number of commonsense physical infer-ences, based on very incomplete knowledge of the situation and of the dynamic laws that govern the objects involved. These inferences have been automatically verified using the first-order theorem prover SPASS [42].1.1. Incomplete informationThe issues of complete and incomplete information can easily be misunderstood, so let us make clear what we have in mind. Of course, few representations are truly complete or entirely precise; in virtually any representation, some aspects are omitted, some are simplified, and some are approximated. However, techniques such as simulation, or STRIPS-like represen-tations, require that the initial conditions of the scenario and that the dynamics of the microworld be fully specified relative to a given level of description. That is, the representational framework specifies some number of critical relations between entities and properties of entities. A complete representation of a situation relative to that framework enumerates all the entities that are relevant to the situation, and specifies all the relations in the framework that hold between those entities. The description must be detailed and precise enough that the situation at the next time step is likewise fully specified, in the same sense.For instance, the standard blocks world representation omits the size, shape, and physical characteristics of the blocks involved, and the trajectory of the actions. Situations are describe purely in terms of the predicate On(t,x,y) (object x is on object y at time t) and actions are described in terms of Puton(t,x,y) (the agent puts object x onto y at time t). However, the dynamic theory is a complete account at this level of description; that is, a complete enumeration of the On relations that hold in one situation completely determines what actions are feasible, and determines all the On relations that will hold once the action is executed. Additionally, most projection and most planning problems provide a complete enumeration of the On relations that hold in the initial situation.By contrast, in the theory that we develop in this paper, both general domain axioms and problem specifications may give full specifications of some of the features involve, but leave others partially specified or wholly unspecified. For instance, inference 1 (section 8) specifies that initially object Ox1 is inside box Ob1, but it does not specify whether or not there are any other objects inside Ob1 nor does it specify whether Ox1 is in contact with box Ob1, nor does it specify the spatial relation of the agent to either of these. The physical laws given specify that if the agent drops an object that it is holding, \f48E. Davis et al. / Artificial Intelligence 248 (2017) 46–84the object will end up in a stable state, but the theory does not in general specify where it will end up, or where it will pass through while it is falling, or how it might impact other objects. The theory does support the inference that if it is inside an open container when dropped, it will remain inside the container, and not come into contact with any object outside the container. Some necessary conditions and some sufficient conditions are given for the feasibility of the agent being able to move from a starting to an ending positions are given, but the necessary conditions are much weaker than the sufficient conditions; in many cases, it is indeterminate.2. ContainersWe begin with a general discussion of the properties of containers as encountered in everyday situations and of the characteristics of commonsense reasoning about containers.A container can be made of a wide range of materials, such as rigid materials, paper, cloth, animal body parts, or combinations of these. The only requirement is that the material should maintain its shape to a sufficient degree that holes do not open up through which the contents can escape. Under some circumstances, there can even be a container whose bottom boundary is a liquid; for instance, an insect can be trapped in a region formed by the water in a basin and an upside-down cup. A container can also have a wide range of shapes (precise geometric conditions for different kinds of containers are given in section 6.1).The material of the contents of a container is even less constrained. In the case of a closed container, the only constraint is that the material of the contents cannot penetrate or be absorbed into the material of the container (e.g. you cannot carry water in a paper bag or carry light in a cardboard box); and that the contents cannot destroy the material of the container (you cannot keep a gorilla in a balsa wood cage). Using an open container requires additionally that the contents cannot fly out the top [8]. Using a container with holes requires that the contents cannot fit or squeeze through the holes.Those are all the constraints. In the case of a closed container, the material of the contents can be practically anything with practically any kind of dynamics. For i",
            {
                "entities": [
                    [
                        134,
                        211,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 406–416www.elsevier.com/locate/artintWhat evolutionary game theory tells us about multiagent learningKarl Tuyls a,∗, Simon Parsons ba Institute for Knowledge and Agent Technology, Maastricht University, The Netherlandsb Department of Computer and Information Science, Brooklyn College, City University of New York, 2900 Bedford Avenue, Brooklyn,11210 NY, USAReceived 1 May 2006; received in revised form 8 January 2007; accepted 9 January 2007Available online 26 January 2007AbstractThis paper discusses If multi-agent learning is the answer, what is the question? [Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Intelligence 171 (7) (2007) 365–377, this issue] from the perspectiveof evolutionary game theory. We briefly discuss the concepts of evolutionary game theory, and examine the main conclusions from[Y. Shoham, R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Intelligence 171 (7)(2007) 365–377, this issue] with respect to some of our previous work. Overall we find much to agree with, concluding, however,that the central concerns of multiagent learning are rather narrow compared with the broad variety of work identified in [Y. Shoham,R. Powers, T. Grenager, If multi-agent learning is the answer, what is the question? Artificial Inteligence 171 (7) (2007) 365–377,this issue].© 2007 Elsevier B.V. All rights reserved.Keywords: Evolutionary game theory; Replicator dynamics; Multiagent learning1. IntroductionIn If multi-agent learning is the answer, what is the question? by Shoham, Powers and Grenager [20], the authorsmake a valiant effort to analyse the state of the field of multiagent learning, to summarise the results that have beenachieved within the field, to discern the major research directions that have been followed, and to issue a call to arms.In short, Shoham et al. conclude that most work in multiagent learning can be placed into one of five “buckets” eachof which is associated with a distinct research agenda (these descriptions are taken directly from the “caricatures” inSection 5 of [20]):(1) Computational: learning algorithms are a way to compute the properties of a game.(2) Descriptive: learning algorithms describe how natural agents learn in the context of other learners.(3) Normative: learning algorithms give a means to determine which sets of learning rules are in equilibrium withone another.(4) Prescriptive, cooperative: learning algorithms describe how agents should learn in order to achieve distributedcontrol of dynamic systems.(5) Prescriptive, non-cooperative: learning algorithms describe how agents should act to obtain high rewards.* Corresponding author.E-mail addresses: k.tuyls@micc.unimaas.nl (K. Tuyls), parsons@sci.brooklyn.cuny.edu (S. Parsons).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.01.004\fK. Tuyls, S. Parsons / Artificial Intelligence 171 (2007) 406–416407In addition [20]:Not all work in the field falls into one of these buckets. This means that either we need more buckets, or some workneeds to be revisited or reconstructed so as to be well-grounded.The authors also point out that research in multiagent learning is often unclear about which of these agendas it ispursuing—and that, in contrast one needs to be very clear about one’s aims—that the field cannot progress by defining“arbitrary learning strategies and analys(ing) whether the resulting dynamics converge in certain cases to a Nashequilibrium or some other solution concept”, and that the field needs to take evaluation more seriously, especially onsome set of standard problems.We basically agree with all of the points that we have quoted above, and below will expand on those that wefeel our background leaves us best qualified to discuss. However, we do have one major point of disagreement withthe views expressed in [20]. The point we disagree with is the idea that there is some overall taxonomy of researchagendas into which all work can be slotted. This is not explicitly stated—all that Shoham et al. say is what we quotedabove, that there are five distinct agendas to which some additional ones may need to be added—but the existence ofan underlying taxonomy into which these additional categories can be slotted seems to be implied.Our objection is neatly summarised by the following passage from McWhorter’s The Power of Babel: A naturalhistory of language [15] in which the author tries to express how the original language, spoken by our commonancestors, became the many thousands of languages that descended from it. He starts by saying “I have implied thatspeech varieties have developed like a bush, starting from a single sprout and branching in all directions, each branchthen developing subbranches, and so on . . . ” before going on to explain that the inter-relationships between languages,the constant process of adoption of terms from one language into another, and the formation of dialects, creoles andintertwined languages means that [15, page 94]:we might do just as well with another analogy, say stewing a good spring lamb stew without much juice (becausethe juice messes up the analogy). Clearly, one can distinguish the lamb from the peas from the potatoes from thecarrots from the leeks from the rosemary leaves. Yet all of these ingredients, if it’s a good stew, are suffused withjuice and flavor from the other items as well. Every now and then, you even encounter a piece of something that,covered with liquid and cooked out of its original shape and consistency, you have to work to figure out the originalidentity of . . . Overall, there is nothing in this stew that tastes or even looks like it would if you had just dumped itinto a pot of boiling water by itself.It seems to us that multiagent learning is such a stew and though it is very helpful to identify the variousingredients—especially if, to stretch the metaphor, some of them would be better taken out of the pot—to concentrateon the constituents misses some of the essence. It is the places in which the agendas that make up the stew meldinto new things, things that cannot be put into a taxonomy because they are a mixture, that we often find the mostinteresting work.1That said, we should reiterate that we are largely in agreement with the agendas identified in [20], and in the nextsection amplify our agreement by examining all five agendas through the lens of evolutionary game theory (EGT),which is an area of multiagent learning in which we have been working, and one that is not much discussed in [20].Following that exploration, we return to our point about the interplay between agendas, illustrating our discussionwith some of our recent work.2. The five research agendas from the perspective of evolutionary game theoryIn this section we will use EGT to illustrate our reaction to the analysis of multiagent learning presented in [20]. Todo this, we first consider what each of the five research agendas means in terms of EGT, taking them in the order thatbest fits our argument, rather than the order in which they are presented by Shoham et al.1 Though one has to be especially careful to be clear what one is doing at these junctures.\f408K. Tuyls, S. Parsons / Artificial Intelligence 171 (2007) 406–4162.1. Normative and descriptive agendasOur view of EGT is that it represents a move away from the normative agenda (in the terms of [20]) and towards thedescriptive agenda. In particular, as summarised by [6], recent years have seen an important shift in game theory awayfrom classical solution concepts such as Nash equilibrium, and towards EGT solution concepts such as the evolutionarystable strategy2 (ESS) and the replicator equations. The obvious reasons for this are that the Nash equilibrium is hardto compute, often does not describe the best way to behave, both in terms of optimality and stability, and is not ableto deal with highly dynamic situations. EGT [8,10,13,19] suffers less from these problems, and in our opinion, thedescriptive approach that it embodies matches the overall goals of multiagent learning much better than the normativeapproach that is the preserve of traditional game theory (GT). In the subsequent sections we will explain the basis forthese beliefs.2.1.1. From game theory to evolutionary game theoryWhen John Maynard-Smith applied game theory to biology [13,14], and thus invented evolutionary game theory,he relaxed the premises behind GT. Classical GT is a normative theory, in the sense that it expects players or agentsto be perfectly rational and behave accordingly [24,27,29]. In classical game theory, interactions between rationalagents are modelled as games of two or more players that can choose from a set of strategies and the correspondingpreferences. Game theory is thus the mathematical study of interactive decision making in the sense that the agentsinvolved in the decisions take into account their own choices and those of others. Choices are determined by stablepreferences concerning the outcomes of their possible decisions, and strategic interaction whereby agents take intoaccount the relation between their own choices and the decisions of other agents.Players in the classical setting have a perfect knowledge of the environment and the payoff tables, and try tomaximise their individual payoff. However, under the biological circumstances considered by Maynard-Smith, itbecomes impossible to judge what choices are the most rational. Instead of figuring out, a priori, how to optimise itsactions, the question now facing a player becomes how to learn to optimise its behaviour and maximise its return,and it does this based on local knowledge and through a process of trial and error. This learning process matches theconcept of evolution in biology, and forms the basis of EGT. In contrast to classical GT, then, EGT is a descriptivetheory, describing this process of l",
            {
                "entities": [
                    [
                        72,
                        136,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1369–1406Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintKernel functions for case-based planningIvan SerinaFree University of Bozen-Bolzano, Viale Ratisbona, 16, I-39042 Bressanone, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 5 September 2008Received in revised form 14 July 2010Accepted 16 July 2010Available online 30 July 2010Keywords:Case-based planningDomain-independent planningCase-based reasoningHeuristic search for planningKernel functionsCase-based planning can take advantage of former problem-solving experiences by storingin a plan library previously generated plans that can be reused to solve similar planningproblems in the future. Although comparative worst-case complexity analyses of plangeneration and reuse techniques reveal that it is not possible to achieve provable efficiencygain of reuse over generation, we show that the case-based planning approach can be aneffective alternative to plan generation when similar reuse candidates can be chosen.In this paper we describe an innovative case-based planning system, called OAKplan,which can efficiently retrieve planning cases from plan libraries containing more than tenthousand cases, choose heuristically a suitable candidate and adapt it to provide a goodquality solution plan which is similar to the one retrieved from the case library.Given a planning problem we encode it as a compact graph structure, that we callPlanning Encoding Graph, which gives us a detailed description of the topology of theplanning problem. By using this graph representation, we examine an approximate retrievalprocedure based on kernel functions that effectively match planning instances, achievingextremely good performance in standard benchmark domains.The experimental results point out the effect of the case base size and the importanceof accurate matching functions for global system performance. Overall, we show thatOAKplan is competitive with state-of-the-art plan generation systems in terms of numberof problems solved, CPU time, plan difference values and plan quality when cases similarto the current planning problem are available in the plan library.© 2010 Elsevier B.V. All rights reserved.1. IntroductionPlanning is a process which usually involves the use of a lot of resources. The efficiency of planning systems can beimproved by avoiding repeating the planning effort whenever it is not strictly necessary. For example this can be donewhen the specification of the goals undergoes a variation during plan execution or execution time failures turn up: it isthen advisable to change the existing plan rather than replanning from scratch. One might even think of basing the wholeplanning process on the modification of plans, a procedure also known as planning from second principles [47]. In fact thismethod does not generate a plan from scratch, but aims at exploiting the knowledge contained in plans that were generatedbefore. The current problem instance Π is thus employed to search for a plan in a library that, maybe after a number ofchanges, might turn out useful to solve Π .In Case-Based Planning (CBP), previously generated plans are stored as cases in memory and can be reused to solvesimilar planning problems in the future. CBP can save considerable time over planning from scratch, thus offering a po-tential (heuristic) mechanism for handling intractable problems. Similarly to other Case-Based Reasoning (CBR) systems,CBP is based on two assumptions on the nature of the world [38]. The first assumption is that the world is regular: sim-E-mail address: ivan.serina@unibz.it.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.07.007\f1370I. Serina / Artificial Intelligence 174 (2010) 1369–1406ilar problems have similar solutions; as a consequence, solutions for similar problems are a useful starting point for newproblem-solving. The second assumption is that the types of problems an agent encounters tend to recur; hence futureproblems are likely to be similar to current problems.Different case-based planners differ on how they store cases, how they adapt a solution to a new problem, whether theyuse one or more cases for building a new solution or not, etc. [58]. From a theoretical point of view, in the worst case,adapting an existing plan to solve a new problem is not more efficient than a complete regeneration of the plan [47]. More-over finding a good reuse candidate in a plan library may be already very expensive, because it leads to more computationalcosts than those that can be saved by reusing the candidate. In fact, the retrieval of a good plan from a library of plansrepresents a serious bottleneck for plan reuse in domain independent case-based planning systems. This happens becausethe problem of defining the best matching among the objects of two planning problems is NP-hard.In this paper we present some data structures and new matching functions that efficiently address the problem ofmatching planning instances, which is NP-hard in the general case. These functions lead to a new case-based plannercalled OAKplan (acronym of Object Assignment Kernel case-based planner), which is competitive with state of the art plangeneration systems when sufficiently similar reuse candidates can be chosen.Following the formalisation proposed by Liberatore [39], a planning case is a pair (cid:2)Π0, π0(cid:3), where Π0 is a planningproblem and π0 is a plan for it, while a plan library is a set of cases {(cid:2)Πi, πi(cid:3) | 1 (cid:2) i (cid:2) m}. Our approach is based on acompact graph representation which uses the initial and goal facts in order to define a detailed description of the topologyof the planning problem examined. On the basis of this graph representation we use ideas from different research areas. Inparticular a lot of work has been done in molecular biology to analyse efficiently chemical databases which typically containthousands of molecules encoded as graphs. Similarly to the rascal system [51], we use graph degree sequences [55] in orderto filter out unpromising planning cases and reduce the set Cds = {(cid:2)Πi, πi(cid:3)} of cases that have to be examined accuratelyup to a suitable number.1Following Nebel and Koehler’s formalisation of matching functions [47], we examine the problem of defining a matchbetween the objects of the current planning problem and those of the selected planning cases. Since an exact matchingevaluation is infeasible from a computational point of view even for a limited number of candidate cases [47], we developan approximate evaluation based on kernel functions [56] to define a match among the objects of the planning problemsconsidered. Our kernel functions are inspired by Fröhlich et al.’s work [19–21] on kernel functions for molecular structures,where a kernel function can be thought of as a special similarity measure that can be defined among arbitrarily structuredobjects, like vectors, strings, trees or graphs [35,65]. The computational attractiveness of kernel methods comes from thefact that they can be applied in high-dimensional feature spaces without suffering the high cost of explicitly computing themapped data [56].In contrast to other CBP approaches that define exact matching functions among the objects of Π0 and those of theplan library whose computation requires exponential time [29,34,47], our kernel functions can compute in polynomial timean approximate matching function for each element of the set Cds; this matching function can choose a subset of thecandidate plans efficiently for the successive plan evaluation phase. These plans are evaluated accurately through a simulatedexecution that determines the capacity of a plan πi to solve the current planning problem. This phase is performed byexecuting πi and evaluating the presence of inconsistencies corresponding to the unsupported preconditions of the actionsof πi ; in the same way the presence of unsupported goals is identified. The best plan is then adapted, if necessary, in orderto be applicable to the current initial state and solve the current goals. This phase is based on the lpg-adapt system [16]which has shown excellent performance in many domains. When the adaptation phase is concluded, a new planning casecorresponding to the current planning problem and its solution plan can be inserted into the library or can be discarded.OAKplan can efficiently retrieve planning cases from plan libraries with more than ten thousand elements, heuristicallychoose a suitable candidate, possibly the best one, and adapt it to provide a good quality solution plan similar to the oneretrieved from the case base. We hope that this work will be able to renew interest in the case-based planning approach.Current research in planning has been devoted primarily to generative planning since no effective retrieval functions wereavailable in the past. To the best of our knowledge this is the first case-based planner that performs an efficient domain in-dependent objects matching evaluation. We examine it in comparison with state of the art plan generation systems showingthat the case-based planning approach can be an effective alternative to plan generation when “sufficiently similar” reusecandidates can be chosen. This is a major improvement on previous approaches on CBP which can only handle small planlibraries (see Section 5) and can hardly be compared with plan generation systems.The paper is organised as follows. Section 2 introduces the essential notions required by the paper. In particular weexpose the notion of union of graphs which is fundamental for the definition of the graphs used by our matching functionsand we introduce the basic concepts of kernel functions. Section 3 presents the main phases of our case-based plannerexamining the different steps required by the Retrieval and Evaluation phases in detail. In Section 4 a detailed analysis ",
            {
                "entities": [
                    [
                        138,
                        178,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 305 (2022) 103682Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSensitive loss: Improving accuracy and fairness of face representations with discrimination-aware deep learningIgnacio Serna a,∗a School of Engineering, Universidad Autonoma de Madrid, Spainb Center for Humans & Machines, Max Planck Institute for Human Development, Berlin, Germany, Aythami Morales a, Julian Fierrez a, Nick Obradovich ba r t i c l e i n f oa b s t r a c tArticle history:Received 8 October 2020Received in revised form 27 January 2022Accepted 8 February 2022Available online 14 February 2022Keywords:Machine behaviorBiasFairnessDiscriminationMachine learningLearning representationsFaceBiometricsWe propose a discrimination-aware learning method to improve both the accuracy and fairness of biased face recognition algorithms. The most popular face recognition benchmarks assume a distribution of subjects without paying much attention to their demographic attributes. In this work, we perform a comprehensive discrimination-aware experimentation of deep learning-based face recognition. We also propose a notational framework for algorithmic discrimination with application to face biometrics. The experiments include three popular face recognition models and three public databases composed of 64,000 identities from different demographic groups characterized by sex and ethnicity. We experimentally show that learning processes based on the most used face databases have led to popular pre-trained deep face models that present evidence of strong algorithmic discrimination. Finally, we propose a discrimination-aware learning method, Sensitive Loss, based on the popular triplet loss function and a sensitive triplet generator. Our approach works as an add-on to pre-trained networks and is used to improve their performance in terms of average accuracy and fairness. The method shows results comparable to state-of-the-art de-biasing networks and represents a step forward to prevent discriminatory automatic systems.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionArtificial Intelligence (AI) is developed to meet human needs that can be represented in the form of objectives. To this end, the most popular machine learning algorithms are designed to minimize a loss function that defines the cost of wrong solutions over a pool of samples. This is a simple but very successful scheme that has enhanced the performance of AI in many fields, such as Computer Vision, Speech Technologies, and Natural Language Processing. But this optimization of specific computable objectives may not lead to the behavior one may expect or desire from AI. International agencies, academia, and industry are alerting policymakers and the public to the unforeseen effects and behaviors of AI agents, not initially considered during the design phases [1]. In this context, aspects such as trustworthiness and fairness should be included as learning objectives and not taken for granted. (See Fig. 1.)Machine vision in general and face recognition algorithms, in particular, are good examples of recent advances in AI [3–6]. The performance of automatic face recognition has been boosted during the last decade, achieving very competitive * Corresponding author.E-mail addresses: ignacio.serna@uam.es (I. Serna), aythami.morales@uam.es (A. Morales), julian.fierrez@uam.es (J. Fierrez), obradovich@mpib-berlin.mpg.de (N. Obradovich).https://doi.org/10.1016/j.artint.2022.1036820004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fI. Serna, A. Morales, J. Fierrez et al.Artificial Intelligence 305 (2022) 103682Fig. 1. The objective of the learning process is an abstraction of the expected behavior of an AI. There is usually no direct path between the machine expected behavior and the machine behavior, which is normally evaluated in terms of its utility. Learning objectives are usually determined by factors such as task, data, algorithms, and experimental protocols, losing sight of key aspects of the expected behavior such as fairness. Figure inspired by the standard model proposed in [2].accuracies in the most challenging scenarios [7]. These improvements have been made possible due to advances in machine learning (e.g., deep learning), powerful computation (e.g., GPUs), and larger databases (e.g., on a scale of millions of images). However, recognition accuracy is not the only aspect to be considered when designing biometric systems. There is currently a growing need to study AI behavior in order to better understand its impact on our society [1]. Face recognition systems are especially sensitive due to the personal information present in face images (e.g., identity, sex, ethnicity, and age). The number of published works pointing out the potential discriminatory effects in the results of face detection and recognition algorithms is large [8–17].In this environment, only a limited number of works analyze how biases affect the learning process of algorithms dealing with personal information [18,19]. There is a lack of understanding regarding how demographic information affects popular and widely used pre-trained AI models beyond their performance.On the other hand, the right to non-discrimination is deeply rooted in the normative framework that underlies various national and international regulations, and can be found, for example, in Article 7 of the Universal Declaration of Human Rights and Article 14 of the European Convention on Human Rights, among others. As evidence of these concerns, the European Parliament passed the General Data Protection Regulation (GDPR)1 in April 2018, a set of laws aimed at regulating the collection, storage, and use of personal information. According to paragraph 71 of GDPR, controllers of sensitive data processing, have to “implement appropriate technical and organizational measures” that “prevent, inter alia, discriminatory effects”.The aim of this work is to analyze face recognition models using a discrimination-aware perspective and to demonstrate that learning processes involving such a discrimination-aware perspective can be used to train more accurate and fairer algorithms. The main contributions of this work are:• A comprehensive analysis of the causes and effects of biased learning processes, including: (i) discrimination-aware performance analysis based on three public datasets, with 64K identities equally distributed across demographic groups; (ii) study of deep representations and the role of sensitive attributes such as sex and ethnicity; (iii) complete analysis of demographic diversity present in some of the most popular face databases, and analysis of new databases available to train models based on diversity.• Based on our analysis of the causes and effects of biased learning algorithms, we propose an efficient discrimination-aware learning method to mitigate bias in deep face recognition models: Sensitive Loss. The method is based on the inclusion of demographic information in the popular triplet loss representation learning. Sensitive Loss incorporates fairness as a learning objective in the training process of the algorithm. The method works as an add-on that is applied over pre-trained representations to improve their performance and fairness without requiring a complete re-training. We evaluated the method in three public databases, showing an improvement in both overall accuracy and fairness. Our results show how to incorporate discrimination-aware learning rules to significantly reduce bias in deep learning models.Preliminary work in this research line was presented in [20]. Key improvements here over [20] include: (i) in-depth anal-ysis of the state-of-the-art, including an extensive survey of face recognition databases; (ii) inclusion of two new datasets in 1 EU 2016/679 (General Data Protection Regulation). Available online at: https://gdpr-info .eu/.2\fI. Serna, A. Morales, J. Fierrez et al.Artificial Intelligence 305 (2022) 103682Fig. 2. Face recognition block diagrams. The screener is an algorithm that given two face images decides if they belong to the same person. The trainer is an algorithm that generates the best data representation for the screener.the experiments involving 40,000 new identities and more than 1M images; and (iii) a novel discrimination-aware learning method called Sensitive Loss.The rest of the paper is structured as follows: Section 2 summarizes the related work. Section 3 presents our general formulation of algorithmic discrimination. Section 4 presents the proposed discrimination-aware learning method. Section 5describes the evaluation procedure. Section 6 presents the experimental results. Finally, Section 7 summarizes the main conclusions.2. Related work2.1. Face recognition: methodsA face recognition algorithm, like other machine learning systems, can be divided into two different algorithms: screener and trainer. Both algorithms are used for different purposes. [21].∗The screener takes the characteristics of an individual and returns a prediction of that individual’s outcome, while the trainer produces the screener itself. In our case, the screener (see Fig. 2) is an algorithm that, given two face images, generates an output associated with the probability that they belong to the same person. This probability is obtained by comparing the two learned representations from a face model defined by the parameters w. These parameters are previously trained from a given dataset D (see Fig. 2). If properly trained, the output of the trainer would be a model with parameters w, capable of representing the input data (e.g., face images) in a highly discriminant feature space x.The most popular architecture used to mode",
            {
                "entities": [
                    [
                        135,
                        246,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 92 (1997) 25-89 Artificial Intelligence Clause trees: a tool for understanding and implementing resolution in automated reasoning J.D. Horton *, Bruce Spencer ’ University of New Brunswick, Fredericron, New Brunswick, Cunada E3B 5A3 Received July 1995; revised November 1996 Abstract structure, is developed in first order for automated A new methodology/data the clause logic. A clause tree, tree T on a set S of clauses reasoning is a 4-tuple based on resolution (N, E, L, M), where N is a set of nodes, divided into clause nodes and atom nodes, E is a set of edges, each of which joins a clause node to an atom node, L is a labeling of N U E which assigns to each clause node a clause of S, to each atom node an instance of an atom of some clause of S, and to each edge either + or - . The edge joining a clause node to an atom node is labeled by the sign of the corresponding two atom literals. The merge of two identical nodes of different clause trees which represent complementary atom nodes into the set M literals is represented by placing leaf, while the head remains of chosen merge paths. The tail of the merge path becomes a closed an open leaf which can be resolved on. The clause cl(T) is the set of literals to the labels of the open leaves modified by the signs of the incident edges. The corresponding fundamental from S using resolution. literal in the clause. A resolution that cl(T) can be derived is represented by unifying the two corresponding purpose of a clause tree T is to show that T represents the path joining Loveland’s model elimination ME, the selected literal procedure SL, and Shostak’s graph trees. The condition procedure GC are explained construction required for choosing a merge path whose head is not a leaf is given. This allows a clause tree to be built in one way (the build ordering) but justified as a proof in a unified manner using clause The ordered clause set restriction trees of merge path on clause ideas from ME, GC and Spencer’s ordered clause set restriction tighter than any of the top down procedures above, and the foothold score restriction reversal. A new procedure in another (the proof ordering). the are explained using called ALPOC, which (OC), to form a new is developed and shown to be sound operation combines procedure and complete. * Corresponding author. E-mail: jdh@unb.ca. ’ E-mail: bspence@unb.ca. 0004-3702/97/$17.00 PII SOOO4-3702(96)00046-X 0 1997 Elsevier Science B.V. All rights reserved \f26 J.D. Horton, B. Spencer/Artificial Intelligence 92 (1997) 25-89 clause tree. Any non-minimal Another operation on clause trees called surgery that non-minima1 clause trees are redundant. A sound procedure MinALPOC clause thereby showing produces only minima1 clause trees is given. Mergeless clause trees are shown to be equivalent each of input resolution, unit resolution some known results. Many other new proof procedures using clause leaving many open questions. 0 1997 Elsevier Science B.V. to define a minima1 to a minima1 clause tree using surgery, that to thereby giving short proofs of trees are discussed briefly, and relative Horn sets, tree can be reduced is defined, and used Keywords: Automated theorem proving; Redundancy; Minimality; Proof procedures 1. Introduction reasoning is the disjunction that one wants using binary resolution. Starting over a set of literals, one applies the that one the result is usually is found. This clause the most common method starts by negating for a contradiction. In this paper a clause is represented This paper is concerned with automated the clause with a set of clauses, each of which to them until resolution empty clause, because wants to prove, and then looking in graph by a tree to atom nodes each of which connected labeling clause, a or -a, which atom node an atom node can correspond the clause node. Fig. terms. An theory input clause is represented is labeled by an atom. However to either a positive or negative by a clause node the atom a in the the the clause literal the edge joining is indicated by a + or - to shows -d}. Such a tree is called a clause tree. l(a) sign labeling tree the representing {a, 6, -c, literals the clause (a, b, -c, resolution. For example Clauses can be combined using trees also can be resolved, the from two different clauses, as shown -d} -d, e, -g] upon b to form the new clause {a, -c, that identifying leaf nodes in Fig. l(b). The tree are the literals of the resulting clause. But two of the leaves the union of -d the two atom nodes to the same literal can be joined with a merge path as in Fig. l(c). The to be a literal of the can resolve with the clause {-b, e, -g}. Clause -4 represent complementary leaves of the resulting are labeled by -d. The merging of the two literals two sets occurs, is not handled automatically that correspond literal at the corresponding tail of a merge path clause. by clause trees. Instead that occurs when considered longer is no by (a) (b) Fig. 1. Example clause trees. \fJ.D. Horton, B. Spencer/Artificial intelligence 92 (1997) 25-89 27 la, b, cl \\ la, 4, dl / \\ / \\ / la, c, 4 \\ \\ l-a, dJ / / /c. dl (4 la, 4, 4 \\ \\ \\ I I-a, 4 / / I-b, di \\ /a, b. cl / ;. c, d; @I Fig. 2. Two different results from resolutions on the same clauses. In ordinary resolution with clauses represented by sets, the order in which a sequence of resolutions is done can have a significant impact on the result. For example suppose we have the clauses {a, b, c), {a, -6, d}, and {-a, d}. Resolving between the first two clauses on b produces {a, c, d}, and then resolving the result with the third clause on a produces {c, d}. See Fig. 2(a). However, if we begin by resolving between the second and third clause on a producing {-b, dj and then resolve with the first clause on b, we obtain the inferior result {a, c, d). See Fig. 2(b). Fig. 3 shows the same sequences of resolutions as Fig. 2, but using clause trees instead of sets to represent the clauses. Leaves with the same label are merged as soon as they are connected by a path. However the tree on the bottom of Fig. 3(b) can be improved by choosing a merge path from the open leaf labeled u to the internal node with the same label. Thus the inferior result is improved to yield a clause tree whose clause is {c, d}. If clause trees are used it does not matter in which order the resolutions b \\ / b +d A \\ a+- a \\ ‘h, / a+ +c -T t / b \\ \\ / / +c a+ -?-- t b Fig. 3. Clause trees from Fig. 2. \f28 J.D. Horton, B. Spencer/Artijicinl Intelligence 92 (1997) 25-89 are done, as the resulting corresponds to two different clause tree can be made the same. Hence the clause tree searches. between in which the clause is presented how clause trees distinguish Fig. 3 illustrates in an ordinary tree is constructed the order the resolution proof ( proof ordering), and the resolutions must be performed tree (build ordering). The final clause in which order the build ordering of Fig. 3(b) but is justified by the proof ordering could be built using in Section 3.1 where we present a way of Fig. 3(a). A more general example procedure, ME, in which the proof ordering of looking at the (weak) model elimination are required is different of the procedure. with ancestor clauses, as would be required In a manner similar These ancestor resolutions in build to MESON literal SL ordering. These procedure [29] respectively. Using clause trees, it is easily seen that GC is a restriction of a variant of SL, and that SL is a restriction of ME. In the proof ordering no resolutions in the usual justification [16] and Shostak’s graph construction GC procedure in Sections 3.3 and 3.4 to the selected [21], ancestor merges correspond to the insertion of merge paths are replaced by merges ideas are extended the build ordering. in proof ordering. from Section 4 develops the new concepts of visibility and support, which are relations between nodes of clause trees. The results of this paper rest on these relations. Section 5 shows that merge paths between nodes can be reversed, and that this does not essentially change relation. the visibility the foothold score restriction It also adapts the ordered clause set restriction [32] to clause [30,31] and trees. proof procedures its result more general. As shown A theorem prover can take advantage of the internal nodes of a clause basic ways. It can improve a proof, making an internal merge path can be chosen, resolution-based that tautologies be avoided. Since a clause tree represents detect if any one of those proofs contains a tautology or misses an opportunity literals. The operation clause tautologies hence tree that subsumes surgery cannot be applied are said to be minimal. tree in two in Fig. 3, to remove a literal. But more can be done. Most that merges be done wherever possible and several distinct proofs, we can to merge these internal tree, and to which and unused merges by cutting out some branches of the clause trees finds a smaller clause in Section 6, removes tree surgery, defined the original. Clause require Section 7 introduces ALP and AllPaths, trees. Using clause arises by reordering instance, each of these procedures clause set restriction. Moreover, avoided. As a stronger ALPOC produces only minimal trees, a theorem prover can avoid building steps, and so can avoid the resolution for building top down procedures clause tree that searching. For in Section 7 can be further restricted by the ordered can also be the procedure Min- tree that contains redundant the same clause redundant a tautology search, any clause example of avoiding clause trees. clause clause trees without merge paths, and shows Section 8 investigates clauses admits a mergeless refutation, that is a relative Horn set that is unsatisfiable. Although three concepts are equivalent, concept provide examples of using clause reasoning with resolution. that a set of if it admits an input if and only if it admits a unit refutation, and if and only if it contains a",
            {
                "entities": [
                    [
                        73,
                        162,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 81 ( 1996) 273-295 Artificial Intelligence Critical behavior in the computational cost of satisfiability testing Bart Selman ay l, Scott Kirkpatrickb*c*2 a AT&T Bell Laboratories, Murray Hill, NJ 07974, USA h IBM Thomas J. Watson Research Centeer; Yorktown Heights, NY 10598, USA ’ Racah Institute of Physics and Center for Neural Computation, Hebrew UniversityS Jerusalem, 91904 Israel Received July 1994; revised April 1995 Abstract finite-size scaling, a method In previous work, we employed from statistical mechanics, to explore the crossover from the SAT regime of k-SAT, where almost all randomly generated expressions are satisfiable, to the UNSAT regime, where almost all are not. In this work, we extend the experiments to cover critical behavior in the computational cost. We find that the median computational cost takes on a universal form across the transition regime. Finite-size scaling accounts for its dependence on N (the number of variables) and on M (the number of clauses in the IE-CNF expression). We also inquire into the sources of the complexity by studying distributions of computational cost. In the SAT phase we observe an unusually wide range of costs. The median cost increases linearly with N, while the mean is significantly increased over the median by a small fraction of large costs are incurred. We show that the large spread in cost of cases in which exponentially finding assignments is mainly due to the variability of running time of the Davis-Putnam (DP) procedure, used to determine the satisfiability of our expressions. In particular, if we consider a single satisfiable expression and run DP many times, each time randomly relabelling the variables in the expression, the resulting distribution of costs nearly reproduces the distribution of costs encountered by running DP search once on each of many such randomly generated satisfiable expressions. There are intriguing similarities and differences between these effects and kinetic phenomena studied in statistical physics, in glasses and in spin glasses. Keywords: Dynamical critical phenomena; Phase transition; Finite-size scaling; Satisfiability; k-satisfiability; Computational cost scaling; Complexity ’ E-mail: selman@research.att.com. 2 Corresponding author. E-mail: kirk@watson.ibm.com. 0004-3702/96/.$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDlOOO4-3702(95)00056-9 \fB. Selman, S. KirkpatrickIArtijicial Intelligence 81 (1996) 273-295 Fig. 1. (a) Threshold for random 3-SAT. (b) Resealed data with a, = 4.17 and v = 1.5. (c) 4-SAT data resealed with cu, = 9.25 and Y = 1.25 (from Kirkpatrick and Selman [ 161). 1. Introduction In [ 161, we considered threshold phenomena occurring in randomly generated Boolean expressions, and showed that the threshold has characteristics typical of a phase tran- sition in the statistical mechanics of disordered materials. The problem considered is a classic, usually called “k-satisfiability” or k-SAT. (See [22] for some history.) The expressions considered in R-SAT are Boolean formulas, generated at random in conjunc- tive normal form (CNF), that is as the AND of M “clauses”, with each clause the OR of k Boolean variables, and each variable selected at random from a set of N variables. Each variable selected is negated with 50 per cent probability. The ratio (Y = M/N determines what fraction of the randomly generated formulas is satisfiable. At low ratios, almost all formulas are satisfiable, whereas at high ratios almost all formulas are unsatisfiable [ 6,20,22]. Fig. 1 (a) shows the threshold function for 3-SAT. The curves are determined empirically. Note that the threshold sharpens up for higher values of N, which is characteristic of threshold phenomena in general. Threshold functions in combinatorics have been introduced as surfaces in some pa- rameter spaces which separate different behaviors. For example, Bollob&s [2] showed that for the random graph ensemble with N vertices and M edges, as long as M-N/2 > or < AN213 \fB. Selman, S. Kirkpatrick/Artificial Intelligence 81 (I 996) 273-295 215 I I Resealed 3SAT data I I L,@ N=12 N=20 N=24 N=40 o + 0 x 1 I 0 I I 1 I 2 I 3 I 4 I 5 6 Resealed 4SAT data 1 I ,.UO’. # : o N=12 N=24 + N = 50 -o- x N=65 0.6 -2 -1 I 1 0.9 0.6 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 -2 -1 0 1 2 3 4 5 6 Fig. I -continued. \f276 B. Selman, S. Kirkpatrick/Artificial Intelligence 81 (1996) 273-295 for any A, then almost every graph in the ensemble is (>) connected over O(N) vertices, or ( <) disconnected into finite clusters. The threshold function AN2j3 captures precisely the changing scale over which phase-transition-like effects occur as N increases. In terms of the ratio, CY = M/N, this range narrows as N-‘j3. In time, A came to be used to parameterize the critical region itself, by setting AN2j3 equal to M-N/2. See especially Spencer [ 251 or Janson et al. [ 131, who succeeded in calculating many details of distributions of functions induced on the random graph ensemble in terms of A. Note that we can express A in terms of the other quantities as A = N”3(cr - l/2). In the k-SAT problem, N is the number of Boolean variables, and M is the number of clauses (each the OR of k randomly selected variables) in a CNF expression. An ensemble of randomly generated expressions results when LY = M/N is held constant. We similarly define a scale-invariant parameter, y, which measures distance from the threshold in a way which becomes independent of N for sufficiently large N, or suf- ficiently close to the threshold. (See [ 171, for a derivation.) We plot all nonsingular quantities measured experimentally against y = N”“(a - (Y~)/cu,, where I, and (Ye are constants. In [ 161, we used this resealing approach to identify an invariant function characterizing the crossover from almost always satisfiable to almost always unsatisfiable at finite N. F( M, N), the fraction of expressions which are unsatisfiable, was reduced to a function of y alone. While the invariant function depends approaches the limiting in detail on k for k = 2, 3 or 4, for larger values of k, f(y) form (first obtained by Troyansky), f(y) = em*-‘. Figs. 1 (b) and 1 (c) give the universal form f(y) resulting from resealing data for 3- SAT and 4-SAT. Note that in our resealing approach, the exponent ( l/y) and the critical ratio a, must be determined empirically and are subject to uncertainty about how much of the data we should try to fit, especially when the computations are costly and N cannot be very large. We have normalized by CY, in order to permit the comparison of models with different thresholds, e.g., different k. The threshold phenomenon in k-SAT is of particular interest because the computa- tionally hardest instances cluster in the transition region. Mitchell et al. [22] consider the median cost of determining satisfiability as a function of the ratio (Y. They observe an easy-hard-easy pattern. For (random) formulas with LY well below or well above the threshold it is relatively easy to determine satisfiability. Around the threshold the cost increases dramatically. Thus, when plotting the median computational cost, one obtains a curve that peaks around the threshold. The peak sharpens up for higher values of N. Mitchell et al. [22] were unable to determine the mean cost accurately, hence their concentration on the median. See [4] for closely related work on random graph problems. \fB. Selman, S. Kirkpatrick/Art$cial Intelligence 81 (1996) 273-295 277 In the first part of this paper, we will show that finite-size scaling can be used to identify a universal form for the median computational cost in the transition re- gion. This means that our resealing approach again captures the changing scale in the phase-transition-like area in K-SAT, and may thus also be useful in characterizing the dependency on N of other properties at or near the phase transition in combinatorial problems. In the second part of the paper, we will study the distribution of the com- putational cost in more detail. First, we will show that below the threshold, one can find formulas that appear to be extremely hard. This is consistent with results reported by Hogg and Williams [ 111 for coloring random graphs and by Gent and Walsh [ 91 for variable-clause-length random SAT problems. However, we find that the supposedly hard instances are easily solved after a simple renaming of the variables. The appar- ent hardness of such instances thus appears due to interaction between our systematic backtrack-style satisfiability procedure and our random instances. (See [ 11 for closely related observations.) In a further experiments, we will show that the distribution of computational costs for a random sample of different formulas is almost identical to the distribution of computational costs of running many times on the same formula, each time with its variables randomly relabelled. Our results imply that for any formula below the threshold there are random relabellings that appear to make the formula very hard, and that any two such formulas behave very similarly when solved several times under random relabellings. Given the existence of relabellings that lead to relatively small computational costs, it also follows that there can be a dramatic payoff in the parallel execution of a systematic search procedure on multiple random relabellings of a problem instance. For related work on parallel approaches to solving instances in the phase transition area, see Hogg and Williams [ 121. 2. Determining satisfiability We used the Davis-Putnam [ 71 to determine the satisfiability of expressions. DP is typical of depth-first recursive search algorithms employed in solving combinatorial problems. The procedure consist of the following steps. Consider an expression consisting of a set of clauses 2 defined over a set of variables V. (DP) procedure l If 2 is empty, return “satisfiable”. l If _Z contains an empty clause, return “unsatisfiable",
            {
                "entities": [
                    [
                        76,
                        145,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 79 ( 1995) 241-292 Artificial Intelligence Performance of linear-space search algorithms * Weixiong Zhang *, Richard E. Korf Computer Science Department, Universiry of California at Los Angeles, Los Angeles, CA 90024, USA Received December 1992: revised June 1994 Abstract space linear Search that use algorithms (DFBnB), iterative-deepening tree T( b, d) that has mean branching in the search depth are widely employed such as planning and scheduling. search algorithms, that are the sum of the costs of the edges from the root to the nodes. We prove in practice In this paper, we study to solve difficult problems optimally, including depth-first branch-and- the average-case performance of linear-space (ID), and recursive best-first search (RBFS). To facilitate bound factor b, depth d, and node our analyses, we use a random that the costs expected number of nodes expanded by DFBnB on a random tree is no more than bd times the expected number of nodes expanded by best-first search (BFS) on the same tree, which usually in depth d. We also show that DFBnB is asymptotically optimal requires space that is exponential time, and ID and RBFS are asymptotically optimal when the edge when BFS runs in exponential If bpo is the expected number of children of a node whose costs costs of T( b,d) are integers. are the same as that of their parent, three then the expected number of nodes expanded by these is exponential when bpo < 1, at most 0( d4) when bpo = 1, and at most linear-space algorithms factor of T( b, d) and the quadratic when bpo > 1. In addition, we study the heuristic branching factor of BFS, DFBnB, ID, and RBFS on T( b, d). Furthermore, we use our effective branching analytic and to in the performance predict in the Asymmetric Traveling Salesman Problem. to explain a surprising anomaly the existence of a complexity of these algorithms, transition results 1. Introduction and overview Search is a fundamental problem-solving technique. In this paper, we study search algorithms that are widely used in practice for problem solving. In particular, we are *This research was supported by NSF Grant, #IRI-9 119825, and a grant from Rockwell second author, and partially by a GTE Graduate Fellowship Year Fellowship * Corresponding 1001. Marina de1 Rey, CA 90292, USA. Telephone: author. Current address: USC/Information to the first author. (310)822-1511. ( 1993-94) Sciences E-mail: zhang@isi.edu. ( 1992-93) and a UCLA Chancellor’s Dissertation International to the Institute, 4676 Admiralty Way, Suite 0004-3702/95/$X)9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDlOOO4-3702(94)00047-6 \f242 initial state goal state pI#FlJ (a) initial and goal states (b) Searching for the goal state Pig. I. An Eight Puzzle example. in those algorithms linear-space interested we call are the algorithms problems and-bound, paper is to understand when they are employed [ II]. The known iterative-deepening, of choice algorithms. Linear-space for algorithms that use space that is linear in the search depth, which they are important because such as the NP-hard include depth-first branch- and recursive best-first search. The primary goal of this algorithms large and difficult problems, search algorithms time complexity of these linear-space linear-space the average-case to solve difficult problems optimally. 1.1. Search problems We start by discussing two search problems, the sliding-tile puzzles, which have been intelligence, used extensively as example problems in operations Traveling Salesman Problem, which problems and model we will use and the search algorithms we will analyze. in artificial is ubiquitous are used as benchmarks for our experiments, and the (Asymmetric) research. These two the analytic to introduce We first present the problems themselves, can be solved. Operators are used to decompose if the original one cannot be solved directly. The lower-bound cost functions, their most effective operators, and the most and then briefly describe into cost functions a problem lower-bound used or most efficient commonly how these problems subproblems are used to guide a search algorithm. 1.1. I. Sliding-tile puules A square sliding-tile puzzle consists of a k x k frame holding k2 - 1 distinct movable tiles, and a blank space (see Fig. 1). Any tiles that are horizontally or vertically adjacent to the blank may move is any such legal move. into the blank position. An operator Given an initial and goal state of a sliding-tile puzzle, we are asked to find a minimum number of moves that transform the initial state into the goal state, which is NP-complete [ 431. for arbitrary-size A commonly used cost function, or heuristic evaluation, puzzles ;e( n) is the number of moves from the initial state to state rr, and h(n) is f(n) = g(n) + h( n), where is the Manhattan \fW Zhang, R.E. Kmf/Artifcial Intelligence 79 (1995) 241-292 243 for the number of moves along the grid it is away from its is computed by counting, from n to the goal state. The Manhattan distance distance each tile not in its goal position, these values over all tiles, excluding goal location, and summing is an underestimate distance number of moves of the minimum since every tile must move at least its Manhattan distance problem, and only one tile can move at a time. the blank. Manhattan required the to its goal location, to solve adjacent at the initial A given sliding-tile state. The cost function puzzle can be solved as follows. Starting state is expanded by individually moving each tile that is horizontally state, or to the blank. Each such possible move produces a new state, a child to all new states. A state that is then selected as the next current state, and the current vertically of the current has been generated but not yet expanded this state-selection than or equal to the cost of the best states, or all unexpanded goal node found so far. How a new state is selected depends on the search algorithms employed, which process continues until there are no unexpanded states have costs greater and state-expansion in Section 1.3. is then applied is discussed in detail 1.1.2. The Asymmetric Traveling Salesman Problem Given n cities, { 1,2,3,. . . , n}, and a matrix the Traveling Salesman Problem tour that visits each city exactly once and returns (ci,j) of intercity costs that defines a (TSP) is to find a to the starting city. problems can be formulated as TSPs, such as computer wiring, etc. [ 291. When the cost matrix equal to the cost from each pair of cities, cost between minimum-cost Many NP-hard combinatorial vehicle routing, workshop scheduling, is asymmetric, city j to city i, then the problem optimization i.e. the cost from city i to city j is not necessarily is the asymmetric TSP (ATSP) . lower-bound cost function The most effective [ 1,361. The assignment problem for the ATSP is to assign to the is the solution to each city i another such that the total cost of all assignments is a relaxation of the ATSP since the assignments tour, allowing collections of disjoint subtours, and thus provides of each city to its assignment problem city j, with ci,j as the cost of this assignment, is minimized. The assignment problem need not form a single a lower bound on the cost of the ATSP tour, which is an assignment successor tour, it is the solution time [36]. in the tour. If the assignment problem solution happens to be a single complete in O(n3) to the ATSP as well. The assignment problem is solvable for the given six cities. Assume that the assignment illustrated in Fig. 2, to introduce the operators [ 1 I. We first contains problem problem two subtours We use an example, the assignment solution solve problem assignment If subtour 2 + 3 ---$ 2 is chosen either exclude edge (2,3) or edge (3,2), additional subproblems, still not a single complete solution contains constraint, tour. shown subtours, we try to eliminate in the root node of the tree. Since the them, one at a time. two choices. We may each of which leads to a subproblem with an the excluded edge. We then solve the assignment problems of the is if its assignment problem solution to be eliminated, we have and further decompose a subproblem In order to keep the total number of subproblems should avoid generating duplicate subproblems. generated as small as possible, we in This can be realized by including \fI=( (2,3) t 6) t t 2) Fig 2. An exarnplc OF solving the ATSP. that were excluded suppose any edges that we generate the current subproblem example, The second subproblem B excludes edge (3.2), fore. no subproblems under B will have edge disjoint. generated under A can have edge guaranteeing in previous subproblems. edge In our (2,3). the edge (2,3). There- but all subproblems that the subproblems will be mutually but includes the first subproblem A by excluding (2,3), (2.3), In general, let E denote the set of excluded edges, and I the set of included edges of a tour. We choose problem , x,}, that into t children, with the kth one having subproblem whose assignment problem solution one subtour, solution are not in 1. We then decompose excluded arc set Ek and included arc set II, such that the assignment that there are t edges in the subtour, {xt , x2,. is not a single complete from the one with minimum to eliminate Assume number of edges, the problem Ek =Eu(Xk} fI,=IU{x I,...,. XL-,} , k=l,? ,__., t (1) Since _KL is an excluded edge of the kth subproblem, edge of the (k + I )st subproblem, XL E 1~. 1, any subproblems kth subproblem I )st subproblem must generated, and the state space is a tree of unique nodes. Briefly, a given ATSP can be solved by taking cannot contain edge _~i. but all subproblems .rk. Therefore, no duplicate include edge xk E Ek, and it is an included from the the (k + subproblems will be generated from obtained problem and repeating the assignment the following: First, solve subproblem current subproblem. If the assignment then select a subtour, and generate all child",
            {
                "entities": [
                    [
                        76,
                        121,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 101 (1998) 135-163 Artificial Intelligence A belief network approach to optimization and parameter estimation: application to resource and environmental management Olli Varis ’ Laborutor?; of Water Resources, Helsinki University of Technolog)? l?O. Box 5300, FIN-02015 HUT, Helsinki, Finland Received 11 January 1996; received in revised form 23 June 1997 Abstract An approach is constructed in optimization to use Bayesian belief networks on resource and environmental management. A belief network a deterministic model, and it is used to update conditional probabilities components at the model components parameter values, and other information used. An iteration scheme was developed posterior distributions information. The scheme can be used in different optimization and optimization between various policy options. Also multiobjective optimization approach Elsevier Science B.V. All rights reserved. is presented, with an illustration to associated with different of that model. The divergence between prior and posterior probability distributions between model structure, to force prior and between different sources of tasks including parameter estimation is possible. The is illustrated with an example on cost-effective management of river water quality. 0 1998 is used as an indication on the inconsistency to become equal. This removes to work parallel inconsistencies Keywords: Bayesian methods; Belief networks; Environmental policies; Hybrid models; Parameter estimation; Probabilistic models; Optimization: Resource management; Water quality 1. Introduction Uncertainty ment. Interest is among the most discussed in probabilistic assessment, topics in environmental and resource manage- risk analysis, and related techniques has grown ’ Email: ovaris@leka.hut.fi. 0004-3702/98/S19.00 0 1998 Elsevier Science B.V. All rights reserved. PM: SOOO4-3702(98)00010-l \f136 0. Varis /Arti$cial Intelligence 101 (1998) 135-163 [ 1,5,45]. Probabilistic and risk analyses are increasingly in many countries. Risk-conscious, in the recent years in practical assessment work by international typically rapidly cepted thorities precautionary theory, together with various recently developed computational uncertain in the field. At present, utilized. ac- and by national au- such as the principle have been endorsed by numerous governments. Modern decision for processing to applications are far from being properly known and fully techniques information, provide a wide base for novel, potential approaches organizations risk-averse approaches these opportunities [8,43]: (1) acquisition, can be grouped of information The concept of uncertainty has several facets in this context. From a decision-theoretic presentation, of a given into systems, etc.) and fuzzy set theory, etc.). In this study, Bayesian in three clusters available; issues. Pearl (2) preferences [19] divides computational view, uncertainty and propagation problem; two groups: probabilistic ones (Bayes, Dempster-Shafer, calculus unified approach estimation to have a strong theoretical basis and to provide an theories, and to questions of testing and and (3) structural logic-based to statistical and deterministic logic in rule-based is used because and objectives (monotonous it is known approaches techniques inference, and resource management, is restricted the entire model as a construct have been dominated by classical Bayesian space. In decision the Bayesian analysis to uncertainty considering from the game theory of the 1930s and 1940s [25]. Games evolved against uncontrolled ‘nature’, and abstractions Bayesian decision theoretical [8,16,20]. the applications of Bayesian analysis in which theory, the idea of stem and subjectivity into sequential games trees were developed. [44]. These the late 1960s to the parameter subject into more applicable ones until increasing notice and emphasis concepts were not developed i.e., parameter estimation, theory gradually gained such as decision [9]. Within environmental Further development has been linked with advances in related computational mathemat- impact within intelligence has had a rapidly growing approaches applicable or potentially the last ten ics [2,21,26]. Artificial years. A set of probabilistic, Bayesian-type applica- ble to decision analysis under high uncertainty has emerged [7,19,25,30]. Characteristic of these techniques-known Markov networks, of interdependencies lows construction and to operate interactively application areas, including nition. principle used al- realizable way to many theory, medicine, and pattern recog- as belief networks, causal networks, Bayesian nets, qualitative the network presentation between probabilistic variables. The local-updating influence diagrams, or constraint networks-is In recent years, they have spread quickly of large and densely coupled networks and on-line. fault diagnosis, in a practically reliability According to Bobrow [3], a particularly successful [17,19], which was also used technique has been the belief network and in the present impact on much of approach by Pearl Pauker [30] stated that “. . . Pearl’s formulation has had a revolutionary AI”. As is usual in such techniques, to Bayesian analysis, not only the parameter space (cf. [6,18,27]). probability evident violation of the Kolmogorov strongly argues against subjected to classical theory, different sets of outcomes are allowed for related nodes, yielding an of the Bayes formula, yet Pearl [ 171 hypothesis space-is In contrast “It is not hard to see that this textbook this very axiomatization: the entire model-the study. Szolovits axiomatization \fis from Pearl. a wider practical 0. Varis/Artijicial Intelligence 101 (1998) 135-163 137 view of probability its most interesting aspects.” Many decision analytic approaches have also been with these ideas (see, for instance, theory presents a rather distorted view of human reasoning and misses in line [4,22,23]). in resource management [17-191, and offered suggestions for making Varis [33] examined Pearl’s methodology and environmen- the approach more suitable for decision analysis tal studies. The suggested approach has adapted ideas particularly from Bayesian decision analysis and from some common practices within the field. The most essential suggestion was that nodes can be linked in two layers: (1) the probabilities of all outcomes (all possible cal- state values) of the each model variable (node) can be propagated using belief-function (algebraic or logi- culus; and (2) the outcomes can be linked using deterministic cal). This implies to updating simulations (such as Monte Carlo analysis) useless. This updating works instantly and does not require off-line simulation In the present is understood as an approximate, numerical approach in different parts of the model, making probabilistic runs. approach, the basic uncertainty that the network the uncertainty propagation equations scheme Yet, several extensions were developed applicability: to it, in order to provide l Direction speci$c link: instead of Milj = Mjli that Pearl uses (e.g., pp. 158-159 and continuation in [ 19]), also Milj # Mjli is allowed. l The link strength approach: one parameter can be used to define the link matrix. between l Negative . Node dependency level: the sum of the link strength parameters of links two variables can also be negative. links: the interconnection to a node define how dependent the node is from the rest of the network. The goal of this study was to formulate and test the use of this approach to look at inconsistencies to a deterministic model and parameter estimation. The basic concept-stemming network parallel the model-is information observations prior and posterior probabilities treatment iteration scheme was developed such as management targets to which the model should be fitted. Inconsistencies indices, are shown by diverging in control variables (such as parameters or, say, wastewater levels). In addition, certain properties of the links are adjusted empirically. An to handle uncertainties between (cost in optimization from the idea of using a belief in different parts of and external etc.) or the model outcomes levels, environmental for this purpose. are concerned, and presentation, listed above (i.e., propagation All three categories of uncertainty jectives and preferences, and structure) are supported. Uncertain using discrete belief-function calculus. As far as the presentation ties in objectives and preferences the use of many concepts of utility information following manner: by a network of conditional assigned number of possibilities one meta-model. ob- is propagated information and analysis of uncertain- domain allows analysis and value-of- in the equations, and second to be dependency between variables. The approach also provides a [34,36,39] within probabilities. This structure allows a degree of belief first, the variables can be linked by deterministic to use models from different modeling analysis. Structural uncertainty in the two-layered model the discrete probabilistic to a deterministic theory, including risk-attitude is handled traditions The approach can also be understood as a generalized, discrete Kalman filter, in which also the state equation uncertainty-the structural uncertainty of the deterministic model- \f138 0. Varis /ArtiJicial Intelligence IO1 (1998) 135-163 is estimated. Bayesian filtering approaches bi-directional propagation scheme. influence diagrams [22,23] have been previously [46], but without the structural uncertainty property, and without been used in the The approach is illustrated by a series of numerical examples, and a case study of is in continuum with a number of water policy analysis of a river basin. This work policy studies on resource and environmental management using and developing Bayesian approaches. The methodology decision analysis has included [13,34,35,39,40,42], probabilistic lake water quality managemen",
            {
                "entities": [
                    [
                        67,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 25–48Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintNon-Markovian control in the Situation Calculus ✩Alfredo GabaldonCenter for Artificial Intelligence, New University of Lisbon, Lisbon, Portugala r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Reasoning about actionsSituation CalculusIn reasoning about actions,it is commonly assumed that the dynamics of domainssatisfies the Markov Property: the executability conditions and the effects of all actionsare fully determined by the present state of the system. This is true in particular inIn this paper, we generalizeReiter’s Basic Action Theories in the Situation Calculus.Basic Action Theories by removing the Markov property restriction, making it possibleto directly axiomatize actions whose effects and executability conditions may depend onpast and even alternative, hypothetical situations. We then generalize Reiter’s regressionoperator, which is the main computational mechanism used for reasoning with Basic ActionTheories, so that it can be used with non-Markovian theories.© 2010 Elsevier B.V. All rights reserved.Since the 1960’s when John McCarthy’s papers (in particular the 1969 paper with Pat Hayes) appeared introducing theSituation Calculus, researchers have been studying and working on this language for reasoning about dynamic domains. TheSituation Calculus, one of John’s many great inventions, is the topic of this paper and I am delighted to have this opportunityto make a contribution to a special issue in John’s honor.1. IntroductionAn assumption commonly made in formalisms for reasoning about the effects of actions is the so called Markov property:the executability of an action and its effects are entirely determined by the current state or situation. In particular, Reiter’sBasic Action Theories [2], a Situation Calculus [3,4] based axiomatization, define the value of a fluent after the executionof an action in terms of a formula that can only talk about the situation in which the action would be executed. Thepreconditions of an action are specified by formulas with the same restriction. In this paper we generalize Basic ActionTheories by removing this restriction. The generalized theories will allow the executability conditions and the effects of anaction to depend not only on what holds when the action is to occur, but also on whether certain conditions were satisfiedat different points in the past and even alternative hypothetical evolutions of the system.As an example, imagine a robot that works in a biological research facility with different safety-level areas. The dynamicsis such that a material will be considered contaminated after the robot touches it if the robot has been to a low safety areaor has directly been in contact with a hazardous material, and has not been to the disinfection station since then. So theeffect of touching the material depends on the history of robot activities. We could also imagine that the robot cannotexecute the action open(Entrance, Lab1) if temp(Lab1) > 30 was ever true since the last time closed(Entrance, Lab1) occurred.The latter is an example of an action with non-Markovian preconditions.In simple scenarios, it is not difficult to extend a theory to preserve the necessary history by means of new statevariables, especially when the domain is finite. But in complex domains it may not be obvious how to do it, and the✩A preliminary abstract of this paper appeared in Proc. of AAAI’02 (A. Gabaldon (2002) [1]).E-mail address: ag@di.fct.unl.pt.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.012\f26A. Gabaldon / Artificial Intelligence 175 (2011) 25–48resulting theory may be substantially more complex, with a larger number of state variables and corresponding axiomsdescribing their dynamics.Our goal in this paper is to generalize Reiter’s Basic Action Theories [5,2] by removing the Markov property requirementand generalize the main reasoning mechanism used with these theories, namely the regression operator R, so that itcan be used with non-Markovian theories, and applied to Situation Calculus formulas that refer to the past, to alternativeevolutions, and to definite future situations.This generalized regression operator is not only useful in cases where the action theory is non-Markovian. Even if thebackground theory is Markovian, the operator is useful for answering queries that refer to past situations through quan-tification and the subsequence relation (cid:2). This is not possible with Reiter’s original regression operator. In [2, Section 4.8],Reiter presents a few specialized procedures for evaluating certain historical queries with respect to a database log (a se-quence of ground action terms) and a Markovian action theory. Those queries are a very small subset of the class of queriesthat the generalized regression operator we present here can handle.Our work is relevant to a variety of research problems that involve the formalization of dynamic properties:(1) Some work in database theory has been concerned with the semantics of dynamic integrity constraints [6,7]. Theseconstraints are typically expressed in Past Linear Temporal Logic, a logic with temporal connectives Previous, Sometimein the past, Always in the past, and Since. In a formalization of a database system in the Situation Calculus, suchtemporal connectives amount to references to past situations, and the constraints to restrictions on when a sequence ofactions can be considered a “legal” database system evolution. These past temporal logic connectives have an encodingas formulas in the non-Markovian Situation Calculus and hence the latter can be used as a logical framework forthe study, specification and modeling of databases with dynamic integrity constraints. The advantage of carrying outsuch work in this framework is that all the different aspects of the problem, i.e. database dynamics, transactions andconstraints, can be captured within the same Situation Calculus framework.(2) Also in the area of databases, more specifically in work on database transaction systems, the rollback operation, whichreverts a database back to its original state after a long transaction fails or is canceled, clearly has a non-Markovianflavor: its effects depend not on what is true in the state it is executed, but on the state right before the transactionbeing reversed started. Indeed, Kiringa [8] and Kiringa and Gabaldon [9,10] present logical specifications of databasetransactions in the non-Markovian Situation Calculus.(3) In planning, domain dependent knowledge for search control has been used with great success [11,12]. Bacchus andKabanza’s forward-chaining planning system, TLPlan, uses search control knowledge in the form of temporal logic for-mulas. The same approach has been applied in the Situation Calculus with some simple planners written in Golog [2].The latter planners perform a forward search, eliminating partial plans if they lead to “bad situations.” Search controlknowledge is encoded through a predicate badSituation(s) whose definition is restricted to properties of the currentsituation s. The generalization of the action theories and the regression operator we shall develop here allows the def-inition of this predicate to refer to any situation that precedes s and bounded future situations. As we mention above,past temporal logic expressions can be encoded as Situation Calculus formulas suitable for regression with our gen-eralized operator and be used in the definition of badSituation(s). In other words, the generalized regression operatorallows one to use temporal search control knowledge of a similar form and expressive power as used in TLPlan directlyin Golog planners with the badSituation(s) predicate. Search control knowledge in this context is further explored inour recent work [13,14].(4) Another area where non-Markovian features arise naturally is in specifying reward functions in decision theoretic plan-ning. There, agents are often rewarded based on their long-term behavior rather than just on the current state of affairs.Bacchus, Boutilier and Grove [15,16] have developed techniques for solving such non-Markovian Decision Processes.More recent work on non-Markovian rewards appears in [17,18].(5) Finally, some time ago John McCarthy [19] described a programming language called “Elephant 2000” which, amongother features, “does not forget.” This is a language that would allow one to write programs that explicitly and directlyrefer to past states of the programming environment. The generalized regression operator we present here could formthe foundation for a non-forgetting Golog [20]. Such a dialect of Golog would allow test conditions that refer to thepast, for instance, as in the statement if (P since Q ) then δ.This paper is organized as follows: we start in Section 2 with an overview of the Situation Calculus and Reiter’s BasicAction Theories. In Section 3 we introduce a class of Situation Calculus formulas that can refer to past and finite futuresituations and can be regressed, and based on this, our generalization of action theories for non-Markovian control. InSection 4 we present a regression operator that works for those formulas and theories and prove its correctness, followedby a Prolog implementation in Section 5 and our concluding remarks in Section 6.2. Overview of the Situation Calculus and Basic Action TheoriesThe Situation Calculus [3,4] is a dialect of classical logic for representing and reasoning about dynamically changingworlds. A theory in this language consists of a collection of axioms describing how the world changes when actions occur.Accordingly, the ontology of the Situation Calculus includes three main ingredients: actions, situations, and fluents. Situ-\fA. Gabaldon / Artificial Intelligence 175 (2011) 25–4827ations refer to possible evolutions",
            {
                "entities": [
                    [
                        134,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 72–102Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOrdered completion for logic programs with aggregatesVernon Asuncion a, Yin Chen b, Yan Zhang a, Yi Zhou a,∗a Artificial Intelligence Research Group (AIRG), School of Computing, Engineering and Mathematics, University of Western Sydney, Australiab Department of Computer Science, South China Normal University, Guangzhou, Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 7 August 2013Received in revised form 16 March 2015Accepted 21 March 2015Available online 25 March 2015Keywords:Knowledge representation and reasoningAnswer Set ProgrammingAggregatesFirst-order logicLogic programmingWe consider the problem of translating first-order answer set programs with aggregates into first-order sentences with the same type of aggregates. In particular, we show that, on finite structures, normal logic programs with convex aggregates, which cover both monotone and antimonotone aggregates as well as the aggregates appearing in most benchmark programs, can always be captured in first-order logic with the same type of aggregates by introducing auxiliary predicates. More precisely, we prove that every finite stable model of a normal program with convex aggregates is corresponding to a classical model of its enhanced ordered completion. This translation then suggests an alternative way for computing the stable models of such kind of programs. We report some experimental results, which demonstrate that our solver GROCv2 is comparable to the state-of-the-art answer set solvers. We further show that convex aggregates form a maximal class for this purpose. That is, we can always construct a normal logic program under any given non-convex aggregate context and prove that it can never be translated into first-order sentences with the same type of aggregates unless NP = coNP.© 2015 Elsevier B.V. All rights reserved.1. IntroductionIn this paper, we consider to translate first-order Answer Set Programming (ASP), a predominant declarative program-ming paradigm in the area of knowledge representation and logic programming [3,20,24,25], into first-order logic. Work in this direction is not only of theoretical interests but also of practical relevances as it suggests an alternative way to implement ASP.Recently, Asuncion et al. [2] proposed a notion of ordered completion (a first-order sentence with some extra predicates) for first-order normal logic programs, and showed that the stable models of a normal program are exactly corresponding to the classical models of its ordered completion on finite structures. Interestingly, there is no such translation on arbi-trary structures nor prohibiting extra predicates. Based on this translation, they developed a new ASP solver, which first translates a program to its ordered completion, then grounds this first-order sentence, and finally calls an SMT solver. This is significantly different from previous ASP solvers, which ground the first-order programs directly. A first implementation shows that this new solver is promising as it performs relatively well for the Hamiltonian Circuit program, particularly on big instances [2].However, their work cannot handle aggregates, a very important building block for modern Answer Set Programming. The reason why aggregates are crucial in answer set solving is twofold. Firstly, they enhance the expressive power of ASP, and often they can simplify the representation task. For many applications, one can write a simpler and more elegant logic * Corresponding author.E-mail address: y.zhou@uws.edu.au (Y. Zhou).http://dx.doi.org/10.1016/j.artint.2015.03.0070004-3702/© 2015 Elsevier B.V. All rights reserved.\fV. Asuncion et al. / Artificial Intelligence 224 (2015) 72–10273program by using aggregates, for instance, the job scheduling program [28]. Secondly and more importantly, aggregates can improve the efficiency of ASP solving [19]. Normally, the program using aggregates can be solved much faster [12].In this paper, we consider the problem of extending ordered completion for programs with aggregates. This is a challeng-ing task as some programs with aggregates are expressive enough to capture disjunctive logic programming (see in [16]), thus can never be captured in first-order logic with the same type of aggregates providing some general assumptions in the computational complexity theory (see Proposition 6 in [2]).Hence, an important task is to draw a boundary between the normal programs with aggregates that can be captured in first-order logic with the same type of aggregates and those programs that cannot. For this purpose, we extend the notion of convex constraints proposed by Liu and Truszczy ´nski [23] into first-order convex aggregates. We show that the class of convex aggregates is exactly the boundary we need in the sense that• First-order normal logic programs with convex aggregates can always be captured in first-order logic with the same type of aggregates on finite structures. More precisely, we extend the notion of ordered completion for first-order normal logic programs with convex aggregates, and show that every stable model of such a program is corresponding to a classical model of its enhanced ordered completion.• Given any non-convex aggregate context, there exists a normal program under this context such that it can never be translated into first-order sentences with the same type of aggregates unless NP = coNP.In fact, the class of convex aggregates is expressive enough to capture both monotone and antimonotone aggregates [23] as well as the aggregates appearing in most benchmark programs [5]. Therefore, based on our theoretical results, we are able to develop an alternative ASP solver for first-order normal programs with convex aggregates. Following this idea, we implement a new ASP solver GROCv2. Our experimental results demonstrate that GROCv2 is comparable to the state-of-the-art ASP solvers.The paper is organized as follows. Section 2 reviews basic concepts and notations that we will need through out the paper. Section 3 presents the ordered completion for logic programs with aggregates, and proves the main theorems. Sec-tion 4 introduces the implementation of the ASP solver GROCv2, and reports some experimental results. Finally, Sections 5and 6 discuss some related work and draw our conclusions respectively. We leave the very long proofs of some theorems to Appendix A for a more fluent reading.2. PreliminariesWe consider a second-order language without functions but with equality =. A signature contains a finite set of constants and a finite set of predicates. A term is either a variable or a constant. A standard atom is an expression P (t), where P is a predicate and t is a tuple of terms which matches the arity of P . An equality atom is an expression t1 = t2, where t1 and t2are terms.be two multisets. We denote by M ⊆ MA multiset (also called a bag) is a pair M = (Ms, M f ), where Ms is a set and M fis a function, called the multiplicity function, from Ms to N, i.e., the set of positive integers {1, 2, 3, . . .}. A multiset (Ms, M f ) is finite if Ms is finite. Let M and if M(cid:3) ⊆ M. For convenience, a multiset M, where Ms = {a1, . . . , an} and M f (ai) = ci (1 ≤ i ≤ n), is also denoted as M ⊆ Mand M} }. The order of the elements is irrelevant. For example, { {a, a, b, c} } is the multiset M, { {a1, . . . , a1, . . . , an, . . . , an, . . . , ai, . . . , ai(cid:5)(cid:3)(cid:4)(cid:2)(cid:5)(cid:5)(cid:2)c1(cid:3)s and for all elements a ∈ Ms, M f (a) ≤ M(cid:3)f (a). We write M = Mif Ms ⊆ M(cid:3)(cid:4)cn(cid:3)(cid:4)ci(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)where Ms = {a, b, c} and M f (a) = 2, M f (b) = M f (c) = 1.2.1. The syntax of aggregatesAggregate is a crucial auxiliary building block for answer set programming [12,13,16,19,22,23,28]. We first define the syntax of aggregates in the first-order case. We assume a set of aggregate symbols AG and a (fixed) set of comparison operators on numbers CO = {<, ≤, =, (cid:7)=, ≥, >}.Definition 1. An aggregate atom δ is an expression of the formop(cid:9)v : ∃wQ 1(y1) ∧ · · · ∧ Q s(ys) ∧ ¬R1(z1) ∧ · · · ∧ ¬Rt(zt)(cid:12) (cid:13) t,1where• op ∈ AG is an aggregate symbol,• Q i(yi) (1 ≤ i ≤ s) and R j(z j) (1 ≤ j ≤ t) are standard atoms or equality atoms. In addition,Q 1(y1) ∧ · · · ∧ Q s(ys) ∧ ¬R1(z1) ∧ · · · ∧ ¬Rt(zt)is called the body of δ, denoted by Bd(δ),1 Here, w could be empty. In this case, (1) is simply written as op(cid:9)v : Bd(δ)(cid:12) (cid:13) t.(1)(2)\f74V. Asuncion et al. / Artificial Intelligence 224 (2015) 72–102• v and w are tuples of variables mentioned in (2), and v ∩ w = ∅,• (cid:13)∈ CO is a comparison operator on numbers,• t is a term, and we assume that variables occurring in t are not in v ∪ w.For convenience, we use P s(δ) and N g(δ) to denote the sets {Q 1(y1), . . . , Q s(ys)} and {R1(z1), . . . , Rt (zt)} respectively. Given an aggregate atom δ of the form (1), a variable in δ is a free variable if it is not a variable in v ∪ w.Example 1. Let sum and card be aggregate symbols in AG. The following are two aggregate atoms:card(cid:9)x : P (x)(cid:12) = 2,sum(cid:9)x : P (x)(cid:12) ≤ 5.Intuitively, they are equivalent to the weight constraints2{p(X)}2,{p(X) = X}5in smodels [29], and the aggregate atoms#count{ X : p(X)} = 2,#sum{ X : p(X)} ≤ 5in DLV [14] and ASP-Core-2.2 (cid:2)An atom is either an equality atom, or a standard atom, or an aggregate atom. A first-order formula with aggregates (or formula for short) is built from atoms and logical connectives as usual. A formula without aggregate atom is called a classicalformula in this paper. The free variable of a formula is defined as usual. We use free(φ) to denote the set of free variables of a formula φ.2.2. The semantics for first-order logic with aggregatesAs aggregate is an extra building block, we need to extend the standard semantics for classical first-orde",
            {
                "entities": [
                    [
                        135,
                        188,
                        "TITLE"
                    ],
                    [
                        6165,
                        6218,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1007–1026Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the measure of conflicts: Shapley Inconsistency Values ✩Anthony Hunter a,∗, Sébastien Konieczny ba Department of Computer Science, University College London, UKb CRIL – CNRS, Université d’Artois, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 16 July 2007Received in revised form 9 June 2010Accepted 9 June 2010Available online 18 June 2010Keywords:Inconsistency managementInconsistency toleranceInconsistency measuresConflict resolutionParaconsistencyShapley valuesThere are relatively few proposals for inconsistency measures for propositional belief bases.However inconsistency measures are potentially as important as information measures forartificial intelligence, and more generally for computer science. In particular, they can beuseful to define various operators for belief revision, belief merging, and negotiation. Themeasures that have been proposed so far can be split into two classes. The first class ofmeasures takes into account the number of formulae required to produce an inconsistency:the more formulae required to produce an inconsistency, the less inconsistent the base.The second class takes into account the proportion of the language that is affected by theinconsistency: the more propositional variables affected, the more inconsistent the base.Both approaches are sensible, but there is no proposal for combining them. We addressthis need in this paper: our proposal takes into account both the number of variablesaffected by the inconsistency and the distribution of the inconsistency among the formulaeof the base. Our idea is to use existing inconsistency measures in order to define a gamein coalitional form, and then to use the Shapley value to obtain an inconsistency measurethat indicates the responsibility/contribution of each formula to the overall inconsistencyin the base. This allows us to provide a more reliable image of the belief base and of theinconsistency in it.© 2010 Elsevier B.V. All rights reserved.1. IntroductionThere are numerous works on reasoning under inconsistency. One can quote for example paraconsistent logics, argu-mentation frameworks, belief revision and fusion, etc. All these approaches illustrate the fact that the dichotomy betweenconsistent and inconsistent sets of formulae that comes from classical logics is not sufficient for describing these sets. Asshown by these works, normally when given two inconsistent sets of formulae, they are not trivially equivalent. They donot contain the same information and they do not contain the same contradictions.Measures of information à la Shannon have been studied in logical frameworks (see for example [31]). Roughly theyinvolve counting the number of models of the set of formulae (the less models, the more informative the set). The problemis that these measures regard an inconsistent set of formulae as having a null information content, which is counter-intuitive(especially given all the proposals for paraconsistent reasoning). So generalizations of measures of information have beenproposed to solve this problem [39,53,36,32,24].In comparison, there are relatively few proposals for inconsistency measures [22,27,35,32,28,18]. However, these mea-sures are potentially important in diverse applications in artificial intelligence, such as belief revision, belief merging, andnegotiation, and more generally in computer science. Already some provisional studies indicate that measuring inconsistency✩This paper is a revised and extended version of the paper “Shapley Inconsistency Values” presented at KR’06.* Corresponding author.E-mail addresses: a.hunter@cs.ucl.ac.uk (A. Hunter), konieczny@cril.fr (S. Konieczny).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.06.001\f1008A. Hunter, S. Konieczny / Artificial Intelligence 174 (2010) 1007–1026may be seen to be a useful tool in analysing a diverse range of information types including news reports [29], integrity con-straints [18], software specifications [9,10,42], and ecommerce protocols [12].The current proposals for measuring inconsistency can be classified in two approaches. The first approach involves“counting” the minimal number of formulae needed to produce the inconsistency. The more formulae needed to producethe inconsistency, the less inconsistent the set [35]. This idea is an interesting one, but it rejects the possibility of a morefine-grained inspection of the (content of the) formulae. In particular, if one looks to singleton sets only, one is back to theinitial problem, with only two values: consistent or inconsistent.The second approach involves looking at the proportion of the language that is touched by the inconsistency. This allowsus to look inside the formulae [27,32,18]. This means that two formulae viewed as two whole belief bases (singleton sets)can have different inconsistency measures. But, in these approaches one can identify the set of formulae with its conjunction(i.e. the set {ϕ, ϕ(cid:3)} has the same inconsistency measure as the set {ϕ ∧ ϕ(cid:3)}). This can be sensible in some applications, butthis means that the distribution of the contradiction among the formulae is not taken into account.What we propose in this paper is a definition for inconsistency measures that allow us to take the best of the twoapproaches. This will allow us to build inconsistency measures that are able to look inside the formulae, but also to takeinto account the distribution of the contradiction among the different formulae of the set.The above-mentioned approaches define inconsistency measures, i.e. functions that associate a number to each belief base.These global base-level measures are sufficient for a variety of applications. But in some cases we need an evaluation ona finer level, that is for each formula of the base. We call these functions, that associate a number to each formula of abase, inconsistency values. Such a function allows us to identify which are the most problematic formulae of a belief basewith respect to the inconsistency. This can be very useful for applications such as belief revision or negotiation. Theseinconsistency values provide a more detailed view of the inconsistency, and they can be used to defined new inconsistencymeasures which more accurately reflect the inconsistency of the whole base.To this end we will use a notion that comes from coalitional game theory: the Shapley value. This value assigns toeach player the payoff that this player can expect from her utility for each possible coalition. The idea is to use existinginconsistency measures (that allow us to look inside the formulae) in order to define a game in coalitional form, and thento use the Shapley value to obtain an inconsistency measure with the desired properties. From these inconsistency values, itis possible to define new interesting inconsistency measures. We present these measures, we state a set of logical propertiesthey satisfy, and we show that they are more interesting than the other existing measures.The plan of the paper is as follows: After some preliminaries in the next section, Section 3 introduces inconsistencymeasures that count the number of formulae needed to produce an inconsistency. Section 4 presents the approaches wherethe inconsistency measure depends on the number of variables touched by the inconsistency. Section 5 introduces theproblem studied in this paper and illustrates that the naive solution is not adequate. Section 6 gives the definition ofcoalitional games and of the Shapley value. Section 7 introduces the inconsistency measures based on Shapley value. Thenwe study the logical properties of these measures in Section 8, and we provide a complete axiomatization of a particularmeasure in Section 9 through a set of intuitive axioms. Section 10 sketches the possible applications of those measures forreasoning and for belief change operators. Finally Section 11 concludes by giving perspectives of this work and its possibleapplications for belief change operators.2. PreliminariesWe will consider a propositional language L built from a finite set of propositional symbols P . We will use a, b, c, . . . todenote the propositional variables, and Greek letters α, β, ϕ, . . . to denote the formulae. An interpretation is a total functionfrom P to {0, 1}. The set of all interpretations is denoted W . An interpretation ω is a model of a formula ϕ, denoted ω |(cid:5) ϕ,if and only if it makes ϕ true in the usual truth-functional way. Mod(ϕ) denotes the set of models of the formula ϕ, i.e.Mod(ϕ) = {ω ∈ W | ω |(cid:5) ϕ}. We will use ⊆ to denote the set inclusion, and we will use ⊂ to denote the strict set inclusion,i.e. A ⊂ B iff A ⊆ B and B (cid:2) A. Let A and B be two subsets of C , we note C = A ⊕ B if A and B form a partition of C, i.e.C = A ⊕ B iff C = A ∪ B and A ∩ B = ∅. We will denote the set of real numbers by R.A belief base K is a finite set of propositional formulae. More exactly, as we will need to identify the different formulaeof a belief base in order to associate them with their inconsistency value, we will consider belief bases K as vectors offormulae. For logical properties we will need to use the set corresponding to each vector, so we suppose that there is afunction mapping each vector K = (α1, . . . , αn) into ¯K , the set {α1, . . . , αn}. As it will never be ambigous, in the followingwe will omit the graphical distinction and write K as both the vector and the set.Let us note KL the set of belief bases definable from formulae of the language L. A belief base is consistent if there isat least one interpretation that satisfies all its formulae.If a belief base K is not consistent, then one can define the minimal inconsistent subsets of K as:MI(K ) =(cid:2)(cid:3) ⊆ KK(cid:3)(cid:3) K(cid:3) (cid:13) ⊥ and ∀K(cid:3)(cid:3) ⊂ K(cid:3), K(cid:4)(cid:3)(",
            {
                "entities": [
                    [
                        138,
                        195,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 101 (1998) i65-200 Artificial Intelligence Methods for task allocation via agent coalition formation * Onn Shehory a,*, Sarit Kraus b3c a The Robotics Institute, Carnegie-Mellon Universiv, 5000 Forbes Ave, Pittsburgh, PA 15213, USA b Department of Mathematics and Computer Science, Bar Ilan University, Ramat Gun, 52900 Israel ’ Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USA Received 17 April 1997; received in revised form 7 April 1998 Abstract may require environments in multi-agent Task execution that will perform is necessary when to a group of agents the task. Task allocation that the agents form coalitions to the single agents’ performance. tasks cannot be performed by a single agent. However cooperation they have to satisfy, we consider agents. Given a set among situations where each task of agents and a set of tasks which to groups of should be attached it may also be agents In beneficial when groups perform more efficiently with respect to the problem of task allocation among autonomous agents. this paper we present several solutions and suggest the efficiency of their performance. We present efficient distributed algorithms with low ratio bounds and with low computational complexities. These properties are proven theoretically and supported by simulations in an agent system. Our methods are based on both the algorithmic aspects of and an implementation combinatorics to agent coalition formation where each agent must be a member of only one coalition. Next, we present the domain of overlapping coalitions. We proceed with a discussion of the domain where tasks may have a precedence order. Finally, we discuss in an open, dynamic agent that will lead agents to the formation of coalitions, system. For each case we provide an algorithm where each coalition they are simple, efficient and easy to implement. 0 1998 Published by Elsevier Science B.V. All rights reserved. is assigned a task. Our algorithms are any-time algorithms, for NP-hard problems. We first present an approach the case of implementation in order to perform and approximation tasks or improve algorithms Keyor&: Multi-agent cooperation; Coalition formation; Task allocation + This material is based upon work supported in part by the NSF under grant. No. IRi-9423967 results of this research were published and Army in the Research Lab under contract No. DAAL0197K0135. proceedings of IJCAI-95 and ICMAS-96. Preliminary * Corresponding author, Email: Onn_Shehory@ursa.cimds.ri.cmu.edu. 0004-3702/98/$19.00 PII: SOOO4-3702(98)00045-9 0 1998 Published by Elsevier Science B.V. All rights reserved. \f166 0. Shehory, S. Kraus/ArtijTcial Intelligence 101 (1998) 165-200 1. Introduction Autonomous agents in multi-agent environments may need to cooperate in order to fulfill tasks. Given a set of tasks to be satisfied, we consider situations where each task is assigned a group of agents to perform tasks, if such exist, are due to competing or execution precedence order. The allocation of tasks to groups of agents is necessary when tasks cannot be performed by them inefficiently. Various groups of agents single agents or when single agents perform may have different degrees of efficiency in task performance due to differing capabilities of their members. Task allocation it. We address cases in which dependencies requirements should be done with respect to these differences. resources’ among The purpose of the allocation of tasks to groups of agents is to maximize benefits via the agents for such a solution. Hence, their performance. We seek an algorithm i.e., without a central authority. A low computational important property enable coalitions. For the development algorithmic methods and distributed computing using this paper. We will concentrate necessarily approach and concepts these algorithms from operations are beneficial on coalition ’ [ 11,2 I]. super-additive artificial that will enable a distributed task allocation, an that to form groups and assign a task to each group. We call these groups in this paper we present algorithms shall be considered complexity of the required algorithms, we combine a combinatorial systems methods. The coalitions for systems of cooperative formation research, with autonomous agents’ the agents form when agents, as we show in in environments which are not (DAI) solving Distributed intelligence tries to increase (MAS), where each agent is concerned with problem formation problem have been suggested by researchers [28,44,64]. Most of these solutions are given for coalition agents in a super-additive formation in Multi- its own personal utility via in the case of MAS is how the common outcome of a coalition among its members. We present coalition in which several agents interact in order to execute tasks. During the past few years, several solutions to the coalition in the field of DAI. These solutions concentrate on the special case of autonomous environment Agent Systems cooperation. One of the main problems of coalition to distribute for Distributed Problem Solving * (DPS) [6] formation algorithms which are appropriate cases where agents cooperate the overall outcome of the system [45] and are not concerned with their personal payoffs as they are in MAS. In such cases, the as they are in MAS. In addition, our disbursements Since in the case of a super- solution formation process for additive environment the non- DPS systems In super-additive and may be very realistic. is costly, 4 as the size of the cases where the addition of every new agent to the coalition in super-additive environment to the agents are not as important shall be very simple. Conversely, case is much more challenging is expected, 3 a coalition to the super-additive in order to increase the grand coalition is not restricted environments environment. formation t In a super-additive details see Section 3. environment any combination of two groups of agents into a new group is beneficial. For 2 Recently, DPS agent systems are referred 3 A grand coalition is a coalition that includes all of the agents [43]. to as cooperative MAS [52]. 4 Such costs may arise from the intra-coalition coordination and communication costs: these increase with the size of the coalition. \f0. Shehory S. Kraus /Artificial Intelligence 101 (1998) 165-200 167 coalition increases, is most appropriate it may becomes non-beneficial for such non-super-additive cases. to form it. We suggest a solution which the problem we intend We begin by illustrating the basic definitions problems to solve (Section 2). Then, we give a of the environment with which we deal in Section 3. We also briefly in Section 3.1 and the set covering and set in Sections 4 and 5, in Section results and their analysis, and in Section 9 we discuss in an open MAS. Related research is brief description present partitioning their ratio bounds are discussed 7. Section 8 contains the requirements referred to in Section 10, and Section 11 ends our paper with a discussion and conclusions. and properties of an implementation in Section 6, and their complexity in Section 3.2. The algorithms and assumptions the simulation are described is analyzed 2. Illustration of the problem in this paper The problem we solve is that of task allocation of its benefits by satisfying among groups of agents in a DPS system. Given a set of tasks, the system as a whole must seek autonomous tasks. 5 We consider cases where tasks may a maximization the tasks among have a precedence order. We assume no central authority the agents. Therefore, seeking a maximal outcome. This is achieved via the formation of coalitions, possibly overlapping ones. that distributes task allocation by themselves, they shall reach an efficient Initial configuranon mi Final configuration Schema I. 5 Ideally, all of the tasks should be satisfied, however when attempting to maximize benefits, the execution of some tasks may be hindered. \f168 0. Shehmy, S. Kraus /Artificial Intelligence lOl(l998) 165-200 We demonstrate the problem using a Blocks World domain as Schema 1. The blocks are of various sizes (for simplicity, we consider the case of a unit block and a row of attached unit-blocks). Each unit-block weighs one weight-unit. The blocks should be moved from to the final configuration. This should be done by a group of agents, the initial configuration each capable of lifting a limited weight (e.g., 2 weight-units) it aside as much as necessary. Each block can be carried by a limited number of agents (due to physical limitations). We do not discuss the planning problem but assume a previously provided plan. This plan shall divide the goal into subgoals with a precedence order. Such subgoals, in Schema 2. In such a subgoal, one cannot which are part of the global plan, are presented place block C before blocks A and B are properly located. In addition, cooperation among agents is necessary. Block C cannot be lifted by one agent. However, 4 agents can do so but less efficiently, due to coordination costs, and 20 of them will be far too many. Obviously, any member of the group that places C may be a member of a group that places A or B. However, after performing if the agents have a limited amount of fuel, they may cease functioning they cannot be part of all working groups. a set of tasks, and therefore and moving Sub-goal Schema 2. blocks A I, B1, CI ; subgoal II-locate into several subgoals. For instance, The global goal may be partitioned to three subgoals: subgoal I-locate III-locate it may be blocks partition AZ, B2, C2; subgoal block C3. Each of these subgoals can be performed by a coalition of agents, and subgoal III can be performed only after subgoals I and II have been that perform either subgoal I (Cr) or subgoal II (Ctt) performed. Members of the coalitions may be members of the coalition that members of Ct be members of Cn and vice versa. However, the efficiency of the performance of subgoals This wil",
            {
                "entities": [
                    [
                        67,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 190–213Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimal social choice functions: A utilitarian view ✩Craig Boutilier a,1, Ioannis Caragiannis b, Simi Haber c, Tyler Lu a,2, Ariel D. Procaccia d,∗, Or Sheffet ea Dept. of Computer Science, University of Toronto, Canadab Computer Technology Institute “Diophantus” and Dept. of Computer Engineering and Informatics, University of Patras, Greecec Dept. of Mathematics, Bar-Ilan University, Israeld Computer Science Dept., Carnegie Mellon University, United Statese Center for Research on Computation and Society, Harvard SEAS, United Statesa r t i c l e i n f oa b s t r a c tArticle history:Received 12 April 2014Received in revised form 11 June 2015Accepted 14 June 2015Available online 25 June 2015Keywords:Computational social choiceWe adopt a utilitarian perspective on social choice, assuming that agents have (possibly latent) utility functions over some space of alternatives. For many reasons one might consider mechanisms, or social choice functions, that only have access to the ordinal rankings of alternatives by the individual agents rather than their utility functions. In this context, one possible objective for a social choice function is the maximization of (expected) social welfare relative to the information contained in these rankings. We study such optimal social choice functions under three different models, and underscore the important role played by scoring functions. In our worst-case model, no assumptions are made about the underlying distribution and we analyze the worst-case distortion—or degree to which the selected alternative does not maximize social welfare—of optimal (randomized) social choice functions. In our average-case model, we derive optimal functions under neutral (or impartial culture) probabilistic models. Finally, a very general learning-theoretic model allows for the computation of optimal social choice functions (i.e., ones that maximize expected social welfare) under arbitrary, sampleable distributions. In the latter case, we provide both algorithms and sample complexity results for the class of scoring functions, and further validate the approach empirically.© 2015 Elsevier B.V. All rights reserved.1. IntroductionClassic models in social choice theory assume that the preferences of a set of agents over a set of alternatives are represented as linear orders; a social choice function, given these preferences as input, outputs a single socially desirable alternative. A host of clever social choice functions have been designed to satisfy various normative criteria. Most work in computational social choice studies computational aspects of these models, addressing questions such as the complexity of computing social choice functions [5,17] or manipulating them (see the survey by Faliszewski and Procaccia [13]).E-mail addresses: cebly@cs.toronto.edu (C. Boutilier), caragian@ceid.upatras.gr (I. Caragiannis), simi@math.biu.ac.il (S. Haber), tl@cs.toronto.edu (T. Lu), ✩A preliminary version of this paper appeared in the proceedings of EC’12.* Corresponding author.arielpro@cs.cmu.edu (A.D. Procaccia), osheffet@seas.harvard.edu (O. Sheffet).1 Currently on leave at Google, Inc., Mountain View, CA.2 Currently at Google, Inc., Mountain View, CA.http://dx.doi.org/10.1016/j.artint.2015.06.0030004-3702/© 2015 Elsevier B.V. All rights reserved.\fC. Boutilier et al. / Artificial Intelligence 227 (2015) 190–213191Under ordinal preferences, an axiomatic approach to obtaining a socially desirable outcome seems—on the face of it—necessary, absent concrete measures of the quality of an alternative. In contrast, some work in economics assumes cardinalpreferences and takes a utilitarian approach. This viewpoint dates to the work of Bentham at the end of the 18th century, who argued that “it is the greatest happiness of the greatest number that is the measure of right and wrong.” This axiom suggests that happiness can be quantified, and indeed, having coined the term utility, Bentham proposed that the goal of government is to maximize the sum of individual utilities—the social welfare (defying contemporary wisdom that the goal of government is to enrich the coffers of the ruler). The utilitarian approach is prevalent, for example, in mechanism design, and perhaps even more so in algorithmic mechanism design [25].In this paper we view the social choice problem through this utilitarian lens. Our premise is that agents have (possibly implicit) utility functions, and the goal of a social choice function is to maximize the (utilitarian) social welfare3—i.e., (possibly weighted) sum of agent utilities—of the selected alternative. The utilitarian perspective is not appropriate for all social choice problems (a point we discuss further below). However, the methods of social choice—especially voting systems—are finding increasing application in recommender systems, web search, product design, and many more practical domains, in which the primary aim is often, as in much of mechanism design, to aggregate preferences so that utility or efficiency is maximized. Indeed, one motivation for our work is the development of group recommendation systems for a variety of domains, including low-stakes consumer applications and higher profile public policy and corporate decisions. Our work can be viewed as a step toward supporting groups of users making decisions using social choice functions that are automatically optimized for their needs. In these settings, a utilitarian perspective is often called for.If we could directly access the utilities of agents, the socially desirable alternative could be easily identified. However, such access is often not feasible for a variety of reasons. As a result, we use agent preference orders as a proxy for their utility functions; and the social choice function, taking preference orders as input, should perform well with respect to the underlying utilities. From this point of view, a social choice function is optimal if it maximizes social welfare given the available information. Using a preference order as proxy for utility in this fashion serves several purposes. First, behavioral economists have argued that people find it difficult to construct utilities for alternatives. Second, the cognitive and commu-nication burden of articulating precise utilities has long been recognized within decision analysis, behavioral economics, and psychology. By contrast, simply comparing and ordering alternatives is considerably easier for most people, which makes soliciting preference orders more practical than eliciting utilities. Furthermore, choice behavior among alternatives can of-ten be interpreted as revealing ordinal (rather than cardinal) preference information, providing ready access to (sometimes incomplete) orders in many of the domains described above. Hence we content ourselves with orders as inputs.1.1. Our resultsOur study of optimal social choice functions incorporates three distinct but related models, each with its own assump-tions regarding available information and therefore its own notion of optimality. One common thread is that the family of scoring functions—social choice functions that score alternatives based only on their position in each agent’s preference order—plays a key role in optimizing social welfare.In Section 3 we study a model where no information about agents’ utility functions is available when constructing the so-cial choice function. A worst-case analysis is thus called for. We believe that the study of this model is of theoretical interest, but it is certainly the least practical of our three models. Specifically, given a collection of agents’ preferences—a preference profile—there are many consistent collections of utility functions—utility profiles—that induce this preference profile in the natural way (by ranking alternatives with higher utility closer to the top). The distortion of a social choice function on a preference profile is the worst-case ratio (over feasible utility profiles) of the social welfare of the best alternative to the social welfare of the alternative that is selected by the function. A worst-case optimal social choice function minimizes the distortion on every preference profile.√We first derive upper and lower bounds on the least distortion that one can hope for, focusing on randomized social choice functions. We show that there exists a preference profile where every randomized social choice function must have m), where m is the number of alternatives. We complement this result with a randomized social distortion at least (cid:2)(∗choice function whose distortion on every preference profile is O(m). A slightly weaker upper bound is obtained via a randomized variation of a natural scoring function that we call the harmonic scoring function (a new canonical scoring function that may be of independent interest). Finally, we establish that the worst-case optimal social choice function (which achieves minimum distortion on every profile) is polynomial-time computable. The proof is based on linear programming, and (roughly speaking) relies on embedding the dual of a sub-problem within a carefully constructed larger LP, in order to avoid quadratic constraints.m log√In Section 4 we study an average-case model, assuming a known distribution D over utility functions. We assume that the utility function of each agent is drawn independently from D. Given reported agent preferences, one can compute the expected utility any agent has for an alternative with respect to D. An average-case optimal social choice function selects an alternative that maximizes expected social welfare given the reported profile. We show that when D is neutral, i.e., symmetric with respect to alternatives, the average-case optimal social choice function must be a scoring function. The 3 Hereinafter, we simply write “social welfare” to refer t",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 248–278Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms for electric vehicle scheduling in large-scale mobility-on-demand schemesEmmanouil S. Rigas a,∗a Aristotle University of Thessaloniki, 54124, Thessaloniki, Greeceb Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, UK, Sarvapali D. Ramchurn b, Nick Bassiliades aa r t i c l e i n f oa b s t r a c tArticle history:Received 17 July 2016Received in revised form 14 February 2018Accepted 10 June 2018Available online 18 June 2018Keywords:Mixed integer programmingHeuristic searchLocal searchMax-flowElectric vehiclesShared vehiclesMobility on demandWe study a setting where Electric Vehicles (EVs) can be hired to drive from pick-up to drop-off points in a Mobility-on-Demand (MoD) scheme. The goal of the system is, either to maximize the number of customers that are serviced, or the total EV utilization. To do so, we characterise the optimisation problem as a max-flow problem in order to determine the set of feasible trips given the available EVs at each location. We then model and solve the EV-to-trip scheduling problem offline and optimally using Mixed Integer Programming (MIP) techniques and show that the solution scales up to medium sized problems. Given this, we develop two non-optimal algorithms, namely an incremental-MIP algorithm for medium to large problems and a greedy heuristic algorithm for very large problems. Moreover, we develop a tabu search-based local search technique to further improve upon and compare against the solution of the non-optimal algorithms. We study the performance of these algorithms in settings where either battery swap or battery charge at each station is used to cope with the EVs’ limited driving range. Moreover, in settings where EVs need to be scheduled online, we propose a novel algorithm that accounts for the uncertainty in future trip requests. All algorithms are empirically evaluated using real-world data of locations of shared vehicle pick-up and drop-off stations. In our experiments, we observe that when all EVs carry the same battery which is large enough for the longest trips, the greedy algorithm with battery swap with the max-flow solution as a pre-processing step, provides the optimal solution. At the same time, the greedy algorithm with battery charge is close to the optimal (97% on average) and is further improved when local search is used. When some EVs do not have a large enough battery to execute some of the longest trips, the incremental-MIP generates solutions slightly better than the greedy, while the optimal algorithm is the best but scales up to medium sized problems only. Moreover, the online algorithm is shown to be on average at least 90% of the optimal. Finally, the greedy algorithm scales to 10-times more tasks than the incremental-MIP and 1000-times more than the static MIP in reasonable time.© 2018 Elsevier B.V. All rights reserved.1. IntroductionIn a world where over 60% of the total population will be living in, or around, cities the current personal transportation model is not sustainable as it is based almost entirely on privately owned internal combustion engine vehicles. These * Corresponding author.E-mail addresses: erigas@csd.auth.gr (E.S. Rigas), sdr1@soton.ac.uk (S.D. Ramchurn), nbassili@csd.auth.gr (N. Bassiliades).https://doi.org/10.1016/j.artint.2018.06.0060004-3702/© 2018 Elsevier B.V. All rights reserved.\fE.S. Rigas et al. / Artificial Intelligence 262 (2018) 248–278249vehicles cause high pollution (e.g., air and sound), and face low utilization rates1 [52]. Electric Vehicles (EVs) can be an efficient alternative to those using internal combustion engines when it comes to running costs [17], environmental impact, and quality of driving. However, these advantages come with a trade-off, as EVs have short ranges and long charging times. To address such issues, cities typically resort to building a large number of charging stations with fast chargers, or battery swapping capabilities. Now, such facilities are only worth building if there are enough EVs to use them. However, drivers will not buy EVs if charging stations are not first available, leading to a catch-22 situation.In order to increase vehicle utilization, Mobility-on-Demand (MoD) schemes have been advocated [30]. MoD involves vehicles that are used by either individuals, or small groups of commuters, thus providing them with an alternative from using their privately owned vehicles. Such systems have the potential to reduce traffic congestion in urban areas, as well as the need for large numbers of parking spots.2 By doing so, MoD also aims to achieve considerably higher vehicle utilization rates compared to individually owned ones (i.e., few vehicles will cover the transportation needs of many commuters). Moreover, other advantages include the fact that car ownership is reduced, as well as less up-front charges which means low-income people may be better served.Given the benefits of EVs and MoD schemes, in this paper we explore scenarios within which EVs could be used within MoD schemes, and consider their associated optimisation challenges. By addressing these challenges, the advantages of the two transportation modes would be combined [30,10]. Moreover, the use of EVs in MoD schemes offer an opportunity to further market EVs to potential car owners as they get to try the technology before buying it. In this way, EV-equipped MoD schemes would help popularise EVs, while at the same time having a positive impact in urban traffic conditions as well as the environment.To date, a number of MoD schemes, such as ZipCar,3 or CarShare4 have been proposed, albeit most of them using normal cars. However, EVs present new challenges for MoD schemes. For example, EVs have a limited range that requires them to either charge regularly or have their battery swapped when they stop. Moreover, if such MoD schemes are to become popular, it is important to ensure that charging/swap capacity is managed and scheduled to allow for the maximum number of consumer requests to be serviced across a large geographical area. In addition, in order for MoD schemes to be economically sustainable, and given the higher cost of buying EVs compared to conventional vehicles, it is important to have them working at maximum capacity and servicing the maximum number of customers around the clock.Against this background, we model the MoD scheme for EVs and develop a number of algorithms to solve the problem of scheduling trips for MoD consumers in order to maximize the number of trip requests serviced while coping with the limited range of EVs. These algorithms attempt to deal with the computational complexity of the scheduling problem in a number of contexts (online v/s offline, with battery swap or battery charge, small-sized or large problems). Thus, we first recast the scheduling problem as a max-flow problem whose solution lets us determine the (upper limit) of trip requests able to be executed given a set of available EVs. Then, we show how the scheduling of trips in the MoD scheme is a highly combinatorial problem, for which an optimal offline solution, where all demand is known in advance, scales only up to medium sized problems (tens of EVs and hundreds of trips). Thus, to cope with large problems, we also develop two near-optimal offline solutions, namely an incremental MIP and a greedy heuristic, as well as a tabu search-based local search technique to further improve the solution quality of the non-optimal algorithms. Moreover, to tackle the online version of the problem, where demand is not known in advance, we develop an online scheduling algorithm. In all cases, and given the limited range of EVs, we consider situations where they can either have their battery swapped (with a fully charged one), or charged at the stations. The work presented here has been initiated at [38] with basic versions of the MIP and the greedy algorithms for battery swapping. Specifically, this paper advances the state of the art as follows:1. We provide a characterisation of the MoD scheme as a max-flow problem. By solving this problem, we are able to determine the set of all feasible trips given a set of available EVs.2. We propose an optimal Mixed Integer Programming (MIP) formulation of the problem of scheduling EVs in a MoD scheme that maximizes the number of completed tasks (i.e., trip requests from consumers) or the EV utilization (i.e., number of time points each EV is travelling), either using battery swap or battery charging at each station.3. Given the average scalability of the optimal solution, we develop an incremental-MIP and a greedy heuristic algorithm which are shown to generate near-optimal solutions with considerably lower execution times.4. We propose a tabu search-based local search technique in order to further improve the solution quality of the non-optimal algorithms.5. We propose a battery swap optimization algorithm which minimizes the number of necessary battery swaps in order to reduce the need for spare batteries and thus, cost.1 EVs can be used as energy storage devices when not being driven. In this way (renewable) energy utilization can increase. Thus, in the EVs domain the word utilization refers to both the driving and the use of them as energy storage devices.2 Demand for travel is not reduced. However, the fact that multiple users end up using the same cars means that there are fewer cars on the road and hence, less congestion (i.e., this indirectly can improve congestion as it could reduce the number of cars parked at the sides of the roads. Such parked cars create some congestion).3 http://www.zipcar.com/.4 http://www.enterprisecarshare .com/.\f250E.S. Rigas et al. / Artificial Intelligence 262 (2018) 248–2786. We propose an online algorithm for scheduling EV trips across the MoD that can cope with uncertainty in the numbe",
            {
                "entities": [
                    [
                        136,
                        220,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 739–778www.elsevier.com/locate/artintSolving logic program conflict through strong and weak forgettings ✩Yan Zhang a,∗, Norman Y. Foo ba Intelligent Systems Laboratory, School of Computing and Mathematics, University of Western Sydney, Penrith South DC, NSW 1797, Australiab School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, AustraliaReceived 6 September 2005; received in revised form 23 February 2006; accepted 23 February 2006Available online 29 March 2006AbstractWe consider how to forget a set of atoms in a logic program. Intuitively, when a set of atoms is forgotten from a logic program,all atoms in the set should be eliminated from this program in some way, and other atoms related to them in the program mightalso be affected. We define notions of strong and weak forgettings in logic programs to capture such intuition, reveal their closeconnections to the notion of forgetting in classical propositional theories, and provide a precise semantic characterization forthem. Based on these notions, we then develop a general framework for conflict solving in logic programs. We investigate varioussemantic properties and features in relation to strong and weak forgettings and conflict solving in the proposed framework. Weargue that many important conflict solving problems can be represented within this framework. In particular, we show that allmajor logic program update approaches can be transformed into our framework, under which each approach becomes a specificconflict solving case with certain constraints. We also study essential computational properties of strong and weak forgettings andconflict solving in the framework.© 2006 Elsevier B.V. All rights reserved.Keywords: Conflict solving; Knowledge representation; Answer set semantics; Logic program update; Computational complexity1. Introduction1.1. MotivationOne promising approach in the research of reasoning about knowledge dynamics is to represent agents’ knowledgebases as logic programs on which necessary updates/revisions are conducted as a way of modeling agents’ knowledgeevolution. A key issue in this study is to solve various conflicts and inconsistencies in logic programs, e.g. [15].We observe that some typical conflict solving problems in applications are essential in reasoning about agents’knowledge change, but they may not be properly handled by traditional logic program updates. Let us consider a✩ Some results presented in this paper were published in IJCAI-2005 and AAAI-2005 [Y. Zhang, N.Y. Foo, K. Wang, Solving logic programconflict through strong and weak forgettings, in: Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI-05), 2005,pp. 627–632; Y. Zhang, N.Y. Foo, A unified framework for representing logic program updates, in: Proceedings of the 20th National Conferenceon Artificial Intelligence (AAAI-05), 2005, pp. 707–712].* Corresponding author.E-mail addresses: yan@cit.uws.edu.au (Y. Zhang), norman@cse.unsw.edu.au (N.Y. Foo).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.02.002\f740Y. Zhang, N.Y. Foo / Artificial Intelligence 170 (2006) 739–778scenario. John wants Sue to help him to complete his assignment. He knows that Sue will help him if she is not sobusy. Tom is a good friend of John and wants John to let him copy John’s assignment. Then John learns that Sue hatesTom, and will not help him if he lets Tom copy his assignment, which will be completed under Sue’s help. While Johndoes not care whether Sue hates Tom or not, he has to consider Sue’s condition to offer him help. What is John goingto do? We formalize this scenario in a logic programming setting. We represent John’s knowledge base ΠJ :r1: complete(John, Assignment) ← help(Sue, John),r2: help(Sue, John) ← not Busy(Sue),r3: goodFriend(John, Tom) ←,r4: copy(Tom, Assignment) ← goodFriend(John, Tom), complete(John, Assignment),and Sue’s knowledge base ΠS :r5: hate(Sue, Tom) ←,r6: ← help(Sue, John), copy(Tom, Assignment).In order to take Sue’s knowledge base into account, John may update his knowledge base ΠJ in terms of Sue’sΠS . In this way, John obtains a solution: Π final= {r1, r2, r3, r5, r6} or its stable model, from which we know thatSue will help John to complete the assignment and John will not let Tom copy his assignment. Although the conflictbetween ΠJ and ΠS has been solved by updating, the result is somehow not always satisfactory. For instance, whileJohn wants Sue to help him, he may have no intention to contain the information that Sue hates Tom into his newknowledge base.JAs an alternative, John may just weaken his knowledge base by forgetting atom copy(Tom, Assignment) fromΠJ in order to accommodate Sue’s constraint on help. Then John will have a new program Π final(cid:4)= {r1, r2, r3}—John remains a maximal knowledge subset which is consistent with Sue’s condition without being involved in Sue’spersonal feeling about Tom.JThe formal notion of forgetting in propositional theories was initially considered by Lin and Reiter from a cognitiverobotics perspective [18] and has recently received a great attention in KR community. It has been shown that thetheory of forgetting has important applications in solving knowledge base inconsistencies, belief update and merging,abductive reasoning, causal theories of actions, and reasoning about knowledge under various propositional (modal)logic frameworks, e.g. [13,14,19,24]. Then a natural question is: whether can we develop an analogous theory offorgetting in logic programs and apply it as a foundational basis for various conflict solving in logic programs? Thispaper provides an answer to this question.1.2. Summary of contributions of this paperThe main contributions of this paper can be summarized as follows.(1) We define two notions of strong and weak forgettings in logic programs under answer set programming semantics.We reveal their close connections to the notion of forgetting in classical propositional theories, and provide aprecise semantic characterization for them.(2) Based on these notions, we develop a general framework for conflict solving called logic program contexts.Under this framework, conflicts can be solved by strongly or/and weakly forgetting certain sets of atoms fromcorresponding programs. We show that our framework is general enough to represent many important conflictsolving problems. In particular, for the first time we demonstrate that all major logic program update approachescan be transformed into our framework.(3) We investigate essential computational properties in relation to strong and weak forgettings and conflict solvingin the proposed framework. Specifically, we show that under the answer set programming with no disjunctionin the head, the associated inference problem for strong and weak forgettings is coNP-complete, and the irrele-vance problem related to strong and weak forgettings and conflict solving is coDP-complete. We also study othercomputational problems related to the computation of strong and weak forgetting and conflict solving.\fY. Zhang, N.Y. Foo / Artificial Intelligence 170 (2006) 739–7787411.3. Structure of the paperThe rest of this paper is organized as follows. We first present preliminary definitions and concepts in Section 2.In Section 3, we give formal definitions of strong and weak forgettings in logic programs, and present their essentialproperties. Based on notions of strong and weak forgettings, in Section 4 we propose a framework called logic programcontexts for general conflict solving in logic programs. In Section 5, we investigate various semantic properties andfeatures in relation to strong and weak forgettings and conflict solving in the proposed framework. In Section 6, weshow that our conflict solving framework is general enough to represent all major logic program update approaches. InSection 7, we study essential computational properties of strong and weaking forgettings and conflict solving. Finally,in Section 8 we conclude the paper with some discussions.2. PreliminariesWe consider finite propositional normal logic programs in which each rule is of the form:a ← b1, . . . , bm, not c1, . . . , not cn,(1)where a is either a propositional atom or empty, b1, . . . , bm, c1, . . . , cn are propositional atoms, and not presents thenegation as failure. From (1) we know that a normal logic program does not contain classical negation and has nodisjunction in the head. When a is empty, rule (1) is called a constraint. Given a rule r of the form (1), we denotehead(r) = {a}, pos(r) = {b1, . . . , bm}, neg(r) = {c1, . . . , cn}, and body(r) = pos(r) ∪ neg(r). Therefore, rule (1) maysimply be represented as the form:head(r) ← pos(r), not neg(r),(2)here we denote not neg(r) = {not c1, . . . , not cn}. We also use atom(r) to denote the set of all atoms occurring in rule r.For a program Π , we define notions head(Π) =r∈Π neg(r),body(Π) =r∈Π atom(r). Given sets of atoms P and Q, we may use notionr∈Π body(r), and atom(Π) =r∈Π head(r), pos(Π) =r∈Π pos(r), neg(Π) =(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:4)r: head(r) ←(cid:3)pos(r) − P(cid:4), not(cid:4)(cid:3)neg(r) − Qto denote rule r (cid:4) obtained from r by removing all atoms occurring in P and Q in the positive and negation as failureparts respectively.The stable model of a program Π is defined as follows. Firstly, we consider Π to be a program in which each ruledoes not contain negation as failure not. A finite set S of propositional atoms is called a stable model of Π if S is thesmallest set such that for each rule a ← b1, . . . , bm from Π , if b1, . . . , bm ∈ S, then a ∈ S. Now let Π be an arbitrarynormal logic program. For any set S of atoms, program Π S is obtained from Π by deleting (1) each rule from Π thatcontains not c in the body if c ∈ S; and (2) all subformulas of not c in the bodies of the remaining rules. Then S isa stable model of Π if and only i",
            {
                "entities": [
                    [
                        72,
                        138,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1644–1672Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSemantic forgetting in answer set programming ✩Thomas Eiter a, Kewen Wang b,∗,1a Institut für Informationssysteme, Technische Universität Wien, Favoritenstraße 9-11, A-1040 Vienna, Austriab School of Information and Communication Technology, Griffith University, Brisbane QLD 4111, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 3 November 2007Received in revised form 6 May 2008Accepted 24 May 2008Available online 29 May 2008Keywords:Answer set programmingNonmonotonic logic programsKnowledge representationForgettingComputational complexityThe notion offorgetting, also known as variable elimination, has been investigatedextensively in the context of classical logic, but less so in (nonmonotonic) logic program-ming and nonmonotonic reasoning. The few approaches that exist are based on syntacticmodifications of a program at hand.In this paper, we establish a declarative theoryof forgetting for disjunctive logic programs under answer set semantics that is fullybased on semantic grounds. The suitability of this theory is justified by a number ofdesirable properties. In particular, one of our results shows that our notion of forgettingcan be entirely captured by classicalforgetting. We present several algorithms forcomputing a representation of the result of forgetting, and provide a characterization ofthe computational complexity of reasoning from a logic program under forgetting. Asapplications of our approach, we present a fairly general framework for resolving conflictsin inconsistent knowledge bases that are represented by disjunctive logic programs, and weshow how the semantics of inheritance logic programs and update logic programs from theliterature can be characterized through forgetting. The basic idea of the conflict resolutionframework is to weaken the preferences of each agent by forgetting certain knowledge thatcauses inconsistency. In particular, we show how to use the notion of forgetting to providean elegant solution for preference elicitation in disjunctive logic programming.© 2008 Published by Elsevier B.V.1. IntroductionFor intelligent agents, the ability to discard irrelevant information has been recognized as an important feature (that ismastered well by humans) and received broad attention in artificial intelligence, both from a cognitive and a computationalperspective. In the area of knowledge representation, this ability is often referred to as forgetting [49] or variable elimina-tion [9], but has been studied under many different names including irrelevance, independence, irredundancy, novelty, orseparability (see [34,63] for more details).Forgetting has its root in Boolean Algebra [6] where it is a fundamental reasoning process. C.I. Lewis [41] has pointed outthat, for purposes of application of Boolean logic to commonsense reasoning, the elimination/forgetting is a process moreimportant than solution2 since most processes of reasoning take place through the elimination of “middle” variables. Boolewrites of such middle variables that it “usually happens in commonsense reasoning, and especially when we have morethan one premises, that some of the elements [in the premises] are not required to appear in the conclusion”.✩Preliminary versions of this paper with some of the results have been presented at AAAI 2006 and at NMR 2006.* Corresponding author.E-mail addresses: eiter@kr.tuwien.ac.at (T. Eiter), k.wang@griffith.edu.au (K. Wang).1 Part of the work was done while this author was visiting Technische Universität Wien.2 In [41] a problem is formulated as a Boolean equation such that a solution of the Boolean equation corresponds to a solution of the given problem. Inparticular, solving a Boolean equation is treated as a process of eliminating/forgetting variables that represent unknowns.0004-3702/$ – see front matter © 2008 Published by Elsevier B.V.doi:10.1016/j.artint.2008.05.002\fT. Eiter, K. Wang / Artificial Intelligence 172 (2008) 1644–16721645Forgetting and its applications have been investigated extensively in the context of classical logic, for example, [5,34,36,37,49,55,56,67], but less so in nonmonotonic logic programming and reasoning. In this context, it was first considered in[70,71], where two types of forgetting—strong and weak forgetting—have been defined by first transforming a logic programP into a reduced form and then deleting some rules (and literals) from it. While this approach works well in a number ofcases, it has two major drawbacks. First, its semantic underpinning is not fully clear. Specifically, the relationship betweenthe intended semantics of a logic program, in terms of its answer sets, and the result of the syntactic transformations thatare carried out by strong and weak forgetting is unclear. Second, this approach does not address desirable properties fora reasonable notion of forgetting in nonmonotonic logic programming. In particular, one may ask what is the difference ofthese notions of forgetting from traditional approaches to deletion of rules/literals in logic programming and databases.A further aspect is that both strong and weak forgetting are syntax-sensitive, i.e., programs that are semantically equiva-lent may have different results after forgetting about the same literal. For example, the programs P = {p ← . q ← not p}and Q = {p ←} are equivalent under the answer set semantics. Weak forgetting about p from P yields the programWForgetLP(P , p) = {q ←} and from Q the program WForgetLP(Q , p) = { }; clearly, these programs are not equivalent.While the role of syntax in logic programming is, with respect to reading of rules as in classical logic well-acknowledged,one might argue that relative to the semantics of this syntax, equivalent programs should behave in the same way. Inparticular, in this example the result of forgetting about p in P and Q should yield semantically the same result (note that,under answer set semantics, the second rule in P is redundant).A similar phenomenon can be observed for strong forgetting. Consider P = {q ← not p. q ← not q} and Q = {q ←}. Thenthese two programs are equivalent under the answer set semantics. However, the results of strong forgetting about p fromP and Q are SForgetLP(P , p) = {q ← not q} and SForgetLP(Q , p) = {q ←}, respectively, which are obviously not equivalent.The discrepancy is here even more noticeable: the result of strong forgetting about an atom from a consistent program canbe inconsistent.Thus, an alternative notion of forgetting for nonmonotonic logic programming is highly desirable. In this paper, we chooseanswer set programming (ASP) [44] as the underlying nonmonotonic logic. ASP is a new paradigm of logic programmingunder the answer set semantics [29], which is becoming a major tool for knowledge representation and reasoning due toits simplicity, expressive power, and connection to major nonmonotonic logics. A number of efficient ASP solvers, such asDLV, Smodels, ASSAT, Cmodels, or Clasp are available (see [3]), which can handle large problem instances.Prior to defining a notion of forgetting for nonmonotonic logic programming, we may pose the question what desirableproperties a reasonable theory of forgetting should have. The following ones appear to be natural candidates for us. Let Pbe a logic program and let Pbe the result of forgetting about a literal l in P .(cid:4)(F1) The proposed notion of forgetting should be a “natural” generalization of, and relate to, forgetting in classical logic., i.e., the vocabulary stays the same.(F2) No new symbols are introduced in P(F3) The reasoning under P(F4) The result of forgetting is not sensitive to syntax in that the results of forgetting about l in semantically equivalentis equivalent to the reasoning under P if l is ignored.(cid:4)(cid:4)programs should also be semantically equivalent.(F5) The semantic notion of forgetting is coupled with a syntactic counterpart, i.e., there is effective constructible syntax forrepresenting the result of forgetting.(cid:4)Property (F1) specifies the major intuition behind forgetting and clarifies the difference of forgetting from deletion. (F2) isnecessary because the forgetting is to eliminate the symbols to be forgotten. This is a difference between forgetting andsome approaches to revision, update, and deletion, such as [1,10,16,19,31]; note that to combine forgetting with other ap-proaches to adding new information is a different issue. Property (F3) provides a semantic justification for the forgetting.Note that Pand P may have different answer sets in general (see Proposition 1); (F4) guarantees that the notion of forget-ting is semantically well-defined. Finally, property (F5) is useful for applications of forgetting in knowledge representation.To the best of our knowledge, there is no theory of forgetting in nonmonotonic reasoning or logic programming whichis based on the above criteria; notice that properties (F3) and (F4) do not hold for weak and strong forgetting from [70,71](see Section 7 for more discussion). However, the definition of forgetting in classical logic cannot be directly adapted tologic programming (cf. Section 3.1). The main contributions of the present paper are as follows.• We establish a declarative, semantically defined notion of forgetting for disjunctive logic programs under answer set se-mantics called semantic forgetting. The suitability of semantic forgetting is justified by a number of desirable properties,including the ones given above.• As one of them, we show that our notion of forgetting naturally captures classical forgetting. As we show, this canbe exploited for reasoning under forgetting about a literal from a logic program by resorting to representations of anonmonotonic logic program in terms of classical logic [39,50,51].• As another such property, for every consistent disjunctive program P and literal l, a",
            {
                "entities": [
                    [
                        138,
                        183,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 83 (1996) 75-141 Artificial Intelligence Qualitative system identification: deriving structure from behavior A.C. Cem Say*, Selahattin Kuru Department of Computer Engineering, BogaziGi University, Bebek 80815, Istanbul, Turkey Received August 1993; revised December 1994 Abstract comparative (which perform simulation, it using a library of model fragments and input them. System identification their behaviors. We present Qualitative reasoning programs analysis, data interpretation, etc.) either take the model of the physical system to be considered as input, or compose about how to combine is the task of creating models of systems, using data algorithm QSI, about the qualitative which takes as input a set of qualitative behaviors of a physical system, and produces as its input output a constraint model of the system. QSI’s output when simulated. Furthermore, “deep” in the input behaviors. Various aspects of parameters of the system which do not appear QSI and its applicability are discussed. to produce the QSI-made models usually contain meaningful to diagnosis, as well as the model fragment formulation problem, is guaranteed identification information system 1. Introduction Research in in qualitative reasoning many programs designed being produced. These the underlying mechanism of the system under consideration as part of their input and analyze or predict reasoning about physical systems [36] has resulted to achieve various reasoners in one of a variety of ways. take a “deep” model of tasks of commonsense its behavior Before performing any kind of model-based reasoning, one has to have a model of the system which will be reasoned about. The model composition methods used large amounts of by some current or information issue of initial mechanisms about physical that can be used the various kinds of components to build systems, overlook require possession of reasoners, which laws and the * Corresponding author. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDZ 0004-3702(95)00016-X \f76 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 75-141 it is in these cases that the modeling creation of model fragments with which the complete system models are built. When faced with a novel situation, or a new mechanism whose description is not in the library, reasoners employing such an approach may be unable to available task is the achieve modeling, even though most important and interesting. Leaving the preparation of the models completely to the “user”, on the other hand, is clearly not a way out, from the point of view of artificial intelligence, which aims to automate human behavior. When one examines what humans do in similar situations, mental model of the “laws” of the system under consideration after a period of observation “algorithm” whose input is the behavior of the system, and whose output system model. This is essentially does. quantitative, it is seen that a can be formed, the system’s behavior, which suggests an is the the reverse of what simulation, qualitative or of This task of behavior-based model construction mature field, named system identification. As a result of extensive research field, widespread in the numerical domain have been produced. identification program which performs Qualitative System Identification, representation, physical system, and its output is a constraint model of that system. algorithms which perform is the subject of an already in this system In this paper, QSI, a using the qualitative is presented. QSI’s input is a set of qualitative behaviors of a of efficient applications reasoning and algorithm, which we have borrowed The outline of the paper is as follows: Section 2 is an overview of the aspects of relevant to the modeling problem. The device- views of modeling are briefly examined. The QSIM in the construc- system the of The for QSI, is discussion on the to diagnosis as to other work in the field. Section 7 is issues, and contain several qualitative physical centered and process-centered [19, 221 representation tion of QSI, are summarized. Section 3 puts QSI identification algorithm, qualitative noise filtering method, designed to serve as a preprocessor presented strengths and weaknesses of the QSI algorithm, well as model formulation, a conclusion. The appendices cover some technical examples of the program into a detailed and correctness in Section 5. Section 6 contains a comprehensive Section 4 contains its complexity perspective. and analyses of the broader explanation its applicability and its relation properties. in action. 2. Qualitative physical reasoning: an overview This section is an overview of the technique of qualitative simulation; the major approaches will be briefly discussed in chronological order. De Kleer and Brown [7] established the foundations of the qualitative calculus. by a finite their signs. The time derivatives of each quantity The basic idea is that real (continuous) quantities are represented number of qualitative values: is are similarly represented. The fact that a quantity represented by its derivative having the value +. A mechanistic world view is adopted; every system to be simulated is assumed to be a mechanism composed of is increasing, for instance, \fA.C.C. Say, S. Kuru ! Artijicial Intelligence 83 (1996) 75-141 77 is supposed if the program in the simulator’s component input system models are formed by connecting com- simple components. The library (which obviously has to be ponent models large to deal with a large variety of to be able systems), according to the device topology of the system. Each component has its own “law”, an equation relating the variables involved with it. The laws of all the this means that they can be components the qualitative values of all the solved as a system of equations variables to to determine which transitions other syslem states, where certain variables have qualitatively different values, are possible. A graph of system states, each path through which represents a different prediction to determine in them. The derivatives are examined for the behavior of the simulated system, is thus constructed. of a mechanism have to be satisfied; the constraints use of a process their configuration, library reasons) is the process-centered as discussed. An alternative in the considered active. A process reflecting Since time derivative The method of de Kleer and Brown embodies a component-centered scene are determined is something which causes changes; approach approach of to modeling, the relationships holding among the qualitative process theory [13]. In this theory, that are by the processes quantities currently like heating, cooling, boiling, stretching, etc. Given information about the values, individuals, (which should be as big as and possible, again for the above-mentioned is made to come up with the system m’odel, properly composed of various model fragments contributed by the the system active processes, quantities it is possible t’o determine which quantity is nearing which landmark. (A landmark is a a point value which is significant for the purposes of the symbol the set of active processes, change model.) The system state and, sometimes, when a quantity crosses a landmark value. A state graph, similar to the one mentioned states to successor states determined an of qualitative simulation. The method of transition ordering, which can be used to determine which of a group of related quantities in the system will change qualitative value earlier, was first presented in [38]. Williams focused his work on the domain of electrical circuits, where the need for tutoring, design, and diagnosis aids which can explain the workings of the circuits in terms of causal explanations based on the simple component is constructed by linking predecessor in this manner. role is also kept for quantities, in the previous paragraph, laws is evident. the perfection [38] played representing impose on information important Williams they that in The QSIM algorithm [19] is in many ways the most advanced qualitative of qualitative models in our simulator. We chose to adopt QSIM’s representation research. QSIM leaves the modeling task entirely system model has to be written explain in detail, before simulation can begin. in the qualitative to the user; a correct and complete format, which we will now Each ODE (Ordinary Differential Equation) obeying certain restrictions can be that is, a to a corresponding QDE (Qualitative Differential Equation), translated set of qzulitative constraints, which describes are time-invariant relationships between the same system. These constraints func- the parameters (continuous-valued \f78 A.C.C. Say, S. Kuru I Artificial Intelligence 83 (1996) 7.5-141 Table 1 The qualitative constraint types Constraint ADD(X, Y, Z) DERIV(X, Y) M+ (X, Y) M-(X, Y) MINUS(X, Y) MULT(X, Y, Z) Explanation Z(C) = X(t) + Y(t) dXldt = Y X(t) =f(Y(t)), wheref’ > 0 throughout X(t) =f(Y(t)), wheref’ <O throughout x(t) = -Y(t) z(t) = X(t) * Y(t) (except tions of time) comprising the system. There are six types of constraints Each constraint type) may possess those of corresponding values (CVs) of particular values of the parameters manner, additional be represented. QDEs are formed of instances of constraints parameters. A system may have several operating regions, each corresponding cases in which it is governed by a different QDE, as exemplified below. (Table 1). tuples of it binds; in this information about the relation embodied by the constraint can linking the system to the DERIV As a classic [22] example that will also be used later in the discussion, consider how a simple U-tube (Fig. 1) is modeled. The U-tube, state, is made of two tanks connected by a pipe. The QDEs for the cases where tank A or regions to tank B are burst will also be considered. So one has three operating model: NORMAL, A-BURST, and B BURST. in its “healthy” After a lot of sim",
            {
                "entities": [
                    [
                        74,
                        141,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 298 (2021) 103502Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExplaining individual predictions when features are dependent: More accurate approximations to Shapley values ✩Kjersti Aas∗, Martin Jullum, Anders LølandNorwegian Computing Center, P.O. Box 114, Blindern, N-0314 Oslo, Norwaya r t i c l e i n f oa b s t r a c tArticle history:Received 3 October 2019Received in revised form 5 January 2021Accepted 29 March 2021Available online 31 March 2021Keywords:Feature attributionShapley valuesKernel SHAPDependenceExplaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from such models by learning simple, interpretable explanations. Shapley value is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model. Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent. Since Shapley values currently suffer from inclusion of unrealistic data instances when features are correlated, the explanations may be very misleading. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionInterpretability is crucial when a complex machine learning model is to be applied in areas such as medicine [1], fraud detection [2] or credit scoring [3]. In many applications, complex hard-to-interpret machine learning models like deep neural networks, random forests and gradient boosting machines are currently outperforming the traditional, and to some extent interpretable, linear/logistic regression models. However, often there is a clear trade-off between model complexity and model interpretability, meaning that it is often hard to understand why these sophisticated models perform so well. This lack of explanation constitutes a practical issue – can I trust the model? [4], and a legal issue – those who develop the model can be required by law to explain what the model does to those who are exposed to automated decisions (the General Data Protection Regulation [5]). In response, a new line of research has emerged that focuses on helping users to interpret the predictions from advanced machine learning methods.Existing work on explaining complex models can be divided into two main categories; global and local explanations. The former tries to describe the model as a whole, in terms of which variables/features that influenced the general model the most. Two common methods for such an overall explanation are permutation based feature importance [6] or partial depen-dence plots [7]. Local explanations, on the other hand, try to identify how the different input variables/features influenced a specific prediction/output from the model, and are often referred to as individual prediction explanation methods. Such ✩This paper is part of the Special Issue on Explainable AI.* Corresponding author.E-mail addresses: kjersti.aas@nr.no (K. Aas), martin.jullum@nr.no (M. Jullum), anders.loland@nr.no (A. Løland).https://doi.org/10.1016/j.artint.2021.1035020004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fK. Aas, M. Jullum and A. LølandArtificial Intelligence 298 (2021) 103502explanations are particularly useful for complex models which behave rather different for different feature combinations, meaning that the global explanation is not representative for the local behavior.Local explanation methods may further be divided into two categories: model-specific and model-agnostic (general) ex-planation methods. In this paper the focus is on the latter. The methods in this category usually try to explain individual predictions by determining simple, interpretable explanations of the model specifically for a given prediction. Three exam-ples are Explanation Vectors [8], LIME (Local Interpretable Model-agnostic Explanations) [4] and Shapley values [9–11]. The latter approach, which builds on concepts from cooperative game theory [12], has a series of desirable theoretical properties [11].The Shapley value is a method originally invented for assigning payouts to players depending on their contribution towards the total payout. In the explanation setting, the features are the players and the prediction is the total payout. In this framework, the difference between the prediction and the average prediction is perfectly distributed among the features. This property distinguishes Shapley values from other methods like for example LIME, which does not guarantee perfectly distributed effects. It should be noted that LIME and Shapley values actually explain two different things. For instance, if the prediction to be explained is the probability of person A crashing his car, the sum of the Shapley values for all features is equal to the difference between this prediction and the mean probability of a person crashing his car, where the mean is taken over all persons having a driver license. The sum of the LIME values is also equal to the difference between this prediction and a mean probability, but here the mean is taken over all persons “similar to” person A. That is, Shapley values explain the difference between the prediction and the global average prediction, while LIME explains the difference between the prediction and a local average prediction. Appropriate model explanations should be consistent with how humans understand that model. In their study, [11] found a much stronger agreement between human explanations and Shapley values than with LIME.Shapley values have also been used for measuring global feature importance. For instance, it has been used to partition the R2 quantity among the d features in a linear regression model (“Shapley regression values”), both assuming independent features [13], and more recently also for dependent features [14–16]. A general Shapley framework for global additive importance measures is suggested by [17].The main disadvantage of the Shapley value is that the computational complexity grows exponentially and becomes in-tractable for more than, say, ten features. This has led to approximations like the Shapley Sampling Values [9,10] and Kernel SHAP [11]. The latter requires less computational power to obtain a similar approximation accuracy. Hence, in this paper, the focus is on the Kernel SHAP method. While having many desirable properties, this method assumes feature independence. In observational studies and machine learning problems, it is very rare that the features are statistically independent, meaning that the Shapley value methods suffer from inclusion of predictions based on unrealistic data instances when features are correlated. This is the case even if a simple linear model is used.The main contribution of this paper is to extend the Kernel SHAP method to handle dependent features. The methodology has been implemented in the R-package shapr available on CRAN [18]. Our paper is a revised version of an unpublished paper [19], which, to the best of our knowledge, was the first to address and account for dependence within Shapley value based individual prediction explanation.Later there has been several papers discussing the difference between our approach and the original Kernel SHAP method, termed respectively the observational and the interventional approach in the succeeding literature. Lundberg and Lee [11] advocate the observational approach, but uses the interventional approach for computational reasons. Janzing et al. [20] argue for a causal interpretation of Shapley values, where they replace conventional “conditioning by observation” with “conditioning by intervention”, as in Pearl’s do-calculus [21]. Frye et al. [22] suggest so-called asymmetric Shapley val-ues as a way to incorporate causal knowledge in the real world by restricting the possible permutations of the features when computing the Shapley values to those consistent with a partial causal ordering. In line with our approach, they then apply conventional conditioning by observation to make sure that the explanations respect the multivariate distribution of the data, which they denote the “data manifold”. Heskes et al. [23] generalize the work on causal Shapley values further, partly based on our approach. They define our approach as “symmetric conditional Shapley values”. Chen et al. [24] argue that neither is preferable in general, but that the choice between the observational (“true to the data”) or interventional (“true to the model”) approach is application dependent.All the above-mentioned approaches are model-agnostic in the sense that they can be used to explain any machine learning method. In addition to these methods, there is a method called TreeSHAP [25] which is specially designed for tree ensemble methods like XGBoost [26]. According to the authors, TreeSHAP accounts for some of the feature dependence, but not all. As will be apparent from our simulation experiments, this method can be inaccurate when the features are dependent.The rest of this paper is organized as follows. Section 2 reviews the Shapley values and the Kernel SHAP method. Sec-tion 3 contains the main contribution of the paper, that is the proposed approaches for accounting for the dependence, while Section",
            {
                "entities": [
                    [
                        135,
                        244,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 90 ( 1997) 25-77 Artificial Intelligence Continuous case-based reasoning A. Ram ‘, J.C. Santamaria* College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA Received December 1994; revised September 1996 Abstract Case-based reasoning systems have traditionally been used to perform high-level reasoning in problem domains that can be adequately described using discrete, symbolic representations. However, many real-world problem domains, such as autonomous robotic navigation, are better representations. Such problem domains also require continuous characterized using continuous performance, such as on-line sensorimotor interaction with the environment, and continuous adap- tation and learning during the performance task. This article introduces a new method for contin- uous case-based reasoning, and discusses its application to the dynamic selection, modification, and acquisition of robot behaviors in an autonomous navigation system, SINS (self-improving navigation system). The computer program and the underlying method are systematically eval- uated through statistical analysis of results from several empirical studies. The article concludes with a general discussion of case-based reasoning issues addressed by this research. Keywords: Case-based control; Motor schema-based navigation reasoning; Machine learning; Reinforcement learning; Robot navigation; Reactive 1. Introduction reasoning Case-based systems have traditionally been used to perform high-level rea- soning in problem domains that can be adequately described using discrete, symbolic representations. For example, CHEF uses case-based planning to create recipes [ 211, AQUA uses case-based explanation to understand newspaper stories [ 451, HYPO uses case-based interpretation for legal argumentation [ 51, MEDIATOR uses case-based prob- lem solving for dispute resolution [26], and PRODIGY uses case-based reasoning in the form of derivational analogy for high-level robot planning [60]. * Corresponding ’ E-mail: ashwin@cc.gatech.edu. URL: http://www.cc.gatech.edu/faculty/ashwin. author. E-mail: carlos@cc.gatech.edu. URL: http://www.cc.gatech.edu/ai/students/jcs. 0004-3702/97/$17.00 PIISOOO4-3702(96)00037-9 @ 1997 Published by Elsevier Science B.V. All rights reserved. \f26 A. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 In our research, we have been investigating real-time problem domains, the problem of performance such as autonomous and learn- robotic navigation. representations require different underlying solving process and place ad- [ 131. In this article, we present a reasoning which can be used to guide action and to learn the systems for the design of case-based this class of problems, to addressing In addition reasoning problem domains ing in continuous, Continuous ditional constraints new method in continuous research presented here has implications in general. problem domains. on the problem for case-based domains. 2 Learning called continuous Our method, mental assumptions bolic problem guided by previous adapting ing lies on the retrieve-adapt-apply-learn [21,27,49]. them. New cases are of what might be called “discrete” experience. New problems reasoning is integrated with performance. case-bused reasoning, shares many of the funda- in sym- case-based is cases and test- and solving mechanism re- systems reasoning are solved by retrieving solutions proposed cycle common by evaluating to case-based Performance learned them on a real or simulated world. The basic problem However, of continuous the requirements problem domains are significantly different reasoning methods. the problem of driving a car on a highway. Car driving experiences in ways that do not permit ready application of traditional case-based For example, consider can vary from one another in one experience might continuously from, say, the highway operate continuously; process at which and 54 mph in another. Within a given episode, to an exit ramp. The problem solving and learning process must there in the to do so. ’ in infinitely many ways. The speed of a car might be 55 mph the speed of the car to moment, and significantly think, nor a logical point vary, both infinitesimally from moment to stop and is no time Such problem domains are “continuous” in three senses. First, they require continuous (within representations problem domains Second, continuous the limits of the digitization task requires is a continuous For example, a robotic navigation information. The input representations. ceptual and motor control data from ultrasonic and other sensors; of an input parameter can vary infinitesimally sampling parameters). mance. For example, driving a car requires continuous, solving performance is incremental to the reasoning system can at best execute evaluate actually encounters and learning. As the problems encountered become more varied and difficult, necessary in an incremental manner to rely on continuous experiences. of per- stream of perceptual the data itself is analog in the sense that the value and require continuous perfor- on-line action. Often, problem of necessity because of limited knowledge available the to it and then re- it require continuous adaptation it becomes to act, and to adapt actions and learn from system and/or because of the unpredictability the “best” short-term its progress. A robot, for example, may not know where obstacles these problem domains detailed knowledge to use fine-grained, of the environment; actions available the environment them. Third, feedback lie until from 2 We do not eschew symbolic representations; representations, whether symbolic, numeric, or otherwise. rather, proposed the issue is the continuous, time varying nature of any \fA. Ram, J.C. Santamaria/Art$cial Intelligence 90 (1997) 25-77 21 enhancements requires significant in discrete, symbolic Case-based reasoning in such problem domains reasoning methods used to be addressed. When are two experiences the basic case-based Several issues need warrant consideration as independent is the entire car trip from one’s house example, can be used to guide and improve one’s driving performance should “continuous How can they be used to guide performance? How are they learned and modified experience? And how can this performance on-line, In to systems. to is the scope of a single case? For to the grocery store a single case that in future situations? How they be matched and retrieved? through into a continuous, real-time process? this article, we provide cases” be represented? How should and learning be integrated reasoning different cases? What enough an answer to these questions task. The proposed methods are fully for its performance for continuous adaptation experience. The computer through is into a robot navigation puter system which uses reactive control reasoning learning system), implemented tion of the task domain, proposed method and eral empirical studies are analyzed using proach, putational model, mic choices, eters under various mental methods. conditions, and studies of the system the appropriate to predict circumstances, to understand the computer to determine to analyze to analyze the system of the performance element the relevant (self-improving system, SINS based on our research implemented in a com- element and case-based and for continuous navigation robot. We begin with a descrip- technical details of the sev- to evaluate our approach. The results of these the efficacy of the ap- in terms of the design of the com- and algorith- the system’s design param- environ- the proposed system behavior under changing the “sources of power” behind it. We then present that implements representational to demonstrate settings for statistical methods the behavior of the system on a Denning MRV-III after which we discuss impact of different recommended systems-and to many case-based learning We conclude with the contributions systems reasoning of a case in response case”-a representations and adaptation. We discuss of the solution reasoning sign of case-based our approach, which are common cuss the merits of fine-grained support on-line adaptation”-adaptation tion, as in standard case-based modification the notion of a “virtual may not have actually had-and experiences subsequent uous dynamic memory”, reasoning SINS system, beneficial evaluation methods used here can be used fruitfully evaluate a proposed computer the system. analogous [53]. We argue such as time history (as similar experiences. Our system, to a situation representative in case-based in standard case-based reasoning) reasoning systems systems system but also analyze of our research and their implication for the de- in general. We discuss the assumptions underlying and show how such representations reasoning systems. Next, we dis- can the differences between “solution to fit a new situa- by a case “case modification”-retroactive in which experience it is used. We introduce that the system may or show how virtual cases can represent not just past but also alterations by introduced a kind of “contin- implements case-based therefore, to the dynamic memory of traditional that these and other than rather innovations instantaneous in general. We also believe representations, introduced in the can be that the empirical in other AI applications not just to the theoretical model underlying \f28 A. Ram, J.C. Santamar~a/Artijicial Intelligence 90 (1997) 25-77 2. The robot navigation task Autonomous robotic navigation is defined as the task of finding a path along which a robot can move safely from a source point to a destination point in an obstacle ridden terrain, and executing the actions to carry out the movement in a real or simulated world. Several methods have been proposed for this task, ranging from high-level plan- ning methods to reactive methods. High-level planning methods use extensive world knowledge about available actions and their consequences to formul",
            {
                "entities": [
                    [
                        65,
                        96,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1757–1789Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDecentralized MDPs with sparse interactionsFrancisco S. Melo a,∗, Manuela Veloso ba GAIPS – INESC-ID, TagusPark, Edifício IST, 2780-990 Porto Salvo, Portugalb Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 26 April 2010Received in revised form 29 April 2011Accepted 7 May 2011Available online 10 May 2011Keywords:Multiagent coordinationSparse interactionDecentralized Markov decision processesCreating coordinated multiagent policies in environments with uncertainty is a challengingproblem, which can be greatly simplified if the coordination needs are known to belimited to specific parts of the state space. In this work, we explore how such localinteractions can simplify coordination in multiagent systems. We focus on problems inwhich the interaction between the agents is sparse and contribute a new decision-theoreticmodel for decentralized sparse-interaction multiagent systems, Dec-SIMDPs, that explicitlydistinguishes the situations in which the agents in the team must coordinate from thosein which they can act independently. We relate our new model to other existing modelssuch as MMDPs and Dec-MDPs. We then propose a solution method that takes advantageof the particular structure of Dec-SIMDPs and provide theoretical error bounds on thequality of the obtained solution. Finally, we show a reinforcement learning algorithm inwhich independent agents learn both individual policies and when and how to coordinate.We illustrate the application of the algorithms throughout the paper in several multiagentnavigation scenarios.© 2011 Elsevier B.V. All rights reserved.1. IntroductionDecision-theoretic models, such as Dec-MDPs and Dec-POMDPs, provide a rich framework to tackle decentralizeddecision-making problems. However, using these models to create coordinated multiagent policies in environments withuncertainty is a challenging problem, even more so if the decision-makers must tackle issues of partial observability. Assuch, solving finite-horizon Dec-POMDPs is a NEXP-complete problem and thus computationally too demanding to solveexcept for the simplest scenarios.Recent years have witnessed a profusion of work on Dec-POMDP-related models that aim at capturing some of thefundamental features of this class of problems, such as partial observability, without incurring the associated computationalcost. In this paper, we contribute to this area of research, and introduce a new model for cooperative multiagent decision-making in the presence of partial observability. Our model is motivated by the observation that, in many real-world scenarios,the tasks of the different agents in a multiagent system are not coupled at every decision step but only in relativelyinfrequent situations. We refer to such problems as having sparse interactions.Multi-robot systems provide our primary motivation, as the interaction among different robots is naturally limited byeach robot’s physical boundaries, such as workspace or communication range, and limited perception capabilities. Therefore,when programming a multi-robot system to perform some task, one natural approach is to subdivide this task into smallertasks that each robot can then execute autonomously or as part of a smaller group. As an example, consider the scenarioin Fig. 1. In this scenario, three robots must navigate to their goal locations, marked with dashed lines. While Robot 3 can* Corresponding author.E-mail address: fmelo@inesc-id.pt (F.S. Melo).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.05.001\f1758F.S. Melo, M. Veloso / Artificial Intelligence 175 (2011) 1757–1789Fig. 1. Example of a simple navigation task.navigate to its goal, disregarding the remaining robots, Robots 1 and 2 need to coordinate so as not to cross the narrowdoorway simultaneously. However, this coordination needs only occur around the doorway.Other examples include problems of sequential resource allocation, in which groups of agents must interact only tothe extent that they need to share some common resource. In this context, several methods have been proposed thatleverage sparse interactions by decomposing the global problem into several smaller local problems that can be solvedmore efficiently, and then combining the obtained solutions [1,2]. Such approaches, however, are not particularly concernedwith partial observability issues. Additional examples include problems of task allocation, where the different agents ina multiagent system are assigned to different subtasks, and the interactions between the agents when performing suchsubtasks is localized to small regions of the joint state space [3]. Such problems include emergency response scenarios,where emergency teams are assigned different subtasks (for example, assisting different victims) and interact only in specificlocalized situations.Several approaches have exploited simplified models of interaction in multiagent settings. For example, learning tasksinvolving multiple agents can be partitioned in a state-wise manner, allowing different agents to independently learn theresulting “smaller tasks” [4]. Similarly, a hierarchical learning algorithm can be used that considers only interactions betweenthe different agents at a higher control level, while allowing the agents to learn lower level tasks independently [5]. Otherworks use coordination graphs to compactly represent dependences between the actions of different agents, thus capturingthe local interaction between them [6,7]. Local interactions have also been exploited to minimize communication duringpolicy execution [8] and in the game-theoretic literature to attain compact game representations. Examples include graphicalgames [9] and action-graph games [10].In this article we consider Dec-MDPs with sparse interactions, henceforth Dec-SIMDPs. Dec-SIMDPs leverage the indepen-dence between agents to decouple the decision process in significant portions of the joint state space. In those situationsin which the agents interact—the interaction areas—Dec-SIMDPs rely on communication to bring down the computationalcomplexity of the joint decision process. Dec-SIMDPs balance the independence assumptions with observability: in anygiven state, the agents are either independent or can share state information (e.g., by communicating).1 A related modelhas recently been proposed under the designation of distributed POMDPs with coordination locales [13]. We postpone untilSection 6 a more detailed discussion of this and other related models.The contributions of this article are threefold. We provide a precise formalization of the Dec-SIMDP model and discussthe relation with well-established decision-theoretic models such as Dec-MDPs, MMDPs and MDPs. We then contribute twonew algorithms that exhibit significant computational savings when compared to existing algorithms for Dec-SIMDPs, andillustrate their application in several simple navigation tasks. Finally, we investigate the influence of interaction areas in theperformance of a multiagent system and contribute a new learning algorithm that allows each agent in one such system toindividually learn those interaction areas.2. Decision-theoretic models for multiagent systemsWe now review several standard decision-theoretic models that are relevant for our work [14–16]. We start with singleagent models, namely Markov decision processes (MDPs) and their partially observable counterparts (POMDPs) before mov-ing to multiagent models such as multiagent MDPs (MMDPs) and their partially observable counterparts (Dec-POMDPs). Weestablish the notation we use and review some fundamental concepts of later relevance.To fully specify the different models in this section, we should explicitly include the initial state x0 or a distributionthereof. However, in order to avoid cluttering the notation, we omit the explicit reference to this initial state, with theunderstanding that one such state is implicit.1 Both independence assumptions and communication can significantly bring down the computational complexity in Dec-POMDP related models [11,12].\fF.S. Melo, M. Veloso / Artificial Intelligence 175 (2011) 1757–178917592.1. Markov decision processesA Markov decision process (MDP) describes a sequential decision problem in which a single agent must choose an action atevery time step to maximize some reward-based optimization criterion. We use MDPs in the Dec-SIMDP model proposed inSection 3 to describe an agent in those situations where its actions are independent of other agents—i.e., in those situationswhere the agent can be modeled individually.Formally, an MDP is a tuple M = (X, A, P, r, γ ), where X represents the finite state space, A represents the finiteaction space, P(x, a, y) represents the transition probability from state x to state y when action a is taken, and r(x, a)represents the expected reward for taking action a in state x. The scalar γ is a discount factor.A Markov policy is a mapping π : X × A → [0, 1] such that, for all x ∈ X ,(cid:2)a∈Aπ (x, a) = 1.Solving an MDP consists of determining a policy π so as to maximize, for all x ∈ X ,V π (x) = EπX(t), A(t)(cid:3)(cid:4)γ tr∞(cid:2)t=0(cid:7)(cid:5) (cid:6)(cid:6) X(0) = x,where X(t) denotes the state at time step t, A(t) denotes the action taken at that time instant such that(cid:8)(cid:6)(cid:6) H(t) = h(cid:9)(cid:8)(cid:6)(cid:9)(cid:6) X(t) = xP= PA(t) = a= π (x, a),where H(t) = { X(0), A(0), . . . , X(t − 1), A(t − 1), X(t)} is the random variable corresponding to the history of the MDP up totime t, and h denotes a particular realization of H(t) such that X(t) = x. We write A(t) ∼ π to denote the above dependenceof A(t) on the policy π . We define the Q -function associated with a policy π asA(t) = a(cid:3)Q π (x, a) = Eπ(cid:4)",
            {
                "entities": [
                    [
                        138,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 80–103Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTeaming up humans with autonomous synthetic charactersRui Prada∗, Ana PaivaIST-Technical University of Lisbon and INESC-ID, Avenida Prof. Cavaco Silva – Taguspark, 2744-016 Porto Salvo, Portugala r t i c l ei n f oa b s t r a c tArticle history:Received 3 August 2007Received in revised form 17 August 2008Accepted 24 August 2008Available online 7 September 2008Keywords:Group dynamicsTeamworkSocial intelligenceAutonomous synthetic charactersBelievabilityComputer–human interactionAutonomous synthetic characters have the potential to promote the social engagement ofusers in virtual environments, enhancing their interaction experience. In computer games,for example, poor interaction with game characters can drastically detract from the gamingexperience, making the design of autonomous synthetic characters an important issue. Inparticular, in Role Playing Games (RPGs), for example, users and autonomous charactersoften perform in a group. Usually, the role of such characters is very limited since theylack the social skills to perform coherently in group scenarios.The goal of the work presented here is to endow autonomous synthetic characters withsocial skills that allow them to perform in groups with human members. However, tosuccessfully achieve this, it is not enough to assure that the characters behave in a coherentmanner from an individual perspective or that they are able to perform the group taskoptimally. It is also necessary that the autonomous characters exhibit behaviours that arecoherent with the group’s composition, context and structure.For this reason, we have developed a model to support group dynamics of autonomousinspired by theories developed in human socialsynthetic characters (SGD model)psychological sciences. This model defines the knowledge that each individual should buildabout the others and the group, and how this knowledge drives their interactions. Themodel was used in a collaborative computer game that was tested with users. The resultsshowed that the model had a positive effect on the users’ social engagement, namely, ontheir trust and identification with the group.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe creation of autonomous synthetic characters has been widely studied in the past years, especially because such char-acters can improve the interaction of users with virtual environments [7]. For this reason, autonomous synthetic charactershave been used in several different domains such as entertainment [11,45], business [9] and education [59,65]. They havebeen particularly important in computer games that make use of narrative, such as Role Playing Games (RPGs), because theyconstitute the main driving force to create successful narrative experiences that improve gameplay [39,66].The crucial issue in designing autonomous synthetic characters is making them believable or creating the “illusion oflife” for the user [8]. In other words, autonomous synthetic characters must be coherent with the users’ expectations.The work presented here focuses on believability issues of autonomous synthetic characters when they interact as agroup. The work is focused on groups with few members (small groups) who are committed to a collaborative task andwithout a strong organisational structure. Thus, we are not concerned with large groups such as crowds or complex societies.In addition, our goal is to engage the user as an active member of the group.* Corresponding author.E-mail addresses: rui.prada@gaips.inesc-id.pt (R. Prada), ana.paiva@gaips.inesc-id.pt (A. Paiva).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.006\fR. Prada, A. Paiva / Artificial Intelligence 173 (2009) 80–10381Typically, autonomous characters lack the necessary social skills to interact in a group. Therefore, their role in the groupis very restricted, and their autonomy is limited. For example, in RPGs, the autonomous characters only take secondaryroles, such as a salesperson, while the main characters are controlled by the user.Moreover, most of the studies conducted on the believability of autonomous synthetic characters are focused on theinteractions of a single user with a single character [9,57]. However, in group scenarios, it is not enough to ensure that thecharacters behave in a coherent manner from an individual perspective; it is also necessary that they exhibit behaviours thatare coherent with the group’s composition, context and structure. On the other hand, approaches to create team-orientedautonomous agents focus primarily on the optimal results of the group [46,70,77]. Although the group’s performance mayaffect the experience of users when interacting in a group, their perception about their experience is highly influenced bytheir social identification and their trust of the group [3,22]. In fact, these two factors are closely related to the satisfactionof people in group interactions [4].In order to achieve such an experience and properly engage users with the group, we argue that autonomous members’behaviours cannot be solely driven by their need to solve the task but also by the socio-emotional dimensions of the group,such as the structure of interpersonal relations.To prove this, we have developed a model for group dynamics (SGD model) that allows each individual character toreason about other characters and the group. This model was inspired by theories developed in human social psychologicalsciences and is driven by a characterisation of the different types of interactions that may occur in the group, taking intoaccount the socio-emotional interactions as well as the task-related ones.We have implemented the model into the behaviour of autonomous synthetic characters that collaborate with the userin the resolution of tasks within a virtual environment (a collaborative game). This game was developed with the purposeof testing the effects of our model in users’ interaction experiences. The results of the experiment showed that the modelhad a positive effect on the users’ trust and social identification with the group.This paper is organised as follows. First, we discuss related work concerning the interaction of autonomous characters in agroup. Then, we present the fundamentals of group dynamics on which we grounded our model followed by the descriptionof the model itself. Then, we describe the computer game that we developed to test our model and the experiment thatwas conducted to assess the effects of the model in the users’ interaction experience. We finish with some conclusions andcomments regarding future work.2. Related workThe problem of multiple autonomous synthetic agents that interact in a group has been previously addressed by severalresearchers. The focus of their approaches can be seen in two different perspectives: (1) centred on believability issues ofthe group interactions or (2) centred on the efficiency of the group’s performance. We will briefly describe some of themost relevant work and make some comments regarding the focus of the work presented in this paper.The first example of the first perspective can be found in Reynolds’ Boids [63], which implements a flocking behaviour ina group of flying creatures. In the same line of work, we can additionally find research concerning the generation of crowds[53] that is often used in commercial systems for film creation. One well-known example of this is “The Lord of the Rings”film trilogy [54], which includes numerous fighting scenes involving armies of thousands of warriors, most of these beingplayed by synthetic actors generated by the MASSIVE1 platform.The Boids’ flocking behaviour and crowd generation make use of emergent group dynamics and result in a believablelife-like group behaviour. However, agents in these examples do not have deep social awareness and lack the ability to buildsocial relations, which we believe to be essential for the interaction with a user. In addition, these groups do not have anexplicit common goal.Guye-Vuilleme [28] has extended the work on the generation of the behaviour of crowds by introducing a model for thesimulation of the movement and interaction of individuals driven by the group’s social context. This includes behavioursfor social avoidance of collisions, social approach and the calculation of suitable interaction distances and angles. The socialcontext consists of a model of interpersonal relationships of individuals. Although incorporating interpersonal relations toinfluence the autonomous characters’ behaviours, Guye-Vuilleme’s crowds cannot be seen as performing teamwork, sincethey do not have an explicit collaborative task.Another example is the AlphaWolf [71] system, which simulates the behaviour of a pack of six grey wolves. In thissystem, the different synthetic characters are able to build domination-submission relationships. These relations are builtin the form of emotional memories that drive the characters’ behaviour. In addition, three users can interact with thesystem and influence the behaviour of three of the wolves. AlphaWolf has successfully implemented a believable simulationof group interactions in a pack of wolves, and it has engaged the user in such interactions. However, the user and thesynthetic characters do not engage in the resolution of a collaborative task and do not have a strong notion of group.Schmitt and Rist [67] developed a model of virtual group dynamics for small group negotiations. In their system, usersdelegate the task of scheduling their appointment meetings to a virtual agent. The agents will later meet in an arena andnegotiate the times and dates of the meetings. Each agent has an individual personality and builds social attraction relations1 For more details on MASSIVE, please check http://www.massivesoftware.com.\f82R. Prada, A. Paiva / Artificial Intelligence 173",
            {
                "entities": [
                    [
                        135,
                        189,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 75 (1995) 241-295 Artificial Intelligence Robust reasoning: integrating rule-based and similarity-based reasoning Ron Sun* Department of Computer Science, University of Alabama, Tuscaloosa, AL 35487, USA Received February 1993; revised March 1994 Abstract through to account for without to be accounted The paper attempts for common patterns is identified. A principled architecture with dual representations is performed, which unifies these patterns in commonsense reasoning as embodied reasoning inte- in connectionist models. grating rule-based reasoning and similarity-based syn- Reasoning examples are analyzed and a diverse range of patterns that were thesis based on simple rules and similarities individually. A two-level before difficult for connectionist in detail how the common patterns can be generated by this caving mechanism. Finally, it is argued that the brittleness problem of rule-based models can be remedied in a principled way, with the theory proposed here. This work demonstrates rules and similarities can result in more robust reasoning models, and many seemingly disparate patterns of commonsense reasoning are actually different manifestations of the same underlying process and can be generated using the integrated architecture, which captures the underlying process to a large extent. is proposed as a computational mechanism out the theory. It is shown specialized mechanisms that combining 1. Introduction 1.1. Patterns in reasoning Commonsense reasoning reasoning monsense times fallible such commonsense very concept, is one of the main problems in artificial structured yet flexible, and usually is somewhat [ 11,29,61]. It has been extremely difficult intelligence. Com- reliable but some- to capture the to characterize: we cannot define for AI programs knowledge and reasoning in all its power and flexibility. Even commonsense reasoning, is difficult * E-mail: rsun@cs.ua.edu 0004-3702/95/$09.50 SSDIOOO4-3702(94)00028-Y @ I995 Elsevier Science B.V. All rights reserved \f242 R. Sun/Art$cial Intelligence 75 (199.5) 241-295 reasoning is. Roughly what commonsense what knowledge at least for the kind of commonsense informal kinds of reasoning oftentimes more critical than accuracy. in everyday is, just as it is hard to define what intelligence speaking, however, corm-nonsense reasoning explored life regarding mundane is, or reasoning can be taken, to issues, where speed is in this work, as referring the study It The study of commonsense reasoning as envisaged here is neither about reasoning reasoning idiosyncratic across a wide range of domains in any particular domain, reasoning patterns; that is, the recurrent, domain-independent that are applicable of a particular domain, nor about deals with commonsense basic forms of reasoning believe of commonsense Noticing ited by the protocols, he argues for alternative commonsense common patterns plicable across domains of them). This standpoint studying commonsense (as we that such forms do exist. ’ ) Allan Collins collected a large number of protocols and the like. the reasoning patterns exhib- found in various for patterns in the existence of believe that are widely ap- (versus domain specific and/or ad hoc processes) logical formulation (thus they actually developed a generalized and the data on which it is based is also the starting point of logic in explaining formalisms [ 8, lo] of traditional tasks. Collins and Michalski in the area of elementary the inadequacy in this work. geography reasoning reasoning [lo] 1.2. Rigor and flexibility reasoning to enable effective on the type of models is how we should handle the the exact prerequisites [ 10,27,35]. inferences agent: and so forth issue in modeling commonsense in reasoning on one hand, and the flexible, approximate, One important rigor and clarity and evidential character of the same process on the other hand. For example, we need clearly-defined structures edge possessed by a cognitive outcome of a given situation, requirements as unsuitable; works can be considered systems with the power of non-linearity from a few crucial shortcomings. For example, because of the complexity of non-linear signal propagation they cannot keep track of their reasoning processes and produce explanations been attempted by e.g. portance of conditions not) ; they do not have enough symbol manipulation for compositionality and we need precise ways of encoding knowl- the precise This imposes some necessary net- they can simulate any rule-based they suffer functions, rule extraction has the im- are necessary or essential, and which are e.g. to fully account [ 171) ; they cannot distinguish (i.e. which conditions for, although of their node activation layers, for their conclusions that are applicable. Simple backpropagation through multiple and systematicity for an action, introspection) in symbolic capabilities, (although (through systems existing [ 161. On the other hand, commonsense reasoning data (such as Collins’s protocols, later) also shows that there is much flexibility detailed agent. Specifically, we need means of evidential combination, with graded this, we also need corresponding to capture In order to be in the reasoning of a cognitive in our model. (fuzzy information flexibility ’ The question of whether independent, recurrent common patterns especially instance-based in commonsense is open reasoning models and rule-based (cf. 111,291). reasoning models It is somewhat related (see e.g. [ 36,421) there exist any domain reasoning, in reasoning, to the debate between \fR. Sun/Artificial Intelligence 75 (1995) 241-295 243 (to be values [ 18,581. confidence incrementally and capable of accumulating [ 34,611). We should also be able to deal with similarity (In this paper, the word$exibility is used throughout and uncertain) explained; reasoning above aspects; see Section 7.3 for further discussions.) in their prevailing in that only several be handled with separate mechanisms [ lo] regarding psychologically motivated work) ; to model similarity-based reasoning, [ 3,261. Rule-based forms seem too cumbersome isolated kinds of inexactness and analogical to denote these systems to handle various sorts of inexactness can be accounted for and they have to and approaches or analogical and/or complex search procedures too. * to strike an systems may have difficulties with other types of flexibility on both sides, rigor and flexibility, we have places a major constraint they require special structures/mechanisms (cf. [ 111 regarding them carefully-this the requirements on developing logic-based To satisfy Traditional rule-based a balance between adequate theory to account for commonsense reasoning. 1.3. Connectionism versus rule-based reasoning issue that comes to mind A relevant reasoning. versus rule-based of implementing rule-based as well as other types of reasoning. However l Can connectionist models of rule-based in this connection is the debate of connectionism It is quite clear now that connectionist models are capable etc.), in a variety of ways (e.g., [ 1,4,28,44,56], reasoning the following questions reasoning do more in terms of accounting remain: for robust human l Can connectionist soning examples rule-based systems reasoning reasoning models (as questioned reproduce directly in, for example, [ 42])? (such as those in [ lo]) that are difficult in a simple and straightforward way? those commonsense to be accounted rea- for by Clearly, symbolic constructs flexibility, lack certain leads to particularly for a compact, modular rules are efficient computational reasoning. Rules are capable of rigorous descriptions they traditionally sentation and direct, efficient relevant knowledge. However, before, which tion 7.2). There are combined probabilistic [ 34]), models bility and thus deal with the brittleness problem to date can solve two aspects: probabilistic forth. None of them deals with similarity-based repre- of as pointed out severe brittleness (or rigidity; more on this in Sec- for example, in rules factor flexi- to a certain extent, but none of them the problem very well, since each of them only deals with one or the and so fuzzy logic (as in [ 611) does not deal well with cumulative approach (for dealing with vague concepts in nature [61] ), and the certainty These models have certain fuzzy (which are probabilistic (as in [ 341) does not deal well with graded concepts, or analogical reasoning very well. theory, for treating uncertainty (based on the probability reasoning logic representations, and numerical evidence, [6,22]). Connectionist models are inherently massively parallel and have and fault tolerance. Connectionist the advantage of and reasoning being robust, exhibiting generalization * Researchers adopting a logic-based approach does not need reasoning the incorporation systems more realistic and descriptive. of such flexibility to involve such flexibility. The main point of this research, however, [ 1 I, 29 I may argue that a normative study of commonsense is precisely to make efficient manner into reasoning systems, in a computationally \f244 R. Sun/Artificial Intelligence 75 (199.5) 241-295 training cases, either individually or collectively to be similarity-based: it usually involves utilizing previous in a statistical way (cf. [2,37] are often said learning similar for various analyses). We will show, in this paper, how rule-based reasoning and similarity-based in connectionist (as embodied to a new theory of robust reasoning. This theory in its simple form can be implemented in a connectionist networks) can be integrated, and that this integration architecture. reasoning leads 1.4. The plan for this paper Based on a detailed is proposed reasoning characteristics bust reasoning commonsense ing essential reasoning, CONSYDERR, tational scheme and distributed are examined in detail ponents, which enables Some discussions robust reasoning rules and logics in CONSYDERR analysis of exampl",
            {
                "entities": [
                    [
                        66,
                        137,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 73 (1995) l-30 Artificial Intelligence Analysis of adaptation and environment Ian Horswill * MIT Art$cial Intelligence Laboratory Received September 1992; revised September 1994 Abstract Designers often improve the performance of artificial agents by specializing them. We can to an make a rough, but useful distinction between specialization to a task and specialization to an environment can be difficult to understand: it may be unclear environment. Specialization the agent depends, or in what manner it depends on on what properties of the environment into a each individual property. In this paper, I discuss a method for analyzing specialization series of conditional optimizations: formal transformations which, given some constraint on the environment, map mechanisms to more efficient mechanisms with equivalent behavior. I apply the technique to the analysis of the vision and control systems of a working robot system in day to day use in our laboratory. The method is not intended as a general theory for automated synthesis of arbitrary specialized agents. Nonetheless, it can be used to perform posr-hoc analysis of agents so as to make explicit the environment properties required by the agent and the computational value of each property. This post-hoc analysis helps explain performance in normal environments and predict performance in novel environments. In addition, the transformations brought out in the analysis of one system can be reused in the synthesis of future systems. 1. Introduction Scientists and mathematicians seek general principles: for one reason or another explain a large class of phenomena. Engineers forced solve a wide range of problems, mechanisms problems. than to pay the price needed individual principles seek general mechanisms, to use highly specialized ones. When one needs it may be more desirable to design a set of specialized that each but are often to to build a single mechanism that can solve all * E-mail: ian@ai.mit.edu. 0004-3702/95/$09.50 SSDIOOO4-3702(94)00057-3 @ 1995 Elsevier Science B.V. All rights reserved \fComputer science, being a curious combination of engineering and generality for ever simpler more compact and mathematics, often at once. Theorists and program- abstract computing (e.g. the 2-counter Turing machine [ 331 or search language designers that are still Turing-equivalent pushes both extremes of specialization ming machines the lambda calculus of specialized machines mapping [ 171. Finally, compiler designers the general machines circuits with which [ lo,41 ] ). while computer architects search for the best collections the behavior of these general computing for automatically search for better methods to emulate into specialized machines [ 31. Specialization and to an environment to a task is no different to a task (e.g. navigation Throughout this paper, I will adopt the somewhat artificial distinction vs. car assembly) of an agent cialization forests versus highways). specialization of a normal computer program explicit definition of the task and consciously agent or program. Often structure of the task, with modules of the mechanism of the overall However, of her agent’s environment agent’s assumptions the agent. Such factors conspire between spe- (e.g. than the to a task. The designer usually has an in the design of the uses that definition the internal reflects structure of the mechanism to subproblems [ 71.) formal description of the behavior In addition, the represented within the agent. These (the exception being simple virtual worlds). its environment tacit knowledge may be spread diffusely to make specialized in the case of biological are often not explicitly it is rare for a designer to have a complete is not as clear agents difficult to understand. corresponding agents, see the internal throughout about (This task. The fundamental usefully described behavior when when specialized mechanisms the paper. the agent claim of this paper in terms of transformations is situated is that environmental specialization can be over possible agents that provably preserve type of environment. The issue of the scope of in some specific should be used in the first place is outside 2. Example to avoid obstacles by turning Fig. I shows an image of an office taken with a camera mounted on a robot. Suppose we want the robot left when there is more free space to the left and right when there is more free space to the right. To do this, the robot must to the problem determine which side of the image has more free space. This amounts of finding which regions of the floor are free and which have objects on top of them. loses information, The problem depth the structure of the scene information images or of additional without additional assumptions. the image projection process in particular, and so we cannot uniquely determine in the form of additional is difficult because information either the features the problem A common way of solving is to build a complete depth map of the scene and then project in the depth map into the floor plane. Those parts of the floor onto which no features are projected will be free space. A common way of features building depth maps is to use two cameras (usually edges) can be found the matching of the features, we can compute each feature’s shift due to parallax, and from in a stereo configuration. Distinctive in the two images and matched to one another. Given \fI. Horswill/Art$icial Intelligence 73 (1995) l-30 3 Fig. 1. (Left) Image of an office taken from the robot’s camera. The dots in the lower middle of the image in the rendering process. The structure are artifacts due to the quantization in the lower right-hand portion of in the top-left are (left to right) a doorway viewed from the image is a Hegged an oblique angle, a small trash can, and a file cabinet. The homogeneous left is the carpet. (Right) The pixels with significant office chair. The structures in the lower and middle texture. region -Lp__ situation m image Fig. 2. An observer views a cliff of a textureless sides of the cliff may produce a local variation is still no texture depth, or even the presence, of the cliff from stereo data. surface in the image above or below the discontinuity which would allow the observer (Left). Although variations in image brightness at the point of discontinuity in lighting of the two there (Right), to infer the that, the 3D positions of the features (see The stereo approach, while perfectly [ 41) . reasonable, does have undesirable properties. in the matching phase. It may also require is that the floor in this environment are marked from a distance, expensive, particularly and so has no features in which pixels with significant in white. The region corresponding It is computationally very high resolution data. A more important problem appears textureless map of the image gradients) black. The stereo process cannot make any depth measurements region of the image because can be remedied by interpolating compute depth. the depth of the floor directly, but because happens general case (see Fig. 2). there are no features a flat surface In that case, the stereo system to be true of floors in office environments. texture to match. Fig. 1 shows a (actually, significant to the floor intensity is uniformly in the most important there to be matched. The problem in the absence of texture from which to is working not because it is measuring assumption that is not true in the it is making a smoothness The assumption This brings out two important points. First truly general systems are extremely rare, the mechanisms we in advance and so claims of generality build have hidden assumptions. These can be particularly difficult should be considered carefully. Often to uncover \f4 I. Horswill/Arfifcial Intelligence 73 (1995) I-30 Fig. 3. The carpet blob extracted there is more exposed carpet. from Fig. I using the coloring algorithm. Note that the blob is taller where choose are bad. Quite the contrary: test data that fit them. This is not to say that because we may unconsciously can lead to great im- implicit assumptions provements in performance. However, we as engineers need to make informed decisions about our use of specialization. We need to understand more clearly what assumptions our agents make about their environments, the particular environments and how often those assumptions in which they operate. those assumptions are true of 2. I. A more ejficient algorithm The stereo system worked on the scene obstacles had texture. We can make a different system much more efficient, by using these facts directly and by treating the floor as a useful feature of the environment rather than a problem in Fig. 1 because the floor was flat and the to solve the problem, one that is the lack of texture on to be overcome. Notice This blob is easily computed by region coloring: each image column, marking pixels until a textured pixel is found marked pixels will form floor in the corresponding exposed the amount of free space in that direction. that the floor forms a single, connected black blob at the bottom of Fig. 1. in Fig. 3. I will call this the carpet blob. The carpet blob is shown alone trace up in that column. The the blob. The height of the blob varies with the amount of direction, giving us a rough and ready measure of starting at the bottom of the screen, We can then solve our navigation problem simply by extracting in which the carpet blob is tallest. This technique capabilities tours of the AI lab at MIT. The navigation turning in the direction the low level navigation simple real time on a low-end personal computer. the Polly system the carpet blob and is the basis of [ 18,191, a mobile robot that gives in algorithm can easily be executed 2.2. Preliminary analysis of coloring algorithm Both mechanisms the stereo algorithm and the coloring (blob-based) algorithm that make assumptions about the structure of their environments. are specializ",
            {
                "entities": [
                    [
                        63,
                        101,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 1017–1029www.elsevier.com/locate/artintEvent calculus and temporal action logics comparedErik T. MuellerIBM Thomas J. Watson Research Center, P.O. Box 704, Yorktown Heights, NY 10598, USAReceived 11 November 2005; received in revised form 8 May 2006; accepted 8 May 2006Available online 12 June 2006AbstractWe compare the event calculus and temporal action logics (TAL), two formalisms for reasoning about action and change.We prove that, if the formalisms are restricted to integer time, inertial fluents, and relational fluents, and if TAL action typespecifications are restricted to definite reassignment of a single fluent, then the formalisms are not equivalent. We argue thatequivalence cannot be restored by using more general TAL action type specifications. We prove however that, if the formalisms arefurther restricted to single-step actions, then they are logically equivalent.© 2006 Elsevier B.V. All rights reserved.Keywords: Commonsense reasoning; Reasoning about action and change; Event calculus; Temporal action logics (TAL)1. IntroductionReasoning about action and change is a fundamental area of research within artificial intelligence. This is an im-portant area because action and change are pervasive aspects of the world in which intelligent agents operate. Over theyears, a number of formalisms and frameworks for reasoning about action and change have been developed. Amongthem are the situation calculus [25,33], the event calculus [19,36], features and fluents [34,35], action languages [7–9],and the fluent calculus [12,41,42].Although there has been some cross-pollination, the various formalisms have been developed in relative isolation,and the relationship between them is not always well understood. But understanding the relationship between theformalisms is important for the following reasons:• It helps to advance the field. An understanding of the space of possible formalisms and where each formalism issituated in this space is essential to their refinement.• It enables sharing of reasoning tools. A number of reasoning tools are available, as shown in Table 1. If problemsin one formalism can be translated into another formalism, they can be solved using reasoning tools for the otherformalism.• It enables sharing of problem libraries developed for each of the formalisms and reasoning tools.• It facilitates collaboration. Researchers working using one formalism can understand and build on the results ofresearchers using another formalism.E-mail address: etm@us.ibm.com (E.T. Mueller).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.001\f1018E.T. Mueller / Artificial Intelligence 170 (2006) 1017–1029Table 1Tools for reasoning about action and changeFormalismSituation calculusEvent calculusTALC+EFluent calculusToolKM [3]http://www.cs.utexas.edu/users/mfkb/km.htmlEvent calculus planner [39]http://www.iis.ee.ic.ac.uk/~mpsha/planners.htmlDiscrete Event Calculus Reasoner [28]http://decreasoner.sourceforge.net/VITAL [20]http://www.ida.liu.se/~jonkv/vital/CCALC [9,23]http://www.cs.utexas.edu/users/tag/cc/E-RES [14,15]http://www.ucl.ac.uk/~uczcrsm/LanguageE/FLUX [43]http://www.fluxagent.org/Two major streams of research in reasoning about action and change are temporal action logics (TAL) [4–6,21],which has its origins in the features and fluents framework, and the event calculus [29,37]. TAL and the event calculusappear to be similar because they both have characterizations in classical logic and both use linear time. But theirexact relationship has been unclear.In this paper, we compare the event calculus with support for events with duration [26,37] and TAL 1.0 [4,5].1We start by restricting the event calculus and TAL 1.0 to integer time, inertial fluents, and relational fluents. Wefurther restrict TAL 1.0 action type specifications to definite reassignment of a single fluent. We then prove that theserestricted versions are not equivalent. We show that equivalence cannot be restored even if more general TAL actiontype specifications are used. We then further restrict the two formalisms to single-step actions and prove that theseversions are logically equivalent.2. Past workIn the past, four approaches have been used to compare formalisms for reasoning about action and change:(1) Two formalisms are proved to be logically equivalent.(2) A syntactic translation is defined from a domain description in one formalism to a domain description in anotherformalism, and the two domain descriptions are proved to entail the same results. Translations may be providedin one or both directions.(3) Semantic (model theoretic) conditions are defined under which a domain description in one formalism matchesa domain description in another formalism, and matching domain descriptions are proved to entail the sameresults.(4) A general formalism is defined, and formalisms are shown to be special cases of the general formalism.In order to ease comparison, the formalisms are often extended or restricted in various ways.The first approach is used by Kowalski and Sadri [17,18], who consider a version of the event calculus extendedwith branching time, but without concurrent events, continuous change, and release from the commonsense law ofinertia. They show that this version of the event calculus is logically equivalent to a version of the situation calculussimilar to that of Reiter [32]. The first approach is also used by Mueller [27], who proves that, if the domain of thetimepoint sort is restricted to the integers, the continuous event calculus is logically equivalent to a discrete version ofthe event calculus.We use the first approach in this paper.1 We use the variant of TAL 1.0 in which actions are treated as first-class citizens [5, pp. 19–20].\fE.T. Mueller / Artificial Intelligence 170 (2006) 1017–10291019The second approach is used by a number of researchers. Kartha [16] defines a translation from domain descriptionsof action language A [8] into three versions of the situation calculus [1,30,31]. He asserts that for any sequence ofevents, the A domain description and the situation calculus translations entail the same truth values of fluents.Thielscher [40] restricts A to a single sequence of actions, and restricts ego world semantics [35] to inertial fluents,relational fluents, and single-step actions. He defines a translation from A domain descriptions to ego world semanticsdomain descriptions, and defines a translation from ego world semantics domain descriptions to A domain descrip-tions. He sketches proofs that in both cases, the models of the domain descriptions entail the same event occurrencesand fluent truth values.Giunchiglia and Lifschitz [11] define a translation from unrestricted domain descriptions of action language C [10]into the situation calculus, and define a classical logic translation of the transition semantics of C domain descriptions.They prove that for any domain description, the two translations are logically equivalent. They also define a translationfrom restricted C domain descriptions to TAL domain descriptions, and define another classical logic translation ofthe transition semantics of C domain descriptions. They prove that for any domain description, the first translation isa conservative extension of the second translation.The third approach is used by Miller and Shanahan [26], who consider a version of the E action language [13] anda version of the event calculus without release from the commonsense law of inertia, continuous change, and stateconstraints. They define semantic conditions under which an E domain description matches an event calculus domaindescription. They prove that, if an E domain description matches an event calculus domain description, the domaindescriptions entail the same event occurrences and fluent truth values.The fourth approach is used by Van Belleghem, Denecker, and De Schreye [44], who define a general formalismthat encompasses both the situation calculus and a version of the event calculus without concurrent events, continuouschange, and release from the commonsense law of inertia. They describe how the situation calculus and this versionof the event calculus are obtained by restricting the general formalism.Bennett and Galton [2] define a versatile event logic (VEL) whose semantics includes a number of formalisms fortemporal reasoning, and present ways of describing the situation calculus and the event calculus within VEL. Theyconsider a version of the event calculus without continuous change and release from the commonsense law of inertia.A related approach is that of Sandewall [35], who defines ontological families and the intended models of a do-main description of a given family. The correctness of any particular formalism is then assessed against these formalspecifications.3. The event calculus and TALHow shall we go about proving logical equivalence of the event calculus with events with duration and TAL 1.0?As shown in Table 2, the formalisms do not support the same features. In addition, the formalisms do not addressindirect effects and nondeterministic effects using the same language features. Indirect effects are represented in theevent calculus using causal constraints and effect constraints [38], whereas they are represented in TAL 1.0 usingdependency constraints [5, pp. 16–18]. Nondeterministic effects are represented in the event calculus using determin-ing fluents [37, pp. 419–420], whereas they are represented in TAL 1.0 using disjunctions in reassignment operators[4, pp. 35–36].At this point, we have two choices. We can either extend the formalisms with their missing features, or we canrestrict the formalisms to their common features. We choose the second approach. We disallow causal constraints,continuous change, continuous time, and effect constraints in the event calculus, and we disallow dependency con-straints, disjunctions in reassignment operators, durational fl",
            {
                "entities": [
                    [
                        74,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 228 (2015) 45–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBi-goal evolution for many-objective optimization problemsMiqing Li a, Shengxiang Yang b,∗a Department of Computer Science, Brunel University, London UB8 3PH, UKb Centre for Computational Intelligence (CCI), School of Computer Science and Informatics, De Montfort University, Leicester LE1 9BH, UK, Xiaohui Liu aa r t i c l e i n f oa b s t r a c tArticle history:Received 22 August 2014Received in revised form 14 June 2015Accepted 20 June 2015Available online 3 July 2015Keywords:Evolutionary multi-objective optimizationMany-objective optimizationProximityDiversityBi-goal evolutionThis paper presents a meta-objective optimization approach, called Bi-Goal Evolution (BiGE), to deal with multi-objective optimization problems with many objectives. In multi-objective optimization, it is generally observed that 1) the conflict between the proximity and diversity requirements is aggravated with the increase of the number of objectives and 2) the Pareto dominance loses its effectiveness for a high-dimensional space but works well on a low-dimensional space. Inspired by these two observations, BiGE converts a given multi-objective optimization problem into a bi-goal (objective) optimization problem regarding proximity and diversity, and then handles it using the Pareto dominance relation in this bi-goal domain. Implemented with estimation methods of individuals’ performance and the classic Pareto nondominated sorting procedure, BiGE divides individuals into different nondominated layers and attempts to put well-converged and well-distributed individuals into the first few layers. From a series of extensive experiments on four groups of well-defined continuous and combinatorial optimization problems with 5, 10 and 15 objectives, BiGE has been found to be very competitive against five state-of-the-art algorithms in balancing proximity and diversity. The proposed approach is the first step towards a new way of addressing many-objective problems as well as indicating several important issues for future development of this type of algorithms.© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionReal-world problems commonly involve multiple objectives/criteria which are required to be optimized simultaneously. For example, an individual would like to maximize the chance of being healthy and wealthy while still having fun and time for family and friends. A software engineer would be interested in finding the cheapest test suite while achieving full coverage (e.g., statement coverage, branch coverage and decision coverage). When prescribing radiotherapy to a cancer patient, a doctor would have to balance the attack on tumor, potential impact on healthy organs, and the overall condition of the patient. These multi-objective optimization problems (MOPs) can be seen in many fields, including engineering, science, medicine and logistics. They share the same issue of pursuing several objectives at the same time, and have long been regarded as a substantial challenge in artificial intelligence (AI) [73,25].There have been a variety of approaches for MOPs, including traditional mathematical programming methods, local search techniques, and evolutionary algorithms (EAs). Inspired by biological evolution mechanisms, EAs have been demon-strated to be successful in diverse AI applications [73,10]. For example, an EA-based AI planner, Divide and Evolutionary * Corresponding author.E-mail address: syang@dmu.ac.uk (S. Yang).http://dx.doi.org/10.1016/j.artint.2015.06.0070004-3702/© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f46M. Li et al. / Artificial Intelligence 228 (2015) 45–65(DaE) [8], won the Deterministic Temporal Satisficing track during the International Planning Competition (IPC7) at the 21st International Conference on Automated Planning and Scheduling (ICAPS 2011).1 Recently, DaE has been successfully applied to multi-objective AI planning (called MO-DaE) [58]. MO-DaE, working with a well-known multi-objective EA, i.e., the indicator-based EA (IBEA) [99], has shown clear advantage over the metric-based approach using LPG metric sensitive planner [58].A key strength of EAs for MOPs is their population-based feature which allows individuals to simultaneously approximate different parts of the Pareto front within a single execution [19,97]. Intuitively, the search process of an EA has two basic goals:• minimizing the distance of the population to the Pareto front (i.e., proximity) and• maximizing the distribution of the population along the Pareto front (i.e., diversity).Since the optimal outcome of an MOP is a set of Pareto optimal solutions, the Pareto dominance relation naturally becomes a criterion to distinguish between solutions. Given two solutions p and q for an MOP, p is said to Pareto dominate q, if and only if p is better than q for at least one objective and is not worse for any of the others. The Pareto dominance reflects the weakest assumption about the preferred structure of the decision-maker.As the primary selection criterion in the evolutionary multi-objective optimization (EMO) area, Pareto dominance is commonly used to evaluate the proximity of solutions. When Pareto dominance fails (e.g., the interested solutions are non-dominated to each other), EMO algorithms often introduce a density-based criterion to maintain diversity of the population. For example, the nondominated sorting genetic algorithm II (NSGA-II) [23] separates individuals in a population into dif-ferent layers (ranks) by their Pareto dominance relation, and prefers 1) individuals in lower layers and 2) individuals with lower crowding degrees (measured by the crowding distance [23]) when they are located in the same layer.An MOP with more than three objectives is called a many-objective optimization problem. Many-objective optimization is an important but very challenging topic and there has been increasing interest in the use of EAs to tackle many-objective optimization problems [14,16,26,35]. Although Pareto-based algorithms are the most popular approaches, they scale up poorly with the number of objectives [18,48,75]. When dealing with an MOP with many objectives, Pareto dominance often loses its effectiveness to differentiate individuals [57], which makes most individuals in a population become incomparable in terms of proximity (e.g., in NSGA-II most individuals fall into the first layer). Consequently, the density-based selection criterion will play a decisive role in determining the survival of individuals during the evolutionary process, leading to the individuals in the final population distributed widely over the objective space but far from the desired Pareto front [85].A straightforward way to handle this problem (i.e., the ineffectiveness of Pareto-based algorithms in many-objective opti-mization) is to modify the Pareto dominance relation. Some interesting attempts include loosening the dominance condition or controlling the dominance angle, such as (cid:2)-dominance [22,36,61,84], α-dominance [43], (cid:2)-box dominance [60], and dom-inance area control [78]. By relaxing the area of an individual dominating, these dominance relations are able to provide sufficient selection pressure towards the Pareto front. However, how to set a proper value of the parameter(s) to determine the relaxation degree is a crucial issue in these methods, needing further studies [62,69,79].On the other hand, the way of comparing individuals according to their quantitative difference in objectives has been found to be effective in converging towards the Pareto front. Many recent EMO algorithms originate from this motivation, introducing a variety of new criteria to distinguish between individuals, e.g., average ranking [52,70], fuzzy Pareto optimality [37,39], subspace partition [2,51], preference-inspired rank [88,87], grid-based rank [70,92], distance-based rank [32,71,91], and density adjustment strategies [1,66]. These methods provide ample alternatives to deal with many-objective optimiza-tion problems, despite some having the risk of leading the population to concentrate in one or several sub-areas of the whole Pareto front [50,67,81,65].Recently, there has been significant interest in the use of selection criteria that involve both proximity and diversity to solve MOPs. Some such criteria, like the decomposition-based [94] and indicator-based [99] criteria, have been shown to be very promising in many-objective optimization [15,20,41,44,85]. The former uses the idea of single-objective aggregated optimization, decomposing an MOP into a number of scalar subproblems and optimizing them simultaneously. The latter defines an optimization criterion with regard to a specified performance indicator and uses this criterion to guide the search of the population. The indicator hypervolume is one of the most popular indicator-based criteria due to its good theoretical and empirical properties [7,13,29,42,101]. Whereas super-polynomial time complexity is required in the calculation of the hypervolume indicator (unless P = N P ) [11], lots of effort is being made to reduce its computational cost, in terms of both the exact computation [6,12,90] and the approximate estimation [4,14,49]. Nevertheless, balancing proximity and diversity using one single criterion is not an easy task [76,38,69,68], especially for a many-objective optimization problem in which the conflict between the objectives is generally more serious than that in an MOP with two or three objectives [75,1].In fact, evolving a population towards the optimum as well as diversifying its individuals over the whole Pareto front in many-objective optimization is, by ",
            {
                "entities": [
                    [
                        134,
                        192,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1470–1494Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEnhanced qualitative probabilistic networks for resolving trade-offs ✩Silja Renooij∗, Linda C. van der GaagDepartment of Information and Computing Sciences, Utrecht University, P.O. Box 80.089, 3508 TB Utrecht, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 18 October 2006Received in revised form 9 April 2008Accepted 14 April 2008Available online 20 April 2008Keywords:Probabilistic reasoningQualitative reasoningTrade-off resolutionQualitative probabilistic networks were designed to overcome, to at least some extent, thequantification problem known to probabilistic networks. Qualitative networks abstract fromthe numerical probabilities of their quantitative counterparts by using signs to summarisethe probabilistic influences between their variables. One of the major drawbacks of thesequalitative abstractions, however, is the coarse level of representation detail that doesnot provide for indicating strengths of influences. As a result, the trade-offs modelledin a network remain unresolved upon inference. We present an enhanced formalism ofqualitative probabilistic networks to provide for a finer level of representation detail.An enhanced qualitative probabilistic network differs from a basic qualitative network inthat it distinguishes between strong and weak influences. Now, if a strong influence iscombined, upon inference, with a conflicting weak influence, the sign of the net influencemay be readily determined. Enhanced qualitative networks are purely qualitative in nature,as basic qualitative networks are, yet allow for resolving some trade-offs upon inference.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThe formalism of probabilistic networks introduced in the 1980s [26], is an intuitively appealing formalism for capturingknowledge of complex problem domains along with the uncertainties involved. Associated with the formalism are powerfulalgorithms for reasoning with uncertainty in a mathematically correct way. These algorithms for probabilistic inference allowfor causal reasoning, diagnostic reasoning as well as case-specific reasoning; probabilistic inference, however, is known tobe NP-hard [7]. Applications of probabilistic networks can be found in areas such as (medical) diagnosis and prognosis,planning, monitoring, vision, and information retrieval (see, for example, [1,2,4,5,20,31]).A probabilistic network basically is a concise representation of a joint probability distribution on a set of statisticalvariables. It consists of an acyclic directed graph encoding the relevant variables from a domain of application along withtheir probabilistic interrelationships. Associated with each variable is a set of conditional probability distributions describingthe relationship of the variable with its predecessors in the graph. The first task in constructing a probabilistic network isto identify the important domain variables, their values, and their interdependencies. This knowledge is then modelled ina directed graph, referred to as the network’s qualitative part. The final task is to obtain the probabilities that constitutethe network’s quantitative part. As (conditional) probability distributions are to be stated for each variable in the graph, thenumber of required probabilities can be quite large, even for small applications. While the construction of the qualitativepart of a probabilistic network is generally considered feasible, its quantification is a far harder task. Probabilistic informationavailable from literature or data is often insufficient or unusable, and domain experts have to be relied upon to assess the✩This research was (partly) supported by the Netherlands Organisation for Scientific Research (NWO). We would very much like to thank Hans Bodlaenderfor his advice relating to the complexity issues addressed in this paper.* Corresponding author.E-mail addresses: silja@cs.uu.nl (S. Renooij), linda@cs.uu.nl (L.C. van der Gaag).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.04.001\fS. Renooij, L.C. van der Gaag / Artificial Intelligence 172 (2008) 1470–14941471required probabilities [14]. Unfortunately, experts are often uncomfortable with having to provide probabilities. Moreover,the problems of bias encountered when directly eliciting probabilities from experts are widely known [19]. The usuallylarge number of probabilities required for a probabilistic network, as a consequence, tends to pose a major obstacle to theirapplication [14,18].To mitigate the quantification bottleneck to at least some extent, qualitative probabilistic networks have been intro-duced [34]. Qualitative networks in essence are qualitative abstractions of probabilistic networks. Like a probabilisticnetwork, a qualitative network encodes variables and the probabilistic relationships between them in a directed graph.However, while the relationships between the represented variables are quantified by conditional probabilities in a prob-abilistic network, these relationships are summarised in its qualitative abstraction by qualitative signs capturing stochasticdominance. The probabilistic information captured by signs is more robust than exact numbers are and is more easilyobtained from domain experts [10]. Elicitation methods to this end are being designed [33].Originally, the benefits of using qualitative probabilistic networks included the complexity of inference: for reasoningwith a qualitative probabilistic network, an efficient algorithm is available, based on the idea of propagating and combiningthese signs [11]. In practice, however, nowadays the complexity of probabilistic inference is less of a problem and interestin qualitative probabilistic networks has shifted more to the construction and validation phase of probabilistic networks forreal-life application domains. As the assessment of the various probabilities required is a hard task, it is performed onlywhen the probabilistic network’s graph is considered robust. Now, by assessing signs for the influences modelled in thegraph, a qualitative network is obtained that can be exploited for studying the projected probabilistic network’s reasoningbehaviour prior to the assessment of probabilities. Patterns of qualitative influences can also be used to recognise differenttypes of causal interaction, such as the noisy-or, which greatly simplify the quantification effort [24]. In addition, qualitativesigns can be used in several ways as constraints on the quantification. For example, by interpreting the signs as continuoussubintervals of the probability interval, the constraints they impose on the conditional probability distributions involved canbe used for stepwise quantification of a probabilistic network: once a conditional probability table for a certain variableis filled, the interval associated with all direct influences upon that variable can be tightened [28]. These semi-qualitativeprobabilistic networks can also include assessments based on probabilistic logic and credal sets [6]. More recently, the signsof qualitative probabilistic networks have been used to constrain the probabilities learned from small data sets [3,15,17]. Ata somewhat higher level, the constraints imposed by qualitative influences can be used to bound the entire space of pos-sible joint probability distributions over the network’s variables [13]. Finally, the qualitative signs can be used for verifyingmonotonicity properties in a probabilistic network [32], and for explanation of the (qualitative) probabilistic network’s rea-soning processes [10]. Given the increasing variety of useful applications of qualitative probabilistic networks, it is importantto derive as much information as possible from such networks.Qualitative probabilistic networks, by their nature, have a coarse level of representation detail. Influential relationshipsbetween variables can be modelled as positive, negative, zero or ambiguous, but no indication of their strengths can beprovided as in a quantified network. One of the major drawbacks of this coarse level of representation detail is the easewith which the ambiguous ‘?’-sign arises upon inference. Ambiguous signs typically arise from trade-offs. A qualitativenetwork models a trade-off if two nodes in the network’s digraph are connected by multiple parallel reasoning chains withconflicting signs. In the absence of a notion of strength of influences, qualitative networks do not provide for resolving suchtrade-offs. Inference with a qualitative network for a real-life domain of application, as a consequence, often introducesambiguous signs. Moreover, once an ambiguous sign has been generated, it will spread throughout major parts of thenetwork. Although not incorrect, ambiguous signs provide no information whatsoever about the influence of one variableon another and are therefore not very useful in practice.Ambiguous results from inference can be averted by enhancing the formalism of qualitative probabilistic networks toprovide for a finer level of representation detail. Roughly speaking, the finer the level of detail, the more trade-offs can beresolved during inference. The finer levels of detail, however, typically come at the price of a higher computational com-plexity of inference. The problem of trade-off resolution for qualitative networks has been addressed by various researchersand we detail the relation between their work and ours in the Related work section of this paper. In short, S. Parsons, for ex-ample, has introduced the concept of categorical influence, which is either an influence that serves to increase a probabilityto 1, or an influence that decreases a probability to 0, and thus serves to resolve any trade-off in which it is involved [25].Parsons has also studied the use of order-of-magnitude reasoning in the context of quali",
            {
                "entities": [
                    [
                        138,
                        206,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 286–310www.elsevier.com/locate/artintOn the evaluation of argumentation formalisms ✩Martin Caminada a, Leila Amgoud b,∗a Institute of Information and Computing Sciences, Universiteit Utrecht, Utrecht, The Netherlandsb Institut de Recherche en Informatique de Toulouse, 118 route de Narbonne, 31062 Toulouse Cedex 9, FranceReceived 9 March 2006; received in revised form 26 February 2007; accepted 26 February 2007Available online 3 March 2007AbstractArgumentation theory has become an important topic in the field of AI. The basic idea is to construct arguments in favor andagainst a statement, to select the “acceptable” ones and, finally, to determine whether the original statement can be accepted or not.Several argumentation systems have been proposed in the literature. Some of them, the so-called rule-based systems, use a particularlogical language with strict and defeasible rules. While these systems are useful in different domains (e.g. legal reasoning), theyunfortunately lead to very unintuitive results, as is discussed in this paper. In order to avoid such anomalies, in this paper we areinterested in defining principles, called rationality postulates, that can be used to judge the quality of a rule-based argumentationsystem. In particular, we define two important rationality postulates that should be satisfied: the consistency and the closure of theresults returned by that system. We then provide a relatively easy way in which these rationality postulates can be warranted for aparticular rule-based argumentation system developed within a European project on argumentation.© 2007 Elsevier B.V. All rights reserved.Keywords: Formal argumentation; Nonmonotonic logic; Commonsense reasoning1. IntroductionAgents express claims and judgments when engaged in decision making, drawing conclusions, imparting informa-tion, and when persuading and negotiating with other agents. Information may be uncertain and incomplete, or theremay be relevant but partially conflicting information. Also, in multi-agents systems, conflicts of interest are inevitable.To address these problems, agents can use argumentation, a process based on the exchange and valuation of argumentsfor and against opinions, proposals, claims and decisions.Argumentation, in its essence, can be seen as a particular useful and intuitive paradigm for doing nonmonotonicreasoning. The advantage of argumentation is that the reasoning process is composed of modular and quite intuitivesteps, and thus avoids the monolithic approach of many traditional logics for defeasible reasoning. The process ofargumentation starts with the construction of a set of arguments based on a given knowledge base. As some of thesearguments may attack each other, one needs to apply a criterion for determining the sets of arguments that can be re-garded as “acceptable”: the argument-based extensions. The last step is then to examine whether a particular statement✩ This work has been supported by the EU-ASPIC project.* Corresponding author.E-mail addresses: martinc@cs.uu.nl (M. Caminada), amgoud@irit.fr (L. Amgoud).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.003\fM. Caminada, L. Amgoud / Artificial Intelligence 171 (2007) 286–310287can be regarded as justified. This can for instance be the case if every extension contains an argument which has thisstatement as its conclusion. An interesting property of the argumentation approach is that it can be given dialecticalproof procedures that are quite close to the process by which humans would discuss an issue. The similarity withhuman-style discussions gives formal argumentation an advantage that can be useful in many contexts.Argumentation has developed into an important area of study in artificial intelligence over the last fifteen years,especially in sub-fields such as nonmonotonic reasoning (e.g. [19,25,26,28,43,45]), multiple-source information sys-tems (e.g. [7,9,21]), decision making (e.g. [2,11,12,20,30–32]), and modeling interactions between agents (e.g. [3,8,10,14,18,35–38,41]). Several argumentation systems have been developed for handling inconsistency in knowledgebases (e.g. [5,15–17,29,33,34,39,42,44]), in other words for inference. All these systems are built around a logicallanguage and an associated consequence relation that is used for defining an argument. Some of these systems, calledrule-based systems, use a particular logical language defined over a set of literals, and two kinds of rules: strict rulesand defeasible ones. Arguments and conflicts among them are first identified, and then an acceptability semantics (e.g.Dung’s semantics) is applied in order to determine the “acceptable” arguments. Examples of such systems are Prakkenand Sartor’s system [42], Garcia and Simari’s system [33], Governatori et al.’s system [34], and Amgoud et al.’s sys-tem [4]. Such systems are suitable in some domains like legal reasoning, where knowledge cannot be represented ina classical propositional language for instance. Unfortunately, existing rule-based systems fail to meet the objectivesof an inference system, and can lead to very unintuitive results. Indeed, with these systems it may be the case that anagent believes that “if a then it is always the case that b”, and the system returns as output a but not b. Worse yet, ifthe agent also believes that “if c then it is always the case that ¬b”, the system may return a and c, which means thatthe output of the system is indirectly inconsistent.In what follows, we will focus only on rule-based argumentation systems. In order to avoid anomalies like theones discussed above, the aim of this paper is twofold: on the one hand, as in the field of belief revision, where thewell-known AGM-postulates serve as general properties a system for belief revision should fulfill, we are interested indefining some principles (called rationality postulates) that any rule-based argumentation system should obey. Thesepostulates will govern the sound definition of an argumentation system and will avoid anomalous results. In this paperwe focus particularly on two important postulates: the closure and the consistency of the results that an argumentationsystem may produce. These postulates are violated in systems such as [4,33,34,42]. On the other hand, we studyvarious ways in which these postulates can be warranted in the argumentation system developed in [4], as well as invarious other systems.This paper is structured as follows. First, in Section 2, we recall the basic concepts behind argumentation theory.We present the abstract argumentation framework of Dung [28], as well as one particular instantiation of it, forwhich we have chosen the ASPIC argumentation formalism [4]. In Section 3, we show some examples that yieldvery unintuitive and undesirable results, not only for the ASPIC argumentation system, but also for various otherargumentation formalisms. Then, in Section 4, we state a number of postulates, based on the analysis of the examplesin Section 3, that we think any rule-based argumentation formalism should satisfy. Section 5 proposes a numberof generic solutions which can be applied to the argumentation formalism described in Section 2, as well as to otherargumentation formalisms where similar problems occur (such as [33,34,42]). Two main solutions are suggested, eachof which satisfies all the earlier mentioned rationality postulates. The first approach is applicable to formalisms thatmake use of classical logic, the other one is applicable to formalisms that do not. Section 6 then contains an overviewof the main results of this paper, as well as some open research issues.2. Argumentation processArgumentation can be seen as a reasoning process consisting of the following four steps:(1) Constructing arguments (in favor of/against a “statement”) from a knowledge base.(2) Determining the different conflicts among the arguments.(3) Evaluating the acceptability of the different arguments.(4) Concluding, or defining the justified conclusions.Some argumentation formalisms also allow arguments to be of different strengths, but for the sake of simplicity wewill not address this issue in the current paper. Many argumentation formalisms are built around an underlying logical\f288M. Caminada, L. Amgoud / Artificial Intelligence 171 (2007) 286–310language L and an associated notion of logical consequence, defining the notion of argument. Argument constructionis a monotonic process: new knowledge cannot rule out an argument but only gives rise to new arguments which mayinteract with the first argument. Since the knowledge bases may give rise to inconsistent conclusions, the argumentsmay be conflicting too. Consequently, it is important to determine among all the available arguments, the ones that areultimately acceptable. In [28], an argumentation system is defined as follows:Definition 1 (Argumentation system). An argumentation system is a pair (cid:3)A, Def (cid:4) where A is a set of arguments andDef ⊆ A × A is a defeat relation. We say that an argument A defeats an argument B iff (A, B) ∈ Def (or A Def B).Starting from the set of all (possibly conflicting) arguments, it is important to know which of them can be relied onfor inferring conclusions and for making decisions. To answer this question, different attempts for defining semanticsfor the notion of acceptability have been made. Some approaches return a unique set of acceptable arguments, calledan extension, giving a unique status to each argument, whereas others return several extensions, allowing multiplestatus for arguments. In [28] different semantics for the notion of acceptability have been proposed. These last havebeen recently refined in [13,24]. In what follows, only Dung’s semantics are recalled for illustration purposes.Definition 2 (Conflict-free, Defense). Let A and B be sets of arguments, and let B ⊆ A.• B is conflict-free iff there exist no A, B in B such tha",
            {
                "entities": [
                    [
                        72,
                        117,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 222 (2015) 49–66Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFinding core for coalition structure utilizing dual solution ✩Atsushi Iwasaki a,∗a Graduate School of Information Systems, University of Electro-Communications, Tokyo, Japanb Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japanc National Institute of Informatics, Tokyo, Japan, Suguru Ueda c, Naoyuki Hashimoto b, Makoto Yokoo ba r t i c l e i n f oa b s t r a c tArticle history:Received 21 December 2013Received in revised form 13 January 2015Accepted 19 January 2015Available online 24 January 2015Keywords:Game theoryCooperative gamesCoreCoalition structureWhen forming the grand coalition is not possible or optimal, agents need to create a coalition structure. The idea of the core can be extended to such a case. In this paper, we propose an innovative exact algorithm called CoreD to check core-non-emptiness for coalition structures. A more straightforward exact algorithm based on existing techniques, which we call CoreP, first obtains the value of optimal coalition structure by solving an integer programming problem. Then, it checks whether that value can be divided without making a blocking (dissatisfied) coalition. In contrast, CoreD first finds a minimal value of the optimal coalition structure so that there exists no blocking coalition. Next, it checks whether the optimal value equals the minimal value We empirically show that when the core is empty, CoreD is by far superior to CoreP. Also, to find a second-best payoff vector +when the core is empty, we propose a new solution concept called the weak ε-core, which can utilize the approximate value of the optimal coalition structure. Based on the idea of CoreD, we further develop an algorithm for checking the non-emptiness of the weak ε-core+.© 2015 Elsevier B.V. All rights reserved.1. IntroductionCoalition formation is an important capability in automated negotiation among self-interested agents. As a result, coali-tional game theory has attracted much attention from AI and multi-agent systems (MAS) researchers [7,12]. In a traditional model of coalitional game theory, it is assumed that all coalitions are possible and that the characteristic function is super-additive; when two coalitions are merged, the merged coalition can obtain at least the sum of the values of the two original coalitions. However, organizing a large coalition can be costly, e.g., such coordination overhead as communication costs. If time is limited, the agents may not have time to carry out the communications and the computations required to coordinate effectively within the composite coalition, and so component coalitions may be more advantageous.Furthermore, in many real-world applications, there can be inherent constraints on possible coalitions. For example, in many countries, antitrust laws prohibit the formation of certain coalitions of companies (cartels) that can dominate an entire market. Constraints may be placed on coalition sizes to permit or prohibit particular sizes. There can be some underlying graphical structure that determines the possible communication patterns among agents. Therefore, it is natural to assume ✩This paper is an extended version of a conference paper that appeared as [17].* Corresponding author.E-mail addresses: iwasaki@is.uec.ac.jp (A. Iwasaki), s-ueda@nii.ac.jp (S. Ueda), hashimoto@agent.inf.kyushu-u.ac.jp (N. Hashimoto), yokoo@inf.kyushu-u.ac.jp (M. Yokoo).http://dx.doi.org/10.1016/j.artint.2015.01.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f50A. Iwasaki et al. / Artificial Intelligence 222 (2015) 49–66that making a coalition is possible only when its members can communicate with each other. There exist several works that have considered such constraints on possible coalitions [41,11,29,35,31,21].When the grand coalition, i.e., the coalition of all agents, is not possible or optimal, the agents should be divided into smaller coalitions; agents need to create a coalition structure to maximize the reward they can obtain [37]. Furthermore, to make a coalition structure stable, agents need to agree how to divide among themselves the reward obtained by the coalition structure. The core [13], which is a prominent solution concept in the traditional model of coalitional game theory, can be extended to such a case when the grand coalition is not possible or optimal and agents form a coalition structure [2].For instance, consider a coalitional form game with three agents: A = {a, b, c}. The characteristic function v represents a mapping from a coalition S (a subset of agents) to the worth or the value earned by the coalition: v({a}) = v({b}) = 0, v({c}) = 3, v({a, b}) = 12, v({b, c}) = v({c, a}) = 8, and v({a, b, c}) = 15. A payoff vector y = ( ya, yb, yc) that belongs to the core can be computed by linear programming in such a way that for every coalition S, v(S) does not exceed the total payoff of the agents in S and such that the total payoff equals v( A). In this example, the core payoff vector is y = (p, 12 − p, 3), where p ∈ [5, 7]. Let us turn to a case where the grand coalition is prohibited in the above example. The concept of the core can be extended to this situation. The agents can create coalition structure CS = {{a, b}, {c}} and obtain 15 reward and share it efficiently. The coalition structure {{a, b}, {c}} is optimal in the sense that the total payoff V (CS) is maximized. The payoff vector in the core for the coalition structure is the same as in the first example.Checking whether the core is non-empty or not in itself is done in polynomial time in the number of allowed coalitions because it is formulated as a linear programming problem. However, Conitzer and Sandholm [8] pointed out that it requires many constraints for all the subcoalitions and the size of the representation (input) is exponential in the number of agents. Any algorithm for computing the core payoff vector requires time exponential as long as it reads all the input. If a coalition is prohibited or if its value is not explicitly specified, the algorithm may need to compute every value of such coalitions. Computing a value of a coalition is not necessarily straightforward because the agents must solve a complex collaborative planning problem.In general, as we noted below, computing an optimal coalition structure is known to be NP-hard and checking whether there exists a core for the (optimal) coalition structure or not is NP-complete unless its value is explicitly provided. Thus, our research goal is to develop an exact algorithm whose average runtime is much faster than traditional methods, although the worst-case complexity is doomed to be exponential in the number of explicitly given coalitions. Based on existing techniques, we can construct an algorithm to check core-non-emptiness for coalition structures, which we call CoreP. In this ∗) is obtained by solving an integer programming (IP) problem [25]. algorithm, the value of optimal coalition structure V (CS∗) can be divided without making a blocking (dissatisfied) coalition by solving a linear The algorithm checks whether V (CSprogramming (LP) problem [8].In this paper, we propose an exact algorithm called CoreD, which utilizes the dual problem of the linear relaxation of the above IP problem. Experimental evaluations show that CoreD is by far superior to CoreP when the core is empty. To find a +second-best payoff vector when the core is empty, we introduce a new approximate solution concept called weak ε-corefor the weak ε-core for the optimal coalition structure. The weak ε-core is defined for a particular coalition structure that may or may not be not optimal, relaxes only the non-blocking condition with parameter ε, and efficiently distributes the does not specify a particular coalition rewards that the coalition structure earns. On the other hand, the weak ε-corestructure beforehand. It then relaxes the efficiency condition of the weak ε-core (for the optimal coalition structure), in addition to the non-blocking condition, and efficiently distributes the reward that the dual solution provides. Thus, the sum of the elements in the payoff vector, i.e., the sum of the rewards distributed to agents, can be less than the value of the optimal coalition structure, but the difference must be at most ε · n, where n is the number of agents. Based on the idea of CoreD, we also develop an algorithm for checking the non-emptiness of the weak ε-corecalled ECore+(ε).++This paper is organized as follows. Section 2 briefly describes the basic terms and notations and Section 3 introduces an existing technique for checking core-non-emptiness, proposes our proposed technique, and derives an associated theorem. Based on the our technique, Section 4 develops a novel solution concept, which we call weak ε-core. Section 5 empirically examines our proposed algorithm from some criteria. Section 6 describes four issues to our contributions, and Section 7concludes this paper.+1.1. Related worksThis subsection briefly explores related works. In traditional models of coalitional game theory, it is assumed that all coalitions are possible and that the characteristic function is super-additive. Forming the grand coalition is guaranteed to be optimal and the main research topic is how to divide the gain of the grand coalition among agents. The traditional theory of coalitional games provides a number of solution concepts, such as the core [13], the Shapley value [39], and the nucleolus [38].More recently, AI and MAS researchers have been considering the case where forming the grand coalition is not possible or not optimal. In such cases, agents should form a coalition structure to maximize the reward they can obtain. This problem is called the coalition structure generation (CSG) problem and has been an active research topic in AI and MAS.Sandholm et al. [37] ",
            {
                "entities": [
                    [
                        134,
                        194,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 189 (2012) 19–47Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiscovering hidden structure in factored MDPsAndrey Kolobov∗, Mausam, Daniel S. WeldDept. of Computer Science and Engineering, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 1 August 2010Received in revised form 8 April 2012Accepted 9 May 2012Available online 15 May 2012Keywords:Markov Decision ProcessMDPPlanning under uncertaintyGeneralizationAbstractionBasis functionNogoodHeuristicDead end1. IntroductionMarkov Decision Processes (MDPs) describe a wide variety of planning scenarios rangingfrom military operations planning to controlling a Mars rover. However, today’s solutiontechniques scale poorly, limiting MDPs’ practical applicability. In this work, we proposealgorithms that automatically discover and exploit the hidden structure of factored MDPs.Doing so helps solve MDPs faster and with less memory than state-of-the-art techniques.Our algorithms discover two complementary state abstractions — basis functions andnogoods. A basis function is a conjunction of literals; if the conjunction holds true in a state,this guarantees the existence of at least one trajectory to the goal. Conversely, a nogood is aconjunction whose presence implies the non-existence of any such trajectory, meaning thestate is a dead end. We compute basis functions by regressing goal descriptions through adeterminized version of the MDP. Nogoods are constructed with a novel machine learningalgorithm that uses basis functions as training data.Our state abstractions can be leveraged in several ways. We describe three diverseapproaches — GOTH, a heuristic function for use in heuristic search algorithms suchas RTDP; ReTrASE, an MDP solver that performs modified Bellman backups on basisfunctions instead of states; and SixthSense, a method to quickly detect dead-end states.In essence, our work integrates ideas from deterministic planning and basis function-basedapproximation, leading to methods that outperform existing approaches by a wide margin.© 2012 Elsevier B.V. All rights reserved.Markov Decision Processes (MDPs) are a popular framework for modeling problems involving sequential decision-makingunder uncertainty. Examples range from military-operations planning to user-interface adaptation to the control of mobilerobots [1,36]. Unfortunately, however, existing techniques for solving MDPs, i.e. deciding which actions to execute in varioussituations, scale poorly, and this dramatically limits MDPs’ practical utility.Humans perform surprisingly well at planning under uncertainty, largely because they are able to recognize and reuseabstractions, generalizing conclusions across different plans. For example, after realizing that the walls of a particular Marscrater are too steep for the rover to escape, a human planner would abandon attempts to collect any of the rock samples inthe crater, while a traditional MDP solver might rediscover the navigational problem as it considered collecting each samplein turn.This article presents new algorithms for automatically discovering and exploiting such hidden structure in MDPs. Specif-ically, we generate two kinds of abstraction, basis functions and nogoods, each of which describes sets of states that share asimilar relationship to the planning goal. Both basis functions and nogoods are represented as logical conjunctions of statevariable values, but they encode diametrically opposite information. When a basis function holds in a state, this guarantees* Corresponding author.E-mail addresses: akolobov@cs.washington.edu (A. Kolobov), mausam@cs.washington.edu (Mausam), weld@cs.washington.edu (D.S. Weld).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.05.002\f20A. Kolobov et al. / Artificial Intelligence 189 (2012) 19–47that a certain trajectory of action outcomes has a positive probability of reaching the goal. Our algorithms associate weightswith each basis function, encoding the relative quality of the different trajectories. In contrast, when a nogood holds in astate, it signifies that the state is a dead-end; no trajectory can reach the goal from this state. Continuing the Mars roverexample, a conjunction that described presence in the steep-walled crater would be a nogood.Our notions of basis function and nogood are similar to the rules learned in logical theories in explanation-based learn-ing and constraint satisfaction [27,14], but our work applies them in a probabilistic context (e.g., learns weights for basisfunctions) and provides new mechanisms for their discovery. Previous MDP algorithms have also used basis functions [21,39], but to perform generalization between different problems in a domain rather than during the course of solving a singleproblem. Other researchers have used hand-generated basis functions in a manner similar to ours [22,23,20], but we presentmethods for their automatic generation.1.1. Discovering nogoods and basis functionsWe generate basis functions by regressing goal descriptions along an action outcome trajectory using a determinizedversion of the probabilistic domain theory. Thus, the trajectory is potentially executable in all states satisfying the basisfunction. This justifies performing Bellman backups on basis functions, rather than states — generalizing experience acrosssimilar states. Since many basis functions typically hold in a given state, the value of a state is a complex function of theapplicable basis functions.We discover nogoods using a novel machine learning algorithm that operates in two phases. First it generates candidatenogoods with a probabilistic sampling procedure using basis functions and previously discovered dead ends as trainingdata. It then tests the candidates with a planning graph [6] to ensure that no trajectories to the goal could exist from statescontaining the nogood.1.2. Exploiting nogoods and basis functionsWe present three algorithms that leverage our basis function and nogood abstractions to speed MDP solution and reducememory usage.• GOTH uses a full classical planner to generate a heuristic function for an MDP solver for use as an initial estimate of statevalues. While classical planners have been known to provide an informative approximation of state value in probabilisticproblems, they are too expensive to call from every newly visited state. GOTH amortizes this cost across multiple statesby associating weights to basis functions and thus generalizing the heuristic computation. Empirical evaluation showsGOTH to be an informative heuristic that saves MDP solvers considerable time and memory.• ReTrASE is a self-contained MDP solver based on the same information-sharing insight as GOTH. However, unlike GOTH,which sets the weight of each basis function only once to provide the starting guess at states’ values, ReTrASE learnsthe basis functions’ weights by evaluating each function’s “usefulness” in a decision-theoretic way. By aggregating theweights, ReTrASE constructs a state value function approximation and, as we show empirically, produces better policiesthan the participants of the International Probabilistic Planning Competition (IPPC) on many domains while using littlememory.• SixthSense is a method for quickly and reliably identifying dead ends, i.e., states with no possible trajectory to the goal, inMDPs. In general, this problem is intractable — one can prove that determining whether a given state has a trajectoryto the goal is PSPACE-complete [19]; therefore, it is unsurprising that modern MDP solvers often waste considerableresources exploring these doomed states. SixthSense acts as a submodule of an MDP solver, helping it detect and avoiddead ends. SixthSense employs machine learning, using basis functions as training data, and is guaranteed never togenerate false positives. The resource savings provided by SixthSense are determined by the fraction of dead ends inthe MDP’s state space and reach 90% on some IPPC benchmark problems.In the rest of the paper, we present these algorithms, discuss their theoretical properties, and evaluate them empirically.Section 2 reviews the background material and introduces relevant definitions, illustrating these with a running example.Sections 3, 4, and 5 present descriptions of and empirical results on GOTH, ReTrASE, and SixthSense respectively. Section 6discusses potential extensions of the presented algorithms. Finally, Section 7 describes the related work and Section 8concludes the paper.2. Preliminaries2.1. ExampleThroughout the paper, we will be illustrating various concepts with the following scenario, called GremlinWorld. Con-sider a gremlin that wants to sabotage an airplane and stay alive in the process. To achieve the task, the gremlin can pickup several tools. The gremlin can either tweak the airplane with a screwdriver and a wrench, or smack it with a hammer.\fA. Kolobov et al. / Artificial Intelligence 189 (2012) 19–4721(define (domain GremlinWorld)(:types tool)(:predicates (has ?t - tool)(gremlin-alive)(plane-broken))(:constants Wrench - toolScrewdriver - toolHammer - tool)(:action pick-up:parameters (?t - tool):precondition (and (not (has ?t))):effect (and (has ?t)))(:action tweak:parameters ():precondition (and (has Screwdriver):effect (and (plane-broken)))(has Wrench))(:action smack:parameters ():precondition (and (has Hammer)):effect (and (plane-broken)(probabilistic 0.9)(and (not (gremlin-alive))))))(define (problem GremlinProb)(:domain GremlinWorld)(:init (gremlin-alive))(:goal (and (gremlin-alive) (plane-broken))))Fig. 1. A PPDDL-style description of the example MDP, GremlinWorld, split into domain and problem parts.However, smacking will, with high probability, lead to accidental detonation of the airplane’s fuel, which destroys the air-plane but also kills the gremlin. Fig. 1 describes this s",
            {
                "entities": [
                    [
                        143,
                        188,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 187–188 (2012) 133–155Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLocal properties in modal logicHans van Ditmarsch a, Wiebe van der Hoek b,∗, Barteld Kooi ca Department of Logic, University of Seville, Spainb Department of Computer Science, University of Liverpool, UKc Faculty of Philosophy, University of Groningen, The Netherlandsa r t i c l ei n f oa b s t r a c tArticle history:Received 18 August 2011Received in revised form 1 March 2012Accepted 22 April 2012Available online 2 May 2012Keywords:Knowledge representationModal logicCorrespondenceCanonicityLocal propertiesEpistemic logicIn modal logic, when adding a syntactic property to an axiomatisation, this property willsemantically become true in all models, in all situations, under all circumstances. Forinstance, adding a property like Ka p → Kb p (agent b knows at least what agent a knows)to an axiomatisation of some epistemic logic has as an effect that such a property becomesglobally true, i.e., it will hold in all states, at all time points (in a temporal setting), afterevery action (in a dynamic setting) and after any communication (in an update setting),and every agent will know that it holds, it will even be common knowledge. We propose away to express that a property like the above only needs to hold locally: it may hold in theactual state, but not in all states, and not all agents may know that it holds. We achieve thisby adding relational atoms to the language that represent (implicitly) quantification over allformulas, as in ∀p(Ka p → Kb p). We show how this can be done for a rich class of modallogics and a variety of syntactic properties. We then study the epistemic logic enrichedwith the syntactic property ‘knowing at least as much as’ in more detail. We show that theenriched language is not preserved under bisimulations. We also demonstrate that addingpublic announcements to this enriched epistemic logic makes it more expressive, which isfor instance not true for the ‘standard’ epistemic logic S5.© 2012 Elsevier B.V. All rights reserved.1. IntroductionModal logic has become the framework for formalising areas in computer science and artificial intelligence as diverse asdistributed computing [14], reasoning about programs [15], verifying temporal properties of systems [17], game theoreticreasoning [25], and specifying and verifying multi-agent systems [31]. Regarding the latter example alone, since Moore’spioneering work [19] on knowledge and action, agent theories like intention logic [5] and BDI [20] use modal logic (wherethe modalities represent time, action, informational attitudes like knowledge or belief, or motivational attitudes like desiresor intentions) to analyse interactions between modalities, like perfect recall, no-learning, realism, or different notions of com-mitment. As for epistemic modal logic, since the seminal work of Hintikka [16], modal epistemic logic has played a keyrole in knowledge representation, witnessed by the literature on reasoning about knowledge in computer science [7], andartificial intelligence [18]. The current activities in dynamic epistemic logic [1,27] can be seen as providing a modal logicalanalysis in the area of belief revision, thereby providing it with a natural basis for multi-agent belief revision, giving anaccount of the change of higher order information, and capturing this all in one and the same object language: a modallanguage, indeed.The popularity of modal logic in those areas is partly explained by its appealing semantics: the notion of state isa very powerful one when it comes to modeling computations of a machine, or describing possibilities that an agent* Corresponding author.E-mail addresses: hvd@us.es (H. van Ditmarsch), wiebe@csc.liv.ac.uk (W. van der Hoek), B.P.Kooi@rug.nl (B. Kooi).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.007\f134H. van Ditmarsch et al. / Artificial Intelligence 187–188 (2012) 133–155thinks/desires/fears to be possible. Another strong feature of modal logic is its flexibility: the fact that temporal, dynamic,informational and motivational attitudes can be represented by modalities does not mean that they all satisfy the same laws.Rather, depending on the interpretation one has in mind, one can decide to either embrace or abandon certain principlesfor each of the modalities used. Syntactically, this means one assumes a number of axioms or inference rules for a modalityor for the interaction of some modalities, and more often than not, this semantically corresponds to assuming some specificproperties of the associated accessibility relations in the corresponding models.In the context of epistemic logic for instance, adding specific modal axioms allows one to specify that the knowingagent is veridical (Ka p → p): if agent a knows that p, then p must be true, or that he is positively (Ka p → Ka Ka p) ornegatively (¬Ka p → Ka¬Ka p) introspective. Those axioms happen to correspond (in a precise way: correspondence theoryfor modal logic is already some decades old, cf. [23]) to reflexivity, transitivity and Euclidicity of the associated accessibilityrelation Ra, respectively. Moreover, the axioms are canonical for it: adding the syntactic axiom to a modal logic enforces thecanonical model for the logic to have the corresponding property, which then in turn implies that completeness of the logicwith respect to the class of models satisfying that relational property is guaranteed. At this point, it is important to note thedifference between Ka p → p as a formula and that as a scheme, or axiom: as a formula, it merely expresses that regardingthe atom p, agent a does not know it without it being true. However, when we assume it as an axiom, or as a scheme, itmeans that we declare it to hold for every substitution instance of p, in other words, we assume that for all formulas ϕ,the implication Kaϕ → ϕ holds.It is often argued (indeed, already by Hintikka in [16]) that a distinguishing feature between knowledge and belief isthat whereas knowledge is veridical, belief need not be, i.e., the scheme Ba p → p should not be assumed as an axiom forbelief. This then simply entails that epistemic logics have veridicality as an axiom, and doxastic logics have not. Semanticallyspeaking: the accessibility relations denoting knowledge are reflexive, those denoting belief need not be. But how then todeal with a situation where we want to express that “currently, a’s beliefs happen to be true”? If we add Ba p → p asan axiom to our logic, the effect is that in all models (with respect to which the logic is complete), and in all states, allinstances of that axiom are true, i.e., for all models M, for all states s and for all formulas ϕ, we then have M, s |(cid:5) Baϕ → ϕ.Given a model M and a state s we can express that a’s belief that an individual proposition q holds is correct: M, s |(cid:5) Baq ∧q.And we can express that a’s belief about q is correct: M, s |(cid:5) (Baq → q) ∧ (Ba¬q → ¬q). But what we cannot express inmodal logic is that Baϕ → ϕ holds for all ϕ in one state, without claiming at the same time it should hold throughout themodel. As a consequence, we cannot express in the object language that agent b thinks that agent a’s beliefs are correct,while agent c believes that a is wrong about a proposition q. The closest one gets to expressing that would be to say thatfor all ϕ, in M, s we have M, s |(cid:5) Bb(Baϕ → ϕ) ∧ Bc((Baq ∧ ¬q) ∨ (Ba¬q ∧ q)) (but here, the quantification over ϕ is on ameta-level, and not in the scope of Bb). Neither can we say, in a temporal doxastic context, that a’s beliefs now are correct,but tomorrow they need not be.To give another example of the same phenomenon, suppose one adds the scheme Ka p → Kb p to a modal logic (b knowseverything that a knows). Semantically, this means Rb ⊆ Ra. If the logic is about a set of agents A, then it becomes commonknowledge among A that b knows at least what a knows! And if there is a notion of time, we have that it will always bethe case that b knows at least what a knows, and, when having modalities for actions, it follows that no action can makeit come about that a has a secret for b, in particular, it is impossible to inform a about something that b does not alreadyknow—this rules out dynamics which are, in contrast, very possible in dynamic epistemic logic.So, the general picture in modal logic that we take as our starting point is the following. One has a modal logic to whichone adds an axiom scheme θ (say, Ba p → p). If one is lucky, the scheme corresponds to a relational property Θ(x) (in thecase above, Rxx). However, adding θ to the logic means having Θ(x) true everywhere, implying that θ is always true. Whatwe are after is looking at ways to enforce the scheme θ locally. To do so, we will add a marker (cid:2) to the modal language,such that (cid:2) is true locally, in a state s, if and only if Θ is true, locally (i.e., Rss holds).In [28], in the context of a multi-agent logic S5, this is done for the scheme ‘knowing at least as much as’. The expressiona (cid:3) b in [28], when true at w means formally ‘a considers at least as many accessible worlds from w as b’, and informally‘a is at least as uncertain as b about the actual state of affairs at w’, is an example of such a marker (cid:2)(a, b), namedSup(a, b) here, and in this case Θ(a, b)(x) is the property ∀ y(Rbxy ⇒ Raxy). The results of [28] are generalised in [29] tomore general modal logics K(+ϕ1, . . . , +ϕn) for formulas ϕi satisfying some additional condition, and this is also the mainfocus of our current contribution.It is also possible to add several markers at the same time. This then enables that not only can we make global propertieslocally true, but it also allows for more subtle quantifications over formulas than is allowed in modal logic. This makes itpossible to express properties like ",
            {
                "entities": [
                    [
                        149,
                        180,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2223–2245Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintParallel belief revision: Revising by sets of formulasJames Delgrande∗, Yi JinSchool of Computing Science, Simon Fraser University, Burnaby, B.C. V5A 1S6, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 30 July 2010Received in revised form 2 October 2011Accepted 3 October 2011Available online 7 October 2011Keywords:Knowledge representation and reasoningBelief changeIterated belief revisionEpistemic statesThe area of belief revision studies how a rational agent may incorporate new informationabout a domain into its belief corpus. An agent is characterised by a belief state K , andreceives a new item of information α which is to be included among its set of beliefs.Revision then is a function from a belief state and a formula to a new belief state.We propose here a more general framework for belief revision, in which revision is afunction from a belief state and a finite set of formulas to a new belief state. In particular,we distinguish revision by the set {α, β} from the set {α ∧ β}. This seemingly innocuouschange has significant ramifications with respect to iterated belief revision. A problem inapproaches to iterated belief revision is that, after first revising by a formula and then by aformula that is inconsistent with the first formula, all information in the original formulais lost.This problem is avoided here in that, in revising by a set of formulas S, the resulting beliefstate contains not just the information that members of S are believed to be true, butalso the counterfactual supposition that if some members of S were later believed to befalse, then the remaining members would nonetheless still be believed to be true. Thusif some members of S were in fact later believed to be false, then the other elementsof S would still be believed to be true. Hence, we provide a more nuanced approach tobelief revision. The general approach, which we call parallel belief revision, is independentof extant approaches to iterated revision. We present first a basic approach to parallelbelief revision. Following this we combine the basic approach with an approach due to Jinand Thielscher for iterated revision. Postulates and semantic conditions characterising theseapproaches are given, and representation results provided. We conclude with a discussionof the possible ramifications of this approach in belief revision in general.© 2011 Elsevier B.V. All rights reserved.1. IntroductionAn agent situated in a sufficiently complex domain will have only incomplete and possibly inaccurate information aboutthat domain. Consequently, such an agent would be expected to receive new information about the domain which it wouldincorporate into its belief corpus. Since new information may conflict with the agent’s accepted beliefs, the agent may alsohave to discard some of its beliefs before the new information can be consistently incorporated. Belief revision is the areaof knowledge representation that addresses how an agent may incorporate new information about a domain into its beliefcorpus. It is generally accepted that there is no single best revision operator, and different agents may have different revisionfunctions. However, revision functions are not arbitrary, but may be considered as being guided or characterised by variousrationality criteria, expressed formally as a set of postulates. The original and best-known set of postulates is called the AGMpostulates [1,16] named after the developers of this framework. As well, several formal constructions of revision functions* Corresponding author.E-mail addresses: jim@cs.sfu.ca (J. Delgrande), yij@cs.sfu.ca (Y. Jin).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.10.001\f2224J. Delgrande, Y. Jin / Artificial Intelligence 176 (2012) 2223–2245have been proposed based, for example, on an ordering on sentences of the language or on an ordering on possible states ofthe world. Ideally, a set of postulates is linked with a formal construction by a representation result, showing that a revisionfunction that satisfies a postulate set can be represented by the formal construction, and vice versa.The foundations of AGM revision are well studied and well understood.1 Subsequently, there has been a great deal ofattention paid to iterated belief revision, which addresses logical relations among a sequence of revisions involving possibly-conflicting observations. While there has been much progress in the area of iterated belief revision, virtually all such worksuffers from the following problem: if one revises by a formula and then by a formula that is inconsistent with this formula,then the agent’s beliefs are exactly the same as if only the second revision had taken place.For example, consider the situation where there was a party, but where you have no knowledge about whether Alice (a)or Bob (b) were there. You are subsequently informed by a reliable source that both Alice and Bob went to the party. Thiswould correspond to a revision by a ∧ b, and your resulting belief state would be one in which you believe a ∧ b to betrue. You later learn that Alice in fact did not go to the party. Not only do you now accept ¬a, but in all major approachesto iterated belief revision, including [9,6,32,21], you no longer accept b either. While there may indeed be cases where it’sreasonable to no longer believe Bob was at the party (for example perhaps Bob is Alice’s spouse), this certainly shouldn’tbe a required outcome.This example can be exaggerated to emphasise the point: Consider where an agent initially has no contingent beliefs,and so its beliefs are characterised by the set of tautologies. Next, a substantial body of knowledge, given by the conjunctionp1 ∧ · · · ∧ p1012 , is loaded into the agent’s knowledge base. If we subsequently revise by, say, the negation of p1, then allother knowledge is lost. That is, if the agent’s original (tautological) beliefs were given by K and ∗ is the revision function,we would obtain:(cid:2)(cid:3)K ∗ (p1 ∧ · · · ∧ p1012 )∗ ¬p1 ≡ K ∗ ¬p1.(1)Thus all other information is lost, except for the newly-negated item. Again, this is clearly too strong a condition to imposeon every revision function in all circumstances.We suggest that this problem is appropriately addressed not by modifying the foundations of belief revision, but ratherby providing a more nuanced or expressive approach to revision. Specifically, we propose that the second argument of arevision function be generalised to be a set of formulas. This then distinguishes revision by a set of formulas from revisionby the conjunction of that set of formulas. Consider again our Alice/Bob example, where again at the outset you have nobeliefs about whether either of them attended a party or not, but you are subsequently informed that they both went tothe party. Consequently, if you were now asked “Do you believe that Alice went to the party?”, clearly you would answer inthe affirmative. Assume further that you have no reason to believe that Alice and Bob know each other well, nor have beenin contact; i.e. each individual’s attendance is independent of the other’s. If you were asked “If it were in fact the case thatAlice did not go, would you still believe that Bob went?”, then again you would answer in the affirmative. However, it canbe noted that this last question is a counterfactual query, in that as far as you know the antecedent is false. We are not goingto be concerned with counterfactuals per se in this paper; however, this does have implications for further revisions: If youwere subsequently informed that in fact Alice did not go, then you should in turn continue to believe that Bob went. If, onthe other hand, you had some reason to believe that Alice and Bob’s attendance were linked – for example that they’re acouple – then this would no longer apply.The key point here is that we are treating the propositions A and B as separate items of information. Our central thesisis that revision by a conjunction and revision by the set of conjuncts should be treated differently. If a formula is takenas representing some item of information, then informally a conjunction represents a single item of information, while thecorresponding set of conjuncts represents a collection of items of information. To be sure, the conjunction α ∧ β and theset {α, β} have the same logical content, in that they entail exactly the same formulas. Hence an agent’s contingent beliefsshould be the same regardless of whether a revision is by a conjunction or a corresponding set of formulas. However,as argued above, in revising by a set {α, β} the agent’s resulting belief state should be such that, if there is no knownconnection between α and β, then if β were subsequently learned to be false, then α should still be believed to be true.To this end, we develop an account of belief revision that we call parallel belief revision in which the second argument toa revision function is a finite set of formulas. Thus, if the agent’s belief state is given by K2 and ∗ is a revision function, thenwe distinguish K ∗ {α ∧ β} from K ∗ {α, β}. In the former, revision is by a single formula that happens to be expressed as aconjunction. If a subsequent revision contradicts this formula, then this formula is simply no longer believed. On the otherhand, if the agent views α and β as independent, then it makes sense that α is believed in K ∗ {α, β} ∗ {¬β}, since if oneelement of the input set is contradicted, this need not affect belief in other element. Essentially, for a revision K ∗ {α, β}, theagent comes to believe not only that α and β are contingently true, but also counterfactual assertions such as if β were falsethen α would (where “reasonable”) still be believed to be true. In terminology introduced in the next section, the agent’sbelief state or",
            {
                "entities": [
                    [
                        147,
                        201,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 105 (1998) 47-75 Artificial Intelligence Empirically-derived estimates of the complexity of labeling line drawings of polyhedral scenes P. Parodi *, R. Lancewicki, A. Vijh, J.K. Tsotsos University of Toronto, Department of Computer Science, 6 King’s College Road, Room 283, Toronto, Ontario, Canada MS 3H5 Received 10 September 1996; received in revised form 16 December 1997 Abstract Several results have been obtained in the past about the complexity of understanding line drawings scenes. Kirousis and Papadimitriou (1988) have shown that the problem of labeling line of polyhedral drawings of trihedral scenes is NP-complete. The human brain, however, seems to grasp at a glance the 3D structure associated with a line drawing. A possible explanation of this discrepancy, offered is that the worst-case complexity does not reflect the real by Kirousis and Papadimitriou difficulty of labeling line drawings, which might be far less in the average or in “typical” cases. However, no statistical analysis has ever been carried out to test this conjecture. themselves, The core of this paper is an algorithm for the generation of random instances of polyhedral scenes. Random instances of line drawings are then obtained as perspective projections of these scenes, and can be used as an input to standard labeling algorithms so as to derive experimental estimates of the complexity of these algorithms. The results indicate that the median-case complexity is linear in the number of junctions. This substantiates instances of line drawings are easy to label, and may help explain the ease by which the brain is able to solve the problem. 0 1998 Elsevier Science B.V. All rights reserved. the conjecture that “typical” Keywords: Line drawings; Computational complexity; Random polyhedral scenes 1. Introduction The problem of understanding the three-dimensional structure of an object from a two-dimensional concise in computer vision and artificial attempts to tackle the problem description (e.g., a line drawing) of it has intrigued intelligence since from a computational the early seventies, when standpoint were independently researchers the first put * Corresponding author. Email: parodi@sissa.it. 00043702/98/$ PII: SOOO4-3702(98)00077-O - see front matter 0 1998 Elsevier Science B.V. All rights reserved \f48 I? Parodi et al. /Art&ial Intelligence 105 (1998) 47-75 to represent for a line drawing forward by Huffman condition arrangement of polyhedral objects was labelability, that is the consistent assignment segments of the line drawing of a label (+, -, +, convexity, concavity, occlusion. The work of Huffman and Clowes was extended directions and sufticient condition that, given a labeled line drawing, instance of Linear Programming. [lo] and Clowes [4]. They both showed that an important necessary the perspective or planar projection of an actual to the such 3D properties as in several [30-321 that a necessary for the realizability of a line drawing was found. Sugihara showed into an [ 11,16,29,34], but it was not until the work of Sugihara problem could be translated the realizability describing t) algorithm that there is an efficient line drawings, at least qualitatively the 3D structure of a scene from a single More recently, several efforts have been concentrated on complexity even for the simple case of trihedral, solid scenes. This unexpected issues. As our brain image with is very efficient at reconstructing (i.e., no texture, color or shading, one might be led to conclude (by labeling that interprets polynomial-time) [ 131, however, have proved that this is unlikely their segments). Kirousis and Papadimitriou that both the labeling problem and the realizability problem are to be the case, by showing result Af?-complete in order to find special cases for which the labeling problem has stimulated much research solvable. In the same paper [ 131, Kirousis and Papadimitriou proved that was polynomially the labeling problem has polynomial for line drawings of Legoland scenes, i.e., scenes made of objects whose 3D edges can only have one of three possible orthogonal in [23] to show that once the location of the vanishing directions. This result was extended the labeling problem points of the line drawing of a trihedral, is known, becomes that the brain may exploit of a scene from a line drawing. geometrical to break It was also shown [21] that the information the NP-completeness drastically reduces the number of legal labelings associated with a line drawing. line drawing of Origami scenes, although this information in order to find a 3D reconstruction time. These results suggests on vanishing points is not sufficient in polynomial solid scene complexity regularities of labeling solvable between for the discrepancy information which the NP-completeness the brain uses geometric Thus, a possible explanation result in natural might be that scenes. Another possible explanation, which was offered by Kirousis and Papadimitriou is that the distribution of natural scenes might be such that the average-case themselves, for the set of line drawings extracted from real scenes is polynomial, unlike the complexity exists also. For a related visual complexity for general visual search and that visual of unbounded [33] proved problem, search becomes linear in the image size when a target is used to guide the matching process. The claim there is that the brain can optimize visual processing by using known appearance of objects and thus for the set of well-known objects, visual processing line drawings. A third possibility the NP-completeness is efficient. is often found As it is well known for other problems instances of a problem are often elusive and can only be found with a careful some characteristic parameters. Furthermore, heuristics have been presented-such relaxation procedure devised by Waltz [34]-which search methods and allegedly provide an efficient way to deal with line drawing (such as SAT [19,25] and CSP [3,9,35]), hard tuning of as the can be used in conjunction with tree- The objective of this paper is to provide a method line drawings with a useful distribution, to the complexity of understanding to generate so as to shed light on several questions random labeling. instances of related scenes: what is the average- images of polyhedral \fI? Parodi et al. /Art$cial Intelligence 105 (1998) 47-7.5 49 techniques tree-search? More generally, our line drawings by relaxation before performing satisfaction complexity of labeling? How much do we gain techniques which achieve some kind are the available techniques competitive with the performances of the the general notion Is this still true when case (either mean-case or median-case) by pre-processing of local consistency computational brain? And can these performances be assessed more precisely, beyond that images of natural scenes are perceived at a glance by humans? scenes display a more random character? to the is organized line drawings. random labeling problem. Section 3 addresses scenes; line A method drawings are obtained by projecting image plane. These line drawings are then used in Section 4 to estimate the complexity of some tree-search methods and other heuristics. for labeling Section 5 draws the conclusions previous works in line drawing analysis. the problem of generating instances of polyhedral these scenes on an arbitrary line drawings and to assess the efficiency of relaxation as follows. Section 2 provides a general of the work and discusses the relation of this paper to the random introduction to generate The paper is devised random 2. The labeling problem The first mathematical results about the interpretation of line drawings date back to [lo] and Clowes [4], who independently an important for the realizability of a line drawing as the 2D projection introduced (lubelability) the works of Huffman necessary condition of a polyhedral Labeling scene. a line drawing means assigning the is the properties of the corresponding projection of a visible convex edge, “-” means that it is the projection of a visible concave edge, and “-+” means that it is the projection of a convex edge such that only one face (the one at the right of the arrow) is visible. 3D edge. The label “+” means to every segment describing that the segment a label see, for example, Huffman and Clowes focused on the case of trihedral scenes (exactly 3 faces meeting that shapes (Y, E, L, T) are possible and that only a few as the (see of a few different of labels are allowed at junctions form the so-called junction dictionary at every vertex; only junctions combinations projection of 3D vertices; Fig. 1 (B)). the line drawing of Fig. these legal labelings to be realizable if they were l(A)). They found A line drawing is said to be labelable iff a label can be assigned to every segment so that every junction is labeled according to this dictionary. in the past for labeling Several methods have been proposed man [lo] and Clowes [4] proposed a reduction algorithm which reported good average running segments). The algorithm achieves local consistency junctions all legal labelings of the junction which is compatible with it. Repeat this procedure until no further progress can be made. To label a line drawing, and then achieve global consistency by tree searching with depth-first backtracking. a line drawing. Huff- to SAT. Waltz [34] devised a filtering in the number of time (roughly rule out for which there is no labeling of the neighbor first achieve local consistency in this way: given a junction, linear \f50 t! Parodi et al. /Artijicial Intelligence IO5 (1998) 47-75 A Fig. 1. (A) An example of a trihedral scene. (B) The Huffman-Clowes vertices. catalogue of legal labelings for trihedral The work on line drawings has stimulated (CSP; Satisfaction Problem the analysis of a more general problem, see Mackworth and Freuder [15] for a the Constraint retrospective): we have a set of variables X1, . . ",
            {
                "entities": [
                    [
                        65,
                        159,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 236–263Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintStable models and circumscriptionPaolo Ferraris a, Joohyung Lee b, Vladimir Lifschitz c,∗a Google, Inc., 1600 Amphitheatre Parkway, Mountain View, CA 94043, United Statesb Department of Computer Science and Engineering, Arizona State University, 699 South Mill Avenue, Tempe, AZ 85281, United Statesc Department of Computer Sciences, University of Texas at Austin, 1 University Station C0500, Austin, TX 78712, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Available online 13 April 2010Keywords:Answer set programmingCircumscriptionNonmonotonic reasoningProgram completionStable models1. IntroductionThe concept of a stable model provided a declarative semantics for Prolog programswith negation as failure and became a starting point for the development of answer setprogramming. In this paper we propose a new definition of that concept, which coversmany constructs used in answer set programming and, unlike the original definition, refersneither to grounding nor to fixpoints. It is based on a syntactic transformation similar toparallel circumscription.© 2010 Elsevier B.V. All rights reserved.Answer set programming (ASP) is a form of declarative logic programming oriented towards knowledge-intensive searchproblems, such as product configuration and planning. It was identified as a new programming paradigm ten years ago [25,29], and it has found by now a number of serious applications. An ASP program consists of rules that are syntacticallysimilar to Prolog rules, but the computational mechanisms used in ASP are different: they use the ideas that have led to thecreation of fast satisfiability solvers for propositional logic [11].ASP is based on the concept of a stable model [9]. According to the definition, to decide which sets of ground atoms are“stable models” of a given set of rules we first replace each of the given rules by all its ground instances. Then we verifya fixpoint condition that is similar to the conditions employed in the semantics of default logic [33] and autoepistemiclogic [28] (see [19, Sections 4, 5] for details).In this paper we investigate a new approach to defining the concept of a stable model. It is based on a syntactictransformation similar to circumscription [26,27]. The new definition refers neither to grounding nor to fixpoints. It turnsout to be more general, in a number of ways, than the original definition.This treatment of stable models may be of interest for several reasons. First, it provides a new perspective on theplace of stable models within the field of nonmonotonic reasoning. We can distinguish between “fixpoint” nonmonotonicformalisms, such as default logic and autoepistemic logic, and “translational” formalisms, such as program completion [1]and circumscription. In the past, stable models were seen as part of the “fixpoint tradition.” The remarkable similaritybetween the new definition of a stable model and the definition of circumscription is curious from this point of view.Second, we expect that the new definition of a stable model will provide a unified framework for useful answer setprogramming constructs that have been defined and implemented by different research groups. For instance, it may help uscombine choice rules in the sense of lparse [34] with aggregates in the sense of dlv [3]. A step in this direction is describedin [14].* Corresponding author.E-mail address: vl@cs.utexas.edu (V. Lifschitz).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.011\fP. Ferraris et al. / Artificial Intelligence 175 (2011) 236–263237Third, our definition is applicable to non-Herbrand models. In such a model, different ground terms may have the samevalue. This may be useful for knowledge representation purposes; we may wish to write, for instance:Father(Jack) = Father(Jane).This possibility is related also to the use of arithmetic functions in ASP, when different ground terms may have the samevalue (2 + 2 = 1 + 3).The new definition of a stable model is introduced in Section 2, and its relation to the original definition is discussedin Section 3. Several useful theorems about the new concept are stated in Section 4. Then we extend the idea of strongequivalence to this framework (Section 5), relate general stable models to program completion (Section 6), and define“pointwise stable models,” which are similar to pointwise circumscription (Section 7). In Section 8, we show how ourtheory of stable models handles strong (or classical) negation, and Section 9 discusses related work. Proofs of theorems arecollected in Appendix A.To make the presentation more self-contained, we include brief reviews of parallel and pointwise circumscription (Sec-tions 2.2 and 7.1) and of two approaches to the stable model semantics proposed earlier (Section 3.1).This article is an extended version of the conference paper [6].2. Stable models2.1. Logic programs as first-order sentencesThe concept of a stable model will be defined here for first-order sentences,1 possibly containing function constantsand equality. Logic programs are viewed in this paper as alternative notation for first-order sentences of special types. Forinstance, we treat the logic programp(a, a),p(a, b),q(x) ← p(x, y)as shorthand forp(a, a) ∧ p(a, b) ∧ ∀xy(cid:2)(cid:3)p(x, y) → q(x).The constraint← p(x), not q(x)(1)(2)(3)is identified with the formula(cid:2)∀x¬(cid:3)p(x) ∧ ¬q(x),and the disjunctive rulep(x); q( y) ← r(x, y)with(cid:2)r(x, y) →(cid:2)∀xy(cid:3)(cid:3)p(x) ∨ q( y).As another example, take the choice rule(cid:4)(cid:5)p(x)← q(x).It says, informally speaking: for every x such that q(x), choose arbitrarily whether or not to include p(x) in the stable model.We can treat this rule as shorthand for(cid:2)(cid:3)(cid:3).(4)(cid:2)q(x) →∀xp(x) ∨ ¬p(x)This formula is logically valid, so that appending it as a conjunctive term to any sentence F would not change the class ofmodels of F . But the class of stable models of F may change, as we will see, after appending (4).The next example involves an aggregate. The rulep(x) ← # card(cid:4)(cid:5)y: q(x, y)< 2means intuitively: if the cardinality of the set { y: q(x, y)} is less than 2 then include p(x) in the stable model. We can treatthis rule as an abbreviation for the formula(cid:2)∀x¬∃ y1 y2(cid:2)q(x, y1) ∧ q(x, y2) ∧ y1 (cid:9)= y2(cid:3)(cid:3)→ p(x).(5)1 A sentence is a formula without free variables.\f238P. Ferraris et al. / Artificial Intelligence 175 (2011) 236–2632.2. Review of circumscriptionSince the new definition of a stable model is similar to the definition of parallel circumscription, we will begin with abrief review of the latter.Both definitions use the following notation. If p and q are predicate constants of the same arity then p (cid:2) q stands forthe formula(cid:2)(cid:3)p(x) → q(x),∀xwhere x is a tuple of distinct object variables. If p and q are tuples p1, . . . , pn and q1, . . . , qn of predicate constants thenp (cid:2) q stands for the conjunction(p1 (cid:2) q1) ∧ · · · ∧ (pn (cid:2) qn),and p < q stands for (p (cid:2) q) ∧ ¬(q (cid:2) p). In second-order logic, we apply the same notation to tuples of predicate variables.Let p be a list of distinct predicate constants.2 The circumscription operator with the minimized predicates p, denoted byCIRCp, is defined as follows: for any first-order formula F , CIRCp[F ] is the second-order formula(cid:2)F ∧ ¬∃u(cid:3)(u < p) ∧ F (u),where u is a list of distinct predicate variables of the same length as p, and F (u) is the formula obtained from F bysubstituting the variables u for the constants p.3If the list p is empty then we understand CIRCp[F ] as F . We will drop the subscript in the symbol CIRCp when this doesnot lead to confusion.For any sentence F , a p-minimal (or simply minimal) model of F is an interpretation of the underlying signature thatsatisfies CIRCp[F ]. Since the first conjunctive term of CIRCp[F ] is F , it is clear that every minimal model of F is a modelof F .Example 1. If F is formula (2) then CIRCpq[F ] is(cid:3)(cid:3)(cid:2)(cid:2)∀xyp(a, a) ∧ p(a, b) ∧∧ ¬∃uv(cid:2)(cid:2)(cid:3)(u, v) < (p, q)p(x, y) → q(x)∧ ∀xy(cid:2)u(a, a) ∧ u(a, b) ∧(cid:2)u(x, y) → v(x)(cid:3)(cid:3)(cid:3).It can be equivalently rewritten without second-order variables as follows:(cid:2)∀x(cid:3)p(x, y) ↔ (x = a ∧ y = a) ∨ (x = a ∧ y = b)(cid:2)q(x) ↔ x = a∧ ∀xExample 2. Let F be the formula(cid:2)(cid:3)p(x, y) → t(x, y)∀xy∧ ∀xyz(cid:2)(cid:3)t(x, y) ∧ t( y, z) → t(x, z)(“p is a subset of t, and t is a transitive relation”). Then CIRCt[F ] is(cid:3).(6)(7)(cid:2)∀xy(cid:3)p(x, y) → t(x, y)(u < t) ∧ ∀xy(cid:2)∧ ¬∃u∧ ∀xyz(cid:2)(cid:3)p(x, y) → u(x, y)(cid:2)(cid:3)t(x, y) ∧ t( y, z) → t(x, z)(cid:2)∧ ∀xyzu(x, y) ∧ u( y, z) → u(x, z).(cid:3)(cid:3)This condition cannot be expressed by a first-order formula, but its meaning is straightforward: it says that t is the transitiveclosure of p.If we conjoin (7) withp(a, b) ∧ p(b, c)(8)and include both p and t in the list of minimized predicates then the circumscription formula will become expressible infirst-order logic as(cid:2)∀xy(cid:3)p(x, y) ↔ (x = a ∧ y = b) ∨ (x = b ∧ y = c)∧ ∀xy(cid:2)(cid:3)t(x, y) ↔ (x = a ∧ y = b) ∨ (x = b ∧ y = c) ∨ (x = a ∧ y = c).(9)2 In this paper, equality is not considered a predicate constant, so that it is not allowed to be a member of p.3 This definition of the circumscription operator allows F to have free variables, unlike the definition from [17]. Similarly, the definition of the stablemodel operator below is applicable to formulas with free variables, unlike the definition proposed in the conference paper [6].\fP. Ferraris et al. / Artificial Intelligence 175 (2011) 236–2632392.3. Operator SMWe will now define the stable model operator with the intensional predicates p, denoted by SMp. Some details of thedefinition depend on which propo",
            {
                "entities": [
                    [
                        136,
                        169,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 238 (2016) 96–118Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMaking the right exceptions ✩,✩✩Harald Bastiaanse, Frank Veltman∗Institute for Logic, Language and Computation, Universiteit van Amsterdam, P.O. Box 94242, 1090 GE Amsterdam, The Netherlandsa r t i c l e i n f oa b s t r a c tArticle history:Received 2 December 2013Received in revised form 26 May 2016Accepted 30 May 2016Available online 2 June 2016Keywords:CircumscriptionDefaultsNonmonotonic logicInheritance networksThis paper is about the logical properties of sentences of the form S’s are normally P, and starts from the idea that any logical theory for such sentences should meet the following simple requirement:If the only available information about some object x is that x has property S, it must be valid to infer by default that x has all the properties P that objects with property Snormally have.We investigate how this requirement can be met by theories developed within the framework of circumscription, and specify a constraint – the exemption principle – that must be satisfied to do so. This principle determines in cases of conflicting default rules which objects are exempted from which rules, and, as such, is the main source for the capricious logical behavior of the sentences we are interested in.To facilitate comparison (and implementation) we supply an algorithm for inheritance networks and prove that arguments that can be expressed in both frameworks are valid on the circumscriptive account if and only if the inheritance algorithm has a positive outcome.© 2016 Elsevier B.V. All rights reserved.1. IntroductionDiscussions often end before the issues that started them have been resolved. In the 1980s and 1990s default reasoning was a hot topic in the field of logic and AI. The result of this discussion was not one single theory that met with general agreement, but a collection of alternative theories, each with its merits, but none entirely satisfactory. This paper aims to give a new impetus to this discussion.The issue is the logical behavior of sentences of the formS’s are normally PSuch sentences function as default rules. What they mean is roughly this: when you are confronted with an object with property S, and you have no evidence to the contrary, you are legitimized to assume that this object has property P .The research for this paper was partly financed by the Netherlands Organisation for Scientific Research (project NWO-360-20-200), whose support is ✩gratefully acknowledged.This paper has a long history. Successive drafts have been presented between 2009 and 2015 in Amsterdam, Groningen, Gent, Göttingen, Westport, ✩✩Ann Arbor, Beijing, and Guangzhou. We thank the audiences for their valuable feedback. We also want to thank the referees, whose suggestions led to significant improvements both in content and in presentation.* Corresponding author.E-mail addresses: bastiaanse_harald@hotmail.com (H. Bastiaanse), f.veltman@uva.nl (F. Veltman).http://dx.doi.org/10.1016/j.artint.2016.05.0050004-3702/© 2016 Elsevier B.V. All rights reserved.\fH. Bastiaanse, F. Veltman / Artificial Intelligence 238 (2016) 96–11897The ‘evidence to the contrary’ can vary. Sometimes it simply consists in the empirical observation that the object con-cerned is in fact an exception to the rule. On other occasions the evidence may be more indirect. Consider:premise 1premise 2premise 3premise 4A’s are normally ES’s are normally not ES’s are normally Ac is A and c is Sby defaultc is not EThis is a case of conflicting defaults.1 At first sight one might be tempted to draw both the conclusion that c is E (from premises 1 and 4) and that c is not E (from premises 2 and 4), and maybe on second thought to draw neither. But the third premise states that objects with the property S normally have the property A as well. So, apparently, normal S’s are exceptional A’s, as the rule that A’s are normally E does not hold for them. In other words, only the S-defaults apply to c. So, presumably, c is not E.Default reasoning has been formalized in various ways, and within each of the existing theoretical frameworks a number of strategies have been proposed to deal with conflicting defaults. In the following we will focus on two of these frameworks, Circumscription (McCarthy [1,2]), and Inheritance Networks (Horty et al. [3]), and implement a new strategy to deal with conflicting rules in each of these.2. Naive circumscriptionWithin the circumscriptive approach a sentence of the form S’s are normally P is represented by a formula of the form∀x((Sx ∧ ¬ Ab SxP x x) → P x).Here Ab SxP x x is a one place predicate. The subscript ‘SxP x’ serves as an index, indicating the rule concerned. If an object asatisfies the formula Ab SxP x x, this means that a is an abnormal object with respect to this rule.More generally, let L0 be a language of monadic first order logic. With each pair (cid:6)ϕ(x), ψ(x)(cid:7),2 we associate a new one-place predicate Abϕ(x)ψ(x), thus obtaining the first order language L.A default rule is a formula of L of the form∀x((ϕ(x) ∧ ¬ Abϕ(x)ψ(x) x) → ψ(x)).Here, ϕ(x) and ψ(x) must be formulas of L0 that are quantifier-free and in which no individual constant occurs. The formula ϕ(x) is called the antecedent of the rule, Abϕ(x)ψ(x) x is its abnormality clause, and ψ(x) its consequent. Again, the index ϕ(x)ψ(x) is there just to indicate that it concerns the abnormality predicate of the rule with antecedent ϕ(x) and consequent ψ(x). When it is clear which variable is at stake we will write Abϕψ rather than Abϕ(x)ψ(x). And often we will shorten ‘∀x((ϕ(x) ∧ ¬ Abϕψ x) → ψ(x))’ further to∀x(ϕ(x) (cid:2) ψ(x)).Since it is clear from the antecedent and the consequent of a default rule what the abnormality clause is, this should not cause confusion.3In ordinary logic, for an argument to be valid, the conclusion must be true in all models in which the premises are true. The basic idea underlying circumscription is that not all models of the premises matter but only the most normal ones – only the ones in which the extension of the abnormality predicates is inclusion-wise minimal given the information at hand. Formally:Definition 2.1.(i) Let L be a language as described above, and let A = (cid:6)A, I(cid:7) and A(cid:8) = (cid:6)A(cid:8), I(cid:8)(cid:7) be two models for L with the following properties:(a) A = A(cid:8)(b) for all individual constants c, I(c) = I(cid:8)(c);;1 If a concrete example is wanted, substitute ‘adult’ for A, ‘employed’ for E, and ‘student’ for S.2 Notation: we write ϕ(x) to denote a formula ϕ of L0 in which (at most) the variable x occurs freely.3 Some readers may not like the fact that in this set up the formulas ∀x(Sx (cid:2) P x) and ∀ y(S y (cid:2) P y) are not logically equivalent, because they contain different abnormality predicates. We could remedy this defect by introducing the same abnormality predicate Abϕ(·)ψ(·) for all pairs (cid:6)ϕ(x), ψ(x)(cid:7), indepen-dent of the free variable x occurring in ϕ(x) and ψ(x). Here ‘·’ refers to a symbol that does not belong to the vocabulary of L0, and by ϕ(·), we mean the expression that one obtains from ϕ(x) by replacing each free occurrence of x by an occurrence of ·.Some readers may insist that on top of this we should enforce that whenever ϕ(x) is logical equivalent to χ (x), and ψ(x) to θ(x), ∀x(ϕ(x) (cid:2) ψ(x))gets equivalent to ∀x(χ (x) (cid:2) θ(x)). This can be done by stipulating that we are only interested in models that assign the same extension to Abϕ(·)ψ(·) and Abχ (·)θ (·) if ϕ(x) is logical equivalent to χ (x) and ψ(x) to θ(x). However, for our purposes, we can keep things simple.\f98H. Bastiaanse, F. Veltman / Artificial Intelligence 238 (2016) 96–118(c) for all abnormality predicates Abϕψ , I( Abϕψ ) ⊆ I(cid:8)( Abϕψ ).Then A is at least as normal as A(cid:8).(ii) Let C be a class of models. Then A = (cid:6)A, I(cid:7) is an optimal model in C iff A ∈ C and there is no model in C that is more normal than A.(iii) Let (cid:6) be a set of sentences. Then (cid:6) |=c ϕ iff ϕ is true in all optimal models of (cid:6).Notice that in (i) of this definition nothing is said about the interpretation of ordinary predicates. A can be at least , while for all P ∈ L0, the interpretations I(P ) and I(cid:8)(P ) are totally different. However, in practice we as normal as A(cid:8)are always looking for the most normal models within a given class C, and it may very well happen that within C the interpretation of the ordinary predicates is heavily constrained or even fixed.If (cid:6) |=c ϕ, we say that ϕ follows by circumscription from (cid:6). Here is an example.premise 1 Adults normally have a bank accountpremise 2 Adults normally have a driver’s licensepremise 3premise 4John is an adultJohn does not have a driver’s licenseby defaultJohn is an adult with a bank accountThis can be formalized aspremise 1premise 2premise 3premise 4∀x(( Ax ∧ ¬ Ab A B x) → Bx)∀x(( Ax ∧ ¬ Ab A D x) → Dx)A j¬D jby circumscription B jIt is easy to check that the conclusion B j follows by circumscription from the premises.This example illustrates why the abnormality predicates have a double index referring to both the antecedent and the consequent of the rule, rather than a single one referring to just the antecedent. It is not sufficient to distinguish between normal and abnormal A’s, and formalize a sentence like Adults normally have a bank account as ∀x(( Ax ∧ ¬ Ab A x) → Bx). The distinction has to be more fine grained. An object with the property A can be a normal A in some respects and an abnormal A in other. Even though John is an abnormal adult in not having a driver’s license, he is a normal adult in having a bank account, or at least we want to be able to conclude by default that he is. If we had formalized the argument in the following way, we would not have gotten very far.4premise 1 ∀x(( Ax ∧ ¬ Ab A x) → Bx)premise 2 ∀x(( Ax ∧ ¬ Ab A x) → Dx)pr",
            {
                "entities": [
                    [
                        135,
                        162,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 413–436Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUsing arguments for making and explaining decisions ✩Leila Amgoud∗, Henri PradeInstitut de Recherche en Informatique de Toulouse, CNRS – University of Toulouse III, 118 route de Narbonne, 31062 Toulouse, Cedex 09, Francea r t i c l ei n f oa b s t r a c tArticle history:Received 8 November 2006Received in revised form 13 November 2008Accepted 17 November 2008Available online 24 November 2008Keywords:Decision makingArgumentationArguments play two different roles in day life decisions, as well as in the discussion ofmore crucial issues. Namely, they help to select one or several alternatives, or to explainand justify an already adopted choice.This paper proposes the first general and abstract argument-based framework for decisionmaking. This framework follows two main steps. At the first step, arguments for beliefs andarguments for options are built and evaluated using classical acceptability semantics. At thesecond step, pairs of options are compared using decision principles. Decision principlesare based on the accepted arguments supporting the options. Three classes of decisionprinciples are distinguished: unipolar, bipolar or non-polar principles depending on whetheri) only arguments pros or only arguments cons, or ii) both types, or iii) an aggregationof them into a meta-argument are used. The abstract modelis then instantiated byexpressing formally the mental states (beliefs and preferences) of a decision maker. Inthe proposed framework, information is given in the form of a stratified set of beliefs.The bipolar nature of preferences is emphasized by making an explicit distinction betweenprioritized goals to be pursued, and prioritized rejections that are stumbling blocks tobe avoided. A typology that identifies four types of argument is proposed. Indeed, eachdecision is supported by arguments emphasizing its positive consequences in terms ofgoals certainly satisfied and rejections certainly avoided. A decision can also be attackedby arguments emphasizing its negative consequences in terms of certainly missed goals,or rejections certainly led to by that decision. Finally, this paper articulates the optimisticand pessimistic decision criteria defined in qualitative decision making under uncertainty,in terms of an argumentation process. Similarly, different decision principles identified inmultiple criteria decision making are restated in our argumentation-based framework.© 2008 Elsevier B.V. All rights reserved.1. IntroductionDecision making, often viewed as a form of reasoning toward action, has raised the interest of many scholars includingphilosophers, economists, psychologists, and computer scientists for a long time. Any decision problem amounts to selecting✩The present paper unifies and develops the content of several conference papers [L. Amgoud, J.-F. Bonnefon, H. Prade, An argumentation-based approachto multiple criteria decision, in: Proceedings of the 8th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty(ECSQARU’05), 2005, pp. 269–280; L. Amgoud, H. Prade, A bipolar argumentation-based decision framework, in: Proceedings of the 11th InternationalConference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU’06), 2006, pp. 323–330; L. Amgoud, H. Prade,Comparing decisions in an argumentation-based setting, in: Proceedings of the 11th International Workshop on Non-Monotonic Reasoning (NMR’06), 2006;L. Amgoud, H. Prade, Explaining qualitative decision under uncertainty by argumentation, in: Proceedings of the 21st National Conference on ArtificialIntelligence (AAAI’06), 2006, pp. 219–224 [2,7–9]].* Corresponding author.E-mail address: amgoud@irit.fr (L. Amgoud).URL: http://www.irit.fr/~Leila.Amgoud/ (L. Amgoud).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.006\f414L. Amgoud, H. Prade / Artificial Intelligence 173 (2009) 413–436the “best” or sufficiently “good” action(s) that are feasible among different alternatives, given some available informationabout the current state of the world and the consequences of potential actions. Note that available information may beincomplete or pervaded with uncertainty. Besides, the goodness of an action is judged by estimating, maybe by means ofseveral criteria, how much its possible consequences fit the preferences or the intentions of the decision maker. This agentis assumed to behave in a rational way [41,42,49], at least in the sense that his decisions should be as much as possibleconsistent with his preferences. However, we may have a more requiring view of rationality, such as demanding for theconformity of decision maker’s behavior with postulates describing how a rational agent should behave [45].Decision problems have been considered from different points of view. We may distinguish two main trends, which arecurrently influencing research in artificial intelligence (AI): classical decision theory on the one hand, and cognitively-orientedapproaches such as practical reasoning or beliefs-desires-intentions (BDI) settings on the other hand.1.1. Classical decision making vs. practical reasoningClassical decision theory, as developed mainly by economists, has focused on making clear what is a rational decisionmaker. Thus, they have looked for principles for comparing different alternatives. A particular decision principle, such asthe classical expected utility [45], has been justified on the basis of a set of rationality postulates to which the preferencerelation between actions should obey. This means that in this approach, rationality is captured through a set of postulatesthat describe what is a rational decision behavior. Moreover, a minimal set of postulates is identified in such a way that itcorresponds to a unique decision principle. The inputs of this approach are a set of candidate actions, and a function thatassesses the value of their consequences when the actions are performed in a given state, together with complete or partialinformation about the current state of the world. In other words, such an approach distinguishes between knowledge andpreferences, which are respectively encoded in practice by a distribution function assessing the plausibility of the differentstates of the world, and by a utility function encoding preferences by estimating how good a consequence is. The output is apreference relation between actions encoded by the associated principle. Note that such an approach aims at rank-orderinga group of candidate actions rather than focusing on a candidate action individually. Moreover, the candidate actions aresupposed to be feasible. Roughly speaking, we may distinguish two groups of works in AI dealing with decision that followthe above type of approach. The first group is represented by researches using Bayesian networks [40], on planning underuncertainty (e.g. [21]). Besides, some AI works have aimed at developing more qualitative frameworks for decision, but stillalong the same line of thoughts (e.g. [22,27,47]).Other researchers working on practical reasoning, starting with the generic question “what is the right thing to do foran agent in a given situation” [41,43], have proposed a two steps process to answer this question. The first step, oftencalled deliberation [49], consists of identifying the goals of the agent. In the second step, they look for ways of achievingthose goals, i.e. for plans, and thus for intermediary goals and sub-plans. Such an approach raises issues such as: howare goals generated ? are actions feasible ? do actions have undesirable consequences ? are sub-plans compatible ? arethere alternative plans for achieving a given goal, . . . . In [16], it has been argued that this can be done by representingthe cognitive states, namely agent’s beliefs, desires and intentions (thus the so-called BDI architecture). This requires arich knowledge/preference representation setting, which contrasts with the classical decision setting that directly uses anuncertainty distribution (a probability distribution in the case of expected utility), and a utility (value) function. Besides,the deliberation step is merely an inference problem since it amounts to finding a set of desires that are justified on thebasis of the current state of the world and of conditional desires. Checking if a plan is feasible and does not lead to badconsequences is still a matter of inference. A decision problem only occurs when several plans or sub-plans are possible,and one of them has to be chosen. This latter issue may be viewed as a classical decision problem. What is worth noticingin most works on practical reasoning is the use of argument schemes for providing reasons for choosing or discarding anaction (e.g. [30,35]). For instance, an action may be considered as potentially useful on the basis of the so-called practicalsyllogism [48]:• G is a goal for agent X• Doing action A is sufficient for agent X to carry out goal G• Then, agent X ought to do action AThe above syllogism is in essence already an argument in favor of doing action A. However, this does not mean that theaction is warranted, since other arguments (called counter-arguments) may be built or provided against the action. Thosecounter-arguments refer to critical questions identified in [48] for the above syllogism. In particular, relevant questionsare “Are there alternative ways of realizing G?”, “Is doing A feasible?”, “Has agent X other goals than G?”, “Are thereother consequences of doing A which should be taken into account?”. Recently in [10,11], the above syllogism has beenextended to explicitly take into account the reference to ethical values in arguments. Anyway, the idea of using argumentsfor justifying or discarding candidate decisions is certainty very old, and its account in the literature at least dates",
            {
                "entities": [
                    [
                        136,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 235 (2016) 63–94Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBelief and truth in hypothesised behavioursStefano V. Albrecht a,∗a The University of Texas at Austin, United Statesb Masdar Institute of Science and Technology, United Arab Emiratesc The University of Edinburgh, United Kingdom, Jacob W. Crandall b, Subramanian Ramamoorthy ca r t i c l e i n f oa b s t r a c tArticle history:Received 27 July 2015Received in revised form 29 January 2016Accepted 29 February 2016Available online 4 March 2016Keywords:Autonomous agentsMultiagent systemsGame theoryType-based methodThere is a long history in game theory on the topic of Bayesian or “rational” learning, in which each player maintains beliefs over a set of alternative behaviours, or types, for the other players. This idea has gained increasing interest in the artificial intelligence (AI) community, where it is used as a method to control a single agent in a system composed of multiple agents with unknown behaviours. The idea is to hypothesise a set of types, each specifying a possible behaviour for the other agents, and to plan our own actions with respect to those types which we believe are most likely, given the observed actions of the agents. The game theory literature studies this idea primarily in the context of equilibrium attainment. In contrast, many AI applications have a focus on task completion and payoff maximisation. With this perspective in mind, we identify and address a spectrum of questions pertaining to belief and truth in hypothesised types. We formulate three basic ways to incorporate evidence into posterior beliefs and show when the resulting beliefs are correct, and when they may fail to be correct. Moreover, we demonstrate that prior beliefs can have a significant impact on our ability to maximise payoffs in the long-term, and that they can be computed automatically with consistent performance effects. Furthermore, we analyse the conditions under which we are able complete our task optimally, despite inaccuracies in the hypothesised types. Finally, we show how the correctness of hypothesised types can be ascertained during the interaction via an automated statistical analysis.© 2016 Elsevier B.V. All rights reserved.1. IntroductionThere is a long history in game theory on the topic of Bayesian or “rational” learning (e.g. [73,35,65,63]). Therein, players maintain beliefs about the behaviours, or “types”, of other players in the form of a probability distribution over a set of alternative types. These beliefs are updated based on the observed actions, and each player chooses an action which is expected to maximise the payoffs received by the player, given the current beliefs of the player. The principal questions studied in this context are the degree to which players can learn to make correct predictions, and whether the interaction process converges to solutions such as Nash equilibrium [74].This general idea, which we here refer to as the type-based method, has received increasing interest in the artificial intelligence (AI) community, where it is used as a method to control a single agent in a system composed of multiple agents (e.g. [4,11,52,25]). This interest is, in part, motivated by applications that require efficient and flexible interaction * Corresponding author.E-mail address: svalb@cs.utexas.edu (S.V. Albrecht).http://dx.doi.org/10.1016/j.artint.2016.02.0040004-3702/© 2016 Elsevier B.V. All rights reserved.\f64S.V. Albrecht et al. / Artificial Intelligence 235 (2016) 63–94with agents whose behaviours are initially unknown. Example applications include adaptive user interfaces, robotic elderly care, and automated trading agents. Learning to interact from scratch in such settings is notoriously difficult, due to the essentially unconstrained nature of what the other agents may be doing and the fact that their behaviours are a priori unknown. The type-based method is seen as a way to reduce the complexity of such problems by focusing on a relatively small set of points in the infinite space of possible behaviours.More concretely, the idea is to hypothesise (“guess”) a set of types, each of which specifies a possible behaviour for the other agents. A type may be of any structural form, and here we simply view it as a “blackbox” programme which takes as input the interaction history and chooses actions for the next step in the interaction. Such types may be specified manually by a domain expert or generated automatically, e.g. from a corpus of historical data or the problem description. By compar-ing the predictions of the types with the observed actions of the agents, we can form posterior beliefs about the relative likelihood of types. The beliefs and types are in turn utilised in a planning procedure to find an action which maximises our expected payoffs with respect to our beliefs. A useful feature of this method is the fact that we may hypothesise any types of behaviours, which gives us the flexibility to interact with a variety of agents. Moreover, since each type specifies a com-plete behaviour, we can plan actions in the entire interaction space, including in situations that have not been encountered before.Nonetheless, there are several questions and concerns associated with this method, pertaining to the evolution and impact of beliefs as well as the implications and detection of incorrect hypothesised types. Specifically, how should evidence (i.e. observed actions) be incorporated into beliefs and under what conditions will the beliefs be correct? What impact do prior beliefs have on our ability to maximise payoffs in the long-term? Furthermore, under what conditions will we be able to complete our task even if our hypothesised types are incorrect? And, finally, how can we ascertain the correctness of our hypothesised types during the interaction?The AI literature on the type-based method has focused on experimental evaluations, exploration mechanisms, and com-putational issues arising from recursive beliefs, but not or only partially on the questions outlined above. (We defer a detailed discussion of related works to Section 2). On the other hand, the game theory literature addresses such questions primarily in the context of equilibrium attainment in repeated games (cf. Section 2). However, there are several reasons why this renders the game theory literature of limited applicability to domains such as the ones mentioned earlier. First, equilibrium concepts such as Nash equilibrium are based on normative assumptions, including perfect rationality with re-spect to one’s payoffs. However, such normative assumptions are difficult to justify in situations in which we assume no prior knowledge about the behaviour of other agents. For example, there is evidence that humans do not satisfy such strict assumptions (e.g. [64]). Second, an equilibrium solution prescribes behaviours for all involved agents, whereas we control only a single agent and assume no control over the choice of behaviour for the other agents. Finally, the existence of multi-ple equilibria with possibly differing payoff profiles means that equilibrium attainment may itself not be synonymous with payoff maximisation for our controlled agent.The purpose of the present article is to improve our understanding of the type-based method by providing insight into the questions outlined above. Our analysis is based on stochastic Bayesian games, which are an extension of Bayesian games [56] that include stochastic state transitions, and Harsanyi–Bellman Ad Hoc Coordination (HBA), which can be viewed as a general algorithmic description of the type-based method [4]. After discussing related work in Section 2 and technical preliminaries in Section 3, the article makes the following contributions:• Section 4 considers three basic methods to incorporate observations into posterior beliefs and analyses the conditions under which they converge to the true distribution of types, including in processes in which type assignments may be randomised and correlated. We also discuss examples to show when beliefs may fail to converge to the correct distribution.• Section 5 investigates the impact of prior beliefs on payoff maximisation in a comprehensive empirical study. We show that prior beliefs can indeed have a significant impact on the long-term performance of HBA, and that the magnitude of the impact depends on the depth of the planning horizon (i.e. how far we look into the future). Moreover, we show that automatic methods can compute prior beliefs with consistent performance effects.• Section 6 analyses what relation the hypothesised types must have to the true types in order for HBA to be able to complete its task, despite inaccuracies in the hypothesised types. We formulate a hierarchy of increasingly desirable termination guarantees and analyse the conditions under which they are met. In particular, we give a novel characteri-sation of optimality which is based on the concept of probabilistic bisimulation [69].• Section 7 shows how the truth of hypothesised types can be contemplated during the interaction in the form of an automated statistical analysis. The presented algorithm can incorporate multiple statistical features into the test statis-tic and learns its distribution during the interaction process, with asymptotic correctness guarantees. We show in a comprehensive set of experiments that the algorithm achieves high accuracy and scalability at low computational costs.Finally, Section 8 concludes this work and discusses directions for future work. Elements of this work appeared in [2,7,6,5].\fS.V. Albrecht et al. / Artificial Intelligence 235 (2016) 63–94652. Related workThis section discusses related work and situates our work within the literature. We distinguish between research on the type-based method in the areas of game theory and artificial intelligence.2.1. Type-based method in game ",
            {
                "entities": [
                    [
                        134,
                        177,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 312 (2022) 103771Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQ-Learning-based model predictive variable impedance control for physical human-robot collaboration ✩Loris Roveda a,∗Dario Piga aa Istituto Dalle Molle di studi sull’Intelligenza Artificiale (IDSIA), Scuola Universitaria Professionale della Svizzera Italiana (SUPSI), Università della Svizzera italiana (USI), via la Santa 1, 6962, Lugano, Switzerlandb Politecnico di Milano, Department of Mechanical Engineering, via La Masa 1, 20156, Milano, Italy, Andrea Testa b, Asad Ali Shahid a, Francesco Braghin b, a r t i c l e i n f oa b s t r a c tArticle history:Received 21 September 2021Received in revised form 18 July 2022Accepted 6 August 2022Available online 11 August 2022Keywords:Physical human-robot collaborationIndustry 4.0Machine learningModel-based reinforcement learning controlNeural networksQ-LearningStabilityVariable impedance controlPhysical human-robot collaboration is increasingly required in many contexts (such as industrial and rehabilitation applications). The robot needs to interact with the human to perform the target task while relieving the user from the workload. To do that, the robot should be able to recognize the human’s intentions and guarantee safe and adaptive behavior along the intended motion directions. The robot-control strategies with such attributes are particularly demanded in the industrial field, where the operator guides the robot manually to manipulate heavy parts (e.g., while teaching a specific task). With this aim, this work proposes a Q-Learning-based Model Predictive Variable Impedance Control (Q-LMPVIC) to assist the operators in a physical human-robot collaboration (pHRC) tasks. A Cartesian impedance control loop is designed to implement a decoupled compliant robot dynamics. The impedance control parameters (i.e., setpoint and damping parameters) are then optimized online in order to maximize the performance of the pHRC. For this purpose, an ensemble of neural networks is designed to learn the modeling of the human-robot interaction dynamics while capturing the associated uncertainties. The derived modeling is then exploited by the model predictive controller (MPC), enhanced with the stability guarantees by means of Lyapunov constraints. The MPC is solved by making use of a Q-Learning method that, in its online implementation, uses an actor-critic algorithm to approximate the exact solution. Indeed, the Q-learning method provides an accurate and highly efficient solution (in terms of computational time and resources). The proposed approach has been validated through experimental tests, in which a Franka EMIKA panda robot has been used as a test platform. Each user was asked to interact with the robot along the controlled vertical z Cartesian direction. The proposed controller has been compared with a model-based reinforcement learning variable impedance controller (MBRLC) previously developed by some of the authors in order to evaluate the performance. As highlighted in the achieved results, the proposed controller is able to improve the pHRC performance. Additionally, two industrial tasks (a collaborative assembly and a collaborative deposition task) have been demonstrated to prove the applicability of the proposed solution in real industrial scenarios.© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).✩This paper is part of the Special Issue: “Risk-aware Autonomous Systems: Theory and Practice”.* Corresponding author.francesco.braghin@polimi.it (F. Braghin), dario.piga@supsi.ch (D. Piga).E-mail addresses: loris.roveda@idsia.ch (L. Roveda), andrea8.testa@mail.polimi.it (A. Testa), asadali.shahid@idsia.ch (A.A. Shahid), https://doi.org/10.1016/j.artint.2022.1037710004-3702/© 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fL. Roveda, A. Testa, A.A. Shahid et al.Artificial Intelligence 312 (2022) 1037711. Introduction1.1. ContextTo meet customers needs, which are becoming more and more oriented on tailor-made products, companies are updat-ing their production processes by means of new flexible and agile tools [1]. In this context, collaborative robotics plays a key role [2], providing powerful solutions to assist the operators in the execution of different activities, such as co-manipulation [3,4], task’s knowledge transfer to the robotic system [5,6], easy programmable and deployable applications [7], etc. Physical human-robot collaboration (pHRC) is currently one of the most investigated topics [8]. In fact, pHRC is nowadays demanded in many fields of applications, both for collaborative robots [9] and exoskeletons [10]. However, many open issues in the state of the art are still to be overcome, in particular considering safety/stability guarantees in the human-robot inter-action, human-robot dynamics modeling, human’s intention recognition (for active assistance/empowering purposes), and computation efficiency (for real-time control adaptation and optimization).To tackle the above mentioned issues within the pHRC scenario, this paper proposes a Q-Learning-based Model Predictive Variable Impedance Control (Q-LMPVIC) to assist the operator while physically interacting with a collaborative robot. Based on Cartesian impedance control (providing to the controlled manipulator a compliant and decoupled behavior in the Carte-sian space), an MPC is designed in order to online optimize its parameters (i.e., setpoint and damping parameters) to assist the user along the detected intended motion direction(s), maximizing the collaboration performance. The MPC exploits a learned human-robot interaction dynamics model, obtained by means of an ensemble of neural networks. Therefore, the lack of sophisticated analytical models for the human-robot interaction dynamics is overcome, employing a method that is capable to capture the complexity and uncertainties of such a dynamics. An MPC objective function is designed in order to minimize the user’s effort during the collaboration with the robot. Indeed, the user’s intention of motion can be detected, making it possible to assist him/her along the intended direction(s) of motion. The designed MPC is also enhanced with stability guarantees by means of Lyapunov constraints. In such a way, safety/stability issues are tackled by the proposed methodology. The MPC is then (online) solved making use of a Q-Learning method, exploiting an actor-critic algorithm to approximate its exact solution. The obtained solution is accurate and highly efficient, being able to tackle the issue related to computation efficiency that might compromise the implementation of the controller for real applications.In the following Section, the state of the art related to the pHRC control is addressed, to highlight the open issues in the field and the solutions provided by the proposed approach.1.2. Related workAmong other strategies [11,12], physical human-robot collaboration (pHRC) is commonly enabled by implementing a low-level impedance controller [13], that provides the robot with a safe and compliant behavior, suitable for interacting with the surrounding environment (including human subjects [14]). The impedance control parameters (i.e., mass/inertia, stiffness, damping, and setpoint) are then tuned/adapted by means of high-level control strategies during the execution of a task [15], e.g., to achieve human-like adaptability skills [16,17], to maximize the human-robot collaboration performance [18], etc. Such high-level control strategies can be designed using the analytical models of the human-environment interaction [19]. However, the solutions realized through these methods are limited by the specific modeling adapted and the impossibility of the models to capture the complex interaction dynamics. Therefore, machine learning (ML)-based approaches have been investigated to implement flexible controllers. Two types of ML-based solutions are available in the state of the art: model-based ML approaches [20], and model-free ML approaches [21]. Model-based ML approaches provide powerful algorithms for control tuning purposes that are capable of capturing the complex and uncertain interaction dynamics. The main drawback of such strategies consists in the limited variation of task conditions that can be faced by the proposed controllers. In order to be effective, the adopted models should accurately represent the target scenario, losing generalizability [22]. Model-free approaches, on the other hand, allow to achieve acceptable results in a wide set of scenarios by exploiting an autonomous tuning through trial-and-error. However, the tuning procedures are costly (both in terms of the computational resources and the time), requiring a vast amount of trails to achieve the target performance [4].Many efforts are, therefore, put into the development of combined solutions exploiting the advantages of both model-based and model-free ML solutions. In [23] is implemented a systematic approach to optimize the gains of an admittance controller online, without any prior knowledge of the target position or other task characteristics. A fuzzy Q-Learning algo-rithm is used to regulate damping so that the robot trajectory approaches the minimum jerk and the cooperation becomes more effective. The partitioning of the robot state with fuzzy sets is an efficient method to deal with the curse of dimen-sionality of continuous space. However, it requires a number of parameters to be manually tuned and it works selecting a deterministic action from a small set using fuzzy Q values to obtain a quicker convergence. According to [24], restricting the search for optimal action to the agent’s action set or a restricted set of Q values, it is a myopic idea. Herein, their",
            {
                "entities": [
                    [
                        135,
                        234,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1346–1365Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSequential decision making with partially ordered preferences ✩Daniel Kikuti, Fabio Gagliardi Cozman∗, Ricardo Shirota FilhoEscola Politécnica, Universidade de São Paulo, Av. Prof. Mello Moraes, 2231 São Paulo, SP, Brazila r t i c l ei n f oa b s t r a c tThis paper presents new insights and novel algorithms for strategy selection in sequentialdecision making with partially ordered preferences;is, where some strategiesmay be incomparable with respect to expected utility. We assume that incomparabilityamongst strategies is caused by indeterminacy/imprecision in probability values. Weinvestigate six criteria for consequentialist strategy selection: Γ -Maximin, Γ -Maximax,Γ -Maximix, Interval Dominance, Maximality and E-admissibility. We focus on the populardecision tree and influence diagram representations. Algorithms resort to linear/multilinearprogramming; we describe implementation and experiments.that© 2010 Elsevier B.V. All rights reserved.Article history:Received 28 February 2009Received in revised form 11 August 2010Accepted 11 August 2010Available online 2 December 2010Keywords:Sequential decision making underuncertaintyPartially ordered preferencesSets of probability measuresCriteria of choiceConsequentialist and resolute normsLinear and multilinear programming1. IntroductionIt is often possible, in a decision problem, to express preferences that are completely ordered; that is, for every twoalternatives, the decision maker either prefers one to the other, or is indifferent between them. In fact, expected utilitytheory is based on the assumption that revealed preferences are completely ordered. However, preferences are often partiallyordered; examples can be found in the theory of CP-nets and the theory of nondeterministic planning, as briefly discussedin Section 2. When preferences are partially ordered, two alternatives may be incomparable and incomparability may fail tobe transitive.In this paper we focus on preferences that can be represented by a single utility function and a set of probabilitymeasures. Whenever there are incomplete or partial beliefs, or disagreements amongst experts concerning chances, onemay fail to assign a precise probability value to every event, thus producing a partial order with respect to expected utility[3,46,73]. This is the situation we wish to focus on. Section 2 contains the necessary background on these topics.The literature describes many criteria of choice when preferences are partially ordered [71]. These criteria are coveredin Section 3 and can be roughly divided into two groups: (1) criteria that enforce a complete ordering amongst choices(Γ -Maximin, Γ -Maximax and Γ -Maximix); and (2) criteria that select a set of incomparable actions (Interval Dominance,Maximality and E-admissibility). Practical approaches to decision making with sets of probabilities have been mainly limitedto the first category; however, recent discussions [60] have highlighted theoretical and behavioral problems when usingthis group of criteria, and the second group of criteria has been advocated as a more adequate approach. Nevertheless,incomparability comes at a cost, and very little has been observed in the literature in terms of algorithmic progress, mainlydue to computational complexity and inability to deal with incomparable choices.✩This work has been financially supported by FAPESP, grants 2003/11165-9, 2004/09568-0, 2005/58090-9, 2008/03995-5.* Corresponding author.E-mail addresses: danielkikuti@yahoo.com.br (D. Kikuti), fgcozman@usp.br (F.G. Cozman), ricardo.shirota@poli.usp.br (R.S. Filho).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.017\fD. Kikuti et al. / Artificial Intelligence 175 (2011) 1346–13651347There are also distinct behavioral norms when it comes to sequential decision making with partially ordered preferences;that is, whenever a sequence of decisions must be made. For instance, a decision maker may be resolute in that she commitsherself to a complete strategy once and for all, or consequentialist in that she allows herself to change the current strategyin case another one is appropriate in view of the future possible choices.The interplay between criteria of choice, behavioral norms, and models such as decision trees and influence diagramshas not been explored in the literature; this paper aims at filling this gap to some extent. There are indeed insights to belearned from an organized discussion of criteria of choice and behavioral norms; for instance, we discuss in Section 5 thefact that the standard LIMID model clashes with a consequentialist stance.Another, more substantial, contribution of the paper is the development of algorithms for consequentialist sequentialdecision making expressed through decision trees [56] and influence diagrams [34]. Algorithms for decision making underΓ -Maximin and similar criteria have appeared in many settings [58,69,74], while algorithms for decision making underMaximality and E-admissibility have been suggested by Kyburg and Pittarelli [43] and proposed more recently by Kikutiet al. [42] and Utkin and Augustin [72].1 Section 3 presents algorithms and computational analysis for several criteria ofchoice. The most valuable contribution of Section 3 is the algorithm for E-admissibility. We also present a new algorithmfor strategy selection using linear programming in a family of decision trees where partial preferences have considerableregularity.Sections 4 and 5 respectively present algorithms for decision making in problems specified through decision trees andinfluence diagrams. We should note the scarcity of previous literature on influence diagrams under partially ordered prefer-ences, perhaps due to the fact that several criteria of choice require the manipulation of an exponential number of strategies.To reduce this complexity, we examine “ordered” LIMIDs, and we analyze both their conceptual foundation (in particulartheir clash with consequentialism) and their computational properties.In short, we present novel results and algorithms for sequential decision making with decision trees and influencediagrams, plus new insights for single-stage decision making under Interval Dominance and E-admissibility. The broadergoal of the paper is to combine both the philosophical underpinnings and the computational properties of partially orderedpreferences, a combination we feel is missing in the current literature.2. Partially ordered preferences, behavioral norms, and credal setsThroughout, our decision makers must select one or more actions within a finite set of possible alternatives A ={a1, . . . , am}. Performing action a yields a reward a(ω) for each state of nature ω; the set of states of nature is assumed tobe a finite set Ω = {ω1, . . . , ωn}. We assume that a(ω) is a real number expressed in utiles. Even though some theories ofpreference allow multiple utilities to be defined for a single decision problem [2], in this paper we assume that utilities areprecisely fixed in a given decision problem, and consequently every action is identified with a single real-valued functionover the states of nature. Note that a utility function is a function that returns a value in utiles for each possible outcome;so we are assuming that a single utility function is fixed.The connection between preference and expected utility, in decision making under risk [47], is based on the axiomati-zation of preference relations. Denote the strict preference of ai over a j by ai (cid:3) a j , and define indifference between twoactions as ai ∼ a j ⇔ ¬(ai (cid:3) a j) ∧ ¬(a j (cid:3) ai). Suppose (cid:3) satisfies (recall that actions are functions that can be multiplied andadded) [23]:Axiom 1 (completeness). The relation (cid:3) is complete and negatively transitive (recall that (cid:3) is negatively transitive if itsatisfies for all ai , a j , ak: (ai (cid:2) a j) ∧ (a j (cid:2) ak) ⇒ (ai (cid:2) ak)).Axiom 2 (independence). For α ∈ (0, 1], ai (cid:3) a j ⇒ αai + (1 − α)ak (cid:3) αa j + (1 − α)ak (this axiom says that whenever ai (cid:3) a j ,a compound action made of ai and ak will be preferred to a compound action made of a j and ak, where α denotes the ratioof mixture between the actions).Axiom 3 (continuity). If ai (cid:3) a j (cid:3) ak, then there exists α, β ∈ (0, 1) such that αai + (1 − α)ak (cid:3) a j (cid:3) βai + (1 − β)ak.Then there must exist a single probability measure P and a related expected utility representation for (cid:3); that is, thevalue of an action ai is given by E[ai] =j=1 P (ω j)ai(ω j), and ai (cid:3) a j if and only if E[ai] > E[a j].(cid:2)nSeveral theories relax these axioms, attempting to accommodate various observed decision making patterns [1,20,40]. Forinstance, lexicographic preferences violate Axiom 3 and are encoded through expected utility vectors, ordered with respectto a lexicographic hierarchy [5,23]. Other theories violate Axiom 2 and lead to non-additive functionals that representpreferences [49, Section 2.3]. Partially ordered preferences violate Axiom 1 by assuming that preferences are not completelyordered; this is exactly the situation we examine in the present paper. If we assume a single utility function and doif and only if E P [ai] > E P [a j] for all P innot require the preference relation (cid:3) to be complete, we have that ai (cid:3) a j1 Most results are based on material presented in Kikuti et al. [42] and Kikuti and Cozman [41]. The third author participated in developing the columngeneration method, and the experiments, reported in Section 4.3.\f1348D. Kikuti et al. / Artificial Intelligence 175 (2011) 1346–1365Fig. 1. A sequential decision problem represented through a decision tree.a set of probability measures [26,61,62]. That is, the preference relation (cid:3) can be completely represented by a set",
            {
                "entities": [
                    [
                        138,
                        199,
                        "TITLE"
                    ],
                    [
                        3957,
                        4018,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1317–1359www.elsevier.com/locate/artintRedundancy in logic III: Non-monotonic reasoningPaolo LiberatoreUniversità di Roma “La Sapienza”, Dipartimento di Informatica e Sistemistica, Via Ariosto 25, I-00185 Roma, ItalyReceived 14 October 2005; received in revised form 15 February 2008; accepted 18 February 2008Available online 4 March 2008AbstractResults about the redundancy of certain versions of circumscription and default logic are presented. In particular, propositionalcircumscription where all variables are minimized and skeptical default logics are considered. This restricted version of circum-scription is shown to have the unitary redundancy property: a CNF formula is redundant (it is equivalent to one of its proper subsets)if and only if it contains a redundant clause (it is equivalent to itself minus one clause); default logic does not have this property ingeneral. We also give the complexity of checking redundancy in the considered formalisms.© 2008 Elsevier B.V. All rights reserved.Keywords: Logical redundancy; Non-monotonic reasoning; Computational complexity; Circumscription; Default logic1. IntroductionIn this paper, we study the problem whether a circumscriptive [36] or default [44] theory is redundant, that is, itcontains unnecessary parts. Formally, a theory is redundant if it is equivalent to one of its proper subsets; a part isredundant in a theory if the theory is not semantically changed by the removal of the part. The problem of redundancyin other settings has been extensively analyzed in the literature. The complexity of establishing whether a CNF, 2CNF,and Horn formula is redundant has been studied by the author of the present article [26,30], who also analyzed someproblems related to irredundant equivalent subsets of formulae. These problems are all considered in the settings ofclassical propositional logic.The related problem of minimizing a propositional theory, in particular when in Horn form, has been analyzedby several authors [1,22,23,34,37,52]. Minimization is significantly different from redundancy: a formula is minimalif there is no shorter formula that is equivalent to it. Minimal formulae are also irredundant, but not the other wayaround: a formula may be irredundant because no part can be removed from it, but still a completely different formulais both shorter than it and equivalent to it. For example, {a ∨ b, a ∨ ¬b} is irredundant (because none of the twoclauses can be removed from it while maintaining equivalence with the original set) but is not minimal (because it isequivalent to the shorter set {a}). There are motivations for studying both minimization and redundancy. Minimizationproduces the shortest possible formula equivalent to a given one, and this has obvious advantages; making a formulairredundant may not produce a formula as short as the minimal ones, but has the additional advantage of not changingthe structure of the original formula, but only to remove parts from it.E-mail address: paolo@liberatore.org.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.02.003\f1318P. Liberatore / Artificial Intelligence 172 (2008) 1317–1359A related problem is that of studying the properties of formulae that are already known to be irredundant. Büningand Zhao [7] studied the problems of equivalence and extension-equivalence of irredundant formulae. Also related isthe problem of minimal unsatisfiability, that is, checking whether an unsatisfiable formula would become satisfiableas soon as a clause is removed from it [5,14,43].Other authors have studied redundancy in settings different from that in this article. Ginsberg [18] and Schmolzeand Snyder [48] studied the redundancy of production rules. Gottlob and Fermüller [17] studied the redundancy of aliteral within a clause in first-order logic.The settings considered in this article are those of circumscription and default logic, which are two of the most stud-ied [2,4,6,10,13,29,31,36,38,44] forms of non-monotonic reasoning, as opposite to classical logic, which is monotonic.A logic is monotonic if the consequences of a set of formulae monotonically non-decrease with the set. In other words,all formulae that are entailed by a set are also entailed by every superset of it. Circumscription and default logic do nothave this property, and are therefore non-monotonic. For circumscription, we assume that all variables are minimized;the rationale for this restriction is that fixed and varying variables can be efficiently eliminated [8,9], which showsthat the minimized variables are the “core” of the circumscription formalism. Other authors have indeed consideredcircumscription only under this restriction [6,25,40]. This shows that this restriction of circumscription is of inter-est; however, results about redundancy in this case do not necessarily extend to the general case, as discussed in theconclusions.For default logic, there are several semantics; for most of them, one can choose between the “credulous” and“skeptical” approach. In this article, we consider the skeptical approach under the original semantics [44] and threesimilar ones: justified [33], constrained [11,46], and rational [39]. We however also consider the case in which weassume that the semantics of a theory is the set of its extensions, without combining these extensions in a skepticalmanner. The results obtained in this case hold for the credulous approach under the original semantics (where nototherwise stated, the skeptical approach is assumed). The properties of redundancy in the credulous approach underthe other semantics is left open. Since redundancy is defined in terms of equivalence (namely, equivalence of a formulato a proper subset of it), it is affected by the kind of equivalence used. In particular, equivalence can be defined in twoways for default logic: equality of extensions and equality of consequences. This leads to two different definitions ofredundancy in default logic.Both circumscription and default logic differ from classical propositional logic. This difference affects redundancy.If a CNF formula contains a redundant clause, it is redundant (equivalent to one of its proper subsets); the converse istrue in propositional logic, but not in all logics. In particular, it may be the case that a formula is equivalent to one ofits proper subsets, but none of its clauses is redundant. We will indeed show a situation in default logic where {a, b}is equivalent to ∅ but neither to {a} nor to {b}, which means that {a, b} is redundant but does not contain any singleredundant element.The property that a formula is redundant if and only if it contains a redundant clause is called unitary redundancy.Classical logic has this property; other logics, like default logic, do not. We show three different sufficient conditionsfor this property to hold in a logic; one of them involves monotonicity, another involves cumulativity [35]. A propertythat entails unitary redundancy is that of monotonic redundancy: if (cid:2)(cid:4) ⊆ (cid:2)(cid:4)(cid:4) ⊆ (cid:2) and (cid:2)(cid:4) and (cid:2) are equivalent then(cid:2)(cid:4)(cid:4) and (cid:2) are equivalent as well. This is the property for which the sufficient conditions are actually proved; unitaryredundancy follows.Regarding the specific non-monotonic formalisms considered here, we show that monotonic redundancy, and there-fore unitary redundancy, holds for circumscription and for the redundancy of the background theory in default logicwhen all defaults are categorical (prerequisite-free) and normal. In the general case, default logic does not have theunitary redundancy property (and therefore does not have the monotonic redundancy property either). We also consid-ered the redundancy of defaults in a default theory. In this case, monotonic and unitary redundancy hold for justifieddefault logic but not for the other three considered semantics.Regarding the complexity results, we show that checking whether a clause is redundant in a formula and whether aformula is redundant according to circumscriptive inference are (cid:2)p2 -complete problems. For default logic, the resultsare as follows. Checking redundancy, based on extensions, of a clause in the background theory is (cid:2)p2 -complete forReiter and justified default logics, and (cid:2)p3 -complete for constrained and rational default logic; checking redundancybased on skeptical consequences is (cid:2)p3 -complete for all four semantics. Checking redundancy of a background theoryis (cid:3)p4 -complete, respectively, for equivalence based on extensions and skeptical consequences. Theproofs of the latter two results are of some interest by themselves, as they are done by first showing that the problems3 -complete and (cid:3)p\fP. Liberatore / Artificial Intelligence 172 (2008) 1317–135913192 -complete and (cid:2)pare (cid:2)p3 -complete, respectively, and then showing that such complexity results can be raised onelevel in the polynomial hierarchy. This technique allows for a proof of hardness for a class such as (cid:3)p4 withoutinvolving complicated QBFs such as ∃W ∀X∃Y ∀Z.F . Regarding the credulous approach, we prove that equality ofextensions and equality of credulous consequences coincide for the Reiter default logic, but not for the other threeconsidered semantics. Regarding the redundancy of defaults, we only considered Reiter default logic with equivalencebased on equality of extensions; we proved that the redundancy of a default is (cid:2)p2 -complete and the redundancy of aset of defaults is (cid:3)p3 -complete in this case.For the sake of clarity, long proofs and very technical parts are in the appendix.2. PreliminariesIf (cid:2) and (cid:4) are sets, (cid:2)\\(cid:4) denotes the set of elements that are in (cid:2) but not in (cid:4). This operator is often calledset subtraction because the elements of (cid:4) are “subtracted” from (cid:2). An alternative definition of this ",
            {
                "entities": [
                    [
                        74,
                        122,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 101 (1998) 201-226 Artificial Intelligence What robots can do: robot programs and effective achievability Fangzhen Lin a,*, Hector J. Levesque b, ’ ’ Department of Computer Science, The Hong Kong University of Science and Technology, Hong Kong b Department of Computer Science, University of Toronto, Toronto, Canada M5S 3H5 Received 14 May 1997; received in revised form 19 March 1998 Abstract result of the paper is a proof that a simple robot programming In this paper, we propose a definition of goal achievability: given a basic action theory describing an initial state of the world and some primitive actions available to a robot, including some actions information, what goals can be achieved by the robot? The main which return binary sensing technical in that any effectively achievable goal can be achieved by getting the robot to execute one of the robot programs. The significance of this result is at least twofold. First, it is in many ways similar to to robots the equivalence whose actions are specified by an action theory. Secondly, for using for our work on robotics. 0 1998 Elsevier the simple robot programming Science B.V. All rights reserved. functions, but applied it provides formal justifications theorem between Turing machines and recursive language as a foundation is universal, language Kqword.sc Robotics; Cognitive Theories of actions; Situation calculus robotics; Robot programs; Achievability; Effective achievability; Abilities; 1. Introduction Imagine that in the not too distant future, you are given a robot of some sort, and that you want to figure out what it can do. Browsing through the manual that came with it, you discover primitive that actions the robot al, is capable . . , a,. According of performing any of a set of to the manual, what each action ai actually does under computer control depends on the state of the environment. First, to complete successfully, a precondition * Corresponding ’ Email: hector@ai.toronto.edu. author. Email: flin@cs.ust.hk. 0004.3702/98/$19.00 PII: SOOO4-3702(98)0004 I - I 0 1998 Elsevier Science B.V. All rights reserved. \f202 E: Lin, H.J. Levesque /ArtiJicial Intelligence I01 (1998) 201-226 of the action must hold in the environment. Next, assuming its effect on the environment may also depend on certain other conditions. Finally, some of to sensors and can return a binary value indicating when a certain the actions are connected to do some programming, what condition holds. The question do we expect to be able to achieve with the robot? is: assuming we are willing is successful, the action In this paper, we propose an answer to this question. Specifically, we propose an abstract of what goals are effectively achievable as a function of a given logical to the framework where questions the initial state of the world and the primitive actions available characterization theory describing robot. The main contribution of the paper is a precise technical of goal achievability the universality of the simple robot programming out that a goal is effectively achievable according program result is a proof of can be posed and answered. The main technical introduced in [7]: it will turn theory T iff there is a robot that achieves it according language to logical to T. 1.1. A motivating example To make the problem more concrete, that you are also given a solid steel box imagine that contains a treasure. There is a small robot-sized door on the box, which is currently closed, and there are two buttons beside it, a green one and a red one. The primitive actions to the robot are pressGreen, pressRed, and fetch. The manual says that if the robot available to be pressed, to be beside happens andpressRed similarly. The manual also says that the robot has a heat sensor so that a press action returns 1 when the button pressed was hot, and 0 otherwise. Thefetch action causes that the robot is the robot to trundle is beside getting the treasure, under assumptions the door and the door is open. 2 The goal we are interested the closed door, pressGreen causes the green button the box and retrieve what’s inside, provided in here, obviously, inside (1) (2) (3) the treasure by forcing the robot to press the buttons like the following: If we know nothing else about the environment, we want our account of achievability that we cannot achieve the goal. Of course, we might end up eventually to predict the door open with a crowbar, or by saying some getting magic words, or even by getting in some order. But there is no reason to believe a priori that any of these methods will work. If we know that the red button opens the door of the box, we want our account of the robot: we get it to do achievability the sequence pressRed, the door might jam, lightning might strike the robot, a comet might hit the earth. But there is no reason to believe If we know that one of the buttons opens the door of the box, and the other button locks the door permanently, but we don’t know which is which, our account should predict the robot. As in (2), we know that there is a sequence of actions but here we do not know what that sequence the goal using then fetch. Of course, something might go wrong: that the sequence will fail given what we have been told. the goal using that will work-press to say that we can achieve that we cannot achieve one of the buttons thenfetch- is. ’ In a more realistic setting, of course, there would be a large number of other preconditions for actions like these. \fE Lin, H.J. Levesque /Art@ial Intelligence 101 (1998) 201-226 203 the following situation: we know that the door can be opened by first (4) But consider the green button, and then pressing one more button, but we are not told pressing it wrong locks the door permanently. However, suppose which, and again, getting that felt that we know that the safe will lock forever iff the robot pushes a button hot on the previous press. As in (3), we know that there is a sequence of actions that will work, and again we cannot say what that sequence is. This time, however, our account should predict that we can achieve the goal: we get the robot to pressGreen, and then pressGreen once more if the button was cold, but pressRed if it was hot. (5) Finally, that after pressing suppose we know the green button some unspecified the red button will open the door and number of times and at least once, pressing the green one will lock it forever. With no other information, we clearly pressing cannot obtain if we also know as in (4) that the door will lock forever iff the robot presses a button that was just hot, then we can once again achieve the goal: we get the robot to repeatedly press the green button until it feels hot, then press the red one to open the door, and then fetch the treasure. the treasure. However, To the best of our knowledge, intuitively correct answers for examples like these. there is as yet no formal framework that would give the 1.2. Relation to other work There are, however, three areas of research that come close to providing these answers. related as in [2,13,19,23]. to the concept of planning As the five examples above illustrate, Planning. a robot is clearly conditional planning, that the treasure was obtainable precisely when we could formulate obtain it. Why then not simply define goal achievability the idea of a goal being achievable by the sensing, and especially, given In all of the variants above, we ended up saying some sort of plan to in terms of the existence of a plan? exactly what we mean by a plan. An The problem with this involves characterizing is sufficient. But in some of the variants obvious case is when a fixed sequence of actions and iterative plans, which suggests a structure above, we needed in a traditional these would not be programs more like that of a program language like C or LISP. For one thing, the primitive statements of the program would have to involve the actions ai, rather than the usual variable assignment or read/write statements. statement? How What would we use as the conditions should the execution of programs containing in an if-then-else or a while-loop to consider conditional the ai be defined? [14]. Clearly We believe achievability design decisions first define achievability language programming in terms of such programs that these questions can be resolved and that it is possible to characterize (see Section 4 below) . However, to avoid making to that a to be arbitrary or restrictive, we prefer way, and then prove initially appear in a general program-independent that might is adequate according to this definition. A second concept related to achievability Computability. ity [ 161. As will become clear, we will end up defining achievable goals as those where what to do next to achieve them, given what is known about the actions and the initial state of the world, can be “computed” as a function of what the sensors tell the robot. is that of effective computabil- \f204 E LitI, H.J. Levesque /Arti$cial Intelligence 101 (1998) 201-226 information to typical accounts of computability, for two reasons. the surrounding However, we cannot simply use an existing account of computability about the environment First, we want to allow for incomplete robot. In contrast the need only be partially specified by a collection of axioms. The second reason concerns primitive actions. In typical computability models, the available actions are predefined and internal to write and to the machine registers, or to assign values read a Turing machine to variables, and so on. In our case, by contrast, the primitive actions for a robot are not outside of the predefined robot. These actions are also described by a collection of axioms, which specify the action preconditions (or formalism). For instance, we might have actions tape, or to increment and are e_xternal, in that they have effects in the environment and effects, and deal with the frame problem. the initial state of the environ",
            {
                "entities": [
                    [
                        67,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 1–14Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFixing balanced knockout and double elimination tournaments ✩Haris Aziz a,∗Paul Stursberg d, Toby Walsh aa Data61, CSIRO and UNSW Sydney, Australiab Carnegie Mellon University, USAc IBM Research, USAd Technische Universität München, Germany, Serge Gaspers a, Simon Mackenzie b, Nicholas Mattei c, a r t i c l e i n f oa b s t r a c tArticle history:Received 9 February 2017Received in revised form 24 April 2018Accepted 19 May 2018Available online 25 May 2018Keywords:Knockout tournamentsSeedings of a tournamentComputational complexityBalanced knockout tournaments are one of the most common formats for sports competi-tions, and are also used in elections and decision-making. We consider the computational problem of finding the optimal draw for a particular player in such a tournament. The problem has generated considerable research within AI in recent years. We prove that checking whether there exists a draw in which a player wins is NP-complete, thereby settling an outstanding open problem. Our main result has a number of interesting implications on related counting and approximation problems. We present a memoization-based algorithm for the problem that is faster than previous approaches. Moreover, we highlight two natural cases that can be solved in polynomial time. All of our results also hold for the more general problem of counting the number of draws in which a given player is the winner. Finally, we show that our main NP-completeness result extends to a variant of balanced knockout tournaments called double-elimination tournaments.© 2018 Elsevier B.V. All rights reserved.1. IntroductionBalanced knockout tournaments are one of the most widely-used formats for sports competitions [7,10,13]. A prominent example is the Wimbledon Men’s Singles tennis tournament in which 128 players enter the tournament and the player who wins seven consecutive matches right from the first round to the final wins the tournament. The format is also used in certain elimination style election and decision making schemes and has received considerable interest in the field of artificial intelligence [12,16,17,23,34,36,37,27,1] as well as social sciences [5,21,22,25,33]. Knockout tournaments which are balanced are of particular interest, as they are considered to be fair [20] and allow a large number of matches to be played in parallel.Consider the setting in which there is a set of players N = [n] (we use the notation [n] := {1, . . . , n}) where n = 2c for some integer c.1 Given N, an ordered balanced knockout tournament T(N, π ) is defined as a balanced binary tree with nThis is a revised and expanded version of Aziz et al. [3] with additional proof details as well as new results for tournaments with kings and double ✩elimination tournaments.* Corresponding author.N.Mattei@ibm.com (N. Mattei), paul.stursberg@ma.tum.de (P. Stursberg), toby.walsh@data61.csiro.au (T. Walsh).1 The setting is general enough to cover the case where some players get byes in the first round. In that case we can consider a dummy player who always loses to the player who gets a bye.E-mail addresses: haris.aziz@unsw.edu.au (H. Aziz), serge.gaspers@data61.csiro.au (S. Gaspers), simonm@andrew.cmu.edu (S. Mackenzie), https://doi.org/10.1016/j.artint.2018.05.0020004-3702/© 2018 Elsevier B.V. All rights reserved.\f2H. Aziz et al. / Artificial Intelligence 262 (2018) 1–14leaf nodes where the seeding π specifies the labeling of the leaf nodes with respect to N. All ordered balanced knockout tournaments that are isomorphic to each other (with respect to the labeling of the leaf nodes) are said to have the same draw. They are represented by a single (unordered) balanced knockout tournament (BKT) T(N, σ ) where σ denotes the draw. The set of all draws is denoted by (cid:4). Whereas the total number of seedings is n!, the number of draws is n!2n−1 as all pairwise matchups in the leaf nodes are the same if adjacent elements of the seeding are swapped, but even this grows very rapidly. For a tournament like Wimbledon, n = 128 and the number of distinct draws is ≈ 2.2665 · 10177. This is significantly more than the number of atoms in the universe, or even a googol.A BKT T(N, σ ) is conducted in the following fashion. Players that correspond to sibling leaf nodes play a match against each other. The winner of the match proceeds up the tree to the next round. The winner of T(N, σ ) is the player who reaches the root node. We are given a pairwise comparison matrix P such that P i j ∈ [0, 1] denotes the probability of player i beating player j in a pairwise elimination match and 0 ≤ P i j = 1 − P ji ≤ 1. We call P deterministic if P i j ∈ {0, 1} for all players i, j ∈ N. In this case, we say that player i beats player j if P i j = 1. Given N, P and a draw σ , each player i ∈ N has a certain probability wp(i, N, P , σ ) of being the winner of T(N, σ ). This probability can be computed in time O (n2) via a recursive formulation [36]. We denote by mwp(i, N, P ) := maxσ ∈(cid:4)(wp(i, N, P , σ )) the maximum possible winning probability of i in T(N, σ ) taken over all draws σ ∈ (cid:4).We can now define the Probabilistic Tournament Fixing Problem (PTFP) in which the probability of each player beating another player is known and the goal is to find a draw that maximizes the probability of a certain player winning the BKT.Probabilistic Tournament Fixing Problem (PTFP)Instance: Player set N, pairwise comparison matrix P , a distinguished player iQuestion: Does there exist a draw σ for the player set N for which the probability of i∗∗ ∈ N, and target probability q ∈ [0, 1].winning T(N, σ ) is at least q?PTFP was proposed by Vu et al. [36] and has been studied in numerous papers (see e.g., [29–31]). It is a well-motivated problem in sports analytics [28]. PTFP has been shown to be NP-hard for various restrictions, including the case where the entries of P are restricted to {0, 12 , 1} [36] and the case where the matrix P is deterministic and certain matches are not allowed [34].Nevertheless, the computational complexity of a particularly natural and interesting special case, the Tournament Fixing Problem (TFP), has remained a major open question. In the TFP, the matrix P is deterministic and all matches are allowed. The winner of each match is deterministically known beforehand and the question is whether there exists a draw for which a given player wins in the corresponding BKT.Tournament Fixing Problem (TFP)Instance: Player set N, deterministic pairwise comparison matrix P , and a distinguished player iis the winner of T(N, σ )?Question: Does there exist a draw σ for the player set N for which i∗∗ ∈ N.TFP is equivalent to checking whether there exists a seeding π for which iis the winner of T(N, π ). We note that TFP is a special case of the problem with the same name as defined in Vassilevska Williams [34], where there can be additional constraints by which certain matches are disallowed. TFP is also a special case of #TFP — the problem of counting the number of draws for which a given player is the winner. This count can be used to compute the probability of a player winning in a draw chosen uniformly at random. It can also be interpreted as the relative strength of the player.∗Contributions We first settle the computational complexity of TFP by showing that it is NP-complete. The question was explicitly stated as an open problem a number of times [12,19,35,26,29–31,34,36,37]. As a corollary, we show that unless P = NP, there exists no polynomial-time approximation algorithm for computing the maximal winning probability of a player. This inapproximability result provides additional motivation for the line of work in which heuristic algorithms have been proposed for PTFP [37]. Another corollary is that there exists no fully polynomial time randomized approximation scheme(FPRAS) for counting the number of draws for which a player is the winner.In view of these intractability results, we identify two natural cases for which even #TFP (and hence also TFP) can be solved in polynomial time. In the first case, the players can be divided into a constant number of player types. This setting appeals to the scenario where players can be divided into groups based on similar intrinsic ability. In the second case, there is a linear ordering on the ability of players with a constant number of exceptions where a player with lower ability beats a player with higher ability.2 Finally, we provide an exact memoization-based algorithm to solve #TFP that is faster than known exact approaches to solve the problem: it runs in time O (2.8285n) and uses space O (1.7548n). If only polynomial space is available, the running time becomes 4n+o(n), and we give a range of possible time-space trade-offs.Finally, we consider double-elimination tournaments which are a variant of knockout tournaments in which the losers get a second chance to win the overall tournament. We show that TFP is NP-complete for this problem as well thereby answering another open problem [32].2 The condition is quite natural since in many competitions there is a clear-cut ranking of the players according to their skills with only a few pairs of players for which the weaker player can beat the stronger player. For example, as of 15/01/2014, Nikolay Davydenko was the only tennis player among the men’s top 64 who had a winning head-to-head record against Rafael Nadal. Russell and van Beek [26] as well as Mattei and Walsh [24] provide an extended discussion and empirical data on these phenomena.\fH. Aziz et al. / Artificial Intelligence 262 (2018) 1–143Related work After the work of Vu et al. [36], PTFP and TFP have been studied in a number of research papers. Vassilevska Williams [34] identified various sufficient conditions for a player to be a winner of a BKT, e.g. if he is a king who beats half of all players. I",
            {
                "entities": [
                    [
                        133,
                        192,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1195–1218www.elsevier.com/locate/artintThe measurement of ranks and the laws of iterated contractionMatthias Hild a, Wolfgang Spohn b,∗,1a Darden Graduate School of Business Administration, PO Box 6550, Charlottesville, VA 22906, USAb Department of Philosophy, University of Konstanz, 78457 Konstanz, GermanyReceived 2 February 2007; received in revised form 28 December 2007; accepted 14 March 2008Available online 20 March 2008AbstractRanking theory delivers an account of iterated contraction; each ranking function induces a specific iterated contraction behavior.The paper shows how to reconstruct a ranking function from its iterated contraction behavior uniquely up to multiplicative constantand thus how to measure ranks on a ratio scale. Thereby, it also shows how to completely axiomatize that behavior. The completeset of laws of iterated contraction it specifies amend the laws hitherto discussed in the literature.© 2008 Elsevier B.V. All rights reserved.Keywords: Ranking theory; Belief revision theory; Difference measurement; Contraction; Iterated contraction1. IntroductionRanking theory, as first presented in Spohn ([30, Section 5.3] and [31]) is well known to offer a complete modelof the dynamics of belief, i.e., it allows to state an arbitrarily iterable rule of belief change. By contrast, AGM beliefrevision theory, as summarized by Gärdenfors [13], founders at the problem of iterated belief change, as observed inSpohn ([30, Section 5.2] and [31, Section 3]), because it violates the principle of categorical matching, as Gärdenfors,Rott [14, p. 37] called it later on. Both theories agree, though, on single belief changes.There is a price to pay for the greater strength of ranking theory; it makes substantial use of numerical degreesof (dis-)belief. While one can well see how the dynamics of belief works on the basis of these degrees, one maywonder about the meaning of these degrees; they look arbitrary and seem to lack intuitive access (unlike subjectiveprobabilities, for instance). By contrast, AGM belief revision theory, in order to justify its revision postulates, onlyappeals to entrenchment orderings, an ordinal and intuitively well grasped notion.This difference does not weigh much for those interested in computing, but for the more philosophically minded—recall that both, AGM and ranking theorizing, originated in philosophy—there remains a problem. What do numericalranks mean? Where exactly is the difference between two numerically different, but ordinally equivalent rankingfunctions? Just in vague feelings concerning the strength of belief? This would certainly be a poor answer.* Corresponding author.E-mail addresses: matthias@hild.org (M. Hild), wolfgang.spohn@uni-konstanz.de (W. Spohn).1 We are indebted to three anonymous referees. Their extensive reviews helped improving this paper considerably.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.03.002\f1196M. Hild, W. Spohn / Artificial Intelligence 172 (2008) 1195–1218Is there really an objection? This is debatable. Historically, though, this kind of objection has played a most im-portant role. Cardinal utility became acceptable only after von Neumann, Morgenstern [34, Chapter 3] proved thatpreferences conforming to certain axioms determine cardinal utilities on an interval scale. Thus, the cardinal conceptturned out to be definable by, or reducible to, the ordinal concept; one cannot accept the one and reject the other.Ranks likewise are psychological magnitudes, and hence it appears legitimate, at least from an operationalistic pointof view, to demand a measurement theory for them, too.Perhaps, though, the concern is not operationalism, but rather logic. Customarily, any logical calculus is ennobledby a correctness and completeness, i.e., soundness theorem. There are calculi that live well without such a theorem.Still, we need not rehearse the historic examples for the tremendous insight delivered by such soundness theorems. Ifthe calculus looks sensible, if the semantics is intelligible, and if a soundness theorem proves them to be equivalent,then mutual support makes for a nearly unassailable theory.AGM belief revision theory has these virtues. Originally, it came in a logical disguise; its beginnings reach backto Gärdenfors’ [12] epistemic approach to the logic of counterfactuals. Its soundness theorem was that the revisionpostulates (K∗1–8) (cf. Alchourrón et al. [1, Sections 2+3], or Gärdenfors [13, Section 3.3]) and the contractionpostulates (K÷1–8) (cf. Alchourrón et al. [1, Sections 2+3], or Gärdenfors [13, Section 3.4]) were proved to beexactly those justified by an underlying entrenchment relation (cf. Alchourrón et al. [1, Section 4], or Gärdenfors [13,Chapter 4]). Indeed, many of those proposing postulates for iterated belief change also offered a model relative towhich the postulates are correct and complete. By contrast, ranking theory did not offer a comparable result, thusgiving rise to the impression that ranks are somehow arbitrary.The aim of this paper is to show that ranking theory, despite its greater strength, can meet these concerns. It willpresent a rigorous measurement of ranks on a ratio scale in terms of iterated contractions, thus fully satisfying whateveroperationalistic requirements one tends to impose. So, when Rott [28] emphasizes in his concluding Section 15 that hehas made “it fully clear that no numbers are needed for any of the belief change methods considered”, we think this issimply a false opposition; the appropriate method of belief change automatically guarantees the numbers. Moreover,the paper will specify a complete set of laws of iterated contraction, something much desired in its own right and in thepresent context comparable to a soundness theorem in logic. The connection will, of course, be that the measurementresult is in effect the proof of the completeness of the laws proposed.The basic idea of this paper is quite simple. It is to exploit iterated contractions for getting information about thecomparative size of rank differences. If the iterated contractions behave appropriately, these rank difference compar-isons will behave appropriately, too, i.e., such that the theory of difference measurement as propounded in Krantz etal. [21, Chapter 4] applies. It requires some skill, though, to find an elaboration of this guiding idea that is intuitivelyilluminating as well as formally sound.The plan of the paper is straightforward. In Section 2 we shall briefly introduce ranking theory as far as neededin the rest of the paper. In Section 3 we shall equally briefly introduce the required basics of the theory of differencemeasurement. Section 4 works up to the announced measurement result. Section 5 then states the complete laws ofiterated contraction entailed by this result and gives a comparative discussion of them, in order to explain their contentas well as how far they go beyond the present discussion of iterated contraction. Section 6, finally, proves that themeasurement theory indeed entails these laws. A conclusion will round up the paper.A few words about the history of this paper: Its core ideas are already found in Hild [18], a rough first draft thatremained unpublished; in particular the present Sections 5 and 6 were already far developed there. The other authorindependently had the same ideas, less well and less completely realized in Spohn [32], a mere internet publication.Somehow, it took us a long time to start elaborating these ideas in full detail. To our knowledge, the present paper isthe first mature presentation of the issue.2. A brief sketch of ranking theoryRanking theory assumes propositions to be the objects of belief, and not sentences or sentence-like representa-tions. This is an important and debatable decision right at the beginning of all epistemological theorizing. As thingspresently stand, it is at the same time a decision between being able and not being able to pursue a substantial way ofepistemological theorizing. AGM belief revision theory only apparently proceeds in a different way. It takes sentencesand sets of sentences as being in the domain of their belief change operators. At the same time it postulates so-called“extensionality” axioms stating that logically equivalent sentences show exactly the same behavior (are members of\fM. Hild, W. Spohn / Artificial Intelligence 172 (2008) 1195–12181197the same belief sets, produce the same revision results, etc.). So, it differs only superficially. Then, however, it alwaysseemed to us easier to deal with identical propositions than with logically equivalent sentences (even though the morecomplicated way has become standard in the literature).Anyway, let us simply stick to propositions without further discussion. Let W be a set of possibilities, e.g., possibleworlds, centered worlds, or small worlds, or what have you, and let A be any Boolean algebra of subsets of W ; theelements of A are called propositions. Only in Section 4 we shall require some further assumptions about the richnessof the Boolean algebra considered.The core notion of ranking theory is this:Definition 2.1. κ is a negative ranking function for A iff κ is a function from A into R+ = R ∪ {∞} such that for allA, B ∈ A:(a) κ(A) (cid:2) 0, κ(W ) = 0, and κ(∅) = ∞,(b) κ(A ∪ B) = min{κ(A), κ(B)}[the law of disjunction (for negative ranks)].Spohn [30,31] originally referred to such functions as ordinal conditional functions. Since Goldszmidt, Pearl [15],they were mostly called ranking functions. We have now added the adjective “negative”. The reason is their standardinterpretation: negative ranks (that are non-negative numbers) are degrees of disbelief. Thus, κ(A) = 0 says that A isnot disbelieved at all according to κ; κ(A) > 0 says that A is disbelieved, and the stronger the larger κ(A). Hence,¯A is disbelieved to some degree, i.e., iff κ( ¯A) > 0. So, the axioms (2.1a) and (2.1b) s",
            {
                "entities": [
                    [
                        74,
                        135,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 104–144Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCoherence graphsEnrique Miranda a,∗, Marco Zaffalon ba Rey Juan Carlos University, Department of Statistics and Operations Research, C-Tulipán, s/n, 28933 Móstoles, Spainb IDSIA, Galleria 2, CH-6928 Manno (Lugano), Switzerlanda r t i c l ei n f oa b s t r a c tArticle history:Received 23 April 2008Received in revised form 14 August 2008Accepted 4 September 2008Available online 11 September 2008Keywords:Walley’s strong and weak coherenceCoherent lower previsionsGraphical modelsProbabilistic logicSatisfiabilityWe study the consistency of a number of probability distributions, which are allowed to beimprecise. To make the treatment as general as possible, we represent those probabilisticassessments as a collection of conditional lower previsions. The problem then becomesproving Walley’s (strong) coherence of the assessments. In order to maintain generalityin the analysis, we assume to be given nearly no information about the numbers thatmake up the lower previsions in the collection. Under this condition, we investigatethe extent to which the above global task can be decomposed into simpler and morelocal ones. This is done by introducing a graphical representation of the conditionallower previsions that we call the coherence graph: we show that the coherence graphallows one to isolate some subsets of the collection whose coherence is sufficient for thecoherence of all the assessments; and we provide a polynomial-time algorithm that findsthe subsets efficiently. We show some of the implications of our results by focusing onthree models and problems: Bayesian and credal networks, of which we prove coherence;for which we provide an optimal graphical decomposition;the compatibility problem,probabilistic satisfiability, of which we show that some intractable instances can insteadbe solved efficiently by exploiting coherence graphs.© 2008 Elsevier B.V. All rights reserved.1. IntroductionWe focus on studying the consistency of a number of conditional and unconditional distributions of some variables.In order to make our treatment as general as possible, we are going to represent these probabilistic assessments usingthe theory of coherent lower previsions developed by Walley in [33], which is based on de Finetti’s work about subjectiveprobability [10,11]. This allows us to study the case where the above distributions are imprecise, i.e., where each of themis actually a closed convex set of precise distributions, which includes as a particular case that where our assessments areprecise probabilities. It also allows us to work with any type of variable, without placing restrictions on the admissiblepossibility spaces (finite, countable, continuous). The approach by Walley includes also as particular cases most of the otherimprecise probability models appearing in the literature.Studying the consistency problem is important both for theoretical and applied reasons. On the theoretical side, it hasbeen shown by de Finetti that a subjective theory of precise probability (such as the Bayesian theory) can be founded ona single axiom of consistency. Williams [35] and later Walley have shown that this continues to hold when such a theoryis generalised to handle imprecision in probability. In these theories proving consistency is therefore a necessary step toexploit all the tools they provide us with, such as Bayes’ rule and its generalisations. The application of these tools alone,* Corresponding author.E-mail addresses: enrique.miranda@urjc.es (E. Miranda), zaffalon@idsia.ch (M. Zaffalon).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.09.001\fE. Miranda, M. Zaffalon / Artificial Intelligence 173 (2009) 104–144105on the other hand, does not necessarily lead to self-consistent inference, even in the case of precise probabilities, as shownby Walley.On the applied side, it is a very common requirement that an inference method should not give rise to inconsistencies.This requirement is present, for example, in probabilistic logic [26], where one has to check first of all that the availableassessments are self-consistent. It is also present in the many other models and methods designed so as to give rise toa joint distribution, which is often regarded as a feature that ensures global consistency. Exactly this argument was used,for example, to support Bayesian networks versus rule-based systems already at the time of Pearl’s seminal work [27]. Butconsistency is quite a subtle concept to deal with. The following striking example adapted from [33, Section 7.3.5] showsthat the existence of a compatible joint is not always a good way to get rid of inconsistencies.Example 1. Let X1, X2 be two variables taking values in {1, 2, 3}, and assume that X1 = 3 if and only if X2 = 3, and for theother cases we have the contradictory information X1 = X2 and X1 (cid:3)= X2. We can model this by the conditional probabilitiesP ( X1 = 3| X2 = 3) = 1 = P ( X2 = 3| X1 = 3), P ( X1 = 1| X2 = 1) = 1 = P ( X1 = 2| X2 = 2) and P ( X2 = 1| X1 = 2) = 1 = P ( X2 =2| X1 = 1). Despite the contradiction, it can be checked that the assessments are compatible with the joint mass functiondetermined by P ( X1 = 3, X2 = 3) = 1, in the sense that this joint induces the above conditionals by Bayes’ rule when theconditioning events have positive probability.1The key here is that Bayes’ rule cannot be always applied because of the presence of events with zero probability; thistechnical issue prevents the contradiction from being identified. It follows that in order to check consistency we generallyneed stronger tools than those based on the existence of a compatible joint distribution. Walley’s notion of coherenceappears to be one such tool.In fact, Walley considers two different consistency concepts for conditional lower previsions, called weak coherence and(strong) coherence (these will be introduced in Section 2, along with other material about Walley’s theory). What we showin Section 3 is that a number of conditional lower previsions are weakly coherent when they can all be induced by the samejoint via Bayes’ rule (or its generalisation for the imprecise case) and marginalisations. In other words, we show that weakcoherence is the generalisation to imprecise probability of the consistency criterion based on the existence of a compatiblejoint. Coherence, on the other hand, strengthens weak coherence and it can be shown that the difference between weakand strong coherence is indeed related to conditioning on sets of probability zero (see [21]).Our goal in this paper is to simplify the verification of the weak or the strong coherence of a number of assessments. Toachieve this, we introduce in Section 5 a new graphical representation called coherence graphs. We prove in Section 6 thatcoherence graphs allow us to decompose the task of verifying weak and strong coherence in a number of simpler tasks.Specifically, they help us determine a partition of the set of assessments with the property that coherence (resp., weakcoherence) within each of the elements of the partition implies coherence (resp., weak coherence) of all the assessments.We prove moreover that this is the finest partition with this property in the case of weak coherence. Besides, this partitionof our set of assessments can be determined with a polynomial-time algorithm, which we present in Section 7.Then we move to show some of the implications of our results for artificial intelligence by considering three well-knownrelated research fields. In Section 8.1, we consider Bayesian networks [27] and their extension to imprecise probability calledcredal networks [8]. By joining coherence graphs with a notion of probabilistic independence, we show for the first timeand to a very large extent that Bayesian and credal networks are coherent models. In Section 8.2 we focus on the so-called compatibility problem (see [9] and the references therein for a recent overview), i.e., the problem of deciding whethera number of distributions has a compatible joint. In this case we exploit our results about weak coherence to delivernew graphical criteria that enable one to optimally decompose such a problem, under a very general formulation. Finally,in Section 8.3 we relate our results to a powerful form of probabilistic satisfiability based on consistency that has beenrecently proposed in [34]. In particular, we discuss how probabilistic satisfiability can be used to check the consistency ofa number of (possibly imprecise) conditional and unconditional mass functions, and we outline that this task can easilybecome intractable as a consequence of the NP-hardness of the problem [5]. Moreover, we show that coherence graphs candecompose such a task in a way that makes it possible to solve some instances of the problem that would otherwise beintractable.As we said, our results are very general, in the sense that they are applicable for variables taking values on finite orinfinite spaces, and that we can also consider precise or imprecise representations. We make nevertheless some assumptions,like the logical independence of the variables studied or the representation of our assessments through a functional definedon a sufficiently large domain. In Section 9, we comment on the extent to which these assumptions can be relaxed. Thisis an important problem in order to relate our work more tightly with other areas of research. Finally, we conclude thepaper in Section 10 with some additional discussion. To make the paper easier to read, we have relegated all the proofs toAppendix A.1 This consistency notion is what we shall call later in this paper weak coherence. Note that the contradictory assessments X1 = X2 and X1 (cid:3)= X2 can alsobe modelled by other conditional probabilities that do not even satisfy this consistency notion, for instance P ( X1 = 1| X2 ",
            {
                "entities": [
                    [
                        136,
                        152,
                        "TITLE"
                    ],
                    [
                        1974,
                        1990,
                        "TITLE"
                    ],
                    [
                        6887,
                        6903,
                        "TITLE"
                    ],
                    [
                        6931,
                        6947,
                        "TITLE"
                    ],
                    [
                        7800,
                        7816,
                        "TITLE"
                    ],
                    [
                        8831,
                        8847,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 8 1 ( 1996) 11 I- 125 Artificial Intelligence Some pitfalls for experimenters with random SAT David G. Mitchell *, Hector J. Levesque 2 Department of Computer Science, University of Toronto, Toronto, Ontario M5S IA4, Canada Received July 1994; revised April 1995 Abstract We consider the use of random CNF formulas in evaluating the performance of SAT testing algorithms, and in particular the role that the phase transition phenomenon plays in this use. the properties of formula Examples in distributions prior to designing an experiment. We expect the field. the importance of understanding this to be of increasing from the literature importance illustrate Keywords: Satisfiability; Random problems; Phase transitions: Experimental design 1. Introduction tasks, problems reasoning to various Satisfiability the performance this is especially generated CNF formulas testing relationship lies at the core of many computational of SAT testing programs. Not surprisingly, of its close intelligence. Randomly for evaluating of formula distribution In formulas. sources of test material region” associated with the satisfiable-to-unsatisfiable the number of clauses examples to the the literature of experiments where sufficient consideration was not given from properties of the formulas used. In most cases, the test formulas were implicitly assumed and because so in artificial are a popular class of test problems the choice random investigation families of distributions were more useful the “hard phase transition which occurs as is increased. Here we make this concrete, by presenting than others, and suggested choosing to the validity of any [26], we argued that some is crucial formulas using from ’ Corresponding author. E-mail: mitchell@cs.toronto.edu. Work carried out while at Simon Fraser University, Bumaby, Canada, supported by the Institute of Robotics and Intelligent Systems and an EBCO/EPIC Graduate Scholarship. *Fellow of the Canadian Institute for Advanced Research. Supported in part by a grant from the Natural Sciences and Engineering Research Council of Canada. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved XSDlOOO4-3702( 95)00049-6 \fI12 D.G. Mitchell. H.J. L.evesque/Art@cial Intelligence 81 (1996) I II-125 to be challenging in some way, or at least to have hardness dependent on a particular parameter, which we show in further experimentation not to be the case. Our examples are based on currently popular “unstructured” random formulas. The be value of these as test material-even when sampled from the “hard region”-can questioned on the grounds that they may not be much like real problems [ 5,17,20], but some of these distributions appear challenging for a variety of methods, and we expect their use to continue. Moreover, most available alternatives are either puzzle-type problems (such as cross-word puzzles) or other distributions with no a priori greater validity. Nonetheless, some classes of “structured” random formulas are likely to become more popular, and in Section 8 we discuss the implications of our examples for such distributions. In Section 2 we describe our SAT testing algorithm and the formula distributions under consideration, and in Section 3 we survey some properties of these formulas. Sections 4-7 examine individual experiments, in light of what we now know about the formulas used. Additional data is presented as needed. In Section 8 we summa- rize. 2. Materials and methods We assume the reader is familiar with the problem SAT as defined in [ 121. The data for our analysis was produced by testing randomly generated SAT instances with a simple version of the Davis-Putnam Procedure [ 81. Our procedure, which we refer to as “DP”, is shown in Fig. 1. In the figure, w denotes a CNF formula and w\\p denotes the formula that results when we simplify w by setting the variable p true. We assume the variables are ordered, and let uars(w) denote the set of variables mentioned in w, and min{vars(w)) the least variable mentioned in w. DP is essentially the splitting variant of the Davis-Putnam Procedure as described in [7], but without the pure literal rule. It uses no heuristics other than unit propagation. This is perhaps the simplest complete SAT testing procedure that performs well enough to be useful, and so provides a kind of baseline for performance of many related methods. We count each recursive DP call (or equivalently, each simplification) as a step. We procedure DP( w) if w is empty then return satisfiable else if w contains an empty clause then return unsatis$able else if w contains a unit clause (1) then return DP(w\\l). else let p := min(vars(w)} if DP( o\\p) = satisfiable then return satisfiable else return DP(w\\7p) end DP Fig. 1. The procedure DP. \fD.G. Mitchell, H.J. L.mesque/Artijcial Intelligence 81 (1996) 111-125 113 report the median number of DP steps to find a satisfying assignment, if there is one, or report failure otherwise. (For most of the distributions used here, the median number of steps is highly correlated with mean, and also with mean and median run times.) We also report the proportion of formulas which are satisfiable. Each point in a graph represents a sample statistic based on 5000 formulas. We examine three families of random CNF formulas. Each family has three parame- ters; the number of variables n, the number of clauses M and for each n, a distribution of clauses over n variables. We will see that the constructed parameter c = m/n, the ratio of clauses to variables, is often more useful than m. The families are as fol- lows. l The widely studied fixed clause length family, which we call “random k-SAT”. Clauses are selected uniformly at random, with replacement, from the set of all 2k(‘$ nontrivial3 clauses of length k defined over n variables. l The “constant density” distributions. In the simplest version, a clause is constructed by including each of the 2n literals with some probability p (which may be a function of n) . Clause lengths are binomially distributed, with expected length 2np. It is often useful to study these formulas in terms of expected clause length k, in which case we set p = k/2n. Since empty clauses, unit clauses and trivial clauses are easy to simplify out,4 experimenters began using variants in which certain clause types were disallowed (in which case expected clause length is altered slightly by rejection of forbidden clause types). In Section 4 we consider the case where unit clauses are permitted, but trivial and empty clauses are forbidden. In Sections 3 and 5 we consider the case where empty, unit and trivial clauses are forbidden. We call this version random &k-SAT (using E to denote that k is an expectation). l Distributions with clause lengths distributed uniformly over some fixed range [k, Z] . We will call such distributions “[ k,l] -SAT”. 3. Patterns in random SAT In this section we will survey some basic (empirical) properties of random formulas for reference in following sections. 3.1. Random k-SAT The upper graph of Fig. 2 shows the proportion of random k-SAT formulas with n = 25 variables which are satisfiable. There is one curve for each clause length k E {2,3,4,5}, and for each curve the ratio of clauses to variables c is varied from l/5 to 30. As has been shown before, at small ratios almost all formulas are satisfiable and at high ratios almost all are unsatisfiable. For each k there is some range of c values over which the proportion of satisfiable formulas changes from almost 1 to almost 0. The location of is trivial if it contains both a variable and its negation. instances of this family with probability [27] extending work by Franc0 [9] and others presented an algorithm which not less than 1 - E, for any constant E > 0, in polynomial 3 A clause 4 Moreover, Wu and Tang solves expected time. See also [ 2,221. \f114 D.C. Mitchell. H.J. L.evesyue/Artijicial Intelligence 81 (1996) 11 l-125 Pr[SAT] 1:: -71 DP Steps 0.0 10000 1000 100 10 0 5 10 15 20 25 30 Ratio of Clauses to Variables Fig. 2. Median DP steps for random k-SAT: varying c for selected values of k. this “transition ratio for all values of n is analytically c = 4.758 bounded region” varies with k, but for each k it occurs at approximately The asymptotic the same region above and below: For k = 3, the currently known bounds are location of the transition [ 4,14,24]. [lo] transition respectively. (to distinguish k. As expected, y-axis, necessitated by the dramatic the median number of DP steps required from the regions is not to say there are no hard formulas [ 191 and c = 3.003 to test The lower graph of Fig. 2 shows increase the same formulas, Note the logarithmic the peak at each k lines up with the of peak difficulty with increasing region, We call the part of the curve near the peak the “hard corresponding far from the transition, which it qualitatively region” in the for small n are relatively easier. This “easy region”, nor that the “hard region” sense). Moving there is a range of ratios, for each curve, over little as the ratio is varied, and which we will refer to as the which difficulty changes the number of DP steps is just less than 25 (the number “plateau” of variables) speaking, DP just assigns values to variables by guessing and using unit propagation. We refer to the region below region. c = 1, where difficulty drops off quickly with decreasing When c is increased beyond region, difficulty gradually decreases. This general pattern is also found for larger k than is shown here (although we do not know if it holds for very large k). to the left from the hard region, and almost no backtracking region. In this region, hard in any rigorous c, as the “shoulder” occurs. Roughly is necessarily the transition Random 2-SAT Observe the difficulty of random 2-SAT increases only to the level of the plateau region and then begins to decrease again. Random 2-SAT does in Fig. 2 that as c is increased \fD.G. Mitchell, H.J. L",
            {
                "entities": [
                    [
                        79,
                        126,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 259 (2018) 167–185Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSafe inductions and their applications in knowledge representation ✩Bart Bogaerts a,∗a Department of Computer Science, KU Leuven, 3001 Heverlee, Belgiumb Department of Computer Science, KU Leuven, Campus De Nayer, 2860 Sint-Katelijne-Waver, Belgium, Joost Vennekens a,b, Marc Denecker aa r t i c l e i n f oa b s t r a c tIn many knowledge representation formalisms, a constructive semantics is defined based on sequential applications of rules or of a semantic operator. These constructions often share the property that rule applications must be delayed until it is safe to do so: until it is known that the condition that triggers the rule will continue to hold. This intuition occurs for instance in the well-founded semantics of logic programs and in autoepistemic logic. In this paper, we formally define the safety criterion algebraically. We study properties of so-called safe inductions and apply our theory to logic programming and autoepistemic logic. For the latter, we show that safe inductions manage to capture the intended meaning of a class of theories on which all classical constructive semantics fail.© 2018 Elsevier B.V. All rights reserved.Article history:Received 1 December 2017Received in revised form 13 March 2018Accepted 25 March 2018Available online 28 March 2018Keywords:Approximation fixpoint theoryLattice operatorInductive definitionsInduction processConstructionWell-founded semanticsGroundednessLogic programmingAutoepistemic logicAbstract argumentation1. IntroductionIn many fields of computational logic, natural forms of induction show up. Such an induction can be seen as a sequence of semantic structures obtained by iterative applications of rules or a semantic operator. For instance, in logic programming, it is natural to think of sequences of interpretations where at each stage a number of rules whose bodies are satisfied are triggered (i.e., their head is added to the current interpretation). For positive logic programs, all such sequences converge to the minimal model. For non-positive programs, this strategy may yield meaningless results. For instance, for the program(cid:2)(cid:3)P =ab ← ¬a,one such sequence isA short version of this paper was published in the proceedings of the IJCAI’17 conference [6]. This paper extends the previous work with more ✩theoretical results, examples, proofs of all propositions and applications of the work to argumentation frameworks.* Corresponding author.E-mail addresses: bart .bogaerts @cs .kuleuven .be (B. Bogaerts), joost .vennekens @cs .kuleuven .be (J. Vennekens), marc .denecker @cs .kuleuven .be(M. Denecker).https://doi.org/10.1016/j.artint.2018.03.0080004-3702/© 2018 Elsevier B.V. All rights reserved.\f168B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185N1 = ∅, {b}, {b, a},the limit of which is not even a supported model of the logic program. On the other hand, the sequenceN2 = ∅, {a}is another such sequence that does end in the intended model of P , namely its perfect model. Intuitively, what is wrong with N1 is that the rule b ← ¬a is applied too soon, before the value of a is established. For stratified programs, like P , this problem has been resolved, e.g., by Apt et al. [2]. For the general case, the well-founded semantics [33] offers a solution that uses three-valued interpretations instead of two-valued interpretations.In recent work, the notions of natural and safe inductions for inductive definitions were introduced [15,16]. It was argued that this kind of process forms the essence of our understanding of inductive definitions.In this paper, we lift those ideas of safe and natural inductions to a more general setting: we provide a principled study of such inductions in the context of approximation fixpoint theory (AFT) (Denecker, Marek and Truszczy ´nski (DMT) [10]), an algebraic theory that provides a unifying framework of semantics of nonmonotonic logics. We show convergence of safe inductions in this general setting and study the relationship between (algebraic) safe inductions and various fixpoints defined in approximation fixpoint theory.By presenting our theory in AFT, our results are broadly applicable. DMT [10] originally developed AFT to unify seman-tics of logic programs [32], autoepistemic logic [26] and default logic [28]. Later, it was also used to define semantics of extensions of logic programs, such as HEX logic programs [1] and an integration of logic programs with description log-ics [23]. Strass [30] showed that many semantics for Dung’s argumentation frameworks (AFs) [17] and abstract dialectical frameworks (ADFs) [7] can be obtained by direct application of AFT. Bogaerts and Cruz-Filipe [3] showed that AFT has applications in database theory, for defining semantics of active integrity constraints [19].The theory we present in this paper induces for each of the above logics notions of (safe) inductions and a safe semantics. Our complexity results are obtained for general operators and hence can also be transferred to various logics of interest. Throughout the paper, we give examples from logic programming.In Section 7, we apply our theory to autoepistemic logic. There we show that safe inductions induce a constructive semantics that captures the intended semantics of a class of theories for which classical constructive semantics fail. This failure was recently exposed and solved using a notion of set-inductions which is based on sets of lattice elements instead of intervals (which are standard in AFT) [5]. We show that safe inductions provide an alternative solution to this problem. Our solution is more direct: in contrast to set-inductions or well-founded inductions [14], safe inductions do not require any form of approximation; they are sequences in the original lattice. For logic programming, this means that they are sequences of interpretations such that some atoms are derived in each step. For AEL, this means that they are sequences of possible world structures such that additional knowledge is derived in each step.In Section 8, we apply our theory to Dung’s argumentation frameworks [17], where we show the surprising result that two different operators that exist for a given argumentation framework have the same safely defined point. Furthermore, this point corresponds to an existing semantics: it is the so-called grounded extension.The rest of this paper is structured as follows. In Section 2, we give preliminaries regarding lattices and operators. In Section 3, we define (safe) inductions and provide some basic results. We continue by studying complexity of some inference problems related to safe inductions in Section 4. In Section 5, we recall the basics of AFT; we use this in Section 6 to study how (safe) inductions relate to various fixpoints studied in AFT. Afterwards, in Sections 7 and 8, we apply our general theory to autoepistemic logic and argumentation frameworks respectively. We conclude in Section 9.2. Preliminaries: lattices and operators(cid:4)A partially ordered set (poset) (cid:5)L, ≤(cid:7) is a set L equipped with a partial order ≤, i.e., a reflexive, antisymmetric, transitive relation. We write x < y for x ≤ y ∧ x (cid:9)= y. If S is a subset of L, then x is an upper bound, respectively a lower bound of S if for every s ∈ S, it holds that s ≤ x, respectively x ≤ s. An element x is a least upper bound, respectively greatest lower boundof S if it is an upper bound that is smaller than every other upper bound, respectively a lower bound that is greater than every other lower bound. If S has a least upper bound, respectively a greatest lower bound, we denote it lub(S), respectively glb(S). As is custom, we sometimes call a greatest lower bound a meet, and a least upper bound a join and use the related S = lub(S) and x ∨ y = lub({x, y}). We call (cid:5)L, ≤(cid:7) a complete lattice if every notations subset S of L has a least upper bound and a greatest lower bound. A complete lattice has a least element ⊥ and a greatest element (cid:13).S = glb(S), x ∧ y = glb({x, y}), An operator O : L → L is monotone if x ≤ y implies that O (x) ≤ O ( y) and anti-monotone if x ≤ y implies that O ( y) ≤O (x). An element x ∈ L is a prefixpoint, a fixpoint, a postfixpoint of O if O (x) ≤ x, respectively O (x) = x, x ≤ O (x). Every monotone operator O in a complete lattice has a least fixpoint [31], denoted lfp(O ), which is also O ’s least prefixpoint and the limit of any terminal monotone induction of O , defined below.(cid:5)Definition 2.1. A monotone induction of a lattice operator O : L → L is an increasing sequence (for some ordinal β) (xi )i≤β of elements xi ∈ L satisfying\fB. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185169• x0 = ⊥,• xi ≤ xi+1 ≤ O (xi), for successor ordinals i + 1 ≤ β,• xλ = lub({xi | i < λ}), for limit ordinals λ ≤ β.A monotone induction is terminal if O (xβ ) = xβ .Logic programming. Let (cid:4) be an alphabet, i.e., a collection of symbols which are called atoms. A literal is an atom p or the negation ¬q of an atom q. The former are called positive literals; the latter are called negative literals. A logic program Pis a set of rules r of the form h ← ϕ, where h is an atom called the head of r, denoted head(r), and ϕ is a conjunction of literals called the body of r, denoted body(r). An interpretation I of (cid:4) is a subset of (cid:4). The set of interpretations 2(cid:4) forms a lattice equipped with the order ⊆. The truth value (t or f) of a propositional formula ϕ in a structure I , denoted ϕ I , is defined as usual. With a logic program P , we associate an immediate consequence operator T P [32] that maps a structure I to the structure{p ∈ (cid:4) | ∃r ∈ P : head(r) = p ∧ body(r)I = t}.This is an operator on the lattice (cid:5)2(cid:4), ⊆(cid:7). We call a logic program P positive if for each rule r ∈ P , body(r) consists of only",
            {
                "entities": [
                    [
                        136,
                        202,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 99 (1998) 1-19 Artificial Intelligence GAS, a concept on modeling species in genetic algorithms ’ MGrk Jelasity a**, J6zsef Dombi b*2 a Research Group of Artificial Intelligence, Jdzsef Attila University and the Hungarian Academy of Sciences, Aradi Vertanuk tere 1, H-6701 Szeged, Hungary b Department of Applied Informatics, .I&sef Attila University, Szeged, Hungary Received April 1996; revised December 1996 Abstract chart) using a radius function This paper introduces a niching structure creates a su.bpopulation radius, and a “cooling” method similar to simulated annealing. GAS offers a solution radius prob:lem with the help of these presented domains. We also discuss coding examined empirically. The first is a difficult second the traditional genetic algorithm. @ 1998 Elsevier Science B.V. technique called GAS (S stands for species) which dynamically instead of a single (taxonomic to the niche is the radius function. Speed functions are given for both real and binary tools of the sphere packing problem on binary domains using some the output of the system. Finally two problems are test function with unevenly spread local optima. The to techniques. A method based on the speed of species task, where a comparison to make it possible is a-n NP-complete for determining combinatorial is presented optimization to evaluate theory Keywords: Multimodal optimalization; Niching; Niche radius problem; Genetic algorithms 1. Introduction In recent years much work has been done with the aim of extending genetic algorithms to make it possible (GAS) reduce the probability purpose are known as niching techniques. Besides to find more than one local optimum of a function and so to for this the greater probability of the success the global optimum. The techniques developed of missing * Corresponsling ’ This work was supported by the OTKA grant TO20150 and the MKM grant 220. * Email: dombi@inf.u-szeged.hu. author. Email: jelasity@inf.u-szeged.hu. http://www.inf.u-szeged.hu/Njelasity. 0004-3702/98/$19.00 PIISOOO4-3702(97)00071-4 @ 1998 Elsevier Science B.V. All rights reserved. \f2 M. Jelasity, J. Dombi/Artifcial Intelligence 99 (1998) I-19 of the algorithm and a significantly niche techniques provide useful in a wide range of applications better performance on GA-hard problems (decision making, several designing (see [ 1 ] ) , on the problem, which is very tasks, etc.). the user with more information 1.1. Best-known approaches Simple iteration runs the simple GA several [ 61. The fitness of an individual it and so the GA is forced near the results of the particular and Richardson individuals Subpopulations can also be maintained kind of communication them developed GA (or any other optimizing after every run the optimized so that the optimum between procedure) function just found will not be located again. runs. Fitness sharing has been is reduced times to the same problem, and collects introduced by Goldberg if there are many other to maintain in the population. diversity in parallel, usually with the allowance of some [4]). The GAS method has (see, for example, in [ 11. The times on the same problem, but is run many is modified (multiplied by a derating function) from this approach. The sequential niche technique is described 1.2. Problems These the evaluation techniques yield good results Simple iteration is unintelligent; from several viewpoints, but mention should be made of some of their drawbacks, which do not arise in the case of our method, GAS. if the optima are not of the same value relatively bad local optima are found with low probability, while good optima are located several times in every which is highly unnecessary. Fitness sharing needs 0( n2) distance evaluations step, besides local optima to each other than the niche radius (a parameter of the method); that are much closer in other words, evenly spread throughout is known as the niche radius problem. The sequential niche technique also involves the niche radius problem. The complexity increases after every iteration due to the additional derating function of the optimized functions. too are found. the function Since The method seems difficult problems or structural optimization tasks, which are the most promising is modified many to use for combinatorial that the local optima are approximately the search space. This latter problem of the fitness function. times, “false” optima It cannot distinguish it is assumed GAS offers a solution to these problems the niche radius problem, which fields of GA applications. including is the most important drawback of all of the methods mentioned earlier. 1.3. Outline of the paper In Section 2 we give a brief description of GAS that is needed for an understanding of the following part of the paper. The reader who is interested refer to the Appendix on how to obtain more information in more details should or GAS itself. to the niche radius problem with the help of In Section 4 we give a possible solution the GAS system. Both real and binary problem domains are discussed. In Section 5 we present experimental demonstrates how GAS handles results. Two problems are examined. The first of the local optima of the the uneven distribution \fM. Jelasity, J. Dombi/Art$cial Intelligence 99 (1998) 1-19 3 optimized comparison function. The second is an NP-complete combinatorial problem, where a is presented to the traditional GA. 2. Species and GAS 2.1. Basic ideas and motivations The motivation optima of multimodal seemed to be the best choice. of this work was to tackle optimization problems. For this purpose, a subpopulation the problem of finding unevenly spread approach The obvious drawback of subpopulation approaches is that managing subpopulations and the system need special algorithms to use as well. There are considerable have its own attributes of the fitness mating different that make it possible landscape. The subpopulations subpopulations restrictions that usually allow breeding only to understand is relatively difficult and maybe advantages, however. Every subpopulation may regions local search due to the and the for them to adapt to the different perform effective inside of a subpopulation, can even communicate with each other. it is likely is intended (or species) spread optima, the same hill (heuristics will be given In our method GAS, every subpopulation of the fitness function. Thus, new species are created when to occupy a local that maximizer they are thought the parents are on different hills, and species have to be fused when later). To shed some light on the way to climb that is well GAS copes with unevenly and known from the field of simulated annealing. Thus, when illustrating our definitions the ability of escaping methods, we will talk about from an explicit attribute of every the “temperature” local optima. (it is the attraction of species, see Definition 5). This allowed us to offer an species algorithm are is that “warmer” allowed their own local species are allowed are of attraction. the system while species of different “temperatures” time. The basic to create “cooler” species autonomously that “cools down” to exist at the same In our system, we made idea of the algorithm to use a terminology the “temperature” it is natural of species, discovering Finally, llet us mention that due to our theoretical results, the large number of param- eters of GAS can be reduced to a couple of easy-to-understand ones (see Section 4). 2.2. Basic dejinitions Using the notations in the Introduction of [ 121, let D be the problem domain, f : D + W the fitness function function. ((GAS searches for the maxima of f!) and g : (0, 1)” --+ D for some m E {2,3,. . .} the coding Let us assume that a distance function d : D x D + R and term section (section : D x D + .P( D), where P(D) is the power set of D) are defined. Example 1. D C Em, D is convex. section(x,y) = {z 1 z = n + t(y -x), t E [O,l]}. \f4 M. Jelasity. J. Dombi/Art@cial Intelligence 99 (1998) I-19 (a) (b) Fig. 1. (a) A possible radius function. (b) Terms related to species. Example2. D={O,l}” (soif~~Dthenn=(xr,...,x,)). section( x, y) = {Z 1 if Xj = yj then zj = xi}. Defmition 3. R : N -+ R is a radius function over D if it is monotonic positive, R(0) = max{ d(el,ez) 1 el,e2 E D} and decreasing, lim R(n) = 0. “‘CC Fig. 1 (a) exemplifies the in a given step (see speed of “cooling”. Section 3). This sheds some light on the special requirements we made in Definition 3. these properties. The radius function will be used to control In fact, it gives the “temperature” of the system Let us fix a radius function R. Definition 4. A species s over D is given by (0, 1, S) ), where S is a population als of s; o( E S) is the center of s and is such that f(o) = max f(S) radius index or the level of s, and so the radius of s is R(l). Recall (or bag) of individuals population the triplet over D and the members of S are the (e.g. S = (xi, x1, x2)). is a multiset (0, I, S) individu- ; l( E IV) is the that in GAS a (notation: s = Definition 5. attraction of s. s = (0, I, S) is a species. Let A(s) = {u E D 1 d(a, o) < R(I)} be the Fig. 1 (b) Species with small attraction behave as they were “cooler”; the terms defined above. illustrates small area, their motion that are relatively optima o is “almost” determined population would be one, Definition that S G A(s) . necessary in the space is slower but they can differentiate to each other. Note close by S. If the maximal number of different maximizers they discover a relatively local that for a species s = (0, I, S), in a that it is not between 4 would be redundant. Also note \fM. Jelasify, J. Dombi/Art$cial Intelligence 99 (1998) 1-19 5 procedure begin activity while (population size of T-n < maximum allowed) do begin two parents two off spring the parents and the offspring back in the population choose create place end dying-off fusion end Fig. 2. The basic algorithm that creates If,+, from Tn. Definition 6. Let T be a gra",
            {
                "entities": [
                    [
                        63,
                        119,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 1752–1782Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintModelling and solving temporal reasoning as propositional satisfiabilityDuc Nghia Pham a,b,∗, John Thornton a,b, Abdul Sattar a,ba SAFE Program, NICTA Ltd., Queensland, Australiab Institute for Integrated and Intelligent Systems, Griffith University, Queensland, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 24 November 2006Received in revised form 2 June 2008Accepted 11 June 2008Available online 19 June 2008Keywords:Temporal reasoningInterval AlgebraSatisfiabilitySatisfiability modulo theoriesDPLLSearchRepresenting and reasoning about time dependent information is a key research issue inmany areas of computer science and artificial intelligence. One of the best known andwidely used formalisms for representing interval-based qualitative temporal information isAllen’s interval algebra (IA). The fundamental reasoning task in IA is to find a scenario thatis consistent with the given information. This problem is in general NP-complete.In this paper, we investigate how an interval-based representation, or IA network, can beencoded into a propositional formula of Boolean variables and/or predicates in decidabletheories. Our task is to discover whether satisfying such a formula can be more efficientthan finding a consistent scenario for the original problem. There are two basic approachesto modelling an IA network: one represents the relations between intervals as variablesand the other represents the end-points of each interval as variables. By combining thesetwo approaches with three different Boolean satisfiability (SAT) encoding schemes, weproduced six encoding schemes for converting IA to SAT. In addition, we also showedhow IA networks can be formulated into satisfiability modulo theories (SMT) formulae basedon the quantifier-free integer difference logic (QF-IDL). These encodings were empiricallystudied using randomly generated IA problems of sizes ranging from 20 to 100 nodes.A general conclusion we draw from these experimental results is that encoding IA into SATproduces better results than existing approaches. More specifically, we show that the newpoint-based 1-D support SAT encoding of IA produces consistently better results than theother alternatives considered. In comparison with the six different SAT encodings, the SMTencoding came fourth after the point-based and interval-based 1-D support schemes andthe point-based direct scheme. Further, we observe that the phase transition region mapsdirectly from the IA encoding to each SAT or SMT encoding, but, surprisingly, the locationof the hard region varies according to the encoding scheme. Our results also show a fixedperformance ranking order over the various encoding schemes.© 2008 Elsevier B.V. All rights reserved.1. Introduction and backgroundRepresenting and reasoning about time dependent information (i.e. temporal reasoning) is a central research issue in manyreal world AI applications such as planning, plan recognition, scheduling, natural language understanding, and medicaldiagnosis [36]. The basic research tasks include the design and development of efficient reasoning methods to check theconsistency of temporal information, to infer new information and to answer temporal queries [10].Temporal reasoning is an important subdiscipline within the field of constraint satisfaction research and has been subdi-vided into two basic areas: qualitative and quantitative temporal reasoning.* Corresponding author at: SAFE Program, NICTA Ltd., Queensland, Australia.E-mail addresses: duc-nghia.pham@nicta.com.au (D.N. Pham), john.thornton@nicta.com.au (J. Thornton), abdul.sattar@nicta.com.au (A. Sattar).0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.003\fD.N. Pham et al. / Artificial Intelligence 172 (2008) 1752–178217531.1. Quantitative temporal reasoningQuantitative problems have to deal with situations where there is definite metric information about time intervals, suchas one event being at least 20 minutes long or starting at exactly 2 o’clock. Such scenarios can be treated as temporal con-straint satisfaction problems (TCSPs) where variables represent continuous domain time points and constraints representsets of intervals that restrict the domains of particular variables [11]. For example, we could represent the unary con-straint T i that time point xi occurs within the intervals ([a1, b1], [a2, b2]) as (a1 (cid:2) xi (cid:2) b1) ∨ (a2 (cid:2) xi (cid:2) b2) or the binaryconstraint T i j that the duration between time points xi and x j lies within the interval [a1, b1] as (a1 (cid:2) x j − xi (cid:2) b1).A general TCSP can be represented as a directed constraint graph with nodes representing variables and edges represent-ing binary constraints, where each edge can be labelled with a set of intervals. If we further specify that each edge must belabelled with a single interval we arrive at a simple temporal problem (STP) [10].Deciding the consistency of a general TCSP is known to be NP-complete whereas finding the consistency of an STP canbe decided in polynomial time using shortest-path algorithms [11]. This has led to the development of methods that decidethe consistency of a TCSP by selecting one disjunct label from each edge and testing whether the resulting problem is aconsistent STP.Subsequent work has looked at disjunct temporal problems (DTPs) that allow the inclusion of non-binary constraints.Techniques for solving these problems treat the task of selecting a consistent STP from the original DTP as a meta-CSP [50]that takes each constraint in the original problem as a variable in the meta-problem and performs a backtracking searchwith forward-checking over the space of possible STPs.A DTP can also be represented as a satisfiability (SAT) problem, consisting of clauses containing disjunctions of literalsthat each represent a temporal constraint (e.g. x1 − x2 (cid:2) 2). Such problems can be solved using generic SAT solvers thatadditionally test the consistency of the underlying STP problems represented by the clauses during the search [3]. Currently,some of the most promising results in the DTP area have been produced using SAT solvers that incorporate the latestadvances from the general SAT solving complete search community [5].1.2. Qualitative temporal reasoningHowever, there are notions of time used in day to day decision making that do not refer directly to quantitative metricdata about time points or durations. For example, we may have a constraint that one event must start before another oroccur during a third event. Here we are only concerned with the relative time ordering of events and not with exactlywhen each event starts and stops. For instance, consider the ordering of events in the construction of a house. Here weare typically unable to predict or control exactly when a particular task will occur but we do have hard constraints aboutnot fitting out the interior until the roof is attached. These qualitative temporal relations were formalised in Allen’s intervalalgebra (IA) [1].In IA there are 13 atomic relations that define all the possible qualitative arrangements that can exist between twotime intervals. These relations cover the basic situations that two events can be before, during, overlapping, meeting, starting,finishing or equal to each other (see Table 1). As with the formulation of a TCSP, an IA problem can be expressed as directedconstraint graph. However, here each node represents an interval of unspecified length and the edges represent constraintslabelled by sets of atomic relations. In this form, IA is an expressively rich framework and, as with the general TCSP, thereasoning problem is computationally intractable. Existing IA techniques are typically based on the backtracking approach(proposed by Ladkin and Reinefeld [29]), which uses path consistency as forward checking. Although this approach hasTable 1The 13 IA atomic relations. Note that the endpoint relations X− < X+and Y− < Y+have been omittedAtomic relationSymbolX before YY after XX meets YY met by XX overlaps YY overlapped by XX during YY includes XX starts YY started by XX finishes YY finished by XX equals YbbimmiooiddissiffieqMeaningX(cid:2)(cid:3) Y(cid:2)(cid:3)X(cid:2) (cid:3) Y(cid:2) (cid:3)X(cid:2) (cid:3)(cid:2) (cid:3)YX(cid:2) (cid:3)(cid:3)(cid:2)YX(cid:2) (cid:3)(cid:2)(cid:3)YX(cid:2) (cid:3)(cid:3)(cid:2)YX(cid:2)(cid:2)Y(cid:3)(cid:3)Endpoint relations− < Y−, X+ < Y−, X− < Y+ < YXX++− < Y+ = Y−, X−, X− < Y+ < YXX++− < Y+ > Y−, X−, X− < Y+ < YXX++− > Y+ > Y−, X−, X− < Y+ < YXX++− = Y+ > Y−, X−, X− < Y+ < YXX++− > Y+ > Y−, X−, X− < Y+ = YXX++− = Y+ > Y−, X−, X− < Y+ = YXX++\f1754D.N. Pham et al. / Artificial Intelligence 172 (2008) 1752–1782been further improved [36,53], all variants still rely on path consistency checking at each step to prune the search space.This native IA approach has the advantage of being fairly compact, but is disadvantaged by the overhead of continuallyensuring path-consistency. Additionally, the native IA representation of variables and constraints means that state-of-the-artlocal search and complete search techniques (such as unit propagation look ahead in Satz [32] or nogood recording andnon-chronological backtracking in Chaff [35]) cannot be easily transferred to the IA domain.In practice, existing native IA backtracking approaches are only able to find consistent solutions for relatively smallgeneral IA instances [48,51]. On the other hand, recent research has shown that modelling and solving hard combinato-rial problems (including DTPs and planning problems) as SAT instances can produce significant performance benefits oversolving problems in their original form [5,24,26,41]. These results have motivated us to undertake the current study.In other related work, stochastic local search techniques (SLS) were applied ",
            {
                "entities": [
                    [
                        138,
                        210,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 267 (2019) 39–57Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProbably bounded suboptimal heuristic searchRoni Stern a,∗a Ben Gurion University of the Negev, Israelb University of Toronto, Canada, Gal Dreiman a, Richard Valenzano ba r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2017Received in revised form 15 June 2018Accepted 8 August 2018Available online 25 October 2018Keywords:Artificial intelligenceHeuristic searchFinding an optimal solution to a search problem is often desirable, but can be too difficult in many cases. A common approach in such cases is to try to find a solution whose suboptimality is bounded, where a parameter (cid:2) defines how far from optimal a solution can be while still being acceptable. A scarcely studied alternative is to try to find a solution that is probably optimal, where a parameter δ defines the confidence required in the solution’s optimality. This paper explores this option and introduces the concept of a probably bounded-suboptimal search (pBS search) algorithm. Such a search algorithm accepts two parameters, (cid:2) and δ, and outputs a solution that with probability at least 1 − δ costs at most 1 + (cid:2) times the optimal solution. A general algorithmic framework for pBS search algorithms is proposed. Several instances of this framework are described and analyzed theoretically and experimentally on a range of search domains. Results show that pBS search algorithms are often faster than a state-of-the-art bounded-suboptimal search algorithm. This shows in practice that finding solutions that satisfy a given suboptimality bound with high probability can be done faster than finding solutions that satisfy the same suboptimality bound with certainty.© 2018 Elsevier B.V. All rights reserved.1. IntroductionConsider a search problem in which we must find a path in a state space from a given initial state to a goal state. Given enough memory and running time, standard heuristic search algorithms like the Aalgorithm [1] can solve a given search problem optimally, i.e., find the lowest-cost path from the initial state to a goal. However, it is often the case that there is not enough memory or runtime to find an optimal solution. For such cases, a range of search algorithms have been proposed that return suboptimal solutions [2–5]. In particular, bounded-suboptimal search algorithms are algorithms that are guaranteed to return a solution whose cost is at most (1 + (cid:2)) times the optimal solution. Ideal bounded-suboptimal algorithms introduce a natural tradeoff between solution quality and search runtime: when (cid:2) is high, solutions are returned quickly but can have poorer quality, while when (cid:2) is low solutions are harder to find but usually have higher quality (i.e., lower cost).∗Bounded-suboptimal search algorithms are very strict, in the sense that the cost of the solution they return must be at most 1 + (cid:2) times the cost of an optimal solution. Current techniques to achieve this guarantee rely on admissible heuristics – heuristics that are a lower bound on the optimal solution cost. Such heuristics are often inaccurate, resulting in increased search runtime.* Corresponding author.E-mail addresses: sternron@post.bgu.ac.il (R. Stern), gal.dreiman@gmail.com (G. Dreiman), rvalenzano@cs.toronto.edu (R. Valenzano).https://doi.org/10.1016/j.artint.2018.08.0050004-3702/© 2018 Elsevier B.V. All rights reserved.\f40R. Stern et al. / Artificial Intelligence 267 (2019) 39–57In this paper, we propose an alternative type of solution quality guarantee. Search algorithms with this quality guarantee return solutions that are optimal with high probability. Instead of controlling the suboptimality of the returned solution (i.e., (cid:2)), these algorithms accept a parameter δ that controls the confidence in which the returned solution is optimal. δ allows a similar tradeoff of solution quality and runtime, where increasing δ is expected to decrease the search effort at the cost of increasing the likelihood that a suboptimal solution will be returned.Both types of solution quality guarantees can be combined, through the novel notion of a probably bounded-suboptimal search (pBS search). A pBS search algorithm is given two parameters, (cid:2) and δ, and is required to return a solution that is at most 1 + (cid:2) times the optimal solution, with probability higher than 1 − δ. We call 1 + (cid:2) the desired suboptimality, and 1 − δthe required confidence. Introducing and defining the concept of a pBS search is the first main contribution of this work.In many domains the solution found by current bounded-suboptimal search algorithms has a much lower (i.e., better) suboptimality in practice than the suboptimality guaranteed by the bound. Since there is usually a tradeoff between runtime and solution quality, this means the user of the search algorithm paid in runtime more than it was needed for the desired solution quality. A key benefit of the novel form of bounded suboptimality we propose is that it provides users of search algorithms with more control over the time-quality tradeoff. We observed this experimentally: by using some of the pBS algorithms we propose it is often possible to obtain a solution with the desired suboptimality significantly faster by only slightly relaxing the required confidence from 1.0 to 0.9.The second contribution is a general framework for developing pBS algorithms called Psf. Psf has two main building blocks: a solution generator and a stopping condition. The solution generator can be any algorithm that produces a sequence of solutions. The stopping condition is responsible for identifying when the current solution is sufficient, in the sense that it has the desired suboptimality with the required confidence. We propose three such stopping conditions – Absolute, h-ratio, and Open-based – and prove that using these conditions results in a pBS search algorithm. For the Absolute and h-ratioconditions we also propose a solution generator that is specifically designed to satisfy these stopping conditions quickly. These stopping conditions and new solution generator are the third contribution of this work.Finally, we evaluate the different instances of Psf experimentally on four search domains: the Pancakes puzzle, Dockyard robot, Vacuum cleaner, and grid-based pathfinding. The experiments on these diverse set of domains show that varying both (cid:2) and δ offers a flexible control over the solution quality versus runtime tradeoff: in general, increasing either (cid:2) or δ results in smaller running time and lower solution quality. In particular, setting δ > 0 indeed allows us to find solutions faster.Some of the material in this work was previously published in the proceedings of the Symposium on Combinatorial Search (SoCS) [6,7]. This paper summarizes and goes well beyond these two conference papers. In particular, it extends these prior works by:• The experimental evaluation in these prior conference publications considered only one domain: the 15-puzzle. This work significantly extends that evaluation through the implementation and evaluation of all Psf instances on four additional domains (see Section 5).• The theoretical basis of pBS search is properly defined and analyzed. This includes several corrections to the original work (see Appendix B).• For the Absolute and h-ratio stopping conditions, we propose a solution generator that is specifically designed for them, which is based on recent bounded-cost search algorithms (see Section 6).In addition, in previous work [6,7], this line of research was referred to as Probably Approximately Correct (PAC) search, since it was inspired by the notion of PAC learning from the theoretical machine learning literature [8]. Given that there are significant differences between the concept of PAC and the solution quality guarantees considered in this paper, we have changed the name to probably bounded-suboptimal search to avoid confusion. A comparison of these related concepts can be found in Section 8.2. Preliminaries and backgroundA graph search problem or a search problem is defined by a graph G, a source vertex s ∈ V , and a non-empty set of target vertices T ⊆ V . The edges in G are associated with a non-negative cost, denoted by c(e), and the cost of a path p in G, denoted c(p), is the sum of costs of its constituent edges. A solution to a search problem P is a path in G from s to a vertex in T . A solution is called optimal if there is no other solution that has a lower cost. Let Opt P denote the cost of the optimal solution to P . The suboptimality of a solution is the ratio between its cost and Opt P . Hence, the suboptimality of an optimal solution is 1. Note that alternative forms of suboptimality have also been introduced [9] and the concepts in this paper can easily be extended to them. For clarity, we focus in this paper on the aforementioned definition of suboptimality.A search algorithm is a procedure that accepts a search problem and tries to return a solution to it. Note that in some cases the underlying graph G is not given to the search algorithm explicitly, e.g., because it is too large to fit in memory. Instead, the search algorithm can be given a source vertex s and a set of state transition operators, which implicitly define G as the set of all states reachable by applying sequences of state transition operators to s.\f2.1. Properties of search algorithmsR. Stern et al. / Artificial Intelligence 267 (2019) 39–5741Let cost( A, P ) denote the cost of the solution returned by algorithm A when given problem P . A search algorithm A is called an optimal search algorithm if for every search problem P it holds that cost( A, P ) = OptP . A search algorithm A is called a bounded-suboptimal search algorithm if it accepts a parameter (cid:2) and for every problem P it holds that cost( A, P ) ≤(1 + (cid:2)) ",
            {
                "entities": [
                    [
                        134,
                        178,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 73 ( 1995) 271-306 Artificial Intelligence Reinforcement learning of non-Markov decision processes Steven D.Whitehead a**, Long-Ji Lin b,* a GTE Laboratories Incorporated, 40 Sylvan Road, Waltham, MA 02254, USA h School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA Received September 1992; revised April 1993 Abstract Techniques based on reinforcement learning (RL) have been used to build systems that learn to perform nontrivial sequential decision tasks. To date, most of this work has focused on learning tasks that can be described as Markov decision processes. While this formalism is useful for modeling a wide range of control problems, there are important tasks that are inherently non- Markov. We refer to these as hidden state tasks since they arise when information relevant to from the agent’s immediate identifying sensation. Two important types of control problems that resist Markov modeling are those in which ( 1) the system has a high degree of control over the information collected by its sensors (e.g., as in active vision), or (2) the system has a limited set of sensors that do not always provide adequate information about the current state of the environment. Existing RL algorithms perform unreliably on hidden state tasks. the state of the environment is hidden (or missing) This article examines two general approaches to extending reinforcement learning to hidden state tasks. The Consistent Representation (CR) Method unifies recent approaches such as the Lion algorithm, the G-algorithm, and CS-QL. The method is useful for learning tasks that require the agent to control its sensory inputs. However, it assumes that, by appropriate control of perception, the external states can be identified at each point in time from the immediate sensory inputs. A second, more general set of algorithms in which the agent maintains internal state over time is also considered. These stored-state algorithms, though quite different in detail, share the common feature that each derives its internal representation by combining immediate sensory inputs with internal state which is maintained over time. The relative merits of these methods are considered and conditions for their useful application are discussed. * Correponding ’ Currently at Siemens Corporate Research author. Fax: (617) 890-9320. E-mail: swhitehead@gte.com. 755 College Road East, Princeton, NJ 08540, USA. Fax: (609) 734-6565. E-mail: Incorporated, Ijl@learning.scr.siemens.com. 0004-3702/95/$09.50 SSDI 0004-3702( @ 1995 Elsevier Science B.V. All rights reserved 94)00012-P \f272 S.D. Whitehead. L.-J. Lin/Artijiciul lnfelligence 73 (1995) 271-306 1. Introduction is necessary robots cannot be achieved theories of agent-environment interaction need to include an account of to develop and maintain intelligent agents. Sophisticated too complex, idiosyncratic, are too rigid and through meticulous programming and uncertain inexpressive alone. The real to know ahead of time, and to be for programming alone agents must bear at least some of the burden of skill acquisition the world does not stand still, to maintain a high agents must learn new skills and adapt old ones to changes level in the is much Computational learning. Learning real-world world programming feasible. Intelligent themselves. Also, because of performance, environment. Though languages there are many kinds of learning, and many things in the end, all learning boils down to learning control. The value of anything only be measured in terms of its ability in terms of its effect on the agent’s the environment interaction with its environment, This article to control focuses on reinforcement that is well suited to learning, environments to a desired end. a paradigm [ 7,461. that an agent might learn, learned can is modeled as a controller In reinforcement learning to a finite state are unknown). At each time step, the controller to change state and generate a payoff. a that maximizes control policy coupled control (whose in highly interactive interaction transition probabilities learning the agent-environment machine performs an action which causes The agent’s objective measure of the total payoff received over time. that make reinforcement the environment Some of the features ( 1) RL is a weak method is to learn a state-dependent in that through (a) (b) trial-and-error learning occurs ment; the feedback used for learning teacher, who offers the “correct answer” learning (RL) appealing are: experimentation with the environ- takes the form of a scalar payoff-no explicit is required; (c) on sequential decision making tasks, payoffs may be sparse and considerably delayed; and little or no prior knowledge (d) is required. (2) RL is incremental (3) RL can be used to learn direct sensory-motor mappings, and is, thus, appropriate to unexpected tasks in which the agent must respond quickly and can be used online. for highly reactive events in the environment. (4) RL is valid in nondeterministic (5) When used in conjunction with temporal difference environments. (TD) methods has proven checkers to be effective on difficult sequential decision making [ 381, pole balancing [ 8,301, and backgammon [ 491) . (6) RL architectures incorporate supervised are extensible. Recently, RL systems have been extended aspects of planning [ 15,24,56] learning [ 25,45,5X], and hierarchical intelligent exploration Traditionally, research in RL has focused on Markov decision processes [ 19,441, RL (e.g., tasks to [ 21,23,5 11, control [ 16,26,4 1,621. intuitively the agent directly observes the (MDPs). corresponds Described to a control formally in Section 2, a Markov decision process task in which at each point in time (a) \fS.D. Whitehead, L.-J. Lin/Artijcial Intelligence 73 (1995) 271-306 273 (b) and to predicting in its internal in time, encodes all the information In most applications, the effects of actions for two reasons. First, the agent does not observe relevant It is important the effects of actions depend only upon in the sense of being given a label which names the action the state of the state. repre- is known as important focusing on Markov decision processes of stochastic processes and learning methods, [ 441, rely on the Markov property during credit assignment, to apply the classical mathematicals [ 7,44,54,55]. state. directly, that the agent, at each point state of the environment and the current the environment This assumption sentation the Murkov assumption. to the theoretical development has allowed dynamic programming which use TD-methods and may perform badly when are important as Markov decision processes. These non-Markov hidden information situation. they occur whenever (or missing) to as for a relevant piece of of the current [ 18,593. Nevertheless, (or easily) is violated that are not naturally tusks, since to be hidden there formulated tasks are commonly control problems Second, existing of RL, because the assumption it is possible representation reinforcement it has been the agent’s researchers referred learning from state learning to distinguish then guessing into bins according than guess a classification. in the context of autonomous Hidden state tasks arise naturally to their color, say Bin-l red from blue, robots. The the agent’s sensors for the task at hand. Suppose a robot is charged with the task of sorting for red, Bin-2 for blue. If the robot’s it can do then for any given block If there are an equal number of blocks of each if the robot to achieve 100% performance. The former case is missing simplest example of a hidden state task is one which occurs when are inadequate blocks sensors are unable no better color, can detect color, corresponds from the agent’s available In general, readings, to uniquely needed information task, then the decision problem is always available. sensor the sensors do not provide all the to the internal if there are circumstances identify is non-Markov. The latter case is Markov since once a color sense the state of the environment with respect the information if a robot’s than chance. On the other hand, is defined only by its immediate to achieve optimal performance can do no better decision problem, to a non-Markov since relevant representation. it can easily representation information in which needed learn and is state resources perception of integrating [ 601. In active perception, tasks are also a natural consequence Hidden tive/selective over the allocation of its sensory is used to sense visual processing modules) an efficient, is not properly maintained data generated by the sensors may fail to code a relevant piece of information, resultant the environment. be periods of time when decision learning with ac- the agent has a degree of control (e.g., controlling visual attention or selecting in then the and the to the current state of there will its sensors, the representation may be ambiguous with respect that if the agent must learn to control It follows [ 3,5,6]. This control if control representation will be inadequate. Therefore task-specific way. However, the environment the internal internal task will be non-Markov. for applying Techniques reinforcement learning to non-Markov the central technique focus of this article. We describe a generalized sistent Representation (CR) Method that can be used to learn control the CR-method active perception [ 571. The principal idea underlying is decision processes called the Con- in systems with is to split con- \f214 S.D. Whitehead, L.-J. Lin/Artificial Intelligence 73 (I 995) 271-306 phase and an overt phase. During (or sensor configuration) actions the perceptual in order to gen- of the current external environment. is used to select overt action; that is, an into representation that changes (i.e., Markov) the overt stage, this representation the system performs two phases, a perceptual sensing trol phase, erate an adequate During action representation met",
            {
                "entities": [
                    [
                        76,
                        131,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 102 (1998) 97-141 Artificial Intelligence The value of the four values Ofer Arieli *, Arnon Avron ’ Departmeni of Computer Science, School of Mathematical Sciences, Tel-Aviv University, Ramat-Aviv 69978, Israel Received 30 June 1997 Abstract is a very suitable setting for computerized that the logical role that the four-valued In his well-known paper “How computer should think” Belnap (1977) argues that four-valued this thesis semantics structure has among Ginsberg’s bilattices is by showing similar to th’e role that the two-valued algebra has among Boolean algebras. Specifically, we provide several theorems logics can actually be characterized as four-valuled inference use of four-valued information, logics with the inconsistent or uncertain is in favor of the latter. 0 1998 Elsevier Science B.V. All rights reserved. logics, and show that at least for the task of handling that show that the most useful bilattice-valued reasoning. In this paper we vindicate relations. In addition, we compare the use of three-valued the comparison Keywords: Bilattices; Paraconsistency; Multiple-valued systems; Preferential logics; Reasoning 1. Introdulction In [8,9] Belnap introduced a logic intended to deal in a useful way with inconsistent (no knowledge), lack of information the classical ones, information. This logic is based on a structure called FOUR, which has t and f, and two new ones: and T that indicates and incomplete that intuitively four truth values: (“over”- denotes should knowledge). Belnap gave quite convincing think” should be based on these four values. In [26,27] Ginsberg proposed algebraic structures called bilattices that naturally generalize Belnap’s FOUR. The idea is to consider in two closely an arbitrary number of truth values, and to arrange related partial orders, each forming for introducing bilattices was to provide a uniform approach arguments why “the way a computer a lattice. The original motivation for a diversity of applications I inconsistency them (as in FOUR) of Ginsberg * Corresponding ’ Email: aa@math.tau.ac.il. author. E-mail: ofera@math.tau.ac.il. 0004-3702/98/$19.00 PII: SOOO4-3702(98)00032-O 0 1998 Elsevier Science B.V. All rights reserved. \f98 0. Arieli, A. Avron /Artificial Intelligence IO2 (1998) 97-141 in AI. Bilattices were further investigated by Fitting, who showed that they are useful also for providing semantics for logic programs [ 17,19-211. In [2,3] we presented bilattice- based logics and corresponding proof systems. These logics turned out to have many desirable properties (like paraconsistency). In the present paper we proceed with this logical approach. In particular, we consider bilattice-based logics that are preferential in the sense of Shoham [42,43], i.e., they are based on the idea that inferences should be taken not according to all models of a given theory, but only with respect to a subset of them, determined making such preferences among bilattice-based models: according to certain preference criteria. We use here two main guidelines for (1) Prefer models that assume as much consistency as possible. This approach reflects the intuition that contradictory data corresponds to inadequate information about the real world, and therefore should be minimized. (2) Prefer models that assume a minimal amount of knowledge; The idea this time is that we should not assume anything FOUR, the structure that corresponds that is not really known. four-valued to Belnap’s logic, is the minimal bilattice, exactly as the structure that is based on the classical two values is the minimal Boolean algebra. The main goal of this paper is to show that the logical among bilattices role of FOUR algebra has among Boolean to that the two-valued is also very similar algebras. introduced Indeed, it turned out that all the natural bilattice-valued that we had for various purposes can be characterized using only the four basic values! logics This does not mean, of course, that from now on bilattices have no value (exactly as the fact, that Boolean algebras can be characterized algebras have no value). It does demonstrate, however, in {t, f}, does not mean the fundamental that Boolean role of the four values. In an opposite direction to that taken by Ginsberg and Fitting, other authors tried to get along by using just three values for achieving the same (or similar) goals. We show, however, that the use of four values is preferable to the use of three even for tasks that can in principle be handled using only three values. Taken together, the main import of our results is a strong vindication (so we believe) of Belnap’s goal of computerized reasoning. thesis concerning the fundamental importance of the four basic values for the The rest of this paper is organized as follows: In Section 2 we introduce a propositional language with four-valued semantics. Our language is based on the basic bilattice operators together with an appropriate implication connective. In Section 3 we show the adequacy of this language by exploring its expressive power as well as those of its fragments. Section 4 is devoted to introducing the most important consequence relations that are based on FOUR, and to an examination of their main properties. In Section 5 we compare four- valued formalisms with three-valued ones, and in Section 6 we generalize the four-valued logics of Section 4 to arbitrary bilattices. The main result of this section is that by doing so we do not get any new logic. Finally, in Section 7 we summarize the main results and conclusions of this work. \f0. Arieli, A. Avon /ArtQicial Intelligence 102 (1998) 97-141 99 Fig. 1. FOUR. 2. The language and its four-valued semantics 2.1. The algebraic structure and its basic connectives logic mentioned The truth values of Belnap’s logical partial order, &, which intuitively above have two natural orderings: First in the reflects differences to this order, f is the minimal t is the maximal one, and I, T are two intermediate values that are incomparable. lattice with an order reversing we have the standard “measure of truth” that every value represents. According element, ((t, f, T, A-}, &) -T = T and -I respectively. is a distributive involution 1, for which = 1. We shall denote the meet and the join of this lattice by A and v, (again, intuitively) that each or information The other partial order, <k, is understood the amount of knowledge as reflecting differences in truth value exhibits. Again, ((t, f, T, A_}, <k) is a lattice where _L is its minimal element, T-the maximal element, and t, f are incomparable. Following Fitting [ 17,181 we shall denote the meet and the join of the <k-lattice by @ and @, respectively. The twcl lattice orderings are closely related. The knowledge operators @ and @ are monotone with respect to the truth ordering &, and the truth operators A, v, and 1 (as well, of course, as @ and CT+) are monotone with respect to <k. Moreover, all the 12 laws hold, as well as De Morgan’s laws. The structure that consists of these four distributive elements and the five basic operators (A, v, l,C3, @) is usually called FOUR. A double Hasse diagram of FOUR is given in Fig. 1. 2.2. Designated elements and models The next step in using FOUR for reasoning The obvious choice is 2, = (t , T], since both values intuitively to be true. The set V has the property are in V, while a v b E V the various semantic notions are defined on FOUR as natural generalizations is to choose its set of designated elements. formulae known represent that a A b E D iff a @ b E ;I) iff both a and b this point of similar iff either a or b is in ID. From iff a @ b E V \f100 0. Arieli, A. Avron /Art$cial Intelligence 102 (1998) 97-141 that assigns a truth value from FOUR to each classical notions: A valuation v is a function atomic formula. Any valuation in the obvious way. We to complex is extended will sometimes write + : b E v instead of v(e) = b. A valuation u satisjies @ iff u(e) E 27. is a model of r. The A valuation set of all models of r is denoted mod(r). The structure FOUR together with 23 as the set of the designated elements will be denoted in the sequel by (FOUR). in a given set r of formulae that satisfies every formula formulae 2.3. Implication connectives Unlike in the classical calculus, Belnap’s logic has no tautologies. Thus, excluded middle is not valid in it. This implies that the definition of the material as -$ instead the following there for representing and equivalence operation on (FOUR) : v 4 is not adequate implications entailments. We introduce implication + H $J therefore Definition 1 (Arieli and Avron [2,6]). a>b= b t ifaED, ifa$D, a-+b=(a>b)r\\(-b>-a), attb=(a+b)r\\(b-+a). Proposition 2. (a) v(+ -+ 4) is designated t, 4) is designated (b) v(+ ifsu(@) Gt u(4). iflu = v(4). Notes. (1) (2) (3) Unlike the connectives of the basic language, with respect to &. On [t, f} so also implication. The sense in which III is a true implication will be clarified in Proposition 20 below. are identical, of the classical the new connectives are not monotone the material the connectives (H) and the two new implications 1 are generalizations of Definition implication 2.4. Canonical examples Example 3 (Tweety dilemma). Consider the following well-known puzzle: bird(Tweety) ~Jly(Tweety) penguin(Tweety) > bird(Tweety) penguin(Tweety) > -JEy(Tweety) bird(Tweety) penguin(Tweety) Denote this set by r. The first assertion of r H (i.e., $I H ~5 = -@ ~4). This is an instance of a rule which is weaker than the other two is formulated by the material “implication” \f0. Arieli, A. Avmn /Artijicial Intelligence 102 (1998) 97-141 101 Model No. bird(Tweety) fly(Tweety) penguin(Tweety) Ml-M2 M3-M4 M5-M6 T T t T f T T,t T,t T, t Fig. 2. The models of r. quaker(Nixon) republican(Nixon) hawk(Nixon) dove(Nixon) T, t T, t T T,t T T,t T f T,t T T,t f Fig. 3. The models of A. >, that is defined rules, since it has exceptions. The rules without exceptions are formul",
            {
                "entities": [
                    [
                        75,
                        103,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 86 ( 1996) 269-357 Artificial Intelligence Collaborative plans for complex group action Barbara J. Grosza,*, Sarit Kraus b,c,l a Division of Engineering and Applied Sciences, Harvard ~n~versi~, Cambridge, MA 02138, USA ’ Deparfment of mathematics and Computer Science, Bar Ilan Universi~, Ramat Can, 52900 Israel ’ Institute for Advanced Computer Studies, Universiry of Maryland, College Park, MD 20742, USA Received October 1995 Abstract The original fo~ulation of SharedPlans by B. Grosz and C. Sidner ( 1990) was developed to provide a model of collaborative planning in which it was not necessary for one agent to have toward an act of a different agent. Unlike other contemporaneous approaches (J.R. intentions-to Searle, 1990), this formulation provided for two agents to coordinate their activities without in- troducing any notion of irreducible joint intentions. However, it only treated activities that directly decomposed into single-agent actions, did not address the need for agents to commit to their joint activity, and did not adequately deal with agents having only partial knowledge of the way in which that addresses plans meshes with the definition of SharedPlans. The new definitions also allow for contracting out cer- that results has the features required by Bratrnan’s ( 1992) account tain actions. The formalization (H. Levesque et al., of shared cooperative than alternative accounts 1990; E. Sonenberg et al., 1992). to perform an action. This paper provides a revised and expanded version of SharedPlans ( 1990) definition of individual this reformulation It also reformulates Pollack’s in which a single agent has only partial knowledge; activity and is more general these shortcomings. to handle cases 1. Introduction problem Cooperative and communication. requires solving by teams composed of people and computers activity, is a special type of coordinated collaboration one in which the participants work jointly with each other, together performing a task or carrying out the activities needed to satisfy a shared goal. Because collaborative action comprises actions by different agents, collaborative planning and activity involve the Collaboration * Corresponding author. E-mail: grosz@eecs.harvard.edu. L E-mail: saritObimacs.cs.biu.ac.il. 0004-3702/96/$15.00 Copyright @ 1996 Elsevier Science B.V. All rights reserved. SSDIOOO4-3702(95)00103-4 \f270 B.J. Gras;. S. Kruu.s/Ar/ijicirr/ Intelligence 86 (1996) 269-357 intentions of multiple agents. As a result, collaborative plans cannot be recast simply terms of the plans of individual and intentions process of planning collaboration in treatment of the beliefs planning is modified over the course for is a refinement process: a partial plan description cannot be patched on, but must be designed in the collaboration. Thus, capabilities agents, but require an integrated in from the start [ 23,581. of the different agents involved. Furthermore, the collaborative by the multiple involved agents roles systems together important in dialogues in multi-agent behavior exhibited than previous existing [ 221. The collaborative In this paper we present a formal model of collaborative plans that deals more com- theories of actions, plans, and the plan treatment property of in all modalities and thus is a factor that must be reck- for human-computer pletely with collaboration recognition process. This model grew out of an attempt to provide an adequate of the collaborative dialogue affects communication oned with in developing more advanced regardless of the modality of communication. Communication several for working most multi-agent rate some mechanism require conflicting (see amongst others collectively will perform) entailed. The model presented here is intended puter agents the intentional the avoidance of in itself in some cases agents must decide they (i.e., actions for performing com- for modeling as well as to provide a framework [ 22,43 1. actions. First, communication (see for example also play provides a means I6,13, 14, 16,651) : that are fully collaborative component of dialogue is a necessary part of such capabilities but is not sufficient ). For example, they will take to acting in which the agents need to coordinate and negotiate about responsibilities to plan and act collaboratively; that agents have an ability to achieve shared objectives Second, many multi-agent the basis for constructing incorpo- situations on the approach and collaboration to communicate. the constituent communication their activities the subsidiary [ 19,35,37,67] for agents to provide systems actions actions [ 53,541 together planning in which The original to the situation state model of plans four constituent mental attitudes: of the SharedPlan model of collaborative form a plan to perform a complex action requiring contributing formulation extended Pollack’s mental agents by both agents. Pollack’s definition of the individual plan of an individual an action cr includes certain actions p, would entail performance (2) belief the /?;; (4) an intention Sidner of mental belief). augmenting SharedPlans 1231 two activity to do of “a recipe for cw”; to do each of intentions the /?,. To define SharedPlans, Grosz and actions and aspects (e.g., mutual and that the agent could perform each of the pi; to do Q by doing the p; constituted (3) In subsequent work 142,451, in the context of a dialogue. algorithms were provided to incorporate multi-agent for a pair of agents these components that performance for constructing [23] modified their activities to coordinate state needed ( I) belief of a; agent (e.g., Although overcame in applications this formulation for discourse recognition agent’s actions emerged when we attempted environments multi-agent agent action decomposed not adequately provide for complex activities entailing for meshing of individual several problems with previous models of plan the treatment of intentions of one agent toward another that of speech act theory in that every multi- the model did levels or plans for joint 142,451. First, the original model presumed directly [ I ] ), it had several problems it to dialogue processing action with collaborative joint activity at multiple and complex actions actions. As a result, plans for individual into single-agent to apply \fE.J. Grosz, S. KraudArtijkial Intelligence 86 (1996) 269-357 271 action. Second, the model did not account for the commitment of an agent to the success of a collaborative partner’s actions. 2 Third, the agents who undertake the development of a collaborative plan often do not know a complete recipe for accomplishing their joint action; the model did not provide a sufficient means of describing the mental state of agents in this situation. The notion of a partial Sh~edPl~, to represent this kind of partiality, but was never specified in any detail. One or more of these limitations applies to alternative models developed subsequently [28,29,40, 611. The formulation presented in this paper overcomes each of these deficiencies and thus provides a more complete and accurate model than the original formulation and alternative approaches. SharedPlan*, intended was Collaborative activity must rest eventually on the actions of individual agents; as a result, the collaborative plans of a group of agents must include as constituents the individual plans of group members. These individual plans may be more complex than those accounted for in Pollack’s formulation [53,54] in three ways, First, Pollack’s formulation presumed that an agent had a complete recipe for the action it was per- forming, whereas individual agents, as well as groups of agents, may initially have only partial knowledge of how to perform an action; one function collaborators may serve is to assist an agent in completing a partial recipe. Second, Pollack considered only two types of action relations, generation [20] and enablement; her fo~ali~tion of “simpte plans” uses only generation (and the plans are named “simple” because of this limitation). Balkanski [4] describes several additional action relations that arise in the performance of complex tasks, including sequential and parallel execution. Third, agents may “contract out” to other agents some of the actions to be done. We provide an extended definition of the plans of an individual agent that overcomes these limitations. Because the formal plan definitions are complex, highly recursive and dependent on several new modal operators, in the next section we provide informal descriptions of several examples that motivate the definitions presented in the paper. We will refer to these examples throughout the paper to illustrate the range of collaborative behavior the model is intended to cover and the way in which it does so. Section 3 provides an overview of the formalization and its major distinguishing features. Section 4 presents auxiliary functions, predicates, and modal operators that are used in the plan definitions. It includes a characterization of the different intentional attitudes that play a role in collaborative planning followed by definitions and axioms for them. It also provides definitions of predicates used to modeI an agent’s ability to perform an action given different degrees of partial knowledge about how to perform the action, a property that is essential to the plan definitions; and, it describes certain processes that play central roles in expanding partial plans to more complete ones. Sections 5 and 6 provide the formal plan definitions. At each stage we discuss those aspects of the resulting the- * The last clause of the original definition was intended to ensure this commitment as welt as other properties of coordinated acting. It specified that the agent performing an action intended to do that action to con~bute to the performance of the group action. (See the reply [ 241 for a discussion of replacing the BY operator used in the original definitions by Con",
            {
                "entities": [
                    [
                        67,
                        111,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 500–529Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAllocation and scheduling of Conditional Task GraphsMichele Lombardi, Michela Milano∗DEIS Universita’ di Bologna, Viale Risorgimento, 2, 40136 Bologna, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 29 October 2008Received in revised form 22 February 2010Accepted 22 February 2010Available online 24 February 2010Keywords:Constraint ProgrammingProbabilistic reasoningScenariosConditional Task GraphsConditional constraintsOptimizationWe propose an original, complete and efficient approach to the allocation and schedulingof Conditional Task Graphs (CTGs). In CTGs, nodes represent activities, some of themare branches and are labeled with a condition, arcs rooted in branch nodes are labeledwith condition outcomes and a corresponding probability. A task is executed at run timeif the condition outcomes that label the arcs in the path to the task hold at scheduleexecution time; this can be captured off-line by adopting a stochastic model. Tasks needfor their execution either unary or cumulative resources and some tasks can be executedon alternative resources. The solution to the problem is a single assignment of a resourceand of a start time to each task so that the allocation and schedule is feasible in eachscenario and the expected value of a given objective function is optimized. For thisproblem we need to extend traditional constraint-based scheduling techniques in twodirections: (i) compute the probability of sets of scenarios in polynomial time, in orderto get the expected value of the objective function; (ii) define conditional constraintsthat ensure feasibility in all scenarios. We show the application of this framework onproblems with objective functions depending either on the allocation of resources to tasksor on the scheduling part. Also, we present the conditional extension to the timetableglobal constraint. Experimental results show the effectiveness of the approach on a set ofbenchmarks taken from the field of embedded system design. Comparing our solver with ascenario based solver proposed in the literature, we show the advantages of our approachboth in terms of execution time and solution quality.© 2010 Elsevier B.V. All rights reserved.1. IntroductionConditional Task Graphs (CTG) are directed acyclic graphs whose nodes represent activities, linked by arcs representingprecedence relations. Some of the activities are branches and are labeled with a condition; at run time, only one of the suc-cessors of a branch is chosen for execution, depending on the occurrence of a condition outcome labeling the correspondingarc. The truth or the falsity of those condition outcomes is not known a priori: this sets a challenge for any off-line designapproach, which should take into account the presence of such elements of uncertainty. A natural answer to this issue isadopting a stochastic model. Each activity has a release date, a deadline and needs a resource to be executed. The problemis to find a resource assignment and a start time for each task such that the solution is feasible whatever the run timescenario is and such that the expected value of a given objective function is optimized. We take into account differentobjective functions: those depending on the resource allocation of tasks and those depending on the scheduling side of theproblem.* Corresponding author.E-mail address: michela.milano@unibo.it (M. Milano).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.004\fM. Lombardi, M. Milano / Artificial Intelligence 174 (2010) 500–529501Fig. 1. Some pseudo-code and a its translation into a CTG.CTG are ubiquitous to a number of real life problems. In compilation of computer programs [13], for example, CTGs areused to explicitly take into account the presence of conditional instructions. Similarly, in the field of system design [39],CTGs are used to describe applications with if-then-else statements; in this case tasks represent processes and arcs are datacommunications. Once a hardware platform and an application is given, to design a system amounts to allocate platformresources to processes and to compute a schedule; in this context, taking into account branches allows better resource usage,and thus lower costs. CTG may be used also in the Business Process Management (BPM) [34] and in workflow management[30], as a mean of describing operational business processes with alternative control paths.For solving the allocation and scheduling problem of CTG we need to extend the traditional constraint based techniqueswith two ingredients. First, to compute the expected value of the objective function, we need an efficient method forreasoning on task probabilities in polynomial time. For example, we have to compute the probability a certain task executesor not, or, more in general, the probability of a given set of scenarios with uniform features (e.g. the same objective functionvalue). Second, we need to extend traditional constraints to take into account the feasibility in all scenarios.For this purpose, we define a data structure called Branch/Fork Graph – BFG. We show that if the CTG satisfies a propertycalled Control Flow Uniqueness – CFU, the above mentioned probabilities can be computed in polynomial time. CFU is aproperty that holds in a number of interesting applications, such as for example the compilation of computer programs,embedded system design and in structured business processes.The paper is organized as follows: Section 2 presents some applications where CTG is a convenient representation ofproblem entities and their relations; in Section 3 we provide some preliminary notions on Constraint-Based Scheduling.Section 4 introduces the concept of Conditional Task Graphs, Control Flow Uniqueness, sample space and scenarios anddefines the scheduling and allocation problem we consider. In Section 5 we define the data structure used for implementingefficient probabilistic reasoning, namely the Branch/Fork Graph and related algorithms. In Section 6 we use these algorithmsfor efficiently computing the expected value of three objective function types, while in Section 7 we exploit the BFG forimplementing the conditional variant of the timetable global constraint. Section 8 discusses related work and Section 9shows experimental results and a comparison with a scenario based approach.2. Applications of CTGsConditional Task Graphs can be used as a suitable data structure for representing activities and their temporal relationsin many real life applications. In these scenarios, CTG allocation and scheduling becomes a central issue.In compilation of computer programs [13], for example, CTGs are used to explicitly take into account the presenceof conditional instructions. For instance, Fig. 1 shows a simple example of pseudo-code and a natural translation intoa CTG; here each node corresponds to an instruction and each branch node to an “if” test; branch arcs are label withthe outcome they represent. In this case, probabilities of condition outcomes can be derived from code profiling. Clearly,computer programs may contain loops that are not treated in CTGs, but modern compilers adopt the loop unrolling [17]technique that can be used here for obtaining cycle free task graphs.Similarly, in the field of embedded system design [39] a common model to describe a parallel application is the taskgraph. The task graph has a structure similar to a data flow graph, except that the tasks in a task graph represent largerunits of functionality. However, a task graph model that has no control dependency information can only capture datadependency in the system specification. Recently, some researchers in the co-synthesis domain have tried to use conditionaltask graph to capture both data dependencies and control dependencies of the system specification [42,18]. Once a hardwareplatform and an application is given, to design a system amounts to allocate platform resources to processes and to computea schedule; in this context, taking into account branches allows better resource usage, and thus lower costs. However, thepresence of probabilities makes the problem extremely complex since the real time and quality of service constraints shouldbe satisfied for any execution scenario. Embedded system design applications will be used in this paper to experimentallyevaluate the performance and quality of our approach.CTG appear also in Business Process Management (BPM) [34] and in workflow management [30] as a mean of describingoperational business processes with alternative control paths. Workflows are instances of workflow models, that are repre-sentations of real-world business processes [41]. Basically workflow models consist of activities and the ordering amongstthem. They can serve different purposes: they can be employed for documentation of business processes or can be used asinput to a Workflow Management System that allows their machine-aided execution.\f502M. Lombardi, M. Milano / Artificial Intelligence 174 (2010) 500–529One of the most widely used systems for representing business processes is BPEL [27]. BPEL is a graph-structured lan-guage and allows to define a workflow model using nodes and edges. The logic of decisions and branching is expressedthrough transition conditions and join conditions. Transition conditions and join conditions are both Boolean expressions.As soon as an activity is completed, the transition conditions on their outgoing links are evaluated. The result is set as thestatus of the link, which is true or false. Afterwards, the target of each link is visited. If the status of all incoming links isdefined, the join condition of the activity is evaluated. If the join condition evaluates to false, the activity is called dead andthe status of all its outgoing links is set to false. If the join condition evaluates",
            {
                "entities": [
                    [
                        136,
                        188,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 748–788Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPractical solution techniques for first-order MDPs ✩Scott Sanner a,∗, Craig Boutilier ba Statistical Machine Learning Group, National ICT Australia, Canberra, ACT, 0200, Australiab Department of Computer Science, University of Toronto, Toronto, ON M5S 3H5, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 21 October 2007Received in revised form 4 November 2008Accepted 9 November 2008Available online 24 November 2008Keywords:MDPsFirst-order logicPlanningin the number of domain objects and exponentialMany traditional solution approaches to relationally specified decision-theoretic planningproblems (e.g., those stated in the probabilistic planning domain description language,or PPDDL) ground the specification with respect to a specific instantiation of domainobjects and apply a solution approach directly to the resulting ground Markov decisionprocess (MDP). Unfortunately, the space and time complexity of these grounded solutionapproaches are polynomialin thepredicate arity and the number of nested quantifiers in the relational problem specification.An alternative to grounding a relational planning problem is to tackle the problem directlyat the relational level. In this article, we propose one such approach that translates anexpressive subset of the PPDDL representation to a first-order MDP (FOMDP) specificationand then derives a domain-independent policy without grounding at any intermediate step.However, such generality does not come without its own set of challenges—the purpose ofthis article is to explore practical solution techniques for solving FOMDPs. To demonstratethe applicability of our techniques, we present proof-of-concept results of our first-orderapproximate linear programming (FOALP) planner on problems from the probabilistic trackof the ICAPS 2004 and 2006 International Planning Competitions.Crown Copyright © 2008 Published by Elsevier B.V. All rights reserved.1. IntroductionThere has been an extensive line of research over the years aimed at exploiting structure in order to compactly repre-sent and efficiently solve decision-theoretic planning problems modeled as Markov decision processes (MDPs) [12]. Whiletraditional approaches from operations research typically use enumerated state and action models [62], these have provedimpractical for large-scale AI planning tasks where the number of distinct states in a model can easily exceed the limits ofprimary and secondary storage on modern computers.Fortunately, many MDPs can be compactly described by using a factored state and action representation and exploitingvarious independences in the reward and transition functions [12]. The independencies and regularities laid bare by suchrepresentations can often be exploited in exact and approximate solution methods as well. Such techniques have permittedthe practical solution of MDPs that would not have been possible using enumerated state and action models [22,36,38,75].However, factored representations are only one type of structure that can be exploited in the representation of MDPs.Many MDPs can be described abstractly in terms of classes of domain objects and relations between those domain objectsthat may change over time. For example, a logistics problem specified in the probabilistic planning domain description✩Parts of this article appeared in preliminary form in [S. Sanner, C. Boutilier, Approximate linear programming for first-order MDPs, in: Uncertainty inArtificial Intelligence (UAI-05), Edinburgh, Scotland, 2005, pp. 509–517; S. Sanner, C. Boutilier, Practical linear evaluation techniques for first-order MDPs,in: Uncertainty in Artificial Intelligence (UAI-06), Boston, MA, 2006].* Corresponding author.E-mail address: ssanner@nicta.com.au (S. Sanner).0004-3702/$ – see front matter Crown Copyright © 2008 Published by Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.11.003\fS. Sanner, C. Boutilier / Artificial Intelligence 173 (2009) 748–788749language (PPDDL) [89] may refer to domain objects such as boxes, trucks, and cities. If the objective is to deliver all boxesto their assigned destination cities then the locations of these boxes and trucks may change as a result of actions takenin pursuit of this objective. Since action templates such as loading or unloading a box are likely to apply generically todomain objects and can be specified independently of any ground domain instantiation (e.g., 4 trucks, 5 boxes, and 9 cities),this permits compact MDP descriptions by exploiting the existence of domain objects, relations over these objects, and theability to express objectives and action effects using quantification.Unfortunately, while relational specifications such as PPDDL permit very compact, domain-independent descriptions ofa variety of MDPs, this compactness does not translate directly to effective solutions of the underlying planning problems.For example, one approach to solving a relational decision-theoretic planning problem might first construct sets of statevariables and actions for all possible ground instantiations of each relation and action with respect to a specific domain(e.g., 4 trucks, 5 boxes, and 9 cities). Then this approach might apply known solution techniques to this ground factoredrepresentation of an MDP. Unfortunately, such an approach is domain-specific; and the size of the ground MDP growspolynomially in the number of domain objects, and exponentially in the predicate arity and the number of nested quantifiersin the problem specification. For sufficiently large domains and complex relational MDP specifications, grounding may notbe a viable option.An alternative approach to grounding is to apply a solution approach directly at the relational level. In this article,we discuss one such technique that translates an expressive subset of the relational PPDDL representation to a first-orderMDP (FOMDP) [14] specification. A symbolic policy may then be derived with respect to this FOMDP, resulting in a domain-independent solution that exploits a purely lifted version of the Bellman equations and avoids grounding at any intermediatestep. This stands in contrast to alternate first-order approaches discussed in Section 6.2 that induce symbolic representationsof the solution from samples of the Bellman equation in ground problem instances.Unfortunately, the use of first-order logical languages to describe our FOMDP specification and solution introduces theneed for computationally expensive logical simplification and theorem proving. While this means that exact solutions arenot tractable for many FOMDPs, there is often a high degree of regularity and structure present in many FOMDPs that canbe exploited by the approximate (heuristic) solution techniques proposed in this article. To this end, this article continuesthe tradition of exploiting structure to find effective solutions for large MDPs.After providing a review of MDPs and relevant solution techniques in Section 2 and the FOMDP formalism and itssolution via symbolic dynamic programming [14] in Section 3, we make the following contributions to the practical solutionof FOMDPs:(1) Section 3.2.2: We show how to translate a subset of PPDDL problems including universal and conditional effects toFOMDPs.(2) Section 4.1: We show how to exploit the logical structure of reward, value, and transition functions using first-orderextensions of algebraic decision diagrams (ADDs) [4] for use in both exact and approximate FOMDP solutions.(3) Section 4.2: We apply additive decomposition techniques to universal reward specifications in a manner that leads toefficient solutions for our FOMDP representation and reasonable empirical performance on example problems.(4) Section 5.3: We show how to generalize the approximate linear programming technique for MDPs [19,36,72] to the caseof FOMDPs by casting the optimization problem in terms of a first-order linear program.(5) Section 5.4: We define a linear program (LP) with first-order constraints and provide a constraint generation algorithmthat utilizes a relational generalization of variable elimination [91] to exploit constraint structure in the efficient solutionof this first-order LP (FOLP).To demonstrate the efficacy of our techniques, we present proof-of-concept results of our first-order approximate linearprogramming (FOALP) planner on problems from the probabilistic track of the ICAPS 2004 and 2006 International Plan-ning Competitions in Section 5.6. Following this, we discuss a number of related first-order decision-theoretic planningapproaches and discuss the relative advantages and disadvantages of each in Section 6. We conclude with a discussion ofpossible extensions to our techniques in Section 7.2. Markov decision processesMarkov decision processes (MDPs) were first introduced and developed in the fields of operations research and eco-nomics [6,41,73]. The MDP has since been adopted as a model for decision-theoretic planning with fully observable state inthe field of artificial intelligence [7,8,12] and as such provides the formal underpinning for the framework that we describein this article. In this section, we describe various algorithmic approaches for making optimal sequential decisions in MDPsthat we later generalize to the case of first-order MDPs. The following presentation derives from Puterman [62].2.1. The MDP model and optimality criteriaFormally, a finite state and action MDP is specified by a tuple (cid:3)S, A, T , R, h, γ (cid:4). S is a set of distinct states. An agentin an MDP can effect changes to its state by executing actions from the set A. We base our initial presentation in thissection on finite state and action MDPs; but in much of what follows, we will assume an infinite, discrete state and action\f750S. Sanner, C. Boutilier / Artificial Intelligence 173 (2009) 748–788space. The standard techniques for",
            {
                "entities": [
                    [
                        136,
                        186,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 199–200 (2013) 45–66Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLifting integrity constraints in binary aggregationUmberto Grandi∗, Ulle EndrissInstitute for Logic, Language and Computation, University of Amsterdam, Postbus 94242, 1090 GE Amsterdam, The Netherlandsa r t i c l ei n f oa b s t r a c tWe consider problems in which several individuals each need to make a yes/no choiceregarding a number of issues and these choices then need to be aggregated into a collectivechoice. Depending on the application at hand, different combinations of yes/no may beconsidered rational. We describe rationality assumptions as integrity constraints using asimple propositional language and we explore the question of whether or not a givenaggregation procedure willlift a given integrity constraint from the individual to thecollective level, i.e., whether the collective choice will be rational whenever all individualchoices are.© 2013 Elsevier B.V. All rights reserved.Article history:Received 25 April 2012Received in revised form 24 April 2013Accepted 3 May 2013Available online 6 May 2013Keywords:Collective decision makingComputational social choiceMulti-issue domainsCombinatorial voteJudgment aggregation1. IntroductionSocial Choice Theory (SCT) is the study of mathematical models for collective decision making. In recent times, this disci-pline has received increasing attention in Artificial Intelligence (AI), as testified by a large number of papers on social choiceat the major AI conferences and by the creation of an entirely new research agenda under the name of Computational SocialChoice [6]. There are several good reasons for this trend. On the one hand, a number of methods developed in AI and, moregenerally, in Computer Science have turned out to be useful to deepen our understanding of social choice and, in somecases, can even suggest an entirely new perspective on classical problems. Examples include the complexity-theoretic analy-sis of optimisation problems arising in social choice [15,16] and the creation of new choice procedures inspired by classicaltechniques in knowledge representation [27]. On the other hand, methods from SCT have natural important applications inAI. They can, e.g., be employed to achieve consensus amongst the autonomous software agents in a multiagent system [39],to aggregate the output of several search engines [2], or to inform the design of online recommender systems [34]. Oneparticular problem of interest for AI is the case of social choice in combinatorial domains, in which the space of alternativesfrom which the individuals have to choose has a multi-attribute structure [26,7]. Classical examples include voting in mul-tiple referenda, where we have to decide which of a set of propositions to accept, or electing a committee, where we haveto decide how to fill each seat. There have been several attempts to tackle the high complexity that arises in this context byusing tools from AI, such as methods for modelling preferences inspired by knowledge representation [28,38]. Finally, SCTprovides tools for the analysis of collective choices of groups of agents, and as such is of immediate relevance to the studyof multiagent systems.A central problem in SCT, and, in view of our previous discussion, in all its applications to AI, is the problem of ag-gregation: Suppose a group of agents each supply a particular piece of information regarding a common problem and wewant to aggregate this information into a collective view to obtain a summary of the individual views provided. A classical* Corresponding author at: Department of Mathematics, University of Padova, Via Trieste 63, 35121 Padova, Italy. Tel.: +39 (0) 498271357; fax: +39 (0)498271499.E-mail addresses: umberto.uni@gmail.com (U. Grandi), ulle.endriss@uva.nl (U. Endriss).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.05.001\f46U. Grandi, U. Endriss / Artificial Intelligence 199–200 (2013) 45–66example is that of preferences [3]: each agent declares their individual preferences over a set of alternatives by providingan ordering over this set, and we are asked to amalgamate this information into a collective ranking that represents theindividual preferences provided. The same methodology has also been applied more recently to a number of other types ofinformation, such as beliefs [23,24] and judgments [29].One of the main features of the study of aggregation is the problem of collective rationality: given a rationality assumptionthat bounds the choices of the individuals, we ask whether the output of an aggregator still satisfies the same rationalityassumption. To understand this problem better, consider the following example: three autonomous agents need to decideon whether to perform a collective action. This action is performed if two parameters are estimated to exceed a certainthreshold. We can model the choice situation with a multi-attribute domain in which there are three issues at stake: “thefirst parameter is above the threshold” (T 1), “the second parameter is above the threshold” (T 2), and “the action should beperformed” ( A). The rationality assumption that links the three issues together can be modelled using a simple propositionalformula, namely T 1 ∧ T 2 → A. The individual views on the three issues are then aggregated using the majority rule, whichaccepts an issue if a majority of the individual agents do. Consider now the following situation:Agent 1Agent 2Agent 3MajorityT 1YesNoYesYesT 2YesYesNoYesAYesNoNoNoIn the situation described above the collective action A is not performed, even though a majority of the individuals thinkthat the first parameter exceeds the threshold and a (different) majority agree that also the second parameter exceeds thethreshold. Situations like the one above are considered paradoxical: even if each individual agent is rational (i.e., each ofthem satisfies the rationality assumption), the collective view derived using the majority rule is not. That is, the majorityrule fails to lift the integrity constraint T 1 ∧ T 2 → A from the individual to the collective level. This example shows thatthe majority rule violates collective rationality in certain specific cases. Similar examples can be devised for a number ofdifferent situations ranging from voting to rank aggregation, to the development of a collective judgment in court cases.Classical work in SCT was restricted to particular studies of collective rationality in a given aggregation situation and fora given class of aggregation procedures. Dokow and Holzman [11], for instance, characterise binary domains of aggregationover which every procedure that satisfies certain desirable axiomatic properties, namely, independence and unanimity, isdictatorial (see Section 8). This is a good example for the use of the axiomatic method in economic theory: the aim is toidentify the appropriate set of axiomatic properties (e.g., to model real-world economies, specific moral ideals, etc.) andthen to prove a characterisation (or impossibility) result for those axioms. Given the wide variety of potential applicationsin AI, on the other hand, in this context we require instead a systematic study that, depending on the situation at hand,can give answers to the problem of collective rationality. With every new application the principles underlying a systemmay change; so we may be more interested in devising languages for expressing a range of different axiomatic propertiesrather than identifying the “right” set of axioms; and we may be more interested in developing methods that will help usto understand the dynamics of a range of different social choice scenarios rather than in technical results for a specific suchscenario.In this paper we put forward a general framework that encompasses most of the classical studies of collective rationalityin SCT, and that can prove useful to diverse research areas in AI. We base our framework on binary aggregation, in whichindividuals are required to choose from a multi-issue domain where issues represent different binary choices. Classicalframeworks for the study of aggregation, such as preference and judgment aggregation, can be embedded in this framework.We model rationality assumptions using a simple propositional language, and we give a precise definition of collectiverationality with respect to a given rationality assumption. We classify rationality assumptions with respect to their syntacticproperties, and we give a systematic treatment of the question of how to relate collective rationality with respect to asyntactically defined sublanguage to classical axiomatic properties from SCT. For instance, we have already seen that themajority rule is not collectively rational with respect to the integrity constraint T 1 ∧ T 2 → A. It is also not collectivelyrational with respect to the 3-clause T 1 ∨ T 2 ∨ A: to see this, consider a scenario with three agents, where each agentaccepts exactly one issue, and no two agents accept the same issue. On the other hand, as we shall see, any 2-clause willalways be lifted, i.e., the majority rule is collectively rational with respect to the language of 2-clauses. We will then beable to describe the majority rule in terms of classical axioms (see Proposition 2) or in terms of the subset of integrityconstraints it lifts (see Theorem 28). It is results of this kind that we shall explore in depth in this paper, establishing a linkbetween standard axiomatic requirements from SCT and collective rationality with respect to fragments of the propositionallanguage.This paper expands our initial work on this topic [20], complementing it with further results from previous work [21,19,18].The paper is organised as follows. We begin by defining the basic notions that constitute the framework of binaryaggregation with integrity constraints in Section 2. In this secti",
            {
                "entities": [
                    [
                        147,
                        198,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 223 (2015) 65–81Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOptimizing ontology alignments through a Memetic Algorithm using both MatchFmeasure and Unanimous Improvement RatioXingsi Xue a,b, Yuping Wang a,∗a School of Computer Science and Technology, Xidian University, Xi’an, Shaanxi, Chinab School of Information Science and Engineering, Fujian University of Technology, Fuzhou, Fujian, Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 1 April 2014Received in revised form 14 February 2015Accepted 1 March 2015Available online 5 March 2015Keywords:Ontology alignmentMemetic AlgorithmMatchFmeasureUnanimous Improvement RatioThere are three main drawbacks of current evolutionary approaches for determining the weights of ontology matching system. The first drawback is that it is difficult to simultaneously deal with several pairs of ontologies, i.e. finding a universal weight configuration that can be used for different ontology pairs without adjustment. The second one is that a reference alignment between two ontologies to be aligned should be given in advance which could be very expensive to obtain especially when the scale of ontologies is considerably large. The last one arises from f-measure, a generally used evaluation metric of the alignment’s quality, which may cause the bias improvement of the solution. To overcome these three defects, in this paper, we propose to use both MatchFmeasure, a rough evaluation metric on no reference alignment to approximate f-measure, and Unanimous Improvement Ratio (UIR), a measure that complements MatchFmeasure, in the process of optimizing the ontology alignments by Memetic Algorithm (MA). The experimental results have shown that the MA using both MatchFmeasure and UIR is effective to simultaneously align multiple pairs of ontologies and avoid the bias improvement caused by MatchFeasure. Moreover, the comparison with state-of-the-art ontology matching systems further indicates the effectiveness of the proposed method.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOntologies are regarded as the solution to data heterogeneity on the semantic web. However, because of human sub-jectivity, the ontologies could themselves introduce heterogeneity: given two ontologies, one entity can be given different names or simply be defined in different ways. Addressing this heterogeneity problem requires to identify correspondences between entities of various ontologies. This process is commonly known as ontology alignment which can be described as follows: given two ontologies with each describing a set of discrete entities (which can be classes, properties, instances, etc.), we have to find the relationships (e.g., equivalence or subsumption) that hold between these entities [1].It is highly impractical to align the ontologies manually when the size of ontologies is considerably large. Thus, numerous ontology matching systems have arisen over the years. Each of them could provide, in a fully automatic or semi-automatic way, a numerical value of similarity between elements from separate ontologies that can be used to decide whether those * Corresponding author.E-mail address: ywang@xidian.edu.cn (Y. Wang).http://dx.doi.org/10.1016/j.artint.2015.03.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f66X. Xue, Y. Wang / Artificial Intelligence 223 (2015) 65–81elements are semantically similar or not. Since none of the similarity measures could provide the satisfactory result inde-pendently, most ontology matching systems combine a set of different similarity measures together by aggregating their aligning results. How to select the appropriate similarity measures, weights and thresholds in ontology aligning process in order to obtain a satisfactory alignment is called meta-matching which can be viewed as an optimization problem and be addressed by evolutionary approaches like Memetic Algorithms (MA).Since modeling the meta-matching problem is a complex (nonlinear problem with many local optimal solutions) and time-consuming task (large scale problem), particularly when the number of similarity measures is significantly large, ap-proximate methods are usually used for computing the parameters. From this point of view, evolutionary optimization methods could represent an efficient approach for addressing this problem. However, the slow convergence and premature convergence are two main shortcomings of the classical evolutionary algorithms (e.g. Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) algorithm) for this kind of problem. It makes these algorithms incapable of effectively searching the optimal solution for large scale and complex problems. Starting from these considerations, our work investigates the methodology of using an emergent class of evolutionary algorithms, named Memetic Algorithms (MA), to efficiently tackle the meta-matching problem. MA is a population-based search method which combines genetic algorithms (global search) and local refinements (local search). This marriage between global search and local search allows keeping high population diversity via strong mutation (thus, reducing the possibility of the premature convergence) and increasing the convergence speed via the local search (in fact, local search can greatly improve the solution quality and thus make the solution ap-proaches to optimal solution more quickly). Therefore, MA is very suitable to the problem considered.Nevertheless, there are three main drawbacks of current evolutionary approaches for determining the weights of ontology matching systems. The first drawback is that it is difficult to simultaneously deal with several pairs of ontologies, i.e. finding a universal weight configuration that can be used for different ontology pairs without adjustment. The second one is that a reference alignment between two ontologies to be aligned should be given in advance which could be very expensive to obtain especially when the scale of ontologies is considerably large. The last one arises from f-measure, a generally used evaluation metric of the ontology alignment’s quality, which may cause the bias improvement of the solution. To be specific, the improvement of f-measure does not say anything about whether both evaluation metrics involved (i.e. recall and precision) are simultaneously improved or not. In other words, no matter how large a measured improvement in f-measure is, it can still be extremely dependent on how we are weighting the evaluation metrics involved. To overcome these three defects, in this paper, we propose to use both MatchFmeasure, a rough evaluation metric on no reference alignment to approximate f-measure, and Unanimous Improvement Ratio (UIR) [27], a measure that complements MatchFmeasure, in the process of optimizing the ontology alignments by Memetic Algorithm (MA). In particular, our proposed method applies to the specific scenario that the target ontologies are the variations of the same source ontology. For example, given a source ontology O A , three target ontologies O B , O C and O D which are different variations of O A in terms of different lexical, linguistic and ontology structure respectively, the goal of our proposed method is to determine the optimal parameters, in terms of both MatchFmeasure and UIR, for the ontology matching tasks that match O A with O B , O A with O C and O Awith O D respectively. Moreover, the obtained parameter set could be reused in the task of matching O A with O E which is another target ontology that has different lexical, linguistic and ontology structure from O A at the same time.The remainder of the paper is organized as follows: Section 2 gives a brief foundation of our work; Section 3 presents the related work about MA and evolutionary algorithm for the ontology alignment problem; Section 4 provides a detailed description of the basic concepts of the similarity measures, the aggregation strategy and the ontology alignment evaluation metrics; Section 5 presents the details of MA based on MatchFmeasure and UIR; Section 6 shows the experimental results of our approach; finally, in Section 7, we draw conclusions and propose the future improvement.2. FoundationThere are numerous definitions of ontology over years. But the most frequently referenced one was given by Gruber in 1993 which defined the ontology as an explicit specification of a conceptualization. For the convenience of understanding the work in this paper, the ontology is defined as following:Definition 1. (See [25].) An ontology is a 9-tuple O = (C, P , I, A, ≤C , ≤P , φC P , φC I , φP I ), where:• C is a nonempty set of classes,• P is a nonempty set of properties,• I is a set of instances (it can be empty),• A is a set of axioms which should not be empty,• ≤C is a partial order on C , called class hierarchy or taxonomy,• ≤P is a partial order on P , called property hierarchy,• φC P : P → C × C is a function which associates a property p ∈ P with two linked classes through the property p. We denote the domain by dom(p) := π1(φC P (p)) and the range by ran(p) := π2(φC P (p)) where π1() and π2() are two functions obtaining the domain class and range class respectively,• φC I : C → P(I) is a function which associates a concept c ∈ C with a subset of I representing the instances of the concept c,\fX. Xue, Y. Wang / Artificial Intelligence 223 (2015) 65–8167• φP I : P → P(I 2) is a function which associates a property p ∈ P with a subset of Cartesian product I × I representing the pair of instances related through the property p.In general, classes, properties and individuals are referred as entities.At present, ontologies are viewed as a practical way to conceptualize information that is expressed in electronic for-mat, and are used in many applications from different areas. However, certain systems that encompass a large number of components associated with different domains would ge",
            {
                "entities": [
                    [
                        134,
                        249,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 670–684Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMonte Carlo tree search in KriegspielPaolo Ciancarini∗, Gian Piero FaviniDipartimento di Scienze dell’Informazione, University of Bologna, Italya r t i c l ei n f oa b s t r a c tArticle history:Received 20 September 2009Received in revised form 4 April 2010Accepted 4 April 2010Available online 9 April 2010Keywords:GamesChessKriegspielIncomplete informationMonte Carlo tree search1. IntroductionPartial information games are excellent examples of decision making under uncertainty. Inparticular, some games have such an immense state space and high degree of uncertaintythat traditional algorithms and methods struggle to play them effectively. Monte Carlo treesearch (MCTS) has brought significant improvements to the level of computer programsin games such as Go, and it has been used to play partial information games as well.However, there are certain games with particularly large trees and reduced informationin which a naive MCTS approach is insufficient: in particular, this is the case of gameswith long matches, dynamic information, and complex victory conditions. In this paper weexplore the application of MCTS to a wargame-like board game, Kriegspiel. We describe andstudy three MCTS-based methods, starting from a very simple implementation and movingto more refined versions for playing the game with little specific knowledge. We comparethese MCTS-based programs to the strongest known minimax-based Kriegspiel program,obtaining significantly better experimental results with less domain-specific knowledge.© 2010 Elsevier B.V. All rights reserved.Partial information games provide a good model and testbed for many real-world situations involving decision mak-ing under uncertainty. They can be very difficult for a computer program to play well. These games typically require acombination of complex tasks such as heuristic search, belief state reconstruction, and opponent modeling.Moreover, some games are particularly challenging because at any time the number of possible, indistinguishable statesfar exceeds the storage and computational abilities of present-day computers. In this paper, the focus is on one such game,Kriegspiel or invisible chess. The game is interesting for at least three reasons. Firstly, its rules are identical to those of Chess,a very well-known game; however, the players’ perception of the board is different, only being able to see their own pieces.Secondly, it is a game with a huge number of states and limited means of acquiring information. Finally, the nature ofuncertainty is entirely dynamic. These issues put Kriegspiel in a category different from other partial information gamessuch as Stratego or Phantom Go (the partial information variant of Go [1]), wherein a newly discovered piece of informationremains valid for the rest of the game. Information in Kriegspiel is scarce, precious, and ages fast.In fact, even if it is an old game, well known to game theorists and even discussed by von Neumann and Morgensternin [2] under the name of blind chess, the first attempt to build an effective Kriegspiel playing program came only in 2005and was based on Monte Carlo sampling [3]. It was, however, defeated by our first program, described in [4] and based ona form of minimax on a game tree of data structures called metapositions. These had been first defined in [5] for a partialinformation variant of Shogi, that is Japanese Chess. Our program was better than other competing programs, but was notgood enough to compete with the best human players.* Corresponding author.E-mail address: cianca@cs.unibo.it (P. Ciancarini).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.017\fP. Ciancarini, G.P. Favini / Artificial Intelligence 174 (2010) 670–684671Fig. 1. The four phases of Monte Carlo tree search: selection, expansion, simulation and backpropagation.In this paper we present and study different ways of applying Monte Carlo tree search to Kriegspiel. Monte Carlo treesearch has been imposing itself over the past years as a major tool for games in which traditional minimax techniquesdo not yield good results due to the size of the state space and the difficulty of crafting an adequate evaluation function.The game of Go is the primary example, albeit not the only one, of a tough environment for minimax where Monte Carlotree search was able to improve the level of computer programs considerably [6,7]. Since Kriegspiel shares the two traits ofbeing a large game and a difficult one to express with an evaluation function (unlike its complete information counterpart),it is only natural to test a similar approach.The paper is organized as follows. Section 2 contains a high-level introduction to Monte Carlo tree search (MCTS), withan emphasis on its successful application to Phantom Go. In Section 3, we introduce the game of Kriegspiel, its rules,and what makes it similar, yet very different, to Phantom Go. Section 4 contains the most significant research results onKriegspiel, especially those related to previous Monte Carlo methods. We give a high-level view of three MCTS approachesin Section 5, showing how they are similar and where they differ; the corresponding programs are then described in greaterdetail separately. Section 6 contains some experimental tests comparing the strength and the performance of the variousprograms. Finally, we give our conclusions and some future research directions in Section 7.2. Monte Carlo tree searchMonte Carlo tree search (MCTS) is an evolution of some simpler and older methods based on Monte Carlo sampling.While the core concept is still the same – a program plays a large number of random simulated games and picks the movethat seems to yield the highest victory ratio – the purpose of MCTS is to make the computation converge to the right valuemuch more quickly than pure Monte Carlo. This is accomplished by guiding the simulations with a game tree that grows toaccommodate new nodes over time; more promising nodes are, in theory, reached first and visited more often than nodesthat are likely to be unattractive.MCTS is an iterative method that performs the same four steps until its available time runs out. These steps are summa-rized in Fig. 1.• Selection. The algorithm selects a leaf node from the tree based on the number of visits and their average value.• Expansion. The algorithm optionally adds new nodes to the tree.• Simulation. The algorithm somehow simulates the rest of the game one or more times, and returns the value of thefinal state (or their average, if simulated multiple times).• Backpropagation. The value is propagated to the node’s ancestors up to the root, and new average values are computedfor these nodes.After performing these phases as many times as time allows, the program chooses the root’s child that has received themost visits and plays the corresponding move. This may not necessarily coincide with the node with the highest meanvalue. A discussion about why the mean operator alone does not make a good choice is contained in [8].\f672P. Ciancarini, G.P. Favini / Artificial Intelligence 174 (2010) 670–684MCTS should be thought of as a method rather than a specific algorithm, in that it does not dictate hard policies forany of the four phases. It does not truly specify how a leaf should be selected, when a node should be expanded, howsimulations should be conducted or how their values should be propagated upwards. In practice, however, game-playingprograms tend to use variations of the same algorithms for several of the above steps.Selection as a task is similar in spirit to the n-bandit problem since the program needs to strike a balance betweenexploration (devoting some time to new nodes) and exploitation (directing the simulations towards nodes that have shownpromise so far). For example, programs can make use of the UCT algorithm (Upper Confidence bound applied to Trees) firstgiven in [6]. This algorithm chooses at each step the child node maximizing the quantity(cid:2)U i = v i + cln Nni,where v i is the value of node i, N is the number of times the parent node was visited, ni is the number of times node iwas visited, and c is a constant that favors exploitation if low, and exploration if high.Expansion varies dramatically depending on the game being considered, its state space and branching factor. In gen-eral, most programs will expand a node after it has been visited a sufficient number of times. Simulation also dependswildly on the type of game. There is a large literature dealing with MCTS simulation strategies for the game of Go alone.Backpropagation offers the problem of which backup operator to use when calculating the value of a node.2.1. MCTS and partial information in Phantom GoMonte Carlo tree search has been used successfully in large, complex partial information games, most notably PhantomGo. This game is the partial information version of the classic game of Go: the player has no direct knowledge of hisopponent’s stones, but can infer their existence if he tries to put his own stone on an intersection and discovers he isunable to. In that case, he can try another move instead. [1] describes an MCTS algorithm for playing the game, obtaininga good playing strength on a 9 × 9 board. A thorough comparison of several Monte Carlo approaches to Phantom Go, withor without tree search, has recently been given in [9]. We are especially interested in Phantom Go because its state spaceand branching factor are much larger than most other (already complex) partial information games such as poker, for whichgood Monte Carlo strategies exist; see, for example, [10].MCTS algorithms for Phantom Go are relatively straightforward in that they mostly reuse knowledge and methods fromtheir Go counterparts: in fact, they mostly differ from Go programs because in the simulation phase the st",
            {
                "entities": [
                    [
                        136,
                        173,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER. Artificial Intelligence 102 (1998) 143-155 Artificial Intelligence A unifying approach to temporal constraint reasoning Peter Jonsson *, Christer Biickstriim ’ Department of Computer and Information Science, Linkiiping University, S-581 83 LinkOping, Sweden Received 25 September 1997 Abstract We present a formalism, Disjunctive Linear Relations constraints. DLRs subsume most of the formalisms the literature and is therefore computationally Horn DLRs, which have a polynomial-time to tractable algebra by Nebel and Btirckert and the simple temporal constraints by Dechter et al. Thus, DLRs is a suitable unifying formalism for reasoning about temporal constraints. 0 1998 Elsevier Science B.V. All rights reserved. for reasoning about temporal in type of DLRs, satisfiability problem. We prove that most approaches the ORD-Horn (DLRs), for temporal constraint expensive. We also present a restricted temporal constraint reasoning can be encoded as Horn DLRs, including reasoning proposed Keywords: Temporal constraint reasoning; Disjunctive linear relations; Complexity; Algorithms 1. Introduction Reasoning about temporal knowledge abounds [4,11]. In most applications, other areas, such as planning biology terms of collections of relations between tasks include determining from those formalisms; information., relations between in artificial intelligence [2], natural language understanding knowledge of temporal constraints applications and [23] and molecular in is expressed time intervals or time points. Typical reasoning the satisfiability of such collections and deducing new relations that are known. The research has largely concentrated systems of inequalities on and systems of constraints to encode quantitative to encode qualitative time intervals. Some attempts have been made to integrate quantitative time points in Allen’s [6,18,21] algebra on two kinds of [l] * Corresponding author. E-mail: petej@ida.liu.se. 1 Email: cba@ida.liu.se. 0004-3702/98/$39.00 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00031-9 \f144 R Jonsson, C. BZickstrtim /Art$icial Intelligence 102 (1998) 143-155 and qualitative is NP-complete from computational for Allen’s algebra difficulties. reasoning into unified frameworks [16,21]. Since the satisfiability problem the qualitative and unified approaches have suffered In response to the computational the TIMEGRAPH type of quantitative subalgebras have been proposed have later been extended with mechanisms example, a limited [22] which is the unique maximal relations. Hence, it would be especially information respect to its qualitative expressiveness. since the maximality II system in the literature [8,9,11,22,24]. for handling quantitative hardness of the full Allen algebra, several polynomial Some of these algebras For information. [24] with algebra all basic to extend this algebra with quantitative is the ORD-Horn tractable subclass of Allen’s algebra containing the pointisable interest [lo] extends interesting algebra information. Of special result would carry over to the new algebra, at least with To give a concrete form to the topic of temporal constraint the fictious crime scenario. Professor Jones has been found shot on the beach near following her house. Rumours tell that she was almost sure of having a proof that P # NP, but had not yet shown it to any of her colleagues. The graduate student Hill is soon to defend his thesis on his newly invented complexity class, NRQPx(I~)~, which would unfortunately be of no value were it to be known for certain thus one of the prime suspects and inspector Smith is faced with the following observations: to say, Hill is facts and that P # NP. Needless reasoning, consider to the post-mortem. Professor Jones died between 6 pm and 11 pm, according Mr Green, who lives close to the beach, is certain that he heard a gunshot sometime in the evening, but certainly after the TV news. The TV news is from 7.30 pm to 8.00 pm. A reliable neighbour of Hill claims Hill arrived at home sometime between 9.15 pm and 9.30 pm. It takes between 10 and 20 min to walk or run from the place of the crime to the closest parking It takes between 45 and 60 min to drive from this parking lot to Hill’s home. lot. The first thing to do is verifying obviously time of death to the interval between 8.00 pm and 11 pm, assuming Mr Green actually was the killing shot. the case here. We can also draw some further conclusions, that these facts and observations are consistent, which is the like narrowing the gunshot heard by Now, suppose inspector Smith adds the hypothesis murder at the time of the gunshot, which is only known to occur somewhere from 8.00 pm to 11 .OO pm. If the set of facts and observations becomes then inspector Smith can rule out Hill as the murderer. 2 inconsistent, that Hill was at the place of the in the interval together with this hypothesis This problem can easily be cast in terms of a temporal-constraint-reasoning and qualitative problem, and over it seems like this simple example cannot be solved by any of It can, however, be solved tractable methods reported in the literature. time points, relations intervals both quantitative involving durations. Unfortunately, the computationally in polynomial time by the method proposed in this paper. 2 Unfortunately, it seems like Hill will be in need of juridicial assistance. \fI? Jonsson, C. Biickstrtim /Artijicial Intelligence 102 (1998) 143%I55 145 We introduce a formalism, Disjunctive Linear Relations (DLRs), for reasoning about for temporal constraint problem including, in the literature e.g., Allen’s algebra. Consequently, temporal constraints. DLRs subsumes most of the formalisms reasoning proposed satisfiability must Linear Relations (Horn DLRs for short) which allows for polynomial-time checking. Horn DLRs subsumes for encoding quantitative different base our method upon managing thus abstracted away, the resulting algorithm the for DLRs is NP-complete. To reason efficiently about DLRs, one impose some type of restriction on the formalism. We present Hone Disjunctive satisfiability algebra and most of the formalisms is rather approaches. We tool for is information. Since most of the low-level handling of time points from the commonly used constraint network or graph-theoretic linear programming which proves in the literature. The approach to be a convenient the ORD-Horn is surprisingly information proposed temporal simple. and Bjtieland is in reasoning We strongly believe reasoning. One example in other areas of computer that Horn DLRs are useful science about action and change where to obtain that replacing Horn DLRs with It is worth noticing the in their approach seems nontrivial; to express disjunctions. Another example where Horn DLRs may be useful are et al. languages than temporal Drakengren computationally standard ability query [ 141 has some resemblance with Horn DLRs. [7] has shown how Horn DLRs can be used in deductive databases. For instance, the proposal by Kanellakis tractable formalisms. linear programming the method needs appeared [ 191, who published Parts of Ithis article have previously that some of the results were independently in a conference paper [12]. It should discovered by Manolis be acknowledged Koubarakis them at another conference only a few weeks after we first presentlzd our results. The paper is structured as follows. We begin by giving the basic terminology to complexity time algorithm algorithm, we show NP-completeness stated temporal constraint discussion of the results. issues in linear programming. We continue by presenting for deciding satisfiability of Horn DLRs. As a direct consequence of this of DLRs. After having results, we compare DLRs and Horn DLRs with a number of formalisms proposed in the literature. The paper concludes with a short and definitions used in the rest of the paper together with a brief introduction the polynomial- the complexity of deciding satisfiability 2. Prelimharies We begin by defining some different types of relations. Definition 1. Let X = (x1, . . . , x,) be a set of real-valued variables. Let a be a linear (i.e., a polynomial of degree one) over X and c an integer. A hear disequation polynomial over X is an expression of the form a! # c. A hear equality over X is an expression of the form CY = c. A linear relation over X is an expression of the form w-c where relation over X is an expression of the form olr,, c r E {-c, <, ==, #, 2, >}. A convexlinear where r, E ( -c , <, =, 3, > }. A disjunctive linear relation (DLR) is a set of one or more linear relations. \f146 F! Jonwm, C. Bdckstriim /Art$cial Intelligence 102 (1998) 143-155 The restriction to integral coeffecients is not important in practice; integral (but rational) coeffecients can be transformed coeffecients by multiplication with suitable factors. to equivalent relations with non- relations with integral Example 2. The set (2x1 + x2 - x3 < 5,12x3 - 7x2 # 0, x2 = 5) is a DLR over &1,X2,X3}. It is no limitation to assume the right-hand sides of the relations a relation of the form o r /3 where a! and /I are linear polynomials equivalent relation of the form o’ r c where c is a constant. to be constants since can be rewritten as an We assume all sets of DLRs to be finite. The definition of satisfiability for DLRs is then straightforward. Definition 3. Let X = {XI, . . . , x,) be a set of real-valued variables and let R = {RI, _ . . , Rk] be a set of DLRs over X. We say that R is satisjiable of real values to the variables true. in X that makes at least one member of each Ri , 1 6 i < k, iff there exists an assignment For DLRs we have the following decision problem. Definition 4. The decision problem DLRSAT is defined as follows: INSTANCE: A finite set 0 of DLRs. QUESTION: Is 0 satisfiable? We continue by classifying different types of DLRs. Definition 5. Let y be a DLR. C(y) denotes disequations lC(y)( = 0. If y is convex or disequational we say that y is homog",
            {
                "entities": [
                    [
                        77,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 76 ( 1995) 89-123 Artificial Intelligence Approximate planning * Matthew L. Ginsberg * Clh!L., 1269 University of Oregon, Eugene, OR 97403-1269, USA Received April 1993; revised March 1994 Abstract This paper makes two linked contributions. First, we argue that planning systems, instead of being correct (every plan returned achieves the goal) and complete (all such plans are returned), should be approximately correct and complete, in that most plans returned achieve the goal and that most such plans are returned. The first contribution we make is to formalize this notion. Our second aim is to demonstrate the practical importance of these ideas. We argue that the cached plans used by case-based planners are best thought of as approximate as opposed to exact, and also show that we can use our approach to plan for subgoals gr and g2 separately and to combine the plans generated to produce a plan for the conjoined goal go A gz. The computational benefits of working with subgoals separately have long been recognized, but attempts to do so using correct and complete planners have failed. 1. Introduction When we talk about a plan for achieving a goal, we typically mean not one plan but a turkey I will sweet to wish from my stated goal of many. As an example, involves stuffing and roasting take between now and when potatoes and pumpkin pie, buying a bottle of wine, calling them happy holidays, turkey preparation. that my plan for preparing that these are the only actions I may also plan on making if I say on Thanksgiving it, I hardly mean the turkey and other actions even further removed family members is done. In fact, my plan “stuff the turkey and then roast it” might be represented something like this: [ . . . stuff . . . roast . . .] (1) * Supported by the Air Force Office of Scientific Research under contract 92-0693 and by ARPA/Rome Labs under contracts F30602-91-C-0036 and F30602-93-C-00031. * E-mail: ginsberg@cs.uoregon.edu. 0004-3702/95/@9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00077-8 \f90 M.L. Ginsberg/Artificial Intelligence 76 (1995) 89-123 A B C D Fig. 1. Get A on B on C without building a four-block tower. where the ellipses denote currently undetermined action sequences that I might inter- sperse into the above plan. If I need to roast the turkey immediately after stuffing it, I might write that as [ . . . stuff roast. . .] (2) where the second set of ellipses has been dropped. There are, of course, many instances of ( 1) that are unsatisfactory. Perhaps I run the turkey through a paper shredder before beginning preparation, or unstuff it after stuffing it, or garnish it liberally with peanut butter before serving. In what sense can we say that ( 1) is our plan when so many things can go wrong? The conventional approach to this problem is to deal not with plans such as that appearing in ( 1) , but with far more specific plans such as [stuff yams telephone roast eat] (3) where there are guaranteed to be no extraneous actions that might interfere with our achieving our goal. But from a practical point of view, the plan (3) is nearly worthless, since it is almost inconceivable that I execute it exactly as written. There are many other examples of this phenomenon. If we intend to construct plans by retrieving them from a library of known solutions to similar problems (so-called case-based planning [ 14]), it is important that the plans in the library include some measure of flexibility. After all, it is unlikely that the new situation in which we find ourselves will be an exact match for the situation in which the plan was constructed. Our ability to plan for conjunctive goals rests on similar ideas. When possible, it is important that we plan for conjuncts separately and then merge the results; this appears to require that the solutions to the individual conjuncts be plan schemas such as ( 1). Planning for conjuncts separately enables us to take computational advantage of the benevolence of our environment as reflected in the frame assumption-we can typically achieve one subgoal and then not worry about it while we work on other things. Another example of a conjunctive planning problem appears in Fig. 1. The goal is to get A on B and B on C, but there is a restriction to the effect that one cannot build a four-block tower. For a human planner, the problem is easy. We realize that the general plan for getting B onto C is simply to move it there, and similarly for getting A on B. When we combine these two plans, however, we encounter a problem-the action of moving A to B will fail. We therefore modify the plan for getting B onto C, adding the additional action of moving C to the table. \fML. Ginsberg/Artificial Intelligence 76 (1995) 89-123 91 I presented this problem to the authors of two generative planning systems-Minton (PRODIGY [ 171) and Wilkins ( SIPE [ 211) . Both reported (personal communication) that the problem would pose no significant difficulties for them and that they could solve it by adding an additional precondition to the action move(x, y) to the effect that y had to be either on the table or on a block z that was on the table. 1 The problem with this approach is that it doubles the branching factor for all plan- ning problems. This will lead to prohibitive computational difficulties as the problems involved get larger; imagine having to move a block prior to constructing a 13-block tower in a domain that prohibits 1Cblock ones. As an example of the immediacy of these difficulties, Penberthy and Weld’s UCPOP system [ 181 proved incapable of solving the four-block version of the problem in Fig. 1 without the inclusion of domain-specific control information. * Worse still is the fact that the branching factor is being increased on all problems, not just those that involve tall towers. Imagine, for example, that we can only put a blue block on a red one if the red block is on the table. The branching factor will still be doubled even if we are working in a domain without blue blocks! 3 Explicit control rules provide potential ways around these particular difficulties, but their use is problematic. What control rule are we to use if the previous domain includes painting actions, so that the colors of blocks can change? What control rule would allow us to efficiently solve the problem in Fig. 1 if the constraint were changed so that only jive-block towers were prohibited? Related problems appear in plan debugging. If a human planner discovers a bug in one portion of a plan to achieve a complex goal, the typical response is to restrict the impact of the bug to a small portion of the analysis and to then plan around the problem. That we can make modifications that address the bug without destroying the effect of the original plan depends on our commonsense ability to construct and manipulate plans that, while not holding universally, do hold in general. like ( I)-plans My intention in this paper is to develop a formalization of the ideas that are implicit in the plan ( 1)) and to then describe the use of these constructs in conjunctive planning. Please bear with me while we work through the mathematics, since there are a variety of fundamentally new ideas that we need to formalize. ( 1) We first need to describe plans that can have new actions added to them in arbitrary ways but that can still include the immediacy requirements of a plan such as (2). This is our goal in the next section, where we also present a variety of mathematical results about these new plans that will be needed later. (2) We next need to define conditions under which a plan approximately achieves a goal. The basic idea here is that a plan P is approximately correct if most instances of P that could actually be executed do indeed achieve the goal. We 1 Wilkins made the alternative suggestion of creating two move operators. This is equivalent in practice, however; doubling the branching factor by introducing a second move operator is equivalent to doubling it by introducing a disjunction into the precondition. *Will Harvey, personal communication. The problem is not one of time, but of space; UCPOP reported that it had exhausted its available memory while working on this problem. s This is assuming that we treat color as a precondition and not as a filter. We would need to do this if there were actions available that changed blocks’ colors. \f92 M.L. Ginsberg/Art$icial Intelligence 76 (1995) 89-123 formalize this in Section 3 by introducing the idea of an exception to a plan and formalizing conditions under which plans hold sufficiently frequently that we are prepared to treat them as approximately correct. (3) The problem of building a planner around these ideas is discussed in Sections 4 and 5. Section 4 discusses the theoretical issues involved in the construction of the planner, showing that it is indeed possible to plan for conjuncts separately using our ideas. Section 5 discusses a preliminary implementation of our work. (4) Concluding remarks are contained in Section 6, and proofs have been deferred to an appendix. Let me end this introduction with something of a disclaimer. I do not mean to imply that existing implemented systems are incapable of manipulating expressions such as ( 1) . Tate’s O-Plan system, for example [ 2,201, appears to use ideas such as these rou- tinely. But planners that behave in this fashion have thus far lacked formal foundation, and correcting that is my intention here. In providing a solid formal foundation for nonlinear planning, McAllester and Rosenblitt’s paper [ 161 was both a step forward and a step back; although it formalized many ideas that had previously eluded precise description, it omitted many of the procedural tricks that make implemented planners effective. As a result, formally well-grounded planners such as that described by Pen- berthy and Weld [ 181 typically exhibit performance far worse than that of the informal system",
            {
                "entities": [
                    [
                        66,
                        86,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 570–590www.elsevier.com/locate/artintOn the notion of concept IMichael FreundLaLICC, University of Paris Sorbonne, 28 rue Serpente, 75006 Paris, FranceReceived 25 September 2006; received in revised form 11 September 2007; accepted 15 September 2007Available online 20 September 2007AbstractIt is well known that classical set theory is not expressive enough to adequately model categorization and prototype theory. Re-cent work on compositionality and concept determination showed that the quantitative solution initially offered by classical fuzzylogic also led to important drawbacks. Several qualitative approaches were thereafter tempted, that aimed at modeling member-ship through ordinal scales or lattice fuzzy sets. Most of the solutions obtained by these theoretical constructions however are ofdifficult use in categorization theory. We propose a simple qualitative model in which membership relative to a given concept fis represented by a function that takes its value in a finite abstract set Af equipped with a total order. This function is recursivelybuilt through a stratification of the set of concepts at hand based on a notion of complexity. Similarly, the typicality associated witha concept f will be described using an ordering that takes into account the characteristic features of f . Once the basic notions ofmembership and typicality are set, the study of compound concepts is possible and leads to interesting results. In particular, weinvestigate the internal structure of concepts, and obtain the characterization of all smooth subconcepts of a given concept.© 2007 Elsevier B.V. All rights reserved.Keywords: Categorization; Concept; Extension; Intension; Typicality; Membership; Modular orders; Fuzzy sets; Formal concepts analysis1. IntroductionIn this paper we propose a new framework for the study of some basic notions classically used in categorizationtheory. In particular, we shall be concerned with the problem of finding a suitable theoretical apparatus to model thenotions of membership and typicality that underlie prototype theory. It is well recognized since the work of EleanorRosch [18] that membership, for instance, is not an all-or-not matter: the classical set-theoretical or the two-valuelogic model are of therefore of little use to render count of most of the cognition process. This drove Zadeh and hisfollowers [24] and [25] to propose a representation of concepts by fuzzy sets, membership being modeled through areal function with values in the unit interval. Such a representation nevertheless lead to counterintuitive results: see forinstance the seminal papers of Kamp and Partee and of Osherson and Smith [12,16,17]. At a quite elementary level,for instance, it was observed that the membership degree relative to a compound concept could never be greater thanthe degree induced by any of its components, a result that cannot be accepted for both theoretical and experimentalreasons. Even for elementary concepts, the representation of concepts as quantitative fuzzy sets poses problems:vague concepts like to-be-an-adult or to-lie are given continuous values in the unit interval, but what does it meanE-mail address: Michael.Freund@paris4.sorbonne.fr.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.09.003\fM. Freund / Artificial Intelligence 172 (2008) 570–590571to qualify somebody as adult ‘with degree .4837’? In particular, as observed by several authors (for instance [14])there is no reason why the same set–the unit interval—should serve as a uniform criterion, being invariably referredto as a measure of membership whatever the concept at hand. True, in practice membership is often evaluated throughstatistical data, and the membership degree identified with a simple frequency. But the fact that, say, 87 individualsout of 100 consider a car seat as a piece of furniture by no means involves that, in an agent mind, the membershipdegree of a car-seat relative to the concept to-be-a-piece-of-furniture is equal .87.These drawbacks led to various solutions which all aimed at replacing the primitive quantitative model by a qual-itative one: thus, attention focused on ordinal scales and on lattice fuzzy sets—see for instance [11] or [25]. For abrief analysis of the most recent work on this area, the reader may refer to [14] or [3]. However, we consider that thesolutions that were proposed are not fully adapted to model prototype theory, and that they cannot be easily exploitedto address the classical questions raised by categorization theory.In a different area, Peter Gärdenfors [9] or [8] proposed a geometrical model as a framework for concept theory:a concept is defined as a convex region of a multidimensional space, each dimension corresponding to a basic quality.Convexity is related with a notion of betweenness that is supposed to be meaningful for the relevant quality dimen-sions: if two objects are exemplars of a concept, such will be the case for any object that lies ‘between’ them. Thetypical instances of a concept are those which are located ‘near the center’ of the considered region. This Geometryof Thought, as the author calls it, provides interesting tracks in the analysis of concepts. However, it is mostly basedon quantitative notions, which we find not best appropriate to model the cognition process. Furthermore, it does notseem that the distinction between vague and sharp concepts is fully taken into account.For these reasons, we propose to revisit the basic notions linked with categorization theory and treat them froma qualitative point of view. Concerning membership, for instance, and rather than dealing with uniform gradationfunctions that take their values in the unit interval, we represent membership relative to a concept by a function whoseset of values depends on the chosen concept. This set is endowed with a total order that can be used to evaluate towhich degree a object falls under this concept. We think indeed that such a representation is the most adequate tomodel notions like: object x plainly falls under the concept f , object x falls definitely not under the concept f orobject x falls more than object y under the concept f . These notions, which are the basis of categorization theory, arealso the firsts one should deal with in order to understand the problems that arise with vague concepts: for instance,an agent may consider that an elevator is definitely less a vehicle than a chairlift, while being unable at the same timeto attribute a precise numerical membership degree to any of these items. We propose in this paper an example ofconstruction such an order, by making use of the set of defining features attached to the concepts at hand. Postulatingthe existence of such a set is part of most of the theories on categorization: see for instance [1,4,21,22] or morerecently [2], where a concept is assimilated with a set of properties which things that fall under the concept typicallyhave or are believed to have. These defining features, from the point of view of the agent, help understanding thechosen concept; they are individually necessary and collectively sufficient to decide whether or not an item is anexemplar of this concept. Given a vague concept f , we shall use this associated defining feature set to compare thef -membership of two items in the following way: an object x will be considered as falling less under f than an objecty if it falls less than y under the f -defining features. The circularity of this definition will be avoided by attributingto each concept a complexity level: the sharp concepts, those for which membership is an all-or-not matter, will begiven complexity level 0; at level 1, we shall rank all the vague concepts whose defining feature set only consistsof sharp concepts; at level 2, we will have the vague concepts whose defining feature set consists of concepts thathave complexity level equal to 0 or 1, and so on. This ranking will eventually render possible a recursive definition ofmembership, and, consequently, the construction of a membership order among the set of objects at hand.Having represented concepts by means of order-functions poses the problem of finding an adequate representationof the notion of typicality. Since the work of E. Rosch, a considerable amount of study has been carried out on thisnotion, and it is now widely accepted that, relative to a given concept, objects may be classified following their degreeof typicality. Although a precise and general definition of this typicality degree is still missing, one generally agrees onthe fact that such a degree has to faithfully reflect the number of characteristic features attached to the concept at hand,together with the relative pertinence, or the frequency, of these features [15, Chapter 2]. Nevertheless the attempts at arigorous construction are rare, and none of them seem to have gained general recognition. Besides, researchers in thisdomain restricted themselves to elementary cases, dealing with sharp concepts, for which membership is an all-or-notmatter, or with concepts with sharp features. In particular, they did not seem to be concerned with situations in whichthe typicality relative to a concept depends on the membership relative to another concept: in order to determine the\f572M. Freund / Artificial Intelligence 172 (2008) 570–590relative typicality of a hen as a bird, for instance, they would not consider that it is necessary to first evaluate itsmembership degree relative to the concept to-fly. We think on the contrary that typicality must be determined throughmembership, and that these two notions are correlatedWe therefore propose the construction of a ‘typicality order’—in fact a partial preorder—clear and easy to evaluate,that faithfully conforms with our intuition. This order is meant to reflect a particular agent’s judgment at a precisetime. It is based on the agent’s choice, for each conc",
            {
                "entities": [
                    [
                        72,
                        98,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 77 (1995) 28.5-319 Artificial Intelligence A comparative study of open default theories Michael Kaminski* Department of Computer Science, The Hong Kong University of Science and Technology, Clear Water Bay Road, Kowloon, Hong Kong Received February 1993; revised December 1993 Abstract The paper examines the definitions of open default theories known from First it is shown Next a new approach definitions, but possesses that none of them is considered. their positive properties. is satisfactory either for formal or for intuitive It is free from the obvious deficiencies the literature. reasons. of the known 1. Introduction One of the widely used nonmonotonic is Reiter’s default logic [HI. This logic deals with rules of inference called defaults which are expressions of the form formalisms 6(x) = a(x) : MP, (4, . . . , W, (4 Y(X) 7 of formulas where a(x), PI(x), . . . , P,(x), Y(X), m 3 1, are is predicate calculus whose free variables are among x =x1, . . . ,x,. A default closed if none of (Y, PI, . . . , &, y contains a free variable. Otherwise a default is called open. The formula cy(x) is called the prerequisite of the default rule, the formulas PI(x) , . . . , p,(x) the justijications, and the formula y(x) is called the conclusion. Roughly speaking, the intuitive meaning of an open default is as follows. For every n-tuple of objects t = t,, . . . , t,,, if a(t) is believed, and the to deduce -y(t). Thus an open default pi(t)% can be thought of as a kind of a “default scheme”, where the free variables x can then one is permitted are consistent, are called first-order the * Current address: Department of Computer Science, Tecbnion-Israel 32000, Israel. Institute of Technology, Haifa 0004-3702/95/$09.50 SSDZ 0004-3702(94)00035-Y 0 1995 Elsevier Science B.V. All rights reserved \f286 M. Kaminski I Artijicial Intelligence 77 (1995) X5-319 be replaced by any of the theory’s objects. Various examples of deduction by default rules can be found in [15]. there towards is no common attitude Whereas closed defaults have been quite thoroughly investigated, very little is their known about open ones. Moreover, meaning. However, interesting cases of default reasoning usually deal with open defaults, because the intended use of a default is to determine whether an object rather than accepting or rejecting a “fixed statement”. possesses a given property to the treatment of open defaults are known from the Three major approaches literature. The first one belongs to Reiter [El, where he gives explicit names to language with new constants. Then the theory objects by extending in the enriched Reiter language. The second approach to Poole [14] who replaces an open default by the set of all its closed instances over the is that of Lifschitz [9], where free variables original in defaults are treated as object variables, rather than metavariables for the closed terms of the theory. treats an open default as a set of all its closed instances is similar to the first one and belongs language. The last approach the theory theory for an open default the above approaches In this paper we examine from formal and intuitive the most natural formal test for accepting a definition to the theory. However, definitions points of view. Obviously, of an extension original definition of Reiter, when applied to a closed default of is not sufficient, because this necessary extensions for closed default theories become different when one extends them to open default theories. Since there are no (and cannot be any) formal criteria for a in order to choose the right definition we should rely on our sufficient condition, to tell us what we should expect from an extension for an open intuition imprecise default is that it must be equivalent equivalent condition theory. sound. is counterintuitive to implicitly defined objects In particular, Reiter’s definition from a formal point of view, Poole’s definition As the result of our analysis we argue that all Reiter’s, Poole’s and Lifschitz’s that gives definitions are not entirely and also is not explicit names acceptable that deals only with explicitly defined objects is too weak (yet it passes the formal test), and Lifschitz’s that treats explicitly defined objects as implicitly defined ones is not definition reason. However, Lifschitz’s either acceptable definition to seems Lifschitz’s definition which makes it free from its obvious deficiencies. The main feature of the modified definition is that it clearly separates between explicitly and implicitly defined theory objects. It also passes the formal test and its connection to circumscription for a formal or for an intuitive to be more promising, is similar to the original one. and we propose a modification for closed default theories, The paper is organized as follows. In the next section we recall the definition of in Sections 3 and 4 we examine, respective- extensions ly, Poole’s and Reiter’s definitions of extensions for open default theories, and in to Reiter’s definition. Section 6 Section 5 we consider a possible modification contains a semantical definition of extensions for closed default theories, which is In Section 7 we examine the starting point for Lifschitz’s and our approaches. in Section 8 we present a modi- Lifschitz’s approach to open default theories, \fM. Kaminski I Artificial Intelligence 77 (1995) 285-319 287 fication to this approach which is more robust than the original, and in Section 9 we show how extensions for default logic with fixed constants can be expressed in terms of the modified approach. In Section 10 we establish a relationship between the modified Lifschitz’s approach and circumscription. Finally, we end the paper with some concluding remarks. 2. Closed default theories In this section we recall Reiter’s definition of extensions for closed default for In for open default if we accept Reiter’s definition for closed default theories as a “right one”, then a “right” definition theory, for open default theories. This definition accepting or rejecting definitions of extensions particular, in the introduction, of extensions of extensions must be equivalent is frequently used in this paper as a formal criterion theories. theories, when applied to a closed default to Reiter’s definition. as was mentioned Definition 1. A default theory is a pair (D, A), where D is a set of defaults and A is a set of first-order sentences (axioms). A default theory is called closed, if all its defaults are closed. Otherwise it is called open. Definition 2. Let (D, A) be a closed default theory. For any set of sentences S let q,,,,(S) that satisfies the following = B, where B is the smallest set of sentences three properties.’ (beliefs) (Dl) AcB. (D2) Th(B) = B, i.e., B is deductively closed. (D3) A set of senten:es E is an extension for (D, A) if T;,,,,(E) If u’Mpl,...,MPm~D, and -&,...,1/3,,,$S, aEB, then yEB. = E, i.e., if E is a fixed point of the operator qD,A). All the examples, but one, we consider very intuitive case of defaults of the form w without prerequisites. We shall need the following lemma. in this paper deal with the simplest and which are called normal defaults Lemma 3. Let D be a set of closed normal defaults without prerequisites. Then a is a consistent extension for (D, A) if and only if it is a maximal set of sentences consistent set of sentences of the form Th(A U A’), where A’ C {p: $@ E D}. Proof. The “if” part of the lemma is, actually, closed defaults. [14, Theorem 4.11 restricted to I This definition I;,,,,(S) = B. This notation is more convenient for a technical reason. follows [9] and differs from the original one in [15] in introducing the notation \f288 M. Kaminski i Artificial intelligence 77 (1995) 285-319 For the “only if” part, let E be an extension for (D, A), and let A, = E fl It remains {p: +@ ED}. Th en, by [15, Theorem 2.51, E = Th(A U A,). to show that Th(A U A by) (=E) set of to the sentences of the form Th(A U A’), where A’ C {p: 9 contrary that this is not the case. and let Th(A U A’), where A’ C {j?: 9 E D}, be a maximal consistent set of sentences containing E as a proper subset. By the “if” part of the lemma, Th(A U A’) is an extension with the Minim&y is a maximal consistent E D}. Assume [15, Theorem 2.41. 0 in contradiction of Extensions for (D, A), 3. Poole’s definition of open default theories In this section we analyze Poole’s definition of open default theories. Even eight years later than Reiter’s one, it is reason. For both Poole’s and Reiter’s though, discussed approaches we need the following definition. this definition was introduced first for a methodological Definition 4. A. (closed) instance of an open default 6(x) = u(X) ’ MBl’“,:x;- ’ MP&) a closed default S(t) = a(t) ’ MP~(:);tJ. MP&) . where t = t,, . (or ground) all closed instances of 6 is denoted by 6, and for a set of defaults D, d = U,,, is the set of all closed instances of all defaults of D. is , t, is a tuple of closed language L. For an open default 6, the set of 8 terms of the underlying In [14] Poole deals with normal defaults without prerequisites only, and treats an open default theory if all defaults (D, A) as a closed default from D are closed, that Note then D = D. Therefore Poole’s definition when applied to closed default theories is equivalent to Reiter’s original definition. However Example 5 below’ shows that Poole’s approach which deals individuals, only with explicitly defined theory is too weak. theory (0, A). 5. Let Intuitively, (D, A) be a default Example {ilxQ(x)}. satisfying Q that it satisfy P in the extension expect of 3x(P(x) A Q(x)) (D, A) has a unique Poole extension E = A. to belong theory, where D = {w}, and A = individual for this theory. That is, one would since b = 0, to the extension. However, one would expect of an implicitly defined 4. Reiter’s definition of open default theories In [15] Reiter suggests an interpretation of an open default as the collection of ",
            {
                "entities": [
                    [
                        76,
                        120,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 107 (1999) 303-333 Artificial Intelligence Expressiveness of concept expressions in first-order description logics Natasha Kurtonina a, 1, Maarten de Rijke b,, a 1RCS, University of Pennsylvania, 3401 Walnut Street, Phildelphia, PA 19104-6228, USA b 1LLC, University of Amsterdam, Plantage Muidergracht 24, 1018 TVAmsterdam, The Netherlands Received 4 January 1998; received in revised form 15 November 1998 Abstract We introduce a method for characterizing the expressive power of concept expressions in first- order description logics. The method is essentially model-theoretic in nature in that it gives preservation results uniquely identifying a wide range of description logics as fragments of first-order logic. The languages studied in the paper all belong to the well-known ,Y'/~- and ,AZ~ hierarchies. © 1999 Published by Elsevier Science B.V. All rights reserved. Keywords: Knowledge representation; Description Logic; Expressive power; Model theory; Semantic characterizations I. Introduction Description logics have been proposed in knowledge representation to specify systems in which structured knowledge can be expressed and reasoned with in a principled way. They provide a logical basis to the well-known traditions of frame-based systems, semantic networks and KL-ONE-like languages, object-oriented representations, semantic data models, and type systems. Generally speaking, description logics have three main ingredients: (1) a language for defining concept expressions, (2) means to specify knowledge about concepts and individuals, and (3) methods for reasoning about the knowledge being represented. * Corresponding author. Email: mdr@wins.uva.nl. 1 Email: natashak@linc.cis.upenn.edu. 0004-3702/99/$ - see front mauer © 1999 Published by Elsevier Science B.V. All fights reserved. PII: S0004-3702(98)00109-X \f304 N. Kurtonina, M. de Rijke / Artificial Intelligence 107 (1999) 303-333 In this paper we are only concerned with the first aspects, i.e., with languages for defining concept expressions. In the design of such languages two important theoretical consider- ations are complexity and expressive power. A popular slogan here is \"complexity versus expressiveness\": the more expressive a description logic is, the higher the complexity of the reasoning tasks that can be performed in it. The complexity of satisfiability and sub- sumption problems for description logics has been studied extensively (cf. 9,10), but the problem of expressiveness of concept expressions has hardly been addressed so far; we are aware of only three publications on this topic 2,6,7. The purpose of this paper is to help fill this gap. We characterize and compare the expressive power concept expressions definable in all logics in two well-known hierarchies of description logics. The methods we use first identify the concept expressions definable in description logics as fragment of first-order logic, and then characterize these fragments in terms of a unique model-theoretic property. The main technical tool used is preservation under a suitable notion of (hi-)simulation. More precisely, with each description logic ~ we associate a characteristic (bi-)simulation such that all and only the /Z-concepts are preserved under this (bi-)simulation. Then, the expressive power of concept expressions of two description logics can be compared by comparing the model-theoretic behavior of their concepts with respect to their respective (bi-)simulations. The characteristic (bi-)simulations can then be used to classify the concepts that are definable in description logics. We think that our results are significant for the knowledge representation community because, for the first time, they give exact and expficit model-theoretic characterizations of the expressive power of concept expressions definable in a wide range of description logics. In addition, they illustrate a general method for coping with expressiveness issues; we hope they may be useful for understanding knowledge based systems, especially with respect to the descriptive desiderata one may have. Baader 2 seems to have been the first to propose a formal definition of the expressive power of description logics; the only other formal papers on the issue are 6,7. Our definition of expressive power is somewhat simpler than Baader's, as we are only concerned with the expressive power of concept descriptions. Implicitly, Borgida 6 considers the same notion of expressive power as we do. Cadoli et al. 7 explore notions of expressive power that are appropriate for hybrid languages that combine description logics with rule-based query languages. Our paper differs from 2,6,7 in that we give exact and explicit model-theoretic characterizations of the expressive power of concept expressions definable in a wide range of logics (cf. Section 5 for further discussion). The results in this paper are based on preservation theorems that are similar to ones found in the literature on modal and temporal logic and the modal/z-calculus 4,19,21. However, as description logics often lack some boolean operations, the proofs of our preservation theorems require novel technical tools and methods. Our preservation results arc: similar in spirit to the characterizations of finite variable fragments in terms of pebble games due to 17. Furthermore, there is a considerable body of work on the expressive power of query languages, but most of this is phrased in terms of complexity classes 1,18. The results in the present paper, however, are entirely model-theoretic. We proceed as follows. In Section 2 we describe the technical prerequisites for the paper, and review our notation. Section 3 then explains our method and the definition of \fN. Kurtonina, M. de Rijke / Artificial Intelligence 107 (1999) 303-333 305 expressive power used. The main results of the paper are contained in Section 4, together with illustrations of their use. Section 6 contains concluding remarks and describes ongoing work. Formal proofs of the main characterization results are included in two appendices. 2. Technical background The main ingredients of description logics are c o n c e p t s  a n d  roles. The former are interpreted as subsets of a given domain, and the latter as binary relations on the domain. Table 1 lists constructors that allow one to build (complex) concepts and roles from (atomic) concept names and role names. For instance, the concept Man rq 3Child.T n ¥Ghild.Human denotes the set of all fathers. Description logics differ in the constructions they admit. By combining constructors taken from Table 1, two well-known hierarchies of description logics may be obtained. The logics we consider here are extensions of f £ - ; this is the logic with T, 2 ,  universal quantification, conjunction and unqualified existential quantification 3 R . T .  2 ,AE extends .TE- by negation of concept names (that is, negations of the form -,A, where A is an atomic concept name). Extensions of .T'E- and ,A£ are denoted by postfixing the name of the constructors being added. For instance, 5rECL/- is ) r E -  with (full) existential quantification and disjunction. Table 1 Constructors in first-order description logics Constructor name Syntax Concept name Top Bottom Conjunction Disjunction (ld) Negation (C) Universal quantification Existential quantification (E) Number restriction (At') Role name Role conj. (7-4.) A T ± C (cid:127) D C u D ~ C ¥ R . C 3R.C (t> n R) (<. n R ) R Q n R Semantics A Z c_ A Z A 27 13 C Z (7 D Z C Z tO D Z A Z \\ C Z {dl I ¥d2 (dl, d2) e R Z ~ d 2 e C Z} {dl I Bd2 (dl, d2) 6 R Z A d 2 e C Z} {dt I{(dl, d2) e R27}>>. n} {dl l{(dl,d2) eRZ}<~n} R Z C_ A Z x A Z Q z  N R Z Description logics are interpreted on i n t e r p r e t a t i o n s  Z ---- (A I ,  .I), where A 2: is a non- empty domain, and .z is an interpretation function assigning subsets of A 2- to concept 2 Some definitions of ~ ' £ -  don't include T and ± in the logic; cf. 10. To simplify the formulation of our results we have decided to include them. \f306 N. Kurtonina, M. de Rijke /Artificial Intelligence 107 (1999) 303-333 names and binary relations over A 7: to role names; complex concepts and roles are interpreted using the recipes specified in Table 1. The semantic value of an expression E in an interpretation 2- is simply the set E I .  Two expressions are called equivalent if they have the same semantic value in every interpretation. For further details on both applications and theoretical aspects of description logics, / / d l .  k r . we refer the reader to 10, or to the description logic home page at h t t p : org/dl/. 3. Defining expressive power In this section we define our notion of expressive power, and explain our method for determining the expressive power of a given description logic. Our aim in this paper is to determine the expressive power of concept expressions of every extension of 9rE - and ,A£ that can be defined using the constructors in Table 1. We say that a logic £1 is at least as expressive as a logic £2 if for every concept expression in £2 there is an equivalent concept expression in £~; notation: £2 <<, £1. If £2 ~< £j and /~1 ~ £2, we write £2 < £~; if both £1 ~< £2 and £:2 ~ £1 hold, we write £1 : £2. The method we use for explaining the expressive power of description logics has the following ingredients: (1) a mapping taking concept expressions in description logics to fragments of first- order logic; (2) characterizations of these fragments by model-theoretic means; and (3) comparisons between (the expressive power of) the concepts definable in description logics based on comparisons between the corresponding first-order fragments; cf. Fig. 1, where the rectangle denotes first-order logic, and the closed curves denote (fragments corresponding to) concepts definable in description logics. In line with our methodology we will pursue the above items (1), (2), and (3) for each of the description logics considered ",
            {
                "entities": [
                    [
                        76,
                        147,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 167 (2005) 13–30www.elsevier.com/locate/artintWord sense disambiguation with picturesKobus Barnard a,∗, Matthew Johnson ba Computer Science Department, University of Arizona, USAb Department of Engineering, University of Cambridge, USAReceived 25 July 2004; received in revised form 21 February 2005; accepted 14 April 2005Available online 11 August 2005AbstractWe introduce using images for word sense disambiguation, either alone, or in conjunction withtraditional text based methods. The approach is based on a recently developed method for automat-ically annotating images by using a statistical model for the joint probability for image regions andwords. The model itself is learned from a data base of images with associated text. To use the modelfor word sense disambiguation, we constrain the predicted words to be possible senses for the wordunder consideration. When word prediction is constrained to a narrow set of choices (such as possiblesenses), it can be quite reliable. We report on experiments using the resulting sense probabilities asis, as well as augmenting a state of the art text based word sense disambiguation algorithm. In orderto evaluate our approach, we developed a new corpus, ImCor, which consists of a substantive portionof the Corel image data set associated with disambiguated text drawn from the SemCor corpus. Ourexperiments using this corpus suggest that visual information can be very useful in disambiguatingword senses. It also illustrates that associated non-textual information such as image data can helpground language meaning. 2005 Elsevier B.V. All rights reserved.Keywords: Word sense disambiguation; Image auto-annotation; Region labeling; Statistical models* Corresponding author.E-mail address: kobus@cs.arizona.edu (K. Barnard).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.04.009\f14K. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–30Fig. 1. Five senses of bank, illustrated using images from the Corel dataset.1. IntroductionA significant portion of words in natural language have a number of possible meanings(senses), depending on context. This is illustrated in Fig. 1 with the arguably overused“bank” example. A priori, the word “bank” has a number of meanings including financialinstitution and a step or edge as in “snow bank” or “river bank”. Words which are spelledthe same but have different meanings (polysemes) confuse attempts to automatically attachmeaning to language. As there are many such ambiguous words in natural language texts,word sense disambiguation—determining the exact sense of words—has been identifiedas an important component of natural language processing, and has been studied by manyresearchers leading to a large body of literature [2–4,27,32,40,41,47,49,50].Since the words are spelled the same, resolving what they mean requires a considerationof context. A purely natural language based approach considers words near the one inquestion. Thus in the bank example, words like “financial” or “money” are strong hints thatthe financial institution sense is meant. Interestingly, despite much work, and a number ofinnovative ideas, doing significantly better than choosing the most common sense remainsdifficult [47].In this paper we develop a method for using image information to disambiguate thesenses of words. We posit that image information can be an orthogonal source of infor-\fK. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–3015mation for distinguishing senses. In the extreme case, disambiguation using nearby textalone is impossible as in the sentence: “He ate his lunch down by the bank”. In suchcases, alternative sources of information offer attractive possibilities for grounding theword meanings. Even when not essential, non-textual information has the capacity to behelpful. Our method for using associated visual information can be used alone, or in con-junction with text based methods. Naturally, when no images are available, the system mustfall back on non-image methods. Incorporation of computer vision into the word sensedisambiguation process is a novel approach. As far as we know, all other word sense disam-biguation methods use document text and/or additional text carrying domain or documentcontext semantic information. However, we acknowledge related work using WordNet [42]to propagate sense (and thus semantic) information between feature based classes in thecontext of multimedia information systems [12,13].To use image information we exploit a recently developed method for predicting likelywords for images [5,9,22]. The method is based on a statistical model for the joint proba-bility distribution of words and image region features. The model is learned from a trainingset of images with associated text. Additional details are provided below (Section 3).To use the model for word sense disambiguation, we constrain the predicted words to befrom the set of senses for the word under consideration. In general, when word prediction isconstrained to a narrow set of choices (such as possible senses), it can be quite reliable. Wereport on experiments using the resulting sense probabilities as is, as well as augmentingtwo state of the art text based word sense disambiguation algorithms.In order to evaluate our approach, it was necessary to develop a new corpus, ImCor,which consists of a substantive portion of the Corel image data base associated with disam-biguated text drawn from the SemCor corpus. (We have made ImCor available for researchpurposes [31].) Our experiments using this corpus suggest that visual information can bevery useful for disambiguating word senses.This work suggests approaches to exploiting multiple data modes to increase our abilityto automatically search and browse multi-media information. For example, text data on theweb is often augmented with image data. Searches based on text currently do not make useof that information, even though in many cases it would be helpful. While computationalmethods for effectively understanding arbitrary visual data are still a long way off, usingvisual features to improve the rankings of query results may not require such a full under-standing. For example, if text data can be better sense disambiguated by using image data,then an unambiguous query can be better executed against this data.2. Disambiguating words using textual contentResearch into automatic methods for disambiguating word senses has resulted in a va-riety of ways of using the surrounding text, or the “textual context”, to infer word sense.Disambiguating sense is a semantic problem, and the underlying assumption is that theword to be disambiguated is semantically linked to the nearby words, as text tends to besemantically coherent. Co-occurrence statistics will reflect semantic linking, and thus re-searchers have developed methods based on statistical models for senses [16]. A largenumber of other methods attempt to quantify this linking using known word semantics. For\f16K. Barnard, M. Johnson / Artificial Intelligence 167 (2005) 13–30example, word classes, as defined by a Thesaurus, can be integrated into a combined weightof indicators in the textual context [48]. Going further, most word sense disambiguation al-gorithms use a semantic network such as WordNet [42]. WordNet is a machine-readabledictionary covering a large proportion of the English language (152,059 words) organizedinto 115,424 sets of synonyms (synsets). It provides relationships between the sets, themost commonly used one being the hypernym (“is a”) relationship. The graph created byhypernym relationships forms a tree in which every node is a hypernym of its children. Thepath connecting two words can be used to define semantic distances, which has been usedin word sense disambiguation algorithms [2,20,35,41].Usage statistics are also helpful for word sense disambiguation. In WordNet, the “sensenumber” roughly corresponds to decreasing common usage frequency (the first WordNetsense is that which it considers to be most commonly used). Going further, researchers haveexploited the SemCor sense-attributed corpus [28,41,43,46]. SemCor, short for the Word-Net Semantic Concordance [26], consists of 25% of the Brown corpus [25] files whichhave been fully tagged with part-of-speech and is sense disambiguated.A number of word sense disambiguation methods have been compared at the threeSenseval conferences [1,23,33]. Based on the results from the second Senseval we choseto implement an algorithm based on iterative word sense disambiguation, SMUaw [41].We were also intrigued by the fact that choosing the most common sense according toWordNet evaluates higher than many of the algorithms currently in use [47]. Thus we alsoimplemented an algorithm which provides a usage distribution over the senses to provideadditional evaluation of our algorithm [36].There has been some work done incorporating multiple alternative knowledge sources tohelp disambiguate words in context. In [19], “world knowledge” derived from alternativesynset contexts obtained through WordNet was used to supplement a learning algorithmand showed marked improvement over the unaided version. Another interesting exampleis found in [44], where, for every word being disambiguated, a feature set is formed basedon multiple sources, including the part of speech of neighboring words, morphologicalform, the unordered set of neighboring words, local collocations and verb-object syntacticrelation. During training, disambiguated sentences were mined for features, so that duringtesting, a feature set obtained for a word can be compared against many training sets. Theproposal is that the similarity so found is directly proportional to the probability that thesense of the word in a training set is the correct sense for the test word. While this systemrelied on the surrounding text to obtain the feature set during testing, training data couldhave po",
            {
                "entities": [
                    [
                        70,
                        109,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 449–478Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSoft arc consistency revisitedM.C. Cooper a, S. de Givry b, M. Sanchez b, T. Schiex b,∗a IRIT, University of Toulouse III, 31062 Toulouse, Franceb UBIA, UR-875, INRA, F-31320 Castanet Tolosan, Francec Center for Machine Perception, Czech Technical University, 12135 Praha 2, Czech Republica r t i c l ei n f oa b s t r a c t, M. Zytnicki b, T. Werner cArticle history:Received 31 January 2009Received in revised form 25 January 2010Accepted 28 January 2010Available online 2 February 2010Keywords:Valued constraint satisfaction problemWeighted constraint satisfaction problemSoft constraintsConstraint optimizationLocal consistencySoft arc consistencyGraphical modelSubmodularitylocal cost functions defined over discrete variables.The Valued Constraint Satisfaction Problem (VCSP) is a generic optimization problemIt hasdefined by a network ofapplications in Artificial Intelligence, Operations Research, Bioinformatics and has beenused to tackle optimization problems in other graphical models (including discrete MarkovRandom Fields and Bayesian Networks). The incremental lower bounds produced by localconsistency filtering are used for pruning inside Branch and Bound search.In this paper, we extend the notion of arc consistency by allowing fractional weights and byallowing several arc consistency operations to be applied simultaneously. Over the rationalsand allowing simultaneous operations, we show that an optimal arc consistency closure cantheoretically be determined in polynomial time by reduction to linear programming. Thisdefines Optimal Soft Arc Consistency (OSAC).To reach a more practical algorithm, we show that the existence of a sequence of arcconsistency operations which increases the lower bound can be detected by establishingarc consistency in a classical Constraint Satisfaction Problem (CSP) derived from the originalcost function network. This leads to a new soft arc consistency method, called, Virtual ArcConsistency which produces improved lower bounds compared with previous techniquesand which can solve submodular cost functions.These algorithms have been implemented and evaluated on a variety of problems, includingtwo difficult frequency assignment problems which are solved to optimality for the firsttime. Our implementation is available in the open source toulbar2 platform.© 2010 Elsevier B.V. All rights reserved.1. IntroductionGraphical model processing is a central problem in AI. The optimization of the combined cost of local cost functions,central in the valued CSP framework [52], captures problems such as weighted Max-SAT, Weighted CSP or Maximum Prob-ability Explanation in probabilistic networks. It also has applications in areas such as resource allocation [9], combinatorialauctions, optimal planning, and bioinformatics [50]. Valued constraints can be used to code both classical crisp constraintsand cost functions.Since valued constraint satisfaction is NP-hard, heuristics are required to speed up brute-force exhaustive search. Byshifting weights between cost functions, soft arc consistency allows us to transform a problem in an equivalent problem.This problem reformulation can provide strong, incrementally maintainable lower bounds which are crucial for Branch andBound search [44].* Corresponding author.E-mail addresses: cooper@irit.fr (M.C. Cooper), simon.degivry@toulouse.inra.fr (S. de Givry), marti.sanchez@toulouse.inra.fr (M. Sanchez),thomas.schiex@toulouse.inra.fr (T. Schiex), matthias.zytnicki@toulouse.inra.fr (M. Zytnicki), werner@cmp.felk.cvut.cz (T. Werner).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.02.001\f450M.C. Cooper et al. / Artificial Intelligence 174 (2010) 449–478Similarly to classical arc consistency in CSPs (constraint satisfaction problems), previously-defined soft arc consistencyproperties are enforced by the chaotic application of local soft arc consistency operations shifting integer costs between differentscopes, until a fixpoint is reached [19,3]. Unlike the arc consistency closure in CSPs, this fixpoint is often not unique andmay lead to different lower bounds. In this paper, we instead consider local consistencies enforced by carefully plannedsequences of soft arc consistency operations which necessarily increase the lower bound. Since costs may need to be dividedinto several parts in order to be shifted in several directions, the resulting transformed problem may contain fractionalcosts. By allowing the introduction of rational multiples of costs, we both avoid the intractability of finding an optimal softarc consistency closure involving only integer costs [19] and produce a strictly stronger notion of soft arc consistency.The two new techniques presented in this paper aim at finding a reformulation of the original problem P with an op-timized constant cost term c∅. This constant cost provides an explicit lower bound provided that all costs are non-negative.Optimal soft arc consistency (OSAC) identifies a sequence of soft arc consistency operations (shifting of costs between costfunctions, of which at most one has arity greater than 1) which yields an optimal reformulation. Intermediate reformula-tions may contain negative costs provided all costs in the final version are non-negative. Such operations can be found inpolynomial time by solving a linear program [54]. We considerably extend this result by showing that a polynomial-timealgorithm exists even in the presence of crisp constraints coded by infinite costs and an upper bound coded by using anaddition-with-ceiling aggregation operator.Alternatively, we show that when a problem is not Virtual Arc Consistent (VAC), it is possible to find a sequence of softarc consistency operations which improve the lower bound and are such that all intermediate problems have non-negativecosts. Our iterative VAC algorithm is based on applying arc consistency in a classical CSP which has a solution if and onlyif P has a solution of cost c∅. We show that OSAC is strictly stronger than VAC. However, finding a lower bound using ourVAC algorithm is much faster than establishing OSAC, and hence has potentially many more practical applications.The idea of using classical local consistency to build lower bounds in Max-CSP or Max-SAT is not new. On Max-CSPproblems, [48] used independent arc inconsistent subproblems to build a lower bound. For Max-SAT, [45] used minimal UnitPropagation inconsistent subproblems to build a lower bound. These approaches do not use problem transformations butrely on the fact that the inconsistent subproblems identified are independent and costs can simply be summed. They lack theincrementality of soft consistency operations. In Max-SAT again, [31] used Unit Propagation inconsistency to build sequencesof integer problem transformations but possibly strictly above the arc level, generating higher-arity weighted clauses (costfunctions). OSAC and VAC remain at the arc level by allowing rational costs. It should be pointed out that our VAC algorithmis similar to the “Augmenting DAG” algorithm independently proposed by [39] for preprocessing 2-dimensional grammars,recently reviewed in [56]. Our approach is more general, in that we can treat cost functions of arbitrary arity, infinite costsand a finite upper bound.Note that the special case of real-valued binary VCSPs over Boolean domains has been extensively studied under thename of quadratic pseudo-Boolean function optimization [7]. In the case of Boolean domains, it is well known that findingan equivalent quadratic posiform representation (i.e. an equivalent binary VCSP) with an optimal value of c∅ can be formu-lated as a linear programming problem [30] and can even be solved by finding a maximum flow in an appropriately definednetwork [7]. It is also worth noting that in this special case of Boolean binary VCSPs, determining whether there exists azero-cost solution is an instance of 2SAT and hence can be completely solved in polynomial time.The two new notions presented in this paper (optimal soft arc consistency and virtual arc consistency) can be applied tooptimization problems over finite domains of arbitrary size, involving local cost functions of arbitrary arity. Crisp constraintscan be coded by infinite costs and an upper bound can be coded by using an addition-with-ceiling aggregation operator. Weshow that the resulting arc consistency properties have attractive theoretical properties, being capable of solving differentpolynomial classes of weighted CSP without detecting them a priori. We also show their strengths and limitations on variousrandom and real problem instances. Some of the problems considered are solved for the first time to optimality using theselocal consistencies.We begin in Section 2 with the definition of a valued constraint satisfaction problem. Section 3 introduces the notion ofan equivalence-preserving transformation and gives the three basic equivalence-preserving transformations that are requiredto establish all forms of soft arc consistency considered in this paper. In Section 4 we review previously defined notions ofsoft arc consistency. These definitions are necessary to define the soft arc consistency EDAC [43], with which we compareboth theoretically and experimentally the new notions of soft arc consistency defined in this paper. Section 5 defines OSAC(Optimal Soft Arc Consistency) and Section 6 reports the results of experimental trials which demonstrate the potentialutility of OSAC during preprocessing. The rest of the paper is devoted to Virtual Arc Consistency (VAC) which providesa practical alternative to OSAC which can be applied during search. Section 7 introduces VAC and shows formally theconnection between this definition and the existence of a sequence of soft arc consistency operations which increase thelower bound. Section 8 introd",
            {
                "entities": [
                    [
                        136,
                        166,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Attificial intelligence 87 ( 1996) 75-143 Artificial Intelligence From statistical knowledge bases to degrees of belief * Fahiem Bacchus a,1, Adam J. Grove bp2, Joseph Y. HalpernCv3, Daphne Keller d,* a Computer Science Department, University of Waterloo, Waterloo. Ont., Canada N2L 3Gl b NEC Research Institute, 4 Independence Way? Princeton, NJ 08540, USA ’ IBM Almaden Research Center. 650 Harry Road, San Jose, CA 95120-6099, USA d Computer Science Department, Stanford Universiry, Stanford, CA 94305, USA Received June 1994; revised December 1995 Abstract An intelligent agent will often be uncertain about various properties of its environment, and when acting in that environment it will frequently need to quantify its uncertainty. For example, if the agent wishes to employ the expected-utility paradigm of decision theory to guide its actions, it will need to assign degrees of belief (subjective probabilities) to various assertions. Of course, these degrees of belief should not be arbitrary, but rather should be based on the information available to the agent. This paper describes one approach for inducing degrees of belief from very rich knowledge bases, that can include information about particular individuals, statistical correlations, physical laws, and default rules. We call our approach the random-worlds method. The method is based on the principle of indifference: it treats all of the worlds the agent considers possible as being equally likely. It is able to integrate qualitative default reasoning with quantitative probabilistic reasoning by providing a language in which both types of information can be easily expressed. Our results show that a number of desiderata that arise in direct inference (reasoning in the International * A preliminary version of this paper appeared Intelligence, Joint Conference on Artificial 1993 [ 51. Some of this work was performed while Adam Grove was at Stanford University and at IBM Almaden Research Center, and while Daphne KoIIer was at U.C. Berkeley and at IBM Almaden Research their NSERC and IRIS Center. This research has been supported programs, by the Air Force Office of Scientific Research by an IBM Graduate Fellowship, and by a University of California President’s Postdoctoral Fellowship. The United States Government * Corresponding I E-mail: 2 E-mail: grove@research.nj.nec.com. D E-mail: halpem@almaden.ibm.com. ( AFGSR) under Contract F49620-91-C-0080, author. E-mail: koller@cs.stanford.edu. in part by the Canadian Government to reproduce and distribute fbacchus@logos.uwaterloo.ca. for governmental is authorized purposes. through reprints 0004-3702/96/$15.00 PII SOOO4-3702( Copyright @ 1996 Elsevier Science B.V. All rights reserved. 96) 00003-3 \f16 E Bucchus er cd. /Art$ciul Intelhgence 87 (1996) 75-143 to conclusions about individuals) information from statistical from the semantics of random worlds. For example, of reasoning assumptions intuitive semantics of random worlds allow the method scope of many other nondeductive such as specificity, of independence. reasoning systems. Furthermore, inheritance, and default reasoning follow directly important patterns and default the expressive power of the language used and the the random worlds captures to irrelevant to deal with problems that are beyond information, indifference 1. Introduction its for a of Consider an agent with a knowledge base, KB, who has to make decisions a doctor may need to decide on a treatment about information information, information, including: first-order e.g., “80% of patients with jaundice e.g., “all patients with hepatitis have jaundice”; typically have a fever”; and informa- the in the world. For example, statistical information, e.g., “patients with hepatitis the particular patient at hand, e.g., “Eric has jaundice”. complete base will not contain actions particular patient, say Eric. The doctor’s knowledge base might contain different types, have hepatitis”; default tion about knowledge For example, the efficacy of a treatment will almost certainly depend on the disease, for the doctor More generally, [ 49,67]), (see, e.g., events. For example, as “Eric has hepatitis”. This paper describes one particular method agent to use its knowledge base to assign degrees of belief call this method an agent must assign probabilities, the doctor may wish to assign a degree of belief likelihood tools for decision making the doctor may be uncertain the random-worlds method. individual. that Eric has. Since it is important of various possibilities. theory such as decision or degrees of belief, to various to an event such that allows such an in a principled manner; we about a particular to apply standard the exact disease In most cases, the relative to be able to quantify information about typically by attempting [ 641, and the various approaches There has been a great deal of work addressing inference deals with the problem of deriving degrees of belief to find a suitable the degree of belief. For instance, a suitable aspects of this genera1 problem. relevant are the work on direct inference, Two large bodies of work that are particularly to nonmonotonic reasoning. going back to Reichenbach from statistical Direct reference class whose statistics information, reference class for can be used to determine is the patient Eric might be the class of all patients with jaundice. While direct inference concerned with statistical knowledge, reasoning, on the other hand, deals mostly with knowledge bases that contain default rules. As we shall argue, none of the systems proposed reasoning interested order, default, and statistical hand, can deal with such complex knowledge bases, and handles several paradigmatic problems can deal adequately with in. In particular, none can handle rich knowledge bases that may contain bases we are first- approach, on the other the large and complex knowledge the field of nonmonotonic in both nonmonotonic The random-worlds and reference-class or nonmonotonic reference-class information. for either reasoning reasoning We now provide a brief overview of the random-worlds in the knowledge base is expressed language augments [3]. Bacchus’s information by Bacchus in a variant of the language first-order introduced logic by allowing statements remarkably well. approach. We assume that the \fE Bacchus et al./Artificial Intelligence 87 (1996) 75-143 77 of the form I]Hep(x) 1 Juun(x) have hepatitis. Notice, however, unintended) consequence 5. To avoid this problem, we use approximate IlfWx) I Jaun(x) IL x 0.8, read “approximately hepatitis”. close to 80%: i.e., within some tolerance T of 0.8. Intuitively, that Not only does the use of approximate [Ix = 0.8, which says that 80% of patients with jaundice this statement has the (probably that in finite models the number of patients with jaundice equality rather is a multiple of than equality, writing 80% of patients with jaundice have is this says that the proportion of jaundiced patients with hepatitis equality solve the problem of unintended it lets us express default advantage: information. con- that “Almost significant such as “Birds it has another sequences, We interpret a statement sertion as I]Fly(x) 1 Bird(x)II, M 1. This interpretation applying probabilistic of these approaches, Having described semantics all birds to nonmonotonic and Section 6 for further discussion. the language fly”. Using approximate typically fly” as expressing the statistical equality, we can represent as- this to various approaches [ 591 for an overview is closely related logic; see Pearl for assigning degrees of belief (which are essentially is the Bayesian paradigm. There, one assumes a space of possibilities need to decide how to assign degrees of belief given a knowledge base. Perhaps widely used framework probabilities) a probability distribution over this space (the prior distribution), probabilities use this approach, we must specify it. In Bayesian done in general. difficulty of making historic unpopularity Our approach in which our knowledge base is expressed, we now the most subjective and and calculates posterior (in our case, the knowledge base). To over and the distribution the space of possibilities little consensus as to how this should be is that these decisions are subjective. The for the to have been an important in symbolic AI [ 541. that the KB contains all the knowledge there is relatively the usual philosophy seems approach these decisions of the Bayesian is different. We assume reasoning, Indeed, on what is known by conditioning reason that any knowledge is already has, and we allow a very expressive This assumption means distribution construction probability assertion the resulting posterior distribution. included of a space of possibilities space, we can use the Bayesian language the agent has that could so as to make this assumption the agent reasonable. the prior in the KB. As a consequence, we give a single uniform over it. Once we have this the probability of an the probability of rp using and a distribution approach: to compute influence (p given KB, we condition on KB, and then compute between the probability to degrees of belief space ? One general in terms of a probability So how do we choose [ 301, is to give semantics strategy, discussed by distri- the statistical assertions and degrees of belief. As we suggested above, I Juun(n) [Ix M 0.8 is true or false in a particular Halpern bution over a set of possible worlds, or first-order models. This semantics clarifies distinction a statistical assertion world, depending other hand, a degree of belief semantics only with respect tribution over them. There agent’s KB and the distribution ever, we clearly want there to be some connection. base her degrees of beliefs on her information in that world. On the has dis- in the between over worlds that determines her degrees of belief. How- In particular, we want the agent to about the world, including her statistical in a parti",
            {
                "entities": [
                    [
                        75,
                        128,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 232 (2016) 76–113Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCharacteristic function games with restricted agent interactions: Core-stability and coalition structuresGeorgios Chalkiadakis a, Gianluigi Greco b,∗a Technical University of Crete, Chania, Greeceb Department of Mathematics and Computer Science, University of Calabria, Italyc Athens University of Economics and Business, Athens, Greece, Evangelos Markakis ca r t i c l e i n f oa b s t r a c tArticle history:Received 15 January 2014Received in revised form 14 December 2015Accepted 17 December 2015Available online 23 December 2015Keywords:Coalitional gamesSolution conceptsComputational complexityTreewidthMarginal contribution networksIn many real-world settings, the structure of the environment constrains the formation of coalitions among agents. These settings can be represented by characteristic function games, also known as coalitional games, equipped with interaction graphs. An interaction graph determines the set of all feasible coalitions, in that a coalition C can form only if the subgraph induced over the nodes/agents in C is connected. Our work analyzes stability issues arising in such environments, by focusing on the core as a solution concept, and by considering the coalition structure viewpoint, that is, without assuming that the grand-coalition necessarily forms.The complexity of the coalition structure core is studied over a variety of interaction graph structures of interest, including complete graphs, lines, cycles, trees, and nearly-acyclic graphs (formally, having bounded treewidth). The related stability concepts of the least core and the cost of stability are also studied. Results are derived for the setting of compactcoalitional games, i.e., for games that are implicitly described via a compact encoding, and where simple calculations on this encoding are to be performed in order to compute the payoff associated with any coalition. Moreover, specific results are provided for compact games defined via marginal contribution networks, an expressive encoding mechanism that received considerable attention in the last few years.© 2015 Elsevier B.V. All rights reserved.1. Introduction1.1. Coalitional games and interaction graphsCooperative game theory aims to provide models of cooperation among interacting agents. One of the prevalent classes of games used within this framework is the class of characteristic function games. A characteristic function game (CFG) is defined over a set N = {1, . . . , n} of agents and is determined by a payoff function v : 2N (cid:3)→ R, such that, for each coalition C , i.e., for any non-empty set C ⊆ N of agents, the value v(C) expresses the payoff that the members of C can jointly achieve by cooperating among themselves [1,2]. The outcome is an allocation, i.e., a payoff vector x = (cid:6)x1, . . . , xn(cid:7) ∈ Rn assigning some payoff to each agent i ∈ N. Characteristic function games are also known as coalitional games with transferable utility, as it is assumed that the agents forming a coalition C can distribute the payoff v(C) among themselves in any way. The * Corresponding author.E-mail addresses: gehalk@intelligence.tuc.gr (G. Chalkiadakis), ggreco@mat.unical.it (G. Greco), markakis@gmail.com (E. Markakis).http://dx.doi.org/10.1016/j.artint.2015.12.0050004-3702/© 2015 Elsevier B.V. All rights reserved.\fG. Chalkiadakis et al. / Artificial Intelligence 232 (2016) 76–11377Fig. 1. Coalitional games in Example 1.1 and Example 1.3.question of interest for such games, is to identify desirable (e.g., fair and stable) outcomes in terms of worth distributions, which are called solution concepts.Characteristic function games provide a rich framework for understanding and reasoning about cooperative actions and have a wide spectrum of applications in different areas of research. Indeed, while they have been traditionally grounded in the game theory and economic literature, they have gained popularity in the context of multi-agent systems and artificial intelligence research as a means of studying interactions among autonomous agents (see, e.g., [3–9]). Moreover, they have recently attracted attention in engineering too, because of their use in the design of intelligent protocols and middleware algorithms for wireless communication networks [10–12]. As an example, we next illustrate a wireless cooperative file sharing system, where mobile subscribers cluster together by downloading (portions of) files of interest over long-range cellular links, and by exchanging them over a wireless ad-hoc network (see, e.g., [13]).Example 1.1. Consider the setting with three mobile users (hence, N = {1, 2, 3}) that is illustrated in the left part of Fig. 1, and a function v such that, for each coalition C ⊆ N, v(C) is meant to express the payoff that users in C can jointly achieve when clustering together and cooperating to download the given file of interest. In particular, assume that v({1}) = 10, v({2}) = 5, v({3}) = 4, v({1, 2}) = 17, v({2, 3}) = 10, and v({1, 2, 3}) = 22. Intuitively, the payoff of each coalition C is meant to express the sum of the utilities that the agents in C get when the file is downloaded minus the cost that they overall incur for the download, with this cost being proportional to the time required and to certain technological features, such as bandwidth and energy consumption.For instance, when 1 and 2 cluster together, each of them can download only half of the file and then share the portion via the wireless connection. While doing so, each of them increases the throughput due to the better performance of the wireless network when compared to the cellular links, and reduces the overall downloading costs. This is reflected in the payoff function v, which is such that v({1, 2}) ≥ v({1}) + v({2}). Similarly, 2 and 3 can cluster together leading to the payoff v({2, 3}) ≥ v({2}) + v({3}).In contrast, note that users 1 and 3 are outside of each other’s transmission range, hence it is impossible for them to cluster together (and, in fact, the payoff function is not specified for this coalition). However, user 2 might still act as a bridge between them, so that when all users join together, the resulting payoff is v({1, 2, 3}) = 22. Indeed, it is advantageous for the users to cluster all together, because v({1, 2, 3}) ≥ v({1, 2}) + v({3}), v({1, 2, 3}) ≥ v({1}) + v({2, 3}), and v({1, 2, 3}) ≥v({1}) + v({2}) + v({3}). While doing so, each user gets the payoff that can be achieved by downloading the whole file alone, and a surplus of v({1, 2, 3}) − (v({1}) + v({2}) + v({3})) = 22 − (10 + 5 + 4) = 3 still remains to be divided among (cid:2)them. As the above example demonstrates, characteristic function games might be defined within an environment imposing restrictions on the formation of coalitions. Indeed, users 1 and 3 are outside each other’s transmission range, and the coalition {1, 3} cannot form.In general, for reasons that might range from physical limitations and constraints to legal banishments, certain agents might not be allowed to form coalitions with certain others. Sensor networks, communication networks, or transportation networks, within which units are connected through bilateral links, provide natural settings for such classes of games. In many multiagent coordination settings, agents might be restricted to communicate or interact with only a subset of other agents in the environment, due to limited resources or existing physical barriers. Another example is provided by hierarchies of employees within an enterprise, where employees at the same level work together under the supervision of a boss, i.e., of an employee at the immediately higher level in the hierarchy. In all these settings, the environment can be seen to possess some structure that forbids the formation of certain coalitions. This can be formalized as an interaction graph G = (N, E), an undirected graph, where agents are transparently viewed as nodes so that a coalition C is feasible, i.e., allowed to form, only if the subgraph of G induced over the nodes of C is connected [14]. For instance, it is immediate to check that the graph shown in the left part of Fig. 1, is the interaction graph associated with the game of Example 1.1, where all coalitions are allowed to form but {1, 3}.Note that when an interaction graph G is the complete graph over N, then G induces no structural restrictions and we are back to the basic setting where a game is completely specified by its payoff function (and all coalitions are allowed to form). Hence, the setting with interaction graphs generalizes the basic one.\f78G. Chalkiadakis et al. / Artificial Intelligence 232 (2016) 76–1131.2. Stability and coalition structuresThe main solution concept adopted in the literature in order to deal with the problem of stability in characteristic function games (i.e., what are the incentives for the agents to stay in formed coalitions), is, arguably, the core [15,16].In settings without any restriction on the possible interactions among the agents, the core is defined as the set of all allocations that are stable because there is no coalition having an incentive to deviate, that is, as the set{x ∈ Rn | x(N) = v(N) and x(C) ≥ v(C), for each coalition C ⊆ N},(cid:2)where x(C) is a shorthand for i∈C xi . Note that it is implicitly assumed here that the grand-coalition of all players in Nforms and, accordingly, the solution concept suggests how the total payoff v(N) can be divided among them in a way that is stable [2].In the presence of an interaction graph, the core can be smoothly adapted so as to focus only on feasible coali-tions [17–19], as illustrated below—formal definitions are provided in Section 2.Example 1.2. The core of the characteristic function game defined in Example 1.1 consists of all allocations (cid:6)x1, x2, x3(cid:7) ∈ R3that are solutions to the following set of lin",
            {
                "entities": [
                    [
                        135,
                        240,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 297 (2021) 103486Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA unifying look at sequence submodularity ✩Sara Bernardini a,∗a Department of Computer Science, Royal Holloway University of London, Egham, Surrey, TW20 0EX, UKb Department of Mathematical Sciences, Politecnico di Torino, Torino, 10129, Italyc Augmenta Inc., Toronto, M5A 1E1, Canada, Fabio Fagnani b, Chiara Piacentini ca r t i c l e i n f oa b s t r a c tArticle history:Received 11 September 2020Received in revised form 9 January 2021Accepted 16 February 2021Available online 24 February 2021Keywords:SubmodularitySequence submodularityGreedy algorithmsSuboptimal algorithmsDetection problemsSearch-and-trackingEnvironmental monitoringSchedulingRecommender systems1. IntroductionSeveral real-world problems in engineering and applied science require the selection of sequences that maximize a given reward function. Optimizing over sequences as opposed to sets requires exploring an exponentially larger search space and can become prohibitive in most cases of practical interest. However, if the objective function is submodular (intuitively, it exhibits a diminishing return property), the optimization problem becomes more manageable. Recently, there has been increasing interest in sequence submodularityin connection with applications such as recommender systems and online ad allocation. However, mostly ad hoc models and solutions have emerged within these applicative contexts. In consequence, the field appears fragmented and lacks coherence. In this paper, we offer a unified view of sequence submodularity and provide a generalized greedy algorithm that enjoys strong theoretical guarantees. We show how our approach naturally captures several application domains, and our algorithm encompasses existing methods, improving over them.© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).Many real-world applications in engineering and applied science have at their core the selection of sequences of objects that maximize a reward. In information gathering missions, for example, the objects are observations and the goal is to select a sequence of them that maximizes the information gain [1,2]. In a similar fashion, a movie recommender system aims to provide its users with sequences of items that maximize relevance [3,4]. The crucial point in these applications is that the value of the sequence depends not only on the objects belonging to it, but also on their relative order. This is because the value of each object changes based on its position in the sequence.If optimizing over sets is already a daunting task, optimizing over sequences quickly becomes unmanageable when the problem at hand grows. However, the identification of special properties in the objective function helps in making the task more approachable. Submodularity, in particular, has emerged as a powerful feature that can be leveraged to control complexity in the maximization of both set and sequence functions. Submodularity can be understood intuitively as a dimin-ishing return condition. Consider again an information-gathering mission. Each new observation increases the information gain, but it does it to a smaller extent than the previous observations, with gain vanishing at infinity.In areas as variegated as optimization, machine learning, economics, medicine and sensor networks, there has been a vast amount of work on the maximization of submodular set functions (see Section 2). Only recently, the scientific commu-✩This paper is an invited revision of a paper which first appeared at the 2020 International Conference Automated Planning and Scheduling (ICAPS-20).* Corresponding author.E-mail address: sara.bernardini@rhul.ac.uk (S. Bernardini).https://doi.org/10.1016/j.artint.2021.1034860004-3702/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fS. Bernardini, F. Fagnani and C. PiacentiniArtificial Intelligence 297 (2021) 103486nity has started to pay closer attention to sequence submodularity prompted by applications such as online ad allocation [5]and recommendations in online shopping [6], entertainment [3] and courses [7]. However, having arisen in specific applica-tive contexts, the proposed models as well as the corresponding algorithms lack generality and require making restrictive assumptions on the objective function to maintain efficiency.In this paper, to remedy the current ad hoc approach and lack of coherence in the field, we offer a unified view of sequence submodularity. By abstracting away specific applicative details, we show that the optimization problem that lies behind several applications can be captured by a particular type of recursive submodular function. We study its structure and, based on its properties, we propose a generalized greedy algorithm that has theoretical guarantees as strong as its classical counterpart on set functions but does not require unrealistic restrictive assumptions. Our generalized algorithm encompasses and improves the specific algorithms that have been developed for several practical applications. Another property that confers flexibility to our approach is that we can easily enforce constraints on the cardinality of the elements in the sequence (e.g. all elements must be distinct) in the domain description, which is particularly useful in applicative problems.The paper is organized as follows. After discussing related work in Section 2, we state the problem formally and introduce our running example in Section 3. In Section 4, we recall the concept of submodularity for sequence functions and show how, in general, a simple generalization of the classical greedy algorithm from sets to sequences fails to achieve good performance for several optimization problems of practical relevance. Subsequently, in Section 5, we propose and analyze a new greedy algorithm that is proven to achieve the same performance as the classical one for submodular set functions (Theorem 1). In Section 6, we study how this result can be applied to the general class of problems that we are interested in solving (Theorem 2 and Corollary 1) and, in Sections 7 and 8, we present several different application domains, which demonstrate the expressiveness and generality of our approach. Finally, Section 9 provides explicit numerical simulations for two of the applicative setups discussed in the previous two sections, while Sections 10 offers conclusive thoughts.2. Related workWork on submodularity spreads across multiple fields, including optimization [8,9], machine learning [10,11], economics [12,13], medicine [14] and sensor networks [15,16]. This body of work focuses on set functions and, as most of the problems considered are NP-complete, revolves around finding good approximations of the optimal solution via greedy approaches, which are very effective for non-decreasing, submodular functions [9]. We do not review this literature here as set functions are not our focus. For a comprehensive review on this topic, we refer the readers to the literature [17].Only recently, work on sequence submodularity has emerged. Streeter and Golovin [18] first considered this problem in the context of online resource allocation applications. Shortly after, Alaei and Malekian [5] introduced the term sequence submodularity and showed that if the submodular function is non-decreasing and differentiable, a greedy approach always achieves a solution that is at least 1 − 1e of the optimal one for the maximization problem.Zhang et al. [15] consider string submodularity, which is a weaker concept as the submodularity holds for the prefix relationship instead of for any type of subsequence relationship. They improve on Alaei and Malekian’s approximation by introducing additional constraints on the degree of string submodularity (curvature) of the objective function.Other authors have defined sequence submodularity within a graph-based setting. Tschiatschek et al. [4] consider cases in which dependencies between elements of a sequence can be captured via directed acyclic graphs (DAGs) and present an algorithm with theoretical guarantees for them. However, repetitions in the sequence are not allowed and DAG submodular functions are not necessarily string or sequence submodular.Mitrovic et al. [7] extend this graph-based framework to graphs and hypergraphs with bounded in or out degrees.Finally, Qian et al. [19] take a departure from the greedy approach and propose a Pareto optimization method for se-quence selection. They show that, for any class of submodular functions previously studied, their approach can always reach the best known approximation guarantee.Mitrovic et al. [20], on the other hand, consider the case in which the value of a sequence depends not only on the items selected and their order but also on the states of the items, which might be initially unknown (adaptive submodularity).Against the backdrop of this body of work, we aim to show that the submodular functions appearing in practical ap-plications do not satisfy the constraints imposed by the approaches highlighted here. However, they do present a common structure that can be exploited to equip a suitably modified greedy algorithm with strong theoretical guarantees.3. Problem statementIn this section, we formally introduce the optimization problems that we study in this paper. Let (cid:2) be a set and H((cid:2))be the language over (cid:2), i.e. the set of sequences of elements in (cid:2) of any length including the empty sequence ∅. Let Hd((cid:2))denote the sub-language consisting of all sequences in H((cid:2)) with distinct elements. If S = (S 1, . . . , Sn) ∈ H((cid:2)), with S ibeing the element of sequence S in position i, we denote with |S| = n the length of the sequen",
            {
                "entities": [
                    [
                        135,
                        176,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 160 (2004) 105–143www.elsevier.com/locate/artintA causal approach to nonmonotonic reasoningAlexander BochmanComputer Science Department, Holon Academic Institute of Technology, 52 Golomb St., Holon 58102, IsraelReceived 11 January 2004; accepted 24 July 2004AbstractWe introduce logical formalisms of production and causal inference relations based on in-put/output logics of Makinson and Van der Torre [J. Philos. Logic 29 (2000) 383–408]. Theseinference relations will be assigned, however, both standard semantics (giving interpretation totheir rules), and natural nonmonotonic semantics based on the principle of explanation closure.The resulting nonmonotonic formalisms will be shown to provide a logical representation of ab-ductive reasoning, and a complete characterization of causal nonmonotonic reasoning from McCainand Turner [Proc. AAAI-97, Providence, RI, 1997, pp. 460–465]. The results of the study suggestproduction and causal inference as general nonmonotonic formalisms providing an alternative repre-sentation for a significant part of nonmonotonic reasoning. 2004 Elsevier B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Causality; Abduction; Reasoning about action and change1. IntroductionThe field of nonmonotonic reasoning is so abundant with different formalisms, thatan attempt to introduce and justify yet another one appears to be doomed from the verybeginning. Nevertheless, this is precisely the main aim of this study.1 Accordingly, we haveto explain, first of all, what was the problem such that the new formalism is the suggestedsolution.E-mail address: bochmana@hait.ac.il (A. Bochman).1 A preliminary version of this paper has appeared as [7].0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.07.002\f106A. Bochman / Artificial Intelligence 160 (2004) 105–143To begin with, studies in nonmonotonic reasoning have given rise to two basicallydifferent approaches that could be called, respectively, preferential and explanatory non-monotonic reasoning, with little interaction between them.2 The first approach encom-passes nonmonotonic inference relations of [20], as well as a general theory of beliefchange. A detailed description of this approach can be found in [6]. The second approachincludes various default and modal nonmonotonic logics, as well as logic programming. Infact, all the papers in the famous 1980 issue of the Artificial Intelligence on NonmonotonicReasoning could be seen as belonging to this latter camp (though McCarthy’s circumscrip-tion is expressible also by the first approach). The formalism suggested in the present paperwill also belong to the explanatory approach.The above two approaches reflect, respectively, two different senses in which a logi-cal system can be nonmonotonic. First, its rules may not admit addition of new premises,that is, they do not satisfy Strengthening the Antecedent. Second, adding further rules tothe system may possibly invalidate earlier conclusions. These two kinds of nonmonotonic-ity are largely independent. Thus, preferential inference relations are nonmonotonic in thefirst sense, but monotonic in the second sense, since addition of new conditionals does notinvalidate previous derivations. On the other hand, default logic exemplifies monotonic-ity of the first kind and nonmonotonicity of the second kind. Default rules freely admitstrengthening of their pre-requisites and justifications, since this does not change the setof extensions (see [5]). However, adding arbitrary new rules to a default theory may cre-ate new extensions, so the nonmonotonic conclusions made earlier will not, in general, bepreserved.We believe that nonmonotonic reasoning should give us a more direct and adequatedescription of the actual ways we think about the world than, say, the classical logic. Inthis respect, the preferential nonmonotonic reasoning has a definite advantage over exist-ing explanatory counterparts in that it provides a direct semantic representation for its mainnonmonotonic objects, namely default conditionals “If A, then normally B”. This semanticrepresentation allows us to assess our default claims and determines, ultimately, the actualchoice of default assumptions made in particular circumstances. Default logic and its rel-atives take a different, less direct, route to assessing what can be inferred from a givenset of default rules. Namely, they require from the user to provide an explicit informationabout when one default can ‘block’ another default. This information is used as a sole fac-tor in determining acceptable combinations of defaults. This strategy can be remarkablysuccessful in resolving difficult cases of default interaction, which can be seen as the mainreason why the explanatory nonmonotonic reasoning so far has had a greater impact onpractical applications of nonmonotonic reasoning in AI. Still, the explanatory approach re-mains largely syntactic in nature, and does not give us a transparent and systematic way ofrepresenting empirical data. More precisely, due to the fact that default rules do not havea direct semantic interpretation, the task of knowledge representation in these formalismsbecomes really an art rather than a systematic methodology.32 They have been called, respectively, classical and argumentative nonmonotonic reasoning in [6].3 As was rightly mentioned by the reviewer, this is actually the problem with many other KR formalisms aswell.\fA. Bochman / Artificial Intelligence 160 (2004) 105–143107An additional, more specific, problem with the explanatory approach consists in theepistemic understanding of default rules it presupposes. A distinctive feature of both de-fault and modal nonmonotonic logics is that they are inherently epistemic formalisms.Namely, they are essentially based on such notions as belief and knowledge, unlike theextensional classical logic used for a direct representation of facts about the world. Accord-ingly, the intended semantic models of these formalisms represent (possibly incomplete)sets of beliefs one can have, while their rules allow to make inferences based on absenceof belief, or consistency, with respect to candidate belief sets (cf. the introductory sectionsof [33]). It seems that this modal formulation of many nonmonotonic formalisms is mainlydue to historical reasons: at the time these formalisms have emerged, modal logics alreadyreigned in the literature as a standard paradigm of logical representation. The epistemicinterpretation strongly influenced also logic programming in that the negation as failurehas often been formulated as absence of knowledge (or derivation).Due to its modal character, default logic has turned out to be a logically weak formalismthat does not support many classical inference principles (such as reasoning by cases). Ithas also other well-known shortcomings, and numerous variants of default logic have beensuggested in attempts to overcome them and make it more in accord with our intuitions.On our opinion, however, a relatively modest success of these attempts has shown that it isimpossible to radically improve default logic without abandoning its underlying epistemicinterpretation.The shortcomings of default logic became especially vivid in attempts to apply it toone of the primary application fields of nonmonotonic reasoning, a formal representationof actions and change. It was realized quite early that classical logic alone cannot providean efficient representation for reasoning about change due to the famous frame problem[30]—a problem of giving an efficient description for the state of the world after perform-ing an action that would avoid computationally unbearable reproduction of all the factsthat remain unaffected. There was also a related ramification problem of determining theindirect effects (ramifications) of actions that arise due to the laws of the domain. Andit was only natural to expect that nonmonotonic reasoning should help in resolving theseproblems.After some less successful attempts to formalize temporal nonmonotonic reasoning inexisting nonmonotonic logics, a dominant recent approach to solving these problems hasbeen based on causal reasoning. Given a set of action and causal rules describing the do-main, the causal approach employs a distinction between facts that hold in a situationversus facts that are caused (explained) by other facts and the rules. The corresponding ex-planation closure assumption amounts to a requirement that all facts that hold in a situationshould be either caused by other occurrent facts, or else preserve their truth-values in time(due to the associated inertia assumption). A natural formalization of these principles hasbeen given in the framework of causal theories, introduced in [26]. A causal theory is a setof causal rules that express causal (or explanatory) relations among propositions. The non-monotonic semantics of such theories is determined by causally explained models, namelythe models that both satisfy the causal rules and such that every fact holding in them isexplained by some causal rule. The resulting nonmonotonic formalism has been shown toprovide a plausible and efficient solution for both the frame and ramification problem (see[17,21,37] for a detailed exposition and applications in representing action domains). Re-\f108A. Bochman / Artificial Intelligence 160 (2004) 105–143lated causal approaches to representing actions and change have been suggested in [23,36,38], to mention only a few.From the point of view of the present study, the causal reasoning constitutes an impor-tant conceptual shift in the general framework of explanatory nonmonotonic reasoning,since it is based on a direct and transparent description of factual and causal (explanatory)information about the world. In other words, it shows that the epistemic view of non-monotonic reasoning is not the only possibility. Accordingly, the primary aim of our studywill consist in",
            {
                "entities": [
                    [
                        72,
                        115,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 639–669Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPartial observability and learnability ✩Loizos MichaelOpen University of Cyprus, Cyprusa r t i c l ei n f oa b s t r a c tArticle history:Received 11 November 2007Received in revised form 30 March 2010Accepted 30 March 2010Available online 1 April 2010Keywords:Partial observabilityAppearanceRealityMasking processSensingMissing informationAutodidactic learningProbably approximately correctInformation recoveryReductionWhen sensing its environment, an agent often receives information that only partiallydescribes the current state of affairs. The agent then attempts to predict what it has notsensed, by using other pieces of information available through its sensors. Machine learningtechniques can naturally aid this task, by providing the agent with the rules to be used formaking these predictions. For this to happen, however, learning algorithms need to bedeveloped that can deal with missing information in the learning examples in a principledmanner, and without the need for external supervision. We investigate this problem herein.We show how the Probably Approximately Correct semantics can be extended to deal withmissing information during both the learning and the evaluation phase. Learning examplesare drawn from some underlying probability distribution, but parts of them are hiddenbefore being passed to the learner. The goal is to learn rules that can accurately recoverinformation hidden in these learning examples. We show that for this to be done, oneshould first dispense the requirement that rules should always make definite predictions;“don’t know” is sometimes necessitated. On the other hand, such abstentions should not bedone freely, but only when sufficient information is not present for definite predictions tobe made. Under this premise, we show that to accurately recover missing information, itsuffices to learn rules that are highly consistent, i.e., rules that simply do not contradictthe agent’s sensory inputs. It is established that high consistency implies a somewhatdiscounted accuracy, and that this discount is, in some defined sense, unavoidable, anddepends on how adversarially information is hidden in the learning examples.Within our proposed learning model we prove that any PAC learnable class of monotone orread-once formulas is also learnable from incomplete learning examples. By contrast, weprove that parities and monotone-term 1-decision lists, which are properly PAC learnable,are not properly learnable under the new learning model. In the process of establishing ourpositive and negative results, we re-derive some basic PAC learnability machinery, such asOccam’s Razor, and reductions between learning tasks. We finally consider a special caseof learning from partial learning examples, where some prior bias exists on the manner inwhich information is hidden, and show how this provides a unified view of many previouslearning models that deal with missing information.the proposed learning model goes beyond a simple extension ofWe suggestsupervised learning to the case of incomplete learning examples. The principled andgeneral treatment of missing information during learning, we argue, allows an agent toemploy learning entirely autonomously, without relying on the presence of an externalteacher, as is the case in supervised learning. We call our learning model autodidactic toemphasize the explicit disassociation of this model from any form of external supervision.© 2010 Elsevier B.V. All rights reserved.that✩A preliminary version of this work appeared as: Loizos Michael, Learning from partial observations, in: Manuela M. Veloso (Ed.), Proceedings of theTwentieth International Joint Conference on Artificial Intelligence (IJCAI’07), January 2007, pp. 968–974. This work was completed while the author was atthe School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USA, and was supported by grant NSF-CCF-04-27129.E-mail address: loizos@ouc.ac.cy.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.03.004\f640L. Michael / Artificial Intelligence 174 (2010) 639–6691. IntroductionIt can be argued that a central aspect of a fully autonomous agent is the ability to learn the rules that govern its envi-ronment, without any form of external supervision. An autonomous agent senses its environment and obtains informationthat is often incomplete, which serves, then, as input to the learning process. Such settings necessitate, thus, the use oflearning algorithms that can deal with such incomplete learning examples.In this work we propose a framework within which learning from incomplete learning examples can be formally studied.For concreteness, our framework can be viewed as an extension of the Probably Approximately Correct semantics [28]. Ourgoal is to show that it is possible to learn rules that accurately predict information missing in an agent’s sensory readings,and that these rules can be obtained efficiently, and be accompanied by formal PAC-like guarantees, irrespectively of howinformation is hidden in the learning examples available during the learning and evaluation phases. We note, however, andpoint out throughout this work, that the problem of learning from incomplete learning examples goes beyond learningclassification rules as in the original PAC model. We view the results of this work as a first step towards the more ambitiousgoal of devising learning algorithms that can identify more general rules.Our exposition starts in Section 2, where the problem of learning from incomplete information is put into context,as the problem underlying the process of scientific discovery: identifying the structure of some underlying reality, givenonly partial appearances of that reality. We continue to show how the PAC semantics can be extended to this effect.As in the PAC model, learning examples are drawn independently at random from some underlying probability distribu-tion. Unlike the PAC model, these examples are never directly accessible by an agent. Instead, some arbitrary stochasticprocess hides parts of these examples, giving rise to what we call partial observations. These observations are then givento the agent, both during the learning phase as a means to facilitate learning, and during the evaluation phase as theinput on which learned rules are to be applied to make predictions, and against which these predictions are to betested.Due to lack of complete information during the evaluation phase, we allow learned rules to make “don’t know” pre-dictions, but only when the rules cannot be unambiguously evaluated on a given observation. Under this provision, wedefine a rule to be consistent with an observation if the rule’s prediction does not directly contradict what is stated inthe observation. In particular, if the observation does not offer any information on some target attribute, then any pre-diction is consistent. Learning is successful if highly consistent rules can be obtained efficiently in the relevant learningparameters.We then consider a stronger notion oflearnability, that of deriving rules that make predictions in a mannernot only consistent with an observation, but accurate with the underlying example. Thus, even if the observationdoes not offer any information on some target attribute, the prediction may be accurate or not depending on whatthe hidden underlying value of the target attribute is. We show that this more stringent notion oflearnability isinformation-theoretically unattainable when information is hidden adversarially in observations. We introduce a metriccalled concealment to capture the extent of this adversity, and show that consistency, accuracy, and concealment aretied together in a natural manner: consistency implies accuracy discounted by some factor determined by the conceal-ment. This allows us to focus on the conceptually simpler notion of consistent learnability for the remaining of thiswork.Section 3 discusses some of the choices we have made in our learning model, and contrasts them against existing work inStatistical Analysis and Learning Theory. Three main aspects are discussed: (i) when are “don’t know” predictions allowed,and what does it mean to predict “don’t know”; (ii) to what extent is autonomy possible when learning; and (iii) howmuch regularity is assumed in the way information is missing in learning examples. This discussion shows, in particular,that unlike most previous work, our learning framework does without the assumption of an external teacher. We call thelearning framework autodidactic in recognition of this property.The two subsequent sections provide positive and negative learnability results for autodidactic learnability. Section 4establishes that certain machinery available in the PAC model applies also, in some form, in the context of autodidacticlearnability. In particular, Occam’s Razor [4] applies unchanged as in PAC learnability, while reductions between learningtasks [23] can be formalized in a way that accommodates the more stringent requirements that need to be met for auto-didactic learnability. Using reductions we then establish that any PAC learnable concept class that contains only monotoneor read-once formulas can also be learned autodidactically. Hence, in a broad set of domains, the lack of complete infor-mation does not render learnability any harder. By contrast, Section 5 establishes that incomplete information may in somecases diminish learnability. We show that, although they are properly PAC learnable, the concept classes of parities andmonotone-term 1-decision lists are not properly learnable in the autodidactic model, unless RP = NP.The case where information is not hidden completely arbitrarily in learning examples is examined in Section 6. We argue,and demonstrate, that depending on how structured such informatio",
            {
                "entities": [
                    [
                        136,
                        174,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 289 (2020) 103384Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintQuantifying controllability in temporal networks with uncertainty ✩Shyan Akmal a,b,1, Savana Ammons a,c,1, Hemeng Li a,d,1, Michael Gao a,e,1, Lindsay Popowski a, James C. Boerkoel Jr. a,∗a Harvey Mudd College, Claremont, CA, USAb Massachusetts Institute of Technology, Cambridge, MA, USAc University of Illinois at Urbana-Champaign, Champaign, IL, USAd Cornell University, Ithaca, NY, USAe Stanford University, Stanford, CA, USAa r t i c l e i n f oa b s t r a c tArticle history:Received 1 November 2019Received in revised form 16 July 2020Accepted 7 September 2020Available online 23 September 2020Keywords:SchedulingTemporal planningControllabilityProbabilistic simple temporal networksSimple temporal networks with uncertaintyControllability for Simple Temporal Networks with Uncertainty (STNUs) has thus far been limited to three levels: strong, dynamic, and weak. Because of this, there is currently no systematic way for an agent to assess just how far from being controllable an uncontrollable STNU is. We provide new insights inspired by a geometric interpretation of STNUs to introduce the degrees of strong and dynamic controllability — continuous metrics that measure how far a network is from being controllable. We utilize these metrics to approximate the probabilities that an STNU can be dispatched successfully offline and online respectively. We introduce new methods for predicting the degrees of strong and dynamic controllability for uncontrollable networks. We further generalize these metrics by defining likelihood of controllability, a controllability measure that applies to Probabilistic Simple Temporal Networks (PSTNs). Finally, we empirically demonstrate that these metrics are good predictors of actual dispatch success rate for STNUs and PSTNs.© 2020 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionWhen tasked with making a schedule, a planner would ideally have the capability to pick exact times for every event that could occur. In practice however, autonomous agents rarely have control over all events affecting their plans. For example, imagine a chemist named Dr. V running a small experiment. She first combines 20 mL of chemical W and chemical X in a beaker. The exact amount of time it takes these chemicals to react is uncertain: all Dr. V knows is that it will take between twenty and thirty-one minutes for the reaction to finish (unfortunately, not much is known about the reaction rates of chemicals W and X). Within ten minutes of this reaction completing, she must add 20 mL of chemical Y to the mixture, ✩This paper is an invited revision of a paper [1] which first appeared at the 2019 International Conference on Automated Planning and Scheduling (ICAPS-19).* Corresponding author.lpopowski@hmc.edu (L. Popowski), boerkoel@hmc.edu (J.C. Boerkoel).E-mail addresses: naysh@mit.edu (S. Akmal), sammons@hmc.edu (S. Ammons), hl2359@cornell.edu (H. Li), mgao@hmc.edu (M. Gao), URL: https://www.heatlab.org (J.C. Boerkoel).1 Work on this paper was primarily completed while an undergraduate student at Harvey Mudd College.https://doi.org/10.1016/j.artint.2020.1033840004-3702/© 2020 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fS. Akmal, S. Ammons, H. Li et al.Artificial Intelligence 289 (2020) 103384Fig. 1. An STNU representation of Dr. V’s experiment.which catalyzes a new reaction taking thirty to thirty-five minutes. Finally, Dr. V must collect a product, precipitate Z, from the solution within ten minutes of the reaction completing.To run the experiment successfully, Dr. V needs to schedule several different events. She is able to select times for some events, such as the addition of chemical Y, but other events, such as the completion times of the reactions, are not under her control. There are multiple different strategies Dr. V can use to deal with this uncertainty in timing and ensure the experiment’s success. The effectiveness of different types of scheduling strategies is related to the scheduling problem’s controllability — how easily the experiment can be successfully executed given its inherent uncertainty. Currently, all forms of controllability discussed in the literature are discrete — they tell Dr. V whether her experiment is controllable or not, but do not tell her “how” controllable or uncontrollable the experiment is.In this paper, we extend the notion of controllability by introducing two new continuous metrics on temporal networks: the degrees of strong and dynamic controllability [1]. These metrics are motivated by a geometric interpretation of STNUs as pairs of polytopes and characterize how far a network is from being controllable given different types of execution strategies. These metrics naturally relate to the probability that a network can be successfully dispatched. In that context, we define optimization problems for determining the probability of successful dispatch given online/offline plans, and offer approximate solutions to these problems. Finally, we show that the degrees of both strong and dynamic controllability extend naturally and effectively to PSTNs [2].2. Background2.1. Simple Temporal NetworksA Simple Temporal Network (STN) is a tuple S = (cid:3)T , C(cid:4), where T is the set of temporal events ti , and C is the set of binary constraints on T [3]. Each element in C is of the form t j − ti ≤ ci j , for some ci j ∈ R. By convention, the event t0 ∈ T in an STN represents a fixed reference point assigned time zero. Because of this, when we say that an STN has n temporal events, we really mean that it has n time-points in addition to this reference event. A solution to an STN is an assignment of values to the timepoints ti that satisfies all constraints. A common approach to checking if an STN is consistent, that it has a solution, is to apply a shortest-path algorithm to a weighted, directed graph representation of the STN called a distance graph. If a negative cycle is discovered during the shortest-path process, it implies that the STN is inconsistent and thus no solutions exist; otherwise the resulting distance graph is a representation of the space of solutions.2.2. Simple Temporal Networks with UncertaintyA Simple Temporal Network with Uncertainty (STNU) is an STN that explicitly models uncertainty [4]. In an STNU, the set of events T is partitioned into a set of controllable events T c and a set of uncontrollable events T u . An agent is allowed to schedule specific times for the events in T c , but the times for events in T u are determined by “Nature,” a force external to the agent. For every t j ∈ T u , there exists a unique ti ∈ T c forming a contingent constraint of the form t j − ti ∈. We use Cc to denote the set of these contingent constraints, and Cr to denote the remaining requirement constraints between events in T . Then an STNU is defined as a quadruple (cid:3)T c, T u, Cr, Cc(cid:4) satisfying the aforementioned properties.(cid:2) j, u j(cid:2)(cid:3)In an STNU, a decision is an assignment of time values to each of the controllable events. A realization is a selection of values for contingent edges (relative start times of the uncontrollable events) assigned by Nature. The set of all possible realizations forms the realization space (cid:3) for the STNU. If a decision does not violate any of the constraints between pairs of controllable events, we say the decision is admissible. A decision together with a realization determines a schedule σ for the network. If σ satisfies all constraints in the STNU, we call σ a valid schedule.For example, Dr. V’s experiment from the introduction can be modeled as an STNU. There are five events of interest: the beginning of the first reaction, the conclusion of this initial reaction, the addition of chemical Y, the completion of the subsequent reaction, and the extraction of the precipitate. If we measure time relative to the experiment’s start, we can refer to these events as ti , where i ranges from 0 to 4 respectively. Events t0, t2 and t4 are under Dr. V’s control, while events t1 and t3 are uncontrollable. This STNU representation of the experiment is depicted in Fig. 1. Events in the network are drawn as nodes. Requirement and contingent edges are drawn as straight and curvy arrows respectively. The edges are labeled by intervals indicating the lower and upper bounds of the STNU’s constraints.2\fS. Akmal, S. Ammons, H. Li et al.2.3. ControllabilityArtificial Intelligence 289 (2020) 103384An STNU is controllable when an agent has a reasonable way of working around the uncertainty in the network to schedule events. Prior research has focused primarily on detecting three types of controllability: strong, dynamic, and weak. We focus on strong and dynamic controllability, since they are important for dispatch. We omit weak controllability from our discussion because it is less relevant to STNU execution [4]. Henceforth in this paper, we use the term “uncontrollable STNU” to refer to both STNUs that are not strongly controllable and those that are not dynamically controllable.An STNU is strongly controllable if there is a single fixed decision the agent can make that guarantees success regardless of how Nature behaves. More formally, a network is strongly controllable if there exists a decision δ such that for all ω ∈ (cid:3), the schedule determined by δ and ω is valid [4]. We call such a decision a strong decision. Using the example from the introduction, one can check that Dr. V’s experiment is not strongly controllable because there is no fixed decision she can make to guarantee the experiment’s success before it takes place.An STNU is dynamically controllable ",
            {
                "entities": [
                    [
                        135,
                        200,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 103 (1998) 237-271 Artificial Intelligence Inheritance comes of age: applying nonmonotonic techniques to problems in industry IBM ZJ. Watson Research Center; 30 Saw Mill River Road, Hawthorne, NY 10532, USA Leora Morgenstern ’ Abstract reasoning Nonmonotonic is virtually absent from industry and has been so since its inception; increasingly marginalized within AI. We argue that this the result is that the field is becoming is largely because researchers in the area focus exclusively on commonsense problems which are irrelevant to industry and because few efficient algorithms or tools have been developed. A sensible strategy is thus to focus on industry problems and to develop solutions within tractable subtheories of nonmonotonic logic. We examine an example of nonmonotonic formula-augmented reasoning insurance domain-and to a broader and more powerful kind of nonmonotonic in industry-inheritance of business rules show how the paradigm of inheritance with exceptions can reasoning. This is done by semantic networks (FANS), semantic networks which attach well- is that to other industry problems. 0 1998 Published by Elsevier Science B.V. All rights is given and discussed. Finally we discuss to nodes. The problem of inheriting well-formed formulae within this structure the underlying lessons in the medical be extended introducing formed formulae explored, and an algorithm can be generalized reserved. Keywords: Artificial intelligence; Inheritance; Inheritance networks; Semantic networks; Expert systems; Nonmonotonic reasoning; First-order logic; Rule-based systems; Insurance; Medical insurance; Benefits inquiry; Applications; Commercial applications; Medical AI; Nonmonotonic logic; Nonmonotonic techniques 1. Introduction Nonmonotonic logic, the formalization of plausible reasoning, is invisible and virtually nonexistent in industry. It is in a worse position, in this respect, than most other areas of ’ Email: leora@watson.ibm.com. 0004-3702/98/$ - see front matter 0 1998 Published by Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00073-3 \f238 L. Morgenstern /Artijkiul Intellipm 103 (1998) 237-271 Intelligence. It is true that AI researchers have long accustomed Artificial the huge gap between AI hype, which promises great things (e.g., housekeeping and AI reality, which delivers much less (robots that have a hard time collecting balls). themselves to robots), tennis reasoning circuit configuration, The absence of nonmonotonic that are based on nonmonotonic Yet AI as a whole is quite visible in the early eighties, when AI showed endless promise, and financial applications; such examples in industry and the marketplace. Although AI has delivered less than was anticipated one or two decades ago, there is enough going on: expert systems are used in medical diagnosis, dictation systems for restricted domains are on the market. Unfortunately, reasoning. 2 do not include applications from the commercial world may have been small cause for concern research money was plentiful, and the field was very young. As we approach the end of the nineties, for however, we have reason research programs future. There inhabit isolated; are no better off than researchers result the field will shrink, of a vibrant reasoning. to and research will dry up to the point where we that as a (or worse, philosophy); instead in to worry. Funding has shrunk, and there is little tolerance results in the foreseeable and industry is tackling one of the hardest problems reasoning will become marginalized leaving only a few die-hards research community which that do not promise-and is the real danger-if separate worlds-that for nonmonotonic in mathematics to one another deliver-practical nonmonotonic nonmonotonic that funding reasoning continue talking I believe of schadenfreude and I am concerned and the resentment of practitioners I do not feel happy about writing I am a member of the nonmonotonic about the current state of nonmonotonic one is used to hear from people outside the field of nonmonotonic rather than pessimism: and strengthen nonmonotonic that last paragraph. These are the sort of gloomy logic. in the past, I have usually put them down to some toward theorists. This reasoning prognostications When I have heard these sentiments combination is not the case here. On the contrary: research. But community, that we can stop the field from being this is concern reasoning as a central part of mainstream AI. marginalized, to In order to do so, we must find some way to make nonmonotonic industry. We need to understand why nonmonotonic reasoning and industry are so far apart and to figure out how to bridge the gap. We also need to see if there are any examples of nonmonotonic and mistakes The paper underlying strategies to bring these two areas closer together. Sections 3 through 5 examine example of a nonmonotonic inquiry the reasons reasoning and industry and suggests possible in detail an a benefits the standard paradigm in industry, and to study these examples for lessons to generalize as follows. Section 2 discusses industry. The system extends the gap between nonmonotonic system that I developed for industry-specifically, to avoid in the future. for the insurance reasoning useful is accordingly structured reasoning system ’ It might be argued that fuzzy logic [43], which also claims industrial applications. Without commenting fuzzy logic and nonmonotonic fuzzy logic in industry says little about the field of nonmonotonic (such as the logic programming nonmonotonicity. We discuss logic programming logic are quite separate in Section 2. to capture plausible reasoning, has been used in on the merits of this argument, we merely note that the fields of thus, the presence of in both philosophy and community; reasoning. It is also true that logic programming language Prolog [3]) is used in industry, though it is generally not used to capture \fL. Morgenstem / Artijcial Intelligence IO3 (1998) 237-2 71 239 inheritance formulae network. We explore how one can inherit well-formed by adding general well-formed of nonmonotonic an inheritance this structure, examine inquiry system with the necessary expressiveness we can avoid the complexity problems subsequently consider generalizations can be applied in general to joining nonmonotonic to the nodes in formulae using the benefits and reasoning ability, and discuss how systems. We reasoning of the system, and finally examine the lessons which reasoning and the commercial world. the ways in which nonmonotonic that beset nonmonotonic techniques provide 2. Analyzing the gap between nonmonotonic reasoning and industry 2.1. Reasons for the gap includes reasoning to conclusions Nonmonotonic in order to reasoning in the late 1970s [25,27,34] and retracting such conclusions ’ Plausible reasoning with default rules (rules that talk about a typical member of and if they are proved to be wrong. The first- that could reason more flexibly and fluently to make AI easier. logic would become a reasoning was first introduced formally capture plausible or default reasoning. with exceptions, a class, rather than all members of a class), reasoning with incomplete jumping aim in those early days was to construct a logic that is more powerful order logic and to aid in developing programs then available. Nonmonotonic than the programs As such, it could have been reasonably expected that nonmonotonic tool of software engineers In fact, this has not happened: is found only in academia and tolerant research labs. (as is the case, for example, with object-oriented two decades later, open activity logic was supposed in nonmonotonic programming). than classical information, research What went wrong? The answer, in a nutshell, near ready to handle industrial-strength been freely admitting is in itself cause for concern. Much of AI and all of industry Confession will not save us here: we need to determine why nonmonotonic not helped get things done. Three reasons come to mind. is nowhere freely admit this, and have it for the last twenty years. After this length of time, the admission is about getting things done. reasoning has problems. Researchers is that nonmonotonic reasoning (1) Nonmonotonic research has focussed almost exclusively on reasoning. The canonical Tweety problem-inferring is a bird and that birds that Tweety is a penguin-is typically seriously tackle when they develop new nonmonotonic toy problems oj’ that Tweety can fly that fly; and retracting still one of the benchmark logics the facts that Tweety upon discovering commonsense from conclusion problems or modify old ones. 4 that researchers 3 These papers, as well as other classic papers in the field. are collected in [ 121. 4 While all existing nonmonotonic on this problem are beyond some well-known nonmonotonic system based on consequence is a robin, robins are birds, and birds typically consequence-relation problem; reasoning problems. is that it is far from obvious systems. For example, a nonmonotonic Iogics, as far as I know, can solve the Tweety problem. simple variations reasoning infer that Tweety can fly from the facts that Tweety is in general not permitted in that can solve this variant Tweety systems can solve very simple logics.) A relatively simple fix [lo] results in a system the point, however, (as in [23]) cannot that nonmonotonic fly. (The problem is that chaining relations \f240 L. Morgenstem /Artificial Intelligence 103 (1998) 237-271 Indeed, nonmonotonic as the well-known Yale Shooting problem a gun, waits, and then fires the gun at a turkey, the turkey will die. 5 theories have trouble solving a host of other toy problems such [ 171, which involves predicting that if one loads It can be argued with a good deal of justification that commonsense is one for AI to model [5] and that sneering at reasoning of the more difficult areas of intelligent behavior research on the Tweety and Yale Shooting problems merely ref",
            {
                "entities": [
                    [
                        67,
                        149,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 193–219Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFirst-order logical filteringAfsaneh Shirazi∗, Eyal AmirUniversity of Illinois at Urbana-Champaign, Department of Computer Science, Urbana, IL 61801, USAa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:FilteringFirst-order logicBelief updateSituation calculus1. IntroductionLogical filtering is the process of updating a belief state (set of possible world states) aftera sequence of executed actions and perceived observations. In general, it is intractable indynamic domains that include many objects and relationships. Still, potential applicationsfor such domains (e.g., semantic web, autonomous agents, and partial-knowledge games)encourage research beyond intractability results.In this paper we present polynomial-time algorithms for filtering belief states that areencoded as First-Order Logic (FOL) formulas. Our algorithms are exact in many cases ofinterest. They accept belief states in FOL without functions, permitting arbitrary arity forpredicates, infinite universes of elements, and equality. They enable natural representationwith explicit references to unidentified objects and partially known relationships, stillmaintaining tractable computation. Previous results focus on more general cases that areintractable or permit only imprecise filtering. Our algorithms guarantee that belief-staterepresentation remains compact for STRIPS actions (among others) with unbounded-sizedomains. This guarantees tractable exact filtering indefinitely for those domains. The restof our results apply to expressive modeling languages, such as partial databases and beliefrevision in FOL.© 2010 Elsevier B.V. All rights reserved.Many everyday scenarios are dynamic and partially observable: a robot in one room cannot see the state of anotherroom, a camera overlooking a bookshelf cannot detect the title of a book that is obscured, and one cannot readily observethe amount of money an agent has. Many applications in such domains compute information about the current world state(belief state, i.e. set of possible states or a distribution over such a set) after performing actions and perceiving observations.This computation is called filtering (also, state estimation, belief update, and database progression). They use this informationto make decisions (e.g., “increase the asking price for my car”), answer questions (e.g., “where is my calculus book?”), andexplore (e.g., “go to room 2 and sense the state of the circuit break”).Filtering is intractable in general for discrete domains [17], and much research is dedicated to its approximation instochastic domains (e.g., [6,15,20]). Still, these approximations introduce unbounded errors many times, take unboundedcomputation time in others, and are not usable in most deterministic domains.Recent progress on logical methods for filtering of propositional belief states (sets of states) [3] with actions and obser-vations has shown that exact filtering is tractable when belief states are represented as propositional formulas, and certainnatural assumptions are met. Still, many domains have propositional encodings that are too large. In some domains, propo-sitional representation is not possible at all. This includes domains with large numbers of objects, unknown numbers of* Corresponding author.E-mail addresses: hajiamin@cs.uiuc.edu (A. Shirazi), eyal@cs.uiuc.edu (E. Amir).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.015\f194A. Shirazi, E. Amir / Artificial Intelligence 175 (2011) 193–219AlgorithmAssumptionsTime (1 step)SpaceDeduction filter (Section 3.2)Factored filter (Section 4)Unit-case filter (Section 5.1)STRIPS filter (Section 5.2)STRIPS filter (Section 5.2)none1:1 actions; Finite FOL filtering of atoms;precompilation stage1:1 Unit-Cases actions; UNAaSTRIPS actions; known success; UNA; ϕ inclausal formb; cases fully instantiatedSTRIPS actions; known success; UNA; ϕ in2-clausalc formunbounded (lazy computation)precompilation unbounded; O (|ϕ| · C)O (Rl(l + |ϕ| + p))O ((l|ψ|)2e)O (m2(R + n)2R )unboundedO (|ϕ| · C), C depends on pre-compilationO (Rl(l + |ϕ| + p))O ((l|ψ|)2e);O (m2(R + n)2R ) for any t > 0time stepsLegend: ϕ: input (initial) belief state; m: number of predicate symbols; R: maximum arity of predicates; n: number of constant symbols (not objects, whichmay be infinitely many); l: total number of cases for action a’s successor-state axioms; p: number of distinct atoms in the precondition of a; e: number ofdistinct affected literals of a.a UNA: Unique-Names Assumption.b Clausal form: Conjunction of disjunctions in ∃∗∀∗c 2-clausal: Every clause has (cid:2) 2 literals.fragment of FOL.Fig. 1. The algorithms presented in this paper, their properties, and their assumptions for correct filtering. All algorithms assume no function symbols. Noalgorithm assumes a finite domain or requires a closed-world assumption (CWA). (The CWA is made in many planning domains. It assumes that the onlyobjects in the domain are those mentioned explicitly.)objects, and observations with partial knowledge about identity of objects. Propositional methods are very inefficient insuch domains, and representations are typically large and cumbersome.In this paper we present tractable algorithms and theoretical results for filtering belief states that are represented in First-Order Logic (FOL). These representations permit belief states of infinite sizes, uncertainty about the number of objects andtheir identity, and observations that do not distinguish between some objects. It also enables more compact representationsthan those of propositional logic.More specifically (detailed results table is presented in Fig. 1), we present the following algorithms and complexitybounds on their performance: First, we show that when actions are partial functions that map states 1:1, we can filterarbitrary FOL belief-state formulas in time O (|ψ| · C), for ψ the input belief state representation, after a precompilationstage of the domain (not including ψ ). The output size is O (|ψ| · C), for C a constant (possibly large) that depends on ouractions’ definitions (not on the input sequence of actions or the initial belief state).Second, we examine in more detail two action representations that permit faster and more compact filtering withoutprecompilation of the domain. Both of those classes of domains represent the effects of actions by cases.For the first class of actions we show that filtering takes time O (Rl · (|ψ| + l + p)) for R the arity of predicate fluents, lthe total number of cases into which filtered actions break, and p the number of distinct atoms appearing in preconditionsof the action and in cases. The belief state returned has representation size O (Rl · (|ψ| + l + p)). To obtain these results weassume that actions are 1:1 and can be broken into cases conditioned on unit clauses (this is defined formally in Section 5.1),and that different constant symbols refer to different elements in our domain (this is the Unique Names Assumption (UNA)).We present a different result for the second class of action representations, namely, STRIPS actions [18] in two differentscenarios. In the first scenario we assume that every action case for a but one instantiates all variables in every affectedpredicate (thus making it a proposition). Also, we assume the UNA and that actions are executable when they are filtered.Given those, we show that filtering takes time O ((l|ψ|)2e) per action, for e the number of affected literals for action a. Also,we show that the resulting belief state formula is represented in space bounded by O ((l|ψ|)2e) (here, |ψ| is the size of theinput belief state).Focusing on filtering sequences of length T > 0, and assuming input belief states that have only clauses of (cid:2) 2 literals, weget a final, better result. Assuming UNA and STRIPS actions, not assuming full-instantiation of cases (cases may instantiatesubsets of variables), we show that the same algorithm for STRIPS actions takes time O (m2(R + n)2R ) per action, for mpredicates of arity at most R and n constant symbols. The output belief-state space representation is bounded by O (m2(R +n)2R ) regardless of the number of filtering steps. Thus, filtering a sequence of t > 0 actions and observations takes time(tm2(R + n)2R ).Notice that the domain may still be large (or infinite) when R, m, n are small, so this result enables tractable filteringfor some very large domains. This result guarantees tractable filtering for arbitrary sequence lengths with such domains. Itapplies to standard STRIPS actions, among others.These results support a growing belief that FOL can be used efficiently for representing and updating partial knowledge[40,66,53,41,65].En route to these contributions we relate deterministic Situation Calculus [53] with a FOL transition model [4]. In thetransition model, every belief state is a set of FOL structures over the FOL language of a state. We encode this set ofstructures with FOL formulas. We re-state results of [40,64] showing that filtering such belief states can be captured exactlyby deduction in FOL and that deduction can be carried out one time step at a time, if all we wish is to answer queries abouta particular future or past state.This forms the foundations for the rest of our results, which give an efficient (polynomial-time) exact algorithm forcomputing this deduction, under some common conditions as mentioned above.The rest of the paper is organized as follows. Section 2 describes the semantics that we use for FOL filtering. In Section 3we provide a naive algorithm for filtering and prove its correctness. Section 4 offers a polynomial time algorithm for FOL\fA. Shirazi, E. Amir / Artificial Intelligence 175 (2011) 193–219195filtering that requires domain precompilation and is exact for 1:1 actio",
            {
                "entities": [
                    [
                        136,
                        165,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 93 ( 1997) 201-260 Artificial lntelli~en~e Automated modeling of complex systems to answer prediction questions Jeff Rickela,* Bruce Porterb a Information Sciences Insrifufe and Depurfment of Computer Science, University of Southern California, 4676 Admiralty Way, Marina de1 Rey, CA 90292, USA h Depuriment of Computer Sciences, Universify of Texas at Austin, Austin, TX 78712-1188, USA Received April 1996; revised November 1996 Abstract A question about the behavior of a complex, physical system can be answered by simulating challenge is building a model of the system that is approp~ate for answering the the system-the question. If the model omits relevant aspects of the system, the predicted behavior may be wrong. If, on the other hand, the model includes many aspects that are irrelevant to the question, it may be difficult to simulate and explain. The leading approach to automated modeling, “compositional modeling”, constructs a simplest adequate model for a question from building blocks (“model that are designed by knowledge engineers. This paper presents a new compositional fragments”) modeling algo~thm that constructs models from simpler building blocks-the individual influences addresses important modeling issues that previous programs left to among system variables-and the knowledge engineer. In the most rigorous test of a modeling algorithm to date, we implemented our algorithm, applied it to a large knowledge base for plant physiology, and asked a domain expert to evaluate the models it produced. @ 1997 Elsevier Science B.V. Keywords: Automated modeling; Reasoning about physical systems: Large knowledge bases 1. Introduction Biologists, ecologists, doctors and engineers of a class of complex physical deep understanding and simulate models of these systems cal conditions. This skill is required to predict for many skill: each has a share an important systems, the system’s response tasks, such as evaluating and each can construct to hypotheti- designs and * Corresponding author. E-mail: rickel@isi.edu. 00043702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PI1 SOOO4-3702(96)00052-S \f202 J. Ricked, 3. I’~rter/Art~~i~ll Intelligence 93 (1997) 20i-260 and teaching. While the effects of trends (e.g., global warming), there are well-developed methods testing diag- for simulating control strategies, predicting nostic hypotheses, models, cause model construction prone, our objective knowledge of how a complex thetical conditions the system interest. that can adequately research on constructing models automatically requires is to automate expertise the modeling and system works) and some variables of interest), predict and explain is still time consuming is often task: given domain knowledge in its early stages. Be- and ergot (i.e., (i.e., hypo- construct the simplest model of the behavior of the variables of and a prediction question shift decisions important modeling Current modeling programs engineer. For example, some early programs useful models of the physical a relatively perform programs model for answering approach build-all combinatorially detail with which each phenomenon is impractical the models task: each question. To answer questions engineer the knowledge (the “graph of models” approach to the knowledge required a knowledge base of all potentially ] I ] >. These the best this alone, for a wide range of questions. The set of models grows levels of about complex systems, cannot anticipate-let they select, but do not generate, with the number of phenomena in the system and the various system easy required because Recent modeling can be modeled. take a more practical [ 121: the domain knowledge provides models of different approach, programs (“model fragments”), to the question. aspects of the and the modeling program uses them as building blocks the the those that modeling” system to construct an appropriate model for each question. To build an appropriate model, faces many difficult decisions. From all the phenomena governing program typically system’s behavior, the program must select, and include are relevant will be unreliable; model might be difficult phenomena, example, or as a complex sequence of more-detailed decomposed). Because compositional modeling programs automatically phenomena anticipate the relevant for each one. For reaction (each of which could be similarly choose relevant engineer need not and understand. the program must choose an appropriate irrelevant phenomenal to selecting can be described as a single chemical In addition level of detail the process of photosynthesis and build all the models the model’s predictions that might be needed. relevant phenomena, if it includes many on the other hand, in the model, only for each question, levels of detail the knowledge to simulate If it omits reactions and called “compositional Although knowledge, engineer, First, must group domain building blocks for making modeling model conditions this is knowledge is not readily available fragment, the compositional modeling approach simplifies current programs still shift important modeling decisions the task of encoding domain to the knowledge bundles indivisible fragments; the model the knowledge facts into coherent, engineer must design that is, he that the program can use as for constructing models. Second, he must supply most of the criteria each the assumptions. Because about constructing models, not about how a physical system works, it represent incompatibilities from among different modeling he must and among ~sumptions, the dependencies the assumptions underlying decisions: and that require choosing from domain experts. This paper describes a new compositional modeling algorithm that does not require such knowledge. Our algorithm constructs models from simple building blocks-the \f.I. Rickel, B. Porter/Artijicial Intelligence 93 (1997) 201-260 203 them-and is adequate [ 151 among for answering than alternative models. system, and the influences issues that previous programs these issues, our algorithm uses novel, domain-independent variables of the physical the modeling individual left to the knowledge engineer. To addresses that define address it when a model (See Section 3.) With these criteria, a modeler can is simpler that govern make decisions while knowing a physical role of variables and influences system; in every modeling decision. We prove that our modeling algorithm will build a simplest that adequate model one can be built (See Section 4.) the building blocks provided by the domain knowledge. little more than the variables and influences a particular prediction question and when for each prediction question, assuming (as defined by the criteria) the criteria demonstrate the central criteria from We implemented our modeling algorithm we integrated TRIPEL with a qualitative Compiler is to combine questions. simulation [ 14]), which simulates TFUPEL'S models to fully automate the pieces needed in a program called TRIPEL. ' In addition, (the Qualitative Process program to generate predictions. * Our goal prediction the task of answering in constructed in the domain of plant physiology. three ways. First, to encode tested on examples rigorous, that can support a wide range of tasks, not just prediction. We evaluated our algorithm by applying TRIPEL to the task of answering predic- (See Section 5.) While previous by their design- the domain fundamental tion questions have only been modeling programs ers, our evaluation is considerably more knowledge was encoded by a botany expert. His goal was textbook knowledge the same knowledge fact, answering questions description domain knowledge he encoded ical plant and 1500 influences Finally, the questions who judged TRIPEL'S models by comparing the questions. Our goal to answer unanticipated perts. (In tasks, such as the it describes 700 properties of a prototyp- levels of detail. including many different to evaluate TRIPEL were produced by the botany expert, for answering robust ex- to his own models that bases built by domain is to build a modeling using questions base has been used successfully is extensive: them, among and generating English [ 3 I-331 .) Second, large knowledge is sufficiently for other program them used text The evaluation identified the most important that, for some modeling decisions, it showed than TRIPEL uses. TRIPEL is designed for each type of modeling TRIPEL, and each module algorithm. decision are encapsulated can be improved without to easily topics for future research. the expert uses more sophisticated incorporate new criteria: In particular, criteria the criteria in an independent module of to the other changes requiring To lay the groundwork algorithm. modeling for these topics, the next section describes the input to our ’ The name TRIPEL. is an acronym for “Tailoring Relevant Influences for Predictive and Explanatory Lever- age”. It is also a style of strong ale made by Trappist Monks in Belgium. 2 Although TRIPEL has only been used to construct qualitative models algorithm differential equations. (See Section 6.) is equally capable of building numerical models, consisting of algebraic [ 531, we believe that our modeling and ordinary equations \f204 J. Rickel, B. P~~~te~/Art~cial intelligence 93 (I 997) 20/-260 2. System descriptions and prediction questions Our modeling algorithm requires form of a prediction physical system works system. The following question, general a plant’s consisting tions variables of interest the example would describe soil. transpirations of a physical (e.g., decreasing (e.g., (the system description), from question: rate ?” A prediction system two inputs: domain knowledge and a prediction “How would decreasing the domain of plant physiology, question about illustrates about how some the the affect scenario, its soil) and some driving condi- and asks for the resulting behavior of specified for transpiration the plant and its rate). Th",
            {
                "entities": [
                    [
                        67,
                        135,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 107 (1999) 63-98 Artificial Intelligence Reasoning about nondeterministic and concurrent actions: A process algebra approach * Xiao Jun Chen a,1 , Giuseppe De Giacomo b,* a School of Computer Science, University of Windsor, 401 Sunset Avenue, Windsos Ontario, Canada N9B 3S7 b Dipartimento di Informatica e Sistemistica, Vniversitci di Roma “L.a Sapienza”, via Salaria 113, 00198 Roma, Italy Received 10 December 1996; received in revised form 12 May 1998 Abstract actions) We present about processes activities (complex concurrent a framework for reasoning that are constituted performed by various by interacting agents. The framework is based on several formalism, which is a CCS-like process algebra associated two distinct formalisms: a representation is an extension of modal mu- with an explicit global store; and a reasoning logics such as PDL and APDL, and logic of programs calculus, a powerful branching logics such as CTL and CTL*. The reasoning service of interest in this setting is temporal model checking in contrast to logical implication. This framework, although directly applicable only when complete information on the system behavior is available, has several interesting features for reasoning about actions in Artificial Intelligence. tools from in Computer Science, to deal with complex actions, treating suitably aspects the area of Concurrency like nonterminating and interruptions. 0 1999 Published by Elsevier Science B.V. All rights reserved. executions, parallelism, communications, it inherits formal and practical that subsumes dynamic formalism, which Indeed, Keywords: Process algebra; Modal mu-calculus; Reasoning about actions; Concurrency; Model checking; Logical implication 1. Introduction In this paper, we present a piece of research in Artificial the area of Reasoning about Actions in Computer Science. that can be regarded as a bridge between and the area of Concurrency Intelligence * A shorter version of this paper appeared in the Proceeding of the Thirteenth National Conference on Artificial Intelligence (AAAI-96). * Corresponding 1 Email: xjchen@cs.uwindsor.ca. author. Email: degiacomo@dis.uniromal .it. 0004-3702/99/$ PII: SOOO4-3702(98)00104-O - see front matter 0 1999 Published by Elsevier Science B.V. All rights reserved. \fOn the one hand, we follow a methodology that is typical of Reasoning about Actions for specifying and reasoning about dynamic systems (e.g., see the a set of facts whose value changes as the system e#ect.s of (atomic) actions on such a set of facts resulting axioms in [49]). We also axioms in to change during the evolution of the system to this general picture, we allow that will become clear later in Artificial Intelligence situation calculus in [49]): introducing evolves (cf. &YZ~.F in [49]); specifying (cf. effect axioms in [49]); devising a suitable means to obtain the successor-state from executing an action in the current state (cf. successor-state introduce a specification of preconditions [49]). However, we allow such a specification (differently from precondition for multiple atomic actions to occur together on. we call the resulting actions synchmni~ed actions instead of concurrent actions as, e.g., in [2.5,24,42,50]), control structures by introducing (elementary) actions within suitable recursion, etc.) an explicit notion of process in describing for executing actions (cf. precondition and we allow for organizing axioms in [49]). In addition (sequential composition, parallel composition, (for reasons iteration, On the other hand, we make use of modeling in Computer Science to formalize concurrent processes, of Concurrency typically used in Reasoning about Action in Artificial in order to make use of such tools, we need to describe concrete level of abstraction Intelligence the dynamic In general, we may choose among several than the one typically adopted in Reasoning about Actions. levels of abstraction when describing in the area instead of the ones (i.e., logics). However, system on a more the system. tools that have been developed dynamic system, depending on the information we assume available. We distinguish following three levels: a the (1) At a very concrete evolution, which can be represented we assume complete action will be performed next. level, we may characterize the system by its unique actual as a sequence of states/actions. At this level, information on each state, and we assume knowledge of which (2) At a more abstract system, the system In this case, as a transition that can be performed level, we may characterize as a p&h on such a graph. One of these paths is going is represented instead of a single sequence. The single evolution the system by all its possible graph, called evolutions. at level 1 transition is represented to be the actual evolution of the system, yet we do not have the knowledge on which one a state) has several labeled out-arcs which represent it is. Each node (representing the transition the actions of the system from the current state to a possible successor-state. We remark different out-arcs may be labeled by the same action. has several alternative outcomes: assume complete is completely known. action action is going to be performed next. Moreover, not known which of the alternative that the action In this case, is nondeterministic. At this level, we on the possible evolutions of the system: each state to be performed, and each leads to some completely known state. However, we do not know which it is actions, resulting states is going to be the next one. in that state. Each action causes including which actions enabled for nondeterministic information the action (3) At the third level, we model the system by selecting a set of transition instead of a unique one. Each of such transition possible behavior. At this level, we assume partial systems systems represents an alternative on the possible information \fX.J. Chen, G. De Giacomo /Artz$cial Intelligence 107 (1999) 63-98 h5 evolutions of the system: each state is only partially known, and so are the states resulting from performing an action in it. too concrete: Generally, level 1 is considered to obtain such complete in order to single out a unique system run. 2 Levels 2 and 3 instead, have been it is unrealistic information both used in modeling dynamic systems. In particular, level 3 is the one usually adopted by research logic (situation calculus, dynamic in reasoning about actions logic, etc.) is [24,37,38,41,42,49,51], used both to represent and to reason about the dynamic problem of interest in this case is logic& implication where a certain systems. The typical reasoning (validity) in the form where l-’ are axioms used to select the set of transition the dynamic system; Sinit is a formula, which is a (partial) description of the initial state; @ is a formula, which is the property we want to prove, e.g., the reachability of a state where a certain property (the goal) holds. systems that represent In this paper, we adopt of level 2. Following the viewpoint in [27], we use a representation the possible evolutions formalism to define the model checking the transition formalism of the system, and a reasoning reactive and tool for describing concurrent and multiprocess systems. 3 Process properties we want to check. This framework is the (e.g., CCS [45], CSP [30], ACP [3]) to model as a are generally systems. They provide us with a recognized algebras for specifying approach proposed system representing (a suitable logic) one typically used in process algebras concurrent convenient clean way to express parallelism, synchronizations/asynchronizations, that can be interpreted on finite developed and implemented satisfied by the process (e.g., [6,10,11,44]). reactivity, communications, interruptions, etc. Moreover, for finite state processes transition systems), various practical to verify whether a given modal/temporal coordinations, (processes tools have been is logic formula The reasoning problem of interest in this case is model checking in the form where 7 is a transition system representing the possible evolutions of our dynamic system; sinit is the initial state of 7; Q, is a formula, which is the property we want to prove, e.g., the reachability of a state where a certain property (the goal) holds. In our work, the state of the system called conjigurution, called process and a passive component the activities of all component describes subroutines, a set of primitive propositions, describes are going on. The configuration in fact make the system evolve. environment, the agents is composed of an active called global store. The process robots, persons, pieces of software, etc.) in the system. The global store, which is characterized by that in the process, which the state of the world except for the activities can only be changed by the activities (e.g., 2 However, one can describe a dynamic system by specifying its properties using Linear-time Temporal Logics that are interpreted over system runs (see, e.g., [18]). 3 In Artificial research be considered at this level. In contrast, Intelligence, in search-based planning, research in deductive planning including much work on STRIPS (e.g., [8]) can is typically carried out at level 3. \f66 X.J. Chen, G. De Gincomo /Artificial lntvlli~ence 107 (1999) 63-98 Making use of a global store associated in terms of the difference between the effects of an action the current global store and the resulting one. Properties not mentioned among such effects are kept unchanged. 4 Note that this treatment [34], where is different from most of the approaches all properties of the state resulting in the literature on logics of programs from an action must be specified explicitly. to a process, we specify In order to reason about the properties of such modeled dynamic a suitable extension of modal mu-calculus subsumes dynamic CTL” [ 181. We show that model checking checking efficiently our setting. the existi",
            {
                "entities": [
                    [
                        65,
                        148,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 274 (2019) 44–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDistributional semantics of objects in visual scenes in comparison to textTimo Lüddecke a,∗Minija Tamosiunaite a,b, Florentin Wörgötter aa Georg-August-University Göttingen, Third Institute of Physics, Germanyb Vytautas Magnus University, Faculty of Informatics, Lithuania, Alejandro Agostini a, Michael Fauth a, a r t i c l e i n f oa b s t r a c tArticle history:Received 24 July 2017Received in revised form 31 May 2018Accepted 4 December 2018Available online 7 February 2019Keywords:Object semanticsVision and languageSemanticsDistributional hypothesisComputer visionThe distributional hypothesis states that the meaning of a concept is defined through the contexts it occurs in. In practice, often word co-occurrence and proximity are analyzed in text corpora for a given word to obtain a real-valued semantic word vector, which is taken to (at least partially) encode the meaning of this word. Here we transfer this idea from text to images, where pre-assigned labels of other objects or activations of convolutional neural networks serve as context. We propose a simple algorithm that extracts and processes object contexts from an image database and yields semantic vectors for objects. We show empirically that these representations exhibit on par performance with state-of-the-art distributional models over a set of conventional objects. For this we employ well-known word benchmarks in addition to a newly proposed object-centric benchmark.© 2019 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionIt remains a matter of debate, which aspects constitute the meaning of a word or of an object in a scene and the term meaning is heavily discussed in different fields. Here we are specifically concerned with the distributional representation hypothesis by Harris [17], which states that the company of a word determines its meaning (distributional semantics). This study sets out to test this hypothesis on images.For the definition of meaning in the above sense, natural language processing (NLP) uses semantic vectors, which repre-sent word-neighborhoods in a sentence. This approach has proven to be useful in many different applications, e.g. for text translation between different languages [27], for determining the sentiment of a sentence [33] and for question answering [39]. Thesaurus generation, spelling correction, and query expansion count among further applications discussed by Turney and Pantel [37].Analogously, context in visual scenes is also important for defining the meaning of objects. It might serve as a basis for a variety of approaches in image understanding that involve interactions across multiple objects, e.g. determining useful robotic actions or finding task-relevant objects in a scene. Thus, in this work, inspired by NLP approaches, we develop methods to obtain semantic vector representations of objects by considering their respective contexts in real world scenes that are composed of multiple objects.* Corresponding author.E-mail address: timo.lueddecke@phys.uni-goettingen.de (T. Lüddecke).https://doi.org/10.1016/j.artint.2018.12.0090004-3702/© 2019 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\fT. Lüddecke et al. / Artificial Intelligence 274 (2019) 44–6545Fig. 1. By assessing object co-occurrences and visual features we obtain semantic vectors for objects (right, actual output).Texts and scenes are akin structures, both being composed of many individual but inter-related constituents: words or objects. The location of a word in a sentence but also that of an object in a scene is subject to some constraints. On the one hand, these constraints can be fundamental, e.g. imposed by grammar or physics. The violation of these constrains will render a sentence wrong or make a scene impossible or nonsensical. E.g., grammar forbids two subsequent articles as much as a chair can not stand on the ceiling due to gravity.On the other hand, obeying only grammatical constraints does not guarantee that a sentence will make sense and the laws of physics will also not guarantee that a room has a useful structure. For making sense also the respective neighbor-hoods need to be appropriate, i.e. the context in which words are used or the arrangement of items in a room.Furthermore, context can help to disentangle multiple meanings of words or objects. For example in natural language, the meaning of a polyseme depends on its context and, similarly, multi-functional objects are employed differently depending on the situation. In the same way that e.g. the word “board” acquires a particular sense (out of many) by contextual words, objects surrounding a coffee cup in a scene constrain the set of useful actions involving the cup (e.g. at a coffee klatsch v.s. when the same cup is in the sink with dirty dishes).However, it is only text analysis where there has been a long history of approaches that address the question of distribu-tional semantics and that derive the meaning of a word, at least to some degree, from context. Interest in these approaches recently revived by the success of large-scale methods [28,29] exhibiting remarkable performance in judging similarity or analogy of concepts. By contrast, little work has been done on obtaining meanings of objects by considering their scene contexts. This should, however, be possible, in particular due to the large-scale data-sets that have recently been published in the computer vision community, which allow now for the investigation of distributed semantics in the domain of objects. Therefore, it seems justified to investigate the learning of semantic vectors not only of words but also of objects.In this work we study the hypothesis that the spatial context contributes to the meaning of an object in a scene, anal-ogously to surrounding words defining the meaning of a word. To gather evidence we design an algorithm that extracts semantic vectors from scenes as visualized in Fig. 1. We aim at analyzing a big enough set of images to arrive at a represen-tation, where semantic vectors for similar objects would group together. Fig. 1 schematically shows this for cake, spoon, forkand knife, which group together (see schema with object names) but remain separate from bicycle, motorcycle and car, which form a different group. Just from common sense one would hope to obtain such clustering results, but there are obvious differences between sentences and scenes. In contrast to a scene, a text is a linear structure, i.e. each word has a predeces-sor and a successor. Thus, while there is the straightforward assumption that the distributional hypothesis should also hold for images, it remains quite a question whether or not the more complex 3D layout of the visual world (or its 2D image projections) might not render context relations too spread out? Hence, we ask: Will scenes provide equally strong context relations than text? In this paper we address this question comparing a large set of different NLP as well as image-based methods.1.1. Overview of the approachA schematic introduction to our approach in comparison to linguistic approaches is presented in Fig. 2. Common distri-butional models (top) take natural language text corpora, determine word sequences, and generate context vectors by word co-occurrence. A context vector describes the surrounding of individual entities (such as words) by an array of real numbers. Different methods are used to combine such vectors so that finally semantic vector representations emerge for different con-cepts that can be compared. In essence, our approach (middle) is similar, but it only considers concepts that are objects. We take scene datasets and extract different image descriptors, which are (see numbering in the figure): 1) Human-assigned object labels, 2) object labels automatically obtained by applying an RCNN [14] to detect objects, and 3) CNN activations, which are features generated using pre-trained convolutional neural networks. From all three approaches we extract context vectors for each object in each scene. Context vectors are then merged together to create the unique semantic vector for a specific object class. This allows directly comparing not only the three types of descriptors but also benchmarking our results against automatic NLP-based methods (top) as well as against human rater-based methods (bottom). This is done by measuring semantic distances between objects (the inverse of semantic similarity) in the respective semantic vector spaces.\f46T. Lüddecke et al. / Artificial Intelligence 274 (2019) 44–65Fig. 2. Flow diagrams of the analyzes performed here with standard natural language processing, our new approach, as well as based on human labeling. In red, we show the abbreviation of the different analysis methods used (for descriptions see Methods). (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)1.2. ContributionsWe propose a simple algorithm to compute semantic vectors for object classes in segmented images and extensively compare this with existing (text-based) methods. This paper is to our knowledge the first to specifically focus on objects in scenes. In addition to the analysis of existing data, we also collected a dataset of similarity and relatedness judgments for 250 object pairs from 20 raters specifically slanted towards everyday objects.Our analysis shows that the obtained image-based representations are on par with existing text-based representation methods. Quality can be further improved by concatenating different context models. These findings indicate that not only text might serve as a basis for distr",
            {
                "entities": [
                    [
                        134,
                        208,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 51–71Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA logic of delegationTimothy J. Norman a,∗, Chris Reed ba Department of Computing Science, University of Aberdeen, Aberdeen AB24 3UE, Scotland, UKb School of Computing, University of Dundee, Dundee DD1 4HN, Scotland, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 29 October 2008Received in revised form 1 October 2009Accepted 4 October 2009Available online 13 October 2009Keywords:DelegationGroupsImperativesResponsibilityAgent communication1. IntroductionDelegation is a foundational concept for understanding and engineering systems thatinteract and execute tasks autonomously. By extending recent work on tensed actionlogic, it becomes possible to pin down a specific interpretation of responsibility witha well specified semantics and a convenient and intuitive logic for expression. Oncedescriptions of direct agent responsibility can be formed, there is a foundation uponwhich to characterise the dynamics of how responsibility can be acquired, transferred anddischarged and, in particular, how delegation can be effected. The resulting logic, designedspecifically to cater for responsibility and delegation, can then be employed to offer anaxiological and semantic exploration of the related concepts of forbearance, imperativesand group communication.© 2009 Published by Elsevier B.V.Delegation is a concept that pervades agent-based computing — tasks such as the purchase of goods within an electronicinstitution may be delegated to a software agent acting on behalf of a user [14,16], a goal may be delegated from oneagent to another each representing different commercial organisations via, for example, the Contract Net protocol [49], oran agent representing a manager within one organisation may, by virtue of their organisational position, delegate a taskto an agent representing a subordinate [33]. Understanding the nature and complexities of delegation, therefore, has thepotential to impact upon a wide audience within AI. In this paper we address the problem of understanding delegationdirectly by presenting a responsibility-based semantics of delegation (Section 2), that provides for an axiological account ofhow responsibility is transferred during delegation. With the basic mechanics of delegation in place, several tricky cases arethen examined in detail, including:(1) the interaction between delegation and time (and specifically, how axioms of delegation might be extended in a tensedlogic) (Section 3.1);(2) the relationship between responsibility and the concept of forbearance (and in particular, whether the Refref conjec-ture [2], by which activity is claimed to be equivalent to refraining from refraining, is a defensible axiom) (Section 3.2);and(3) the way in which group-addressed communication can effect delegative transfer of responsibility (and specifically, howdistributive and collective responsibility [43] is composed from the responsibilities of the individuals in a group) (Sec-tion 3.3).* Corresponding author.E-mail addresses: t.j.norman@abdn.ac.uk (T.J. Norman), chris@computing.dundee.ac.uk (C. Reed).0004-3702/$ – see front matter © 2009 Published by Elsevier B.V.doi:10.1016/j.artint.2009.10.001\f52T.J. Norman, C. Reed / Artificial Intelligence 174 (2010) 51–71Finally, with a rich account of delegation in place, we explore how imperative communication can be used to executedelegation, how responsibility is acquired as a result, and how it can be discharged through appropriate action meeting theconstraints of whole-hearted satisfaction [23] (Section 4).2. FoundationThe first step in characterising delegation is to construct a model of agent responsibility, so that the former can bedefined as a special case of the latter in which particular actions (often communicative actions) lead to a transfer of re-sponsibility. Such a model needs to tie together agent intentions, actions, and states of the world. Elsewhere [42] we haveargued that to handle this richness competently, it is necessary to adopt an approach that represents both states and eventsas first class objects. The argument there, and subsequent exploration of the system that results, leans heavily on founda-tional work carried out by Hamblin [23] in his investigation of imperatives. In this section we summarise a logic designed tocapture the nature of the imperative based upon Hamblin’s Action-State Semantics. The logic captures, at both the semanticand syntactic levels, the important ontological distinction between ‘responsibility for the achievement of a state of affairs’(captured by the modality S) and ‘responsibility for the execution of an action’ (captured by the modality T). This is one ofthe key distinguishing features of the language, which we refer to as ST.2.1. SyntaxIn presenting the syntax of our language, ST, we begin by defining the set of well-formed formulae, then briefly discussaxioms and rules of inference of the modalities S and T and of a standard Peircean tense logic which is used to enable theexpression of tensed responsibility formulae. This, along with the Hamblinian semantics of ST summarised in Section 2.2,lays the groundwork for the detailed analysis of the nature of delegation presented in Section 3.Basic atoms of the language ST include states of affairs, referred to using upper case Roman letters ( A, B, C , . . . ), actions,which are referred to using lower case Greek letters (α, β, γ , . . . ), and agents, for which we use x, y, . . . . We denote that aspecific agent, x, executes action α in the following manner: αx. Where the agent of an action is not specified, it is assumedthat the action is carried out by some agent but it is not important which one.The modalities S and T are relativised to specific agents and refer to state formulae and event formulae respectively. Inthis way, Sx A refers to agent x being responsible for the achievement of the state of affairs A, and Txα refers to x beingresponsible for the execution of action α. Note that these modal statements do not specify any particular action for agent x.In satisfying Txα, for example, agent x may order some other agent, y, to carry out α.Any sentence in the language may be tensed through the use of the modalities G (always true in all futures) and H(always true in all pasts), and their respective duals, F (true at some point in a possible future) and P (true at some point ina possible past). Tensed sentences are S-formulae; to say that something will be true, or that some action has been done,etc. is a state of affairs. It is, however, entirely reasonable to permit tense operators to range over both states and events:states of affairs may have held in the past, and events may happen in the future, etc.We may now define the well-formed formulae of our language ST. The basic atoms of our language are divided intotwo classes: (i) event formulae — those that consist entirely of propositional expressions of action (bound or unbound), and(ii) state formulae — all others. All such basic atoms are wffs. By conventional Propositional Logic (PL), for any two wffs, φand ψ , that are event formulae, φ ∨ ψ , φ ∧ ψ , φ → ψ and ¬φ are also wffs that are event formulae. Similarly for any twowffs that are state formulae, any PL combination of them is also a wff that is a state formula. For the action modalities,any wffs that are event formulae can be used to form a further wff with the T modality: Txα, Txαx, Tx(α y ∨ β), etc., whichare themselves state formulae. Any wff that is a state formula can be used to form a further wff with the S modality Sx A,SxT yαz, etc. that are state formulae. Finally, for any ψ that is either an event formula or a state formula, Gψ , Hψ , Fψ andPψ are also wffs that are state formulae.The logic of modality Sx is that of a regular modal system of type RT [10, p. 237]. This is the smallest system containingall axioms of Propositional Logic and closed under the rule of inference RE:REA ↔ BSx A ↔ Sx Bwith the additional axiom T, which is characteristic of logic of successful actionTSx A → Aand, of course, the distribution axiom K, which is minimally true of all modal logicsKSx( A → B) → (Sx A → Sx B)Unlike other models of agentive action [3,11,26] however, we include neither the rule of necessitation ( A/Sx A) nor that ofanti-necessitation (¬ A/¬Sx A). Consequently the logic of Sx is non-normal. A key advantage of including neither of theseaxioms is that we may include the equivalence R without introducing inconsistency. Axiom R captures the intuition that ifan agent is responsible for achieving A and responsible for achieving B then it is responsible for achieving the conjunction of\fT.J. Norman, C. Reed / Artificial Intelligence 174 (2010) 51–7153Gφ → ψ → (Gφ → Gψ)Hφ → ψ → (Hφ → Hψ)φ →(cid:3)Hφ → (Gφ → GHφ)(cid:2)Gφ → FφHφ → PφGφ → GGφHφ → HHφFig. 1. Axioms of a Peircean tense logic.these states, and that if an agent is responsible for achieving the conjunction of A and B then it is responsible for achievingeach conjunct. In the logic of action specified by Jones and Sergot [26], for example, including axiom Sx( A ∧ B) → Sx A ∧ Sx Balong with the rule of anti-necessitation will lead to a contradiction. Axiom R for modality Sx is:RSx( A ∧ B) ↔ Sx A ∧ Sx BFinally, we include axiom D in the logic of Sx, which captures the intuition that an agent cannot be responsible for theachievement of contradictory states of affairsDSx A → ¬Sx¬ AThe characterisation of modality Tx is identical to that of Sx; both being regular modal systems of type RT. It should benoted, however, that these modalities operate over different worlds in their interpretation (see Section 2.2).To enable us to explore the interpretation of responsibility over time, we require the use of a logic of time. For ourpurposes we adopt a simple Peircean tense logic. In this logic of time, there are two basic modalities: G and H. Their dualswith respec",
            {
                "entities": [
                    [
                        134,
                        155,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1122–1152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe local geometry of multiattribute tradeoff preferencesMichael McGeachie a,∗, Jon Doyle ba Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USAb Department of Computer Science, North Carolina State University, Raleigh, NC 27695-8206, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 2 March 2009Received in revised form 10 August 2010Accepted 10 August 2010Available online 2 December 2010Keywords:Decision theoryPreference representationMultiattribute tradeoffsCeteris paribus reasoningExisting representations for multiattribute ceteris paribus preference statements haveprovided useful treatments and clear semantics for qualitative comparisons, but havenot provided similarly clear representations or semantics for comparisons involvingquantitative tradeoffs. We use directional derivatives and other concepts from elementarydifferential geometry to interpret conditional multiattribute ceteris paribus preferencecomparisons that state bounds on quantitative tradeoff ratios. This semantics extends thefamiliar economic notion of marginal rate of substitution to multiple continuous or discreteattributes. The same geometric concepts also provide means for interpreting statementsabout the relative importance of different attributes.© 2010 Elsevier B.V. All rights reserved.1. Building value functions from preferences and tradeoffsKnowledge of someone’s preferences can be used to make decisions on their behalf. Following the work of von Neumannand Morgenstern [35], direct and complete elicitation of preferences and their representation in the form of utility functionshas enabled decision analysts to advise decision makers on how to decide specific questions. To go beyond manual construc-tion of specific decision models, and to automate decision analysis in a way that applies in a broad range of mundane andfleeting human activities, one must find richer representations that permit making decisions with imprecise, incomplete,and accumulating information about preferences.We pursue this end by presenting semantics for several different types of preference statements that build on earliersemantics for ceteris paribus preferences (preference other things being equal) [38,14]. We focus on quantitative tradeoffstatements, such as “having a CPU speed of 3 GHz is at least twice as important as having 4 GB memory and a 250 GB diskin my new computer purchase.” Such statements say that some outcomes that satisfy one condition (CPU speed of 3 GHz)are preferred to some outcomes that satisfy another condition (4 GB memory and 250 GB disk), and also bound belowhow much better the former are than the latter. We provide semantics for numerous types of statements of this charac-ter, including multiattribute tradeoffs that relate more than one attribute at a time; tradeoffs over discrete or continuousdomains; conditional or unconditional tradeoffs; and quantitative or purely qualitative comparisons. We also treat relatedtypes of statements about attribute importance, such as “increasing CPU speed is at least twice as important as increasingmemory and disk size in my new computer purchase.” Such statements say that the weight given to some attribute orattributes in a decision should be greater than that given to other attributes.Computing expected utility of actions requires a numerical utility or value function that represents preferences in thesense that the numerical representation assigns a greater value to one outcome than to a second outcome if the preferencestatements entail that the first outcome is preferred to the second. Building on earlier constructions [32], we accompany* Corresponding author.E-mail addresses: mmcgeach@csail.mit.edu (M. McGeachie), Jon_Doyle@ncsu.edu (J. Doyle).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.014\fM. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521123the semantics for ceteris paribus preferences statements with companion algorithms for compiling utility or value functionsfrom collections of multiattribute tradeoff statements.1.1. Decision-analytic methodologyOur methodology seeks to extend traditional decision analysis by relaxing assumptions and restrictions on the form andcharacter of the preference information captured in the preference acquisition process. In particular, we aim for represen-tations of preference information that permit automation of the process of constructing decision models starting at earlierpoints in the process than has been possible with traditional modeling methods.In traditional decision analysis methodology [33,25], a human decision analyst does considerable work in understandingand analyzing a decision informally before the point at which the tools of traditional decision theory [35,34,19] are broughtto bear. The decision analyst first interviews the decision maker about what dimensions or attributes of the decision are ofconsequence. The decision analyst then assesses utility functions on each of these dimensions by standard gambles or othermeans. This assessment requires the decision maker to think carefully about the upper and lower bounds of each dimension,to consider his or her attitude toward risky hypothetical choices, and to determine which attributes are utility independentof other attributes. The relative importance of each dimension must then be assessed, at which point the decision analystcan combine the results into a multiattribute utility function that models the preferences of the decision maker.This traditional methodology has the virtue of producing considered and complete decision models appropriate to thedecision at hand. It also, however, demands much effort on the part of the decision maker by requiring careful attentionto complexities of the decision that might not have been considered previously, and that perhaps should not be answeredimmediately with only the information currently on hand. All this makes the interviewing and analysis steps lengthy andtime-consuming in many cases, so that one mainly applies decision analysis in detail to repetitive decisions in which the costof analysis can be amortized over many individual decisions, and to one-off decisions of great import, such as governmentalpolicy or complicated life-or-death medical decisions.We seek to begin the process of formalization earlier than with traditional decision analytic techniques. The traditionalformal techniques apply once the analyst has done much of the work needed to identify the dimensions along which pref-erences vary. Our preference semantics allows one to formalize partial information about preferences. Such information maybe stated and captured naturally without any requirement that the stated preferences involve independent or fundamentalattributes, and without explicit indications of utility independence or preferential independence. In our view, such inde-pendence relations properly reflect conclusions reached during the analysis of some decision, as inferences from the wholebody of stated conditions on preferences, rather than presuppositions underlying the entire analysis. We thus address theidentification of dependencies and independencies among attributes in our numerical-compilation methods, which performanalyses that yield model-structuring conclusions akin to those reached by a human analyst at the point at which thehuman analyst begins quantitative assessment procedures. Our approach thus supports protracted incremental deliberationprior to the introduction of traditional formal decision analysis, and helps automate the initial steps previously relegated toinformal reasoning that produce the formal framing of a problem.1.2. IllustrationTo illustrate these ideas, we describe a fictitious scenario in which Mike, a human, informs an automated personalshopping agent of his preferences so that it can watch for online deals on computer hardware he may find attractive. Mikewill buy a new laptop if there is a good deal on one he likes. Mike does not try to tell the agent all about his preferences atthe start, as without detailed knowledge of what is currently available he might not yet have developed definite preferencesregarding the options. Mike instead gives his agent information about his preferences bit by bit as he learns more aboutwhat preferences are germane.His agent retrieves a list of laptops for sale at various vendors’ websites. Seeing the list, Mike decides that, with respectto price and speed, a $1500, 3 GHz machine is preferable to a $2000, 3.4 GHz machine, other things being equal. Thispreference sets up a tradeoff between price and speed, so the agent then filters out the results that are very expensive eventhough they are somewhat faster than average. Thinking about it a little more, Mike decides that the first machine is muchbetter than the other one, in fact that it is at least five times better.Looking at some of the expensive options with many attractive features, Mike then realizes that adding features andadding ounces of weight at the same time is not what he wants. Mike tells the agent that Weight is more important thanPrice. The agent readjusts its evaluation of options, and shows more laptops ordered by weight, with several attractivelight-weight options at the top of the list.Mike sees that there are some good machines available that are light, moderately powerful, and within his price range,but realizes that he must decide how big a screen and what resolution he needs to do his work on the road, since thisscreen on a 4.5 pound machine for $1700 is better than aadversely impacts the price and the weight. Mike decides a 12(cid:3)(cid:3)screen on a 6 pound machine for $1800. This suffices to order the remaining options in a way that satisfies Mike, ",
            {
                "entities": [
                    [
                        138,
                        195,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 209 (2014) 11–28Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcept drift detection via competence modelsNing Lu, Guangquan Zhang∗, Jie LuDecision Systems & e-Service Intelligence (DeSI) Lab, Centre for Quantum Computation & Intelligent Systems (QCIS), Faculty of Engineeringand Information Technology, University of Technology, Sydney, PO Box 123, Broadway, NSW 2007, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 1 November 2012Received in revised form 16 October 2013Accepted 9 January 2014Available online 10 January 2014Keywords:Concept driftCompetence modelCase-base maintenanceIncremental supervised learningClassificationDetecting changes of concepts, such as a change of customer preference for telecomservices, is very important in terms of prediction and decision applications in dynamicenvironments. In particular, for case-based reasoning systems, it is important to knowwhen and how concept drift can effectively assist decision makers to perform smartermaintenance operations at an appropriate time. This paper presents a novel method fordetecting concept drift in a case-based reasoning system. Rather than measuring the actualcase distribution, we introduce a new competence model that detects differences throughchanges in competence. Our competence-based concept detection method requires no priorknowledge of case distribution and provides statistical guarantees on the reliability of thechanges detected, as well as meaningful descriptions and quantification of these changes.This research concludes that changes in data distribution do reflect upon competence.Eight sets of experiments under three categories demonstrate that our method effectivelydetects concept drift and highlights drifting competence areas accurately. These resultsdirectly contribute to the research that tackles concept drift in case-based reasoning, andto competence model studies.© 2014 Elsevier B.V. All rights reserved.1. IntroductionLearning under concept drift poses an additional challenge to existing learning algorithms. Instead of considering all thepast training data, or making a stationary distribution assumption [1–3], an effective learner should be able to track thesechanges and quickly adapt to them [4]. Otherwise, as concept drifts, the induced pattern may not be relevant to the newdata [5,6], which may result in an increasing number of errors [7].The issue of concept drift refers to the change of distribution underlying the data [4,8]. More formally, the problem canbe framed as follows. If we denote the feature vector as x and the class label as y, then the data stream will be an infinitesequence of (x, y). If the concept drifts, it means the distribution of p(x, y) is changing between the current data chunk andthe yet-to-come data. If we decompose p(x, y) into the following two parts as p(x, y) = p(x) × p( y|x), we could say thereare two sources of concept drift: one is p(x), which evolves with time t, and can also be written as p(x|t), and the other isp( y|x), the conditional probability of feature x [2].Concept drift can be categorized into two basic types: virtual concept drift (or drift in data distribution), and real conceptdrift (or drift in decision concepts) [8]. Other kinds of concept drift have also been defined and discussed; for example, basedon the extent of drift, Stanley [9] mentioned three kinds of drift: sudden drift, moderate drift and slow drift. Based on classdistribution, Forman [10] classified concept drift into three categories: shifting class distribution – shifting the distributionamong categories but remaining stable within a given class; shifting sub-class distribution – shifting distribution sub-classes* Corresponding author.E-mail addresses: Ning.Lu@uts.edu.au (N. Lu), Guangquan.Zhang@uts.edu.au (G. Zhang), Jie.Lu@uts.edu.au (J. Lu).0004-3702/$ – see front matter © 2014 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2014.01.001\f12N. Lu et al. / Artificial Intelligence 209 (2014) 11–28within a category, but remaining stable within a given sub-class; and fickle concept drift – individual cases may take ondifferent ground truth labels at different times. Zhang et al. [2] defined and analyzed two kinds of concept drift in theirstudies: loose concept drifting, in which the genuine concepts remain relatively stable, whereas the vision of the drift ismainly caused by the biased observation of instances; and rigorous concept drifting, in which the genuine concepts undergocontinuous change, although such changes can worsen in the face of biased observation. Tsymbal et al. [11] discusseda special scenario of concept drift called local concept drift, by which they mean that the change of concept or datadistribution occurs only in some regions of the instance space.Based on the literature, many learning algorithms have been used as base models to handle concept drift. These includerule-based learning [4,8,12], decision trees and their incremental versions [5,13,14], info-fuzzy networks [15], clustering[16], support vector machines [17], and case-based reasoning (CBR) [11,18–20]. Among them, the CBR method has threereported advantages for handling the concept drift problem [21]. First, CBR performs well with disjointed concepts. Second,CBR, as a lazy learner, is easy to update. Third, CBR allows easy sharing of knowledge for particular types of problems,making it easier to maintain multiple distributed case-bases. Therefore, this study focuses on concept drift detection forCBR.According to a literature review [22], the first attempt to handle concept drift with the case-based technique was IB3[20], which discards noisy and outdated cases by monitoring each case’s accuracy and retrieval frequency. IB3 has beencriticized for being suitable only for gradual concept drift, and for its costly adaptation process [4]. The Locally WeightedForgetting (LWF) algorithm [23], which reduces the weights of the k-nearest neighbors of a new case and discards a case ifits weight falls below a threshold θ , was believed to be one of the best adaptive learning algorithms of its time. Klinkenberg[17] later showed in his experiments that instance weighting techniques tend to overfit the data and perform more poorlythan analogous instance selection techniques. Elwell and Polikar [24] presented an ensemble learning algorithm for non-stationary environments (Learn++.NSE) that assumes data are incrementally acquired in batches. For each incoming datasetDt , their algorithm trains an independent base classifier ht which is forced to emphasize misclassified data by adjusteddata weighting. Then, a weight is assigned to each base classifier based on its performance on the latest dataset. The finalclassification result is determined by weighted majority voting of all base classifiers. Recent research and development incase-base maintenance (CBM) provides a number of methods for updating all knowledge containers [25] of a CBR system.Among them, the competence-based CBM methods [19,26–30] and case-base mining technologies [31] have been empiri-cally shown to be capable of preserving the competency of a CBR system while removing noisy and redundant cases. Fewstudies, however, discussed when to trigger maintenance operations, which is also an important consideration, according toWilson and Leake’s CBM framework [32]. In addition, current methods are incapable of distinguishing between noisy casesand cases representing a new concept. Knowing whether concept drift happens could help to recognize obsolete cases thatconflict with current concepts and distinguish noise cases from novel cases. Moreover, developing a detection method thatis able to explain where and how concept drifts could facilitate further decision capabilities and be suitable for handlinglocal concept drift problems [11].Motivated by these issues, we propose a new method of concept drift detection for CBR systems, which compares thecase distributions of existing cases with newly available cases. The proposed method requires no prior knowledge about thecase distribution, but estimates the probability distribution and detects change via a competence model. Besides determiningwhether there is a concept drift, our method also quantifies and describes the detected change in terms of the competencemodel. To the best of our knowledge, no literature has reported any research that uses a competence model for conceptdrift detection purposes.Compared with other famous non-parametric methods, our detection method demonstrates the following advantages:1) it can be easily adopted in multi-dimensional data while maintaining similar results in one-dimensional data; 2) it ismore stable and achieves better results as shown in experiments, especially for small samples, because data can sharedistribution contributions among related competence areas, rather than splitting strictly by cutting edges, which makes itmore tolerable to sample bias; 3) it is able to describe the detected changes by highlighting some competence areas, whichis testified by a real world application.The novelty and main contribution of this paper lie in the endeavor to discover the difference between the inner natureof the competence group model and our proposed competence closure model. The detailed definitions and theorems affordother researchers an inside view of case-base competence, which has never been discussed in the literature. The theoreticalstudy provided in this paper also reveals the essential differences between the two competence models, and identifies threeimportant aspects of the competence closure model which the competence group model does not possess. Compared withour previous work on competence-based concept drift detection [33], which aims to investigate the impact of concept drifton case-base competence and assert to the possibility of detecting change via competence models, this paper additiona",
            {
                "entities": [
                    [
                        134,
                        179,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 160 (2004) 1–34www.elsevier.com/locate/artintGeneralized Region Connection Calculus ✩Sanjiang Li ∗, Mingsheng YingState Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology,Tsinghua University, Beijing 100084, P.R. ChinaReceived 7 June 2002; accepted 18 May 2004AbstractThe Region Connection Calculus (RCC) is one of the most widely referenced system of high-level(qualitative) spatial reasoning. RCC assumes a continuous representation of space. This contrastssharply with the fact that spatial information obtained from physical recording devices is nowadaysinvariably digital in form and therefore implicitly uses a discrete representation of space. Recently,Galton developed a theory of discrete space that parallels RCC, but question still lies in that canwe have a theory of qualitative spatial reasoning admitting models of discrete spaces as well ascontinuous spaces? In this paper we aim at establishing a formal theory which accommodates bothdiscrete and continuous spatial information, and a generalization of Region Connection Calculus isintroduced. GRCC, the new theory, takes two primitives: the mereological notion of part and thetopological notion of connection. RCC and Galton’s theory for discrete space are both extensions ofGRCC. The relation between continuous models and discrete ones is also clarified by introducingsome operations on models of GRCC. In particular, we propose a general approach for constructingcountable RCC models as direct limits of collections of finite models. Compared with standard RCCmodels given rise from regular connected spaces, these countable models have the nice property thateach region can be constructed in finite steps from basic regions. Two interesting countable RCCmodels are also given: one is a minimal RCC model, the other is a countable sub-model of thecontinuous space R2. 2004 Elsevier B.V. All rights reserved.✩ This work was partly supported by the National Foundation of Natural Science of China (60305005,60496321, 60321002).* Corresponding author.E-mail addresses: lisanjiang@tsinghua.edu.cn (S. Li), yingmsh@tsinghua.edu.cn (M. Ying).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.05.012\f2S. Li, M. Ying / Artificial Intelligence 160 (2004) 1–34Keywords: (Generalized) Region Connection Calculus; Qualitative spatial reasoning; (Generalized) Booleanconnection algebra; Mereology; Mereotopology; Continuous space; Discrete space1. IntroductionQualitative Spatial Reasoning (QSR) is an important subfield of AI which has appli-cations in areas such as Geographical Information Systems(GIS) [4,24,52], spatial querylanguages [10], natural languages [1] and many other fields. We invite the reader to consult[11] for an introduction and an overview of current trends.This paper focus on one of the most important formalism for QSR, viz. the RegionConnection Calculus (RCC). RCC was initially described by Randell, Cohn and Cui in [31,32], which is intended to provide a logical framework for incorporating spatial reasoninginto AI systems.RCC takes regions rather than points as fundamental notion and is based on a singleprimitive (binary relation) C (for connection). Unlike other mereotopologies, RCC makesno distinction between closed, open, and semi-open regions and does not support the notionof boundaries. It is also a well-known result that regular connected topological spacesprovide models of the RCC axioms by taking a region to mean a non-empty regular closedset and saying two regions are connected if they have common points [25]. But since eachregion is infinitely divisible, it has nothing to do with discrete spaces (in the sense that eachregion is a union of atomic regions). Randell, Cui and Cohn [32] suggest ways of atomicversions of RCC, but, as commented by Bennett [3], each of the alternatives seem morecomplex than is desirable and have not been worked out in detail. They also suggest in thatpaper that the problem lies with the definition of P, but a revised definition was not given.On the other hand, discrete spaces are evidently important in implementations of spa-tial information systems, and their mereotopological aspects have only recently begun tobe investigated [22,24,30,39,44]. As noted by Galton in [24], high-level qualitative ap-proaches to handling spatial information are widely perceived as having little relevanceto the domain of low-level quantitative data inhabited by “real-world” applications, andthe congruity between the continuous space models favored by high-level approaches andthe discrete, digital representations used at the lower level is one amongst many possiblereasons for this.Recently, Galton [24] attempts to bridge this gap by developing a high-level qualitativespatial theory of discrete space that parallels RCC, but questions still lie in, e.g., “Can wehave a high-level theory of QSR which admits models of continuous spaces as well as dis-crete spaces?” and “What is the relation between continuous spaces (e.g., R2) and discretespaces (e.g., Z2)?”. In the present paper we try to answer these questions by introducing ageneralized theory of RCC. The new theory, termed Generalized Region Connection Cal-culus (GRCC henceforth), is a subtheory of both RCC1 and Galton’s theory for discretespace.1 We are concerned in this paper with only ‘strict’ RCC [45], i.e., the extensionality of C is an axiom.\fS. Li, M. Ying / Artificial Intelligence 160 (2004) 1–343The original formulation of RCC is inspired by the earlier work of Whitehead [48] andClarke [7,8]. These systems are all based on a single primitive, namely the concept ofconnection, and notions such as part are defined in terms of connection. This use of a sin-gle primitive relation is seen by Smith as problematic. In [42, p. 288], Smith puts: “Thesystem has a single primitive, that of connection, in terms of which the notion of part isdefined by means of what, intuitively, appears to be a logical trick. This means that themereological and topological components of the resultant theories are difficult or impos-sible to separate formally. The power of the approach is thus reduced, since experimentsin axiom-adjustment at different points in the theory cannot be carried out in controlledfashion”.This possible deficiency of the RCC theory, however, as Stell [45], as well as this pa-per, has shown, can be completely avoided. In [45], Stell introduces Boolean connectionalgebras (BCAs) and proves that these structures are equivalent to models of the RCC ax-ioms.2 Such an algebra is able to provide a neat separation of mereological and topologicalaspects of a set of regions. Moreover, by replacing the Boolean algebra by Łukasiewiczalgebra, Roy and Stell [38] obtain a theory of vague spatial regions. The present paper isalso strongly influenced by Stell’s idea on the treatment of spatial regions.In the GRCC theory proposed in this paper, however, we use two primitive notions: themereological notion of part P and the topological notion of connection C. This treatmentis not novel, the reader may consult for instance the work of Varzi [47] and Mosolo andVieu [30] for more discussion. In [47], Varzi systematically examines three main ways ofcombining mereologies (as theories of parthood) and topologies (as theories of wholeness)to build general mereotopologies, namely unified theories of parts and wholes. Both work,particularly that of Mosolo and Vieu [30], also investigate the possibilities of characterizingatomicity in these mereotopologies.Our mereology of GRCC (as well as the reformulated RCC theory) falls under the firstaccount of Varzi’s classifications, where mereology and topology form two independent(though mutually related) domains. Indeed, the mereological part of GRCC is the sameas the Closed Extensional Mereology (CEM) [47] (with the additional requirement thatthe universe exists). The GRCC theory is then obtained by adding three additional axiomsto the Ground Mereotopology CEMT [47]. The first requires a region a is connected tothe (mereological) sum of two regions b, c if and only if it is connected to either one ofb, c; the second stipulates in essence the universe is self-connected; the third requires thereexist at least two different regions. The original RCC theory is then obtained by adding toGRCC an additional axiom which requires that any region other than the universe cannotbe connected to all regions. Moreover, the theory of Galton for discrete space [24] is also anextension of the (atomistic) GRCC theory. Indeed, Galton’s theory is obtained by addingto GRCC three more axioms. The first two stipulate that the Boolean algebra is atomiccomplete and the third requires two regions are connected if and only if there are twoconnected atoms contained respectively in these two regions.2 The fact that each RCC model leads to a Boolean algebra is also pointed out independently by Düntsch,Wang and McCloskey [17].\f4S. Li, M. Ying / Artificial Intelligence 160 (2004) 1–34Eschenbach [22] also introduces a formal theory of Closed Region Calculus (CRC)based on two primitives: P for mereological notion of part and DC for the topological no-tion of disconnection or separation. CRC is similar to RCC and the 9-intersection calculus[19]. It provides the same terminology and justifies the same composition table, but differswith respect to the ontology. The main difference between CRC and RCC is that a finiteset of regions that is explicitly represented in a spatial information system can be a modelof CRC [22]. Our theory of GRCC is also a generalization of CRC in essence, it differsfrom CRC mainly in two aspects. The first is that GRCC is a first order theory while CRCis second order. The second lies in that the two theories use different topological primitivesand different systems of axioms.The fact that GRCC admits both continuous spaces and discrete spaces as models makesit possible to study the rela",
            {
                "entities": [
                    [
                        69,
                        107,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 94 (1997) 217-268 Artificial Intelligence Modeling agents as qualitative decision makers Ronen I. Brafman a,*, Moshe Tennenholtz b a Department of Computer Science, Universify of British Columbia, Vancouvel; B.C., Canada V6T 124 b Faculty of Industrial Engineering and Management, Technion - Israel Institute of Technology, Haifa 32000, Israel Abstract this requires specifying We investigate the semantic foundations of a method for modeling agents as entities with a mental state which was suggested by McCarthy and by Newell. Our goals are to formalize this modeling approach and its semantics, to understand the theoretical and practical issues that it the model’s parameters raises, and to address some of them. In particular, and how these parameters are to be assigned (i.e., their grounding). We propose a basic model in which the agent is viewed as a qualitative decision maker with beliefs, preferences, and a decision strategy; and we show how these components would determine the agent’s behavior. We ground this model in the agent’s interaction with the world, namely, in its actions. This is done by viewing model construction as a constraint satisfaction problem in which we search for a model consistent with the agent’s behavior and with our general background knowledge. In addition, we investigate the conditions under which a mental state model exists, characterizing a class of “goal-seeking” agents that can be modeled in this manner; and we suggest two criteria for choosing between consistent models, showing conditions under which they lead to a unique choice of model. @ 1997 Elsevier Science B.V. Keywords: Agent modeling; Mental states; Qualitative decision making; Belief ascription; Multi-agent systems; Prediction 1. Introduction This article investigates formal notions of mental as agents are described the semantic state if they are qualitative to represent foundations of a modeling method and reason about agents. that uses In this method, state decision makers with a mental * Corresponding author. Email: brafman@cs.ubc.ca. ’ Email: moshet@ie.technion.ac.il. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIISOOO4-3702(97)00024-6 \f218 R.I. Brajinan, M. Tennenholtz/Art@ial Intelligence 94 (1997) 217-268 consisting of mental attributes such models, which we refer [43] and by Newell this modeling process, some of them. The ability such as beliefs, knowledge, to as mental-level models, was proposed by McCarthy and preferences. The use of [45], and our goals are to provide a formal semantic account of it raises, and to address some of the key issues to understand likely is useful In particular, to model agents in many settings. in multi-agent the success of one’s action or plan depends on the actions of other agents, systems, that are and a good model of these agents can help construct more to this more agents, task: they provide an abstract, and they are built from intuitive and useful attributes, such as beliefs, goals and inten- tions. The abstract nature of mental-level models has a number of important practical implications. informed plans properties way of representing to succeed. Mental-level models bring implementation-independent two promising ( 1) A single platforms guages and who have followed different design paradigms. formalism and written by designers who have used different programming can capture different agents running on different hardware lan- (2) We may be able the internal these abstract models. to construct mental-level models without privileged access details do not appear to in state of the agent because implementation (3) Fewer lower-level details may mean faster computation. is also important and analyzing agents, much for theoretical schemes. The second property, [40] allows for abstract analysis of knowledge The abstract nature of mental-level models It provides a uniform basis for comparing Computers as believers paradigm resentation since one approach that are difficult intuitive high-level models. beliefs and goals are useful when we want or correct erroneous beliefs. These abilities are sought after in cooperative multi-agent systems, areas. analysis. like Levesque’s rep- in design validation of agents into designs, in terms of their their goals is valuable low-level descriptions such as procedural programs or mechanical intuitiveness, is to transform systems, and in user interfaces, intuitive descriptions of agents these agents achieve to design validation to name but a few in intelligent In addition, to analyze, information to help 1.1. Issues in mental-level modeling Despite their promising properties, mental-level modeling has not been studied ex- in AI. The scarcity of citations on this issue in a recent survey of work on tensively mental states within AI by Shoham and Cousins although Newell’s paper on the Knowledge Level [45] is among papers up on these only exception. [46], Newell ideas by the “logicist community”. He mentions Levesque’s [ 51, in his perspective paper [58] attests laments to this fact.* Similarly, the most referenced AI the lack of work following [40] as the Given this situation, it is worth clarifying what we view as the four central questions in mental-level modeling. They are: * The only modeling related works there deal with plan recognition. \fR.I. Bra&an, M. Tennenholtz/Art#cial Intelligence 94 (1997) 217-268 219 ( 1) Structure-what (2) Grounding-how class of models should we consider? can we base the model construction process on a definite and ob,jective manifestation of the agent? (3) Existence-under what conditions will a model exist? (4) Choice-how do we choose between different models that are consistent with our data? The importance of the first question is obvious, however, the others deserve a few words of explanation. Many researchers support an agent design approach in which the designer specifies an initial (database of beliefs, goals, intentions, etc., which is then explicitly manipulated by the agent (e.g., [ 6,49,52,57] and much of the work on belief revision). Grounding may not seem a crucial issue for such work because human designers are likely to find memal attitudes natural to specify. However, grounding is crucial for modeling applications. The whole point here is that we cannot directly observe the mental state of another agent. Moreover, there are good reasons why general background knowledge alone will not do. First, there is no reason we should know the mental state of agents designed by other designers, a common case in multi-agent systems. Second, one cannot always predict into the distant future the mental state of agents that learn and adapt, even if she designed these agents. Finally, and perhaps most importantly, what we mean by the mental state of an agent is not even clear when this agent is not designed using a knowledg,e-based approach, for example, when it is a C program or the result of training a neural net. This last point is crucial if we take seriously Newell’s idea of mental state models as abstract descriptions of agents. Grounding is important semantically even from the design perspective: it makes concrete the abstract Kripke semantics [35] that is often used in the literature, and it allows us to answer a central question in the theoretical analysis of agents and their design: Does program X implement mental-level specification Y? While grounding has been discussed by some authors (see Section 8)) the questions of model choice, and in particular, model existence have not received much attention. We see rnodel existence as the central theoretical question in this area. Answers to it will allow us to evaluate any proposal for mental-level models by telling us under what conditi0n.s it is applicable and hence, what assumptions or biases we are making when we model agents in this manner. Techniques for choosing among possible models are crucial for practical applications, especially prediction, since different models may give rise to different predictions. 1.2. An overview of our approach Having described the main questions in mental-level modeling, we proceed with an overview of this paper and its view of mental-level modeling. Model structure We propose a structure for mental-level models (Sections 2 and 3) that is motivated by work in decision theory [41] and previous work on knowledge ascription [20,54] in which the agent is described as a qualitative decision maker. This model contains \f220 R.1. Brajkaan, M. Tennenholtz/Arf#icial intelligence 94 (1997) 2I7-268 three key components: essential components of the world, beliefs, preferences, and a decision criterion. We see these as the of any mental-level structure, accounting for the agent’s perception its goals, and its method of choosing actions under uncertainty. to be plausible. For example, The beliefs of the agent determine which among states of the world it the possible worlds of interest may be rainy tell the agent has two possible taking or leaving an umbrella, whose outcomes are described by the following considers and ~~~-~~~~y, and the agent believes us how much actions, table: to be plausible. The agent’s preferences it likes each outcome. For example, the possible suppose rainy rainy not-rainy take umbrella leave umbrella dry, heavy wet, light dry, heavy, look stupid dry, light The agent’s preferences tell us how much these values, where it values each of these outcomes. We indicate better larger numbers will use real numbers outcomes: to describe take umbrella leave umbrella 5 -4 -1 10 its decision criterion The agent chooses its action by applying actions at the plausible worlds. A simple example of a decision criterion different maximin, in which the action with the best worst-case outcome if the agent believes both worlds action take umbrella, since its worst case outcome case outcome of Zeuve umbrella ( -4). However, be plausible, is now much better than that of take umbrella (- 1) ",
            {
                "entities": [
                    [
                        75,
                        121,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 462–471www.elsevier.com/locate/artintRanking functions and rankings on languagesFranz HuberCalifornia Institute of Technology, USAReceived 8 June 2005; received in revised form 24 October 2005; accepted 26 October 2005Available online 21 November 2005AbstractThe Spohnian paradigm of ranking functions is in many respects like an order-of-magnitude reverse of subjective probabilitytheory. Unlike probabilities, however, ranking functions are only indirectly—via a pointwise ranking function on the underlyingset of possibilities W —defined on a field of propositions A over W . This research note shows under which conditions rankingfunctions on a field of propositions A over W and rankings on a language L are induced by pointwise ranking functions on W andthe set of models for L, ModL, respectively. 2005 Elsevier B.V. All rights reserved.Keywords: Extension theorem for rankings on languages; Probabilities; Ranking functions; Rankings on languages; Spohn1. Introduction: Pointwise ranking functionsThe Spohnian paradigm of ranking functions [16,17] is in many respects like an order-of-magnitude reverse ofsubjective probability theory [9]. “Ranks represent degrees”—or rather: grades—“of disbelief” ([19]: 6). Whereas ahigh probability indicates a high degree of belief, a high rank indicates a high grade of disbelief.There are many parallels between probability theory and ranking theory [16,18], and in Footnote 22 of his [16]Spohn “wonder[s] how far the mathematical analogy [of his ranking functions to probabilities] could be extend-ed”.1 The starting point of this paper is one of the few places where ranking theory differs from subjective probabilitytheory as well as qualitative-logical approaches to the representation of epistemic states such as entrenchment order-ings in belief revision theory: the domain on which these models are defined, that is, what they take to be the objectsof belief.Unlike probabilities, ranking functions are only indirectly—via a pointwise ranking function on a non-empty set ofpossibilities (possible worlds, models) W —defined on some finitary/σ -/complete field A over W , i.e., a set of subsetsof W containing the empty set and closed under complementation and finite/countable/arbitrary intersections. Let ushave a closer look.E-mail address: franz@caltech.edu (F. Huber).1 Ranking theory is very similar to possibility theory [5], and it would be highly desirable to know to what extent the results below also hold forpossibility measures. Unfortunately this goes beyond the scope of this research note.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.10.016\fF. Huber / Artificial Intelligence 170 (2006) 462–471463A function κ from W into the set of natural numbers N is a pointwise ranking function on W iff κ(ω) = 0 for atleast on ω ∈ W . A pointwise ranking function κ : W → N is extended to a function (cid:4)κ on a field A over W with rangeN ∪ {∞} by defining, for each A ∈ A,(cid:1)(cid:4)κ (A) =min{κ(ω): ω ∈ A},∞,if A (cid:5)= ∅,if A = ∅.As will be seen below, it is useful to allow that some possibility ω ∈ W is sent to ∞, which amounts to ω being a“virtually impossible possibility” (according to κ). In order to distinguish the more restricted notion of a pointwiseranking function as defined above from the more liberal one allowing for virtually impossible possibilities, let us callthe former natural pointwise ranking functions (because the range of κ is restricted to the set of natural numbers N ).Pointwise ranking functions κ are functions defined on a non-empty set of possibilities W that take natural numbersor ∞ as values. They are extended to functions (cid:4)κ on a field A over W by stipulating that the rank of any non-emptyproposition A ∈ A equals the minimum rank of the possibilities in A, i.e., (cid:4)κ (A) = min{κ(ω): ω ∈ A}, and the emptyproposition is sent to ∞.In case W is a finite set of possibilities and A its powerset, every possibility corresponds to a proposition (viz.the singleton containing it). But already when W is the set of all models ModL for a propositional language Lwith infinitely many propositional variables and A is the field {Mod(α) ⊆ W : α ∈ L}, no possibility corresponds toa proposition. Furthermore, one has to specify a ranking over uncountably many possibilities in order to assign apositive finite rank to a single proposition. But clearly, we often have a definite opinion about a single proposition(represented in terms of a sentence) even if we do not have an idea of what the underlying set of possibilities lookslike—let alone what our ranking over these possibilities might be. For instance, I strongly disbelieve that one can buya bottle of Schilcher for less than 1 Euro, though I lack the relevant enological vocabulary in order to know whatall the possibilities are. Indeed, it seems the underlying set of possibilities should not matter for my disbelief in thisproposition.More generally, we should be able to theorize about our epistemic states even if all we are given is a rankingover the sentences or propositions of some language or field, and we have no ranking over the underlying set ofpossibilities. After all, what we as ordinary or scientific believers do have are plenty of beliefs and grades of beliefin various propositions—usually if not always via beliefs and grades of belief in sentences or other representations ofthese propositions. When we want to attach ranks to sentences, pointwise ranking theory first has us specify a set ofpossible worlds for the language the sentences are taken from; then we have to specify a ranking over these possibleworlds, which in turn induces a ranking over sets of possible worlds; and only then can we identify the rank of asentence with the rank of the proposition containing exactly the possible worlds making our sentence true.This is a bit awkward. What one would like to do is to start with a ranking of the sentences in L, and then be ableto induce a pointwise ranking function on the corresponding set of possible worlds that yields the original ranking.The question is whether this is always possible. In order to answer it, let us first define ranking functions on fields ofpropositions and rankings on languages. (For a similar generalization of pointwise ranking functions see [21].)2. Ranking functions and rankings on languages(Finitely minimitive) ranking functions are functions (cid:4) from a field A over a set of possibilities W into the set ofnatural numbers extended by ∞2 such that for all A, B ∈ A:(1) (cid:4)(∅) = ∞;(2) (cid:4)(W ) = 0;(3) (cid:4)(A ∪ B) = min{(cid:4)(A), (cid:4)(B)}.If A is a σ -field/complete field, (cid:4) is a σ -minimitive/completely minimitive ranking function iff, in addition to (1)–(3),we have for every countable/possibly uncountable B ⊆ A:2 One can also take the set of ordinal numbers smaller than or equal to some limit ordinal β and send ∅ to β, but we do not need this generalityhere.\f464(cid:2)(4) (cid:4)(B) = min{(cid:4)(B): B ∈ B}.F. Huber / Artificial Intelligence 170 (2006) 462–471In case A is finite, i.e., if A contains only finitely many elements, these distinctions collapse. According to (4), therange of ranking functions has to be well-ordered. Therefore N is a natural choice. A ranking function (cid:4) on A isa pre-ranking iff (cid:4) is a finitely minimitive ranking function on A such that(cid:7)(cid:3)(cid:4)(cid:5)(cid:6)(cid:4)(A): A ∈ B= minB(cid:4)for every countable B ⊆ A such thatB ∈ A. A ranking function (cid:4) is regular iff (cid:4)(A) < (cid:4)(∅) for every non-emptyA ∈ A. The conditional ranking function (cid:4)(· | ·) : A × A → N ∪ {∞} based on the ranking function (cid:4) : A → N ∪ {∞}is defined such that for all A, B ∈ A with B (cid:5)= ∅,(cid:2)(cid:1)(5) (cid:4)(B | A) =(cid:4)(B ∩ A) − (cid:4)(A),0,if (cid:4)(A) < ∞,if (cid:4)(A) = ∞.The second clause says that, conditional on a (virtually) impossible proposition, no non-tautological proposition isbelieved in (cid:4). Goldszmidt and Pearl ([9]: 63) define (cid:4)(B | A) = ∞ for A = ∅, which means that, conditional on theimpossible proposition, every proposition is maximally believed in (cid:4). We further stipulate that (cid:4)(∅ | A) = ∞ for everyA ∈ A, which completes the definition of a conditional ranking function and ensures that (cid:4)(· | A) : A → N ∪ {∞} is aranking function.If the function (cid:4)κ : A → N ∪ {∞} is induced by a (natural) pointwise ranking function κ : W → N , (cid:4)κ is a (regularand) completely minimitive ranking function. The converse is not true. The triple A = (cid:9)W, A, (cid:4)(cid:10) with W a set ofpossibilities, A a finitary/σ -/complete field over W , and (cid:4) : A → N ∪ {∞} a ranking function is called a finitary/σ -/complete ranking space. A is called regular iff (cid:4) is regular, and A is called natural iff (cid:4) is induced by some naturalpointwise ranking function κ.A proposition A ∈ A is believed in (cid:4) iff (cid:4)(A) > 0. (cid:4)’s belief set Bel(cid:4) = {A ∈ A: (cid:4)(A) > 0} is consistent anddeductively closed in the finite/countable/complete sense whenever (cid:4) is finitely/σ -/completely minimitive. Here Bel isB (cid:5)= ∅ for every finite/countable/possibly uncountable B ⊆ Bel;consistent in the finite/countable/complete sense iffand Bel is deductively closed in the finite/countable/complete sense iff for all A ∈ A: A ∈ Bel wheneverB ⊆ A forsome finite/countable/possibly uncountable B ⊆ Bel.3(cid:8)(cid:8)Observation 1. For any ranking space A = (cid:9)W, A, (cid:4)(cid:10) and all A, B ∈ A:1. min{(cid:4)(A), (cid:4)(A)} = 0.2. A ⊆ B ⇒ (cid:4)(B) (cid:1) (cid:4)(A).Rankings κ : L → N ∪ {∞} on languages L are defined such that for all α, β ∈ L:0. α (cid:12)(cid:13) β ⇒ (cid:4)(α) = (cid:4)(β).1. α (cid:13) ⊥ ⇒ (cid:4)(α) = ∞.2. (cid:13) α ⇒ (cid:4)(α) = 0.3. (cid:4)(α ∨ β) = min{(cid:4)(α), (cid:4)(β)}.4. β (cid:5)(cid:13) ⊥ ⇒ (cid:4)(β | α) = (cid:4)(α ∧ β) − (cid:4)(α",
            {
                "entities": [
                    [
                        72,
                        115,
                        "TITLE"
                    ],
                    [
                        6373,
                        6416,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2170–2197Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFoundations of instance level updates in expressive description logicsHongkai Liu a, Carsten Lutz b, Maja Miliˇci ´c c, Frank Wolter d,∗a Institut für Theoretische Informatik, TU Dresden, Germanyb Fachbereich Informatik, Universität Bremen, Germanyc School of Computer Science, The University of Manchester, UKd Department of Computer Science, University of Liverpool, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 9 July 2010Received in revised form 25 June 2011Accepted 14 August 2011Available online 23 August 2011Keywords:Description logicsABoxesUpdates1. IntroductionIn description logic (DL), ABoxes are used for describing the state of affairs in an applicationdomain. We consider the problem of updating ABoxes when the state changes, assumingthat update information is described at an atomic level, i.e., in terms of possibly negatedABox assertions that involve only atomic concepts and roles. We analyze such basic ABoxupdates in several standard DLs, in particular addressing questions of expressibility andsuccinctness: can updated ABoxes always be expressed in the DL in which the originalABox was formulated and, if so, what is the size of the updated ABox? It turns out thatDLs have to include nominals and the ‘@’ constructor of hybrid logic for updated ABoxes tobe expressible, and that this still holds when updated ABoxes are approximated. Moreover,the size of updated ABoxes is exponential in the role depth of the original ABox and thesize of the update. We also show that this situation improves when updated ABoxes areallowed to contain additional auxiliary symbols. Then, DLs only need to include nominalsfor updated ABoxes to exist, and the size of updated ABoxes is polynomial in the size ofboth the original ABox and the update.© 2011 Elsevier B.V. All rights reserved.Description Logics (DLs) are a traditional family of knowledge representation formalisms which, in recent years, haveplayed an important role as a logical underpinning of ontology languages such as the W3C recommendation OWL [1]. In DLs,a knowledge base (KB) typically consists of two parts: a TBox to store intensional knowledge, i.e., a general formalization ofthe relevant concepts and relationships of the application domain; and an ABox to store extensional knowledge, i.e., instancelevel assertions that describe the current state of affairs in the application. Just like database systems, DL knowledge basesare not static entities, but have to be modified when the application domain evolves. This raises the fundamental updateproblem, which consists of rewriting the knowledge base to incorporate new information from the application withoutunnecessarily losing any existing knowledge. In the case of a DL knowledge base, at least three different incarnations of theupdate problem can be distinguished:• TBox updates, triggered by changes of the intensional knowledge of the application domain;• ABox updates, which have to be carried out when the intensional knowledge remains stable, but the state of affairs inthe application changes;* Corresponding author.E-mail addresses: liuhkai@tcs.inf.tu-dresden.de (H. Liu), clu@uni-bremen.de (C. Lutz), maja.milicic@manchester.ac.uk (M. Miliˇci ´c), frank@csc.liv.ac.uk(F. Wolter).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.003\fH. Liu et al. / Artificial Intelligence 175 (2011) 2170–21972171• KB updates, which do not distinguish between the two levels of knowledge and allow simultaneous modification of theTBox and the ABox.In typical applications, instance level knowledge stored in the ABox tends to change frequently whereas intensional knowl-edge in the TBox often remains stable for longer periods of time. Moreover, automatic TBox modifications are rarely desiredbecause the TBox is typically the result of a careful and time-consuming manual modeling process, and thus its syntacticstructure should not be changed in a radical way.These observations lead us to study ABox updates as a fundamental and basic form of updates in a DL context. A centralproperty of DL ABoxes is that they store incomplete knowledge, reflected by an open world semantics and the use of com-pound logical expressions that can involve disjunction and existential quantification. It follows that, technically, updating DLABoxes is equivalent to updating logical theories, a problem with a long tradition in both the database and AI communities[4–8].In the database and AI literature, for a long time no proper distinction was made between updates as studied in thispaper and the related notion of a revision. While the purpose of update is to bring the knowledge base up to date whenthe world described by it changes, revision aims at incorporating new knowledge that was obtained about a static world.Katsuno and Mendelzon [6] discuss this distinction in detail, show that update and revision are fundamentally differentoperations, and give 8 postulates that any rational update operator should satisfy. The prototypical update semantics thatcomplies with these postulates is Winslett’s well-known PMA semantics [4] whose general idea can, in our context, bestated as follows. The models of the original knowledge base K are viewed as those states of the world that are consideredpossible; when K is to be updated with new information U , then the models of the resulting updated knowledge baseK(cid:3)should satisfy U , but also be ‘as close as possible’ to the models of K (the principle of minimal change). In the caseof updating propositional theories and logical databases as considered in [6,4], the difficulty of defining what ‘as close aspossible’ means mainly derives from the following two features: (i) the newly added information may be non-deterministic,e.g. when it involves disjunction; and (ii) the updated theory must satisfy additional domain constraints stated in theform of a logical background theory. As discussed in more detail in Section 6 of this paper, the combination of thesefeatures with the first-order quantification present in description logics leads to serious semantic difficulties and also tocomputational problems. For this reason, we concentrate on a simple, yet fundamental form of update where (i) the newlyadded information U consists of a set of ground literals, i.e., sets of ABox assertions A(a) or r(a, b) and their negations,where A is a concept name and r a role name (thus both are atomic); and (ii) no background theory is present, i.e., theknowledge base K comprises only an ABox, but no TBox. In this case, there seems to be only one sensible formalizationof ‘as close as possible’: the models of K(cid:3)are obtained from the models of K by (deterministically!) applying the changesdictated by the ground literals in U . This semantics, which we adopt in the current paper, can thus be viewed as anincarnation of Winslett’s semantic that avoids the potentially controversial cases.As a starting point for the current paper, we observe that, in standard ‘expressive’ DLs such as those between ALC andALCQIO, we can find an ABox A and update U of the restricted form described above such that the result of updatingA with U cannot be expressed in the given DL. As a concrete example, take the following ABox A, which is formulated inALC, the basic expressive DL with Boolean operators. It states that John is a parent with only happy children, that Peter ishis child, and that Mary is a person:john:Person (cid:4) ∃has-child.Person (cid:4) ∀has-child.(Person (cid:4) Happy)has-child(john, peter)mary:Person.Suppose now that the situation changes by Mary becoming unhappy. The result of updating A with U = {Mary : ¬Happy} canbe represented by the following ABox A(cid:3), which is formulated in ALCO, the extension of ALC with nominals (individualnames inside concept descriptions):john:Person (cid:4) ∃has-child.Person (cid:4) ∀has-child.(cid:2)Person (cid:4)(cid:2)Happy (cid:7) {mary}(cid:3)(cid:3)has-child(john, peter)mary:Person (cid:4) ¬Happy.To understand why A(cid:3)is appropriate, note that A provides no information about whether or not Mary is a child of John.Because we cannot exclude that this is the case, John may now have an unhappy child, which is Mary. Thus, the newknowledge concerning Mary also resulted in an update of the knowledge concerning John. Using the nominal {mary} inthe assertion for john is actually unavoidable as it can be shown that there is no ALC-ABox that is equivalent to theALCO-ABox A(cid:3). As a consequence, the update of the ALC-ABox A with U cannot be expressed in ALC.We say that a description logic L does not have updates if there are an L-ABox A and update U such that the resultof updating A with U cannot be expressed in L. The first main aim of this paper is to understand how the problem of non-expressibility of updated ABoxes can be overcome. In particular, we consider two options: (i) increasing the expressive power ofDLs by adding additional constructors and (ii) relaxing the definition of updated ABoxes.\f2172H. Liu et al. / Artificial Intelligence 175 (2011) 2170–2197Regarding (i), we show that the addition of nominals (as in the example above) and the ‘@’ constructor from hybrid logicsuffices to ensure the existence of updated ABoxes in all DLs between ALC and ALCQIO. Intuitively, the ‘@’ constructorenables ‘jumps’ between individuals by allowing the formation of concepts such as @aC which is satisfied at any point of aninterpretation whenever the individual a satisfies the concept C . We also show that the ‘@’-constructor (but not nominals)can be replaced by Boolean ABoxes, i.e., ABoxes that admit Boolean operators to be applied to ABox assertions.Regarding (ii), we consider the following definitions of updated ABoxes. An ABox A(cid:3)is• a semantic update of A with U if the models of A(cid:3)are precisely those interpre",
            {
                "entities": [
                    [
                        138,
                        208,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2075–2098Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLearning heuristic functions for large state spacesShahab Jabbari Arfaee a, Sandra Zilles b,∗, Robert C. Holte aa University of Alberta, Department of Computing Science, Edmonton, Alberta, Canada T6G 2H8b University of Regina, Department of Computer Science, Regina, Saskatchewan, Canada S4S 0A2a r t i c l ei n f oa b s t r a c tArticle history:Received 19 September 2010Received in revised form 27 July 2011Accepted 1 August 2011Available online 5 August 2011Keywords:Heuristic searchPlanningLearning heuristics∗We investigate the use of machine learning to create effective heuristics for searchor heuristic-search planners such as FF. Our method aims toalgorithms such as IDAgenerate a sequence of heuristics from a given weak heuristic h0 and a set of unsolvedtraining instances using a bootstrapping procedure. The training instances that can besolved using h0 provide training examples for a learning algorithm that produces aheuristic h1 that is expected to be stronger than h0. If h0 is so weak that it cannot solveany of the given instances we use random walks backward from the goal state to createa sequence of successively more difficult training instances starting with ones that areguaranteed to be solvable by h0. The bootstrap process is then repeated using hi in lieu ofhi−1 until a sufficiently strong heuristic is produced. We test this method on the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world. In every case∗to solve randomly generated problemour method produces a heuristic that allows IDAinstances quickly with solutions close to optimal.The total time for the bootstrap process to create strong heuristics for these large statespaces is on the order of days. To make the process effective when only a single probleminstance needs to be solved, we present a variation in which the bootstrap learning ofnew heuristics is interleaved with problem-solving using the initial heuristic and whateverheuristics have been learned so far. This substantially reduces the total time needed tosolve a single instance, while the solutions obtained are still close to optimal.© 2011 Elsevier B.V. All rights reserved.1. IntroductionModern heuristic search and planning systems require good heuristics. A popular approach to creating heuristics fora state space is abstraction: from the state space description one creates a description of an abstract state space that iseasier to search; exact distances in the abstract space give admissible estimates of distances in the original space [4,5,16,24,34,36]. One limitation of this approach is that it is often memory-intensive. This has led to the study of compressionschemes [3,7,42], disk-based methods [52], and distributed methods [8]. These methods extend the range of problems towhich abstraction is applicable, but since combinatorial problems grow in size exponentially it is easy to imagine problemsso large that, with the computers of the foreseeable future, even the best heuristics created by these systems will be tooweak to enable arbitrary instances to be solved reasonably quickly.A second limitation of abstraction is that it can only be applied to state spaces given in a suitable declarative form.There are situations in which there is no such state-space description, for example, if a planner is controlling a system orcomputer game, or when such a description would be vastly less efficient than a “hard-coded” one, or when the state spaceis described declaratively but in a different language than the abstraction system requires. We call such representations* Corresponding author.E-mail addresses: jabbaria@cs.ualberta.ca (S. Jabbari Arfaee), zilles@cs.uregina.ca (S. Zilles), rholte@ualberta.ca (R.C. Holte).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.001\f2076S. Jabbari Arfaee et al. / Artificial Intelligence 175 (2011) 2075–2098opaque. With an opaque representation, a state space is defined by a successor function that can be called to compute astate’s children but cannot otherwise be reasoned about. By definition, abstraction cannot be applied to create heuristicswhen the state space is represented opaquely.An approach to the automatic creation of heuristics that sidesteps both of these limitations is to apply machine learningto a set of states whose distance-to-goal is known (the training set) to create a function that estimates distance-to-goalfor an arbitrary state, i.e., a heuristic function. This idea has been applied with great success to the 15-puzzle and otherstate spaces of similar size (see Ernandes and Gori [9] and Samadi, Felner, and Schaeffer [41]), but could not be appliedto larger spaces, e.g., the 24-puzzle, because of the excessive time it would take to create a sufficiently large training setcontaining a sufficiently broad range of possible distances to goal. To overcome this obstacle, Samadi et al. [41] reverted tothe abstraction approach: instead of learning a heuristic for the 24-puzzle directly they learned heuristics for two disjointabstractions of the 24-puzzle and combined them to get a heuristic for the 24-puzzle. This approach inherits the limitationsof abstraction mentioned above and, in addition, the crucial choices of which abstractions to use and how to combine themare made manually.Ernandes and Gori [9] proposed a different way of extending the machine learning approach to scale to arbitrarilylarge problems, but never implemented it. We call this approach “bootstrap learning of heuristic functions” (bootstrapping,for short). The contribution of the present paper is to validate their proposal by supplying the details required to makeautomatic bootstrapping practical and showing experimentally that it succeeds on state spaces that are at or beyond thelimit of today’s abstraction methods.Bootstrapping is an iterative procedure that uses learning to create a series of heuristic functions. Initially, this proce-dure requires a heuristic function h0 and a set of states we call the bootstrap instances. Unlike previous machine learningapproaches to creating heuristics, there are no solutions given for any instances, and h0 is not assumed to be strong enough[29]) is run with h0 in an attempt toto solve any of the given instances. A standard heuristic search algorithm (e.g., IDAsolve the bootstrap instances within a given time limit. The set of solved bootstrap instances, together with their solutionlengths (not necessarily optimal), is fed to a learning algorithm to create a new heuristic function h1 that is intended to bebetter than h0. After that, the previously unsolved bootstrap instances are used in the same way, using h1 as the heuristicinstead of h0. This procedure is repeated until all but a handful of the bootstrap instances have been solved or until asuccession of iterations fails to solve a large enough number of “new” bootstrap instances (ones that were not solved onprevious iterations).∗If the initial heuristic h0 is too weak to solve a sufficient number of the given bootstrap instances within the given timelimit we use a random walk method to automatically generate bootstrap instances at the “right” level of difficulty (easyenough to be solvable with h0, but hard enough to yield useful training data for improving h0).As in the earlier studies by Ernandes and Gori [9] and Samadi et al. [41], which may be seen as doing one step of thebootstrap process with a very strong initial heuristic, the learned heuristic might be inadmissible, i.e., it might sometimesis not guaranteed to find optimal solutions with the learned heuristic. Withoverestimate distances, and therefore IDAbootstrapping, the risk of excessive suboptimality of the generated solutions is much higher than with the one-step methodsbecause on each iteration the learning algorithm might be given solution lengths larger than optimal, biasing the learnedheuristic to even greater overestimation. The suboptimality of the solutions generated is hence an important performancemeasure in our experiments.∗We test our method experimentally on four problem domains that are at, or beyond, the limit of what current abstractionmethods can solve optimally—the 24-sliding-tile puzzle, the 35-pancake puzzle, Rubik’s Cube, and the 20-blocks world—ineach case starting with an initial heuristic so weak that the previous, one-step methods would fail because they would notbe able to generate an adequate training set in a reasonable amount of time. In all the domains, bootstrapping succeeds in∗to solve randomly generated problem instances quickly with solutions that are veryproducing a heuristic that allows IDAclose to optimal. On these domains our method systematically outperforms Weighted IDA[30] and BULB [15].∗The time it takes for our bootstrap method to complete its learning on these large state spaces is on the order of days.This is acceptable when the learned heuristic will be used to solve many instances, but a different approach is neededin order to solve a single instance quickly. For this we introduce a method that interleaves the bootstrapping process forcreating a succession of ever stronger heuristics with a process that uses the set of heuristics that are currently available(initially just h0) to try to solve the given instance. The total time required to solve a single instance using this methodis substantially less than the learning time for the bootstrap method, and the solutions it produces are of comparablesuboptimality. For example, with this method the total time to solve an instance of the 24-puzzle is just 14 minutes, onaverage, and the solution found is only 6.5% longer than optimal. When applied to the blocksworld instances used in theIPC2 planning competition, our interleaving method solves all the instances within the 30-minute time limit, and almost allare solve",
            {
                "entities": [
                    [
                        138,
                        189,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 86–110Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomated query learning with Wikipedia and genetic programmingPekka Malo∗, Pyry Siitari, Ankur SinhaAalto University, School of Economics, P.O. Box 21210, FI-00076 Aalto, Finlanda r t i c l ei n f oa b s t r a c tArticle history:Available online 19 June 2012Keywords:WikipediaGenetic programmingConcept recognitionInformation filteringAutomatic indexingQuery definitionMost of the existing information retrieval systems are based on bag-of-words model andare not equipped with common world knowledge. Work has been done towards improvingthe efficiency of such systems by using intelligent algorithms to generate search queries,however, not much research has been done in the direction of incorporating human-and-society level knowledge in the queries. This paper is one of the first attempts where suchinformation is incorporated into the search queries using Wikipedia semantics. The paperpresents Wikipedia-based Evolutionary Semantics (Wiki-ES) framework for generatingconcept based queries using a set of relevance statements provided by the user. The querylearning is handled by a co-evolving genetic programming procedure.To evaluate the proposed framework, the system is compared to a bag-of-words basedgenetic programming framework as well as to a number of alternative document filteringtechniques. The results obtained using Reuters newswire documents are encouraging. Inparticular, the injection of Wikipedia semantics into a GP-algorithm leads to improvementin average recall and precision, when compared to a similar system without humanknowledge. A further comparison against other document filtering frameworks suggeststhat the proposed GP-method also performs well when compared with systems that donot rely on query-expression learning.© 2012 Elsevier B.V. All rights reserved.1. IntroductionA central challenge in building expert systems for information retrieval (IR) is to provide them with common worldknowledge. As succinctly put by Hendler and Feigenbaum [23], in order to build any system with “significant levels ofcomputational intelligence, we need significant bodies of knowledge in knowledge bases”. That is, if a system is expected tounderstand the general semantics in text, closer to the way human brains do, then it should have access to the extensivebackground knowledge that people use while interpreting concepts (units of knowledge) and their dependencies. Of course,statistical methods and natural language processing can be used to extract semantics from text or data, but the ability oftext collections to convey human- and society-level semantics is quite limited [67]. Currently, there is an ongoing questto find new ways of integrating semantic knowledge into document modelling along with multiple other aspects (suchas document timeliness and novelty) without time-consuming knowledge engineering; see e.g. Pasi et al. [48]; Meij et al.[37]; Navigli and Crisfulli [45]; and references therein. One of the emerging trends is to use socially developed resources ofsemantic information.In this paper, we consider the use of Wikipedia as a source of common world knowledge for an automated query learningsystem. The purpose is to assist users to express their information needs as queries which are written in terms of Wiki-pedia’s concepts instead of word tokens. The proposed system extends the Inductive Query By Example (IQBE) paradigm of* Corresponding author.E-mail addresses: pekka.malo@aalto.fi (P. Malo), pyry.siitari@aalto.fi (P. Siitari), ankur.sinha@aalto.fi (A. Sinha).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.006\fP. Malo et al. / Artificial Intelligence 194 (2013) 86–11087Smith and Smith [59] and Chen et al. [9] by incorporating human-level semantics using Wikipedia. The underlying principleof IQBE is quite simple: assume that a user provides a small collection of relevant (and irrelevant) example documents,the task is to learn a query based on those documents. The learnt query is then used to filter relevant documents from anewstream or document database according to the topic definition implied by the sample collection. The approach proposedin this paper uses concept-relatedness information contained in Wikipedia’s link-structure to learn semantic queries usinga co-evolutionary procedure. This transition from an ordinary boolean query [55] to a semantified query is necessary forintegrating human- and society-level semantic information into the information retrieval (IR) system. The use of concept-based knowledge enables the IR systems to detect the relevance of a document based on the central concepts and notjust words. It also allows the system to identify those documents as relevant which contain concepts closely related to thequery concepts. The paper contributes towards construction of an IR framework where Wikipedia-concept based queries arelearnt using a co-evolving genetic programming (GP) algorithm. The proposed framework is called Wiki-ES (Wikipedia-basedEvolutionary Semantics).The traditional automated query learning systems usually represent both queries and documents using a bag-of-wordsapproach. Moreover, the recent studies on IQBE paradigm have almost exclusively focused on finding the best evolutionaryalgorithms and fitness functions for learning boolean queries; see e.g. Cordón et al. [12,13], García and Herrera [21], andLópez-Herrera et al. [30,29]. The use of IQBE systems is largely motivated by the portability of queries, which allows themto be interpreted as additional query generation components that can be placed on top of other retrieval systems witha boolean query interface. However, restricting the query and document models to word-level information eliminates thepossibility of leveraging human-level semantics on how the different topics and concepts are related. It should be notedthat a query is composed of a number of concepts, and it represents the topic the user wants to search. To illustratethe difference between word based search and concept based search, consider a situation where a user is searching forinformation on a particular topic, for which he crafts a simple query “economy AND espionage”. Then, suppose that a newlyarrived document has concepts “Trade secret” and “spying”. If we now ask a human reader to judge whether the documentis about economic espionage, he would most likely find it relevant due to the close relationships between the concepts.However, if only word-level information is used, the boolean query will ignore the document as the original query wordsnever appear.In this paper, we focus on the benefits of using concepts instead of bag-of-words in query learning and documentfiltering. As a test-bed for Wiki-ES system, we consider TREC-11 dataset with Reuters RCV1 corpus which provides a realisticexample of a multi-domain news-stream. The experiments suggest that the concept-based approach is well-fitted to be usedin conjunction with evolutionary algorithms. We observe that replacing tokens with Wikipedia’s concepts yields considerableimprovement in filtering results as measured by precision and recall. A comparison of Wiki-ES with other general documentfiltering algorithms is also drawn. The given benchmarks represent a number of paradigms. The obtained results indicatedstrong performance in terms of TREC-11 measures which motivates further research on the use of semantic information indocument retrieval.The structure of this paper is following. Section 2 summarizes the main contributions of the paper. Section 3 gives areview on IQBE model for automated query learning, and how Wikipedia can be used as a source of semantic information.Section 4 presents our framework Wikipedia-based Evolutionary Semantics (Wiki-ES). The co-evolutionary GP algorithm ispresented in Section 5. Finally, Section 6 summarizes the experimental results.2. ContributionsThe key contributions of the paper are summarized in the following points.2.1. Use of Wikipedia semantics in query learningWhen a set of documents concerning a particular topic is to be retrieved from a database, it is common for a userto generate a query composed of tokens (terms). This query is used to decide the relevance of documents in a databaseby performing a search for the tokens in those documents. However, analyzing the problem from a user point of view,it is recognized that the user is not just interested in the documents containing the exact matching tokens, rather sheis seeking all such documents which contain the concept represented by the token. This provides a motivation to worktowards generating queries composed of concepts rather than tokens. Queries composed of concepts contain wide human-and society-level knowledge, providing a better representation of the topic being searched. In this paper, we use Wikipediasemantics to convey the concept behind a token. There is no previous study to the knowledge of the authors, which utilizesthe Wikipedia semantics to construct a concept based query. The benefits of this transition from tokens to concepts, towardsretrieval of documents, has been evaluated in the paper and its significance has been established.2.2. Development of a co-evolving GPGenerating an accurate query for a search is often an iterative and tedious task to perform. However, if there is a setof documents available at hand, with each document marked relevant or irrelevant, the task of query generation can beentirely avoided by directing the documents to a genetic programming algorithm. Based on the relevance or irrelevance of\f88P. Malo et al. / Artificial Intelligence 194 (2013) 86–110the training documents, a concept based query can be learnt by the algorithm, saving the user from a monotonous task.The paper contributes towards development of a co-evolving evolutionary algorithm specialize",
            {
                "entities": [
                    [
                        144,
                        207,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 99 (1998) 21-71 Artificial Intelligence Learning metric-topological maps for indoor mobile robot navigation ’ Sebastian Thrun 2 Computer Science Department and Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA Received June 1996; revised October 1997 Abstract Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their com- plexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and con- sistent topological maps are often difficult to learn and maintain in large-scale environments, particularly if momentary sensor data is highly ambiguous. This paper describes an approach that integrates both paradigms: grid-based and topoIogica1. Grid-based maps are learned using artificial neural networks and naive Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms, and effi- the approach presented here gains advantages from both worlds: accuracy/consistency ciency. The paper gives results for autonomous exploration, mapping and operation of a mobile robot in populated multi-room environments. @ 1998 Elsevier Science B.V. Keywords: Autonomous robots; Exploration; Mobile robots; Neural networks; Occupancy grids; Path planning; Planning; Robot mapping; Topological maps I This research is sponsored in part by Daimler-Benz Research Foundation under award IRI-9313367, IJSAF, and Command, F33615-93-l-1330, and the Defense Advanced Research Projects Agency System Command document are those of the author and should not be interpreted as necessarily endorsements, Air Force Materiel Command, the National Science the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel the DARPA Advanced Research Projects Agency (DARPA) under grant number (DARPA) via the Air Force Missile in this representing official policies or the the National Science Foundation, the Air Force Missile System Command, or the United States Government. either expressed or implied, of Daimler-Benz Research, under contract number FO4701-97-C-0022. The views and conclusions (via Frieder Lohnert), contained 2 Email: thrun@heaven.leaming.cs.cmu.edu. 0004-3702/98/$19.00 PII SOOO4-3702( @ 1998 Elsevier Science B.V. All tights reserved. 97)00078-7 \f22 S. Thrun/Arti$cial Intelligence 99 (1998) 21-71 1. Introduction To efficiently carry out complex missions autonomous mobile robots must be able to acquire and maintain models of their environments. The problem factors impose of acquiring models limitations practical is difficult and far from being solved. The following on a robot’s ability to learn and use accurate models: in indoor environments, (i) Sensors. Sensors often are not capable of directly measuring the quantity of interest. For example, cameras measure color, brightness and saturation of light, such as “there is a whereas door in front of the robot.” for navigation one might be interested in assertions (ii) Perceptual transducers, global limitations. The perceptual range of most sensors cameras) is limited to a small range around (such as ultrasonic the robot. To acquire information, the robot has to actively explore its environment. (iii) Sensor noise. Sensor measurements are typically corrupted by noise. Often, the distribution of this noise is not known. (iv) Drift/slippage. Robot motion odometric errors accu- mulate over time. For example, even the smallest rotational errors can have huge effects on subsequent is inaccurate. Unfortunately, errors when estimating the robot’s position. translational ing it principally impossible (v) Complexity and dynamics. Robot environments (vi) Real-time requirements. Time requirements must be simple and easily accessible. For example, models of complex to be generated indoor environments in real-time. are complex and dynamic, mak- to maintain exact models and to predict accurately. that internal models fine-grain CAD if actions have accurate are often inappropriate often demand Recent research has produced vironments: approaches, and Koren grid cell may, for example, region of the environment. and Byun, MatariC and others ronments by graphs. Nodes landmarks between them. two fundamental paradigms for modeling indoor robot en- the grid-based such as those proposed by Moravec and Elfes [ 81 and many others, represent environments (metric) paradigm and the topological paradigm. Grid-based and Borenstein grids. Each [ 3 1,32,73] by evenly-spaced indicate Topological the presence of an obstacle in the corresponding such a those proposed by Kuipers robot envi- represent to distinct situations, places, or (such as doorways). They are connected by arcs if there exists a direct path approaches, [ 34,56,59,68,84,111,118,121], in such graphs correspond and weaknesses. environments Both approaches to robot mapping exhibit orthogonal strengths and to maintain to construct incrementally, in large-scale based on odometric grids are easy Occupancy grid approaches disambiguate position within a global coordinate Occupancy different places based on the [9,107,108]. is robot’s geometric estimated taken by the robot. Thus, occupancy grid approaches usually use an unbounded number of sensor to determine a robot’s location. To the extent that the position of a mobile robot readings look alike can be tracked accurately, different positions are naturally disambiguated. Nearby geometric places are recognized as such, even if the sensor measurements the case in dynamic environments where, e.g., humans can block a robot’s sensors. for which sensors measurements frame. The robot’s position and sensor readings differ-which information is often \fS. ThrudArtifcial Intelligence 99 (1998) 21-71 23 Table 1 Advantages and disadvantages of grid-based and topological approaches to map building Grid-based (metric) approaches Topological approaches easy to build, represent, and maintain recognition of places (based on geometry) is non- ambiguou:s and view point-independent facilitates computation of shortest paths planning inefficient, space-consuming (resolution does not depend on the complexity of the envi- ronment) requires accurate determination of the robot’s po- sition poor interface for most symbolic problem solvers + + + - _ _ permits efficient planning, low space complexity (resolution depends on the complexity of the en- vironment) does not require accurate determination of the robot’s position convenient representation ner/problem solver, natural language for symbolic plan- difficult to construct and maintain in large-scale environments if sensor information is ambiguous recognition of places often difficult, sensitive to the point of view may yield suboptimal paths approaches. Topological approaches determine the to the model primarily based on landmarks or distinct, mo- that look alike, if these places are the same if these places have been reached via different paths). Also, since ap- strongly on the view-point of the robot, often have difficulty determining if the robot traverses two places topological This is not the case for topological approaches sensor features. For example, position of the robot relative mentary topological or not (particularly sensory proaches may fail to recognize geometrically making it difficult highly ambiguous. input usually depends to construct large-scale maps, particularly if sensor information is nearby places even in static environments, On the other hand, grid-based approaches the resolution suffer from their enormous of a grid must be fine enough space and time to capture The resolution The compactness of the environment. three key advantages is because detail of the world. The key advantage of topological of topological maps corresponds complexity. This every important is their compactness. complexity them (b) they facilitate provide more natural topological position of the robot, they often recover better from drift and slippage-phenomena must constantly be monitored and compensated both paradigms Table 1. to symbolic planners for human they permit and problem-solvers, approaches usually do not require of topological (a) they (such as: “go CO room A”). Since of the geometric that representation directly representations strengths and weaknesses, which are summarized in grid-based approaches. To summarize, fast planning, and (c) the exact determination have orthogonal over grid-based to the gives approaches: instructions interfacing interfaces in This paper advocates (see also the integration of both paradigms to gain the best of both representations. [ 151). The approach presented here combines worlds and topological sensor values are interpreted by an artificial neural network and mapped ities for occupancy. Multiple interpretations On top of the grid representation, more compact (metric) a grid-based model of the environment, into probabil- are integrated over time using Bayes rule. topological maps are generated by To construct grid-based \f24 S. ThrudArtificial Intelligence 99 (1998) 21-71 Fig. 1. The robots used in our research: RHINO The software has also been ported to RWI’s B14 robots. (University of Bonn), XAVIER, and AMELIA (both CMU) the metric map into coherent regions, separated to narrow passages such as doorways. By partitioning than smaller of both representations splitting lines correspond into a small number of regions, of magnitude the integration either approach and maintain sistently is grounded ing. The approach also the considerably tion. and disambiguates in the metric in isolation: in environments inherits larger memory the number of topological the number of cells in the grid representat",
            {
                "entities": [
                    [
                        64,
                        131,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 83 (1996) 143-166 Artificial Intelligence Abduction to plausible causes: an event-based model of belief update * Craig Boutilier * Department of Computer Science, University of British Columbia, Vancouver; BC, Canada V6T 124 Received March 1994; revised November 1994 Abstract The Katsuno and Mendelzon (KM) theory of belief update has been proposed as a reasonable model for revising beliefs about a changing world. However, the semantics of update relies on information which is not readily available. We describe an alternative semantical view of update in which observations are incorporated into a belief set by: (a) explaining the observation in terms of a set of plausible events that might have caused that observation; and (b) predicting further consequences of those explanations. We also allow the possibility of conditional expluna~ions. We show that this picture naturally induces an update operator conforming to the KM postulates under certain assumptions. However, we argue that these assumptions are not always reasonable, and they restrict our ability to integrate update with other forms of revision when reasoning about action. 1. Introdnction Reasoning about action and change has been a central many years, dating at least to the origins of the situation calculus planning to verify whether a potential plan achieves a desired goal. Actions effect changes the world, and agents must be able to modify such considerations. in AI for [ 201. For example, a the effects of its actions on the world in order in to reflect in a dynamic world must be able agent must be able to predict their beliefs about focus of research an agent situated Furthermore, the world * Some parts of this report appeared Proceeding.1 Tenth Canadian Conference on AI, Banff, Alta. ( 1994). * E-mail: c:ebly@cs.ubc.ca. in preliminary form as “An event-based abductive model of update”, in: 0004-3702/96/$15.00 SSDIOOO4-3702(94)00097-2 @ 1996 Elsevier Science B.V. All rights reserved \f144 C. Boutilier/Art@cial Intelligence 83 (1996) 143-166 to reason about changes occurrence of exogenous events as well. in the world not simply due to its own actions, but due to the [ 11. Imagine and Makinson One of the most influential theories of belief change has been the ACM theory pro- a con- the possible ways in which the agent can change KB in order to accommodate that this revision of KB need not be straightforward, posed by Alchourron, Gardenfors belief set or knowledge base KB. The AGM straining a new belief A. Notice belief A may conflict with beliefs AGM theory is inappropriate of a changing world. A new form of belief change dubbed update was proposed generality by Katsuno and Mendelzon from the AGM postulates, in belief due to the evolution in full [ 161, who provided a set of postulates, distinct in KB. It was pointed out by Wmslett theory provides a set of postulates for the new that the this type of belief change. an agent possesses that characterize about changes for reasoning [27] have shown as describing the most plausible ways in which Semantically, Katsuno and Mendelzon that belief update can be charac- terized by positing a family of orderings over possible worlds, with each ordering being indexed by some world. The ordering associated with a specific world can be viewed intuitively that world can change. To update a knowledge base KB with some proposition A, the worlds admitted by KB are each updated by finding A (we describe observes book outside on the patio, but concludes are two possible worlds admitted by her knowledge, 0 and 0 it is not). When book conditional agent’s updated belief set. the most plausible change associated with that world satisfying that someone that the grass in front of her house is wet. She is not sure whether she left her it is wet too. There (the book is outside or is updated with the observation of wet grass, a wet the book remains dry. The is part of our belief 0 E W (the book is wet if and only if it was outside) this formally below). As a concrete example, that if the book is outside the second possibility is the result. When the first possibility is updated, suppose In this paper, we present an abductive model of belief change suitable to a changing world. While our semantics in response that is somewhat more general the most compelling into smaller, more primitive parts. We argue in response aspect of our model beliefs change operators operators, semantics more natural perspective on belief update exploits a system. change used to capture changes models conforming to the KM postulates). In the following, we use the term update in belief due to change information is the fact that it breaks for updating induces a class of belief (KM) update the KM that such a model provides a in the world, and to changes from users of to describe any process of belief those in the world (not simply that is more readily available or easily obtainable than Katsuno-Mendelzon In general, we take update to be a two-stage process of explanation first, an agent explains an observation that observation that could have caused second, an agent predicts the (further) to this initial state. In our example, them the sprinkler turning on automatically, of these causing including the book events, our agent concludes if it is out there. Had sprinkler been a different conclusion would have been reached: to its initial by postulating to hold, relative consequences followed by some plausible event state of these events, there are several possible causes of wet is the most or rain. If rain on the patio the most plausible the book would be dry that everything prediction: or events of knowledge; relative grass, among plausible is wet, explanation, \fC. Boutilier/Art@cial Intelligence 83 (1996) 143-166 145 It is these considerations in the world are most plausible. regardless of its location. just what changes the effects of (events, as well as their relative plausibility, will be more readily available or easier of the world. that allow an agent Intuitively, than a direct ordering of plausibility to determine about over possible “evolutions” information to assess this notion We formalize this connection that are similar and Becher by explicit belief abductive process, we may also take update [5] present a model of abduction where explanations revision. Given in an abstract manner obtaining a class of explanation-change in spirit and intent to KM update operators, but somewhat more [ 121. are and the fact that update to be a in stark contrast with the accepted wisdom forms of belief change. While we could cast our this would detract from the main point of the paper. operators general. We note that explanation has often been closely linked with belief revision Indeed, Boutilier determined can be viewed as an essentially certain kind of belief revision. This stands that update and revision are orthogonal model as al form of belief revision, However, we do elaborate on this connection the KM postulates this semantics more closely, and break in the concluding for belief update and the KM semantics. it into more basic to the naturally give rise as general a special class of update In Section 2 we review In Section 3 we analyze elements. We describe our abductive view of update and show its relationship KM model _ In particular, we show that certain semantic assumptions to the KM theory; however, we argue that these assumptions update principles. We also briefly describe and characterize operators. to belief to observaltions update. Finally, we compare our construction Val and Shoham In Section 4, we analyze our model more deeply and discuss revision. We also argue in dynamic the connections of belief states in response of belief revision and belief to the model of update proposed by de1 that proper modification involves a combination [ 81. Proofs of the main results can be found in Appendix A. are inappropriate section. settings 2. The semantics of update Katsuno and Mendelzon [ 161 have proposed is distinguished a general characterization from belief revision conceptually update. Update reflecting belief change to be more appropriate Update acceptable update operators and a possible worlds semantics, both of which we review here. in the world, whereas revision erroneous) and Mendelzon with a set of postulates in response for changing is described by Katsuno to changes (possibly of belief by viewing update as is thought beliefs about a static world. constraining We assume an agent about propositional, of possible worlds (or models) the current the existence of some knowledge base KB, state of the world. We take our underlying logic language Lcp~. We use W to denote the set of beliefs held by to be the set based on a finitely generated suitable If some new fact A is observed in response (unspecified) change (i.e., some action or event occurrence), this change. The KM postulates the formula KB o A denotes [ 161 governing admissible world new belief set incorporating update operators are: in the the for this language. to some then \f146 C. Boutilier/Artificial Intelligence 83 (1996) 143-166 to KB. then KB o A is satisfiable. k A. (Ul) KBoA (U2) (U3) (U4) (U5) (U6) (U7) (U8) A better understanding If KB k A then KB o A is equivalent If KB and A are satisfiable, IfbA=BthenKBoA-KBoB. (KBoA)AB/=KBo(AAB). IfKBoAbBandKBoBkAthenKBoArKBoB. If KB is complete A (KBoB) (KBI v KB;,) oA = (KBI oA) v (KB20A). of the mechanism then (KBoA) b KBo (AV B). underlying update can be achieved by the possible worlds semantics described by Katsuno and Mendelzon, which considering to the postulates. For any proposition A, let 11 AlI denote they show to be equivalent the set of worlds satisfying A, Clearly, the set of possibilities we are 0 is the result of prepared for each possibility w E JIKBI(, some change the most plausible way (or ways) in order to make 0 true. We will call such a change in any world an “evolution” of that world. To capture this i",
            {
                "entities": [
                    [
                        75,
                        143,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 234 (2016) 120–151Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the expressivity of inconsistency measuresMatthias ThimmInstitute for Web Science and Technologies, Universität Koblenz-Landau, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 19 June 2015Received in revised form 26 January 2016Accepted 28 January 2016Available online 29 January 2016Keywords:Inconsistency measuresInconsistency managementWe survey recent approaches to inconsistency measurement in propositional logic and provide a comparative analysis in terms of their expressivity. For that, we introduce four different expressivity characteristics that quantitatively assess the number of different knowledge bases that a measure can distinguish. Our approach aims at complementing ongoing discussions on rationality postulates for inconsistency measures by considering expressivity as a desirable property. We evaluate 16 different measures on the proposed characteristics and conclude that the distance-based measure I(cid:2)dalal from Grant and Hunter (2013) [8] and the proof-based measure IPm from Jabbour and Raddaoui (2013) [16]have maximal expressivity along all considered characteristics. In our study, we discovered several interesting relationships of inconsistency measurement to e.g. set theory and Boolean functions and we also report these findings.© 2016 Elsevier B.V. All rights reserved.1. IntroductionInconsistency measurement is about the quantitative assessment of the severity of inconsistencies in knowledge bases. Consider the following two knowledge bases K1 and K2 formalized in propositional logic:K1 = {a, b ∨ c, ¬a ∧ ¬b, d}K2 = {a, ¬a, b, ¬b}Both knowledge bases are classically inconsistent as for K1 we have {a, ¬a ∧ ¬b} |(cid:4)⊥ and for K2 we have, e.g., {a, ¬a} |(cid:4)⊥. These inconsistencies render the whole knowledge bases useless for reasoning if one wants to use classical reasoning tech-niques. In order to make the knowledge bases useful again, one can either rely on non-monotonic/paraconsistent reasoning techniques [23,27] or one revises the knowledge bases appropriately to make them consistent [9]. Looking at the knowledge bases K1 and K2 one can observe that the severity of their inconsistency is different. In K1, only two out of four formulas (a and ¬a ∧ ¬b) are “participating” in making K1 inconsistent while for K2 all formulas contribute to its inconsistency. Furthermore, for K1 only two propositions (a and b) are conflicting and using e.g. paraconsistent reasoning one could still infer meaningful statements about c and d. For K2 no such statement can be made. This leads to the assessment that K2should be regarded more inconsistent than K1.Inconsistency measures can be used to analyze inconsistencies and to provide insights on how to repair them. An incon-sistency measure I is a function on knowledge bases, such that the larger the value I(K) the more severe the inconsistency in K. A lot of different approaches of inconsistency measures have been proposed, mostly for classical propositional logic [10,12,13,22,25,32,7,8,24,15], but also for classical first-order logic [6], description logics [21,33], default logics [5], and prob-abilistic and other weighted logics [19,30,26]. Due to this plethora of inconsistency measures it is hard to determine which E-mail address: thimm@uni-koblenz.de.http://dx.doi.org/10.1016/j.artint.2016.01.0130004-3702/© 2016 Elsevier B.V. All rights reserved.\fM. Thimm / Artificial Intelligence 234 (2016) 120–151121measure to use for an application and which measure is meaningful. Rationality postulates have been proposed that ad-dress the issue of assessing the quality of a measure—see e.g. [11,25]—but many of these properties have been criticized to address only a specific point of view, see [2] for a recent discussion on this topic.In this paper, we take a different perspective on the evaluation of inconsistency measures by considering a quantitativeanalysis of their expressivity, that is, we study how many different (inconsistent) knowledge bases can be distinguished by a given inconsistency measure. By the term expressivity we here refer to the property of a semantical concept—here, an inconsistency measure—and its capability to distinguish syntactical constructs—here, knowledge bases—, similarly as it has been done for the analysis of expressivity of semantics for other logical languages, see e.g. skepticism relations for formal argumentation [1]. Our analysis is meant to complement the study on rationality postulates and is, of course, not meaningful on its own as the compliance of measures with the basic intuitions behind inconsistency measures can only be assessed by rationality postulates. However, we introduce expressivity of inconsistency measures as an additional method to evaluate their quality. In particular, we propose four different expressivity characteristics that quantify the relation between the number of different values of an inconsistency measure wrt. different notions of the size of the knowledge base, such as number of formulas or number of propositions. We conduct a thorough comparative analysis of 16 different inconsistency measures from the literature [12,13,7,17,31,8,25,16,32,5] and classify these measures in a hierarchy of expressivity. In our study, we made several interesting observations, such as the relation between the measure IMI [7] and Sperner families [28]and of the measure Ifrom Grant and Hunter [8] and the proof-based measure IPm from Jabbour and Raddaoui [16] have maximal expressivity along all considered characteristics.MIC [7] with profiles of Boolean functions. One of our results is that the distance-based measure I(cid:2)dalalIn summary, the contributions of this paper are as follows:1. We conduct a focused survey of 16 inconsistency measures from the recent literature (Section 3).2. We propose four different expressivity characteristics, evaluate the considered inconsistency measures wrt. these char-acteristics, and study our findings (Section 4).3. We classify the evaluated measures into hierarchies of expressivity and thus provide a means to quantitatively compare different measures (Section 5).We give necessary preliminaries in Section 2 and provide a summary in Section 6. Appendix A contains proofs of technical results and Appendix B lists all example knowledge bases and families of knowledge bases used in the paper. All incon-sistency measures discussed in this paper have been implemented and an online interface to try out these measures is available.12. PreliminariesLet At be some fixed propositional signature, i.e., a (possibly infinite) set of propositions, and let L(At) be the corre-sponding propositional language constructed using the usual connectives ∧ (and), ∨ (or), and ¬ (negation).Definition 1. A knowledge base K is a finite set of formulas K ⊆ L(At). Let K be the set of all knowledge bases.If X is a formula or a set of formulas we write At( X) to denote the set of propositions appearing in X . Semantics to a propositional language is given by interpretations and an interpretation ω on At is a function ω : At → {true, false}. Let (cid:4)(At)denote the set of all interpretations for At. An interpretation ω satisfies (or is a model of) a proposition a ∈ At, denoted by ω |(cid:4) a, if and only if ω(a) = true. The satisfaction relation |(cid:4) is extended to formulas in the usual way.As an abbreviation we sometimes identify an interpretation ω with its complete conjunction, i.e., if a1, . . . , an ∈ At are those propositions that are assigned true by ω and an+1, . . . , am ∈ At are those propositions that are assigned false by ω we identify ω by a1 . . . anan+1 . . . am (or any permutation of this). For example, the interpretation ω1 on {a, b, c} with ω(a) = ω(c) = true and ω(b) = false is abbreviated by abc.For (cid:5) ⊆ L(At) we also define ω |(cid:4) (cid:5) if and only if ω |(cid:4) φ for every φ ∈ (cid:5). Define furthermore the set of models Mod( X) = {ω ∈ (cid:4)(At) | ω |(cid:4) X} for every formula or set of formulas X . If Mod( X) = ∅ we also write X |(cid:4)⊥ and say that X is inconsistent.3. Inconsistency measuresLet R∞≥0 be the set of non-negative real values including ∞. Inconsistency measures are functions I : K → R∞≥0 that aim at assessing the severity of the inconsistency in a knowledge base K, cf. [7]. The basic idea is that the larger the inconsistency in K the larger the value I(K) and I(K) = 0 if and only if K is consistent. However, inconsistency is a concept that is not easily quantified and there have been a couple of proposals for inconsistency measures so far, in particular for1 http://tweetyproject.org/w/incmes/.\f122M. Thimm / Artificial Intelligence 234 (2016) 120–151Table 1Definitions of the considered inconsistency measures.Id(K) =(cid:2)1 if K |(cid:4)⊥0 otherwiseIMI(K) = |MI(K)|MIC (K) =I(cid:3)M∈MI(K)1|M|Iη(K) = 1 − max{ξ | ∃P ∈ P(At) : ∀α ∈ K : P (α) ≥ ξ }Ic(K) = min{|υ−1(B)| | υ |(cid:4)3 K}IL Pm (K) = Ic(K)/|At(K)|Imc(K) = |MC(K)| + |SC(K)| − 1Ip(K) = |(cid:4)M|M∈MI(K)Ihs(K) = min{|H| | H is a hitting set of K} − 1dalal(K) = min{I(cid:2)(cid:3)α∈Kdalal(K) = min{maxI maxα∈Kdd(Mod(α), ω) | ω ∈ (cid:4)(At)}dd(Mod(α), ω) | ω ∈ (cid:4)(At)}dalal(K) = min{|{α ∈ K | dd(Mod(α), ω) > 0}| | ω ∈ (cid:4)(At)}I hitID f (K) = 1 − (cid:11)|K|i=1(1 − R i(K)/i)(cid:3)a∈At(cid:5)|IPm (K) =Imv (K) =|PKm (a)| · |PKm (¬a)|M∈MI(K) At(M)||At(K)|Inc(K) = |K| − max{n | ∀K(cid:14) ⊆ K : |K(cid:14)| = n ⇒ K(cid:14) (cid:16)|(cid:4)⊥}classical propositional logic, see e.g. [2,24,15,14] for some recent works. We selected 16 inconsistency measures from the literature in order to conduct our analysis on expressivity, taken from [12,13,7,17,31,8,25,16,32,5]. We briefly introduce these measures in this section for the sake of completeness, but we refer for a detailed explanation to the corresponding original papers.To illustrate the different in",
            {
                "entities": [
                    [
                        136,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 94 (1997) 57-77 Artificial Intelligence Rationality and intelligence Stuart J. Russell 1 Computer Science Division, University of California, Berkeley, CA 94720, USA Abstract The long-term goal of our field is the creation and understanding of intelligence. Productive in AI, both practical and theoretical, benefits from a notion of intelligence that is precise to allow the cumulative development of robust systems and general results. The concept of to fulfill this role. This paper outlines to our informal that brings theory and practice. Some research enough rational agency has long been considered a leading candidate in the formal conception of rationality a gradual evolution conception of intelligence directions for future research are indicated. @ 1997 Elsevier Science B.V. and simultaneously the gap between it closer reduces Keywords: Philosophical foundations; Intelligence; Rationality; Bounded rationality; Bounded optimality 1. Artificial intelligence AI is a field whose ultimate goal has often been somewhat dispute. Some researchers of intelli,gence without concern useful artifacts without concern to aim to emulate human cognition, others aim at the creation and still others aim to create and subject ill-defined for human characteristics, for abstract notions of intelligence. This variety and provides abhor a definitional feasibility not subscribe. is not necessarily fertilization a bad thing, since each approach uncovers new ideas that, since philosophers to the others. But one can argue vacuum, many of the damaging and ill-informed the of AI to which we as AI researchers do debates about of AI have been about definitions My own motivation for studying AI is to create and understand general property of systems, to be an appropriate goal for the field as a whole, and it certainly of useful artifacts-both as a spin-off and as a focus and driving rather than as a specific attribute of humans. intelligence as a this the creation force for technological I believe includes ’ Email: russell@cs.berkeley.edu. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PII SOOOG-3702 (97) 00026-X \f58 S.J. Russell/Artificial Intelligence 94 (1997) 57-77 The difficulty with this “creation of intelligence” view, however, is that that we have some productive notion of what intelligence can say “Look, my model correctly predicted this experimental but few of us are happy with papers saying “Look, my system can say “Look, my system is. Cognitive observation is saving is cognition”, and artifact developers development. it presupposes scientists of human lives/megabucks”, intelligent”. This difficulty to allow us to design complex of others. “Intelligent” must be given a definition system’s AI subsides vehicle control, into a smorgasbord of fields-intelligence is compounded intelligence systems with confidence and further by the need for theoretical scaffolding to build on the results to the that can be related directly input, structure, and output. Such a definition must also be general. Otherwise, as chess playing, intelligence as as medical diagnosis. the development I shall examine to characterize systems each definition of such definitions over the history as a predicate P that that are intelligent. For each P, I and at least the is P” is interesting development to which the statement “Look, my system true, and the sort of research and technological In this paper, I shall outline supposedly, of AI and related disciplines. can be applied, shall discuss whether sometimes study of P-systems leads. I shall begin with successful behaviour-the definitions of intelligence the idea that intelligence so-called “agent-based” are as follows: is strongly related view of AI. The candidates to the capacity for for formal l PI : Pelfect rationality, or the capacity to generate maximally successful behaviour given the available information. l P2: Calculative rationality, or the in-principle to compute the perfectly rational decision given the initially available capacity information. l P3: Metakvel rationality, or the capacity computation-sequence-plus-action, selected by the computation. under to select the constraint the optimal that combination of the action must be l P4: Bounded optimality, or the capacity successful behaviour given the available information to generate maximally resources. and computational All four definitions will be fleshed out in detail, and I will describe some results have been obtained work under lines. Then I will describe ongoing rationality these the headings of calculative and bounded optimality. so far along that and future results technical a suitable a condition increasingly bounded optimality is always a danger, I shall be arguing that, of these candidates, comes closest to in this sort of claim, characterized the original Is research on bounded the needs of AI research. There the case of AI, the problem of creating can lead to “premature mathematization”, that have meeting that its acceptance by increasingly problem-in optimality bounded optimality, with real and desirable about the nature of intelligence. Some important questions about intelligence formulated thereof. Only time will tell, however, whether bounded optimality additional practical progress it is a real problem intuitions can only be the framework of bounded optimality or some relative research, perhaps with to support significant is more suitable solutions, for research on intelligence? than PI through P3 because little intelligence. it satisfies some essential and answered within can generate enough and also because to do with refinements, scaffolding theoretical that P4, to show stand-in I hope in AI. \fS.J. Russell/Art$cial Intelligence 94 (1997) 57-77 59 2. Agents recently, it was common fairly faculties” Until “mental systems”, that. This does not provide much guidance. lem of designing systems “right”. or “intelligent study of to define AI as the computational catalogue it at various kinds, and Instead, one can define AI as the prob- for leave that do the right thing. Now we just need a definition This approach involves considering the intelligent and acts upon entity as an agent, it. Formally that is to say is actions to actions instantiates. that senses that the agent its environment speaking, an agent from percept sequences the agent can carry out in the external world a system defined by the mapping Let 0 be the set of percepts set of possible action of doing nothing). Thus the agent function behaves under all circumstances. What counts in the first instance not necessarily what it thinks, or even whether consider reason as occurring “cognitive the right rather systems can do the right thing without such cognitive more subsystems. that the agent can observe at any instant, and A be the the : 0* -+ A defines how an agent is what the agent does, to -further constraints on the internal workings of the agent (such as that it should it allows us to view such in the service of finding that it allows of and reasoning it encompasses than excludes faculties it thinks at all. This to consider various and interconnections in three ways: to do; second, for example) specifications, [ 1,4] ; third, the position as planning boundaries, (including faculties” logically, freedom refusal initial helps thing first, f The agent-based and “embeddedness” Rational agents, of view of the information it was designed). Rationality it does c:onstrain-the emphasized dural rationality make and Thought the fact that reasoning not, be a good cognitive lem. to describe by Simon structures to mainstream view of AI has moved quickly from workshops on “situatedness” in Newsweek. loosely speaking, are agents whose actions make sense from the point possessed by the agent and its goals (or the task for which is a property of actions and does not specify-although [ 10,391 and buzzwords textbooks process by which [ 461, who coined the difference between the question of how to make lecture was titled “Intelligence without Reason” is (perhaps) a derived property of agents implementation scheme that many AI researchers th& question of what decision it. That Rod Brooks’ 1991 Computers the actions are selected. This was a point rationality and proce- the terms substantive to and [5] ) emphasizes that might, or might the Justifying is not an easy prob- rational behaviour. take for granted (see also to achieve One other consequence of the agent-based view of intelligence from other fields that have traditionally looked on the embedded is that it opens AI up agent topic of study. Control theory is foremost among and indeed evolutionary biology itself also have these, but evolutionary to contribute.* ideas to competition as a natural programming ‘1 view lhis as a very positive development. AI is a field defined by its problems, not its methods. insights-among the learning, use, and compilation of explicit knowledge from other fields. This is especially Its in the service of true certainly withstand the influx of new methods principal decision making-can when other, fields are simultaneously them embracing the insights derived within AI. \f60 S.J. Russell/Artificial Intelligence 94 (1997) 57-77 Percept history State history \\Ir Value Fig. 1. The agent receives percepts environment value of the agent. to generate a state history. The performance measure evaluates the state history from the environment and generates a behaviour which in turn causes the to arrive at the The prevalence problems, fragility of a subsystem and interpreting its outputs. of the agent view has also helped avoiding what Brooks calls the “hallucination” the field move problem towards solving that arises when is masked by having an intelligent human providing input real the to it 3. Perfect rationality to provide Perfect rationality an agent’s actions constrains the information inputs available. We can expand to the definition of success given Fig. 1) . The fundamen",
            {
                "entities": [
                    [
                        64,
                        92,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 87 ( 1996) 187-2 13 Artificial Intelligence Reasoning with models * Roni Khardon *, Dan Roth ’ Aiken Computation Laboratory, Harvard University, 33 Oxford Street, Cambridge, MA 02138, LISA Received August 1994; revised January 1996 Abstract We develop a model-based approach to reasoning, in which the knowledge base is represented as a set of models (satisfying assignments) rather than a logical formula, and the set of queries is restricted. We show that for every propositional knowledge base (KB) there exists a set of characteristic models with the property that a query is true in KB if and only if it is satisfied by the models in this set. We characterize a set of functions for which the model-based representation is compact and provides efficient reasoning. These include cases where the formula-based repre- sentation does not support efficient reasoning. In addition, we consider the model-based approach to abductive reasoning and show that for any propositional KB, reasoning with its model-based representation yields an abductive explanation in time that is polynomial in its size. Some of our technical results make use of the monotone theory, a new characterization of Boolean functions recently introduced. The notion of restricted queries is inherent in our approach. This is a wide class of queries for which reasoning is efficient and exact, even when the model-based representation KB provides only an approximate representation of the domain in question. Moreover, we show that the theory developed here generalizes the model-based approach to reasoning with Horn expressions and captures even the notion of reasoning with Horn approxi- mations. Keywords: Knowledge representation; Common-sense reasoning; Automated reasoning *An earlier version of the paper appears in the Proceedings of the National Conference on Artificial Intelligence, AAAI-94. * Corresponding author. Research supported by AR0 grant DAAL03-92-G-0115 (Center for Intelligent Control Systems). E-mail: roni@das.harvard.edu. L Research supported by NSF grant CCR-92-00884 and by DARPA AFOSR-F4962-92-J-0466. Current address: Department of Applied Mathematics & CS, Weizmann Institute of Science, Rehovot 76100, Israel. E-mail: danr@wisdom.weizmann.ac.il. 0004-3702/96/$15.00 Copyright @ 1996 Elsevier Science B.V. All rights reserved. PII SOOO4-3702(96)00006-9 \f188 R. Khurdorr. 0. Rorh/Arrific~~ul huelligence R7 (1996) 187-213 1. Introduction systems framework in intelligent for reasoning is the knowledge- in some representation A widely accepted [ 261. The idea is to keep the knowledge based system approach are assigned language with a well-defined meaning stored in a knowledge base (KB) which is combined with a reasoning mechanism, used reasoning to determine what can be inferred to capture our is usually abstracted as follows: Given that about the domain knowledge is assumed at hand, decide whether KB implies LY (denoted to capture W + a). This can be understood as the question: “Is cr consistent with the current state of knowledge?’ to those sentences. The sentences the knowledge base KB, assumed and a sentence LY, a query in the KB. Deductive from the sentences (the “world”), the situation in question Solving the question KB /= u, even in the propositional theoretic beliefs requires exponential cast, is co-NP-hard and under time. Many other forms the current complexity of reasoning which have been developed difficulties, were also shown to be hard to compute [ 30,3 1 1. at least partly to avoid these computational and theory reasoning [23 J who argued that common-sense is influenced by convincing amount of recent work on reasoning that we should give a computational A significant ments of Levesque of reasoning its speed and flexibility. Most of the work in this direction kind of theorem proving process, and is based on the belief sources of the computational capture common-sense line of research aims at identifying can perform the strong meets see [ 351 ), even though to be implausible argued argu- is a distinct mode for both that accounts still views reasoning as a that a careful study of the to for efficient reasoning. Thus, this classes of limited expressiveness, with which one 11. None of these works, however, (e.g. reasoning for common-sense there has been of classes discussed the limited expressiveness [ 71. difficulties may lead to a formalism expressive enough knowledge, while still allowing theorem proving efficiently [ 3.24.30,3 required requirements tractability Levesque argues [23,24] that reasoning with a more direct representation is easier the knowledge base to the real world. This the truth value of the to represent reasoning. He suggests and better suits common-sense KB in a vivid form, which bears a strong and direct relationship might be just a model of KB [ 8,281 on which one can evaluate query LY. It is not clear, however, how one might derive a vivid form of the knowledge likely model of the real world, base. Moreover, under various reasonable criteria, in order to achieve an efficient solution the the problem KB /= a. problem: inference problem but rather a different problem. whose exact relation depends on the method selected hard [ 28,321. Most importantly, this approach modifies reasoning with a vivid representation to the reasoning problem the knowledge base. no longer solves is computationally a model which to the original is the most to simplify selecting A model-based approach to reasotzitzg In this work we embark on the development of a model-based approach to common- sense reasoning. It is not hard to motivate a model-based cognitive point of view and indeed, many of the proponents of this approach approach to reasoning to reasoning from a \fR. Khardon, D. Roth/Art@cial intelligence 87 (1996) 187-213 189 have been cognitive psychologists be seen as an example of Levesque’s notion of “vivid” studied [ 12,13,22]. in [ 141. In the AI community reasoning this approach can and has already been The deduction problem KB b cy can be approached using the following model-based strategy: Test set: A set S of possible assignments. Test: If there is an element x E S which satisfies KB, but does not satisfy CY, deduce that KB p LY; Otherwise, KB + a. Since, by the model theoretic definition of implication, KB k cr if and only model of KB is a model of LY, the suggested (satisfying is the set of all models approach becomes useful A model-based fairly small set of models as the test set, and still perform under some criterion. assignments) strategy solves the inference problem if every if S of KB. But, this set might be too large. to use a if one can show that it is possible reasonably good inference, We define a set of models, the characteristic models of the knowledge to deduce the model-based test with it suffices small, and thus the model-based set of queries. We prove that for a fairly wide class of representations, show that performing a restricted set is sufficiently restricted queries is inherent common-sense all possible queries. For a wide class of queries we show that exact reasoning done efficiently, of the “world”. We show in formalizing reasoning, we take the view that a reasoner need not answer efficiently the reasoner keeps in KB an “approximate” that the theory developed here generalizes since we are interested in our approach; the model-based representation even when approach approach base, and that KB b a, for this is feasible. The notion of can be theory approximations reasoning with Horn expressions, reasoning with Horn expressions phenomena sentation expressive the model-based families of propositional for which there, observed and the approach regarding suggested [33]. representation expressions, to in [ 141, and captures even the notion of the In particular, our results characterize the in [ 141 is useful and explain repre- of KB. We also give other examples of formula suggested the relative sizes of the logical for which our approach in independently is useful. the relational We note that characteristic models were studied database community definite Horn expressions. The results domain (e.g., bounding (where in this paper have immediate [ 2,251, for the special case of in this implications relations), which are described elsewhere they are called “generators”) the size of Armstrong [171. In addition, we consider and show the problem of performing abduction using a model-based base, using a model-based that for any propositional explanation Some of our technical knowledge in time yields an abductive representation. that is polynomial in the size results make use of a new recently of Boolean functions, called the monotone theory, introduced [4]. some more results on reasoning with models have been derived, exhibiting repre- include algorithms logic as well as some cases of to handle some fragments of Reiter’s default the usefulness of this approach. These sentations that use model-based approach representation of the model-based characterization by Bshouty Recently, \f[ 201. A theory of reasoning with partial models and the learnability of circuit diagnosis in [ 2 I 1. The question of translating between characteris- such representations tic models and propositional theory as well) (which has also been studied. Some results on the complexity of this and related questions are described in database expressions is relevant in [ I7 1. is studied Most of the work on reasoning that the knowledge base is given assumes the question of how this knowledge might be acquired in this paper we also take this point of view, we are interested form. and While entire process of le~lnzirrg a knowledge base representation particular, Bshouty representation we consider here when given access to a membership oracle and an equivalence oracle. In [ 191 we discuss the importance of the model-based in some is not considered. in studying the and reasoning with it. In the issue of “learning for this problem",
            {
                "entities": [
                    [
                        77,
                        98,
                        "TITLE"
                    ],
                    [
                        8764,
                        8785,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 171 (2007) 1–18www.elsevier.com/locate/artintIterated belief revision, revised ✩Yi Jin 1, Michael Thielscher ∗Department of Computer Science, Dresden University of Technology, GermanyReceived 8 September 2005; received in revised form 1 November 2006; accepted 9 November 2006Available online 13 December 2006AbstractThe AGM postulates for belief revision, augmented by the DP postulates for iterated belief revision, provide widely acceptedcriteria for the design of operators by which intelligent agents adapt their beliefs incrementally to new information. These postulatesalone, however, are too permissive: They support operators by which all newly acquired information is canceled as soon as an agentlearns a fact that contradicts some of its current beliefs. In this paper, we present a formal analysis of the deficiency of the standardpostulates alone, and we show how to solve the problem by an additional postulate of independence. We give a representationtheorem for this postulate and prove that it is compatible with AGM and DP.© 2006 Elsevier B.V. All rights reserved.Keywords: Iterated belief revision; Implicit dependence; Conditional beliefs1. IntroductionThe capability of gathering information about the world and revising its beliefs based on the new informationis crucial for an intelligent agent. Belief revision therefore is a central topic in Artificial Intelligence. Technically,belief revision is the process of changing the beliefs of an agent to accommodate new, more precise, or more reliableevidence that is possibly inconsistent with the existing beliefs.The formal study of belief revision took as starting point the work of Alchourrón, Gärdenfors, and Makinson(AGM) during the first half of the 1980s [1–3]. The AGM framework studies idealized mathematical models of beliefrevision. Given an underlying logic language L, the beliefs of an agent are represented by a set of sentences in L(known as belief set) which is closed under logical consequence. New evidence is also a sentence in L, and a beliefrevision operator incorporates the new evidence into the current belief set to obtain a revised belief set. The authors ofthe original AGM framework have developed their theory under two basic assumptions regarding the new evidence:it is intended to describe facts of the static world; and it is more reliable (hence prioritized in the revision process)than the prior beliefs. The latter assumption is often referred to as primacy of update. The necessity and ideas ofdistinguishing belief revision from belief update (suitable for a situation where the new evidence describes a change✩ This article is a substantial extension of the conference paper [Y. Jin, M. Thielscher, Iterated belief revision, revised, in: Proceedings of theInternational Joint Conference on Artificial Intelligence (IJCAI), Edinburgh, Scotland, August 2005, pp. 478–483].* Corresponding author.E-mail addresses: yijin@inf.tu-dresden.de (Y. Jin), mit@inf.tu-dresden.de (M. Thielscher).1 The first author is funded by the Deutsche Forschungsgemeinschaft under grant no. Gr 334/3.0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.11.002\f2Y. Jin, M. Thielscher / Artificial Intelligence 171 (2007) 1–18of the world) was first noticed by Keller and Winslett [24] and later on formalized in [22]. Belief revision where thenew evidence is not prioritized, is a relatively recent topic studied by many researchers [5,10,12,18]. In this paper, wewill concentrate on the problem of prioritized belief revision where iterations are necessary.In situations where the new evidence is consistent with the existing beliefs, the two can just be merged; we call thismild revision. More interesting and complicated are situations where the evidence conflicts with the prior beliefs, inwhich case the agent needs to remove some of its currently held beliefs in order to accommodate the new evidence.This kind of revision is referred to as severe revision [13]. To provide general design criteria for belief revisionoperators, a set of postulates has been developed [3]. As first argued by the AGM trio and later frequently repeatedby others [9,13], the guiding principle of the AGM postulates is that of economy of information, or minimal changeof belief sets, which means not to give up currently held beliefs and not to generate new beliefs unless necessary.However, Rott [33,34] has recently pointed out that “it is a pure myth that minimal change principles are the foundationof existing theories of belief revision, at least as far as the AGM tradition is concerned”. His argument is mainly basedon the fact that so-called full meet revision [1] discards all prior beliefs in a severe revision and at the same timesatisfies all AGM postulates. This implies that the AGM postulates are too weak to capture the principle of minimalchange.For the incremental adaptation of beliefs, the AGM postulates proved to be overly weak, too [8,9]. This has led tothe development of additional postulates for iterated belief revision by Darwiche and Pearl (DP), among others (e.g.,[6,13,27]).Still, however, the AGM and DP postulates together are too permissive in that they support belief revision operatorswhich assume arbitrary dependencies among the pieces of information which an agent acquires along its way. Theseoperators have a drastic effect when the agent makes an observation which contradicts its currently held beliefs: Theagent is forced to cancel everything it has learned up to this point [28,30]. In this paper, we first give a formal analysisof this problem of implicit dependence, and then we present, as a solution, an Independence postulate for iterated beliefrevision. We give a representation theorem for our new postulate and prove its consistency by defining a concrete beliefrevision operator. We also contrast the Independence postulate to the so-called Recalcitrance postulate of [28,30] andargue that the latter is too strict in that it rejects reasonable belief revision operators.The rest of the paper is organized as follows. In the next section, we recall the classical AGM approach in apropositional setting as formulated by [23], followed by the approach of [8] for iterated belief revision. In Section 3,we formally analyze the problem of the DP postulates to be overly permissive. In Section 4, we present an additionalpostulate to overcome this deficiency, and we give a representation theorem for the postulate along with a concreterevision operator. We conclude in Section 5 with a detailed comparison to related work. Proofs of the main results canbe found in Appendix A.2. BackgroundIn this paper, we will deal with a propositional language L generated from a finite set P of atomic propositions.The language is that of classical propositional logic, i.e., with the classical consequence relation (cid:3). We say thattwo sentences α and β are logically equivalent, written as α ≡ β, iff α (cid:3) β and β (cid:3) α. As usual, a propositionalinterpretation (world) is a mapping from P to {(cid:5), ⊥}. The set of all interpretations is denoted by W. If an interpretationw truth-functionally maps a sentence μ to (cid:5), then w is called a model of μ (denoted by w |= μ). Given a sentence μ,we denote by Mods(μ) the set of all models of μ.A total pre-order (cid:2) (possibly indexed) is a reflexive, transitive binary relation s.t., either α (cid:2) β or β (cid:2) α holds forany α, β. The strict part of (cid:2) is denoted by <, that is, α < β iff α (cid:2) β and β (cid:7)(cid:2) α. As usual, α = β abbreviates α (cid:2) βand β (cid:2) α. Given any set S and total pre-order (cid:2), we denote by min(S, (cid:2)) the set of minimal elements of S wrt (cid:2).2.1. KM postulatesKatsuno and Mendelzon (KM) rephrased the AGM postulates for the propositional setting [23]. The beliefs of anagent are represented by a sentence ψ in L.2 Any new evidence is a sentence μ in L, and the result of revising ψ2 As L is assumed finite, any belief set can be represented as a sentence (modulo logical consequence). In this paper, we therefore do notdistinguish belief sets from sentences.\fY. Jin, M. Thielscher / Artificial Intelligence 171 (2007) 1–183with μ is also a sentence (denoted by ψ ∗ μ) which belongs to L. This is then the reformulation of the original AGMpostulates:(KM1) ψ ∗ μ (cid:3) μ.(KM2) If ψ ∧ μ is consistent, then ψ ∗ μ ≡ ψ ∧ μ.(KM3) If μ is consistent, then ψ ∗ μ is also consistent.(KM4) If ψ1 ≡ ψ2 and μ1 ≡ μ2, then ψ1 ∗ μ1 ≡ ψ2 ∗ μ2.(KM5) (ψ ∗ μ) ∧ φ (cid:3) ψ ∗ (μ ∧ φ).(KM6) If (ψ ∗ μ) ∧ φ is satisfiable, then ψ ∗ (μ ∧ φ) (cid:3) (ψ ∗ μ) ∧ φ.Readers are referred to [14] for the motivation and interpretation of these postulates.Katsuno and Mendelzon have given a representation theorem for Postulates (KM1)–(KM6) wrt a revision mecha-nism based on total pre-orders over possible world:Definition 1. A function that maps each belief set ψ to a total pre-order (cid:2)ψ on W is called a faithful assignment overbelief sets iff• If w1, w2 |= ψ , then w1 =ψ w2.• If w1 |= ψ and w2 (cid:7)|= ψ, then w1 <ψ w2.• If ψ ≡ φ, then (cid:2)ψ = (cid:2)φ.The intuitive meaning of w1 (cid:2)ψ w2 is that w1 is at least as plausible as w2 from the viewpoint of the agent whopossesses the belief set ψ. The total pre-order (cid:2)ψ is also called a faithful ranking wrt ψ.We particularly note that the last condition in Definition 1 says that faithful rankings of logically equivalent beliefsets must be identical. This essentially prohibits the possibility that in different situations the agent has the same beliefset but with different preferences among the beliefs.Theorem 1. [23] A revision operator ∗ satisfies Postulates (KM1)–(KM6) iff there exists a faithful assignment thatmaps a belief set ψ to a total pre-order (cid:2)ψ s.t.,Mods(ψ ∗ μ) = min(cid:2)Mods(μ), (cid:2)ψ(cid:3)Although the KM postulates were meant to be a reformulation of the AGM postulates for propositional logics,there is a",
            {
                "entities": [
                    [
                        69,
                        102,
                        "TITLE"
                    ],
                    [
                        2734,
                        2767,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 305 (2022) 103661Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintLMMS reloaded: Transformer-based sense embeddings for disambiguation and beyondDaniel Loureiro a,∗a LIAAD - INESC TEC, Dept. of Computer Science, FCUP, University of Porto, Portugalb School of Computer Science and Informatics, Cardiff University, United Kingdom, Alípio Mário Jorge a, Jose Camacho-Collados ba r t i c l e i n f oa b s t r a c tArticle history:Received 20 May 2021Received in revised form 20 December 2021Accepted 3 January 2022Available online 5 January 2022Keywords:Semantic representationsNeural language modelsDistributional semantics based on neural approaches is a cornerstone of Natural Language Processing, with surprising connections to human meaning representation as well. Recent Transformer-based Language Models have proven capable of producing contextual word representations that reliably convey sense-specific information, simply as a product of self-supervision. Prior work has shown that these contextual representations can be used to accurately represent large sense inventories as sense embeddings, to the extent that a distance-based solution to Word Sense Disambiguation (WSD) tasks outperforms models trained specifically for the task. Still, there remains much to understand on how to use these Neural Language Models (NLMs) to produce sense embeddings that can better harness each NLM’s meaning representation abilities. In this work we introduce a more principled approach to leverage information from all layers of NLMs, informed by a probing analysis on 14 NLM variants. We also emphasize the versatility of these sense embeddings in contrast to task-specific models, applying them on several sense-related tasks, besides WSD, while demonstrating improved performance using our proposed approach over prior work focused on sense embeddings. Finally, we discuss unexpected findings regarding layer and model performance variations, and potential applications for downstream tasks.© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionLexical ambiguity is prevalent across different languages and plays an important role in improving communication ef-ficiency [87]. Word Sense Disambiguation (WSD) is a long-standing challenge in the field of Natural Language Processing (NLP), and Artificial Intelligence more generally, with an extended history of research in computational linguistics [75].Interestingly, both computational and psychological accounts of meaning representation have converged on high-dimensional vectors within semantic spaces.From the computational perspective, there is a rich line of work on learning word embeddings based on statistical regularities from unlabeled corpora, following the well-established Distributional Hypothesis [41,35, DH]. The first type of distributional word representations relied on count-based methods, initially popularized by LSA [27], and later refined with GloVe [82]. Before GloVe, word embeddings learned with neural networks, first introduced by Bengio et al. [7], gained wide adoption with word2vec [72] and, afterwards, culminated with fastText [12]. The development and improvement of word embeddings has been a major contributor to the progress of NLP in the last decade [38].* Corresponding author.E-mail addresses: daniel.b.loureiro@inesctec.pt (D. Loureiro), amjorge@fc.up.pt (A. Mário Jorge), camachocolladosj@cardiff.ac.uk (J. Camacho-Collados).https://doi.org/10.1016/j.artint.2022.1036610004-3702/© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fD. Loureiro, A. Mário Jorge and J. Camacho-ColladosArtificial Intelligence 305 (2022) 103661From the psychological perspective, there is also ample behavioral evidence in support of distributional representations of word meaning. Similarly to word embeddings, these representations are related according to the degree of shared features within semantic spaces, which translates into proximity in vector-space [97,48]. Understandably, the nature of the features making up this psychological account of semantic space, among other aspects (e.g., learning method), is not as clear as we find in the computational account. Nevertheless, contextual co-occurrence is among the most informative factors for meaning representation as well [67,32,91]. There are even use cases in neurobiology motivating research into accurate dis-tributional representations of word meaning. In Pereira et al. [83], word embeddings have proven useful for decoding words and sentences from brain activity, after learning a mapping between corpus-based embeddings (i.e., GloVe and word2vec) and fMRI activation.The current understanding of how humans perform disambiguation attributes major relevance to sentential context, and other linguistic and paralinguistic cue’s (e.g., speaker accent) to a lesser extent [97,14]. However, the previously mentioned computational approaches are not designed for sense-level representation due to the Meaning Conflation Deficiency [15], as they converge different senses into the same word-level representation. Some works have explored variations on the word2vec method for sense-level embeddings [99,45,90,65], but the dynamic word-level interactions composing sentential context were not targeted by those works.The works of Melamud et al. [68], Yuan et al. [126], Peters et al. [84] were among the first to propose Neural Language Models (NLMs) featuring dynamic word embeddings conditioned on sentential context (i.e., contextual embeddings). These works showed that NLMs (trained exclusively on language modeling objectives) can produce contextual embeddings for word forms that are sensitive to the word’s usage in particular sentences. Furthermore, these works also addressed WSD tasks with a simple nearest neighbors solution (k-NN) based on proximity between contextual embeddings. Their results rivaled systems trained specifically for WSD (i.e., with additional modeling objectives), highlighting the accuracy of these contextual embeddings.However, it was not until the development of Transformer-based NLMs, namely BERT [29], that contextual embeddings from NLMs showed clearly better performance on WSD tasks than previous systems trained specifically for WSD (LMMS, Loureiro & Jorge [61]).In this earlier work, we explored how to further take advantage of the representational power of NLMs through propa-gation strategies and encoding sense definitions. Besides pushing the state-of-the-art of WSD, in Loureiro & Jorge [61] we created sense embeddings for every entry in the Princeton WordNet v3.0 (200k word senses, [34]), so that the semantic space being represented is granular and expansive enough to encompass general knowledge domains for various parts-of-speech of the English language. With this fully populated semantic space at our disposal we suggested strategies for uncovering biases and world knowledge represented by NLMs.Since our work on LMMS, others have shown additional performance gains for WSD with fine-tuning or classification approaches that make better usage of sense definitions [44,11], semantic relations from external resources [104,9], or alto-gether different approaches to WSD [5].However, there are several questions still standing regarding how to leverage NLMs for creating accurate and versatile sense embeddings, beyond optimizing for WSD benchmarks only. Given that semantic spaces with distributional represen-tations of word meanings feature prominently in both the conventional computational and psychological accounts of word disambiguation, these questions warrant further exploration.Contributions. In this extension of LMMS, we broaden our scope to more recent Transformer-based models in addition to BERT [124,59,52] (14 model variants in total), verify whether they exhibit similar proficiency at sense representation, and explore how performance variation can be attributed to particular differences in these models. Striving for a principled approach to sense representation with NLMs, we also introduce a new layer pooling method, inspired by recent findings of layer specialization [95], which we show is crucial to effectively use these new NLMs for sense representation. Most importantly, in this article we provide a general framework for learning sense embeddings with Transformers and perform an extensive evaluation of such sense embeddings from different NLMs on various sense-related tasks, emphasizing the versatility of these representations.Outline. This work is organized as follows. We first provide some background information on the main topics of this re-search: Vector Semantics (§2.1), Neural Language Modeling (§2.2) and Sense Inventories (§2.3). Next, we describe related work on Sense Embeddings (§3.1), WSD (§3.2) and Probing NLMs (§3.3).The method used to produce this work’s sense embeddings is described in Section 4, covering aspects of the method introduced in Loureiro & Jorge [61] (from §4.1 to §4.3), as well as our new layer pooling method in Section 4.4.In Section 5 we describe our experimental setting, providing relevant details about our choice of NLMs (§5.1) and anno-tated corpora used to learn sense embeddings (§5.2).The layer pooling methodology described in Section 4.4 requires validating performance under two distinct modes of ap-plication. Consequently, in Section 6 we report on performance variation per layer across NLMs (§6.1), highlight differences between disambiguation and matching profiles (§6.2), and present the rationale for choosing particular profiles for each task (§6.3).In Section 7, we tackle several sense-related tasks using our proposed sense embeddings and compare results against the state-of-the-art, namely: WSD (§7.1), Uninformed Sense Matching (§7",
            {
                "entities": [
                    [
                        135,
                        214,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 76 (1995) 455-480 Artificial Intelligence Backtracking techniques for the job shop scheduling constraint satisfaction problem* Norman Sadeh*, Katia Sycara, Yalin Xiong 5000 Forbes Avenue, The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213-3891, USA Received June 1993; revised May 1994 Abstract This paper studies a version of the job shop scheduling problem in which some start that improve time windows ordering heuristics In this paper, we combine techniques and variable/value time windows). This problem (CSP). A popular method for solving this type of problems that cannot be completed without violating some constraints). (i.e. earliest/latest operations have to be scheduled within non-relaxable is a well-known NP-complete Constraint possible Satisfaction Problem involves using depth-first backtrack search. In our earlier work, we focused on the development of consistency enforcing the these techniques with new efficiency of this search procedure. look-back schemes that help the search procedure recover from so-called deadend search states (i.e. partial solutions (1) More specifically, we successively describe and de- Dynamic Consistency Enforcement termines how far to backtrack by selectively enforcing higher levels of consistency among (2) Learning Ordering From Failure variables participating dynamically modifies based on earlier conflicts, and (3) Zncomplete Backjumping Heuristic abandons areas of the search space efforts. These schemes are shown to (1) that appear further (2) enable our that could not be solved otherwise due to excessive system to efficiently solve problems computation than other look-back schemes advocated cost, and (3) be more effective at solving job shop scheduling problems in these critical subproblems, the order the average complexity of the backtrack search procedure, to require excessive computational identifies critical subproblems in which variables three “intelligent” in the literature. backtracking dynamically instantiated schemes: reduce are l This research was supported, in part, by the Defense Advanced Research Projects Agency under contract #F30602-91-F-0016, and in part by grants from McDonnell Aircraft Company and Digital Equipment Corporation * Corresponding author. 0004-3702/95/$09.50 SSDZ 0004-3702(95)00078-6 0 1995 Elsevier Science B.V. All rights reserved \f456 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 1. Introduction This paper is concerned with the design of recovery schemes for incremental scheduling approaches sions in order to complete that sometimes require undoing earlier scheduling deci- the construction of a feasible schedule. that have for operations (e.g. earliest possible start to be scheduled within non-relaxable Job shop scheduling deals with the allocation of resources over time to perform a collection of tasks. The job shop scheduling model studied in this paper further allows time possible finish time windows). windows is a well-known NP-complete Constraint Satisfaction Problem This problem (CSP) in which some operations shifts, in which time windows are determined by spacecraft mission scheduling problems, astronomical rescheduling prob- lems, in which a small set of operations need to be rescheduled without revising the schedule of other operations, to be performed within one or several events over which we have no control, include factory scheduling problems, Instances of this problem time/latest factory have [lo]. etc. through One approach this approach, assignment of a reservation scheduling problems can be solved to solving CSPs is to use depth-first backtrack search [2,12,26]. the iterative Using to be scheduled next (i.e. variable selection) and the selection of an operation If in the tentative that cannot be is reached process of constructing a schedule, a partial solution completed without violating some of the problem constraints, one or several earlier assignments need to be undone. This process of undoing earlier assign- ments is referred the efficiency of the search to come up with a solution. While the procedure and increases the time required worst-case complexity of backtrack search to several is exponential, reduce its average-case complexity have been proposed techniques [6]: to as backtracking. to that operation. in the literature It deteriorates (i.e. value) in search time. techniques prune in a global solution that cannot participate the amount of consistency enforced the search space is [16]. There in each Consistency- enforcing schemes: These from alternatives generally a tradeoff between search state’ and the savings achieved Variable/value ordering heuristics: These heuristics help judiciously decide to instantiate next and which value to assign to that variable which variable [2, 6, 8, 13, 17, 181. By first instantiating difficult variables, the system increases the current partial solution without backtracking [S, 13, 181. Good value ordering heuristics reduce backtracking by selecting values solutions Look-buck enforcing average, very effective at reducing backtracking, While it is possible to design consistency that are, on to impossible [4,7,11,24]: and variable/value heuristics it is generally its chances of completing in a large number of that are expected schemes schemes to participate ordering [6,18]. 1 A search state is associated with each partial solution. Each search state defines a new CSP whose variables are the variables that have not yet been instantiated and whose constraints are the initial problem constraints along with constraints reflecting current assignments. \fN. Sadeh et al. I Artijicial Intelligence 76 (1995) 455-480 457 efficiently guarantee backtrack-free to help the system recover from deadend states and, if possible, past mistakes. search. Look-back schemes are designed learn from earlier work, we focused on the development techniques and variable/value of efficient consistency In our enforcing ordering heuristics for job shop schedul- ing CSPs [8, 18, 20-23, 251. In this paper, we combine these techniques with new look-back the average complexity of the search procedure. They also enable our system to efficiently that could not be efficiently solved otherwise. Finally, experimen- solve problems tal results that these techniques are more effective at solving job shop scheduling problems schemes. These schemes are shown than other to further indicate reduce look-back schemes advocated to strategy goes back in the literature. the most to The search values is said recovery states. When simplest deadend the variable. This strategy the source of the current deadend recently instantiated variable with at least one alternative value left, and assigns one of the is known as chronological remaining backtracking. Often is not the most recent assignment but an earlier one. Because it typically modifies assignments that have to no impact on the conflict at hand, chronological backtracking often returns to be thrashing. similar deadend this happens, Thrashing can be reduced using backjumping schemes that attempt to backtrack all the way to one of the variables at the source of the conflict [ll]. Search efficiency can be further improved by learning from past mistakes. For instance, a system can record earlier conflicts in the form of new constraints it from repeating earlier mistakes [7,24]. Dependency-directed technique though dependency-directed search states that need to be explored, exponential worst-case complexity of its constraint recording component time and space). Simpler techniques have also been developed the dependency-directed amount of book-keeping required by full-blown backjumping by assuming that any two variables directly connected by a constraint may have been assigned conflicting values [4].* Nth-order deep and shallow learning reduce the constraint by only recording complexity of dependency-directed recording conflicts involving N or fewer variables [4]. is a [24]. Al- the number of reduce this scheme is often impractical due to the (both in that will prevent backtracking that approximate reduces and constraint can greatly both backjumping backtracking. incorporating backtracking backtracking Graph-bused backjumping recording Graph-bused backjumping works best on CSPs with sparse constraint graphs [4]. Instead, constraint job shop scheduling problems have highly interconnected graphs. Furthermore graph-based backjumping does not increase search efficiency when used in combination with forward checking [13] mechanisms or stronger consistency enforcing mechanisms such as those entailed by job shop scheduling [18]. Our experiments suggest that Nth-order deep and shallow learning problems techniques to job shop these techniques use constraint size as the scheduling problems. This is because search efficiency when applied fail to improve often * Two variables are said to be “connected” by a constraint if they both participate in that constraint. \f458 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 to decide whether or not record earlier failures. When they limit to small-size conflicts, they fail to record some important constraints. only criterion themselves When they do not, their complexities become prohibitive. techniques that have yielded good three look-back Instead, this paper presents results on job shop scheduling problems: (1) Dynamic Consistency Enforcement (DCE): a selective dependency-directed scheme that dynamically focuses its effort on critical resource subproblems; (2) Learning Ordering From Failure (LOFF): an adaptive scheme that suggests new variable orderings based on earlier conflicts; (3) Incomplete Backjumping Heuristic (IBH): a scheme that gives up searching areas of the search space that require in scheduling includes Related work Nth-order that of Badie et al. whose system learning which a minimum set is heuristically selected as the source of the conflict [l]. implements a variation of deep",
            {
                "entities": [
                    [
                        66,
                        149,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 202 (2013) 52–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPOMDP-based control of workflows for crowdsourcingPeng Dai∗, Christopher H. Lin, Mausam, Daniel S. WeldDepartment of Computer Science and Engineering, University of Washington, Seattle, WA 98195, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Received 20 December 2011Received in revised form 8 June 2013Accepted 9 June 2013Available online 20 June 2013Keywords:Partially-Observable Markov DecisionProcessPOMDPPlanning under uncertaintyCrowdsourcing1. IntroductionCrowdsourcing, outsourcing of tasks to a crowd of unknown people (“workers”) in anopen call, is rapidly rising in popularity. It is already being heavily used by numerousemployers (“requesters”) for solving a wide variety of tasks, such as audio transcription,content screening, and labeling training data for machine learning. However, quality controlof such tasks continues to be a key challenge because of the high variability in workerquality. In this paper we show the value of decision-theoretic techniques for the problemof optimizing workflows used in crowdsourcing. In particular, we design AI agents that useBayesian network learning and inference in combination with Partially-Observable MarkovDecision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs.We use these techniques for three distinct crowdsourcing scenarios: (1) control of votingto answer a binary-choice question, (2) control of an iterative improvement workflow,and (3) control of switching between alternate workflows for a task. In each scenario,we design a Bayes net model that relates worker competency, task difficulty and workerresponse quality. We also design a POMDP for each task, whose solution provides thedynamic control policy. We demonstrate the usefulness of our models and agents in liveexperiments on Amazon Mechanical Turk. We consistently achieve superior quality resultsthan non-adaptive controllers, while incurring equal or less cost.© 2013 Elsevier B.V. All rights reserved.The ready availability of the Internet across the world has had far-reaching consequences. Not only has widespread onlineconnectivity revolutionized communication, politics, entertainment, and other aspects of everyday life, it has enabled theability to easily unite large groups of people around the world (a crowd) for a common purpose. This ability to crowdsourcehas in turn opened up radical new possibilities and resulted in novel successes, like Wikipedia1 – a whole encyclopediawritten by the crowd, and platforms that are rapidly impacting the world’s laborforce by bringing them together in onlinemarketplaces that provide work on-demand.We believe that Crowdsourcing, “the act of taking tasks traditionally performed by an employee or contractor, and out-sourcing them to a group (crowd) of people or community in the form of an open call,”2 has the potential to revolutionizeinformation-processing services by coupling human workers with intelligent machines in productive workflows [21].* Corresponding author. Current affiliation: Google Inc., 1600 Amphitheater Pkwy, Mountain View, CA 94043.E-mail addresses: daipeng@cs.washington.edu (P. Dai), chrislin@cs.washington.edu (C.H. Lin), mausam@cs.washington.edu (Mausam),weld@cs.washington.edu (D.S. Weld).1 http://en.wikipedia.org.2 http://en.wikipedia.org/wiki/Crowdsourcing.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.06.002\fP. Dai et al. / Artificial Intelligence 202 (2013) 52–8553Fig. 1. A handwriting recognition task (almost) successfully solved on Mechanical Turk using an iterative-improvement workflow. Workers were shown thetext written by a human and in a few iterations they deduced the message (with minimal errors highlighted). Figure adapted from [37].While the word “crowdsourcing” was only coined in 2006, the area has grown rapidly in economic significance with theemergence of general-purpose platforms such as Amazon’s Mechanical Turk,3 task-specific sites for call centers,4 program-ming jobs5 and more [37,4,7,33,24].Crowdsourced workers are motivated by a variety of incentives. Common incentives include entertainment, e.g., in thecontext of playing games with a purpose [63,10], contribution to science,6 a sense of community, and monetary rewards.While our work is applicable to several crowdsourcing scenarios, we focus on financially motivated micro-crowdsourcing –crowdsourcing of small jobs in exchange for monetary payments. Labor markets, like oDesk, handle medium and large-sizedtasks requiring a diverse range of skills and micro-crowdsourcing has become very popular with requesters, who use aconcert of small-sized jobs to handle a wide variety of higher-level tasks, such as audio transcription, language translation,calorie counting [42], and helping blind people navigate unknown surroundings [7]. It has also been immensely popularwith workers in both developed and developing countries [49].On popular micro-crowdsourcing platforms, like Mechanical Turk, requesters often use workflows, a series of steps, tocomplete tasks. For instance, for a simple image classification task (e.g. “Is there a lion in this picture?”), a workflow assimple as asking several workers the same binary-choice question will suffice. For a more difficult task like the handwritingrecognition task shown in Fig. 1, a requester might create a more complicated workflow like iterative improvement, in whichworkers incrementally refine each others’ solutions until no further improvement is necessary [37]. A plethora of researchshows that for simple binary classification workflows, micro-crowdsourcing can achieve high-quality results [58,60]. Simi-larly, iterative improvement, find–fix–verify [3] and other workflows have been shown to yield excellent output even whenindividual workers err.But the use of these workflows raises many important questions. For example, when designing a workflow to handleproblems like the handwriting recognition task shown in Fig. 1, we do not know answers to questions like: (1) What is theoptimal number of iterations for such a task? (2) How many ballots should be used for voting? (3) How do these answerschange depending on workers’ skill levels?Our paper offers answers to these questions by constructing AI agents for workflow optimization and control. We studythree distinct crowdsourcing scenarios. We start by considering the problem of dynamically controlling the aggregation ofthe simplest possible workflow: binary classification. Next, we extend our model to control the significantly more complexiterative improvement workflow. Finally, we show how our model can be used to dynamically switch between alternativeworkflows for a given task.We use a shared toolbox of techniques on each of these crowdsourcing scenarios; there are two key components. First, wepropose a probabilistic model for worker responses. This model relates worker ability, task difficulty and worker responsequality by means of a Bayesian network. Second, we view the problem of workflow control as a problem of decision-theoretic planning and execution, and cast it as a Partially-Observable Markov Decision Process (POMDP) [6]. The Bayesnet provides the model for the POMDP, and the POMDP policy controls the workflow to obtain a high-quality output in acost-efficient manner.We make several important contributions. First, we provide a principled solution to dynamically decide the numberof votes for a task based on the exact history of workers who worked on a task instance, their answers and a notion of3 http://mturk.com.4 http://liveops.com.5 http://topcoder.com.6 http://galaxyzoo.org, Audubon Christmas Bird Count, etc.\f54P. Dai et al. / Artificial Intelligence 202 (2013) 52–85varying problem difficulty. We also provide a framework for answering more complex questions in larger workflows (e.g. thenumber of iterations in an iterative improvement workflow). The commonality of approaches in these diverse tasks suggestsan underlying abstraction, which may be exploited for optimizing and controlling many different kinds of workflows. Ourexperiments consistently outperform best known baselines by large margins, e.g., obtaining 50% error reduction in thescenario of multiple workflows, or 30% cost savings for iterative improvement.Moreover, our work reveals some surprising discoveries. First, for the iterative improvement scenario, our AI agentproposes a rather unexpected voting policy, which was not predicted by any human expert (see Section 4). Second, wedemonstrate that judiciously using alternative workflows for a task is much better than using a single “best” workflow.While the base idea is not novel, the fact that we can do this dynamic switching between workflows automatically toobtain high-quality results is a surprising discovery.The rest of the paper is structured as follows. Section 2 formally defines Markov Decision Processes and Partially-Observable Markov Decision Processes (POMDP). Then we review and propose planning algorithms for solving POMDPs.Section 3 details how we model and control the aggregation of a simple binary classification workflow using our firstagent, TurKontrol0. Section 4 extends our model and agent to iterative improvement workflows to create our secondagent, TurKontrol. We present some simulation-based investigation of the performance of TurKontrol, illustrate howto learn the model parameters, and finally demonstrate the usefulness of TurKontrol on Mechanical Turk, with realtasks. Section 5 details how we model the availability of multiple workflows and the design of our third agent, Agen-tHunt, which dynamically selects the next best workflow to use. We illustrate how to learn model parameters and thendemonstrate the usefulness of AgentHunt in simulation and on Mechanical Turk. Finally, we present related work, proposefuture work, and m",
            {
                "entities": [
                    [
                        143,
                        193,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 186 (2012) 157–173Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAugmenting tractable fragments of abstract argumentation ✩,✩✩Wolfgang Dvoˇrák, Sebastian Ordyniak, Stefan Szeider∗Institute of Information Systems, Vienna University of Technology, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 19 August 2011Received in revised form 12 January 2012Accepted 7 March 2012Available online 8 March 2012Keywords:Abstract argumentationBackdoorsComputational complexityParameterized complexityFixed-parameter tractability1. IntroductionWe present a new approach to the efficient solution of important computational problemsthat arise in the context of abstract argumentation. Our approach makes known algorithmsdefined for restricted fragments generally applicable, at a computational cost that scaleswith the distance from the fragment. Thus, in a certain sense, we gradually augmenttractable fragments. Surprisingly, it turns out that some tractable fragments admit suchan augmentation and that others do not.More specifically, we show that the problems of Credulous and Skeptical Acceptance arefixed-parameter tractable when parameterized by the distance from the fragment of acyclicargumentation frameworks—for most semantics. Other tractable fragments such as thefragments of symmetrical and bipartite frameworks seem to prohibit an augmentation:the acceptance problems are already intractable for frameworks at distance 1 from thefragments.For our study we use a broad setting and consider several different semantics. For thealgorithmic results we utilize recent advances in fixed-parameter tractability.© 2012 Elsevier B.V. All rights reserved.The study of arguments as abstract entities and their interaction in form of attacks as introduced by Dung [13] hasbecome one of the most active research branches within Artificial Intelligence, Logic and Reasoning [3,4,35]. Argumentationhandles possible conflicts between arguments in form of attacks. Arguments may either originate from a dialogue betweenseveral agents or from the pieces of information available to a single agent, this information may even contain contradic-tions. A main issue for any argumentation system is the selection of acceptable sets of arguments, called extensions, wherean acceptable set of arguments must be in some sense coherent and be able to defend itself against all attacking argu-ments. Abstract argumentation provides suitable concepts and formalisms to study, represent, and process various reasoningproblems most prominently in defeasible reasoning (see, e.g., [5,34]) and agent interaction (see, e.g., [33]).Unfortunately, important computational problems such as determining whether an argument belongs to some extension(Credulous Acceptance) or to all extensions (Skeptical Acceptance), are intractable (see, e.g., [11,16]). In order to solve theseproblems on medium or large-sized real world instances, it is significant to identify efficient algorithms. However, a fewtractable fragments are known where the acceptance problems can be efficiently solved: the fragments of acyclic [13],symmetric [10], bipartite [14], and—for most semantics—noeven [16] argumentation frameworks.✩Ordyniak and Szeider’s research has been funded by the European Research Council, grant reference 239962 (COMPLEX REASON). Dvoˇrák’s research hasbeen funded by the Vienna Science and Technology Fund (WWTF) through project ICT08-028.✩✩A preliminary and shortened version of this paper appeared in IJCAI 2011.* Corresponding author.E-mail address: stefan@szeider.net (S. Szeider).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.03.002\f158W. Dvoˇrák et al. / Artificial Intelligence 186 (2012) 157–173Table 1Complexity of acceptance problems, parameterized by the distance from a fragment.FragmentAcycNoevenBipSymadmCAFPTXPhardhardcomCAFPTXPhardhardprfCA/SAFPTXPhardhardsemCA/SAFPTXPhardhardstbCA/SAFPTXPhardhardstgCA/SAhardhardhardhardIt seems unlikely that an argumentation framework originating from a real-world application belongs to one of theknown tractable fragments, but it might be “close” to a tractable fragment.In this paper we study the natural and significant question of whether we can solve the relevant problems efficiently forargumentation frameworks that are of small distance to a tractable fragment. As the distance we take the smallest number ofarguments that must be deleted to put the framework into the tractable fragment under consideration. One would certainlyhave to pay some extra computational cost that increases with the distance from the tractable fragment, but ideally thisextra cost should scale gradually with the distance. To get a broad picture of the complexity landscape we take severalpopular semantics into consideration, namely the semantics introduced by Dung [13], i.e., admissible, complete, preferred,and stable semantics, and further semi-stable [6,7,40], and stage [40] semantics (see [2] for a survey). Our approach isinspired by the notion of “backdoors” which originates from the area of propositional satisfiability (see, e.g., [28,39,42]),and has been successfully used in other problem areas, including quantified Boolean formulas and nonmonotonic reasoning[24,38].Results. On the positive side we show that for all the considered semantics, except for stage semantics, the fragments ofacyclic and noeven argumentation frameworks admit an augmentation. In particular, we show that we can solve Credulousand Skeptical Acceptance in polynomial time for argumentation frameworks that are of bounded distance from either ofthe two fragments. We further show that with respect to the acyclic fragment, the order of the polynomial time boundis independent of the distance, which means that both acceptance problems are fixed-parameter tractable (see [12]) whenparameterized by the distance from the acyclic fragment. To obtain these results we introduce the new notion of partiallabelings of argumentation frameworks and apply recent results from fixed-parameter theory. We use partial labelings tocapture and propagate the acceptance state of certain key arguments (forming a backdoor) of the argumentation framework.On the negative side, we show that the fragments of bipartite and symmetric argumentation frameworks do not admitan augmentation. In particular, we show that the problems Credulous and Skeptical Acceptance are already intractable forargumentation frameworks at distance 1 from either of the two fragments. We also show that the acyclic and noevenfragments do not admit an augmentation with respect to the stage semantics, in contrast to the other five consideredsemantics. In particular, we show that the acceptability problems for the stage semantics are already intractable for noevenargumentation frameworks, and for argumentation frameworks at distance 1 from the acyclic fragment.To put our tractability results into context, we compare the parameters “distance to the acyclic fragment” and “distanceto the noeven fragment” with other parameters that, if bounded, make acceptance problems tractable. We show that ourdistance-based parameters are incomparable with the previously considered parameters treewidth and clique-width [14,23].Hence our augmentation approach provides an efficient solution for instances that are hard for other known methods.Table 1 summarizes our results for the different semantics and fragments. The table can be read as follows: A columnmarked CA concerns Credulous Acceptance, and a column marked CA/SA concerns both Credulous and Skeptical Acceptance,each with respect to a particular semantics as indicated. For the admissible and complete semantics we omit SkepticalAcceptance because the corresponding problems are already tractable for arbitrary frameworks [10,13]. An entry “XP”means that acceptance can be decided in polynomial time for argumentation frameworks whose distance to the fragmentis bounded by a constant (the order of the polynomial may depend on the distance); an entry “FPT” means that the accep-tance problem is fixed-parameter tractable, parameterized by the distance from the fragment; an entry “hard” means thatCredulous or Skeptical Acceptance are at least NP-hard or coNP-hard, respectively, even for instances of distance 1 from thefragment.The reminder of the paper is organized as follows. In Section 2 we provide basic definitions and preliminaries. In Sec-tion 3 we introduce the important concept of partial labelings that will be an important tool to obtain our tractabilityresults. In Section 4 we give efficient algorithms for the augmentation of the acyclic and noeven fragments. In Section 5 weestablish intractability for the bipartite and symmetric fragments. In Section 6 we strengthen the tractability results fromSection 4 with the help of strong backdoors. In Section 7 we compare our newly found parameters with already knownstructural parameters such as treewidth and clique-width. We close in Section 8 with concluding remarks. Some proofs oftechnical lemmas and theorems are given in Appendix A.2. PreliminariesAn abstract argumentation system or argumentation framework (AF, for short) is a pair ( X, A) where X is a (possiblyinfinite) set of elements called arguments and A ⊆ X × X is a binary relation called attack relation. In this paper we will\fW. Dvoˇrák et al. / Artificial Intelligence 186 (2012) 157–173159Fig. 1. Left: the AF F from Example 1. Right: indicated in gray the only non-empty complete extension of F .restrict ourselves to finite AFs, i.e., to AFs for which X is a finite set. If (x, y) ∈ A we say that x attacks y and that x is anattacker of y.An AF F = ( X, A) can be considered as a directed graph, and therefore it is convenient to borrow notions and notationfrom graph theory. For a set of arguments Y ⊆ X we denote by F [Y ] the AF (Y , {(x, y) ∈ A | x, y ∈ Y }) and by F − Y the AFF [ X \\ Y ].Example",
            {
                "entities": [
                    [
                        145,
                        201,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 935–981Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDialogue games that agents play within a societyNishan C. Karunatillake a,∗, Nicholas R. Jennings a, Iyad Rahwan b,c, Peter McBurney da School of Electronics and Computer Science, University of Southampton, SO17 1BJ, United Kingdomb (Fellow) School of Informatics, University of Edinburgh, Edinburgh, EH8 9LE, United Kingdomc Faculty of Informatics, The British University in Dubai, PO Box 502216 Dubai, United Arab Emiratesd Department of Computer Science, University of Liverpool, Liverpool, L69 7ZF, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 21 December 2007Received in revised form 19 January 2009Accepted 3 February 2009Available online 21 February 2009Keywords:Dialogue game protocolsMulti-agent negotiationSocial conflict resolutionArgument schemesHuman societies have long used the capability of argumentation and dialogue to overcomeand resolve conflicts that may arise within their communities. Today, there is an increasinglevel of interest in the application of such dialogue games within artificial agent societies.In particular, within the field of multi-agent systems, this theory of argumentation anddialogue games has become instrumental in designing rich interaction protocols and inproviding agents with a means to manage and resolve conflicts. However, to date, much ofthe existing literature focuses on formulating theoretically sound and complete models formulti-agent systems. Nonetheless, in so doing, it has tended to overlook the computationalimplications of applying such models in agent societies, especially ones with complexsocial structures. Furthermore, the systemic impact of using argumentation in multi-agent societies and its interplay with other forms of social influences (such as those thatemanate from the roles and relationships of a society) within such contexts has alsoreceived comparatively little attention. To this end, this paper presents a significant steptowards bridging these gaps for one of the most important dialogue game types; namelyargumentation-based negotiation (ABN). The contributions are three fold. First, we presenta both theoretically grounded and computationally tractable ABN framework that allowsagents to argue, negotiate, and resolve conflicts relating to their social influences within amulti-agent society. In particular, the model encapsulates four fundamental elements: (i) ascheme that captures the stereotypical pattern of reasoning about rights and obligationsin an agent society, (ii) a mechanism to use this scheme to systematically identify socialarguments to use in such contexts, (iii) a language and a protocol to govern the agentinteractions, and (iv) a set of decision functions to enable agents to participate in suchdialogues. Second, we use this framework to devise a series of concrete algorithms that giveagents a set of ABN strategies to argue and resolve conflicts in a multi-agent task allocationscenario. In so doing, we exemplify the versatility of our framework and its ability tofacilitate complex argumentation dialogues within artificial agent societies. Finally, we carryout a series of experiments to identify how and when argumentation can be useful foragent societies. In particular, our results show: a clear inverse correlation between thebenefit of arguing and the resources available within the context; that when agents operatewith imperfect knowledge, an arguing approach allows them to perform more effectivelythan a non-arguing one; that arguing earlier in an ABN interaction presents a more efficientmethod than arguing later in the interaction; and that allowing agents to negotiate theirsocial influences presents both an effective and an efficient method that enhances theirperformance within a society.© 2009 Elsevier B.V. All rights reserved.* Corresponding author.E-mail addresses: nnc@ecs.soton.ac.uk (N.C. Karunatillake), nrj@ecs.soton.ac.uk (N.R. Jennings), irahwan@acm.org (I. Rahwan), mcburney@liverpool.ac.uk(P. McBurney).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.02.002\f936N.C. Karunatillake et al. / Artificial Intelligence 173 (2009) 935–9811. IntroductionAutonomous agents usually exist within a multi-agent community, performing actions within a shared social contextto achieve their individual and collective objectives [81]. In such situations, the actions of these individual agents are in-fluenced via two broad forms of motivations. First, the internal influences reflect the intrinsic motivations that drive theindividual agent to achieve its own internal objectives. Second, as agents reside and operate within a social community, thesocial context itself influences their actions. For instance, when agents function within a society that has an organisationalstructure, they may assume certain specific roles or be part of certain relationships. These, in turn, may influence the actionsthat an agent may perform. Here, we categorise such external forms of motivations as social influences.Now, in many cases, both these forms of influence are present and they may give conflicting motivations to the individualagent. For instance, an agent may be internally motivated to perform a specific action. However, at the same time, it mayalso be subject to an external social influence (via the role it is assuming or the relationship that it is part of) not todo so. To illustrate this more clearly, let us consider an example relationship that exists between the two roles supervisorand student.1 Assume that, as a result of this supervisor-student relationship, any agent who assumes the role of studentis socially influenced to produce and hand over his thesis to his supervisor in a timely manner. Therefore, if an agentnamed Andy assumes the role of the student and another named Ben assumes the role of his supervisor, Andy will besocially influenced by Ben to hand over the thesis in time. However, if Andy also has a certain internal motivation to usethat limited time on some other activity (i.e., finish some programming work), a conflict will arise between Andy’s socialinfluence and his internal influence. In such a case, if Andy decides to pursue his internal motivation at the expense ofhis social influence, this may, in turn, manifest itself as a conflict between the two agents since Ben may well have aninterest in Andy abiding by his social influence and hand over his thesis in time. Also an agent may face situations wheredifferent social influences motivate it in a contradictory manner (one to perform a specific action and the other a differentconflicting action). For instance, if Andy is also part of a project, his project manager (Cindy) may socially influence Andyto use his time integrating some software component. Similar to above, in such an event, if the agent decides to abide by acertain social influence and forgo the other, it may also lead to a conflict between that agent and the agent that exerts theneglected social influence.In addition to such disparate motivations, due to the complexity and dynamism usually present within multi-agent sys-tems, in many cases, agents have to carry out their actions with imperfect knowledge about their environment. Specifically,when agents operate within a social context, they may not have complete knowledge about the capabilities, roles, or rela-tionships that they and their counterparts are deemed to assume within the society. Thus, in such instances, an agent maynot be aware of the existence of all the social influences that could or indeed should affect its actions. For instance, Andymay not be aware that Cindy was appointed as the new project manager. Thus, he may not believe that he is required toperform any integration work that Cindy may demand of him. Moreover, agents may also lack the knowledge of certainspecific social and internal influences that motivate other agents’ actions within the community. For instance, Andy may notbe aware of the fact that the university will incur a large penalty if the project integration is not completed in time. Thus,due to the absence of this knowledge, he may chose to write his thesis believing it is more important than the integrationwork. As can be seen, therefore, the lack of knowledge about social influences can also lead to conflicts between agents.From the above discussion, it can be seen that when agents operate in a society with incomplete information and withdiverse and conflicting influences, they may, in certain instances, lack the knowledge, the motivation and/or the capacityto abide by all their social influences. However, to function as a coherent society it is important for these agents to havea means to resolve such conflicts, manage their internal and social influences, and, thus, come to a mutual understandingabout their actions.In searching for a solution to this problem, we observe that when individuals operate within a human society, theyencounter similar forms of conflicts in their day to day life. For instance, when carrying out their actions humans encounterinfluences from different elements within the society, some of which are in conflict with one another. Furthermore, theyalso perform their actions in the presence of incomplete information about their social context. Thus, they also face conflictsdue to their lack of knowledge about certain influences within the society. However, mainly due to their skill in language,dialogue, and debate, human beings have adapted to use different forms of complex interactions to manage and resolve suchconflicts. To this end, researchers and philosophers from different branches of AI, linguistics, dialogue theory, and logic havelong been inspired by this human social ability and have tried to capture and model such behaviour [53,75]. Such studieshave given birth to a number of different dialogue models [80]",
            {
                "entities": [
                    [
                        136,
                        184,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 85 ( 1996) 3-44 Artificial Intelligence A systematic methodology for cognitive modelling R. Cooper a,*, J. Fox b, J. Farringdon”, T. ShalliceC a Department of Psychology, Birkbeck College, Malet Street. London, UK WC 1E 7HX h Advanced Computation Laboratory, Imperial Cancer Research Fund, London, UK ’ Department of Psychology, University College London, London, UK Received January 1995; revised August 1995 Abstract implementation The development is typically ad hoc: theories would be considerably justified mechanisms with pragmatic principles guide the process. Consequently and testing of computational models of cognition few computational mod- details, and aspects of theories are frequently hard to identify. We argue that attempts assisted by the availability of appropriate for specifying cognitive models. Such languages should: ( 1) be syntactically clear and (3) be executable; and (4) explicitly support the divi- (2) be operationally well defined; detail. In support of our arguments we introduce Sceptic, theory and implementation these requirements. specification generally agreed methodological els often conflate empirically essential theoretical to construct cognitive languages succinct; sion between an executable including Soar, Sceptic has been successfully in a technical appendix. The sim- and details of the Sceptic specification to be seen, and plicity of Sceptic Soar permits three aids investigation of alternative computational to the functioning of working memory within Soar. Although our focus is on Soar, the thrust of the work is more concerned with general methodological the essentials of the underlying cognitive assumptions. We demonstrate theoretical language which goes some way towards satisfying theory this by reporting issues in cognitive modelling. a number of cognitive models involving modifications of Soar are included used to implement experiments 1. Introduction The natural complexity considerable methodological of experimental design and data analysis. Notwithstanding psychology cognitive and variability of ordinary human behaviour creates a need for students experimental research. Consequently, are routinely sophistication in cognitive in rigorous trained the many ambiguities of cognitive theory, the * Corresponding author. E-mail: r.cooper@psyc.bbk.ac.uk. QOO4-3702/96/$15.00 SSDIOOO4-3702(95)00112-3 Copyright @ 1996 Elsevier Science B.V. All rights reserved. \fresearch arc judged are public and largely uncontroversial. side the situation is informal. Theories are often presented criteria by which experimental On the theoretical psychology (see, e.g., [ 3.29.421 1, or draw on natural box-arrow notation and its underlyin g assumptions it has been argued that “attractive metaphors [ 39. p. 4021. This informal approach restricts statements. is less satisfactory. Most theoretical discussion language metaphors in in terms of box and arrow diagrams (see, e.g., [ 4 I 1). but the are generally poorly specified, and than they resolve” to make clear theoretical raise more obscurities the field’s ability In response, many cognitive scientists have looked (both connectionist their theories. Frequently formulating niques Such techniques of all aspects essential might otherwise be overlooked. Computational drawn from those theories by simulation. to the theory’s and symbolic) they have turned to computational modelling for developing and presenting for more satisfactory ways of tech- their proposals. the detailed specification including many aspects which to be also allow predictions implementation, techniques lead to precise statements of theory by forcing lcad techniques programming its predictions. is to be delivered Sound methodological principles are necessary, however, to cognitive if the full potential of com- such principles the exploration foundation. Such exper- empirical data, but the a theory science. Without allows to programs which is in direct conflict with the standard scientific method of evaluating computational mechanisms with little theoretical replicate putational there are two clear dangers. Firstly, unconstrained of alternative imental programming may strategy by testing of the phenomena derive implementation asserted putational which are not theoretically motivated. Without appropriate methodological the distinction within implementation results from supposedly theory. The abstract nature of psychological details cannot be ensured. Moreover, some form of reverse engineering the program an explanation of its behaviour. Secondly, the that, for com- of a theory will include aspects principles, theoretically motivated aspects and of a theory can lead to situations where the program details obscure if such programs are to further our understanding the implementation any computational the unconstrained the independence of simulation completeness, In addition, in question. instantiation is required in order to theorising irrelevant between requires from implementation The utility of sound, systematic methodologies formal science, successfully software development methodologies for example, has developed for specifying program designs linguistics [ 121 ), uncertainty in AI as a technical discipline applied Computer duction of systematic languages ily interested furthermore, tional (e.g., [ 451 ). There is now a general consensus tematic programming methods yields deeper understanding software, grams and their underlying and engineers ical investigation. with better principles. While central techniques rather frameworks ( e.g.. leads to clearer communication, and decision making [ 5. 191 ), reasoning are not necessarily and facilitates (e.g., details cannot be determined. can be seen (e.g., rapidly in a number of fields. in recent years, with the intro- ) and formal (e.g., 1441 ). AI technologists (those primar- than as a natural have, science) in many areas, such as computa- representation [ 15.2 I] ), knowledge ]37,47] (e.g.. [ I] ) and expert systems (e.g., that increased use of formal design and sys- of assessment of pro- and greater predictability independent the methods and tools of mathematicians to the natural sciences, whose core is empir- and presenting for formulating computational \fR. Cooper et al./Artijicial Intelligence 85 (1996) 3-44 5 for developing and testing them, cognitive science in computational In particular, Newell has argued that “it is time to get going on producing advocated of improved modelling methodologies comes theories, and a stronger methodology would seem likely the [empirical] theories of cognition-before to advance more certainly. for the development of the goals and methods currently Further motivation from an examination psychology. unified number of [theoretical] clashes increases by the square or the cube” [ 23,3 1,401 can be seen as the culmination theorists must aim for cumulative fashions represents programme details but advances a hard core. In the case of Soar computer programs, its predecessors. development [31] argues in the tradition of Imre Lakatos this progression to provide a more adequate [ 301. In this vein Newell a research programme incarnation in understanding of his long-argued position of a theory may prove each aiming is embodied any one database doubles again and the [ 3 1, p. 251 and Soar that psychological transitory and avoid paradigm-related, that the work of the Soar community [25]. In such a to be incorrect in peripheral upon in a series of related than account theoretical are made possible by building progressively implementing and documenting are, like most psychological available methodolo- theories match up to At this point, however, we have to question whether currently computational gies for designing, Newell’s challenge. Take Soar itself. From the point of view of theoretical methodology than much current cognitive psychological modelling. Soar seems more sophisticated infor- Statements of Soar as a theory of cognition mal; a set of claims and assumptions in ordinary about cognitive processing [ 3 1,401). As we argue below, however, there is a substantial gap between English (e.g., realisation of the theory as a LISP or these informal statements into C program. This gap has important cognitive question theory, and the degree realisa- [ lo] ). This is not a criticism of Soar or the Soar community, tions of that theory but a general methodological weakness which undermines need to be able to express our theories less ambiguously generally in ways that are more open to detailed scrutiny; against to which Soar can truly be said to be a well-articulated technologies; more easily evaluated for evaluating Soar. It brings can be said to be accurate and the computational the implementations research. We computational consequences in particular the degree expressed enmeshed to which theories, (see This paper describes an attempt accepted criteria of adequacy; and hence more easily compared. these problems by applying specification is an executable to address science. Our goal theoretical proposals which avoids, as far as possible, some lessons a language: the diffi- and of putative it should provide a way of executing or animating should explic- the properties and interdependencies should provide a notation for succinctly the language regarding In addition to determine how it will truly behave. Finally, earlier. Such a language proposals formulating from AI and computer language for expressing culties mentioned clearly cognitive mechanisms. the theory itly support details. the distinction between theoretically motivated aspects and implementation We begin with what is essentially of theory articulation, arguing theory/implementation highlighting for the utility of executable a requirements analysis. We survey existing forms the failings of a variety of current methods, before and the necessity of the specification languages distinction. In Section 3 we introduce Sceptic, an executable \ftheories, in",
            {
                "entities": [
                    [
                        64,
                        112,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 101 (1998) 35-62 Artificial Intelligence Using modeling knowledge to guide design space search Andrew Gelsey *, Mark Schwabacher I, Don Smith 2 Computer Science Department, Rutgers University, New Brunswick, NJ 08903, USA Received 26 March 1997; received in revised form 5 January 1998 Abstract Automated search of a space of candidate designs is an attractive way to improve the traditional engineering design process. To make this approach work, however, an automated design system must include both knowledge of the modeling limitations of the method used to evaluate candidate designs and an effective way to use this knowledge to influence the search process. We argue that a productive approach is to include this knowledge by implementing a set of model functions which measure how much each modeling assumption is violated. The search is then guided by using the values of these model constraint functions as constraint inputs to a standard constrained nonlinear optimization numerical method. A key result of our work is a successful demonstration of the application of AI techniques to an important engineering problem. In an empirical study of parametric conceptual aircraft design, we observed a cost improvement of two orders of magnitude. The principal contribution of our work is a new design optimization methodology which makes explicit the interaction between models of artifacts, and validity models of artifact models. @ 1998 Elsevier Science B.V. All rights reserved. constraint Keywo&r Design; Engineering; Model; Optimization; Physics; Search; Aircraft; Constraint; Numerical 1. Introduction Automated search is not commonly widely held belief process by producing that search automation better designs used in real-world design in spite of the engineering in less time. We explain why automated design the traditional improve should tasks, * Corresponding author. Email: gelsey@cs.rutgers.edu. ’ Email: schwabac@cs.rutgers.edu. 2 Email: dsmith@cs.rutgers.edu. 0004-3702/98/$19.00 PII: SOOO4-3702(98)00012-5 @ 1998 Elsevier Science B.V. All rights reserved. \f36 A. Gelsey et al. /Arti$cial Intelligence I01 (1998) 35-62 their limits), do not know can of the simulators. The is a new design optimization methodology which the interaction between models of artifacts, and validity models of artifact problem, and show how this problem to an important engineering of AI techniques the limitations that model an effective compromise as given, or, on the other hand, completely between, on the one hand, using re-engineering the results of a it declaratively. in previous research (e.g. [9], see Section 7) but contribution of our work (simulators is not used be overcome using model constraints principal makes explicit models. We show an application presenting simulator Re-engineering may be prohibitively A key contribution has been successful expensive. AI techniques conceptual The details of this study appear improvements may transfer If the design process of our work is a successful demonstration of the application of to an important engineering problem. In an empirical aircraft design, we observed a cost improvement study of parametric of two orders of magnitude. later in this paper, as well as some evidence that such to other domains. simulation is automated, each step of the automated this evaluation must be done by computational search requires evalu- (e.g., aircraft, our main simulation. However, compu- is based on a model of the physics of the artifact, and this model tractable. to be used by human experts, and ating the quality of candidate designs, and for complex artifacts example), tational will generally make simplifying Most existing computational thus Instead, from portions of the design space that will violate are intended of their modeling representation that the experts will use their domain knowledge simulators include no explicit assumptions. to stay away typically it is assumed in order to be computationally the simulator’s assumptions. assumptions they is a physical phenomenon that occurs when a wing For example, a typical assumption for an aircraft simulator might be that the wings is operated at will not stall. Stall lift. The physics of stall is too high an angle of attack and therefore ceases to generate understood, and there is in principle no reason not to model it in a simulator. However, a human expert aircraft designer does not want to design a plane that stalls during normal operation, In our interactions with aircraft in fact be quite satisfied with an incomplete them the ability to recognize candidate design would actually stall and should be discarded. that human experts may lift model. Their domain knowledge gives that the so he does not need a detailed prediction of stall behavior. industry expert design engineers, we have found high” lift coefficients and thus realize “impossibly However, rather the design the simulator’s the simulator may be invoked by another program than by a human expert. In this case the automated space, such as an automated that it is quite search procedure will examine designs the evaluation search procedure in exploring which violate of the design quality computed by the simulator may be meaningless. Furthermore, value may appear better than the value for any physically meaningless thus leading the search procedure problem engineering this realizable design, to a worthless but apparently very good design. This is one reason design. For those candidate designs, is not commonly that automated in “real-world” assumptions. search likely used In our earlier work [ 161, we have investigated are needed so that a simulator also described algorithms can be reliably for detecting assumption the types of modeling knowledge that invoked by another program. We have that and other problems violations \fA. Gelsey et al. /Artificial Intelligence 101 (1998) 35-62 31 might lead to incorrect or unreliable the question of how information communicated procedure which contains candidate designs to an automated to focus simulation about model assumption violations search procedure. This communication results. In the present article, we address can be effectively allows the search the subset of the design space its search for good designs within that do not violate model assumptions. 2. Communication strategies As mentioned above, the focus of this research is the effective communication of about model assumption information search procedure which is exploring work we have used a gradient-based procedure. discussing following more general of information search procedure which (This search procedure the details of this particular about model assumption violation between a simulator a space of candidate designs. constrained optimization and an automated In our experimental algorithm as our search in Section 4.) However, before the like to present is further described search method, we would list of strategies. These strategies can be used for communication violation between a simulator and an automated is exploring a space of candidate designs: The Null Strategy: ignore the model violation-the search procedure uses whatever value to be computed by the inapplicable model for the quality of the candidate happens design. The Boolean Strategy: when any model violation occurs, always give the search proce- dure a standard “very bad value” as the quality of the candidate design. Model Constraints: when a candidate design is evaluated, give the search procedure not only a value for the quality of the candidate design, but also values for a set of “model constraint” are satisfied or violated. functions which measure how much the various modeling assumptions Model Penalties: same as the model constraints is returned strategy, except that only the value for to the search procedure, and that value to the amount by which the various modeling assumptions the quality of the candidate design is penalized are violated. in proportion In this article we will focus primarily on the boolean strategy and model constraints. The null strategy as either be useful - the boolean its advantages include: is unlikely to be useful unless strategy or the model penalties it coincidentally to be the same strategy. The boolean strategy can happens l easy to implement: as soon as a violation is detected, just return immediately with a standard “very bad” value for the objective function, l it can be used even with unconstrained search methods. The model constraints strategy, but our experimental search method is considerably penalties strategy strategy is more complicated to implement than the boolean results that allows constraints, better than that of the boolean strategy. We do not investigate later in this article show that when used with a strategy the performance of the model constraints the model in this article, but discuss possible uses for it in Section 8. \f38 A. Gelsey et ul./Art@icial Intelligence IOI (1998) 35-62 0 engine&ale = 1.532 wingArea = 4652 aspectRatio = 1.57 fuselageTaperLength = 121.3 WingThicknessRatio = 3 ws_div_dma = 1 .I58 \\ taperRatio = 0 drawingscale = 2.09 -42 I 0 n i 42 Fig. 1. Supersonic transport aircraft designed by our system (dimensions in feet). Phase 1 2 3 Mach 0.227 0.85 2.0 Altitude (ft. ) Duration (min.s) Comment 0 40,000 60,000 5 85 180 “takeoff subsonic cruise (over land) supersonic cruise (over ocean) capacity: 70 passengers Fig. 2. Mission specification for aircraft in Fig. I \fA. Gelsey et al. /ArtQicial Intelligence 101 (1998) 35-62 39 3. Aircraft design We have pursued our investigation aircraft. However, in our design in the domain of conceptual design of supersonic task the key design variables have already so a more level industry design expert) of our problem might be “parametric design at a system (in collaboration with an aircraft transport identified been precise characterization of abstraction”. Fig. 1 shows a diagram of an airplane designed transpo",
            {
                "entities": [
                    [
                        74,
                        127,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 229 (2015) 105–125Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVariable symmetry breaking in numerical constraint problems ✩Alexandre Goldsztejn a, Christophe Jermann b,∗Carme Torras ca IRCCyN, CNRS, Nantes, Franceb LINA, Université de Nantes/CNRS, Nantes, Francec Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain, Vicente Ruiz de Angulo c, a r t i c l e i n f oa b s t r a c tArticle history:Received 10 December 2014Received in revised form 6 August 2015Accepted 16 August 2015Available online 20 August 2015Keywords:Constraint programmingSymmetriesNumerical constraintsVariable symmetriesSymmetry breaking has been a hot topic of research in the past years, leading to many theoretical developments as well as strong scaling strategies for dealing with hard applications. Most of the research has however focused on discrete, combinatorial, problems, and only few considered also continuous, numerical, problems. While part of the theory applies in both contexts, numerical problems have specificities that make most of the technical developments inadequate.In this paper, we present the rlex constraints, partial symmetry-breaking inequalities corresponding to a relaxation of the famous lex constraints extensively studied in the discrete case. They allow (partially) breaking any variable symmetry and can be generated in polynomial time. Contrarily to lex constraints that are impractical in general (due to their overwhelming number) and inappropriate in the continuous context (due to their form), rlex constraints can be efficiently handled natively by numerical constraint solvers. Moreover, we demonstrate their pruning power on continuous domains is almost as strong as that of lex constraints, and they subsume several previous work on breaking specific symmetry classes for continuous problems. Their experimental behavior is assessed on a collection of standard numerical problems and the factors influencing their impact are studied. The results confirm rlex constraints are a dependable counterpart to lexconstraints for numerical problems.© 2015 Elsevier B.V. All rights reserved.1. IntroductionNumerical constraint solvers are nowadays beginning to be competitive and even to outperform, in some cases, classical methods for solving systems of equations and inequalities over the reals. As a consequence, their application has raised interest in fields as diverse as neurophysiology and economics [2], biochemistry, crystallography, robotics [3] and, more generally, in those related to global optimization [4]. Symmetries naturally occur in many of these applications, and it is advisable to exploit them in order to reduce the search space and, thus, to increase the efficiency of the solvers.E-mail addresses: alexandre.goldsztejn@irccyn.ec-nantes.fr (A. Goldsztejn), christophe.jermann@univ-nantes.fr (C. Jermann), ruiz@iri.upc.edu✩This paper is an extended version of [1] presented at the conference CP 2011.* Corresponding author.(V. Ruiz de Angulo), torras@iri.upc.edu (C. Torras).http://dx.doi.org/10.1016/j.artint.2015.08.0060004-3702/© 2015 Elsevier B.V. All rights reserved.\f106A. Goldsztejn et al. / Artificial Intelligence 229 (2015) 105–125Numerical solvers follow the Branch&Prune scheme, similarly to discrete constraint solvers: At each iteration, a sub-domain is selected, pruned according to the constraints, and then split into several sub-domains to be further explored. The main differences with discrete solvers are that (sub)domains being continuous only their boundaries are contracted, and that a sub-domain is declared to be a solution whenever it reaches some prescribed computational precision. Because of the resemblance of the solving processes, it is tempting to port symmetry breaking methods designed for discrete Constraint Satisfaction Problems (CSPs) to numerical ones.Considerable work on symmetry breaking has been done for discrete CSPs in the last decades [5–7]. Two main symmetry-breaking strategies have been pursued: 1) to devise specialized search algorithms that avoid symmetric portions of the search space [8,9]; and 2) to add symmetry-breaking constraints (SBCs) that filter out redundant subspaces [10,11]. Contrarily, there exists very little work on symmetry breaking for numerical problems. For cyclic variables permutations, an approach divides the initial space into boxes and eliminates symmetric ones before the solving starts [12]. SBCs have also been pro-posed, but only for either specific problems [13,14] or specific symmetry classes [15–17], and often only partially breaking the considered symmetries.In this paper, we propose the first general SBCs for numerical constraint problems that (partially) break any variable symmetry. These SBCs take the form of simple binary inequalities of the form xi ≤ x j where xi and x j are two distinct variables of the problem and i < j. Thus, at most n(n−1)inequalities are generated to deal with any symmetry. They can be generated in polynomial time knowing a generator of the symmetry group, using classical group theory algorithms. Moreover we demonstrate that these SBCs are suitable and optimal for numerical problems, i.e., they enclose tightly an asymmetric search subspace and thus have a better, or similar, pruning power than other SBCs.2The outline of the paper is as follows: Section 2 provides the necessary background on numerical problems and sym-metries; Section 3 introduces our SBCs as a relaxation of the lexicographic-ordering based SBCs [18] widely used by the discrete CSP community, and it also establishes the good properties of this relaxation; Section 4 introduces the state-of-the-art and compares our SBCs to existing alternatives; Section 5 assesses the practical interest of our SBCs on a benchmark of standard problems and analyzes the factors influencing their impact. Section 6 concludes the paper with future research directions.2. Principles of variable symmetry breakingA CSP is defined as a triple (cid:4)x, d, c(cid:5), where x = (x1, . . . , xn) is a list of variables, d = (d1, . . . , dn) is a list of domains for the variables, and c = (c1, . . . , cm) is a list of constraints. The focus of this paper is on numerical CSPs (NCSPs), whose variables are continuous, and thus domains are subsets of R, typically represented as a set of intervals (box) x. To conform mathematical notations in use for numerical problems, the same symbols are used for variables and their valuations, i.e., x will often denote a point in Rn. For the same reason, we adopt a functional notation for the evaluation of a constraint ci : Rn → {true, false} and for the evaluation of the conjunction of the constraints c : Rn → {true, false}. Hence a solution of a NCSP is a point x ∈ x that satisfies c(x), and its solution set is χ = {x ∈ x : c(x)}.A bijective function s : Rn → Rn is a symmetry of a (N)CSP if it maps solutions to solutions,1 i.e., for any x ∈ x such that c(x) = true, s(x) ∈ x and c(s(x)) = true. We say x and s(x) are symmetric points and, in case they are solutions, symmetric solutions. The symmetries of a (N)CSP form a group for the composition law. This symmetry group is denoted (cid:3) in the following. Though the identity function is forcibly part of (cid:3), since it is a trivial symmetry of any CSP, it is not considered in the following as it is irrelevant to break.In this paper, we consider only symmetries that are permutations of variables. Let Sn be the set of all permutations of {1, . . . , n}. The image of i by a permutation σ is denoted by iσ . Any permutation σ is completely defined by the image of each integer in {1, . . . , n}, and it is usually described as a vector [1σ , 2σ , . . . , nσ ]. A symmetry s is a variable symmetry iff there is a permutation σ ∈ Sn such that for any point x ∈ x, s(x) = (x1σ , . . . , xnσ ). We identify such symmetries with their associated permutations and denote both by σ in the following. Consequently, the group of variable symmetries of a CSP is isomorphic to a permutation subgroup of Sn, which are both identified and denoted by (cid:3) in the following. The application of a variable symmetry σ to a point x is denoted by xσ , this notation being extended to sets (discrete or continuous) of points X ⊆ x by X σ = {xσ : x ∈ X}.Example 1. The 3-cyclic roots problem consists in finding all (x1, x2, x3) ∈ R3 satisfying (x1 + x2 + x3 = 0) ∧ (x1x2 + x2x3 +x3x1 = 0) ∧ (x1x2x3 = 1). This problem has six variable symmetries (including identity):(cid:3) = {[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]},(1)i.e., (cid:3) = S3. Indeed, all the variables are syntactically interchangeable within all the constraints by the commutativity laws of product and sum.1 Nothing is required for non-solution points, i.e., we consider only solution symmetries [19].\fA. Goldsztejn et al. / Artificial Intelligence 229 (2015) 105–125107We can define the symmetry class of any point x ∈ x as the set of the images s(x) for all the symmetries s of the problem. In the case of variable symmetries, it can be noted x(cid:3) = {xσ : σ ∈ (cid:3)}. Provided that the domain satisfy the symmetries, i.e. x = xσ for all σ ∈ (cid:3), being in the same class is an equivalence relation and thus the symmetry classes form a partition of x.The symmetries of a (N)CSP are broken when a single representative in each symmetry class is retained. To this end, it is possible to add symmetry-breaking constraints (SBCs) which exclude all but a single representative in each symmetry class [5,7,20]. Crawford et al. [18] proposed lexicographic ordering constraints (lex) to address variable symmetry breaking. Recall that given x and y in Rn, the lexicographic order is defined inductively as:for n = 1,for n > 1,x (cid:10)lex y ≡ (x1 ≤ y1)x (cid:10)lex y ≡ (x1 < y1) ∨(cid:2)(cid:3)(x1 = y1) ∧ (x2:n (cid:10)lex y2:n)where, given a list z = (z1, z2, . . . , zn), zi: j denotes the sublist",
            {
                "entities": [
                    [
                        136,
                        195,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 268 (2019) 96–114Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputing a small agreeable set of indivisible items ✩Pasin Manurangsi a, Warut Suksompong ba Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USAb Department of Computer Science, University of Oxford, UKa r t i c l e i n f oa b s t r a c tArticle history:Received 10 March 2018Received in revised form 12 August 2018Accepted 13 October 2018Available online 18 December 2018Keywords:AgreeabilityIndivisible itemsResource allocationSocial choiceWe study the problem of assigning a small subset of indivisible items to a group of agents so that the subset is agreeable to all agents, meaning that all agents value the subset as least as much as its complement. For an arbitrary number of agents and items, we derive a tight worst-case bound on the number of items that may need to be included in such a set. We then present polynomial-time algorithms that find an agreeable set whose size matches the worst-case bound when there are two or three agents. We also show that finding small agreeable sets is possible even when we only have access to the agents’ preferences on single items. Furthermore, we investigate the problem of efficiently computing an agreeable set whose size approximates the size of the smallest agreeable set for any given instance. We consider two well-known models for representing the preferences of the agents—the value oracle model and additive utilities—and establish tight bounds on the approximation ratio that can be obtained by algorithms running in polynomial time in each of these models.© 2018 Elsevier B.V. All rights reserved.1. IntroductionA typical resource allocation problem involves dividing a set of resources among interested agents. We are often con-cerned with the efficiency of the allocation, e.g., achieving high social welfare or ensuring that no other allocation would make every agent better off than the current allocation. Another important issue is the fairness of the allocation. For exam-ple, we might want the resulting allocation to be envy-free, meaning that every agent regards her bundle as the best among all bundles in the allocation [23,55], or proportional, meaning that every agent obtains at least her proportionally fair share [51]. A common feature of such problems is that one agent’s gain is another agent’s loss: The setting inherently puts the agents in conflict with one another, and our task is to try to resolve this conflict as best we can according to our objectives. Resource allocation problems constitute a major area of study in artificial intelligence.We study in this work a variant of the resource allocation problem where instead of the agents being pitted against one another, they belong to one and the same group. We will collectively allocate a subset of items to this group; our goal is to make this subset “agreeable” to all agents. Agreeability can be thought of as a minimal desirability condition: While an agent may be able to find other subsets of items that she personally prefers, the current subset is still acceptable for her, and she can agree with its allocation to the group. In other words, if the agreeability condition is not met for some This paper unifies and expands earlier versions that appeared in Proceedings of the 25th International Joint Conference on Artificial Intelligence [52]✩and Proceedings of the 26th International Joint Conference on Artificial Intelligence [40]. In particular, Theorems 5, 10, and 11 are new to this version, and Theorems 4, 6, and 7 improve corresponding results in the earlier versions. These additions lead to asymptotically tight bounds in Sections 3.3 and 4.1.E-mail address: warut.suksompong@cs.ox.ac.uk (W. Suksompong).https://doi.org/10.1016/j.artint.2018.10.0010004-3702/© 2018 Elsevier B.V. All rights reserved.\fP. Manurangsi, W. Suksompong / Artificial Intelligence 268 (2019) 96–11497Table 1Summary of the upper bounds on the size of the smallest agreeable set, presented in Section 3.n = 2n ≥ 3Full preferences(cid:2) m2min(cid:3) + 1 (Theorem 1)(cid:3)(cid:4)(cid:2)(cid:5)m+n2, m(Theorem 1)Ordinal preferences(cid:2)(cid:3)+ 1 (Theorem 2)m2+ (cid:2)(log m) for constant n (Theorems 4, 5)m2agent, then the agent will be unsatisfied and tempted to leave the group. We consider a notion of agreeability based on the fairness notion of envy-freeness: a subset of items is said to be agreeable to an agent if the agent likes it at least as much as the complement set. Agreeability, or minor variants thereof, has been considered in the context of fair division, where each group consists of a single agent [7,13,16]. For example, Brams et al. [16] calls the property “worth at least 50 percent”. An appealing aspect of agreeability is that it can be defined for arbitrary ordinal preferences, which constitutes a considerably larger class of preferences than those represented by additive cardinal utility functions [5,15,17,39,53]. Indeed, for most of this work we only assume that the agents’ preferences are monotonic, meaning that an agent always values a set of items at least as much as any of its subsets. Since in a large majority of resource allocation settings agents can simply ignore items that yield negative value to them, the monotonicity assumption is usually made without loss of generality.As applications of our agreeability notion, one could imagine that the agents are going together on a trip and agreeing on the set of items to put in a shared luggage, or choosing a subset of items as prizes from a team competition that they won together. Without further constraints, the problem described so far would be trivial, since we could simply allocate the entire set of items to the agents. We therefore impose a constraint that the allocated subset should be as small as possible. This constraint on size is reasonable in a variety of settings, including in the two given examples. Indeed, in the first example a luggage has limited space, and in the second example the organizers may want some items to be left as prizes for the losing teams, perhaps so that the allocation seems fair to an outsider. Similar cardinality constraints have been considered in the context of fair division [11]. In the example of agents going together on a trip, a subset of items that they take is agreeable if they like it no less than the complement subset of items left at home. Put differently, based on the set of items chosen, every agent would rather go on the trip than stay at home. Similarly, for agents taking items as prizes from a team competition, if the competition is between two teams and a subset of items is not agreeable to some agent in the winning team, we will have an undesirable situation where the agent envies the losing team that takes the remaining items.While our study is based on the framework of resource allocation, agreeability is also relevant in other areas of social choice theory and artificial intelligence. In particular, one could think of choosing an agreeable set of items as an election of a committee from a set of candidates, where the committee size is unspecified but perhaps should be minimized. The theory of committee elections provides a number of specific ways to instantiate the notion of agreeability. For example, if one uses approval elections, where every agent either approves or disapproves each candidate and approves a committee if it contains at least one of her approved candidates, an agreeable committee according to our notion corresponds to one where every agent has an approved candidate in the committee. In general, the preferences of the agents for various committees can be quite complex, and several variants of committee elections have been investigated in the literature [6,50]. We see our work as a starting point that deals with a particularly simple and natural agreeability notion, and our hope is that this work will lay a foundation for studying different notions that may be appropriate for other applications.1.1. Our resultsIn this work, we initiate the study of agreeability in resource allocation. First, in Section 3, we establish upper bounds on the size of the smallest agreeable set, both when the algorithm has access to the agents’ full preferences and when the algorithm only has access to the agents’ preferences on single items. In addition, we present algorithms that compute agree-able sets whose size matches the worst-case bounds under both assumptions. Our results in this section are summarized in Table 1.In Section 3.1, we derive a tight upper bound on the number of items that may need to be included in an agreeable set, for any number of agents and items. Remarkably, even though agents may have vastly differing and perhaps conflicting preferences, the number of extra items that we might need to choose in order to accommodate all of them is surprisingly small, i.e., half an item per additional agent (Theorem 1). Our result holds under a very weak assumption that preferences are monotonic, meaning that an agent cannot be worse off whenever an item is added to her set. Interestingly, to establish this result we make use of Kneser’s conjecture, a combinatorial result whose proof by Lovász [37] gave rise to the field of topological combinatorics.In Section 3.2, we turn our attention to the question of whether we can efficiently compute an agreeable set whose size matches the worst-case bound given in Section 3.1. We answer the question in the affirmative for the cases of two and three agents. To this end, we make the assumption that preferences are responsive, meaning that an agent cannot be worse off when an item is added to her set or replaced by another item that she weakly prefers to the original item. While responsiveness is stronger than monotonicity, it is still a generalization of additivity, a very common assumption on prefere",
            {
                "entities": [
                    [
                        135,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 227 (2015) 71–92Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFair assignment of indivisible objects under ordinal preferencesHaris Aziz∗, Serge Gaspers, Simon Mackenzie, Toby WalshNICTA and University of New South Wales, Sydney 2052, Australiaa r t i c l e i n f oa b s t r a c tArticle history:Received 28 June 2014Received in revised form 7 June 2015Accepted 14 June 2015Available online 18 June 2015Keywords:Fair divisionResource allocationEnvy-freenessProportionalityWe consider the discrete assignment problem in which agents express ordinal preferences over objects and these objects are allocated to the agents in a fair manner. We use the stochastic dominance relation between fractional or randomized allocations to systematically define varying notions of proportionality and envy-freeness for discrete assignments. The computational complexity of checking whether a fair assignment exists is studied for these fairness notions. We also characterize the conditions under which a fair assignment is guaranteed to exist. For a number of fairness concepts, polynomial-time algorithms are presented to check whether a fair assignment exists. Our algorithmic results also extend to the case of unequal entitlements of agents. Our NP-hardness result, which holds for several variants of envy-freeness, answers an open question posed by Bouveret, Endriss, and Lang (ECAI 2010). We also propose fairness concepts that always suggest a non-empty set of assignments with meaningful fairness properties. Among these concepts, optimal proportionality and optimal weak proportionality appear to be desirable fairness concepts.© 2015 Elsevier B.V. All rights reserved.1. IntroductionA basic yet widely applicable problem in computer science and economics is to allocate discrete objects to agents given the preferences of the agents over the objects. The setting is referred to as the assignment problem or the house allocation problem (see, e.g., [1,8,28,32,40,50,51]). In this setting, there is a set of agents N = {1, . . . , n}, a set of objects O = {o1, . . . , om}with each agent i ∈ N expressing ordinal preferences (cid:2)i over O . The goal is to allocate the objects among the agents in a fair or optimal manner without allowing transfer of money. The assignment problem is a fundamental setting within the wider domain of fair division or multiagent resource allocation [23]. The model is applicable to many resource allocation or fair division settings where the objects may be public houses, school seats, course enrollments, kidneys for transplant, car park spaces, chores, joint assets of a divorcing couple, or time slots in schedules. Fair division has become a major area in AI research in the last decade, and especially the last few years (see, e.g., [3,12–15,18,23,25,29,37,44]).In this paper, we consider the fair assignment of indivisible objects. Two of the most fundamental concepts of fairness are envy-freeness and proportionality. Envy-freeness requires that no agent considers that another agent’s allocation would give him more utility than his own. Proportionality requires that each agent should get an allocation that gives him at least 1/n of the utility that he would get if he was allocated all the objects. When agents’ ordinal preferences are known but * Corresponding author.E-mail addresses: haris.aziz@nicta.com.au (H. Aziz), sergeg@cse.unsw.edu.au (S. Gaspers), simon.mackenzie@nicta.com.au (S. Mackenzie), toby.walsh@nicta.com.au (T. Walsh).http://dx.doi.org/10.1016/j.artint.2015.06.0020004-3702/© 2015 Elsevier B.V. All rights reserved.\f72H. Aziz et al. / Artificial Intelligence 227 (2015) 71–92Fig. 1. Inclusion relationships between fairness concepts. Envy-freeness is abbreviated as EF and Proportionality is abbreviated as Prop. Possible completion is abbreviated as PC. Necessary completion is abbreviated as NC. An arrow represents inclusion. For example, every SD envy-free outcome is also SD proportional. Double lines represent equivalence. For example, SD EF and Necessary EF are equivalent.utility functions are not given, then ordinal notions of envy-freeness and proportionality need to be formulated. We consider a number of ordinal fairness concepts. Most of these concepts are based on the stochastic dominance (SD) relation which is a standard way of comparing fractional/randomized allocations. An agent prefers one allocation over another with respect to the SD relation if he gets at least as much utility from the former allocation as the latter for all cardinal utilities consistent with the ordinal preferences. Although this paper is restricted to discrete assignments, using stochastic dominance to define fairness concepts for discrete assignments turns out to be fruitful. The fairness concepts we study include SD envy-freeness, weak SD envy-freeness, possible envy-freeness, SD proportionality, and weak SD proportionality. We consider the problems of computing a discrete assignment that satisfies some ordinal notion of fairness if one exists, and the problems of verifying whether a given assignment satisfies the fairness notions.Contributions We present a systematic way of formulating fairness properties in the context of the assignment problem. The logical relationships between the properties are proved. Interestingly, our framework leads to new solution concepts such as weak SD proportionality that have not been studied before. The motivation to study a range of fairness properties is that, depending on the situation, only some of them are achievable. In addition, only some of them can be computed efficiently. In order to find fairest achievable assignment, one can start by checking whether there exists a fair assignment for the strongest notion of fairness. If not, one can try the next fairness concept that is weaker than the one already checked (Fig. 1).We present a comprehensive study of the computational complexity of computing fair assignments under ordinal prefer-ences. In particular, we present a polynomial-time algorithm to check whether an SD proportional exists even when agents may express indifferences. The algorithm generalizes the main result of [46] (Theorem 1) who focused on strict preferences. For the case of two agents, we obtain a polynomial-time algorithm to check whether an SD envy-free assignment exist. The result generalizes Proposition 2 in [12] in which preferences over objects were assumed to be strict. For a constant number of agents, we propose a polynomial-time algorithm to check whether a weak SD proportional assignment exists. As a corol-lary, for two agents, we obtain a polynomial-time algorithm to check whether a weak SD envy-free or a possible envy-free assignment exists. Even for an unbounded number of agents, if the preferences are strict, we characterize the conditions under which a weak SD proportional assignment exists. We show that the problems of checking whether possible envy-free, SD envy-free, or weak SD envy-free assignments exist are NP-complete. The result for possible envy-freeness answers an open problem posed in [12]. Our computational results are summarized in Table 1.We show that our two main algorithms can be extended to the case where agents have different entitlements over the objects or if we additionally require the assignment to be Pareto optimal. Our study highlights the impacts of the following settings: i) randomized/fractional versus discrete assignments, ii) strict versus non-strict preferences, and iii) multiple objects per agent versus a single object per agent.Since the fairness concepts we introduce may not be guaranteed to exist, we suggest possible ways to extend the fair-ness concepts. Firstly, we consider the problem of maximizing the number of agents for whom the corresponding fairness constraint is satisfied. A criticism of this approach is that there can still be agents who are completely dissatisfied. We then consider an alternative approach in which the proportionality constraints is weakened in a natural and gradual manner. We refer to the concepts as optimal proportionality and optimal weak proportionality. The fairness concepts are not only at-tractive but we show that an optimal proportional assignment can be computed in polynomial time and an optimal weak proportional assignment can be computed in polynomial time for a constant number of agents.2. Related workProportionality and envy-freeness are two of the most established fairness concepts. Proportionality dates back to at least the work of Steinhaus [48] in the context of cake-cutting. It is also referred to as fair share guarantee in the literature [41]. A formal study of envy-freeness in microeconomics can be traced back to the work of Foley [31].\fH. Aziz et al. / Artificial Intelligence 227 (2015) 71–9273Table 1Complexity of checking the existence of a fair assignment of indivisible goods for n agents and m objects. The results in bold are from this paper.Weak SD proportionalin P for strict preferences (Theorem 7)in P for constant n (Theorem 8)SD proportionalin P (Theorem 6)Weak SD envy-freePossible envy-freeNP-complete (Theorem 11)in P for strict preferences [12]in P for n = 2 (Corollary 2)NP-complete (Theorem 11)in P for strict preferencesin P for n = 2 (Corollary 2)SD envy-freeNP-complete even for strict preferences [12]in P for n = 2 (Corollary 1)The computation of fair discrete assignments has been intensely studied in the last decade within computer science. In many of the papers considered, agents express cardinal utilities for the objects and the goal is to compute fair assignments (see, e.g., [9,13,15,28,35,39,42,45]). A prominent paper is that of Lipton et al. [39] in which algorithms for approximately envy-free assignments are discussed. It follows from [39] that even when two agents express cardinal utilities, checking whether there exists a proportional or envy-free assignment is NP-complete. A closely relat",
            {
                "entities": [
                    [
                        134,
                        198,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 228 (2015) 129–152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConfidence-based reasoning in stochastic constraint programming ✩Roberto Rossi a,∗a Business School, University of Edinburgh, United Kingdomb Department of Computer Science, Taif University, Taif, Saudi Arabiac Department of Management, Cankaya University, Ankara, Turkeyd Insight Centre for Data Analytics, University College Cork, Ireland, Brahim Hnich b, S. Armagan Tarim c,d,1, Steven Prestwich d,1a r t i c l e i n f oa b s t r a c tArticle history:Received 7 November 2014Received in revised form 5 July 2015Accepted 8 July 2015Available online 15 July 2015Keywords:Confidence-based reasoningStochastic constraint programmingSampled SCSP(α, ϑ)-solution(α, ϑ)-solution setConfidence interval analysisGlobal chance constraint1. IntroductionIn this work we introduce a novel approach, based on sampling, for finding assignments that are likely to be solutions to stochastic constraint satisfaction problems and constraint optimisation problems. Our approach reduces the size of the original problem being analysed; by solving this reduced problem, with a given confidence probability, we obtain assignments that satisfy the chance constraints in the original model within prescribed error tolerance thresholds. To achieve this, we blend concepts from stochastic constraint programming and statistics. We discuss both exact and approximate variants of our method. The framework we introduce can be immediately employed in concert with existing approaches for solving stochastic constraint programs. A thorough computational study on a number of stochastic combinatorial optimisation problems demonstrates the effectiveness of our approach.© 2015 Elsevier B.V. All rights reserved.The stochastic constraint satisfaction/optimisation framework introduced in [2,3] constitutes an expressive declarative formalism for modelling problems of decision making under uncertainty. A stochastic constraint satisfaction problem (SCSP), alongside decision variables, features random variables, which follow some probability distribution and can be used to model uncertainty. Relationships over subsets of random and decision variables can be expressed in a declarative manner via stochastic constraints. The fact that a given relationship over subsets of random and decision variables should be satisfied according to a prescribed probability can be expressed by means of chance constraints. Finally, since problems of decision making under uncertainly are sequential in nature, the modeller can define a stage structure, that is a sequence of decision stages, in each of which a subset of all possible decisions are taken and a subset of all possible random variables are observed. A solution to an SCSP can be represented in general by means of a policy tree, which records feasible or optimal decisions associated with each possible set of random variable realisations.✩This work is an extended version of [1].* Corresponding author at: Business School, University of Edinburgh, 29 Buccleuch place, EH8 9JS, Edinburgh, UK. Tel.: +44 (0)131 6515239; fax: +44 (0)131 650 8077.E-mail addresses: roberto.rossi@ed.ac.uk (R. Rossi), hnich.brahim@gmail.com (B. Hnich), armtar@yahoo.com (S.A. Tarim), s.prestwich@cs.ucc.ie(S. Prestwich).1 This publication has emanated from research supported in part by a research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289.http://dx.doi.org/10.1016/j.artint.2015.07.0040004-3702/© 2015 Elsevier B.V. All rights reserved.\f130R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152As shown in [3, Theorem 1], solving SCSPs is a computationally hard task. Even trivial instances with a dozen of decision and random variables require a computational effort out of reach even for the most advanced hardware/software combina-tion. This is due to the fact that the size of the policy tree grows exponentially in the number of random variables in the model and in the size of their support. Furthermore, a major limitation of all existing complete SCSPs solution methods, such as [3] and [4], is the fact that they assume the support of random variables is finite, otherwise a solution cannot be expressed as a finite policy tree. In practice, however, it is often the case that random variables either range over continu-ous supports or have a very large number (possibly infinite) of values in their domain. To date, no general purpose method exists for solving large-scale SCSPs, or SCSPs featuring random variables with continuous or discrete infinite support; for the sake of brevity we shall name this latter class of SCSPs “infinite SCSPs.”The main contribution of this paper is to propose a framework for solving large-scale or infinite SCSPs. More specifically, we argue that in solving large-scale or infinite SCSPs, one should not consider the ultimate feasible/optimal solution, which in some cases may even be impossible to represent; rather, the decision maker should aim for a solution that she “suffi-ciently trusts,” which she may claim to be optimal or feasible with a given confidence level, and for which a certain degree of error may be tolerated. In order to obtain such a solution, the decision maker should only look at a possibly limited number of samples drawn from the random variables in the model. In other words, she should try to “estimate” the quality of this solution.Our approach has several analogies with established techniques in statistics. When a survey is conducted on a sample population — e.g. an electoral poll — a statistician typically associates a certain confidence level with the results obtained from the chosen sample population. For instance, one may claim that there is a 90% chance that the actual mean being estimated is within a given interval. We argue that the very same approach may be adopted in stochastic decision making. If the infinite or large-scale m-stage SCSP does not admit any closed form solution and is complex enough to rule out any chance of obtaining an exact solution, we suggest that — as is done in statistics — one may introduce a confidence level α and a tolerated estimation error ±ϑ . The decision maker, instead of looking for an exact solution, may then aim to “estimate” — according to the chosen α and ϑ — whether the actual satisfaction probability guaranteed by an assignment is greater than or equal to the given target value for each of the chance constraints in the model. By choosing given values for α and ϑ the set of solutions may vary. For this reason we will introduce a new notion of solution that is parameterised by these two parameters and that we call an (α, ϑ)-solution. Intuitively, as α tends to 1 and ϑ tends to 0 the set of (α, ϑ)-solutions will converge to the set of actual solutions to the original stochastic constraint satisfaction problem, which we therefore rename (1, 0)-solutions. One should note that an approach of this kind has been recently advocated in [5, Chap. 4].In this work, we make the following contributions to the stochastic constraint programming literature:• we discuss how to obtain compact instances of infinite or large-scale stochastic constraint programs via sampling: we call these instances “sampled SCSPs;”• we introduce the concepts of (α, ϑ)-solution and of (α, ϑ)-solution set; and show how to compute a priori the mini-mum sample size that guarantees the attainment of such classes of solutions;• we show how the above tools can be employed in order to find approximate solutions to infinite or large-scale stochas-tic constraint satisfaction/optimisation problems that cannot be solved by existing exact approaches in the stochastic constraint programming literature;• we conduct a thorough computational study on three well-known stochastic combinatorial problems to validate our theoretical framework and assess its effectiveness, efficiency, and scalability.This work is structured as follows: in Section 2 we introduce the relevant formal background in constraint programming, stochastic constraint programming, and confidence interval analysis; in Section 3 we introduce sampled SCSPs; in Section 4we discuss properties of the solutions of sampled SCSPs and formally introduce (α, ϑ)-solutions; in Section 5 we introduce (α, ϑ)-solution sets; in Section 6 we extend our discussion to stochastic constraint optimisation problems; in Section 7 we discuss connections with established techniques in statistics; in Section 8 we present our computational study; in Section 9we discuss related works; finally, in Section 10 we draw conclusions and discuss future research directions.2. Formal backgroundWe now introduce the relevant background in constraint programming, stochastic constraint programming, and confi-dence interval analysis.2.1. Constraint programmingA Constraint Satisfaction Problem (CSP) [6] consists of a set of decision variables, each with a finite domain of values, and a set of constraints specifying allowed combinations of values for some variables. A solution to a CSP is an assignment of variables to values in their respective domains such that all of the constraints are satisfied. Constraint solvers typically explore partial assignments enforcing a local consistency property. A constraint c is generalised arc consistent (GAC) if and only if when a variable is assigned any of the values in its domain, there exist compatible values in the domains of all the \fR. Rossi et al. / Artificial Intelligence 228 (2015) 129–152131other variables of c. In order to enforce a local consistency property on a constraint c during search, we employ filtering algorithms that remove inconsistent values from the domains of the variables of c. These filtering algorithms are repeatedly called until no more values are pruned. This process is called constraint propagation.2.2. Stochastic constraint programmingThe following definitions are based on [4",
            {
                "entities": [
                    [
                        136,
                        199,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1194–1203Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRational choice and AGM belief revisionGiacomo Bonanno 1Department of Economics, University of California, Davis, CA 95616-8578, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 24 October 2008Received in revised form 8 May 2009Accepted 11 May 2009Available online 30 May 2009Keywords:Rational choiceRevealed preferenceBelief revisionPartial belief revision functionChoice functionArrow’s axiom1. IntroductionWe establish a correspondence between the rationalizability of choice studied in therevealed preference literature and the notion of minimal belief revision captured by theAGM postulates. A choice frame consists of a set of alternatives Ω, a collection E ofsubsets of Ω (representing possible choice sets) and a function f : E → 2Ω (representingchoices made). A choice frame is rationalizable if there exists a total pre-order R on Ωsuch that, for every E ∈ E,f (E) coincides with the best elements of E relative to R.We re-interpret choice structures in terms of belief revision. An interpretation is obtainedby adding a valuation V that assigns to every atom p the subset of Ω at which p istrue. Associated with an interpretation is an initial belief set and a partial belief revisionfunction. A choice frame is AGM-consistent if, for every interpretation of it, the associatedpartial belief revision function can be extended to a full-domain belief revision functionthat satisfies the AGM postulates. It is shown that a finite choice frame is AGM-consistentif and only if it is rationalizable.© 2009 Elsevier B.V. All rights reserved.The dominant theory of belief revision is due to Alchourrón, Gärdenfors and Makinson [1] and is known as the AGMtheory. In their approach beliefs are modeled syntactically as sets of formulas and belief revision is construed as an operationthat associates with every deductively closed set of formulas K (thought of as the initial beliefs) and formula φ (thought ofas new information) a new set of formulas B K (φ) representing the new beliefs after revising by φ.We establish a correspondence between the AGM theory and the set-theoretic structures studied in rational choice theory(also known as revealed preference theory; see, for example, [22] and [24]). Rational choice theory considers structures(cid:4)Ω, E, f (cid:5) consisting of a set of alternatives Ω , a collection E of subsets of Ω (representing possible choice sets) and afunction f from E into the set of subsets of Ω , representing choices made. The main objective of rational choice theory isto investigate the conditions under which the function f can be rationalized by a total pre-order R on Ω in the sense that,for every E ∈ E , f (E) coincides with the best elements of E relative to R.We re-interpret choice structures in terms of belief revision. The set Ω is now interpreted as a set of states. A modelbased on (or an interpretation of) a choice structure is obtained by adding to it a valuation V that assigns to every atomicformula p the set of states at which p is true. Truth of an arbitrary formula at a state is then obtained as usual. Given amodel (cid:4)Ω, E, f , V (cid:5) we define the initial beliefs as the set of formulas φ such that f (Ω) is a subset of the truth set of φ,denoted by (cid:6)φ(cid:6). Hence f (Ω) is interpreted as the set of states that are initially considered possible. We then interpret thecollection of events (sets of states) E as a set of possible items of information. If φ is a formula such that (cid:6)φ(cid:6) ∈ E , we definethe revised beliefs upon learning that φ as the set of formulas ψ such that f ((cid:6)φ(cid:6)) ⊆ (cid:6)ψ(cid:6). Thus the event f ((cid:6)φ(cid:6)) is interpretedas the set of states that are considered possible after learning that φ is the case. Hence associated with every model is aE-mail address: gfbonanno@ucdavis.edu.1 I am grateful to three anonymous reviewers for helpful and constructive comments.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.05.001\fG. Bonanno / Artificial Intelligence 173 (2009) 1194–12031195partial belief revision function (partial because, in general, it is not the case that, for every formula φ, (cid:6)φ(cid:6) ∈ E , that is, notevery piece of information is potentially available or contemplated). We say that a choice frame (cid:4)Ω, E, f (cid:5) is AGM-consistentif, for every model based on it, the associated partial belief revision function can be extended to a full-domain belief revisionfunction that satisfies the AGM postulates. We show that, when the set of states is finite, the properties of AGM-consistencyand rationalizability are equivalent.In the next section we review the notion of belief function and the AGM postulates. In Section 3 we develop the corre-spondence between AGM belief revision and rational choice. Section 4 contains a brief discussion of related literature andconcluding remarks.2. Belief revision functionsLet Φ be the set of formulas of a propositional language based on a countable set A of atomic formulas.2 Given a subsetK ⊆ Φ, its PL-deductive closure [K ]P L (where ‘PL’ stands for Propositional Logic) is defined as follows: ψ ∈ [K ]P L if and onlyif there exist φ1, . . . , φn ∈ K (with n (cid:2) 0) such that (φ1 ∧ · · · ∧ φn) → ψ is a tautology (that is, a theorem of PropositionalLogic). A set K ⊆ Φ is consistent if [K ]P L (cid:9)= Φ (equivalently, if there is no formula φ such that both φ and ¬φ belong to[K ]P L ). A set K ⊆ Φ is deductively closed if K = [K ]P L . A belief set is a set K ⊆ Φ which is deductively closed.Let K be a consistent belief set representing the agent’s initial beliefs and let Ψ ⊆ Φ be a set of formulas representingpossible items of information. A belief revision function based on K is a function B K : Ψ → 2Φ (where 2Φ denotes the set ofsubsets of Φ) that associates with every formula φ ∈ Ψ (thought of as new information) a set B K (φ) ⊆ Φ (thought of as therevised beliefs).3 If Ψ (cid:9)= Φ then B K is called a partial belief revision function, while if Ψ = Φ then B K is called a full beliefrevision function.Definition 1. Let B K : Ψ → 2Φ be a (partial) belief revision function and Bthat BK is an extension of B K if, for every φ ∈ Ψ , BK (φ) = B K (φ).∗∗∗K: Φ → 2Φ a full belief revision function. We sayA full belief revision function is called an AGM function if it satisfies the following properties, known as the AGM postu-lates: ∀φ, ψ ∈ Φ,(AGM1) B K (φ) = [B K (φ)]P L ,(AGM2) φ ∈ B K (φ),(AGM3) B K (φ) ⊆ [K ∪ {φ}]P L ,(AGM4) if ¬φ /∈ K , then [K ∪ {φ}]P L ⊆ B K (φ),(AGM5) B K (φ) = Φ if and only if φ is a contradiction,(AGM6) if φ ↔ ψ is a tautology then B K (φ) = B K (ψ),(AGM7) B K (φ ∧ ψ) ⊆ [B K (φ) ∪ {ψ}]P L ,(AGM8) if ¬ψ /∈ B K (φ), then [B K (φ) ∪ {ψ}]P L ⊆ B K (φ ∧ ψ).AGM1 requires the revised belief set to be deductively closed. AGM2 requires that the information be believed. AGM3says that beliefs should be revised minimally, in the sense that no new formula should be added unless it can be deducedfrom the information received and the initial beliefs.4 AGM4 says that if the information received is compatible with theinitial beliefs, then any formula that can be deduced from the information and the initial beliefs should be part of therevised beliefs. AGM5 requires the revised beliefs to be consistent, unless the information φ is a contradiction (that is, ¬φis a tautology). AGM6 requires that if φ is propositionally equivalent to ψ then the result of revising by φ be identical tothe result of revising by ψ . AGM7 and AGM8 are a generalization of AGM3 and AGM4 that“applies to iterated changes of belief. The idea is that if B K (φ) is a revision of K [prompted by φ] and B K (φ) is to bechanged by adding further sentences, such a change should be made by using expansions of B K (φ) whenever possible.More generally, the minimal change of K to include both φ and ψ (that is, B K (φ ∧ ψ)) ought to be the same as theexpansion of B K (φ) by ψ , so long as ψ does not contradict the beliefs in B K (φ)” (Gärdenfors [12], p. 55; notationchanged to match ours).5We now turn to a semantics for belief revision, using structures that are known in rational choice theory as choicefunctions. We shall call them choice frames.2 Thus Φ is defined recursively as follows: if p ∈ A then p ∈ Φ and if φ, ψ ∈ Φ then ¬φ ∈ Φ and (φ ∨ ψ) ∈ Φ.∗φ or K ∗ φ instead of B K (φ), but for our purposes the latter notation is clearer.3 In the literature it is common to use the notation K4 For every formula ψ , ψ ∈ [K ∪ {φ}]P L if and only if (φ → ψ) ∈ K (since, by hypothesis, K = [K ]P L ).5 The expansion of B K (φ) by ψ is [B K (φ) ∪ {ψ}]P L . Note, again, that, for every formula χ , χ ∈ [B K (φ) ∪ {ψ}]P L if and only if (ψ → χ ) ∈ B K (φ) (since,by AGM1, B K (φ) = [B K (φ)]P L ).\f1196G. Bonanno / Artificial Intelligence 173 (2009) 1194–12033. Choice frames and AGM belief revisionDefinition 2. A choice frame is a triple (cid:4)Ω, E, f (cid:5) whereΩ is a non-empty set of states (or possible worlds); subsets of Ω are called events.E ⊆ 2Ω is a collection of events (2Ω denotes the set of subsets of Ω ) such that ∅ /∈ E and Ω ∈ E .f : E → 2Ω is a function that associates with every event E ∈ E an event f (E) satisfying the following properties:(1) f (E) ⊆ E and (2) f (E) (cid:9)= ∅.In rational choice theory a set E ∈ E is interpreted as a set of available alternatives and f (E) is interpreted as the subsetof E which consists of the chosen alternatives (see, for example, [22] and [24]). In our case, we think of the elements ofE as possible items of information and the interpretation of f (E) is that, if informed that event E has occurred, the agentconsiders as possible all and only the states in f (E). The set f (Ω) is interpreted as the states that are initially consideredpossible.6In order to interpret a choice frame (cid:4)Ω, E, f (cid:5) in t",
            {
                "entities": [
                    [
                        138,
                        177,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 224 (2015) 1–27Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAn SMT-based approach to weak controllability for disjunctive temporal problems with uncertainty ✩Alessandro Cimatti a, Andrea Micheli a,b,∗a Fondazione Bruno Kessler, Istituto per la Ricerca Scientifica e Tecnologica, Via Sommarive 18, 38123 Povo, Trento, Italyb Doctoral School in Information and Communication Technology, University of Trento, Via Sommarive 9, 38123 Povo, Trento, Italy, Marco Roveri aa r t i c l e i n f oa b s t r a c tArticle history:Received 11 November 2013Received in revised form 27 February 2015Accepted 5 March 2015Available online 12 March 2015Keywords:Weak controllabilityTemporal problemsSatisfiability modulo theoryStrategy synthesisThe framework of temporal problems with uncertainty (TPU) is useful to express temporal constraints over a set of activities subject to uncertain (and uncontrollable) duration. In this work, we focus on the most general class of TPU, namely disjunctive TPU (DTPU), and consider the case of weak controllability, that allows one to model problems arising in practical scenarios (e.g. on-line scheduling).We first tackle the decision problem, i.e. whether there exists a schedule of the activities that, depending on the uncertainty, satisfies all the constraints. We propose a logical approach, based on the reduction to a problem of Satisfiability Modulo Theories (SMT), in the theory of Linear Real Arithmetic with Quantifiers. This results in the first implemented solver for weak controllability of DTPUs.Then, we tackle the problem of synthesizing control strategies for scheduling the activities. We focus on strategies that are amenable for efficient execution. We prove that linear strategies are not always sufficient, even in the sub-case of simple TPU (STPU), while piecewise-linear strategies, that are multiple conditionally-applied linear strategies, are always sufficient. We present several algorithms for the synthesis of linear and piecewise-linear strategies, in case of STPU and of DTPU.All the algorithms are implemented on top of SMT solvers. We provide experimental evidence of the scalability of the proposed techniques, with dramatic speed-ups in strategy execution compared to on-line reasoning.© 2015 Elsevier B.V. All rights reserved.1. IntroductionMany practical settings, such as planning and scheduling, require the solution of sets of constraints over time points, that typically represent the time at which activities begin and end. For example, constraints may represent a bound on the overall time span, or lower/upper bounds on the distance between two activities.The Temporal Problem (TP) [18,36] is a well studied formalism to model such temporal constraints. In the basic form of TP, also referred to as TP without uncertainty, the durations of activities are assumed to be controllable by the executor. This means that the executor assumes to have the possibility of choosing any duration that it may want. A solution is an assignment to all the time points (i.e., the beginning time and the end time of the activities), that satisfies the constraints. ✩This paper is an extended version of [10] published at AAAI 2012, Toronto, Canada.* Corresponding author.E-mail addresses: cimatti@fbk.eu (A. Cimatti), amicheli@fbk.eu (A. Micheli), roveri@fbk.eu (M. Roveri).http://dx.doi.org/10.1016/j.artint.2015.03.0020004-3702/© 2015 Elsevier B.V. All rights reserved.\f2A. Cimatti et al. / Artificial Intelligence 224 (2015) 1–27Depending on the structure of the constraints, TPs range from simple temporal problems (STP) [18], to temporal constraint satisfaction problems (TCSP) [18], to disjunctive temporal problems (DTP) [36].In practice, activities may also have uncertain (and uncontrollable) durations. For example, it may be impossible to know precisely the time taken by a drilling or locomotion procedure; yet, the production of an overall schedule must be able to take this uncertainty into account. The formal framework of TPs has been extended with uncertainty (TPU), thus obtaining STPU, TCSPU, and DTPU [38,32,37]. Because of uncertainty, TPUs are much more complicated than TPs without uncertainty. In fact, they can be thought in terms of games, where the scheduler/executor must play against an “adversarial” envi-ronment. Intuitively, the variables representing the time points are separated into controllable ones (that are existentially quantified), and uncontrollable ones (universally quantified).Within this setting, several degrees of solution have been identified for TPUs [38]. In strong controllability, a solution is a fixed, unconditioned assignment to each controllable time point, that will satisfy the constraints regardless of the uncontrollable duration of the activities. This corresponds to devising a time-triggered program, where activities are started at fixed times.In dynamic controllability, a solution is a strategy where the values of controllable variables may depend on the values of the uncontrollable ones, as long as they can be observed, i.e. they occur in the past. The corresponding execution must deal with branching, and may interleave the start of activities with the observation of the uncontrollable (but observable) “end of activity” events.In this paper we focus on weak controllability, that is concerned with the existence of a strategy that associates values to the controllable starting points of each activity, as a function of the uncontrollable durations. The values for the uncon-trollable durations are not known at the moment of solving the problem; however, the executor is given the actual value of such durations just before the execution starts.There are several reasons for studying weak controllability. From the temporal problems perspective, weak controllabil-ity is a conceptually interesting dual of the strong controllability problem. In addition, deciding whether a given TPU is weakly controllable may serve as a pre-check for more complex problems such as dynamic controllability. In fact, weak controllability is a necessary condition for dynamic controllability [38].From the practical standpoint, weak controllability allows for the modeling of a setting where a number of tasks is to be repeatedly executed, but with modalities that depend on some environmental parameters that become available just prior to execution. For example, an automated production line may be required to perform a set of activities, whose duration functionally depends on the measured size of the objects to be manipulated. The duration of the activities is unknown a priori, except for an upper and lower bound, but it becomes precise once the actual objects materialize. Similarly, in a multi-core processor, the power management may dynamically control the actual clock speeds, thus affecting the duration of jobs. An on-line scheduler may be required to decide the appropriate allocation based on information that may be made available by the power management unit. Another example of application is given in the setting of remote systems (such as space exploration rovers or satellites), where the degradation due to use causes many activities to change duration over time. For example, the movement speed of many components may decrease with the age of the system. These domains share the fact that the tasks may be repeated multiple times, on platforms of limited capacity, and in conditions that can be estimated prior to execution. As such, they can be encoded as weak controllability problems.In this paper, we tackle weak controllability for DTPUs (i.e. in its most general form), making the following contributions. First, we propose a general decision procedure for the problem of weak controllability for DTPUs. Our approach makes use of the framework of Satisfiability Modulo Theory (SMT) [4], a formal framework that allows for the analysis of problems in decidable fragments of First Order Logic. The decision procedure is based on a reduction to an SMT problem for the theory of Quantified Linear Real Arithmetic (LRA). The encoding can be thought as working by refutation: we state the existence of an assignment to uncontrollable time points that cannot be countered by any controllable assignment. This means that the SMT problem is satisfiable if and only if the TPU is not weakly controllable. The problem can thus be directly provided to an efficient SMT solver. This approach accounts for the first implemented decision procedure for weak controllability of DTPUs.Then, we investigate the problem of on-line strategy execution, i.e. given a weakly controllable DTPU, how to repeatedly produce a suitable schedule for the controllable time points as a function of a valuation to the uncontrollable ones. We propose an approach, referred to as implicit strategy execution, based on the run-time execution of a solver for TP without uncertainty: any valuation to the uncontrollable durations removes the uncertainty from the problem, and thus transforms the TPU at hand into a TP. The solver is then invoked to solve the consistency problem yielding an assignment to the controllable time points. Unfortunately, this solution imposes strong requirements on the run-time: most notably, the control platform must support the execution of a solver; in addition, at each iteration it is required to solve an NP-hard problem, i.e. a DTP (without uncertainty).This motivates the investigation of efficient run-time execution for weakly controllable TPUs. We analyze the spectrum of explicit strategies, expressed in a form that does not require reasoning, and can thus be directly evaluated. We consider linear strategies, that are strategies in which the values for the controllable time points are a linear function of the uncontrollable ones; and piecewise-linear strategies, that are combinations of different linear strategies, each associated with an activation condition defined over",
            {
                "entities": [
                    [
                        133,
                        229,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 245 (2017) 115–133Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAn initial study of time complexity in infinite-domain constraint satisfactionPeter Jonsson a, Victor Lagerkvist b,∗a Department of Computer and Information Science, Linköping University, SE-581 83 Linköping, Swedenb Institut für Algebra, TU Dresden, 01069 Dresden, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 6 November 2015Received in revised form 9 January 2017Accepted 25 January 2017Available online 27 January 2017Keywords:Constraint satisfactionInfinite domainTime complexityThe constraint satisfaction problem (CSP) is a widely studied problem with numerous applications in computer science and artificial intelligence. For infinite-domain CSPs, there are many results separating tractable and NP-hard cases while upper and lower bounds on the time complexity of hard cases are virtually unexplored. Hence, we initiate a study of the worst-case time complexity of such CSPs. We analyze backtracking algorithms and determine upper bounds on their time complexity. We present asymptotically faster algorithms based on enumeration techniques and we show that these algorithms are applicable to well-studied problems in, for instance, temporal reasoning. Finally, we prove non-trivial lower bounds applicable to many interesting CSPs, under the assumption that certain complexity-theoretic assumptions hold. The gap between upper and lower bounds is in many cases surprisingly small, which suggests that our upper bounds cannot be significantly improved.© 2017 Elsevier B.V. All rights reserved.1. IntroductionThis introductory section is divided into three parts: we begin by motivating our work, continue by discussing the problems that we study, and finally briefly present our results.1.1. MotivationThe constraint satisfaction problem over a constraint language (cid:2) (CSP((cid:2))) is the problem of finding a variable assignment which satisfies a set of constraints, where each constraint is constructed from a relation in (cid:2). This problem is a widely studied computational problem and it can be used to model many classical problems such as k-coloring and the Boolean satisfiability problem, in a natural and uniform way. In the context of artificial intelligence, CSPs have been used for for-malizing a wide range of problems, cf. Rossi et al. [55]. Efficient algorithms for CSP problems are hence of great practical interest. If the domain D is finite, then a CSP((cid:2)) instance I with variable set V can be solved in O (|D||V | · poly((cid:3)I(cid:3))) time by enumerating all possible assignments. Hence, we have an obvious upper bound on the time complexity. This bound can, in many cases, be improved if additional information about (cid:2) is known, cf. the survey by Woeginger [65] or the textbook by Gaspers [29]. There is also a growing body of literature concerning lower bounds [34,39,42,61].* Corresponding author.E-mail addresses: peter.jonsson@liu.se (P. Jonsson), victor.lagerqvist@tu-dresden.de (V. Lagerkvist).http://dx.doi.org/10.1016/j.artint.2017.01.0050004-3702/© 2017 Elsevier B.V. All rights reserved.\f116P. Jonsson, V. Lagerkvist / Artificial Intelligence 245 (2017) 115–133When it comes to CSPs over infinite domains, there is a large number of results that identify polynomial-time solvable cases, cf. Ligozat [45] or Rossi et al. [55]. However, almost nothing is known about the time complexity of solving NP-hard CSP problems. One may conjecture that a large number of practically relevant CSP problems do not fall into the tractable cases, and this motivates a closer study of the time complexity of hard problems. Thus, we initiate such a study in this article.1.2. Computational problemsAssume that we are given an instance of CSP((cid:2)) where (cid:2) is a constraint language over an infinite domain. Which upper bounds can we provide for CSP((cid:2))? Clearly, the method for finite-domain CSPs, based on enumerating all possible variable assignments, no longer work since the domain is infinite. In fact, infinite-domain CSPs are in general undecidable [7]. A first step is therefore to only consider decidable infinite-domain CSPs. However, even for such problems, for every recursive function, one can find a decidable CSP problem which cannot be solved faster than this [4]. Hence, we first need to fix a class of constraint languages X such that CSP((cid:2)) is included in a reasonable complexity class for every (cid:2) ∈ X . Througout this article we exclusively study the case when CSP((cid:2)) is included in NP, since this is a natural and well-studied class of problems. However, when considering CSPs over infinite domains, representational issues also become highly important. A relation in a finite-domain CSP problem is easy to represent by simply listing the allowed tuples. When considering infinite-domain CSPs, the relations need to be implicitly represented. A natural way is to consider disjunctive formulas over a finite set of basic relations. Let B denote some finite set of basic relations such that CSP(B) is tractable. Let B∨ω denote the closure of B under finitary disjunctions, and let B∨k be the subset of B∨ω containing only disjunctions of length at most k. We first consider a finite-domain example for illustrative purposes: let D = {true, false} and let B = {B 1, B2} where B1 = {true} and B2 = {false}. In other words a unary constraint of the form B 1(x) forces the variable x to be mapped to true, and B2( y) forces the variable y to be mapped to false. It is then easy to see that CSP(B∨ω) corresponds to the Boolean SAT problem while CSP(B∨k) corresponds to the k-SAT problem. Early examples of disjunctive constraints over infinite-domains can be found in, for instance, temporal reasoning [43,37,58], reasoning about action and change [26], and deductive databases [41]. More recent examples include interactive graphics [48], rule-based reasoning [46], and set constraints (with applications in descriptive logics) [10]. There are also works studying disjunctive constraints from a general point of view [16,21] but they are only concerned with the separation of polynomial cases from NP-hard cases, and do not further investigate the time complexity of the hard cases.There is also an important connection to constraint languages containing first-order definable relations (see Section 2.2for details). Assume (cid:2) is a finite constraint language containing relations that are first-order definable in B, and that the first order theory of B admits quantifier elimination. Then, upper bounds on CSP((cid:2)) can be inferred from results such as those that will be presented in Sections 3 and 4. This indicates that studying the time complexity of CSP(B∨ω) is worthwhile, especially since our understanding of first-order definable constraint languages is rapidly increasing [8].CSPs in certain AI applications are often based on binary basic relations and unions of them (instead of free disjunctive formulas). This is the predominant way of representing constraints in, for instance, spatial reasoning. Clearly, such relations are a subset of the relations in B∨k and we let B∨=denote this set of relations. We do not explicitly bound the length of disjunctions since they are bounded by |B|. The literature on such CSPs is voluminous and we refer the reader to Renz and Nebel [54] for an introduction. We remark that there exists examples of undecidable CSP problems over constraint languages of the form B∨=[32]. Hence, even for such restricted problems it is impossible to give general upper bounds, unless additional restrictions are imposed on the set B of basic relations.1.3. Our resultsThroughout the article, we primarily measure time complexity in the number of variables. Historically, this has been the most common way of measuring time complexity: the vast majority of work concerning finite-domain CSPs concentrates on the number of variables. One reason for this is that an instance may be massively larger than the number of variables — a SAT instance I = (V , C) (where V is the set of variables and C is the set of clauses) may contain up to 22|V |distinct clauses if repeated literals are disallowed — and measuring in the instance size may give far too optimistic figures. This may be quite detrimental since naturally appearing test examples tend to contain a moderate number of constraints. In light of |V | · poly((cid:3)I(cid:3))) time (where (cid:3)I(cid:3) denotes the total this, it is much more informative to know that SAT can be solved in O (2(cid:3)I(cid:3) · poly((cid:3)I(cid:3))) time (which number of bits needed for representing I ) instead of merely knowing that it is solvable in O (2|V | · poly((cid:3)I(cid:3))) that increasing of course is true since |V | ≤ (cid:3)I(cid:3)). For instance, we immediately conclude from the bound O (2the number of variables increases the run time much more rapidly than increasing the number of clauses. This is something (cid:3)I(cid:3) · poly((cid:3)I(cid:3))).that one cannot immediately infer from the bound O (2Let us now turn to the time complexity of solving infinite-domain CSPs. To solve such problems in practice, backtracking algorithms are usually employed. The literature on heuristically guided backtracking algorithm and empirical analyses of such algorithms is huge: we refer the reader to any good textbook (such as Dechter [24] or the handbook edited by Rossi et al. [55]) on constraint satisfaction for more information about this. What we find lacking in the literature are analyses of the asymptotical performance of such algorithms, i.e. their worst-case behavior. Unfortunately, we show in Section 3that they can be highly inefficient in the worst case. Let p denote the maximum arity of the relations in the set of basic \fP. Jonsson, V. Lagerkvist / Artificial Intelligence 245 (2017) 115–133117relations B, let m = |B|, and let |V | d",
            {
                "entities": [
                    [
                        136,
                        214,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 80 (1996) 29-93 Artificial Intelligence Diagnosis based on explicit means-end models Jan Eric Larsson * Department of Automatic Control, Lund Institute of Technology, Box 118, S-221 00 Lund, Sweden Received June 1993; revised March 1994 Abstract validation, This artrcle describes three diagnostic methods for use with industrial processes. They are i.e., consistency checking of sensor and measurement values using any measurement redundancy of instrumentation; alarm analysis, i.e., analysis of multiple alarm situations to find which alarms ate directly connected to primary faults and which alarms are consequential effects of the primary ones; andfault diagnosis, i.e., a search for the causes of and remedies for faults. The three methods use multilevel Jaw models (MFM), to describe the target process. They have been implemented in the real-time expert system tool G2, in C, and in Common Lisp, and successfully tested on simulations of several processes. The knowledge representation ontology used is based on the notion of$ows, of mass, energy, and information, which are used to describe physical systems. The relationships between structure and function of a system is described by teleological relations, which connect the flow structures into a graph, built at model construction time. This allows the diagnostic reasoning to be implemented as searchers in a static graph structure, and it can thus be performed extremely rapidly. As with other model-based approaches, general algorithms are used over a representation with generative capacities. The representation gains strength from being functional with a very abstract physical level, more abstract than most qualitative physics models. It works well with systems that can be described using flows, while it currently lacks the capability of capturing important aspects of other types of systems, for example, electronic circuits. * This arti’cle is based on the author’s doctor’s of Automatic Control, Lund the Department fellowship visit at Knowledge Institute of ‘Technology, Lund, Sweden, and on work done during a postdoctoral Stanford University, Palo Alto, CA. Current address: Knowledge Systems Laboratory, Systems Laboratory, Department of Computer Science, Stanford University, 701 Welch Road, Building C, Palo Alto, CA 94304, USA. thesis from 0004-3702/96/$15.00 SSDIOOO4-3702(94)00043-3 @ 1996 Elsevier Science B.V. All rights reserved \f30 J.E. LarssodArtificial In?elligence 80 (1996) 29-93 1. Introduction Diagnosis of industrial processes can be performed with different types of models. types in use today focus on physical structure and behavior, and for information. The latter is important to try and incorporate more teleological However, most model contain diagnosis, knowledge little or no means-end, i.e., teleological, though, and it seems to be worthwhile in model-based diagnosis. level of abstraction, This article describes diagnosis using one type of explicit means-end models, mul- [ 731. These are functional models of for a formal that in [ 79,801, and in [ 671. The following work is based on tilevel jaw models (MFM), as developed by Lind with a very high goals, or purposes, of the modeled language there are several minor differences between different versions of MFM, as presented [ 731, in Lind’s newer version the version described The contributions reasoning using MFM: combined with a teleological system. Lind has suggested a syntax ideas on how to use the MFM representation. Note in [ 671, while the latest definition of MFM appears of this article are descriptions in [ 79,801. for diagnostic and given general of three methods representation validation, l measurement 0 alarm analysis, l fault diagnosis. The measurement validation algorithm takes a set of measured to check consistency. A single erroneous flow values and uses is flow measurement redundancy any available marked and corrected. of measurements If there are several conflicting are marked but no flow value is corrected. values, the consistent subgroups The alarm analysis algorithm flow, highJlow, low volume, and high volume. Each alarm an MFM model, and the method recognizes are either primary or consequences of the primary ones. takes as input a set of alarm states such as normal, low is associated with a part of the primary alarms, while the other alarms The fault diagnosis algorithm uses an MFM model ing” style of diagnosis. The input can come from questions from measured signals and triggering of rules. The system explanations, and gives remedies. to produce a “backward chain- answered by the user or looks for faults, provides 2. The basic concepts of MFM An MFM model has been designed three basic concept is a normative description of a system, a representation to do, how it should do it, and with what it should do it. Thus, types of MFM are: of what it the 0 goals, l functions, l physical components. The goals are the objectives or purposes of the system, structors and operators want the system the goals are obtained, that the con- to reach. The functions are the means by which i.e., the powers or capabilities of the system. The physical com- i.e., the ends \fJ.E. L.ursson/Art$cial Intelligence 80 (1996) 29-93 31 Fig. 1. Goals, functions, components, are connected while the components relations, but this is not shown via condition and relations. The functions are connected to functions via realize relations. Subgoals may be connected to goals via achieve relations, to functions in the figure. All three kinds of relations are many-to-many. ponents are what the system is constructed The go,&, and components from, the equipment of which it consists. depend on each other in specific ways. Thus, in MFM types of relations, that can be used to connect the objects: functions, there are different relations, relations, relations. l achieve l condition 0 realize An achieve functions are used to obtain into a tank could be used enough. A condition relation connects relation connects a set of functions that goal. For example, to achieve the goal of keeping to a goal, and it signifies that these the function of transporting water the level of the tank high in order for the function be fulfilled case for a mass transport electrical power to the pump must be fulfilled flow. function a goal to a function, and signifies to be available. For example, that the goal must this would be the realized as a pump, where the subgoal of delivering to drive the mass in order for the pump A reaZi:~e relation connects a physical component is used to realize or implement that the to a function, and signifies the function. For example, a pump could be component used to realize a mass transport function. to observe It is important that all the relations can be many-to-many. Several functions can be usNed to achieve one goal, one function may satisfy several goals, one goal can by several goals, be a condition one function can implement can be realized with many different components, functions, one function may be conditioned and one component several different see Fig. 1. to several functions, MFM dlemands that goals, functions, that functions and physical components are separate entities. The assumption from components no function in structure assumption of qualitative physics. In addition assumes by the designer during model construction. that the goals are not given by separate functions. Instead be viewed as separate to the is similar to this, MFM also they must be stated 3. Goals The concept of a goal to MFM, as it is the representational is central It is important part to be able to recognize in every activity using means-end device for and describe goals, as information. Without teleologic,al information. they play an important \f32 J.E. Lmsson/Art$cial Intelligence 80 (1996) 29-93 knowing broad definition of a goal is as follows: the goals, it is more or less impossible to know the available functions. A A goal is the outcome towards which certain activities of a system are directed. However, specific descriptions. Thus, three different this definition types of goals are recognized: is very general, and it is useful to narrow it down to more l production goals, 0 safety goals, l economy goals. Production goals A production goal is used to express that to enable production, some specific process i.e., that an inequality of the following variable should be kept within a specified form should be satisfied: general interval, Of course, one of the limits could be infinitely system will be kept in a certain state, where production small or large. This means is indeed possible. that the Safety goals to express A safety goal process variable interval, case is probably a one-sided should be kept within safe regions, that for reasons of safe operation, is used some specific should be kept above or below some value, or inside or outside an the same test as for a production goal. However, a more common that some process variables this means far enough from dangerous values. i.e., essentially In practise, interval. Economy goals An economy goal is used to express considerations of overall process optimization. to a rather complex function G( xt , x2, x3, . . .) , depending efficiency. The satisfaction could be expressed Thus, it is typically connected on operational as satisfaction of the following constraints and economical inequality: Go < G(Xl,X2,X3,...) < Gl, where GO and Gt are numerical tory efficiency. i.e., an inequality of the following It would also be possible form: limits inside which the system is working with satisfac- to define an economy goal as an optimization, Often, however, translated it is impossible to use this form directly. into one of the earlier forms in order to be useful. Instead, the test must be \fJ.E. LmssodArtijcial Intelligence 80 (1996) 29-93 33 4. Functions The second important concept of MFM is that of afunction. In the context of processes it is possible to find several interpre",
            {
                "entities": [
                    [
                        64,
                        108,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 164 (2005) 1–22www.elsevier.com/locate/artintA formal analysis of why heuristic functions workB. John Oommen a,∗,1, Luis G. Rueda b,2a Senior Member, IEEE. School of Computer Science, Carleton University, 1125 Colonel By Dr.,Ottawa, ON, K1S 5B6, Canadab School of Computer Science, University of Windsor, 401 Sunset Ave., Windsor, ON, N9B 3P4, CanadaReceived 10 May 2001AbstractMany optimization problems in computer science have been proven to be NP-hard, and it is un-likely that polynomial-time algorithms that solve these problems exist unless P = NP. Alternatively,they are solved using heuristics algorithms, which provide a sub-optimal solution that, hopefully,is arbitrarily close to the optimal. Such problems are found in a wide range of applications, in-cluding artificial intelligence, game theory, graph partitioning, database query optimization, etc.Consider a heuristic algorithm, A. Suppose that A could invoke one of two possible heuristic func-tions. The question of determining which heuristic function is superior, has typically demanded ayes/no answer—one which is often substantiated by empirical evidence. In this paper, by using Pat-tern Classification Techniques (PCT), we propose a formal, rigorous theoretical model that providesa stochastic answer to this problem. We prove that given a heuristic algorithm, A, that could utilizeeither of two heuristic functions H1 or H2 used to find the solution to a particular problem, if theaccuracy of evaluating the cost of the optimal solution by using H1 is greater than the accuracy ofevaluating the cost using H2, then H1 has a higher probability than H2 of leading to the optimal solu-tion. This unproven conjecture has been the basis for designing numerous algorithms such as the A*algorithm, and its variants. Apart from formally proving the result, we also address the correspond-ing database query optimization problem that has been open for at least two decades. To validateour proofs, we report empirical results on database query optimization techniques involving a fewwell-known histogram estimation methods. 2005 Elsevier B.V. All rights reserved.* Corresponding author.E-mail addresses: oommen@scs.carleton.ca (B.J. Oommen), lrueda@scs.carleton.ca (L.G. Rueda).1 Partially supported by NSERC, the Natural Science and Engineering Research Council of Canada. Fellow ofthe IEEE.2 This work was partially supported by Departamento de Informática, Universidad Nacional de San Juan,Argentina, and by NSERC. Member of the IEEE.0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2002.02.001\f2B.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–22Keywords: A* algorithms; Heuristic algorithms; Pattern recognition; Optimization1. Introduction1.1. OverviewThe area of computer science has still quite a few open, unsolved problems. In thispaper, we are concerned with one such problems, namely that of using heuristics to solveoptimization problems.Any arbitrary optimization problem3 is typically defined in terms of instances which aredrawn from a (finite) set, X , an objective function, and some feasibility functions. The aimis to find an (and hopefully, the unique) instance of X , which leads to the maximum (or theminimum) value of the objective function subject to the feasibility constraints. A formaldefinition of an optimization problem can be found in [10]. But to be more specific, con-sider the well-known Traveling Salesman Problem (TSP), in which the cities are numberedfrom 1 to n, and the salesman starts from city 1, visits every other city once, and returnsto city 1. An instance of X is a permutation of the cities, for example, 1 4 3 2 5, if weare considering a world consisting of five cities. The objective function for that instance,f (1 4 3 2 5) is obtained by performing the summation of the inter-city distances: 1 → 4,4 → 3, 3 → 2, 2 → 5, and 5 → 1. The optimal solution is the instance that minimizes thevalue of f .A heuristic algorithm is an algorithm that attempts to find a certain instance of X thatmaximizes f (or the profit) by iteratively invoking a heuristic function. The instance thatmaximizes f will be the optimal solution4 to the optimization problem. A heuristic is amethod that performs one or more modifications to a given solution or instance, in order toobtain a different solution which is either superior, or which leads to a superior solution.The heuristic, in turn, invokes a heuristic function, which estimates (or measures) the costof the solution at the particular state in the search process. This is the context in which weuse these terms.Many heuristic algorithms and heuristic functions have been reported in the literature,where the former include the alpha-beta search [11], backtracking, hill-climbing [10], sim-ulated annealing [1], genetic algorithms [13], tabu search [7], learning automata [15], etc.The issue of how heuristic functions are used in such heuristic algorithms in searching,game playing, etc., can be found in [16,24] and is, indeed, an enormous field of study initself. This question is not addressed here.To clarify issues, let us consider the classical n-puzzle problem [16]. This problem con-sists of a square board containing n square tiles and an empty position called the “blank”.The aim is to rearrange the tiles from some pre-defined (usually random) initial configura-tion into a pre-determined goal configuration, by sliding any tile adjacent to the blank into3 Every optimization problem can also be formulated as a decision problem [6].4 We use the term “solution” to refer to an element x ∈ X , and the term “profit” to refer to the value of f (x).In minimization problems, f (.) will be a cost function.\fB.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–223the blank position. A heuristic algorithm solves this problem by examining, using a heuris-tic function, some of the possible valid movements. Viewed from the perspective of theunderlying state graph, the possible states encountered at the next level form the childrennodes of the current node in the search structure. Other variants of heuristic algorithmsinvolve the examination of lower levels as well. The breadth-first search and depth-firstsearch schemes are examples of heuristic algorithms, useful in any such problem solvingstrategy. An example of a heuristic function, however, is the measurement (or estimate) ofthe number of tiles that are out of place. Another measure is the sum of the depth of thenode and the number of tiles that are out of place.One of the better-known solutions to the n-puzzle problem is the A* algorithm. Thisalgorithm is a graph search algorithm that is used to find the path of minimum cost betweentwo nodes, the start node and the goal node. The A* maintains a tree which stores the pathsthat are already explored. Using these paths, a measure, f , of the potential advantage ofchoosing each path is calculated. The value of f , which is the cost of traversing the graphbetween two nodes, can be calculated by using different heuristic functions. A heuristic issaid to be admissible, and the A* converges to the correct result, if the heuristic function isan upper bound of the true cost from all nodes to the goal node.In general, for any arbitrary problem, the question of how useful a heuristic functionis, in determining the cost of traversing from one node to another, has no known analyticsolution—it has traditionally been empirically analyzed. In this paper, we present a formalanalysis that provides a stochastically positive answer to the question of comparing therelative advantages of potential heuristic functions.The A* algorithm and its variants (like the A+ algorithm) have also been success-fully applied to other problems, such as object recognition using deformable templates[16,26,28]. Various solutions to optimization problems using different heuristic functionsare found in [28]; we shall use this paper, [28], to highlight the difference between theheuristic algorithms, and the effect of the same algorithm using various potential heuristicfunctions. The authors of [28] address the problem of tracking roads in satellite imagesusing the twenty-question search paradigm, and the A+ algorithm, a “cousin” of the A*algorithm. Using these algorithms the roads can be represented in terms of straight-linesegments. The various paths are expanded by the application of an ensemble of heuristicfunctions. One such heuristic function is the one based on the conditional entropy mea-surements of the branches, which are used to choose the most “promising” path. Whilethe paper discusses other heuristic functions, the question of how one can compare thesolutions obtained using the various heuristic functions is achieved by comparing the em-pirical simulation results. We hope that our formal analysis can be a tool to achieve a morerigorous comparison of these heuristic functions in [28], and other similar scenarios.5The tools we propose to use are drawn from the well-established theory of PatternRecognition (PR) [5,27]—a prominent field of machine intelligence. Broadly speaking, PRinvolves decision-making, based on a priori and learned knowledge of the classes and ob-jects being recognized. More specifically, the system learns information about the features5 The model presented here has some limitations when investigating the quality of solutions yielded by anA*-like algorithm. These limitations will be discussed in a later sub-section.\f4B.J. Oommen, L.G. Rueda / Artificial Intelligence 164 (2005) 1–22of a set of classes. Subsequently, given an object of unknown identity, and this informa-tion, the system attempts to recognize the unknown object as belonging to one of the knownclasses with some arbitrary accuracy. Necessarily, our overview of PR is brief!There are many applications of PR, including face and speech recognition, fingerprintidentification, character recognition, medical diagnosis, etc. I",
            {
                "entities": [
                    [
                        69,
                        118,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 74 (1995) 55-81 Artificial Intelligence Inductive functional programming using incremental program transformation Roland Olsson * Department of Computer Science. &fold College, OS Alle’ 9, 1777 Halden, Norway Received April 1993; revised March 1994 Abstract The paper presents a system, ADATE, for automatic functional programming. ADATE uses specifications that contain few constraints on the programs to be synthesized and that allow a wide range of correct programs. ADATE can generate novel and unexpected recursive programs with automatic invention of recursive auxiliary functions. Successively better programs are developed using incremental program transformations. A key to the success of ADATE is the exact design of these transformations. and how to systematically search for appropriate transformation sequences. 1. Introduction This paper reports on a system, ADATE& that synthesizes recursive Standard ML programs using a specification consisting of sample inputs and an output evaluation function. The name ADATE, Automatic Design of Algorithms Through Evolution, in- dicates that the goal of the research is automatic invention of new algorithms and not only automatic implementation of algorithms that the ADATE user already knows. One major dimension along which to differentiate inductive inference systems is the amount of information in the specifications that they employ. At one extreme are [ 11. At the same end of the spectrum are systems that use traces of computations systems requiring specifications that consist of input-output pairs [ 2,8, lo] or positive In such systems, and negative examples as in inductive logic programming [ 6,7,9,12]. the input-output pairs or the examples must have a structure that corresponds to a specific algorithm. * E-mail: Roland.Olsson@hiof.no. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00042-5 \f56 R. Olsson/Artifcial Intelligence 74 (1995) 55-81 such that the ratio between At the other end of the spectrum are genetic algorithm [ 51 and ADAm, which use specifications the difficulty of writing a desirable program and the difficulty of specification may be enormous. An important difference recursive between ADATE and GA systems search programs of the program space. is that the latter are very poor at inferring they use primitive program and an unsystematic (GA) systems transformations since syntactic complexity space. Section 3 presents the search of the program Section 2 explains how to specify programs and gives measures of program quality and time complexity. These measures are used such as correctness, the subset of Standard to guide ML in which inferred programs are written. Programs are synthesized using incremental transformations replace- ment, function and type embedding. The overall strategy the program space is given in Section 5. This strategy is based on iterative- for searching details and experimental deepening results. The next section discusses that are related to ADATE. The final section contains merits and drawbacks with ADATE and directions [ 41. Sections 6 and 7 list implementation systems in Section 4. These transformations as discussed abstraction, for future research. case-distribution are expression inference inductive 2. Specification and selection of programs A specification wants a program chosen specification are: implicitly defines a set C of correct programs. The specification writer for a from a set D of desirable programs. Some requirements ( 1) The specification should be as easy as possible to write and preferably be much simpler than any desirable program. (2) The specification (3) All desirable programs should facilitate efficient inference. should be correct according to the specification, i.e., D C C. (4) A computer correct. should reasonably quickly be able to decide if a given program is ( 1) and (2) are often in conflict. One main goal of the research presented to be as simple as possible. The only efficiency that were should be possible using computers inferences Requirements in this paper was to allow specifications goal was that many generally available A specification interesting in 1993. that satisfies requirement that eliminate if requirement does not contain constraints are loose. Even in comparison with the programs very simple the well-known NP-hard problems can be used to construct employ sample inputs and an output evaluation 4 is satisfied, that satisfy function. (3) is said to be loose. A loose specification desirable programs. ADATE specifications there are still many specifications that are them. For example, most of such specifications, which Example 2.1. Assume that the specification writer knows the minimum I. It is easy to construct of nodes. Here is a simple specification of a program P. that I is a large instance of the traveling salesman problem and cycle on in time O(n*), where n is the total number length &ii, of a Hamiltonian such an instance \fR. Olsson/Artijicial Intelligence 74 (1995) 55-81 57 Given input I, P is required to output a Hamiltonian cycle C of length &, less than n2/106 CPU seconds. in Note that it takes time O(n) to check if C is a Hamiltonian cycle of length L,,,,t,. The correctness of P is thus decidable in time 0(n2/106) + O(n) = 0(n2) even though P may be extremely difficult to find. The Journal of Algorithms maintains a list with hundreds of NP-complete problems that can be used to construct similar specifications. 2.1. Specijcation form Assume that a specification is to be used to check a synthesized ML program P. P is a definition of a function f which is an approximation of a desirable function. An ADAm specification consists of ( 1) a set of types, (2) (3) (4) a set of sample inputs { It, 12, . . ., Z# I }, evaluation (5) an output the primitive functions that are to be used in inferred programs, the type of f, function oe, which uses the set { (Zt , f( II)), . . ..(Z+YI.~(Z+YI))} torate P. The sample inputs need to be chosen so that incremental inference is facilitated. This means that the inputs should contain sufficiently many special cases. The sample inputs in the specification of a list sorting program may for example include an empty list, a singleton list, a sorted list and a few random lists. One interesting progression of more and more difficult sample inputs would be the problems in mathematics textbooks, rang- ing from first grade in elementary school up to university level. Even if the specification writer may not need to be as “pedagogical” as the authors of such textbooks, the sample inputs still need to be carefully chosen. It is important that specifications are not required to be based on input-output pairs. We have identified the following four problems with input-output pair specifications. Problems. ( 1) The choice of output sometimes reflects the particular algorithm that was used to construct it. The specification writer needs to know this algorithm to be able to provide output. An inference system naturally becomes much less useful if the writer is required to know the algorithm to be inferred. (2) Looseness is lost if the pairs do not include all possible outputs for a given input. (3) An input-output pair specification grades an output as correct or wrong. It is often desirable to use more than two grades. For example, the grades can be all real numbers in some interval. (4) It may be too difficult for the user to provide optimal outputs. Here are four examples such that example number (i) illustrates problem number (i) . \f58 Examples. R. Ol.wm/Arti$cial Intelligence 74 (1995) 55-81 ( 1) Consider the specification of a function split : ‘a list -> ‘a list * ‘a list that splits a list Xs into a pair of lists (Ys , Zs) such that the lengths of Ys and Zs differ by at most one. The split is useful when implementing merge sort. The input-output function pair ([1,2,3,4,5,6,7,81, (l.l,2,3,4l,C5,6,7,8l>) reflects the particular algorithm obviously and Zs to the second half. However, and faster. that chooses Ys to the first half of Xs is both simpler the following split algorithm fun split nil = (nil,nil) I split (Xl::Xsl) = case split Xsl of (Ys,Zs) => (Xl::ZS,YS) An input-output pair that reflects this algorithm is thus ([1,2,3,4,5,6,7,81, (C1,3,5,71,[2,4,6,81)). Instead of giving outputs, function. Assume means output evaluation that Bs is a permutation that the function function computes it is much better to provide an output evaluation is-perm of As. Given is defined so that is_perm(As,Bs) (Ys, Zs), input Xs and output the is_perm(Xs,YsQZs) andalso abs(length Ys - length Zs) <= 1, where Q is the ML operator for list concatenation. (2) Problem (2) can be exemplified using ification only allowed programs of length Lmin, a program regarded as incorrect. The specification would tour exists. that produces another the above TSP specification. that produce a particular pre-determined If the spec- tour tour of length Lh” would be therefore not be loose if such a (3) This example illustrates intersects the usefulness of grades. Consider navigation of a poly- function the output evaluation any obstacle, compute if a given path, represented by a series of points and angles of the length and curvature of the path, gon among polygonal obstacles. When computing one might check rotation, the amount of rotation along the path and its safety i.e., margin In order consider choosing be difficult for the specification writer to provide optimal outputs i.e., Hamiltonian cycles of minimum to provide optimal outputs, It would then random graphs as inputs in the TSP specification. it may be problematic to obstacles. to illustrate length. that (4) 2.2. The output evaluation function Since the output evaluation in ADATE, the exact form of oe is described below. An inferred program may contain a special to be considered when defining oe. A ? constant means “don’t- constant, ?, that needs function oe is of fundamental i",
            {
                "entities": [
                    [
                        73,
                        146,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 220 (2015) 1–27Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSTR3: A path-optimal filtering algorithm for table constraints ✩Christophe Lecoutre a, Chavalit Likitvivatanavong b,∗a CRIL-CNRS UMR 8188, Université d’Artois, F-62307 Lens, Franceb School of Computing, National University of Singapore, 13 Computing Drive, Singapore 117417, Singapore, Roland H.C. Yap ba r t i c l e i n f oa b s t r a c tArticle history:Received 27 August 2014Received in revised form 3 December 2014Accepted 9 December 2014Available online 16 December 2014Keywords:Constraint satisfaction problemsGeneralized arc consistencyNon-binary constraintsBacktracking searchConstraint propagation is a key to the success of Constraint Programming (CP). The principle is that filtering algorithms associated with constraints are executed in sequence until quiescence is reached. Many such algorithms have been proposed over the years to enforce the property called Generalized Arc Consistency (GAC) on many types of constraints, including table constraints that are defined extensionally. Recent advances in GAC algorithms for extensional constraints rely on directly manipulating tables during search. This is the case with a simple approach called Simple Tabular Reduction (STR), which systematically maintains tables of constraints to their relevant lists of tuples. In particular, STR2, a refined STR variant is among the most efficient GAC algorithms for positive table constraints. In this paper, we revisit this approach by proposing a new GAC algorithm called STR3 that is specifically designed to enforce GAC during backtrack search. By indexing tables and reasoning from deleted values, we show that STR3 can avoid systematically iterating over the full set of current tuples, contrary to STR2. An important property of STR3 is that it can completely avoid unnecessary traversal of tables, making it optimal along any path of the search tree. We also study a variant of STR3, based on an optimal circular way for traversing tables, and discuss the relationship of STR3 with two other optimal GAC algorithms introduced in the literature, namely, GAC4 and AC5TC-Tr. Finally, we demonstrate experimentally how STR3 is competitive with the state-of-the-art. In particular, our extensive experiments show that STR3 is generally faster than STR2 when the average size of tables is not reduced too drastically during search, making STR3 complementary to STR2.© 2014 Elsevier B.V. All rights reserved.1. IntroductionAlgorithms that establish Generalized Arc Consistency (GAC) on constraint problems (networks) filter out inconsistent values from variable domains in order to reduce the combinatorial search spaces of such problems. They have been a staple of Constraint Programming (CP) since its origin in the field of Artificial Intelligence (AI) in the seventies, with for example the introduction of algorithms (G)AC3 [2] and (G)AC4 [3,4]. Typically, GAC is enforced at each step of a complete backtrack ✩This is an expansion of the article which previously appeared in ECAI-12 [1].* Corresponding author.E-mail addresses: lecoutre@cril.fr (C. Lecoutre), likitchav@gmail.com (C. Likitvivatanavong), ryap@comp.nus.edu.sg (R.H.C. Yap).http://dx.doi.org/10.1016/j.artint.2014.12.0020004-3702/© 2014 Elsevier B.V. All rights reserved.\f2C. Lecoutre et al. / Artificial Intelligence 220 (2015) 1–27Fig. 1. Standard and dual representations of the relation of a ternary constraint C with scope { X, Y , Z }.search, leading to the so-called MAC, Maintaining (generalized) Arc Consistency, algorithm [5]. This paper introduces a new GAC algorithm, called STR3, that works with positive table constraints. Furthermore, unlike most GAC algorithms, STR3 is specifically conceived to be used within MAC rather than being standalone.A table is just a relation, as in classical relational database, and a positive table constraint contains (in a table) all permit-ted combinations of values for a subset of variables (whereas a negative table constraint contains all forbidden combinations of values). Table constraints have been well studied in the artificial intelligence literature and arise naturally in many ap-plication areas. For example, in configuration and databases, they are introduced to model the problem no matter whatever the domain is. Besides, table constraints can be viewed as the universal mechanism for representing constraints, provided that space requirements can be controlled. The importance of table constraints makes them commonly implemented in all major constraint solvers that we are aware of (e.g., Choco, GeCode, JaCoP, OR-Tools).For table constraints, many classical filtering algorithms that reduce search through inference (such as [6–9]) work with constraints that stay unaltered while running. However, recent developments suggested that reducing the amount of traversal by discarding irrelevant tuples from tables can lead to faster algorithms. Simple Tabular Reduction (STR) and its improvements [10,11] fall into this category and have been shown to be among the best GAC algorithms for positive table constraints.The main idea behind simple tabular reduction is to remove invalid tuples from tables as soon as possible in a systematic fashion. STR3 is based on the same principle as STR1 [10] and STR2 [11] but employs a different representation of table constraints. Similarly to a few other algorithms (e.g., GAC-allowed [6] and GAC-va [8]), STR3 provides an index for each constraint table, enabling a tuple sought with respect to a domain value to be found without visiting irrelevant tuples, thus reducing time complexity. Fig. 1 shows an example for a ternary constraint. Importantly, for each constraint relation, STR3 maintains some specific data structures designed so that no constraint tuple is processed more than once along any path, through the search tree, going from the root to a leaf.Most of the GAC algorithms for table constraints previously introduced in the literature suffer from repeatedly traversing the same tables or related data structures during search [11,12]. In contrast, STR3 avoids such repetition and is path-optimal: each element of a table is examined at most once along any path of the search tree. An important feature of STR3 is that it is designed specifically to be interleaved with backtracking search, where the main goal is to maintain the consistency while minimizing the cost of backtracking. As such, unlike most other GAC algorithms, STR3 is only applicable within the context of search: STR3 maintains GAC, but before commencement of search, GAC must be enforced by some other algorithm, such as STR2 for example.We also investigated a promising circular manner for traversing tables in STR3. Although this seemed attractive at first because the circular approach described in [13] has an optimal run time per branch when amortized across a search tree, our experiments found that it was not really effective for STR3 in practice. To conclude our theoretical analysis, we discuss the relationships between STR3 and two other optimal GAC algorithms for table constraints, namely, GAC4 [4] and AC5TC-Tr [14].We present an extensive experimental study that demonstrates that STR3 is competitive with state-of-the-art algorithms. In particular, our experiments show that STR3 is rather complementary to STR2. STR2 is faster than STR3 where simple tab-ular reduction can eliminate so many tuples from the tables that they become largely empty. STR3, by contrast, outperforms STR2 when constraint relations do not shrink very much during search (this is when STR2 is the more costly). Hence, STR3 is complementary to STR2.This paper is organized as follows. Technical background is provided in Section 2. In Section 3, the concept of STR3 is explained together with its algorithm. A detailed example of STR3’s step-by-step execution is given in Section 4. Sec-tion 5 analyzes the relationships among STR’s data structures in greater detail. Theoretical analysis of STR3 is carried out in Sections 6 and 7. A variant of STR3 is studied in Section 8. Previous works related to STR3 are discussed in Section 9. Experimental results are reported in Section 10. The paper concludes in Section 11.\fC. Lecoutre et al. / Artificial Intelligence 220 (2015) 1–2732. PreliminariesIn this section, we introduce some technical background concerning the constraint satisfaction problem, and we recall the operation of a data structure called sparse set, which is key to STR3’s optimality.2.1. Constraint satisfaction problemA finite constraint network P is a pair (X , C ) where X is a finite set of n variables and C is a finite set of e constraints. Each variable X ∈ X has an initial domain, denoted by D( X), which is the set of values that can be assigned to X . Each constraint C ∈ C involves an ordered subset of variables of X , denoted by scp(C), that is called the scope of C . The arityof a constraint C is the number of variables involved in C , i.e., |scp(C)|. A binary constraint involves two variables whereas a non-binary constraint involves strictly more than two variables. The semantics of a constraint C is given by a relation, (cid:2)denoted by rel(C); if scp(C) = { X1, . . . , Xr}, then rel(C) ⊆ri=1 D( Xi) represents the set of satisfying combinations of values, called allowed tuples, for the variables in scp(C).A solution to a constraint network is an assignment of a value to every variable such that every constraint is satisfied. A constraint network is satisfiable iff at least a solution exists. The Constraint Satisfaction Problem (CSP) is the NP-complete task of determining whether a given constraint network is satisfiable or not. Thus, a CSP instance is defined by a constraint network, which is solved either by finding a solution or by proving that no solution exists. Solving a CSP instance usually involves a complete backtrack search that is interleaved",
            {
                "entities": [
                    [
                        133,
                        195,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1053–1091Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintComputational techniques for a simple theory of conditional preferencesNic Wilson∗Cork Constraint Computation Centre, Department of Computer Science, University College Cork, Cork, Irelanda r t i c l ei n f oa b s t r a c tA simple logic of conditional preferences is defined, with a language that allows thecompact representation of certain kinds of conditional preference statements, a semanticsand a proof theory. CP-nets and TCP-nets can be mapped into this logic, and the semanticsand proof theory generalise those of CP-nets and TCP-nets. The system can also expresspreferences of a lexicographic kind. The paper derives various sufficient conditions for a setof conditional preferences to be consistent, along with algorithmic techniques for checkingsuch conditions and hence confirming consistency. These techniques can also be used fortotally ordering outcomes in a way that is consistent with the set of preferences, and theyare further developed to give an approach to the problem of constrained optimisation forconditional preferences.© 2010 Elsevier B.V. All rights reserved.Article history:Received 28 February 2009Received in revised form 9 August 2010Accepted 9 August 2010Available online 2 December 2010Keywords:Conditional preferencesComparative preferencesCeteris paribus preferencesCP-netsTCP-netsConstrained optimisationLexicographic preferences1. Introduction(cid:3)(cid:3), where x, xThe formalism CP-nets [3,4] is designed for compactly expressing conditional comparative preferences in multivariateproblems. A CP-net involves statements of the form: u : x > xare values of a variable X and u is an assignmentto a set of variables U (called the parents of X ). The interpretation is that, given u, x is (strictly) preferred to x, all else(cid:3)being equal (ceteris paribus); that is, for all assignments s to the other variables S, sux is preferred to sux, where e.g., suxis the outcome (complete assignment) α such that α( X) = x, α(U ) = u and α(S) = s. The statement therefore compactlyrepresents exponentially many preferences between outcomes. This is a conditional preference, since the preference betweenvalues of X is conditional on the values of other variables U . It represents comparative preferences, in that the preferencestatements relate directly to the ordering between outcomes; this is in contrast to many theories of preference whichassign some form of grade to outcomes, and outcomes are compared by comparing their grades. Comparative preferencestatements can be easier to reliably elicit: often it is easier to judge that one alternative is preferred to another than it is toallocate particular grades of preference to the alternatives.(cid:3)Another key feature of CP-nets and related languages is the ceteris paribus aspect of the interpretation. If someone tellsus they’d prefer a green car to a white car, they wouldn’t usually mean that they’d prefer any green car to any white car;a ceteris paribus interpretation, that any green car is preferred to a car which is similar except being white, seems muchmore natural. However, this will tend to lead to quite weak inferences, and a user will sometimes want to express muchstronger statements such as those of the form: x is preferred to xirrespective of the values of other variables, where the variableX is the most important variable, and, for example, xrepresents a value that should be avoided if at all possible.(cid:3)(cid:3)This paper develops a formalism along similar lines to CP-nets, but where a richer language of preference statementscan be expressed: stronger conditional preference statements as well as the usual CP-nets ceteris paribus statements. The* Tel.: +353 21 4205954, fax: +353 21 4205369.E-mail address: n.wilson@4c.ucc.ie.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.018\f1054N. Wilson / Artificial Intelligence 175 (2011) 1053–1091(cid:3)to W and assignments t to S − W , tuxw is preferred to tux(cid:3)[W ] (where W is a subset of S), which represents that for all assign-language consists of statements of the form u : x > x(cid:3)ments w, w. So, given u and any t, x is preferred to xirrespective of the values of W . CP-nets ceteris paribus statements are represented by such statements with W = ∅, and the(cid:3)[V − { X}], where V is the setstrong conditional preference statement in the previous paragraph corresponds to (cid:5) : x > xof all variables. As in CP-nets, and their extension TCP-nets [6,8], this is a compact representation: each statement typicallycorresponds to many preferences between outcomes.w(cid:3)(cid:3)The next section introduces the new formalism, which can be viewed as a simple logic of conditional preferences. A cp-theory Γ has an associated preference relation >Γ on outcomes; Γ can be considered to be a compact representation of >Γ .A semantics is given and also a complete proof theory, based on ‘swapping sequences’, which is a natural generalisation offlipping sequences in CP-nets and TCP-nets. Section 3 examines the relative expressivity of the language as compared withCP-nets. It shows how CP-net orderings (Section 3.1) and TCP-net orderings (Section 3.2) can be represented within thelanguage; however, this stronger kind of preference statement, which can be used, for example, to construct a lexicographicorder on outcomes, is not expressible within the languages of CP-nets or TCP-nets (see Sections 3.3 and 3.4). Section 3.5illustrates that the ceteris paribus statements of CP-nets tend to be rather weak, by showing how hard it is for a CP-net togenerate a total order on outcomes.Sections 4, 5, 6 and 7, are all concerned with the inter-related topics of determining consistency of a cp-theory, totallyordering sets of outcomes, and constrained optimisation. Most of the work on CP-nets and TCP-nets has assumed a verystrong acyclicity property on the variables (though see [12,11]); here we generally make much weaker assumptions, whichis desirable since natural sets of conditional preference statements can easily fail to be acyclic in this sense. A necessarycondition for consistency is derived, “local consistency” (Section 4.1), and some sufficient conditions; determining whetherthese conditions hold is much less hard than determining consistency.A cp-theory is consistent if and only if there exists a strict total order on outcomes that satisfies it. We focus on aparticular kind of strict total order: one generated by a complete search tree (or “cs-tree”, see Section 4.2), as used inbacktracking search for solutions of a constraint satisfaction problem; the associated strict total order is the order in whichoutcomes are visited by such a search tree. We derive various sufficient conditions for a cs-tree to satisfy a cp-theory. Ifwe can show that there exists a cs-tree satisfying a cp-theory Γ , then we have proved that Γ is consistent. Furthermore,we can use such a satisfying cs-tree for totally ordering sets of outcomes, and in a constrained optimisation algorithm(Section 4.4), making use of an upper approximation of the preference relation, i.e., a relation on outcomes that extends thepreference relation.For the fully acyclic case, i.e., when the graph formed by dependencies and importance is acyclic, defining a satisfyingcs-tree is straightforward, as shown in Section 5; this implies that Γ is consistent if and only if it is locally consistent,with the latter condition often being very easy to check. For more general cases, the situation is more complicated, and inSections 6 and 7 we derive more complex methods for constructing satisfying cs-trees. Section 6 considers weaker forms ofacyclicity for cp-theories, that we call strong conditional acyclicity (Section 6.1) and cuc-acyclicity (Section 6.2), and whichare sufficient conditions for a cp-theory to be consistent. A polynomial upper approximation is derived for cuc-acyclic cp-theories.Proving consistency of a cp-theory by explicitly giving a cs-tree that satisfies the cp-theory will typically not be feasible,since the cs-tree is an exponentially large object. However, cs-trees can be defined in a compact way based on implicitrepresentations of the variable and value orderings; defining the value ordering is easy, given that the cp-theory is locallyconsistent. Section 7 defines a compact computational structure and associated techniques for defining the variable order-ings of a cs-tree satisfying the cp-theory; this can be used for confirming consistency, ordering outcomes and constrainedoptimisation.Section 8 discusses related work, Section 9 concludes, and Appendix A contains most of the proofs.2. A logic of conditional preferencesIn this section, a simple logic of conditional preferences is defined, with a language, semantics and a kind of prooftheory. As we will see in Sections 3.1 and 3.2, CP-nets and TCP-nets can be expressed within this language. The logic has asomewhat restrictive language, but the restrictions entail some nice properties, generalising properties of CP-nets.After giving some basic definitions of ordering relations in Section 2.1, we define cp-theories and their associated pref-erence relations in Section 2.2. A semantics (Section 2.3) and a proof theory (Section 2.4) are defined, with a completenessresult (Theorem 1).2.1. Ordering relationsIn this section we give some basic definitions and properties of ordering relations that will be used throughout thepaper.A binary relation (cid:6) on a set Ω is defined to be a subset of Ω × Ω ; the notations “(a, b) ∈ (cid:6)” and “a (cid:6) b” are usedinterchangeably. Since binary relations are sets, we can talk about the intersection and union of them, and containment ofone by another. So, in particular, if (cid:6) and (cid:6)(cid:3)holds if and only if a (cid:6) b impliesb. We may also say in this case that (cid:6)(cid:3",
            {
                "entities": [
                    [
                        138,
                        209,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 100 ( 1998) 275-322 Artificial Intelligence Pragmatic navigation: reactivity, heuristics, and search Susan L. Epstein * Deprrttnent of Computer Science, Hunter College und The Graduate School of The City University (f New York, 695 Park Avenue, New York, NY 10021. USA Received I7 April 1997; revised 15 October 1997 Abstract techniques is an architecture the Right Reasons) set of solution methods first has the opportunity for learning and problem solving (the serial testing of known, triggered incomplete and overlapping it represents that inte- to address complex problems. some facet of domain expertise, may vary in reliability and FORR (For grates a possibly Each method, although speed. The principal contribution of this paper is the extension of FORR to include situation-based behavior reactivity and heuristic based, and addresses problem reasoner activates a set of reactive If they, too, fail to produce a response, rationales. All three components experiments, strate how each component plays an important of this paper include a FORR-based, pragmatic, cognitively plausible approach learned heuristic through there. Empirical evidence demonstrates and guidelines for problem solving in a domain) with reasoning. FORR categorizes methods as reactive, heuristic, or situation- solving with one category of methods at a time. A hierarchical the reasoner tailored to specific situations. among heuristic In a series of is shown to be effective and efficient. Ablation experiments demon- role in problem solving. Additional contributions to navigation with territory and travel experience interact is both effective and efficient, to other domains are provided. @ 1998 Elsevier Science B.V. search procedures resorts learned the reasoner reference knowledge it, and a careful study of how situation-based to collaboration from experience. to react correctly. If no ready reaction behavior, reactivity, and heuristics that the resultant system triggers for time-limited for generalization this architecture two-dimensional approximations that describe is computed, Keywords; AI architectures; Heuristic search; Machine solving; Satisficing; Situation-based search; Spatial representation learning; Multistrategy learning; Navigation; Problem * Email: epstein@roz.hunter.cuny.edu 0004-3702/98/$19.00 PIf SOOO4-3702(97)00083-O @ 1998 Elsevier Science B.V. All rights reserved. \f216 S.L. Ep.~tein/Artijiciul Intelligence 100 (1998) 275-322 Naive geographic reasoning is probably the most common and basic form of human intelligence-Egenhofer & Mark, 1995 rational behavior are applied of the world reasoning principles is, however, another is the serial testing of known, trigger action without conscious in a domain. The principal contribution search space, people employ a variety of devices to is automatic; certain reasoning. AI researchers this automaticity with reactive systems. Other portions of this behavior in some combination. limitedly When confronted with an intractable make what they hope will be expert decisions. Some of this behavior perceptions have modeled are heuristic; There Situation-based solving (For it integrates a complex problem, FORR heuristic expertise, may vary in reliability and speed. Additional contributions a pragmatic, of how situation-based evidence important mechanism people use, a kind of restricted search. for problem of this paper is the extension of FORR so that reasoning. To solve set of some facet of domain of this paper include to navigation with FORR; a careful study there; and empirical a possibly solution methods. Each method, although an architecture behavior with reactivity structures reactivity, and heuristics is both effective and efficient. the Right Reasons), situation-based incomplete it represents that the resultant and overlapping and heuristic and problem for learning cognitively techniques behavior, approach triggered plausible solving, interact system Consider example. situation-based first how reactivity, and a decision constitutes behavior, and heuristics would behave In the grid world studied here, the robot knows and those of the goal. (Other kinds of grid worlds could be treated in four line to any visible for a robot, with situation-based separately on a path-finding its own coordinates similarly.) The robot has no map; it can “see” only orthogonal directions, location, Fig. 1 shows a goal at (9,6) the legal moves behavior, or heuristics would encounter difficulties here. Without experience cyclic behaviors. Without every relevant decision-making could err, resorting And without efficient decision making, heavy search costs. record of its recent to learn, a purely reactive system could become mired in local rule, a purely heuristic system to either random choice or search when no heuristic was applicable. incur a move in a straight locations of reactivity, from RI striped. Unilateral to the nearest obstruction and three possible system would and the ability situation-based application a purely k?.Y obstl q legal G goal uction moves from Rl R 1, R2, R3 robot locations Fig. I. Robot R seeks to move to goal G. \fS.L. Ep.wein/Art@iciul Intelligence IOa (1998) 275-322 277 In contrast, FORR strikes an economical balance among reactivity, situation-based responds it gives priority first to correct reactions, behavior, and heuristics. Rather than exhaustively deliberate on a complete model of the in a variety of efficient ways to a partial, feature-based model. world, FORR As a three-tiered then to situation- architecture, to the model learned during based behaviors, and finally it is an inexpensive way to problem solving. Reactivity make the right obvious decisions it is costly, situation-based of computational limited manner. Heuristics right decision the partial model. relies upon triggers to justify cycles on search, and relies upon restricted to search in a very resort, applied when the in restricted search to heuristics, all with reference top priority because is given the appropriate expenditure routines and to avoid the wrong obvious ones. Although is not obvious and the problem solver cannot thus become a last, albeit frequent, behavior justify but had been a move to (7,5), a correct reaction would be to eliminate Consider how FORR would deal with each of the robot locations at RI contemplated it was a dead-end, consideration. Now consider a robot at R2 with no immediate little progress on its task, and recognized was an intervening circumnavigate with the goal, say at (9,9) with the path in Fig. 1. If a robot that that move from any further If it had made that it was aligned with the goal but there to the robot obstruction, FORR could activate a time-limited If the search algorithm were able to realign there before and remembered search algorithm that obstruction. reactions. ((636) (697) (7,7) (798) (878) (839) (939)) the goal (Happily, performance and executed any particular as implemented in two-dimensional situation. Aligning as a way of addressing that entire path would be proposed situation. Finally, consider a robot at R3, one that has no immediate then recognized is and does not recognize generally a good heuristic, so (6,6) might be a good choice. Then again, if the robot is having difficulty on the trip, trying a location might be helpful. Of course, be good choices. Since long-step heuristic might value them more highly. Achieving a consensus such as these is nontrivial. Pragmatic navigation, it has not yet visited, say (4,8) or (6,5), and (8,8) might two of those choices are in the general direction of the goal, a large steps speed travel, so (3, S), (6,3), the reactions the robot with the dilemma at R3 will be resolved here by FORR, aspires space, performance in origin and destination. learns its way around a new territory, a pragmatic navigator is resilient for a particular from a series of trips through competent time and expertise territory differ. Just as a person who detailed description pragmatic navigator of a detailed map, pragmatic navigation or make territory, a pragmatic navigator learns features of the territory its performance. As envisioned accurate; travels efficiently trip or remember trips whose origins and destinations through a campus does not retain a tree and rock, a of each the location of each ignores much travel history and many topographical details. Instead travel into a room or an extended wall. In a new initially performs as a competent novice, and then, as it from traveling to improve there, it uses that knowledge rather than absolutely here, most features are heuristic that describe a territory and travel experience they are useful approximations that support efficient relies upon features it more difficult, such as a door to provide that improves Instead of pre-engineered from heuristics in Section 4.) robust, across the territory, to changes \f278 S.L. Epstch /Art(jicid lmlligence 100 (1998) 275-322 1 2 3 4 5 6 7 6 9 1011121314 1 2 3 4 5 6 7 a 9 10 11 12 13 14 Fig. 2. A problem and its solution in a maze it. Such representation through storage, retrieval, and computation. deliberately sacrifices detail in exchange for efficient travel learned about it appropriately through unmapped tasks for a perceptually-limited to context, both in a cognitively situation-based features there. This approach works because It is the thesis of this work that expert navigation territory can behavior, and care- the territory allocates control and plausible way. The first section of this paper in unknown agent find that so difficult, and pro- the that balances search, reactivity, and how for decision making, those navigation principles with learned that demonstrate responsible including guidelines these ideas in other domains. The final sections address related and future be achieved as the integration of correct reactions, fully balanced heuristics, many of which reference during responds frames navigation as a set of travel territory",
            {
                "entities": [
                    [
                        77,
                        133,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artiticial Intelligence 106 (1998) 267-334 Artificial Intelligence The logical foundations of goal-regression planning in autonomous agents * John L. Pollock ’ Department of Philosoph)! Univer.si~ of Arizona, PO Box 210027, Tucson, AZ 85721. USA Received 1 April 1998; received in revised form 17 August 1998 Abstract planning planning in autonomous This paper addresses the logical foundations of goal-regression rational It focuses mainly on three problems. The lirst is that goals and subgoals will often be to a conjunction we usually have to plan the resulting subplans. A logical problem arises interfere with each other. This problem has been there is satisfied. This assumption pertains to the computability agents. and to apply goal-regression conjunctions, separately for the conjuncts and then combine from the fact that the subplans may destructively partially solved in the AI literature (e.g., in SNLP and UCPOP), but the solutions proposed work only when a restrictive assumption of threats. It is argued that this assumption may fail for an autonomous complex environment. Relaxing this assumption is formulated precisely and an implementation is that goal-regression in a leads to a theory of defeasible planning. The theory that runs afoul of the Frame Problem. It is argued that a previously proposed solution to the Frame Problem legitimizes goal-regression that some restrictions must be imposed on the logical form of goals and subgoals amenable have to do with temporal-projectibility. planning, but also has the consequence to such planning. These restrictions in the OSCAR architecture rational agent operating in terms of reasoning The second problem planning proceeds is discussed. these restrictions The third problem is that the theory of goal-regression planning found in the AI literature imposes restrictive syntactical constraints on goals and subgoals and on the relation of logical consequence. leads to a generalization of the notion of a threat, related to collective Relaxing that the previously reasoning. Relaxing defeat in defeasible adequate definition of “expectable-result” no longer guarantees closure under logical consequence, rule for goal- and must be revised accordingly. That in turn leads to the need for an additional regression planning. Roughly, the rule allows us to plan for the achievement of a goal by searching for plans that will achieve states that “cause” the goal. Such a rule was not previously necessary, but becomes necessary when the syntactical constraints are relaxed. the restrictions also has the consequence ’ This work was supported by NSF grant no. IRI-9634106 ’ Email: pollock@tizona.edu. 00043702/98/$ PII: SOOO4-3702(98)00100-3 - see front matter 0 1998 Elsevier Science B.V. All rights reserved \f268 J.L. Pdlock /Art&id Intdligmcr 106 (I 998) 267-334 The final result is a general semantics for goal-regression planning and a set of procedures that is It is shown that this semantics can easily handle concurrent actions, and effects, creation and destruction of objects, and causal connections provably sound and complete. quantified preconditions embodying complex temporal relationships. 0 1998 Elsevier Science B.V. All rights reserved. Keywords: Autonomous agents; Defeasible reasoning; Goal regression: OSCAR: Planning 1. Introduction as the theory develops. interested to construct for autonomous This paper addresses some logical problems theory of rational cognition is concerned with what to believe, and practical cognition that arise in the course of formulating in realistically rational agents operating a theory of plan construction is to understand how truly intelligent agents complex environments. My ultimate objective as part of the theory of plan construction in the real world. I approach can get around an attempt in such agents. Within a general rational cognition we can distinguish between epistemic cognition and practical cognition. is concerned Epistemic cognition into four parts: with what to do. We can think of practical cognition as dividing (4) plan execution. Viewing (1) goal adoption, turns out to impose constraints plan construction logical problems not satisfied by standard planning some for a theory of plan construction, to them. The focus of this paper will of those problems precisely and propose solutions in the OSCAR be theoretical, however, architecture to date. I will say more about implementation intent for rational agents. 2 This has been partially accomplished systems. These constraints generate and the purpose of this paper from this somewhat broader perspective (2) plan construction, (3) plan adoption, is to implement is to formulate the ultimate the theory roughly in constructing In this paper, I am not particularly a theory of human rational agents that we cognition. However, humans are the most successful autonomous useful to reflect upon how humans solve some know about, and so it will be occasionally is rational agents. Human plan construction that face all autonomous of the problems generally based on goal-regression planning. The basic idea is a simple one, going back at least to Aristotle. To achieve a goal, we consider an action that would achieve it under in those some specified circumstances, in circumstances those circumstances from the goal that are already achieved. The resulting through subgoals until we arrive at subgoals sequence of actions constitutes in this paper is to provide precise logical foundations becomes a subgoal. The idea is to work backwards and then try to find a way of putting ourselves in order to achieve the goal by performing the goal. My ultimate objective the action. Rutting ourselves a plan for achieving for goal-regression planning. Much work in AI has been directed at the task of formalizing regression planning. This forms the basis of a large part of AI planning result is what I will refer to as the “conventional” Section 2 I will give a precise formulation of the conventional in that section will mostly be familiar, although which I have combined and automating goal- theory, and the In planning. theory. The ideas developed in the way in them into a logically precise theory. there may be some novelty theory of goal-regression ideas and developed familiar * Pollock [34]. \fJ.L. Polkock /Artificial Intelligence 106 (I 998) 267-334 269 theory, ra- to implement theory proposes it. In a sense to In effect, the conventional in quite the way the conventional the basic correctness of the conventional rather than by running a semi-decidable cannot in general perform goal-regression In Section 3 I will argue that, assuming tional agents situated in a complex environment planning be explained, planning must be done defeasibly algorithm. Section 4 will describe how that can be done. In Section 5 I will argue that, theory turns upon an indefen- even given the modifications of Section 4, the conventional sible assumption. In in light of Section 5. Section 6 1 will show how the conventional In Sections 7 and 8 I will suggest further modifications constraints logical consequence. The final result is a general semantics and a set of procedures illustrate tions, quantified preconditions connections planning that is provably sound and complete. The short closing sections ac- and effects, creation and destruction of objects, and causal theory imposes on goals and subgoals and on the relation of theory runs afoul of the Frame Problem. the power of this semantics by showing that it can easily handle concurrent theory must be modified temporal relationships for goal-regression aimed at relaxing and metric time. the conventional the syntactical embodying complex 2. The conventional theory of goal-regression planning planning as “(A/C) Goal-regression is based upon conditionals l G”. I will refer to C as the precondirion to the effect that if an action A I will write such a is performed under circumstances C, the goal G will be achieved. conditional of the conditional, A as the action, and G as the goal. For the time being, I will not attempt to be more precise about the logical form of these conditionals. That is a topic to which I will return in Section 5. planning, human beings make I will call these planning-connirional. explicit appeal theory into the actions from which follows the lead of STRIPS the plans are constructed in a separate reasons explicitly. Allowing database of background multiple planning-conditionals to employing plan operators with conditional [lo] in building (the “plan operators”) By contrast, most work in AI planning the same action is equivalent to planning-conditionals. from which a planner instead of storing In goal-regression these conditionals information concerning effects. ’ them Goal-regression planning aims to construct a plan for achieving a goal. But what exactly out of plan-steps, which prescribe actions. Plan-steps is a plan? Plans are constructed the same action may be cannot be identified with the actions prescribed by more than one step in a single plan. The plan-steps must be executed in a proper order, so I will take a plan to include both the set of plan-steps and the ordering of the plan-steps. they prescribe, because in a plan for the purpose of achieving In constructing step is included ultimate goal of the plan). Subgoals, subgoals step). Causal-links, mechanism a plan, we must keep track of the purpose of each plan-step. A plan- (or the in turn, are adopted for the purpose of achieving other (or the ultimate goal) 6~ performing a specific action (executing a specific plan- [24], provide a convenient introduced by McAllester these purposes. In the simplest case, I will take a causal-link some particular and Rosenblitt for recording subgoal to 3 Conditional effects are discussed by Pednault 1271. and were first implemented in UCPOP [28J \f270 J L. Pollock /Artijiciul Intelligence 106 (I 998) 267-334 explanatory. the information that step 1z1 is intended structure is useful both in constructing",
            {
                "entities": [
                    [
                        67,
                        139,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1308–1345Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSpecifying and computing preferred plans ✩Meghyn Bienvenu a, Christian Fritz b, Sheila A. McIlraith c,∗a CNRS & Université Paris-Sud, Franceb Palo Alto Research Center, USAc Department of Computer Science, University of Toronto, Canadaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 April 2009Received in revised form 30 July 2010Accepted 30 July 2010Available online 2 December 2010Keywords:Knowledge representationPreferencesPlanning with preferencesIn this paper, we address the problem of specifying and computing preferred plans usingrich, qualitative, user preferences. We propose a logical language for specifying preferencesover the evolution of states and actions associated with a plan. We provide a semantics forour first-order preference language in the situation calculus, and prove that progressionof our preference formulae preserves this semantics. This leads to the development ofPPlan, a bounded best-first search planner that computes preferred plans. Our preferencelanguage is amenable to integration with many existing planners, and beyond planning,can be used to support a diversity of dynamical reasoning tasks that employ preferences.© 2011 Elsevier B.V. All rights reserved.1. IntroductionResearch in automated planning has historically focused on classical planning – generating a sequence of actions toachieve a user-defined goal, given a specification of a domain and an initial state. However, in many real-world settingssatisficing plans are plentiful, and it is the generation of high quality plans, meeting users’ preferences and constraints, thatpresents the greatest challenge [50].In this paper we examine the problem of preference-based planning – generating a plan that not only achieves a user-defined goal, but that also conforms, where possible, to a user’s preferences over properties of the plan. To address theproblem of preference-based planning, we require a language for specifying user preferences, as well as a means of gener-ating plans that is capable of optimizing for the defined class of preferences. To this end, we propose LPP , a first-orderlanguage for specifying domain-specific, qualitative user preferences. LPP is expressive, supporting the definition of tem-porally extended preferences over the evolution of actions and states associated with a plan. LPP harnesses much of theexpressive power of first-order and linear temporal logic (LTL) [51]. We define the semantics of our first-order preferencelanguage in Reiter’s version of the situation calculus [47,53]. Leveraging this semantics, we also define an extension of LPPthat allows for the specification of preferences over the occurrence of Golog complex actions [44,53]. Golog is an Algol-inspired agent programming language that supports the construction of complex actions using programming language-likeconstructs over primitive and complex actions. Golog has proven of great utility in a diversity of agent programming appli-cations.LPP ’s situation calculus semantics enables us to reason about preferences over situations (corresponding to trajectoriesor partial plans) within the language, which is beneficial for a diversity of reasoning tasks where distinguishing a preferredsituation or trajectory is relevant. Such tasks include but are not limited to plan understanding, diagnosis of dynamical✩The majority of the work presented in this paper was performed while the authors were affiliated with the University of Toronto. Revisions of the paperwere carried out while the first author was at Université Paul Sabatier and Universität Bremen, and the second author at Information Sciences Institute.* Corresponding author.E-mail addresses: meghyn@lri.fr (M. Bienvenu), cfritz@parc.com (C. Fritz), sheila@cs.toronto.edu (S.A. McIlraith).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.021\fM. Bienvenu et al. / Artificial Intelligence 175 (2011) 1308–13451309systems, and requirements modeling within software engineering. LPP can also be used to characterize ordered defaultsand norms for default and deontic reasoning.Despite LPP ’s roots in the situation calculus, planning with LPP does not require the use of deductive plan synthesisand a theorem prover. LPP is amenable to use by any state-of-the-art planner that can take LTL-based preferences as input.Indeed, as we will discuss later, work by Baier and McIlraith [2] provides a compilation algorithm that enables preference-based planners that do not accept LTL formulae as input to plan with LPP -like LTL preferences. In this paper, we proposePPLAN, a bounded best-first search forward-chaining planner in the spirit of TLPlan [1] and TALPlanner [43]. PPLAN exploitsprogression to efficiently evaluate LTL preference satisfaction over partial plans. To guide search towards an optimal plan, wepropose an admissible evaluation function that, in concert with A* search, results in the generation of optimal plans.There is a significant body of research on preferences both within artificial intelligence (AI) and in related disciplines.A recent special issue of AI Magazine [36] provides a high-level overview of some of the latest AI research in this field,including research on planning with preferences [6]. In the last four years, there has been growing interest within theplanning community in preference-based planning. This includes study of the specification of preferences for planning (e.g.,Son and Pontelli [59,60] and Delgrande, Schaub, and Tompits [23]), and in particular an extension to the Planning DomainDefinition Language (PDDL) [48] by Gerevini and Long to include preferences (PDDL3) [33]. In 2006, the biennial Interna-tional Planning Competition (IPC-2006) included a track on planning with preferences specified in PDDL3. A number ofpreference-based planners were developed in and around this time, and subsequently (e.g., [24,25,41,61,9,10,29,3,5,35]). Wediscuss this related work in detail in Section 7.This paper is organized as follows. In Section 2 we provide a brief review of the situation calculus. Then in Section 3,we introduce the syntax and semantics of our LPP preference language for planning, illustrating its use through a moti-vating example which is carried throughout the paper. With the semantics of our preference language in hand, we returnto the general problem of planning with preferences. In Section 4, we define the notion of progression over LPP pref-erence formulae and prove that it preserves the semantics of our preferences. We also define an admissible evaluationfunction, which can be used with progression and A* search to generate optimal plans. Then, in Section 5, we describe thePPLAN algorithm, a bounded best-first forward-chaining planner that plans with preferences. We prove the correctness ofthe PPLAN algorithm and present experimental results for a proof-of-concept implementation of the algorithm in Prolog.Finally, in Section 6 we extend LPP to enable definition of preferences over Golog complex actions. We correspondinglyextend our notion of progression to include these new preference formulae. We conclude the paper with a discussion ofrelated work and a summary.2. PreliminariesThe situation calculus is a sorted, logical language with equality designed for specifying and reasoning about dynamicalsystems [53]. The signature of the language is specified in terms of three sorts: the set of action terms, A, consists ofconstants or functions mapping objects and sometimes other actions into elements of type action; the set of situation termsconsists of the constant S0, denoting the initial state of the world, and terms of the form do(a, s) where a is an actionterm and s is another situation term; finally object terms encompass everything that is neither an action nor a situation.In the situation calculus, the state of the world is expressed in terms of functions and relations (called fluents) which arerelativized to a particular situation s, e.g., F ((cid:3)x, s). In this paper, we consider only relational fluents, and we distinguishbetween the set F of fluents (e.g., isSnowing(s)), which are used to model dynamic properties of the world, and the setR of non-fluent relational formulae (e.g., meal(spaghetti)), which describe properties of the world that do not change overtime. A situation s is a history of primitive actions a ∈ A performed from the initial, distinguished situation S 0. The functiondo maps a situation s and an action a into a new situation do(a, s). The theory induces a tree of situations, rooted at S 0.states that situation s precedes situation sA basic action theory D in the situation calculus comprises four domain-independent foundational axioms and a set ofdomain-dependent axioms. The foundational axioms Σ define the situations, their branching structure and the situationpredecessor relation (cid:2). s (cid:2) sin the situation tree. Σ includes a second-orderinduction axiom. The domain-dependent axioms are strictly first-order and are of the general form described below. Thereader is also directed to Appendix A for an example axiomatization of the dinner domain, which we use throughout thispaper to illustrate concepts. Note that we follow the notational convention established by Reiter [53] and assume that freevariables in situation calculus formulae are universally quantified from the outside, unless otherwise noted. In later sections,when discussing preferences and Golog, we also adopt the convention of referring to fluents in situation-suppressed form,e.g., at(home) rather than at(home, s).(cid:5)(cid:5)• A set Dap of action precondition axioms which describe the conditions under which it is possible to execute an actionA in a situation s. An action precondition axiom for an action A takes the form(cid:2)PossA((cid:3)x), s(cid:3)≡ Π A((cid:3)x, s)where Π A((cid:3)",
            {
                "entities": [
                    [
                        138,
                        178,
                        "TITLE"
                    ],
                    [
                        645,
                        685,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 925–952www.elsevier.com/locate/artintGenerating and evaluating evaluative argumentsGiuseppe Carenini a,∗, Johanna D. Moore ba Computer Science Department, University of British Columbia, 2366 Main Mall, Vancouver, BC Canada V6T 1Z4b Human Communication Research Centre, University of Edinburgh, 2 Buccleuch Place, Edinburgh, United Kingdom EH8 9LWReceived 21 June 2005; received in revised form 15 May 2006; accepted 23 May 2006AbstractEvaluative arguments are pervasive in natural human communication. In countless situations people attempt to advise or persuadetheir interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). With the proliferation of on-line systemsserving as personal advisors and assistants, there is a pressing need to develop general and testable computational models forgenerating and presenting evaluative arguments. Previous research on generating evaluative arguments has been characterizedby two major limitations. First, researchers have tended to focus only on specific aspects of the generation process. Second, theproposed approaches were not empirically tested. The research presented in this paper addresses both limitations. We have designedand implemented a complete computational model for generating evaluative arguments. For content selection and organization, wedevised an argumentation strategy based on guidelines from argumentation theory. For expressing the content in natural language,we extended and integrated previous work in computational linguistics on generating evaluative arguments. The key knowledgesource for both tasks is a quantitative model of user preferences. To empirically test critical aspects of our generation model,we have devised and implemented an evaluation framework in which the effectiveness of evaluative arguments can be measuredwith real users. Within the framework, we have performed an experiment to test two basic hypotheses on which the design ofthe computational model is based; namely, that our proposal for tailoring an evaluative argument to the addressee’s preferencesincreases its effectiveness, and that differences in conciseness significantly influence argument effectiveness. The second hypothesiswas confirmed in the experiment. In contrast, the first hypothesis was only marginally confirmed. However, independent testing byother researchers has recently provided further support for this hypothesis.© 2006 Elsevier B.V. All rights reserved.Keywords: Natural language generation; User tailoring; Preferences; Empirical evaluation1. IntroductionEvaluative arguments are pervasive in natural human communication. In countless situations, people attempt toadvise or persuade their interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). For instance,doctors need to advise patients about which treatment is best for them. A teacher may need to convince a studentthat a certain course is (is not) the best choice for the student. And salespeople often need to compare similar prod-ucts, explaining why one of the products would be more to the current customer’s liking than the other(s). With the* Corresponding author.E-mail address: giuseppe.carenini@gmail.com (G. Carenini).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.05.003\f926G. Carenini, J.D. Moore / Artificial Intelligence 170 (2006) 925–952explosion of information available on-line and the ever-increasing availability of wireless devices, we are witnessinga proliferation of computer systems serving as personal assistants or advisors, e.g., [9,62], which aim to support orreplace humans in similar communicative settings. The success of such systems will crucially depend on their abilityto generate and present effective evaluative arguments.In the 1990s, considerable research was devoted to developing computational models for automatically generatingand presenting evaluative arguments. Several studies have investigated the process of selecting and structuring thecontent of an argument (e.g., [7,31,35,47]), and [23] developed a detailed model of how the selected content shouldbe realized in natural language. Despite the abundance of prior work on this topic, the previous research has beencharacterized by two major limitations. First, because of the complexity of generating natural language, researchershave tended to focus only on specific aspects of the generation process. Second, because of a lack of systematicevaluation, it is difficult to gauge the effectiveness, scalability and robustness of the proposed approaches.The research presented in this paper addresses these limitations. By following principles from argumentation the-ory and computational linguistics, we have developed a complete computational model for generating evaluativearguments. In our model, all aspects of the generation process are covered in a principled way, from selecting and or-ganizing the content of the argument, to expressing the selected content in natural language. For content selection andorganization, we devised an argumentation strategy based on guidelines from argumentation theory. For expressingthe content in natural language, we extended and integrated previous work on generating evaluative arguments. Thekey knowledge source for both tasks is a quantitative model of user preferences. To empirically test critical aspects ofour generation model, we have devised and implemented an evaluation framework in which the effectiveness of evalu-ative arguments can be measured with real users. The design of the evaluation framework was based on principles andtechniques from several research fields, including computational linguistics, social psychology, decision theory andhuman computer interaction. Within the framework, we have performed an experiment to test two basic hypotheseson which the design of the computational model is based; namely, that tailoring an evaluative argument to a model ofthe addressee’s preferences increases its effectiveness, and that differences in conciseness significantly influence ar-gument effectiveness. The first hypothesis was only marginally confirmed in the experiment (0.05 < p < 0.10), whilethe second one was confirmed at p < 0.05. Moreover, recent work [62], which is a direct extension of our research,provided further independent empirical support for the first hypothesis.In the next section, we focus on the problem of generating evaluative arguments tailored to a model of the user’spreferences and we describe the design and development of our Generator of Evaluative Argument (GEA). In Sec-tion 2, we describe our evaluation framework. First, we justify the design of the evaluation framework by reviewingliterature on persuasion from social psychology as well as previous work on evaluating natural language generationtechniques. Next, we introduce and motivate the user task at the core of the framework. In particular, we illustratehow, in the context of this task, the effectiveness of an argument can be assessed by measuring its effects on user’sbehaviors, beliefs and attitudes. Section 3 describes the experiment we ran within the evaluation framework and inSection 4 we discuss related work on generating and evaluating evaluative arguments.2. Generating evaluative argumentsThe generation of evaluative arguments has been extensively investigated in the past. Yet, the computational modelsdeveloped in previous work only cover sub-parts of the generation process. For instance, [35] provided a sophisticatedapproach only to content selection, while [23] was mainly limited to content realization. Furthermore, all earliermodels were not informed by argumentation theory [42], a theory, rooted in rhetoric, providing guidelines on howeffective arguments are to be generated.In this section we present GEA, the first computational model that covers all aspects of generating evaluativearguments in a principled way, by effectively integrating general principles and techniques from argumentation theoryand computational linguistics. GEA is a rather complex computational model. In this section, we describe its designand development in a top-down fashion. First, we illustrate how GEA specializes the pipeline architecture typicallyadopted in Natural Language Generation (NLG) systems and introduce the basic algorithms and knowledge structures.Then, we discuss a set of guidelines from argumentation theory on which an effective argumentation strategy can bebased. After that, we introduce the quantitative model used in GEA to represent the user’s preferences and describean argumentation strategy that tailors the content as well as structure of an evaluative argument to such a model. The\fG. Carenini, J.D. Moore / Artificial Intelligence 170 (2006) 925–952927Fig. 1. The GEA architecture as a specialization of the generic NLG pipeline architecture.section concludes with a detailed description of how GEA realizes the content selected by the argumentation strategyin natural language.2.1. The architecture of the Generator of Evaluative Arguments (GEA)Text generation involves two fundamental tasks: a process that selects and organizes the content of the text (deepgeneration), and a process that expresses the selected content in natural language (surface generation). GEA, likemost previous work in NLG, makes the assumption that deep generation should strictly precede surface generation,and adopts the resulting pipeline architecture [50]. In this architecture (see center of Fig. 1 from top to bottom) a textplanner selects and organizes content from a domain model by applying a communicative strategy to achieve a set ofcommunicative goals, which are given as input. The output of text planning is a text plan, a data structure that spec-ifies: the rhetorical structure of the text, the propositions that the text should convey and a partial order among thosepropositions. Then, a text Micro-Planner packages the selected cont",
            {
                "entities": [
                    [
                        72,
                        118,
                        "TITLE"
                    ],
                    [
                        7255,
                        7301,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 247 (2017) 313–335Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintContinual curiosity-driven skill acquisition from high-dimensional video inputs for humanoid robotsVarun Raj Kompella∗, Marijn Stollenga, Matthew Luciw, Juergen SchmidhuberThe Swiss AI Lab IDSIA, USI & SUPSI, Galleria 2, 6928 Manno-Lugano, Switzerlanda r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 12 October 2014Accepted 2 February 2015Available online 12 February 2015Keywords:Reinforcement learningArtificial curiositySkill acquisitionSlow feature analysisContinual learningIncremental learningiCubIn the absence of external guidance, how can a robot learn to map the many raw pixels of high-dimensional visual inputs to useful action sequences? We propose here Continual Curiosity driven Skill Acquisition (CCSA). CCSA makes robots intrinsically motivated to acquire, store and reuse skills. Previous curiosity-based agents acquired skills by associating intrinsic rewards with world model improvements, and used reinforcement learning to learn how to get these intrinsic rewards. CCSA also does this, but unlike previous implementations, the world model is a set of compact low-dimensional representations of the streams of high-dimensional visual information, which are learned through incremental slow feature analysis. These representations augment the robot’s state space with new information about the environment. We show how this information can have a higher-level (compared to pixels) and useful interpretation, for example, if the robot has grasped a cup in its field of view or not. After learning a representation, large intrinsic rewards are given to the robot for performing actions that greatly change the feature output, which has the tendency otherwise to change slowly in time. We show empirically what these actions are (e.g., grasping the cup) and how they can be useful as skills. An acquired skill includes both the learned actions and the learned slow feature representation. Skills are stored and reused to generate new observations, enabling continual acquisition of complex skills. We present results of experiments with an iCub humanoid robot that uses CCSA to incrementally acquire skills to topple, grasp and pick-place a cup, driven by its intrinsic motivation from raw pixel vision.© 2015 Elsevier B.V. All rights reserved.1. IntroductionOver the past decade, there has been a growing trend in humanoid robotics research towards robots with a large number of joints, or degrees of freedom, notably the ASIMO [1], PETMAN [2] and the iCub [3]. These robots demonstrate a high amount of dexterity and are potentially capable of carrying out complex human-like manipulation. When interacting with the real-world, these robots are faced with several challenges, not the least of which is the problem of how to solve tasks upon processing an abundance of high-dimensional sensory data.In the case of well structured environments, these robots can be carefully programmed by experts to solve a particu-lar task. But real-world environments are usually unstructured and dynamic, which makes it a daunting task to program these robots manually. This problem can be substantially alleviated by using reinforcement learning (RL; [4,5]), where a * Corresponding author.E-mail address: varun@idsia.ch (V.R. Kompella).http://dx.doi.org/10.1016/j.artint.2015.02.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\f314V.R. Kompella et al. / Artificial Intelligence 247 (2017) 313–335Fig. 1. A playroom scenario for a baby humanoid-robot in a lab environment, where it is placed next to a table with a few moving objects. The robot has a limited field-of-view and encounters continuous streams of images as it holds or shifts its gaze. Figure shows three such perspectives oriented towards the moving objects. How can the robot learn to solve tasks in the absence of an external guidance?robot learns to acquire desired task-specific behaviors, by maximizing the accumulation of task-dependent external rewards through simple trial-and-error interactions with the environment.Unfortunately, for humanoid robots equipped with vision, the sensory and joint state space are so large that it is ex-tremely difficult to procure the rewards (if any exist) by random exploration. For example, if the robot receives a reward for sorting objects, it could take an extremely long time to obtain the reward for the first time. Therefore, it becomes necessary to (a) build lower-dimensional representations of the state-space to make learning tractable and (b) to explore the envi-ronment efficiently. But how can these robots learn to do this in the presence of external rewards that are typically only sparsely available?Much of the human capacity to explore and solve problems is driven by self-supervised learning [6,7], where we seek to acquire behaviors by creating novel situations and learning from them. As an example, consider a simple playroom scenario for a baby humanoid as shown in Fig. 1. Here, the robot is placed next to a table with a few moving objects. The robot has a limited field-of-view and encounters continuous streams of images as it holds or shifts its gaze. If the robot can learn compact representations and predictable behaviors (e.g., to grasp) from its interactions with the cup, then by using these learned behaviors, it can speed up the acquisition of external rewards related to some teacher-defined task, such as placing the cup at a particular location. Continually acquiring and reusing a repertoire of behaviors and representations of the world, learned through self-supervision, can therefore make the robot adept in solving many external tasks.But how can the robot (a) self-supervise its exploration, (b) build representations of the high-dimensional sensory inputs and (c) continually acquire skills that enable it to solve new tasks? These problems have individually been researched in the machine learning and robotics literature [8–29]. However, to develop a single system that addresses all these important is-sues together is a challenging open problem in artificial intelligence (AI) research. We propose an online-learning framework that addresses this open problem.In order to make the robot self-supervised or intrinsically-motivated to explore new environments, we use the theory of Artificial Curiosity (AC; [30,31]). AC mathematically describes curiosity and creativity. AC-driven agents are interested in the learnable but as-yet-unknown aspects of their environment, and are disinterested in the already learned and inherently unlearnable (noisy) aspects. Specifically, the agent receives intrinsic rewards for action sequences, and these rewards are pro-portional to the improvement of the agent’s internal model or predictor of the environment. Using RL and the self-generated intrinsic rewards derived using AC [32–36,25], the agent is motivated to explore the environment where it makes maximum learning progress.Most RL algorithms however, tend to work only if the dimensionality of the state space is small, or its structure is simple. In order to deal with massive high-dimensional streams of raw sensory information obtained, for example through vision, it is essential to reduce the input dimensionality by building low-dimensional but informative abstractions of the environment [37]. An abstraction maps the high-dimensional input to a low-dimensional output. The high-dimensional data sensed by a robot is often temporally correlated and can be greatly compressed if the temporal coherence in the data is exploited. Slow Feature Analysis (SFA; [14,38,39]) is an unsupervised learning algorithm that extracts temporal regularities from rapidly changing raw sensory inputs. SFA is based on the Slowness Principle [40–42], which states that the underlying causes of changing signals vary more slowly than the primary sensory stimulus. For example, individual retinal receptor responses or gray-scale pixel values of video may change quickly compared to latent abstract variables, such as the position of a moving object. SFA has achieved success in many problems and scenarios, e.g., extraction of driving forces of a dynam-ical system [43], nonlinear blind source separation [44], as a preprocessor for reinforcement learning [39], and learning of place-cells, head-direction cells, grid-cells, and spatial view cells from high-dimensional visual input [38].SFA techniques are not readily applicable to open-ended online learning agents, as they estimate covariance matrices from the data via batch processing. We instead use Incremental Slow Feature Analysis (IncSFA; [45,46]), which does not \fV.R. Kompella et al. / Artificial Intelligence 247 (2017) 313–335315need to store any input data or computationally expensive covariance matrix estimates. IncSFA makes it feasible to handle high-dimensional image data in an open-ended manner.IncSFA, like most online learning approaches, gradually forgets previously learned representations whenever the statistics of the input change, for example, when the robot shifts its gaze from perspective two to perspective one in Fig. 1. To ad-dress this issue, in our previous work, we proposed an algorithm called Curiosity-Driven Modular Incremental Slow Feature Analysis (Curious Dr. MISFA; [47,48]), which retains what was previously learned in the form of expert modules [29]. From a set of input video streams, Curious Dr. MISFA actively learns multiple expert modules comprising slow feature abstractions, in the order of increasing learning difficulty. The algorithm continually estimates the initially unknown learning difficulty through intrinsic rewards generated by exploring the input streams.Using Curious Dr. MISFA, the robot in Fig. 1 finds its interactions with the plastic cup more interesting (easier to encode) than the complex movements of the other objects. This results in a compact slow featur",
            {
                "entities": [
                    [
                        136,
                        235,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 62–85Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTransforming Wikipedia into a large scale multilingual concept networkVivi Nastase∗, Michael StrubeHITS gGmbH, Heidelberg, Germanya r t i c l ei n f oa b s t r a c tArticle history:Available online 26 June 2012Keywords:Knowledge baseMultilingualityKnowledge acquisition1. IntroductionA knowledge base for real-world language processing applications should consist of a largebase of facts and reasoning mechanisms that combine them to induce novel and morecomplex information. This paper describes an approach to deriving such a large scale andmultilingual resource by exploiting several facets of the on-line encyclopedia Wikipedia.We show how we can build upon Wikipedia’s existing network of categories and articles toautomatically discover new relations and their instances. Working on top of this networkallows for added information to influence the network and be propagated throughout itusing inference mechanisms that connect different pieces of existing knowledge. We thenexploit this gained information to discover new relations that refine some of those foundin the previous step. The result is a network containing approximately 3.7 million conceptswith lexicalizations in numerous languages and 49+ million relation instances. Intrinsic andextrinsic evaluations show that this is a high quality resource and beneficial to various NLPtasks.© 2012 Elsevier B.V. All rights reserved.While the availability of large amounts of data has encouraged the development of successful statistical techniques fornumerous natural language processing tasks, there is a concurrent quest for computer accessible knowledge. Knowledgeallows a system to counter data sparsity (e.g. lexical semantic knowledge), as well as make connections between entities(e.g. BARACK OBAMA president_of UNITED STATES OF AMERICA).Shortly after its launch in January 2001, the potential of Wikipedia as a large scale source of knowledge for Artificial Intel-ligence and Natural Language Processing in particular became apparent to researchers in the field. The appeal of Wikipediais that it strikes a middle ground between accurate, manually created, limited-coverage resources such as WordNet [9], Cyc[18], general purpose (SUMO, [33]) or domain-specific ontologies (Gene Ontology,1 UMLS2), dictionaries and thesauri, andautomatic, wide-coverage, but still noisy knowledge mined from the web [38].Unlike resources prepared by trained linguists, Wikipedia’s structures have arisen through the collaboration of contribu-tors and, with the exception of the category structure which was encouraged by the contribution guidelines, without priorplanning. This may bring the quality of a resource based on such underspecified criteria into question, but its usefulness in avariety of Natural Language Processing (NLP) tasks has already been shown [22]. The category structure was not intended tobe an ontology-like structure, but what has emerged is a folksonomy, mirroring the shared categorization preferences of thecontributors. The collaborative aspect has also led to the implicit encoding of much information that when made explicit,reveals millions of new bite-sized pieces of knowledge.* Corresponding author.E-mail addresses: vivi.nastase@h-its.org (V. Nastase), michael.strube@h-its.org (M. Strube).1 http://www.geneontology.org.2 http://www.nlm.nih.gov/research/umls/.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.06.008\fV. Nastase, M. Strube / Artificial Intelligence 194 (2013) 62–8563Wikipedia contains a wealth of multi-faceted information: articles, links between articles, categories which group articles,infoboxes, a hierarchy that organizes the categories and articles into a large directed network, cross-language links, andmore. These various types of information have been usually exploited independently from each other.This paper presents WikiNet3 – the result of jointly bootstrapping several information sources in Wikipedia to produce alarge scale, multilingual and self-contained resource. The starting point is the category and article network. The most inter-esting feature of our approach is that it works completely automatically, in that it itself discovers relations in Wikipedia’scategory names for which it then finds numerous instances based on the category structure.Building WikiNet involves three main steps. First, category names are deconstructed to retrieve the categorization crite-rion, which leads to the discovery of numerous binary relation instances. In the second step the relation instances discoveredin the first step are refined based on information in the articles’ infoboxes. In the last step the network obtained up to thispoint is formalized by merging nodes that refer to the same concept, and by adding lexicalizations for these concepts fromredirect, disambiguation and cross-language links from Wikipedia versions in different languages. The resulting resource is anetwork consisting of 3 707 718 concepts and 49 931 266 relation instances (for 454 relations),4 and covers multiple dimen-sions: multilinguality, world knowledge, lexical semantics, collocations, paraphrases, named entities. Because the processingdoes not rely on manual feedback, and both the relations and their instances in the network are automatically discoveredin Wikipedia’s categories and infoboxes, the algorithm can easily be applied to the latest Wikipedia versions to generate anupdated resource.Intrinsic evaluation of the knowledge extracted shows that combining different types of information leads to the deriva-tion of accurate facts, not overtly expressed within articles or infoboxes, and as such not to be found by processing singleaspects of Wikipedia. We contrast this approach with DBpedia [1] and YAGO [45] – the largest repositories of facts extractedfrom Wikipedia to date. We perform extrinsic evaluation through two tasks – semantic relatedness computation betweenpairs of terms, and metonymy resolution, i.e. finding the correct interpretation of terms which are not used in any of theirliteral senses (e.g. White House is often used to refer to the President of the United States). The extrinsic evaluation resultsshow that the resource is of good quality – evidenced by high correlation results with manually assigned relatedness scoreson disambiguated data – but it also has high ambiguity which cannot be solved for pairs of terms out of context. ApplyingWikiNet to the task of metonymy resolution shows consistent increase in precision and recall when using world knowledgeto find the correct interpretation of potentially metonymic words, but due to the small size of the available data theseincreases are not statistically significant.2. Building WikiNetThe starting point for building WikiNet is the category and article network from one language version of Wikipedia.This network is modified step by step as more types of information from Wikipedia are taken into account. In the finalstep the nodes in the network are considered to represent concepts. Concepts and their lexicalizations are separated, andeach concept – now represented through a language independent ID – has associated numerous lexicalizations in a varietyof languages. An overview of the processing is shown in Algorithm 1, and each step is presented in more detail in theremainder of the section.Algorithm 1 Algorithm for building a large scale multilingual knowledge network.Input:W – the English Wikipedia dumpR – a set of relational nouns{W X } – a set of additional Wikipedia dumps in different languagesOutput:WikiNet – a graph with nodes as concepts, and edges as relations between them1: R 1 = DeconstructWikipediaCategories(W , R)2: R 2 = PropagateInfoboxRelations(W , R1)3: return WikiNet = BuildConceptNetwork(R2, W , {W X })The Wikipedia dump W is the file containing all English Wikipedia articles in XML format,5 and R is a set of relationalnouns extracted from an existing resource (NOMLEX,6 Meyers et al. [23]) used for detecting one of four classes of rela-tions in Wikipedia category names. The result of the category deconstruction process – R 1 – is a set of relation instances,represented as tuples (x, r, y), where x, y are strings, some of which are Wikipedia article or category names, others arefragments of category names, and r is a relation, also derived from the category names. R2, the result of infobox relation3 This article builds upon and expands [27,29]. It expands on this previous work by using a list of relational nouns extracted from NOMLEX. Itpresents a new method for computing semantic relatedness between a pair of terms, and its evaluation with standard data sets.It presents ex-periments on embedding the resource into an NLP task, in particular metonymy resolution. WikiNet can be downloaded from http://www.h-its.org/english/research/nlp/download/wikinet.php.4 The statistics reported in this paper refer to the WikiNet built starting from the English Wikipedia dump of 2011/01/15, and adding several otherlanguage versions. Details are in Section 3.1.5 Wikipedia dumps are available from http://download.wikimedia.org/. We use the pages-article.xml.bz2 file.6 http://nlp.cs.nyu.edu/meyers/nombank/nombank.1.0/NOMLEX-plus.1.0.\f64V. Nastase, M. Strube / Artificial Intelligence 194 (2013) 62–85propagation, has the same structure as R1, with the difference that some of the previously extracted relation instances areassigned new relations. WikiNet, derived from R 2 and additional information from W and {W X }, is a graph. The nodesare concepts, which are identified through a unique numeric ID and have associated multiple lexicalizations in various lan-guages. The edges are relation instances between concepts corresponding to the tuples in R 2, after mapping the argumentsonto concepts and filtering out the tuples for which at least o",
            {
                "entities": [
                    [
                        143,
                        213,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 304 (2022) 103650Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExact stochastic constraint optimisation with applications in network analysisAnna L.D. Latour a,∗Holger H. Hoos a,c, Siegfried Nijssen d,∗a LIACS, Leiden University, P.O. Box 9512, 2300 RA Leiden, the Netherlandsb Polytechnique Montréal, Montréal (Québec), H3T 1J4, Canadac University of British Columbia, Vancouver (British Columbia), V6T 1Z4, Canadad ICTEAM, UCLouvain, Place Sainte-Barbe 2 bte L5.02.01, B-1348 Louvain-la-Neuve, Belgium, Behrouz Babaki b, Daniël Fokkinga a, Marie Anastacio a, a r t i c l e i n f oa b s t r a c tArticle history:Received 15 August 2020Received in revised form 8 October 2021Accepted 4 December 2021Available online 10 December 2021Keywords:Constraint programmingProbabilistic inferenceStochastic constraintsOrdered binary decision diagramsMonotonic probability distributionsGlobal constraintsAutomated algorithm configurationProbabilistic networksWe present an extensive study of methods for exactly solving stochastic constraint (optimisation) problems (SCPs) in network analysis. These problems are prevalent in science, governance and industry. The first method we study is generic and decomposes stochastic constraints into a multitude of smaller local constraints that are solved using a constraint programming (CP) or mixed-integer programming (MIP) solver. However, many SCPs are formulated on probability distributions with a monotonic property, meaning that adding a positive decision to a partial solution to the problem cannot cause a decrease in solution quality. The second method is specifically designed for solving global stochastic constraints on monotonic probability distributions (SCMDs) in CP. Both methods use knowledge compilation to obtain a decision diagram encoding of the relevant probability distributions, where we focus on ordered binary decision diagrams (OBDDs). We discuss theoretical advantages and disadvantages of these methods and evaluate them experimentally. We observed that global approaches to solving SCMDs outperform decomposition approaches from CP, and perform complementarily to MIP-based decomposition approaches, while scaling much more favourably with instance size. Both methods have many alternative design choices, as both knowledge compilation and constraint solvers are used in a single pipeline. To identify which configurations work best, we apply programming by optimisation. Specifically, we show how an automated algorithm configurator can be used to find optimised configurations of our pipeline. After configuration, our global SCMD solving pipeline outperforms its closest competitor (a MIP-based decomposition pipeline) on all test sets we considered by up to two orders of magnitude in terms of PAR10 scores.© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionIn business, governance, science as well as in our daily lives, we often have to solve problems that involve optimal decision making under constraints and uncertainty. Examples of these problems arise in planning and scheduling, but they * Corresponding authors.m.i.a.anastacio@liacs.leidenuniv.nl (M. Anastacio), hh@liacs.nl (H.H. Hoos), siegfried.nijssen@uclouvain.be (S. Nijssen).E-mail addresses: a.l.d.latour@liacs.leidenuniv.nl (A.L.D. Latour), behrouz.babaki@polymtl.ca (B. Babaki), d.b.fokkinga@umail.leidenuniv.nl (D. Fokkinga), https://doi.org/10.1016/j.artint.2021.1036500004-3702/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\fA.L.D. Latour, B. Babaki, D. Fokkinga et al.Artificial Intelligence 304 (2022) 103650also occur naturally in fields such as data mining and bioinformatics. Given the abundance of relational data in these areas, many problems also involve probabilistic network data.Consider, for example, the following spread of influence problem, as studied in the data mining literature [26,41]. We are given a social network of people (vertices) that have stochastic influence relationships (edges). To promote a new product, we want to rely on word-of-mouth advertisement to turn acquaintances of people who buy our product into new customers. We start this process by ‘infecting’ a set of people in the network by giving them a free sample. The budget for this marketing campaign is limited (a constraint), so we can distribute at most k samples. Each person who is a customer can influence their friends to become a customer with a certain probability. Given the social network, which k people should we give free samples in order to maximise the expected number of eventual customers (our objective)? We note that adding a person to the set of people who receive a free product sample can never decrease the expected number of people that will eventually be infected by the viral campaign.Another example is an optimisation variant of the power transmission grid reliability problem [29]. We are given a power transmission network of power lines, power producers, power consumers and transmission stations. Natural disasters, such as earthquakes and hurricanes, may cause power lines to break, and if too many such breaks occur, households lose power. We can reinforce power lines to make them less likely to break during a natural disaster, and we are given a budget bfor these upgrades (a constraint). Which power lines do we reinforce such that we maximise the expected number of households that will still have power after a natural disaster (our objective), while not exceeding our budget? Note that adding a power line to the set of lines that are reinforced can never decrease the expected number of households that still have power after a disaster.A third example is an enumeration problem, aimed at finding sets of members of a social network who are, in ex-pectation, highly influential to certain communities in their distribution of fake news. Using again a probabilistic spread-of-influence framework similar to the one described above, we combine this framework with a frequent itemset mining (FIM) [1]approach and associated constraint. Here, we repeatedly solve a constraint satisfaction problem, to find all solutions to that problem, instead of solving an optimisation problem.These problems are instances of a general class of problems, known as stochastic constraint (optimisation) problems (SCPs). SCPs have the following characteristics:• They involve decision variables and stochastic (or random) variables.• They involve reasoning over (typically) complex probability distributions.• They involve possibly complex constraints that limit the decisions we can take.The three problems described above feature a fourth characteristic:• The probabilities and expectations are higher if more nodes or edges are selected, which makes these probability dis-tributions monotonic.We call these special cases of SCPs stochastic constraint (optimisation) problems on monotonic distributions (SCPMDs). While this fourth characteristic seems limiting, problems that have this property are plentiful in network analysis; examples include the applications mentioned above, but also a signalling-regulatory pathway inference problem described in the bioinformat-ics literature [24,52] and a variant on landscape connectivity [74]. We discuss the relation of SCPs and SCPMDs to other problems in Section 10.Both SCPs and SCPMDs are difficult to solve exactly (i.e., in a way that produces provably optimal solutions). Well-known instances of SCPMDs, such as spread of influence problems, are NP-hard [41]. Calculation of a probability in probabilistic networks requires solving a counting problem that is known to be #P-complete [62]. Exact solving requires finding an optimal solution in a search space that grows exponentially with problem size.In this work we present two main approaches for solving SCPs exactly. The first is based on decomposing hard constraints on probability distributions into a multitude of local constraints, and is applicable to SCPs in general. The second is designed for solving SCPMDs (and can only be applied to those), exploiting structures that result from monotonicity to obtain a global constraint propagation algorithm for solving those stochastic constraints. We discuss SCPs, SCPMDs and how to solve them in Section 2.The main algorithmic contributions in this work are as follows1:1. We present new versions of a constraint decomposition method for solving SCPs [43], based on ordered binary decision diagram (OBDD) [14] representations of probability distributions (Section 4).1 We presented an earlier version of this work in a conference paper [44]. This article extends this earlier publication with a more elaborate description of the propagation algorithm from [44], new proofs and additional contributions 4–6. Preliminary versions of contributions 4 and 5 were presented in a workshop paper [31]. Here, we have extended that work by including earlier approaches from Latour et al. [43] to the configuration experiments and by significantly extending the design space of our methods.2\fA.L.D. Latour, B. Babaki, D. Fokkinga et al.Artificial Intelligence 304 (2022) 1036502. We show that this decomposition approach is not generalised arc consistent (GAC), thus causing it to prune the search space insufficiently, and that a straightforward arc consistent modification of this approach does not significantly im-prove performance (Section 4.2).3. To address this inefficiency in the search, we introduce a global constraint on OBDD representations of monotonic distributions, which we call the stochastic constraint on monotonic distributions (SCMD), and introduce a GAC-by-design propagation algorithm for this constraint (Section 5).In summary, the benefits of the decomposition methods are:• They are",
            {
                "entities": [
                    [
                        135,
                        213,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 194 (2013) 130–150Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEvaluating Entity Linking with WikipediaBen Hachey a,∗, Will Radford b,c, Joel Nothman b,c, Matthew Honnibal d, James R. Curran b,ca Research & Development, Thomson Reuters Corporation, St. Paul, MN 55123, USAb School of Information Technologies, University of Sydney, NSW 2006, Australiac Capital Markets CRC, 55 Harrington Street, NSW 2000, Australiad Department of Computing, Macquarie University, NSW 2109, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Available online 23 April 2012Keywords:Named Entity LinkingDisambiguationInformation extractionWikipediaSemi-structured resources1. IntroductionNamed Entity Linking (nel) grounds entity mentions to their corresponding node in aKnowledge Base (kb). Recently, a number of systems have been proposed for linkingentity mentions in text to Wikipedia pages. Such systems typically search for candidateentities and then disambiguate them, returning either the best candidate or nil. However,comparison has focused on disambiguation accuracy, making it difficult to determine howsearch impacts performance. Furthermore, important approaches from the literature havenot been systematically compared on standard data sets.We reimplement three seminal nel systems and present a detailed evaluation of searchstrategies. Our experiments find that coreference and acronym handling lead to substantialimprovement, and search strategies account for much of the variation between systems.This is an interesting finding, because these aspects of the problem have often beenneglected in the literature, which has focused largely on complex candidate rankingalgorithms.© 2012 Elsevier B.V. All rights reserved.References to entities such as people, places and organisations are difficult to track in text, because entities can bereferred to by many mention strings, and the same mention string may be used to refer to multiple entities. For instance,David Murray might refer to either the jazz saxophonist or the Iron Maiden guitarist, who may be known by other aliasessuch as Mad Murray. These synonymy and ambiguity problems make it difficult for language processing systems to collectand exploit information about entities across documents without first linking the mentions to a knowledge base.Named Entity Linking (nel) is the task of resolving named entity mentions to entries in a structured Knowledge Base(kb). nel is useful wherever it is necessary to compute with direct reference to people, places and organisations, rather thanpotentially ambiguous or redundant character strings. In the finance domain, nel can be used to link textual informationabout companies to financial data, for example, news and share prices [34]. nel can also be used in search, where resultsfor named entity queries could include facts about an entity in addition to pages that talk about it [8].nel is similar to the widely-studied problem of word sense disambiguation (wsd, [36]), with Wikipedia articles playingthe role of WordNet synsets [20]. At core, both tasks address problems of synonymy and ambiguity in natural language.The tasks differ in terms of candidate search and nil detection. Search for wsd assumes that WordNet is a complete lexicalresource and consists of a lexical lookup to find the possible synsets for a given word. The same approach is taken inwikification, where arbitrary phrases including names and general terms are matched to Wikipedia pages [32,33,27,15].* Corresponding author.E-mail address: ben.hachey@gmail.com (B. Hachey).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.005\fB. Hachey et al. / Artificial Intelligence 194 (2013) 130–150131However, this does not provide a mechanism for dealing with objects that are not present in the database. nel, on theother hand, does not assume the kb is complete, requiring entity mentions without kb entries to be marked as nil [8,31].Furthermore, named entity mentions vary more than lexical mentions in wsd. Therefore, search for nel requires a noisiercandidate generation process, often using fuzzy matching to improve recall [48,28].Until recently, wide-coverage nel was not possible since there was no general purpose, publicly available collectionof information about entities. However, Wikipedia has emerged as an important repository of semi-structured, collectiveknowledge about notable entities. Accordingly, it has been widely used for knowledge modelling [46,6,37,42]. It has beenused for nlp tasks like automatic summarisation [45,50]. And it has also been exploited for a number of information extrac-tion tasks ranging from ner learnt from Wikipedia link structure [40] to relation extraction learnt from the nearly structuredinformation encoded in Wikipedia Infoboxes [51].The most popular data sets for nel were distributed as part of the recent Knowledge Base Population tasks at the nistText Analysis Conference (tac). The thirteen participants in the 2009 task developed systems that linked a set of 3904 entitymentions in news and web text to a knowledge base extracted from Wikipedia infoboxes. The highest accuracy achievedwas 82.2% [48] with subsequent publications reporting results as high as 86% [21].The popularity of the tac shared tasks has led to a wide range of innovative entity linking systems in the literature.However, since all participants were individually striving for the highest accuracy they could achieve, the systems all differalong multiple dimensions, so it is currently unclear which aspects of the systems are necessary for good performance andwhich aspects might be improved.In this paper, we reimplement three prominent entity linking systems from the literature to obtain a better understand-ing of the named entity linking task. Our primary question concerns the relative importance of search and disambiguation:an nel system must first search for a set of candidate entities that the mention string might refer to, before selecting a sin-gle candidate given the document. These phases have not been evaluated in isolation, and the systems from the literaturetend to differ along both dimensions.We find that the search phase is far more important than previously acknowledged. System descriptions have usuallyfocused on complicated ranking methods. However, search accounts for most of the variation between systems. Furthermore,relatively unremarked search features such as query expansion based on coreference resolution and acronym detection seemto have a much larger impact on system performance than candidate ranking.2. Review of named entity disambiguation tasks and data setsSeveral research communities have addressed the named entity ambiguity problem. It has been framed in two differentways. Within computational linguistics, the problem was first conceptualised by Bagga and Baldwin [4] as an extension ofthe coreference resolution problem. Mihalcea and Csomai [32] later used Wikipedia as a word sense disambiguation dataset by attempting to reproduce the links between pages, as link text is often ambiguous. Finally, Bunescu and Pa ¸sca [8] usedWikipedia in a similar way, but include ner as a preprocessing step and require a link or (nil) for all identified mentions. Wewill follow the terminology of these papers, and refer to the three tasks respectively as cross-document coreference resolution(cdcr), wikification, and named entity linking (nel). We use the more general term named entity disambiguation when wemust avoid referring specifically to any single task.The cdcr, wikification, and nel tasks make different assumptions about the problem, and these lead to different evalu-ation measures and slightly different techniques. The cdcr task assumes that the documents are provided as a batch, andmust be clustered according to which entities they mention. Systems are evaluated using clustering evaluation measures,such as the B3 measure [3]. The wikification task assumes the existence of a knowledge base that has high coverage overthe entities of interest, and that entities not covered by the knowledge base are relatively unimportant. And nel requiresa knowledge base but does not assume that it is complete. Systems are usually evaluated on micro-accuracy (percentageof mentions linked correctly) and macro-accuracy (percentage of entities linked correctly). In this section, we review themain data sets that have been used in cdcr and nel research. Although we make some reference to approaches used, werereserve the main description of named entity disambiguation techniques for Section 3.2.1. Early cross-document coreference datasetsThe seminal work on cross-document coreference resolution (cdcr) was performed by Bagga and Baldwin [4]. Theyperformed experiments on a set of 197 documents from the New York Times whose text matched the expressionJohn.*?Smith—where .*? is a non-greedy wildcard match up to the first instance of Smith, e.g., only John DonnelSmith would be matched in John Donnell Smith bequeathed his herbarium to the Smithsonian. The documents were manuallygrouped according to which John Smith entities they mentioned. None of the articles mentioned multiple John Smiths, sothe only annotations were at the document level.The John Smith dataset approaches the problem as one name, many people: there are many entities that are referred toby an ambiguous name such as John Smith. However, there is another side to the problem: one person, many names. Anentity known as John Smith might also be known as Jack Smith, Mr. Smith, etc. In other words, there are both synonymy andambiguity issues for named entities.\f132B. Hachey et al. / Artificial Intelligence 194 (2013) 130–150Most cdcr datasets are similarly collected by searching for a set of canonical names, ignoring non-canonical coreferentforms. For instance, Mann and Yarowsky [29] collected a data set of",
            {
                "entities": [
                    [
                        145,
                        185,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 72 ( 1995) 217-304 Artificial Intelligence On information invariants in robotics * Bruce Randall Donald* Computer Science Department, Cornell University, 4130 Vpson Hall, Ithaca. NY 14853-7.501, USA Received September 1992; revised April 1994 Abstract We consider the problem of determining the information requirements to perform robot tasks, invariants. This paper represents our attempt to characterize a using the concept of information family of complicated and subtle issues concerned with measuring robot task complexity. We also provide a first approximation to a purely operational theory that addresses a narrow but interesting special case. We discuss several measures for the information complexity of a task: (a) How much internal state should the robot retain? (b) How many cooperating agents are required, and how much communication between them is necessary? the in order to record state or sensory information to perform a task? (d) How much environment information is provided by sensors? and (e) How much computation is required by the robot? in order to compare the We consider how one might develop a kind of “calculus” on (a)-(e) power of sensor systems analytically. To this end, we attempt to develop a notion of information invariants. We develop a theory whereby one sensor can be “reduced” to another (much in the spirit of computation-theoretic among collaborating autonomous agents. reductions), by adding, deleting, and reallocating (a)-(e) (c) How can the robot change (side-effect) *This paper describes research done in the Robotics and Vision Laboratory at Cornell University. Support for research is provided our robotics IRI-9000532, the Air Force Office of Sponsored Research, Bell laboratories. IRI-9201699, in part by the National Science Foundation under grants No. IRI-8802390, and by a Presidential Young Investigator the Mathematical Sciences award to Bruce Donald, and in part by and AT&T Institute, Intel Corporation, * E-mail: brd@cs.comell.edu. 0004-3702/95/$09.50 SSDIOOO4-3702(94)00024-U @ 1995 Elsevier Science B.V. All rights reserved \f218 B.R. Donald/Artificial Intelligence 72 (1995) 217-304 Part I-State, communication, and side-effects 1. Introduction In this paper we investigate the information requirements for robot tasks. Our work to the takes as its inspiration robotics community can be found the information in 1989 [ 241, although in the theoretical literature invariants that Erdmann rigorous examples of information invariants from as far back as 1978 (see, for example, introduced ’ 11,351). Part I of this paper develops the basic concepts and tools behind information invariants in plain language. Therein, we develop a number of motivating examples. provide a fairly detailed analysis. sensors and computation. This analysis will call for some machinery whose complexity is best deferred until In Part II, we In particular, we admit more sophisticated models of that time. A central has been robot’s actions to determine what to acquire theme to previous work (see the survey article information that information is needed by a particular [ 111 for a detailed review) is required to solve it. Key questions concern: to solve a task, and to direct a (1) (2) (3) (4) robot to accomplish a particular What information How may the robot acquire such information? What properties of the world have a great effect on the fragility of a robot plan/program? What are the capabilities environments) (in a given environment of a given robot or class of task? ? that (say) is encoded In addition is not dynamic. robots, contribute towards simplifying into both the environment These questions can be difficult. Structured environments, such as those found around the robot’s task because a great amount implicitly, and the robot’s (and their effects) are difficult to measure. We wish to the mechanics are quasi- in the assumption how much in the assumptions, we may ask the converse: how much infor- strategies to reduce com- the possible outcomes of little or no industrial of information is encoded, often control program. These encodings encoded the information quantify static, or that the environment information mation must the control system or planner compute? Successful manipulation often exploit properties of the (external) physical world (e.g., compliance) uncertainty putation, in which an action by dint of physical computation; expensive. Since during execution we may witness very little “computation” of “algorithm”, in obtaining meaningful that a theory of information in the sense to apply upper and lower bounds on the true task complexity. We hope the sensitivity of plans such strategies may require these strategies may be computationally laws. Executing in contrast, planning or simulating and hence gain information. Often, such strategies exploit mechanical from computer science have been difficult of the task circumscribes can be used to measure the mechanics to determining techniques traditional invariants ’ Erdmann introduced the notion of measuring task complexity somewhat complicated; the interested reader is referred to [ 24 1. in bit-seconds; the example is important but \fB.R. Donald/Artificial Melligence 72 (I 995) 217-304 219 to particular possible. assumptions about the world, and to minimize those assumptions where in from robotics invariants represents to perform information a paradigm the intrinsic Increasingly, less relevant the scientific tasks or sensors for characterizing the world. From researchers doubt of plan construction culture. This change seems relevance the external environment. algorithms. Unfortunately, the world and incrementally that the robot, on booting, We would like to develop a notion of information of robotics operations. We may view information this measure it remains a useful tool. Its apparent diminished to online algorithms. assume a strictly offline paradigm. For example, sensors, invariants to some measure of information. The idea is that the task-if you required in computational geometry, a successful input sizes and upper and lower bounds in robotics, in embedded systems shift that we may in the offline model, we reads a geometric model of the world from to plan. As an alternative, we would also like to consider online builds data structures ‘Qpically, online agents are not to have an a priori world model when the task begins. Instead, as time evolves, forces the agent to move, sense, and (perhaps) build data structures tasks, and the complexity as a mapping this measure characterizes will, a measure of complexity. For example, measure has been developed for characterizing for geometric although reflects a change from ofline reasonably might assume a disk and proceeds paradigms where the robot investigates that in some sense represent assumed the task effectively to represent the complexity model?’ often appear secondary, working their capabilities, online our work to the recent but intense agents. In particular, we discuss what kind of data structures the environment. We also discuss through a system of spatially it is profitable systems. However, is given an u priori world two robots. We discuss formal models of in Part I link robots, TOMMY and LILY, which may be viewed as online and how they are programmed. We also consider for situated autonomous robots can build to represent of state sensorimotor directions. In particular, online paradigm. The chief lacuna is a principled strategies gap in Part II, where we provide a theory of situated framework Our theory intrinsic hardness or difficulty. serve as “lower bounds” developed agents and in certain crucial in the of devices for analyzing online to fill this systems. We attempt sensor systems. We argue that this certain kinds of important questions about sensors. invariants. When a measure of to a measure of could invariants then in the same way that lower bounds have been the online viewpoint, offline questions for a known environment, separated agents. to explore online paradigms sensing has never been carefully considered or modeled the situated automata of [ 11. The examples In Part I of this paper, we describe theory of sensori-computational of state, and the distribution If these notions are truly is natural is intended information then in the armamentarium to reveal a system’s in online paradigms it leads naturally the externalization for autonomous such as “what if not artificial. can be found, to be extended the framework for answering foregrounding in computer in robotics, We believe information invariants intrinsic, science. remains interest robots, these In our quest for a measure of the intrinsic information are inspired by Erdmann’s monograph on sensor design interesting (in motion planning the complexity-theoretic lower bounds [ 9,30,43,45] (see, e.g., questions requirements of a task, we [ 251. Also, we note that many for sense) have been obtained see, e.g., 14, ; for upper bounds \f220 U.K. Donuld/Art~ficirrl Intelligence 72 (1995) 217-304 The goals outlined here are ambitious that are “faithful” attack on perceptual to it [46]. His theory has developed a theory of synthetic automata which explore the is set in a framework where sensors are logical predicates. Perhaps our theory could be attack on a similar problem. This work was inspired by the [ 141 and [32] has developed the kinds of assumptions its environment. He also gives source- to the work research on 6, 121). Rosenschein world and build data structures logical viewed as a geometric theoretical by the experimental a semantics a sensori-computational to-source discussed here in Section 1, for a detailed bibliographic the geometric systems program makes about In addition essay on previous theory of planning under uncertainty, begun by Donald and Jennings that models and quantifies and Rus [33]. Horswill on sensori-computational studies of Jennings transformations for sensory equivalence “circuits”. see, e.g., [ 11",
            {
                "entities": [
                    [
                        76,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 320 (2023) 103919Contents lists available at ScienceDirectArtificial Intelligencejournal homepage: www.elsevier.com/locate/artintReasoning about causality in gamesLewis Hammond a,∗Alessandro Abate a, Michael Wooldridge aa University of Oxford, United Kingdomb DeepMind, United Kingdom, James Fox a,∗, Tom Everitt b, Ryan Carey a, a r t i c l e i n f oa b s t r a c tArticle history:Received 17 March 2022Received in revised form 1 April 2023Accepted 2 April 2023Available online 5 April 2023Keywords:CausalityGame theoryGraphical modelsContentsCausal reasoning and game-theoretic reasoning are fundamental topics in artificial intel-ligence, among many other disciplines: this paper is concerned with their intersection. Despite their importance, a formal framework that supports both these forms of reasoning has, until now, been lacking. We offer a solution in the form of (structural) causal games, which can be seen as extending Pearl’s causal hierarchy to the game-theoretic domain, or as extending Koller and Milch’s multi-agent influence diagrams to the causal domain. We then consider three key questions:i) How can the (causal) dependencies in games – either between variables, or between strategies – be modelled in a uniform, principled manner?ii) How may causal queries be computed in causal games, and what assumptions does this require?iii) How do causal games compare to existing formalisms?To address question i), we introduce mechanised games, which encode dependencies be-tween agents’ decision rules and the distributions governing the game. In response to question ii), we present definitions of predictions, interventions, and counterfactuals, and discuss the assumptions required for each. Regarding question iii), we describe correspon-dences between causal games and other formalisms, and explain how causal games can be used to answer queries that other causal or game-theoretic models do not support. Finally, we highlight possible applications of causal games, aided by an extensive open-source Python library.© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).1.2.Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.1.Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.2.Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Causal models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.1.Game-theoretic models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.2.3345573. Mechanised MAIDs and relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10* Corresponding authors.E-mail addresses: lewis.hammond@cs.ox.ac.uk (L. Hammond), james.fox@cs.ox.ac.uk (J. Fox).https://doi.org/10.1016/j.artint.2023.1039190004-3702/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/).\fL. Hammond, J. Fox, T. Everitt et al.Artificial Intelligence 320 (2023) 1039197.6.4.5.3.1. Mechanised MAIDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103.2.Relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13Causality in games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154.1.Interventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164.2.4.3.Counterfactuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17Solution concepts and subgames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21Nash equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215.1.Subgames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225.2.Equilibrium refinements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235.3.Connections to EFGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256.1.Equivalences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266.2.Causality in EFGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276.3.Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28Case study: insurance pricing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287.1.Blame, intent, incentives, and fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307.2.Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31Advantages and disadvantages of causal games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318.1.Future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328.2.Declaration of competing interest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32Data availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Appendix A.Transformations between game representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33Theoretical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34Further examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42Counterfactuals using the closest possible world principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42Non-existence results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43Reasoning about existing concepts using causal games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46Codebase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48Creating MAIDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48Computing equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51B.1.B.2.B.3.Appendix B.Appendix C.A.1.A.2.C.1.C.2.8.NotationSymbolObjectAncVcRGChVDescVdodom(V )EVEEFaVGIJMM(ζk)MVmGmMNPaVPr or PPrπ or P σQRR(mM)r DAncestors of VCondensed R-Relevance GraphChildren of VDescendants of VDo OperatorDomain of VExogenous Variable for VEdgesExtensive-Form GameFamily of VGraphInterventionIntervention SetModelPerturbed ModelMec",
            {
                "entities": [
                    [
                        153,
                        187,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 100 (1998) 5-85 Artificial Intelligence Interpreting a dynamic and uncertain world: task-based control Richard J. Howarth ’ School of Cognitive and Computing Sciences, University of Sussex, Falmer; Brighton BNI 9QH, United Kingdom Received 13 May 1995; revised 23 July 1997 Abstract In this paper we show that it can be beneficial to have a high-level vision component that guides the reasoning of the whole vision system when interpreting a dynamic and uncertain world. This guidance is provided by an attentional mechanism that exploits knowledge of the specific problem being solved. Here we develop a general framework for such an attentional mechanism and its application to understanding dynamic scenes. This attentional mechanism can enable a vision system to perform a given domain task while expending minimal resources. We have developed a component that uses Bayesian networks combined with a deictic representation to select what, when and how to use processed data from a fixed camera. We apply two forms of Bayesian network, which ( 1) create a dynamic structure to reflect the spatial organisation of the data and (2) measure task relatedness. Together these give attentional focus making the reasoning performed relevant to the task. @ 1998 Elsevier Science B.V. Keyw0rd.v: High-level computer vision; Surveillance; Attention; Event reasoning; Visual behaviour 1. Introduction In the modern world there is an increasing use of surveillance, need for automatic or semi-automatic methods of processing Surveillance concerns more than just observation. and knowledge, some known automated, to is still along way to go before such systems can be fully in this paper is a step in this direction. A visual is often much more purposive, complying to having some intelligence the processing performed the work described the dynamic task. There In addition although resulting in the input data. ’ Email: richardh@cogs.susx.ac.uk or howarth@dcs.qmw.ac.uk. 0004.3702/98/$19.00 PIISOOO4-3702(98)00004-6 @ 1998 Elsevier Science B.V. All rights reserved. \f6 R.J. Howarth/Art$cial Intelligence 100 (1998) 5-85 the perceiver surveillance system since problem of understanding in the scene, and also with processing general to extract system also provides a less complex problem just views than a fully interacting vision the scene of interest. We are still left with the the various unfolding dynamic behaviours of the actors/objects associated with using machine-based to noise, occlusion, is subject the many problems the visual evidence which and the ill-posed nature of inferring what we perceive the scene from image data. a restricted and consider is often a surprisingly the full visual understanding problem, case of the surveillance difficult process and we instead we make a number of Understanding do not address assumptions scenes. Our restricted visual understanding more of rigid objects interest the main in the activities of the various special vehicles aeroplanes. surveillance problem has the following tractable: we use a fixed camera of wide-area dynamic that make the activity in a structured domain. Examples scene where is the road vehicles, and airport holding areas where we are interested the passenger simplifications that observes a road-traffic that unload and service include: To perform surveillance we need to reason about to this work. We can separate vision the activities of the objects is performed that is complex is an important part of into (or late). Low-level [ 721)) and concerns visual receptors, sensors, with low-level image features vision is less well understood, and high-level to provide (Horn (or early), this visual perception that acts on the results from the visual receptors, intermediate-level [ 5 11, Marr from a television video camera or biological low-level is the best understood are perceived. The process by which and will not be fully addressed here. However, since perception surveillance we need to sketch its relationship three stages: vision be they artificial, processing such as edges, corners and flow vectors. Intermediate-level and concerns describes vision. High-level vision the evolving what intermediate-level In progressing be performed. is at the lower levels and levels. It is the development intermediate-level we use this to obtain a greater understanding is the least well understood that is provided by intermediate-level visual processing of objects for 3D interpretation, of high-level visual processing the more abstract, visual processing the recognition a framework information up these (e.g., model matching and tracking). Marr [ 721 to address intermediate-level that begins (or even low-level visual processing) and concerns of the interpretation vision as well as directing should information levels we see that image oriented symbolic descriptions are at the higher that allows the results from to be used for reasoning over longer time scales and of what is going on in the field-of-view. Until techniques that extract rare to find visual behaviours [ 881 and Howarth issues of high-level In this paper we concentrate it has been (but see, for example, Rimey and Brown to be on lower-level recently computer vision The focus tends rather than on identifying operate. placed on how what we know about an environment observed object behaviour. And, by using a single issues associated with active cameras and multisensor visual data to address surveillance tasks. Understanding starts by tracking objects objective of this work is to go further and form conceptual descriptions control connected with [55] >. from images tasks and how these on the role of high-level vision, with emphasis of the the interpretation fixed camera we ignore difficult ample fusion, while providing the activity of moving objects the beginning. The the that capture in an image sequence, but this is just appropriate information for visual affects \fR. J. Howarth /Art@cial Intelligence 100 (1998) 5-85 7 interactions dynamic of the advantages obtained by reinterpreting more active vision, situated approach. * of objects in a meaningful way. To discuss this we describe some a pipelined, passive vision system under a To address the surveillance problem we introduce the concept of the “official-observer” of our single that takes place in any interaction the official-observer the official-observer does not participate and is not a partner aware of this. Things In the surveillance problem here the tasks from the particular point-of-view visually attends to them, the observed people/objects which acts to coordinate camera. the environment Although not necessarily to differ greatly from those of the parties official-observer’s place in the dynamic wide-area scene it perceives and from this obtain an understanding interactions of the scene objects. There are constraints on of the dynamic and improvised the official-observer’s in the scene: we only see the objects of the objects that are in the camera’s field-of-view; we do not know each participant’s goal (typically something (rather than deeply planned). fixed in in the scene. 3 are are likely interaction. From the taking like “go to place X”) ; and what we see is mostly reactive behaviour input we wish to obtain a description of the activity that are relevant involved to the official-observer in the observed interpretation camera a in order that uses task-based to illustrate and motivation This paper begins by describing the background control program to address In Section 2 the initial project framework and the constraints computer problem. brought are explained. Then in Section 3 we describe an initial attempt at addressing surveillance problem. This first architecture serve first architecture why it is appropriate of the architecture used in Section 6, where theoretical details are given. Implementation in Section 7 and control operates. The parts of this paper following Section 8 consist of a discussion of related work, conclusions for developing the surveillance this framework the control, but does of this for why task-based control was developed and In Section 5 we present an overview that are details are given that illustrate how task-based the surveillance problem. Section 4 contains that does use task-based control, emphasizing for the surveillanceproblem. does not use task-based in Section 8 examples and appendices. those elements a reassessment are presented justification presenting 2. VIEWS and HIVIS In the ESPRIT II project 2152, VIEWS (Yisual (for an overview see Corral1 et al. [ 28,291)) area Scenes) is from images steps, which, as shown Component (2) to behavioural or “conceptual” descriptions. This involves a number of (PC) which performs in Fig. 1, can be coarsely separated low- and intermediate-level ( 1) the Perceptual and (SAC) which performs high-level control and visual processing, into: the Situation Assessment Component Inspection and Evaluation of Wide- the overall flow of information ’ The ideas behind “active vision” are described at the beginning of Section 5. By using the word “situated” we are recognising the broader ‘We use the word “object” issues of “being to refer to physical in the world” some of which are covered in Section 5.3.1. entities like cars, trams, and planes, where the person operating the machine may not be visible to the official-observer. \fR.J. Howarth/Artificial Intelligence 100 (1998) 5-85 I. The perception Fig. visual processing. The SAC performs high-level processing. and situation-assessment components. The PC performs low- and intermediate-level interpretation. On the left of the figure we depict an example scene, a complex junction, in this case a roundabout. What we want to determine is the behaviour of the vehicles that pass through this junction. This separation of the two components was done to allow simultaneous that we discuss but also led to a strong interface between in this paper, HIVIS-MONITOR of both components syste",
            {
                "entities": [
                    [
                        64,
                        126,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 164 (2005) 81–119www.elsevier.com/locate/artintOn the logic of cooperation and propositional controlWiebe van der Hoek ∗, Michael WooldridgeDepartment of Computer Science, University of Liverpool, Liverpool L69 7ZF, United KingdomReceived 24 August 2004Available online 5 February 2005AbstractCooperation logics have recently begun to attract attention within the multi-agent systems com-munity. Using a cooperation logic, it is possible to represent and reason about the strategic powersof agents and coalitions of agents in game-like multi-agent systems. These powers are generallyassumed to be implicitly defined within the structure of the environment, and their origin is rarelydiscussed. In this paper, we study a cooperation logic in which agents are each assumed to control aset of propositional variables—the powers of agents and coalitions then derive from the allocation ofpropositions to agents. The basic modal constructs in this Coalition Logic of Propositional Control(CL-PC) allow us to express the fact that a group of agents can cooperate to bring about a certainstate of affairs. After motivating and introducing CL-PC, we provide a complete axiom system for thelogic, investigate the issue of characterising control in CL-PC with respect to the underlying powerstructures of the logic, and formally investigate the relationship between CL-PC and Pauly’s Coali-tion Logic. We then show that the model checking and satisfiability problems for CL-PC are bothPSPACE-complete, and conclude by discussing our results and how CL-PC sits in relation to otherlogics of cooperation. 2005 Elsevier B.V. All rights reserved.Keywords: Multi-agent systems; Cooperation logic; Logics for control* Corresponding author.E-mail address: wiebe@csc.liv.ac.uk (W. van der Hoek).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.01.003\f82W. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–1191. IntroductionCooperation logics are logics that are intended to enable reasoning about coalitionsin multi-agent systems, and in particular, the powers that such coalitions have. Probablythe two best known examples of cooperation logics are Pauly’s Coalition Logic [36–38],and the Alternating-time Temporal Logic (ATL) of Alur, Henzinger, and Kupferman [5].Both of these systems are based upon the notion of a cooperation modality: a unary modaloperator, indexed by a set of agents, which is used to represent the fact that this set of agentscan cooperate so as to make true the state of affairs given as an argument to the operator.In Coalition Logic, for example, a formula [1, 2](p ∧ q) is used to express the fact that thecoalition {1, 2} can cooperate in such a way as to make the formula p ∧ q true. Althoughthey differ on technical details, the semantics of both logics are essentially equivalent [19]:coalition C are able to achieve ϕ if there exists a collective strategy for C such that, byfollowing this strategy, C can enforce ϕ (that is, ϕ is true in every outcome that couldarise by following the strategy). In both logics, the strategies available to a coalition, andthe outcomes consistent with these strategies, are implicitly enumerated within the logic’smodels: in the case of Coalition Logic, by means of effectivity functions (cf. [1]), and inthe case of ATL, by means of a system transition function.In this paper, we study a variant of cooperation logic that we refer to as the CoalitionLogic of Propositional Control (CL-PC). The key idea in CL-PC is that each agent is as-sumed to control a set of propositional variables. The strategies, or choices available toan agent then correspond to the different possible assignments of truth or falsity to thesepropositions. On top of that, the ability of a coalition to bring about some state of affairsderives from the propositional variables that are under the overall control of the coalition.There are at least two reasons why CL-PC is a system worthy of study in its own right:• First, and perhaps most importantly, if we are interested in building software agents,then it is extremely natural to think of the ability of these agents in terms of settingand unsetting bits in some digital control system. Indeed, this is arguably the mostfundamental kind of control that can be imagined.• Second, in implemented systems for reasoning about cooperation in game-like multi-agent scenarios, the individual powers of agents are actually specified by allocatingagents propositions that lie under their control. For example, this is exactly the ap-proach taken in the MOCHA model checking system for ATL, where the keywordcontrols is used to indicate the fact that an agent (or “module”, in the terminol-ogy of MOCHA) is uniquely able to determine the value of a propositional variable[3,6].Against this background, the present paper makes four main contributions to the study ofcooperation logics.First, although we have taken inspiration and some methodology from ATL and Coali-tion Logic, we note that the basic cooperation modalities of these logics have a ratherunusual modal flavour, which is neither wholly universal nor wholly existential. This isbecause these logics are intended to capture ∃∀-ability, or α-ability [1, pp. 11–12], the ideabeing that a coalition C have the α-ability to achieve some state of affairs ϕ if C have\fW. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–11983a collective choice such that, no matter what the agents outside C do, ϕ will hold as aconsequence of this choice. This type of ability is entirely natural when we wish to studythe circumstances under which a coalition can “reliably” bring about some state of affairs.However, the ∃∀ nature of cooperation modalities in these logics, and the fact that they areneither conventionally existential nor conventionally universal, means that (i) they are hardfor “logic users” to understand, as they have some counterintuitive properties (particularlyin their dual forms); and (ii) from a technical standpoint, the fact that they are a combina-tion of existential and universal modality makes them somewhat awkward to work with,at least compared with conventional “box” and “diamond” modalities. In CL-PC, however,the basic cooperation modalities capture contingent ability—a weaker notion of abilitythan the α-ability of Coalition Logic and ATL. Contingent ability is the ability to achievesome state of affairs under the assumption that, apart from our actions, the world remainsstatic. This is the type of ability that is implemented in classic AI planning systems such asSTRIPS [17,28]. Although contingent ability is perhaps not of great interest in its own right,it turns out that the contingent ability constructs of CL-PC are sufficient to define α-ability(as well as a related type of ability known as β-ability). Thus, although we appear to startwith a weaker notion of ability than those of Coalition Logic and ATL, it turns out that thisis in fact all we need to define these stronger types of ability. Moreover, the contingentability operators of CL-PC have the advantage of being “true modal diamonds”: they thushave a much simpler semantics than α-ability operators, and are easier to work with from atechnical point of view (for example, when using such conventional modal logic constructssuch as canonical models to prove completeness [11, pp. 59–61]).Second, although our basic cooperation modalities are conventional modal diamonds,and hence we can give them a more-or-less conventional Kripke semantics [9, p. 42], weare also able to give an alternative semantics to CL-PC, which is directly based on thepower structures that underpin the logic. We show that the two semantics are, in a precisesense, equivalent, and that we can thus move between the two semantics as we see fit. Theadvantage of this is that we can work with whichever semantics seems most appropriate tothe task at hand.Third, although complete axiomatizations are known for both ATL [19] and CoalitionLogic [36–38], we are able to provide an axiomatization for CL-PC that draws upon thesimple underlying power structures of the logic. As a consequence, our axiomatization ofCL-PC has a rather different flavour to those of Coalition Logic and ATL.Fourth, and finally, we present an analysis of control in CL-PC: when a coalition controlssome state of affairs. In particular, we show how the control that a coalition is able to exertwith respect to some state of affairs is related to the power structure underlying the logic.The remainder of this paper is structured as follows. Following a formal definition ofCL-PC, in Section 3 we present a complete axiomatization for the logic. In Section 4.1,we show how α- and β-ability modalities can be defined in terms of the basic constructsof CL-PC, and in Section 4.2, we investigate the characterisation of control in CL-PC, withparticular reference to the underlying power structures. In Section 5, we investigate thecomputational complexity of the model checking and satisfiability problems for the logic,and show that both problems are PSPACE-complete. We conclude with a discussion on theimplications of our results, and how the logic stands in relation to other similar systems.\f84W. van der Hoek, M. Wooldridge / Artificial Intelligence 164 (2005) 81–1192. The coalition logic of propositional controlIn this section, we give a formal definition of CL-PC. We begin with an informal in-troduction to the main features of the logic (readers familiar with Coalition Logic or ATLmay wish to skip or skim through this section). We then formally define the syntax ofCL-PC, and give two alternative semantics. The first is a “direct” or “propositional” seman-tics, which has the advantages of being both simple and closely related to the intuitionsunderpinning the language, but has the disadvantage of being rather unconventional in themodal logic sense, and hence rather hard to work with from the point o",
            {
                "entities": [
                    [
                        71,
                        124,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 89 ( 1997) l-29 Artificial Intelligence On the logic of iterated belief revision Adnan Darwiche *, Judea Pearl * Cognitive Systems Laboratory, Computer Science Department, Universiry of California, Los Angeles, CA 90024, USA Received February 1994; revised September I996 Abstract We show in this paper that the AGM postulates are too weak to ensure the rational preservation of conditional beliefs during belief revision, thus permitting improper responses to sequences of observations. We remedy this weakness by proposing four additional postulates, which are sound relative to a qualitative version of probabilistic conditioning. Contrary to the AGM framework, the proposed postulates characterize belief revision as a process which may depend on elements of an epistemic state that are not necessarily captured by a belief set. We also show that a simple modification to the AGM framework can allow belief revision to be a function of epistemic states. We establish a model-based representation theorem which characterizes the proposed postulates and constrains, under iterated belief revision. in turn, the way in which entrenchment orderings may be transformed Keywords: Iterated revision; AGM postulates; Conditional beliefs; Probabilistic conditioning; Epistemic states; Qualitative probability 1. Introduction The process of belief change has been formalized logic, probabilistic [ 2 1 ] ), belief change nonmonotonic (e.g., new facts In probabilistic uct of conditioning reasoning (e.g., a probability reasoning, and belief revision. in several frameworks, most notably logic is viewed as a byproduct of extending a database containing rules called “defaults”. is viewed as a byprod- thereof) on abstraction >, belief change (or some qualitative [ 10,13,23,24] function In nonmonotonic in accordance with a set of extension-construction * Corresponding author. Current address: Department of Mathematics, American University of Beirut, P.O. Box I l-236, Beirut, Lebanon. E-mail: darwiche@aub.edu.lb. ’ E-mail: pearl@cs.ucla.edu. 0004-3702/97/$17.00 Copyright @ 1997 Elsevier Science B.V. All rights reserved. PII SOOO4-3702 (96)00038-O \f2 A. Durwiche, J. Peurl/Art~ciul lntellijience 89 (1997) 1-29 in accordance with Bayes’ new evidence, changes are characterized by a set of constraints which modifies implying the new information the set $J of currenily held beliefs ,u. rule. In the belief revision (called “postulates”) framework, belief on an operator o to produce a new belief set Ic, o p, While many studies have emphasized [ 8,9,14,22] ), serious that are common features incompatibilities works above (e.g., point to belief the standard belief properly response revision to some fundamental limitations and inadequacies This paper addresses one such framework, as encapsulated [3-5,131. revision regulate to a string of observations. iterated belief revision, that is, the sequential have also been observed of the operator-based limitation, in the AGM postulates to the three frame- that approach the failure of [ 11, to in revision of beliefs iterated revisions, and need to be strengthened We will first demonstrate that the AGM postulates, to enforce plausible permissive tional constraints. We will then argue that any rational comply with four postulates which are not part of the AGM necessary show that one of these postulates framework the framework epistemic states, rather than belief sets. to maintain plausible behavior under stands contrary should be broadened and, hence, as they currently stand, are too by addi- system of belief change should lexicon, and which are iterated belief change. Finally, we will to the basic tenet of the operator-based to permit operations on between belief sets and epistemic To understand the requirements in addition in particular, to employ at that given including, to, a set of “conditional the distinction the set of propositions state contains, recalling acterizes An epistemic ent reasoning, agent wishes alent conditioned ior under successive observations, revised itself which conditional evidence. on any hypothetical is enough (this beliefs”, to which an agent iterated imposed by is committed at any given revision we should start by states. A belief set $ char- time. needed for coher- to @, the entire information the very strategy of belief the time. Any such strategy encodes, and is equiv- to adopt To fully specify behav- one must encode, not merely how beliefs are to be strategy to specifying [ 2,3,15,16,19,20]. revision which that is, beliefs the revision is prepared that one in turns, evidence beliefs are to be retained and which ones deleted with each piece of is to be modified by each new evidence. This amounts, for the first stage only) but also how The hallmark of the AGM postulates is the principle of minimal belief change, that those to preserve as much of earlier beliefs as possible and to add only that are absolutely compelled by the revision specified. But despite this emphasis the AGM postulates place almost no constraints on is expressed is that the AGM theory the next belief the to regulate conditional beliefs because is, the need beliefs on preserving propositional the preservation mainly set ought language of one-step postulates such a language deals only with transformation of revision policies as encoded of belief sets and not with transformation states. the current belief set and the current evidence. However, in terms of one-step postulates which of conditional beliefs. The reason tell us what properties is not rich enough to have, given in epistemic beliefs, In fact, a central result of the AGM theory states that the postulates are equivalent the existence of a total pre-order on all propositions erltrenchment such that belief revisions always to to their degree of epistemic in retain more entrenched propositions according \fA. Danviche. .I. Penrl/Artificitrl InrelliRence 89 (1997) l-29 3 to less entrenched for belief revision, preference necessary step postulates, hence, the postulates cannot always regulate how the ordering during belief revision. cannot be always constrained using this ordering, which carries ones. But the language of one- transforms the information Since the relative entrenchment among hypothetical beliefs is crucial for distinguishing the preservation of this relative entrenchment is as important as the preservation in of principle themselves. Moreover, since the information content of this relative entrenchment beliefs, requires two-step postulates about the revision of conditional the preservation of the former future beliefs from future disbeliefs, accordance with some minimal-change beliefs is equivalent postulates beliefs. to that of conditional the latter, namely, about The over-permissiveness for example, has tried the sweeping beliefs but conditional to changes in conditional the AGM authors them- to conditional beliefs have remedy of beliefs as result lit- triviality of the AGM postulates [ 3,191, relative including [ 2,8], but attempts at applying preservation principles into an inconsistency large, seems still reluctant in the belief set not merely propositional beliefs has been noted by several workers selves not been very successful. Gardenfors, including faltered well, and quickly [8, pp. 156-1661. Attempts at circumventing erature which, by and and propositional vation policies. More recently, Boutilier has suggested vising a belief set to propositional AGM postulates would permit egy, too, is an excessive results. As it turns out, by AGM, preserved. remedy if one [3]. We show then one is forced to accept beliefs are two different species which require the fact that conditional totally different preser- approach by de- revision operator, called natural revision, which still restricts a belief beliefs as the that this strat- beliefs, but provably preserves as many conditional in this paper, however, a promising to the AGM weakness and leads insists on preserving all conditional beliefs to retract some propositional to counterintuitive beliefs permitted to be that ought known as Gardenfors’ this result now make up voluminous The solution we suggest for preserving conditional as an operation on epistemic into if preserved, the second category of conditional is more cautious. Viewing beliefs two distinct categories; that may compromise those and those that may not. We then insist on preserv- four beliefs, and we do this proposing states, we show that conditional succinctly beliefs beliefs revision belief can be classified propositional ing only postulates. 2 as follows. is structured The rest of the paper In Section 2 we review and present a number of scenarios proposal tulates and yet exhibit counterintuitive pose a modification temic states a satisfactory minimal-change postulates the AGM the AGM pos- beliefs. Next, we pro- to epis- is necessary for in Section 4 the principle of conditional beliefs. Based on this analysis, we propose four iter- in which that such modification treatment of iterated belief revision. We then analyze in Section 5 that properly preserve conditional beliefs-hence, instead of belief sets and argue that are consistent with of the AGM postulates in conditional are applied regulating revisions changes ’ The postulates we propose are inspired by a method [ I I, 121. extended by Goldszmidt for belief change suggested by Spohn \\23,24 ] and \f4 A. Danviche, J. Pearl/ArtQicial Intelligence 89 (1997) l-29 ated revisions-and which extends [ 171. We then show a qualitative provide by discussing Appendix B. further provide a representation the one provided by Katsuno theorem for the newly proposed postulates for the AGM postulates and Mendelzon in Section 6 that the new postulates are sound with respect version of Jeffrey’s insights behind current and future rule of probabilistic conditioning. the choice of our postulates and conclude related work. Proofs of theorems to In Section 7, we in Section 8 to a",
            {
                "entities": [
                    [
                        73,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 74 ( 1995) 249-310 Artificial Intelligence Tractable reasoning via approximation * Marco Schaerf a,b,l, Marco Cadoli b** a lstituto di Elettrotecnica, Universitd di Cagliari, Piazza d’Armi, 90123 Cagliari, Italy b Dipartimento di Informatica e Sistemistica, Universitci di Roma “LA Sapienza”, via Salaria 113, 00198 Roma, Italy Received May 1993; revised November 1993 Abstract Problems in logic are well known to be hard to solve in the worst case. ‘l%o different strate- gies for dealing with this aspect are known from the literature: language restriction and theory approximation. In this paper we are concerned with the second strategy. Our main goal is to define a semanti- cally well-founded logic for approximate reasoning, which is justifiable from the intuitive point of view, and to provide fast algorithms for dealing with it even when using expressive languages. We also want our logic to be useful to perform approximate reasoning in different contexts. We define a method for the approximation of decision reasoning problems based on multivalued logics. Our work expands and generalizes, in several directions, ideas presented by other researchers. The major features of our technique are: ( 1) approximate answers give semantically clear information about the problem at hand; (2) approximate answers are easier to compute than answers to the original problem; (3) approximate answers can be improved, and eventually they converge to the right answer; (4) both sound approximations and complete ones are described. The method we propose is flexible enough to be applied to a wide range of reasoning problems. In our research we considered approximation of several decidable problems with different worst- case complexity, involving both propositional and first-order languages. In particular we defined approximation techniques for: propositional logic, fragments of first-order logic (concept descrip- *Work supp0rte.d by the ESPRIT Basic Research Action 6810-COMPLLOG II and by the Progetto Finalizzato Sistemi Informatici e Calcolo Parallel0 of the CNR (Italian Research Council). Parts of this paper appeared in prGninaxy form in papers presented at the Fourth Conference on Theoretical Aspects of Reasoning about Knowledge (TARK-92), the Third International Conference on the Principles of Knowledge Representation and Reasoning (KR-92) and the Second Italian Conference on AI ( AI*IA-91) . * Corresponding author. E-mail: cadoli@assi.dis.uniromal .it. 1 E-mail: schaerf@assi.dis.uniromal.it. 0004-3702/95/.@9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00009-P \f250 M. Schaerf. M. Cudoli/Artifciul Intelligence 74 (1995) 249-310 tion languages) and modal logic. In our research we also addressed the issue of representing the knowledge of a reasoner with limited resources and how to use such a knowledge for approximate reasoning purposes. 1. Introduction The benefits of formalizing AI problems in logic are manifold [ 45,601. Nevertheless to perform have high computational to be hard to solve in the worst case: the prototypical NP-complete problem we have to pay a price for that: one of the major drawbacks of logic as an AI tool is in the tasks that we are that if we formalize AI problems as logical problems in logic are well supposed is to known check whether a formula of propositional r.e.-complete [ 641. We notice which update.) [ 171, while the prototypical logic is inconsistent task, is a basic (e.g. knowledge the AI perspective-consistency formalisms is to check whether a formula of first-order is subsumed by many complexity. Problems logic is consistent in knowledge then typically representation that-from checking problem The computational drawback caused by logical formalization of problems of AI: Vardi in [73] shows how an increase of databases as logical objects versus in complexity their characterization characterizes is not a the as physical peculiarity formalization objects. In fact the use of “fancy” drawback the computational AI typically have higher computational order-logic. NP-complete, while consistency which complete As an example, consistency checking used for representing is commonly [ 521. forms of logic as tools for knowledge even more sensible. Logical complexity formalisms than classical-propositional representation makes in that are used or first- is logic logic PSPACE- classical logic S4-a [ 431 -is checking in propositional in the propositional modal the knowledge modality Since researchers realized this fundamental drawback, two different strategies emerged in the literature: ( 1) According to the ideas presented in [ 61, we can restrict knowledge so that the formalization representing sible, but resulting or at least decidable. As an example, propositional Horn clauses, which allow linear algorithms tasks are computationally feasible, for satisfiability of interesting the language used for cases is still pos- tractable to i.e. polynomially logic can be restricted testing [ 281. (2) According to [ 551, we could use a form of logic that allows weaker feasible is computationally power but language. As an example, propositional admits polynomial even with a full expressiveness calculus without testing for consistency algorithms [ 36,541. the modus ponens inferential in the rule Both ideas received great attention both from the theoretical and from the application- the whole database oriented community. The limited expressiveness approach. The CLASSIC built at AT&T and currently used in an industrial environment, uses both strategies. CLASSIC adopts a re- stricted avoiding some sources of intractability-but strategy underlies [4,5], allows constructors representation language-thus knowledge system \fM. Schaee M. Cadoli/Art$cial Intelligence 74 (1995) 249-310 251 that lead to intractable reasoning problems. Such constructors are dealt with incomplete inference algorithms grounded on non-standard semantics. For what concerns the language restriction approach, fundamental studies on the com- plexity of fragments of classical propositional [ 661 and first-order logic [ 291 have been done in the last decades. More recently, computational studies about several logical formalisms relevant for KR appeared. Studies analyzing the so-called tractability thresh- old between polynomially tractable and intractable languages are of particular practical interest. Among the most significant in this group we cite [27] on concept description languages, [ 48,7 11 on default logic, [ 101 on closed-world reasoning and circumscrip- tion, [ 3 1 ] on logic-based abduction, [ 701 on path-based inheritance, [ 81 on set covering abduction. As far as weak forms of reasoning are concerned, it is well known that AI has incompleteness and heuristics. The kind of weak always dealt with approximation, reasoning we are interested in in this work can be described in a nutshell as follows: we have a satisfactory logical formalization of a reasoning problem, but we don’t want to implement it exactly as it is, because it is computationally too expensive; hence we look for a formalization that “looks like” our favorite one, but it is easier to compute. In this work we are mainly interested in decision problems, as reasoning problems usually admit a boolean answer. Informally, an approximate solution to a decision problem is a “maybe” answer, equipped with reasons to believe that the “maybe” is actually a “yes” or to believe that it is actually a “no”. In a form of approximate reasoning called sound reasoning we have two possible answers: “yes” and “maybe no”. In the dual form of approximate reasoning (complete reasoning), the two possible answers are “no” and “maybe yes”. The obvious important questions we are faced with are: how do we measure the accuracy of an approximate answer? How do we know an approximate answer is any better than another one? It is important to recall that in logic we have no explicit metric that gives an immediate answer to the above questions. In this respect, approximation of reasoning problems is more difficult to study than approximation of optimization problems. Approximation schemata for reasoning problems are typically justified by means of cognitive or epistemic arguments (e.g. “this is an approximate but satisfactory description of how people reason”). Logic-based study of approximate reasoning is receiving increasing attention in the Al community. Several formalisms for weak reasoning that are supported by a “reasonable” semantics recently appeared. To this end the most significant approaches to a formal description of partial reasoning are Levesque’s [ 54-561 architecture based on incomplete reasoning, Frisch’s [ 35,361 limited inference systems, Crawford and Kuiper’s [ 191 access-limited logic, Kautz and Selman’s [47,49,69] knowledge compilation and Dean and Boddy’s [23] any-time algorithms, further investigated by Russell and Zilberstein in [ 651 and by Ginsberg in [ 391. In this work we are interested in the “tractability via approximation” approach. Our goal is to define a semantically well-founded logic for approximate reasoning, justifiable from the intuitive point of view, and to provide fast algorithms for dealing with it even when using expressive languages. We also want our logic to be useful to perform approximate reasoning in different contexts. \f252 M. Schaerf; M. Cudoli/Art~ciul Intelligence 74 (I995) 249-310 We define a method for the approximation logics. The use of multivalued tractable reasoning of decision logics for representing problems based forms of local, reasoning has already been attempted by other ideas in several directions [ 36,541.) Our work expands and generalizes on multivalued incomplete authors presented by those researchers. and polynomially (cf. In order to introduce the topic of logic-based in the approximation, in this paper we survey literature by other authors: Levesque’s reasoning and Selman and Kautz’s knowledge compil",
            {
                "entities": [
                    [
                        76,
                        113,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1555–1569Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHybrid tractability of valued constraint problems ✩Martin C. Cooper a, Stanislav Živný b,c,∗a IRIT, University of Toulouse III, 31062 Toulouse, Franceb University College, University of Oxford, Oxford OX1 4BH, UKc Computing Laboratory, University of Oxford, Oxford OX1 3QD, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 24 August 2010Received in revised form 6 December 2010Accepted 19 February 2011Available online 24 February 2011Keywords:Constraint optimisationComputational complexityTractabilitySoft constraintsValued constraint satisfaction problemsGraphical modelsForbidden substructuresThe constraint satisfaction problem (CSP) is a central generic problem in computer scienceand artificial intelligence: it provides a common framework for many theoretical problemsas well as for many real-life applications. Valued constraint problems are a generalisation ofthe CSP which allow the user to model optimisation problems. Considerable effort has beenmade in identifying properties which ensure tractability in such problems. In this work, weinitiate the study of hybrid tractability of valued constraint problems; that is, propertieswhich guarantee tractability of the given valued constraint problem, but which do notdepend only on the underlying structure of the instance (such as being tree-structured) oronly on the types of valued constraints in the instance (such as submodularity). We presentseveral novel hybrid classes of valued constraint problems in which all unary constraintsare allowed, which include a machine scheduling problem, constraint problems of arbitraryarities with no overlapping nogoods, and the SoftAllDiff constraint with arbitrary unaryvalued constraints. An important tool in our investigation will be the notion of forbiddensubstructures.© 2011 Elsevier B.V. All rights reserved.1. IntroductionAn instance of the constraint satisfaction problem (CSP) consists of a collection of variables which must be assignedvalues subject to specified constraints. Each CSP instance has an underlying hypergraph, known as its constraint hypergraph,whose vertices are the variables of the instance and whose hyperedges are the scopes of the constraints. Such a hypergraphis also known as the structure of the instance.An important line of research on the CSP is to identify all tractable cases which are recognisable in polynomial time.Most of this work has been focused on one of the two general approaches: either identifying forms of constraint which aresufficiently restrictive to ensure tractability no matter how they are combined [1,2], or else identifying structural propertiesof constraint networks which ensure tractability no matter what forms of constraint are imposed [3].The first approach has led to identifying certain algebraic properties known as polymorphisms [4] which are necessaryfor a set of constraint types to ensure tractability. A set of constraint types which ensures tractability is called a tractableconstraint language. The second approach has been used to characterise all tractable cases of bounded-arity CSPs (such asbinary CSPs): the only class of structures which ensures tractability (subject to certain complexity theory assumptions) areessentially structures of bounded tree-width [5,6].✩A preliminary version of part of this work appeared in Proceedings of the 16th International Conference on Principles and Practice of Constraint Programming(CP), LNCS, vol. 6308, 2010, pp. 152–166. This work was supported by EPSRC grant EP/F01161X/1. Stanislav Živný was supported by Junior ResearchFellowship at University College, Oxford.* Corresponding author at: Computing Laboratory, University of Oxford, Wolfson Building, Parks Road, Oxford OX1 3QD, UK. Tel: +44 (0)1865 273884.E-mail addresses: cooper@irit.fr (M.C. Cooper), standa.zivny@comlab.ox.ac.uk (S. Živný).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.02.003\f1556M.C. Cooper, S. Živný / Artificial Intelligence 175 (2011) 1555–1569In practice, constraint satisfaction problems usually do not possess a sufficiently restricted structure or use a sufficientlyrestricted constraint language to fall into any of these tractable classes. Nevertheless, they may still have properties whichensure they can be solved efficiently, but these properties concern both the structure and the form of the constraints. Suchproperties have sometimes been called hybrid reasons for tractability [7–11].Since in practice many constraint satisfaction problems are over-constrained, and hence have no solution, or are under-constrained, and hence have many solutions, soft constraint satisfaction problems have been studied [7]. Several very generalsoft CSP frameworks have been proposed in the literature [12,13]. In this paper we focus on one of the very generalframeworks, the valued constraint satisfaction problem (VCSP) [12]. In an instance of the valued CSP, every constraint isassociated with a cost function (rather than a relation as in the CSP) which allows the user to express preferences amongdifferent partial assignments, and the goal is to find an optimal assignment (i.e. an assignment of smallest total cost).Similarly to the CSP, an important line of research on the VCSP is to identify tractable cases which are recognisable inpolynomial time. It is well known that structural reasons for tractability generalise to the VCSP [7]. In the case of languagerestrictions, only a few conditions are known to guarantee tractability of a given set of valued constraints [14–16,22].Up until now there have been very few results on hybrid tractability for the VCSP, that is, tractability of subproblems ofthe VCSP defined by properties which are not exclusively language-based or structure-based. For instance, Kumar defines aninteresting framework for hybrid tractability for the Boolean weighted CSP [10]. However, to the best of our knowledge, thisframework has so far not provided any new hybrid classes. In fact, all tractable classes presented in [10] are not hybrid andare already known.Contributions. The main contribution of the paper is the study of hybrid tractability of VCSPs and the introduction of novelhybrid tractable classes of VCSPs. As a first step, we start with binary VCSPs.We introduce the class defined by the joint-winner property (JWP). This class generalises the SoftAllDiff constraint witharbitrary unary valued constraints. Moreover, we generalise this class to a larger class of non-binary VCSPs including CSPand MAX-CSP instances with no overlapping nogoods.The rest of the paper is organised as follows. In Section 2, we define binary constraint satisfaction problems (CSPs),valued constraint satisfaction problems (VCSPs) and other necessary definitions needed throughout the paper. In Section 3,we study binary VCSPs whose only soft constraints are unary. A connection between these VCSPs and the maximum weightindependent set problem in certain graph classes leads in a straightforward manner to corresponding hybrid tractable classesof VCSPs. In Section 4, we define the joint-winner property and give several examples of studied problems that satisfy thejoint-winner property. In Section 5, we study important properties of VCSP instances satisfying the joint-winner property,which allow us, in Section 6, to present a polynomial-time algorithm for solving binary VCSPs satisfying the joint-winnerproperty. In Section 7, we prove that this new tractable class is maximal. In Section 8, we extend the class of tractable VCSPsdefined by the joint-winner property. Finally, in Section 9, we summarise our work and finish with some open problems.We remark that even though our results are formulated as valued constraint satisfaction problems, it is clear that theseresults apply to various other optimisation frameworks that are equivalent to valued constraint problems such as Gibbsenergy minimisation, Markov Random Fields and other graphical models [17,18].2. PreliminariesIn this paper we firstly focus on binary valued constraint satisfaction problems before generalising to problems with costfunctions of arbitrary arity. We denote by Q+ the set of all non-negative rational numbers. We denote Q+ = Q+ ∪ {∞} withthe standard addition operation extended so that for all a ∈ Q+, a + ∞ = ∞. Members of Q+ are called costs.A unary cost function over domain D i is a mapping ci : D i → Q+. A binary cost function over domains D i and D j is amapping ci j : D i × D j → Q+. If the range of ci (ci j respectively) lies entirely within Q+, then ci (ci j respectively) is called afinite-valued cost function.If the range of ci (ci j respectively) is {α, ∞}, for some α ∈ Q+, then ci (ci j respectively) is called a crisp cost function.Note that crisp cost functions are just relations; that is, subsets of D i (in the unary case) or D i × D j (in the binary case)corresponding to the set of finite-cost tuples. If ci (ci j respectively) is not a crisp cost function, it is called soft.A binary VCSP instance [12] consists of a set of variables (denoted as v i , where i ∈ {1, . . . , n}); for each variable v i adomain D i containing possible values for variable v i ; and a set of valued constraints. Each valued constraint is either of theform (cid:7)v i, ci(cid:8), where v i is a variable and ci is a unary cost function (constraints of this form are called unary constraints),or of the form (cid:7)(cid:7)v i, v j(cid:8), ci j(cid:8), where v i and v j are variables with i < j, the pair (cid:7)v i, v j(cid:8) is called the scope of the constraint,and ci j is a binary cost function (constraints of this form are called binary constraints). A constraint is called crisp if itsassociated cost function is crisp, and similarly a constraint is called soft if its associated cost function is soft. For notationalconvenience, throughout this paper we assu",
            {
                "entities": [
                    [
                        138,
                        187,
                        "TITLE"
                    ],
                    [
                        1223,
                        1272,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 87 ( 1996) 2 15-254 Artificial Intelligence Improving accuracy by combining rule-based and case-based reasoning Andrew R. Golding a,*, Paul S. Rosenbloom b a Mitsubishi Electric Research Laboratories, b Information Sciences Institute and Computer Science Department, University of Southern California, 201 Broadway, 8th Floes Cambridge, MA 02139. USA 4676 Admiralty Way, Marina de1 Rey, CA 90292, USA Received October 1994; revised November 1995 Abstract An architecture is presented reasoning. The architecture for combining that are understood rule-based and case-based reasonably well, but still imperfectly. for domains is intended It uses a set of rules, which are taken to be only approximately correct, to obtain a preliminary answer for a given problem; it then draws analogies from cases to handle exceptions to the rules. Having rules together with cases not only increases the architecture’s domain coverage, it also allows innovative ways of doing case-based reasoning: the same rules that are used for rule-based reasoning are also used by the case-based component to do case indexing and case adaptation. The architecture was applied to the task of name pronunciation, and, with minimal knowledge engineering, was found to perform almost at the level of the best commercial systems. Moreover, its accuracy was found to exceed what it could have achieved with rules or cases alone, thus demonstrating the accuracy improvement afforded by combining rule-based and case-based reasoning. 1. Intmduction to which and correctly Domains vary in the degree have been codified completely those for which no such rules are known. This paper fall between these two extremes, but closer which a set of rules domain. The rules must also be able to be run efficiently. cases both provide valuable knowledge. While they are understood, ranging in terms of a set of rules of behavior, is concerned with domains to the “well-understood” end-domains from those that to that for of the rules and that In such domains, the rules embody the understanding is known, but the rules do not cover the full complexities * Corresponding author. E-mail: golding@merI.com. 0004-3702/96/$15.00 Copyright @ 1996 Elsevier Science B.V. All rights reserved. SSD10004-3702(95)00120-4 \fform-illustrations in the rules the idiosyncratic has been codified over the years by experts, cases contain knowledge of the domain a more unprocessed complete with idiosyncrasies codified knowledge of cases, while by known combining The architecture to obtain a preliminary to handle exceptions that occur of actual behaviors and irregularities. Neither source subsumes is not necessarily well represented knowledge is the basis in in the domain, the other-the by any given set captured presented here for [ 20,301. correct, from cases (CBR) uses a set of rules, which arc taken to be only approximately rules. This observation rule-based answer to the rules. (RBR) 1 171 and case-based it then draws analogies for a given problem; for the architecture is not necessarily in the cases reasoning reasoning rules Having innovations the domain incorporates it also allows two novel methods to supply appropriate the architecture in CBR for CBR that are based on exploiting together with the cases not only allows First, termed prediction-based to take advan- technology. The tage of more domain knowledge. the architecture the rules are used to index the cases. The index- rules of the RBR component. indexing, hangs cases directly off the rules, using ing scheme, cues for case retrieval. This avoids having the rule antecedents indexing to analyze features; in the rules, and hence already available. The second role of the rules in CBR is for case adaptation, via a strategy of “case adaptation by factoring”. The rules are used to factor each source the case, through a process of case into rational reconstruction. The individual that the fine grained to target, despite overall dispar- relevant ones can be transferred verbatim ities between the source case to enable transfer from source is thus a way of adapting to identify a suitable vocabulary of direct and derived it takes advantage of the domain steps that were applied within steps are then sufficiently to globally dissimilar the cases. Factoring the individual structure instead, implicit To test the architecture task. it was applied engineering, the resulting to perform almost at the level of the best commercial pronunciation. With minimal knowledge was found systems, and substantially task (two versions of NETtalk). Moreover. Anapron’s what it could have achieved with rules or cases alone, improvement than other machine-learning rule-based and case-based afforded by combining better thus demonstrating reasoning. accuracy was found systems applied to this to exceed the accuracy to the problem of name ’ system, Anapron, name-pronunciation The next section presents the architecture, independent of the domain of name pronun- system. which instantiates ciation. The Anapron is then described. A set of experiments on Anapron are presented, an empirical demonstration The last two sections discuss related work. and conclude. of the improvement the architecture obtained by combining for name pronunciation, the key result being rules and cases. 2. The architecture The architecture is organized as a set of modules that can be configured according to the needs of the domain; see Fig. I The minimal configuration consists of four modules, ’ Anapron stands for Rrrulogical prmunciatlon system target cases. for a real-world \fA.R. Gelding, P.S. Rosenbioom/Artijciul Intelligence 87 (1996) 215-254 217 Weak theory I Problem/answer Similarity metric I Problen 4nswer Core method Fig. 1. Anatomy of the architecture. The black outer rectangle represents the overall architecture for combining RBR and CBR; the gray inner rectangle encloses the core method. Boxes represent modules of the architecture, and icons stand for knowledge structures. Links indicate dependencies between components. termed four modules the core method, shown in the diagram enclosed are the heart of the architecture-they three modules, collectively rectangle. These method for combining RBR and CBR. The remaining modules, perform various Each of these modules may be included, on a domain-by-domain make up the difference knowledge in the gray inner the implement termed the support the knowledge needed by the core method. to the basis, as needed needed by the core method and that is already available roles in acquiring in the domain. the knowledge between The sections below describe and the support followed by a discussion of design issues. For ease of exposition, examples will the core method of the architecture domain; the instantiation to name pronunciation modules, be drawn from a toy (but implemented) to Section 3. is deferred \fProcedure RC-Hybrid(pmhlm) (a) RBR: Use the rules to select an operator ( h 1 CBR: Look (c) Combination: Decide between that contradict for analogles to apply. the operator suggested by RBR. the operators suggested by RBR and CBR Fig. 2. Top-level procedure l’ur combming rule-based and case-based reasoning. 2.1. The cm-e ruethad from cases The core method to draw analogies of RBR and CBR. The central is the heart of the architecture; answer, and idea is expressed solving as a process of applying operators to get an approximate to the rules. This treats problem it is solved. The procedure by a combination problem exceptions The procedure problem until chooses It then looks for analogies the combination by RBR or one suggested by CBR. Underlying and line tuning with the cases is the assumption of rules applies CBR and RBR in the opposite order. it is the part that solves problems idea is to apply the rules to the target to cover in the RC-Hybrid procedure of Fig. 2. to the target It iteration. to apply via the rules. ln to actually apply-the one suggested this strategy of starting with the rules fast and accurate set that a reasonably If not, a different architecture may be called for, such as one that it selects an operator the rules and suggest alternative operators. in three steps. First that contradict step, it decides which operator applies one operator on each the operator is available. The core method gets its domain knowledge in the domain using a set of rules. It has two components: and a set of operators. The operators define the legal actions from four sources: a weak theory of the domain. a case library, a similarity metric, and a set of thresholds. The weak theory is a method for solving problems in the the rules themselves, domain. Each operator may have an associated applicability that limits the set of states in which it can be applied. The rules provide search control, specifying exactly is weak in the to apply one operator the right operator sense that it does not always suggest it did, there would in the first place. In fact, even if the weak theory be no reason to apply the architecture the architecture may be able to recover does not contuirr failures by applying in the case library, and which invents new of the weak theory (see Section 2.2.2). operators theory extension. which detects such missing operators by noticing for examples the failures in every problem-solving the right operator state. A weak (and rules) to account to apply-if to correct to apply, condition theory As an example of a weak theory, consider a toy version of a problem in auto insurance: to assess the risk of insuring a new client. Solving a problem three steps: determining whether he2 is in a hostile driving environment, his level of risk. Each step is implemented operators. For example, implemented driver-is the first step-determining by applying the attentive the client whether either in this domain consists of is an attentive driver, determining whether assessing inferences, and, based on the previous by applying one of a corresponding set of the client, c, is a",
            {
                "entities": [
                    [
                        77,
                        144,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 78 (1995) 213-238 Artificial Intelligence Understanding positioning from multiple images Roger Mohr ‘, Boubakeur Boufama2, Pascal Brand 3 Lifa-lnria, 46 avenue F&.x Kallel, 38031 Grenoble Cedex, France Received October 1993; revised December 1994 Abstract structure of a scene using only correspondences It is possible images to recover taken with uncalibrated the three-dimensional cameras transformation (faugeras 1992). The reconstruction obtained between of the 3D space. However, this kind this way is only defined up to a projective of structure allows some spatial reasoning such as finding a path. In order to perform more specific reasoning, or to perform work with a robot moving in Euclidean space, Euclidean or affine constraints have to be added to the camera observations. Such constraints arise from constraints on lines, etc. First, this the knowledge of the scene: it discusses how the framework of paper presents a reconstruction method projective geometry allows symbolic or numerical to be derived, and how knowledge Implementation about the scene can be used for computing issues and experimental results are discussed. location of points, geometrical then information about positions symbolic or numerical for the scene, relationships. 1. Introduction I. 1. Motivation In the late seventies, Artificial interpretation. image of image relations between for instance Expressing izontally. More complex hard to define, as an image [4] ) reduce such a relation the labelling implicitly relationships Intelligence techniques were introduced Symbolic features. For instance, knowledge was introduced constraints during possibilities into the field by means of geometric (see process. forward hor- they are like above(sky, the interpretation is looking tree) assumes like inside may also be used, however that the camera is only a 2D projection of the 3D scene. 1 E-mail: mohr@imag.fr. * Current address: mpartement d’Informatique, Universite de Moncton, Moncton, New Brunswick, Canada ElA 3E9. E-mail: boufama@clement.info.unmoncton.ca. 3 E-mail: brand@imag.fr. 0004-3702/95/$09.50 SSDIOOO4-3702(95)00035-6 0 1995 Elsevier Science B.V. All rights reserved \f214 R. Mohr et trl. /Artificial Intelligence 78 (1995) 213-238 The goal of this paper is to show how geometry provides a set of basic tools for computing numerically what is often implicit geometric knowledge and inside. symbolic relationships, and to make explicit and computable in such relationships. The framework will point out the kind of like above that is needed and how to explicitly compute relations From a single it is very hard to derive 3D relationships image is to use high level alternative framework allows high level reasoning, but on the other hand for this reasoning plementary outputs are mainly numerical 3D information in the scene. An in [7,29]. This required to the domain considered. Such approaches are com- and the to the one presented here: we use very little a priori information and some simple symbolic of the scene as is done is very specific the knowledge relationships. interpretation This paper presents a general way for expressing geometrical such as 3D relationships information to compute how observed in the images. Such numerical computations by at least two cameras and the points are matched we allow the burden of calibration. change, the field of active vision. the camera position and orientation the uncalibrated framework constraints between geometrical assume in the different and shows features that the scene is observed images. However, to be unknown. This allows us to avoid the focus and aperture in be placed Since camera parameters vary when that we outline here can conveniently It was shown in [6, lo] (i.e. non-metric is possible. The reconstruction of the 3D projective eras a collineation struction past few years. Projective However, space can be seen as a constrained provided. Euclidean information based comparison tries). and relationships relationships information that reconstruction of the scene with uncalibrated has no metric space. However, cam- is defined up to the use of this kind of recon- in the cross ratio, etc. like parallelJo, midpoint&f are affine properties. Since affine space, additional knowledge needs to be information), space allows us to talk about collinearity, has received more and more attention projective and space can be seen as a constrained is needed yet more knowledge must be provided between projective, affine space, so if Euclidean (see [ 141 for an invariant geome- affine and Euclidean 1.2. Outline Projective, affine and Euclidean geometries in Section 2. Firstly we introduce They are introduced are needed, and then, show how projective least squares approach. An outline of this approach was presented new results on real images are discussed, aspects of the method. reconstructions illustrating form the basic framework of this paper. tools that the in [ 201. Here, some can be obtained using the basic geometrical both qualitative and quantitative Next, we consider different relationships between geometric entities. We will show that than just projective space contains more in projective done in fact the reconstruction information. possible affine information relation needs additional to compute In fact, so called quasi-affine information some qualitative affine relationships is not enough information for some precise relationships. about the vertical direction. is available, from which it is and convex hulls. However, For instance, above \fR. Mohr et al. /Ar#cial Intelligence 78 (1995) 213-238 215 This leads to a hierarchy of geometrical knowledge which allows us to define sets of symbolic relationships. knowledge affine geometry, geometry of similarities can be considered Classical 19th century geometry describes a hierarchy of embedded geometries: pro- geometry. the con- a jective geometry, However, other non-standard servation of convexity particular direction From a practical point of view, this hierarchy of geometries corresponds of constraints provided reconstruction geometry. to a hierarchy can be the general geometry, while preserving sub-tine on the perceived from a priori knowledge, scene. Section 3 shows how these constraints and Euclidean too. For instance leads to the notion of quasi-alone and how they can be integrated like the vertical direction leads to a particular framework. into Section 4 presents reconstruction mediate spaces. Finally, we discuss results and examples of computations issues raised by the present work. in the inter- 2. The geometrical framework 2.1. Introduction to projective geometry the reader with the geometrical background to under- This section aims at providing stand the remainder of the paper. the image formation We model system as a pure perspective projection, systems. Sometimes model we adopt is the pinhole model. This is a good approximation acquisition [ 3 11, and if a very high accuracy necessary in order to simulate this model has to be corrected is needed more sophisticated [ 171. It has to be mentioned the pure pinhole model. that these last models mainly correct of existing i.e. the camera image for radial distortion correction methods are the image and therefore provides clear understanding We will present a short introduction Projective geometry deals elegantly with the general case of perspective projection of the geometric aspects of image formation. and vocabulary of projective geometry. The reader is referred to [ 251 for a gentle introduction or to [ 151 for advanced vision oriented considerations on projective geometry. to the definitions Projective space Consider the (n + 1 )-dimensional space Wn+’ - { (0, . . . , 0) } with the equivalence relation: (XI,...,x,+I) N (x’, ,... ,x;+~> iff 3A # 0 such that (x’,, . . .,x;+,) = A(xl,. . . ,xn+l). (1) The quotient space obtained Thus the (n + 1) -tuples of coordinates in the projective same point from this equivalence (xl,. . . , .x,+1 ) and (xi,. relation is the projective space P”. . . , XL,, ) represent the coordinates. space and are called affine space A” is mapped the homogeneous into P” through the correspon- The usual n-dimensional dence ?‘: \f216 R. Mohr et al./ArtiJicial Inielligence 78 (1995) 213-238 P: (x I,..., x,) --f (x ,,..., x,,l). (2) and Note that p that only is a one-to-one mapping . . ,A-,,, 0) are not reached. the points ly provides us with an understanding by of the points it space; if we con- (yt , . . , y,,, 0) as the limit of (yt , . . . , y,,, A) while h -+ 0, i.e. the limit of in the direc- . , y,,, 0) as the “point at infinity” (xl,. (XI >. . . ,x,, 1) which can be viewed as the usual point also provides us with an intuitive understanding sider ( yt /A, . . tion (yt,... (or ideal point) , y,/A, 1). This is the limit of a point in W” going to the infinity , yn ). Therefore, we can consider (yt , . of the remaining in this direction. the Euclidean represented points: in A hyperplane H in P” is defined by a homogeneous (n + I)-tuple of coefficients, H = (a,,. . , anfl ) . This defines the set of points whose coordinates satisfy ,,+ I c U;Xi = HXr = 0. A particular points at infinity. case is the ideal hyperplane x,+1 = 0: this is the hyperplane with all its A collineation or projective transformation (n + 1) x (n + 1) matrix W such that the image of (XI,. . . ,xn+l) from P” into P” is the mapping defined is by a full rank defined in the usual way by: Since the column Therefore, a collineation vectors are defined up to a scaling factor, the matrix W is too. has (n + 1) x (n + 1) - 1 degrees of freedom. space P” A basis of a projective is given by n + 2 points, of which no n + 1 lie in the same hyperplane. The canonical . . ., ( 1 , 1, . . . , 1). For the regular 3D pro- (0, 0, , 0, 1) augmented with the “unit point” jective spaces, these four first points are the point at infinity on the x-axis, on the y-axis, on the z-axis and the origin, basis usually chose",
            {
                "entities": [
                    [
                        75,
                        121,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 241 (2016) 191–216Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintFinding a collective set of items: From proportional multirepresentation to group recommendation ✩Piotr Skowron a,∗a University of Oxford, Oxford, UKb AGH University of Science Technology, Krakow, Polandc Université Paris-Dauphine, Paris, France, Piotr Faliszewski b, Jérôme Lang ca r t i c l e i n f oa b s t r a c tWe consider the following problem: There is a set of items (e.g., movies) and a group of agents (e.g., passengers on a plane); each agent has some intrinsic utility for each of the items. Our goal is to pick a set of K items that maximize the total derived utility of all the agents (i.e., in our example we are to pick K movies that we put on the plane’s entertainment system). However, the actual utility that an agent derives from a given item is only a fraction of its intrinsic one, and this fraction depends on how the agent ranks the item among the chosen, available, ones. We provide a formal specification of the model and provide concrete examples and settings where it is applicable. We show that the problem is hard in general, but we show a number of tractability results for its natural special cases.© 2016 Elsevier B.V. All rights reserved.Article history:Received 29 October 2015Received in revised form 3 June 2016Accepted 16 September 2016Available online 22 September 2016Keywords:Proportional representationOrdered weighted averageChamberlin–Courant ruleComputational complexityApproximationElectionsVoting1. IntroductionA number of real-world problems consist of selecting a set of items for a group of agents to jointly use. Examples of such activities include picking a set of movies to put on a plane’s entertainment system, deciding which journals a university library should subscribe to, deciding what common facilities to build, or even voting for a parliament (or other assembly of representatives). Let us consider some common features of these examples.First, there is a set of items1 and a set of agents; each agent has some intrinsic utility for each of the items (e.g., this utility can be the level of appreciation for a movie, the average number of articles one reads from a given issue of a journal, expected benefit from building a particular facility, the feeling—measured in some way—of being represented by a particular politician).Second, typically it is not possible to provide all the items to the agents and we can only pick some K of them, say (a plane’s entertainment system fits only a handful of movies, the library has a limited budget, only several sites for the facilities are available, the parliament has a fixed size).Third, the intrinsic utilities for items extend to the sets of items in such a way that the utility derived by an agent from a given item may depend on the rank of this item (from the agent’s point of view) among the selected ones. Extreme ✩The preliminary version of this paper was presented at AAAI-2015.* Corresponding author.E-mail addresses: piotr.skowron@cs.ox.ac.uk (P. Skowron), faliszew@agh.edu.pl (P. Faliszewski), lang@lamsade.dauphine.fr (J. Lang).1 We use the term ‘item’ in the most neutral possible way. Items may be candidates running for an election, or movies, or possible facilities, and so on.http://dx.doi.org/10.1016/j.artint.2016.09.0030004-3702/© 2016 Elsevier B.V. All rights reserved.\f192P. Skowron et al. / Artificial Intelligence 241 (2016) 191–216examples include the case where each agent derives utility from his or her most preferred item only (e.g., an agent will watch his or her favorite movie only, will read/use the favorite journal/favorite facility only, will feel represented by the most appropriate politician only), from his or her least preferred item only (say, the agent worries that the family will force him or her to watch the worst available movie), or derives 1/K of the utility from each of the available items (e.g., the agent chooses the item—say, a movie—at random). However, in practice one should expect much more complicated schemes (e.g., an agent watches the top movie certainly, the second one probably, the third one perhaps, etc.; or, an agent is interested in having at least some T interesting journals in the library; an agent feels represented by some top T members of the parliament, etc.).The goal of this paper is to formally define a model that captures all the above-described scenarios, provide a set of examples where the model is applicable, and provide an initial set of computational results for it in terms of efficient algorithms (exact or approximate) and computational hardness results (NP-hardness and inapproximability results).Our work builds upon, generalizes, and extends quite a number of settings that have already been studied in the litera-ture. We provide a deeper overview of this research in Section 8 and here we only mention the two most directly related lines of work. First, our model where the agents derive utility from their most preferred item among the selected ones directly corresponds to winner determination under the Chamberlin–Courant’s voting rule [18,50,7] (it is also very deeply connected to the model of budgeted social choice [41,49,42]) and is in a certain formal sense a variant of the facility location problem. Second, the case where for each item each agent derives the same fraction of the utility is, in essence, the same as K -winner range-voting (or K -winner Borda [21]); that agents enjoy equally the items they get is also a key assumption in the Santa Claus problem [6], and in the problem of designing optimal picking sequences [14,10,35].The paper is organized as follows. First, in Section 2 we discuss several important modeling choices and provide the for-mal description of our model. Then, in Section 3, we discuss the applicability of the model in various scenarios. Specifically, we show a number of examples that lead to particular parameter values of our model. We give an overview of our results in Section 4 and then, in Sections 5, 6, and 7, we present these results formally. In Section 5 we present results regarding the complexity of computing exact solutions for our model. In the next two sections we discuss the issue of computing approximate solutions. First without putting restrictions on agents’ utilities (Section 6) and, then, for what we call non-finicky utilities (Section 7). Intuitively put, under non-finicky utilities the agents are required to give relatively high utility values to a relatively large fraction of the items. We believe that the notion of non-finicky utilities is one of the important contributions of this paper. We discuss related work in Section 8 and conclude in Section 9.2. The modelIn this section we give a formal description of our model. However, before we move on to the mathematical details, let us explain and justify some high-level assumptions and choices that we have made.First, we assume that the agents have separable preferences. This means that the intrinsic utility of an object does not depend on what other objects are selected. This is very different from, for example, the case of combinatorial auctions. However, in our model the impact of an object on the global utility of an agent does depend on its rank (according to that agent) among the selected items. This distinction between the intrinsic value of an item and its value distorted by its rank is also considered in several other research fields, especially in decision theory (where it is known as “rank-dependent utility theory”) and in multicriteria decision making, from which we borrow one of the main ingredients of our approach, the ordered weighted average (OWA) operators [58] (for technical details see the work of Kacprzyk et al. [34]). OWAs were recently used in social choice in several contexts [31,3,23]; we discuss these works in detain in Section 8.Second, throughout the paper we navigate between two views of the agents’ intrinsic utilities:1. Generally, we assume that the utilities are provided explicitly in the input as numerical values, and that these values are comparable between agents. Yet, we make no further assumptions about the nature of agents’ utilities: they do not need to be normalized, they do not need to come from any particular range of values, etc. Indeed, it is possible that some agent has very strong preferences regarding the items, modeled through high, diverse utility values, whereas some other agent does not care much about the selection process and has low utility values only.2. In some parts of the paper (which will always be clearly identified), we assume that utilities are heavily constrained and are derived from non-numerical information, such as approval ballots specifying which items an agent approves (leading to approval-based utilities), or rankings over alternatives, from which utilities are derived using an agent-independent scoring vector (typically, a Borda-like vector).Formally, the latter view is a special case of the former, but we believe that it is worthwhile to consider it separately. Indeed, many multiwinner voting rules (such as the Chamberlin–Courant [18] rule or the Proportional Approval Voting rule [37]) fit the second view far more naturally, whereas for other applications the former view is more natural.Third, we take the utilitarian view and measure the social welfare of the agents as the sum of their perceived utilities. One could study other variants, such as the egalitarian variant, where the social welfare is measured as the utility of the worst-off agent. We leave this as possible future research (our preliminary attempts indicated that the egalitarian setting is computationally even harder than the utilitarian one). Very recently, Elkind and Ismaïli [23] used OWA operators to define variants of the Chamberlin–Courant rule that lay between the utilitarian and egalitarian variants, while Amanatidis et al",
            {
                "entities": [
                    [
                        136,
                        232,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 213 (2014) 42–59Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe price of query rewriting in ontology-based data accessGeorg Gottlob a, Stanislav Kikot b, Roman Kontchakov b, Vladimir Podolskii c,Thomas Schwentick d, Michael Zakharyaschev b,∗a Department of Computer Science, University of Oxford, UKb Department of Computer Science and Information Systems, Birkbeck, University of London, UKc Steklov Mathematical Institute, Moscow, Russiad Fakultät für Informatik, TU Dortmund, Germanya r t i c l ei n f oa b s t r a c tArticle history:Received 7 July 2013Received in revised form 13 March 2014Accepted 26 April 2014Available online 5 May 2014Keywords:OntologyDatalogConjunctive queryQuery rewritingSuccinctnessBoolean circuitMonotone complexity1. Introduction±±linear Datalogand sticky DatalogWe give a solution to the succinctness problem for the size of first-order rewritingsof conjunctive queries in ontology-based data access with ontology languages such as. We show that positive existential andOWL 2 QL,nonrecursive datalog rewritings, which do not use extra non-logical symbols (except forintensional predicates in the case of datalog rewritings), suffer an exponential blowupin the worst case, while first-order rewritings can grow superpolynomially unless NP ⊆P/poly. We also prove that nonrecursive datalog rewritings are in general exponentiallymore succinct than positive existential rewritings, while first-order rewritings can besuperpolynomially more succinct than positive existential rewritings. On the other hand,we construct polynomial-size positive existential and nonrecursive datalog rewritingsunder the assumption that any data instance contains two fixed constants.© 2014 Elsevier B.V. All rights reserved.±.Our aim in this article is to give a solution to the succinctness problem for various types of conjunctive query rewritingin ontology-based data access (OBDA) with basic ontology languages such as OWL 2 QL and fragments of DatalogThe idea of OBDA has been around since about 2005 [14,19,28,47]. In the OBDA paradigm, an ontology defines a high-level global schema and provides a vocabulary for user queries. An OBDA system rewrites these queries into the vocabularyof the data and then delegates the actual query evaluation to the data sources (which can be relational databases, triplestores, datalog engines, etc.). OBDA is often regarded as an important ingredient of the new generation of information sys-tems because it (i) gives a high-level conceptual view of the data, (ii) provides the users with a convenient vocabulary forqueries, thus isolating them from the details of the structure of data sources, (iii) allows the system to enrich incompletedata with background knowledge, and (iv) supports queries to multiple and possibly heterogeneous data sources.A key concept of OBDA is first-order (FO) rewritability. An ontology language L is said to enjoy FO-rewritability if anyconjunctive query (CQ) q over any ontology Σ , formulated in L, can be rewritten to an FO-query qsuch that, for any datainstance D, the answers to the original CQ q over the knowledge base (Σ, D) can be computed by evaluating the rewriting(cid:4)* Corresponding author.E-mail addresses: georg.gottlob@cs.ox.ac.uk (G. Gottlob), staskikotx@gmail.com (S. Kikot), roman@dcs.bbk.ac.uk (R. Kontchakov), podolskii@mi.ras.ru(V. Podolskii), thomas.schwentick@udo.edu (T. Schwentick), michael@dcs.bbk.ac.uk (M. Zakharyaschev).http://dx.doi.org/10.1016/j.artint.2014.04.0040004-3702/© 2014 Elsevier B.V. All rights reserved.\fG. Gottlob et al. / Artificial Intelligence 213 (2014) 42–5943(cid:4)(cid:4)(cid:4)over D. As qis an FO-query, the answers to qqcan be obtained using a standard relational database management system(RDBMS). Ontology languages with this property include the OWL 2 QL profile of the Web Ontology Language OWL 2, whichis based on description logics of the DL-Lite family [16,4], and fragments of Datalogsuch as linear tgds [11] (also knownas atomic-body existential rules [6]) or sticky tgds [12,13]. To illustrate, consider an OWL 2 QL-ontology Σ consisting of thefollowing tuple-generating dependencies (tgds):±(cid:2)∀x(cid:2)∀x∀x, y∀x, y(cid:2)RA(x) → ∃ yProject(x) → ∃ y(cid:2)worksOn(x, y) ∧ Project( y)(cid:3)(cid:3),(cid:2)(cid:2)isManagedBy(x, y) ∧ Professor( y)(cid:3)worksOn(x, y) → involves( y, x)(cid:3)isManagedBy(x, y) → involves(x, y),,(cid:3)(cid:3),and the CQ q(x) asking to find those who work with professors:q(x) = ∃ y, z(cid:2)(cid:3)worksOn(x, y) ∧ involves( y, z) ∧ Professor(z).A moment’s thought should convince the reader that the (positive existential) query(cid:4)q(x) = ∃ y, z(cid:4)worksOn(x, y) ∧(cid:2)(cid:3)worksOn(z, y) ∨ isManagedBy( y, z) ∨ involves( y, z)(cid:5)∧ Professor(z)(cid:5)worksOn(x, y) ∧ Project( y)(cid:4)∃ y(1)(2)(3)(4)(5)∨∨ RA(x)is an FO-rewriting of q(x) and Σ in the sense that, for any set D of ground atoms and any constant a in D, we have(Σ, D) |(cid:10) q(a)if and only if D |(cid:10) q(cid:4)(a).(In Section 2, we shall consider this example in more detail.) A number of different rewriting techniques have beenproposed and implemented for OWL 2 QL (PerfectRef [47], Presto/Prexto [55,54], Rapid [18], the combined approach [37],Ontop [51,33]) and its various extensions (Requiem/Blackout [45,46], Nyaya [25,43], Clipper [20] and [35]). However, allFO-rewritings constructed so far have, in the worst case, been exponential in the size of the query q. Thus, despite thefact that, for data complexity, CQ answering over ontologies with FO-rewritability is as complex as standard database queryevaluation (both are in AC0), rewritings can be too large for RDBMSs to cope with. It has become apparent, in both theoryand experiments, that for the OBDA paradigm to work in practice, we have to restrict attention to those ontologies and CQsthat ensure polynomial FO-rewritability (in the very least).The major open question we are going to attack in this article is whether the standard ontology languages for OBDA (inparticular, OWL 2 QL) enjoy polynomial FO-rewritability. Naturally, the answer depends on what means we can use in theof q and Σ above, we did not use any non-logical symbols other than those thatrewritings. For example, in the rewriting qoccurred in q and Σ . Such rewritings (perhaps also containing equality) may be described as ‘pure’ as they can be used withall possible databases; cf. [16]. (Note that all known rewritings apart from the one in the combined approach [37] are purein this sense.) Other important parameters are the available logical means (connectives and quantifiers) in rewritings and theway we represent them. Apart from the class of arbitrary FO-queries, we shall also consider positive existential (PE) queriesand nonrecursive datalog (NDL) queries as possible formalisms for rewritings (needless to say that pure NDL-rewritings maycontain new intensional predicates).(cid:4)At first sight, the results we obtain in this article could be divided into negative and positive. The bad news is thatthere is a sequence of CQs qn and OWL 2 QL ontologies Σn, both of size O (n), such that any pure PE- or NDL-rewritingof qn and Σn is of exponential size in n, while any pure FO-rewriting is of superpolynomial size unless NP ⊆ P/poly. Weobtain this negative result by first showing that OBDA with OWL 2 QL is powerful enough to compute monotone Booleanfunctions in NP, and that PE-rewritings correspond to monotone Boolean formulas, NDL-rewritings to monotone Booleancircuits, and FO-rewritings to arbitrary Boolean formulas. Then we use the celebrated exponential lower bounds for the sizeof monotone circuits and formulas computing the (NP-complete) Boolean function Cliquen,k ‘a graph with n nodes containsa k-clique’ [50,49]; a superpolynomial lower bound for the size of arbitrary (not necessarily monotone) Boolean formulascomputing Cliquen,k is a consequence of the assumption NP (cid:11)⊆ P/poly. We also use known separation results [49,48] formonotone Boolean functions such as ‘a bipartite graph with n vertices in each part has a perfect matching’ and ‘a givenvertex is accessible in a path accessibility system with n vertices’ to show that pure NDL-rewritings are in general exponen-tially more succinct than pure PE-rewritings, while pure FO-rewritings can be superpolynomially more succinct than purePE-rewritings.On the other hand, we have some good news as well: assuming that every data instance contains two fixed distinctindividual constants, we construct polynomial-size impure PE- and NDL-rewritings of any CQ and any ontology with the±polynomial witness property (in particular, any ontology in OWL 2 QL, linear Datalogof bounded arity). In essence, the rewriting guesses a polynomial number of ground atoms with database individuals andlabelled nulls (encoded as tuples over the two fixed constants), and checks whether these atoms satisfy the given CQand form a sequence of chase steps. We first construct a polynomial-size impure PE-rewriting and then show how itsdisjunctions can be encoded by a polynomial-size NDL-rewriting with intensional predicates of small arity. As the twoof bounded arity or sticky Datalog±\f44G. Gottlob et al. / Artificial Intelligence 213 (2014) 42–59constants in the impure PE-rewriting can be replaced with two fresh existentially quantified variables, say x and y, suchthat x (cid:11)= y, we also obtain a polynomial-size pure FO-rewriting over data instances with at least two domain elements.How to reconcile these seemingly contradictory results? To establish exponential and superpolynomial lower boundsfor the size of pure rewritings, we show that computing monotone Boolean functions in NP is polynomially reducible toanswering CQs over OWL 2 QL-ontologies and data instances with a single individual. As evaluating queries over such datainstances is tractable, pure rewritings of the CQs and ontologies computing NP-complete monotone B",
            {
                "entities": [
                    [
                        134,
                        192,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 220 (2015) 64–103Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintBackdoors to tractable answer set programming ✩Johannes Klaus Fichte a,b, Stefan Szeider a,∗a Vienna University of Technology, Favoritenstrasse 9-11, 1040 Vienna, Austriab University of Potsdam, August-Bebel-Strasse 89, 14482 Potsdam, Germanya r t i c l e i n f oa b s t r a c tArticle history:Received 7 March 2014Received in revised form 1 December 2014Accepted 6 December 2014Available online 15 December 2014Keywords:Answer set programmingBackdoorsComputational complexityParameterized complexityKernelizationAnswer Set Programming (ASP) is an increasingly popular framework for declarative programming that admits the description of problems by means of rules and constraints that form a disjunctive logic program. In particular, many AI problems such as reasoning in a nonmonotonic setting can be directly formulated in ASP. Although the main problems of ASP are of high computational complexity, complete for the second level of the Polynomial Hierarchy, several restrictions of ASP have been identified in the literature, under which ASP problems become tractable.In this paper we use the concept of backdoors to identify new restrictions that make ASP problems tractable. Small backdoors are sets of atoms that represent “clever reasoning shortcuts” through the search space and represent a hidden structure in the problem input. The concept of backdoors is widely used in theoretical investigations in the areas of propositional satisfiability and constraint satisfaction. We show that it can be fruitfully adapted to ASP. We demonstrate how backdoors can serve as a unifying framework that accommodates several tractable restrictions of ASP known from the literature. Furthermore, we show how backdoors allow us to deploy recent algorithmic results from parameterized complexity theory to the domain of answer set programming.© 2015 Elsevier B.V. All rights reserved.1. IntroductionAnswer Set Programming (ASP) is an increasingly popular framework for declarative programming [115,122]. ASP admits the description of problems by means of rules and constraints that form a disjunctive logic program. Solutions to the program are so-called stable models or answer sets. Many important problems of AI and reasoning can be succinctly repre-sented and successfully solved within the ASP framework. It has been applied to several large industrial applications, e.g., social networks [97], match making [74], planning in a seaport [129], optimization of packaging of Linux distributions [69], and general game playing [145].The main computational problems for ASP (such as deciding whether a program has a solution, or whether a certain atom is contained in at least one or in all solutions) are complete for the second level of the Polynomial Hierarchy [41]; thus, ASP problems are “harder than NP” and have a higher worst-case complexity than CSP and SAT. In the literature, several restrictions have been identified that make ASP tractable, most prominently the Horn fragment and the stratified fragment [78,2], for a detailed trichotomy (tractable, first level, second level of PH) see [148].Fichte and Szeider’s research was supported by the European Research Council, grant reference 239962 (COMPLEX REASON). Fichte’s research was ✩partially supported by the Austrian Science Fund (FWF) project Y698.* Corresponding author.E-mail addresses: fichte@kr.tuwien.ac.at (J.K. Fichte), stefan@szeider.net (S. Szeider).http://dx.doi.org/10.1016/j.artint.2014.12.0010004-3702/© 2015 Elsevier B.V. All rights reserved.\fJ.K. Fichte, S. Szeider / Artificial Intelligence 220 (2015) 64–103651.1. ContributionIn this paper we use the concept of backdoors to identify new restrictions that make propositional ASP problems tractable. Small backdoors are sets of atoms that represent “clever reasoning shortcuts” through the search space and represent a hidden structure in the problem input. Backdoors were originally introduced by Williams, Gomes, and Selman [152,153] as a tool to analyze the behavior of DPLL-based SAT solvers. Backdoors have been widely used in theoretical investigations in the area of propositional satisfiability [152,135,138,103] and constraint satisfaction [84], and also for abductive reasoning [125], argumentation [40], and quantified Boolean formulas [137]. A backdoor is defined with respect to some fixed target class for which the computational problem under consideration is polynomial-time tractable. The size of the backdoor can be seen as a distance measure that indicates how far the instance is from the target class.In this paper we develop a rigorous theory of backdoors for answer set programming. We show that the concept of backdoors can be fruitfully adapted for this setting, and that backdoors can serve as a unifying framework that accommodates several tractable restrictions of propositional ASP known from the literature.For a worst-case complexity analysis of various problems involving backdoors such as finding a small backdoor or using it to solve the problem, it is crucial to investigate how the running time depends on the size of the backdoor, and how well running time scales with backdoor size. Parameterized Complexity [35,55,85] provides a most suitable theoretical framework for such an analysis. It provides the key notion of fixed-parameter tractability which, in our context, means polynomial-time tractability for fixed backdoor size, where the order of the polynomial does not depend on the backdoor size. We show how backdoors allow us to deploy recent algorithmic results from parameterized complexity theory to the domain of answer set programming.Parameterized complexity provides tools for a rigorous analysis of polynomial-time preprocessing in terms of kerneliza-tion [7,58]. A kernelization is a polynomial-time self-reduction of a parameterized decision problem that outputs a decision equivalent problem instance whose size is bounded by a function f of the parameter (the kernel size). It is known that every decidable fixed-parameter tractable problem admits a kernelization, but some problems admit small kernels (of size polynomial in the parameter) and others do not. We provide upper and lower bounds for the kernel size of the prob-lems backdoor evaluation and backdoor detection for disjunctive answer set programs. These bounds provide worst case guarantees and limits for polynomial-time preprocessing for the considered problems.Several algorithms in the literature are defined for disjunction-free (i.e., normal) programs only. We introduce a general method for lifting these parameters to disjunctive programs, preserving fixed-parameter tractability under certain conditions.Although our main focus is on a theoretical evaluation, we present some experimental results where we consider the backdoor size of structured programs and random programs of varied density.1.2. Background and related workComplexity of ASP problems Answer set programming is based on the stable-model semantics for logic programs [78,79]. The computational complexity of various problems arising in answer set programming has been subject of extensive studies. Eiter and Gottlob [41] have established that the main decision problems of (disjunctive) ASP are complete for the second level of the Polynomial Hierarchy (Σ P2 -complete, respectively). Moreover, Bidoít and Froidevaux [5] and Marek and Truszczy ´nski [114] have shown that the problems are NP-complete (co-NP-complete respectively) for disjunction-free (so-called normal) programs. Several fragments of programs where the main reasoning problems are polynomial-time tractable have been identified, e.g., Horn programs [78], stratified programs [2] and programs without even cycles [156]. Dantsin et al. [27] survey the classical complexity of the main reasoning problems for various semantics of logic programming, including fragments of answer set programming.2 - or Π PASP solvers Various ASP solvers have been developed in recent years. Many of them utilize SAT solvers as black boxes or search techniques from SAT. There are solvers that deal with one or more fragments of disjunctive programs (normal, tight, or head-cycle-free), e.g., Smodels [141], Assat [111], Cmodels2 [82], and Clasp2 [71]. There are also solvers that deal with the full set of disjunctive programs, e.g., Clasp3 [37], Cmodels3 [108], DLV [107], and GnT [92]. Compilations to other problem domains and respective solvers have been considered for normal programs, e.g., propositional satisfiability [91], mixed integer programming [112], satisfiability modulo theories [93,76]. We would like to point out that these solvers use heuristics without non-trivial worst-case performance guarantees. In contrast we provide for the main reasoning problems of answer set programming theoretical worst-case time bounds that take certain hidden structures in disjunctive programs into account.Preprocessing techniques and unit propagation used in solvers might be considered in a wider sense as implicitly exploit-ing Horn fragments. Grounders like Gringo [64] already solve Horn programs simply by propagating atoms which trivially (do not) belong to the minimal model, e.g., atoms that occur in the head of rules with an empty body, atoms that occur in the head of rules where all atoms in the positive body already belong to the minimal model, atoms that cannot belong to the minimal model according to some constraint, and atoms that cannot belong to the minimal model as they occur in no head. Moreover, SAT-based solvers like Clasp [62] transform the program into a propositional formula using Clark’s completion (see e.g., [73]) where the resulting formula characterizes the classical models and necessary conditions for atoms to belong to a model. If the program contains no cycles in its positive dependency graph, unit propagation (as part of a \f66J.K. Fichte, S. Sz",
            {
                "entities": [
                    [
                        135,
                        180,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 78 ( 1995) 239-288 Artificial Intelligence 3D object recognition using invariance Andrew Zisserman a,*, David Forsyth b, Joseph Mundy c, Charlie Rothwell d, Jane Liu e, Nit Pillow a ’ Robotics Research Group, Department of Engineering Science, University of Oxford, Parks Rd, Oxford, UK h Department of Computer Science, University of Iowa, Iowa City, IA, USA ’ GE Corporate Research and Development, Schenectady, M: USA d INRIA, 2004, Route des Lucioles. Sophia Antipolis, France e Rensselaer Polytechnic Institute, Troy, Ne USA Received September 1993; revised November 1994 Abstract The systems and concepts described in this paper document the evolution of the geometric invariance approach to object recognition over the last five years. Invariance overcomes one of the fundamental difficulties in recognising objects from images: that the appearance of an object depends on viewpoint. This problem is entirely avoided if the geometric description is unaffected by the imaging transformation. Such invariant descriptions can be measured from images without any prior knowledge of the position, orientation and calibration of the camera. These invariant measurements can be used to index a library of object models for recognition and provide a principled basis for the other stages of the recognition process such as feature grouping and hypothesis verification. Object models can be acquired directly from images, allowing efficient construction of model libraries without manual intervention. A significant part of the paper is a summary of recent results on the construction of invariants for 3D objects from a single perspective view. A proposed recognition architecture is described which enables the integration of multiple general object classes and provides a means for enforcing global scene consistency. Various criticisms of the invariant approach are articulated and addressed. 1. Introduction The computer recognition the last 25 years. It is now widely accepted of objects has attracted considerable that object recognition, research effort over in the setting of real * Corresponding author. E-mail: az@robots.oxford.ac.uk. 0004-3702/95/$09.50 SSDI 0004-3702( 95)00023-2 @ 1995 Elsevier Science B.V. All rights reserved \f240 A. Zissermun et al. /Arrijicral Intelligence 78 (1995) 239-288 in a scene It is also accepted that the most reliable the use of object models is derived in the form of 2D geometric shading. Thus, object recognition world scenes and based on a single perspective view, is a difficult problem and cannot to guide the processing of image data and be achieved without to confirm object hypotheses. information which from a geometric description of the object based on is available to, for example, its projection its intensity systems draw on a library of geometric models, which usually contain known objects, or image sequence. Recognition in an image can be explained object. the shape and appearance of a set of image as a perspective projection of a geometric model of the if any, of those objects appear if the geometric configuration image features, as opposed to determine which, is considered in a given information successful about At present, 3D recognition tively simple objects. Progress systems generally have small modelbases containing rela- is needed on three fronts: l Larger modelbases: Systems should be able to thousands of models. The methods of pose consistency to deal with modelbases containing hundreds Section 1.1)) which are commonly are infeasible with such sizes clearly for large modelbases because of the computational requires some partitioning of the modelbase. in used for modelbases with only a few objects, expense. Coping (reviewed l More general shape models: Typically polyhedra are used, which are a poor model is required. for curved objects. A direct representation for nontrivial curved objects l Automatic segmentation and grouping: This is the process, also called figure-ground and grouping. including separation, of extracting outlines without such grouping In addition mechanisms is a significant barrier to representing for their feature segmentation a framework the background image feature groups which correspond to individual object and other occluding objects. The lack of in current systems. the shape of 3D objects, models will have to provide to successful recognition the camera This paper establishes for the next generation of 3D model-based systems which will have large modelbases, with objects partitioned vision into a images of the objects could be partially occluded, and library. The object classes are defined in terms of symmetry or other 3D geometric constraints. The constraint invariants of a 3D object in the class to be extracted from a single image of the that enable recognition number of different 3D object classes. Recognition scenes, where the scene might contain objects not in the model geometrically enables object outline; grouping. relations on the image outline is from single perspective and also generates is uncalibrated, invariant Although the paper concentrates in weak-perspective applicable linear approximation is small compared lines are imaged as parallel valid for weak-perspective. to distance to perspective, (or “affine”) images, imaging on perspective the methods are, of course, a is appropriate as a camera model when object relief is that parallel world imaging are also situations. Weak-perspective, for perspective computed from the camera. A consequence lines. Invariants A major constraint underlying the work presented here is that recognition view of a scene. Our motivation is that this restriction applies one uncalibrated of the current and future applications image database query processing, for object recognition, image-hypertext and is based on in many such as aerial surveillance, images if more editing. Even \fA. Zisserman et al. /Art$icial Intelligence 78 (199.5) 239-288 241 are available, generally be known up to some ambiguity views. for example in the case of video processing, initially. Any grouping, recognition from a single image, can be propagated camera calibration will not hypothesis, or object recovered to subsequent to advantage A central question explored in this paper is the nature of the shape representation representations systems. However, under the most general imaging conditions, (metric) nec- are routinely used in many struc- recognition transformation for recognition. Euclidean essary existing ture is recovered up to a projective than Euclidean). We demonstrate nition. A stratification groups: projective, tation hierarchy projectively concerned with the projective other strata will be used to advantage at particular is progressively more of representations affine, similarity that projective equivalent need not be affine or similarity (i.e., a more general transformation representations are adequate for recog- is provided by the hierarchy of transformation and Euclidean. This represen- two objects (scaled Euclidean), restrictive; for example, that are stratum, since this covers the “worst-case” equivalent. We will be primarily ambiguity. The that is the use of quasi-invatiants A related area property or relation over a useful range of views. Invariants of other transformation given above are sometimes quasi-invariants in grouping Examples of quasi-invariants are given in the paper. to projective and partial invariant indexing though is not [5]. Quasi-invariants even stages of the recognition process. [4]. A quasi-invariant transformations, groups is an object is stable but in the hierarchy can be very effective they vary under perspective projection. Our geometric notion of class differs from the more usual functional one. For example, in our definitions, a vase is considered as a surface of revolution as opposed to a container for flowers and water. A geometric class is not specific to a particular object but instead relations. describes a family of objects which are unified by their common 3D constraint A number of examples of these 3D object classes are given in Section 3. from through image grouping architecture which integrates and 3D scene constraints. Recognition based on image curves, and subsequently We have defined a recognition ences each level of the architecture, the modelbase by a classification ticular model within many existing architecture, a large-scale This effort will culminate class of 3D structures with thousands of individual object instances these ideas. Class influ- to organisation of first proceeding of a par- the class using values of geometric attributes. This contrasts with identified. The demonstrates that is now warranted. a broad in the model library. combined with the success of existing system systems where a particular object in an object recognition based on an invariant that can recognise the identification implementations, implementation is class-based, recognition framework is directly system 1.1. Related approaches to object recognition Recognition is the establishment of a correspondence between features. Most recent approaches to those defined (similar The aim of grouping ground discrimination) come from a single object to recognition have been implemented indexing, and verification. in [ 271) : grouping, (also called perceptual organisution [ 371, selection, or $gure- to have is to provide an association of features together using in a scene. Features are typically grouped that are likely image and model in three stages \f242 A. Zissermun CI ul. /Artificial Intelligence 78 (1995) 239-288 features, and features on a model [ 12,611. The indexing cues such as proximity, parallelism curvature image determines match is used to project hypothesis and model-to-image support. the consistency and approximate stage hypothesises [ 3,371 collinearity, in the grouped in the library. The final stage, verification, of this hypothesis with the image data. The image-model the model onto the",
            {
                "entities": [
                    [
                        67,
                        105,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 239 (2016) 70–96Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintDiffusion centrality: A paradigm to maximize spread in social networksChanhyun Kang a, Sarit Kraus b, Cristian Molinaro c,∗V.S. Subrahmanian aa Department of Computer Science, University of Maryland, USAb Department of Computer Science, Bar-Ilan University, Israelc DIMES, Università della Calabria, Italyd Department of Computer Science, Boise State University, USA, Francesca Spezzano d, a r t i c l e i n f oa b s t r a c tArticle history:Received 7 February 2015Received in revised form 21 May 2016Accepted 30 June 2016Available online 7 July 2016Keywords:Social networksDiffusion modelLogic programmingQuantitative logicWe propose Diffusion Centrality (DC) in which semantic aspects of a social network are used to characterize vertices that are influential in diffusing a property p. In contrast to classical centrality measures, diffusion centrality of vertices varies with the property p, and depends on the diffusion model describing how p spreads. We show that DC applies to most known diffusion models including tipping, cascade, and homophilic models. We present a hypergraph-based algorithm (HyperDC) with many optimizations to exactly compute DC. However, HyperDC does not scale well to huge social networks (millions of vertices, tens of millions of edges). For scaling, we develop methods to coarsen a network and propose a heuristic algorithm called “Coarsened Back and Forth” (CBAF) to compute the top-k vertices (having the highest diffusion centrality). We report on experiments comparing DC with classical centrality measures in terms of runtime and the “spread” achieved by the k most central vertices (using 7 real-world social networks and 3 different diffusion models). Our experiments show that DC produces higher quality results and is comparable to several centrality measures in terms of runtime.© 2016 Elsevier B.V. All rights reserved.1. IntroductionAn increasingly important problem in social networks (SNs) is that of assigning a “centrality” value to vertices which will reflect their importance within the SN. Well-known measures such as degree centrality [21,46], betweenness centrality [8,20], PageRank [9], closeness centrality [49,5], and eigenvector centrality [7] only take the structure of the network into account—they do not differentiate between vertices that are central w.r.t. spreading one topic or meme or sentiment vs. spreading another. A vertex that is important in spreading awareness of a mobile phone program may be very unimportant in spread-ing information about a restaurant. Likewise, most past work assumes that there is no information about properties of the vertices/edges or edge weights, but in modern social networks, at least some self-declared properties exist and, in many cases, analysis of tweets and posts can provide further information. These omissions can cause different problems as shown in the following toy example.* Corresponding author.E-mail address: cmolinaro@dimes.unical.it (C. Molinaro).http://dx.doi.org/10.1016/j.artint.2016.06.0080004-3702/© 2016 Elsevier B.V. All rights reserved.\fC. Kang et al. / Artificial Intelligence 239 (2016) 70–9671Fig. 1. A small HIV social network. Shaded vertices denote people with HIV.Example 1 (HIV). Fig. 1 shows four people a, b, c, d, where b has HIV. Solid edges denote sexual relationships, while dashed edges denote friend relationships. Both “friend” and “sexual partner” relationships can play a role in the diffusion of HIV (as friends may, unbeknownst to us, also be sexual partners). Edge weights denote the intensity of the relationships.The table below shows the centrality of a, b, c, d w.r.t. various centrality measures. Notice that the nature of the rela-tionships (i.e., friend and sexual partner) are not taken into account by these centrality measures, as they consider only the topological structure of the network.Centrality measureDegreeBetweennessPageRankClosenessEigenvectora120.3670.330.375b0.3300.1410.20.125c0.6600.2460.250.25d0.6600.2460.250.25The only person in this network capable of spreading HIV is b. However, b has the lowest centrality according to all five centrality measures mentioned above.Example 2. Consider again the same network shown in Fig. 1 and suppose the vertices denoted users on Twitter. A solid edge (u, v) denotes the fact that u and v have both retweeted at least one of the other’s tweets, while a dashed edge indicates that they are friends (i.e., u follows v and vice versa). Suppose b was the only person to have tweeted a positive opinion about a political candidate while none of the others have done so. Then, by the same reasoning as in the previous example, and given that Fig. 1 is the entire network, we can again infer that any other user (i.e., a, c, d) who tweets positively about the same candidate was either influenced by b or was influenced by some exogenous process. b should clearly get more credit for the other user’s positive tweet than anyone else, but has the lowest centrality according to classical centrality measures.Past centrality measures do not take into account (i) the property of interest w.r.t. which a vertex’s “importance” is measured, (ii) how properties (e.g., HIV in the example above) diffuse through the SN, and (iii) any semantic aspect of the network (properties of vertices and edges), solely focusing on the topological structure. Taking all of these aspects into account is crucial in determining the most central vertices. We can readily think of networks (e.g., Twitter) where person A has the highest centrality in terms of spread of support for Republicans, while person B is the central player in terms of spread of support for conserving gorillas. The network in both cases is the same (Twitter), but the most “central” person depends on the diffusive property with respect to which a vertex is considered “influential” or “central”. Taking into account diffusion models (e.g., how one person influences another) is another crucial aspect. Different ways of spreading a property (e.g., a disease) may lead to different central vertices. Furthermore, intrinsic properties of vertices (customers, patients) and the nature and strength of the relationships (edges) are important too. For instance, [45] talks about the role of nine different demographic factors in influencing online purchases across 14 product categories, showing that some demographic factors are relevant for some product types, while others are relevant for others. This paper proposes the novel notion of diffusion centrality that takes an SN, a diffusive property p, and a previously learned diffusion model (cid:2) for p, and defines centrality of vertices based on this input. We do not provide algorithms to automatically learn diffusion models—interested readers may find one such algorithm in [10].The paper’s goal is to show how diffusion centrality can be used to achieve higher spread of a diffusive property p by using diffusion models for p rather than classical centrality measures. We further show that this can be done for most diffusion models we have seen in the literature. Last but not least, our methods are shown to scale to social networks with over 2M vertices and 20M edges.Real-world diffusion models fall into three diverse categories. In cascade models, there is some probability that a vertex will spread a diffusive property p to one of its neighbors [34,36]—these include popular disease spread models such as the SIR model of disease spread [26]. Tipping models use other mathematical calculations such as cost-benefit analysis, often involving no probabilities, in order to decide whether a vertex will adopt a certain behavior. Tipping models were introduced by Nobel laureate Tom Schelling [50] to model segregation of neighborhoods, and by Granovetter [24]. In homophilic models, similarities between two vertices are considered in order to decide if the two vertices will adopt a similar behavior [42,12,3]. \f72C. Kang et al. / Artificial Intelligence 239 (2016) 70–96Homophilic models use various types of distance measures between attributes of a vertex (e.g., age, occupation, gender) and combine them via non-probabilistic measures to achieve a degree of similarity between two vertices.Because diffusion models vary dramatically, a paradigm to express them must be capable of: (i) expressing semantic properties of vertices and connections between them, (ii) representing probabilistic inferences, and (iii) expressing inferences based on non-probabilistic, quantitative reasoning. The suite of knowledge representation paradigms offers several starting points. Bayesian nets and causal inference [47] offer an obvious place to start as they can be used to express cascade models. However, it is not clear if they can be used to express generic quantitative information, which is needed to express many other real diffusion models, such as tipping and homophilic models. In contrast, the language of Generalized Annotated (logic) Programs (GAPs) [35] has been well-studied in knowledge representation and is rich enough to capture a wide variety of different forms of reasoning. It can represent both the structure of social networks (with semantics and weight annotations) as well as these diverse types of diffusion models. Indeed, as shown in [51], many existing diffusion models from all three aforementioned categories can be expressed as GAPs, including: the Susceptible–Infectious–Removed (SIR) [2]and Susceptible–Infectious–Susceptible (SIS) [26] models of disease spread; the Big Seed marketing approach [57], which is a strategy of advertising to a large group of individuals who are likely to spread the advertisement further through network effects; models of diffusion of “favorited” pictures in Flickr [13]; tipping models like the Jackson–Yariv model [28]. We also considered richer versions of GAPs, such as hy",
            {
                "entities": [
                    [
                        134,
                        204,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 103 (1998) 49-76 Artificial Intelligence Vehicles capable of dynamic vision: a new breed of technical beings? Ernst D. Dickmanns ’ Universiftit der Bundeswehs Munich, D-85577 Neubiberg, German_y Abstract A survey in the field, encompassing is given on two decades of developments computing power by four orders of magnitude. The ‘4-D approach’ methods from systems dynamics and control engineering with methods from AI has allowed to create in the technical realm: autonomous road vehicle guidance in vehicles with unprecedented capabilities public traffic on freeways at speeds beyond 130 km/h, on-board-autonomous landing approaches of aircraft, and landmark navigation for AGV’s, for road vehicles and for helicopters 0 1998 Elsevier Science B.V. All rights reserved. turn-offs onto cross-roads, in the latter case). in low-level flight (real-time, hardware-in-the-loop integrating expectation-based an increase simulations including in Keywords; Machine vision; Autonomous vehicles; Mobile robots; Dynamic scene understanding; Image processing 1. Introduction Road vehicle guidance based on video-signal in Japan [39], in Europe [26], and in the USA [21]. While processing has been picked up indepen- in Japan analog signal dently processing has been used and (quasi-steady) AI-methods predominated in the US, recursive estimation methods well known from systems engineering have been extended to image se- the resulting method has been dubbed quence processing at the author’s institute ‘4-D approach’, then, dis- in the problem domain. The numerical regarding of recursive estimation which directly efficiency and compactness finally, led to its wide- allowed control applications in the vision community. Artificial neural nets (ANN) also found wide spread acceptance (UBM); in contrast to the 2-D, 2.5-D, and 3-D methods under discussion variable in state representation for generating behavioral capabilities, time as the fourth independent ’ Email: emst.dickmanns@unibw-muenchen.de. 00043702/98/$ PII: SOOO4-3702(98)0007 -see I -X front matter 0 1998 Elsevier Science B.V. All rights reserved \facceptance 1000 pixel = 1 Kpel), usually, was much less than with recursive estimation image, even at a higher image rate). in the USA 13 l] and around the globe even though image resolution used (about (80 Kpel per road vehicles to run autonomously Both methods allowed control the 4-D approach allowed along highways and other types of roads up to rather high speeds, initially on empty roads only [7,30], but finally in normal freeway traffic also [ 11,3 1,371; however, while ANN’s stayed confined to either [ 171 at a time (the other mode had to be controlled lateral [25,3 l] or longitudinal the spatio- to detect, track and determine by a human driver), to about on a 3-D surface) temporal a dozen other objects the own vehicle VITA II of Daimler-Benz and VaMP of UBM [ 1 1,401, may well be considered as the first two road vehicles of a new species capable of understanding and of reacting properly to the actual needs on their own (completely autonomous). relative in front of and behind in the European project Prometheus: [ 121. The two final demonstrator in a range of up to 100 meters (part of) their environment and velocity components state (position vehicles Dynamic remote sensing requires for intelligent motion control in an environment with rapidly changing elements the use of valid spatio-temporal models for efficient handling of the large data streams involved. Other objects have to be recognized with their relative motion components, this for collision avoidance; has to be achieved while the own vehicle body carrying the cameras moves in an intended way and is, simultaneously, the near ones even with high precision subject to perturbations hardly predictable. to vision sensing in addition For this complex scenario, rate feedback is of great help; inertial to a viewing direction control device allows to stabilize negative angular and in the image sequence. Measured accelerations the appearance of stationary objects velocities will, via signal and rotational positions affecting the perspective mapping process. These predictions are good in the short inertial sensors are run, but may drift slowly in the long run, especially when inexpensive used. These drifts. however, can easily be compensated of static scene elements. yield predictions for translational interpretation integration, by visual 2. Simultaneous representations on differential and multiple integral scales systems, In order to and integral Combined use of inertial and visual sensing is well known from biological introduced: simultaneous to eyes in vertebrates. e.g., the vestibular apparatus and its interconnections make optimal use of inertial and visual signals, on different scales both in space and in time are being exploited; Table 1 representations the point ‘here and the upper left corner represents shows the four categories of a sensor or an actuator with the real now’ in space and time where all interactions world take place. Inertial sensors yield information (arrow 1 from field (1,l) to field (3,3) in the table) and turn rates of this point. Within a rigid structure of an object the turn rates are the same all over the body; therefore, rate signals (arrow 2 from field (1,3) to (3,3)) are drawn on the spatial object level (row 3). The local surface of a structure may be described by the change of its tangent direction the inertially measured on local accelerations differential along some arc length; geometrical characterization this is called curvature and is an element of local shape. It is a form; row 2 in Table 1 of this part of the object in differential \fE.D. Dickmanns /Art&id Intelligence 103 (lYY8) 49-76 Table 1 Differential and integral representations on different scales for dynamic perception measuremen represents or curved ones) in the image under certain aspect conditions. these local spatial differentials which may cause specific edge features (straight (represented the feature distribution to be local spatial integrals Single objects may be considered in connection with the aspect conditions also these arrangements of objects of relevance for behavior decision and reactive control. For this reason, in row 3 of on Table I), the shapes of which are determined by their spatial curvature distributions and the photometric properties of the surface; in the image. Since, in general, several the surface they determine objects may be viewed simultaneously, in a task context, called ‘geometrical elements of a situation’, are perceived and taken into the visual data input account process, labeled by the index 3 at the corresponding field (3,3), has three components: features not yet associated with an object, with a strong predictive component other objects. Looked at this way, vision simultaneously both on differential maneuvering, for the environment which preshapes the maneuver space for the self and all the (row 2) and integral scales (rows: 3 for a single objects, 4 for local tracking component and (3~) the perception (3b) the object-oriented improvement, the so-called detection component; and 5 for mission performance). arrows into the central provides geometrical (3a) for measured for efficiency interpretation information element \f52 E.D. Dickmanns /Artificial Intelligence 103 (1998) 49-76 Temporal change is represented in column 2 which yields the corresponding time derivatives to the elements associated with numerical differentiation Awcos(wt)), this operation from odometry; especially, image points. Even on the feature effect, as used in recursive estimation, in the column to the left. Because of noise amplification of high frequency signals is usable only for smooth signals, it is avoided deliberately to do optical like for computing (d/dt (A sin(wt)) = speed at flow computation level, the operation of integration with a smoothing is preferred. In the matrix field (3,2) of Table 1 the key knowledge elements and the corresponding tools for sampled data processing are indicated: due to mass and limited energy availability, in the real world are constrained; good models for unperturbed motion of motion processes in the natural and engineering to specific classes are available sciences objects belonging rate of change of the state variables on which represent the dependence of the temporal ‘dynamical models’. For both the state- and the control variables, These are the so-called constant control inputs over the integration period, these models can be integrated to yield difference equations which link the states of objects in column 3 of Table 1 to those in the gap of column 2; in control engineering, methods and column 1, thereby bridging to handle all problems arising. Once the states libraries with computer codes are available at one point in time are known, time derivatives are delivered by these models. the corresponding Recursive estimation techniques developed since the 60s exploit this knowledge by making state predictions over one cycle disregarding perturbations; models are applied yielding predicted measurements. communicated efficiency from measured features then yields the prediction errors used for state update. to improve (arrow 4 from field (3,3) to (1,3) in Table 1 on the object to (2,3) on the feature extraction to the image processing in order stage (3,3) then, the measurement In the 4-D approach, these are image evaluation level, and arrow 5 level). A comparison with the actually inputs; In order to better understand what is going to happen on a larger scale, these predictions likely in road vehicle guidance, to have a longer term state I and by arrow 6; Section 6 may be repeated several to many times in a very fast in advance simulation assuming control a finite sequence of ‘feed-forward’ transition effect. These are represented below will deal with these problems. for stereotypical maneuvers control is known in f",
            {
                "entities": [
                    [
                        74,
                        141,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 163–188Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the adoption of abductive reasoning for time series interpretationT. Teijeiro∗, P. FélixCentro Singular de Investigación en Tecnoloxías da Información (CITIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spaina r t i c l e i n f oa b s t r a c tArticle history:Received 31 March 2017Received in revised form 10 November 2017Accepted 4 June 2018Available online 20 June 2018Keywords:AbductionInterpretationTime seriesTemporal abstractionTemporal reasoningNon-monotonic reasoningSignal abstractionTime series interpretation aims to provide an explanation of what is observed in terms of its underlying processes. The present work is based on the assumption that the common classification-based approaches to time series interpretation suffer from a set of inherent weaknesses, whose ultimate cause lies in the monotonic nature of the deductive reasoning paradigm. In this document we propose a new approach to this problem, based on the initial hypothesis that abductive reasoning properly accounts for the human ability to identify and characterize the patterns appearing in a time series. The result of this interpretation is a set of conjectures in the form of observations, organized into an abstraction hierarchy and explaining what has been observed. A knowledge-based framework and a set of algorithms for the interpretation task are provided, implementing a hypothesize-and-test cycle guided by an attentional mechanism. As a representative application domain, interpretation of the electrocardiogram allows us to highlight the strengths of the proposed approach in comparison with traditional classification-based approaches.© 2018 Elsevier B.V. All rights reserved.1. IntroductionThe interpretation and understanding of the behavior of a complex system involves the deployment of a cognitive appara-tus aimed at guessing the processes and mechanisms underlying what is observed. The human ability to recognize patterns plays a paramount role as an instrument for highlighting evidence which should require an explanation, by matching infor-mation from observations with information retrieved from memory. Classification naturally arises as a pattern recognition task, defined as the assignment of observations to categories.Let us first state precisely at this point what is the problem under consideration: we wish to interpret the behavior of a complex system by measuring a physical quantity along time. This quantity is represented as a time series.The Artificial Intelligence community has devoted a great deal of effort on different paradigms, strategies, methodologies and techniques for time series classification. Nonetheless, in spite of the wide range of proposals for building classifiers, ei-ther by eliciting domain knowledge or by induction from a set of observations, the resulting classifiers behaves as deductive system. The present work is premised on the assumption that some of the important weaknesses of this approach lie in its deductive nature, and that an abductive approach can address these shortcomings, which are described below.* Corresponding author.E-mail address: tomas.teijeiro@usc.es (T. Teijeiro).https://doi.org/10.1016/j.artint.2018.06.0050004-3702/© 2018 Elsevier B.V. All rights reserved.\f164T. Teijeiro, P. Félix / Artificial Intelligence 262 (2018) 163–188Let us remember that a deduction contains in its conclusions information that is already implicitly contained in the premises, and thus it is truth-preserving. In this sense, a classifier ultimately assigns a label or a set of labels to observations. This label can designate a process or a mechanism of the system being observed, but it is nothing more than a term that summarizes the premises implied by the observations. Conversely, abduction, or inference to the best explanation, is a form of inference that goes from data to a hypothesis that best explains or accounts for the data [21]. Abductive conclusions contain new information not contained in the premises, and are capable of predicting new evidence, although they are fallible. Abductions are thus truth-widening, and they can make the leap from the language of observations to the language of the underlying processes and mechanisms, responding to the aforementioned problem in a natural way [24]. For example, consider a simple rule stating that if a patient experiences a sudden tachycardia and a decrease in blood pressure, then we can conclude that he or she is suffering from shock due to a loss of blood volume. From a deductive perspective, loss of blood volume is just a name provided by the rule for the satisfaction of the two premises. However, from an abductive perspective, loss of blood volume is an explanatory hypothesis, a conjecture, that expands the truth contained in the premises, enabling the observer to predict additional consequences such as, for example, pallid skin, faintness, dizziness or thirst.Of course, the result of a classifier can be considered as a conjecture, but always from an external agent, since a classifier is monotonic as a logical system and its conclusions cannot be refuted from within. Classifier ensembles aim to overcome the errors of individual classifiers by combining different classification instances to obtain a better result; thus, a classifier can be amended by others in the final result of the ensemble. However, even an ensemble represents a bottom-up mapping, and classification invariably fails above a certain level of distortion within the data. The interpretation and understanding of a complex system usually unfolds along a set of abstraction layers, where at each layer the temporal granularity of the representation is reduced from below. A classification strategy provides an interpretation as the result of connecting a set of classifiers along the abstraction structure, and the monotonicity of deduction entails a propagation of errors from the first abstraction layers upwards, narrowing the capability of making a proper interpretation as new abstraction layers are successively added. Following an abductive process instead, an observation is conjectured at each abstraction layer as the best explanatory hypothesis for the data from the layer or layers below, within the context of information from above, and the non-monotonicity of abduction supports the retraction of any observation at any abstraction layer in the search for the best global explanation. Thus, bottom-up and top-down processing complement one another and provide a joint result. As a consequence, abduction can guess the underlying processes from corrupted data or even in the temporary absence of data.On the other hand, a classifier is based on the assumption that the underlying processes or mechanisms are mutually exclusive. Superpositions of two or more processes are excluded; they must be represented by a new process, corresponding to a new category which is different and usually unrelated to previous ones. Therefore, an artificial casuistry-based heuristics is adopted, increasing the complexity of the interpretation and reducing its adaptability to the variability of observations. In contrast, abduction can reach a conclusion from the availability of partial evidence, refining the result by the incremental addition of new information. This makes it possible to discern different processes just from certain distinguishable features, and at the end to infer a set of explanations as far as the available evidence does not allow us to identify the best one, and they are not incompatible with each other.In a classifier, the truth of the conclusion follows from the truth of all the premises, and missing data usually demand an imputation strategy that results in a conjecture: a sort of abducing to go on deducing. In contrast, an abductive interpretation is posed as a hypothesize-and-test cycle, in which missing data are naturally managed, since a hypothesis can be evoked by every single piece of evidence in isolation and these can be incrementally added to reasoning. This fundamental property of abduction is well suited to the time-varying requirements of the interpretation of time series, where future data can compel changes to previous conclusions, and the interpretation task may be requested to provide the current result as the best explanation at any given time.Abduction has primarily been proposed for diagnostic tasks [10,33], but also for question answering [15], language understanding [22], story comprehension [6], image understanding [36] or plan recognition [28], amongst others. Some studies have proposed that perception might rely on some form of abduction. Even though abductive reasoning has been proven to be NP-complete or worse, a compiled form of abduction based on a set of pre-stored hypotheses could narrow the generation of hypotheses [24]. The present work takes this assumption as a starting point and proposes a model-based abductive framework for time series interpretation supported on a set of temporal abstraction patterns. An abstraction pattern represents a set of constraints that must be satisfied by some evidence in order to be interpreted as the hypothetical observation of a certain process, together with an observation procedure providing a set of measurements for the features of the conjectured observation. A set of algorithms is devised in order to achieve the best explanation through a process of successive abstraction from raw data, by means of a hypothesize-and-test strategy.Some previous proposals have adopted a non-monotonic schema for time series interpretation. TrenDx system detects significant trends in time series by matching data to predefined trend patterns [19,20]. One of these patterns plays the role of the expected or normal pattern, and the other patterns are fault patterns. A matching score of each pattern is based",
            {
                "entities": [
                    [
                        136,
                        205,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 245–269Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConformant plans and beyond: Principles and complexityBlai BonetDepartamento de Computación, Universidad Simón Bolívar, Caracas 89000, Venezuelaa r t i c l ei n f oa b s t r a c tArticle history:Received 16 September 2008Received in revised form 29 October 2009Accepted 29 October 2009Available online 3 November 2009Keywords:PlanningComplexity of planningPartially-observable planningNon-deterministic planningModal logicConformant planning is used to refer to planning for unobservable problems whosesolutions, like classical planning, are linear sequences of operators called linear plans.The term ‘conformant’ is automatically associated with both the unobservable planningmodel and with linear plans, mainly because the only possible solutions for unobservableproblems are linear plans. In this paper we show that linear plans are not only meaningfulfor unobservable problems but also for partially-observable problems. In such case, theexecution of a linear plan generates observations from the environment which must becollected by the agent during the execution of the plan and used at the end in order todetermine whether the goal had been achieved or not; this is the typical case in problemsof diagnosis in which all the actions are knowledge-gathering actions.Thus, there are substantial differences about linear plans for the case of unobservableor fully-observable problems, and for the case of partially-observable problems: whilelinear plans for the former model must conform with properties in state space, linearplans for partially-observable problems must conform with properties in belief space.This differences surface when the problems are allowed to express epistemic goals andconditions using modal logic, and place the plan-existence decision problem in differentcomplexity classes.Linear plans is one extreme point in a discrete spectrum of solution forms for planningproblems. The other extreme point is contingent plans in which there is a branch point forevery possible observation at each time step, and thus the number of branch points is notbounded a priori. In the middle of the spectrum, there are plans with a bounded numberof branch points. Thus, linear plans are plans with zero branch points and contingent plansare plans with unbounded number of branch points.In this work, we lay down foundations and principles for the general treatment of linearplans and plans of bounded branching, and provide exact complexity results for noveldecision problems. We also show that linear plans for partially-observable problems arenot only of theoretical interest since some challenging real-life problems can be dealt withthem.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConsider the game of Mastermind which is a two-person code-breaking game played by the codemaker and the code-breaker. The game begins when the codemaker chooses a secret code, made of 4 pegs colored from 6 available colors(repetitions allowed), and the task of the codebreaker is to discover the code by questioning the codemaker and assessinghis answers. Each question, called a guess, is also a sequence of 4 colored pegs that is answered by the codemaker withtwo tokens of information: first the number of exact matches in the guess, i.e. the number of pegs of the right color andE-mail address: bonet@ldc.usb.ve.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.11.001\f246B. Bonet / Artificial Intelligence 174 (2010) 245–269Fig. 1. Optimal contingent plan for Mastermind with 3 pegs and 3 colors.in the right position, and second the number of near matches in the guess, i.e. the number of pegs of the right color butin wrong position. The codebreaker wins if he can discover the secret code in at most 10 guesses, otherwise the codemakerwins. This popular game has captivated the attention of millions of people [60] including some renowned mathematicians[14,18,37,38].The game proceeds in guess-and-answer stages in which a guess may depend on the information acquired during theprevious stages. A winning strategy for Mastermind can be depicted as a tree whose nodes are the subsets of the possiblesecret codes at a given stage. For example, the root node is the set of 64 = 1296 possible secret codes since, at the beginning,the codebreaker has no information whatsoever. Each internal node of the tree is labeled with the guess to be done in casethe game reaches that stage, and for each possible answer to the guess, there is a child node that corresponds to the subsetof secret codes compatible with the answer. The leaves of the tree are nodes that correspond to singletons since theserepresent stages of the game at which the codebreaker has discovered the secret code.Fig. 1, for example, depicts an optimal strategy for a game of Mastermind with 3 pegs and 3 colors. Although the labelson the edges that tell the possible answers to the guesses are not shown, the important thing to note is the form of thesolution, i.e. its tree structure.The game of Mastermind can be cast as a non-deterministic planning problem with partial observability, and hencesolutions can be obtained with planners that perform search in belief space. Indeed, subsets of possible states (secret codesin Mastermind) are called belief states, and solutions like Fig. 1 are called contingent plans in belief space or contingentplans with partial observability. In general, if b is a belief state in the solution graph, o is an operator applicable at b, andz1, . . . , zn are the possible observations obtainable after the application of the operator o at b, then the children of b in thesolution graph are the beliefs bz1o denotes the belief that results after applying o at b and observing zi .o where bzio , . . . , bznThere are natural variations of the game such as the ones that result by increasing the number of colors in the secretcode or the number of available colors to choose from. However, there is a more interesting variation that is known asstatic Mastermind [14,23]. In this variation, the codebreaker is asked to give ahead a linear sequence of guesses such thatthe secret code can be determined from the answers upon such guesses. For example, for a game with 3 pegs and 3 colors,the sequence(cid:3)(cid:2)guess(2, 0, 0), guess(2, 1, 0), guess(2, 2, 1)σ =is guaranteed to succeed independently of the chosen secret code. Moreover, its length is minimum among all such se-quences, and hence corresponds to an optimal sequence. Also observe that the length of σ is greater than or equal to thelength of any branch in the optimal contingent plan in Fig. 1; this is not a coincidence since the sequence σ must discoverthe secret code independently of its value.We call a sequence like σ a linear or conformant plan for a partially-observable problem. Linear plans had beenstudied before in the context of unobservable planning by the name of conformant planning [16,21,24,30,57]. Unlikepartially-observable problems like Mastermind, unobservable problems only admit linear plans as solutions, since underthe hypothesis of null observability, the decision maker has no available input on which to base his decisions. In unobserv-able problems, a linear plan generates a collection of trajectories that result from the uncertainty in the initial state and thenon-determinism in the actions of the problem. A linear plan is a valid plan when each trajectory that starts at an initialstate ends in a goal state. This is the reason for the name ‘conformant’ as it means that the trajectories generated by theplan conform with the goal of the problem.\fB. Bonet / Artificial Intelligence 174 (2010) 245–269247Until now, linear plans had been only generally considered for unobservable planning problems. However, as the ex-ample of Mastermind shows, it also makes sense to consider linear plans for problems with partial observability (andalso for problems with full observability). Hence, we think that the term ‘conformant’ has been improperly used torefer to two different things: a class of solutions, namely linear plans, and to the class of unobservable planning prob-lems.In fully-observable domains, a linear plan does not make use of the information available at each time step as the plandetermines the actions to do at each step independently of contingencies. Thus, this case is essentially the same as theunobservable one and, from now on, we treat unobservable problems as non-deterministic fully-observable problems forwhich only linear plans are acceptable. In partially-observable domains, a linear plan also dictates the actions to do ateach time step, without deviating from a unique line of execution, yet there is an important difference with respect to theformer case as now the decision maker must collect the observations generated during the application of the plan in orderto achieve the goal at the end of the plan.There are substantial differences between the cases of linear plans for fully-observable and partially-observable domains.The first important difference is about the guarantees offered by such a plan. In the former case, the agent has the guaran-tee that the last state after the application of the plan will be a goal state. In the latter case however, as illustrated in theexample of Mastermind, the agent has the guarantee that after applying the plan and collecting the observations generatedalong, he will have enough information to achieve the goal, e.g., computing the secret code in Mastermind. Hence, while con-formance in fully-observable domains is about the compliance of a set trajectories in state space, conformance for partially-observabledomains is about the compliance of a set of trajectories in belief space.The second important difference appears when studying the computational complexity of decision problems for bothnotions of conformance: ",
            {
                "entities": [
                    [
                        136,
                        190,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1722–1736Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAlgorithms and complexity results for persuasive argumentation ✩,✩✩Eun Jung Kim a, Sebastian Ordyniak b, Stefan Szeider b,∗a AlGCo project-team, CNRS, LIRMM, Montpellier, Franceb Institute of Information Systems, Vienna University of Technology, Austriaa r t i c l ei n f oa b s t r a c tArticle history:Received 1 October 2010Received in revised form 2 March 2011Accepted 4 March 2011Available online 8 March 2011Keywords:Abstract argumentationValue-based argumentation frameworksComputational complexityGraphical modelsBounded treewidthThe study of arguments as abstract entities and their interaction as introduced byDung (1995) [1] has become one of the most active research branches within ArtificialIntelligence and Reasoning. A main issue for abstract argumentation systems is theselection of acceptable sets of arguments. Value-based argumentation, as introduced byBench-Capon (2003) [8], extends Dung’s framework. It takes into account the relativestrength of arguments with respectto some ranking representing an audience: anargument is subjectively accepted if it is accepted with respect to some audience, it isobjectively accepted if it is accepted with respect to all audiences.Deciding whether an argument is subjectively or objectively accepted, respectively, arecomputationally intractable problems.In fact, the problems remain intractable understructural restrictions that render the main computational problems for non-value-basedargumentation systems tractable. In this paper we identify nontrivial classes of value-basedargumentation systems for which the acceptance problems are polynomial-time tractable.The classes are defined by means of structural restrictions in terms of the underlyinggraphical structure of the value-based system. Furthermore we show that the acceptanceproblems are intractable for two classes of value-based systems that where conjectured tobe tractable by Dunne (2007) [12].© 2011 Elsevier B.V. All rights reserved.1. IntroductionThe study of arguments as abstract entities and their interaction as introduced by Dung [1] has become one of the mostactive research branches within Artificial Intelligence and Reasoning, see, e.g., [2–4]. Argumentation handles possible con-flicts between arguments in form of attacks. The arguments may either originate from a dialogue between several agents orfrom the pieces of information at the disposal of a single agent, this information may even contain contradictions. A mainissue for any argumentation system is the selection of acceptable sets of arguments, where an acceptable set of argumentsmust be in some sense coherent and be able to defend itself against all attacking arguments. Abstract argumentation pro-vides suitable concepts and formalisms to study, represent, and process various reasoning problems most prominently indefeasible reasoning (see, e.g., [5,6]) and agent interaction (see, e.g., [7]).Extending Dung’s concept, Bench-Capon [8] introduced value-based argumentation systems that allow to compare argu-ments with respect to their relative strength such that an argument cannot successfully attack another argument that isconsidered of a higher rank. The ranking is specified by the combination of an assignment of values to arguments and an✩Ordyniak and Szeider’s research was supported by the European Research Council, grant reference 239962. Kim’s research was partially supported bythe EPSRC, grant reference EP/E034985/1.✩✩A preliminary and shortened version of this paper appeared in COMMA 2010.* Corresponding author.E-mail address: stefan@szeider.net (S. Szeider).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.03.001\fE.J. Kim et al. / Artificial Intelligence 175 (2011) 1722–17361723ordering of the values; the latter is called an audience [9]. As laid out by Bench-Capon, the role of arguments in this settingis to persuade rather than to prove, demonstrate or refute. Whether an argument can be accepted with respect to all possibleor at least one audience allows to formalize the notions of objective acceptance and subjective acceptance, respectively.An important limitation for using value-based argumentation systems in real-world applications is the computationalintractability of the two basic acceptance problems: deciding whether a given argument is subjectively accepted is NP-hard, deciding whether it is objectively accepted is co-NP-hard [10]. Therefore it is important to identify classes of value-based systems that are still useful and expressible but allow a polynomial-time tractable acceptance decision. However,no nontrivial tractable classes of value-based systems have been identified so far, except for systems with a tree structurewhere the degree of nodes and the number of nodes of degree exceeding 2 are bounded [11]. In fact, as pointed out byDunne [12], the acceptance problems remain intractable for value-based systems whose graphical structures form trees, instrong contrast to the main computational problems for non-value-based argumentation that are linear-time tractable fortree systems, or more generally, for systems of bounded treewidth [12].1.1. Our contributionIn this paper we introduce nontrivial classes of value-based systems for which the acceptance problems are tractable.The classes are defined in terms of the following notions:• The value-width of a value-based system is the largest number of arguments of the same value.• The extended graph structure of a value-based system has as nodes the arguments of the value-based system, two argu-ments are joined by an edge if either one attacks the other or both share the same value.• The value graph of a value-based system has as vertices the values of the system, two values v 1 and v 2 are joined by adirected edge if some argument of value v 1 attacks an argument of value v 2 [11].We show that the acceptance problems are tractable for the following classes of value-based systems:(P1) value-based systems with a bipartite graph structure where at most two arguments share the same value (i.e., systemsof value-width 2);(P2) value-based systems whose extended graph structure has bounded treewidth; and(P3) value-based systems of bounded value-width whose value graphs have bounded treewidth.In fact, we show that both acceptance problems are linear-time tractable for the classes (P2) and (P3), the latter beinga subclass of the former. Our results suggest that the extended graph structure is a suitable structural representation ofvalue-based argumentation systems. The positive results (P1)–(P3) hold for systems with unbounded number of arguments,attacks and values.We contrast our positive results with negative results that rule out classes conjectured to be tractable. We show that theacceptance problems are (co)-NP-hard for the following classes:(N1) value-based systems of value-width 2;(N2) value-based systems where the number of attacks between arguments of the same value is bounded (systems ofbounded attack-width);(N3) value-based systems with bipartite value graphs.In fact, we show that both acceptance problems are intractable for value-based systems of value-width 2 and attack-width 1.Classes (N1) and (N2) were conjectured to be tractable [12], the complexity of (N3) was stated as an open problem [11].The reminder of the paper is organized as follows. In Section 2 we provide basic definitions and preliminaries. In Sec-tion 3 we define the parameters value-width and attack-width and establish the results involving systems of value-width 2,we also discuss the relationship between systems of value-width 2 and dialogues [9]. In Section 4 we consider value-basedsystems with an extended graph structure of bounded treewidth and show linear-time tractability. We close in Section 5with concluding remarks. Some proofs of technical lemmas are given in Appendix A.The main results of this paper have been presented in preliminary and shortened form at COMMA’10 [13]. Here weprovide full proofs, examples, and additional discussions. Further new additions are the results (P3) and (N3) involvingvalue graphs, and the discussion of the relationship between systems of value-width 2 and dialogues.2. Arguments, attacks, values, and audiencesIn this section we introduce the objects of our study more formally.2.1. Abstract argumentation systemDefinition 1. An abstract argumentation system or argumentation framework is a pair ( X, A) where X is a finite set of elementscalled arguments and A ⊆ X × X is a binary relation called the attack relation. If (x, y) ∈ A we say that x attacks y.\f1724E.J. Kim et al. / Artificial Intelligence 175 (2011) 1722–1736Fig. 1. The abstract argumentation system F 0 and value-based system F of Examples 1 and 2, respectively.An abstract argumentation system F = ( X, A) can be considered as a directed graph, and therefore it is convenient toborrow notions and notation from the theory of directed graphs [14]. For example we say that a system F = ( X, A) is acyclicif ( X, A) is a DAG (a directed acyclic graph).Example 1. An abstract argumentation system F 0 = ( X, A) with arguments X = {a, b, c, d, e, f } and attacks A = {(a, d), (a, e),(b, a), (c, d), (d, b), ( f , c)} is displayed in Fig. 1.Next we define commonly used semantics of abstract argumentation systems as introduced by Dung [1]. For thediscussion of other semantics and variants, see, e.g., Baroni and Giacomin’s survey [15]. Let F = ( X, A) be an abstractargumentation system and S ⊆ X .1. S is conflict-free in F if there is no (x, y) ∈ A with x, y ∈ S.2. S is acceptable in F if for each x ∈ S and each y ∈ X with ( y, x) ∈ A there is some x3. S is admissible in F if it is conflict-free and acceptable.4. S is a preferred extension of F if S is admissible in F and there is no admissible set S(cid:5) ∈ S with (x(cid:5), y) ∈ A.(cid:5)of F that properly con",
            {
                "entities": [
                    [
                        138,
                        200,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 20–50Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSolving coalitional resource gamesPaul E. Dunne b, Sarit Kraus a,c,∗, Efrat Manisterski a, Michael Wooldridge ba Department of Computer Science, Bar-Ilan University, Ramat Gan, 52900, Israelb Department of Computer Science, University of Liverpool, Liverpool L69 7ZF, UKc Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 10 April 2008Received in revised form 18 September2009Accepted 22 September 2009Available online 25 September 2009Keywords:Coalitional gamesNTU gamesSolution conceptsThe coreBargainingAlgorithmsComplexity1. IntroductionCoalitional Resource Games (crgs) are a form of Non-Transferable Utility (ntu) game, whichprovide a natural formal framework for modelling scenarios in which agents must poolscarce resources in order to achieve mutually satisfying sets of goals. Although a numberof computational questions surrounding crgs have been studied, there has to date beenno attempt to develop solution concepts for crgs, or techniques for constructing solutions.In this paper, we rectify this omission. Following a review of the crg framework and adiscussion of related work, we formalise notions of coalition structures and the core forcrgs, and investigate the complexity of questions such as determining nonemptiness of thecore. We show that, while such questions are in general computationally hard, it is possibleto check the stability of a coalition structure in time exponential in the number of goalsin the system, but polynomial in the number of agents and resources. As a consequence,checking stability is feasible for systems with small or bounded numbers of goals. Wethen consider constructive approaches to generating coalition structures. We present anegotiation protocol for crgs, give an associated negotiation strategy, and prove that thisstrategy forms a subgame perfect equilibrium. We then show that coalition structuresproduced by the protocol satisfy several desirable properties: Pareto optimality, dummyplayer, and pseudo-symmetry.© 2009 Elsevier B.V. All rights reserved.There is currently much interest in the possibility of delegating complex tasks to semi-autonomous software agents[34,37]. A highly desirable requirement for such domains is that the agents should be able to reach agreements with one-another on matters of common interest. For example, in order to accomplish the goals that they have been delegated, agentsmay need to share a scarce resource, work together to achieve a common goal, or come to a common understanding abouta disputed domain of discourse. This requirement has motivated work in automated negotiation [22,28], online auctions [11]and computational social choice theory [15].In this paper, our interest lies in domains with the following characteristics:We desire some goal to be achieved, and delegate the goal to an agent, along with some bundle of resources, which may be expendedby the agent in order to accomplish the goal. Accomplishing the goal may require resources not possessed by the agent, promptingthe need for cooperation. A group of agents will thus pool resources to accomplish a set of goals to the satisfaction of all contributors.Our primary aim is for the agent to satisfy our goal, and to this end, if it is necessary to expend all the resources we endow it with,* Corresponding author.E-mail addresses: ped@csc.liv.ac.uk (P.E. Dunne), sarit@macs.biu.ac.il (S. Kraus), mjw@csc.liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.09.005\fP.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–5021then this is acceptable. However, if there are multiple ways of satisfying the goal, we desire that the agent should minimize resourceusage.The formal model we use to capture such scenarios is a refinement of the Coalitional Resource Games (crgs) framework,which was introduced in [39]. In a crg, each agent has a set of goals, and is endowed with some quantity of resources;each goal requires a specified quantity of each resource in order to accomplish it. The main change to the basic crg modelthat we make here is to introduce the idea of preferring outcomes that minimize resource consumption. To capture thesepreferences, we introduce costs: the cost to an agent of a particular scenario is simply the sum of the resource quantities itcontributes in this scenario.Many important real world scenarios seem to fit within this model. Consider agents that support arranging carpoolschemes.1The idea in a carpool scheme is to encourage people who live and work close to each other to share cars to and from work, ratherthan each driving their own car. We model car pooling in our framework as follows. A possible goal of an agent is arrangingtransportation for all necessary days and times. An agent may have more than one possible goal when the transportation can beon different possible days (e.g., a worker might visit the main office on either Monday or Wednesday). The resources are places incars for specific days, origin, destination, and time. An agent would prefer that another agent provides a ride, if possible, even if heis available on that day and has the car, since this will save his resources.One characteristic of our domains is that utility is non-transferable. In cooperative games with transferable utility, thevalue of a coalition is simply a real number, corresponding to payoff that can be divided amongst coalition members in anyway they see fit [25, p. 257]. In such games, utility is transferable because it can be transferred between coalition members.Most existing work in multi-agent negotiation and resource allocation assumes transferable utility [22,28]. The rationalefor our choice is that there are domains in which utility is non transferable, which is why non-transferable utility games(ntu games) have been studied in the literature [25, p. 268]. As an example with respect to our domain, when scientistscollaborate on a joint paper, the resources they contribute include their experience and expertise. Such resources are noteasy to value or trade explicitly, and the utility that one scientist gets from publishing a paper cannot usually be transferredto those that he or she cooperated with. (We elaborate on this issue in more detail in Section 3.)We emphasise that the scenarios we consider typically require cooperation: it is not in general the case that an agentcan achieve its goals in isolation, and will need to cooperate with others in order to do so. The possible outcomes of thesecooperative games are structures in which coalitions commit to achieve certain goals, and in which members of a coalitioneach commit to contribute some part of their resource endowment. Presented with a number of different possible outcomes,we want an agent to choose one that achieves its delegated goal while minimizing the cost to itself (i.e., minimizes thequantity of resources that it contributes). Given that we are in the realm of cooperative games, a number of issues thussuggest themselves for consideration [29]: Which coalitions will form? And how will these coalitions choose an outcomefrom those that are available to them, given the different preferences that agents have over outcomes?With respect to the former question, we formalise the core for our domain, and investigate the complexity of severalquestions surrounding the core. We show that it is co-np-complete to check whether a particular outcome is in the coreof a game, while it is co-np-hard to check whether the core is non-empty, or to check whether the core is non-emptyand contains a non-trivial outcome. However, as we will see, the core may be empty even with quite strong constraints ongames, and this motivates us to consider other types of outcomes.Our second contribution is to consider a constructive, bargaining-based approach to coalition structure generation.We present a negotiation protocol for the domain, and investigate its properties. Using backward induction, we derivestrategies that are in subgame perfect equilibrium, and prove that outcomes generated will, on average, satisfy three de-sirable properties: pseudo-symmetry, dummy player, and Pareto optimality. Although n-agent bargaining for ntu gameshas been considered in the game theory literature [16], there has been little work on this in computer science/ai (seee.g., [7]).A comment on notation and proofs. The remainder of the paper makes use of much notation, and for the reader’s conve-nience, we summarise the main notations used in Appendix A. In addition, in the interests of readability, we omit all longerproofs from the main text, presenting them instead in Appendix B.1 This is not a frivolous example: car pooling is a major activity, heavily promoted by some national governments as a means of reducing road traffic(and hence pollution, etc.). See, for example:http://www.carpoolworld.com/.Carpools have already been the subject of study using coalitional games, although from a somewhat different (more abstract) perspective than the presentpaper [24].\f22P.E. Dunne et al. / Artificial Intelligence 174 (2010) 20–502. Background and related workIf we are to build computer programs that can cooperate with each other, then it is natural to ask what models havebeen previously developed to model cooperative scenarios. Game theory is a valuable source of models for multi-agentsystems in general, and cooperative game theory in particular studies cooperation, addressing itself to such problems as whowill cooperate with who (i.e., which coalitions will form), and how such coalitions will share the benefits of cooperation.Within cooperative game theory, perhaps the simplest, best-known, and most widely studied model of cooperative gamesis the coalitional game with transferable utility [2",
            {
                "entities": [
                    [
                        134,
                        168,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 78 (1995) 121-145 Artificial Intelligence Multilevel enhancement and detection of stereo disparity surfaces Yibing Yang *, Alan L. Yuille Division of Applied Sciences, Harvard University, Cambridge, MA 02138, USA Received September 1993; revised December 1994 Abstract images arising from viewing The problem of stereo vision has been of increasing interest over the past decade. This paper presents a new computational for matching a pair of In contrast to stereo previous work, this approach formulates the matching problem as detection of a “bright”, coherent disparity surface in a 3D image called the spatio-disparity space (SDS) image. The SDS images represents the goodness of each and every possible match. to the computer vision community framework the same object from two different positions. A nonlinear filter is proposed for enhancing the disparity surface in the SDS image and for suppressing the noise. This filter is used to construct a hyperpyramid representation of the SDS image. Then the disparity surface is detected using a coarse-to-fine control structure. The proposed method is robust to photometric and geometric distortions in the stereo images, and has a number of computational advantages. It produces good results for complex scenes. 1. Introduction 1. I. Stereo matching and feature detection When viewed from two different perspectives, the same object will give rise to a pair of different images. The 3D shape and location of the object can be recovered by fusing the stereo pair. The human ability of stereo vision was first observed by Wheatstone [ 321, and the computational standpoint important the underlying mechanism [4,14,18]. applications for machine perception. The most Stereo are cartography [ 81 and robot vision is a useful method investigated has been [ 20,211. from * Corresponding author. Current address: Polaroid Co., 750M-3J, Cambridge, MA 02139, USA. E-mail: yangy@polaroid.com. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00028-3 \f122 Y Yung. A.L. Yuillr/Artificiul intelligence 78 (1995) 121-145 In recovering 3D shape using stereo, the most difficult is to find its corresponding the problem line constraint, we may assume raster image points constraint may be introduced. line.) Stereo matching tend to have roughly that corresponding task is image matching. Given point in the right image. lie is made possible by two facts: the same disparity. Based on this in the two points points (2) Corresponding from the same point on the object, appear similar; stereo matching otherwise. Based on this fact, a photometric constraint may be a point in the left image, (Thanks to the epipolur on the same horizontal ( I ) Neighboring fact, a geometric images, originating would be impossible formulated. Many stereo algorithms have been proposed. As a common proaches attempt sumption generically, piecewise This paper presents to match a left-image point is locally constant [ 2,3,5,22,25,3 smooth a new approach that the disparity feature, existing ap- to a right-image point, based on the as- [ 9- 11,13,16,17,19,24,26,27] or more 1,331. the matching to a feature detection problem. To match a pair of 1D stereo images I’ = Z’(X) to stereo matching. We convert problem and I’ = Zr( x), we may assign a numerical value E( x, u) to measure similarity between for every possible match E = E(x, M). As such the task becomes image E = E(Y, u). the SDS images, Z= E(“(x,.Y,U). In the case of matching the “bright” disparity (x, M) we get an spatio-disparity the detection the problem is to detect surface (SDS space image the “bright” disparity curve image) in 2D stereo in the 3D SDS image two conventional the point x’ in I’ and the point (X - u) in I’. By computing E(x, M) the photometric the disparity curve and simultaneously the 1D case where the SDS image is E = 3(x, u). We want a filter which the noise. The disparity from it different filter should be that makes curves such as fingerprints. The disparity curve sensitive Consider can enhance curve has a number of photometric/geometric conventional able to take advantage of these properties. Conventional in this respect. curve detectors prove ineffective properties suppress We will present a new filter which is sensitive to the disparity surface/curve in the SDS image. The filter is quite simple, and can be synthesized filters-a morphological the filter undulations in an effective and efficient way. filter. Unlike conventional it to accommodate filter and a linear the nonlinearity is nonlinear; enables from two conventional curve detectors, surface disparity 1.2. Hierarchical methods Hierarchical methods based on pyramid data structures have been widely used in in stereo matching. Traditional hierarchical for stereo matching are based on the multiresolution representations [6] of the [ 28,291, and in particular, computer vision methods stereo images and thus can be characterized 19,27,3 1 1. Fig. 1 illustrates a pair of pyramids {I:} and {I;} 1: and 1: are respectively performed II. The belief is that by smoothing reduced-resolution the multiresolution paradigm. The first step is to construct for the input stereo images I’ and I’. At the kth level, is is to match Z: and versions of I’ and I’. Then matching in a coarse-to-fine manner. At the kth level, the problem the stereo images matching is simplified. as multiresolution methods [ 1,7,9,10,17, \fZ Yang, A.L. Yuille/Artijicial Intelligence 78 (1995) 121-145 123 Fig. 1. The multiresolution paradigm for disparity detection. The multiresolution is counterproductive the psychophysical instead, dense scheme, however, the input images stereo information smoothed perspective, by smoothing From to fuse; methods often have difficulty coping with sloping surfaces stereo image points have regularity intensity. But the viewed surface images of sloping Lambertian surfaces have the regularity in the smoothed is fronto-parallel. remains, unless the same is helpful in textured regions stereo pairs are not necessarily for stereo fusion. Moreover, multiresolution for some types of scenes; is also filtered out. easier in the scene. For example, that corresponding images, no photometric texture In this paper we will propose a new hierarchical method for stereo matching called the the disparity representa- in Fig. 2, the hyperpyramid is based on a hyperpyramid to detecting constructed; Bk+t multilevel method. As stated above, stereo matching amounts surface in the SDS image. The multilevel method tion {Bk} of the SDS image B = E( X, y, U) . As illustrated is recursively filter is the surface-sensitive version of z”k. We can envision integration of stereo information integrating regions. Once surfaces { uk} in a coarse-to-fine manner. is a filtered and reduced-size the hyperpyramid filter mentioned above; Bk+t this stereo information we do not assume disparity constancy compute is constructed, we recursively the construction in I’ and I’ over successively-larger of the SDS image hyperpyramid image regions. version of Bk, where the is not a reduced-resolution as the In in the image the disparity 2. The SDS image 2.1. Spatio-disparity space At an image position (x, y), the xyu-space between points a match. the spatio-disparity the disparity value u can be any real number. We call space (SDS) which consists of all possible matches (x, y, U) in the SDS represents in the left and right images. Any point \fI24 Y Ycmg. A.L Yuille/Arrijiciul Intelligence 78 (I 995) 121-145 Fig. 2. The multilevel paradigm for disparity detection Fig. 3. Lines of sight in the cyclopean SDS We want to investigate the disparity SDS can be defined with respect image. (x + 14/2, y) in th e e t Image, and point In the cyclopean SDS, a point 1 f surface U(x,y) in the context of the SDS. The to the left image or the right image or the cyclopean the match between point (x, y, 14) represents (x - u/2,y) in the right image. is defined by an image point and the corresponding Fig. 3 shows the lines of sight for the left and right views in the cyclopean SDS. (A line of sight In the cyclopean SDS the right lines of sight have a slope of 2 and the left lines of sight have a slope of -2. Of course, constraint the disparity A left line of sight or a right line of sight can intersect with the disparity surface at no more than one point. Fig. 3 shows a profile of a valid disparity surface lines of sight are parallel surface the cyclopean regarding is the uniqueness in the xu-plane. to the u-axis. An important focal point.) constraint: \fY Yang, A.L. Yuille/Artijcial Intelligence 78 (1995) 121-145 125 The region between a and b is visible only in the left image and, on the other hand, the region between c and d is visible only in the right image. 2.2. SDS image A point in the SDS represents a match, and the goodness of the match can be evaluated similarity measure. By assigning a numerical value, or intensity, by using an appropriate to each SDS point we get an SDS image. Given a pair of stereo images I’ = I’( x, y) , I’ = F(x, y), the SDS image can be defined by using the sum-of-squared-difference measure. Let Then the intensity of an SDS point (x, y, u) is defined as B(&YTu) = -~wm?)(edb7) - eml)))27 (1) 5.7 where w is a window ruble: w = w( 5,~) = w( 5) w(v) w( ., .) is normalized: Cf,T = 1. function which has the following properties: ; (2) w( .) is symmetric and nonnegative-dejnite; ( 1) w( ., .) is sepa- (3) A more desirable similarity measure intensity the SDS image can be expressed as: is normalized correlation. Based on this measure, P(x,y,u) = C,,w(5,77)81(~,77)er(S,rl) (2) dCr~w(5,rl)(er(~.?7))* CF,ow(5,17)(er(5,71))2’ where 0 < Z(X, y, u) < E,,,,, E 1. This measure has the advantage of being to the photometric distortions position. The results reported from in this paper were obtained using robust the change of viewing this measure. in the stereo pair arising 2.2.1. Problem of ambiguity In the SDS image a po",
            {
                "entities": [
                    [
                        75,
                        140,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 95 ( 1997) 257-3 16 Artificial Intelligence Modeling belief in dynamic systems, Part I: Foundations * Nir Friedman a,*, Joseph Y. Halpern b,l a Computer Science Division, 387 Soda Hall, Universiry of California, Berkeley, CA 94720, USA h Computer Science Department, Cornell University, Ithaca, NY 148.53, USA Abstract Belief change is a fundamental problem in AI: Agents constantly have to update their beliefs to accommodate new observations. In recent years, there has been much work on axiomatic characterizations of belief change. We claim that a better understanding of belief change can be gained from examining appropriate semanfic models. In this paper we propose a general framework in which to model belief change. We begin by defining belief in terms of knowledge and plausibility: an agent believes C$ if he knows that C$ is more plausible than -4. We then consider some properties defining the interaction between knowledge and plausibility, and show how these properties affect the properties of belief. In particular, we show that by assuming two of the most natural properties, belief becomes a KD45 operator. Finally, we add time to the picture. This gives us a framework in which we can talk about knowledge, plausibility (and hence belief), and time, which extends the framework of Halpem and Fagin for modeling knowledge in multi-agent systems. We then examine the problem of “minimal change”. This notion can be captured by using prior plausibilities, an analogue to prior probabilities, which can be updated by “conditioning”. We show by example that conditioning on a plausibility measure can capture many scenarios of interest. In a companion paper, we show how the two best-studied scenarios of fit into our framework. @ 1997 Elsevier Science belief change, belief revision and belief update, B.V. *Some of this work was done while both authors were at the IBM Almaden Research Center. The first author was also at Stanford while much of the work was done. IBM and Stanford’s support are gratefully acknowledged. The work was also supported under Contract F496’20-91-C-0080 IRI-96-25901. A preliminary version of this paper appears Aspects of Reasoning About Knowledge ( 1994) pp. 44-64, under for belief change. Part I: Foundations”. and in Proceedings of the 5th Conference on Theoretical in part by the Air Force Office of Scientific Research the title “A knowledge-based and grant F94620-96-l-0323 and by NSF under grants IRI-95-03109 framework (AFSC), * Corresponding ’ Email: halpem@cs.comell.edu. author. Email: nir@cs.berkeley.edu. http://www.cs.berkeley.edu/wnir. http://www.cs.comell.edu/home/halpem. 0004-3702/97/$17.00 PIf SOOO4-3702( @ 1997 Elsevier Science B.V. A11 rights reserved 97)00040-4 \f258 N. Friedman, J.E Halpern/Arr@cial Intelligence 95 (1997) 257-316 Keywords: Belief change; Belief revision; Minimal change; Logic of knowledge; Logic of belief; Logic of time; Plausibility measures; AGM postulates 1. Introduction imagine situations where the corridor In order to act in the world we must make assumptions, is clear” or “my car is parked where I left it”. These assumptions, however, are defeasible. We can easily is blocked, or where the car is stolen. We call the logical consequences of such defeasible assumptions beliefs. As time passes, we constantly or withdraw understand how beliefs should change. assumptions. The problem of belief change is to that might cause us to make additional obtain new information some of our previous such as “the corridor assumptions In the literature, two instances of this general phenomenon The study of belief change has been an active area in philosophy [ 27,381. in detail: Belief revision [ 1,271 attempts a new belief and in artificial have intelligence to describe how an agent should been studied about a static accommodate world. Belief update [ 381, on the other hand, attempts to describe how an agent should change his beliefs as a result of learning in the world. Belief revision and belief update describe only two of the many ways in which beliefs can change. Our in general. This paper to reason about belief change goal is to construct describes the [23] we consider paper In a companion special cases of belief revision and update in more detail. inconsistent with his other beliefs) the details of that framework. about a change a framework (possibly Perhaps approach to belief change the most straightforward represent an in some language and then put constraints on agent’s beliefs as a closed set of formulas how these beliefs can change. This is essentially as their results show, much can be done with this framework. The main problem with this for belief. As we hope to show in approach this paper and in [23], such a semantics of how and why beliefs change. Moreover, the tools to deal with complicating can give us a much deeper understanding this semantics provides factors such actions, external events, and multiple agents. is that it does not provide a good semantics in [ 1,27,38]; the approach is to simply taken have then to giving semantics One standard approach Intuitively, [ 3,3 1,38,57] to beliefs is to put a preference ordering on such an ordering captures the set of worlds that the agent considers possible. the relative interpreted likelihood of worlds. Various authors “the agent believes @’ as “4 is true in the most plausible worlds that the agent considers is to put a probability measure over the set of possible possible”. An alternative approach of $ is close worlds. Then we can interpret “the agent believes @’ as “the probability based on plausibility to 1” [ 501. We examine a new approach just associates with an measures, introduced in some partially ordered event (i.e., a set of possible worlds) to modeling uncertainty, set. This approach such as probability measures, belief and preference orderings. We interpret of e5 is greater than that of l@‘. As we show, the “agent believes 6’ as “the plausibility to “$ is true in the most plausible worlds”. (but not always) equivalent this is often its plausibility, an element is easily seen to generalize other approaches in [20,24], where a plausibility measure to modeling uncertainty functions, \fN. Friedman, J.E Halpern/Art$cial Intelligence 95 (I 997) 257-316 259 that beliefs implies By modeling is subjective, [ 3,411.) This in this way, there is being made: namely, the plausibility measure the agent’s estimate of the plausibility is an assumption state. (This assumption that the plausibility mea- sure is part of the agent’s epistemic is actually made explicitly in is, it de- scribes of each event. But actually, an even is char- stronger assumption acterized by a single plausibility measure. We feel that this latter assumption makes they cannot the models represent such as “Alice does a situation where in the summer”. To cap- not know several plausibility measures possible; ture it typically does. * As we shall see, in some this extra expressive power is necessary scenarios of belief change. to be. In particular, is not sure about what is plausible, it typically does not rain and in others that this, we need to capture some interesting it typically does not rain that the agent’s epistemic in San Francisco than they ought to allow Alice less expressive to consider the agent state that To deal with this, in addition to plausibility measures, we add a standard accessibility to represent knowledge. Once we have knowledge that an agent believes C#I if she knows that C$ is typically she considers possible, 4 is more plausible in the picture, we define true. That is, to all the plausibility measures relation belief by saying according than -4. these keeping generalizes probability. interactions, of knowledge that defines knowledge. We study relation that plausibility and probability that arise The properties of belief depend on how the plausibility measure In view of this, that many of the issues studied by Fagin and Halpern interacts with the in it is perhaps not sur- [ 141 when consider- in our framework. There to the inter- and belief. As we shall see, if we take what are perhaps is characterized introspective the interaction by Kraus [40]. Although our major goal is not an abstract study of the proper- interpretation accessibility mind prising ing the interaction are, however, a number of new issues action between knowledge the most natural restrictions by the axioms of the modal knowledge between knowledge and Lehmann ties of knowledge under which approach. about her beliefs, but may have false beliefs). Moreover, also arise in our framework due and belief, we view the fact that we have a concrete to be an important side-benefit of our (where an agent has complete on this logic KD45 the standard properties our notion of belief and belief satisfies these properties can be studied interaction, considered the beliefs of the agent before and after the change, This framework time explicitly for modeling knowledge in order to study belief change. We want a is is in into the framework. The resulting [33] Having a notion of belief is not enough that captures framework achieved by introducing an extension of the framework of Halpern and Fagin multi-agent and time. This framework time studied represented change. is analogous to combination systems, and allows to talk about knowledge, plausibility in [ 351. AS we show by example, having knowledge, plausibility, explicitly gives us a powerful and expressive framework of knowledge, probability (and hence belief), and and time for capturing belief * In fact, this issue is discussed by Boutilier [ 3 1, although his framework does not allow him to represent such a situation. \f260 N. Friedman, J.E Halpern/Artijicial Intelligence 95 (1997) 257-316 reasoning, t. In probabilistic this new information; at time t + 1 to incorporate This framework is particularly suited to studying how plausibility intuition we would like to capture at time t + 1 to have changed minimally a",
            {
                "entities": [
                    [
                        68,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 738–771www.elsevier.com/locate/artintSolving quantified constraint satisfaction problems ✩Ian P. Gent a, Peter Nightingale a, Andrew Rowley a, Kostas Stergiou b,∗a School of Computer Science, University of St Andrews, St Andrews, Fife, KY16 9SS, UKb Department of Information and Communication Systems Engineering, University of the Aegean, GreeceReceived 15 August 2006; received in revised form 2 April 2007; accepted 5 November 2007Available online 22 November 2007AbstractWe make a number of contributions to the study of the Quantified Constraint Satisfaction Problem (QCSP). The QCSP is anextension of the constraint satisfaction problem that can be used to model combinatorial problems containing contingency oruncertainty. It allows for universally quantified variables that can model uncertain actions and events, such as the unknown weatherfor a future party, or an opponent’s next move in a game. In this paper we report significant contributions to two very differentmethods for solving QCSPs. The first approach is to implement special purpose algorithms for QCSPs; and the second is to encodeQCSPs as Quantified Boolean Formulas and then use specialized QBF solvers. The discovery of particularly effective encodingsinfluenced the design of more effective algorithms: by analyzing the properties of these encodings, we identify the features in QBFsolvers responsible for their efficiency. This enables us to devise analogues of these features in QCSPs, and implement them inspecial purpose algorithms, yielding an effective special purpose solver, QCSP-Solve. Experiments show that this solver and ahighly optimized QBF encoding are several orders of magnitude more efficient than the initially developed algorithms. A final,but significant, contribution is the identification of flaws in simple methods of generating random QCSP instances, and a means ofgenerating instances which are not known to be flawed.© 2007 Elsevier B.V. All rights reserved.Keywords: Quantified constraint satisfaction problems; Quantified Boolean formulas; Arc consistency; Search algorithms; Random problems1. IntroductionQuantified Constraint Satisfaction Problems (QCSPs) can be used to model various PSPACE-complete combina-torial problems from domains like planning under uncertainty, design, adversary game playing, and model checking.For example, in game playing we may want to determine if a consistent strategy exists for all possible moves of theopponent. In a design problem it may be required that a configuration must be possible for all possible sequences ofuser choices. As a final example, when planning in a safety critical environment, such as a nuclear station, we may✩ Parts of this paper have appeared in the conference papers [I. Gent, P. Nightingale, A. Rowley, Encoding quantified CSPs as quantified Booleanformulae, in: Proceedings of ECAI-2004, 2004, pp. 176–180; I. Gent, P. Nightingale, K. Stergiou, QCSP-Solve: A solver for quantified constraintsatisfaction problems, in: Proceedings of IJCAI-2005, 2005].* Corresponding author.E-mail addresses: ipg@dcs.st-and.ac.uk (I.P. Gent), pn@dcs.st-and.ac.uk (P. Nightingale), agdr@dcs.st-and.ac.uk (A. Rowley),konsterg@aegean.gr (K. Stergiou).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.11.003\fI.P. Gent et al. / Artificial Intelligence 172 (2008) 738–771739require that an action is possible for every eventuality. QCSPs extend traditional, unquantified, CSPs to deal with thekind of contingency found in the above examples.The QCSP naturally generalizes the standard CSP formalism by allowing for universally quantified variables.Universal variables are used to model actions or events which are contingent, for which we are uncertain, or justthose which are not in our control. Examples would be contingencies such as user choices in a configuration problem,uncertainties such as the weather in a plan to hold a garden party, or opponent moves in an adversary game. In aconventional CSP, all variables are existentially quantified, since all are within our control. The values in the domainof a universal variable capture all the possible outcomes of the event or action modelled by this variable. In this way,QCSPs model bounded uncertainty. In a QCSP we try to find a strategy, defining the values of the existential variablesfor all possible sequences of instantiations for the universal variables, so that all the constraints in the problem aresatisfied. Such a strategy guarantees that there is a solution whatever values the universal variables take, i.e. whateverthe outcome of the uncertain actions and events. The generalization of CSPs to QCSPs increases the expressiveness ofthe framework, but at the same time the complexity of the decision task rises from NP-complete to PSPACE-complete[8,26,38].There is already considerable interest in quantified constraint reasoning in the case of Quantified Boolean Formulae(QBF), which is the generalization of SAT that allows universal quantification (for example, [13,23,29,32,33]). Also,there is a significant body of work on quantified problems with continuous real domains (e.g. [5,41]). Ratschan givesnumerous references to papers on this subject [40]. As far as QCSPs with discrete finite non-Boolean domains areconcerned, there is recent research on theory defining the complexity of various reasoning tasks and also specifyingtractable subclasses (e.g. [8,11,15–18]). Also, various useful concepts from CSPs, such as global and local consistency,substitutability and interchangeability, have been defined for QCSPs [11,12]. However, little has been done as faras algorithms for solving QCSPs are concerned. In the few existing works, Bordeaux and Monfroy introduced aframework for implementing arc consistency and described filtering operators for certain classes of constraints [9,12]. Also, very recently, Verger and Bessière proposed a bottom-up solver for QCSPs called BlockSolve [44], whileBenedetti, Lallouet and Vautard implemented QeCode, a QCSP solver built on top of the CSP solver Gecode [4].In this paper we report the first comprehensive attempt to build effective QCSP solvers, although we limit ourselvesto the case where constraints are binary. We make contributions to two very different approaches to solving QCSPs.These are special purpose solvers for QCSPs; and encoding QCSPs as QBF instances so that existing QBF solverscan be used. In each approach we introduce novel and effective techniques. We also show how experience with theencodings directly influenced the design of better techniques for the specialized solvers.We first approach QCSPs directly by extending well-known algorithms from the standard to the quantified case.This is analogous to the approach taken at the early stages of research in QBF. We show that some of the most widelyused techniques for CSPs can be adapted to deal with quantification. We first describe a generic arc consistencyalgorithm that can be used to enforce AC in any binary QCSP. We then extend the chronological backtracking (BT),forward checking (FC), and maintaining arc consistency (MAC) algorithms so that they can handle quantification. Wealso propose modifications of FC and MAC that take advantage of the properties of QCSPs.Then we follow an orthogonal approach, based on encoding QCSPs as QBFs. A particular advantage of encod-ing one search problem as another occurs when, as here, search techniques for the target problem are more highlydeveloped than the original. In contrast to QCSP, numerous advanced solvers are available for QBF. We describe afinely-tuned encoding which can be several orders of magnitudes more efficient than the direct methods described sofar. The tuning of encodings to be effective for search is considerably more involved than in the case of SAT, whereencodings often have an elegant simplicity. A simple way of lifting CSP encodings to QCSP is very ineffective, so weexplore and implement new ideas, without analogues in SAT, that make search very effective.Apart from obtaining efficient tools for QCSP solving, we benefit from the study and development of encodings tolearn valuable lessons that can be transferred to direct algorithms. So in the third, and final, stage in the developmentof algorithms for QCSPs we analyze the advantages offered by our QBF encoding to identify the features responsi-ble for its efficiency. We identify three sophisticated techniques; conflict-based backjumping [39], solution-directedbackjumping [32], and most importantly, the pure literal rule [14], as important reasons for the success of QBF solversin solving encoded QCSP instances. We devise analogues of these features in QCSPs, and implement them on top ofdirect algorithms, to yield a specialized direct solver, called QCSP-Solve.A final issue we address in this paper is that of benchmarking, since there is naturally a distinct lack of benchmarksto compare algorithms on. This is a familiar problem that has appeared in the early stages of experimental research\f740I.P. Gent et al. / Artificial Intelligence 172 (2008) 738–771in various other areas. As was the case with CSP, SAT, and QBF, we address this problem by proposing and usingmethods to generate random instances. We show that a simple generalization of random generation models fromCSPs or QBF to QCSPs is prone to flaws, which quickly affect all generated instances. We then introduce a randomgenerator that is free from these flaws, although it remains possible that it will suffer from a currently unknown flaw.Experiments run on problems created using this generator reveal a progressive, and dramatic, improvement in theefficiency of our methods; starting with the initial direct algorithms and culminating in QCSP-Solve and a highlyoptimized QBF encoding.This paper is structured as follows. In Section 2 we give the necessary definitions and background. We then presentprogressively more efficient methods of handling",
            {
                "entities": [
                    [
                        72,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 173 (2009) 1406–1423Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintEncoding deductive argumentation in quantified Boolean formulaePhilippe Besnard a, Anthony Hunter b,∗, Stefan Woltran ca IRIT-CNRS, Universitè Paul Sabatier, 118 rte de Narbonne, 31062 Toulouse, Franceb Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UKc Institute for Information Systems 184/2, Technische Universität Wien, Favoritenstrasse 9-11, 1040 Vienna, Austriaa r t i c l ei n f oa b s t r a c tThere are a number of frameworks for modelling argumentation in logic. They incorporatea formal representation of individual arguments and techniques for comparing conflictingarguments. A common assumption for logic-based argumentation is that an argument is apair (cid:3)(cid:2), α(cid:4) where (cid:2) is minimal subset of the knowledge-base such that (cid:2) is consistentand (cid:2) entails the claim α. Different logics provide different definitions for consistency andentailment and hence give us different options for argumentation. Classical propositionallogic is an appealing option for argumentation but the computational viability of generatingan argument is an issue. To better explore this issue, we use quantified Boolean formulaeto characterise an approach to argumentation based on classical logic.© 2009 Elsevier B.V. All rights reserved.Article history:Received 27 January 2009Received in revised form 12 May 2009Accepted 25 June 2009Available online 27 June 2009Keywords:Argument systemsArgumentationClassical logicInconsistencyQuantified Boolean formulaeConflicting knowledge1. IntroductionArgumentation is a vital aspect of intelligent behaviour by humans. Consider diverse professionals such as politicians,journalists, clinicians, scientists, and administrators, who all need to collate and analyse information looking for pros andcons for consequences of importance when attempting to understand problems and make decisions.There is a range of proposals for logic-based formalisations of argumentation (for reviews see [8,13,31]). These proposalsallow for the representation of arguments for and against some claim, and for counterargument relationships betweenarguments.In a number of key proposals for argumentation, an argument is a pair where the first item in the pair is a consistentset (or a minimal consistent set) of formulae that proves the second item which is a formula (see for example [1,5,7,15,24,26,30]). Hence, different underlying logics provide different definitions for consistency and entailment and hence give usdifferent options for defining the notion of an argument.Since classical logic has many advantages for representing and reasoning with knowledge including syntax, proof theoryand semantics for the intuitive language incorporating negation, conjunction, disjunction and implication, it is an interestingand promising choice for the underlying logic for argumentation. However, it is computationally challenging to generatearguments from a knowledge-base using classical logic. If we consider the problem as an abduction problem, where weseek the existence of a minimal subset of a set of formulae that implies the consequent, then the problem is in the secondlevel of the polynomial hierarchy [23]. Furthermore, given a knowledge-base (cid:4) and a formula α, it has been shown thatascertaining whether there is a subset (cid:2) of (cid:4) such that (cid:3)(cid:2), α(cid:4) is an argument (i.e. (cid:2) is consistent, (cid:2) entails α, and thereis no subset of (cid:2) that entails α) is a (cid:5) p2 -complete decision problem [29].* Corresponding author.E-mail address: A.Hunter@cs.ucl.ac.uk (A. Hunter).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.006\fP. Besnard et al. / Artificial Intelligence 173 (2009) 1406–14231407Beyond these observations, there remains a range of further important computational complexity questions. So to betterunderstand the use of classical logic in argumentation, and in particular to understand its computational properties, weuse quantified Boolean formulae (QBFs) to characterise an approach to argumentation that is based on classical logic. Thischaracterisation can then be used to obtain computational complexity results in terms of upper bounds.A further reason to characterise logic-based argumentation in the form of QBFs is that we can then harness implementa-tions of QBF solvers to develop prototype implementations for logic-based argumentation. There are numerous QBF solversavailable (see, e.g, [28] and the references therein), and the encodations we present in this paper can be straightforwardlyhandled in them.2. Preliminaries2.1. Logical argumentationIn this section we review an existing proposal for logic-based argumentation [7]. We consider a classical propositionallanguage. We use α, β, γ , . . . to denote formulae and (cid:4), (cid:2), (cid:8), . . . to denote sets of formulae. Deduction in classical propo-sitional logic is denoted by the symbol (cid:5) and deductive closure by Th so that Th((cid:2)) = {α | (cid:2) (cid:5) α}.For the following definitions, we first assume a knowledge-base (cid:4) (a finite set of formulae) and use this (cid:4) throughout.We further assume that every subset of (cid:4) is given an enumeration (cid:3)α1, . . . , αn(cid:4) of its elements, which we call its canonicalenumeration. This really is not a demanding constraint: In particular, the constraint is satisfied whenever we impose anarbitrary total ordering over (cid:4). Importantly, the order has no meaning and is not meant to represent any respective impor-tance of formulae in (cid:4). It is only a convenient way to indicate the order in which we assume the formulae in any subset of(cid:4) are conjoined to make a formula logically equivalent to that subset.The paradigm for the approach is a large repository of information, represented by (cid:4), from which arguments can beconstructed for and against arbitrary claims. Apart from information being understood as declarative statements, there is noa priori restriction on the contents, and the pieces of information in the repository can be as complex as possible. Therefore,(cid:4) is not expected to be consistent. It need not even be the case that every single formula in (cid:4) is consistent.The framework adopts a very common intuitive notion of an argument. Essentially, an argument is a set of relevantformulae that can be used to classically prove some claim, together with that claim. Each claim is represented by a formula.Definition 1. An argument is a pair (cid:3)(cid:2), α(cid:4) such that: (1) (cid:2) ⊆ (cid:4); (2) (cid:2) (cid:7)(cid:5) ⊥; (3) (cid:2) (cid:5) α; and (4) there is no (cid:2)(cid:9) ⊂ (cid:2) suchthat (cid:2)(cid:9) (cid:5) α. We say that (cid:3)(cid:2), α(cid:4) is an argument for α. We call α the claim (or consequent) of the argument and (cid:2) thesupport of the argument (we also say that (cid:2) is a support for α).Example 1. Let (cid:4) = {α, α → β, γ → ¬β, γ , δ, δ → β, ¬α, ¬γ }. Some arguments are:(cid:2)(cid:2)(cid:2)(cid:2)(cid:3)(cid:3){α, α → β}, β{¬α}, ¬α{α → β}, ¬α ∨ β{¬γ }, δ → ¬γ(cid:3).(cid:3)By monotonicity of classical logic the following equivalent characterisation easily follows.Proposition 1. A pair (cid:3)(cid:2), α(cid:4) is an argument iff it satisfies (1)–(3) from Definition 1 together with (4(cid:9)) for each φ ∈ (cid:2), ((cid:2) \\ {φ}) (cid:7)(cid:5) α.Arguments are not independent. In a sense, some encompass others (possibly up to some form of equivalence). To clarifythis requires a few definitions as follows.Definition 2. An argument (cid:3)(cid:2), α(cid:4) is more conservative than an argument (cid:3)(cid:8), β(cid:4) iff (cid:2) ⊆ (cid:8) and β (cid:5) α.Example 2. (cid:3){α}, α ∨ β(cid:4) is more conservative than (cid:3){α, α → β}, β(cid:4).Definition 3. An argument (cid:3)(cid:2), α(cid:4) is strictly more conservative than an argument (cid:3)(cid:8), β(cid:4) iff (cid:2) ⊆ (cid:8), β (cid:5) α, and either (cid:8) (cid:7)⊆ (cid:2)or α (cid:7)(cid:5) β.Some arguments directly oppose the support of others, which amounts to the notion of an undercut.Definition 4. An undercut for an argument (cid:3)(cid:2), α(cid:4) is an argument (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) where {φ1, . . . , φn} ⊆ (cid:2).\f1408P. Besnard et al. / Artificial Intelligence 173 (2009) 1406–1423Example 3. Let (cid:4) = {α, α → β, γ , γ → ¬α}. Then, (cid:3){γ , γ → ¬α}, ¬(α ∧ (α → β))(cid:4) is an undercut for (cid:3){α, α → β}, β(cid:4). A lessconservative undercut for (cid:3){α, α → β}, β(cid:4) is (cid:3){γ , γ → ¬α}, ¬α(cid:4).Definition 5. (cid:3)(cid:8), β(cid:4) is a maximally conservative undercut for (cid:3)(cid:2), α(cid:4) iff (cid:3)(cid:8), β(cid:4) is an undercut for (cid:3)(cid:2), α(cid:4) such that noundercuts of (cid:3)(cid:2), α(cid:4) are strictly more conservative than (cid:3)(cid:8), β(cid:4).The value of the following definition of canonical undercut is that we only need to take the canonical undercuts intoaccount. This means we can justifiably ignore the potentially very large number of non-canonical undercuts.Definition 6. An argument (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) is a canonical undercut for (cid:3)(cid:2), α(cid:4) iff it is a maximally conservative undercutfor (cid:3)(cid:2), α(cid:4) and (cid:3)φ1, . . . , φn(cid:4) is the canonical enumeration of (cid:2).The next result is central.Proposition 2. (See Theorem 5.4 [7].) A pair (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) is a canonical undercut for (cid:3)(cid:2), α(cid:4) iff it is an undercut for (cid:3)(cid:2), α(cid:4)and (cid:3)φ1, . . . , φn(cid:4) is the canonical enumeration of (cid:2).In other words, the canonical undercuts for (cid:3)(cid:2), α(cid:4) are given by all arguments of the form (cid:3)(cid:8), ¬(φ1 ∧ · · · ∧ φn)(cid:4) where(cid:3)φ1, . . . , φn(cid:4) is the canonical enumerat",
            {
                "entities": [
                    [
                        138,
                        201,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 174 (2010) 1460–1480Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAgent decision-making in open mixed networksYa’akov Gal a,b,∗, Barbara Grosz b, Sarit Kraus c,d, Avi Pfeffer e, Stuart Shieber ba Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israelb School of Engineering and Applied Sciences, Harvard University, USAc Computer Science Department, Bar Ilan University, Israeld Institute for Advanced Computer Studies, University of Maryland, USAe Charles River Analytics, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 14 December 2008Received in revised form 18 August 2010Accepted 27 August 2010Available online 21 September 2010Keywords:Human–Computer decision-makingNegotiationComputer systems increasingly carry out tasks in mixed networks, that is in group set-tings in which they interact both with other computer systems and with people. Partic-ipants in these heterogeneous human–computer groups vary in their capabilities, goals,and strategies; they may cooperate, collaborate, or compete. The presence of people inmixed networks raises challenges for the design and the evaluation of decision-makingstrategies for computer agents. This paper describes several new decision-making modelsthat represent, learn and adapt to various social attributes that influence people’s decision-making and presents a novel approach to evaluating such models. It identifies a range ofsocial attributes in an open-network setting that influence people’s decision-making andthus affect the performance of computer-agent strategies, and establishes the importanceof learning and adaptation to the success of such strategies. The settings vary in the ca-pabilities, goals, and strategies that people bring into their interactions. The studies deploya configurable system called Colored Trails (CT) that generates a family of games. CT isan abstract, conceptually simple but highly versatile game in which players negotiate andexchange resources to enable them to achieve their individual or group goals. It provides arealistic analogue to multi-agent task domains, while not requiring extensive domain mod-eling. It is less abstract than payoff matrices, and people exhibit less strategic and morehelpful behavior in CT than in the identical payoff matrix decision-making context. By notrequiring extensive domain modeling, CT enables agent researchers to focus their attentionon strategy design, and it provides an environment in which the influence of social factorscan be better isolated and studied.© 2010 Published by Elsevier B.V.1. IntroductionComputer systems are increasingly being deployed in group settings in which they interact with people to carry out tasks[3,46,42,44,28]. To operate effectively in such settings, computer agents need capabilities for making decisions and negoti-ating with other participants—both people and computer-based agents—about the procurement and allocation of resourcesnecessary to complete their tasks. For example, in a civil disaster like an earthquake, rescue personnel and equipment aredispersed geographically and may be under the jurisdiction of various dispatchers. Dispatchers might depend on computeragents to allocate these limited resources to affected locations quickly and to alert them about changing environmentalconditions, such as wind speed and traffic. In turn, computer agents might depend on people to provide up-to-the-minute* Corresponding author at: Department of Information Systems Engineering, Ben-Gurion University of the Negev, Israel.E-mail address: kobig@bgu.ac.il (Y. Gal).0004-3702/$ – see front matter © 2010 Published by Elsevier B.V.doi:10.1016/j.artint.2010.09.002\fY. Gal et al. / Artificial Intelligence 174 (2010) 1460–14801461information about the availability of personnel and equipment. In another realm, in some electronic auction settings, bothpeople and computer agents (representing groups or individuals) might participate not only to acquire items of value, butalso to exchange information about the reliability of others.1First response and e-commerce are two different kinds of examples of open mixed networks. By “open” we mean that theautonomous agents in the network may be designed by or represent different individuals or organizations. By “mixed” wemean that the participants of the network may be computer agents or people. Computer agents operating in open, mixednetworks may support people in their work (e.g., collaborative human–computer interfaces [47,3]), serve as proxies forpeople or institutions (e.g., electronic commerce [25,44]), or interact with other agents to carry out tasks for which they areresponsible (e.g., robots in rescue operations [46,36]). These examples exhibit several key characteristics of mixed networksettings: (1) the participants are both human and computer-based; (2) they depend on each other to make decisions; (3)they may need to exchange resources and information; (4) they have different, complementary roles.Open mixed network settings present a range of challenges for agent designers. First, the participants in these networks—whether people or computer agents—are loosely coupled and not under the control of any single entity. Agent designersare unlikely to know a priori the strategies that people or agents designed by others will adopt, and they cannot forceothers’ agents to adopt a particular strategy. Second, people’s decision-making behavior in group settings does not followthe strategies of classical economic or game theoretic models, but is affected by such social and psychological factors ascognitive biases, social preferences, and framing effects [12,7,4]. It is difficult to measure the effects of such factors directly,and preferences are hard to elicit explicitly from people [9,35]. Third, agents may differ in their goals and plans, so agentdesigners need to develop strategies that are flexibly able to accommodate different levels of cooperation or competitiveness.For these reasons, it is at best challenging, and at worst, impossible, to construct effective agent strategies purely analytically.An alternative approach is to learn and evaluate agent strategies empirically. However, past empirical investigations ofcomputer agent strategies such as the Trading Agent Competition [1] and RoboCup soccer [2] have typically required a fullyspecified domain model. The need for extensive modeling of domain specific knowledge in such settings makes it difficultto distinguish among possible causes of agents’ failures and successes, such as the way agents model the specifics of thedomain or the way they make decisions more generally.On the other hand, completely abstract settings such as the payoff matrices or decision trees traditionally used in studiesin the behavioral sciences collapse the structure of a domain into a list of choices that does not capture the essentialrelationships among tasks, goals and resources.2 Such relationships often play an important role in decision making.The investigations in this paper were done in an environment that represents an intermediate approach. They use theCT (Colored Trails) system [20] which provides an analogue to the ways in which goals, tasks and resources interact in real-world settings, but abstracts away the complexities of real-world domains. CT supports comparisons of the performanceof different computational strategies for interacting in groups comprising people and computer agents as well as solelycomputer agents.3This paper presents several new decision-making models that represent, learn and adapt to various social attributes ofnegotiation in open, mixed-network settings. We consider in particular, social factors that influence possible negotiationdeals (e.g., joint benefit and inequality of outcome), traits of individual negotiators (e.g., altruism, trustworthiness, helpful-ness) and group structure (e.g., solidarity, hierarchy). Our results show that (1) people exhibit more helpful behavior andincrease their social welfare in CT settings than in payoff-matrix types of settings; and (2) computer agents that modeland learn the social factors that influence human negotiation strategies can outperform traditional game-theoretic equilibriastrategies when interacting with people and other computer agents in mixed networks.The contributions of the paper are four-fold: it presents new multi-agent decision-making models, ones that are ableto learn and adapt to the social attributes that affect behavior in open mixed networks; it presents a novel approach toevaluating such models; it shows empirically that agents using these models outperform traditional game-theoretic equi-libria strategies. Lastly, it describes CT more completely than before as a new environment for investigating the design andperformance for negotiation strategies in open-mixed networks. It integrates earlier reports of initial CT studies [17,16,48]and describes a broader range of experimental investigations which demonstrate the flexibility of the CT infrastructure tosupport different agent-design studies.The purpose of the work reported in this paper was not to design “plug-and-play” strategies for specific applicationssuch as first response or electronic commerce. Rather, the studies we describe show empirically that agents will be betterable to negotiate with people if they take into account social factors. In this respect, our results relate to recent work inthe social sciences that point to societal and cultural factors that people “bring into the game”, as influencing the way theybehave in negotiation settings [41,8]. Our studies differ from these in providing and evaluating computational models fordecision-making in these settings. In particular, they identify the influence of factors that have not been addressed in pasthuman–computer decision-making studies and show the influence of these factors on agent-strategy performance",
            {
                "entities": [
                    [
                        138,
                        182,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 76 (1995) 239-286 Artificial Intelligence An algorithm for probabilistic planning Nicholas Kushmerick*, Steve Hanks, Daniel S. Weld Department of Computer Science and Engineering, Box 352350, Universiv of Washington, Seattle, WA 98195, USA Received June 1993; revised March 1994 Abstract We define the probabilistic planning problem in terms of a probability distribution over initial world states, a boolean combination of propositions representing the goal, a probability threshold, and actions whose effects depend on the execution-time state of the world and on random chance. Adopting a probabilistic model complicates the definition of plan success: instead of demanding a plan that provably achieves the goal, we seek plans whose probability of success exceeds the threshold. In this paper, we present BURIDAN, an implemented least-commitment planner that solves problems of this form. We prove that the algorithm is both sound and complete. We then explore BURIDAN’S efficiency by contrasting four algorithms for pIan evaluation, using a combination of analytic methods and empirical experiments. We also describe the interplay between generating plans and evaluating them, and discuss the role of sc;arch control in probabilistic planning. 1. Introduction Classical planning assumes complete and deterministic information about the world for many domains: the ignition key might usually reasons. Even if a deterministic model is possible state and the effects of actions. These assumptions turning unknown be too complex outdoor weather rather than project of uncertainty: will the freeways be crowded? fail for it might to be useful. For example, when deciding between an indoor and an the to use a probabilistic model the cloud dynamics. The initial world state is also a source are inappropriate start one’s old car, but occasionally for a given domain, site for a wedding, one is likely to forecast * Corresponding author. E-mail: nick@cs.washington.edu. 0004-3702/9.5/$Q9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00087-5 \f240 N. Kushmerick et al. /Art$cial Intelligence 76 (I 995) 239-286 This paper presents a planning algorithm that does not depend on the assumptions of complete and deterministic information. We use a probability distribution over possible world states to model imperfect information about the initial world state, and we model actions using a conditional probability distribution over changes to the world. Adopting a probabilistic model complicates the definition of plan success. Instead of terminating when it builds a plan that provably achieves the goal, our planner terminates when it builds a plan that is s@icientZy likely to succeed: our algorithm produces a plan such that the probability of the plan achieving the goal is no less than a user-supplied probability threshold, if such a plan exists. The work reported here makes several contributions. First, we define a symbolic action representation and provide it probabilistic semantics. Second, we describe an implemented algorithm, BUFUDAN, ' for probabilistic planning. Third, we prove the planner both sound and complete. Fourth, we compare the efficiency of four different probabilistic assessment algorithms both analytically and with empirical experiments. Finally, we explore the interface between the process of generating plans and the process of evaluating them. I. I. Action representation Following [ 281, we extend the standard STRIPS [ 221 representation to allow condi- tional and probabilistic effects. In STRIPS, an action is “enabled” if its preconditions are satisfied when the action is executed, in which case the action has a deterministic effect. If the preconditions do not hold, the action is “disabled”, and executing it is an error or meaningless. This simple model is not sufficient for representing actions with multiple possible consequences. BIJRIDAN models actions that can be executed in any world state, with the effect of executing the action depending on the execution-time state and on random chance. Consider the following simple action from a robot planning domain. Suppose that a robot’s grasping operation is not always successful. We model this action’s effects as depending both on the state of the world at execution time and on random chance. Specifically, we model the uncertainty of this pickup action by describing it in terms of four consequences. In two of the consequences, the robot will be holding the block after executing the action, but in the other two the world state doesn’t change. To each consequence we assign a probability which depends on the state of the world when the action is executed. For example, we might encode the fact that if the gripper is dry then the block is successfully grasped 95% of the time, but if the gripper is wet then the block is grasped only 50% of the time. Fig. 1 shows our representation of the pickup action. Propositions like GD and HB (“gripper dry” and “holding block”) characterize the relevant part of the world’s state. The pL encode the conditional probabilities that the ’ Jean Buridan (ba rE diin’ ) , 1300-l 358, a French philosopher and logician, has been credited with originat- ing probability theory. He seems to have toyed with the idea of using his theory to decide among alternative courses of action: the parable of “Buridan’s Ass” is attributed to him, in which an ass that lacked the ability to choose starved to death when placed between two equidistant piles of hay. \fN. Kushmerick et al, /Art$cial Intelligence 76 (1995) 239-286 241 Fig. 1. The pickup action. GD means “gripper dry”; HI3 means “holding block”. corresponding consequence is realized when the action is executed. For example, pa = 0.95 indicates that consequence LY is realized with probability 0.95 given that GD holds when the action is executed. As shown in Fig. 1, actions are encoded with binary trees. The leaves of the tree are the action’s eflects, the set of changes made to the world state if the corresponding trigger holds when the action is executed. The labels on the path from the root encode the consequence’s trigger, a conjunction expressing the conditions under which this consequence occurs. For example, executing pickup when the gripper is dry (GD), would likely (probability 0.95) cause the robot to be holding the block ( HB). * Like STEuF5’ add- and delete-lists, consequences describe changes to the world state rather than entire states. As shown in the figure, we index an action’s consequences with (Y, p, etc. The binary tree representation enforces the constraint that the triggers for all consequences of an action are mutually exclusive and exhaustive: exactly one will be realized during execution. In classical planning, a world state is described with a set of propositions. Since BURIDAN’S domains are probabilistic, we characterize the agent’s knowledge of the world not as a single state but rather as a probability distribution over possible states. In the classical paradigm, actions cause a transition from one state to another; BURDAN'S actions induce a transition from one probability distribution to another. Graphical depictions of actions like Fig. 1 might give the mistaken impression that we are assigning probabilities directly to propositions in an action’s consequences with- out regard to the state of the world at execution time. This is not the case: we are assigning probabilities to possible world states in which propositions are determinis- tically true or false. Section 2 provides a formal semantics for our action representa- tion. 1.2. The planning algorithm The job of a probabilistic planning algorithm is to construct a sequence of actions such that executing each action in turn, starting from some initial probability distribution over states, results in a final distribution in which the goal expression holds with sufficient ’ Since no set of effects contains i%, our simple model of robot grippers does not capture the phenomenon of dropping an already held block when attempting a pickup. Of course, it would be easy to elaborate our model to account for this phenomenon by introducing HB to the triggers of the action so that the effect of pickup depends on whether something is already held. \f242 N. Kushmerick et al. /Art@ial Intelligence 76 (1995) 239-286 probability, where sufficiency is defined with respect to a user-supplied probability threshold. BURIDAN searches through a space of plans until it finds one that achieves the goal with sufficient probability. Each plan consists of a set of actions, a partial temporal ordering relation over the actions, a set of causal links, and a set of subgoals (each a proposition-action pair). The first two items are straightforward; the last two require some explanation. A causal link [ 381 Ai,‘zAj caches the planner’s reasoning that proposition p could is executed because consequence be true at the time action Aj (the link’s consumer) L of action Ai (the link’s producer) makes it true. The link is said to provide cuusul support for p. To realize this support, the planner must try to increase the probability that consequence L of Ai is realized and prevent p from being made false by other actions. BUFUDAN attempts the former by providing additional causal support to the triggers of Ai’s consequence c. set of subgoals-is The final component of a plan-the used for this purpose. The idea behind these pairs is analogous to a goal agenda in a classical planner: if p is a subgoal for action Aj (written p@Aj), then BURIDAN seeks to increase the probability of p at the time that Aj is executed. For example, one way to increase this probability is to add to the plan a new action that makes p true. Whenever BTJRIDAN does this (suppose it adds Ai whose consequence L makes p true), it records the decision with a BURIDAN then makes each proposition in consequence L’S trigger a causal link Ai,‘J+Aj. subgoal for Ai. When pla",
            {
                "entities": [
                    [
                        75,
                        114,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 2061–2074Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRandomized coalition structure generationTravis Service a,∗, Julie Adams ba Vanderbilt University, 357 Jacobs Hall, 2201 West End Nashville, TN 37235-1824, USAb Vanderbilt University, 359 Jacobs Hall, 2201 West End Nashville, TN 37235-1824, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 25 December 2010Received in revised form 11 July 2011Accepted 1 August 2011Available online 9 August 2011Keywords:Coalition structure generationCoalition formationCharacteristic function game√Randomization can be employed to achieve constant factor approximations to the coalitionstructure generation problem in less time than all previous approximation algorithms. Inparticular, this manuscript presents a new randomized algorithm that can generate a 23n2.587n) time, improving upon the previous algorithm thatapproximate solution in O (√n2.83n) time to guarantee the same performance. Also, the presented newrequired O (techniques allow a 14 approximate solution to be generated in the optimal time of O (2n)and improves on the previous best approximation ratio obtainable in O (2n) time of 18 .The presented algorithms are based upon a careful analysis of the sizes and numbers ofcoalitions in the smallest optimal coalition structures.An empirical analysis of the new randomized algorithms compared to their deterministiccounterparts is provided. We find that the presented randomized algorithms generatesolutions with utility comparable to what is returned by their deterministic counterparts(in some cases producing better results on average). Moreover, a significant speedup wasfound for most approximation ratios for the randomized algorithms over the deterministicalgorithms. In particular, the randomized 12 approximate algorithm runs in approximately22.4% of the time required for the deterministic 12 approximation algorithm for problemswith between 20 and 27 agents.© 2011 Elsevier B.V. All rights reserved.1. IntroductionMany situations require partitioning the agents into disjoint teams or coalitions where each coalition cooperatively com-pletes a subgoal or subtask [1–3]. However, the process of optimally partitioning the agents into coalitions is computationallydifficult due to the fact that the number of potential coalitions scales exponentially with the number of agents.Characteristic function games, a class of cooperative games, models cooperative multi-agent situations by assigning eachcoalition a value indicating the joint utility those agents will receive if they form a coalition [1,2,4–7]. For example, thisutility may be the difference between the utility earned by completing the subtask assigned to the potential coalition andthe estimated cost incurred during task execution. Given a set of agents, N, a characteristic function game is defined by afunction ν : N → R(cid:2)0. The value ν(C), for a coalition C ⊆ N, is the joint utility the members of C will receive if C forms.A coalition structure is simply a partitioning of the agents into disjoint coalitions. The coalition structure generation problem(CSG problem) is to construct a coalition structure C S that maximizes:ν(C S) =(cid:2)C∈C Sν(C).* Corresponding author.E-mail addresses: tservice@acm.org (T. Service), julie.a.adams@vanderbilt.edu (J. Adams).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.08.002\f2062T. Service, J. Adams / Artificial Intelligence 175 (2011) 2061–2074The asymptotically fastest algorithm to solve the CSG problem exactly is based on dynamic programming and runs inO (3n) time [2,8]. Due to the high computational complexity of the optimal CSG algorithm, much research has focused onthe development of anytime algorithms. While these anytime algorithms can quickly return approximate solutions, in theworst case most current anytime algorithms require O (nn) time to determine the optimal solution, far worse than the O (3n)time dynamic programming algorithm. Among the current state-of-the-art is Rahwan et al’s. [1] Integer Partition algorithm.Due to the high computational complexity of constructing the optimal coalition structure, our recent work has focusedon developing approximation algorithms that return solutions with bounds on their quality in time less than O (3n) [9,10].For example, our prior algorithm was capable of returning a solution that was at least 2n2.83n) time.This paper improves upon the state-of-the-art in CSG approximation algorithms by presenting randomized algorithmsthat achieve the same approximation ratios as our prior work, but require significantly less time. For example, our newrandomized approximation algorithm is capable of generating a 2n2.59n) time. This result improvesn2.83n) time deterministic algorithm for the same approximation ratio. We also show how to gen-upon our previous O (4 approximation in the optimal time of O (2n) (i.e., any algorithm must observe the values of all 2n − 1 coalitions inerate a 1order to guarantee any approximate solution [2]).3 approximation in O (3 of the optimal in O (√√√Our methods also permit approximation ratios that are unachievable by current approximation algorithms. For example,our randomized algorithm is the first designed to guarantee a 35 approximation ratio.All of the presented approximation algorithms are probabilistic in the sense that they are guaranteed to return theirstated approximation ratio with high probability. Iteratively running the algorithms a small number of times and simplytaking the highest quality solution yields the stated approximation ratio with high probability. For example, if a givenalgorithm finds a 22 , then running the algorithm k times and taking the bestresult yields a 23 approximation ratio with probability at least 12 )k. Several of the presented algorithmic results are of the form:3 approximation with probability 1 − ( 1Algorithm A returns a coalition structure that is guaranteed to have value within a factor ofprobability greater than 12 . A runs in expected time O (g(n)).f of the optimal withThat is, the output of the algorithm (and hence the quality of the solution it presents) is a random variable, and for someof the presented algorithms, the runtime of the algorithm is also a random variable.An empirical study is presented that shows the randomized algorithms perform similarly to their deterministic coun-terparts in terms of utility and sometimes find higher quality solutions. Further, it is shown that the run time of therandomized algorithms, for most approximation guarantees, is significantly faster than the deterministic algorithms.The remainder of the paper is organized as follows. Section 2 describes the prior work on coalition structure genera-tion. Section 3 presents the new randomized algorithms for coalition structure generation. Section 4 provides an empiricalcomparison of the new randomized algorithms to their deterministic counterparts. Section 5 presents concluding remarks.2. Related workMuch algorithm research has focused on the coalition structure generation problem. The current fastest algorithm that isguaranteed to find the optimal solution is based on dynamic programming and requires O (3n) time to find an optimal coali-tion structure on n agents [7,2,8]. Given this high computational complexity, recent work has focused on the developmentof anytime and approximation algorithms.Sandholm et al. [2] developed one of the first anytime algorithms for the coalition structure generation problem. Sand-holm et al. viewed coalition structure generation as a search through the lattice of partitions of the n agents, which theyreferred to as the coalition structure graph. Sandholm et al.’s algorithm proceeded by searching through the bottom twolevels of the coalition structure graph (i.e., those coalition structures that consisted of only one or two coalitions), followedby a breadth first search from the top of the graph (i.e., examining those coalition structures that consist of i coalitionsfollowed by those coalition structures that consist of i − 1 coalitions and so on). Sandholm et al. derive guarantees on thequality of the best solution found so far based upon which levels of the coalition structure graph have been searched.Among the state-of-the-art in anytime coalition structure generation is Rahwan et al.’s [1,6] Integer Partition algorithm.As with Sandholm et al.’s algorithm, the Integer Partition algorithm searches directly through the space of coalition struc-tures. The Integer Partition algorithm groups coalition structures together into subspaces based upon the sizes of thecoalitions they contain. For example, both the coalition structures {{1, 2}, {3}, {4}} and {{3, 4}, {1}, {2}} are in the samesubspace as they both contain a coalition of size 2 and two coalitions of size 1. Rahwan et al. show how to generate upperand lower bounds on the quality of the coalition structures in each subspace. The Integer Partition algorithm uses thosebounds to perform a branch and bound search through the space of all coalition structures. Empirically, Rahwan et al. haveshown that the Integer Partition algorithm is often capable of quickly pruning many of the subspaces from considerationand performs significantly better than Sandholm et al.’s algorithm.While the Integer Partition algorithm performs well empirically on many problem distributions, it is possible to constructdistributions on which the Integer Partition algorithms performance deteriorates significantly [10]. The worst case runtimerequired to find the optimal solution of both the Integer Partition algorithm and Sandholm et al.’s algorithm is O (nn), sincein the worst case each coalition structure must be examined and there are O (nn) coalition structures.\fT. Service, J. Adams / Artificial Intelligence 175 (2011) 2061–207420632.1. Deterministic approximation algorithmsOur recent work has focused",
            {
                "entities": [
                    [
                        138,
                        179,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 175 (2011) 1951–1983Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintItemset mining: A constraint programming perspectiveTias Guns∗, Siegfried Nijssen, Luc De RaedtKatholieke Universiteit Leuven, Celestijnenlaan 200A, 3001 Leuven, Belgiuma r t i c l ei n f oa b s t r a c tArticle history:Received 31 May 2010Received in revised form 5 May 2011Accepted 6 May 2011Available online 11 May 2011Keywords:Data miningItemset miningConstraint programmingThe field of data mining has become accustomed to specifying constraints on patternsof interest. A large number of systems and techniques has been developed for solvingsuch constraint-based mining problems, especially for mining itemsets. The approachtaken in the field of data mining contrasts with the constraint programming principlesdeveloped within the artificial intelligence community. While most data mining researchfocuses on algorithmic issues and aims at developing highly optimized and scalableimplementations that are tailored towards specific tasks, constraint programming employsa more declarative approach. The emphasis lies on developing high-level modelinglanguages and general solvers that specify what the problem is, rather than outlining howa solution should be computed, yet are powerful enough to be used across a wide varietyof applications and application domains.This paper contributes a declarative constraint programming approach to data mining.More specifically, we show that it is possible to employ off-the-shelf constraint program-ming techniques for modeling and solving a wide variety of constraint-based itemsetmining tasks, such as frequent, closed, discriminative, and cost-based itemset mining.In particular, we develop a basic constraint programming model for specifying frequentitemsets and show that this model can easily be extended to realize the other settings. Thiscontrasts with typical procedural data mining systems where the underlying proceduresneed to be modified in order to accommodate new types of constraint, or novelcombinations thereof. Even though the performance of state-of-the-art data miningsystems outperforms that of the constraint programming approach on some standard tasks,we also show that there exist problems where the constraint programming approach leadsto significant performance improvements over state-of-the-art methods in data mining andas well as to new insights into the underlying data mining problems. Many such insightscan be obtained by relating the underlying search algorithms of data mining and constraintprogramming systems to one another. We discuss a number of interesting new researchquestions and challenges raised by the declarative constraint programming approach todata mining.© 2011 Elsevier B.V. All rights reserved.1. IntroductionItemset mining is probably the best studied problem in the data mining literature. Originally applied in a supermarketsetting, it involved finding frequent itemsets, that is, sets of items that are frequently bought together in transactions ofcustomers [1]. The introduction of a wide variety of other constraints and a range of algorithms for solving these constraint-based itemset mining problems [33,5,41,42,11,31,50,9] has enabled the application of itemset mining to numerous other* Corresponding author. Tel.: +32 16 32 75 67; fax: +32 16 32 79 96.E-mail address: tias.guns@cs.kuleuven.be (T. Guns).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.05.002\f1952T. Guns et al. / Artificial Intelligence 175 (2011) 1951–1983problems, ranging from web mining to bioinformatics [31]; for instance, whereas early itemset mining algorithms focusedon finding itemsets in unsupervised, sparse data, nowadays closed itemset mining algorithms enable the application ofitemset mining on dense data [40,43], while discriminative itemset mining algorithms allow for their application on su-pervised data [35,13]. This progress has resulted in many effective and scalable itemset mining systems and algorithms,usually optimized to specific tasks and constraints. This procedural and algorithmic focus can make it non-trivial to extendsuch systems to accommodate new constraints or combinations thereof. The need to allow user-specified combinations ofconstraints is recognized in the data mining community, as witnessed by the development of a theoretical framework basedon (anti-)monotonicity [33,41,11] and systems such as ConQueSt [9], MusicDFS [50] and Molfea [18]. These systems supporta predefined number of (anti-)monotonicity based constraints, making them well suited for a number of typical data miningtasks.These approaches contrast with those of constraint programming. Constraint programming is a general declarativemethodology for solving constraint satisfaction problems, meaning that constraint programs specify what the problem is,rather than outline how the solution should be computed; it does not focus on a particular application. Constraint program-ming systems provide declarative modeling languages in which many types of constraints can be expressed and combined;they often support a much wider range of constraints than more specialized systems such as satisfiability (SAT) and integerlinear programming (ILP) solvers [10]. To realize this, the model is separated as much as possible from the solver. In the pasttwo decades, constraint programming has developed expressive high-level modeling languages as well as solvers that arepowerful enough to be used across a wide variety of applications and domains such as scheduling and planning [45].The question that arises in this context is whether these constraint programming principles can also be applied to itemsetmining. As compared to the more traditional constraint-based mining approach, this approach would specify data miningmodels using general and declarative constraint satisfaction primitives, instead of specialized primitives; this should makeit easy to incorporate new constraints and combinations thereof as – in principle – only the model needs to be extended tospecify the problem and general purpose solvers can be used for computing solutions.The contribution of this article is that we answer the above question positively by showing that the general, off-the-shelfconstraint programming methodology can indeed be applied to the specific problems of constraint-based itemset mining.1We show how a wide variety of itemset mining problems (such as frequent, closed and cost-based) can be modeled in aconstraint programming language and that general purpose out-of-the-box constraint programming systems can effectivelydeal with these problems.While frequent, closed and cost-based itemset mining are ideal cases, for which the existing constraint programmingmodeling language used suffices to tackle the problems, this cannot be expected in all cases. Indeed, in our formulation ofdiscriminative itemset mining, we introduce a novel primitive by means of a global constraint. This is common practice inconstraint programming, and the identification and study of global constraints that can effectively solve specific subproblemshas become a branch of research on its own [6]. Here, we have exploited the ability of constraint programming to serveas an integration platform, allowing for the free combination of new primitives with existing ones. This property allowsto find closed discriminative itemsets effectively, as well as discriminative patterns adhering to any other constraint(s).Furthermore, casting the problem within a constraint programming setting also provides us with new insights in howto solve discriminative pattern mining problems that lead to important performance improvements over state-of-the-artdiscriminative data mining systems.A final contribution is that we compare the resulting declarative constraint programming framework to well-knownstate-of-the-art algorithms in data mining. It should be realized that any such comparison is difficult to perform; thisalready holds when comparing different data mining (resp. constraint programming) systems to one another. In our com-parison we focus on high-level concepts rather than on specific implementation issues. Nevertheless, we demonstrate thefeasibility of our approach using our CP4IM implementation that employs the state-of-the-art constraint programming li-brary Gecode [47], which was developed for solving general constraint satisfaction problems. While our analysis revealssome weaknesses when applying this particular library to some itemset mining problem, it also reveals that Gecode canalready outperform state-of-the-art data mining systems on some tasks. Although outside the scope of the present paper, itis an interesting topic of ongoing research [37] to optimize constraint programming systems for use in data mining.The article is organized as follows. Section 2 provides an introduction to the main principles of constraint programming.Section 3 introduces the basic problem of frequent itemset mining and discusses how this problem can be addressed us-ing constraint programming techniques. The following sections then show how alternative itemset mining constraints andproblems can be dealt with using constraint programming: Section 4 studies closed itemset mining, Section 5 considersdiscriminative itemset mining, and Section 6 shows that the typical monotonicity-based problems studied in the literaturecan also be addressed in the constraint programming framework. We also study in these sections how the search of theconstraint programming approach compares to that of the more specialized approaches. The CP4IM approach is then evalu-ated in Section 7, which provides an overview of the choices made when modeling frequent itemset mining in a concreteconstraint programming system and compares the performance of this constraint programming system to specialized datamining systems. Finally, Section 8 concludes.1",
            {
                "entities": [
                    [
                        138,
                        190,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 189 (2012) 1–18Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the evaluation of election outcomes under uncertaintyNoam Hazon a,∗, Yonatan Aumann a, Sarit Kraus a, Michael Wooldridge ba Department of Computer Science, Bar-Ilan University, Ramat Gan, Israelb Department of Computer Science, University of Liverpool, Liverpool, United Kingdoma r t i c l ei n f oa b s t r a c tArticle history:Received 7 March 2010Received in revised form 18 April 2012Accepted 30 April 2012Available online 3 May 2012Keywords:Computational social choiceVoting rulesWe investigate the extent to which it is possible to compute the probability of a particularcandidate winning an election, given imperfect information about the preferences of theelectorate. We assume that for each voter, we have a probability distribution over a setof preference orderings. Thus, for each voter, we have a number of possible preferenceorderings – we do not know which of these orderings actually represents the preferencesof the voter, but for each ordering, we know the probability that it does. For the case wherethe number of candidates is a constant, we are able to give a polynomial time algorithmto compute the probability that a given candidate will win. We present experimentalresults obtained with an implementation of the algorithm, illustrating how the algorithm’sperformance in practice is better than its predicted theoretical bound. However, when thenumber of candidates is not bounded, we prove that the problem becomes #P-hard forthe Plurality, k-approval, Borda, Copeland, and Bucklin voting rules. We further show thateven evaluating if a candidate has any chance of winning is NP-complete for the Pluralityvoting rule in the case where voters may have different weights. With unweighted voters,we give a polynomial algorithm for Plurality, and show that the problem is hard for manyother voting rules. Finally, we give a Monte Carlo approximation algorithm for computingthe probability of a candidate winning in any settings, with an error that is as small asdesired.© 2012 Elsevier B.V. All rights reserved.1. IntroductionSocial choice theory is concerned with making group decisions in situations where the preferences of participants in thedecision-making process may be different [1]. The mechanism by which such a collective decision is made is typically a vot-ing procedure. In a voting procedure, participants (voters) express their preferences via votes, and the voting procedure thendefines the social outcome chosen as a function of the votes cast. A fundamental issue in the social choice literature is thedesign of voting procedures that will select a social outcome which reflects the preferences expressed by voters as closelyas possible [13]. In recent years, the computational aspects of social choice theory have been increasingly studied [20]. Froma computational perspective, perhaps the most natural question relating to voting is the following: Given the preferences/votesof all the voters, is it possible to compute efficiently the winning outcome according to a particular voting rule? Fortunately, it seemsthat relatively few widely used voting rules are hard to compute in this sense [5]. Another key computational question thathas been studied in the context of voting procedures is that of manipulation: the extent to which it is computationally easyor hard for a voter to determine how to vote so as to achieve the best outcome possible for themselves [4,15,19].As the references above indicate, the computational aspects of voting procedures have been increasingly studied inrecent years. However, many computational studies of voting procedures assume perfect information about voter preferences* Corresponding author.E-mail addresses: hazonn@cs.biu.ac.il (N. Hazon), aumann@cs.biu.ac.il (Y. Aumann), sarit@cs.biu.ac.il (S. Kraus), mjw@liv.ac.uk (M. Wooldridge).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.009\f2N. Hazon et al. / Artificial Intelligence 189 (2012) 1–18or votes.1 That is, when we compute the social outcome, we are assumed to have complete and correct knowledge of thepreferences/votes of all the voters. However, there are important settings in which obtaining the complete preferences/votesof all voters is either not realistic or else not desirable:• Communication can be unreliable. Social choice theory largely ignores the possibility that preferences/votes may be lost intransit. However, if, for example, voting takes place via a communications network such as the Internet, then thisassumption is not valid. Data communications networks are inherently unreliable, and in many domains, reliablecommunication is simply impossible. In such situations, we may need to make social choices without access to thepreferences/votes of all voters.• Communication can be expensive. In some situations, the cost associated with gathering complete preferences/votes fromvoters may be unrealistically high. For example, if a decision is required very quickly, then the time required to gatherall preferences/votes in a large system may be unacceptable.For these reasons, we study the computational aspects of voting rules with an imperfect information model of prefer-ences/votes. There are of course many ways in which one could model incomplete information about voter preferences.For example, one model that has been studied in the literature is that of incomplete models of preferences [27,30]. Here itis assumed that we have a partial but nevertheless correct model of the preferences of voters. Intuitively, we know howvoters rank some of the candidates, but not all of them. One can then ask, for example, whether there is some “completion”of the preferences of voters that would lead to the election of a particular candidate.In our work, we use a different model of incomplete information; we do not claim this model is superior to thatof [27,30], but it provides an interesting alternative framework for modeling voting scenarios with incomplete information.We assume that for each voter, we have a probability distribution over a set of preference orderings. The idea is that although wedo not know a voter’s preference ordering exactly, we know that it is one of a set of possible orderings (typically a subsetof the overall set of possible preference orders), and we have a probability distribution over these. This information may,for example, be obtained from historical voting data, or by sampling. In this setting, the following fundamental questionarises: Given such an incomplete information model of voter preferences, a particular candidate, and a particular voting rule, what isthe probability that the given candidate would win using the given voting rule, assuming the given voter preference model? We referto this as the Evaluation problem. The Evaluation problem has received very little attention to date.2 Our aim is thus togain an understanding of the computational properties of this problem; and in particular, classes of problem instances forwhich Evaluation is computationally easy, and classes of problem instances for which it is computationally hard.The remainder of the paper is structured as follows. We first give some background and review some common votingrules in Section 2. We formally define theEvaluation problem in Definition 1. In Section 3, we first give a polynomialalgorithm to solve the evaluation problem if the number of candidates is a constant. While a result in [16] establishesthat Evaluation is NP-hard for several key voting procedures, even under quite stringent assumptions about probabilitydistributions, we show that this result holds only for weighted voting rules with weights that are not bounded by poly(n).We then experimentally evaluate our algorithm, showing that the actual running time and space are smaller than theasymptotic bound. Therefore, we also test how many voters the polynomial-time algorithm can handle for a given set ofcandidates. The results demonstrate that even with 6 or 7 candidates, the algorithm can handle more than 100 voters, whichsuggests that it may be used in many real-world voting scenarios. If the number of candidates is not bounded, the evaluationproblem becomes much harder: we show in Section 4 that even for the well-known Plurality, k-approval, Borda, Copeland,and Bucklin voting rules, the problem is #P-hard. We then analyze a simpler question, known as the Chance-Evaluationproblem (Definition 2). This question simply asks whether a candidate has any chance of being the winner (i.e., whetherthe probability that the candidate will win is greater than 0). Surprisingly, this problem is shown to be NP-complete (inthe strong sense) even for the Plurality voting rule, when voters do not all have equal weights. We give a polynomial timealgorithm for Plurality when all voters have equal weights, and show that the Chance-Evaluation problem is hard for manyother voting rules (including k-approval, Borda, Copeland and Bucklin). Finally, we present a Monte Carlo algorithm that isable to approximately answer even the Evaluation problem where the number of candidates is a parameter, with an erroras small as desired. We discuss related work in Section 5. Table 1 summarizes our key results (for comparison, we alsoinclude results from [16]).2. Preliminary definitionsAn election is given by a set of candidates (also referred to as alternatives) C = {c1, . . . , cm} and a set of voters V ={1, . . . , n}. Each voter i ∈ V is associated with a preference order R i , which is a total order over C . A vector R = (R1, . . . , Rn),containing a preference order for each voter, is called a preference profile.A voting rule F is a mapping from the set of all preference profiles to the set of candidates: if F (R) = c, we say thatthat could bec wins under F in R. A voting rule is said to be anonymous if F (R) = F",
            {
                "entities": [
                    [
                        142,
                        198,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 262 (2018) 279–300Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTogether we know how to achieve: An epistemic logic of know-howPavel Naumov a, Jia Tao b,∗a Claremont McKenna College, Claremont, CA, USAb Lafayette College, Easton, PA, USAa r t i c l e i n f oa b s t r a c tThe existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The article studies an interplay between the distributed knowledge, coalition strategies, and coalition “know-how” strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay.© 2018 Elsevier B.V. All rights reserved.Article history:Received 26 May 2017Received in revised form 24 May 2018Accepted 12 June 2018Available online 21 June 2018Keywords:StrategyGame theoryKnowledgeFormal epistemologyLogicAxiomatizationCompletenessImperfect information1. IntroductionAn agent a comes to a fork in a road. There is a sign that says that one of the two roads leads to prosperity, another to death. The agent must take the fork, but she does not know which road leads where. Does the agent have a strategy to get to prosperity? On one hand, since one of the roads leads to prosperity, such a strategy clearly exists. We denote this fact by modal formula Sa p, where statement p is a claim of future prosperity. Furthermore, agent a knows that such a strategy exists. We write this as KaSa p. Yet, the agent does not know what the strategy is and, thus, does not know how to use the strategy. We denote this by ¬Ha p, where know-how modality Ha expresses the fact that agent a knows how to achieve the goal based on the information available to her. In this article we study the interplay between modality K, representing knowledge, modality S, representing the existence of a strategy, and modality H, representing the existence of a know-how strategy. Our main result is a complete trimodal axiomatic system capturing properties of this interplay.1.1. Epistemic transition systemsIn this article we use epistemic transition systems to capture knowledge and strategic behavior. Informally, epistemic transition system is a directed labeled graph supplemented by an indistinguishability relation on vertices. For instance, our motivational example above can be captured by epistemic transition system T 1 depicted in Fig. 1. In this system state w* Corresponding author.E-mail addresses: Pavel.Naumov@ClaremontMcKenna.edu (P. Naumov), taoj@lafayette.edu (J. Tao).https://doi.org/10.1016/j.artint.2018.06.0070004-3702/© 2018 Elsevier B.V. All rights reserved.\f280P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Fig. 1. Epistemic transition system T 1.Fig. 2. Epistemic transition system T 2.Fig. 3. Epistemic transition system T 3.(cid:3)represents death. The original state is u, but it is indistinguishable by the agent arepresents the prosperity and state wfrom state v. Arrows on the diagram represent possible transitions between the states. Labels on the arrows represent the choices that the agents make during the transition. For example, if in state u agent chooses left (L) road, she will transition to the prosperity state w and if she chooses right (R) road, she will transition to the death state w. In another epistemic state v, these roads lead the other way around. States u and v are not distinguishable by agent a, which is shown by the dashed line between these two states. In state u as well as state v the agent has a strategy to transition to the state of prosperity: u (cid:2) Sa p and v (cid:2) Sa p. In the case of state u this strategy is L, in the case of state v the strategy is R. Since the agent cannot distinguish states u and v, in both of these states she does not have a know-how strategy to reach prosperity: u (cid:2) Ha p and v (cid:2) Ha p. At the same time, since formula Sa p is satisfied in all states indistinguishable to agent a from state u, we can claim that u (cid:2) KaSa p and, similarly, v (cid:2) KaSa p.As our second example, let us consider the epistemic transition system T 2 obtained from T 1 by swapping labels on transitions from v to w and from v to w, see Fig. 2. Although in system T 2 agent a still cannot distinguish states u and v, she has a know-how strategy from either of these states to reach state w. We write this as u (cid:2) Ha p and v (cid:2) Ha p. The strategy is to choose L. This strategy is know-how because it does not require to make different choices in the states that the agent cannot distinguish.(cid:3)(cid:3)1.2. Imperfect recallFor the next example, we consider a transition system T 3 obtained from system T 1 by adding a new epistemic state s. (See Fig. 3.) From state s, agent a can choose label L to reach state u or choose label R to reach state v. Since proposition q is satisfied in state u, agent a has a know-how strategy to transition from state s to a state (namely, state u) where q is satisfied. Therefore, s (cid:2) Haq.A more interesting question is whether s (cid:2) HaHa p is true. In other words, does agent a know how to transition from state s to a state in which she knows how to transition to another state in which p is satisfied? One might think that such a strategy indeed exists: in state s agent a chooses label L to transition to state u. Since there is no transition labeled by L that leads from state s to state v, upon ending the first transition the agent would know that she is in state u, where she needs to choose label L to transition to state w. This argument, however, is based on the assumption that agent a has a perfect recall. Namely, agent a in state u remembers the choice that she made in the previous state. We assume that the agents do not have a perfect recall and that an epistemic state description captures whatever memories the agent has in this state. In other words, in this article we assume that the only knowledge that an agent possesses is the knowledge captured by \fP. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300281Fig. 4. Epistemic transition system T 4.Fig. 5. Epistemic transition system T 5.the indistinguishability relation on the epistemic states. Given this assumption, upon reaching the state u (indistinguishable from state v) agent a knows that there exists a choice that she can make to transition to state in which p is satisfied: s (cid:2) HaSa p. However, she does not know which choice (L or R) it is: s (cid:2) HaHa p.1.3. Multiagent settingSo far, we have assumed that only agent a has an influence on which transition the system takes. In transition system T 4depicted in Fig. 4, we introduce another agent b and assume both agents a and b have influence on the transitions. In each state, the system takes the transition labeled D by default unless there is a consensus of agents a and b to take the transition labeled C. In such a setting, each agent has a strategy to transition system from state u into state w by voting D, but neither of them alone has a strategy to transition from state u to state wbecause such a transition requires the consensus of both agents. Thus, u (cid:2) Sa p ∧ Sb p ∧ ¬Saq ∧ ¬Sbq. Additionally, both agents know how to transition the system from state u into state w, they just need to vote D. Therefore, u (cid:2) Ha p ∧ Hb p.In Fig. 5, we show a more complicated transition system obtained from T 1 by renaming label L to D and renaming label R to C. Same as in transition system T 4, we assume that there are two agents a and b voting on the system transition. We also assume that agent a cannot distinguish states u and v while agent b can. By default, the system takes the transition labeled D unless there is a consensus to take transition labeled C. As a result, agent a has a strategy (namely, vote D) in state u to transition system to state w, but because agent a cannot distinguish state u from state v, not only does she not know how to do this, but she is not aware that such a strategy exists: u (cid:2) Sa p ∧ ¬Ha p ∧ ¬KaSa p. Agent b, however, not only has a strategy to transition the system from state u to state w, but also knows how to achieve this: u (cid:2) Hb p.(cid:3)1.4. CoalitionsWe have talked about strategies, know-hows, and knowledge of individual agents. In this article we consider knowledge, strategies, and know-how strategies of coalitions. There are several forms of group knowledge that have been studied before. The two most popular of them are common knowledge and distributed knowledge [1]. Different contexts call for different forms of group knowledge.As illustrated in the famous Two Generals’ Problem [2,3] where communication channels between the agents are unreli-able, establishing a common knowledge between agents might be essential for having a strategy.In some settings, the distinction between common and distributed knowledge is insignificant. For example, if members of a political fraction get together to share all their information and to develop a common strategy, then the distributed knowledge of the members becomes the common knowledge of the fraction during the in-person meeting.Finally, in some other situations the distributed knowledge makes more sense than the common knowledge. For example, if a panel of experts is formed to develop a strategy, then this panel achieves the best result if it relies on the combined knowledge of its members rather than on their common knowledge.In this article we focus on distributed coalition knowledge and distributed-know-how strategies. We leave the common knowledge for the future research. Establishing distributed knowledge though communication between agents might affect what is known by individual agents [4], but the communication between agents is out of the scope of this paper.To illustrate how distributed knowled",
            {
                "entities": [
                    [
                        136,
                        199,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 271 (2019) 74–97Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintCooperative games with overlapping coalitions: Charting the tractability frontierYair Zick a,∗a School of Computing, National University of Singapore, Singaporeb School of Electronic and Computer Engineering, Technical University of Crete, Greecec Department of Computer Science, University of Oxford, UKd Department of Informatics, Athens University of Economics and Business, Greece, Georgios Chalkiadakis b, Edith Elkind c, Evangelos Markakis da r t i c l e i n f oa b s t r a c tArticle history:Received 6 July 2016Received in revised form 24 January 2018Accepted 21 November 2018Available online 30 January 2019Keywords:Cooperative gamesOverlapping coalition formationCoreTreewidthArbitration functionsThe framework of cooperative games with overlapping coalitions (OCF games), which was proposed by Chalkiadakis et al. [1], generalizes classic cooperative games to settings where agents may belong to more than one coalition. OCF games can be used to model scenarios where agents distribute resources, such as time or energy, among several tasks, and then divide the payoffs generated by these tasks in a fair and/or stable manner. As the framework of OCF games is very expressive, identifying settings that admit efficient algorithms for computing ‘good’ outcomes of OCF games is a challenging task. In this work, we put forward two approaches that lead to tractability results for OCF games. First, we propose a discretized model of overlapping coalition formation, where each agent i has a weight W i ∈ N and may allocate an integer amount of weight to any task. Within this framework, we focus on the computation of outcomes that are socially optimal and/or stable. We discover that the algorithmic complexity of this task crucially depends on the amount of resources that each agent possesses, the maximum coalition size, and the pattern of communication among the agents. We identify several constraints that lead to tractable subclasses of discrete OCF games, and supplement our tractability results by hardness proofs, which clarify the role of our constraints. Second, we introduce and analyze a natural class of (continuous) OCF games—the Linear Bottleneck Games. We show that such games always admit a stable outcome, even assuming a large space of feasible deviations, and provide an efficient algorithm for computing such outcomes.© 2019 Published by Elsevier B.V.1. IntroductionConsider the following simple market exchange. Two sellers (Alice and Bob) each own a ton of coffee beans (a divisible good), which they would like to sell to two potential buyers (Claire and Dave). Claire and Dave operate in different markets, so Alice and Bob can justifiably offer them different prices. Suppose that having agreed on a transaction schedule and payments, Alice decides that she is unhappy with her revenue from the deal with Claire; she wants to cancel the deal. However, Dave, upon hearing that Alice reneged on her deal with Claire, no longer wishes to work with Alice, canceling * Corresponding author.E-mail addresses: zick@comp.nus.edu.sg (Y. Zick), gehalk@ece.tuc.gr (G. Chalkiadakis), elkind@cs.ox.ac.uk (E. Elkind), markakis@gmail.com (E. Markakis).https://doi.org/10.1016/j.artint.2018.11.0060004-3702/© 2019 Published by Elsevier B.V.\fY. Zick et al. / Artificial Intelligence 271 (2019) 74–9775his agreement with her as well. Dave’s motivation for doing so may stem from many reasons, e.g. a potential business partnership with Claire, or market ‘best practices’.This setting features several interesting characteristics. First, an agent may sell resources to several agents, and may also buy from several other agents. In other words, agents may allocate resources to several profit-generating tasks. Second, agents may withdraw some of their resources from some agreements. For example, Alice may wish to sell less coffee to some customer, but not change her interactions with other parties. Finally, when trying to strategically change an agreement, agents must be aware of how their actions affect the contracts they still maintain with other (possibly unaffected) parties.In our example, agents must collaborate in order to generate revenue. Having generated revenue by making an exchange, agents are free to share the profits from the exchange as they see fit. Profit sharing can be done directly, if the agents jointly produce a new good using their resources, sell it, and distribute the revenue among themselves. It can also be indirect: a seller shares the profit from her transaction with a buyer by setting a price for her good. In either case, agents must identify a way to generate profits, and, subsequently, share profits among themselves in a reasonable manner. When sharing profits, agents should account for individuals or groups of agents who feel that they are underpaid. Indeed, a group of agents that can get more money by deviating from the proposed agreement may destabilize the entire market, resulting in a cascade of deviations, which may eventually produce a less desirable state (not to mention the cost of actual deviation). However, what constitutes a profitable deviation strongly depends on how non-deviators respond to the deviators’ actions.Reasoning about this system of incentives and reactions is a significant challenge. While many group interaction scenar-ios can be represented by the framework of transferable utility cooperative games (TU games), with stable profit-sharing schemes captured by the notion of the core (see, e.g., Peleg and Sudhölter [2]), the standard setting of TU games is not expressive enough to deal with agents participating in several collaborative agreements simultaneously. A few years ago, Chalkiadakis et al. [1] proposed a novel approach to modeling scenarios where agents can divide resources among several joint tasks, by introducing the framework of overlapping coalition formation games (OCF games) and defining several vari-ants of the notion of core stability for this model, which capture different reactions to deviations by non-deviating agents; these include the conservative core, the refined core, the optimistic core, and the sensitive core. Following their work, Zick et al. [3] proposed the notion of an arbitration function, which provides a general model for handling deviations in OCF games. These two works offer a comprehensive conceptual model for analyzing stability in settings where agents work on several concurrent projects and may deviate in a complex manner.In contrast, there has been a very limited amount of work on computing solution concepts for OCF games. The theory of OCF games is a generalization of classic cooperative game theory [2], where computational issues are relatively well-understood (see [4] for an overview). However, as Chalkiadakis et al. [1] show, more elaborate reactions to deviation may increase computational complexity: even if a solution concept is easy to compute for classic cooperative games, computing its OCF analogue may be NP-hard. For example, Chalkiadakis et al. [1] study a class of games called threshold task games: these are games where each agent is associated with an integer weight, and the value of a coalition is a piece-wise con-stant function of its total weight. They show that a payoff division in the core of a threshold task game can be found in pseudopolynomial time (i.e. in time polynomial in the number of agents and in the largest agent weight), if one assumes that when a set of agents deviates, no other agent will want to work with agents in this set—a reaction termed conservative, which closely approximates the setting of TU games (as explained by Zick et al. [3]). In contrast, if non-deviators agree to work with the members of the deviating set in coalitions that are unharmed by the deviation (a reaction termed refined), the same problem becomes NP-hard.It follows that, when assessing the computational complexity of finding stable outcomes in OCF games, one needs to consider not only structural properties of the characteristic function (i.e. the way agents generate profits), but also the way agents react to deviations. In our work, we study the influence of these two aspects of OCF games on the complexity of answering stability-related questions in OCF games.1.1. Our contributionThe computational complexity of any given problem depends on how the input is represented. For instance, a general TU game with n agents is represented by 2n real values: we need one number for each subset (coalition) of players. Thus, no algorithm that needs to know the value of each coalition can run in time that is polynomial in the number of agents. This issue is even more prominent for games with overlapping coalitions: to describe an OCF game, we need to specify a number for every partial coalition, i.e., agreement of the form ‘agent 1 contributes an x1 fraction of her resources, . . . , agent n contributes an xn fraction of her resources’, for every possible combination of (real) values x1, . . . , xn ∈ [0, 1]. Thus, a general OCF game cannot be described by a finite list of numbers, and hence one cannot meaningfully reason about the complexity of general OCF games. To mitigate this issue, we explore two different strategies:1. We introduce and study discrete OCF games, which place restrictions on how finely an agent can split her resources (Sections 3 to 6). In these games, each agent i is associated with an integer weight W i ∈ N and can only allocate an integer weight between 0 and W i to each task. By definition, a discrete OCF game can be represented as a finite list of numbers, and thus discrete OCF games are amenable to traditional complexity-theoretic analysis.2. We identify a large class of (standard, i.e., non-discrete) OCF games that can be succinctly represented (Section 7). Specifically, we study a rich and expressive class of games t",
            {
                "entities": [
                    [
                        134,
                        215,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 78 (1995) 397-430 Artificial Intelligence Control of perceptual attention in robot driving Douglas A. Reeceaq*, Steve A. Shaferb “Institute for Simulation and Training, University of Central Florida, 3280 Progress Drive, Orlando, FL 328260.544, USA ‘Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA Received March 1993; revised July 1994 Abstract difficult and computationally to solving fields of view, and relatively Computer vision research aimed at performing general scene understanding vision this problem. Active vision systems use optimized to be conceptually approach reduced information motivates research how active vision could be used for a realistic task in a dynamic domain. We are studying such a task: driving an autonomous vehicle in traffic. has proven is a promising sensor settings, to efficiently extract specific simple algorithms is only appropriate in the context of a task that to extract. While there has been a fair amount of from a scene. This approach the selection of the information that describes the extraction processes, there has been little work complex. Active investigates that process introduce that use a method the required and estimate for controlling visual attention three programs the efficiency gained this paper we present for driving, and analyze sensing with a general driving-scene understanding In reasoning describe a model of driving and the driving environment, performing then techniques routines, which use known second program, Ulysses-2, creates an inference data on action choices, and searches Ulysses-3 uses domain knowledge change over time; objects that do not move enough selected as perceptual to measure techniques orders of magnitude when compared as part of the in doing so. We first the complexity of system. We control increasingly to select perceptual actions. The first program, called Ulysses-l, uses perceptual the search for new objects. The to guide input to sense. Finally, to reason about how dynamic objects will move or to affect the robot’s decisions are not in simulation that the cost of perception by 9 to 12 the cost savings realized by using selective perception. We estimate included targets. For each technique we have run experiments the computational to a general perception tree to infer the effect of uncertain this tree to decide which data in Ulysses-3 reduce reference objects sophisticated perceptual system. * Corresponding author. E-mail: dreece@ist.ucf.edu. 0004-3702/95/$09.50 SSDZ 0004-3702(95)00029-l @ 1995 Elsevier Science B.V. All rights reserved \f3% D.A. Keew. S.A. Shafer ’ Artificial lntelligencr 78 (1995) 397-430 1. Introduction I. 1. The need to control perceptuul attentiorl the real world. Computer robot of arbitrary Early mobile research These problems were expressed away from view of a robot by developing descriptions difficult cost. More robots with the information characterize not completely ters, the scene. information to accomplish, Such vision is needed. concentrated in symbolic vision general systems a robot on making solve problems. form, having already been abstracted research to match has attempted that can build complete this symbolic to be extremely scenes. This vision task has proven and when it is possible it is often at great computational recently, activr vision has been seen as a more feasible way to provide they need the entire to solve problems. Active vision systems do scene, but instead optimize sensor parame- field of view. and algorithms systems depend to extract specific information from on an external task to determine the what that active perception in a dynamic is essential for a mobile environment. In addition for such a robot must the to perform task. Thus perception select perceptual actions and action parts of the same control program control called Ulysses, drives a simulated integrates that function. in an environment that is dynamic robot performing actions, information should to choosing to get selection a a be research we have selec- and action that and visually complex. Driving In our perception robot in traffic-a task is encoded set of perceptual its choice of actions, currently Ulysses we developed in such a way that Ulysses can reason how actions. Ulysses considers requests appropriate sensory operates called PHAROS; in a world provided PHAROS simulates and carries out the maneuvers. PHAROS also controls it to select an could about traffic objects data, and commands by a detailed traffic the perceptual the other vehicles We believe task complex controller needed indistinguishable developed a robot tion. The program, is fairly complex, knowledge efficient affect maneuvers. simulator actions in the environment. a example. through an arbitrary shape, reflections, are illustrated following in Fig. 1. It shows a robot driving locations and poses. To recognize the by of this paper scene shown in various central themes vehicles the driving a perception The Consider scene containing vehicle, color. and illumination, surfaces, transparent the directions image of the scene. A perception scene would have the identify of these robot driver Fortunately, occlusions, and all other factors to do in a dynamic it is not necessary completely. robot, scene from system would have to consider variations in vehicle as well as anomalies due to surface markings, etc. The vehicles so appear system in different attempting are different locations distances the in to find all vehicles and robot’s in the to search all possible the perception locations, system would traffic objects, with similar variations. together make such exhaustive perception Even humans situation. ranges, for a robot driver and poses. To interpret to locate also have The combinatorics and of all for a far too expensive cannot to update do this. its world mode1 a throughout completely. Although traffic objects may be found in many locations \fD.A. Reece, S.A. Shafer / Artificial Intelligence 78 (1995) 397-430 399 Fig. 1. A driving scene. it is wasteful to look for all of them because they are not all important scene, the robot. As the robot considers etc. appropriate areas. Fig. 2 illustrates that affect its choice of actions, the various physical limitations, it can look for relevant this limited visual search. to traffic rules, in the objects 1.2. Driving and sensing with Ulysses The Ulysses driving program to understand many complex represents driving knowledge well enough allow Ulysses actions. Driving knowledge also allows Ulysses to reason about perception select perceptual perception. programs: Ulysses-l, to traffic situations and select safe and for controlling three in actions. We present specific methods These methods incrementally implemented have been -2 and -3. three (1) The Ulysses driving model encodes driving rules as a set of constraints and limit the robot’s choice of actions to safe maneuv- to to choose among safe maneuvers allow Ulysses some objective. The constraints and preferences are represented preferences. Constraints ers. The preferences further explicitly as an inference tree with sense inputs on the bottom and an Fig. 2. Selective visual search, \f400 D.A. Kerce, S.A. Shafer Artijiclal fnrelligence 78 (19%) 397-430 (2) Ulysses-l input values propagate action output at the top. The tree acts as a constraint network which uncertain through to yield ranges of possible actions. looks only in the appropriate parts of the scene for traffic objects perceptual instead of looking everywhere. Ulysses-l uses task-dependent operators called perceptual routines to narrow its search area. The routines make use of the fact that the meaning of traffic objects depends on their spatial relations the closest car ahead in this lane). The routines search for objects only near specific reference objects. to other objects (e.g., it looks situation the current to determine the most critical traffic environment to constrain where it does not consider (3) Ulysses-2 constrains search areas and also tries to find the minimum set of the correct action. Although Ulysses-l uses for to determine which tree to objects necessary knowledge of the objects, objects are really important. Ulysses-2 reasons using the inference determine routine tree repeated until there perceptual to get the required data. The new information propagates up the is is no uncertainty about what action should be taken. (4) Ulysses-3 uses the same mechanism used in Ulysses-2 but also maintains a and Ulysses- persistent world model. Facts in the model are time-stamped, to reason about how object characteristics 3 uses domain knowledge reasoning process automatically change over determines when changing objects must be sensed again to reduce uncer- tainty. to constrain possible actions. This selection and sensing process input, and calls the appropriate time. The inference tree In this paper we first present an estimate of the complexity of perception for driving to demonstrate why it is necessary for a driving robot to actively focus its the encoding of the driving task and the perceptual this three perceptual reasoning traffic situations and measuring attention. We then describe techniques experimentally the simulated cost of its perceptual actions. used by running Ulysses in Ulysses. The is estimated impact of in various reasoning 1.3. Related work 1.3.1. Active vision that Ulysses performs The attention control is one aspect of active computer vision. Active vision comprises at least two levels of attention control, however. At a high level, active vision involves deciding which parts of the scene are most for the robot to be looking at given its task. This is the level that this important to look from a given viewpoint, paper addresses. Our system considers where than where to move a viewpoint. At a lower level, active vision concerns rather gaze stabilization, pointing control for object tracking, verging stereo, camera- fo",
            {
                "entities": [
                    [
                        75,
                        123,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 75 (1995) 3-29 Artificial Intelligence Qualitative analysis of behavior of systems of piecewise linear differential equations with two state variables Toyoaki Nishida av*, Shuji Doshita b ’ Graduate School of Information Science, Nara Institute of Science and Technology, 8916-S Takayamu, Ikom, Nara, 630-01 Japan ’ Department of Information Science, Kyoto University, Sakyo-ku, Kyoto, 606-01 Japan Abstract The set of all solution curves in the phase space for a system of ordinary differential equations (ODES) is called the phase portrait. A phase portrait provides global qualitative information about how a given system of ODES behaves under different initial conditions. We are developing a method called Topological Flow Analysis for automating analysis of the topological (VA) structure of the phase portrait of systems of ODES. In this paper, we describe the first version of TFA for systems of piecewise linear ODES with two state variables. TFA has several novel features that have not been achieved before. Firstly, TFA enables to grasp characteristics of all behaviors of a given system of ODES. Secondly, TFA represent behaviors in terms of critical geometric features in the phase allows to symbolically space. Finally, TFA integrates qualitative and quantitative analysis. The current version of TFA has been implemented as a program called PSX2PWL using Common Lisp. 1. Introduction Analysis of dynamical systems is essential to model-based reasoning as a means of from structure. One of the major concerns of qualitative dynamical reasoning systems. Unfortunately, deriving behavior has been deriving qualitative behavior of continuous most conventional scription of ambiguities. language of complex behavior and completeness qualitative reasoning techniques proposed so far lack an adequate de- of prediction due to explosion * Corresponding author. When this article was originally written, this author was with the Department of Information Science, Kyoto University. 0004-3702/95/!$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00062-X \f4 71 Nishidu, S. Doshitu/Arlific.rcrI Intelligence 7.5 (1995) 3-29 To address these problems, we are developing for analyzing the topological equations (ODES). TFA is based on dynamical a sophisticated mathematical theory about qualitative a method called Topological Flow structure of the phase portrait of systems theory systems analysis of dynamical (TFA) Analysis of ordinary differential (DST), systems. In this paper, we present the first version of TFA for systems of piecewise linear ODES (PWL-ODES) with two state variables. TFA has several novel features. Firstly, TFA enables to grasp characteristics of behaviors of a given system of PWL-ODES under all possible all possible symbolically The use of symbolic the behavior, but it also helps to navigate qualitative process. Quantitative to in a phase space. does not only make sense as an explicit description of the analysis process. Finally, TFA integrates the overall analysis initial conditions. TFA does this not by directly computing or approximating solutions, but by reasoning represent behaviors at the abstract in terms of critical geometric level. Secondly, TFA allows analysis helps qualitative analysis. Qualitative analysis guides and quantitative representation features analysis resolve ambiguity. using Common Lisp, is called PSX2PWL. ’ The current version of TFA, implemented 2. Dynamical systems theory (DST theory of dynamical TFA is based on Dynamical Systems Theory qualitative the geometric and topological space. This enables, information given system of ODES, even when a precise form of the solution section, we introduce basic notions of DST. system of ODES: [ 2,3]. DST, called a for short) systems, provides a powerful method of reasoning about features of solution curves of systems of ODES in a phase of the behavior of a In this is not known. to derive qualitative the following for example, Consider $ = f(x) (1) where x is a vector of state variables in Iw as a function of t E IR. An n-dimensional variables {xi} is called space, Eq. ( 1) specifies (XI,. the phase space. For each point c = (cl,. the rate and the orientation of state change: each of which gives some value space spanned by the set of all state in the phase , c,,) . . ,x,) to initial state a = (al, In other words, Eq. ( 1) defines a vector field corresponding the point corresponding by the vector field at each point or an orbit. The collection of all orbits in a phase space is called the phase portrait. in the phase space. A specific solution is a trajectory such that it passes through to the vectors specified is called a solution curve, , u,) to a in the phase space and it is tangent (Fig. 1). Such a trajectory ’ Originally. more complex systems of ODES, as described it was called PSX (Phase Space explorer). Now, we have several other versions of PSXs for in the postscript of this paper. \fT. Nishida, S. Doshita/Arti$cial Intelligence 75 (1995) 3-29 5 (a) the vector field (b) solution curves Fig. 1. Geometric meaning of system of ODES. Theoretically, we can think of an orbit passing on x E U c IRn as a mapping ~,(t):W-tVwhichmapsxtoy~V~IW”asafunctionoft~R.Wecanalso think of ( 1) as specifying a “flow” @(x. r) = & (t) : U x lR -+ V. If uniqueness of solution holds for a given system of ODEs, orbits never intersect with others nor with themselves (the non-intersection construinf) . There is an obvious correspondence between the geometric properties of orbits and the aspects of dynamical behavior. For example, points in a phase space at which the right-hand side of Eq. ( 1) is zero are called JIxed points, and they correspond to equilibrium states which will not evolve for ever. Fixed points are further classified into sinks, sources and saddle nodes. Orbits near a sink and a source arbitrarily approach the sink as t 4 00 and -00, respectively, while both kinds of orbits exist around a saddle node. Closed orbits correspond to periodic behaviors. DST is particularly concerned with analyzing topological structure of asymptotic behaviors of dynamical systems as t -+ foe. In DST, it is proved that orbits in a two- dimensional planar phase space either ( 1) diverge for place at infinity, (2) approach a fixed point, or (3) approach a closed orbit (called a limit cycle), as t + foe. Roughly, orbits to which nearby orbits approach as t + 00 and -co are called artructors and respectively. Attractors and repellors play an important role in qualitative repellers, analysis of phase portrait. A set of points which an orbit passing a point x in a phase space approaches as t -+ oo is called the w-limit set of x. The a-limit set of x is defined similarly, by replacing co by --oo. Although an w-limit set becomes empty if the orbit diverges for a place at infinity as t + CO, we regard a place at infinity as a special kind of places and allow an w-limit set to contain a place at infinity. An w-limit set extended in this way is called \f6 71 Nishidu. S. Doshita/Artijiciul Intelligence 75 (1995) 3-29 Fig. 2. Contracting recursive bundle of orbit intervals a generalized a generalized sink, or a g-sink source (or a g-source for short). for short. A similar extension to an a-limit set is called Unfortunately, it is not straightforward the phase space of systems of ODES based on DST. For example, DST does not provide us with a procedure Hence, we need to develop a computational continuous in a phase space, though theory of representing it gives a definition. about and reasoning for finding an attractor that can explore to implement a program flow. 3. Reasoning about phase portraits TFA is a computational theory of DST. TFA is based on several novel ideas. 2 3.1. Reasoning about bundle of orbits We focus on bundles of orbits rather than single orbits, to derive useful conclusions to regions for example, we have found I and J on the same hypersurface which cannot be made about single orbits. Suppose, a given phase portrait a pattern as shown transverse is called a contracting are also transverse is two-dimensional, boundary, Fig. 3. All orbits f ---t co. in in Fig. 2, in which a bundle of orbits 4 is I. This pattern to I transverse to J, and never leave the region occupied by 4. If the phase space I and J do not share a in I - J approach one of those limit cycles as region J is finitely bounded, then C$ contains one or more attracting and region limit cycle {a~,. . . ,Q} such that J c intervals. All orbits recursive bundle of orbit to the region transverse as shown 2 In the description below, we attempt to generalize these ideas to n-dimensional phase spaces as much as possible, because most of them are independent of the dimensionality of the phase space. \fZ Nishida, S. Doshita/Artifcial Intelligence 75 (1995) 3-29 7 (a) pattern (b) interpretation Fig. 3. Circumstance in which existence of an attracting limit cycle is predicted. Formally, a bundle of orbit intervals is defined as a set of intervals of orbits 4 such that (1) (2) is involved no fixed point for any point p in the internal s which is transverse and (a) all intervals of orbits in the region occupied by 4; 3 region occupied by qS, there exists a hypersurface to the region occupied by 4 at region a that contains p that belong to r$ are transverse to s once and only (b) once. for any point q in a, there exists an interval of an orbit involved is transverse in 4 which to s at q. s in the above definition The hypersurface conditions requests ( 1) and (2a) require the density and continuity the uniformity of orbit intervals is called a cross section of 4. Intuitively, in 4, and (2b) involved of orbit intervals in 4, as shown in Fig. 4. 3.2. Representing a bundle of orbits as $0~ mappings between hyperplanes (n - 1 )-dimensional hyperplanes, phase space to “sample” data about bundles of orbit called sampling hyperplunes, in intervals. We locally defined each bundle of orbits as a sequence of",
            {
                "entities": [
                    [
                        63,
                        174,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 104 ( 19YX) 2 I I-764 Artificial Intelligence Generating multiple new designs from a sketch Thomas F. Stahovich a-‘,*, Randall Davis b, Howard Shrobe b Received 13 August 1997; received in revised form 2 I May I YY8 Abstract that a single transforms a program We describe called SKETCHIT device a into multiple families of new designs. It represents each of these families with a “BEP-Model”. the desired behavior. parametric model augmented with constraints The program that captures mechanical behavior while abstracting away its implementation. The program employs a then uses a paradigm of abstraction and resynthesis: library of primitive mechanical Elsevier Science B.V. All rights reserved. that ensure the device produces space (qc-space). is based on qualitative configuration a novel representation to map from qc-space to new implementations. C 1YYX sketch of a mechanical the initial sketch into qc-space, interactions it abstracts &ww&; Sketch understanding; Design generalization: Mechanical design: Qualitative geometric reasoning 1. Introduction SKETCHIT is a computer program capable of taking a single sketch of a mechanical device and generalizing stylized sketch of the design and a description of the desired behavior; from this it generates multiple it to produce multiple new designs. The program’s families of new designs. input is a The program does this by first transforming the sketch into a representation the behavior of the original design while abstracting away its specific implementation. program representation to multiple new families of implementations. then uses a library of primitive mechanical interactions that captures The to map from this abstract This representation, which * Corresponding ’ Support author. Email: stahov@andrew.cmu.edu. for this project was provided by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract NO00 14-9 I-J-4038. 0004.3702/98/$ PII: SOOO4-3702(98)00058-7 - see front matter 0 1998 Elsevier Science B.V. All rights reserved \f712 FIN. I. A pencil sketch of a circuit breaker. we call qualitative configuration tasks. space, is the key tool allowing SKETCHIT to perform its that ensure the geometry produces the desired behavior. ’ Our program The program represents each of the new families of implementations with what we call a a parametric model augmented with thus behavior ensuring parametric model (“BEP-Model”): constraints takes as input a single sketch of a device and produces as output multiple BEP-Models, each of which will produce the desired behavior. As we illustrate below. SKETCHIT’S ability to generalize a single sketch into multiple for a variety of reasons. During conceptual design, a large number of alternatives. families of new designs for example, a high premium SKETCHIT aids in this case by automatically generating a large variety of designs. Later in the design process SKETCHIT can assist the designer in adapting an initial design to meet other design requirements such as those on size or performance. is placed on examining is useful The next section uses the design of a circuit breaker to illustrate from the program. Later, Section 9 uses the design of a dwell mechanism device) meet specific performance to illustrate how the program assists the designer requirements. the input to and output (yoke and rotor to in refining an initial design in action designing the desired behavior. We conclude In this section we show SKETCHIT a circuit breaker. We begin input: a stylized sketch of the device and a state transition diagram with the program this section with three of the new designs that describing SKETCHIT produces when it finally maps the circuit breaker’s qc-space back to geometry. for a circuit breaker. In normal use, flows from the lever to the hook; current overload causes the bimetallic hook to the current flow. After the hook cools. Fig. 1 shows a pencil sketch of one implementation current heat and bend, releasing pressing and releasing the lever and interrupting the pushrod resets the device. 2 A parametric model i\\ a geometric model in which the shapes are controlled by a set of parameters. \fFig. 2. Stripping away the non-functional part\\ of Fig. I. ! actuator _-____d pushrod (fixed surface) lever ” '16 ’ f2h f3 f4 p t 4 hook: bimetallic strip Fig. 3. Stylized sketch of the circuit breaker as actually input to program. Engagement faces are bold lines. The actuator applied to the pushrod represents the reset motion imparted by the user. For our convenience we use labels to refer to engagement pairs: (fl f6) = push-pair. (f2 f5) = can-follower. (f3 f3) = lever-stop. tf7 fX) = puahrod+top. SKETCHIT is concerned with only the functional parts of the sketch: springs, actuators, kinematic joints, and the faces where parts meet and through which force and motion are transmitted. Fig. 2 shows what is left when we peel away all but the functional parts of the in the stylized sketch that pencil sketch. This is the sort of information SKETCHIT takes as input. that is contained Our software currently provides a mouse driven sketching sketches.’ Fig. 3 shows the stylized version of the circuit breaker interface for creating stylized that the designer 3 Eventually we will develop a pen based sketching to sketch directly on a digitizmg pad with a stylus. The designer will draw the usual sort of sketch (i.e.. like the one in Fig. 1) and then annotate it with the stylus to indicate the functional part\\. the designer allowing interfxe \f214 ZE Stuhmkh et ul. /ArtiJicid Intelligence 104 (1998) 21 i-264 lever-stop pushrod-stop hook=cold Hook Heats push-pair pushrod-stop 1 2 hook=hot Reset 3 Hook Cools push-pair pushrod-stop hook=cold ii Fig. 4. The desired behavior of the circuit breaker. (a) Physical of the three states. the hook is either at its hot or cold neutral position. interpretation. (b) State transition diagram. In each creates with this interface. ’ Line segments are used for part faces; focuses on just the part-faces springs, joints, and actuators. SKETCHIT consideration of the connective geometry (the surfaces that connect make complete solids) is put off until later in the design process. The designer annotates the stylized sketch to indicate which pairs of faces are intended to engage each other (the annotations icons are used for that are functional; are listed in the table contained in the figure). the functional faces to The designer describes the desired behavior of a device transition diagram. Each node in the diagram that are relaxed. s The arcs are the external and the springs Fig. 4(b), for instance, describes how the circuit breaker should behave heating and cooling using a state to SKETCHIT is a list of the pairs of faces that are engaged that drive the device. in the face of the hook and pressing the reset pushrod. inputs that SKETCHIT Fig. 5 shows a portion of one of the BEP-models derives from the sketch of the circuit breaker and the desired behavior. The top of the figure shows the parameters that define the sloped face on the lever (f2) and the sloped face on the hook (f5). The bottom shows the constraints the overall desired behavior: the hook down until the lever the hook springs back to its rest position. As moves past the point of the hook, whereupon one example of how the constraints enforce the desired behavior, this pair of faces plays its role in achieving the lever clockwise pushes the ninth equation, i.e., moving that ensure 0 > R14/TAN(PSI17) + H2_12/SIN(PSIl7). constrains This in turn ensures always increases the deflection of the hook. the geometry so that the contact point on face f2 never moves tangent to face f5. rotation of the lever that when the two faces are engaged, clockwise The parameter values shown in the top of Fig. 5 are solutions of the desired behavior. The values the BEP-Model, hence this particular geometry provides were computed by a program called DesignView, a commercial parametric modeler based equation on variational geometry. to interactively solver which is also capable of drawing lines and arcs.) Using DesignView (For our purposes, DesignView is simply a non-linear to the constraints 1 In the remainder of this document, we use the term sketch to refer to the kind of stylized sketch shown in Fig. 3. 5 The pairs of faces not listed at a node are by default disengaged, the springs not listed are by default not relaxed. \fI L15 0.142 PSI17 134.702 Hi-11 > 0 HZ-12 > 0 S13 > Hl_11 L15 > 0 PHI16 > 90 PHI16 < 180 PSI17 > 90 PSI17 < 180 0 > R14/TAN(PSI17) + H2_12/SIN(PSI17) R14 = SQRT(S13-2 + L15-2 - 2*S13*L15*COS(PHI16)) Fig. 5. Output from the program parameter parameters and constraints IS the current value of that parameter. Bottom: for faces f2 and f5 are shown (a BEP-Model). Top: the parametric geometry; the decimal number next to each the constraints on the parameters. For clarity, only the 0 I f6 fl \\ n fa // f3\\” I \\f5 f4 Fig. 6. Another solution to the BEP-Model of Fig. 5. Shading to flesh out the components. This solution shows that neither the pair of faces at the end of the lever (f2 and f.3) nor the pair of faces at the end of the hook (f4 and f5) need be contiguous. indicates how the faces might be connected adjust parameter values we can easily explore the family of designs defined by the BEP- these Model. Fig. 6. for example, the parameter values satisfy the BEP-Model, desired behavior. As this example the family of designs defined by a BEP- Model includes a wide range of design solutions, many of which would not be obtained with conventional even this rather unusual geometry provides to this BEP-Model. Because shows another solution approaches. illustrates, \f216 TF: Stahovich rt al. /Artificial Intelligence IO4 (1998) 211-264 Ah.waction QC-Spaces BEP-models BEP-11 BEP-12 BEP-21 BEP-22 BEP-31 BEP-32 ? \\ Implementa’ns IMP-111 IMP-112 1 1 a IMP-311 IMP-312 IMP-313 .decr: cm~traint tolution (SKETCH) Fig. 7. Overview of",
            {
                "entities": [
                    [
                        70,
                        115,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 107 (1999) 99-124 Artificial Intelligence Fast Bayes and the dynamic junction forest J.Q. Smith a,*, K.N. Papamichail b,l a Department of Statistics, University of Warwick, Coventry, CV4 7AL, UK b School of Informatics, University of Manchester; Manchestel; Ml3 9PL, UK Received 10 Aprit 1997; received in revised form 11 June 1998 Abstract It has been shown propagating probabilities conditional independence examples how processes whose conditional augmented that junction tree algorithms can provide a quick and efficient method for in complex multivariate problems when they can be described by a fixed In this paper we formalise and illustrate with two practical to high dimensional can be applied structure, as well as their underlying distributions, independence propagation algorithms structure. are these probabilistic through the passage of time. 0 1999 Elsevier Science B.V. All rights reserved. Keywords: Dynamic models; Hellinger metric; Influence diagrams; Multivariate state space models Junction trees; Probabilistic expert systems; 1. Introduction that Bayesian in the problem it has been established Over the last ten years relationships between variables are often represented by influence diagrams or causal networks-see expert systems can be made to work quickly and accurately on a wide range of practical problems provided fixed. These that the underlying relationships [2,8,12, 26,3 l] and later in this paper. However, there are many problems where such relationships coded in the graph may be eroded independencies evolve; for example, as information between variables in any learning environment we believe may change through learning at some point that such an evolution of structure an ignored-for needs different exception see Kjaerulff [ 111. Learning this issue. However, until now this has been the structure of dependencies the passage of time. Indeed is gathered. Alternatively, in a dynamic environment is almost inevitable-so is fundamentally the conditional to address remained machine largely * Corresponding ’ Email: nadia.papamich@man.ak.uk. author. Email: j.g.smith@wanvick.ac.uk. OOW3702I99/$ PII: SOOO4-3702(98)00103-9 - see front matter 0 1999 Elsevier Science B.V. All rights reserved. \fIO0 J.Q. Smith, K. N. Pupumdwil /Artifktrl Intrlli~mw IO7 (IYYY) 99-124 to enable that company that are static in a number of key ways as it can be illustrated from relationships through the following example. Suppose a company produces a number of different brands of products within a large market and knows all her competitors’ brands. There are now marketing to produce a causal network over the vectors techniques available [ 19,201. This causal network codes up of sales made within a given short time interval the sales of different brands at that time and after being the dependency structure between transformed the probability distributions of sales of one product given precise information about collections of others. in a static environment where the causal These quick algorithms are now well understood network remains unchanged over time-for are outlined tree 191 it can be used to update efficiently a helpful introduction in the next section. see Jensen [9]-and into a junction the variables into sales information can induce other dependencies two problems. Firstly. the algorithms in the network. For example, a company will often have much the company’s database will not in the causal network. Instead it will However, in a dynamic environment we encounter of Jensen cannot usually be employed directly because be complete enough to observe directly typically have incomplete noisy data which is not fully disaggregated on the individual brands better information these types of imperfection example of this is when we acquire perfect two brands whose sales S( 1) and S(2) are not dependent, being the market. Having observed S, knowing S(1) tells us precisely the aggregate S induces a dependence possibly also its junction information. Another type of dependence, course a different causal network and its associated junction all possible aggregates, but a dynamic environment processing. It should always be possible even if it is not in the pre-processed the inferential necessary. about its own product sales than those of its competitors. Unfortunately, in the system. The simplest about the sum S of the sales of in different sections of the value of S(2). So between S(1) and S(2). The causal network and in the light of this piece of in [3 11. Of tree might be drawn to include to such pre- as it becomes available to adjust it becomes to absorb new information format. from the influence diagram as and when tree will therefore need to be adjusted induced by missing data, is discussed It is therefore highly desirable is not really conducive framework derived information A second problem generic that components to dynamic environments and the underlying dependence In the application often possible change. competing brand. Alternatively reposition a brand so that it has a different set of competitors. diagram which represents she may choose the dependency for example, above, a competitor may to reprise or re-advertise structure will periodically introduce a new and therefore In this case, the influence like the one above is that it is structure will need to change. In Section 4 of this paper we will formalise of a sequence of graphs called junction experiences in developing forecasting of product sales in a competitive market [2 1,221 and the other the forecasting of the spread of contamination [4,6,29]. The second application after a nuclear accident has been coded up as an operational dynamic junction the description of a dynamic system in terms is based on the authors’ the first, the forests. This formalism fields of application: in two different forest [4]. algorithms In Section 5 we specify an algorithm for automatically adjusting both the graph on which calculations are made and also the objects (the cliques) which form the nodes of that graph. to work when each observation This allows a propagation algorithm+riginally designed \fJ.Q. Smith, K.N. Papamichail /ArtQicial intelligence 107 (1999) 99-124 101 relates only to states in a single clique of the original be valid generally. Such adjustments often reduce the subsequent efficiency of the system because the new junction forest usually has a smaller number of cliques of a larger size. forest-to In Section 6 we introduce several transformations of a junction forest that automatically so that it is a more compact in each of the joint probability distribution changes the representation and efficient form. The method modifies not only the number of states contained clique but also the relationships between discarding techniques a transformation its approximation. This section concludes with an illustration described variables no longer of interest. can also be incorporated within such a system giving an example of such used in conjunction with the Hellinger metric between a density and using the nuclear example them and the existence of the cliques themselves, In Section 7 we outline how approximate in Section 3. We begin the paper with a short review of state space representations of problems and the junction tree propagation algorithm [9,10]. 2. From dynamic influence diagrams to junction graphs For simplicity and only with a slight loss of generality, we shall assume that our dynamic time state space models equation and a system time. One standard class of discrete in terms of an observation [7,34]) is specified in discrete system is defined (see, for example, equation respectively: Y, = Ft0, + ut, 8, = G&e1 + cot. An illustration of the above model is given in Fig. 1. The error distribution of {z/tot: so that an observation Yt at time t = 1,2, . . .} is nearly always chosen t satisfies the conditional independent statement: qJ,,ez 1... I&, (2.1) (2.2) to be mutually independence (2.3) i.e., an observation of the state vector at that time, and at time t only gives direct information about the values of components &+I 1 t&+2, . . . LI f4,...&1 let, (2.4) i.e., states are Markov in time-we vector and then we can determine any probability the future. only need to retain our beliefs about the current state statements we might wish to make about The random vectors ot = 1,2, . . . are called state random vectors. In dynamic systems the state vector is an important object because if we were given its value we could disregard Fig. 1. A discrete time state space model. \f102 J.Q. Smith, K.N. Pupamichail /Artificial Intelligence 107 (1999) 99-124 as irrelevant for predicting future observations Y. In this sense the all other information In our simple information we need for forecasting. state vector contains all the relevant marketing example, the state random vectors will be the vectors of sales of each brand at time t, which typically will not be known precisely by the company. The matrix G specifies in time. The simplest evolution would make G how these sales are expected the identity matrix, which would stipulate t were expected to be the same as they were in the time period t - 1. The error vector Wt, captures the likely random drift in this relationship. Each vector Y,, t = 1,2, . . , is the set t where we can read from the rows of of possibly component of Y, the matrix F the aggregate of brands associated with each observational There will usually be some measurement and the vector ut just represents error associated with these observations incomplete data received that sales of each brand in the time period in the interval to develop this. A useful way of coding conditional (XI. . . , x,) is by a causal independence network (graph of an influence diagram) as a set of random vectors [9]. Given a collection of conditional statements of the form: independence statements (2.5) ~ Xk- I } whose union (n-1, X2, i.e., a directed acyclic graph whose nodes are XI, wh",
            {
                "entities": [
                    [
                        66,
                        108,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 82 ( 1996) 75-127 Artificial Intelligence ALX, an action logic for agents with bounded rationality Zhisheng Huang ‘, Michael Masuch 2, L&z16 Pblos Center for Computer Science in Organization and Management (CCSOM), University of Amsterdam, Sarphatistraat 143, 1018 GD Amsterdam, Netherlands Received June 1993; revised November 1994 Abstract We propose a modal action logic that combines ideas from H.A. Simon’s bounded rationality, is sound, complete and decidable, making it the first complete S. Kripke’s possible world semantics, G.H. von Wright’s preference Stalnaker’s minimal change and more recent approaches to update semantics. ALX logic) operators. ALX avoids important drawbacks of other action logics, especially necessitation closure of goals under logical logic, (the xth action logic for two-place preference the counterintuitive theorem must be a goal) and the equally counterintuitive logic, Pratt’s dynamic rule for goals implication. (every 1. Introduction use by intelligent [ 6,14, [ 24,471, or as a contribution robots is motivated by a different concern. We want for theories of logic. We leads to a new approach theories, especially to action language a formal The difference for (hypothetical) [64]. Our effort for social science logics are usually developed language of program behavior as a description logic Action 40,59,71], to philosophical to develop organizations. combine rationality, G.H. Wright’s approach in combination with binary modal operators, Pratt’s dynamic minimal change, and more recent 251. Although problems of action In particular, ALX avoids fairly simple in motivation logic. ideas from belief revision and update semantics in its construction, ALX is good at handling the counterintuitive logic, Stalnaker’s notion of [ 15, some crucial necessitation ideas from various strands of thought, notably H.A. Simon’s notion of bounded to preferences, Kripke’s possible world semantics ’ E-mail: huang@ccsom.uva.nl. * Corresponding author. Fax: (31-20) 5252800. E-mail: michael@ccsom.uva.nl. 0004.3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSDlOOO4-3702(94)00090-5 \f76 Z. Huang et al. /Art@cial Intelligence 82 (I 996) 75-127 rule for goals (every of goals under model property. logical theorem must be a goal) and the equally counterintuitive and enjoys is complete, decidable implication. ALX closure the finite 2. The framework for ALX Most social science theories are expressed to check language for “softness’‘-a that would allow one natural scaffold to disambiguate acquired a reputation are somewhat dubious. Reformulating would make consistency way for other tasks, such as the examination Understanding the deductive automating AI into theory building We focus on action [45]. logic as a formal the generation of theories in natural their consistency statements. As a consequence, soft way of saying in a rigorous language. They lack a formal fashion, or theories have that their logical properties language with known properties the easier. Also, it would pave these them in a formal of a theory’s deductive closure properties. checking or disambiguation closure properties of a set of formulas from a given set of assumptions is essential and introducing to agents are key to the understanding language, of social phenomena. because actions of individual theories of social relations must be action or In fact, most social [ 1,12, theories hard to grasp in to develop taking First-Order Logic off the shelf. We call the new logic [ 111. This drives our attempt Yet actions engender change and change context of first order languages is notoriously than collective scientists agree that adequate 16,39,52,61]. the extensional a new logic, ALX (the xth action logic). rather Possible Outcomes Behavior Alternatives Perceived Behavior Alternatives Fig. I. Simon’s bounded mtionality \fZ. Huang et al./Art$cial Intelligence 82 (1996) 75-127 17 to overcome the omniscience of rational action. He assumed of bounded rationality is intuitively Herbert A. Simon’s conceptualization (see Fig. 1). His approach [65] serves as a point appealing and had great impact on claims of the (1) an agent, with (2) a (3) a set of future states of affairs (each such state being and (4) a preference order of departure the postwar social sciences. Simon wanted traditional conceptualizations set of behavior alternatives, the outcome of a choice among over future states of affairs. The omniscient would know all behavior the and agent would also have a complete preference order for those outcomes. An agent with bounded in contrast, would not know all the alternatives, would not know the exact outcome of each, and would not have a complete preference order for those outcomes. the exact outcome of each alternative; agent, endowed with “perfect the behavior alternatives), rationality”, alternatives rationality, Kripke’s possible world semantics provides a natural setting for Simon’s conceptual- ization. We assume a set of possible worlds with various relations defined over this set (we may also call those possible worlds states). One can see a behavior alternative as an accessibility a mapping from states to states, so each behavior alternative constitutes for action, relation. An accessibility from a given state to another i.e., as an opportunity relations are expressed by one-place modal operators, as in dynamic state. Accessibility logic (a)4 would express the fact that the agent has an action a at his disposal such that effecting a in the present situation would result in the situation denoted by proposition in turn, can be interpreted as an opportunity relation, for changing the world by moving [ 241. For example, the formula c$. The perfectly rational agent would have a complete description relations and a complete preference of his actual state, order informed. They may have are less well of all accessibility a complete knowledge over states. Agents with bounded description an incomplete incomplete knowledge of the accessibility over situations. actions concept of goal in ALX’s object language. In particular, one can assume is finite. As it turns out, this assumption rationality of their actual state (we call those descriptions situations), relations, and an incomplete preference order that their knowledge and the range of their is crucial for defining a straightforward Situations are represented as sets of states and expressed by propositions. Propositions, about a situation, the more detailed the set of states where description limit case, a complete description, would uniquely in turn, denote knowledge situation would be. The one state. Less specific descriptions would those states where the description would hold (but remaining uncommitted “aspects” not covered by the description). incomplete l201.3 they obtain. So, the more specific an agent’s of that identify the set of about other This is the standard approach lack that uniqueness, the propositional in denotational to representing and epistemic information, identifying semantics [62,63] logic used ’ Framing bounded rationality can see that omniscience-the in an absolute not available. Any formal but those assumption, another. in terms of possible worlds semantics limiting case-is contingent upon the choice of the language. Full rationality reveals a fine point usually ignored: one sense would require a language isormorphic theory about full rationality has to make simplifying nature, violate assumptions the ontology of full rationality by their simplifying is about the world, in some sense or to the universe “out there”, but such a language \f78 Z Huang et al./Artijkial intelligence 82 (1996) 75-127 statement goals-provide is understood Preferences-not the basis for rational action [ 721, a preference the statements that “I prefer oranges the states in which I have an orange in ALX. Following von Wright as a statement about situations. For example, to apples” as the fact that “I prefer to the states in which I have an apple.” to prefer oranges Following to apples should prefer a situation where he has an orange but no apple to a situation where he has an apple but no orange. Preferences are expressed via two-place modal q5 to the proposition +, we write c$IPI,~. operators; even when if the agent prefers the meaning von Wright again, we assume that an agent who claims is context-dependent, of a preference the proposition is interpreted Normally, statement change different approach to conditionals that are minimally cw, to the semantics to an apple later-perhaps he may prefer an orange true about which preferences in all other respects. For situations to prefer an apple to an orange-and this context dependency, we borrow from Stalnaker’s expansion principle only to situations this is not made explicit. An agent may claim actually mean it-but he already had an apple. To capture minimal the conjunction the agent’s present situation-just the propositions function, state, such state as much as possible cw to each element of the situation problems because then the notion of [ 681. The idea is to apply from as different as they really need to be in order to make a binary to a given the old (sets of states), we apply separately. This allows us to avoid some technical are expressed. We introduce a set of “closest” states relative that determines that the new states fulfill some specified conditions, of preferences, its machinery. Closing yields a preference order so one can de- the set that in terms of prefer- (we will argue that there are several plausible goal definitions, arising ALX provides rive new preference of preference serves as the basis ences and accessibilities corresponding this follows be unique; usually incomplete. Also, so agents need not treat undesired consequence use the concept of “goal” as the primitive notion of rational guidance). stronger notions of rationality). Note that goals need not and preference orders are from old ones b",
            {
                "entities": [
                    [
                        75,
                        131,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 170 (2006) 160–185www.elsevier.com/locate/artintLoop formulas for circumscriptionJoohyung Lee a, Fangzhen Lin b,∗a Department of Computer Science and Engineering, Arizona State University, AZ, USAb Department of Computer Science, Hong Kong University of Science and Technology, Clear Water Bay,Kowloon, Hong KongReceived 4 April 2005; received in revised form 13 September 2005; accepted 14 September 2005Available online 2 November 2005AbstractClark’s completion is a simple nonmonotonic formalism and a special case of several non-monotonic logics. Recently there has been work on extending completion with “loop formulas” sothat general cases of nonmonotonic logics such as logic programs (under the answer set seman-tics) and McCain–Turner causal logic can be characterized by propositional logic in the form of“completion + loop formulas”. In this paper, we show that the idea is applicable to McCarthy’s cir-cumscription in the propositional case, with Lifschitz’s pointwise circumscription playing the roleof completion. We also show how to embed propositional circumscription in logic programs and incausal logic, inspired by the uniform characterization of “completion + loop formulas”. 2005 Elsevier B.V. All rights reserved.Keywords: Nonmonotonic reasoning; Commonsense reasoning; Knowledge representation; Circumscription;Clark’s completion; Loop formulas; Logic programming1. IntroductionClark’s predicate completion [5] is a simple and intuitive nonmonotonic formalism.Normally it is applicable when the knowledge base is given as a set of rules, and workswhen the rules do not yield a “cycle”.* Corresponding author.E-mail address: flin@cs.ust.hk (F. Lin).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.09.003\fJ. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185161Despite these limitations, surprisingly perhaps, predicate completion has been used tosolve many problems that were thought to require more sophisticated nonmonotonic logics.For instance, Reiter [34] showed that under certain reasonable assumptions, successor stateaxioms can be computed from action effect axioms by predicate completion, and thussolved the frame problem when there are no state constraints. For state constraints, Lin[25] argued that they should be encoded using a notion of causality, and once they areencoded this way, successor state axioms can once again be computed using predicatecompletion for a class of causal rules that includes almost all of the benchmark planningdomains [25,27].For the “definite” fragment of McCain–Turner causal logic [10,28], the problem of de-termining whether a theory is consistent can be reduced to the satisfiability problem forpropositional logic by the process of “literal completion”—a translation similar to Clark’scompletion. This idea has led to the creation of the Causal Calculator (CCALC),1 a systemfor representing commonsense knowledge about action and change. After turning a definitecausal theory into a classical propositional theory, CCALC finds the models of the latterby invoking a satisfiability solver, such as CHAFF,2 SATO3 and RELSAT,4 which in turncorrespond to the models of the given causal theory. CCALC has been successfully appliedto several challenge problems in the theory of commonsense knowledge [1,4,18,23] and tothe formalization of multi-agent computational systems [2,3].In logic programming where predicate completion is best known and commonly re-ferred to as program completion semantics, its relationships with other semantics, espe-cially the answer set semantics (also known as the stable model semantics) of Gelfondand Lifschitz [9], have been studied quite extensively. First of all, it is well known that ananswer set for a normal logic program is also a model of its completion, while the con-verse, generally, does not hold. Fages [8] showed that a certain syntactic condition, whichis now called “tightness”, is sufficient for establishing the equivalence between them. Er-dem and Lifschitz [7] generalized Fages’ theorem and extended it to programs with nestedexpressions (in the sense of [17]) in the bodies of rules.Instead of looking for conditions that will guarantee the equivalence between the com-pletion semantics and the answer set semantics, Lin and Zhao [24] considered how tostrengthen completion to make it equivalent to the answer set semantics. The idea is that,since the presence of cycles is what causes the mismatch between the models of the com-pletion and the answer sets for a program, one should address the problem raised by themdirectly. The completion semantics captures the intuition that for an atom to be true, oneof the bodies of the rules with the atom as the head must be true. Similarly, Lin and Zhaoassociated with each loop a “loop formula” that captures the intuition that for the atoms ina loop to be true, there must be a rule whose head belongs to the loop, and whose bodyis true but its positive part does not have any atom in the loop. They showed that a set ofatoms is an answer set for a nondisjunctive logic program iff it is a model of the completionand all loop formulas of the program. This idea allows SAT solvers to be used for finding1 http://www.cs.utexas.edu/users/tag/ccalc/.2 http://www.ee.princeton.edu/~chaff/.3 http://www.cs.uiowa.edu/~hzhang/sato.html.4 http://www.almaden.ibm.com/cs/people/bayardo/resources.html.\f162J. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185answer sets and thus has led to the creation of SAT-based answer set solvers ASSAT [24]and CMODELS-2 [11].As it turned out, program completion and loop formulas are not limited to nondisjunc-tive logic programs. Lee and Lifschitz [12] extended the Lin/Zhao theorem to disjunc-tive logic programs and, more generally, to arbitrary programs with nested expressions.Lee [13] showed that a similar result can be obtained for McCain and Turner causal logicand based on this, showed how to embed logic programs in causal logic.Given these results, one wonders how far this idea of “completion + loop formulas”can go. Is it general enough to capture other nonmonotonic logics? In this paper, we an-swer this question positively for circumscription [29,30] in the propositional case. Thus itis interesting to observe that these apparently different nonmonotonic formalisms have auniform view of “completion + loop formulas”. Using this idea, we show how to embedcircumscription in logic programs and in McCain–Turner causal logic.Hopefully, these results will lead to good implementations of propositional circumscrip-tion using SAT solvers and/or answer set solvers. This would be a significant progress innonmonotonic reasoning as circumscription has found applications in commonsense rea-soning, model-based diagnoses, discourse understanding, and others. While many of theseapplications in general make use of first-order circumscription, they can be solved usingpropositional circumscription when their domains are given and finite.This paper is organized as follows. In Section 2, we introduce some notations that wewill use in the rest of the paper, and recast the definition of circumscription in the propo-sitional case. In Section 3, we discuss Clark’s completion, and compare it with Lifschitz’spointwise circumscription [20], as the latter will serve as “completion” for our purpose. InSection 4, we introduce the notion of a loop via the notion of a dependency graph. Section 5contains the main technical results of the paper, which shows that circumscription can becharacterized by completion plus loop formulas. It also discusses some related work. Basedon the results in Section 5, Section 6 shows how circumscription can be embedded in logicprograms under the answer set semantics and in McCain–Turner causal logic. We concludein Section 7.2. Logical preliminariesA literal is a (propositional) atom or the negation of an atom. A (propositional) formulais formed from literals using propositional connectives. A clause is a finite set of literals.We identify a clause C with the disjunction of its elements. It is well known that anyformula can be transformed into an equivalent set of clauses.We use variables that range over 0-place connectives (cid:2) and ⊥, and quantify overthem. For instance, if A(z, p1, . . . , pk) is a propositional formula built with propo-sitional variables z, p1, . . . , pk, we write ∀zA(z, p1, . . . , pk) to denote the formulaA((cid:2), p1, . . . , pk) ∧ A(⊥, p1, . . . , pk), and similarly ∃zA(z, p1, . . . , pk) to denote the for-mula A((cid:2), p1, . . . , pk) ∨ A(⊥, p1, . . . , pk).In the following, we sometimes write a formula A as A(P ) or A(P , Q) for tuples P andQ of atoms. This way, when X is a tuple of variables and atoms of the same length as P ,we use A(X) or A(X, Q) to denote the result of simultaneously replacing all elements\fJ. Lee, F. Lin / Artificial Intelligence 170 (2006) 160–185163of P in A by the corresponding elements of X. We sometimes identify a tuple with thecorresponding set when there is no confusion.For P = (p1, . . . , pn), Q = (q1, . . . , qn),P (cid:1) Q stands forP = Q stands forP < Q stands for(cid:1)(pi ⊃ qi),1(cid:1)i(cid:1)n(cid:1)(pi ≡ qi),1(cid:1)i(cid:1)n(P (cid:1) Q) ∧ ¬(P = Q).Let P and Z be tuples of atoms, and A(P , Z) a formula. The circumscription of P inA(P , Z) ∧ ¬∃XYA(P , Z) with atoms in Z allowed to vary, is the following formula:(cid:2)A(X, Y ) ∧ X < P(cid:3).(1)The formula is denoted by CIRC[A(P , Z); P ; Z], which may also be written asCIRC[A(P ); P ] when Z is empty.The second conjunct of formula (1) is actually a propositional formula as in the follow-ing example:CIRC[p ∨ q; p] = (p ∨ q) ∧ ¬∃x(cid:4)(cid:2)= (p ∨ q) ∧ ¬(cid:3)(cid:2)(x ∨ q) ∧ (x ⊃ p) ∧ (x (cid:10)≡ p)(cid:3)((cid:2) ∨ q) ∧ ((cid:2) ⊃ p) ∧ ((cid:2) (cid:10)≡ p)(cid:2)(⊥ ∨ q) ∧ (⊥ ⊃ p) ∧ (⊥ (cid:10)≡ p)(cid:3)(cid:5)∨≡ (p ∨ q) ∧ ¬(p ∧ q).(2)The models of the circumscription are {p} and {q}.5There is a weaker noti",
            {
                "entities": [
                    [
                        72,
                        105,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 244 (2017) 48–69Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSkypattern mining: From pattern condensed representations to dynamic constraint satisfaction problemsWilly Ugarte a, Patrice Boizumault a, Bruno Crémilleux a,∗Samir Loudni a, Marc Plantevit c, Chedy Raïssi d, Arnaud Soulet ea GREYC (CNRS UMR 6072), University of Caen, F-14032 Caen, Franceb CERMN (UPRES EA 4258 – FR CNRS 3038 INC3M), University of Caen, F-14032 Caen, Francec Université de Lyon, CNRS, Université Lyon 1, LIRIS (UMR5205), F-69622, Franced INRIA Nancy Grand-Est, Francee LI (EA 2101), Université François Rabelais de Tours, F-41029 Blois, France, Alban Lepailleur b, a r t i c l e i n f oa b s t r a c tArticle history:Received in revised form 7 April 2015Accepted 14 April 2015Available online 28 April 2015Keywords:SkypatternsPattern miningConstraint programmingDynamic CSPUser preferencesData mining is the study of how to extract information from data and express it as useful knowledge. One of its most important subfields, pattern mining, involves searching and enumerating interesting patterns in data. Various aspects of pattern mining are studied in the theory of computation and statistics. In the last decade, the pattern mining community has witnessed a sharp shift from efficiency-based approaches to methods which can extract more meaningful patterns. Recently, new methods adapting results from studies of economic efficiency and multi-criteria decision analyses such as Pareto efficiency, or skylines, have been studied. Within pattern mining, this novel line of research allows the easy expression of preferences according to a dominance relation. This approach is useful from a user-preference point of view and tends to promote the use of pattern mining algorithms for non-experts. We present a significant extension of our previous work [1,2] on the discovery of skyline patterns (or “skypatterns”) based on the theoretical relationships with condensed representations of patterns. We show how these relationships facilitate the computation of skypatterns and we exploit them to propose a flexible and efficient approach to mine skypatterns using a dynamic constraint satisfaction problems (CSP) framework.We present a unified methodology of our different approaches towards the same goal. This work is supported by an extensive experimental study allowing us to illustrate the strengths and weaknesses of each approach.© 2015 Elsevier B.V. All rights reserved.1. IntroductionThe process of extracting useful patterns from data, called pattern mining, is an important subfield of data mining, and has been used in a wide range of applications and domains such as bioinformatics [3], chemoinformatics [4], social network analysis [5], web mining [6] and network intrusion detection [7]. Since the key papers of Agrawal et al. [8], Mannila et al. [9], a considerable number of patterns, such as itemsets, strings, sequences, trees and graphs, have been studied and * Corresponding author.E-mail address: bruno.cremilleux@unicaen.fr (B. Crémilleux).http://dx.doi.org/10.1016/j.artint.2015.04.0030004-3702/© 2015 Elsevier B.V. All rights reserved.\fW. Ugarte et al. / Artificial Intelligence 244 (2017) 48–6949used in real-world applications. Nowadays, many pattern extraction problems like subgroup discovery [10], discriminative pattern mining [11], and tiling [12] are understood from both theoretical and computational perspectives.Most existing pattern mining approaches enumerate patterns with respect to a given set of constraints that range from simple to complex. For instance, given a transaction database, a well-known pattern mining task is to enumerate all itemsets (i.e. sets of items) that appear in at least s transactions. However, the output of pattern mining operations can be extremely large even for moderately sized datasets. For instance, in the worst case, the number of frequent itemsets is exponential in the number of the items in the dataset.So far, the community has expended much effort on developing sophisticated algorithms which push the constraints deep into the mining process [13]. But also in on compression (i.e. reduction) techniques to limit the number of output patterns depending on the application contexts [14–16]. The pattern mining community, however, has paid less attention to combining mining constraints. In practice, many constraints entail choosing threshold values such as the well-used minimal frequency. This notion of “thresholding” has serious drawbacks. Unless specific domain knowledge is available, the choice is often arbitrary and may lead to a very large number of extracted patterns which can reduce the success of any subsequent data analysis. This drawback is even more pronounced when several thresholds have to be combined. A second drawback is the stringent enumeration aspect: a pattern is either above or below a threshold. But what about patterns that respect only some thresholds? Should they be discarded? It is often very difficult to apply subtle selection mechanisms. There are very few works such as [17,18] which propose to introduce a softness criterion into the mining process. Other studies attempt to integrate user preferences into the mining task in order to limit the number of extracted patterns such as the top-k pattern mining approaches [19,20]. By associating each pattern with a rank score, this approach returns an ordered list of the k patterns with the highest score to the user. However, combining several measures in a single scoring function is difficult and the performance of top-k approaches is often sensitive to the size of the datasets and to the threshold value, k.We present a unified methodology of two approaches that aim to make the results of pattern mining useful from a user-preference point of view. To this end, we integrate into the pattern discovery process the idea of skyline queries [21] in order to mine skyline patterns in a threshold-free manner. Such queries have attracted considerable attention due to their impor-tance in multi-criteria decision making and economics where they are usually called “Pareto efficiency or optimality queries”. Briefly, in a multidimensional space where a preference is defined for each dimension, a point a dominates another point b if a is better (i.e. more preferred) than b in at least one dimension, and a is not worse than b on every other dimen-sion. For example, a user selecting a set of patterns may prefer a pattern with a high frequency, a large length and a high confidence. In this case, we say that pattern a dominates another pattern b if a.frequency ≥ b.frequency, a.length ≥ b.length, a.confidence ≥ b.confidence, where at least one strict inequality holds. Given a set of patterns, the skyline set contains the patterns that are not dominated by any other pattern.Skyline pattern mining is interesting for several reasons. First, skyline processing does not require any threshold se-lection. In addition, for many pattern mining applications it is often difficult (or impossible) to find a reasonable global ranking function. Thus the idea of finding all optimal solutions in the pattern space with respect to multiple preferences is appealing. Second, the formal property of dominance satisfied by the skyline pattern defines a global interestingness measure with semantics easily understood by the user. These semantics are discussed at length in the economics literature, where the Pareto efficiency is applied to the selection of alternatives in resource distributions. However, while this notion of skylines has been extensively developed in engineering and database applications, it has remained unused for data mining purposes until recently [1]. Thirdly, skyline pattern mining is appealing from an efficiency and usability point of view. The authors of [22] established a loose upper-bound on the average number of skyline tuples O ((ln n)d−1) (with n tuples and |I|) (where |I| represents the d dimensions) which contrasts with the usual worst-case number of possible itemsets O (2cardinality of the set of items).Contributions and roadmap We present significant extensions of our recent papers [1,2] on the discovery of skyline patterns, or “skypatterns”. First, we detail a static method (called Aetheris) based on the theoretical relationships with condensed rep-resentations of patterns (representations which return a subset of the patterns having the same expressiveness as the whole set of patterns [23]). Second, we describe a dynamic method (called CP+Sky) which involves a continuous re-finement of the skyline constraints based on the extracted patterns. This is achieved through a dynamic CSP (Constraint Satisfaction Problems) framework (denoted by DynCSP). Third, the key notion of “skylineability” which constitutes the cor-nerstone of our two methods is explained in more detail. Finally, we present an extensive empirical study which includes a wide range of datasets and comparisons of our techniques. This enables us to draw some lessons about the strengths and weaknesses of each method and to better understand the advantages/weaknesses of the CSP machinery (see Sections 7.1.2and 7.1.3).The rest of this paper is organized as follows. Section 2 surveys the works related to skyline pattern analysis. Section 3introduces some basic definitions, the formal problem statement and an overview of our work. The key notion of sky-lineability is then studied in Section 4. Section 5 discusses the computation of condensed representation of patterns for skypattern queries. Section 6 discusses skylineability but within a DynCSP framework. We report an empirical study on several datasets and a case study from the chemoinformatics domain in Section 7. Finally, Section 8 discusses the learnt lessons.\f50W. Ugarte et al. / Artificial Intelligence 244 (2017) 48–692. Related work2.1. Pattern miningFrequent itemset mining was first descri",
            {
                "entities": [
                    [
                        134,
                        235,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 172 (2008) 103–139www.elsevier.com/locate/artintState-set branching: Leveraging BDDs for heuristic search ✩Rune M. Jensen ∗, Manuela M. Veloso, Randal E. BryantComputer Science Department, Carnegie Mellon University, 5000 Forbes Ave., Pittsburgh, PA 15213-3891, USAReceived 22 February 2006; received in revised form 30 May 2007; accepted 30 May 2007Available online 7 June 2007AbstractIn this article, we present a framework called state-set branching that combines symbolic search based on reduced ordered BinaryDecision Diagrams (BDDs) with best-first search, such as A* and greedy best-first search. The framework relies on an extensionof these algorithms from expanding a single state in each iteration to expanding a set of states. We prove that it is generallysound and optimal for two A* implementations and show how a new BDD technique called branching partitioning can be used toefficiently expand sets of states. The framework is general. It applies to any heuristic function, evaluation function, and transitioncost function defined over a finite domain. Moreover, branching partitioning applies to both disjunctive and conjunctive transitionrelation partitioning. An extensive experimental evaluation of the two A* implementations proves state-set branching to be apowerful framework. The algorithms outperform the ordinary A* algorithm in almost all domains. In addition, they can improvethe complexity of A* exponentially and often dominate both A* and blind BDD-based search by several orders of magnitude.Moreover, they have substantially better performance than BDDA*, the currently most efficient BDD-based implementation of A*.© 2007 Elsevier B.V. All rights reserved.Keywords: Heuristic search; BDD-based search; Boolean representation1. IntroductionInformed or heuristic best-first search (BFS) algorithms1 such as greedy best-first search and A* [27] are consideredimportant contributions of AI. The advantage of these algorithms, compared to uninformed or blind search algorithmssuch as depth-first search and breadth-first search, is that they use heuristics to guide the search toward the goal andin this way significantly reduce the number of visited states. The algorithms differ mainly by the way they evaluatenodes in the search tree. A* is probably the most widely known BFS algorithm. Each search node of A* is associated✩ This work is an extended version of a paper presented at AAAI-02 [R.M. Jensen, R.E. Bryant, M.M. Veloso, SetA*: An efficient BDD-basedheuristic search algorithm, in: Proceedings of 18th National Conference on Artificial Intelligence (AAAI-02), 2002, pp. 668–673]. The work wassupported in part by the Danish Research Agency and the United States Air Force under Grants Nos F30602-00-2-0549 and F30602-98-2-0135.The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the officialpolicies or endorsements, either expressed or implied, of the Defense Advanced Research Projects Agency (DARPA), the Air Force, or the USGovernment.* Corresponding author.E-mail addresses: runej@cs.cmu.edu (R.M. Jensen), mmv@cs.cmu.edu (M.M. Veloso), bryant@cs.cmu.edu (R.E. Bryant).URLs: http://www.cs.cmu.edu/~runej (R.M. Jensen), http://www.cs.cmu.edu/~mmv(M.M. Veloso), http://www.cs.cmu.edu/~bryant(R.E. Bryant).1 In this article, BFS always refers to best-first search and not breadth-first search.0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.05.009\f104R.M. Jensen et al. / Artificial Intelligence 172 (2008) 103–139with a cost g of reaching the node and a heuristic estimate h of the remaining cost of reaching the goal. In eachiteration, A* expands a node with minimum expected completion cost f = g + h. A* can be shown to have muchbetter performance than uninformed search algorithms. However, an unresolved problem for this algorithm is that thenumber of expanded search nodes may grow exponentially even if the heuristic has only a small constant relative error[46]. Such heuristic functions are often encountered in practice, since many heuristics are derived from a relaxationof the search problem that is likely to introduce a relative error. Furthermore, in order to detect duplicate states andconstruct a solution, A* must keep all expanded nodes in memory. For this reason, the limiting factor of A* is oftenspace rather than time.In symbolic model checking [42], a quite different approach has been taken to verify systems with large state spaces.Instead of representing and manipulating sets of states explicitly, this is done implicitly using Boolean functions.2Given a bit vector encoding of states, characteristic functions are used to represent subsets of states. In a similarway, a Boolean function can be used to represent the transition relation of a domain and find successor states viaBoolean function manipulation. The approach potentially reduces both the time and space complexity exponentially.Indeed during the last decade, remarkable results have been obtained using reduced ordered Binary Decision Diagrams(BDDs [9]) as the Boolean function representation. Systems with more than 10100 states have been successfullyverified with the BDD-based model checker SMV [42]. For several reasons, however, only very limited work onusing heuristics to guide these implicit search algorithms has been carried out. First of all, the solution techniquesconsidered in formal verification often require traversal of all reachable states making search guidance irrelevant.Secondly, it is non-trivial to efficiently handle cost estimates such as the g and h-costs associated with individualstates when representing states implicitly.In this article, we present a new framework called state-set branching that combines BDD-based search and best-first search (BFS) and efficiently solves the problem of representing cost estimates. State-set branching applies toany BFS algorithm and any transition cost function, heuristic function, and node-evaluation function defined over afinite domain. The state-set branching framework consists of two independent parts. The first part extends a generalBFS algorithm to an algorithm called best-set-first search (BSFS) that expands sets of states in each iteration. Thesecond part is an efficient BDD-based implementation of BSFS using a partitioning of the transition relation of thesearch domain called branching partitioning. Branching partitioning allows sets of states to be expanded implicitlyand sorted according to their associated cost estimates. The approach applies both to disjunctive and conjunctivepartitioning [15].Two implementations of A* based on the state-set branching framework called FSETA* anf GHSETA* have beenexperimentally evaluated in 10 search domains ranging from VLSI-design with synchronous actions, to classicalAI planning problems such as the (N 2 − 1)-puzzles and problems used in the international planning competitions1998–2004 [2,29,39,40]. We apply four different families of heuristic functions ranging from the minimum Hammingdistance to the sum of Manhattan distances for the (N 2 − 1)-puzzles, and HSPr [8] for the planning problems. In thisexperimental evaluation, the two A* implementations outperform implementations of the ordinary A* algorithm inall domains except one where an efficient Boolean state encoding seems to be challenging to find.3 In addition, theresults show that they can improve the complexity of A* exponentially and that they often dominate both the ordinaryA* algorithm and blind BDD-based search by several orders of magnitude. Moreover, they have substantially betterperformance than BDDA*, the currently most efficient symbolic implementation of A*.The main limitation of the state-set branching framework is that a Boolean state encoding with a compact BDDrepresentation must be found for a target domain. In most cases this is easy, but for general domain representation lan-guages such as PDDL [24] it may be challenging to define automated encoding techniques. Another issue is whetherbranching partitionings are easy to obtain for all heuristics. The experiments in this article show that additive heuris-tics like the sum of Manhattan distances and the HSPr heuristic can be represented compactly. A recent study [32],however, shows that branching partitionings of the max-pair heuristic [28] may be prohibitively large. It is not ourimpression, though, that strong domain dependent heuristics are as combinatorial complex as the max-pair heuristic.2 By an explicit representation, we mean an enumerative representation that uses space linear in the number of represented elements. By animplicit representation, we mean a non-enumerative representation using Boolean expressions to characterize elements.3 By ordinary A* we refer to the graph-search version of A* that maintains a closed list for duplicate elimination and uses an explicit staterepresentation.\fR.M. Jensen et al. / Artificial Intelligence 172 (2008) 103–139105The remainder of this article is organized as follows. We first describe related work in Section 2. We then definesearch problems in Section 3 and describe the general BFS algorithm in Section 4. In Section 5, we extend this algo-rithm to expand sets of states and study a number of example applications of the new best-set-first search algorithm.In Section 6, we introduce branching partitioning and other BDD-based techniques to efficiently implement thesealgorithms. The experimental evaluation is described in Section 7. Finally, we conclude and discuss directions forfuture work in Section 8.2. Related workState-set branching is the first general framework for combining heuristic search and BDD-based search. All previ-ous work has been restricted to particular algorithms. BDD-based heuristic search has been investigated independentlyin symbolic model checking and AI. The pioneering work is in symbolic model checking where heuristic searc",
            {
                "entities": [
                    [
                        72,
                        129,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "ELSEVIER Artificial Intelligence 85 ( 1996) 181-243 Artificial Intelligence The effect of resource limits and task complexity on collaborative planning in dialogue Marilyn A. Walker * AT&T Research Laboratories, 600 Mountain Ave., Rm. 20-441, Murray Hill, NJ 07974, USA Received January 1995; revised October 1995 Abstract to mitigate in communicative testbed whose design ( 1) agents’ resource action can be designed This paper shows how agents’ choice is motivated by the corpus analysis. Experiments the interaction between (2) agents’ choice limits in the context of particular features of a collaborative planning the task. effect of their resource language behavior based on a statistical about effective I first motivate a number of hypotheses analysis of a corpus of natural collaborative planning dialogues. These hypotheses are then tested in a dialogue in the testbed limits in attentional capacity and inferential examine that capacity; tasks affect required, and for communication must be defined tolerance relative to the agents’ resource limits and the features of the task. Algorithms that are inefficient for inferentially simple, low coordination or fault tolerant tasks are effective when tasks require for coordination or complex that, prima facie, appear inefficient, and provide the occurrence of utterances in human dialogues the basis for the design of effective algorithms limited choice for communicative agents. inferences, or are fault intolerant. The results provide an explanation for errors. The results show that good algorithms complexity, degree of belief coordination features of communicative such as inferential in communication; task difficulty for resource and (3) 1. Introduction Agents may engage in conversation to make a plan, or to be social. At each point to establish a contract, agents must make communicative say it. This paper focuses on agents’ communicative dialogues, dialogues whose purpose choices about what planning is to discuss and agree on a plan for future action, choice to say and how and when in collaborative to for a range of reasons, e.g. to acquire information, in a dialogue, * E-mail: walker@research.att.com. 0004-3702/96/$15.00 SSD10004-3702(95)00114-X Copyright @ 1996 Published by Elsevier Science B.V. All rights reserved \fIX? M./l. ll/llXr,-/~~~rrr~ic~rlcl lw!lilgr,rw x.5 (I9961 IHl-243 execute their algorithms and potentially action, relatively unexplored resource of collaborative the degree of belief coordination limits. such as limits planning factors A primary dimension example. consider a simple furnishing by ( I ) and believes that agents’ choices that plan. 1 will argue for language behavior. must be determined with respect in models of collaborative planning dialogues: and inferential capacity; and (2) in attentional in communicative to two ( I ) agents’ features complexity, tasks that affect task difficulty, such as inferential required, and tolerance for errors. of communicative choice is the degree of explicitness. task of agent A and agent B trying For to agree on a plan for realized a two-room house. Imagine that A wants B to believe the proposition that B can infer this from the propositions realized in (2): ’ ( I I in the study. II‘ we agree to put the green couch in the study, we will have a matched pair of furniture t 2 ) c a) I propose C t-11 We intend ( c) Two furniture that we put the green couch in the study. to put the green chair in the study. items of the same color in the same room achieve a matched pair. In naturally occurring dialogues, A may product utterances ( 3 )-( 6 ). or other variations [ 30, 109. 13.3, I3 I 1. realizing the propositions in (3) (4) (5) (6) A: I propose A: We intend couch in the study. A: Two furniture pair. We intend green couch A: I propose pair. that we put the green couch to put the green chair in the study. I propose in the study. that we put the green items of the same color in the same room achieve a matched that we put the in the study. I propose to put the green chair in the study. that we put the green couch in the study. That will get us a matched fact: for any communicative levels of explicitness. the more or less explicit choices in (3 )-( 6) illustrate a general The communicative act. the same effect can be achieved with a range of acts at various This raises a key issue: On what basis does A choose among in C 3 )-C 6) ? versions of the proposal that has been suggested elsewhere The single constraint A should not say information such as “don’t CONSTRAINT: infer. The IUXNINDANC~ DUNDANCY that B could ple dictums Maxim “do not make your contribution more informative operators constraints on planning plans possibility for what A can say is (3). J So. if we assume for the generation [2. 13.27.86.92 that B knows CONSTRAINT in the literature is the FE- that B already knows, or in the form of sim- tell people what they already know”. as Grice’s Quantity appears than is required” [47] and as and recognition of communicative (2b) and (2~). then the only ’ These ewmples arc I‘rom the domain of Design-World to be discussed in Section 4 and are abstractions from naturally occurring examples in which the propositions realized here are realized in a number of different ways. Here the focus i< on the logical relationships between the content of each proposition: (?a) and (2b) arc minor premises and (2~) is the major premise for the inference under discussion. \fM.A. Walker/Art@cial Intelligence 85 (1996) 181-243 183 The REDUNDANCY CONSTRAINT is based on the assumption implicit leave B could a combination I will show infer, any information in other words, of retrieving she believes that agent B can always “fill that B already knows or she believes facts from memory and making that agent A should that is missing” by In Section 2, in what inferences. the REDUNDANCY surprising since the that agents in natural dialogues consistently violate CONSTRAINT. I will argue that this should not be particularly REDUNDANCY CONSTRAINT is based on several simplifying assumptions: (i) UNLIMITED WORKING MEMORY ASSUMPTION: everything an agent knows is always available for reasoning; (ii) LOGICAL OMNISCIENCE ASSUMPTION: (iii) ASSUMPTION: FEWEST UTTERANCES that should be minimized; agents are logically omniscient; utterance production is the only process (iv) No AUTONOMY ASSUMPTION: assertions and proposals by agent A are ac- cepted by default by agent B. these assumptions do not always When agents are autonomous hold, and the problem of communicative for the paper and resource limited, choice remains. The plan is implemented the relationship choice, resource of communicative planning presented from natural collaborative is as follows: Section 2 motivates planning dialogues. These hypotheses a number of hypotheses limits and task features using are the basis in Section 3. Then Section 4 describes planning dialogues called about evidence of a model of collaborative how the model Design-World, which supports experiments on the interaction of agents’ communicative choice, the steps of the method applied so far, and motivate for testing the extent theoretical to other tasks, agent properties, the hypotheses. Section 5 presents to which implications in Section 4.1, I review as a method results and discusses the of these results and the extent to which they can be generalized limits, and features of the task. At this point, the hypotheses were confirmed, and then Section 6 discusses in a testbed for collaborative the use of simulation and communication the experimental strategies. resource 2. Communicative choice in dialogue about Naturally dialogues are design, problem planning [ 14,21,30,37,49,97,104,128,141,143]. collaborative occurring diagnostic or advice giving dialogues to generate hypotheses and task features, collaborative from a corpus of dialogues but I will also draw on data from collaborative computer solving, In order to agent properties in naturally occurring dialogues. Most of the examples discussed below are excerpts [98] ,2 and from a radio talk show for financial planning the relation of communicative advice construction, this section examines design, collaborative [ 28,139,142,143]. communicative planning choice choice Dialogue, add to what is is modeled as a process by which conversants to be already mutually believed or intended. This set of assumed mutual beliefs assumed support dialogues in general, * The corpus consists of 55 dialogues from 5 hours of live radio broadcast, where each dialogue ranged in length from 23 to 100 turns. \fplanning dialogues, is called the DISCOURSE MODEL, or the COMMON the current state of the world and mutual beliefs and intentions and intentions In collaborative about future action and the efficiency of the planning process must be affected by agents’ algorithms communicative GROUND [ II9,140]. to add mutual beliefs about a plan for that the efficacy of the final plan for to the discourse model. the conversants are attempting It is obvious choice. However previous work has not systematically varied factors that affect communicative choice, such as resource has been based on the REDUNDANCY assumptions simplifying (but see [78, 147. 14X] ). To explore the relation of communicative choice limits and task complexity. Furthermore, most previous work CONSTRAINT, and apparently, its concomitant the analysis of naturally occurring collaborative planning dialogues on communicative INFORMATIONALLY the REDUNDANCY REDUNDANI‘ IJTIERANCES, IRUs. defined as:3 acts that violate to effective collaborative planning, in this paper focuses CONSTRAINT. These acts are Definition of informational DUNDANT in a discourse redundancy. An utterance u, is INFORMATIONALLY RE- situation S (i) (ii) a proposition if II, expresses already been said in S; if II, expresses a proposition implicates p, has already been said in S. pL, and another utterance nj pi. and another utterance n, that entails p; has that presupposes or A statistical ",
            {
                "entities": [
                    [
                        76,
                        163,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 258 (2018) 1–65Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintExtracting mutual exclusion invariants from lifted temporal planning domainsSara Bernardini a,∗a Department of Computer Science, Royal Holloway University of London, Egham, Surrey, TW20 0EX, UKb Department of Mathematical Sciences “G. L. Lagrange”, Politecnico di Torino, Corso Duca degli Abruzzi, 24, 10129 Torino, Italyc Intelligent Systems Division, NASA Ames Research Center, Moffett Field, CA 94035, United States, Fabio Fagnani b, David E. Smith ca r t i c l e i n f oa b s t r a c tArticle history:Received 6 January 2017Received in revised form 24 January 2018Accepted 27 January 2018Available online 6 February 2018Keywords:Automated planningTemporal planningMutual exclusion invariantsAutomatic domain analysisWe present a technique for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies a set of invariant templates by inspecting the lifted representation of the domain and then checks these templates against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire temporal structure of the actions and the possible concurrent interactions between them. As a result, we construct a more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains but also a broader set of invariants for sequential domains. Our experimental results provide evidence that our domain analysis is effective at identifying a more extensive set of invariants, which results in the generation of fewer multi-valued state variables. We show that, in turn, this reduction in the number of variables reflects positively on the performance of the temporal planners that use a variable/value representation.© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionThis paper presents a technique for synthesising mutual exclusion invariants from temporal planning domains expressed in PDDL2.1 [21]. A mutual exclusion invariant over a set of ground atoms means that at most one atom in the set is true at any given moment. Mutual exclusion invariants can be expressed as multi-valued state variables by adding a special “null” value so that, at all moments, precisely one value holds. For instance, consider the Floortile domain from the 8th International Planning Competition (IPC’14 – see Appendix A). A mutual exclusion invariant for this domain states that two ground atoms that indicate the position of a robot can never be true at the same time. Intuitively, this means that a robot cannot be at two different locations simultaneously. To give a concrete case, consider a planning problem for the Floortiledomain with one robot r1 and three locations, t1, t2 and t3. We can create a state variable that indicates the position of r1 with a domain of three values: robotAt_r1_t1, robotAt_r1_t2 and robotAt_r1_t3.Although a number of approaches to invariant synthesis have been proposed so far [27,45,46,20,33], they are limited in scope because they deal with sequential domains only. Recently, Rintanen [47] has proposed a technique for temporal domains, but this technique does not scale to complex problems because it requires grounding the domain. We address * Corresponding author.E-mail addresses: sara.bernardini@rhul.ac.uk (S. Bernardini), fabio.fagnani@polito.it (F. Fagnani), david.smith@PSresearch.xyz (D.E. Smith).https://doi.org/10.1016/j.artint.2018.01.0040004-3702/© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\f2S. Bernardini et al. / Artificial Intelligence 258 (2018) 1–65Table 1Examples of planners and their classification based on whether they treat time explicitly or implicitly and whether they use a Boolean propositional representation or a multi-valued state variable representation.PropositionalVariable/valueClassicalTemporalHSP [9] FF [35] YAHSP [49]LPG [25] POPF [12]FD [32] LAMA [44]TFD [18] EUROPA2 [23]both limitations. We find invariants for temporal domains by applying an algorithm that works at the lifted level of the representation and, in consequence, is very efficient and scales to large instances.Our invariant synthesis builds on Helmert [33], which presents a technique to translate the non-temporal subset of PDDL2.2 [17] into the Finite Domain Representation (FDR), a multi-valued planning task formalism used by Fast Down-ward [32]. Since finding invariants for temporal tasks is much more complex than for tasks with instantaneous actions, a simple generalisation of Helmert’s technique to temporal settings does not work. In the temporal case, simultaneity and interference between concurrent actions can occur, hence our algorithm cannot check actions individually against the invari-ance conditions, but needs to consider the entire set of actions and their possible intertwinements over time. In capturing the temporal case, we formulate invariance conditions that take into account the entire structure of the action schemas as well as the possible interactions between them. As a result, we construct a significantly more comprehensive technique that is able to find not only invariants for temporal domains, but also a broader set of invariants for sequential domains.We describe our approach in two major steps. First, we provide a general theory at the ground level and offer results that insure invariance under two types of properties: safety conditions for individual instantaneous and durative actions as well as collective conditions that prevent dangerous intertwinements between durative actions. Then, we lift these results to the level of schemas so that all checks needed for verifying invariance can be performed at this higher level, without the need for grounding the domain. The complexity of these checks are of linear or low polynomial order in terms of the number of schemas and literals appearing in the domain.1.1. MotivationsAutomated planning is a well-established field of artificial intelligence and, in the more than fifty years since its appear-ance, several paradigms have emerged. One fundamental difference between these paradigms is whether time is treated implicitly or explicitly. While classical planning focuses on the causal evolution of the world, temporal planning is concerned with the temporal properties of the world. In classical planning, actions are considered to be instantaneous, whereas in tem-poral planning actions have durations and can be executed concurrently. Another important difference between planning paradigms relates to whether the world is modelled by adopting a Boolean propositional representation or a representation based on multi-valued state variables. The majority of the work in planning has been devoted to classical planning with domains expressed using propositional languages, and in particular PDDL [41] and its successors [21], the language of the International Planning Competition (IPC). However, in parallel with the development of classical propositional planning, a number of temporal planning systems have been proposed for coping with practical problems, especially space mission op-erations [23,11,28,42,24]. Typically, these systems use variable/value representations. Table 1 shows a classification of several well-known planners based on these different characteristics.Recently, a few techniques have been proposed for translating propositional representations into variable/value represen-tations [32,5,47]. A central task of all these techniques is the generation of state variables from propositions and actions. The basic procedure to do this (which we use as the baseline in our experiments) relies on generating one state variable with two values, true and false, for each proposition. Naturally, such translation produces no performance advantage. A more sophisticated strategy, which produces more compact and optimised encodings, rests on extracting mutual exclusion invari-ants from propositional domains and using such invariants to generate multi-valued state variables. This is the focus of our work.These translation techniques are important as they allow fair testing of planners developed for variable/value repre-sentations on PDDL benchmarks (which are propositional). The practical issue is that planners that permit variable/value representation need this feature to be thoroughly exploited and perform competitively. Since translation between the two different representations can be cheaply automated, there is no reason to avoid providing the richer representations to those planners that accept them (if the translation was expensive, one might reasonably argue about the fairness of this process). As a consequence, these translation techniques are extremely useful for comparing alternative planning paradigms and for promoting cross-fertilisation of ideas between different planning communities, which is our primary motivation.However, the importance of these translation techniques goes beyond the engineering of a bridge between different input languages. In transforming propositional representations into state variable representations, they generate new domain knowledge, where new means accessible in this context. Effectively, these techniques are internal mini theorem provers since, rather than merely translating, they firstly selectively explore the deductive closure of the original theory to find theorems that permit optimising the representation, and secondly execute those optimisations. We will show that the cost of performing t",
            {
                "entities": [
                    [
                        133,
                        209,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 193 (2012) 45–86Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlanning as satisfiability: HeuristicsJussi RintanenInstitute for Integrated and Intelligent Systems, Griffith University, Queensland, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 June 2011Received in revised form 2 May 2012Accepted 9 August 2012Available online 5 September 2012Keywords:PlanningSATHeuristics1. IntroductionReduction to SAT is a very successful approach to solving hard combinatorial problems inArtificial Intelligence and computer science in general. Most commonly, problem instancesreduced to SAT are solved with a general-purpose SAT solver. Although there is the obviouspossibility of improving the SAT solving process with application-specific heuristics, thishas rarely been done successfully.In this work we propose a planning-specific variable selection strategy for SAT solving. Thestrategy is based on generic principles about properties of plans, and its performance withstandard planning benchmarks often substantially improves on generic variable selectionheuristics, such as VSIDS, and often lifts it to the same level with other search methodssuch as explicit state-space search with heuristic search algorithms.© 2012 Elsevier B.V. All rights reserved.Translation into SAT, the satisfiability problem of the classical propositional logic, is one of the main approaches to solvingthe planning problem in AI. The basic idea, first presented by Kautz and Selman [1], is to consider a bounded-horizonplanning problem, to represent the values of state variables at every time point as propositional variables, to representthe relation between two consecutive states as a propositional formula, and then to synthesize a propositional formulathat is satisfiable if and only if there is a plan of the given bounded length. This idea is closely related to the simulationof nondeterministic polynomial-time Turing machines in Cook’s proof of NP-hardness of SAT [2]. Kautz and Selman’s ideawas considered to be only of theoretical interest until 1996 when algorithms for SAT had developed far enough to makeplanning with SAT practical and competitive with other search methods [3]. Later, SAT and its extensions have become amajor state-space search method in computer-aided verification [4] and in many other areas.In this work we investigate SAT solving for planning with the conflict-driven clause learning (CDCL) algorithm [5,6], thecurrently leading framework for SAT solving for structured problems. Instead of using standard generic CDCL heuristics suchas VSIDS [7], we propose planning-specific heuristics which radically differ from generic CDCL heuristics and are based on asimple property all solutions to a planning problem have to satisfy. The work is motivated by the need to better understandwhy SAT solvers are successful in solving AI planning and other reachability problems, and by the need and opportunity todevelop more powerful, problem-specific heuristics for SAT.Our heuristic chooses action variables that contribute to the goals or subgoals, based on the current partial valuationof the CDCL algorithm, representing a tentative plan and a state sequence corresponding to its execution. The principle isextremely simple: for a given (sub)goal, choose an action that achieves the (sub)goal and that can be taken at the earliest time inwhich the (sub)goal can become (and remain) true. Intuitively, this principle expresses a preference for short and simple plans.After choosing an action, its preconditions become new subgoals for which supporting actions are found in the same way.The principle is easy to implement: start from a goal (or a subgoal), go backwards step by step until a time point in whichE-mail address: jussi@cecs.anu.edu.au.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.08.001\f46J. Rintanen / Artificial Intelligence 193 (2012) 45–86the goal is false, and choose any of the actions that can turn it from false to true at that time point. If such an action existedin the plan already, perform the procedure recursively with the preconditions of the action as the subgoals.Interestingly, it turns out that heuristics based on the above principle are often far more effective in finding plans thanthe sophisticated heuristics used by modern general-purpose SAT solvers. Furthermore, a naïve application of the principle –leading to a depth-first backward chaining planning algorithm inside the CDCL framework – lifts the efficiency of SAT-basedplanning close to level with the best earlier planners which use other search methods. This is a very significant result,because the currently best state-space search planners, which have their origins in the work of Bonet and Geffner [8], usefar more complex heuristics and additional pruning techniques to achieve a comparable performance.The simplicity and effectiveness of the principle immediately suggests that there are additional heuristics to obtainfurther efficiency improvements. Instead of finding motivation for such heuristics from standard benchmarks, we look atgeneric properties of planning problems and generic structural properties of the search trees generated by the principle. Wepresent heuristics for ordering the new subgoals and for choosing one of the applicable actions, as well as propose a schemethat replaces the pure depth-first backward search by a less directional form of search. For standard benchmark problemsin planning, the additional heuristics lift the performance of the new variable selection scheme still further.We view this work as a step toward developing efficient SAT-based techniques for planning and other related problemssuch as model-checking [4] and discrete-event systems diagnosis [9]. More advanced heuristics for these applications arelikely to also incorporate features from VSIDS, including the computation of weights of variables based on their occurrencein recently learned clauses. We believe that the success of the planner developed in this work with the standard planningbenchmark problems is more an indication of the simple structure of these benchmarks, and that more challenging problemswill need more complex variable selection heuristics. This observation is supported by earlier works that illustrate thescalability of typical planners in solving combinatorially hard problems [10,11].The structure of the paper is as follows. Section 2 describes the background of the work in planning with SAT. InSection 3 we present the variable selection scheme for planning, and in Section 4 we propose additional heuristics for it.Section 5 describes the implementation of a planning system that is based on the preceding two sections and our earlierworks [12]. In Section 6 we experimentally evaluate the planning system, and in Section 7 we discuss related work beforeconcluding the paper in Section 8.2. Planning as satisfiability2.1. BackgroundReduction to the SAT problem was proposed as a way of solving the planning problem in the 1992 paper by Kautz andSelman [1]. At the same time, algorithms for solving the SAT problem were progressing rapidly, and in 1996 Kautz andSelman were able to show their planning system to scale up better than Graphplan [13] and other planning systems of thetime [3]. These results were obtained with SAT solvers such as WalkSat [14,15] and Tableau [16].The reduction to SAT and the general solution method outlined by Kautz and Selman dominated the SAT approach toplanning for the next several years, and became the basis of scientifically and commercially very successful computer-aidedverification methods in the form of bounded model-checking [4]. In the planning community, however, the focus shifted toheuristic state-space search algorithms as proposed by Bonet, Loerincs and Geffner in the HSP planner starting in 1997[17,8].The decreasing interest of planning researchers in SAT at this time can be traced to two factors: the impractically largesize of the CNF formulas generated from the standard benchmark problems with the early encoding schemes, and the veryhigh computational cost of completing the satisfiability tests for horizon lengths shorter than the shortest plan.As proposed by Kautz and Selman, the planners sequentially went through horizon lengths 0, 1, 2, and so on, until theyreached a horizon length for which the formula is satisfiable, yielding a plan. Essentially, Kautz and Selman’s procedurecorresponds to breadth-first search, and these planners proved that the plan that was found had the shortest possiblehorizon. However, guaranteeing that plans have the shortest possible horizon is unimportant, as the horizon length doesnot, for commonly used notions of parallel plans, coincide with relevant plan quality measures, such as the sum of actioncosts. The notion of parallelism also does not correspond to actual temporal concurrency, but the possibility of reordering theparallel actions to a valid sequential plan [12], and therefore should be viewed as a way of inducing a smaller search space.The unsatisfiability proofs could be avoided by using parallelized search strategies [18]. These often speed up planning byorders of magnitude. At the same time, compact linear-size encodings were proposed. Earlier encodings, such as those basedon the planning graphs of Graphplan [13], had a quadratic size, due to the encoding of action mutexes in the most straight-forward way as binary clauses. The linear-size encodings largely eliminated the problem of excessive memory consumption,and also otherwise yielded substantial performance improvements [19,12]. These developments bridged the performancegap between SAT-based planning and explicit state-space search substantially (for standard benchmarks), and reduced thememory consumption so that it was not an obstacle to efficient planning.Since mid-1990s, there have also ",
            {
                "entities": [
                    [
                        143,
                        181,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 78 (1995) 355-395 Artificial Intelligence Topological direction-giving and visual navigation in large environments Il-Pyung Park*, John R. Kender Department of Computer Science, Columbia University, New York, NY 10027, USA Received September 1993; revised January 1995 Abstract In this paper, we propose and investigate a new model for robot navigation in large unstructured environments. Current models, which depend on metric information, have to deal with inherent mechanical and sensory errors. Instead we supply the navigator with qualitative information. Our model consists of two parts, a map-maker and a navigator. Given a source and a goal, the map- maker derives a navigational path based on the topological relationships between landmarks. A navigational path is generated as a combination of “parkway” and “trajectory” paths, both of which are abstractions of the real world into topological data structures. Traversing within a parkway enables the navigator to follow landmarks that are continuously visible. Traversing on a trajectory enables the navigator to move reliably into featureless space, based on local headings formed by visible landmarks that are robust to positional and orientational errors. Reliability measures of parkway and trajectory traversals are defined by appropriate error models that account for the sensory errors of the navigator, the population of neighboring objects, and the rotational and translational errors of the navigator. The optimal path is further abstracted into a “custom map”, which consists of a list of symbolic directional instructions, the vocabulary of which is defined by our environmental description language. Based on the custom map generated by the map-maker, the navigating robot looks for events that are characterized by spatial properties of the environment. The map-maker and the navigator are implemented using two cameras, an IBM 7575 robot arm, and a PIPE (Pipelined Image Processing Engine.) * Corresponding author. Current address: Department of Computer Science, New York Institute of Technology, 1855 Broadway, New York, NY 10023, USA. E-mail: ip@faculty.nyit.edu. 0004-3702/95/.¶09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00030-5 \f356 I.-P Purk. J.R. Kender/Artificial Intelligence 78 (1995) 355-395 1. Introduction We are interested in navigation is regarded as large if at any instant [ 131. An environment to index into a global coordinate is unstructured in a small subset of the whole terrain. Similar definitions in a large and unstructured environment. An envi- the sensory and motor capacities of the can is no way to use object the objects the navigating the navigating system. This may be because if there the trees in a forest), or because (such as a compass), or because the availability of global coordinates is not (like sensor that even ronment agent reside navigating be found in identification themselves agent has no global referencing agent has no global map (so useful). are easily confusable in a small structured environment is necessary that is useful for the navigator that of navigation is mostly qualitative in a large unstructured Navigation than tools information soning high-level we mean symbolic direction-specifying the appropriate navigational until you see an object on your right” “go true north for 200 meters and turn 40 degrees important concepts Without verification landmarks that it has reached are also useful, because in giving directions to be able to handle ambiguities invariants rather than quantitative. High-level information [ 13,14,24,26]. requires different environment and The rea- and errors; by that can be used to capture in your present heading instruction, whereas to the east” is not. One of the most is the use of landmarks. in a large environment them, direction giving would be very hard for the navigator, as would be the between its destination. The relationships topological information. For example, “continue is a high-level directional these also tend to be insensitive to metric errors. navigation in a large the use of a sequence of qualitative, the navigator’s efforts, that minimizes is errors. Part of this paper for topological In this paper, we provide a new framework Our method emphasizes environment. unstructured high-level, directional landmark-based and prevents, detects, and sometimes motivated by questions (2) what visual features of a landmark are important, recognize a landmark efficiently, how to detect errors, and (6) how to recover from them. In attempting questions, we suggest a dichotomy of roles in the navigation giver (the map-maker) instructions corrects navigational I (4) how to describe a landmark simple direction and a relatively landmarks, concerning follower to the navigator, (3) what sensors are to be used to (5) these system: a powerful direction (the navigator). to answer such as (1) what is a good landmark, environmental can be categorized because Our qualitative and the navigator, is preplanned subsystem. the navigator does not absolutely what the navigator’s appropriate algorithms, recovering occasionally It is also reactive because sensors are supposed the navigator from detected errors. navigation system, which consists of the map-maker as both a preplanned and reactive type [ 221. It the desired path of the navigator is computed by the map-maker specify the “custom map” provided by the map-maker the desired path, but rather “describes” for locally to look for. Then, based on the activation of usually progressing, but reacts to the environment, ’ This problem has been addressed by Kender et al. in [ IO], complexity of selecting an optimal set of sensors. Even NP-complete problem. in which is presented the computational in one-dimensional space, this proves to be an \fI.-F? Park, J.R. KenderIArtifcial Intelligence 78 (1995) 355-395 357 2. Related work The efficiency and the accuracy of navigation depends on the depth of the spatial knowledge of the navigating agent. Kuipers introduced the concept of “cognitive maps” to model the proficiency of the navigator, in which spatial knowledge consists of a hierarchy of “sensorimotor”, “procedural”, “topological”, and “metrical” knowledge. Since the assimilation of knowledge proceeds from the lowest (sensorimotor) to the highest (metrical), it is generally more accurate for people to navigate by using lower- level knowledge, such as exact pictures of landmarks [ 12,271. However, experiments done by Chase [4] indicate that novice drivers prefer topo- logically easier roads (major highways) over metrically shorter but more complicated roads (lesser known streets). Landmarks play an important role for these drivers; even with only a partial knowledge of the environment, they are able to navigate reliably by using visual cues. Streeter et al. [ 231 reported that people with low spatial abilities rely heavily on landmarks for navigation, and suggested that future route generating systems should produce a “customized” route that meets the individual’s background skills. Cognitive map research, some of which have been described above, generally supports the importance of landmarks and their interconnection topology in navigation. The navigating agent does not need to have a comprehensive knowledge of the en- vironment for a single navigational task. For example, in order to get to a church for a wedding, the directions given by the host are usually enough. Experiments done by Streeter et al. [ 241 showed that verbal directions, which are roughly equivalent to Kuipers’ procedural level in the cognitive map structure, are superior to the use of a more comprehensive global map. Riesbeck [ 211 asserted that the quality of directional instructions should be judged by the feasibility of the navigator to follow them, as opposed to how accurate they are in terms of the actual environmental geometry. Sim- ilarly, Mark’s [ 17,181 experiments support the relative usefulness of procedural and topological information over metric information. Traditional approaches to robot navigation require metric accuracy of the robot’s paths. These methods include the configuration space by Lozano-Perez [ 151, generalized cones by Brooks [2], the segmented model by Crowley [5], the grid-based model by Moravec and Elfes [ 191, and the convex cell model by Giralt et al. [ 81. Such traditional methods perform reasonably well only in small environments and fail in large unstructured environments [ 131. Metric information becomes inaccurate, due to the low mechanical accuracy and sensory errors [26] ; errors accumulate. Qualitative approaches to robot navigation include: the TOUR model of Kuipers [ 121, the NX Robot by Kuipers et al. [ 131, Qualnav by Levitt et al. [ 141, inexact navigation by Sutherland et al. [ 261, Dai et al.‘s “range-free navigation” [61, and the PV (Panoramic View) representation used by Zheng et al. 1291. Most of the work in qualitative navigation emphasizes the importance of landmarks. However, none provides a formal answer to the question “What is a landmark?‘, and they assume that landmarks can be readily identified by their intrinsic qualities. Otherwise, they use a generic definition of “distinctiveness” of features in the sensory readings to indicate landmarks. We argue that without criteria for defining and selecting good landmarks, topological navigation is not well formulated. In this paper, we present \f358 I.-l? Purk, J.R. Kender/ArtiJciul Intelligence 78 (1995) 355-395 qualitative methods these selected using to define and select landmarks landmarks, and their relative juxtapositions. and we present means to navigate 3. Definitions and assumptions Our navigation is composed of two modules: a powerful direction giver (the system and a relatively map-maker) paths are precomputed jectories”. These are abstractions parkway travel by following one continuously ways are called invisible trajectories, represents an interconn",
            {
                "entities": [
                    [
                        66,
                        138,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 196 (2013) 106–142Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintAutomatic behavior composition synthesisGiuseppe De Giacomo a, Fabio Patrizi a, Sebastian Sardiña b,∗a Dipartimento di Informatica e Sistemistica, Sapienza Università di Roma, Rome, Italyb School of Computer Science and IT, RMIT University, Melbourne, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 9 February 2011Received in revised form 28 November 2012Accepted 13 December 2012Available online 2 January 2013Keywords:Knowledge representation and reasoningIntelligent agentsReasoning about actions and changeAutomated planningSynthesis of reactive systemsThe behavior composition problem amounts to realizing a virtual desired module (e.g.,a surveillance agent system) by suitably coordinating (and re-purposing) the execution of aset of available modules (e.g., a video camera, vacuum cleaner, a robot, etc.). In particular,we investigate techniques to synthesize a controller implementing a fully controllable tar-get behavior by suitably coordinating available partially controllable behaviors that are toexecute within a shared, fully observable, but partially predictable (i.e., non-deterministic),environment. Both behaviors and environment are represented as arbitrary finite state tran-sition systems. The technique we propose is directly based on the idea that the controllerjob is to coordinate the concurrent execution of the available behaviors so as to “mimic”the target behavior. To this end, we exploit a variant of the formal notion of simulationto formally capture the notion of “mimicking”, and we show that the technique proposedis sound and complete, optimal with respect to computational complexity, and robust fordifferent kind of system failures. In addition, we demonstrate that the technique is wellsuited for highly efficient implementation based on synthesis by model checking technolo-gies, by relating the problem to that of finding a winning strategy in a special safety gameand explaining how to actually solve it using an existing verification tool.© 2013 Elsevier B.V. All rights reserved.1. IntroductionIn this paper, we provide a thorough investigation—from theory to implementation—of the behavior composition prob-lem, that is, the problem of how to realize an abstract desired target behavior module by reusing and re-purposing a setof accessible modules implementing certain concrete behaviors. More concretely, we are interested in synthesizing a sort ofcontroller that coordinates the available existing behaviors in order to replicate a given desired target behavior [30,79,80].Generally speaking, a behavior stands for the logic of any artifact that is able to operate in the environment, such as devices,agents, software or hardware components, or workflows. For example, consider a painting blocks world scenario in whichblocks are painted and processed by different robotic arms; different behaviors stand for different types of arms (e.g., a grip-per, a painting arm, a cleaner arm, etc.), all acting in the same environment. The aim is to realize a desired (intelligent)virtual painting system by suitably “combining” the available arms.Behavior composition is of particular interest in agents and multi-agent settings. A (desired) intelligent system maybe built, for example, from a variety of existing different modules operating (that is, performing actions) on a commonenvironment and whose logic is only partially known. These modules may, in turn, be other agents themselves. A set ofRoboCup players with different capabilities can be put together to form an (abstract) more sophisticated “team” player. Sim-ilarly, a BDI (Belief–Desire–Intention) agent may implement a desired deterministic plan (which was probably obtained via* Corresponding author.E-mail addresses: degiacomo@dis.uniroma1.it (G. De Giacomo), patrizi@dis.uniroma1.it (F. Patrizi), sebastian.sardina@rmit.edu.au (S. Sardiña).0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.12.001\fG. De Giacomo et al. / Artificial Intelligence 196 (2013) 106–142107planning or agent communication) by appealing to the set of available user pre-defined non-deterministic plans [36,75]. Inrobot ecologies and ambient intelligence, advanced functionalities, such as a home surveillance agent, are achieved throughthe composition of many simple robotic devices, such as a vacuum cleaner, a lamp, or a video camera [76,17].Our work is really a form of process synthesis as studied in Computer Science [70,1,89,51]. However, while most litera-ture on synthesis concentrates on synthesizing a process satisfying a certain specification from scratch, behavior compositionfocuses on synthesizing a process (the controller) starting from available components [54]. This idea of composing andreusing components has been strongly put forward by Service Oriented Computing, under the name of “service com-position” [2,42,63,86]. Indeed, service composition aims at composing complex services by orchestrating (i.e., controllingand coordinating) services that are already at disposal. When service composition takes into account the behavior of thecomponent service, as in [20,84,16] for instance, it becomes intimately related to what we call here “behavior composi-tion”.When we look at behavior composition from an Artificial Intelligence perspective, the issue of actual controllability ofthe available behaviors becomes prominent. While one can instruct a behavior module to carry out an action, the actualoutcome of the action may not always be foreseen a priori, though it can possibly be observed after execution. Our workhere is based on revisiting a certain stream of work in service composition [13–15], called “Roman Model” in [42,86], butkeeping the need of dealing with partial controllability central. In particular, we consider the problem of synthesizing a fullycontrollable target behavior from a library of available partially controllable behaviors that are to execute within a shared,fully observable, but partially predictable environment [30,79].Technically, we abstract behaviors and the environment as finite state transition systems. More precisely, each availablemodule is represented as a non-deterministic transition system (to model partial controllability); the target behavior isrepresented as a deterministic transition system (to model full controllability); and the environment is represented as anon-deterministic transition system (to model partial predictability). The environment’s states are fully accessible by theother transition systems. Working with finite state transition systems allows us to leverage on research in Verification andSynthesis in Computer Science [69,87,50,3,23].Once we settle for a formal specification of the problem of concern, we develop a novel sound and complete, and optimalw.r.t. worst-case computational complexity technique to generate so-called compositions. The technique is directly based onthe idea that a composition amounts to a controller that coordinates the concurrent execution of the available modulesso as to “mimic” the desired target behavior. We capture “mimicking” through the formal notion of simulation [60,41].Obviously, we need to consider that available behaviors as well as the environment are only partially controllable (i.e.,non-deterministic), and therefore a special variant of the classical notion of simulation ought to be devised.The proposed technique has several interesting features:• The technique is sound and complete, in a very strong sense: it allows to synthesize a sort of meta-controller, calledcontroller generator, that represents all possible compositions. While the set of possible compositions is infinite (in factuncountable) in general, the controller generator is unique.• The technique gives us a very precise characterization of the sources of complexity in the problem: it allows for comput-ing the controller generator (i.e., an implicit representation of all compositions) in time exponential only in the numberof available behaviors, but not in the number of their states. Observe that checking the existence of a composition isknown to be EXPTIME-hard even for deterministic available behaviors running in a stateless environment [61].• Due to its “universality”, the controller generator can be used to generate a sort of lazy composition on-the-fly, possiblyadapting reactively based on runtime feedback.In particular, we shall argue that the composition solutions obtained are robust to behavior failures in two ways. First,they can handle (a) temporary behavior unavailability as well as (b) unexpected behavior/environment evolution in atotally reactive and on-the-fly manner—that is, without any extra effort or “re-planning” required to continue the realiza-tion of the target behavior—if at all possible, by the very nature of the composition generator. Second, the compositionsolutions can be parsimoniously refined when a module (c) becomes permanently unavailable, or (d) unexpectedly re-sumes operation.We complement the proposed technique by showing how it can be implemented by making use of model checkingtechnology applied to some special game structures developed in the context of Synthesis in Computer Science [3,47,40,69,27]. To that end, we show how to polynomially encode behavior compositions into safety games of a specific form, in whicheach strategy for winning the game corresponds to a composition (Section 5). With that reduction at hand, one is then ableto use available tools such as tlv [71] in order to actually compute the controller generator by symbolic model checking(Section 6).Most results presented in this paper appeared at an earlier stage in [30,79,15,80,26]. Here we revise, extend, and combinethem into a uniform and in-depth investigation which includes all the technical details and extended example",
            {
                "entities": [
                    [
                        145,
                        185,
                        "TITLE"
                    ]
                ]
            }
        ],
        [
            "Artificial Intelligence 176 (2012) 2291–2320Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMulti-instance multi-label learningZhi-Hua Zhou∗, Min-Ling Zhang, Sheng-Jun Huang, Yu-Feng LiNational Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210046, Chinaa r t i c l ei n f oa b s t r a c tArticle history:Received 29 April 2010Received in revised form 25 September2011Accepted 13 October 2011Available online 18 October 2011Keywords:Machine learningMulti-instance multi-label learningMIMLMulti-label learningMulti-instance learningIn this paper, we propose the MIML (Multi-Instance Multi-Label learning) framework wherean example is described by multiple instances and associated with multiple class labels.Compared to traditional learning frameworks, the MIML framework is more convenientand natural for representing complicated objects which have multiple semantic meanings.To learn from MIML examples, we propose the MimlBoost and MimlSvm algorithmsbased on a simple degeneration strategy, and experiments show that solving problemsinvolving complicated objects with multiple semantic meanings in the MIML frameworkcan lead to good performance. Considering that the degeneration process may loseinformation, we propose the D-MimlSvm algorithm which tackles MIML problems directlyin a regularization framework. Moreover, we show that even when we do not haveaccess to the real objects and thus cannot capture more information from real objectsby using the MIML representation, MIML is still useful. We propose the InsDif and SubCodalgorithms. InsDif works by transforming single-instances into the MIML representationfor learning, while SubCod works by transforming single-label examples into the MIMLrepresentation for learning. Experiments show that in some tasks they are able to achievebetter performance than learning the single-instances or single-label examples directly.© 2011 Elsevier B.V. All rights reserved.1. IntroductionIn traditional supervised learning, an object is represented by an instance, i.e., a feature vector, and associated with a classlabel. Formally, let X denote the instance space (or feature space) and Y the set of class labels. The task is to learn afunction f : X → Y from a given data set {(x1, y1), (x2, y2), . . . , (xm, ym)}, where xi ∈ X is an instance and yi ∈ Y is theknown label of xi . Although this formalization is prevailing and successful, there are many real-world problems which donot fit in this framework well. In particular, each object in this framework belongs to only one concept and therefore thecorresponding instance is associated with a single class label. However, many real-world objects are complicated, whichmay belong to multiple concepts simultaneously. For example, an image can belong to several classes simultaneously, e.g.,grasslands, lions, Africa, etc.; a text document can be classified to several categories if it is viewed from different aspects,e.g., scientific novel, Jules Verne’s writing or even books on traveling; a web page can be recognized as news page, sports page,soccer page, etc. In a specific real task, maybe only one of the multiple concepts is the right semantic meaning. For example,in image retrieval when a user is interested in an image with lions, s/he may be only interested in the concept lions insteadof the other concepts grasslands and Africa associated with that image. The difficulty here is caused by those objects thatinvolve multiple concepts. To choose the right semantic meaning for such objects for a specific scenario is the fundamentaldifficulty of many tasks. In contrast to starting from a large universe of all possible concepts involved in the task, it maybe helpful to get the subset of concepts associated with the concerned object at first, and then make a choice in the* Corresponding author.E-mail address: zhouzh@lamda.nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2011 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2011.10.002\f2292Z.-H. Zhou et al. / Artificial Intelligence 176 (2012) 2291–2320small subset later. However, getting the subset of concepts, that is, assigning proper class labels to such objects, is still achallenging task.We notice that as an alternative to representing an object by a single instance, in many cases it is possible to representa complicated object using a set of instances. For example, multiple patches can be extracted from an image where eachpatch is described by an instance, and thus the image can be represented by a set of instances; multiple sections can beextracted from a document where each section is described by an instance, and thus the document can be represented by aset of instances; multiple links can be extracted from a web page where each link is described by an instance, and thus theweb page can be represented by a set of instances. Using multiple instances to represent those complicated objects may behelpful because some inherent patterns which are closely related to some labels may become explicit and clearer. In thispaper, we propose the MIML (Multi-Instance Multi-Label learning) framework, where an example is described by multipleinstances and associated with multiple class labels.Compared to traditional learning frameworks, the MIML framework is more convenient and natural for representingcomplicated objects. To exploit the advantages of the MIML representation, new learning algorithms are needed. We proposethe MimlBoost algorithm and the MimlSvm algorithm based on a simple degeneration strategy, and experiments show thatsolving problems involving complicated objects with multiple semantic meanings under the MIML framework can lead togood performance. Considering that the degeneration process may lose information, we also propose the D-MimlSvm (i.e.,Direct MimlSvm) algorithm which tackles MIML problems directly in a regularization framework. Experiments show thatthis “direct” algorithm outperforms the “indirect” MimlSvm algorithm.In some practical tasks we do not have access to the real objects themselves such as the real images and the real webpages; instead, we are given observational data where each real object has already been represented by a single instance.Thus, in such cases we cannot capture more information from the real objects using the MIML representation. Even in thissituation, however, MIML is still useful. We propose the InsDif (i.e., INStance DIFferentiation) algorithm which transformssingle-instances into MIML examples for learning. This algorithm is able to achieve a better performance than learning thesingle-instances directly in some tasks. This is not strange because for an object associated with multiple class labels, ifit is described by only a single instance, the information corresponding to these labels are mixed and thus difficult forlearning; if we can transform the single-instance into a set of instances in some proper ways, the mixed information mightbe detached to some extent and thus less difficult for learning.MIML can also be helpful for learning single-label objects. We propose the SubCod (i.e., SUB-COncept Discovery) algo-rithm which works by discovering sub-concepts of the target concept at first and then transforming the data into MIMLexamples for learning. This algorithm is able to achieve a better performance than learning the single-label examples di-rectly in some tasks. This is also not strange because for a label corresponding to a high-level complicated concept, it maybe quite difficult to learn this concept directly since many different lower-level concepts are mixed; if we can transform thesingle-label into a set of labels corresponding to some sub-concepts, which are relatively clearer and easier for learning, wecan learn these labels at first and then derive the high-level complicated label based on them with a less difficulty.The rest of this paper is organized as follows. In Section 2, we review some related work. In Section 3, we propose theMIML framework. In Section 4 we propose the MimlBoost and MimlSvm algorithms, and apply them to tasks where theobjects are represented as MIML examples. In Section 5 we present the D-MimlSvm algorithm and compare it with the“indirect” MimlSvm algorithm. In Sections 6 and 7, we study the usefulness of MIML when we do not have access to realobjects. Concretely, in Section 6, we propose the InsDif algorithm and show that using MIML can be better than learningsingle-instances directly; in Section 7 we propose the SubCod algorithm and show that using MIML can be better thanlearning single-label examples directly. Finally, we conclude the paper in Section 8.2. Related workMuch work has been devoted to the learning of multi-label examples under the umbrella of multi-label learning. Notethat multi-label learning studies the problem where a real-world object described by one instance is associated with anumber of class labels,1 which is different from multi-class learning or multi-task learning [28]. In multi-class learning eachobject is only associated with a single label; while in multi-task learning different tasks may involve different domains anddifferent data sets. Actually, traditional two-class and multi-class problems can both be cast into multi-label problems byrestricting that each instance has only one label. The generality of multi-label problems, however, inevitably makes it moredifficult to address.One famous approach to solving multi-label problems is Schapire and Singer’s AdaBoost.MH [56], which is an extensionof AdaBoost and is the core of a successful multi-label learning system BoosTexter [56]. This approach maintains a set ofweights over both training examples and their labels in the training phase, where training examples and their correspondinglabels that are hard (easy) to predict get incrementally higher (lower) weights. Later, De Comité et al. [22] used alternatingdecision trees [30] which are more powerfu",
            {
                "entities": [
                    [
                        147,
                        182,
                        "TITLE"
                    ],
                    [
                        531,
                        566,
                        "TITLE"
                    ],
                    [
                        649,
                        684,
                        "TITLE"
                    ],
                    [
                        5136,
                        5171,
                        "TITLE"
                    ]
                ]
            }
        ]
    ]
}