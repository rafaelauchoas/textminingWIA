Artiﬁcial Intelligence 128 2001 3197 Learning logic programs structured background knowledge Tamás Horváth György Turán bc German National Research Center Information Technology Institute Autonomous Intelligent Systems GMDAiS Schloß Birlinghoven D53754 Sankt Augustin Germany b Department Mathematics Statistics Computer Science University Illinois Chicago 851 S Morgan MC 249 Chicago IL 606077045 USA c Research Group Artiﬁcial Intelligence Hungarian Academy Sciences Szeged Hungary Received 12 January 2000 Abstract The efﬁcient learnability restricted classes logic programs studied PAC framework computational learning theory We develop product homomorphism method gives polynomial PAC learning algorithms nonrecursive Horn clause functionfree ground background knowledge background knowledge satisﬁes structural properties The method based characterization concept corresponds relative general generalization set positive examples respect background knowledge The characterization formulated terms products homomorphisms In applications characterization turned explicit combinatorial description translated language nonrecursive Horn clauses We nonrecursive Horn clause polynomially PAClearnable single binary background predicate ground atoms background knowledge form forest If ground atoms background knowledge form disjoint union cycles situation different shortest consistent hypothesis exponential size In case polynomial PAClearnability holds different representation language We consider complexity hypothesis ﬁnding multiple clauses restricted cases 2001 Elsevier Science BV All rights reserved An extended abstract paper appeared L De Raedt Ed Proceedings Fifth International Workshop Inductive Logic Programming Tokyo Japan 1995 pp 5376 Scientiﬁc Report Department Computer Science Katholieke Universiteit Leuven postconference volume L De Raedt Ed Advances Inductive Logic Programming IOS Press AmsterdamOhmsha Tokyo 1996 pp 172191 Corresponding author Email addresses tamashorvathgmdde T Horváth gytuicedu G Turán 0004370201 matter 2001 Elsevier Science BV All rights reserved PII S 0 0 0 4 3 7 0 2 0 1 0 0 0 6 2 5 32 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Keywords Computational learning theory PAC learning Concept learning Inductive logic programming VCdimension 1 Introduction The theoretical study efﬁcient learnability developed separate ﬁeld research ﬁfteen years motivated increasing importance learning practical applications Several learning problems propositional logic automata theory geometry investigated great There increasing number results learnability predicate logic area appears understood general This partly large number possible restrictions consider order obtain learnable fragment predicate logic Learning logic programs referred inductive logic programming 4647 proved successful approach practical applications 39 Positive negative results efﬁcient learnability classes logic programs given example 25714343654 Surveys area given 937 A detailed exposition book 53 Other papers learnability predicate logic deal description logic 818 formalisms 132443446163 A comparison different frameworks given 12 Related generalization problems studied structural context functions algebraic properties associativity commutativity 5859 In formulation learning problems logic programs assumed function symbols background knowledge consists ground atoms background predicates examples ground atoms target predicate 5 14 In paper use assumptions We present learning algorithms nonrecursive Horn clauses use fact general generalizations LGG represented products This relationship mentioned seminal papers Plotkin 5657 study computational aspects The relevance products shown fact related contexts example 81834 It holds concept generated set positive examples respect background knowledge characterized existence certain homomorphism Thus products homomorphisms provide general learning method product homomorphism method enable use algebraic combinatorial tools ﬁnding characterization existence homomorphism translating characterization language nonrecursive Horn clauses Besides providing efﬁcient algorithms approach contributes understanding LGG relative LGG operators work 2 The results paper examples method obtain positive results Since 2 For example provides interesting examples LGG given Plotkins algorithm large reduced examples reduced compact representation It point Plotkins proof existence LGG complicated products provide straightforward argument function symbols T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 33 publication extended abstract paper 31 given application 29 considered noise version problem 30 In learning problems studied paper structural assumptions background knowledge In practical applications assumptions justiﬁed background knowledge structural properties known advance exploited learning process 3 This occur example background predicate successor relation In particular assume background knowledge consists ground atoms single binary background predicate represented directed graph We study cases connected components graph paths trees cycles In basic cases product homomorphism method outlined ﬁrst leads combinatorial characterization concept deﬁned relative LGG set positive examples respect background knowledge This characterization translated short Horn clause deﬁnition evaluated efﬁciently Thus efﬁcient hypothesis ﬁnding algorithm algorithm ﬁnds hypothesis consistent given set examples In order efﬁcient learning algorithms PAC Probably Approximately Correct model learning 62 needs upper bounds sample size estimating VapnikChervonenkis dimension concept classes A polynomial upper bound quantity given byproduct characterization results We improve bounds providing better ones sharp order magnitude The combinatorial arguments independent We note restrictions background knowledge related notion determinateness obtain positive results inductive logic programming 514 In particular having background knowledge consisting paths cycles implies determinateness On hand case forests clauses necessarily determinate Another important difference assume bound depth clauses considered The treestructured determinations studied 60 represent dependencies attributes form different approach background knowledge In case target deﬁnition consist multiple clauses problem appears difﬁcult We consider problem hypothesis ﬁnding turns polynomially solvable background knowledge union paths target predicate unary NPcomplete background knowledge forest union cycles target unary Finally note open problems suggested approach Some mentioned end paper The paper organized follows Section 2 contains necessary deﬁnitions logic learning theory graph theory In Section 3 running example illustrating learning problems discussed In Sections 46 introduce product homomorphism method In Sections 4 5 discuss reformulation LGG relative LGG terms products homomorphisms Section 6 state 3 Another way kind additional information assume background knowledge background knowledge 34 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 product homomorphism theorem main combinatorial tool ﬁnding target clause Sections 79 contain applications product homomorphism method cases background knowledge consists paths trees cycles respectively Although paths special cases trees discussed separately partly permit simpliﬁed characterization partly case positive result proved multiple clause hypothesis ﬁnding This extension discussed Section 10 Section 11 contains remarks open problems Some proofs given appendix 2 Preliminaries In section notions logic learning theory graph theory paper 152733414253 21 Logic Let P R1 Rr predicate symbols arities m m1 mr respectively P distinguished predicate called target predicate R1 Rr background predicates We allow function symbols vocabulary In addition assume constants a1 A term t variable constant An atomic formula atom form P t1 tm Ri t1 tmi ts terms A literal atom negation We atom literal P atom P literal predicate symbol P Similarly speak Ri atoms Ri literals A clause disjunction literals thought set literals The size clause number literals contains An atom literal clause ground contain variables An atom referred unit clause ground unit clauses called facts We consider deﬁnite nonrecursive Horn clauses form L0 L1 Ll 1 L0 P atom Li Rji atom ji 1 cid1 ji cid1 r 1 l l cid2 0 In follows clauses type referred basic clauses A substitution θ x1t1 xsts mapping variables terms xj cid6 tj j 1 s A clause C subsumes generalizes clause D denoted C cid1θ D substitution θ Cθ D Clauses C D equivalent C cid1θ D D cid1θ C A clause reduced equivalent proper subsets A clause C general generalization LGG set clauses D1 Dt C generalization Di C cid1θ Di 1 t Ccid9 generalization D1 Dt Ccid9 generalization C A selection set clauses D1 Dt function assigns clause literals literals sign negated unnegated predicate symbol A structure M predicates P R1 Rr constants a1 given r U universe U interpretation P R1 Rr relations P M RM 1 RM T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 35 n U having arities m m1 mr respectively interpretation a1 elements 1 aM aM The product structures M1 Mt universes U1 Ut denoted M M1 Mt The universe M U U1 Ut The interpretation relations following For cid12b1 cid12bm U m cid12bj b1j btj j 1 m holds P M cid12b1 cid12bm tcid1 i1 P Mi bi1 bim 2 The interpretation RM aM1 aMt ai aM referred nonconstants 1 r analogous The interpretation constant Those elements U interpretations constants b1 bmi implies RM2 A homomorphism structure M1 structure M2 mapping ϕ universe U1 M1 universe U2 M2 preserving relations constants Thus P M1 b1 bm implies P M2 ϕb1 ϕbm b1 bm U m 1 ϕb1 ϕbmi b1 bmi U mi RM1 1 1 r Furthermore interpretation ai M1 mapped interpretation ai M2 ϕaM1 1 n If homomorphism M1 M2 write M1 M2 A projection product component homomorphism A homomorphism rooted mapping ϕ speciﬁed advance nonempty subset U1 called roots If rooted homomorphism M1 M2 mapping ai bi 1 k write M1 cid16a1b1akbkcid17 M2 aM2 A homomorphism single respectively doubly multiply rooted number roots respectively 22 Learning A learning problem speciﬁed domain instance space set concepts forming concept class In paper consider ﬁnite domains Each concept subset domain Concepts usually formal representation The goal learning algorithm identify unknown target concept concept class The precise meaning identiﬁcation precise deﬁnition learning algorithm given specifying model learning In rest subsection ﬁrst concept classes studied paper outline models learning considered A set B ground atoms background predicates referred background knowledge B viewed structure universe UB a1 The relations RB contain tuples b1 bmi corresponding facts Ri b1 bmi B Each constant interpreted The background knowledge B said equal Herbrand base background predicates constants a1 Thus background knowledge contains ground atoms background predicates 36 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 The domain instance space set ground atoms target predicate P A different approach called learning entailment studied 12161734 A concept represented deﬁnite nonrecursive Horn clause C For clause C consider logic program consisting C ground unit clauses belonging B The concept CB represented C respect B set ground atoms target predicate P implied logic program The problem deciding ground atom implied logic program undecidable general Without function symbols problem decidable If furthermore logic program consists single deﬁnite nonrecursive Horn clause set ground atoms problem NP NPcomplete See 10 detailed discussion complexity logic programs In case discussed paper follows results membership hypotheses produced decided polynomial time Clauses C D concept equivalent respect B CB DB clauses represent concept respect background knowledge The concept class CBm set concepts CB corresponding deﬁnite nonrecursive Horn clauses C m denotes arity target predicate P Thus CBm depends background knowledge arity target predicate 4 The parameters measure size learning problem m arity target predicate n number constants B The arity background predicates taken consideration It omitted cases considered paper constant Another point note size clauses bounded advance introduce size target concept parameter It follows characterizations provided Theorems 27 43 57 concept representation size polynomial m n Thus polynomial PAClearnability holds present version These deﬁnitions standard 53753 Using deﬁnitions introduce usual formal models learnability PAClearnability 62 The description informal details given 33 Positive negative examples ground atoms target predicate P labeled according classiﬁcation respect target concept In PAC model assumed ﬁxed unknown probability distribution domain A learning algorithm works drawing sequence random examples respect probability distribution outputting hypothesis concept class When deﬁning polynomial PAClearnability considers family learning problems For example consider family learning problems form CBm single binary background predicate facts belonging B form forest 5 A family learning problems polynomially PAClearnable polynomial pm n 1ε 1δ learning algorithm inputs m n ε δ running time p following holds For learning problem belongs family 4 Considering B structure deﬁne CBm class mary relations deﬁnable existentially quantiﬁed conjunction atoms 5 A set classes called school context learning theory T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 37 having parameters m n ε 0 δ 0 target concept probability distribution domain probability error hypothesis output algorithm inputs m n ε δ ε δ Here error hypothesis probability set misclassiﬁed instances The VapnikChervonenkis dimension VCdimension concept class CBm denoted VCdimCBm size largest shattered subset domain A subset shattered dichotomies realized concept As number concepts large number subsets largest shattered subset holds VCdimension concept class base 2 logarithm number concepts class 3 An important aspect learning computational task hypothesis ﬁnding Given set positive negative examples unknown target concept task ﬁnd consistent hypothesis concept classiﬁes example way label In order prove polynomial PAClearnability use following basic result computational learning theory 325 Theorem 1 A family learning problems polynomially PAClearnable VC dimension concept classes bounded polynomial parameters hypothesis ﬁnding problem solved polynomial time parameters In view 3 order polynomial upper bound VCdimension sufﬁcient logarithm number concepts class polynomial learning parameters Concerning converse theorem results showing polynomiality VCdimension necessary polynomial PAClearnability negative results NPcompleteness hypothesis ﬁnding problem imply non PAClearnability suitable complexity theoretic assumptions RP cid6 NP 25 55 221 Intersection closed concept classes A concept class closed intersection intersection set concepts belongs concept class This property related learnability onesided error 19 cited 33 4951 The concept classes considered paper closed intersection In subsection formulate characterization VCdimension intersection closed concept classes proving upper bounds VCdimension Sections 79 6 Let S subset domain intersection closed concept class assume S contained concept Then consider intersection concepts 6 In upper bounds use Corollary 3 direct consequence simpler half characterization Both halves included characterization The characterization holds inﬁnite classes state generality paper consider ﬁnite classes We able ﬁnd result literature 38 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 containing S This concept denoted GS called concept containing S concept generated S The mapping G referred closure operator standard properties S GS ii S1 S2 implies GS1 GS2 iii GGS GS 11 Theorem 2 The VCdimension intersection closed concept class smallest number d concept ﬁnite subset S concept Scid9 S GScid9 GS Scid9 cid1 d Proof Let S ﬁnite shattered set Then S subset concept Furthermore Scid9 cid1 S GScid9S Scid9 Otherwise concept containing Scid9 containing element GScid9 S Scid9 S shattered Thus GScid9 cid1 GS This implies VCdimension inﬁnite d inﬁnite If VCdimension ﬁnite equal d cid9 follows d cid9 cid1 d For direction let assume VCdimension ﬁnite equal d cid9 We ﬁnite subset S concept Scid9 S GScid9 GS Scid9 cid1 d cid9 Let S ﬁnite subset concept assume GScid9 cid1 GS Scid9 S Scid9 cid1 d cid9 Let Scid9 S Scid9 cid1 d cid9 GScid9 maximal Then S cid2 GScid9 GS GGScid9 GScid9 GS GScid9 Consider element S GScid9 It case Scid9 d cid9 Scid9 d cid9 GScid9 cid3 GScid9 contradicting maximality GScid9 We claim Scid9 shattered Otherwise Scid9 contained concept Y Scid9 b Scid9 Y concept containing Y contains b follows b GScid9 b But GScid9 b GScid9 GScid9 b GGScid9 b GScid9 GScid9 b cid3 GScid9 contradicting maximality GScid9 Now Scid9 shattered Scid9 d cid9 set Scid9 shattered As Scid9 contained concept Z cid1 Scid9 c Scid9 Z concept containing Z contains c Otherwise Z cid1 Scid9 obtains concept intersecting Scid9 Z forming intersection concepts containing Z omitting c c Scid9 Z Hence c GZ Now c cid6 GScid9 But GScid9 c G cid2 GScid9 c cid3 GScid9 cid3 GScid9 contradicting maximality GScid9 Thus d cid1 d cid9 Corollary 3 Let C intersection closed ﬁnite concept class domain belongs C Assume subset S domain Scid9 S GScid9 GS Scid9 cid1 d Then VCdimension concept class d 222 Learning simple logic programs As mentioned earlier Sections 79 assumed background predicate learning task binary predicate R The background T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 39 knowledge B consists facts form Rai aj ai aj 1 cid1 j cid1 n constants In case B represented directed graph vertices a1 edges ai aj corresponding facts Rai aj B In learning problems considered assumed directed graph speciﬁc structure We discuss cases disjoint union paths forest disjoint union cycles A forest disjoint union trees trees assumed edges directed root A disjoint union paths respectively cycles referred path graph respectively cycle graph Logic programs consisting single deﬁnite nonrecursive Horn clause ground unit clauses single binary background predicate B referred simple logic programs Thus sections discuss learning simple logic programs 23 Graphs graph products homomorphisms In paper consider directed graphs Let G V E directed graph Gv respectively vertex set V edge set E Let v vertex G The outdegree d indegree d G v v number edges leaving v respectively entering v The length directed path number edges A walk directed path contain vertex edge A connected component G connected component undirected graph obtained G replacing directed edges undirected ones Let Gi Vi Ei directed graphs 1 t As directed graph structure single binary relation E products homomorphisms directed graphs special cases deﬁnitions given Section 21 For readers convenience repeat cid4 t deﬁnition product The product G G1 Gt denoted i1 Gi cid4 t i1 Vi A pair cid12u cid12v u1 ut v1 vt directed graph vertex set edge G ui vi Ei 1 t The following propositions standard properties graph products Proposition 4 Let G1 Gt directed graphs G vertex G Then cid4 t i1 Gi let cid12u u1 ut d Gcid12u tcid5 i1 d Gi ui d Gcid12u tcid5 i1 d Gi ui Proof To outdegree note cid12v v1 vt cid12u cid12v Gui neighbors ui 1 t Thus number edge G vi d choices cid12v ui The case indegree analogous cid4 t i1 d Gi Now natural correspondence walks graphs Gi walks product times follows Let vi1 vis1 walk length s Gi 1 t let cid12vj v1j vtj product j th vertices walks j 1 s 1 Then vertices cid12v1 cid12vs1 form walk length s G Indeed consider cid12vj v1j vtj cid12vj 1 v1j 1 vtj 1 j 1 s Then cid12vj cid12vj 1 edge G deﬁnition product Conversely 40 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 vertices cid12v1 cid12vs1 cid12vj v1j vtj j 1 s 1 form walk G vertices vi1 vis1 form walks length s Gi 1 t This follows deﬁnition product The following proposition implied directly correspondence A directed graph acyclic contains directed cycles Proposition 5 Let G1 Gt directed graphs G exists 1 cid1 cid1 t Gi acyclic cid4 t i1 Gi Then G acyclic Proof We ﬁrst Gi contains directed cycle G contains directed cycle Let Ci directed cycle length li Gi 1 t let L lcml1 lt common multiple li s The walk obtained going Ci L li times length L The previous remark implies product walks walk length L This walk closed endpoints identical Hence G contains directed cycle For converse let assume G contains directed cycle Using correspondence follows Gi contains closed walk Thus contains simple cycle Proposition 6 Let G1 G2 directed graphs let ϕ homomorphism G1 G2 If walk length d b c G1 walk length d ϕb ϕc G2 Proof This follows directly deﬁnition homomorphism 3 A running example Throughout Sections 47 going use following example Example 7 Let assume 10 objects a1 a2 a10 n 10 background knowledge database B consists complete description binary relation R objects The following facts listed B example Ra1 a2 Ra2 a3 Ra3 a4 Ra5 a6 Ra6 a7 Ra7 a8 Ra8 a9 Ra9 a10 Since R binary B considered directed graph V E V a1 a10 b E Ra b B In case B special structure path graph consisting disjoint directed paths Fig 1 Fig 1 The structure binary relation R T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 41 Let assume like learn unknown ternary target predicate P objects a1 a2 a10 The instance space considered example set cid7 cid6 P ai aj ak 1 cid1 j k cid1 10 X Since background predicate R example concept class CBm m 3 consists subsets X represented functionfree nonrecursive Horn clause form C P R R 4 respect B Thus given target concept CBm ε δ 0 order ﬁnd probably approximately correct hypothesis CBm ﬁnd clause form 4 consistent sufﬁciently large number randomly chosen ground P atoms labeled according target concept In Section 7 sample complexity case B path graph bounded polynomial pm 1ε 1δ independently n The rest example devoted illustrating hypothesis ﬁnding learning process The standard approach try ﬁnd hypothesis clause corresponding concept contains given positive atoms generalizes small possible general generalization relative background knowledge In follows formulate related combinatorial approach provides polynomial size clause concept equivalent relative general generalization respect background knowledge Suppose positive examples negative example A 1 P a2 a9 a4 A 2 P a7 a1 a9 A 1 P a6 a2 a7 The goal ﬁnd consistent clause C form 4 clause satisﬁes 1 CB Since examples labeled respect A target concept clause exists deﬁnition CB A 1 A 2 In Section 6 concept class CBm closed intersection CBm concept generated This means concept GBA 1 A positive examples respect B intersection concepts containing positive examples Thus GBA subset target concept consistent examples Our strategy solving hypothesis ﬁnding problem This clause concept equivalent ﬁnd clause represents GBA 1 A relative general generalization respect background knowledge In Section 7 algorithm computes clause 1 A 2 2 2 C P x1 x2 x3 Ry1 x1 Rx1 y2 Ry2 x3 Rx2 y3 possible solution problem Intuitively clause C says triple b c target concept child grandchild c b father Indeed holds P a2 a9 a4 P a7 a1 a9 hold P a6 a2 a7 a6 grandchild a7 42 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 4 Products general generalizations In section discuss reformulation general generalization terms products homomorphisms This basis combinatorial approach subsequent sections ﬁnd efﬁcient learning algorithms Unlike rest paper section consider general clauses restrict Horn clauses 41 Representation clauses structures Let C clause containing variables X x1 xs We represent C structure MC universe UC X a1 Thus variables xi constants aj considered elements universe UC MC Each predicate interpreted relations corresponding positive negative occurrences clause Thus deﬁne relations P MC P MC RMC 1 r UC For P atom C mtuple formed arguments belongs P MC negated P atom C mtuple formed arguments belongs P MC We recall m arity P The deﬁnition relations RMC similar Each constant interpreted aMC ai 1 n We note exception section paper C deﬁnite nonrecursive Horn clause case relations P MC RMC 1 r RMC RMC Example 8 Consider ground Horn clause C P a2 a9 a4 Ra1 a2 Ra2 a3 Ra3 a4 Ra5 a6 Ra6 a7 Ra7 a8 Ra8 a9 Ra9 a10 Cs head body constructed running Example 7 head positive examples body corresponds background knowledge B As C contain variables universe UC structure MC a1 a10 Each constant ai C interpreted element ai UC 1 10 The interpretation predicates P R deﬁned relations cid6 P MC RMC a2 a9 a4 cid7 P MC cid6 RMC a1 a2 a2 a3 a3 a4 42 Products clauses a8 a9 a9 a10 a5 a6 a6 a7 a7 a8 cid7 Let consider structures MD1 MDt clauses D1 Dt respectively MDt structures universe UDt described Section 2 In order interpret M structure One form product M MD1 U UD1 MD clause D replace ttuple aM ai 1 n T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 43 nonconstant cid12u u1 ut variable xcid12u delete elements belong tuple relations Thus subscript cid12u xcid12u ttuple variables constants The structure obtained transformation form MD clause D This clause D called product clauses D1 Dt write D D1 Dt Example 9 Consider clauses D1 P a2 a9 a4 B D2 P a7 a1 a9 B constructed positive examples background knowledge B given running Example 7 Here B bodies represents list ground atoms belonging B shown Example 8 Let MD1 MD2 structures clauses D1 D2 respectively Then universe product M MD1 MD2 U ai aj 1 cid1 j cid1 10 The interpretation predicates P R cid6cid2 P M RM a2 a7 a9 a1 a4 a9 cid3cid7 P M cid6cid2 RM cid3 a1 a1 a2 a2 cid3 cid2 a1 a2 a2 a3 cid7 Relation RM contains 64 elements given slanted edges Fig 2 Let cid12u u1 u2 cid12v v1 v2 elements U Then RMcid12u cid12v true edge Fig 2 cid12u cid12v Now ready construct structure MD M The universe MD xaiaj 1 cid1 cid6 j cid1 10 UD a1 a10 cid6 xa1a4 xa1a10 xa4a1 xa4a5 xa5a4 xa5a10 xa10a1 xa10a5 cid7 cid6 cid7 Instead deﬁning interpretation P R MD product clause D D1 D2 We list literals body correspond dotted edges Fig 2 cid2 P cid3 xa2a7 xa9a1 xa4a9 Ra1 a2 R cid2 xa1a2 xa2a3 cid3 cid2 cid3 R xa1a3 xa2a4 43 Least general generalizations products It shown Plotkin 56 ﬁnite set clauses LGG 7 In function free case follows following statements Proposition 10 Let C1 C2 clauses Then C1 cid1θ C2 MC1 MC2 7 This usually stated clauses having selection If clauses selection clause LGG 44 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Fig 2 The interpretation RM R M MD1 MD2 MC2 Then exists function ϕ UC1 Proof Suppose MC1 preserving relations constants Let θ substitution C1 deﬁned UC2 xz θ x VarC1 ϕx z x cid6 z VarC1 set variables C1 Since ϕ homomorphism follows construction MC1 MC2 C1θ C2 onlyif Suppose C1 cid1θ C2 Then exists substitution θ form θ x1z1 xszs C1θ C2 Let mapping ϕ UC1 UC2 deﬁned follows cid8 ϕz zcid9 z zzcid9 θ Clearly ϕ homomorphism Proposition 11 Let D1 Dt clauses Then D D1 Dt D1 Dt LGG Proof First D generalization Di 1 t By Proposition 10 sufﬁcient prove MD MDi As noted Section 21 follows considering projection Thus let mapping ϕi UD UDi deﬁned ϕiz cid8 ui z z xcid12u cid12u u1 ut z a1 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 45 Obviously ϕi preserves constants By deﬁnitions product structures product clauses b1 bm U m MD holds P MD b1 bm P MDi cid2 ϕib1 ϕibm cid3 tcid1 i1 cid3 P MD b1 bm P MDi cid2 ϕib1 ϕibm 1 t The argument applies Rj s j 1 r Thus ϕi homomorphism 1 t It remains proven Dcid9 generalization clauses D1 Dt Dcid9 generalization D Suppose Dcid9 cid1θ Di 1 t Then MDcid9 MDi Proposition 10 Let function ϕi UDcid9 UDi homomorphism consider mapping ϕ UDcid9 UD deﬁned ϕz xϕ1zϕt z z z variable ϕ1z ϕt z constant Then ϕz UD z VarDcid9 ϕ deﬁned Furthermore b1 bm U m MDcid9 holds tcid1 P MDcid9 b1 bm P MDi cid2 ϕib1 ϕibm cid3 i1 P MD cid2 ϕb1 ϕbm cid3 5 6 Implication 5 follows fact ϕi homomorphism equivalence 6 holds construction MD The argument applies Rj s j 1 r As ϕ preserves constants MDcid9 MD Thus Dcid9 cid1θ D follows Proposition 10 It noted D clause constructed Plotkins algorithm 56 As noted D1 Dt selection D clause LGG D1 Dt If D1 Dt selection D nonempty In general D reduced 5 Products relative general generalizations The notion subsumption extended subsumption respect background knowledge 44857 We formulate special case sufﬁcient discussion In section consider Horn clauses Let C basic clause deﬁnite nonrecursive Horn clause form 1 A ground P atom let background knowledge B set ground atoms background predicates Then C subsumes A respect background knowledge 46 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 B denoted C cid1θB A logic program consisting C ground atoms B implies A The terminology notation deﬁnition justiﬁed Proposition 12 We denote A B clause head A body consisting ground atoms B The following proposition special case general result 4 established directly More proposition implications example case B inﬁnite given 48 Proposition 12 Let C basic clause A ground P atom B set ground atoms background predicates Then C cid1θB A C cid1θ A B Proof This direction follows directly deﬁnitions θ subsumption semantics logic programs onlyif By deﬁnition C cid1θB A A true Herbrand model MCB logic program C B 41 Since C form 1 B consists ground Ri atoms ground Ri atom belongs MCB belongs B Hence exist substitution θ Cheadθ A Cbodyθ B 8 Now extending notion subsumption similarly extend notion LGG relative LGG respect background knowledge Let A1 At ground P atoms Then deﬁnite nonrecursive Horn clause C relative general generalization RLGG A1 At respect background knowledge B C cid1θB Ai 1 t Ccid9 cid1θB Ai 1 t Ccid9 cid1θ C Proposition 13 Let Di clause Ai B 1 t Ai ground P atom B set ground atoms background predicates Then D D1 Dt RLGG A1 At respect B Proof We ﬁrst note construction D basic clause By Proposition 11 D LGG clauses Ai B 1 cid1 cid1 t Hence 1 t D cid1θ Ai B equivalent D cid1θB Ai Proposition 12 Let Dcid9 clause Dcid9 cid1θB Ai 1 t Applying Proposition 12 Dcid9 cid1θ Ai B 1 t Since D LGG clauses Ai B 1 cid1 cid1 t holds Dcid9 cid1θ D This proposition provides general method ﬁnding relative general generalization set ground atoms respect ground background knowledge 44857 The clause obtained exponential size general In cases reduced ﬁnding reduced clause difﬁcult computational problem 8 We note proposition follows directly Theorem 6 20 As C nonrecursive deﬁnite Horn clause selfresolving Furthermore A B tautological C A B equivalent C cid1θ A B T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 47 One general goals work ﬁnd cases process efﬁcient utilizing structural information available background knowledge 6 From RLGGs hypothesis ﬁnding In section apply previous considerations RLGGs concept learning problem formulated Section 22 First Section 61 observed concept classes closed intersection additional assumption intersection nonempty necessary case background knowledge contains possible facts Thus noted Section 221 deﬁne concept generated set ground P atoms respect background knowledge intersection concepts containing atoms It observed Section 62 clause representing generated concept obtained RLGG atoms respect background knowledge The goal efﬁciently ﬁnd clause concept equivalent RLGG 9 This leads solution hypothesis ﬁnding problem ﬁnd clause consistent given set examples clause exists output follows consistent hypothesis exists clause representing concept generated positive examples respect background knowledge hypothesis In order ﬁnd clause state Section 63 product homomorphism theorem reformulation terms products homomorphisms This main tool rest paper ﬁnding efﬁcient learning algorithms lines sketched 61 The concept classes CBm The concepts CB deﬁned Section 22 In terms subsumption respect background knowledge introduced previous section deﬁnition rewritten follows CB cid6 P b1 bm C cid1θB P b1 bm cid7 Proposition 12 provides useful reformulation deﬁnition ordinary subsump tion This reformulation stated proposition deﬁnition concept classes 37 Proposition 14 Let C basic clause B set ground atoms background predicates Then CB P b1 bm C cid1θ P b1 bm B Proof It follows directly Proposition 12 9 We note clause necessarily equivalent let B Ra1 a2 Ra2 a1 consider RLGG D P y1 y2 Ry1 y2 Ry2 y1 Ra1 a2 Ra2 a1 P a1 a2 P a2 a1 respect B Let C denote basic clause P x1 x2 Rx1 x2 Although C D concept equivalent CB DB equivalent D cid6cid1θ C RLGG For instance 48 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Corollary 15 Let C1 C2 basic clauses B set ground atoms background predicates Then C2B C1B C1 cid1θ C2 Proof Let P b1 bm C2B Since C1 cid1θ C2 cid1θ P b1 bm B P b1 bm C1B Proposition 14 The following example shows converse Corollary 15 true general Example 16 Consider background knowledge B consisting following facts binary predicate R constants a1 a2 Ra1 a1 Ra1 a2 Ra2 a1 Let clauses C1 C2 deﬁned follows C1 P x1 Ra1 x1 C2 P x2 Ra2 x2 Although holds C2B P a1 P a1 P a2 C1B C1 subsume C2 Now turn intersection closure property concept classes CBm First note B contains ground atoms background predicates basic clause C L0 L1 Ll exists substitution θ L0θ ground L1 Llθ B Hence case CBm Consider unit clauses C1 P b1 C2 P b2 b1 b2 different mtuples constants assuming n 1 Since C1B C2B concept class CBm closed intersection case background knowledge 10 On hand following proposition shows examples background knowledge Theorem 17 Let B set ground atoms background predicates If B CBm closed intersection Proof First CBm theorem holds concepts intersection As B ground atom Rsb1 bms s a1 Rs b1 bms B Consider 1 cid1 s cid1 r b1 bms clause C P t1 tm Rs b1 bms Clearly CB 10 Learning CBm B equivalent learning mary atom background knowledge T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 49 Now theorem concepts disjoint It sufﬁcient consider intersection concepts Let C1B C2B concepts CBm C1B C2B cid6 Suppose Ci form P ti1 tim Li1 Lili 7 tij s terms 1 2 j 1 m C1 C2 assumed variable disjoint The set variables constants occurring head C1 C2 denoted T 11 Let ρ denote transitive closure relation cid6 ti1j ti2j ti1j ti2j T i1 i2 1 2 j 1 m cid7 Clearly ρ equivalence relation T For given t T let tρ denote equivalence class ρ containing t Since concepts C1B C2B disjoint heads clauses C1 C2 uniﬁable 12 Let σ substitution satisfying P t11 t1mσ P t21 t2mσ From deﬁnition ρ follows σ uniﬁer terms belonging tρ t T tρσ 1 Hence tρ contain constant Furthermore contains constant σ map variable tρ constant This property ρ fact C1 C2 variable disjoint following construction uniﬁer θ heads C1 C2 Let ϕ function deﬁned set equivalence classes ρ cid8 ϕtρ new variable x tρ a1 term t T consider clause C C1θ C2θ cid6 tϕtρ t T a1 cid7 θ 8 From deﬁnition ρ θ follows t1j θ t2j θ j 1 m Hence θ uniﬁes heads C1 C2 C basic clause 11 The proof presented careful consideration general uniﬁer 66 heads C1 C2 For sake completeness selfcontained argument 12 A set literals respectively terms uniﬁable substitution maps literal respectively term 50 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 We CB C1B C2B A CB C cid1θ A B γ Cγ A B γ C1θ C2θ γ A B γ C1θ γ A B C2θ γ A B C1 cid1θ A B C2 cid1θ A B A C1B C2B Proposition 14 deﬁnition cid1θ 8 9 Proposition 14 We prove equivalence 9 Its onlyif follows directly deﬁnition cid1θ Suppose C1 cid1θ A B C2 cid1θ A B Then substitutions γ1 γ2 C1γ1 C2γ2 A B Since C1 C2 variable disjoint γ1 γ2 substitution unifying heads C1 headγ1 γ2 C2 headγ1 γ2 A Since A ground atom tργ1 γ2 constant t T Consider substitution cid6 cid7 cid3 t T ϕtρ variable γ1 γ2 γ cid2 ϕtρ tργ1 γ2 By deﬁnition θ γ x1γ1 x1θ γ x2γ2 x2θ γ variable x1 C1 x2 C2 Hence C1γ1 C1θ γ C2γ2 C2θ γ C1θ γ C2θ γ A B If intersections required nonempty closure property holds general Corollary 18 CBm closed nonempty intersections Proof The second half proof repeated modiﬁcation 62 The concept generated set ground atoms Let S A1 At nonempty set ground P atoms B background knowledge Corollary 18 implies intersection concepts containing A1 At belongs CBm 13 This intersection denoted GBS called concept generated S Thus cid12 GBS CB CBm S CB 13 Note set ground P atoms deﬁned clause P x1 xm belongs CBm T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 51 The following theorem provides clause representation GBS Theorem 19 Let S A1 At nonempty set ground P atoms B background knowledge Di clause Ai B 1 t Then concept DB corresponding D D1 Dt holds DB GBS Proof By Corollary 18 exists basic clause Dcid9 Dcid9 B GBS Thus Dcid9 cid1θ Ai B 1 t Proposition 14 Since D RLGG A1 At respect B Proposition 13 Dcid9 cid1θ D Hence DB Dcid9 B holds Corollary 15 Let A GBS By Proposition 14 C cid1θ A B C generalization Ai B 1 t Since D LGG Ai B 1 t Proposition 13 applies D Hence D cid1θ A B A DB 63 The product homomorphism theorem The problem ﬁnding consistent hypothesis following given positive examples A1 At negative examples B1 Bs ﬁnd concept CB contains positive examples negative examples answer concept exist It follows Corollary 18 Theorem 19 consistent hypothesis clause representing GBA1 At hypothesis In order ﬁnd clause like combinatorial reformulation problem The following result main tool solving hypothesis ﬁnding problem rest paper We recall M1 cid16a1b1akbkcid17 M2 denotes rooted homomorphism M1 M2 mapping ai bi 1 k Theorem 20 Product homomorphism theorem Let B background knowledge S nonempty set cid6 P b11 b1m P bt1 btm cid7 consisting ground atoms Let cid12bj denote ttuple b1j btj j 1 m Then GBS cid6 P b1 bm Bt cid16cid12b1b1cid12bmbmcid17 B cid7 Proof Let A P b1 bm let ϕ rooted homomorphism structure Bt structure B mapping cid12bj bj j 1 m Let substitution θ deﬁned xcid12ut θ ϕcid12u t cid12u u1 ut nonconstant It follows construction D previous subsection Dθ A B Applying Proposition 14 Theorem 19 A GBS 52 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Suppose A P b1 bm GBS By Theorem 19 holds DB GBS From Proposition 14 follows D cid1θ A B Let θ denote substitution Dθ A B Let mapping ϕ Bt B deﬁned cid8 ϕcid12u ai xcid12uθ cid12u aBt 1 cid1 cid1 n It follows construction D mapping ϕ homomorphism Bt B Ds head P t1 tm tj variable xcid12bj b1j btj identical constant ai b1j btj ai j 1 m In ﬁrst case θ bj In second case hold bj ai In cases ϕcid12bj bj xcid12bj required This theorem suggests following general method called product homomorphism method 1 Find combinatorial characterization existence required rooted homomorphism 2 Translate characterization efﬁciently evaluable Horn clause represen tation In Sections 79 present examples learning simple logic programs steps carried successfully leading efﬁcient hypothesis ﬁnding algorithms In case forest background knowledge clause obtained equivalent RLGG short possible relatively easy A direct application method Proposition 13 produce clause polynomial size exponential time process reducing large clause Furthermore combinatorial interpretation leads hypothesis natural transparent way Without approach reduced clause clause polynomial size hard ﬁnd Example 21 As application previous theorem exists consistent hypothesis running example Suppose contradiction negative example belongs concept generated positive examples B P a2 a9 a4 P a7 a1 a9 P a6 a2 a7 GB 10 cid3 cid2 By Theorem 20 rooted homomorphism ϕ B B B mapping a2 a7 cid30 a6 a9 a1 cid30 a2 a4 a9 cid30 a7 Since ϕ homomorphism map Fig 2 a3 a8 a7 a4 a9 a8 contradiction 631 A remark role constants structures versus graphs Before turning applications method small modiﬁcation simpliﬁes discussion In special case binary background predicate case simple logic programs B Bt considered directed graphs Let Bg graph represent B Sections 39 That cases T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 53 Bg denotes directed graph a1 R In order rooted homomorphism structure Bt structure B mapping elements cid12b1 cid12bm universe Bt elements b1 bm universe B respectively homomorphism graph Bgt Bg mapping product vertices cid12b1 cid12bm vertices b1 bm respectively mapping product constant cid12ai ai ai ai 1 n Bt cid16cid12b1b1cid12bmbmcid17 B Bgt cid16cid12b1b1cid12bmbmcid12a1a1cid12anancid17 Bg 11 cid12ai denotes ttuple ai ai 1 n 14 We consider homomorphisms form specifying product constants roots Hence study rooted homomorphisms graph products In form hope use large number related techniques results graph theory 224252 632 An application VCdimension As ﬁrst application Theorem 20 formulate Lemma 22 Corollary 23 general lower bounds VCdimension concept classes CBm later concept classes studied Sections 79 The proof following lemma Appendix A Lemma 22 Let B background knowledge P unary predicate symbol a0 a1 ad constants S P a1 P ad shattered CB1 ii P ai GBP a0 P ai1 P ai1 P ad 1 d Then VCdimCBm cid2 md Corollary 23 For background knowledge B holds VCdimCBm cid2 m cid2 VCdimCB1 1 cid3 Proof Let VCdimCB1 d 1 let S P a0 set shattered CB1 cid6 P a1 P ad cid7 S Then conditions Lemma 22 hold VCdimCBm cid2 md m cid2 VCdimCB1 1 cid3 In cases considered paper lower bound turns sharp constant factor We know holds general 14 This notation consistent graphs considered structures vocabulary consisting single binary predicate constants 54 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 7 Path graph background knowledge As ﬁrst application product homomorphism method consider learning simple logic programs additional assumption background knowledge B disjoint union directed paths called path graph Let graph G path graph We denote Aa respectively Ba number vertices path containing respectively We denote f successor node f ia f f i1a ith successor We denote f 1a predecessor f ia f 1f i1a ith predecessor We note f ia undeﬁned We denote dpa b signed distance b That f da b dpa b d If b belong different paths dpa b 71 Products path graphs rooted homomorphisms paths In section ﬁrst collect properties products path graphs present necessary sufﬁcient conditions existence rooted homomorphisms paths An illustration product path graphs given Fig 2 Section 4 With exception property omit proofs follow general results stated forests cid4 t Lemma 24 Let Gi Vi Ei path graphs bi ci Vi G corresponding product vertices G Then following properties hold 1 t Let i1 Gi product graph cid12b b1 bt cid12c c1 ct G path graph ii Acid12b mini1t Abi Bcid12b mini1t Bbi iii The product vertices cid12b cid12c belong path G dpcid12b cid12c d bi ci belong connected component Gi dpbi ci d 1 t Proof To prove ﬁrst note vertex G predecessor successor Proposition 4 Furthermore G acyclic Proposition 5 Hence G path graph The proofs ii iii follow general results given Section 81 Now present necessary sufﬁcient conditions existence rooted homomorphisms paths The proofs lemma theorem follow general results given Section 82 Lemma 25 Let G1 G2 paths let b vertex G1 c vertex G2 Then G1 cid16bccid17 G2 Ab cid1 Ac Bb cid1 Bc T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 55 Theorem 26 Let G1 G2 paths Let b1 bk distinct vertices G1 c1 ck vertices G2 k 1 Then G1 cid16b1c1bkckcid17 G2 G1 cid16bi ci cid17 G2 1 k dpbi bj dpci cj j 1 cid1 cid6 j cid1 k 12 13 72 A combinatorial characterization GB We start giving description concept generated set ground atoms Let S P b1 P bt bi bi1 bim 1 t t 1 Let cid12bj denote b1j btj j 1 m Let cid6 cid7 j 1 cid1 j cid1 m cid12bj product constant IconstS IvarS 1 m IconstS HpairsS cid6 u v u v IvarS u cid6 v dpcid12bu cid12bv cid6 cid7 We recall Bg denotes graph represent B Theorem 27 If B path graph GBS cid6 P b1 bm bj aqj cid12bj cid12aqj j IconstS Bgt Bg j IvarS cid16cid12bj bj cid17 dpbu bv dpcid12bu cid12bv u v HpairsS cid7 Proof By Theorem 20 equivalence 11 P b1 bm GBS Bg Bgt cid16cid12b1b1cid12bmbmcid12a1a1cid12anancid17 14 15 16 17 Thus 17 holds 14 15 16 hold Suppose 14 15 16 hold In order 17 holds disjoint paths Bgt considered separately We ﬁrst note path contains vertex corresponds product constant vertices correspond product constants For paths Bgt contain distinguished nonconstant product vertex cid12bj j IvarS projection Bg applied This case includes paths consisting product constants map cid12aq aq q 1 n ii For paths contain single distinguished nonconstant product vertex cid12bj 15 provides required single rooted homomorphism mapping cid12bj bj 56 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 iii If path contains distinguished nonconstant product vertex existence required multiply rooted homomorphism follows 15 16 Theorem 26 onlyif Suppose 17 holds Then proofs 14 15 automatic 16 holds Theorem 26 Applying results Section 71 characterization GBS reformulated follows cid6 GBS P b1 bm bj aqj cid12bj cid12aqj j IconstS Abj cid2 Acid12bj Bbj cid2 Bcid12bj j IvarS dpbu bv dpcid12bu cid12bv u v HpairsS values Acid12bj Bcid12bj dpcid12bu cid12bv directly computed Bg results Section 71 cid7 73 Concept representation Theorem 27 gives combinatorial characterization existence multiply rooted homomorphism required Theorem 20 In section focus second step product homomorphism method We translate conditions Theorem 27 Horn clause C representing GBS Furthermore size C number literals contains polynomial n m C efﬁciently evaluatable The algorithm computing clause given Algorithm 1 First deﬁne subroutine CREATEPATHx y d called Algorithm 1 Here x y variables special symbol λ d cid2 0 CREATEPATHx y d d 0 return x λ return Rz1 z2 Rzd y y λ return Rx z1 Rzd1 zd return Rx z1 Rzd1 y z1 zd new variables That x y different λ subroutine returns set negated Ratoms corresponding directed graph directed path length d x y If x y special symbol λ path length d generated leaving x leading y Algorithm 1 PATHGRAPH input set S P b1 P bt ground atoms path graph B output clause C satisfying CB GBS let C P t1 tm tj constant aqj cid12bj cid12aqj variable xcid12bj j 1 m 1 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 57 2 3 4 5 6 7 j IvarS Bcid12bj minBcid12bk j k HpairsS j k C C CREATEPATHλ tj Bcid12bj Acid12bj minAcid12bk j k HpairsS j k C C CREATEPATHtj λ Acid12bj C C CREATEPATHtj tk dpcid12bj cid12bk k satisﬁes Acid12bk maxAcid12bu u j HpairsS Acid12bu Acid12bj 8 return C Following 14 Line 1 Algorithm 1 deﬁne head output clause C Theorem 27 implies cid12bj cid12aqj bj aqj cid12bu cid12bv bu bv P b1 bm GBS In Loop 27 consider nonconstant distinguished product vertices cid12bj If path containing cid12bj distinguished product vertex respectively cid12bj add set negated Ratoms C forms directed path length Bcid12bj respectively Acid12bj ending respectively starting Lines 3 4 respectively Lines 5 6 If cid12bj ancestor 15 variable xcid12bj distinguished product vertex Line 5 add set negated Ratoms cid12bk denotes C describes directed path length dpcid12bj cid12bk xcid12bj closest proper ancestor cid12bj cid12b1 cid12bm Line 7 xcid12bk Example 28 The steps Algorithm 1 illustrated running Example 7 In running example positive examples S P a2 a9 a4 P a7 a1 a9 Since cid12b1 a2 a7 cid12b2 a9 a1 cid12b3 a4 a9 product constant C P xa2a7 xa9a1 xa4a9 Line 1 The number iterations Line 2 3 IconstS Only cid12b1 cid12b2 meet condition given Line 3 cid12b3 belongs path containing cid12b1 Bcid12b1 Bcid12b3 Since Bcid12b1 1 add literal Ry1 xcid12b1 C On hand cid12b2 add literal C Bcid12b2 0 Line 4 deﬁnition CREATEPATH Similarly j 2 j 3 add literal y2 C Acid12b3 0 Lines 5 6 Line 7 applied cid12b1 Rxcid12b2 Since dpcid12b1 cid12b3 2 add literals Rxcid12b1 C The ﬁnal clause computed example y3 Ry3 xcid12b3 C P xcid12b1 xcid12b2 xcid12b3 Ry1 xcid12b1 Rxcid12b2 y2 Rxcid12b1 y3 Ry3 xcid12b3 Theorem 29 Algorithm 1 correct CB GBS polynomial m n t ii The size C Omn iii C evaluated respect B time polynomial m n 15 We b ancestor descendant b b f ia cid2 0 Thus edges tree directed descendant ancestor This notation convenient consider directed edges representing partial function 58 Proof T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 First correctness The body C viewed usual graph corresponding Rliterals contained In fact graph path graph Let Lj denote path containing variable xcid12bj graph With abuse notation write Lj clause containing negative Rliterals corresponding Bcid12bj It holds edges path It holds Axcid12bj Lj xcid12bj bj subsumes literals correspond ing longest path B contains constant bj By Lemma 25 condition equivalent Axcid12bj bj cid1θ B path Lj xcid12bj Acid12bj Bxcid12bj cid1 Abj Bxcid12bj cid1 Bbj Similarly Bgt Bg cid16cid12bj bj cid17 rooted homomorphism path containing cid12bj path containing bj mapping cid12bj bj turn equivalent Acid12bj cid1 Abj Bcid12bj cid1 Bbj Lemma 25 Thus Bgt cid16cid12bj bj cid17 Bg Lj xcid12bj bj cid1θ B 18 distinguished nonconstant product vertex cid12bj Furthermore construction guarantees cid12bk distinguished nonconstant product vertex path containing cid12bj dpbj bk dpcid12bj cid12bk Lj xcid12bj bj xcid12bk bk cid1θ B 19 cid13 Let L denote body C C form P t1 tm L By construction j 1 Lj Lj j IconstS Lj Lk cid12bj cid12bk belong L path Bgt Then holds m P b1 bm GBS 14 15 16 hold tj aqj cid12bj cid12aqj j IconstS Lj tj bj cid1θ B j IvarS Lj tubu tvbv cid1θ B u v HpairsS C cid1θ P b1 bm B P b1 bm CB 20 21 22 23 20 21 hold Theorem 27 18 19 respectively 22 follows construction L ﬁnally 23 Proposition 14 For proof efﬁciency note IvarS HpairsS polynomial m elements HpairsS computed efﬁciently Lemma 24 A B values product vertex Bgt determined efﬁciently Bg Lemma 24 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 59 ii From Lemma 24 follows length longest path Bgt length longest path Bg n 1 Therefore iteration n literals added C number iterations m iii In order evaluate C respect B decide given assignment constants variables head assignment constants variables body literals body belong B However natural order literals corresponding occurrence CREATEPATH suitable value literal successor predecessor efﬁciently 16 74 Polynomial PAClearnability Now formulate ﬁrst application approach learnability This result generalized section forests weaker upper bound sample complexity Theorem 30 Simple logic programs B path graph polynomially PAC learnable Proof In view general result polynomial PAClearnability given Theorem 1 Section 22 sufﬁcient VCdimension polynomial hypothesis ﬁnding polynomial time According 3 Section 22 CBm polynomial polynomiality VCdimension sufﬁcient log2 Part ii Theorem 29 implies CBm cid1 nmOnm The efﬁciency Algorithm 1 stated Theorem 29 741 Sharper bounds VCdimension As sample complexity PAC model proportional VCdimenson 3 prove sharper bounds VCdimension First lower bound showing VCdimension CBm 8m B path graph Proposition 31 There path graph background knowledge B VC dimension CBm 2m Proof Let assume 3 objects a0 a1 a2 let background knowledge B deﬁned binary relation R objects Ra1 a0 Ra0 a2 The lower bound follows Lemma 22 noting a0 a1 a2 satisfy conditions The following theorem gives upper bound VCdimension In view proposition bound sharp order magnitude Theorem 32 If B path graph VCdimension CBm Om 16 In words C determinate respect B 4853 ordered natural way 60 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Proof Using Corollary 3 upper bound follows set S select subset Scid9 S Scid9 4m GBScid9 GBS In order select subset S note Theorem 27 Lemma 25 follows GBScid9 GBS Scid9 S following conditions hold IvarScid9 IvarS ii HpairsScid9 HpairsS iii Acid12bjScid9 Acid12bjS Bcid12bjScid9 Bcid12bjS j IvarS cid12bjScid9 respectively cid12bjS denotes tuple formed j th arguments atoms Scid9 respectively S We note conditions imply dpcid12buScid9 cid12bvScid9 dpcid12buS cid12bvS u v HpairsS The main steps selection Scid9 deﬁned conditions different order Construction S1 First deal condition iii concerning number vertices path containing cid12bjScid9 j IvarS respectively cid12bjScid9 Let SA SB subsets S smallest cardinalities satisfying min P b1bmSA min P b1bmSB Abj Bbj min P b1bmS min P b1bmS Abj Bbj j IvarS let S1 SA SB Clearly S1 cid1 2m Applying Lemma 24 j IvarS holds Bcid12bjS1 Bcid12bjS Acid12bjS1 Acid12bjS Construction S2 This step corresponds condition holds IvarS1 IvarS For case IvarS1 cid1 IvarS consider set IvarS IvarS1 This set contains arguments j atom S1 j th argument atom S different j th argument For j pick atom add S1 Let enlarged set S2 Since m atoms added S1 S2 cid1 3m Construction S3 Now consider case according condition ii distinguished product vertices belong path product corresponding S2 belong different paths product corresponding S HpairsS cid1 HpairsS2 Let u v HpairsS2 HpairsS Then Lemma 24 implies d n P b1 bm S d dpbcid9 m S2 dpbu bv cid6 d Adding m 1 atoms S2 obtain set S3 HpairsS3 HpairsS Thus cardinality S3 holds v P bcid9 1 bcid9 u bcid9 S3 4m Let Scid9 S3 The construction Scid9 previous remarks imply GBS GBScid9 theorem follows T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 61 8 Forest background knowledge In section generalize results previous section case B forest Throughout section use following example Example 33 Let assume like learn ternary target predicate P having following background knowledge B binary background predicate R constants a1 a19 Ra1 a10 Ra2 a3 Ra3 a4 Ra4 a10 Ra10 a11 Ra11 a12 Ra5 a6 Ra6 a7 Ra7 a8 Ra8 a9 Ra9 a10 Ra13 a18 Ra14 a15 Ra15 a16 Ra16 a17 Ra17 a18 Ra18 a19 The directed graph representing R forest consisting directed trees Fig 3 Suppose P a1 a1 a10 P a16 a4 a13 belong target concept P a3 a9 a9 belong We like ﬁnd exists clause consistent examples respect background knowledge B Let G forest If node f denotes parent f ia f f i1a cid2 0 denotes ith parent f ia undeﬁned We write b respectively b b f ia cid2 0 respectively 0 If b respectively b b ancestor respectively proper ancestor descendant respectively proper descendant b The height denoted ha length longest directed path ending If f ia undeﬁned deﬁne hf ia 0 Let b nodes tree Then b certain number edges directed root followed certain number edges directed away Fig 3 The forest structure background knowledge B Example 33 62 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 root Let numbers dx dy 0 The sequence edges referred dx dywalk b This differs notion walk Section 23 The paths root away root common edge Consider set Da b deﬁned cid6 Da b dx dy dx dywalk b cid7 One Da b cid6 pair d1 d2 Da b dx dy Da b exists nonnegative integer d 0 cid1 d n satisfying dx d1 d dy d2 d In words d1 d2 cid1 dx dy dx dy Da b cid1 denotes partial ordering vectors obtained comparing components We deﬁne distance df b b pair d1 d2 It holds f d1a f d2b This node called common ancestor b denoted lcaa b The node lcaa b belongs dx dywalk b If b belong different trees Da b df b If W set nodes tree lcaW unique smallest respect node ancestor node W Later use following property Proposition 34 Let W set nodes tree let node W Then node b W lcaa b lcaW Proof Let lcaW f da d cid2 0 If lcaa b proper descendant f da b W f d1a common ancestor W Hence case lcaa b f da b W Example 35 Consider nodes a4 a8 Example 33 Fig 3 Since Da4 a8 1 2 2 3 3 4 holds df a4 a8 1 2 lcaa4 a8 a10 81 Products forests In section formulate properties products forests The product copies forest Fig 3 shown Fig 4 Proposition 36 Let Gi forest 1 t Then G cid4 t i1 Gi forest Proof G directed cycles Proposition 5 Furthermore vertex G parent Proposition 4 Hence G forest Lemma 37 Let Gi Vi Ei forest bi Vi 1 t Consider cid4 product vertex cid12b b1 bt product G t i1 Gi For l cid2 0 holds cid2 h f lcid12b cid3 cid2 f lbi h cid3 min i1t 24 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 63 Fig 4 The product copies forest Fig 3 Proof G forest Proposition 36 The arguments Section 23 imply l cid2 0 holds f lcid12b deﬁned f lbi deﬁned 1 t If f lcid12b undeﬁned l cid2 0 24 straightforward deﬁnition h b Suppose f lcid12b deﬁned Then f lbi deﬁned Gi directed path length hf lcid12b ending f lbi 1 t Hence hf lcid12b cid1 hf lbi 1 t cid2 h cid2 f lcid12b h 25 f lbi cid3 cid3 cid1 min i1t Conversely consider longest directed path ending f lbi Gi 1 t The product paths path graph contains directed path G ending f lcid12b Its length mini1t hf lbi cid3 cid2 f lcid12b h cid2 h 26 f lbi cid3 cid2 min i1t 24 follows directly 25 26 64 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Proposition 38 Let Gi Vi Ei forest bi ci Vi 1 t Consider cid4 product vertices cid12b b1 bt cid12c c1 ct product G t i1 Gi Then cid12b cid12c belong tree G bi ci belong tree Gi exist dx dy cid2 0 f dx bi f dyci deﬁned f dxbi f dyci 1 t Proof The follows cid2 f dxb1 f dx bt f dx cid12b cid3 cid2 f dyc1 f dyct cid3 f dy cid12c For let dx dy df cid12b cid12c Such distance dx dy exists cid12b cid12c belong tree assumption Thus f dxcid12b f dycid12c deﬁned identical deﬁnition df Hence components f dxbi f dy ci deﬁned satisfy f dx bi f dyci 1 t Lemma 39 Let G cid12b cid12c previous proposition If cid12b cid12c belong tree G exists k 1 cid1 k cid1 t cid3 cid2 df cid12b cid12c df bk ck max i1t dxi max i1t dyi dxi dyi df bi ci 1 t Proof Let df cid12b cid12c dx dy Then dx dywalk cid12b cid12c bi ci 1 t By deﬁnition df bi ci exists di cid2 0 dx dxi di dy dyi di Therefore value k minimizing di holds cid2 dxk dyk max i1t dxi max i1t dyi cid3 27 28 We dx dxk dy dyk Since dk nonnegative 27 follows dx dy cid2 dxk dyk 29 From 2729 follows dx cid2 dxk cid2 dxi dy cid2 dyk cid2 dyi dx dy dxk dyk dxi dyi 1 t Hence dx dy dxi dyiwalks bi ci dxk dykwalk bi ci 1 t Thus dxk dykwalk cid12b cid12c holds dxk dyk cid2 dx dy Proposition 38 previous lemma efﬁcient algorithm decide product vertices belong tree compute distance explicitly considering product exponential size T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 65 82 Rooted homomorphisms trees In section necessary sufﬁcient conditions existence rooted homomorphisms trees Since paths special case trees section generalizes results Section 71 paths trees Lemma 40 Let G1 G2 trees Let b vertex G1 c vertex G2 Then G1 cid16bccid17 G2 cid2 h f lb cid3 cid2 cid1 h f lc cid3 l cid2 0 30 Proof For l cid2 0 f lb exists let pl paths G2 length hf lc ending f lc Let v arbitrary vertex G1 let k smallest integer directed path v f kb Thus f kb dth parent v d cid2 0 f dv f kb Consider mapping ϕ G1 G2 deﬁned ϕ v cid30 vcid9 vcid9 node pk f dvcid9 f kc Since 0 cid1 d cid1 hf kb vcid9 deﬁned 30 Applying construction d k 0 ϕ maps b c In order ϕ homomorphism consider vertex v G1 f v deﬁned We edge v f v mapped edge ϕ If v f kb k cid2 0 f v f k1b Since ϕv f kc ϕf v f k1c construction ϕv ϕf v edge G2 Otherwise v ancestor b let k cid2 0 smallest number directed path v f kb From assumption case follows f v node path v f v mapped nodes path pk ϕf v f ϕv onlyif If f lb undeﬁned l cid2 0 30 holds directly deﬁnition h If f lb deﬁned l cid2 0 f lc deﬁned homomorphism ϕ map f lb f lc Suppose contradiction 31 consider directed paths G1 length hf lb ending f lb Then Proposition 6 path G2 length hf lb ending f lc contradicting 31 cid2 h f lb f lc cid2 h cid3 cid3 Lemma 41 Let G1 G2 trees let b1 b2 distinct vertices G1 c1 c2 vertices G2 Let df b1 b2 d1 d2 Then G1 cid16b1c1b2c2cid17 G2 1 G1 cid16b1c1cid17 G2 G1 cid16b2c2cid17 G2 2 f d1c1 f d2c2 66 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Proof Let ϕ1 ϕ2 denote corresponding single rooted homomorphisms exist assumption direction If d2 0 direction follows cid2 cid3 cid2 cid3 ϕ1b2 ϕ1 f d1b1 f d1 ϕ1b1 f d1c1 c2 Thus case ϕ1 required doubly rooted homomorphism Suppose d2 0 Let Gcid9 1 subtree G1 rooted f d21b2 Consider mapping ϕ deﬁned cid8 ϕb b vertex Gcid9 1 ϕ2b ϕ1b We edge f d21b2 f d1b1 mapped edge ϕ This holds ϕf d21b2 f d21c2 ϕf d1b1 f d1c1 f d2c2 edge f d21c2 f d2c2 onlyif Let ϕ denote corresponding doubly rooted homomorphism The ﬁrst condition holds automatically The second condition follows f d1c1 f d1 cid2 cid3 ϕb1 cid2 f d1b1 cid2 f d2b2 cid2 ϕb2 ϕ ϕ f d2 f d2c2 cid3 cid3 cid3 Now formulate necessary sufﬁcient condition existence multiply rooted homomorphism trees Theorem 42 Let G1 G2 trees Let b1 bk distinct vertices G1 c1 ck vertices G2 k 1 Then G1 cid16b1c1bkckcid17 G2 G1 cid16bi ci bj cj cid17 G2 cid6 j Proof The direction holds trivially The direction shown induction k The basis automatic For general case assume loss generality subtree G1 rooted bk contain vertex b1 bk1 Let d 0 smallest number f dbk descendant bi cid6 k Let Gcid9 1 subtree rooted f d1bk By induction hypothesis G1 cid16b1c1bk1ck1cid17 G2 let ϕ1 multiply rooted homomorphism Also assumption G1 cid16bi ci bkckcid17 G2 let ϕ2 doubly rooted homomorphism Now deﬁne cid8 ϕb b Gcid9 ϕ2b 1 ϕ1b T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 67 In order ϕ required multiply rooted homomorphism similar argument proof previous lemma 83 A combinatorial characterization GB In section combinatorial description concept generated set ground P atoms forest background knowledge B Let S set ground atoms P b1 P bt bi bi1 bim 1 t t 1 Let cid12bj denote product vertex b1j btj j 1 m Let cid6 cid7 j 1 cid1 j cid1 m cid12bj product constant IconstS IvarS 1 m IconstS HpairsS HconstS j cid6 u v u v IvarS u v df cid12bu cid12bv cid6 cid6 cid7 cid7 aq 1 cid1 q cid1 n cid12bj cid12aq belong tree j IvarS If j IconstS let HconstS j 17 GBS Theorem 43 If B forest cid6 P b1 bm bj aqj cid12bj cid12aqj j IconstS Bgt Bg j IvarS cid16cid12bj bj cid17 Bgt Bgt cid16cid12bubucid12bvbvcid17 cid16cid12bj bj cid12aacid17 Bg u v HpairsS Bg HconstS j j IvarS cid7 32 33 34 35 Proof Theorem 20 equivalence 11 imply P b1 bm GBS Bgt cid16cid12b1b1cid12bmbmcid12a1a1cid12anancid17 Bg 36 Therefore remainder proof 36 holds conditions 3235 hold The automatic In order prove note connected components Bgt considered separately follows If tree contain nonconstant product vertices cid12b1 cid12bm projection Bgt component provides homomorphism Bg mapping occurring product constant cid12a For trees contain exactly distinguished nonconstant product vertex product constants 33 provides required single rooted homomorphisms 17 In case natural deﬁne HconstS j set constants belonging tree cid12bj The current deﬁnition correct simpliﬁes discussion 68 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 For remaining tree Bgt existence multiply rooted homomorphism By Theorem 42 existence multiply rooted homomorphism equivalent existence set doubly rooted homomorphisms This set doubly rooted homomorphisms given theorem 34 35 32 We note Lemmas 40 41 provide explicit lengthy reformulation theorem terms heights path lengths actually apply theorem 84 Concept representation A clause representing concept generated set ground P atoms forest background knowledge constructed Algorithm 2 given The idea similar Section 73 translate conditions Theorem 43 equivalent Horn clause Algorithm 2 FOREST input set S P b1 P bt ground atoms forest background knowledge B output clause C CB GBS let C P t1 tm tj constant aqj cid12bj cid12aqj 1 cid1 qj cid1 n variable xcid12bj j 1 m 1 2 3 j IvarS C C CREATETREEtj h0 hn1 hl hf lcid12bj l 0 n 1 HconstS j C C CREATEWALKtj df cid12bj cid12a u v HpairsS C C CREATEWALKtu tv df cid12bu cid12bv 4 5 6 7 8 return C The subroutines called Algorithm 2 following deﬁnition subroutine CREATEPATH Section 73 CREATETREEx h0 hn1 It returns set negated Ratoms corresponds tree containing node labeled x heights xs ancestors holds hf lx hl l 0 1 n 1 hf nx 0 As length longest path B n hf naq 0 q 1 n Formally CREATETREEx h0 hn1 CREATEPATHλ x h0 cid8 Li Ryi1 yi CREATEPATHλ yi hi hi 0 cid14 cid16 n1cid15 i1 Li T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 69 1 n 1 y0 x y1 yn1 new variables The parameters satisfy 0 cid1 h0 hk hl 0 0 cid1 k n k l n CREATEWALKt1 t2 d1 d2 It returns set negated Ratoms forms d1 d2 walk t1 t2 CREATEWALKt1 t2 d1 d2 cid17 CREATEPATHt2 t1 d2 CREATEPATHt1 t2 d1 CREATEPATHt1 y d1 CREATEPATHt2 y d2 d1 0 d2 0 Here y new variable For instance output CREATETREEx 1 2 4 0 0 clause Rz1 x Rx y1 Ry1 y2 Rz2 z3 Rz3 y1 Rz4 z5 Rz5 z6 Rz6 z7 Rz7 y2 For outputs CREATETREE CREATEWALK propositions hold Proposition 44 Let G tree containing node labeled satisﬁes cid2 h cid3 f la hl l 0 n 1 cid2 h cid3 f na 0 Let B forest background knowledge L output CREATETREEx h0 hn1 x variable Then 1 n holds G cid16aaicid17 Bg Lxai cid1θ B Proof The proof follows directly Lemma 40 deﬁnition CREATE TREE Proposition 45 Let background knowledge B forest aq aw constants 1 cid1 q w cid1 n d1 d2 cid2 0 Then f d1aq f d2aw Lx1aq x2aw cid1θ B L CREATEWALKx1 x2 d1 d2 x1 x2 variables Proof It follows directly Proposition 6 deﬁnition CREATE WALK Now ready prove necessary properties clause C computed Algorithm 2 Theorem 46 Algorithm 2 correct CB GBS polynomial m n t ii The size C Omnm n iii C evaluated respect B time polynomial m n 70 Proof T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 First prove correctness In Line 1 algorithm ﬁrst construct head output clause C according 32 Theorem 43 From Theorem 43 follows cid12bj cid12aqj cid12bu cid12bv imply bj aqj bu bv respectively P b1 bm GBS Then cid12bj j IvarS translate 33 j set literals Lj satisﬁes Bgt cid16cid12bj acid17 Bg Lj tj cid1θ B 37 constant This translation step performed Line 3 algorithm Equivalence 37 holds Proposition 44 In Lines 4 5 according 35 add CREATEWALKtj df cid12bj cid12aq C aq HconstS j set literals Ljaq Applying Lemma 41 37 Proposition 45 Bgt cid16cid12bj acid12aqaqcid17 Bg Lj Ljaq tj cid1θ B 38 constant aq HconstS j We note condition Bgt Bg cid16cid12aq aq cid17 required Lemma 41 holds Finally Lines 67 translate 34 u v HpairsS add set Luv CREATEWALKtu tv df cid12bu cid12bv body C Applying Lemma 41 Proposition 45 37 u v HpairsS Bgt cid16cid12buakcid12avalcid17 k l 1 n Bg Lu Lv Luvtuak tval cid1θ B 39 The output algorithm clause C head P t1 tm body union Ls given 37 38 39 We note construction sets share variables Cs head Combining results P b1 bm GBS 3235 hold C cid1θ P b1 bm B P b1 bm CB The ﬁrst equivalence holds Theorem 43 The second follows deﬁnition C 3739 Finally equivalence Proposition 14 The efﬁciency algorithm follows facts IvarS cid1 m HpairsS cid1 m2 HconstS j cid1 n hold j IvarS distance product vertices Bgt elements HpairsS HconstS j determined efﬁciently Bg Proposition 38 Lemma 39 ii From Lemma 37 follows height product vertex Bgt n nth father product vertex undeﬁned Thus iteration Line 3 add On2 literals C Since length longest path Bgt n embedded loop given Lines 4 5 add On2 literals C Thus ﬁrst loop Lines 25 add Omn2 literals C T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 71 In iteration second loop Lines 67 add 2n literals C Since cardinality HpairsS m2 Om2n upper bound number literals added C loop Thus size C bounded Omn2 m2n iii As proof Theorem 29 order evaluate C respect B decide given assignment constants variables head assignment constants variables body literals body belong B From results chapter follows decided computing heights ancestors distances forest efﬁciently computable B Example 47 The behavior Algorithm 2 illustrated step step positive examples given Example 33 recall n 19 m 3 S P a1 a1 a10 P a16 a4 a13and t 2 In example use abbreviations Lj Luv introduced use standard clause notation Since cid12b1 a1 a16 cid12b2 a1 a4 cid12b3 a10 a13 product constant execution Line 1 C P x1 x2 x3 Applying Lemma 37 hf lcid12b1 0 3 4 5 0 0 l 0 1 18 respectively Hence add set literals CREATETREEx1 0 3 4 5 0 0 body C Line 3 j 1 The trees corresponding x2 x3 respectively generated similarly HconstS 1 HconstS 3 HconstS 2 a1 a2 a12 Hence Lines 4 5 add literals CREATEWALKx2 a1 1 1 CREATEWALKx2 a2 1 3 CREATEWALKx2 a12 3 0 C The parameters CREATEWALK computed Lemma 39 respectively pairsS 1 3 cid12b1 cid12b3 belong tree HpairsS H cid9 square B Therefore Line 6 add set literals CREATEWALKx1 x3 2 1 C The ﬁnal clause C P x1 x2 x3 CREATETREEx1 0 3 4 5 0 0 CREATETREEx2 0 5 6 7 0 0 CREATETREEx3 0 4 5 0 0 0 72 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Fig 5 The body clause generated Algorithm 2 CREATEWALKx2 a1 1 1 CREATEWALKx2 a12 3 0 CREATEWALKx1 x3 2 1 The structure Cs body given Fig 5 Finally note Theorem 19 implies C concept equivalent RLGGs represent concept respect B C equivalent RLGGs To let D RLGG S respect B Then D form P y1 y2 y3 Ry1 z1 Rz1 z2 Ry3 z2 Rz2 z3 substitution θ satisfying Dθ C map y1 x1 y3 x3 z2 lcay1 y3 lcax1 x3 Fig 5 But z3 ancestor z2 mapped θ ancestor lcax1 x3 lcax1 x3 ancestor Hence θ satisfying Dθ C D cid6cid1θ C 85 Polynomial PAClearnability In section generalize Theorem 30 path graphs forests Theorem 48 Simple logic programs B forest polynomially PAC learnable Proof Applying Theorem 1 order efﬁcient PAClearnability sufﬁcient VCdimension polynomial hypothesis ﬁnding solved efﬁciently Using 3 Section 22 VCdimension claims follow Theorem 46 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 73 851 Sharper bounds VCdimension From Proposition 49 Theorem 50 follows B forest VC n bound sharp order magnitude The dimension CBm Om proofs results given Appendix B Proposition 49 There forest background knowledge B m VCdimension CBm m n 2 Theorem 50 If B forest background knowledge VCdimension CBm Om n 9 Cycle graph background knowledge In section consider class simple logic programs Here assume background knowledge B disjoint union directed cycles called cycle graph Example 51 Let assume like learn ternary target predicate P considering following background knowledge B binary background predicate R constant symbols a1 a9 Ra1 a2 Ra2 a1 Ra3 a4 Ra4 a5 Ra5 a3 Ra6 a7 Ra7 a8 Ra8 a9 Ra9 a6 The corresponding directed graph representation B contains directed cycles length 2 3 4 respectively Fig 6 Let P a3 a1 a4 P a7 a1 a6 positive examples let P a2 a1 a2 negative example A consistent hypothesis given clause P x1 a1 x2 Rx1 y1 Ry1 y2 Ry2 y3 Ry3 y4 Ry4 y5 Ry5 y6 Ry6 x2 Rx2 y7 Ry7 y8 Ry8 y9 Ry9 y10 Ry10 x1 The directed graph corresponding body clause consists cycle length 12 Fig 7 Intuitively clause says triple x y z target concept y Fig 6 The structure background knowledge B Example 51 74 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Fig 7 The structure body consistent hypothesis Example 51 a1 x z belong cycle length l l divisor 12 7th parent x z Let G cycle graph The length cycle containing denoted Lcyclea The notation d respectively d cid4 means d divides respectively divide The common multiple integers z1 zn denoted lcmz1 zn b mod n denotes congruent b modulo n For cycle graphs use successor function f path graphs If cycle f ia deﬁned cid2 0 Let b nodes cycle Then distance dca b b deﬁned smallest d cid2 0 f da b If b belong different cycles dca b 91 Products cycle graphs rooted homomorphisms cycles In section prove basic properties cycle graphs Proposition 52 Let Gi cycle graph 1 t Then product G cycle graph cid4 t i1 Gi Proof The outdegree vertex G 1 Proposition 4 Hence G cycle graph Proposition 53 Let Gi Vi Ei cycle graphs 1 t cid12b b1 bt product vertex G cid4 t i1 Gi Then Lcyclecid12b lcm cid2 Lcycleb1 Lcyclebt cid3 Proof The smallest number l 0 satisfying f lbi bi 1 t f lcid12b cid12b lcmLcycleb1 Lcyclebt This proposition implies 2 3 pt ﬁrst t primes product t cid4 t i1 pi It follows cycles lengths 2 3 pt single cycle length T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 75 length cycle containing product vertex computed time polynomial n t Proposition 54 Let Gi Vi Ei cycle graphs 1 t let cid12b i1 Gi Then cid12b cid12c belong b1 bt cid12c c1 ct product vertices G cycle G bi ci belong cycle Gi exists d cid2 0 satisfying d dcbi ci mod Lcyclebi 1 t cid4 t Proof dccid12b cid12c d cid2 0 f dcid12b cid12c d cid2 0 f dbi ci 1 t d cid2 0 d dcbi ci mod Lcyclebi 1 t As congruences solved efﬁciently 38 follows proposition decided efﬁciently product vertices belong cycle distance computed efﬁciently Here efﬁciency means polynomial time n t Proposition 55 Let G1 G2 cycles length l1 l2 respectively There homomorphism G1 G2 G1 G2 l2 l1 Proof Let b c vertices G1 G2 respectively Consider mapping G1 G2 deﬁned ϕ f lb cid30 f lc l 0 l1 1 By deﬁnition ϕ ϕf kb ϕf k1b edge G2 k 0 l1 2 Since l2 l1 f l11c f l21c Thus edge ϕf l11b ϕb f l21c c G2 Hence ϕ homomorphism onlyif Let ϕ homomorphism G1 G2 Then l2 cid1 l1 Furthermore f l1ϕv ϕf l1v ϕv f l2ϕv Thus l2 l1 Now formulate necessary sufﬁcient condition existence multiply rooted homomorphism cycles Theorem 56 Let G1 G2 cycles let b1 bk distinct vertices G1 c1 ck vertices G2 Let l2 denote length cycle G2 Then G1 cid16b1c1bkckcid17 G2 G1 G2 dcbu bv dccu cv mod l2 u v 1 cid1 u v cid1 k 40 41 76 Proof T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Using symmetry cycles 40 follows G1 cid16b1c1cid17 G2 Let ϕ rooted homomorphism G1 G2 mapping b1 c1 Applying 41 ϕbi ϕ cid2 f dcb1bi b1 cid2 ϕb1 cid3 cid3 f dcb1bi f dcb1bi c1 f dcc1ci c1 ci 1 k Thus case ϕ required multiply rooted homomorphism onlyif The proof 40 automatic For proof 41 let ϕ rooted homomorphism given theorem Then cid2 cid3 cv ϕbv ϕ f dcbubvbu f dcbubv cid3 cid2 ϕbu f dcbubvcu u v 1 cid1 u v cid1 k Since cv f dccucv cu holds dcbu bv dccu cv mod l2 92 A combinatorial characterization GB As previous cases section combinatorial characterization concept generated set ground P atoms cycle graph background knowledge B Let S set ground atoms P b1 P bt bi bi1 bim 1 t t 1 Let cid12bj denote product vertex b1j btj j 1 m Let cid6 IconstS IvarS 1 m IconstS HpairsS cid7 j 1 cid1 j cid1 m cid12bj product constant cid6 u v u v IvarS u v dccid12bu cid12bv Theorem 57 If B cycle graph cid6 GBS P b1 bm bj aqj cid12bj cid12aqj j IconstS Bgt dccid12bu cid12bv dcbu bv mod Lcyclebu Bg j IvarS cid16cid12bj bj cid17 u v HpairsS cid7 cid7 42 43 44 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 77 Proof Similarly proofs Theorems 27 43 prove second equivalence P b1 bm GBS Bgt cid16cid12b1b1cid12bmbmcid12a1a1cid12anancid17 Bg 42 43 44 hold The ﬁrst equivalence holds Theorem 20 equivalence 11 Suppose 42 43 44 hold The disjoint cycles Bgt considered separately follows Each cycle Bgt contains constant product vertices nonconstant product vertices For cycle Bgt containing cid12bj j IvarS projection cycle Bg applied providing required homomorphism mapping cid12aq aq q 1 n If cycle contains exactly cid12bj j IvarS 43 provides required single rooted homomorphism The remaining cycles contain product vertices cid12bu cid12bv u v IvarS For cycles 43 44 provide conditions multiply rooted homomorphism required Theorem 56 onlyif The proof 42 43 automatic 44 follows Theorem 56 We observe case cycle graph background knowledge essentially different forests case unary target predicates First formulate results number theory rest section 2345 number primes x sum primes x cid18 cid18 cid19 x log x cid19 x2 log x product primes x 2x 45 46 47 Theorem 58 There exists cycle graph background knowledge B n constants set S ground unary P atoms size consistent clause exponential n Proof Let B cycle graph background knowledge n constants consisting cycles K1 Kl different prime lengths 2 3 pl l large possible The remaining vertices isolated 18 Then 45 implies pl l log l 46 implies n l2 log l So number cycles l nlog n Select constants a1 al cycle Let P a1 P al1 positive examples P al negative example We claim size consistent hypothesis 2 n log n 18 For instance n 20 cycles length 2 3 5 7 3 isolated vertices 78 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Consider consistent hypothesis C Thus C form P x It assumed loss generality C linked graph obtained C taking terms vertices atoms edges connected This implies C contain constants variables P a1 P a2 positive examples As P a1 P al1 positive examples graph GC representing body C homomorphism cycles K1 Kl1 Hence argument given proof Proposition 11 homomorphism product cycle length N cid4 l1 i1 pi Now assume number literals C N Then image homomorphism contain vertices product cycle GC homomorphism path length N But GC homomor phism Kl symmetry Kl contradicts fact P al negative example Thus size C N 2 n log n 47 93 Extended background representation language One way regain polynomial PAClearnability spite Theorem 58 introduce size target concept learning parameter Instead extend background representation language adding new background predicates These predicates efﬁciently computable original background predicate R Using extra predicates holds target concept representation polynomial size original learning parameters m n Thus application product homomorphism method viewed instance semiautomatic predicate invention 19 method suggests predicates enable succinct concept representation The new background predicates form PATHd x y hold path length d x y d 20 Thus PATHd x x holds Lcyclex d Based extended representation language algorithm computing clause represents GBS set S ground P atoms Algorithm 3 CYCLEGRAPH input set S P b1 P bt ground atoms cycle graph B output clause C CB GBS let C P t1 tm tj constant aqj cid12bj cid12aqj 1 j 1 m variable xcid12bj j IvarS 2 3 4 5 6 return C C C PATHtj tj Lcyclecid12bj u v HpairsS C C PATHtu tv dccid12bu cid12bv 19 Predicate invention automatic step introducing new predicates learning For brief overview Chapter 19 53 20 Using standard logic programs predicates implemented ternary predicate PATHx y d T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 79 Theorem 59 Algorithm 3 correct CB GBS polynomial m n t ii The size C Om2 iii C evaluated respect B time polynomial m n Proof As case path graph background knowledge cycle Bgt contains vertex cid12bj j IvarS contain product constant Thus Theorem 57 correctness shown similarly proof Theorem 29 The efﬁciency follows polynomial size IvarS HpairsS earlier remark quantities Lcycle dc algorithm computed efﬁciently Bg ii For second proof note number iterations m HpairsS cid1 m m2 iteration add literal C 21 iii Since variable Cs body occurs head C assignment constants variable head makes C ground 22 Since size C polynomial m truth ground PATHatom decided efﬁciently respect B C evaluated efﬁciently respect B 94 Polynomial PAClearnability To summarize previous results positive PAClearnability result product homomorphism method Theorem 60 Using extended background representation language simple logic programs B cycle graph efﬁciently PAClearnable Proof The proof follows Theorem 59 Theorem 1 similar details proof Theorem 30 941 Sharper bounds VCdimension Proposition 61 Theorem 62 section imply B cycle graph nlog n upper bound VCdimension CBm bound Om sharp order magnitude The proofs results given Appendix C Proposition 61 There cycle graph background knowledge n constants VCdimension CBm 8m nlog n Theorem 62 If B cycle graph VCdimension CBm Om nlog n 21 We note Algorithm 3 optimal Using translation method similar Algorithm 1 modify Algorithm 3 obtain clause size Om 22 In words C constrained clause 53 80 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 10 Multiple clause hypotheses In section consider general case learning logic programs consisting clauses Example 63 Consider path graph background knowledge B given Example 7 Let assume P a3 P a6 P a7 P a9 positive examples P a8 negative example Since cid2 Aa8 2 min Aa3 Aa6 Aa7 Aa9 cid3 cid2 Ba8 3 min Ba3 Ba6 Ba7 Ba9 cid3 1 1 P a8 GBP a3 P a6 P a7 P a9 Theorem 27 Hence consistent hypothesis consisting single clause Although practical ILP systems discover multiple clause hypotheses positive theoretical results direction Džeroski Muggleton Russell 14 assuming ij determinateness multiple clause logic programs learnable LiVitányi 40 version PAClearnability Given background knowledge B basic clauses C1 Ck set C1 CkB contains ground P atoms implied logic program consisting C1 Ck unit clauses corresponding ground atoms B In words C1 CkB kcid15 i1 Ci B We consider following hypothesis ﬁnding problems kclause hypothesis ﬁnding problem Given background knowledge B set positive negative examples ﬁnd consistent hypothesis k clauses exists output exist Here k assumed ﬁxed input Multiple clause hypothesis ﬁnding problem Given background knowledge B set positive negative examples ﬁnd consistent hypothesis k clauses k small possible Note second formulation exists consistent hypothesis 23 simply positive examples unit clauses A polynomial algorithm multiple clause hypothesis ﬁnding problem clearly polynomial algorithm kclause hypothesis ﬁnding problem We consider problems assuming rest paper B path graph forest cycle graph In addition assume target predicate P unary The 23 Assuming example positive negative T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 81 negative results extended directly larger arity On hand open problem positive result extended larger arity We note case instance space size n polynomial size learning parameter n Thus point view prediction learning problem trivial learning computationally difﬁcult required output hypothesis prescribed form 101 Path graphs In order prove positive result case path graph background knowledge ﬁrst deﬁne covering problem Let Qq1q2 x y x cid2 q1 y cid2 q2 upper right quadrant plane corner q1 q2 Let U V ﬁnite subsets upper right quadrant Q00 The quadrants Q1 Qs form cover U V union Q holds U Q V Q The size cover s We consider following problem Given U V ﬁnd cover minimal size output cover exists The sets U V correspond certain sets positive negative examples hypothesis ﬁnding problem Lemma 64 The covering problem solved polynomial time Proof Let U u1 V v1 vr ui ui1 ui2 1 cid1 cid1 p vi vi1 vi2 1 cid1 cid1 r We assume loss generality ui cid6cid1 uj 1 cid1 j cid1 p ui1s strictly monotone increasing ui2s strictly monotone decreasing deleted changing solution Let consider Algorithm 4 Algorithm 4 COVER input U u11 u12 up1 up2 V v11 v12 vr1 vr2 ui1 uj1 ui2 uj2 1 cid1 j cid1 p output cover minimal size cover set ui1 ui2 cid1 vj1 vj2 1 cid1 cid1 p 1 cid1 j cid1 r 1 return 2 1 k 0 3 4 cid1 p j largest cid1 V Qui1u2 5 k k 1 6 Qk Qui1uj2 7 j 1 8 9 return Q1 Qk Clearly nonempty solution exists ui1 ui2 cid5 vj1 vj2 1 p j 1 r Let Qs Quis 1ujs 2 s 1 k quadrants produced algorithm This clearly cover For optimality note points uis 1 uis 2 s 1 k leftmost points U quadrant selected 82 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 algorithm belong different quadrants cover Thus size cover k Now formulate positive result multiple clause hypothesis ﬁnding problem path graph background knowledge Theorem 65 The multiple clause hypothesis ﬁnding problem solved polynomial time background knowledge B path graph P unary Proof Let consider Algorithm 5 Algorithm 5 MULTICLAUSEPATHGRAPH input disjoint sets S S unary ground P atoms path graph B output clauses H C1 Ck smallest k cid2cid13 cid13 S CH CB S CH CB cid3 1 H 2 S 1 P b S P S Aa Ba cid2 Ab Bb These examples remain ground 1 P S S P b S S 3 S 2 1 Aa Ba cid1 Ab Bb S 2 These examples deleted 4 U Ab Bb P b S S 1 5 V Ab Bb P b S 6 Q COVERU V P b S 7 1 8 9 10 H H P x CREATEPATHλ x q2 CREATEPATHx λ q1 11 return H H H P b Qq1q2 Q cid13 First HB CH CB contain negative examples Let P b S C H If C obtained positive example Line 8 C ground atom P b CB S S Otherwise C constructed Line 10 By construction U V Lines 45 U meets requirements given Algorithm 4 condition statement Line 1 Algorithm 4 holds Hence upper quadrant Q corresponding C Line 6 Algorithm 5 contain point Ab Bb Thus P b CB Theorem 27 In order prove HB contains positive examples consider P b S If P b 1 belongs concept represented ground unit clause P b H S Lines 78 Otherwise P b S S 1 upper quadrant Qq1q2 covering problem deﬁned Lines 45 solved Line 6 covers point Ab Bb By deﬁnition S 2 Thus concept represented clause corresponding q1 q2 Line 910 contains P b Theorem 27 Note clauses constructed Line 10 nonground quadrant covers single point U 2 holds P b S T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 83 Table 1 x a3 a6 a7 a9 a8 label P x Ax Bx 1 4 3 1 2 2 1 2 4 3 Fig 8 The covering problem solution For proof optimality let Hcid9 consistent hypothesis Then P b S 1 covered clause head P b Hcid9 This holds basic clause P x covering P b covers P S Aa Ba cid2 Ab Bb As heads clauses ground cover positive examples The remaining clauses Hcid9 cover remaining positive examples Thus particular cover U The optimality Algorithm 4 implies Hcid9 contains clauses H Finally S S cid1 n polynomial running time Algorithm 5 follows polynomial running time Algorithm 4 In example Algorithm 5 ﬁnds consistent hypothesis minimal number clauses multiple clause hypothesis ﬁnding problem given Example 63 S 1 P a3 Aa8 Ba8 cid2 Aa3 Ba3 S 2 Example 66 Consider background knowledge B examples given Exam ple 63 The values A B constants examples given Table 1 Thus solve covering problem U 1 4 3 2 4 1 V 2 3 The corresponding upper quadrants solution covering problem given Fig 8 Hence k exists kclause hypothesis 3 hypothesis P a3 P x Ry1 y2 Ry2 y3 Ry3 y4 Ry4 x Rx y5 P x Ry1 x Rx y2 Ry2 y3 Ry3 y4 84 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 102 Forests In contrast previous case forest background knowledge negative result holds In case kclause hypothesis ﬁnding problem NPcomplete case unary target predicate ﬁxed k cid2 3 Theorem 67 Let k cid2 3 ﬁxed P unary target predicate Then kclause hypothesis ﬁnding problem NPcomplete B forest 1 S Proof Let S k partition positive examples Applying Theorem 43 results Section 8 problem deciding set negative examples 1 cid1 cid1 k disjoint solved efﬁciently Hence problem GBS NP It remains proven NPhard We reduction graph coloring problem Let G V E undirected graph V v1 vt E e1 er From G ﬁrst construct forest background knowledge B consisting trees τ0 τr τ0 tree t distinguished vertices denoted a1 cid2 h f i1aj f i1ai min cid2 h cid3 cid3 1cid1j cid1ticid6j ei vαi vβi E τi tree having distinguished node 1 t l cid2 0 cid2 cid6 hf lat min h f laαi cid2 cid3 h f laβi cid3cid7 1 r The tree τ0 taken tree described proof Proposition 49 trees τi constructed procedure CREATETREE It follows number nodes B polynomial t Let S P a1 P S P 1 P r positive negative examples respectively We claim Scid9 cid1 S 1 r holds cid9 cid9 P GBS P aαi P aβi S 48 By Theorem 43 GBScid9 contains vertices b cid2 P aScid9 h cid2 min f la f lb cid2 h cid3 cid3 holds l cid2 0 If P aαi P aβi Scid9 cid3 cid2 h f lat cid6 min cid2 f laαi h cid3 cid2 h f laβi cid3cid7 cid2 min cid2 P aScid9 h f la cid3 l cid2 0 GBScid9 If P aαi Scid9 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 85 cid2 h f αi1at cid3 cid2 cid3 h f αi1aβi cid3cid7 cid2 cid6 min h cid2 h f αi1aαi cid3 f αi1aαi cid2 P aScid9 h f αi1a min cid3 P GBScid9 As S shattered holds consistent kclause hypothesis consistent kclause hypothesis clauses cover disjoint sets positive examples clause represents concept generated positive examples covers Any hypothesis brought form replacing clause clause representing concept generated subset positive examples covers We G kcoloring consistent kclause hypothesis S S Let V1 Vk partition V S1 Sk corresponding partition S vi Vj P ai Sj 1 t j 1 k Applying 48 V1 Vk form coloring V vαi vβi cid2 Vj 1 r j 1 k P aαi P aβi cid2 Sj 1 r j 1 k P GBSj 1 r j 1 k C1 Ck consistent hypothesis Cj clause representing GBSj respect B j 1 k 103 Cycle graphs For cycle graph background knowledge negative result similar case forest background knowledge Theorem 68 Let k cid2 3 ﬁxed P unary target predicate Then kclause hypothesis ﬁnding problem NPcomplete B cycle graph Proof The proof problem belongs NP similar ﬁrst proof Theorem 67 For proof NPhardness use graph coloring problem Let G V E undirected graph V v1 vt E e1 er We construct following cycle graph background knowledge G Let B consist disjoint cycle length pi containing constant ai vi V disjoint cycle length pαi pβi containing constant ei vαi vβi E pi denotes ith prime number Let n denote number constants B Then n tcid20 i1 pi rcid20 i1 pαipβi cid1 tpt rp2 t 49 As r Ot 2 pt t log t 45 gets n Ot 4 log2 t size B polynomial t 86 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Let positive negative examples S P a1 P S P 1 P r respectively In order G kcoloring consistent hypothesis consisting k clauses S S B similar proof given proof Theorem 67 11 Remarks open problems The product homomorphism method applied learning simple logic programs background knowledge binary predicate representing unary function 29 Since connected component class graphs viewed cycle trees hanging vertices cycle case combination case forests cycle graphs considered present paper requires involved combinatorial arguments Furthermore class graphs includes cycle graphs needs extended representation language order obtain positive results In 30 studied learning simple logic programs presence random classiﬁcation noise We obtained positive learnability results forest background knowledge statistical query model Kearns 3233 A practical application product homomorphism method given 28 The method applied partofspeech tagging problem Hungarian language difﬁculties language fairly free wordorder The paper contains comparison results propositional relational learning systems The general hypothesis ﬁnding problem background knowledge contain known PSPACEhard follows background predicates modiﬁcation 35 37 It known problem belongs PSPACE A related computational problem following Given structures M1 Mk M vocabulary hold M1 Mk M Again known problem PSPACE It interesting study applicability product homomorphism method types background knowledge Such case oriented path graphs background knowledge binary predicate representing disjoint union paths arbitrarily oriented edges There positive results class graphs problems involving products homomorphisms 21266465 Another interesting extension add unary predicates background knowledge case path graphs This version model protein prediction problems positive results interesting As mentioned earlier open efﬁcient algorithm learning multiple clause simple logic programs path graph background knowledge target predicate unary In view negative results interesting study learnability enlarged hypothesis space Acknowledgements We grateful Bob Sloan Stefan Wrobel helpful discussions comments This work partially supported ESPRIT IV Long Term Research Project ILP T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 87 II No 20237 György Turán partially supported NSF grant CCR9800070 OTKA grant T52721 Appendix A Proof Lemma 22 In order prove Lemma 22 ﬁrst following proposition Proposition A1 Let B background knowledge t 0 b1 bt 1 a0 c constants Then Bt cid16b1bt1a0ccid17 B Bt 1 cid16b1bt1a0a0ccid17 B Proof Let ϕ Bt 1 B single rooted homomorphism mapping b1 bt 1 a0 a0 c consider function ϕcid9 Bt B deﬁned ϕcid9 c1 ct cid30 ϕc1 ct ct In order ϕcid9 homomorphism let assume simplicity B single binary relation viewed directed graph The general case analogous Let cid12u u1 ut cid12v v1 vt vertices Bt Then cid12u cid12v edge Bt cid2 u1 ut ut v1 vt vt cid2 ϕu1 ut ut ϕv1 vt vt ϕcid9cid12u ϕcid9cid12v edge B cid3 edge Bt 1 cid3 edge B Thus ϕcid9 homomorphism Furthermore ϕcid9 maps b1 bt 1 a0 c ϕcid9b1 bt 1 a0 ϕb1 bt 1 a0 a0 c onlyif Let ϕ Bt B homomorphism mapping b1 bt 1 a0 c let π Bt 1 Bt projection π c1 ct ct 1 cid30 c1 ct Since π homomorphism ϕπ Bt 1 B homomorphism mapping b1 bt 1 a0 a0 c Proof Lemma 22 The statement obvious m 1 For m 1 let P cid9 predicate arity m let Aij ground atom P cid9b1 bm cid8 bk ai a0 k j k 1 m Consider set Scid9 Aij 1 cid1 cid1 d 1 cid1 j cid1 m 88 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Applying Theorem 20 ii Proposition A1 follows single rooted homomorphism Bmd1 B mapping cid12bj ai cid12bj md 1 tuple formed j th arguments P cid9atoms Scid9 Aij Hence multiply rooted homomorphism Bmd1 B mapping cid12bk a0 k 1 j 1 j 1 m cid12bj ai Thus Theorem 20 Aij GBS cid9 Aij Hence Aij GBScid9cid9 Scid9cid9 Scid9 Aij Also noted domain member CBm Thus follows Scid9 shattered CBm The lemma holds VCdimCBm cid2 Scid9 md Appendix B Forests Sharper bounds VCdimension Proof Proposition 49 Let a0 ad vertices largest possible d directed path pi length 2i 1 ending a0 having ai middle f iai a0 1 d pi pj disjoint exception common endpoint a0 1 cid1 j cid1 d path length d 1 starting a0 See Fig B1 If n number constants form required construction add isolated vertices From construction follows cid2 f i1ak h 1 d f i1ai B1 cid2 h cid3 cid3 min 0cid1kcid1d kcid6i Let P unary predicate symbol Then Lemma 40 Theorem 43 imply a0 a1 ad satisfy conditions Lemma 22 As dd 1 cid1 n d 1d 2 d n 2 VCdimCBm cid2 md m n 2 Proof Theorem 50 As proof Theorem 32 Corollary 3 sufﬁcient S set ground atoms select subset Scid9 size n S generates GBS The process selecting Scid9 analogous Om proof Theorem 32 complicated First note Theorems 42 43 Lemmas 40 41 imply GBScid9 GBS holds Scid9 satisﬁes following conditions IvarScid9 IvarS HpairsScid9 HpairsS HconstScid9 j HconstS j j 1 cid1 j cid1 m hf lcid12bjScid9 hf lcid12bjS l cid2 0 j 1 cid1 j cid1 m df cid12buScid9 cid12bvScid9 df cid12buS cid12bvS u v HpairsS df cid12bjScid9 cid12aScid9 df cid12bjS cid12aS HconstS j j 1 cid1 j cid1 m cid12bjScid9 respectively cid12bjS denotes tuple formed j th arguments atoms Scid9 respectively S cid12aScid9 respectively cid12aS Scid9tuple respectively Stuple T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 89 Fig B1 The construction tree large shattered set In rest proof omit indices product constants follow context The main steps proof deﬁned conditions summarized lemmas follows First deal conditions concerning heights concerning distances Lemma B1 Height lemma Let G V E forest n vertices let Y subset V Then subset Y cid9 Y l cid2 0 holds cid3 cid3 B2 min aY Y cid9 cid1 cid2 f la h 2n cid2 min aY cid9 h f la Proof Let Y cid9 b1 bd minimal subset satisfying B2 Then 1 d exists li 0 cid1 li n B3 cid2 h f li bi cid3 cid2 h f li bj cid3 min 1cid1jcid1d j cid6i Clearly li cid6 lj cid6 j assume loss generality 0 cid1 l1 l2 ld n p1 pd1 pairwise vertex disjoint Let pi path bi f li bi 1 d 1 We like B4 As li s different implies n cid2 1 d 1 dd 12 d 2n 1 lemma follows 90 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 In order B4 ﬁrst note cid2 h f ld bd f ld bi cid2 h cid3 cid3 f ld bi deﬁned f lbi deﬁned 1 d 1 l cid1 ld It holds general k l f lb deﬁned hf kb hf lb Hence B3 cid3 cid2 f li bi h f lj bj f li bj cid2 h cid2 h B5 cid3 cid3 j 1 cid1 j cid1 d 1 Now assume pi pj 1 cid1 j cid1 d 1 common vertex Then endpoints descendant B5 implies f li bi f lj bj Also bj lcabi bj f li bi holds f libi f sbj s The ﬁrst inequality B5 implies s li But f lj bi f lj li f li bi f lj li cid2 cid3 cid2 f sbj cid3 f lj li sbj Now 0 cid1 lj li s lj f lj bi f lj bj This implies hf lj bi hf lj bj contradicts B3 j This proves B4 completing proof lemma The following lemma deals situation points belong different connected components product forest belong connected component partial product It states points disconnected adding factors partial products Lemma B2 Disconnecting lemma Let G V E forest let cid12b1 b11 bt1 cid12b2 b12 bt2 vertices Gt t 1 belonging different connected components Assume b11 bi1 b12 bi2 belong connected component Gi cid1 t 2 Then j k j k cid1 t b11 bi1 bj1 bk1 b12 bi2 bj2 bk2 belong different connected components Gi2 Proof Consider set Dj Dbj1 bj2 lengths possible walks bj1 bj2 G 1 cid1 j cid1 t The assumptions imply D1 Dt cid2 cid3 E D1 Di D b11 bi1 b12 bi2 cid6 B6 Here cid6 d1 l d2 l 0 cid1 l cid1 d cid7 E d d1 d2 df b11 bi1 b12 bi2 Now consider sets Dj j If E Dj j j arbitrary k satisﬁes requirements Otherwise E Dj cid6 d1 l d2 l rj cid1 l cid1 sj cid7 rj cid1 sj j j cid1 t T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 91 Fig B2 Example case discussed Lemma B2 If intervals rj sj nonempty intersection nonempty intersection This called Helly property intervals seen noting minij cid1t sj belongs interval But contradict D1 Dt Hence j k E Dj Dk E Dj E Dk values satisfy requirements Remark The following example shows adding factor sufﬁcient Let G forest shown Fig B2 1 t 3 cid12b1 b11 b21 b31 cid12b2 b12 b22 b32 shown ﬁgure The lemma considers case set points belongs connected component product In case belong connected component partial product On hand distances partial product differ distances product It follows repeated applications lemma distances ﬁxed adding factors partial product number points set Lemma B3 Distance lemma Let G V E forest let T T 1 subset Gt t 1 belonging single connected component Then 1 cid1 cid1 t proper partition T1 T2 T df cid12br cid12bs df bir bis cid12br T1 cid12bs T2 Proof Let cid12b lcaT assume ﬁrst cid12b T Using Proposition 34 choose cid12bu cid12bv T lcacid12bu cid12bv cid12b let df cid12bu cid12bv d1 d2 From assumption cid12b T follows d1 d2 0 By Lemma 39 d1 d2 df biu biv dxj max j 1t df bju bjv dxj dyj j 1 t max j 1t cid2 cid3 dyj The projection ρ Gt ith component homomorphism It follows deﬁnition cid12bu cid12bv ρ injective d1 d2walk cid12bu cid12bv Hence ρcid12b lcabiu biv ρcid12b common ancestor set ρT consisting images elements T holds cid2 cid3 ρcid12b lca ρT B7 92 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 Now deﬁne cid6 cid12bk T bik biu descendants child ρcid12b T1 cid7 T2 T T1 Then cid12bu T1 cid12bv T2 T1 T2 proper partition T Consider cid12br T1 cid12bs T2 If lcacid12br cid12bs cid12b B7 lcabir bis ρ cid2 lcacid12br cid12bs cid3 ρcid12b lca cid3 cid2 ρT contradicting assumption bir bis descendants different children ρcid12b Thus lcacid12br cid12bs cid12b The homomorphism ρ injective shortest walk cid12br cid12bs df cid12br cid12bswalk bis belong T1 Thus holds df cid12br cid12bs df bir bis It remains consider case cid12b T informally T consists single path leading cid12b By deleting path corresponds isomorphic paths component reduce problem previous case More precisely let F cid12x cid12y T cid12x cid12y set vertices cid12x T let topT cid6 cid9 T cid12b cid12b cid9 lca cid2 T F cid12bcid9 cid3cid7 set vertices common ancestor vertices T T topT corresponding trivial case vertices T linearly ordered Otherwise T topT satisﬁes assumption previous case lcaT topT T topT Let T1 T2 partition produced set consider partition T1 topT T2 Then T2 topT cid12bs cid12br cid12bs T2 cid12br topT Hence df cid12bs cid12br df bis bir cid12bs T2 cid12br topT obvious shortest walks fact directed paths case We need technical lemma analogous previous states order ﬁx distances nonconstant vertex constant vertices sufﬁcient add single additional factor product As lemma distinguish constant nonconstant vertices deal forest T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 93 background knowledge B forest G previous lemmas We write Hconstcid12b set constants connected component cid12b Lemma B4 Constant lemma Let background knowledge B forest cid12b b1 bt nonconstant vertex Bt t 1 Hconstcid12b cid6 Then j 1 cid2 df b1 bj Hconstcid12b cid3 df cid12b cid12a Proof If bi bj j Hconstcid12bj f lcid12bj constant vertex Thus b1 cid6 lcab1 bt We bj lcab1 bj lcab1 bt satisﬁes requirements Such bj exists Proposition 34 Let Hconstcid12b let df cid12b cid12a d1 d2 Then f d1bi f d2a B8 1 t Thus f d2a common ancestor bi s ancestor u lcab1 bt f lu f d2a l cid2 0 It follows B8 f dbi u d cid1 d1 1 t If l 0 df bi d l d2 1 t claim holds bj The true l d2 0 If l 0 d2 0 proper descendant u Thus ancestor b1 bj different subtrees u If ancestor b1 respectively bj df cid12b cid12a df b1 d1 d2 respectively df cid12b cid12a df bj d1 d2 implying lemma Now complete proof theorem Let cid7 cid6 P b11 b1m P bt1 btm S set ground atoms We construct subset Scid9CS generating GBS steps Construction S1 Applying Lemma B1 set constants b1j btj j th arguments j 1 m obtains set S1 m 2n atoms Construction S2 By deﬁnition holds IconstS1 IconstS Consider IconstS1 IconstS This set contains arguments j atom S1 j th argu ment atom S different j th argument For j pick atom add S1 Let enlarged set S2 We added m atoms S1 Construction S3 Again deﬁnition holds HpairsS2 HpairsS Consider HpairsS2 HpairsS This set contains pairs u v uth vth arguments S2 connected du dvwalk du dv hold S In words cid12bu cid12bv belong different connected components hold form product structure corresponding S2 Applying Lemma B2 m 1 times increase number connected components number S adding 2m atoms Let new set atoms Scid9 3 By deﬁnition 94 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 holds HconstScid9 3 j HconstS j j 1 m Note HconstS j contains constants belonging tree B Thus applying Lemma B2 m times adding 2m atoms form set S3 HconstS3 j HconstS j j At point partitions nonconstant product vertices constants connected components products corresponding S3 S On hand distances vertices S3product smaller corresponding distances S product Construction S4 Now applying Lemma B3 m 1 times adding m 1 new atoms S3 obtain set Scid9 4 distances nonconstant product vertices Scid9 4product corresponding distances S product Note application lemma forms partition given set points distances points different blocks partition obtain ﬁnal value Thus need m 1 applications Then m applications Lemma B4 adding m atoms achieves goal distances nonconstant product vertices constants forming set S4 atoms Here note n constant vertices care single application lemma works distances nonconstant product vertex constant vertices Thus needs m applications Let Scid9 S4 From construction follows Scid9 satisﬁes conditions given beginning proof theorem GBS GBScid9 By construction Scid9 cid1 m 2n Om Thus Corollary 3 implies number upper bound VCdimension CBm Appendix C Cycle graphs Sharper bounds VCdimension Proof Proposition 61 Let B consist cycles K1 Kl prime lengths p1 pl 1 l Then proof Theorem 58 let ai belong Ki Propositions 53 55 imply P a1 P al shattered subset Hence Corollary 23 implies VCdimCBm cid2 ml 1 m cid18 cid21 cid19 n log n nlog n upper bound Proof Theorem 62 First O VCdimension CB1 Let B cycle graph consider shattered set S P b1 P bd Applying Theorem 57 m 1 holds Lcyclebi cid4 lcm cid2 Lcycleb1 Lcyclebi1 Lcyclebi1 Lcyclebd cid3 1 d Thus distinct prime qi number li 0 q li dcid20 Lcyclebi q li dcid20 cid4 Lcyclebj j cid6 Hence dcid20 n cid2 Lcyclebi cid2 i1 i1 q li cid2 qi i1 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 95 Thus n large sum ﬁrst d primes As noted proof Theorem 58 sum ﬁrst x primes x2 log x This implies d O nlog n The extension proof arbitrary m similar second proof Theorem 32 References 1 D Angluin Learning propositional Horn sentences hints Technical Report YALEDCSRR590 Dept Computer Science Yale University New Haven CT 1987 2 H Arimura Learning acyclic ﬁrstorder Horn sentences entailment M Li A Maruoka Eds Proc 8th International Workshop Algorithmic Learning Theory ALT97 Lecture Notes Artiﬁcial Intelligence Vol 1316 Springer Berlin 1997 pp 432445 3 A Blumer A Ehrenfeucht D Haussler MK Warmuth Learnability VapnikChervonenkis dimension J ACM 36 4 1989 929965 4 W Buntine Generalized subsumption application induction redundancy Artiﬁcial Intelli gence 36 1988 375399 5 WW Cohen PAClearning nonrecursive Prolog clauses Artiﬁcial Intelligence 79 1995 138 6 WW Cohen PAClearning recursive logic programs Efﬁcient algorithms J Artiﬁcial Intelligence Res 2 1995 501539 7 WW Cohen PAClearning recursive logic programs Negative results J Artiﬁcial Intelligence Res 2 1995 541573 8 WW Cohen H Hirsh The learnability description logics equality constraints Machine Learning 17 23 1994 169200 9 WW Cohen CD Page Polynomial learnability inductive logic programming Methods results New Generation Computing Special Issue Inductive Logic Programming 13 34 1995 369410 10 E Dantsin T Eiter G Gottlob A Voronkov Complexity expressive power logic programming Proc 12th Annual IEEE Conference Computational Complexity Ulm Germany IEEE Computer Society Press 1997 pp 82101 11 BA Davey HA Priestley Introduction Lattices Order Cambridge University Press Cambridge 1990 12 L De Raedt Logical settings conceptlearning Artiﬁcial Intelligence 95 1997 187201 13 L De Raedt S Džeroski First order j kclausal theories PAClearnable Artiﬁcial Intelligence 70 1994 375392 14 S Džeroski S Muggleton S Russell PAClearnability determinate logic programs D Haussler Ed Proc 5th Annual ACM Workshop Computational Learning Theory COLT92 ACM Press New York 1992 pp 128135 15 HD Ebbinghaus J Flum Finite Model Theory Perspectives Mathematical Logic Springer Berlin 1995 16 M Frazier Matters Horn features computational learning theory landscape The notion membership PhD Thesis Dept Computer Science University Illinois UrbanaChampaign IL 1994 Technical Report UIUCDCSR941858 17 M Frazier L Pitt Learning entailment An application propositional Horn sentences Proc 10th International Conference Machine Learning Amherst MA Morgan Kaufmann San Mateo CA 1993 pp 120127 18 M Frazier L Pitt CLASSIC learning Machine Learning 25 1996 151193 19 M GerébGrauss Complexity learning onesided examples 1989 Unpublished 20 G Gottlob Subsumption implication Inform Process Lett 24 2 1987 109111 21 W Gutjahr E Welzl G Wöginger Polynomial graphcolorings Discrete Appl Math 35 1992 2945 22 R Häggkvist P Hell DJ Miller V Neumann Lara On multiplicative graphs product conjecture Combinatorica 8 1988 6374 96 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 23 GH Hardy EM Wright An Introduction Theory Numbers 5th edn Oxford University Press London 1979 24 D Haussler Learning conjunctive concepts structural domains Machine Learning 4 1 1989 740 25 D Haussler M Kearns N Littlestone MK Warmuth Equivalence models polynomial learnability Inform Comput 95 2 1991 129161 26 P Hell X Zhu Homomorphisms oriented paths Discrete Math 132 1994 107114 27 WA Hodges Model Theory Cambridge University Press Cambridge 1993 28 T Horváth Z Alexin T Gyimóthy S Wrobel Application different learning methods Hungarian partofspeech tagging S Džeroski P Flach Eds Proc 9th International Workshop Inductive Logic Programming Lecture Notes Artiﬁcial Intelligence Vol 1634 Springer Berlin 1999 pp 128139 29 T Horváth RH Sloan G Turán Learning logic programs product homomorphism method Y Freund R Schapire Eds Proc 10th Annual Conference Computational Learning Theory COLT 97 Nashville TN ACM Pres New York 1997 pp 1020 30 T Horváth RH Sloan G Turán Learning logic programs random classiﬁcation noise S Muggleton Ed Proc 6th International Workshop Inductive Logic Programming ILP96 Lecture Notes Artiﬁcial Intelligence Vol 1314 Springer Berlin 1997 pp 315336 31 T Horváth G Turán Learning logic programs structured background knowledge L De Raedt Ed Advances Inductive Logic Programming IOS Press Amsterdam 1996 pp 172191 32 M Kearns Efﬁcient noisetolerant learning statistical queries J ACM 45 6 1998 9831006 33 MJ Kearns UV Vazirani An Introduction Computational Learning Theory MIT Press Cambridge MA 1994 34 R Khardon Learning functionfree Horn expressions Machine Learning 37 3 1999 241275 35 JU Kietz Some lower bounds computational complexity inductive logic programming PB Brazdil Ed Proc European Conference Machine Learning ECML93 Lecture Notes Artiﬁcial Intelligence Vol 667 Springer Berlin 1993 pp 115123 36 JU Kietz Induktive Analyse Relationaler Daten PhD Thesis Technische Universität Berlin Berlin 1996 37 JU Kietz S Džeroski Inductive logic programming learnability SIGART Bull 5 1 1994 2232 38 DE Knuth The Art Computer Programming Vol 2 Seminumerical Algorithms 2nd edn Addison Wesley Reading MA 1981 39 N Lavraˇc S Džeroski Inductive Logic Programming Techniques Applications Ellis Horwood Chichester 1994 40 M Li PMB Vitányi Learning simple concept simple distributions SIAM J Comput 20 5 1991 911935 41 JW Lloyd Foundations Logic Programming 2nd edn Springer Berlin 1987 42 L Lovász Combinatorial Problems Exercises NorthHolland Amsterdam 1979 43 W Maass G Turán On learnability predicate logic Proc BarIlan Symposium Foundations Artiﬁcial Intelligence BISFAI95 1995 pp 7585 44 E Martin DN Osherson Elements Scientiﬁc Inquiry MIT Press Cambridge MA 1999 45 DS Mitrinovic J Sándor B Crstici Handbook Number Theory Mathematics Its Applications Vol 351 Kluwer Academic Dordrecht 1996 46 S Muggleton Inductive logic programming Proc 1st Conference Algorithmic Learning Theory Ohmsma Tokyo Japan 1990 pp 4362 47 S Muggleton L De Raedt Inductive logic programming Theory methods J Logic Program ming 1920 1994 629679 48 S Muggleton C Feng Efﬁcient induction logic programs S Muggleton Ed Inductive Logic Programming Academic Press New York 1992 pp 281298 49 BK Natarajan On learning boolean functions Proc ACM Symposium Theory Computing STOC87 ACM Press New York 1987 pp 296304 50 BK Natarajan Machine Learning A Theoretical Approach Morgan Kaufmann San Mateo CA 1991 51 BK Natarajan Probably approximate learning sets functions SIAM J Comput 20 2 1991 328 351 52 J Nešetˇril A Pultr On classes relations graphs determined subobjects factorobjetcs Discrete Math 22 1979 187200 T Horváth G Turán Artiﬁcial Intelligence 128 2001 3197 97 53 SH NienhuysCheng R Wolf Foundations Inductive Logic Programming Lecture Notes Artiﬁcial Intelligence Vol 1228 Springer Berlin 1997 54 CD Page AM Frisch Generalization learnability A study constrained atoms S Muggleton Ed Inductive Logic Programming Academic Press London 1992 pp 2961 55 L Pitt LG Valiant Computational limitations learning examples J ACM 35 4 1988 965984 56 GD Plotkin A note inductive generalization B Meltzer D Michie Eds Machine Intelligence Vol 5 Edinburgh University Press Edinburgh 1970 pp 153163 57 GD Plotkin A note inductive generalization B Meltzer D Michie Eds Machine Intelligence Vol 6 Edinburgh University Press Edinburgh 1971 pp 101124 58 L Pottier Algorithmes complétion et généralisation en logique du premier ordre PhD Thesis Université Nice 1989 59 L Pottier Generalisation termes en theorie equationnelle Cas associatifcommutatif Technical Report RR1056 INRIA Institut National Recherche en Informatique et en Automatique 1989 60 P Tadepalli S Russell Learning examples membership queries structured determinations Machine Learning 32 3 1998 245295 61 I Tsapara G Turán Learning atomic formulas prescribed properties P Bartlett Y Mansour Eds Proc 11th Annual Conference Computational Learning Theory COLT98 Madison WI ACM Press New York 1998 pp 166174 62 LG Valiant A theory learnable Comm ACM 27 11 1985 11341142 63 LG Valiant Robust logics Proc ACM Symposium Theory Computing STOC99 ACM Press New York 1999 pp 642651 64 H Zhou Multiplicativity Part I Variations multiplicative graphs digraphs J Graph Theory 15 1991 469488 65 H Zhou Multiplicativity Part II Nonmultiplicative digraphs characterization oriented paths J Graph Theory 15 1991 489509 66 JL Lassez M Maher K Mariott Uniﬁcation revisited J Minker Ed Foundations Deductive Databases Logic Programming Morgan Kaufmann Los Altos CA 1987 pp 587625