Artiﬁcial Intelligence 174 2010 9841006 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Understanding scalability Bayesian network inference clique tree growth curves Ole J Mengshoel Carnegie Mellon University NASA Ames Research Center Mail Stop 2693 Moffett Field CA 94035 United States r t c l e n f o b s t r c t Article history Received 16 January 2009 Received revised form 18 May 2010 Accepted 18 May 2010 Available online 25 May 2010 Keywords Probabilistic reasoning Bayesian networks Clique tree clustering Clique tree growth CV ratio Continuous approximation Gompertz growth curves Controlled experiments Regression One main approaches performing computation Bayesian networks BNs clique tree clustering propagation The clique tree approach consists propagation clique tree compiled BN introduced 1980s lack understanding clique tree computation time depends variations BN size structure In article improve understanding developing approach characterizing clique tree growth function parameters computed polynomial time BNs speciﬁcally ratio number BNs nonroot nodes number root nodes ii expected number moral edges moral graphs Analytically partition set cliques clique tree different sets introduce growth curve total size set For special case bipartite BNs sets growth curves mixed clique growth curve root clique growth curve In experiments random bipartite BNs generated BPART algorithm studied systematically increase outdegree root nodes bipartite Bayesian networks increasing number leaf nodes Surprisingly root clique growth wellapproximated Gompertz growth curves Sshaped family curves previously growth processes biology medicine neuroscience We believe research improves understanding scaling behavior clique tree clustering certain class Bayesian networks presents aid tradeoff studies clique tree clustering growth curves ultimately provides foundation benchmarking developing improved BN inference machine learning algorithms 2010 Elsevier BV All rights reserved 1 Introduction Bayesian networks BNs play central role wide range automated reasoning applications including diagnosis sensor validation probabilistic risk analysis information fusion decoding errorcorrecting codes 6465938376043 58 A crucial issue reasoning BNs forms modelbased reasoning computational scalability Most BN inference problems computationally hard general case 1063611 rea son concerned scalability One progress scalability question studying classes problem instances analytically experimentally Such problem instances come applications randomly generated In area application BNs encouraging discouraging scalability results reported For example prominent bipartite BN medical diagnosis known intractable current technology 64 Decoding errorcorrecting codes understood BN inference tractable empirically solvable high reliability inexact BN inference 2037 On hand wellknown BNs Email address OleMengshoelsvcmuedu 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201005007 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 985 treestructured including socalled naive Bayes model solvable polynomial time exact inference algorithms There encouraging empirical results application BNs close treestructured generally application BNs highly connected 2643 Clique tree clustering inference takes form propagation clique tree compiled BN currently prominent BN inference algorithms 33262 The performance tree clustering algorithms depends BNs treewidth optimal maximal clique size BNs induced clique tree 161115 The performance exact BN inference algorithms depends treewidth A key research question size clique tree generated BN consequently inference time depends structural measures BNs One way investigate use random generation distributions problem instances 665115223 Taking approach increasing ratio CV number leaf nodes C number root nodes V bipartite BNs easyhardharder pattern approximately exponential growth previously observed clique tree clustering certain class BNs BPART BNs 45 In article develop precise understanding easyhardharder pattern This formulating macroscopic approximate models clique tree growth means restricted growth curves illustrate bipartite BNs created BPARTalgorithm 45 For sake work assume clique tree propagation algorithm operating clique tree compiled BN executed order answer probabilistic queries We introduce random variable total clique tree size This random variable case bipartite BNs sum random variables size root cliques size mixed cliques Reﬂecting random variable total clique tree size introduce continuous growth curve total clique tree size sum growth curves size root cliques mixed cliques Of particular growth curve root clique size Gompertz curves form ge g ζ γ parameters turn useful A key ﬁnding Gompertz growth curves justiﬁed theoretical grounds ﬁt experimental data generated BPART algorithm 45 While emphasize bipartite BNs article discuss generalize arbitrary BNs multiple growth curves translating arbitrary BNs bipartite BNs factor graphs 3270 ζ e γ x For experimentation sampled bipartite BNs implementation BPART algorithm For number root nodes V V 20 V 30 The number leaf nodes varied creating BNs varying hardness 100 BNs CV level randomly generated A clique tree inference employing minimum ﬁllin weight heuristic generate clique trees sampled BNs Let W random variable representing number moral edges moral graphs induced random BNs In addition x CV consider x EW independent variable In experiments compared different growth curves investigated x CV versus x EW independent variables Gompertz growth curves Linear regression obtain values parameters ζ γ based linear form Gompertz growth curve values g obtained analysis Gompertz growth curves common biological medical neuroscience research 43517 previously characterize clique tree growth earlier conference paper 41 article extends We provide improved results compared previous research easyhardharder pattern approximately exponential growth upper bounds optimal maximal clique size function CV ratio established 45 We believe research signiﬁcant following reasons First analytical growth curves improve understand ing clique tree clusterings performance certain class BNs BPART BNs Consider Keplers laws planetary motion developed Brahes observational data planetary movement There need develop similar laws clique tree clusterings performance article obtain laws form Gompertz growth curves BPART BNs 45 While admittedly strong empirical basis Gompertz growth curves signiﬁcantly better ﬁt raw data alternative curves Consequently provide better insight underlying mechanisms clique tree clustering algorithm approximately predict performance algorithm Since performance exact BN inference algorithms including conditioning 5511 elimination algorithms 3471 14 depends optimal maximal clique size results signiﬁcance algorithms A sec ond beneﬁt growth curves summarize performance different BN inference algorithms different implementations algorithm benchmark sets problem instances aid evaluations1 Suppose growth curves g1x g2x obtained benchmarking slightly different clique tree algorithms Compared looking evaluating potentially large amounts raw data easier understand perfor mance difference algorithms studying curves g1x g2x comparing respective Gompertz curve parameter values ζ1 γ1 versus ζ2 γ2 A beneﬁt growth curves provide estimates resource consumption terms clique tree size estimates easily translated requirements memory size inference time Hence approach enables tradeoff studies resource consumption requirements versus resource bounds important resourcebounded reasoners 4840 use wants account BN structure learning computational resources needed reasoning The rest article organized follows After introducing notation background concepts related Bayesian networks clique tree clustering Section 2 study context BPART algorithm development 1 Such evaluations performed example recent UAI conferences httpsslieewashingtonedubilmesuai06InferenceEvaluation httpgraphmodicsucieduuai08 details Application BNs benchmarking httpgeniesispittedunetworkshtml httpwwwcs hujiacillabscompbioRepository 986 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 growth BNs causing corresponding clique tree growth Speciﬁcally Section 3 study issue independent variables growth curves particular CV ratio expected number moral edges EW discuss growth curves provide macroscopic model clique trees grow In Section 4 discuss connection random graphs BPART model In Section 5 present experiments BNs generated BPART algorithm varying number root leaf nodes We compare different mathematical models growth ﬁnd Gompertz growth curves best ﬁt sample data We conclude indicate future research directions Section 6 2 Background Graphs particular directed acyclic graphs introduced following deﬁnition play key role Bayesian networks Deﬁnition 1 Directed acyclic graph DAG Let G X E nonempty directed acyclic graph DAG nodes X X1 Xn n cid2 1 edges E E1 Em m cid2 0 An ordered tuple E Y X 0 cid3 cid3 m X Y X represents directed edge Y X Π X denotes parents X Π X Y Y X E Similarly Ψ X denotes children X Ψ X Z X Z E Z X The outdegree indegree node X deﬁned o X Ψ X X Π X respectively In rest article assume simplicity DAGs BNs nonempty explicitly stated Deﬁnition 1 The following classiﬁcation nodes DAGs including BNs turns useful discuss performance BN inference algorithms Deﬁnition 2 Let G X E nonempty DAG X X If X 0 X root node If X 0 X nonroot node If X 0 o X 0 X leaf node If o X 0 X nonleaf node If o X 0 X 0 X trunk nonleaf nonroot node With concepts Deﬁnition 2 hand classify nodes DAG follows Deﬁnition 3 Let G X E DAG We identify following subsets X V X X X 0 root nodes C X X X 0 o X 0 leaf nodes T X X X 0 o X 0 trunk nodes V X X X 0 nonroot nodes C X X o X 0 nonleaf nodes A Bayesian network BN DAG associated set conditional probability distributions 56 In following x deﬁnition let n X let π Xi represent complete instantiation parents Π Xi Xi words π Xi projection complete assignment x X1 x1 Xn xn Deﬁnition 4 Bayesian network A Bayesian network tuple β X E P X E DAG augmented conditional probability distributions P Pr X1 Π X1 Pr Xn Π Xn Here Pr Xi Π Xi conditional probability distribution Xi X The independence assumptions encoded X E imply joint probability distribution Prx Prx1 xn PrX1 x1 Xn xn ncid2 i1 Prxi π Xi 1 In article restrict discrete random variables BN node mean discrete BN node Let BN node X X states x1 xm We use notation Ω X Ω X x1 xm represent state space X In setting conditional probability distribution Pr Xi Π Xi denoted conditional probability table CPT A BN provided input evidence clamping zero nodes observed states Given evidence answers different probabilistic queries computed means BN In context concept instantiation explanation nonclamped nodes key formally deﬁned follows Deﬁnition 5 Explanation Consider BN β X E P X X1 Xn evidence e X1 x1 Xm xm 0 cid3 m n An explanation x deﬁned x xm1 xn Xm1 xm1 Xn xn One interested computing answers queries form Prx e particular ﬁnding probable e cid2 Prx e explanation x In addition explanation MPE An MPE explanation x MPE computation posterior marginals Pr X e X X great To compute answers queries complete incomplete algorithms Bayesian network computation Complete algorithms include clique tree propagation 3322562 conditioning 5511 variable elimination 347114 arithmetic circuit Prx OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 987 evaluation 1298 Incomplete algorithms particular stochastic local search algorithms MPE 273921424446 maximum posteriori hypothesis MAP 5253 computation An important distinction exists algorithms rely offline compilation step example clique tree propagation arithmetic circuit evaluation example variable elimination stochastic local search Compilation beneﬁts comes integration resourcebounded systems including hard realtime systems 4840 Our main emphasis article compilation particular Hugin clique tree clustering approach 3325 clique trees play central role Deﬁnition 6 Clique tree A clique tree βcid6cid6cid6 Γ Φ BN β X E P consists nodes cliques Γ edges Φ Here Γ Φ undirected graph tree needs adhere following conditions clique γ Γ γ X ii family X E appear clique γ Γ iii node X X X γi X γ j X γk γk Γ γk path γi γ j βcid6cid6cid6 The Hugin approach interesting right addition wellestablished relationship arithmetic circuits 54 A clique tree2 βcid6cid6cid6 online computation constructed BN β X E P following way Hugin algorithm 332 A moral graph βcid6 ﬁrst constructed making undirected copy β augmenting moral edges follows For node X X Hugin adds moralization step βcid6 moral Second Hugin creates triangulated graph βcid6cid6 edge pair nodes Π X edge exists βcid6 heuristically adding ﬁllin edges βcid6 chordless cycle length greater exists Third clique tree βcid6cid6cid6 A clique tree constructed sequentially nodes γi γ j clique tree nodes contain γi γ j This known running intersection property informally enforces global consistency local consistency enabling computation marginals MPEs Each CPT Pr X Π X P assigned clique containing X Π X created triangulated graph βcid6cid6 Hugin compute marginals 33 MPEs 13 These computations rely following wellknown result Using βcid6cid6cid6 Theorem 7 Let PrX probability distribution induced BN β let βcid6cid6cid6 Γ Φ corresponding clique tree Then distribution expressed PrX cid2 cid3 cid2 Prγi γi Γ γi γ jΦ Prγi γ j The size clique tree βcid6cid6cid6 essentially determines compilation propagation times computation MPEs marginals The following parameters useful characterizing clique trees computation times algorithms use clique trees Deﬁnition 8 Clique tree parameters Let Γ γ1 γη set cliques clique tree βcid6cid6cid6 Γ Φ The largest clique Γ terms number BN nodes deﬁned cid12Γ arg max γ Γ cid4 cid5 γ 2 cardinality largest clique terms number nodes deﬁned cΓ cid12Γ The state space size s clique γ Γ deﬁned cid2 sγ Ωγ Ω X Xγ X X node β X E P The maximal clique Γ terms state space size deﬁned cid4 mΓ arg max γ Γ cid5 Ωγ maximal clique size m cid6 Γ smΓ The total clique tree size βcid6cid6cid6 cid6 deﬁned kΓ sγ Ωγ γ Γ γ Γ The width wΓ clique tree Γ deﬁned wΓ cΓ 1 size clique trees largest clique width closely related In general clique tree BN interesting consider optimal clique trees deﬁned follows 2 For simplicity denote slightly different concepts authors generally distinguish junction trees clique trees article 3 4 5 988 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Deﬁnition 9 Clique tree optimization Let Γ Γ1 Γ2 set clique tree cliques clique trees βcid6cid6cid6 2 BN β The clique tree optimal minimal largest clique terms number nodes deﬁned 2 1 βcid6cid6cid6 LΓ arg min Γ Γ cid4 cid5 cid12Γ 6 optimal largest clique size cid12Γ cid12LΓ The optimal clique tree terms minimizing total size deﬁned 5 K Γ arg min Γ Γ cid4 cid5 kΓ optimal minimal total clique tree size deﬁned k Γ kK Γ 7 It noted quantities speciﬁcally 2 6 Deﬁnition 9 Deﬁnition 8 strictly graphtheoretic Other quantities speciﬁcally 7 4 account size state spaces BN nodes consequently particular researchers interested scalability computation clique tree clustering The performance complete BN inference algorithms depend treewidth w Γ cid12Γ 1 3315 When BN β clique trees Γ1 Φ1 Γ2 Φ2 obvious ﬁned w context simply write w minimal largest clique clique trees BN Treewidth computation NPcomplete 3 greedy triangulation heuristics compute upper bounds treewidth opti mal maximal clique size typically practice 31 A key research question investigate article clique tree size relates parameters computed BN polynomial time following parameters cid12 1 cid12 V V number root nodes BN V cid2 1 T T number trunk nodes BN T cid2 0 C C number leaf nodes BN C cid2 0 total number BN nodes n C V T P avg average number parents nonroot nodes V X BN 1 cid3 P avg cid3 N 1 Savg average number states BN nodes X Savg cid2 1 Using parameters study bipartite BNs article In bipartite BN β X E P nodes X partitioned root nodes V leaf nodes C according following deﬁnition Deﬁnition 10 Bipartite DAG Let G X E DAG If X split partite sets V X X X 0 root nodes C X X X 0 leaf nodes V C E V V C C G bipartite DAG While approach general discussed Section 33 note important classes application BNs bipartite signiﬁcant induced subgraphs bipartite Naïve Bayes classiﬁers example special case bipartite BNs root node Application areas bipartite BNs include gas path diagnosis turbofan jet engines 60 sensor validation diagnosis rocket engines 6 diagnosis networks 59 medical diagnosis 64 decoding errorcorrecting codes 37 A wellknown bipartite BN medical diagnosis QMRDT diseases root nodes symptoms leaf nodes 64 QMRDT compute likely instantiation disease nodes probable explanation given known symptoms 642450 In research decoding errorcorrecting codes close relationship established Bayesian network computation 3837 It turns subgraph induced nodes corresponding hidden information codeword bits decoding BN forms bipartite BN 38 Fig 7 Bipartite BNs generalize satisﬁability SAT instances root nodes correspond propositional logic variables leaf nodes correspond propositional logic clauses 636145 Special inference algorithms designed bipartite BNs example study approximate inference algorithms bipartite BNs Ng Jordan 50 Finally general BNs nontrivial bipartite components bipartite BNs form stepping stone general multipartite BNs For purpose article emphasis randomly generated BNs approach admits systematic investigation BN inference algorithms 662345 Bipartite BNs generated randomly BPART algorithm 45 generalization algorithm randomly generates hard easy problem instances satisﬁability 47 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 989 Fig 1 Two classes Class A Class B bipartite graphs Bayesian networks BNs In Class A Class B BNs leaf nodes number parents P P 2 In Class A BNs root nodes k k 1 children k cid2 0 In Class B BNs number children vary root nodes Fig 2 Compilation BPART BN β clique tree βcid6cid6cid6 triangulated graph βcid6cid6 leads cliques V 4 V 1 V 2 V 4 V 2 V 3 clique tree βcid6cid6cid6 There loop V 1 V 2 V 3 V 4 moral graph βcid6 leading ﬁllin edge V 2 V 4 The BPART algorithm use signature BPARTV C P S R operates follows3 First V V root nodes C C leaf nodes S states created The value binary input parameter R determines regular Class A R true irregular Class B R false BNs generated Fig 1 In Class B BNs P parent nodes X1 X P leaf node picked uniformly random replacement V root nodes In Class A BNs form strict subset Class B BNs 45 parents picked root nodes exactly k k 1 children k cid2 0 Conditional probability tables CPTs nodes constructed BPART article focus impact structural parameters V C P P avg S Savg clique tree size As defaults parameter values S 2 R false employed use BPARTV C P abbreviation BPARTV C P 2 false An additional default P 2 giving BPARTV C abbreviation BPARTV C 2 Since given context ﬁx P total number edges BPARTV C P BN clearly E C P Here example clique tree clustering small BPART BN Example 11 BPART BN Fig 2 shows BPART BN compiled clique tree For BN leaf node C C1 C2 C3 C4 C5 C6 clique created In addition cliques containing BN root nodes cliques V 1 V 2 V 4 V 2 V 3 V 4 3 The extensive signature BPART Q F V C S R P previously 45 Here Q F parameters control conditional probability table CPT types BN root nonroot nodes respectively The parameter R control regularity number children root nodes Since emphasis article impact parameters V C S P typically use default values Q F R generally simplify signature BPARTV C P S 990 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Table 1 Three different upper bounds total clique tree size seven example bipartite Bayesian networks BN β0 β12 β73 β89 β92 β6 β80 Maximal clique bound 2 cid12 16384 16384 16384 16384 16384 262144 262144 Tree width bound w 13 13 13 13 13 17 17 Clique tree size bound trivial k T 1474560 1474560 1474560 1474560 1474560 23592960 23592960 Clique tree size bound easy k E 1261568 1261568 1261568 1261568 1261568 19136512 19136512 Clique tree size bound sum k S 61056 75840 81200 99138 53344 439776 284192 Relative size 100k S k T 414 514 551 672 362 186 120 Relative size 100k S k E 484 601 644 786 423 230 149 Note clique tree clusterings moralization step creates moral graph βcid6 BPART BN β ensures edges P root nodes share leaf node To discussion succinct BPART creates moral edges explicitly mentioning moralization step moralization actually creates edges BPART BN compiled The compilation bipartite BN Fig 2 illustrates crucial formation cycles BNs moral graph resulting generation ﬁllin edges In bipartite case nonroot nodes leaf nodes n C V It shown analytically empirically ratio C V CV ratio key parameter BN inference hardness 45 We consider nonempty BNs V cid2 1 CV ratio welldeﬁned Speciﬁcally CV ratio predict upper lower bounds optimal maximal clique size treewidth induced clique tree BNs randomly generated BPART algorithm Taking approach upper bounds optimal maximal clique sizes inference times computed Using regression analysis mean number nodes maximal clique approximately linear CV ratio This linear growth translates approximately exponential growth maximal clique size consequently clique tree clustering computation time function CV ratio This true Class A Class B BPART BNs 45 hard compute computes upper bounds w E k tics We focus upper bounds k Y arg max XX ΩX d ΩY wellknown easy extension4 k obtained summing sizes cliques k vations regard related upper bounds First assume treewidth w But NPhard compute treewidth w cid2 w quently use upper bound w heuristics algorithms Hugin heuris 1 n dw 1 Another upper bound S β kΓ Γ computed β Hugin 28 A obser known 3 bounds involving treewidth directly useful Conse forming upper bound k computed k The trivial upper bound k T n w Such upper bounds w S k d w Because w T k k cid12 cid12 E To empirically investigate upper bounds consider existing BNs generated signature BPARTV C P BPART30 60 3 45 Table 6 With reference bounds k E n 30 60 90 k d S 2 Here w S computed implementation Hugin algorithm Results BNs presented Table 1 shows bounds k E good compared k S Speciﬁcally relative size columns Table 1 following The size computed total clique tree size k S relative trivial T ranges 120 worst case 672 best case easy upper bound k upper bound k E slightly better Previously difference order magnitude bounds k S broad range benchmark instances 51 These empirical results illustrate useful consider k S computed clique tree clustering algorithms instead obvious bounds k E growth curves rest article based k T k T k T k T k S In larger BNs important diﬃcult understand predict clique tree clusterings cyclegeneration ﬁllin processes determine maximal clique size total clique tree size A main contribution article discussed Sections 3 4 5 improve understanding growth total clique tree size k S function BPART BN growth Whether computes MPEs marginals structure size clique tree e versus addition marginal numerical operations maximization MPE computation Prx computation Pr X e X X differ The clique tree growth curves discussed article apply cases 3 Developing modelbased reasoners Bayesian networks The development modelbased reasoners including use Bayesian networks typically involves iterative spiral process One starts simple model reﬁned extended information experimental results additional requirements available In words iterative development process manifests 4 The extension introduced anonymous reviewer OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 991 Fig 3 An example bipartite BN V 4 root nodes C 6 leaf nodes right developed grown bipartite BN V 2 root nodes C 4 leaf nodes left model growth example Bayesian network growth More speciﬁcally consider bipartite Bayesian networks diagnosis 6465960 identify forms growth Growth number root nodes V capture additional faults occur modeled In gas path diagnosis BN root nodes represent health parameters turbofan engine 60 increasing number health parameters comprehensive diagnosis computed In BN medical diagnosis additional root nodes introduced wants consider diseases 64 Growth number leaf nodes C represent additional evidence distinguish underlying faults computing marginals MPE MAP In BN gas path diagnosis leaf nodes represent additional measurements turbofan engine 60 In BN medical diagnosis leaf nodes represent additional symptoms tests 64 A hypothetical BN development process small BNs purpose illustration provided Fig 3 The ﬁgure shows different BN growth paths leading BN V 2 C 4 lower left corner Fig 3 larger BN V 4 C 6 upper right corner Fig 3 Even place emphasis growth increase concept change important Our results apply change general increases decreases BN size increase growth perspective prevalent For example knowledge engineering BN structure learning typically proceeds growing BN iteratively In addition want emphasize connection BN growth biological medical growth processes 43517 growth random graphs Section 4 Similar areas research article represents shift away particular BN β families sequences β1 β2 β3 β4 BNs processes BNs developed grown BN growth processes automatic machine learning data mining manual knowledge engineering direct manipulation BN semiautomatic editing highlevel language BNs autogenerated 43 An illustration connection BN growth clique tree growth provided Fig 4 This ﬁgure illustrates important vary cause number leaf nodes BNs density edges moral graphs BNs wide range effects different clique tree sizes studied At highest level want communicate main ideas article The ﬁrst idea use macroscopic growth curve gT x total clique tree size x independent parameter As illustration gT x bipartite BNs emphasized Section 32 approach clearly generalizes bipartite BNs discussed Section 33 As second idea discussed Section 31 investigate different independent parameters x gT x The use x CV C number leaf nodes V number root nodes wellknown A novel aspect work investigation alternative CV The research BPART algorithm generalization MPART algorithm extends existing research gener ating hard instances satisﬁability problem 47 existing research randomly generating BNs 66527 1152222345 Our work BPART article different previous research 45 ways including following The emphasis article total clique tree size instead size largest clique particular form total clique tree size carefully partitioning cliques Γ clique tree 992 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Fig 4 How clique tree size varies number BN leaf nodes varied Horizontally ﬁgure illustrates BN grow having leaf nodes added Vertically ﬁgure shows BNs compiled clique trees The growth BPART4 2 BN left BPART4 4 BN middle ﬁnally BPART4 6 BN right depicted row Clique trees compiled BNs shown row 31 Independent parameters Bayesian networks moral graphs Let W random number moral edges moral graph βcid6 randomly generated BN β Then EW expected number moral edges It turns fruitful use x EW independent parameter growth curve gT x In rest section discuss issue 311 Balls bins The balls bins model balls placed uniformly random bins turns useful analysis clique tree clusterings moralization step Following balls bins model let m denote number balls n denote number bins Further let X Y random variables representing number occupied bins respectively The expected number bins X EX n1 1nm The expected number occupied bins Y EY n 1 1 1nm cid5 cid4 cid4 It wellestablished expected number bins X approximated EX ne mn expected number occupied bins Y approximated EY n 1 e mn cid5 8 9 10 11 How balls bins model apply moral graph created clique tree clustering bipartite BN We restrict5 attention subgraph βcid6 induced V abbreviated βcid6V The bins possible edges moral subgraph βcid6V BN leaf nodes induce actual edges corresponding balls moral graph For clarity edgebin instead bin edgeball instead ball The formal deﬁnition makes connection balls bins model bipartite Bayesian network follows Deﬁnition 12 Edgeballs edgebins Consider root nodes V X bipartite BN β X E P An edgebin possible edge BNs moral subgraph βcid6V edge root nodes V V j V V j V cid11 j The set edgebins V V j V V j V cid11 j edgeball placed edgebin picking edgebin uniformly random probability p 1 cid4 V cid5 2 We use seen shortly balls bins approach obtain expected number moral edges moral graphs induced distributions BNs speciﬁcally BPARTV C P BNs We consider bipartite BNs leaf nodes exactly parents Section 312 arbitrary number parents Section 313 5 The reason restriction clariﬁed Section 32 discuss growth curves g R x gM x The growth total clique tree size changes βcid6V example induced increasing x CV captured g R x OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 993 Fig 5 As compilation clique tree bipartite Bayesian network left transformed moral graph moral edges middle We focus root nodes V 1 V 2 V 3 V 4 particular moral edges moral graphs subgraph induced root nodes right Both moral edges actually created edgebins ﬁlled edgeballs shown solid lines potential moral edges created edgebins ﬁlled edgeballs shown dashed lines shown right 312 Balls bins Two parents In BPARTV C 2 model edgebins uniformly repeatedly eligible placing edgeballs In words sampling replacement Here example applying balls bins model BPART setting Example 13 Fig 5 shows BN sampled BPARTV C P distribution V 4 C 6 P 2 For particular BN 4 6 possible edgebins contain edgeballs seen subgraph induced root nodes V 1 V 2 V 3 V 4 right Fig 5 Intuitively CV ratio increases gets likely given moral edge gets picked times words edgebin contains edgeballs This intuitive argument formalized following result shorten expectation EW C V EW C V obvious Theorem 14 Moral edges exact Let number moral edges created BPARTV C P random variable W The expected number moral edges EW C V P 2 given cid8cid7 cid7 cid7 cid7 EW C V 1 1 1 12 V 2 cid8cid8C cid8 cid9 V 2 Proof We use balls bins model Here edgeballs correspond leaf nodes m C The edgebins possible moral edges n bipartite graph V root nodes Plugging m n 9 gives desired result 12 cid2 V 2 cid5 cid4 It convenient use following approximation EW C V 12 Theorem 15 Moral edges approximate Let number moral edges created BPARTV C P random variable W The expected number moral edges EW C V P 2 approximated follows EW C V 1 exp C cid7 cid8cid7 V 2 cid7 cid7 cid8cid8cid8 cid9 V 2 13 Proof We use balls bins model Here edgeballs correspond leaf nodes m C The edgebins possible moral edges n bipartite graph V root nodes Plugging m n 11 gives desired result 13 cid2 V 2 cid5 cid4 Given 12 13 remarks In contrast CV ratio EV ratio expectation EW takes account effect picking parents pairs BN root nodes replacement For low values CV EV expect effect replacement great large CV EV ratios difference substantial illustrated following examples Example 16 C 30 leaf nodes Let V 30 C 30 P 2 The expected number moral edges EW 2899 12 EW 2902 13 Example 17 C 300 leaf nodes Let V 30 C 300 P 2 The expected number moral edges EW 216 91 12 EW 216 74 13 In Example 16 EW C relatively unlikely edgebins edgeballs In Example 17 hand likely edgebins edgeballs EW C In 994 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 words adding leaf node average smaller net effect number moral edges Example 17 Example 16 captured EW CV EV This important essential difference far cycle clique formation clique tree clustering concerned edgeball ii edgeballs 313 Balls bins Arbitrary number parents We turn BPART instances P arbitrary positive integer The fundamental complication far expected number moral edges EW concerned For P 2 BPART uses combination sampling replacement sampling replacement Picking parents given leaf node Ci amounts sampling replacement picking parents Ci parents C j known j amounts sampling replacement We introduce purpose approximation variant BPARTcid6 works exactly BPART moral edges induced P parent nodes given leaf node Ci picked independently replacement moral graph βcid6 This means Theorem 18 need consider sampling replacement Theorem 18 Moral edges exact Consider BPARTcid6 expected number moral edges V C P let number moral edges created random variable Z The EZ C V P cid7 V 2 cid8cid7 cid7 1 1 1 cid8cid8CP 2cid8 cid7 cid9 V 2 Proof We use balls bins model number edgebins n nodes Since BPARTcid6 9 gives desired result 14 cid2 employs sampling replacement number edgeballs m C V 2 cid4 cid5 P 2 14 cid5 bipartite graph V root cid4 Plugging m n We note Theorem 18 generalization Theorem 14 abbreviate EZ C V P EZ C V P clear context Further note EZ 14 approximated way similar approximation 12 13 We consider areas BPARTcid6 works differently BPART First mentioned issue picking parents replacement versus replacement For BPARTV C P selecting P parents leaf node Ci creates exactly V C P edges moral graph parents distinct ΠCi cid4 cid5 P 2 hand end graph A second issue edgeballs placed BPARTcid6 speciﬁcally edgebins picked form clique In summary note EZ approximation EW BPARTV C P P 2 justiﬁed known fact sampling replacement approximated sampling replacement number objects sampled V root nodes grows edgeballs placed edgebins consequently edges moral P For BPARTcid6 cid4 P 2 cid5 cid4 cid5 P 2 Why balls bins models BN moralization interesting The reason concerned possible causes macroscopic level inﬂuence clique tree size The expected number moral edges cause independent parameter x In context random BNs generated BPART indirectly control placement moral edges place constraints structure BNs BPARTs input parameters When comes effect tree clustering performance natural optimize minimize size maximal clique Since hard 3 current algorithms including Hugin use heuristics upper bound optimal maximal clique size cid12 clique tree size k respectively Such upper bounds clique tree size referred clique tree sizes following seek Section 32 closed form expression y gx dependent parameter clique tree size function independent parameter x cid12 k 32 Growth curves bipartite Bayesian networks Here develop models restricted clique tree growth extend exponential growth curves 45 model unrestricted growth Even Bayesian networks clique trees discrete structures approximate growth continuous growth curves growth functions order simplify analysis We discuss bipartite BNs section generalize arbitrary BNs Section 33 For bipartite BNs including BPART BNs types nodes clique tree reﬂected following deﬁnition Deﬁnition 19 Root clique mixed clique Consider clique tree βcid6cid6cid6 cliques Γ constructed bipartite BN β A clique γ Γ denoted root clique BN nodes γ root nodes β A clique γ Γ denoted mixed clique γ contains root node leaf node OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 995 Fig 6 The clique tree bipartite Bayesian network partitions cliques indicated Here V 4 V 1 V 2 V 4 V 2 V 3 root cliques growth curve g R remaining cliques mixed cliques growth curve gM It easy root mixed cliques clique types induced bipartite BNs root cliques interior nodes clique tree mixed cliques leaf nodes An illustration Deﬁnition 19 provided clique tree Fig 6 The BN clique tree compiled depicted Fig 2 Fig 4 We consider clique trees generated random BNs Random variables K T K R K M represent total clique tree size size root cliques size mixed cliques respectively K T K R K M 15 S corresponding random variables K S K T 15 Total clique tree size sum clique sizes types appropriate clique tree clustering Of particular upper bounds k K algorithms including Hugin We use 15 linearity expectation obtain S Pr K k S S EK T EK R EK M μT μR μM 16 In experimental article μR estimated sample mean ˆμR Collections sample means raw data sets construct growth curves means regression Let X predictor independent random variable Y response dependent random variable In regression setting interested conditional expectation cid10 μx EY X x y f y x dy 16 gives μT x μR x μM x deterministic functions x Here x represents variation BPARTs input parameters For instance C varied V P S kept constant Section 31 details The discussion intended background understanding beneﬁt quantitative growth curves introduce Deﬁnition 20 Clique tree growth curve Let g R R R gM R R Further let g R x growth curve root cliques gM x growth curve mixed cliques The total clique tree growth curve bipartite BN deﬁned gT x g R x gM x Given Deﬁnition 20 provide qualitative discussion growth BPART BNs terms CV ratio x CV This discussion supported previous 4541 current Section 5 experiments connection BPART random graphs Section 4 motivates introduction growth curves In order discussion relatively simple identify broad stages clique tree growth reﬂecting growth root cliques The initial growth stage rapid growth stage saturated growth stage The initial growth stage CV ratio low characterized leaf nodes relative number root nodes There consequently relatively low contribution root cliques clique tree In terms gT x stage dominated mixed cliques gM x Indeed CV 0 root cliques root node During rapid growth stage CV ratio medium root cliques nontrivial size start emerging formation cycles ﬁllin edges required order triangulate moral graph An example emergence cycle seen Fig 2 Fig 4 In stage addition ﬁllin edges root cliques g R x gradually overtake mixed cliques terms contribution total clique tree size gT x The saturated growth stage CV ratio high characterized large number leaf nodes relative number root nodes As CV approaches inﬁnity root clique V BN root nodes size S V BPART model emerges In stage mixed cliques eventually start dominate root clique reached maximal size grow However root clique size exponential number root nodes typically takes long time mixed cliques start dominating For large V effect disregarded main focus generally rapid growth stage 996 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Fig 7 Left Gompertz curves g1x 220e cid6 1x g Right Growth rates g cid6 2x g cid6 3x Gompertz growth curves 5e 03x green dotted curve g2x 220e 15e 03x black solid curve g3x 220e 5e 02x blue boxed curve particular early transition initial rapid growth stages g R x dominating factor gT x In following discuss g R x gM x independently In fact reﬂected informal discussion growth curve mixed cliques gM x generally dramatic growth curve root cliques g R x Therefore place emphasis g R x article investigate restricted growth curves suitable repre senting function A number sigmoidal growth curves Scurves model restricted growth including logistic Gompertz Complementary Gompertz Richards growth curves 43517 For restricted growth curves limx gx al ways exists deﬁne restricting asymptote g lim x gx 17 For unrestricted growth curves including exponential growth curve limx gx exist asymp tote g 17 It turns restricted Gompertz growth curves good approximations root clique growth g R x BPARTV C Section 5 study family curves Deﬁnition 21 Gompertz growth curve Let ζ γ R ζ 0 γ 0 A Gompertz growth curve deﬁned gx ge ζ e γ x 18 The derivative g x d dx g cid6 We discuss general properties form gx 18 For x 0 clearly e γ x 1 giving g0 ζ 18 In words intersection gx yaxis determined parameters g ζ γ x tends 0 meaning e ζ On hand x 18 e tends 1 limx gx ζ e γ x ge ge g The greater γ faster e γ x tends zero leading faster convergence asymptote g cid6x Gompertz growth curve gx gζ γ e γ xe ζ e γ x 19 expresses growth rate gx clearly g cid6x 0 given assumptions Deﬁnition 21 In Fig 7 investigate graphically examples parameters g ζ γ impact shapes Gom pertz curves The parameter g 220 obtained example considering bipartite BNs V 20 binary S 2 cid6x changes parameters ζ γ varied Let ﬁrst vary ζ root nodes Fig 7 shows growth rate g shown Fig 7 By increasing ζ ζ 5 ζ 15 keeping γ 03 constant xlocation maximal growth cid6x maximum change Let vary γ rate g cid6x illustrated Fig 7 As γ decreases γ 03 γ 02 ζ 5 kept constant xlocation maximal g cid6x decreases γ decreasing generally growth gets gradual increases In addition maximal value g γ decreases cid6x increased However value g In context BNs independent variable x growth curve gx parametrized x C x CV x EV C P V x EW depending data available purpose model We introduce BPART total growth curve model includes Gompertz growth curve Theorem 22 BPART Gompertz growth curve The total growth curve gT x BPARTV C P S assuming Gompertz growth root cliques x C independent variable γ x xS P 1 gT x S V e 20 ζ e OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 997 Proof Since BPART BNs bipartite growth curve form gT x g R x gM x g R x g R e γ x Gompertz growth curve For BPARTV C P S g R S V g R x S V e appropriate choices ζ γ Total mixed clique size C S P 1 45 gM x xS P 1 By forming g R x gM x obtain desired result 20 cid2 γ x ζ e ζ e Analytical growth models growth curves model growth organisms tissue biology medicine growth technology use penetration growth organizations societies including Web 43517 However use growth curves model clique tree size grows x C x CV x EW knowledge novel The Gompertz growth curve derived solving differential equation dgxdx agx growth coeﬃcient 4 Here constant exponentially decreasing formally dadx ka k 0 These equations solved obtain 18 4 While detailed study scope article appears plausible differential equations reﬂect macroscopic level clique tree clusterings formation cycles moral graph βcid6 generation ﬁllin edges Once cycle appears βcid6 cycles appearing needing ﬁllin edges Thus cycle formation starts βcid6 faster exponential growth root clique tree size g R x realistic supported previous experimental results 45 This hyperexponential growth article captured Gompertz growth curves We emphasize Gompertz curves provide accurate models clique tree growth For example cid6 R x 0 reﬂect reality small x C Consider ﬁrst BN leaf nodes added BPART When property g leaf node x 0 clearly μR 0 V μM 0 0 When leaf node P parents x 1 μR 1 V P μM 1 S P 1 Since μR 0 μR 1 contribution root cliques total clique tree size cid6 fact decreases x 0 x 1 clearly consistent g R x 0 follows example 19 The situation similar small values x Fig 4 x 2 However early stage growth interesting total clique tree size extremely small typically concern applications Consequently consider issue important limitation approach use CV cid2 12 experiments Finally note Gompertz growth curve linear form deﬁned follow 35 Deﬁnition 23 Gompertz linear form The Gompertz linear form cid7 ln ln cid8 gx g lnζ γ x 21 Using 21 Gompertz curve parameters ζ γ 18 estimated data linear regression Section 5 Other growth curves including logistic Complementary Gompertz forms similar 18 useful parameter estimation means linear regression 35 33 Growth curves general Bayesian networks We brieﬂy discuss generalization bipartite BNs considered earlier section arbitrary BNs There ways going bipartite BNs Generalization analytical approach tailored bipartite BNs arbitrary BNs There ways First maintain use growth curves reconsider cliques assigned order handle arbitrary BNs Second potentially growth curves base analysis ﬁnite set growth curves g1x g2x gkx k cid2 1 We discuss approach Section 331 Translation arbitrary BNs intermediate form bipartite BNs Such translation example based connection Bayesian networks factor graphs bipartite graphs 3219 The resulting bipartite BNs handled techniques discussed article We discuss approach Section 332 331 Generalization growth functions We discuss approaches generalize growth curve analysis discussed earlier Section 3 The ﬁrst ap proach continues use growth curves generalizes meaning Speciﬁcally introduce growth curves g1x g2x Here g1x represents cliques contain leaf nodes parents similar gM x g2x repre sents remaining cliques similar g R x Consequently g2x represents growth cliques containing root nodes cliques containing trunk nodes cliques containing trunk root nodes Clearly straightforward generalization approach simple contexts leading introduce following alternative The second approach amounts introducing arbitrary number growth curves We consider clique tree Γ gen erated arbitrary BN clique tree clustering One way formalize partitioning cliques clique tree Γ γ1 γη means coloring nodes graph BN clique tree follows 998 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Deﬁnition 24 Graph coloring Let G V E graph let Φ 1 φ set colors let h V Φ map coloring nodes colors Then G Φ h forms graph coloring The coloring deﬁnes partitioning graphs nodes φ partitions Deﬁnition 24 applies directed graphs including DAGs undirected graphs including clique trees For BNs abuse notation slightly saying β Φ h graph coloring β X E P BN strictly speaking coloring case DAG X E BN The following deﬁnition coloring h partitions nodes root nodes nonroot nodes Deﬁnition 25 Let G V E DAG let Φ 1 2 set colors The coloring h V Φ reﬂects root versus nonroot status V V deﬁned cid11 hV 1 iV 0 2 iV 0 Similar Deﬁnition 25 deﬁne coloring partitions nodes leaf nodes nonleaf nodes How graph coloring apply BNs clique trees A clique clique tree BN β consists BN nodes nodes different colors induced graph coloring β Φ h To reﬂect introduce concept color combination coloring following obvious result Proposition 26 Let G Φ h graph coloring let φ Φ The number nonempty color combinations κφ 2φ 1 Similar Deﬁnition 19 partition cliques according color combinations Formally amounts forming subsets cliques Γi 1 cid3 cid3 κφ Γ Γ1 Γκφ Γi Γ j cid11 j In bipartite special case discussed Section 32 κφ 2 Γ Γ1 Γ2 Γ1 root cliques Γ2 mixed cliques Assuming BNs randomly distributed let K random size cliques having ith color combination By summing obtain random variable K T representing total clique tree size K T κφcid6 i1 K 22 This sum generalization 15 applies bipartite case For possible color combination reﬂecting growth individual random variables K 22 intro duce separate growth curve gi parameters θ follows Deﬁnition 27 Let G Φ h graph coloring φ Φ let gi R R map parameters θ Then gx θ κφcid6 i1 gix θ g R R θ θ 1 θ κφ total growth curve 23 In words Deﬁnition 27 adds growth curves color combination A color combination corresponds type clique In manner decompose problem estimating growth curves complete clique trees sub problems estimating growth curves smaller pieces clique trees In bipartite case color combination mixed cliques color combination root cliques Deﬁnition 20 resulting growth curves g R x gM x right hand 23 We place restrictions partitioning Deﬁnition 24 Deﬁnition 27 purposes typically makes sense let coloring reﬂect structure graph ii introduce colors needed 332 Generalization factor graphs While main emphasis article Bayesian networks clique trees alternative approaches rep resenting multivariate probability distributions means probabilistic graphical models exist These alternatives include factor graphs 3270 Tanner graphs Markov random ﬁelds 6869 arithmetic circuits 12 For purpose generalizing growth curve approach arbitrary BNs factor graphs 3270 turn particular Informally factor graph FG bipartite graph root nodes variables leaf nodes factors functions directed edge expresses argument relationship variable function More formally following deﬁnition Deﬁnition 28 Suppose function h X1 Xn admits factorization OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 hX1 Xn mcid2 i1 f iS 999 24 S X1 Xn 1 cid3 cid3 m Then factor graph h deﬁned directed bipartite graph X F E variables X X1 Xn root nodes F f 1 fm leaf nodes E edges X F X j f E X j S Intuitively global function h 24 decomposed products local functions F local function f F depends hopefully small subset S X1 Xn We interested probabilistic inference h X1 Xn represents joint probability distribution discrete random variables Summary propagation algorithms iterative algorithms utilize summaries messages 36 introduced exploit factor graph representation h Summary propagation algorithms come ﬂavors sumproduct algorithms maxproduct algorithms Using sumproduct algorithms use factor graphs compute marginal distributions Xi 1 cid3 cid3 m The Viterbi algorithm 6757 generalized arbitrary treestructured graphical models maxproduct algorithm called maxproduct belief propagation 32 Having brieﬂy introduced factor graphs discuss relate use bipartite BNs article Factor graphs extended unify generalize directed graphical models Bayesian networks undi rected graphical models Markov networks 19 The studies Bayesian networks Markov networks factor graphs closely related We speciﬁcally exploit close connection factor graphs BNs consider twostep translation process 70 details First translate arbitrary BN β1 factor graph φ Second translate φ bipartite BN β2 related different β1 A factor graph factor φ leaf node bipartite BN β2 factor graph variable φ root node β2 We observations related translation process There topological restrictions β1 β2 guaranteed bipartite size β2 modest relative β1 This translation approach means translate arbitrary BN β1 bipartite BN β2 apply β2 analytical experimental machinery discussed article 4 Random graphs random Bayesian networks Similar BNs random graphs founded graph theory Random graphs explored 1950s early 1960s Solomonoff Rapoport 65 Erd os Rényi 18 Compared previous graph theory research contribution research random graphs emphasis graphs probabilistic objects similar perspective random BNs including BPART BNs Random graphs continue studied graph theory pure mathematics 7 interesting connections applied areas including social networks spread disease spread information information search World Wide Web 49 While comprehensive discussion random graphs scope article brieﬂy discuss connection random graphs random BNs particular random BNs generated BPART algorithm concerned undirected graphs In Gn p Two prominent random graph models n vertices denoted Gn p Gn m respectively Both models cid5 n edges included probability p In Gn m exactly cid5 2 n 2 edges replacement The sets graphs deﬁned m edges added uniformly random Gn p Gn m form probability spaces cid4 cid4 It turns random graph models including Gn p Gn m respects similar The number edges Gn p clearly follows Binomial distribution expectation p Gn p Gn m behave respects 7 In particular emergence certain global properties including graph structures form trees cycles cliques local connectivity parameters p Gn p model m Gn m model increase ﬁxed varying n How property likely emerge Erd os Rényi studied pn n emergence fast In words properties quickly unlikely likely phase transition certain probability pn If m p n 2 n 2 cid5 cid5 cid4 cid4 Random graphs studied evolutionary perspective In perspective edges added edges p 1 Clearly starting zero edges random graph approaching fully connected graph discussed similarity increasing p Gn p model increasing CV ratio BPART model Early random graph evolution edges isolated isolated components form There cycles edges initially likely merge components create cycles Gradually unicycles trees largest components log n size Then sudden comes socalled doublejump 18 things happen First number cycles increases dramatically Second size largest component grows growth depends c 1 c 1 With p c n c 1 random graph consists small components largest size Θlog n For c 1 hand small components clustered giant component size Θn In words giant component emerges average node degree np 1 n 2 cid4 cid5 1000 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Which random graph models Gn p Gn m relevant work discussed article BPARTV C P certain conditions discuss shortly similar Gn m The conditions follows 1 For BPARTV C P moral edges root nodes induced leaf nodes words undirected moral graph induced root nodes important purposes n V 2 In BPARTV C P consider P 2 yields independence moral edges similar edges picked independently Gn p Gn m To connection Gn m model BPART explicit set n V P 2 stated conditions BPARTn C instead BPARTV C P Now difference Gn m BPARTn C picks edges replacement cid13 m picks edges replacement However difference important situations If difference approximation purposes simply ignored set m C Alternatively difference ignored proceed follows Without loss generality assume m n ﬁxed Gn m consider EW C V given 12 13 substituting V n In case 12 obtain integervalued lower bound Ccid12 upper bound Cu EW Ccid12 V cid3 m cid3 EW Cu V Ccid12 Cu 1 We use Ccid12 Cu input parameter BPART use BPARTn Ccid12 BPARTn Cu bound Gn m If instead 12 use 13 EW m solve C 13 Obviously solution C general integervalued use Ccid12 cid14Ccid15 Ccid12 cid16Ccid17 inputs BPART manner similar n 2 cid5 cid4 The issue treewidth random graphs knowledge extensively researched However results brieﬂy review 30 The following analytical results apply early evolution random graphs giant component emerges Lemma 29 Let 0 c 1 suppose p cn Then graph Gn p connected component tree unicycle graph Corollary 30 If m n 2 graph Gn m treewidth With respect lemmas application BPART note triangulation trees unicycle graphs simple Trees need ﬁllin edges course triangulation unicycle graph k nodes amounts adding cid16 k cid17 ﬁllin edges A consequence Corollary 30 BPART C V 2 CV 12 interesting 2 treewidth perspective We state result applies broader range random graphs 30 including emergence giant component Theorem 31 Let δ cid2 118 Then graph Gn m m cid2 δn treewidth Θn Comparing Gn m BPARTV C m corresponds C number leaf nodes n corresponds V number root nodes The condition m cid2 δn Theorem 31 corresponds C cid2 δ V CV cid2 δ It clear Corollary 30 Theorem 31 CV 1 interesting region setting clique tree clustering BNs assuming BPARTV C model To summarize clear fruitful connections random graphs random BNs In particular hypothesize connection onset rapid growth phase observed BPART BNs δ 118 Theorem 31 behavior modeled large cid6x restricted growth curve gx Gompertz growth curve At time values g caveats concerning use analytical results random graphs analysis random BNs We start identifying structurerelated issues First ignore small difference Gn m BPARTV C 2 identiﬁed moment clear Gn m makes independence assumptions BPARTV C P P 2 Second work treewidth random graphs discussed brieﬂy optimal treewidth central topic random graphs And strictly graphtheoretic perspective issue optimizing maximal clique random graphs optimizing total clique tree size clearly related Total clique tree size previously emphasized BNs 2829 Third random graphs typically considered limit n generally situation random BNs BNs general Fourth random graphs strictly graphtheoretic consider state spaces exhibit important variation BNs To progress understanding clique tree growth BPART model despite limitations applying results theory random graphs turn experimental results 5 Experiments OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 1001 In experiments address following questions context bipartite BNs sampled BPART How Gompertz growth curves match sample data form clique trees generated tree clustering inde pendent parameter nature sample data points varied How Gompertz growth curves ﬁt sample data compared alternative growth curve models In answering questions extend complement pre vious experimental results 45 introducing restricted growth curves including Gompertz growth curves addition sample means unrestricted exponential growth curves ii greater range values CV iii considering V 20 V 30 iv investigating x EW addition x CV independent parameter v dependent parameter total clique tree size k S Clique trees generated sample BNs generated BPART indicated implementation Hugin clique tree clustering algorithm Clique trees optimized heuristically minimum ﬁllin weight triangulation heuristic treewidth computation NPcomplete S size optimal maximal clique cid12 In rest experimental section discuss Section 51 clique tree growth case BPART BNs V 30 root nodes x EW In Section 52 investigate BPART BNs V 20 root nodes consider x EW x CV In Section 53 investigate growth individual BPART BNs 51 Comparison growth models multiple BNs The purpose ﬁrst set experiments compare Gompertz growth model alternatives Ex ponential logistic complementary Gompertz Here report Bayesian networks generated signature BPART30 C 2 2 varying values C speciﬁcally 15 cid3 C cid3 600 12 cid3 CV cid3 20 For CV level considered 100 BNs β1 β100 sampled BPART clique trees respective sizes k S β100 computed Hugin S β1 k We present results Hugin experiments In panel Fig 8 sample means ˆμR x cor responding points different analytical growth curves g R x function x EW presented Sample means ˆμR x obtained averaging particular x k S β100 deducting gM x Here Gom pertz logistic complementary Gompertz exponential functions considered g R x The panel Fig 8 shows growth curves panel obtained linear forms 21 The following Gompertz growth curve obtained cid4 S β1 k g R x 230 exp cid5 1914 exp0005874x x EW The parameters ζ γ growth curves computed similar manner Clearly Gompertz curve ﬁts data better alternative growth curves analyzed R 2 09995 Gompertz versus R2 09413 logistic R2 09407 Complementary Gompertz The excellent ﬁt easily conﬁrmed visually considering sample means corresponding data points Gompertz curve panel Fig 8 52 Gompertz growth model details multiple BNs In second set experiments Bayesian networks generated BPARTV C 2 2 V 20 varying values C speciﬁcally 10 cid3 C cid3 1400 12 cid3 CV cid3 70 Similar CV level 100 BNs sampled BPART Hugin compute clique trees respective sizes k S β100 Using relatively low value V allowed generate BNs generated clique trees exhaust computers memory large C supporting comprehensive analysis Gompertz growth curves x CV x EW independent parameters S β1 k Fig 9 illustrates results experiments Here left column Fig 9 presents Gompertz growth curves g R x right column illustrates growth curves obtained 21 similar In row Fig 9 sample means corresponding points Gompertz growth curve function CV ratio presented As baseline exponential interpolation curve sample means provided Empirically Gompertz growth curve g R x 220 exp cid4 cid5 9906 exp01118x x CV R2 0993477 The parameter values ζ e2293 9906 γ 01118 obtained Gompertz linear form illustrated right Fig 9 based sample means clique tree root cliques linear regression result lnζ γ x 01118x 2293 In row Fig 9 plot expected number moral edges EW xaxis Note right sample average row Fig 9 x EW 123 corresponds sample average CV 10 row Fig 9 In words use x CV allows illustrate broader range behavior 1002 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Fig 8 Experimental results bipartite BNs V 30 root nodes varying number leaf nodes C Top Comparison Gompertz growth curves sample means The superior ﬁt Gompertz curve reﬂected better R2 value R2 099948 Bottom Linear forms showing growth curves obtained inclusion BNs larger number leaf nodes compared x EW We present sample means corresponding points Gompertz growth curve function EW exponential regression curve presented baseline Here Gompertz growth curve empirically determined g R x 220 exp cid4 cid5 1243 exp001187x x EW R2 0999215 The parameters ζ γ computed similar manner summarized right Fig 9 We revisit broad growth stages discussed Section 3 Section 4 terms Fig 9 The sample means easyhardharder pattern monotonically increasing clique tree sizes stages The initial growth stage CV ratio low P 2 approximately CV 1 characterized leaf nodes relative number root nodes The initial growth stage fact diﬃcult Fig 9 sample points stage close In rapid growth stage CV ratio medium P 2 approximately CV 1 CV 20 nontrivial root cliques appear As seen sample means left Fig 9 growth initially faster indicated exponential regression curve slows Clearly Gompertz growth curves better ﬁts respective exponential curves CV EW The saturated growth stage CV ratio high characterized slow growth saturation At saturation root clique γ Ωγ 220 room growth In Fig 9 saturation starts CV 20 Fig 9 clearly shows improved ﬁt provided Gompertz curves compared exponential curves Further x EW provides better ﬁt x CV narrower domain OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 1003 Fig 9 Empirical results bipartite Bayesian networks generated V 20 root nodes varying number leaf nodes C Top left Gompertz growth curve function CV ratio Top right Gompertz growth curves linear form function CV ratio create Gompertz growth curve left Bottom left Gompertz growth curve function EW Bottom right Gompertz growth curves linear form function EW create Gompertz growth curve left 53 Comparison growth models individual BNs The experimental results far section based constructing growth curves g R x sample means ˆμR x clique tree sizes 100 BNs CV value What happens individual BNs instead multiple BNs construct growth curves g R x To investigate question considered set experiments BNs generated signature BPART20 C C varying C 100 C 1200 The following protocol followed order create sequence closely related BNs Starting sampled BPART20 1200 BN 100 leaf nodes deleted time giving sequence BNs consisting BPART20 1100 BN BPART20 1000 BN forth BPART20 100 BN Obviously real development setting sequence BNs different particular machine learning algorithm knowledge engineer start small BN grow way The manner sequence BNs created experimental purposes matter long BPART BNs clearly Experimental results sequences clique trees generated sequences BNs generated according protocol presented Fig 10 For β0 sequence Fig 10 regression results k S Gompertz curve g R x 01125x 22873 R2 09571 Logistic curve g R x 02676x 63575 R2 09265 Complementary Gompertz curve g R x 02411x 61417 R2 08962 For β1 sequence Fig 10 regression results k S Gompertz curve g R x 00816 19406 R2 0971 Logistic curve g R x 02205x 57281 R2 08361 Complementary Gompertz curve g R x 02063x 5635 R2 08074 This ﬁgure clearly shows better ﬁt provided Gompertz curves compared alternatives The better ﬁt reﬂected higher R2 values Gompertz curves sequences We note R 2 values Gompertz curves smaller R2 values Gompertz curves Section 51 Section 52 A key point regard data point represents clique tree size single BN data point 1004 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 Fig 10 Experimental results sequences individual bipartite BNs V 20 root nodes varying number leaf nodes Comparison Gompertz growth curves function CV shown sequences BNs Top The superior ﬁt Gompertz curve sequence BNs reﬂected higher R2 value R2 09571 Bottom The superior ﬁt Gompertz curve sequence BNs reﬂected higher R2 value R2 0971 Section 51 Section 52 represents sample mean clique tree size 100 BNs The poorer ﬁt reported surprising 6 Conclusion future work Substantial progress recently area Bayesian network BN reasoning algorithms area applications BNs Based experience applications clear Bayesian networks useful powerful care needed constructing In particular inherent computational complexity interesting BN queries 1063611 want carefully consider issue scalability generating BNs resourcebounded systems including realtime embedded systems 4840 BN generation performed manually means knowledgebased model construction machine learning methods In resourcebounded systems BN compilation approaches including clique tree propagation 3322562 arithmetic circuit propagation 1298 particular 43 In clique tree approach emphasize article BN inference consists propagation clique tree compiled Bayesian network Total clique tree size important determines inference time Unfortunately precise understanding varying structural parameters BNs causes variation sizes induced clique tree sizes lagging To attack problem article investigated clique tree clustering approach bipartite BNs sampled means BPART algorithm employing restricted unrestricted growth curves We characterized growth clique tree size function expected number moral edges ii CV ratio C number leaf nodes V number nonleaf nodes In article varied ii increasing number leaf nodes bipartite BNs discussed approach applies arbitrary BNs Gompertz growth curves bipartite BNs investigated shown excellent ﬁt empirical clique tree data appear theoretically plausible OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 1005 The growth curve approach presented article earlier paper 41 novel extends previous work 45 We consider expected number moral edges EW CV ratio wide range CV ratio values We focus total clique tree size opposed size largest clique clique tree We believe research reported helps ﬁll gap appears exist theoretical complexity results empirical results speciﬁc algorithms application BNs To ﬁll gap presented approach combines probabilistic analysis restricted growth curves experimentation Analytically experimentally shown restricted growth curves induce stages growing Bayesian networks The initial growth stage rapid growth stage saturated growth stage These stages similar evolution random graphs Our growth curve results provide compared pure complexitytheoretic results admittedly gloss details available raw experimental data Areas future work include following First type approach utilized tradeoff studies design vehicle health management systems including diagnostic reasoners 40 analysis knowledgebased model construction algorithms study machine learning In cases uncertainty impact different BN structures clique tree size consequently computation time In knowledgebased model construction BNs constructed dynamically early design health management systems little information available concerning vehicle developed In machine learning especially structure learning model selection score BNs according estimated computational feasibility addition statistical ﬁt Second analytical growth curves perform forecasts derive requirements largescale BNs clique trees larger current software hardware capable supporting Third natural develop ﬁnegrained analytical models including accurate models arbitrary number parents improving analytical growth models based extensive experimentation Finally exploration connection random BNs random graphs BNs applications interesting Acknowledgements This material based work supported NASA awards NCC21426 NNA07BB97C NNA08205346R NSF awards CCF0937044 ECCS0931978 Comments anonymous reviewers helped improve article acknowledged References 1 AM Abdelbar SM Hedetnieme Approximating MAPs belief networks NPhard theorems Artiﬁcial Intelligence 102 1998 2138 2 SK Andersen KG Olesen FV Jensen F Jensen HUGIN shell building Bayesian belief universes expert systems Proceedings Eleventh International Joint Conference Artiﬁcial Intelligence vol 2 Detroit MI August 1989 pp 10801085 3 S Arnborg DG Corneil A Proskurowski Complexity ﬁnding embeddings ktree SIAM Journal Algebraic Discrete Methods 8 1987 277284 4 RB Banks Growth Diffusion Phenomena Springer New York 1994 5 A Becker D Geiger Approximation algorithms loop cutset problem Proceedings Tenth Annual Conference Uncertainty Artiﬁcial Intelligence UAI94 San Francisco CA 1994 pp 6068 6 TW Bickmore A probabilistic approach sensor data validation AIAA SAE ASME ASEE 28th Joint Propulsion Conference Exhibit Nashville TN 1992 7 B Bollobas Random Graphs Cambridge University Press 2001 8 M Chavira Beyond treewidth probabilistic inference PhD thesis University California Los Angeles 2007 9 M Chavira A Darwiche Compiling Bayesian networks variable elimination Proceedings Twentieth International Joint Conference Artiﬁcial Intelligence IJCAI07 Hyderabad India 2007 pp 24432449 10 FG Cooper The computational complexity probabilistic inference Bayesian belief networks Artiﬁcial Intelligence 42 1990 393405 11 A Darwiche Recursive conditioning Artiﬁcial Intelligence 126 12 2001 541 12 A Darwiche A differential approach inference Bayesian networks Journal ACM 50 3 2003 280305 13 AP Dawid Applications general propagation algorithm probabilistic expert systems Statistics Computing 2 1992 2536 14 R Dechter Bucket elimination A unifying framework reasoning Artiﬁcial Intelligence 113 12 1999 4185 15 R Dechter Y El Fattah Topological parameters timespace tradeoff Artiﬁcial Intelligence 125 12 2001 93118 16 R Dechter J Pearl Networkbased heuristics constraint satisfaction problems Artiﬁcial Intelligence 34 1 1987 138 17 DM Easton Gompertzian growth decay A powerful descriptive tool neuroscience Physiology Behavior 86 3 2005 407414 18 P Erd os A Rényi On evolution random graphs Publ Math Inst Hung Acad Sci 5 1960 1761 19 BJ Frey Extending factor graphs unify directed undirected graphical models Proc 19th Conference Uncertainty Artiﬁcial Intelligence UAI03 2003 pp 257264 20 RG Gallager Low density parity check codes IRE Transactions Information Theory 8 Jan 1962 2128 21 F Hutter HH Hoos T Stützle Eﬃcient stochastic local search MPE solving Proceedings Nineteenth International Joint Conference Artiﬁcial Intelligence IJCAI05 Edinburgh Scotland 2005 pp 169174 22 JS Ide FG Cozman Generating random Bayesian networks Proceedings 16th Brazilian Symposium Artiﬁcial Intelligence Porto Galinhas Brazil November 2002 pp 366375 23 JS Ide FG Cozman FT Ramos Generating random Bayesian networks constraints induced width Proceedings 16th European Conference Artiﬁcial Intelligence 2004 pp 323327 24 TS Jaakkola MI Jordan Variational probabilistic inference QMRDT database Journal Artiﬁcial Intelligence Research 10 1999 291322 25 FV Jensen SL Lauritzen KG Olesen Bayesian updating causal probabilistic networks local computations SIAM Journal Computing 4 1990 269282 26 P Jones C Hayes D Wilkins R Bargar J Sniezek P Asaro OJ Mengshoel D Kessler M Lucenti I Choi N Tu J Schlabach CoRAVEN Modeling design multimedia intelligent infrastructure collaborative intelligence analysis Proceedings International Conference Systems Man Cybernetics San Diego CA October 1998 pp 914919 1006 OJ Mengshoel Artiﬁcial Intelligence 174 2010 9841006 27 K Kask R Dechter Stochastic local search Bayesian networks Proceedings Seventh International Workshop Artiﬁcial Intelligence Statis tics Morgan Kaufmann Fort Lauderdale FL Jan 1999 28 U Kjaerulff Triangulation graphs Algorithms giving small total state space Technical Report R9009 Department Mathematics Computer Science Aalborg University 1990 29 U Kjaerulff Approximation Bayesian networks edge removals Technical Report IR932007 Department Mathematics Computer Science Aalborg University 1993 30 T Kloks Treewidth Computations Approximations SpringerVerlag 1994 31 AMCA Koster HL Bodlaender SPM van Hoesel Treewidth Computational experiments H Broersma U Faigle J Hurink S Pickl Eds Elec tronic Notes Discrete Mathematics vol 8 Elsevier Science Publishers 2001 32 FR Kschischang BJ Frey HA Loeliger Factor graphs sumproduct algorithm IEEE Transactions Information Theory 47 2 2001 498519 33 S Lauritzen DJ Spiegelhalter Local computations probabilities graphical structures application expert systems discussion Journal Royal Statistical Society Series B 50 2 1988 157224 34 Z Li B DAmbrosio Eﬃcient inference Bayes nets combinatorial optimization problem International Journal Approximate Reasoning 11 1 1994 5581 35 JK Lindsey Statistical Analysis Stochastic Processes Time Cambridge University Press Cambridge 2004 36 HA Loeliger An introduction factor graphs IEEE Signal Processing Magazine 21 1 2004 2841 37 DJC MacKay Information Theory Inference Learning Algorithms Cambridge University Press Cambridge UK 2002 38 RJ McEliece DJC Mackay JF Cheng Turbo decoding instance Pearls belief propagation algorithm IEEE Journal Selected Areas Communications 16 2 1998 140152 39 OJ Mengshoel Eﬃcient Bayesian network inference Genetic algorithms stochastic local search abstraction PhD thesis Department Computer Science University Illinois UrbanaChampaign Urbana IL April 1999 40 OJ Mengshoel Designing resourcebounded reasoners Bayesian networks System health monitoring diagnosis Proceedings 18th International Workshop Principles Diagnosis DX07 Nashville TN 2007 pp 330337 41 OJ Mengshoel Macroscopic models clique tree growth Bayesian networks Proceedings TwentySecond National Conference Artiﬁ cial Intelligence AAAI07 Vancouver British Columbia 2007 pp 12561262 42 OJ Mengshoel Understanding role noise stochastic local search Analysis experiments Artiﬁcial Intelligence 172 89 2008 955990 43 OJ Mengshoel A Darwiche K Cascio M Chavira S Poll S Uckun Diagnosing faults electrical power systems spacecraft aircraft Proceedings Twentieth Innovative Applications Artiﬁcial Intelligence Conference IAAI08 Chicago IL 2008 pp 16991705 44 OJ Mengshoel D Roth DC Wilkins Portfolios stochastic local search Eﬃciently computing probable explanations Bayesian networks Journal Automated Reasoning 2010 press 45 OJ Mengshoel DC Wilkins D Roth Controlled generation hard easy Bayesian networks Impact maximal clique size tree clustering Artiﬁcial Intelligence 170 1617 2006 11371174 46 OJ Mengshoel DC Wilkins D Roth Initialization restart stochastic local search Computing probable explanation Bayesian networks IEEE Transactions Knowledge Data Engineering 2010 press 47 D Mitchell B Selman HJ Levesque Hard easy distributions SAT problems Proceedings Tenth National Conference Artiﬁcial Intelligence AAAI92 San Jose CA 1992 pp 459465 48 D Musliner J Hendler AK Agrawala E Durfee JK Strosnider CJ Paul The challenges realtime AI IEEE Computer 28 January 1995 5866 49 M Newman AL Barabási DJ Watts Eds The Structure Dynamics Networks Princeton University Press 2006 50 AY Ng MI Jordan Approximate inference algorithms twolayer Bayesian networks Advances Neural Information Processing Systems vol 12 NIPS99 MIT Press 2000 51 L Otten R Dechter Bounding search space size hypertree decompositions Proc 24th Conference Uncertainty Artiﬁcial Intelligence UAI08 2008 pp 452459 52 JD Park A Darwiche Approximating MAP local search Proceedings Seventeenth Conference Uncertainty Artiﬁcial Intelligence UAI01 Seattle WA 2001 pp 403410 53 JD Park A Darwiche Complexity results approximation strategies MAP explanations Journal Artiﬁcial Intelligence Research JAIR 21 2004 101133 54 JD Park A Darwiche A differential semantics jointree algorithms Artiﬁcial Intelligence 156 2 2004 197216 55 J Pearl A constraintpropagation approach probabilistic reasoning LN Kanal JF Lemmer Eds Uncertainty Artiﬁcial Intelligence Elsevier Amsterdam Netherlands 1986 pp 357369 56 J Pearl Probabilistic Reasoning Intelligent Systems Networks Plausible Inference Morgan Kaufmann San Mateo CA 1988 57 LR Rabiner A tutorial hidden Markov models selected applications speech recognition Proceedings IEEE 77 1989 257286 58 BW Ricks OJ Mengshoel The diagnostic challenge competition Probabilistic techniques fault diagnosis electrical power systems Proc 20th International Workshop Principles Diagnosis DX09 Stockholm Sweden 2009 59 I Rish M Brodie S Ma Accuracy vs eﬃciency tradeoffs probabilistic diagnosis Eighteenth National Conference Artiﬁcial Intelligence AAAI 02 Edmonton Canada 2002 pp 560566 60 C Romessis K Mathioudakis Bayesian network approach gas path fault diagnosis Journal Engineering Gas Turbines Power 128 1 2006 6472 61 D Roth On hardness approximate reasoning Artiﬁcial Intelligence 82 1996 273302 62 PP Shenoy A valuationbased language expert systems International Journal Approximate Reasoning 5 3 1989 383411 63 E Shimony Finding MAPs belief networks NPhard Artiﬁcial Intelligence 68 1994 399410 64 MA Shwe B Middleton DE Heckerman M Henrion EJ Horvitz HP Lehmann GF Cooper Probabilistic diagnosis reformulation INTERNIST1QMR knowledge base I The probabilistic model inference algorithms Methods Information Medicine 30 4 1991 241255 65 R Solomonoff A Rapoport Connectivity random nets Bulletin Mathematical Biology 13 2 June 1951 107117 66 HJ Suermondt GF Cooper Probabilistic inference multiply connected belief networks loop cutsets International Journal Approximate Reasoning 4 1990 283306 67 AJ Viterbi Error bounds convolutional codes asymptotically optimal decoding algorithm IEEE Transactions Information Theory 13 1967 260269 68 M Wainwright T Jaakkola A Willsky MAP estimation agreement hypertrees Messagepassing linear programming approaches IEEE Transactions Information Theory 51 2002 36973717 69 MJ Wainwright TS Jaakkola AS Willsky Treebased reparameterization framework analysis sumproduct related algorithms IEEE Trans actions Information Theory 49 2003 2003 70 JS Yedidia WT Freeman Y Weiss Understanding belief propagation generalizations Exploring Artiﬁcial Intelligence New Millennium Morgan Kaufmann Publishers Inc San Francisco CA USA 2003 pp 239269 71 NL Zhang D Poole Exploiting causal independence Bayesian network inference Journal Artiﬁcial Intelligence Research 5 1996 301328