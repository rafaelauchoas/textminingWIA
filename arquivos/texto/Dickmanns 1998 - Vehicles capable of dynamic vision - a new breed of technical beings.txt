ELSEVIER Artificial Intelligence 103 1998 4976 Artificial Intelligence Vehicles capable dynamic vision new breed technical beings Ernst D Dickmanns Universiftit der Bundeswehs Munich D85577 Neubiberg German_y Abstract A survey field encompassing given decades developments computing power orders magnitude The 4D approach methods systems dynamics control engineering methods AI allowed create technical realm autonomous road vehicle guidance vehicles unprecedented capabilities public traffic freeways speeds 130 kmh onboardautonomous landing approaches aircraft landmark navigation AGVs road vehicles helicopters 0 1998 Elsevier Science BV All rights reserved turnoffs crossroads case lowlevel flight realtime hardwareintheloop integrating expectationbased increase simulations including Keywords Machine vision Autonomous vehicles Mobile robots Dynamic scene understanding Image processing 1 Introduction Road vehicle guidance based videosignal Japan 39 Europe 26 USA 21 While processing picked indepen Japan analog signal dently processing quasisteady AImethods predominated US recursive estimation methods known systems engineering extended image se resulting method dubbed quence processing authors institute 4D approach dis problem domain The numerical recursive estimation directly efficiency compactness finally led wide allowed control applications vision community Artificial neural nets ANN wide spread acceptance UBM contrast 2D 25D 3D methods discussion variable state representation generating behavioral capabilities time fourth independent Email emstdickmannsunibwmuenchende 0004370298 PII SOOO43702980007 I X matter 0 1998 Elsevier Science BV All rights reserved acceptance 1000 pixel 1 Kpel usually recursive estimation image higher image rate USA 13 l globe image resolution 80 Kpel road vehicles run autonomously Both methods allowed control 4D approach allowed highways types roads high speeds initially roads 730 finally normal freeway traffic 113 1371 ANNs stayed confined 171 time mode controlled lateral 253 l longitudinal spatio detect track determine human driver 3D surface temporal dozen objects vehicle VITA II DaimlerBenz VaMP UBM 1 1401 considered road vehicles new species capable understanding reacting properly actual needs completely autonomous relative European project Prometheus 121 The final demonstrator range 100 meters environment velocity components state position vehicles Dynamic remote sensing requires intelligent motion control environment rapidly changing elements use valid spatiotemporal models efficient handling large data streams involved Other objects recognized relative motion components collision avoidance achieved vehicle body carrying cameras moves intended way simultaneously near ones high precision subject perturbations hardly predictable vision sensing addition For complex scenario rate feedback great help inertial viewing direction control device allows stabilize negative angular image sequence Measured accelerations appearance stationary objects velocities signal rotational positions affecting perspective mapping process These predictions good short inertial sensors run drift slowly long run especially inexpensive These drifts easily compensated static scene elements yield predictions translational interpretation integration visual 2 Simultaneous representations differential multiple integral scales systems In order integral Combined use inertial visual sensing known biological introduced simultaneous eyes vertebrates vestibular apparatus interconnections optimal use inertial visual signals different scales space time exploited Table 1 representations point upper left corner represents shows categories sensor actuator real space time interactions world place Inertial sensors yield information arrow 1 field 1l field 33 table turn rates point Within rigid structure object turn rates body rate signals arrow 2 field 13 33 drawn spatial object level row 3 The local surface structure described change tangent direction inertially measured local accelerations differential arc length geometrical characterization called curvature element local shape It form row 2 Table 1 object differential ED Dickmanns Artid Intelligence 103 lYY8 4976 Table 1 Differential integral representations different scales dynamic perception measuremen represents curved ones image certain aspect conditions local spatial differentials cause specific edge features straight represented feature distribution local spatial integrals Single objects considered connection aspect conditions arrangements objects relevance behavior decision reactive control For reason row 3 Table I shapes determined spatial curvature distributions photometric properties surface image Since general surface determine objects viewed simultaneously task context called geometrical elements situation perceived taken visual data input account process labeled index 3 corresponding field 33 components features associated object strong predictive component objects Looked way vision simultaneously differential maneuvering environment preshapes maneuver space self row 2 integral scales rows 3 single objects 4 local tracking component 3 perception 3b objectoriented improvement socalled detection component 5 mission performance arrows central provides geometrical 3a measured efficiency interpretation information element 52 ED Dickmanns Artificial Intelligence 103 1998 4976 Temporal change represented column 2 yields corresponding time derivatives elements associated numerical differentiation Awcoswt operation odometry especially image points Even feature effect recursive estimation column left Because noise amplification high frequency signals usable smooth signals avoided deliberately optical like computing ddt A sinwt speed flow computation level operation integration smoothing preferred In matrix field 32 Table 1 key knowledge elements corresponding tools sampled data processing indicated mass limited energy availability real world constrained good models unperturbed motion motion processes natural engineering specific classes available sciences objects belonging rate change state variables represent dependence temporal dynamical models For state control variables These socalled constant control inputs integration period models integrated yield difference equations link states objects column 3 Table 1 gap column 2 control engineering methods column 1 bridging handle problems arising Once states libraries codes available point time known time derivatives delivered models corresponding Recursive estimation techniques developed 60s exploit knowledge making state predictions cycle disregarding perturbations models applied yielding predicted measurements communicated efficiency measured features yields prediction errors state update improve arrow 4 field 33 13 Table 1 object 23 feature extraction image processing order stage 33 measurement In 4D approach image evaluation level arrow 5 level A comparison actually inputs In order better understand going happen larger scale predictions likely road vehicle guidance longer term state I arrow 6 Section 6 repeated times fast advance simulation assuming control finite sequence feedforward transition effect These represented deal problems stereotypical maneuvers control known field 44 Table like lane changes inputs perturbation With effects direct state feedback known For compensation engineering control state transition closed loop specified characteristics row 4 Table 1 This knowledge linking differential representations ones low frequency high frequency components handled separately frequency domain Laplacetransform left open indicated row column damping field 34 integral time usual aerospace engineering This theory eigenvalues Table 1 systems linear behavioral The feedforward feedback control laws superimposed If sufficiently situations achieving given Sections 68 modes constitute rich set modes activate mission goals This represented field n n lower right discussed vehicle able recognize capabilities parameters autonomous entire missions behavioral autonomous capability performance available capabilities ED Dickmanns Artijicial Intdligence 103 1998 4976 53 levels elegant symbiosis control engineering requires proper sequencing behavioral capabilities symbolic representations higher abstract AImethods Essentially mission performance task context corresponding realized 3 Task domains Though approach general adapted task domains road air vehicle guidance discussed 31 Road vehicles environments autonomous The structured vehicles freeways construction parameters limited access high speed vehicles strict regulations level like lane widths maximum crossings For reason speed driven high usually freeway driving selected firsttask domain autonomous vehicle guidance group 1985 slopes offramps curvatures Six perceptual behavioral capabilities recognition performance freeways 2 obstacle stopping changing performance information navigation On kept freeways 1 lane recognition reaction proper mission navigation sufficient lane following adequate speed convoy driving transition lane change lane lanes availability traffic signs 5 reading interpreting 4 reading obeying including proper lane selection 6 handling entries exits check surface structure watch unexpected Nonetheless usually necessary safe reaction 3 recognition neighboring humans animals entering events required mature autonomous On normal state roads variability road parameters traffic participants larger especially level crossings oncoming objects limited animals normal surface state poor lower order roads potholes especially transition zone shoulders traffic increase relative speed speed kinds lane width average increasing hazard potential lower level Bicyclists traffic participants pedestrians In addition traveling In urban traffic things worse respect crowdedness subjects These mentioned autonomous driving scene complexity computing performance amenable required considered environments roadways However driving minor concrete sealing attacked research purposes performed known including obstacle avoidance However situations traffic macadam past soon available If going support vehicle cross country driving human capabilities systems compete long way autonomous computing power safely increasing ground compared little crossing 54 ED Dickmanns Artijcid Intelligence 103 1998 4976 32 Air vehicles As compared ground vehicles 3 6 degrees freedom available shaping In addition air turbulence trajectory environment harder considered mandatory like lanes roads available aircraft airborne higher altitudes Microwave electronic guidelines established addition visual navigation guidelines roads For reason task domain perturbation winds instead sensing inertial aircraft Vision allows typical task landing approach pilot autonomous certain navigate fixed prepared site usually marked large letter H capabilities landing aids like ILS MLS DGPS future machine vision allows detect obstacles runway landmarks wing aircraft small helicopter These tasks selected demonstrations seeing aircraft Contrary possibly react proper manner electronic relative runway landing For flights close Earth surface terrain lines power obstacle avoidance buildings natural extension technique helicopters For capability recognizing ground hovering improve rescue capabilities delivery performance fixed position unmanned relative napoftheEarth formations recognized air vehicles fixed wings structures objects flights objects despite perturbations Motion control fixed wing aircraft helicopters use proper dynamical models control laws shown 4D approach allows turn craft autonomous agent capable fully automatic mission performance This discussed different Section 8 4 The sensory systems The extremely high data rates image sequences advantage respect acquiring new information environment objectssubjects versatility disadvantage information rely conventional variables minimal time delay respect computing power needed delay time incurred extracted data For reason makes sense sensors addition deliver information specific output 41 Conventional sensor3 speedometers sensors For ground vehicles odometers like actuators pointing devices commonplace angles subparts For aircraft pressure measurement devices yield information speed altitude flown inertial angular gyros sensors image sequence standard Evaluating information processing considerably Based experience gained angular rate sensors adopted inertial sensors like accelerometers inexpensive rate vertical directional conjunction vision alleviates air vehicle applications like accelerometers positions ED Dickmanns Artificial fntrlligrncr 103 1998 4976 Fig I Binocular camera arrangement VaMP rearward looking mirror center upper wind shield road vehicles vision Part discussed beneficial complementary effects relative Section 2 detailed 42 Vision semors practical purposes Because large viewing ranges required single camera vision sensor In past bifocal camera arrangements means sufficient Fig 1 wide angle 45 telecamera fix relative twoaxis platform viewing direction control 12291 future systems field view 100 divergently mounted wide angle cameras 3chip color CCDcamera 131 For highspeed driving German Autobahnen fourth camera relatively strong telelens added allowing meters distance trinocular camera arrangements wide simultaneous 15 aperture mounted lane recognition All data evaluated 25 times second standard European video rate 43 Global positioning GPS sensor For landmark navigation connection maps GPSreceiver integrated order sufficiently good initial conditions landmark detection Even accurate CA code connection inertial time sensing operation 181 GPS signals available second achieved good accuracies interpretation map 5 Spatiotemporal perception 4D approach Since late 7Os observer techniques developed UBM field motion control vision HJ Wuensche thorough comparison observer Kalman filter realizations systems dynamics 23 2627 In early 8Os 56 ED Dickmanns Artiial Intelligence 103 1998 4976 Fig 2 Multiple feedback control image acquisition processing control lower right comer loops different space scales efficient scene interpretation lower left comer 3D imaginationspace behavior control upper half motion applied vision recursive estimation pendulum electrocart vision extended Kalman root formulation standard methods dynamic vision problems UBM filter EKF numerical sequential updates new measurement inverted 43 Since refined versions square UDUTfactorization applied task balancing original stabilization Based experience gained satellite docking 44 road vehicle guidance board autonomous aircraft landing approaches machine vision realized mid aspects 80s joint use dynamical models temporal predictions overall problem parallel key achieving quantum jump performance level autonomous physical objects observed control computation based estimated states gained image feature extraction feature feedback knowledge aggregation efficiency image sequence evaluation orders magnitude systems based machine vision Beside state estimation See Fig 2 graphical overview level allowed increase Following determining state prediction shape measurement models exploited l viewing direction control pointing l locations image information state estimation feature selection twoaxis platform carrying cameras easy nonambiguous accurate ED Dickmanns Artial Intelligence 103 1998 4976 51 orientation edge features allowed reduce number search masks directions length search path function actual measurement uncertainty robust efficient precise edge localization efficient feature aggregation guided idea Gestalt strategies objects Jacobian matrices firstorder derivatives state components interpretation constraints This integral use motion process squares error sense given motion dynamical models contain feature positions information relative rich features measured statistical properties known 1 dynamical models motion center gravity taking actual control outputs time delays account 2 spatial 3D shape models specifying visually measurable 3 perspective mapping models 4 prediction error feedback estimation object state 3D space time closed loop form termed 4D approach It far simultaneously recursive estimation algorithm based arbitrary model assumption arbitrary subspace image plane features It estimated papers referring temporal models based physical processes scan recent publications field today Kalman filters advantage integrated use spatio Initially applications egovehicle assumed moving control relative allow wide simultaneous skew stereo interpretation small area high image resolution smooth surface trajectory cameras fixed vehicle body In meantime general scenarios available cameras spatially arranged solutions platform pointed voluntary vehicle body field view central area These camera arrangements trinocular television The vehicle 6 degrees freedom moving objects independently stationary background One objects fixated tracked pointing device inertial visual feedback signals image A newly appearing object wide field view trigger fast viewing direction change object analysed corresponds saccadic vision known vertebrates allows reduced data rates trades need timesliced attention control complex sense vision It essentially data rate reduction l2 orders sampleddata based scene reconstruction magnitude compared telecameras object centered entire simultaneous high resolution resolution field view keeping The 4D approach lends type vision objectorientation temporal dynamical models available design dynamic vision termed EMSvision focal Saccadic miniature TVcameras twoaxis pointing platform named Multifocal activereactive Vehicle Eye MarVEye This complex Expectationbased Multi set implemented experimental actually 131 58 E D Dickmanns Artial Intelligence 103 1998 4976 In rest paper major developmental decade results achieved reviewed As introduction summarize basic assumptions underlying 4D approach steps 4D approach section 51 Basic assumptions underlying 4D approach It explicit goal approach possible advantage physical real world Models developed centuries simulation technology decision control decades form base mathematical models processes happening natural sciences engineering systems engineering computerinternal 1 The mesoscopic world observed representations realworld processes independent describing variables processes 2 All interactions real world happen nonrelativistic happens 3D space Newtonian models time sufficient location body carrying special inputoutput devices especially locations sensors signal data input actuators control output body regions strongest wheels ground vehicles highest importance interaction world example 3 Eficient interpretation sensor signals requires background processes characteristics components graspable point time Similarly observed Invariants controled temporal process understanding abstract model spatial knowledge 4 efJicient computation favorable optimal control outputs theory provides partial process models account control taking complete methods fast stable reactions 5 Wise behavioral decisions feedback feedforward require knowledge outcome control modes special results obtained integration dynamical models environments This stored appropriately spot analytical solutions available numerical ones derived small fraction realtime possible increasing processing power available Behaviors realized triggering point 4 longerterm certain modes available situations 6 Situations arrangements objects active subjects goals pursued 7 essential recognize single objects subjects intentions order able meaningful relative state future development situation needed possible predictions successful behavioral decisions 8 As term recognition tells usual case assumed objects seen generically known appearance geometrical range operation senses new allows fast jump object hypothesis visual knowledge background Exploiting impressions arrive sets features model based perception process ED Dickmanns Artificial Intvlligencr 103 1998 4976 59 initiated Free parameters efficiently attention control use special algorithms behaviors generic object models determined 9 In order able step 8 efficiently knowledge context tusk domains In addition knowledge discriminating indexing provided represented correct hypothesis generation likely cooccurrences essential features object data base world 10 Most efficient object time compute powerful class description invariants constraints sufficiently usually 3D stereotypical motion image compute motion numerically shape allows flexible general space sequences modern microprocessors visual appearance object given aspect conditions parallel single ones different mapping parameters runtime They powerful Jacobian matrices sensorobject pairs features evaluated respect object state recursive parameter values state parameter estimation The inversion perspective projection reduced squares model fit recursive process started The overall process underlying sufficiently good representations rates like video frequency interpretation scene newly appearing objects search processes occur restricted ureas image bottomup confined areas Passing cars example enter field view ground small class features allows detect reliably nonlinear 25 30 Hz usually assumption local linearizations real process high evaluation process dynamic framework case 1 1 In running 12 Subjects objects capability self induced generation actuation characterized typical motion behavior similar shape spatial domain certain situations This recognizing stereotypical control predictive 13 The objectsubject represented different scales degrees detuil allows flexible efficient use changing contexts function distance degree attention internally 52 Survey structure 4D upproach Fig 3 shows main activities running parallel advanced version 4D approach 1 Detection objects typical collections features assigned object tracked center left upward arrow 1 feature collections stable frames object hypothesis formed new object added list regularly tracked arrow 2 right 2 Trucking objects state estimation Fig 3 control output chosen single step prediction 3D space components translational path concentrating rotational degrees freedom b whatsignal loop lower right real world This step consists path progress motion wheresignal imagined shown time 60 ED Dickmanns Artcial Intelligence 103 199X 4976 I baeliouad 4D atwroach dynamic machine vision y ty jj I j j Fig 3 Survey 4D approach central arrow upwards driven prediction error feedback tracking state estimation dynamic machine vision major areas activity object detection loop lower right learning loop center recursive dealing object shape In order overburden shown figure components 3 Learning concentrating observation data tracking center single step loop low frequency constant parameters Fig 3 estimation component line component batch processing stored data This actual construction site code development autonomous new task domains experience grows Both dynamical models wherepart shape models whatpart shall learnable present open architecture Another component development detailed behavior decision discussed Section 6 Fig 3 situation assessment 53 Generic 4D object classes The efficiency 4D approach dynamic vision achieved associating background knowledge classes objects behavioral capabilities data input This knowledge typical adapted translational object classes special case hand Motion descriptions models space rotational movements fixed specific parameters center gravity form structural available information generic trajectory object ED Dickmanns Artificial Intelligence 103 I 998 4976 61 form socalled whatproblem Typically summing averaging feature positions solve whereproblem differencing whatproblem separated shape descriptions called feature positions contributes whereproblem solving needed 531 Motion description Possibilities object trajectories abundant reasonable effort However good models usually available describing time function actual state These socalled fx u u t x ncomponent vector IJ perturbation dynamical models usually sets nonlinear differential represented evolution inputs equations control state vector u rcomponent perturbation control input Through linearization nominal trajectory xNt obtained integrated analytically matrix description small cycle times T yield approximate locally linearized descriptions local transition xk lT AxkT BukT ukT 1 The elements matrices A B obtained afFfIul standard methods systems theory Ft afaXlN Gt Usually states measured directly output variables _Y given YWTI hXkTl p kT wkT 2 h nonlinear mapping represents measurement noise p mapping parameters w On basis Eq 1 distinction objects proper subjects dependence controls u model ur input agent speak object controlled subject case If ukT activated outputs results internal activity object preprogrammed obtained processing measurement data speak subject 532 Shape feature description image vary considerably 4 Since objects seen different With respect shape objects subjects treated fashion Only rigid objects objects consisting rigid parts linked joints treated elastic plastic modeling appearance size At large ranges 3D shape object usually importance information aspect conditions necessary perceiving seen contains observer crosssection tracking However crosssection depends angular aspectdependent modeling shape efficient dynamic vision This discussed briefly task road vehicles appear normal road traffic coarsetofine ranges Coarsetojne shape models distance road vehicle adequately described encasing convenient values parameters importance larger distances large rectangle shape parameters width b height h Absolute proper scale 2D seen 62 ED Dickmunns Artificial Intelligence IO 1998 4976 4 4 1t I I Ll Fig 4 Coarse fine shape model car rear view encasing rectangle Ushape b polygonal silhouette c silhouette internal structure inferred known object seen like road lane width distance Trucks buses cars easily distinguished Our experience height object omitted loss functionality spatially curved region car body varying environmental reliable Ushape unit height corresponding sufficient image Depending distances l2 dozen pixels line crossing focal conditions simple different absolute tells upper limit tracking upper body boundary difficult 1 m turned practical length corresponds reflections object Fig 4a shows shape model If object image large details features like license plate tires signal light groups usually distinguished shown Fig 4b internal details Fig 4c chosen case areabased yellow reddish color allow robust recognition reliably feature extraction polygonal shape approximation tracking width car image start increasing If view oblique direction comes play Even viewing conditions vehicle observed larger length body sineeffect determine measurements proven robust reliable switching lateral aspect angle body width andlength mapping Usually impossible visual simultaneously body diagonal shape representation realworld scenes 1321 depth dimension length vehicle slightly axis symmetry rapidly Just tracking relative state estimation taking vertical edges lower body lower bound object body proven cases 38 course domain specific knowledge introduced specifying features measurement sufficient In general modeling measurable tells area based features play dependent aspect conditions Experience important realized observing average grey value vehicleside edge features detected computing power available color profiles certain crosssections role robust object tracking yield improved performance recognition object Initially shape model features Full 3D models direrent degrees qf similar 2D rear silhouette different models 3D shape The corresponding encasing box perpendicular image separation line measured precisely good estimates overall body dimensions obtained small image sizes Since space allow details interested surfaces easily distinguished reader referred 132331 Fig 4a surfaces ED Dickmanns Artificial Intelligence 103 1998 4976 63 Fig 5 Intelligent control image feature extraction parameters window state estimation edges marked label Eij Triangle labeled T large rectangles broken lines efficient object tracking algorithms CRONOS 4D approach 54 Image feature extraction Due space restrictions topic detailed interested reader referred 815 Fig 5 shows survey method Two types feature extraction algorithms oriented edge features extracted ternary mask correlations areabased image plane new segmentations horizontal vertical search paths old component stripes certain widths arbitrarily oriented The intelligent control parameters algorithms In 4D approach representations efficient spatio tracking temporal application perspective mapping From Fig 5 seen small percentage image data properly analysed allows track objects reliably frequently precisely tight bottomup 25 Hz seen context Fig 2 parameters set predictions loop traversed topdown essential 55 State estimation The basic approach described remained visual relative state estimation years However order able better deal general case scene recognition strongly perturbed egomotion inertially based component added 4142 269103844 times This type state estimation new compared missiles inexpensive This acceptable visual state estimation loop running parallel inertial navigation accelerometers angular rate sensors resulting drift problems handled combined use resembling 64 ED Dickmanns Acial Intelligence 103 1998 4976 relatively poor inertial signals vestibular apparatus visual signals vertebrate perception Some inertial signals stabilizing viewing direction respect stationary environment angular rates pointing device carrying high rates systems 500 Hz 35 direct negative feedback cameras This feedback actually runs 551 The advantage new component Inertially based egostate estimation IbSE threefold rotational speed components components 2 quantities measured correspond integrated numerically 1 direct encoding body fixed axes time delays yield predictions actually theoretical model disregarding perturbations inertial leading available forces moments effects perturbations perturbation models 3 good models eigenbehavior including accelerations negligeable positions exerted vehicle valuable unknown measurements deeper understanding general predictions allow estimate parameters environmental effects 552 Dynamic vision With respect egostate recognition vision reduced essential func longterm interpretation It stabilize tionality yield information road road curvature vehicles obstacles frequency viewing direction component feature extraction leads higher efficiency overall relative inertially With respect high known reduces search range required vehicle guidance measurable vision task slightly alleviated stationary environment like position orientation environment relative items These effects achieved spatiotemporal models perspective mapping image plane With different measurement models cameras single object model loop fed image data cameras relevant Jacobian recursive matrices exist objectsensor pair link inertial measurements features iteration The nonlinear measurement Eq 2 linearized predicted nominal state XN nominal parameter set PN yielding noise term YWI YNfl SYrktl hXNkT PN kT csx csp 3 parameters c ahaplN Jacobian matrices respect c ahaxN state components involved Since terms right hand equality sign equal definition Eq 3 determine 6x Sp squares sense 6y prediction error messured given core recursive estimation observability 56 Situation assessment For object estimation loop set yielding best estimates egovehicle velocity including spatial velocity components For stationary negative egospeed course Since known relative state landmarks rehably ED Dickmums Artcial Intelligence 103 1998 4976 65 conventional measurements monocular vision exploiting motion stereo 192838 distance landmark determined environment surrounding With information essential task context objects available interpretation process evaluate come conclusion proceed behavioral mode running exploiting dynamical models switch different mode Fast inadvance nearterm alternative evolution situation By comparing stored results decisions simulations inputs yield possible alternatives options resorting precomputed stereotypical situation control 6 Generation behavioral capabilities Dynamic vision geared closedloop behavior task context types behavior relevance course depend special task domain The general aspect behaviors generated control output There basically different types control generation 1 triggering stored forward control events actually observed generically activation time histories socalled feed 2 gearing actual control difference desired actual state relevant systems socalled feedback control In cases actual control parameters depend situation given A general method combine given case list especially easy 4D approach dynamical models available motion understanding The general feedforward control law generic form Ur sM TM 0 r t trrig ZM 4 PM contain averaged state components like speed A typical feedforward control element steer control output lane change set phases rp consist example steer rate hdot formulation time rM final control phase duration generic maneuver constant steer rate R In second fourth phase duration amplitude opposite sign In phase steer rate zero missing duration zero The parameters R TM tp selected TV Am parameters course depend speed driven lateral offset lane width vehicle heading Given idealized control law corresponding state component 0 c r t tTfig c TM AQ computed according additional transition disturbances maneuver superimposed difference Axt xcr force real trajectory completed time control state feedback controller time histories XC good dynamical model input ends In order counteract time period ArD end added real dynamical maneuvers xt ideal 5 The general state feedback control law ur KTAxs 66 ED Dickmwms Artijicial lntelligmcr 103 19 4976 optimal K r x n gain matrix The gain coefficients set pole placement control Riccati design linear quadratic engineering time axis pole placement specifies eigenvalues closed loop Riccati design minimizes weighted include knowledge behavioral characteristics integrals state errors control inputs use dynamical models perception control controller known 20 Both methods The simultaneous evaluation process leading behavior decision makes approach efficient Combining feedforward direct control actual error feedback realize commanded behavior close possible deal perturbations need replanning higher levels All needed mission performance specific sufficiently rich set feedforward feedback behavioral capabilities These activated effect right sequence goals achieved behavioral capability represented upper decision level global descriptions effects end For purpose sufficient 1 For feedforward behaviors corrective represent case 3 given time needed note quasistatic description AImethods This level worry realtime dynamics taken care lower levels It know situations behavioral capabilities activated parameter set feedback superimposed initial final conditions including 2 For feedback behaviors sufficient know mode fast reactions run unlimited periods time interrupted road vehicle guidance reflexlike special event A typical example lane following integral speed distance road These values given information tables checking mission progress upper level irrespective curvatures like maps systems planning traveled Performing complex missions basis begun Fig 6 shows dual lower representation AImethods road vehicle guidance control engineering state charts automaton upper longitudinal procedural methods 24 The newly available computing power lead quick progress mission level general concept defined 7 System integration 71 Overall architecture qf cognitive Fig 7 gives survey new objectoriented architecture development like inertial On lowest signal stabilization gaze direction negative angular rate feedback In general temporal models level data smoothing data processed arrive sensors loops closed directly drift elimination level feedback ED Dickrnunns Artificial Intelligence 103 1998 4976 67 task driving lane automaton longitudinal control rulebased level decision longitudinal control 4Dlevel execution Fig 6 The task drive lane example coupling 4D level rulebased level In image processing feature extraction level arrows downward sent interpretation features grouped preprocessed algorithms run controlled lower left features according prediction error adjacent big arrows left hypothesis generation higher Gestaltidea upward Unassigned higher level On second specialist processes recognizing ground vehicle applications level use spatiotemporal models tracking objects certain classes Shown 1 detection tracking vehicles obstacles ODT 2 detection tracking landmarks 3 tracking road lanes crossroads 4 threedimensional interpretation heightprofile track driven 3DS including LDT surface vehicle relative egostate RDT 5 inertial state body based accelerometer angular rate data stabilized specific visual inputs The resulting actual state parameter vectors objects communicated dynamic data base wide arrow upwards forms link information control engineering intelligence modules artificial exchange ED Dickmanns Artijcial Intelligence 103 1998 4976 Fig 7 OveraIl architecture cognitive recursive effects maneuvers The dynamical models actual rear level central slice In addition dynamical models simulations likely trajectories handled backward loop forcing temporal predictions feedback ideal block predicting trajectory perturbations central support decision making objectssubjects slice block levels fast inadvance crucial importance exploited situation superimposed estimation To right end level control computation blocks use time histories proper feedforward control dynamical models determining fixing closed loop eigenmotion characteristics The vertical data background bottomup activated interact behavior mission monitoring Map information 4D background knowledge actual task list mission performance level contains data substrate actual dynamical data topdown fashion rear right generic shown left end represented level knowledge Halfway upwards shown containing activities decisions performed rudimentary rulebased processing highest level intermediate sublevel lightlytextured situation assessment form procedurally behavior fixed ED Dickmanns Artijicial Intelligence 103 1998 4976 69 right figure This expanded code foreground flexibility introducing measures decision monitoring process created dubbed lack precise confined expression activate behaviors modify control value explicitly stated goals performance general scheme propagated I 1 In addition central self central figure corresponds laws Both control output state time histories resulting logged offline analysis level look apply identification improving background knowledge leftmost disc data level evaluation processes intermediate statistical performance algorithms analyse like eliminating In long errors maps run hopefully intelligence emerge data obtained parameters achieved real learning based framework developed natural engineering approaches The goal powerful methods codes developed engineering organized applications Knowledge access task domains task domains general applicability starting point sciences modern possible fields systems dynamics control This experience actual easy order limit search spaces stored separately graphicsanimation advantage techniques simulation according The self shall capabilities communicate models software packages rule based processing laws mission plans subjects human Over time accumulate individual line experience making basic platform The future limits line development unique starting level data structures like maps control 72 Multiple loops dynamic scene understanding The principles discussed lead parallel realizations multiple interpretation process space time Fig 2 displayed upper half figure essential scales feedback local situation achieving mission goals Table 1 level global mission performance loops spatial aspects In loops object level level behavior decisions scene The multiple These decisions based local extended predictions actual situation knowledge behavioral capabilities vehicle subjects time domain scale inertial viewing direction displayed control hours ground flight vehicles mission scale encompassing sequences maneuvers feedback behavioral modes Fig 8 range millisecond loops The outermost loops labeled quasistatic closed mainly human systems techniques operators software developers They dynamics control engineering methods AI feasible felt unified approach encompassing tackled automation structure developed simulation animation 70 ED Dickmanns Artijicial Intelligence 103 19 4W I4 I extended presence H I Fig 8 Multiple representational feedback loops different time scales visual cognition systems corresponding levels 8 Experimental results 8 I Road vehicles The autonomous observing vehicle With 46 transputers road vehicle VaMP Fig 9 twin VITA II Daimler normal freeway traffic France Germany Benz shown remarkable performance Denmark 1994 VaMP pairs bifocal camera sets focal lengths 75 24 mm looks rear With 320 240 pixels road traffic 100 m image sufficient able lane width number lanes type lane markings 1994 recognize road curvature lane driveway relative state position attitude relative vehicles hemisphere Prometheus near Paris VaMP At final demonstration free lane driving convoy driving speeds demonstrated passing 130 kmh normally dense threelane decision 22 The human safety pilot check validity decision goahead input lane changes safely possible autonomously including EUREKAproject velocity components traffic 111 lane changing image processing capabilities In meantime transputers replaced PowerPCs MPC 601 order magnitude computing power A long range trip 1600 project 95 1995 performed meeting Odense Denmark 71 Fig 9 The autonomous vehicle VaMP UBM distance traveled fully automatically freedom Maximum speed free stretch northern German plain 180 kmh longitudinal lateral degrees construction Since blackandwhite video signals evaluated edge picked early lack simultaneous feature sites yellow markings white ones lane near posed extraction algorithms handled passing vehicles cutting problems took long converge stable field view monocular range estimation interpretation For reasons improved wide field view divergently oriented wide angle cameras central region overlap 3chip color camera covers stereo interpretation central stereo fieldofview This allows trinocular stereo areabased object recognition DualPentiumPro processors provide processing power tens thousands high resolution additionally mask evaluations CRONOS video cycle processor 1985 demonstrated VaMoRs 5ton van operation road driving seen sequence microprocessors PowerPCs general purpose Intel autonomous Intel Pentium 8086 80x86 transputers PentiumPro capability driving state minor unsealed roads speeds 50 kmh 1992 able recognize hilly terrain estimate vertical road curvature horizontal lo early highspeed driving freeways 7 demonstrated In addition addition Recognizing crossroads unknown width angular orientation demon strated turning roads tight curves requiring initial 14281 These capabilities maneuver considerably field view area based color image processing improved new camera arrangement wide simultaneous opposite direction curve Performing entire missions based digital maps started 19 alleviated GPSreceiver introduced 10 000 fully autonomous driving types roadways combination inertial state estimation 2842 The vehicles VaMoRs VaMP accumulated recently record 72 ED Dickmums Articial Intellipzce 103 1998 4976 82 Air vehicles control hardwareintheloop After feasibility autonomous machine vision demonstrated approaches sensing wind gust disturbances safety regulations aircraft twin turboprop 5ton weight near ground flying vision determined 12 state components distances 900 m runway degrees freedom dynamic landing inertial led flight tests 1991 34 Because human pilot relative runway case straightin unperturbed 16 second effort including vision allowed autonomous simulations control threshold The step introduce bifocal vision mild stronger tele lens connection new transputer early 90s 1993 set flight proved visual experiments aircraft University Brunswick range doubled essentially computing power needed robust tracking initialization The PowerPC satisfied requirements detect large obstacles runway sufficiently early safe reactions guidance control task performed hardwarein landmark flight near ground theloop navigation The capability performing small scale mission starting end airport Brunswick hying selected sequence waypoints airport airport slowing vicinity landing helicopter The demanding realtime H end demonstrated 4142 Fig 10 road forks returning possible helicopter simulations including 181 demanding In connection context mission performance task complete separate inertial visual state estimation components developed containing GPS signals data fusion provisions integrate coarsescale imaging radar development radar solution streams intelligent unload difficult task situation stressed limit software package integration In addition image data synthetic aperture The combined use allweather optimal data pilot images systems The capability interpreting future helicopter guidance images highresolution onboard optical infrared considered 9 Technical beings There ongoing discussion best architecture realizing neural nets proposed roads leading type creatures technical beings like architecture agents 336 subsumption Looking results achieved 4D approach problems unreasonable scenarios approaches avoided taking long term results natural sciences engineering expect dynamic vision encountered complex route builds It advantage having clear notion space time objects subjects handle multi processes spatiotemporal ple independent objects subjects intentions goals control capabilities structure necessary representational Fig 10 Landmark simulations taxiways small mission near airport Brunswick frame Heli H final approach navigation helicopters demonstrated realtime Tracking Crossing 2 b Tracking hardwareintheloop In 5 corresponding framework given allows representational systems minimal additional task domain entered effort methodical corresponding realworld problems A corresponding architecture near future sufficient specific handle complex knowledge structures Computing power available complex guidance realtime discussed 24 data solve road vehicle As compared approaches pursued simulation state art engineering autonomous achieve heard systems closed opposed intelligible goals learn point view systems providing technology achieve pledge advantage background knowledge introducing goal functions essential The argument ones neuralnetbased 10 Conclusions The 4D approach dynamic machine vision developed cybernetics conventional engineering long time ago lines layed satisfy 74 ED Dickmanns Artijicial Intelligence 103 1998 4976 control processes shares Artificial expectations Complex perception conditions missioncontrol graphics simulation complemented vision Intelligenceand Neural Netapproaches like ground vehicle guidance diverse maneuver tools dealing inverse problem complex scenes demonstrated degrees freedom The representational Computing power arriving handling realword problems robustness encountered blackandwhite understanding texture demanding respect processing power complemented areabased aswellas edgebased including realtime Lack image color representations Taking advantage suited methods best field unified overall approach promising way The good old stuff discarded competing approaches combining early References Ll JS Albus AM Meystel A reference model architecture design implementation intelligent control large complex systems Intemat J Intelligent Control Systems 1 1 1996 1530 121 R Behringer Visuelle Erkennung und Interpretation des Fahrspurverlaufes durch Rechnersehen fur ein autonomes StraRenfahrzeug PhD Thesis UniBwM LRT 1996 3 RA Brooks AM Flynn Robot beings IEEEiRSJ International Workshop Intelligent Robots Systems Tsukuba Japan September 1989 pp 210 4 D DeCarlo D Metaxas The integration optical flow deformable models applications human IEEE Computer Society Conference Computer Vision Pattern face shape motion estimation Recognition San Francisco CA June 1996 pp 23 l238 fur visuelle Wahrnehmung 51 D Dickmanns Rahmensystem INF 1997 Thesis UniBwM verartderlicher Szenen durch Computer PhD 6 ED Dickmanns 4Ddynamic scene analysis integral spatiotemporal models Proc 4th Internat Symposium Robotics Research Santa Cruz CA 1987 7 ED Dickmanns A Zapp Autonomous high speed road vehicle guidance vision Proc 10th IFAC World Congress Munich Preprint Vol 4 1987 pp 232237 81 ED Dickmanns V Graefe Dynamic monocular machine vision Machine Vision Applications 1 1988 223240 ED Dickmanns V Graefe Applications Applications I 1988 24126 I dynamic monocular machine vision Machine Vision 9 ED Dickmanns Machine perception exploiting highlevel spatiotemporal models AGARD Lecture Series 185 Machine Perception Hampton VAMunich Madrid SeptemberOctober 1992 IO ED Dickmanns B Mysliwetz Recursive 3D road relative egostate recognition IEEE Transactions Pattern Anal Machine Intell Special Issue Interpretation 3D Scenes 14 2 1992 199213 I I ED Dickmanns R Behringer D Dickmanns T Hildebrandt M Maurer F Thomanek Proc Intelligent Vehicles Symposium J Schiehlen 94 Paris October 1994 The seeing passenger car VaMoRsP pp 6873 121 ED Dickmanns Performance improvements autonomous road vehicles Internal Conference Intelligent Autonomous Systems IAS4 Karlsruhe 1995 131 ED Dickmanns Road vehicle eyes high precision navigation Linkwitz et al Eds High Precision Navigation Dtimmler Bonn 1995 pp 329336 141 ED Dickmanns N Mtiller Scene recognition navigation capabilities lane changes turns visionbased vehicle guidance Control Engineering Practice 2nd IFAC Conf Intelligent Autonomous Vehicles 95 Helsinki 1995 ED Dickmanns Articial Intelligence 103 1998 4976 IS 151 ED Dickmanns S Ft A Schubert D Dickmanns scenes Technical Report UniBwMLRTWE13FB971 16 G Eberl Automather 171 H Fritz Modelbased neural distance control autonomous 1997 Landeanflug durch Rechnersehen PhD Thesis UniBwM LRT 1987 Intelligently controlled feature extraction dynamic road vehicles Proc Intelligent Vehicles 96 Symposium Tokyo 1996 pp 2934 181 S Ftirst S Werner D Dickmanns ED Dickmanns Landmark landing Proc AeroSense97 Conference 3088 Orlando FL April autonomous navigation approach obstacle detection aircraft 2025 1997 191 C Hock Wissensbasierte Fahrzeugfiihrung mit Landmarken fur autonome Roboter PhD Thesis UniBwM LRT 1994 ZO T Kailath Linear Systems PrenticeHall Englewood Cliffs NJ 1980 I2 I PJ Klass DARPA envisions new generation machme intelligence Aviation Week Space Technology April 1985 4754 1221 C Kuiawski Deciding behaviour autonomous mobile road vehicle 2nd IFAC Conference 23 241 1251 P61 271 1281 I291 1301 1311 321 331 341 351 I361 371 1381 I391 401 r411 Ed Proc IEEE vehicles interpretation realtime PhD Thesis TS Huang 92 Denver 1992 neural network DS Touretaky autonomous vehicles Neural Information Processing Systems Ed Proc 1st Conference Intelligent Autonomous und Navigieren mit einem sehenden StralJenfahrzeug I Morgan Kaufmann San Mateo CA 1989 mobile robot guidance PhD Thesis CMU CMUCS92 state linear IEEE Trans Mil Electronics 8 1964 29G293 AeroSense97 Intelligent Autonomous Vehicles Helsinki June 1995 DG Luenberger Observing M Maurer ED Dickmanns An advanced control architecture Conference 3087 Orlando FL April 2025 1997 K Mecklenburg T Hrycej U Franke H Fritz Neural control autonomous Vehicular Technology Conference HG Meissner Steuerung dynamischer Systeme aufgrund bildhafter Informationen PhD Thesis UniBwM LRT 1982 HG Meissner ED Dickmanns Control unstable plant vision Image Sequence Processing Dynamic Scene Analysis Springer Berlin 1983 pp 532548 N Mtiller Autonomes Manovrieren UniBwM LRT 1996 B Mysliwetz ED Dickmanns A vision active gaze control structured dynamic scenes LO Hertzberger Systems IASI Amsterdam December 1986 pp 477483 land vehicle DA Pomerleau ALVINN autonomous Advances DA Pomerleau Neural network perception I 151 Carnegie Mellon University Pittsburgh PA February 1992 M Schmid 3DErkennung UniBwM LRT 1994 1 Schick ED Dickmanns Simultaneous estimation 3D shape motion objects vision Proc IEEE Workshop Visual Motion Princeton NJ 1991 ER Schell Bordautonomer lung PhD Thesis UniBwM LRT 1992 J Schiehlen Kameraplattformen 1 Steels The biology technology intelligent autonomous lvano Italy March 112 1993 F Thomanek D Dickmanns Obstacle detection guidance 19Y2 pp 13991406 F Thomanek Visuelle Erkennung und Zustandsschatzung Fahrreugftihrung S Tsugawa T Yatabe T Hirose S Matsumoto An automobile artificial 79 Tokyo 1979 pp 893895 B Ulmer VITA IIActive Paris October 1994 S Werner S Ftirst D Dickmanns ED Dickmanns A visionbased multisensor machine perception autonomous Proc Enhanced Synthetic Vision AeroSense96 Orlando FL April 1996 automatischer Landeanflug aufgrund bildhafter und inertialer MeBdatenauswer fur aktiv sehende Fahrzeuge PhD Thesis UniBwM LRT 1995 road vehicle IROS Vol II Raleigh real traffic Proc Intelligent Vehicles Symposium Intemat Conf Intelligent Robots Systems Echtzeit aus monokularen Bildfolgen agents NATO Advanced Study Institute PhD Thesis UniBwM LRT 1996 von mehreren Straaenfahrzeugen tracking state estimation Proc IEEERSJ collision avoidance landing approach Proc IJCAI von Fahrzeugen autonomous zur autonomen PhD Thesis intelligence aircraft Ed 04 76 ED Dickmanns Artificial Intellipmce 103 1998 4976 421 S Werner Maschinelle Wahmehmung fur den bordautonomen automathen Hubschauberflug PhD Thesis UniBwM LRT 1997 1431 HJ Wuensche Verbesserte Regehmg Sichtinformation Report HSBwiLRTlWE unter Bertlcksichtigung 13aAB832 1983 eines dynamischen der Einfliisse verschiedener Zustandsschatzer Systems durch Auswettung redundanter und Abtastzeiten 44 HJ Wuensche Detection control mobile robot motion realtime vision N Marquino Ed Advances Intelligent Robotics Systems Proc SPIE Vol 727 1986 pp lOC109