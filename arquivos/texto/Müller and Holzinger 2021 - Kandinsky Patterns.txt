Artiﬁcial Intelligence 300 2021 103546 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Kandinsky Patterns Heimo Müller Andreas Holzinger Medical University Graz Austria r t c l e n f o b s t r c t Article history Received 16 September 2019 Received revised form 23 May 2021 Accepted 3 June 2021 Available online 9 June 2021 Keywords Explainable AI Explainability Synthetic test data Ground truth Kandinsky Figures Kandinsky Patterns mathematically describable simple self contained controllable synthetic test data sets development validation training visual tasks explainability artiﬁcial intelligence AI Whilst Kandinsky Patterns computationally manageable properties time easily distinguishable human observers Consequently controlled patterns described humans computers We deﬁne Kandinsky Pattern set Kandinsky Figures ﬁgure infallible authority deﬁnes ﬁgure belongs Kandinsky Pattern With simple principle build training validation data sets testing explainability interpretability context learning In paper basic idea underlying principles Kandinsky Patterns We provide Github repository invite international AI research community challenge experiment Kandinsky Patterns The goal help expand advance ﬁeld AI particular contribute increasingly important ﬁeld explainable AI 2021 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 1 Introduction AI currently successful advances statistical machine learning deep learning ii availability large amounts training data iii available computing power 1 2 The high complexity nonlinearity high dimensionality approaches diﬃcult human interpret approaches considered black box models 3 Boosted DARPAs Explainable Artiﬁcial Intelligence Program 4 ﬁeld explainable AI xAI experienced tremendous renaissance Due imoprtance legal ethical considerations explainability enormously rel evant established important concept In roughly simpliﬁed terms explainability technically highlights decision relevant parts machine representations andor parts contributed model accuracy training xAI community developed variety successful methods However explainability refer human model In certain application domains medical domain need going explainability need causability Causability 5 typo synonym Causality 6 The term Causability intro duced reference wellknown term Usability 7 Causability deﬁned measurable extent explanation resulting explainable AI method human achieves speciﬁed level causal understanding This paper Special Issue Explainable AI Corresponding author Email address heimomuellermedunigrazat H Müller URL httphumancenteredai H Müller httpsdoiorg101016jartint2021103546 00043702 2021 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 measured effectiveness eﬃciency satisfaction speciﬁed context use similar usability This mea sured System Causability Scale SCS 8 Consequently causability refers human model understanding ensured mapping explainability causability A successful mapping require new humanAI interfaces allow domain experts interactively ask questions counterfactual questions gain insight underlying independent explanatory factors result 9 In ideal world human AI statements identical congruent ground truth deﬁned humans AI equally 8 Compared map metaphor explainabilitycausability mapping establishing connections relations drawing new map It identifying areas completely different maps For example explaining predictions deep learning models apply explanation method simple sensitivity analysis understand prediction terms input variables The result explainability method heatmap This heatmap visualization indicates pixels need changed image look AIsystems perspective like predicted class 10 On hand corresponding human concepts contextual understanding needs effective mapping 11 future grand goal humancentered AI 12 The central motivation work lack ground truth testing real data sets Image classiﬁers operate lowlevel features lines circles highlevel concepts domain concepts images storefront With Kandinsky exploration environment produce Kandinsky Figures Kandinsky Patterns ground truth With mathematically describable simple controllable synthetic test data sets enhance development validation training visual tasks explainability Very important time easily distinguishable human observers 2 Kandinsky patterns Wassily Kandinsky 18661944 inﬂuential Russian painter 13 As career progressed Kandinsky produced increasingly abstract images For period 1922 1933 taught famous Bauhaus school Germany celebrated simple colors forms Kandinsky theorist artist derived profound meaning aesthetic experiences One Kandinskys ideas certain fundamental associations colors shapes 14 proposed YellowTriangle BlueCircle RedSquare These associations formulated introspec tively conduct survey Bauhaus 1923 postulated correspondence color form Subsequent empirical studies preference judgments test Kandinskys original colorform combinations usually yielding inconsistent results Recent ﬁndings suggest implicit association original colorform combinations considered universal property visual 15 In work pursue hypothesis visual principles Kandinsky starting point eponym following deﬁnitions A Kandinsky Figure square image containing 1 n geometric objects Each object characterized shape color size position square Objects overlap cropped border All objects easily recognizable clearly distinguishable human observer The set possible Kandinsky Figures k deﬁned general deﬁnition speciﬁc set values shape color size position number geometric objects In following examples use shape values circle square triangle color use values red blue yellow allow arbitrary positions size restriction recognizable Furthermore require Kandinsky Figure contain exactly 4 objects following illustrative examples In demo implementation fact embedded base class Kandinsky Universe generator functions1 Fig 1 A Statement sk Kandinsky Figure k mathematical function sk B B0 1 natural language statement true false Remark The evaluation natural language statement speciﬁc context In followings examples use known concepts human perception linguistic theory If sk given algorithm essential function pure function computational analogue mathematical function A Kandinsky Pattern K deﬁned subset possible Kandinsky Figures k sk 1 natural language statement true sk natural language statement equivalent resulting Kandinsky Patterns tains Kandinsky Figures sk natural language statement deﬁned Ground Truth Kandinsky Pattern In deep learning solution classiﬁcation algorithm visual pattern usually represented highly nonlinear highdimensional network One aim explainable AI identify areas activation network structure correspond concepts natural language statement Problem 1 How explain Kandinsky Pattern know Ground Truth membership Kandinsky Figures Kandinsky Pattern known limited number Kandinsky Figures Problem 2 Generate natural language statement easily understandable equivalent machine expla nation classiﬁcation algorithm 1 httpsgithub com human centered ai lab app kandinskypattern generator 2 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 Fig 1 A Kandinsky Figure 4 objects For interpretation colors ﬁgures reader referred web version article Fig 2 Five Kandinsky Figures Kandinsky Pattern Fig 3 Kandinsky Figures h1k ﬁrst row shows contradictions The process explanation generation reﬁnement hypothesis ﬁnd underlying description The vali dation achieved scientiﬁc method asking question forming testable hypothesis setting experimental design running experiment accepting hypothesis rejecting case according 16 assumption The ground truth prove disprove research hypotheses Ground truthing consequently refers pro cess collecting proper objective provable data testing hypothesis For machine learning algorithm explanation seen successful classiﬁcation algorithm Kandinsky pattern The following example illustrates The ground truth gtk Kandinsky Figure pairs objects shape pair objects color pair different colors pairs disjunct dont share objects deﬁnes Kandinsky Pattern K gt Fig 2 For general hypothesis h1k Kandinsky Figure pairs objects shape Kh1 K gt cid4 Kandinsky Pattern h1k contains Kandinsky Figures Kandinsky Pattern ground truth Fig 3 shows Kandinsky Figures according h1k ﬁrst row contradiction ground truth falsiﬁes h1k A speciﬁc hypothesis like h2k Kandinsky Figure consists triangles different color circles color generates Kandinsky Pattern Kh2 K gt Kh2 cid4 Kandinsky Pattern h2k missing Kandinsky Figures Kandinsky Pattern ground truth Fig 4 shows ﬁrst row Kandinsky Figures according h2k Kandinsky Figures K gt second row falsify h2k Kh K gt K gt Kh set contradictions given hypothesis h 3 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 Fig 4 Kandinsky Figures h2k ﬁrst row Kandinsky Figures K gt second row falsify h2k 3 Background In natural language statement Kandinsky Figure humans use series basic concepts combined logical operators The following incomplete examples illustrate concepts increasing complexity Basic concepts given deﬁnition Kandinsky Figure set objects described shape color size position Existence numbers setrelations number quantity quantity ratios objects Kandinsky Figure contains 4 red triangles yellow objects circles Spatial concepts describing arrangement objects absolute upper lower left right relative touching Kandinsky Figure red objects left blue objects right yellow objects blue squares Gestalt concepts closure symmetry continuity proximity similarity Kandinsky Figure objects grouped circular manner Domain concepts group objects perceived ﬂower In experiments Hubel Wiesel 1962 17 discovered visual builds image simple stimuli complex representations This inspired neural network community socalled deep learning models cascading model cell types follows similar simple rules ﬁrst lines learned shapes objects formed eventually leading concept representations By use backpropagation model able discover intricate structures large data sets indicate internal parameters adapted compute representation layer representation previous layer 2 Building concept representations refers human ability learn categories objects recognize new instances categories In machine learning concept learning deﬁned inference Booleanvalued function training examples inputs outputs 18 words training algorithm distinguish examples nonexamples contradictions Concept learning relevant research area machine learning long time origins cognitive science deﬁned search attributes distinguish exemplars non exemplars categories 19 The ability think abstractions powerful tools humans possess Technically humans order experience coherent categories deﬁning given situation member collection situations responses x y likely appropriate This classiﬁcation passive process understand humans learn abstractions essential understanding human thought building artiﬁcial intelligence machines 20 One interesting study performed 21 presented sets A B simple diagrams diagrams set A common factor attribute lacking diagrams set B The problem ﬁnd common factor These problems described popular book 22 In vision important task ﬁnd likely interpretation W observed image I W includes information spatial location extent objects boundaries Let SW function associated interpretation W encodes spatial location extent component S W j 1 image location j belongs component 0 Given image obtaining optimal likely interpretation W associated SW diﬃcult For example edge detection previous work 23 asked probability given location given image belonging component 24 presented model concept learning computationally grounded able ﬁt human behavior He argued apparently distinct modes generalizing concepts abstracting rules computing similarity exemplars seen special cases general Bayesian learning framework Originally Bayes speciﬁc 25 explained speciﬁc workings modes rules abstracted similarity measured generalization appear different situations This analysis suggests rulessimilarity distinction computationally fundamental useful algorithmic level principled approximation fully Bayesian learning 4 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 GestaltPrinciples Gestalt German shape set empirical laws describing humans gain meaningful perceptions sense chaotic stimuli realworld As Gestaltcues machine learning long time Particularly learning classiﬁcation models segmentation task classify good seg mentations bad segmentations use Gestaltcues features priors train learning model Images segmented manually humans examples good segmentations ground truth bad segmentations constructed randomly matching human segmentation different image 26 Gestaltprinciples 27 seen rules discriminate competing segmentations equal speak gen erally Gestaltlaws particular group Gestaltlaws Gestaltlaws grouping called Prägnanz 28 include law Proximity objects close appear form groups completely dif ferent Law Similarity similar objects grouped law Closure objects perceived incomplete hidden objects 4 Related work Reasoning explanation long history AImachine learning community 29 recently number authors proposed mechanisms generating explanations deep learning models Among Compositional Language Elementary Visual Reasoning diagnostics dataset CLEVR 30 CLEV ERER 31 CLOSURE 32 CURI 33 BongardLOGO 34 VPROM 35 mention We present tiny fraction related work apologize work mentioned refer future work 36 Within machine learning community intensive debate neural networks learn abstract reasoning merely rely pure correlation In recent paper authors 37 propose data set challenge investigate abstract thinking inspired wellknown human IQ test Raven test speciﬁcally Ravens Progressive Matrices RPM Mill Hill Vocabulary Scales developed 1936 use fundamental research genetic environmental determinants intelligence 38 The premise RPMs simple reason relationships perceptually obvious visual features shape positions line colors choose image completes matrix For example size squares increases rows correct image adheres size relation RPMs strongly diagnostic abstract verbal spatial mathematical reasoning ability To succeed challenge models cope generalization regimes training test data differ clearlydeﬁned ways Kandinsky Patterns validation data set experiments explainability similarly following works 39 proposed model focused discriminating properties visible object jointly predicts class la bel They explained predicted label appropriate respective image basis loss function based sampling reinforcement learning learns generate sentences realize global sentence property class speciﬁcity 40 proposed technique producing visual explanations following Gradientweighted Class Activation Mapping GradCAM uses gradients target concept logits dog caption inﬂuencing ﬁnal convolutional layer produce coarse localization map highlight relevant regions image predicting concept 41 introduced called Concept Activation Vectors CAVs provide interpretation neural networks internal state terms humanfriendly concepts Their key idea view highdimensional internal state neural network aid obstacle 30 presented different approach called CLEVR contains diagnostic data set testing visual reasoning abilities The code render synthetic images compositional questions images How small spheres Each question CLEVR represented natural language functional program representation allows precise determination reasoning skills required answer question Questions CLEVR test aspects visual reasoning including attribute identiﬁ cation counting comparison spatial relationships logical operations However work deal concept learning 42 described similar approach earlier addressing task learning novel visual concepts interactions concepts images sentence descriptions 5 Data sets challenges Kandinsky Patterns test data sets research questions address evaluate following topics 1 Describe classes Kandinsky Patterns according ability classiﬁed machine learning algorithms comparison human explanation strategies 2 Investigate transfer learning concepts numbers geometric positions Gestalt principles classiﬁcation explanation Kandinsky Patterns 3 Develop mapping strategies algorithmic classiﬁcation known human explanation Kandinsky Pattern 4 Automatic generation human understandable explanation Kandinsky Pattern 5 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 Fig 5 Kandinsky Figures according ground truth challenge 1 Fig 6 Kandinsky Figures belonging Kandinsky Pattern challenge 1 Fig 7 Kandinsky Figures falsify simple hypothesis challenge 1 Fig 8 Kandinsky Figures according ground truth challenge 2 We invite international machine learning community experiment Kandinsky data set2 reuse contribute Kandinsky software tools3 Please note main aim training data sets following challenges evaluation machine learning algorithms explaining successful classiﬁcation human understandable statements 51 Challenge 1 objects shapes In challenge Objects Shapes ground truth gtk deﬁned Kandinsky Figure small objects arranged big shapes object shapes big shape type X small object type X exists Big square shapes contain blue red objects big triangle shapes contain yellow red objects big circle shapes contain yellow blue objects Fig 5 shows Kandinsky Figures according ground truth Fig 6 shows random Kandinsky Figures approxi mately number objects belonging Kandinsky Pattern Fig 7 Kandinsky Figures generated simple valid hypothesis Question 1 Which machine learning algorithm classify Kandinsky Figures challenge 1 Question 2 Identify layers regions network correspond small big shapes restric tions object membership color Download data set challenge 1 httpstinyurl com KandinskyC14 2 httpsgithub com human centered ai lab dat kandinskypatterns 3 httpsgithub com human centered ai lab app kandinskypattern generator 4 httpsgithub com human centered ai lab dat kandinskypatterns tree master challenge nr1 6 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 Fig 9 Kandinsky Figures belonging Kandinsky Pattern challenge 2 Fig 10 Kandinsky Figures falsify simple hypothesis challenge 2 Fig 11 Kandinsky Figures according ground truth challenge 3 Fig 12 Kandinsky Figures belonging Kandinsky Pattern challenge 3 52 Challenge 2 circles In challenge Nine Circles set Kandinsky Figures consists 9 circles arranged regular grid Fig 8 shows Kandinsky Figures according ground truth Fig 9 shows Kandinsky Figures belonging Kandinsky Pattern Fig 10 shows Kandinsky Figures true fulﬁll hypothesis similar ground truth counter factual Question 1 Explain Kandinsky Pattern algorithmic way train network classiﬁes Kandinsky Figures according ground truth challenge 2 Question 2 Explain Kandinsky Pattern natural language Download data set challenge 2 httpstinyurl com KandinskyC25 53 Challenge 3 blue yellow circles In challenge Blue Yellow Circles set possible Kandinsky Figures consists equal size blue yellow circles Fig 11 shows Kandinsky Figures according ground truth Fig 12 shows Kandinsky Figures approximately number objects belonging Kandinsky Pattern Fig 13 Kandinsky Figures true fulﬁll hypothesis similar ground truth Question 1 Explain Kandinsky Pattern algorithmic way train network classiﬁes Kandinsky Figures according ground truth challenge 3 Question 2 Explain Kandinsky Pattern natural language 5 httpsgithub com human centered ai lab dat kandinskypatterns tree master challenge nr2 7 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 Fig 13 Kandinsky Figures falsify simple hypothesis challenge 3 Download data set challenge 3 httpstinyurl com KandinskyC36 6 Conclusion By comparing strengths machine intelligence human intelligence possible solve problems currently lacking appropriate methods One overriding question How perform task exploiting knowl edge extracted solving previous tasks To answer question necessary insight human behavior goal mimicking human behavior contrast human learning methods machine learning methods We hope Kandinsky Patterns challenge international machine learning community looking forward receiving comments results Updated information accompanying Web page7 Declaration competing We wish conﬁrm known conﬂicts associated publication signiﬁcant ﬁnancial support work inﬂuenced outcome Acknowledgements We grateful valuable comments encouragement anonymous reviewers Parts work received funding European Unions Horizon 2020 research innovation programme grant agreement No 824087 EOSCLife Austrian Science Fund FWF Project P32554 explainable Artiﬁcial Intelligence This publication reﬂects authors view European Commission responsible use information contains References 1 J Schmidhuber Deep learning neural networks overview Neural Netw 61 1 2015 85117 httpsdoi org 10 1016 j neunet 2014 09 003 2 Y LeCun Y Bengio G Hinton Deep learning Nature 521 7553 2015 436444 3 A Holzinger M Plass K Holzinger GC Crisan CM Pintea V Palade A glassbox interactive machine learning approach solving nphard problems humanintheloop arXiv1708 01104 4 D Gunning DW Aha Darpas explainable artiﬁcial intelligence program AI Mag 40 2 2019 4458 httpsdoi org 10 1609 aimag v40i2 2850 5 A Holzinger G Langs H Denk K Zatloukal H Müller Causability explainability artiﬁcial intelligence medicine Wiley Interdiscip Rev Data Min Knowl Discov 9 4 2019 113 httpsdoi org 10 1002 widm 1312 6 J Pearl Embracing causality default reasoning Artif Intell 35 2 1988 259271 httpsdoi org 10 1016 0004 370288 90015 X 7 A Holzinger Usability engineering methods software developers Commun ACM 48 1 2005 7174 httpsdoi org 10 1145 1039539 1039541 8 A Holzinger A Carrington H Müller Measuring quality explanations causability scale scs Comparing human machine explanations Special Issue Interactive Machine Learning Edited Kristian Kersting TU Darmstadt Künstl Intell J Artif Gen Intell 34 2 2020 193198 httpsdoi org 10 1007 s13218 020 00636 z 9 A Holzinger B Malle A Saranti B Pfeifer Towards multimodal causability graph neural networks enabling information fusion explainable ai Inf Fusion 71 7 2021 2837 httpsdoi org 10 1016 j inffus 202101008 10 W Samek T Wiegand KR Müller Explainable artiﬁcial intelligence understanding visualizing interpreting deep learning models arXiv1708 08296 2013 00616 11 BM Lake R Salakhutdinov JB Tenenbaum Humanlevel concept learning probabilistic program induction Science 350 6266 2015 13321338 httpsdoi org 10 1126 science aab3050 12 A Holzinger C Biemann CS Pattichis DB Kell What need build explainable ai systems medical domain arXiv1712 09923 13 H Düchting Wassily Kandinsky 18661944 A Revolution Painting Taschen Köln 2000 14 W Kandinsky Über die Formfrage Der Blaue Reiter 3 1912 74100 15 A Makin S Würger The iat shows evidence Kandinskys colorshape associations Front Psychol 4 2013 616 httpsdoi org 10 3389 fpsyg 16 K Popper Die Logik der Forschung Zur Erkenntnistheorie der modernen Naturwissenschaft SpringerVerlag Wien 1935 17 DH Hubel TN Wiesel Receptive ﬁelds binocular interaction functional architecture cats visual cortex J Physiol 160 1 1962 106154 httpsdoi org 10 1113 jphysiol 1962 sp006837 18 TM Mitchell Machine Learning McGraw Hill New York 1997 6 httpsgithub com human centered ai lab dat kandinskypatterns tree master challenge nr3 7 httpshuman centered ai kandinksychallenge 8 H Müller A Holzinger Artiﬁcial Intelligence 300 2021 103546 19 JS Bruner On attributes concepts Chapter 2 JS Bruner JJ Goodnow GA Austin Eds A Study Thinking John Wiley Sons Inc 1956 pp 2549 20 EB Hunt Concept Learning An Information Processing Problem Wiley Hoboken NJ 1962 21 MM Bongard The Problem Recognition Russian Nauka Moscow 1967 22 Goedel Hofstadter DR Escher Bach An Eternal Golden Braid Basic Books New York 1979 23 P Dollar Z Tu S Belongie Supervised learning edges object boundaries IEEE Computer Society Conference Computer Vision Pattern 24 JB Tenenbaum Bayesian modeling human concept learning SA Solla TK Leen KR Müller Eds Advances Neural Information Processing Recognition CVPR06 IEEE 2006 pp 19641971 Systems NIPS 1999 NIPS Foundation 1999 pp 5968 25 PS Laplace Mémoire sur les probabilités Mém Acad R Sci Paris 1778 1781 227332 httpwwwcs xu edu math Sources Laplace memoir _ probabilities pdf pp 1017 26 X Ren J Malik Learning classiﬁcation model segmentation Ninth IEEE International Conference Computer Vision ICCV IEEE 2003 27 K Koffka Principles Gestalt Psychology Harcourt New York 1935 28 M Wertheimer Laws organization perceptual forms WD Ellis Ed A Source Book Gestalt Psychology Paul Kegan London 1938 pp 7188 29 DL Poole AK Mackworth R Goebel Computational Intelligence A Logical Approach Oxford University Press New York 1998 30 J Johnson B Hariharan L van der Maaten L FeiFei C Lawrence Zitnick R Girshick CLEVR diagnostic dataset compositional language elementary visual reasoning Proceedings IEEE Conference Computer Vision Pattern Recognition CVPR IEEE 2017 pp 29012910 31 K Yi C Gan Y Li P Kohli J Wu A Torralba JB Tenenbaum Clevrer collision events video representation reasoning arXiv1910 01442 32 D Bahdanau H Vries TJ ODonnell S Murty P Beaudoin Y Bengio A Courville Closure assessing systematic generalization clevr models 33 R Vedantam A Szlam M Nickel A Morcos B Lake Curi benchmark productive concept learning uncertainty arXiv2010 02855 34 W Nie Z Yu L Mao AB Patel Y Zhu A Anandkumar BongardLOGO A New Benchmark HumanLevel Concept Learning Reasoning arXiv 35 D Teney P Wang J Cao L Liu C Shen A van den Hengel VPROM A Benchmark Visual Reasoning Using Visual Progressive Matrices arXiv 36 A Holzinger A Saranti H Müller Kandinsky Patterns experimental exploration environment pattern analysis machine intelligence 37 A Santoro F Hill D Barrett A Morcos T Lillicrap Measuring abstract reasoning neural networks 35th International Conference Machine Learning PMLR 2018 pp 44774486 38 J Raven The Ravens progressive matrices change stability culture time Cogn Psychol 41 1 2000 148 httpsdoi org 10 1006 cogp 39 LA Hendricks Z Akata M Rohrbach J Donahue B Schiele T Darrell Generating visual explanations arXiv1603 08507 40 RR Selvaraju M Cogswell A Das R Vedantam D Parikh D Batra GradCAM visual explanations deep networks gradientbased localization 41 B Kim M Wattenberg J Gilmer C Cai J Wexler F Viegas R Sayres Interpretability feature attribution quantitative testing concept ICCV 2017 pp 618626 activation vectors TCAV arXiv171111279 42 J Mao X Wei Y Yang J Wang Z Huang AL Yuille Learning like child fast novel visual concept learning sentence descriptions images Proceedings IEEE International Conference Computer Vision ICCV 2015 2015 pp 25332541 arXiv1912 05783 2010 00763 2020 190712271 2019 arXiv2103 00519 1999 0735 9