Artiﬁcial Intelligence 305 2022 103682 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Sensitive loss Improving accuracy fairness face representations discriminationaware deep learning Ignacio Serna School Engineering Universidad Autonoma Madrid Spain b Center Humans Machines Max Planck Institute Human Development Berlin Germany Aythami Morales Julian Fierrez Nick Obradovich b r t c l e n f o b s t r c t Article history Received 8 October 2020 Received revised form 27 January 2022 Accepted 8 February 2022 Available online 14 February 2022 Keywords Machine behavior Bias Fairness Discrimination Machine learning Learning representations Face Biometrics We propose discriminationaware learning method improve accuracy fairness biased face recognition algorithms The popular face recognition benchmarks assume distribution subjects paying attention demographic attributes In work perform comprehensive discrimination aware experimentation deep learningbased face recognition We propose notational framework algorithmic discrimination application face biometrics The experiments include popular face recognition models public databases composed 64000 identities different demographic groups characterized sex ethnicity We experimentally learning processes based face databases led popular pretrained deep face models present evidence strong algorithmic discrimination Finally propose discriminationaware learning method Sensitive Loss based popular triplet loss function sensitive triplet generator Our approach works addon pretrained networks improve performance terms average accuracy fairness The method shows results comparable stateoftheart debiasing networks represents step forward prevent discriminatory automatic systems 2022 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 1 Introduction Artiﬁcial Intelligence AI developed meet human needs represented form objectives To end popular machine learning algorithms designed minimize loss function deﬁnes cost wrong solutions pool samples This simple successful scheme enhanced performance AI ﬁelds Computer Vision Speech Technologies Natural Language Processing But optimization speciﬁc computable objectives lead behavior expect desire AI International agencies academia industry alerting policymakers public unforeseen effects behaviors AI agents initially considered design phases 1 In context aspects trustworthiness fairness included learning objectives taken granted See Fig 1 Machine vision general face recognition algorithms particular good examples recent advances AI 36 The performance automatic face recognition boosted decade achieving competitive Corresponding author Email addresses ignaciosernauames I Serna aythamimoralesuames A Morales julianﬁerrezuames J Fierrez obradovichmpibberlinmpgde N Obradovich httpsdoiorg101016jartint2022103682 00043702 2022 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Fig 1 The objective learning process abstraction expected behavior AI There usually direct path machine expected behavior machine behavior normally evaluated terms utility Learning objectives usually determined factors task data algorithms experimental protocols losing sight key aspects expected behavior fairness Figure inspired standard model proposed 2 accuracies challenging scenarios 7 These improvements possible advances machine learning deep learning powerful computation GPUs larger databases scale millions images However recognition accuracy aspect considered designing biometric systems There currently growing need study AI behavior order better understand impact society 1 Face recognition systems especially sensitive personal information present face images identity sex ethnicity age The number published works pointing potential discriminatory effects results face detection recognition algorithms large 817 In environment limited number works analyze biases affect learning process algorithms dealing personal information 1819 There lack understanding demographic information affects popular widely pretrained AI models performance On hand right nondiscrimination deeply rooted normative framework underlies national international regulations example Article 7 Universal Declaration Human Rights Article 14 European Convention Human Rights As evidence concerns European Parliament passed General Data Protection Regulation GDPR1 April 2018 set laws aimed regulating collection storage use personal information According paragraph 71 GDPR controllers sensitive data processing implement appropriate technical organizational measures prevent inter alia discriminatory effects The aim work analyze face recognition models discriminationaware perspective demonstrate learning processes involving discriminationaware perspective train accurate fairer algorithms The main contributions work A comprehensive analysis causes effects biased learning processes including discriminationaware performance analysis based public datasets 64K identities equally distributed demographic groups ii study deep representations role sensitive attributes sex ethnicity iii complete analysis demographic diversity present popular face databases analysis new databases available train models based diversity Based analysis causes effects biased learning algorithms propose eﬃcient discrimination aware learning method mitigate bias deep face recognition models Sensitive Loss The method based inclusion demographic information popular triplet loss representation learning Sensitive Loss incorporates fairness learning objective training process algorithm The method works addon applied pretrained representations improve performance fairness requiring complete retraining We evaluated method public databases showing improvement overall accuracy fairness Our results incorporate discriminationaware learning rules signiﬁcantly reduce bias deep learning models Preliminary work research line presented 20 Key improvements 20 include indepth anal ysis stateoftheart including extensive survey face recognition databases ii inclusion new datasets 1 EU 2016679 General Data Protection Regulation Available online httpsgdprinfo eu 2 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Fig 2 Face recognition block diagrams The screener algorithm given face images decides belong person The trainer algorithm generates best data representation screener experiments involving 40000 new identities 1M images iii novel discriminationaware learning method called Sensitive Loss The rest paper structured follows Section 2 summarizes related work Section 3 presents general formulation algorithmic discrimination Section 4 presents proposed discriminationaware learning method Section 5 describes evaluation procedure Section 6 presents experimental results Finally Section 7 summarizes main conclusions 2 Related work 21 Face recognition methods A face recognition algorithm like machine learning systems divided different algorithms screener trainer Both algorithms different purposes 21 The screener takes characteristics individual returns prediction individuals outcome trainer produces screener In case screener Fig 2 algorithm given face images generates output associated probability belong person This probability obtained comparing learned representations face model deﬁned parameters w These parameters previously trained given dataset D Fig 2 If properly trained output trainer model parameters w capable representing input data face images highly discriminant feature space x The popular architecture model face attributes Convolutional Neural Network CNN 22 The pre trained models embedding extractor x l2normalised learned representation face image The similarity face descriptors xr xs calculated Euclidean distance xr xs Two faces assigned identity distance smaller threshold τ The recognition accuracy obtained comparing distances positive matches xr xs belong person negative matches xr xs belong different persons 22 Bias face databases Following trainerscreener division bias rooted trainer The trainer common algorithm usually varies loss function 23 optimization algorithm data uses training Bias traditionally associated unequal representation classes dataset The history automatic face recognition linked history databases algorithm training decades The number publicly available databases high allow training models millions face images Table 1 summarizes demographic statistics frequently cited face databases In order obtain demographic statistics sex ethnicity classiﬁcation algorithms trained based ResNet50 model 24 12K identities DiveFace database equally distributed demographic groups The models evaluated 20K labeled images CelebA performance greater 97 Each databases characterized biases image quality pose backgrounds aging In work highlight unequal representation demographic information popular face recognition databases As seen differences ethnic groups Even people Asia constitute 35 worlds population account 9 content popular face recognition databases Biased databases imply double penalty underrepresented classes On hand models trained according nonrepresentative diversity On hand accuracy measured privileged classes overestimates real performance diverse society Recently diverse discriminationaware databases proposed 1315182527 These databases valu able resources exploring diversity improve face biometrics However databases 3 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Table 1 Demographic statistics stateoftheart face databases ordered number images In order obtain demographic statistics sex ethnicity classiﬁ cation algorithms trained based ResNet50 model 24 12K identities DiveFace database equally distributed demographic groups Models evaluated 20K labeled images CelebA performance 97 The table includes averaged demographic statistics popular face databases literature Dataset ref images identities avg images identity Caucasian AfricanIndian FRVT2018 28 MSCeleb1M 29 MegaFace 30 VGGFace2 31 VGGFace 32 YouTube 33 CASIA 34 CelebA 35 PubFig 36 IJBC 37 UTKface 38 LFW 39 BioSecure 40 Average 27M 85M 47M 33M 26M 621K 500K 203K 58K 21K 24K 13K 27K 12M 100K 660K 9K 26K 16K 105K 102K 200 35K 57K 667 Databases discriminationaware learning BUPTB 18 DiveFace 41 FairFace 27 RFW 25 DemogPairs 15 13M 125K 100K 40K 108K 28K 24K 12K 600 2 85 7 370 1K 390 48 20 294 6 2 4 46 5 3 18 Male 484 524 400 459 437 569 488 339 495 403 262 589 501 Female 165 192 303 302 386 203 332 415 355 302 200 187 36 Male 199 121 62 105 58 77 72 64 65 118 215 96 31 Female 74 39 47 63 69 40 57 82 55 60 163 33 21 46 29 10 6 Asian Male 12 77 106 34 21 79 26 44 20 54 71 72 43 5 Female 04 45 81 36 29 30 26 55 10 62 89 22 45 4 3333 167 250 167 200 3333 3333 167 144 167 139 3333 3333 167 136 167 131 3333 167 167 167 167 167 167 include identities 132627 face images matched images Therefore databases allow adequate training testing face recognition algorithms Note groups databases divided heterogeneous include people different ethnicities We aware limitations grouping human ethnic origins categories According studies 5000 ethnic groups world Our experiments similar reported liter ature include groups order maximize differences classes Automatic classiﬁcation algorithms based reduced categories performances 98 accuracy 10 23 Bias face recognition Facial recognition systems suffer variety biases ranging arising unconstrained environ mental variables illumination pose expression face resolution systematic errors image quality demographic factors like age sex race 9 An FBIcoauthored study 12 tested commercial algorithms supplier companies public organizations US In algorithms African Americans likely successfully identiﬁed likely falsely rejected demographic groups A similar decline surfaced females compared males younger subjects compared older subjects More recently latest NIST evaluation commercial face recognition technology Face Recognition Vendor Test FRVT Ongoing shows sensitivity thresholds resulted white men falsely matched 1K list 167 algorithms twice likely misidentify black women reaching 40 times 28 The number academic studies analyzing fairness face recognition algorithms grown recent years 16 There published studies analyzing face recognition performance demographic groups 12 28 probably systematic comprehensive thorough uptodate 24 Debiasing face recognition Originally statistical sampling methods tackle unbalanced dataset bias face recognition 4243 Recently attempts eliminate bias facial recognition emerging Some semisupervised approaches try use unlabeled faces reduce racial bias performance falls short supervised ones 2544 Others aim remove potential sources variation learned representations This case presented 14 method learn primary classiﬁcation task sex recognition whilst unlearning spurious variables represent undesirable sources bias age ancestral origin pose On hand Das et al proposed MultiTask CNN managed improve performance subgroups sex race 4 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 age 45 These methods intended classiﬁcation tasks face recognition Finally Morales et al developed extension triplet loss function remove sensitive information feature embeddings face recognition 41 In 18 researchers proposed racebalanced reinforcement learning network ﬁnd appropriate margins losses different demographic groups Their model signiﬁcantly reduced performance difference demographic groups However generate adaptive margin policy train convolutional network approach requires ancillary networks oﬄine sampling network deep Qlearning network Similar 18 46 proposed new raceadaptive margin loss function based multitask face recognition network auxiliary task race classiﬁcation Gong et al presented 19 adversarial network learns representation disentangled features sex age race face recognition minimizing correlation debias face recognition demographic attribute estimation These authors devised groupadaptive classiﬁer Presented 47 new classiﬁer focuses attention extracting features best discriminate demographic group To use adaptive convolution kernels attention mechanisms On introduced new objective function reduce variation average intraclass distance demographic groups The aforementioned methods 18194647 applied train debiasing deep architectures face recognition scratch They consist complex architectures require signiﬁcant work exploit combine pre existing networks knowledge important limitation alleviate proposed Sensitive Loss approach 3 Problem statement There formal agreedupon deﬁnition algorithmic discrimination scientiﬁc literature Most approaches rely inequality outcome automatic given sensitive attribute sex ethnicity Discrimination deﬁned Cambridge Dictionary treating person particular group people differently especially worse way way treat people skin color sex sexuality For purpose studying discrimination face recognition systems machine learning large present reformulation Algorithmic Discrimination based dictionary deﬁnition Even ideas similar included formulation 4849 didnt ﬁnd kind formulation related works We hope formalization concepts beneﬁcial fostering research discussion topic Lets begin notation preliminary deﬁnitions Assume xi s learned representation individual I s s 1 S samples individual That representation x different individuals corresponding input image Ii assumed useful task T face authentication emotion recognition That representation x generated input image I artiﬁcial intelligence approach parameters w We assume goodness criterion G task maximizes realvalued performance function f given dataset D collection multiple images form GD max w fD w 1 The popular form previous expression minimizes loss function L set training images D form w arg min w cid2 D Ii s LOIi s w T s 2 O output learning algorithm seek bring closer target function groundtruth T deﬁned task hand On hand individual classiﬁed according demographic criterion d Sex classes CSex Male Female This criterion d source discrimination The particular class k s Male We classes given demographic criterion d given sample noted Cdxi criterion d represented dataset D number samples class signiﬁcant Dk D represents d samples corresponding class k demographic criterion d s CSexxi Finally experimental framework Algorithmic Discrimination deﬁned signiﬁcantly larger difference performing task T face veriﬁcation goodness G considering set data D including multiple samples multiple individuals goodness GDk d subset data corresponding class k Female demographic criterion d The representation x model parameters w typically realvalued vectors set features combining real discrete values Note formulation easily extended case variable number samples S different subjects common case classes K disjoint Note previous formulation based average performances groups individuals In artiﬁcial intelligence tasks common different performance speciﬁc individuals reasons speciﬁc users sensed properly 50 case algorithms average similar performance different classes source discrimination Therefore formulation deﬁnition Algorithmic Discrimination opted use average performances demographic groups 5 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Fig 3 Top Block diagram domainadaptive learning process allows generate unbiased representation ϕx biased represen tation x A Balanced Dataset DT preferable input Sensitive Loss select triplets T This DT different subset generally Unbalanced Dataset D train biased model w appears Eq 1 Bottom Discriminationaware generation triplets given represented unfavored demographic group representation ϕx increases distance d Anchor Negative samples reducing distance Anchor Positive seeking improve performance unfavored group stands independence Other related works example 5152 beginning investigate discrimination effects AI userspeciﬁc methods lack mathematical framework clear deﬁnitions Userspeciﬁc Algorithmic Discrimination UAD comparison deﬁned Groupbased Algorithmic Discrimination GAD We study augment framework analysis UAD future work 4 Proposed disciminationaware learning approach sensitive loss Models trained evaluated privileged demographic groups fail generalize model evaluated groups privileged This behavior caused wrong assumption homogeneity facial characteristics world population In work propose reduce bias face recognition models incorporating discriminationaware learning process The methods proposed work reduce bias based strategies Use balanced heterogeneous data train evaluate models The literature shows training balanced dataset guarantee biasfree results 121825 partially reduce bias ii A modiﬁed loss function Sensitive Loss incorporates demographic information guide learning process inclusive feature space The development new cost functions capable incorporating discriminationaware elements training process way reduce bias Our approach based popular triplet loss function applied pretrained models needing retraining network 41 Discriminationaware learning triplet loss Triplet loss proposed distance metric context nearest neighbor classiﬁcation 53 adapted improve performance face descriptors veriﬁcation algorithms 5432 In work propose incorporate demographic data generate discriminationaware triplets train new representation mitigates biased learning Assume image represented embedding descriptor xi s obtained pretrained model Section 3 notation That image corresponds demographic group Cdxi s A triplet composed different images different people Anchor A Positive P different images person Negative N image different person The Anchor Positive share demographic labels Cdx A s labels differ Negative sample CdxN s The transformation ϕx represented parameters wD D Debiasing trained minimize loss function s CdxP 6 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 cid2 xsT min wD ϕx A s ϕxN s 2 ϕx A s ϕxP s 2 cid3 3 xN s Euclidean Distance cid3 margin genuine impostor distances T set triplets generated online sensitive triplet generator guides learning process details Section 42 The effects biased training include representation fails model properly distance faces different people x A s Asian Female The proposed s triplet loss function considers genuine impostor comparisons allows introduction demographic aware information In order guide learning process discriminationaware spirit demographic groups worst performing triplets prioritized online sensitive triplet generator Asian Females Fig 3 shows block diagram learning algorithm belonging minority demographic groups Cdx A s CdxN Algorithm 1 Sensitive Triplet Generation Selection Input Training data batch B ϕxi Output Resulting Sensitive Loss L L Ø Restricted k demographic classes si1B s1S R possible triplets demographic group R cid5ϕxi m Cdemographicx n cid8 m L add Triplet SelectionR l cid6 Cdemographicxi n Cdemographicxi n ϕxi m ϕx j l k j B n m S l S j cid8 j j end U possible triplets batch m ϕx U cid5ϕxi L add Triplet SelectionU l cid6 j B n m S l S j cid8 j n cid8 m n ϕxi j end function Triplet SelectionT L Ø foreach triplet ts T ts cid5ϕx A s 2 ϕx A s ϕxP s ϕxN L add ϕx A 0 ϕx A s ϕxP s ϕxP s 2 ϕx A s ϕxN s cid6 s 2 cid3 s ϕxN s 2 cid3 end end return S end 42 Sensitive loss sensitive triplets Inspired semihard selection proposed 3254 propose online selection triplets automatically pri oritizes learning step triplets demographic groups algorithm performs Fig 3 Our approach results supervised learning framework loss function minimized assuming heteroge neous population divided demographic groups On hand triplets demographic group improve ability discriminate samples similar anthropometric characteristics reducing false acceptance rate Asian Females On hand heterogeneous triplets triplets involving different demographic groups improve generalization capacity model overall accuracy Each batch generated images different identities evenly distributed different demographic groups images identity In experiments 300 identities 50 group 3 images identity batch For eﬃciency form triplets passing images network computing loss function In triplet formation distinguish generation selection triplets Algorithm 1 Triplet Generation This possible triplets formed joined training batch We evaluated types triplet generation Fig 3 Unrestricted U The generator allows triplets mixed demographic groups Cdx A s cid8 s Thus 300 identities 3 images identity 135K triplets generated s Cdx A s CdxN CdxN semihard ones selected Restricted R The generator allow triplets mixed demographic groups CdxP s Thus 300 identities 6 groups 3 images identity 22K triplets generated semihard ones selected s CdxN 7 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Table 2 Computational load inference face models method Sensitive Loss SL applied The computational load measured number GigaFLOPs GFLOPs ﬂoating point operations ResNet50 SLResNet50 VGGFace SLVGGFace ArcFace No GFLOPs 38 00042 155 00168 242 SLArcFace 00002 s ϕxN Triplet Selection Among triplets generated batch triplet selection chooses 0 ϕx A s 2 cid3 These semihard triplets critical adequate convergence avoiding bad local minima 54 If demographic group modeled network terms genuine impostor comparisons triplets group likely included This selection purely guided performance demographic group change batch depending model deﬁciencies s 2 ϕx A s ϕxP We chose triplet loss basis Sensitive Loss allows incorporate demographicaware learning natural way The process datadriven require large number images identity softmax requires large number samples identity use 3 images identity Another advantage necessary train entire network triplet loss applied domain adaptation technique In case trained model biased domain x unbiased domain ϕx Our results demonstrate biased representations x exhibit clear performance differences contain information necessary reduce differences In words bias partially corrected representations obtained pretrained networks new models trained scratch necessary Similar strategies applied loss functions 5 Evaluation procedure 51 Databases discriminationaware learning DiveFace 41 contains annotations equally distributed classes related sex ethnicity There 24K identities 4K class 3 images identity total number images equal 72K Users grouped according sex male female categories related ethnic physical characteristics Caucasian people ancestral origins Europe NorthAmerica LatinAmerica European origin AfricanIndian people ancestral origins SubSaharan Africa India Bangladesh Bhutan Asian people ancestral origin Japan China Korea countries region Racial Faces Wild RFW 25 divided demographic classes Caucasian Indian Asian African Each class 10K images 3K individuals There major differences pose age sex distribution Caucasian Asian Indian groups The African group smaller age difference females account approximately 35 groups account 10 African group BUPTBalancedface BUPTB 18 contains 13M images 28K celebrities obtained MSCeleb1M 29 Divided 4 demographic groups roughly balanced race 7K subjects race Caucasian Indian Asian African 326K 325K 275K 324K images respectively No sex data available dataset 52 Face recognition models VGGFace 32 Model 138M parameters based VGGVeryDeep16 CNN traditional architecture We pretrained model2 trained VGGFace2 dataset according details provided 31 The VGG models developed Visual Geometry Group VGG University Oxford face recognition demonstrated benchmark vision datasets 32 ResNet50 24 ResNet50 CNN model 25M parameters initially proposed generalpurpose image recognition tasks 24 It combines convolutional neural networks residual connections allow information skip layers im prove gradient ﬂow These models tested competitive evaluations public benchmarks 3231 The model2 trained VGGFace2 dataset ArcFace 55 With ResNet architecture 64M parameters ArcFace obtains stateoftheart results multiple datasets 9980 accuracy LFW 39 We publicly available3 pretrained ArcFace model trained MSCeleb1M 29 2 Available httpsgithub com rcmalli keras vggface 3 httpsgithub com deepinsight insightface 8 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Fig 4 Projections ResNet50 embeddings 2D space generated tSNE b Examples classes available DiveFace database different columns Rows 5 6 averaged Class Activation MAP ﬁrst ﬁlter convolutional block ResNet50 method obtained 20 random face images classes Rows 14 Class Activation MAPs face images Maximum minimum activations represented red blue colors respectively For interpretation colors ﬁgures reader referred web version article 53 Implementation details The proposed debiasing method Sensitive Loss require retraining entire pretrained model Fig 3 The sensitive triplets train dense layer following characteristics number units equal size pretrained representation x 4096 2048 512 units VGGFace ResNet50 ArcFace respectively dropout 05 VGGFace Resnet50 005 ArcFace linear activation random initialization L2 normalization This layer relatively easy train 10 epochs Adam optimizer generate new representation ϕx Table 2 shows FLOPs ﬂoating point operations models evaluated Sensitive Loss layer Sensitive Loss depends size pretrained representation x model different Nevertheless computational load inference added face models orders magnitude cases Experiments conducted kfold crossvalidation users images identity 3 genuine 3 users 1 impostor combinations identity ﬁve folds Thus databases divided training set 80 test set 20 fold This results total 192K genuine comparisons DiveFace 72K RFW 36K BUPT 84K 98M impostor comparisons DiveFace 287M RFW 108M BUPT 587M Note ArcFace evaluated DiveFace model trained MS1M 29 overlaps RFW BUPTB datasets databases obtained Before applying face recognition models cropped face images algorithms proposed 5657 6 Experiments 61 Demographic bias learned representations We applied popular data visualization algorithm better understand importance ethnic features embed ding space generated deep models tSNE algorithm visualize highdimensional data This algorithm minimizes KullbackLeibler divergence joint probabilities lowdimensional embedding highdimensional data Fig 4a shows projection face 2D space generated ResNet50 embeddings tSNE algorithm This tSNE projection unsupervised inputs face embeddings labels After running tSNE colored projected point according ethnic attribute As consequent face representation results clusters highly correlated ethnicity attributes Note ResNet50 trained face recog nition ethnicity detection However information sex ethnicity highly embedded feature space unsupervised tSNE algorithm reveals presence information 9 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Table 3 Face veriﬁcation Performance Equal Error Rate EER face datasets described Section 51 matchers VGGFace ResNet50 ArcFace debiasing Sensitive Loss module U Unrestricted Triplet Generation R Restricted Triplet Generation Also shown Average EER demographic groups Standard deviation lower means fairer Caucasian IndianAfrican Male Female Male Female Female Avg Std Model VGGFace VGGFaceU VGGFaceR ResNet50 ResNet50U ResNet50R ArcFace ArcFaceU ArcFaceR Model VGGFace VGGFaceU VGGFaceR ResNet50 ResNet50U ResNet50R VGGFace VGGFaceU VGGFaceR ResNet50 ResNet50U ResNet50R 162 184 180 063 084 090 079 071 069 176 198 197 073 090 093 085 067 065 Caucasian 822 734 726 362 302 302 718 649 648 324 262 262 206 163 165 088 074 078 111 108 096 Indian 1038 778 775 472 329 322 744 497 503 265 169 172 DiveFace Asian Male 253 138 142 099 058 061 134 124 122 RFW 233 177 177 141 121 122 198 179 188 315 144 142 126 060 062 127 117 119 224 167 25 167 25 098 081 17 084 14 122 111 9 110 10 African 1724 1309 1279 575 399 406 978 773 768 380 272 277 Asian 1367 947 905 596 383 392 BUPTBalancedface 1256 829 820 556 319 312 Avg 1238 942 24 921 26 501 353 30 356 29 924 687 26 685 26 382 256 33 256 32 051 021 58 020 61 028 021 24 021 25 039 037 5 041 5 Std 341 227 34 217 36 093 040 58 044 53 217 128 41 122 44 109 054 50 052 52 We tSNE algorithm embeddings method result Fig 4a This means ethnic information present We propose remove racial information This information key recognition goals remove In fact removing decreases performance shown 19 On different CNNs composed large number stacked ﬁlters These ﬁlters trained extract richest information predeﬁned task face recognition Since face recognition models trained identify individuals reasonable think response models vary slightly person In order visualize response model different faces consider speciﬁc Class Activation MAP CAM proposed 58 named GradCAM This visualization technique uses gradients target ﬂowing selected convolutional layer produce coarse localization map The resulting heatmap highlights activated regions image selected target individual identity case Fig 4b represents heatmaps obtained ﬁrst ﬁlter convolutional block ResNet50 faces demographic groups included DiveFace Each column corresponds demographic group The ﬁrst rows contain face images overlaid heatmap The rows represent heatmaps obtained ResNet50 ﬁlter method averaging results 120 different individuals For better visualization 120 images chosen frontal We averaged small group individuals dataset seen images vary widely pose morphology The activation maps clear differences ethnic groups highest activation Caucasians lowest Asians These differences suggest features extracted model partially affected ethnic attributes However method row activations homogeneous demographic groups This homogeneous activation suggests better representation different ethnic groups Recent work shown correlation high activations performance CNNs architectures 5960 The activation maps obtained VGGFace ArcFace models similar ResNet50 These experiments illustrate presence importance ethnic attributes feature space generated face deep models 10 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Fig 5 ResNet50 face veriﬁcation distance score distributions DiveFace RFW BUPTB demographic groups original representation x proposed representation ϕx Note proposed Sensitive Loss representation ϕx reduces gap impostor distributions dotted lines demographic groups For interpretation colors ﬁgures reader referred web version article 62 Performance sensitive loss Table 3 shows performance Equal Error Rate EER demographic group average EER DiveFace RFW BUPT test sets baseline models VGGFace ResNet50 ArcFace Sensitive Loss methods described Section 41 Unrestricted Restricted In order measure fairness Table 3 includes standard deviation EER demographic groups Std These measures proposed 1819 analyze performance debiasing algorithms If focus attention results obtained Baseline systems denoted VGGFace ResNet50 ArcFace different performances database This caused particular characteristics database age pose distributions samples The results reported Table 3 clearly sex ethnicity signiﬁcantly affect performance biased models These effects particularly high ethnicity large degradation performance class represented training data In DiveFace relative increment Equal Error Rate EER 94 124 150 VGGFace ResNet50 ArcFace respectively regard best class Caucasian Male For RFW BUPTBalancedface differences demographic groups similar large distinction demographic groups ethnic origin sex These differences important mark percentage faces successfully matched faces incorrectly matched certain threshold Let consider performance function f described Eq 1 accuracy face recogni goodness algorithm w tion model recall GDk trained entire set data D Eq 2 considering compute goodness samples corresponding class k demographic criterion d The ﬁndings indicate signiﬁcant differences goodness GDk d different classes k demographic criterion d especially classes k Caucasian Asian difference 2 DiveFace 10 RFW 6 BUPTBalancedface d f Dk d w Concerning triplet generation method Unrestricted Restricted Section 42 methods competitive performances similar improvements baseline approaches The higher number triplets generated Unrestricted method 6 times clear improvements compared Restricted method We biggest improvements achieved VGGFace ArcFace barely improves fact ArcFaceR worsens standard deviation 5 This fact ArcFaces performance highly optimized room improvement VGGFace ResNet50 greater The size embedding obtained VGGFace times larger ArcFace One think ResNet50 state art Yet Table 3 ResNet50 better average accuracy lower average EER ArcFace DiveFace database Normally performance evaluations unbalanced datasets Table 1 dont picture performance For example model perform Asian Female demographic group evaluated test set barely contains samples group little effect overall performance appear good model 11 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 Table 4 EER comparison SOTA debiasing approaches tested RFW dataset face veriﬁcation trained BUPTBalancedface database The results directly copied work In parentheses relative improvement respect baseline approach work NA Not Available Our Sensitive Loss method applied feature embedding space ResNet50 model pretrained VGGFace2 31 Method ref RLRBN 18 DebFace 19 GAC 47 RamFace 46 Sensitive Loss Ours Model ResNet34 ResNet50 ResNet50 ResNet50 ResNet50 Caucasian Indian African Asian Avg 373 405 380 260 277 532 522 502 342 305 500 633 523 375 418 518 567 513 450 350 481 10 532 NA 479 11 357 NA 337 33 Std 063 34 083 NA 058 39 068 NA 054 42 The relatively low performance groups originated limited ability capture best discrimi nant features underrepresented samples training databases ResNet50 learn better discriminant features performs better VGGFace Additionally ResNet50 shows smaller difference demographic groups The results suggest features capable reaching high accuracy speciﬁc demographic group competitive Lets analyze causes degradation Fig 5 represents probability distributions genuine impostor distance scores demographic groups A comparison genuine impostor distributions reveals large differences impostors The genuine distribution intraclass variability groups similar impostor distribution interclass variability signiﬁcantly different Fig 5 shows score distributions obtained ResNet50 model Sensitive Loss debiasing method Unrestricted sensitive triplet generation Table 3 showed performance speciﬁc decision threshold EER face veriﬁcation Now Fig 5 provides information indicators commonly EER FMR FNMR obtained setting decision threshold distributions The improvements Accuracy Fairness caused Sensitive Loss discriminationaware representation ϕx come mainly better alignment impostor score distributions demographic groups To large extent proposed Sensitive Loss learning method able correct biased behavior baseline model The results obtained Sensitive Loss outperform baseline approaches Improving fairness Std The standard deviation performance demographic groups lower Fairness im provements terms EER Std vary model database ranging 5 61 relative improvements average improvement 44 ii Reducing Average EER databases Table 3 The results discriminationaware learning helps generate fairer accurate representations Our Sensitive Loss discrimination aware learning yields better representations speciﬁc demographic groups collectively groups The discriminationaware learning method proposed work Sensitive Loss step forward prevent discrim inatory effects usage automatic face recognition systems The representation ϕx reduces discriminatory effects original representation x differences goodness criteria GDk d demographic groups reduced However differences exist considered deployment technologies 621 Comparison state art Table 4 shows comparison approach recent stateoftheart debiasing techniques 18194647 These methods consist networks trained speciﬁcally avoid bias propose Sensitive Loss entire network addon method reduce biased outcome given network The results comparison interpreted care arrangements different Still com parison gives rough idea range bias mitigation methods The approaches compared trained networks database BUPT Balancedface We instead taken network trained VGGFace2 added layer trained BUPTBalancedface Our network advantage trained VGGFace2 BUPTBalancedface average performance better However looking improve performance reduce discrimination experiments want demonstrate complex models needed DebFace RLRBN GAC RamFace compared ArcFacebased method RFW database included MS1M ArcFace training data set In fact EER Std ArcFace RFW 10 times lower achieved That ResNet50 network comparison From Table 4 seen terms fairness measured performance differences demographic groups approach comparable dedicated networks trained scratch produce unbiased models With similar behavior fairness perspective proposed Sensitive Loss superior compared methods terms simplicity applicability directly applied trained networks need complete retraining 12 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 7 Summary conclusions We presented comprehensive analysis face recognition models based deep learning according new discriminationaware perspective We started presenting new general reformulation Algorithmic Discrimination application face recognition Next showed high bias introduced training deep models popular face databases employed literature Our analysis popular face databases literature revealed large gap number samples different ethnic groups Classes unevenly represented popular face databases New databases benchmarks needed train diverse heterogeneous algorithms Evaluation representative populations different demographic groups important prevent discriminatory effects We looked interior tested models revealing different activation patterns networks different demographic groups This corroborates biased nature popular pretrained face models Popular deep models trained databases biased certain classes according criterion d result feature spaces strong differen tiation classes This differentiation affects obtained representation x enables use tasks trained We evaluated popular pretrained face models VGGFace ResNet50 ArcFace according proposed formulation The experiments carried public databases DiveFace RFW BUPTB comprising 64000 identities 15M images The results showed tested face models highly biased demographic groups In particular observed large performance differences face recognition sex ethnic groups These performance gaps reached 200 relative error degradation best class worst This means false positives 200 likely demographic groups popular face models evaluated work After bias analysis proposed novel discriminationaware training method Sensitive Loss based triplet loss function online selection sensitive triplets Unlike existing related debiasing methods Sensitive Loss works addon pretrained networks facilitating application problems like face recognition hardworked models excellent performance exist little attention fairness aspects paid inception Experiments Sensitive Loss demonstrate simple discriminationaware rules guide learning process fairer accurate representations The results proposed Sensitive Loss representation outperform baseline models evaluated databases terms average accuracy fairness metrics These results encourage training diverse models development methods capable dealing inherent differences demographic groups The framework analyzed work focused analysis Groupbased Algorithmic Discrimination GAD Future work investigate incorporate Userspeciﬁc 61 Algorithmic Discrimination UAD proposed framework 51 Additionally analysis covariates facial expression 6263 age included study Discrimination age important concern applications automatic recruitment tools 64 Other future directions include study new methods detect bias training process low input information 65 application privacypreserving techniques 6667 We hope line research algorithmic discrimination enable future transparent explainable AI 68 Declaration competing The authors declare known competing ﬁnancial interests personal relationships appeared inﬂuence work reported paper Acknowledgements The authors like thank Manuel Cebrian Iyad Rahwan constructive feedback inspiring talks This work supported projects TRESPASSETN MSCAITN2019860813 PRIMA MSCAITN2019860315 BIBECA RTI2018101248BI00 MINECOFEDER BBforTAI PID2021127641OBI00 MICINNFEDER I Serna supported research fellowship Universidad Autónoma Madrid FPIUAM2020 A Morales supported Madrid Government Comunidad MadridSpain Multiannual Agreement Autonomous University Madrid line Encouragement Research Young Researchers context V PRICIT Regional Programme Research Technological Innovation References 1 I Rahwan M Cebrian N Obradovich et al Machine behaviour Nature 568 7753 2019 477486 2 S Russell P Norvig Artiﬁcial Intelligence A Modern Approach Pearson 2016 3 R Ranjan S Sankaranarayanan A Bansal N Bodla J Chen VM Patel CD Castillo R Chellappa Deep learning understanding faces machines May good better humans IEEE Signal Process Mag 35 1 2018 6683 4 X Akhtar A Hadid M Nixon M Tistarelli J Dugelay S Marcel Biometrics search identity security Q A IEEE Multimed 25 3 2018 2235 5 B Bhanu A Kumar Deep Learning Biometrics Advances Computer Vision Pattern Recognition ACVPR Springer 2017 13 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 6 L Shao P Hubert T Hospedales Special issue machine vision deep learning Int J Comput Vis 128 2020 771772 7 PJ Grother ML Ngan KK Hanaoka Ongoing Face Recognition Vendor Test FRVT Part 2 Identiﬁcation NIST Internal Report National Institute 8 CM Cook JJ Howard YB Sirotin JL Tipton AR Vemury Demographic effects facial recognition dependence image acquisition evaluation commercial systems IEEE Trans Biometr Behav Ident Sci 1 1 2019 3241 9 B Lu JC Chen CD Castillo R Chellappa An experimental evaluation covariates effects unconstrained face veriﬁcation IEEE Trans Biometr Standards Technology 2018 Behav Ident Sci 1 1 2019 4255 10 A Acien A Morales R VeraRodriguez I Bartolome J Fierrez Measuring gender ethnicity bias deep models face recognition Iberoamerican Congress Pattern Recognition Springer Madrid Spain 2018 pp 584593 11 K Krishnapriya V Albiero K Vangara M King K Bowyer Issues related face recognition accuracy varying based race skin tone IEEE Trans Technol Soc 1 2020 820 Secur 7 6 2012 17891801 12 BF Klare MJ Burge JC Klontz RWV Bruegge AK Jain Face recognition performance role demographic information IEEE Trans Inf Forensics 2020 pp 330347 13 J Buolamwini T Gebru Gender shades intersectional accuracy disparities commercial gender classiﬁcation SA Friedler C Wilson Eds Conference Fairness Accountability Transparency Proceedings Machine vol 81 Learning Research New York NY USA 2018 pp 7791 14 M Alvi A Zisserman C Nellåker Turning blind eye explicit removal biases variation deep neural network embeddings European Conference Computer Vision ECCV Munich Germany 2018 pp 556572 15 I Hupont C Fernandez DemogPairs quantifying impact demographic imbalance deep face recognition International Conference Automatic Face Gesture Recognition FG Lille France 2019 pp 17 16 P Drozdowski C Rathgeb A Dantcheva N Damer C Busch Demographic bias biometrics survey emerging challenge IEEE Trans Technol Soc 1 2 2020 89103 17 P Terhörst JN Kolf M Huber F Kirchbuchner N Damer A Morales J Fierrez A Kuijper A comprehensive study face recognition biases demographics IEEE Trans Technol Soc 2022 httpsdoi org 10 1109 TTS 20213111823 press 18 M Wang W Deng Mitigate bias face recognition skewnessaware reinforcement learning Conference Computer Vision Pattern Recognition CVPR IEEE Seattle Washington USA 2020 pp 93199328 19 S Gong X Liu A Jain Jointly debiasing face recognition demographic attribute estimation European Conference Computer Vision Virtual 20 I Serna A Morales J Fierrez N Cebrian M Obradovich I Rahwan Algorithmic discrimination formulation exploration deep learningbased face biometrics AAAI Workshop Artiﬁcial Intelligence Safety SafeAI New York NY USA 2020 21 J Kleinberg J Ludwig S Mullainathan CR Sunstein Discrimination age algorithms J Legal Anal 10 2019 113174 22 R Ranjan S Sankaranarayanan et al Deep learning understanding faces machines May good better humans IEEE Signal Process Mag 35 1 2018 6683 23 A Morales J Fierrez A Acien R Tolosana I Serna SetMargin loss applied deep keystroke biometrics circle packing interpretation Pattern Recognit 122 2022 108283 httpsdoi org 10 1016 j patcog 2021108283 24 K He X Zhang S Ren J Sun Deep residual learning image recognition Conference Computer Vision Pattern Recognition CVPR IEEE Las Vegas NV USA 2016 pp 770778 25 M Wang W Deng J Hu X Tao Y Huang Racial faces wild reducing racial bias information maximization adaptation network Interna tional Conference Computer Vision ICCV IEEE Seoul Korea 2019 pp 692702 26 M Merler N Ratha RS Feris JR Smith Diversity faces arXiv190110436 2019 pp 129 27 K Karkkainen J Joo FairFace face attribute dataset balanced race gender age bias measurement mitigation Winter Conference Applications Computer Vision WACV IEEE Virtual 2021 pp 15481558 28 PJ Grother ML Ngan KK Hanaoka Ongoing Face Recognition Vendor Test FRVT Part 3 Demographic Effects NIST Internal Report National Institute Standards Technology 2019 29 Y Guo L Zhang Y Hu X He J Gao Msceleb1m dataset benchmark largescale face recognition European Conference Computer Vision ECCV Springer Amsterdam Netherlands 2016 pp 87102 30 I KemelmacherShlizerman SM Seitz D Miller E Brossard The megaface benchmark 1 million faces recognition scale Conference Computer Vision Pattern Recognition CVPR IEEE Las Vegas Nevada USA 2016 pp 48734882 31 Q Cao L Shen W Xie OM Parkhi A Zisserman Vggface2 dataset recognising faces pose age International Conference Automatic Face Gesture Recognition FG IEEE Lille France 2018 pp 6774 32 OM Parkhi A Vedaldi A Zisserman et al Deep face recognition British Machine Vision Conference BMVC Swansea UK 2015 pp 4114112 33 L Wolf T Hassner I Maoz Face recognition unconstrained videos matched background similarity Computer Vision Pattern Recognition CVPR IEEE Colorado Springs CO USA 2011 pp 529534 34 D Yi Z Lei S Liao SZ Li Learning face representation scratch arXiv14117923 2014 19 35 S Yang P Luo CC Loy X Tang From facial parts responses face detection deep learning approach International Conference Computer Vision ICCV Santiago Chile 2015 pp 36763684 33 10 2011 19621977 36 N Kumar A Berg PN Belhumeur S Nayar Describable visual attributes face veriﬁcation image search IEEE Trans Pattern Anal Mach Intell 37 B Maze J Adams JA Duncan N Kalka T Miller C Otto AK Jain WT Niggel J Anderson J Cheney et al IARPA Janus BenchmarkC face dataset protocol International Conference Biometrics ICB IEEE Gold Coast Australia 2018 pp 158165 38 Z Zhang Y Song H Qi Age progressionregression conditional adversarial autoencoder Conference Computer Vision Pattern Recognition 39 GB Huang M Ramesh T Berg E LearnedMiller Labeled Faces Wild Database Studying Face Recognition Unconstrained Environments CVPR IEEE Honolulu Hawaii USA 2017 pp 58105818 Tech Rep 0749 University Massachusetts Amherst October 2007 40 J OrtegaGarcia J Fierrez et al The multiscenario multienvironment biosecure multimodal database BMDB IEEE Trans Pattern Anal Mach Intell 32 6 2009 10971111 41 A Morales J Fierrez R VeraRodriguez R Tolosana SensitiveNets learning agnostic representations application face recognition IEEE Trans Pattern Anal Mach Intell 43 6 2021 21582164 httpsdoi org 10 1109 TPAMI 2020 3015420 42 S Khan M Hayat SW Zamir J Shen L Shao Striking right balance uncertainty Conference Computer Vision Pattern Recognition CVPR IEEE Long Beach California USA 2019 pp 103112 43 C Huang Y Li CC Loy X Tang Deep imbalanced learning face recognition attribute prediction IEEE Trans Pattern Anal Mach Intell 42 11 44 H Qin Asymmetric rejection loss fairer face recognition arXiv2002 03276 45 A Das A Dantcheva F Bremond Mitigating bias gender age ethnicity classiﬁcation multitask convolution neural network approach European Conference Computer Vision ECCV Munich Germany 2018 pp 573585 2019 27812794 14 I Serna A Morales J Fierrez et al Artiﬁcial Intelligence 305 2022 103682 AIES AAAIACM New York NY USA 2020 pp 400406 Systems NIPS MIT Press 2006 pp 14731480 Recognition CVPR IEEE 2015 pp 815823 46 Z Yang X Zhu C Jiang W Liu L Shen RamFace race adaptive margin based face recognition racial bias mitigation International Joint 47 S Gong X Liu A Jain Mitigating face recognition bias group adaptive classiﬁer Conference Computer Vision Pattern Recognition CVPR Conference Biometrics IJCB IEEE 2021 IEEE Nashville TN 2021 48 T Calders S Verwer Three naive Bayes approaches discriminationfree classiﬁcation Data Min Knowl Discov 21 2 2010 277292 49 ID Raji J Buolamwini Actionable auditing investigating impact publicly naming biased performance results commercial AI products Conference AI Ethics Society AIES AAAIACM New York NY USA 2019 pp 429435 50 F AlonsoFernandez J Fierrez J OrtegaGarcia Quality measures biometric systems IEEE Secur Priv 10 6 2011 5262 51 M Bakker HR Valdes DP Tu K Gummadi K Varshney A Weller A Pentland Fair Enough improving fairness budgetconstrained decision making conﬁdence thresholds AAAI Workshop Artiﬁcial Intelligence Safety SafeAI New York NY USA 2020 pp 4153 52 Y Zhang R Bellamy K Varshney Joint optimization AI fairness utility humancentered approach Conference AI Ethics Society 53 KQ Weinberger LK Saul Distance metric learning large margin nearest neighbor classiﬁcation Advances Neural Information Processing 54 F Schroff D Kalenichenko J Philbin FaceNet uniﬁed embedding face recognition clustering Conference Computer Vision Pattern 55 J Deng J Guo N Xue S Zafeiriou Arcface additive angular margin loss deep face recognition Conference Computer Vision Pattern Recognition CVPR IEEE Long Beach California USA 2019 pp 46904699 56 K Zhang Z Zhang Z Li Y Qiao Joint face detection alignment multitask cascaded convolutional networks IEEE Signal Process Lett 23 10 57 J Deng J Guo E Ververas I Kotsia S Zafeiriou RetinaFace singleshot multilevel face localisation wild Conference Computer Vision Pattern Recognition CVPR IEEE Seattle Washington USA 2020 pp 52025211 58 RR Selvaraju M Cogswell et al GradCAM visual explanations deep networks gradientbased localization International Conference Computer Vision CVPR IEEE Honolulu Hawaii USA 2017 pp 618626 59 D Bau JY Zhu H Strobelt A Lapedriza B Zhou A Torralba Understanding role individual units deep neural network Proc Natl Acad 2016 14991503 Sci 2020 18 Pattern Recognition ICPR IEEE 2021 pp 37203727 60 I Serna A Peña A Morales J Fierrez InsideBias measuring bias deep networks application face gender biometrics IAPR Intl Conf 61 J Fierrez A Morales R VeraRodriguez D Camacho Multiple classiﬁers biometrics Part 2 Trends challenges Inf Fusion 44 2018 103112 62 A Pena J Fierrez A Lapedriza A Morales Learning emotionalblinded face representations IAPR Intl Conf Pattern Recognition ICPR 2021 63 A Pena I Serna A Morales J Fierrez A Lapedriza Facial expressions vulnerability face recognition IEEE Intl Conf Image Processing 64 A Pena I Serna A Morales J Fierrez Bias multimodal AI testbed fair automatic recruitment IEEECVF Conf Computer Vision 65 I Serna D DeAlcala A Morales J Fierrez J OrtegaGarcia IFBiD inferencefree bias detection AAAI Workshop Artiﬁcial Intelligence Safety ICIP 2021 pp 29882992 Pattern Recognition Workshops CVPRw 2020 SafeAI 2022 7 2019 9973599745 66 V Mirjalili S Raschka A Ross FlowSAN privacyenhancing semiadversarial networks confound arbitrary facebased gender classiﬁers IEEE Access 67 M Ghafourian J Fierrez R VeraRodriguez I Serna A Morales OTBmorph onetime biometrics morphing applied face templates IEEECVF Winter Conf Applications Computer Vision Workshops WACVw 2022 68 A Ortega J Fierrez A Morales Z Wang M Cruz CL Alonso T Ribeiro Symbolic AI XAI evaluating LFIT inductive programming explaining biases machine learning Computers 10 11 2021 154 httpsdoi org 10 3390 computers10110154 15