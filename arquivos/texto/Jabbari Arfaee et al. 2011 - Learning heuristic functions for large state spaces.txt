Artiﬁcial Intelligence 175 2011 20752098 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Learning heuristic functions large state spaces Shahab Jabbari Arfaee Sandra Zilles b Robert C Holte University Alberta Department Computing Science Edmonton Alberta Canada T6G 2H8 b University Regina Department Computer Science Regina Saskatchewan Canada S4S 0A2 r t c l e n f o b s t r c t Article history Received 19 September 2010 Received revised form 27 July 2011 Accepted 1 August 2011 Available online 5 August 2011 Keywords Heuristic search Planning Learning heuristics We investigate use machine learning create effective heuristics search heuristicsearch planners FF Our method aims algorithms IDA generate sequence heuristics given weak heuristic h0 set unsolved training instances bootstrapping procedure The training instances solved h0 provide training examples learning algorithm produces heuristic h1 expected stronger h0 If h0 weak solve given instances use random walks backward goal state create sequence successively diﬃcult training instances starting ones guaranteed solvable h0 The bootstrap process repeated hi lieu hi1 suﬃciently strong heuristic produced We test method 24sliding tile puzzle 35pancake puzzle Rubiks Cube 20blocks world In case solve randomly generated problem method produces heuristic allows IDA instances quickly solutions close optimal The total time bootstrap process create strong heuristics large state spaces order days To process effective single problem instance needs solved present variation bootstrap learning new heuristics interleaved problemsolving initial heuristic heuristics learned far This substantially reduces total time needed solve single instance solutions obtained close optimal 2011 Elsevier BV All rights reserved 1 Introduction Modern heuristic search planning systems require good heuristics A popular approach creating heuristics state space abstraction state space description creates description abstract state space easier search exact distances abstract space admissible estimates distances original space 4516 243436 One limitation approach memoryintensive This led study compression schemes 3742 diskbased methods 52 distributed methods 8 These methods extend range problems abstraction applicable combinatorial problems grow size exponentially easy imagine problems large computers foreseeable future best heuristics created systems weak enable arbitrary instances solved reasonably quickly A second limitation abstraction applied state spaces given suitable declarative form There situations statespace description example planner controlling game description vastly eﬃcient hardcoded state space described declaratively different language abstraction requires We representations Corresponding author Email addresses jabbariacsualbertaca S Jabbari Arfaee zillescsureginaca S Zilles rholteualbertaca RC Holte 00043702 matter 2011 Elsevier BV All rights reserved doi101016jartint201108001 2076 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 opaque With opaque representation state space deﬁned successor function called compute states children reasoned By deﬁnition abstraction applied create heuristics state space represented opaquely An approach automatic creation heuristics sidesteps limitations apply machine learning set states distancetogoal known training set create function estimates distancetogoal arbitrary state heuristic function This idea applied great success 15puzzle state spaces similar size Ernandes Gori 9 Samadi Felner Schaeffer 41 applied larger spaces 24puzzle excessive time create suﬃciently large training set containing suﬃciently broad range possible distances goal To overcome obstacle Samadi et al 41 reverted abstraction approach instead learning heuristic 24puzzle directly learned heuristics disjoint abstractions 24puzzle combined heuristic 24puzzle This approach inherits limitations abstraction mentioned addition crucial choices abstractions use combine manually Ernandes Gori 9 proposed different way extending machine learning approach scale arbitrarily large problems implemented We approach bootstrap learning heuristic functions bootstrapping short The contribution present paper validate proposal supplying details required automatic bootstrapping practical showing experimentally succeeds state spaces limit todays abstraction methods Bootstrapping iterative procedure uses learning create series heuristic functions Initially proce dure requires heuristic function h0 set states bootstrap instances Unlike previous machine learning approaches creating heuristics solutions given instances h0 assumed strong 29 run h0 attempt solve given instances A standard heuristic search algorithm IDA solve bootstrap instances given time limit The set solved bootstrap instances solution lengths necessarily optimal fed learning algorithm create new heuristic function h1 intended better h0 After previously unsolved bootstrap instances way h1 heuristic instead h0 This procedure repeated handful bootstrap instances solved succession iterations fails solve large number new bootstrap instances ones solved previous iterations If initial heuristic h0 weak solve suﬃcient number given bootstrap instances given time limit use random walk method automatically generate bootstrap instances right level diﬃculty easy solvable h0 hard yield useful training data improving h0 As earlier studies Ernandes Gori 9 Samadi et al 41 seen step bootstrap process strong initial heuristic learned heuristic inadmissible guaranteed ﬁnd optimal solutions learned heuristic With overestimate distances IDA bootstrapping risk excessive suboptimality generated solutions higher onestep methods iteration learning algorithm given solution lengths larger optimal biasing learned heuristic greater overestimation The suboptimality solutions generated important performance measure experiments We test method experimentally problem domains limit current abstraction methods solve optimallythe 24slidingtile puzzle 35pancake puzzle Rubiks Cube 20blocks worldin case starting initial heuristic weak previous onestep methods fail able generate adequate training set reasonable time In domains bootstrapping succeeds solve randomly generated problem instances quickly solutions producing heuristic allows IDA close optimal On domains method systematically outperforms Weighted IDA 30 BULB 15 The time takes bootstrap method complete learning large state spaces order days This acceptable learned heuristic solve instances different approach needed order solve single instance quickly For introduce method interleaves bootstrapping process creating succession stronger heuristics process uses set heuristics currently available initially h0 try solve given instance The total time required solve single instance method substantially learning time bootstrap method solutions produces comparable suboptimality For example method total time solve instance 24puzzle 14 minutes average solution 65 longer optimal When applied blocksworld instances IPC2 planning competition interleaving method solves instances 30minute time limit solved optimally The remainder paper organized follows Section 2 provides description Bootstrap Ran domWalk methods experimentally evaluated Section 3 The interleaving method quickly solving single instances described evaluated Section 4 Section 5 surveys previous work related bootstrapping Section 6 closes paper summary conclusions S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2077 2 The Bootstrap RandomWalk algorithms This section describes algorithmic approach implementation method learning heuristics The input consists state space ﬁxed goal state g heuristic function h0 set Ins states bootstrap instances set state features learning We assume h0 suﬃciently strong given bootstrap instances solved In principle h0 completely trivial returning 0 states practice useful include weak nontrivial heuristics features learning If makes sense use maximum h0 absence stronger heuristic In ﬁrst subsection focus bootstrap procedure incrementally updates initial heuristic help set bootstrap instances This procedure requires h0 strong solve given instances suboptimally given time limit If set easier instances needed improve initial heuristic point easiest bootstrap instances solved This set easier instances generated random walk method described second subsection 21 The Bootstrap algorithm Our bootstrap procedure Algorithm 1 proceeds stages In ﬁrst stage instance Ins heuristic search algorithm run start state current heuristic hin line 7 Every search cut limited period time tmax If solved time userdeﬁned features solution length added training set In addition features solution lengths states solution path added training set lines 8 9 This increases size training set additional cost balances training set contain instances long short solutions Algorithm 1 instance Ins Add feature vectors distances g P TS end remove Ins NumSolved NumSolved 1 Heuristic Searchi g hin tmax succeeds state s solution path P 1 procedure Bootstraph0 hin Ins hout 2 uses global variables tmax t insmin g 3 create training set TS 4 NumSolved 0 5 NumSolved sizeIns cid2 insmin tmax cid3 t 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 end 24 return hin hlearn learn heuristic TS Deﬁne hinx state x maxh0x hlearnx clear TS NumSolved 0 end NumSolved cid2 insmin tmax 2 tmax end end The second stage examines collected training data If bootstrap instances solved heuris tic hin updated learning algorithm line 17 training set reset If bootstrap instances solved time limit increased changing hin line 21 Either way long current time limit tmax exceed ﬁxed upper bound t bootstrap procedure repeated remaining bootstrap instances current heuristic hin Enough bootstrap instances means number instances ﬁxed threshold insmin line 15 Variable NumSolved keeps track number bootstrap instances solved iteration It increases new instance solved line 12 set zero iteration line 19 The procedure terminates tmax exceeds t remaining set bootstrap instances small Notice line 17 heuristic hin created bootstrap maximum heuristic returned learning algorithm current training set hlearn h0 This essential requirement bootstrap process advisable h0 known admissible heuristic heuristic accurate In experiments reported method It possible maximum previously learned heuristics hlearn h0 add previously learned heuristics set features learning We considerable increase computation time caused Table 1 shows iteration bootstrap procedure 15puzzle deﬁned Section 3 Ins contains 5000 randomly generated solvable instances insmin 75 tmax 1 second The deﬁnition initial heuristic h0 2078 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Table 1 Bootstrap iterations 15puzzle Iteration Number solved Average optimal cost solved instances Average nodes generated solved instances Average suboptimality test instances 0 1 2 3 986 3326 519 156 4611 5437 5852 6044 517295 205836 353997 276792 12 28 55 83 learning method features learning 24puzzle given Section 3 h0 The ﬁrst row shows result initial iteration All 5000 instances Ins attempted IDA able solve 986 time limit column Number solved The average optimal solution length solved instances shown column Average optimal cost The average number nodes generated solving instances shown column Average nodes generated The states 986 solution paths distances goal form training set learning algorithm applied create new heuristic h11 The suboptimality heuristic learned iteration h1 measured independent test set shown column Average suboptimality An attempt h1 solve 4014 instances solved h0 The row iteration 1 shows 3326 solved time limit All states solution paths learn new heuristic h2 attempt solve 688 instances solved ﬁrst iterations The row iteration 2 shows 519 solved The heuristic h3 learned solution paths solved 156 169 instances solved point solution paths provide training data create new heuristic h4 The bootstrap process ends point fewer insmin unsolved instances h4 returned ﬁnal heuristic In example need bootstrap process increase time limit tmax iteration solved insmin instances initial tmax value There strong requirements set Ins bootstrap instancesit set representative instances user However bootstrap process incrementally span gap easiest hardest instances Ins contain instances intermediate levels diﬃculty At present simply intuitive informal requirement proof necessity 22 The RandomWalk algorithm It happen initial heuristic h0 weak heuristic search algorithm unable solve instances Ins h0 suﬃciently large set training data For case need procedure generates bootstrap instances easier solve instances user provided ii harder solve instances solvable simple breadthﬁrst search acceptable time guarantee high quality training data This accomplished random walks backward goal2 suitably chosen length generate instances As described Algorithm 2 ﬁrst test initial heuristic strong solve suﬃcient number insmin userprovided bootstrap instances Ins given time limit tmax line 5 If bootstrap procedure started immediately line 10 Otherwise perform random walks backward goal depth length collect ﬁnal states special bootstrap instances RWIns The bootstrap procedure run special instances line 7 create stronger heuristic This process repeated increasingly longer random walks line 8 produces heuristic strong bootstrapping begin usergiven instances fails produce heuristic suﬃciently instances RWIns solved time limit t Algorithm 2 In random walk disallow inverse previous 1 procedure RandomWalk h0 Ins lengthIncrement hout 2 uses global variables tmax t insmin g 3 length lengthIncrement 4 hin h0 5 hin weak solve insmin instances Ins time tmax tmax cid3 t 6 7 8 9 end 10 return Bootstraph0 hin Ins RWIns 200 instances generated applying length random moves backward g hin Bootstraph0 hin RWIns length length lengthIncrement 1 As explained h1 heuristics created Bootstrap deﬁned state x maximum h0x hlearnx hlearn heuristic created learning algorithm current iteration 2 For spaces uninvertible operators requires predecessor function successor function provided opaque representation Hence RandomWalk process applicable certain opaque domains Moreover RandomWalk procedure works single goal states sets goal states Neither restrictions applies Bootstrap procedure search progresses forward direction S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2079 Table 2 RandomWalk procedure applied 20blocks world Row 1 2 3 4 5 6 7 8 RW length 20 40 60 60 80 80 100 120 Number solved Average optimal cost 197 145 115 79 99 95 174 139 897 1176 1396 1605 1608 1937 2041 2350 Time limit 1 1 1 2 2 4 4 4 The choice lengthIncrement important consideration If large instances generated diﬃcult current heuristic solve process fail If small considerable time wasted applying bootstrap process instances substantially improve current heuristic In lengthIncrement parameter set automatically follows 1 Run breadthﬁrst search backward goal state time limit given initial value tmax Let S set states visited 2 Repeat 5000 times random walk backward goal disallowing inverse previous state S reached Set lengthIncrement ﬂoor average length 5000 random walks The intuition motivating deﬁnition lengthIncrement follows Initially generates problem instances average little diﬃcult solved breadthﬁrst search time limit tmax These expected provide training examples solvable h0 cause nontrivial heuristic function learned On subsequent iterations imagine instances created random walks length larger multiple lengthIncrement short breadthﬁrst search instances solved previous iterationin words slightly diﬃcult average previous instances By slightly diﬃcult easy solved current heuristic provide training instances allow better heuristic learned The RandomWalk approach guaranteed succeed It fail generate problems suitable level diﬃculty easy solvable current heuristic hard help produce better heuristic Table 2 illustrates RandomWalk procedure 20blocks world Ins contains 5000 randomly generated solvable instances insmin 75 tmax 1 second 200 random walk instances generated RWIns distinct random walk length The deﬁnition domain initial heuristic h0 learning method features learning given Section 3 Random walks necessary domain h0 weak solve suﬃcient number insmin bootstrap instances Ins The value lengthIncrement set automatically method 20 The ﬁrst row shows result initial iteration 200 instances RWIns generated random walks length 20 column RW length passed bootstrap procedure h0 IDA h0 heuristic able solve 197 instances column Number solved time limit column Time limit seconds iteration bootstrap process returns new heuristic h1 This heuristic attempt solve bootstrap instances Ins It weak solve suﬃcient number time limit iteration RandomWalk process needed The random walk length increased 20 value lengthIncrement set RWIns 200 instances gener ated random walks length 40 passed bootstrap procedure h1 145 solved ﬁrst bootstrap iteration bootstrap procedure returns new heuristic h2 fewer insmin unsolved RandomWalk instances remain This heuristic attempt solve bootstrap instances Ins It weak solve suﬃcient number time limit iteration RandomWalk process needed The random walk length increased 20 set 200 instances RWIns generated random walks length 60 passed bootstrap procedure h2 The bootstrap process row 3 able solve 115 instances h2 ﬁrst iteration A new heuristic h3 learned passed RandomWalk procedure insmin unsolved RandomWalk instances RWIns A second iteration bootstrap procedure attempts solve new heuristic h3 fails solve suﬃcient number insmin doubles time limit attempts h3 Row 4 shows iteration bootstrap procedure succeeds solving 79 new time limit learns new heuristic h4 Since fewer insmin unsolved RandomWalk instances bootstrap procedure returns h4 RandomWalk process This heuristic attempt solve bootstrap instances Ins It weak solve suﬃcient number time limit iteration RandomWalk process needed As table shows total 6 iterations loop RandomWalk process executed 6 distinct values RandomWalk length iterations bootstrap iterations required ﬁnd heuristic 2080 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Fig 1 System overview solve random walk instances The time limit increased twice The RandomWalk process ended heuristic h8 created RandomWalk instances solved ﬁnal row table able solve suﬃcient number insmin bootstrap instances Ins bootstrap procedure ﬁnally started set bootstrap instances Ins h8 initial heuristic Once bootstrap process begins operate bootstrap instances RandomWalk process invoked However role play If iteration Bootstrap process fails solve suﬃcient number instances instead doubling current time limit line 21 Algorithm 1 instead invoke RandomWalk process generate instances appropriate level diﬃculty Preliminary experiments idea succeeded artiﬁcially contrived sets bootstrap instances 15puzzle 17pancake puzzle failed Rubiks Cube Because abandoned idea experiments reported paper based RandomWalk initial step needed create heuristic strong allow bootstrap process begin operating bootstrap instances 23 Summary System overview A summary overall operation depicted Fig 1 The key inputs user initial heuristic h0 set bootstrap instances The RandomWalk procedure tests h0 strong solve suﬃciently large number bootstrap instances If RandomWalk internally generates instances random walks length determines automatically These instances passed Bootstrap procedure returns heuristic This procedure repeats instances created random walks increasing lengths current heuristic strong solve suﬃciently large number bootstrap instances At point Bootstrap invoked time bootstrap instances The ﬁnal heuristic creates instances heuristic output 3 Experiments Bootstrap RandomWalk Except explicitly stated IDA search algorithm Domains Because essential study able determine suboptimality solutions method produces chose testbeds domains optimal solution lengths computed reasonable time existing heuristic search methods handcrafted optimal solver domain The following domains met criterion3 n2 1Slidingtile puzzle 46 The slidingtile puzzle consists n2 1 numbered tiles moved n n grid A state vector length n2 component k names located kth puzzle position number 1 n2 1 tile symbol representing blank Every operator swaps blank tile adjacent The left Fig 2 shows goal state 24puzzle right shows state created goal state applying operators swapping blank tile 1 swapping tile 6 The number states reachable given state n22 cf 1 We report results 24puzzle n 5 largest version puzzle solved optimally abstractionbased heuristic search methods 32 This domain roughly 1025 reachable states nPancake puzzle 6 In npancake puzzle state permutation n numbered tiles n 1 successors lth successor formed reversing order ﬁrst l 1 positions permutation 1 cid2 l cid2 n 1 3 Experiments smaller versions domains 15puzzle 17 24pancake puzzles 15blocks world previous publication 27 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2081 Fig 2 The goal state 24puzzle left state moves goal right Fig 3 The goal state 35pancake puzzle state goal Fig 4 The goal state Rubiks Cube left state goal right modiﬁed Zahavi et al 51 Fig 5 The goal state 20blocks world left state moves goal right The upper Fig 3 shows goal state experiments lower shows 3rd successor goal ﬁrst positions reversed All n permutations reachable given state We report results n 35 contains 1040 reachable states The largest version puzzle solved optimally generalpurpose abstractionbased methods n 19 22 Rubiks Cube 31 Rubiks Cube 3 3 3 cube 20 moveable 1 1 1 cubies coloured stickers exposed face Each face cube independently rotated 90 degrees clockwise counterclockwise 180 degrees The left Fig 4 shows goal state Rubiks Cube right shows state produced rotating right face 90 degrees counterclockwise We standard encoding puzzle including standard operator pruning methods reduce branch ing factor 18 approximately 1334847 31 The number states reachable given state approximately 43252 1019 31 Rubiks Cube limit todays generalpurpose heuristic search methods ﬁnding optimal solutions nBlocks world 45 In blocks world block block block A block block said table A block block said clear A consists moving clear block clear block table We n 20 blocks experiments number reachable states 1020 45 The left Fig 5 shows goal state right Fig 5 shows state produced goal state moving block 20 table moving block 19 block 20 Learning algorithm features The learning algorithm experiments neural network NN output neuron representing distancetogoal hidden units trained standard backpropagation 40 mean squared error MSE4 Training ended 500 epochs MSE 0005 4 We consider choice particular learning algorithm critical chose neural network setting previous work learning heuristics 941 Using hidden units sure domain experimented number inputs large number hidden units We experimented error measures penalize overestimation yielded substantially 2082 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 It known success machine learning application depends having good features The issue automatically creating good features learning search control knowledge studied context planning Yoon et al 49 In experiments carefully engineer features exploit special properties domain Our intention bootstrap learning approach effective absence carefully chosen features human insight domain We deliberately choose features quickly calculated values needed time heuristic value computed state The input features NN described separately domain values weak heuristics respective problems Initial heuristics The initial heuristic h0 domain deﬁned maximum heuristics features NN In domains Rubiks Cube h0 weak evaluate test instances reasonable time After iteration method new heuristic deﬁned maximum output NN initial heuristic No domainspeciﬁc knowledge geometric symmetry duality 51 augment heuristics experiments reported One advantage h0 compared heuristics generated bootstrapping computed quickly maximum set feature values evaluated faster neural network output features input For example computation neural network heuristic experiments 125 Rubiks Cube 20 24puzzle times slower computation corresponding h0 heuristics Bootstrap instances Ins consisted 500 5000 solvable instances generated uniformly random Rubiks Cube generated random walks lengths 1 25 Numeric parameters In experiments insmin 75 tmax 1 second t 512 seconds size set RWIns 200 The tables summarize results test domains All results based set test instances generated independently bootstrap instances contrast Table 1 measurements based bootstrap instances solved respective Bootstrap iteration In tables Bootstrap results Iteration column indicates Bootstrap iteration described row The No solved Total unsolved columns respectively number bootstrap instances solved particular iteration total number bootstrap instances solved end iteration The Avg subopt column gives average suboptimality solutions test instances heuristic produced end iteration calculated follows We deﬁne suboptimality instance cost solution instance divided optimal solution cost We compute average instances individual suboptimalities subtract For example Avg subopt 7 means average solution test instance 7 longer optimal solution Avg nodes gen average number nodes generated solve test instances heuristic produced end iteration Avg solving time average search time seconds solve test instances Unless speciﬁcally stated time limit imposed systems solving test instances Learning time row iteration time method complete iterations including including RandomWalk processing required iteration 0 begin The letters s m h d represent units timeseconds minutes hours days respectively Each row Other methods tables gives data nonbootstrapping tried given literature The h Algorithm column indicates heuristic search algorithm different IDA parentheses The symbol k indicates heuristic row row k The runtimes taken literature marked asterisk indicate strictly comparable Some suboptimalities WIDA literature computed differently marked asterisk All weighted IDA BULB results implementations algorithms BULB results Rubiks Cube Furcy König 15 The Bootstrap iteration shown tables represents successful iteration Bootstrap process If fewer insmin unsolved bootstrap instances remaining iteration 24puzzle 35pancake puzzle Rubiks Cube 20blocks world 5000 bootstrap instances Bootstrap process terminated soon iteration Bootstrap completion time shown table measures entire time required Bootstrap process equal Learning time reported ﬁnal iteration However insmin unsolved bootstrap instances remaining iteration shown table Rubiks Cube 20blocks world 500 bootstrap instances bootstrap iteration attempted instances Bootstrap terminated creating new heuristic tmax exceeded t In case Bootstrap completion time includes time taken ﬁnal unsuccessful iteration For example Learning time iteration 1 Table 9 shows better results MSE We brieﬂy experimented linear regression instead neural network preliminary results par neural net S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2083 Table 3 24Puzzle Bootstrap 500 bootstrap instances Iteration 0 ﬁrst 1 2 3 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 141 98 112 128 359 261 149 21 51 59 56 57 121691641 156632352 70062610 62559170 15334 s 20568 s 8903 s 8152 s 1 h 38 m 2 h 16 m 3 h 57 m 11 h 43 m Bootstrap completion time 11 hours 43 minutes Table 4 24Puzzle Bootstrap 5000 bootstrap instances Iteration 0 ﬁrst 2 4 6 8 10 12 14 16 18 20 22 24 26 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 413 116 84 116 263 212 112 116 141 270 156 147 79 137 4587 4060 3807 3521 3029 2534 2188 1850 1573 1057 652 393 224 12 47 49 48 50 51 57 62 64 64 72 77 73 79 81 1798903624 1386730491 1051748928 307700388 555085735 140197951 164616540 135943434 35101918 24416967 18566788 12172889 10493649 7445335 236469 s 177641 s 136637 s 40309 s 71979 s 18282 s 22368 s 17511 s 4583 s 3147 s 2460 s 1613 s 1365 s 965 s 19 h 23 h 1 d 09 h 1 d 17 h 1 d 23 h 2 d 04 h 2 d 08 h 2 d 12 h 2 d 20 h 3 d 03 h 3 d 09 h 3 d 12 h 3 d 22 h 4 d 21 h Bootstrap completion time 4 days 21 hours takes 2 days learn ﬁnal heuristic Rubiks Cube 500 bootstrap instances Bootstrap completion time reported 2 days 19 hours The difference 19 hours time required iteration iteration 1 failed solve insmin new instances time limit t 31 24Puzzle Tables 3 4 results 50 standard 24puzzle test instances ﬁrst solved Korf Felner 32 average optimal cost 10078 The input features NN Manhattan distance MD number outof place tiles position blank ﬁve heuristics 4tile pattern database PDB 5 The total memory hold PDBs 50 megabytes The time build pattern databases generate bootstrap instances preprocessing time 2 minutes The initial heuristic suﬃciently weak RandomWalk iterations necessary bootstrapping begin iterations required 500 bootstrap instances Table 3 shows results bootstrap iterations given 500 bootstrap instances Table 4 analogous 5000 bootstrap instances given In cases clear trend search faster successive iteration Avg nodes gen Avg solving time columns suboptimality worse The increase suboptimality likely caused fact solutions training instances increasingly suboptimal successive iterations Suboptimal training instances bias learn new heuristics overestimate greater extent turn leads suboptimal solutions subsequent iterations There clearly rich set timesuboptimality tradeoffs inherent bootstrap approach In paper address issue choose options assume certain number bootstrap instances given heuristic produced ﬁnal bootstrap iteration systems ﬁnal output There clearly interesting relationship Learning time Solving time heuristics created later process solve problems faster average In Section 4 present approach exploiting relationship problem instance solve There key differences 500 5000 bootstrap instances The obvious settings far important total time required combined RandomWalk Bootstrap process Because iteration attempt solve bootstrap instance having 10 times bootstrap instances makes process roughly 10 times slower The second difference subtle The larger bootstrap set contains larger number diﬃcult problems drive Bootstrap process additional iterations case seven additional iterations producing end faster search worse suboptimality fewer bootstrap instances Fig 6 shows distribution suboptimality values iterations 0 13 26 Bootstrap process 5000 bootstrap instances A data point x y plot means y test instances solution x suboptimal 2084 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Fig 6 24Puzzle distribution suboptimality values Fig 7 24Puzzle distribution solving times We acrosstheboard degradation suboptimalities early later iterations curve iteration 26 strictly curve iteration 13 turn strictly curve iteration 0 Fig 7 shows distribution solving times analogous manner xaxis measures solving time seconds The left plot instances solved 200 seconds right plot remaining instances different scale xaxis There test instances extremely long solve heuristic learned ﬁrst iteration iteration 13 instances solved 2500 seconds Using ﬁnal heuristic instances solved 72 seconds We acrosstheboard improvement solving times plot iteration 0 strictly plot iteration 13 turn strictly plot iteration 26 The general trends suboptimality solving time seen test domains speciﬁcally noted Table 5 shows results systems test instances Row 1 reports WIDA initial heuristic h0 multiplied weight W chosen Subopt roughly equal Subopt value achieved ﬁnal bootstrap heuristic Table 4 iteration 26 In Row 2 W chosen Nodes gen roughly equal Nodes gen value achieved ﬁnal bootstrap heuristic Table 4 iteration 26 The results analogous settings BULBs beam width B h0 shown Rows 3 4 Bootstrap Table 4 iteration 26 dominates cases sense W BULB compare Bootstrap values Subopt Nodes gen B set WIDA heuristic obtained ﬁnal Bootstrap iteration Table 4 iteration 26 superior value Note guarantees solution cost achieved factor W optimal onea guarantee WIDA learned heuristics provide This kept mind subsequent comparisons Bootstrap WIDA Row 5 shows results heuristic hsum deﬁned sum heuristic values NNs input features h0 maximum values Although hsum general greater actual distance goal hsum accurate heuristic moderate number weak heuristics NN features experiments By comparing performance Bootstraps return investment learning combine different heuristics opposed giving equal weight hsum As results hsum NN features 24puzzle performs poorly terms suboptimality It superior Bootstrap 500 instances Table 3 iteration 3 Bootstrap 5000 instances Table 4 iteration 26 terms nodes generated solving time S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2085 Table 5 24Puzzle methods Row 1 2 3 4 5 h Algorithm W 15 h0 WIDA W 26 h0 WIDA h0 BULB B 20000 h0 BULB B 10000 hsum Results previous papers 6 7 8 9 10 11 Add 6666 6 DIDA 6 Add 888 6 W 14 RBFS PEANN Add 11112 RBFS 10 W 12 RBFS Avg subopt Avg nodes gen Avg solving time 90 805 138 1229 1814 0 0 0 94 07 37 39356250896 7579345 85136475 7624139 151892 360892479670 75201250 618 65135068005 1400431 118465980 582466 287708 s 55 s 1854 s 134 s 01 s 47 h 10 h s 10 1110 s 07 s Rows 68 results stateoftheart heuristic search methods ﬁnding optimal solutions Row 6 shows results maximum disjoint 6tile PDBs reﬂections main diagonal heuristic Korf Felner 32 Row 7 shows results DIDA obtained Zahavi Felner Holte Schaeffer 50 heuristic In Row 8 heuristic maximum heuristic Row 6 partially created disjoint 8tile PDB Felner Adler 10 solving time reported The large solving times required systems shows 24puzzle represents limit ﬁnding optimal solutions todays abstraction methods memory sizes Row 9 Samadi et al 41 illustrates beneﬁts allowing suboptimality Here RBFS 30 heuristic Row 6 multiplied 14 The number nodes generated plummeted Although result better terms nodes generated solving time Bootstrap Table 4 iteration 26 hinges having strong heuristic noted WIDA initial heuristic badly outperformed Bootstrap Rows 10 11 Table 5 PEANN results Samadi et al 41 As discussed introduction direct application heuristic learning 24puzzle infeasible generate adequate training set onestep method Critical choices abstracting 24puzzle manually obtain results Row 10 shows automatic method superior PEANN way factor 20 terms nodes generated The suboptimality values shown Rows 10 11 directly comparable Tables 3 4 Samadi et al deﬁned average suboptimality differently total length solutions divided total length optimal solutions The suboptimality Bootstrap 5000 instances calculated way happens decimal place Table 4 81 inferior PEANNs Row 11 shows PEANNs learned heuristic suitably weighted outperform Bootstrap nodes generated suboptimality To Bootstraps results change given stronger initial heuristic reran experiment h0 stateoftheart admissible heuristic Korf Felners maximum disjoint 6tile PDBs reﬂections main diagonal 32 We adjusted features neural network accordingly instead 8 features 13 disjoint PDBs reﬂected PDBs sum ﬁrst PDB features sum reﬂected PDB features plus Manhattan Distance position blank number tiles place Note increasing number features increase Bootstraps completion time solving time The use stronger h0 decreased Bootstraps completion time 50 500 bootstrap instances increased 25 5000 bootstrap instances The suboptimality solutions ﬁnal Bootstrap heuristic unaffected use stronger heuristic 500 bootstrap instances increased 81 112 5000 bootstrap instances The important consequence stronger h0 dramatic reduction number nodes generated ﬁnal heuristic Bootstrap produced With 500 bootstrap instances 5087295 nodes generated average 12fold reduction compared Table 3 5000 bootstrap instances use stronger h0 produces 6fold reduction nodes generated BULB strong h0 WIDA We reran WIDA outperformed Bootstrap badly W 145 yields average suboptimality similar Bootstraps 5000 instances strong h0 generates roughly 3 times nodes W 15 generates similar number nodes higher suboptimality 16 average compared 112 BULB strong heuristic clearly outperformed Bootstrap When generating comparable number nodes Bootstrap 5000 instances strong h0 BULBs suboptimality higher Bootstraps 4183 compared 112 B 20000 resulted suboptimality 133 approaching Bootstraps cost generating 36 times nodes average 32 35Pancake puzzle For 35pancake puzzle input features NN seven 5token PDBs binary value indicating middle token place number largest outofplace token Optimal solution lengths computed 2086 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Table 6 35Pancake puzzle Bootstrap 500 bootstrap instances Iteration No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 0 ﬁrst 1 2 3 4 ﬁnal 134 77 81 100 77 366 289 208 108 31 Bootstrap completion time 1 day 2 hours Table 7 35Pancake puzzle Bootstrap 5000 bootstrap instances 104 102 114 113 123 178891711 181324430 169194509 191333354 131571637 217 s 219 s 202 s 228 s 158 s 7 h 9 h 11 h 16 h 1 d 02 h Iteration 0 ﬁrst 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 102 258 128 265 216 95 150 128 250 118 102 210 170 105 170 125 4898 4394 4110 3630 3198 2999 2732 2456 2008 1766 1575 1177 814 600 279 36 92 97 102 108 116 122 123 123 124 132 130 135 142 149 151 154 2766675135 1591749582 586345353 295187243 134075802 65290479 47998040 45571411 39128839 38126208 39440284 36423262 25034580 26089593 13156609 14506413 4168 s 1923 s 687 s 345 s 157 s 102 s 76 s 71 s 45 s 43 s 44 s 52 s 42 s 43 s 21 s 21 s 1 d 17 h 2 d 07 h 2 d 20 h 3 d 08 h 3 d 18 h 4 d 04 h 4 d 20 h 5 d 15 h 5 d 23 h 6 d 05 h 6 d 16 h 7 d 00 h 7 d 10 h 7 d 23 h 8 d 07 h 8 d 11 h Bootstrap completion time 8 days 11 hours Fig 8 35Pancake puzzle distribution solving times ing highly accurate handcrafted break heuristic5 50 randomly generated instances average optimal solution cost 336 testing The preprocessing time build pattern databases bootstrap instances 18 minutes memory hold pattern databases 272 megabytes The initial heuristic weak seven RandomWalk iterations necessary bootstrapping gin 9 iterations required 500 bootstrap instances Table 6 rows bootstrap iterations 500 bootstrap instances Table 7 rows selected iterations 5000 bootstrap instances In cases trends 24puzzle concerning suboptimality solving time inﬂuence number bootstrap instances Fig 8 shows distribution solving times iterations 0 15 30 Bootstrap process 5000 bootstrap instances Like corresponding ﬁgure 24puzzle Fig 7 instances long time solve heuristic learned ﬁrst iteration middle iteration problematic 5 For details break httptomasrokickicompancake Helmert 20 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2087 Table 8 35Pancake puzzle methods Row 1 2 3 4 h Algorithm W 9 h0 WIDA h0 BULB B 20000 h0 BULB B 500 hsum Avg subopt 1089 4054 29079 590 Avg nodes gen 1092647373 426578146 154193966 71081642 Avg solving time 857 s 1360 s 483 s 69 s instances instances solved 500 seconds But unlike 24puzzle speedup solving hardest instances accompanied slowdown solving easier instances left Fig 8 plot iteration 15 iteration 0 By ﬁnal iteration acrosstheboard improvement solving time compared iterations shown Because large size previous generalpurpose search automatically created heuristics BULB hsum None methods applied problem domain Table 8 includes results WIDA BULB Rows 1 3 able achieve Nodes gen value similar Bootstrap 5000 instances For WIDA minimum number nodes algorithms generated tried 15 values W 11 10 15 values B 2 20000 As seen WIDA BULB produce high degree suboptimality generating BULB compete Bootstrap terms suboptimality fewest nodes Looking settings WIDA Bootstraps ﬁnal heuristic iteration 30 Table 7 needed successful Allowing 10 times time IDA BULB inferior test instance WIDA Bootstrap Table 7 iteration 30 terms nodes generated suboptimality complete instances Row 4 shows hsum like WIDA As 24puzzle effect giving Bootstrap strong initial heuristic reran experiments h0 strongest generalpurpose type admissible heuristic known 35pancake puzzle additive heuristics deﬁned Yang et al 48 The particular h0 5555555 additive PDB The features learning seven 5pancake PDBs sum nonPDB features weak h0 The use stronger h0 affect Completion times 500 5000 bootstrap instances For 500 bootstrap instances use stronger h0 decreased suboptimality 123 55 reduced number nodes generated factor 5 For 5000 bootstrap instances stronger h0 decreased suboptimality 154 59 little effect number nodes generated 33 Rubiks Cube For Rubiks Cube input features NN PDBs Korf 31 PDB based corner cubies PDBs based edgecubies 333 megabytes memory PDBs preprocessing took 16 minutes Korfs 10 standard Rubiks Cube instances 31 testing The average optimal solution cost stances 175 The initial heuristic suﬃcient begin Bootstrap process directly random walk iterations necessary Tables 9 10 results bootstrap iteration 500 5000 bootstrap instances given In case bootstrapping produces substantial speedup search h0 For instance 500 bootstrap instances produces heuristic reduces number nodes generated factor 43 compared h0 producing solutions 4 longer optimal The trends bootstrap iterations observed previous experiments The results systems shown Table 11 Rows 1 2 initial heuristic h0 W set test instances Row 3 shows results hsum As Pancake puzzle Bootstrap Table 10 IDA iteration 14 outperforms hsum suboptimality nodes generated Rows 46 results stateoftheart heuristic search methods ﬁnding optimal solutions Row 4 shows results initial heuristic h0 31 Row 5 shows results Zahavi et al 51 dual lookups 11 6edge PDBs conjunction heuristic Row 4 In Row 6 51 edge PDBs Row 5 increased 6edge 7edge dual lookup Bootstrap outperforms optimal systems terms nodes generated solving time For BULB compared results Furcy König 15 obtained h0 However Furcy König different set test instances created 50 solvable instances random walks length 500 backward goal state This set instances currently unavailable making impossible precise comparison method With mind inspection Furcy Königs results shows appropriate setting B BULBs performance terms nodes generated similar Bootstraps average number nodes generated Furcy Königs 50 instances B 50000 189876775 compared 192012863 Bootstrap Korfs 10 instances iteration 14 Table 10 Because optimal solution costs Furcy Königs instances known comparison suboptimalities possible 2088 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Table 9 Rubiks Cube Bootstrap 500 bootstrap instances Iteration 0 ﬁrst 1 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 256 76 244 178 28 40 67264270264 8243780391 78998 s 10348 s 5 m 2 d Bootstrap completion time 2 days 19 hours Table 10 Rubiks Cube Bootstrap 5000 bootstrap instances Iteration 0 ﬁrst 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 2564 355 126 82 166 149 162 166 76 256 85 136 218 206 192 2436 2081 1955 1873 1707 1558 1396 1230 1154 898 813 677 459 253 61 34 46 58 97 126 160 218 201 218 229 229 253 247 275 293 69527536555 7452425544 3314096404 3722365147 974287428 748608645 599503676 614676983 465772443 552259662 518980590 624542989 422066562 251228458 192012863 86125 s 10477 s 3976 s 4444 s 1119 s 848 s 823 s 842 s 626 s 624 s 577 s 686 s 464 s 280 s 208 s 43 m 10 h 1 d 06 h 2 d 16 h 5 d 08 h 7 d 05 h 9 d 09 h 11 d 07 h 13 d 04 h 16 d 14 h 19 d 10 h 23 d 20 h 27 d 06 h 30 d 02 h 31 d 15 h Bootstrap completion time 31 days 15 hours Table 11 Rubiks Cube methods Row 1 2 3 h Algorithm h0 WIDA h0 WIDA hsum W 19 W 33 Results previous papers 4 5 6 h0 4 dual lookup max8 7 7 dual lookup 34 20Blocks world Avg subopt Avg nodes gen Avg solving time 304 764 545 0 0 0 5653954001 217463103 246235226 360892479670 253863153493 54979821557 6632 s 245 s 256 s 102362 s 91295 s 44201 s We 9 input features NN seven 2block PDBs number place blocks number stacks blocks Optimal solutions computed handcrafted blocks world solver PERFECT 45 We 50 random test instances goal state blocks stack The average optimal solution length test instances 3092 The total memory required experiment 3 kilobytes preprocessing took seconds The initial heuristic weak RandomWalk iterations necessary bootstrapping begin iterations 500 bootstrap instances Tables 12 13 bootstrap iterations 20blocks world The heuristics feature vector weak solving test instances early heuristics produced Bootstrap infeasible iteration 0 shown Table 12 iterations 0 2 shown Table 13 The completion time Bootstrap 500 bootstrap instances longer total time learn ﬁnal heuristic iteration 3 Table 12 instances solved iteration Bootstrap process terminated tmax exceeding t The trends results domains discussed previously The results BULB set test instances shown Table 14 For suboptimality BULB compete Bootstrap tried 15 values B 2 20000 The best suboptimality achieved BULB shown Row 1 It shows greater suboptimality BULB inferior Bootstrap terms nodes generated solving time BULBs results B set BULB approximately equal Bootstrap Table 13 iteration 13 terms nodes generated shown Row 2 Again Bootstrap dominates time limits 10 times larger solving time Bootstraps ﬁnal heuristic test instance failed solve half test instances W varied 12 10 In best case W 9 WIDA solved 24 test instances An attempt compare results hsum failed heuristics feature WIDA S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2089 Table 12 20Blocks world Bootstrap 500 bootstrap instances Iteration 1 2 3 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 75 95 90 338 243 167 18 24 38 13 456726519 8886906652 615908785 55213 s 35692 s 2763 s 11 h 1 d 02 h 1 d 10 h Bootstrap completion time 2 days Table 13 20Blocks world Bootstrap 5000 bootstrap instances Iteration 3 4 5 6 7 8 9 10 11 12 13 ﬁnal No solved Total unsolved Avg subopt Avg nodes gen Avg solving time Learning time 275 290 450 556 162 117 508 377 98 83 89 2781 2491 2041 1485 1323 1206 698 321 223 140 51 22 32 35 40 41 54 65 80 87 89 96 12771331089 8885364397 941847444 660532208 789515580 191696476 22413312 11347282 17443378 7530329 5523983 52430 s 35636 s 3828 s 2734 s 3240 s 791 s 93 s 47 s 72 s 31 s 23 s 3 d 06 h 4 d 04 h 5 d 21 h 7 d 03 h 8 d 05 h 9 d 05 h 9 d 22 h 10 d 18 h 10 d 10 h 10 d 20 h 11 d 01 h Bootstrap completion time 11 days 1 hour Table 14 20Blocks world methods Row 1 2 h Algorithm h0 BULB B 20000 h0 BULB B 2400 Avg subopt Avg nodes gen Avg solving time 288 588 278209980 5809791 2482 s 32 s vector weak sum values weak heuristic domain hsum failed solve instance given time limit day instance 4 Solving single instances quickly The preceding experiments demonstrate bootstrap learning help speed search dramatically relatively little degradation solution quality An inherent nonnegligible expense time invested learning heuristic function The Bootstrap completion times reported order days Such lengthy process warranted ﬁnal heuristic going solve numerous problem instances distributed way bootstrap instances expect new instances solved quickly ﬁnal heuristic bootstrap instances time limit iteration bootstrap process However planning problems require single instance solveda task bootstrapping ap proach illsuited large total time required In section investigate variation bootstrapping method quickly solve single instance given problem domain Instead minimizing solving time expense requiring large learning times previous sections looking balance learning solving times sum learning solving times small With goal mind present method involves interleaving learning solving processes The method fully au tomatic ratio solving time learning time speciﬁed We present experimental results 24puzzle 35pancake puzzle Rubiks Cube 20blocks world IPC2 blocksworld instances In domains Rubiks Cube interleaving bootstrap learning problemsolving proves effective solving single instances 41 Method implementation An important factor inﬂuencing total time bootstrap process previous experiments number bootstrap instances For instance Tables 3 4 increasing number 500 5000 increases total time 12 hours 5 days 24puzzle In fact large portion training time spent trying solve bootstrap instances diﬃcult current heuristic This suggests considerable time saved ran initial bootstrap instances given outset random walks create training instances successive levels diﬃculty heuristic created target instance ins quickly solved Following Algorithm 2 procedure basically work follows starting h initial heuristic 2090 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 If h weak solve ins time limit tmax generate set RWIns instances random walks backward goal Improve h applying bootstrap procedure Algorithm 1 h0 h RWIns h0 h Repeat solved current heuristic process increasing length random walks iteration ins h time limit tmax The total time required procedure including training time solving time measure evaluation The obvious problem approach use parameter tmax total time strongly depend value parameter If tmax low need iterations If tmax high force solver weak heuristic spend tmax vain advantageous invest learning Automatic adjustment tmax involves timeconsuming process attempting solve nonnegligible number instances created RandomWalk naive method described expected infeasible Avoiding tmax completely ﬁxing training time trying solve ins heuristic learned ﬁxed training promising Here training time critical parameter set prior knowledge Our approach automated process hinge critically parameters interleave learning solving follows We alternate execution threads learning thread solving thread The learning thread runs RandomWalk process manner described produce sequence stronger stronger heuris Initially thread uses tics The solving thread uses heuristics generated RandomWalk process solve ins initial heuristic When new heuristic produced solving thread updated account existence new probably stronger heuristic There possible ways updating solving thread new heuristic available examine 1 The simplest approach updating solving thread abort current search start new search scratch new heuristic We approach Immediate Restart 2 The second approach ﬁnish current IDA iteration ends solving ins iteration uses new heuristic h IDA computed IDA bound maxDB hins iteration new heuristic instead previous If bound DB use iteration The We approach Heuristic Replacement 3 The approach subdivide solving thread set solving subthreads heuristic known As soon new heuristic learned learning thread approach starts additional solving sub In approach thread stopped completely thread uses new heuristic try solve ins ins solved solving subthreads We approach Independent Solvers6 Regardless approach total time evaluate interleaved learning solving process sum times threads including subthreads point ins solved subthread ts seconds elapsed If ins Pseudocode interleaved learning solving processes Immediate Restart Heuristic Replacement approaches shown Algorithm 3 We use ﬁxed ratio ts tl time allocated solving ts time allocated learning tl7 Line 3 calls continue Solver thread time limit ts This executes solver solved loop lines 410 executed Line 5 calls solved ins continue RandomWalk procedure described time limit tl This resumes execution RandomWalk process point previously suspended runs time tl suspends returns current heuristic time suspension If heuristic returned new solving thread updated described account new heuristic line 7 Line 9 resumes updated solving thread The entire process stops solution ins Algorithm 3 hin ts tl solution h continueRandomWalk tl h new heuristic 1 procedure Interleavingins 2 Create solving thread Solver hin 3 solved continueSolver ts 4 solved 5 6 7 8 9 10 end 11 return solution solving thread end solved continueSolver ts UPDATESolver h 6 As opposed approaches Independent Solvers advantage easily parallelized 7 Technically ratio solving time learning time given actual time units Using ratio 100200 practice yield different results ratio 12 For simplicity set ts 1 second experiments use term ratio refer setting ts tl S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2091 Determining best ratio ts tl domain scope paper current ratio set manually Generally weaker initial heuristic ratio allocate time learning thread We ran experiments ratios 11 110 necessary larger values tl Section 42 details Since initial heuristics experiments weak use ratios favouring solving thread Pseudocode interleaved learning solving processes Independent Solvers approach shown Algo rithm 4 It follows exactly general pattern Algorithm 3 growing list Solvers instead Solver When new heuristic learned new solving subthread heuristic added beginning list The procedure IndependentSolvers divides available time solving ts set available solving threads solved exactly described paragraph No thread terminated ins solving subthreads Algorithm 4 hin ts tl solution h continueRandomWalk tl h new heuristic 1 procedure Interleavingins 2 Create list Solvers containing solving subthread hin 3 solved IndependentSolversSolvers ts 4 solved 5 6 7 8 9 10 end 11 return solution independent solving subthreads end solved IndependentSolversSolvers ts add solving subthread h beginning Solvers For allocation solving time solving subthreads strategies possible The report Exponential When new heuristic learned strategy halves time allocated solving subthreads previous heuristics allocates ts 2 seconds subthread new heuristic Thus solving subthread new heuristic gets half total time available solving round heuristic created The motivation strategy heuristics created later learning process expected stronger created early stages recently created heuristics likely quickly solve target instance It reasonable invest time solvers heuristics learned later iterations The reason suspend solving subthreads weak heuristics completely chance closer ﬁnding solution solving subthread recently created heuristic This time invested subthreads weaker heuristics ii weaker heuristic occasionally behave better particular target instance overall stronger heuristic Other strategies Röger Helmerts alternation technique 39 certainly possible8 Algorithm 5 t t2 S ith subthread Solvers cid5 Solvers 1 procedure IndependentSolvers exponential Solvers time status 2 t time 3 1 Solvers 4 5 6 7 8 9 10 11 end 12 return false end continueS t succeeds return true end Pseudocode Exponential time allocation strategy shown Algorithm 5 The time invested solving sub thread best available heuristic ﬁrst Solvers list twice large invested subthread second best heuristic factor larger time weaker subthread The weakest subthreads allocated time total time spent subthreads sums time allocated solving thread overall This strategy allocating total solving time time budgets currently available heuristic solvers borrows hyperbolic dovetailing approach interleaved search introduced Kirkpatrick 28 Kirkpatrick proved ap proach averagecase optimal worstcase optimal certain variation socalled cow path problem ﬁrst studied BaezaYates Culberson Rawlins 2 However variation cow path problem 8 Not reported results uniform strategy allocates time solving subthreads We performance inferior Exponential strategy See Jabbari Arfaees thesis 26 details 2092 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Table 15 Solving single instance 24puzzle Row Ratio ts tl Immediate restart 11 12 15 best 1 2 3 Heuristic replacement 4 5 6 7 11 12 15 16 best Independent solvers exponential 11 12 15 110 best 8 9 10 11 min max mean med std Subopt 5 m 30 s 4 m 24 s 4 m 04 s 5 m 30 s 4 m 16 s 4 m 04 s 3 m 58 s 20 m 48 s 15 m 36 s 12 m 30 s 11 m 31 s 62 m 05 s 47 m 04 s 51 m 00 s 61 m 54 s 36 m 30 s 37 m 32 s 36 m 34 s 44 m 54 s 43 m 36 s 42 m 42 s 53 m 46 s 18 m 49 s 15 m 54 s 15 m 24 s 18 m 19 s 15 m 06 s 14 m 28 s 14 m 05 s 23 m 36 s 18 m 03 s 15 m 50 s 15 m 48 s 17 m 25 s 14 m 18 s 15 m 18 s 17 m 03 s 13 m 52 s 14 m 08 s 13 m 56 s 21 m 54 s 16 m 30 s 14 m 30 s 14 m 14 s 8 m 45 s 6 m 54 s 7 m 58 s 8 m 29 s 5 m 48 s 5 m 57 s 5 m 48 s 4 m 07 s 4 m 15 s 5 m 53 s 6 m 55 s 63 64 65 62 63 63 65 64 67 69 70 exactly model search problem facing Hence formal guarantees eﬃciency method 42 Experiments We ran experiments comparing versions interleaving approach different ts tl ratios domains Section 3 The experimental settings domain features neural network settings described Section 3 The test instances domain Section 3 individual target instances testing We report results IPC2 blocksworld instances comparisons stateoftheart planners instances In experiments parameter ts Algorithm 4 set 1 second tl varied 1 10 seconds steps 1 Whenever ratio 110 resulted lower mean total time ratios 11 19 tested ratios 111 112 mean total time started increasing The ratio resulting lowest total time marked tables best ratio The tables results ratios 11 12 15 best ratio 421 24Puzzle Table 15 shows results interleaving strategies solvers The min max mean med std columns respectively minimum maximum mean median standard deviation total times 50 instances 24puzzle experiment The subopt column shows average suboptimality solutions calculated manner Section 3 The trends apparent results The average suboptimality increases ts tl ratio increases favour learning thread This explained trends observed Section 3 There seen bootstrap iterations result larger suboptimality Since bootstrap iterations result stronger heuristics target instance likely solved ﬁrst strongest heuristics created interleaving process A solver stronger heuristic solving target instance faster provides solution higher cost solutions solvers weaker heuristics eventually provided The mean median values initially decrease growing tl ts tl ratio favours learning thread It turns average heuristic solves target instance requires seconds solving time Therefore solving time spent unsuccessful trials heuristics Increasing learning time makes produce stronger heuristics faster This turn decreases total solving time instances mean median decreases However mean median values eventually start increase point This happens following reason As noted heuristic solves target instance requires seconds solving time Since ts second means solving thread suspended resumed times order heuristic completely solve instance As tl increases heuristic gets created sooner delays suspending resuming solving thread longer length tl suﬃciently large tl increase delays solving episodes outweigh advantage creating heuristic sooner The mean total times best ratio strategies similar 10 difference The mean total time spent target instance including learning timeunder 16 minutes 960 secondsis substantially lower total time spent bootstrap large set bootstrap instances inter leaving According Tables 3 4 requires 11 hours 500 bootstrap instances 5 days 5000 bootstrap instances Alternatively minimize learning time consider heuristics S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2093 Table 16 Solving single instance 35pancake puzzle Row Ratio ts tl Immediate restart 1 2 3 4 11 12 15 16 best Heuristic replacement 5 6 7 8 11 12 15 18 best Independent solvers exponential 11 12 15 19 best 9 10 11 12 min max mean med 2 h 36 m 2 h 07 m 1 h 45 m 1 h 37 m 2 h 34 m 2 h 06 m 1 h 45 m 1 h 39 m 7 h 13 m 5 h 24 m 4 h 19 m 1 h 50 m 6 h 48 m 5 h 18 m 5 h 57 m 4 h 29 m 6 h 45 m 5 h 15 m 5 h 00 m 4 h 54 m 9 h 48 m 7 h 28 m 6 h 42 m 7 h 01 m 3 h 41 m 2 h 54 m 2 h 38 m 2 h 07 m 3 h 36 m 2 h 50 m 2 h 34 m 2 h 29 m 7 h 36 m 5 h 45 m 4 h 45 m 3 h 23 m 3 h 24 m 2 h 39 m 2 h 26 m 2 h 07 m 3 h 24 m 2 h 39 m 2 h 19 m 2 h 14 m 7 h 28 m 5 h 32 m 4 h 39 m 3 h 28 m std 46 m 40 m 48 m 33 m 42 m 38 m 42 m 42 m 30 m 24 m 28 m 50 m Subopt 75 80 82 83 76 80 82 81 78 80 83 89 created ﬁrst bootstrap iteration With 5000 bootstrap instances heuristic solves instances considerably slower average interleaving methods 23649 seconds 39 minutessee iteration 0 Table 4compared 16 minutes The heuristic created ﬁrst iteration bootstrapping 500 bootstrap instances solves instances faster interleaving 15334 seconds 25 minutessee iteration 0 Table 3 takes 98 minutes learn heuristic Learning time column iteration 0 Table 3 Therefore method solve target instance substantial speedup normal bootstrap method Our method fares comparison systems reported W 15 suboptimality superior BULB B 20000 far superior hsum Table 5 It dominates WIDA Its total time 960 seconds optimal methods Its time inferior weighted RBFS reported line 9 Table 5 suboptimality superior Comparisons PEANN lines 10 11 Table 5 possible training times unknown If Bootstrap given strong initial heuristic h0 maximum disjoint 6666 PDBs reﬂections total times similar reported Table 15 suboptimality reduces roughly 4 interleaving strategies 422 35Pancake puzzle Table 16 provides detailed results 35pancake puzzle The trends observed experiment similar observed 24puzzle Independent Solvers strategy mean median times considerably higher strategies The suboptimality heuristics produced interleaving strategies superior suboptimalities reported basic bootstrapping Tables 6 7 mean total solving time interleaving strategies half time required ﬁnish ﬁrst bootstrapping iteration 500 bootstrap instances 7 hourssee Table 6 In W 9 BULB B cid2 20000 Table 8 instances solved quickly hsum WIDA interleaving methods greater suboptimality If Bootstrap given strong initial heuristic h0 5555555 additive PDB total times slightly smaller Table 16 suboptimality decreases 45 interleaving strategies 423 Rubiks Cube Table 17 shows experimental results Rubiks Cube As 35pancake puzzle Independent Solvers strategy mean median times considerably higher strategies The reason suboptimality variations tested cases instances solved heuristic created bootstrapping This happens h0 ﬁrst learned heuristics weak time 25 hours needed learn fourth heuristic This explain best ratio smaller domains Although interleaving superior basic bootstrapping process single Rubiks Cube instance solve best mean total time Table 17 10 hours 54 minutes 39240 seconds 11 better time required solve average instance optimally best known heuristic Rubiks Cube 44201 seconds Row 6 Table 11 However interleaving strategies shown Table 17 outperform simply initial heuristic solve instance requires 102362 seconds 28 hours 26 minutes average Row 4 W 14 requires time solve Table 11 Heuristic Replacement 15 ratio dominates WIDA instance 12 hours 36 minutes average produces greater suboptimality 133 compared 64 2094 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 Table 17 Solving single instance Rubiks Cube Row Ratio ts tl Immediate restart 11 1 12 best 2 15 3 Heuristic replacement 4 5 6 11 12 15 best Independent solvers exponential 11 7 12 best 8 15 9 min max mean med std Subopt 0 h 41 m 1 h 01 m 2 h 01 m 0 h 41 m 1 h 01 m 2 h 01 m 1 h 22 m 2 h 02 m 4 h 03 m 19 h 27 m 19 h 48 m 28 h 01 m 18 h 43 m 17 h 54 m 19 h 41 m 26 h 16 m 29 h 54 m 29 h 29 m 13 h 29 m 11 h 42 m 13 h 08 m 13 h 21 m 11 h 18 m 10 h 54 m 15 h 36 m 14 h 51 m 17 h 23 m 13 h 50 m 11 h 18 m 11 h 10 m 13 h 28 m 10 h 42 m 9 h 16 m 15 h 02 m 13 h 04 m 14 h 45 m 4 h 54 m 4 h 45 m 7 h 02 m 4 h 59 m 4 h 45 m 5 h 24 m 6 h 34 m 4 h 45 m 4 h 30 m 64 64 64 64 64 64 64 64 64 Table 18 Solving single instance 20blocks world Row Ratio ts tl Immediate restart 1 2 3 4 11 12 15 19 best Heuristic replacement 5 6 7 11 12 15 best Independent solvers exponential 11 12 15 best 8 9 10 min 17 m 17 m 10 m 26 m 17 m 17 m 10 m 17 m 17 m 10 m 424 20Blocks world max mean med std Subopt 25 h 38 m 19 h 24 m 15 h 58 m 15 h 48 m 25 h 35 m 19 h 22 m 15 h 55 m 25 h 52 m 19 h 44 m 15 h 48 m 5 h 18 m 4 h 28 m 4 h 15 m 4 h 01 m 5 h 00 m 4 h 16 m 4 h 06 m 6 h 04 m 4 h 52 m 3 h 49 m 1 h 22 m 1 h 28 m 1 h 24 m 2 h 00 m 1 h 23 m 1 h 16 m 1 h 22 m 2 h 03 m 1 h 52 m 1 h 24 m 7 h 28 m 5 h 53 m 5 h 15 m 4 h 40 m 7 h 17 m 5 h 46 m 5 h 12 m 7 h 38 m 5 h 58 m 4 h 45 m 13 13 13 13 13 13 13 13 13 13 Table 18 shows experimental results 20blocks world In case solutions 13 longer optimal average 37 50 instances solved optimally Unlike previous domains Independent Solvers strategy slightly outperforms terms mean total time In experiment initial heuristic weak takes iterations RandomWalk heuristic suﬃciently strong solver solve instance reasonable time After point iterations learned heuristics enable instances solved quickly changing solution quality For reason observe constant suboptimality 13 different strategies The speedup compared initial bootstrap method needed 2 days 500 bootstrap instances 11 days 5000 bootstrap instances remarkable In addition solution lengths closer optimal cf Tables 12 13 Bootstrap results 20blocks world BULB B cid2 20000 solve single instance faster method Table 14 B 20000 unable ﬁnd value W suboptimality 20 times higher Bootstrap For WIDA solve test instances reasonable time suboptimality close interleaving method base comparison instances solved 2hour time limit instance Heuristic Replacement ratio 15 solved 27 50 instances time limit solutions 24 suboptimal With time limit WIDA W 4 solved 27 instances suboptimality 150 425 IPC2 blocks world instances We tested interleaving technique 35 instances blocks world domains varying size Track 1 IPC2 planning competition9 This version blocks world hand pick blocks opposed handless version 20blocks world experiments paper Despite difference features initial heuristic previous experiments handless 20blocks world 9 See httpwwwcstorontoeduaips2000 details S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2095 Table 19 IPC2 blocks world instances results interleaving exponential allocation strategy Instance Optimal Ratio 11 Ratio 12 Ratio 15 Time Subopt Time Subopt Time Subopt 90 91 92 100 101 102 110 111 112 120 121 130 131 140 141 150 151 161 162 170 30 28 26 34 32 34 32 30 32 34 34 42 44 38 36 40 52 54 52 48 22 13 73 58 2 12 3 1451 170 23 62 313 627 1347 1001 331 48 5 33 19 58 42 3 18 4 1102 1024 51 73 310 475 1271 751 258 48 5 65 2 38 47 46 6 37 9 914 861 67 176 242 393 1105 603 230 48 5 Table 19 shows results hardest 20 instances IPC2 set The ﬁrst column names instances x y refers yth instance consists x blocks The columns total time seconds suboptimality achieved interleaving method exponential allocation strategy In table Time entries indicate total time 01 seconds Subopt entries indicate instance solved optimally The 15 instances fewest blocks 4 8 shown solved optimally 01 seconds Table 19 shows interleaving method capable solving instances 30 minutes time limit solving instance IPC2 competition solutions optimal optimal close optimal The Fast Downward planner 19 setting10 uses multiheuristic bestﬁrst search11 preferred operators solved 35 blocks world instances It took Fast Downward average second solve instance solutions 200 suboptimal12 Our interleaving approach required time 138 seconds average solutions 03 suboptimal The FF planner 23 solved 29 35 instances time limit 30 minutes The solutions generated solved instances 23 suboptimal took 6 seconds average FF solve 29 instances These 29 instances solved optimally interleaving approach greater time 25 seconds average Of course method able solve 6 problems 30 minutes FF The best performing optimal planners IPC5 Gamer HSP 13 solved 30 35 instances time limit 30 minutes 2114 Furthermore landmark cut heuristic 21 competitive stateoftheart optimal planners overall performance solved 28 35 instances time limit Its average solving time 28 instances 76 seconds Our interleaving approach solved 28 instances optimally 19 second average F Yoon Fern Givan 49 report sets results blocks world instances One set method present learning heuristic function guide planning method present learning decision list policy guide planning In cases learned solutions solving easiest 15 instances ones shown Table 19 FFs heuristic solved remaining 20 instances learned heuristicpolicy conjunction FFs heuristic Their methods step methods methods aimed solving single instances quickly The learning phase method learned heuristic took 600 seconds They took 1294 seconds average solve 20 test instances 20 solved 30minute time limit The solutions average suboptimality 12015 Our interleaving method solved instances 242 seconds 10 This setting referred M P Helmerts paper 19 11 This search algorithm bestﬁrst search algorithm alternates expanding nodes different open lists sorted based different heuristics 39 Here casual graph heuristic 19 FFs relaxed plan heuristic 23 12 All results planning systems discussed taken papers cited 13 See httpipcinformatikunifreiburgde details competition planners 14 Neither solving time instances solved reported planners 15 Fern et al computed average suboptimality differently deﬁned paper They deﬁned average suboptimality total length solutions divided total length optimal solutions In paragraph use method compute suboptimality systems allow comparison 2096 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 average optimal solutions average suboptimality 05 Our singleinstance method solve approximately 3 problems scratch time method perform learning solve 3 problems Their method learning decision list policy took time learn solve single instance method 10005 seconds average produced longer solutions average suboptimality 17 5 Related work Bootstrap learning iteratively improve initially weak evaluation function singleagent search idea Rendell 3738 enable unidirectional search solve random instances 15puzzle ﬁrst time Our method differs Rendells key details important Rendell assumed user provide set bootstrap instances iteration required solvable current evaluation function We hand assume entire set bootstrap instances given outset initial solve generates instances The study bootstrap learning heuristics Humphrey BramantiGregor Davis 25 Their SACH learns heuristic solve single instance bootstrapping successive failed attempts solve instance Impressive results obtained ﬁfteen diﬃcult standard 100 instances 15puzzle On average instances solved A 724032 nodes generated total SACHs iterations solutions 2 suboptimal Hauptman et al 1718 use genetic programming 33 iteratively improve initial population heuristic functions The key difference bootstrapping creates new heuristics mutating recombining heuristics current population learning new heuristic solved instances Training instances analog bootstrap instances evaluating ﬁtness newly created heuristics The main application date standard 6 6 Rush Hour puzzle suﬃciently small 36 1010 instances solved quickly heuristic guaranteeing evaluation ﬁtness succeed distinguishing better heuristics worse ones The heuristic learned reduced number nodes generated IDA variant factor 25 compared search heuristic The time required learning suboptimality solutions generated reported They FreeCell testbed 17 application policy evolved guide search heuristic function The online learning heuristics studied Fink 13 related bootstrapping Fink proves learning algo rithm certain desirable properties practical shortcoming requires optimal solution lengths known states generated searches Thayer Dionne Ruml 47 online learning update initial heuristic function greedy bestﬁrst search aims solving speciﬁc instance search problem They computed error heuristic node expanded search algorithm The error deﬁned difference heuristic value state sum heuristic value child largest heuristic estimate cost action generates child This error estimate update heuristic function search Their experimental results showed update greedy bestﬁrst search improve performance initial heuristic terms solution quality solving time For example heuristic created improves Manhattan Distance 15puzzle factor 3 terms solution cost factor 2 terms time needed solve problem instance In experiments Thayer et al included ANNoﬄine learns heuristic onestep manner resembling Ernandes Gori 9 This produced heuristic accurate heuristic learned online method interestingly poorer guiding greedy bestﬁrst search As observe highlights different requirements heuristics pruning unpromising paths focus paper compared heuristics determine order paths explored Other systems learning heuristics limit step bootstrapping process 93541 434449 Such systems typically assume initial heuristic h0 suﬃciently strong arbitrary instances solved use learning create better heuristic allows instances solved quickly h0 greater suboptimality If bootstrap method given initial heuristic strong systems require performs performs iteration produces improved heuristic introducing suboptimality For example 15puzzle Samadi et als onestep 41 creates heuristic allows solutions random solvable instances RBFS generating 2241 nodes average solutions 33 longer optimal Our supplied initial heuristic comparable strength Samadi et als initial heuristic terminates iteration heuristic allows solutions instances RBFS generating 9402 nodes solutions 05 longer optimal 27 Of course bootstrapping method advantage systems require strong initial heuristic succeed given initial heuristic weak solve bootstrap instances reasonable time Two previous systems random walks generate successively diﬃcult instances bootstrap learning search control knowledge form heuristic function Fern Yoon Givan 12 random walks learning policies control Markov Decision Process Finkelstein Markovitch 14 context S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 2097 learning macrooperators augment heuristicguided hillclimbing search In cases initial random walk length increment userspeciﬁed 6 Conclusions This paper gives experimental evidence machine learning create strong heuristics weak ones automatic incremental bootstrapping process augmented random walk method generating succes sively diﬃcult problem instances Our tested problem domains limit current abstraction methods case successfully created heuristics enable IDA solve randomly generated test instances quickly optimally The total time needed create heuristics strongly depends number bootstrap instances given Using 500 bootstrap instances heuristics produced approximately 10 times faster 5000 bootstrap instances Search slower heuristics produced fewer bootstrap stances solutions closer optimal This work signiﬁcantly extends previous onestep methods fail given strong heuristic start The total time bootstrap process create strong heuristics large state spaces order days This acceptable learning time amortized large number test instances To heuristic learning effective single problem instance needs solved presented variation bootstrap learning new heuristics interleaved problemsolving initial heuristic heuristics learned far When tested domains method shown substantially reduce total time needed solve single instance producing solutions close optimal When applied blocksworld instances IPC2 planning competition interleaving method solved instances 30minute time limit solved optimally Acknowledgements Thanks Neil Burch Richard Valenzano Mehdi Samadi Fan Yang Uzi Zahavi Ariel Felner sharing code Jonathan Schaeffer suggesting ideas heuristic replacement immediate restart reviewers insightful comments Alberta Ingenuity Centre Machine Learning NSERC References 1 Aaron F Archer A modern treatment 15puzzle American Mathematical Monthly 106 1999 793799 2 Ricardo A BaezaYates Joseph C Culberson Gregory JE Rawlins Searching plane Information Computation 106 2 1993 234252 3 Marcel Ball Robert C Holte The compression power symbolic pattern databases Proceedings 18th International Conference Automated Planning Scheduling ICAPS 2008 2008 pp 211 4 Blai Bonet Héctor Geffner Planning heuristic search Artiﬁcial Intelligence 129 2001 533 5 Joseph C Culberson Jonathan Schaeffer Searching pattern databases Proceedings Canadian Conference Artiﬁcial Intelligence LNAI vol 1081 Springer 1996 pp 402416 6 Harry Dweighter Problem E2569 American Mathematical Monthly 82 1975 1010 7 Stefan Edelkamp Symbolic pattern databases heuristic search planning Proceedings 6th International Conference Artiﬁcial Intelligence Planning Systems AIPS 2002 2002 pp 274283 8 Stefan Edelkamp Shahid Jabbar Peter Kissmann Scaling search pattern databases Proceedings 5th International Workshop Model Checking Artiﬁcial Intelligence MoChArt LNCS vol 5348 Springer 2009 pp 4965 9 Marco Ernandes Marco Gori Likelyadmissible subsymbolic heuristics Proceedings 16th European Conference Artiﬁcial Intelligence ECAI 2004 2004 pp 613617 10 Ariel Felner Amir Adler Solving 24 puzzle instance dependent pattern databases Proceedings 6th International Symposium Abstraction Reformulation Approximation SARA 2005 LNCS vol 3607 Springer 2005 pp 248260 11 Ariel Felner Uzi Zahavi Jonathan Schaeffer Robert C Holte Dual lookups pattern databases Proceedings 19th International Joint Confer ence Artiﬁcial Intelligence IJCAI 2005 pp 103108 12 Alan Fern Sungwook Yoon Robert Givan Learning domainspeciﬁc control knowledge random walks Proceedings 14th Interna tional Conference Automated Planning Scheduling ICAPS 2004 2004 pp 191199 13 Michael Fink Online learning search heuristics Proceedings 11th International Conference Artiﬁcial Intelligence Statistics AISTATS 2007 2007 pp 114122 14 Lev Finkelstein Shaul Markovitch A selective macrolearning algorithm application N N slidingtile puzzle Journal Artiﬁcial Intelli gence Research 8 1998 223263 15 David Furcy Sven König Limited discrepancy beam search Proceedings 19th International Joint Conference Artiﬁcial Intelligence IJCAI 2005 2005 pp 125131 16 Patrik Haslum Héctor Geffner Admissible heuristics optimal planning Proceedings 5th International Conference Artiﬁcial Intelligence Planning Systems AIPS 2000 2000 pp 140149 17 Ami Hauptman Achiya Elyasaf Moshe Sipper Evolving hyper heuristicbased solvers Rush Hour FreeCell Proceedings 3rd Annual Symposium Combinatorial Search SoCS 2010 2010 pp 149150 18 Ami Hauptman Achiya Elyasaf Moshe Sipper Assaf Karmon GPrush genetic programming evolve solvers Rush Hour puzzle Proceedings 11th Annual Conference Genetic Evolutionary Computation GECCO 2009 ACM New York NY USA 2009 pp 955962 19 Malte Helmert The Fast Downward planning Journal Artiﬁcial Intelligence Research 26 2006 191246 20 Malte Helmert Landmark heuristics pancake problem Proceedings 3rd Annual Symposium Combinatorial Search SoCS 2010 2010 pp 109110 21 Malte Helmert Carmel Domshlak Landmarks critical paths abstractions Whats difference Proceedings 19th International Conference Automated Planning Scheduling ICAPS 2009 2009 pp 162169 2098 S Jabbari Arfaee et al Artiﬁcial Intelligence 175 2011 20752098 22 Malte Helmert Gabriele Röger Relativeorder abstractions pancake problem Proceedings 19th European Conference Artiﬁcial Intelligence ECAI 2010 2010 pp 745750 23 Jörg Hoffmann Bernhard Nebel The FF planning Fast plan generation heuristic search Journal Artiﬁcial Intelligence Research 14 2001 253302 24 Robert C Holte Jeffery Grajkowski Brian Tanner Hierarchical heuristic search revisited Proceedings 6th International Symposium Ab straction Reformulation Approximation SARA 2005 LNAI vol 3607 Springer 2005 pp 121133 25 Timothy Humphrey Anna BramantiGregor Henry W Davis Learning solving problems single agent search Preliminary results Proceed ings 4th Congress Italian Association Artiﬁcial Intelligence AIIA 1995 LNCS vol 992 Springer 1995 pp 5666 26 Shahab Jabbari Arfaee Bootstrap learning heuristic functions Masters thesis Computing Science Department University Alberta 2010 27 Shahab Jabbari Arfaee Sandra Zilles Robert C Holte Bootstrap learning heuristic functions Proceedings 3rd Annual Symposium Combinatorial Search SoCS 2010 2010 pp 5260 28 David G Kirkpatrick Hyperbolic dovetailing Proceedings 17th Annual European Symposium Algorithms ESA 2009 LNCS vol 5757 Springer 2009 pp 516527 29 Richard E Korf Depthﬁrst iterativedeepening An optimal admissible tree search Artiﬁcial Intelligence 27 1 1985 97109 30 Richard E Korf Linearspace bestﬁrst search Summary results Proceedings 10th AAAI Conference Artiﬁcial Intelligence AAAI 1992 1992 pp 533538 31 Richard E Korf Finding optimal solutions Rubiks Cube pattern databases Proceedings 14th AAAI Conference Artiﬁcial Intelligence AAAI 1997 1997 pp 700705 32 Richard E Korf Ariel Felner Disjoint pattern database heuristics Artiﬁcial Intelligence 134 2002 922 33 John R Koza Genetic Programming II Automatic Discovery Reusable Programs MIT Press Cambridge MA May 1994 34 Judea Pearl Heuristics AddisonWesley 1984 35 Marek Petrik Shlomo Zilberstein Learning heuristic functions approximate linear programming Proceedings 18th International Conference Automated Planning Scheduling ICAPS 2008 2008 pp 248255 36 Armand Prieditis Machine discovery effective admissible heuristics Machine Learning 12 1993 117141 37 Larry A Rendell Details automatic evaluation function generator statespace problems Technical Report CS7838 Department Computer Science University Waterloo 1978 38 Larry A Rendell A new basis statespace learning systems successful implementation Artiﬁcial Intelligence 20 1983 369392 39 Gabriele Röger Malte Helmert The merrier Combining heuristic estimators satisﬁcing planning Proceedings 20th International Conference Automated Planning Scheduling ICAPS 2010 2010 pp 246249 40 David E Rumelhart Geoffrey E Hinton Ronald J Williams Learning internal representations error propagation Parallel Distributed Processing Explorations Microstructure Cognition MIT Press Cambridge MA USA 1986 pp 318362 41 Mehdi Samadi Ariel Felner Jonathan Schaeffer Learning multiple heuristics Proceedings 23rd AAAI Conference Artiﬁcial Intelligence AAAI 2008 2008 pp 357362 42 Mehdi Samadi Maryam Siabani Ariel Felner Robert Holte Compressing pattern databases learning Proceedings 18th European Confer ence Artiﬁcial Intelligence ECAI 2008 2008 pp 495499 43 Sudeshna Sarkar Partha P Chakrabarti Sujoy Ghose Learning solving problems best ﬁrst search IEEE Transactions Systems Man Cybernetics Part A 28 1998 535541 44 Sudeshna Sarkar Sujoy Ghose Partha P Chakrabarti Learning eﬃcient search Sadhana Academy Proceedings Engineering Sciences 2 1996 291315 45 John Slaney Sylvie Thiébaux Blocks world revisited Artiﬁcial Intelligence 125 2001 119153 46 Jerry Slocum Dic Sonneveld The 15 Puzzle Slocum Puzzle Foundation 2006 47 Jordan Thayer Austin Dionne Wheeler Ruml Learning inadmissible heuristics search Proceedings 21st International Conference Automated Planning Scheduling ICAPS 2011 2011 pp 250257 48 Fan Yang Joseph Culberson Robert Holte Uzi Zahavi Ariel Felner A general theory additive state space abstractions Journal Artiﬁcial Intelligence Research 32 2008 631662 49 Alan Fern Sungwook Yoon Robert Givan Learning control knowledge forward search planning Journal Machine Learning Research 9 2008 683718 50 Uzi Zahavi Ariel Felner Robert Holte Jonathan Schaeffer Dual search permutation state spaces Proceedings 21st AAAI Conference Artiﬁcial Intelligence AAAI 2006 2006 pp 10761081 51 Uzi Zahavi Ariel Felner Robert C Holte Jonathan Schaeffer Duality permutation state spaces dual search algorithm Artiﬁcial Intelli gence 172 45 2008 514540 52 Rong Zhou Eric A Hansen Externalmemory pattern databases structured duplicate detection Proceedings 20th AAAI Conference Artiﬁcial Intelligence AAAI 2005 2005 pp 13981405