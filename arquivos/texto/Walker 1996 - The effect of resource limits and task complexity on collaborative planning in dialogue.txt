ELSEVIER Artificial Intelligence 85 1996 181243 Artificial Intelligence The effect resource limits task complexity collaborative planning dialogue Marilyn A Walker ATT Research Laboratories 600 Mountain Ave Rm 20441 Murray Hill NJ 07974 USA Received January 1995 revised October 1995 Abstract mitigate communicative testbed design 1 agents resource action designed This paper shows agents choice motivated corpus analysis Experiments interaction 2 agents choice limits context particular features collaborative planning task effect resource language behavior based statistical effective I motivate number hypotheses analysis corpus natural collaborative planning dialogues These hypotheses tested dialogue testbed limits attentional capacity inferential examine capacity tasks affect required communication defined tolerance relative agents resource limits features task Algorithms inefficient inferentially simple low coordination fault tolerant tasks effective tasks require coordination complex prima facie appear inefficient provide occurrence utterances human dialogues basis design effective algorithms limited choice communicative agents inferences fault intolerant The results provide explanation errors The results good algorithms complexity degree belief coordination features communicative inferential communication task difficulty resource 3 1 Introduction Agents engage conversation plan social At point establish contract agents communicative This paper focuses agents communicative dialogues dialogues purpose choices planning discuss agree plan future action choice collaborative range reasons acquire information dialogue Email walkerresearchattcom 00043702961500 SSD1000437029500114X Copyright 1996 Published Elsevier Science BV All rights reserved IX Ml llllXrrrricrlcl lwlilgrrw x5 I9961 IHl243 execute algorithms potentially action relatively unexplored resource collaborative degree belief coordination limits limits planning factors A primary dimension example consider simple furnishing I believes agents choices plan 1 argue language behavior determined respect models collaborative planning dialogues inferential capacity 2 attentional communicative I agents features complexity tasks affect task difficulty inferential required tolerance errors communicative choice degree explicitness task agent A agent B trying For agree plan realized tworoom house Imagine A wants B believe proposition B infer propositions realized 2 I I study II agree green couch study matched pair furniture t 2 c I propose C t11 We intend c Two furniture green couch study green chair study items color room achieve matched pair In naturally occurring dialogues A product utterances 3 6 variations 30 109 133 I3 I 1 realizing propositions 3 4 5 6 A I propose A We intend couch study A Two furniture pair We intend green couch A I propose pair green couch green chair study I propose study green items color room achieve matched study I propose green chair study green couch study That matched fact communicative levels explicitness explicit choices 3 6 illustrate general The communicative act effect achieved range acts This raises key issue On basis A choose C 3 C 6 versions proposal suggested The single constraint A information dont CONSTRAINT infer The IUXNINDANC DUNDANCY B ple dictums Maxim contribution informative operators constraints planning plans possibility A 3 J So assume generation 2 13278692 B knows CONSTRAINT literature FE B knows form sim tell people know Grices Quantity appears required 47 recognition communicative 2b 2 These ewmples arc Irom domain DesignWorld discussed Section 4 abstractions naturally occurring examples propositions realized realized number different ways Here focus logical relationships content proposition 2b arc minor premises 2 major premise inference discussion MA WalkerArtcial Intelligence 85 1996 181243 183 The REDUNDANCY CONSTRAINT based assumption implicit leave B combination I infer information words retrieving believes agent B B knows believes facts memory making agent A missing In Section 2 inferences REDUNDANCY surprising agents natural dialogues consistently violate CONSTRAINT I argue particularly REDUNDANCY CONSTRAINT based simplifying assumptions UNLIMITED WORKING MEMORY ASSUMPTION agent knows available reasoning ii LOGICAL OMNISCIENCE ASSUMPTION iii ASSUMPTION FEWEST UTTERANCES minimized agents logically omniscient utterance production process iv No AUTONOMY ASSUMPTION assertions proposals agent A ac cepted default agent B assumptions When agents autonomous hold problem communicative paper resource limited choice remains The plan implemented relationship choice resource communicative planning presented natural collaborative follows Section 2 motivates planning dialogues These hypotheses number hypotheses limits task features basis Section 3 Then Section 4 describes planning dialogues called evidence model collaborative model DesignWorld supports experiments interaction agents communicative choice steps method applied far motivate testing extent theoretical tasks agent properties hypotheses Section 5 presents implications Section 41 I review method results discusses results extent generalized limits features task At point hypotheses confirmed Section 6 discusses testbed collaborative use simulation communication experimental strategies resource 2 Communicative choice dialogue Naturally dialogues design problem planning 142130374997104128141143 collaborative occurring diagnostic advice giving dialogues generate hypotheses task features collaborative corpus dialogues I draw data collaborative solving In order agent properties naturally occurring dialogues Most examples discussed excerpts 98 2 radio talk financial planning relation communicative advice construction section examines design collaborative 28139142143 communicative planning choice choice Dialogue add modeled process conversants mutually believed intended This set assumed mutual beliefs assumed support dialogues general The corpus consists 55 dialogues 5 hours live radio broadcast dialogue ranged length 23 100 turns planning dialogues called DISCOURSE MODEL COMMON current state world mutual beliefs intentions intentions In collaborative future action efficiency planning process affected agents algorithms communicative GROUND II9140 add mutual beliefs plan efficacy final plan discourse model conversants attempting It obvious choice However previous work systematically varied factors affect communicative choice resource based REDUNDANCY assumptions simplifying 78 147 14X To explore relation communicative choice limits task complexity Furthermore previous work CONSTRAINT apparently concomitant analysis naturally occurring collaborative planning dialogues communicative INFORMATIONALLY REDUNDANCY REDUNDANI IJTIERANCES IRUs defined as3 acts violate effective collaborative planning paper focuses CONSTRAINT These acts Definition informational DUNDANT discourse redundancy An utterance u INFORMATIONALLY RE situation S ii proposition II expresses said S II expresses proposition implicates p said S pL utterance nj pi utterance n entails p presupposes A statistical analysis tinancial advice corpus showed 12 Section 1 particularly definition IRUs reflects simplifying utterances IRUs As mentioned reflects definition entailments propositions definition reflects saying utterance discourse model The fact IRUs occur shows simplifying no1 valid LOGICAL OMNISCIENCE ASSUMPTION propositions uttered NO AUTONOMY inferences discourse discourse model 4 The merely adding p assumptions assumptions For example assumes II expresses proposition p sufficient discourse certain default ASSUMPTION assumes surprising uttered The distributional analysis suggests functional categories IRUs Communicative l Attitude functions IRUs provide evidence supporting beliefs mutual understanding acceptance The definition variation Hirschbergs detinition redundant S9 basis information theoretic work theory scalar implicature This view information ab 16 1 4 Presuppositions implicatures tuo type5 default inferences tagged defaults separately entailments hut evidence analysis II31 I 44466982 functional I24 I The corpus difference MA WalkerArtijicial Infelligence 85 1996 181243 185 manipulate locus attention discourse participants augment evidence supporting beliefs certain inferences Attention making proposition Consequence licensed salient IRUs ANTECEDENTS content IRU direct assertion inferential uj antecedent realized definition IRUs relations ture relations features intonational relation IRU adjacent utterances logical IRU antecedent dialogue utterances originally chain functions struc analysis analyzed utterance realization IRU form IRU ui The communicative features based textual distance discourse identified correlations distributional relations The distributional Below I briefly examples type IRU For explain simplifying utterance task properties IRUs function hypothesized informationally assumptions redundant Then consider hypothetical previous dialogue models predict type I agent 21 Attitude IRUs supporting speakers attitude IRUs provide evidence demonstrating Attitude acceptance agent declarative utterance 726 M H discussing invested occurring CAPS dialogue An Attitude given examples ANTECEDENTS individual retirement IRAs IRU said falling beliefs mutual understanding assertion proposal typical 727 M repeats H asserted funds M husband handle In 7 naturally IRUs italicized IRUs accounts intonation 7 24 H That correct It moved thousand 25 M I 26 H Without penalty 27 M WITHOUT PENALTY 28 H Right 29 M And fact I account couple years ago I working doesnt affect s Each communicative function given includes number subtypes hypothesis tested experiment model attentionworking IRUs rehearsal mechanism In addition aid memory examples propositions agents The hypothesis hypothesis considered indications hesitation planning disfluencies IRUs IRUs 1311 I evidence think agents represented repeat memory DEAD AIR For example long pauses associated support Header prccondition wantprecondi Lion cffcct __ _____ _ INPORMC speaker hearer proposition KNOWI spcakcr proposition speaker want INFORMS speaker hearer proposition KNOWI hearer proposition Fig t_rtlnlllon 01 INFORM pian operalor 1 I The IRU 27 provides direct evidence According indirectly serted arguments elaborated evidence provides M heard exactly H said 82 I 1 1 13 I 1331 Ms response believes H accepts The classilication 727 1 311 IRU lillows horn NOAUTONOMY ASSUMP operator IlON The NOAUTONOMY cooperative FORM planning words cooperative speaker previously response Hs inform ASSUMPTION helpful For example motivation usually characterized 12 Fig I hearer hearer accepts believes asscrtcd But effect INFORM cooperative agent plan effect IN In knows act goes IRU 727 reason M choose produce Attitude f 726 In recent work plan clfect shown Fig I treated default 5 I 6796 105 J inferring 51961 rule handles default acceptance assertions default rule CDR2 handles Pcrraulta bclicl transfer form acts Grosz Sidncrs conversational default acceptance proposals ceptancc assertion P proposal hearer hearer previously believed intended P However Attitude default hearer previously believe intend common paraphrases response inferring inference ac achieve P depends cooperativity achieve situations reason cooperative IRUs repeats caller asks talk host question question Attitude In advice givin g dialogues In cases default IRUs arc produced P Attitude achieve hearer IRU 9202 1 They allow undcrstandin g implicitly Clark Schaefer proposed Attitude standing explicit positive evidence bc sufficient However Clark Schaefer address distinguish Icss positive evidence lead agent produce Attitude IRUs provide positive evidence conveyed current purposes transfer indicating acceptance Further require features current purposes predictions indicating understanding question belief IRU Thus predictions acceptance goes default addition defaults positive evidence model makes agent produce Attitude IRU inference Attitude IRU In order explain function Attitude IRUs NOAUTONOMY replaced assumption accept rcject utterance act intended In Section 3 observations dialogue Results testing hypotheses incorporated ASSUMPTION hearers explicitly implicitly beliefs intentions planning produce Attitude model collaborative choice change related MA WalkerArtificial Intehgence M 1996 181243 187 IRUs presented paper 22 Consequence IRUs 131 133135 discussed Consequence IRUs inferences explicit For example consider 817 8 15 H Oh IRAs available long participant existing pension J Oh I Well I work I work company pension 16 17 H Ahh THEN YOURE NOT ELIGIBLE FOR EIGHTY ONE In 8 815 realizes biconditional inference realizes inference tax year 1981 inference rule 816 instantiates rule modus LOGICAL OMNISCIENCE AS 815 tollens follows premises rule 817 particular 816 The definition 817 IRU follows utterances occur However 817 SUMPTION If entailments model artificial agents logically omniscient inference heavy planning rules 721 especially processing time relevant inferences 4555637395 automatically added known discourse human Agents know relevant speech real time producing interpreting requirements Thus plausible hypotheses l HYPOTHCl inference explicit Agents choose produce Consequence IRUs demonstrate l HYPOTHC2 Agents choose produce Consequence IRUs ensure agent access inferrable information These hypotheses In addition IRUs ensure manner inference motivated fact agents logically omniscient produce Consequence timely information case hypothesis C2 agents choose agents access inferrable believe agent capable making principle However communicative efficiency said Thus plausible relies fact agents refinements hypotheses Cl inferences C2 l HYPOTHC3 The choice measure hard inference produce Consequence produce Consequence IRU directly related IRU directly related l HYPGTHC4 The choice measure important inference l HYPOTHC5 The choice degree produce Consequence IRU directly related task requires agents coordinated inferences hypotheses entails Confirmation hold processing goals FEWEST UTTERANCES ASSUMPTION conversational achieving relevant effort 23 Attentiorl IRUs Attention IRUs manipulate locus attention discourse participants making proposition related f 9 said agent A agent B walking assertion proposal salient Attention speaker work IRUs realize facts inferentially making For example consider 9 Lets walk Walnut St b ITS SHORTER Agent B knew Walnut Street route shorter REDUNDANCY CONSTRAINT A simply said 9a 9b IRU reflects The classification agent knows available UNLIMITED WORKING MEMORY reasoning agents include utterances 9b However choices human agents limited attentionworking memory 59195 artificial agents limited time access memory If assumption communicative known resourcebounded limited attentional capacity If define SALIENT propositions accessible agent particular point 9b provide B salient reason Similar observations IO apply time 1 102 1031 possible hypothesis accept As proposal resource limited A said walk Walnut St 10 Clinton stand abortion rights poor women b HES THE PRESIDENT difference lob In order Here salient reflect PROPOSAL salient WARRANT assertion 6 reason known discourse participants account lob modify saying specific hypothesis utterance type hetween 9a lOa Utterance 10a INFORM In IO A said lob accept As assertion Clintons obligations Utterance makes provide B As 9b 9a adopting As proposal 9a f lob SUPPORT belief l HYPtYIAI Agents produce Attention IRUs support processes deliber ating beliefs intentions production 01 Attention limits limited working memory Hypothesis Al means fact agents basis deliberation The hypothesis salient DISCOURSE INFERENCE CONSTRAINT information support interpretation IRUs surface manifestation accessibility function Attention reasoning formulated beliefs IRUs l HYPOTHA2 There DISCOURSE INFERENCE CONSTRAINT effect inferences salient working memory dialogue derived propositions currently discourse The relationship 189 1 inference speakers views functionally intention equivalent 16 I 93 I utterances ha characterized inference discourse relation 192 1 Moser Moore Hobbs argued MA WalkerArtcial Intelligence 85 1996 181243 189 The DISCOURSE INFERENCE CONSTRAINT general A intends B deductions commonsense WARRANT inferences inferring As plan inferring dialogue defaults related inferences logical relations SUPPORT 92134141 illustrating agents communicative A complex inferential processing telling H talk host money question relationship 113 example choice dialogue limited working memory 11 The caller E invested poses 11 3 4 5 6 7 8 E I wonderingshould H Well difficult But I suggest presume E yes H I E uh huh H Now addition old I continue certificates tell far away 6 month certificates I thisif like start spreading money discussion retirement investments consisting 14 utterances 21 22 23 24 E uh huh H But far certificates concerned b ID LIKE THEM SPREAD OUT A LITTLE BIT c THEYRE ALL 6 MONTH CERTIFICATES E yes H I dont like putting eggs basket realize hypothesis investments utterances discussion retirement 22b 22 47 retirement 47 information established mutually 8 22a H believes propositions IRUs Utterance Since information The utterances initiates subdialogue lieved invest digression discussed ments consists 14 utterances expressed plausible 1361 However H expects E use information 4 7 longer salient inferences INSTANCE OF negatively evaluated condition having eggs basket spread certificates 2 contentbased little bit Here infer inference WARRANT ence INSTANCE OF case deliberationbased second H basing communicative CONSTRAINT In addition choice DISCOURSE INFERENCE types inferences having investments E adopt intention WARRANT examples Attention 6 month certificates H produces naturally It appears ensure inferences occurring IRUs 1 DISCOURSE INFERENCE CONSTRAINT distribution evidence inferences 22 Fig 2 contrasts explicit distribution Consequence Consequence IRUs source IRUs IRU dialogue B Section IRUs paraphrases Antecedents Antecedents salient salient 24 x 43 39 Consequence IRUs Paraphrase IRUs Fig 2 Distribution Consequence IKUs inferences explicit compared paraphrases according antecedents currently salient logically inference rule modus ponens A key difference syntactic semantic distinguished IRU relate transformations paraphrases requiring prior discourse7 arc IWO different ways single antecedent utterance Paraphrases 65901 Inferences application logical inferences multiple antecedents paraphrases A priori expect inferences paraphrases If I This distributional CONSTRAINT evidence salient premises likely INFERENCES y 4835 p 005 DISCOURSE INFERENCE inference salient s However Fig 2 shows distribute differently respect types entailments lo salient premises fact provides evidence PARAPHRASES antecedents likely The data discussed provide evidence DISCOURSE INFERENCE CON clear STRAINT limits working memory inferential multancously follows directly salient inference complexity effect constraint strongly determined corollary constraint In particular related number premises These hypotheses summarized si l HYPOTHA3 The choice produce Attention IRU related inferential taskrelated complexity inferences task measured number premises degree required l HYPOTHA4 The choice resource agent produce Attention limited attentional capacity IRU related degree obvious Finally inferential Consequence sis AS complexity tasks characterized observations IRUs apply belief coordination Attention terms degree IRUs giving hypothe similar l HYPOTHAS The choice task requires agents produce Attention IRU related coordinated inferences degree In sections WC test hypotheses The categories repetitions making implicatures explicit making presuppositions explicit For corpus analysis salient utterances turns This measure perfect replicable MA WalkerArtificial Intelligence 85 1996 181243 191 3 Modeling resource limited collaborative planning dialogues The naturally occurring examples discussed section gave rise previous communicative situations improve plan constructed efficacy collaborative include choices plan efficiency details planning basis dialogue hypotheses tested In thinking models terms features In section I specify I useful consider models number hypotheses IRUs dialogue model collaoorative simulation testbed collaborative ii limits mutual beliefs resources aspect resource consumption planning agent architecture role resource limited minimize mutual belief model mutual beliefs defaults utterance act types types acts available agents effects act cognitive collaborative mixed initiative 9 plan evaluation good collaborative planning planning process initiative agent plan dialogues collaborative iii iv v vi agents constructing plan attempt maximize collaborative aspects function dialogue mutual belief model binary allows establish agents communicate state agents initiator agents equal plan evaluated factors deter precise models hearers specific Most accounts collaborative features For example features accounts provide rich models particular provided Smith Guinn provide richer model mixed 53117 infer utterance act type 186112 1271 However intention communicative knowledge previous work included specification agent architecture relationship plan evaluation process The remainder section provides specification features limits language behavior role resource architecture particular underlying initiative action 3 I Agent architecture mutual belief resource limits Both agent architecture role resource agent architecture based IRMA architecture Fig 3 7991 The IRMA architecture behavior agents dialogue The basic components modified IRMA architecture previously model resourcebounded limits addressed adopting agents shown y This called control natural dialogue control agents primarily known agent primarily determined 52139 1161431 Walker Whittaker Guinn argued information relevant distribution task distributed BELIEF DELIBERATION ATTENTIONMiORKlNG MEMORY AWM MEANSEND REASONER FILTERING MECHANISM I COMPATIBILITY FILTER I I MESSAGE PLANNING mediated dialogue strategies I V INTENTION DELIBERATION COMMUNICATIVE ACTIONS Fig 3 The IRMA agent architecture resourcehounded agents limited attention AWM degree database agents intentions This includes decides agent wants believe conflicting Beliefs database agents beliefs This includes beliefs agent believes mutual Belief deliberation evidence Intentions believes Plan library agent knows plans recipes Meansend options Filtering mechanism plans Options deemed compatible agents existing passed deliberation process reasons existing partial plans proposing plans agent mind compatibility serve subplans achieve goals degree checks options mutual agent intentions reasoner The filtering mechanism presented I 7 j TileWorld complex presented work explored issue current intentions overridden MA WalkerArtcial Intelligence 85 1996 181243 193 types desires I assume 341 agents different maximize utility Desires desire Intention deliberation based desires maximizing Attention working memory ing memory retrieval current beliefs intentions meansend decides set options reasoner utility AWM limited attention module constrains work pursue evaluation architecture extended model For purpose modeling dialogue allows different degrees mutual belief For purpose mutual belief exploring architecture extended model limited attention All modules standard AWM module described mutual belief module briefly described effects resource bounds attention Attentionworking memory model The model limited AWM cognitively results human memory learning based model adapted 761 4315775118121129 cognitively based model AWM model naturally occurring dialogues test theory collaborative behavior commu fits empirical The motivation agents nication humans The key properties model 1 model varied recently likely salient likely salient 581 These recency frequency explore different limits 761 3 hypothesized model role testing hypotheses functions IRUs Below I discuss particular effects key aspect AWM model testing implementation limits AWM parameters items encountered items encountered frequently 51 2 chronological world stored modeled threedimensional space propositions sequence according AWM perceiving moving memory pointer The sequence memory random walk memory loci short distance items encountered multiple times stored multiple sequence storage locations stochastically simulation location previous If 581 The fact times random means recency frequency effects simulation loci storage constitutes determined This means model produces different results time acquired When agent retrieves items memory spreads spherical fact search location follows Hamming distance For example distance actual 1 away 010 locations calculated modulo fashion The resource particular restricted current memory pointer 001 search starts current pointer limited aspect AWM search radius defined loci 0 0 O loci The 100 OIO 100 00I memory size I Some features model hold processors discussed recently likely accessible little effort incoming displace information general feature working memory items information I1 MA WulkrArtificud lnrellrence X5 1996 It243 The limit search radius defines subset belief intentions database fact pointer moves effect salient changing Effectively new facts added displaced SALIENT In addition subset longer salient SALIENT predicate AWM parameter limit defines test effect different Section 5 order dynamic varied The search resource radius Landauer performed showed task requiring ex limitations remembering periments Experiments word belonged AWM 7 reproduces tests performed investigated Human performance model parameterized list words human performance human performance 571 Since systematic tasks collaborative run LOW MID HIGH AWM settings planning results fall middle ranges experiments assumed The model attentionworking memory DISCOURSE INFERENCE CONSTRAINT introduced hypothesized discourse member propositions derived shown Fig 3 limits subset beliefs defined SALIENT inference constraint currently beliefs accessible currently AWM provides means testing Section 23 Re discourse working memory The AWM model meansend reasoning deliberation inferences states AWM 55666895 These beliefs This model contrasts standard view inference agent believes inference constraint P believes P Q agent believes Q The discourse provides principled way limiting premises P P Q salient An axiomatization SALIENT inference rules follows inference inference modeling humans requiring requires predicate rule schema 6 1 1331 Irlfkrencr discoursr irrerlce cwstmirlt SayAB PI 4 SalientB PI SalientB P A BELB P A SalientB P Q A BEL B P Q BELBQ The inference proposition P P proposition P inference B use SALIENT predicate holds rule states agent A says utterance rule states B The second salient rule P t Q believed B salient B realizes B infer Q The model AWM consulted determine The model mutual belief belief 16 19841 extended beliefs qualitative beliefs database left inference inferences endorsements based Lewis shared environment model mutual support different degrees mutual belief tagging time formed stored 29 401 421 Different degrees mutual belief allow actions defaults This makes possible distinguish MA WalkerArtijicial Intelligence 85 1996 181243 explicit acceptance proposal acceptance proposal absence evidence possible information distinguish contrary When agents logically omniscient mutual beliefs mutually discussed dialogue See 131133 195 inferred inferred 32 Discourse acts utterance acts mixed initiative The overall structure discourse collaborative planning dialogues primarily determined task structure dialogue segment task Each subpart task consists agents negotiate 4985100111 As discussed Section 21 wish abandon ASSUMPTION dialogue initiate subdialogue initiate The model allow agent new task 32139 For agent able knowledge task distributed participant basis meansend NO AUTONOMY deliberation participants reasoning Furthermore agents able ACCEPT REJECT anothers proposals remain open negotiation coming collaborative plan higher agreed Each plan step contributing agents committed level goal This contrasts models initiator makes accepted noninitiator work collaborative plan substep noninitiator proposals level goal higher 2651 plan Discourse acts mixed initiative To engage collaborative planning agents turns sending messages turn consist DISCOURSE ACTS Discourse acts OPENING CLOSING PROPOSAL ACCEPTANCE REJECTION CLAFURCATION These higher level acts composed primitives called UTIERANCE ACTS described The schema discourse actions shown acts discourse acts combined schema For step domain plan Fig 4 controls single sequence discourse turn I2 The discourse act PLAN basis algorithm agents achieve COLLABORATIVE ii iii iv reasoning subdialogue options agents perform meansend agents deliberate options preferable individual individual agent initiates agent based options actions proposal subject CEPTED REJECTED agent calculating utility satisfaction goals consisting minimally reasoning contribute identified CLARIFICATION AC maximizes domain PROPOSAL cycle I2 This schema discourse action transitions required extension allow multiple proposals simultaneously type dialogue open f 1071131 80811 IO One KEY Speaker Chanpr Possibly NO Sprnker Change e _ Miy IMlLIIT ____________ OPENING ___ v PROPOSAL I CCEPTANCE 1 ___________ REJECTlON I CLARIFICATION I This algorithm The requirement follows COLLABORATIVE PRINCIPLE ties discourse act schema agents indicate replacing assumption cooperativity Fig 4 IRMA architecture accept reject proposal earlier work 2511 l COLLABORATIVE PRINCIPLE Conversants provide evidence detected discrepancy belief soon possible PRINCIPLE WLS proposed PLANNING PRINCIPLES Whittakerand 1391 The COLLABORATIVE PRINCIPLE means Stenton 13 I 1 abstraction 1431 Walker speakers If action hearer order detect effects utterances dialogue provides evidence belief discrepancy The COLLABORATIVE COLLABORATIVE Whittaker monitor hearer continues inference acceptance licensed default 1391311 IRMA agent architecture The fact agents evaluate assertions proposals deciding Fig 3 As figure intention belief ASSUMPTION agents assessing Fig 3 shows use believe intend follows shows incoming messages intentions deliberation This provides specifying 34384 support evaluation beliefs serve supports warrants salient processes warrants takes place constraints rvhy agent accept reject agents proposal I Agents evaluate assertions proposals limited working memory basis abandoning proposals Finally beliefs subject No AUTONOMY assertions Utterance ucts Fig 4 shows discourse act schema acts composed utterance actually perform Each discourse act performed provides acts primitive basis dialogue Discourse acts agent different ways varying MA WalkerArtificial Intelligence 85 1996 181243 197 number type utterance include additional acts consists For example proposal 9 hearer example convince information There seven utterance act types OPEN CLOSE PROPOSE ACCEPT REJECT ASK SAY realized schemas speaker hearer option Propose Ask speaker hearer belief Say speaker hearer belief speaker hearer option Accept Reject speaker hearer belief Reject speaker hearer option Open speaker hearer option Close speaker hearer intention meansend The content utterance act OPTIONS INTENTIONS representing domain plan act constructed reasoning 3 An OPTION act committed agents act committed intention implicitly The option current proposal deliberation shown Fig agents An INTENTION 7991 An option plan ACCEPTED agents explicitly rejected REJECT schema counterproposal collaborative The content utterance act belief These beliefs agent inferences ASK actions variables belief schema rejection agent starts beliefs communicated agent conversation Beliefs addressee speaker believes option instantiate The belief reason attempts reject proposal belief preconditions proposal hold 139 1 Examples utterance acts dialogue given B processes seven messages specified Store means store AWM eventual database The processing reference IRMA agent architecture Agent A Propose speaker hearer option Section 4 Below In effects storage beliefs involved incoming message understood A send specified longterm Agent B Filter check option compatible current beliefs current beliefs contradict Infer store preconditions MEreason reason b c Meansend preconditions option intention option contributes d Deliberate meansend Indicate e evaluating reasoning option options generated results deliberation accept reject ii Agent A Ask speaker hearer belief Agent B Retrieve beliefs matching speaker hearer belief variable Belief belief memory instantiated respond matching 198 iii iv f vi vii viii Agent A Say speaker hearer belief Agent B Store beIief Agent A C Accept speaker hearer option I3 Agent B Store intend A B option 1 h Store acteffects Agent A Reject speaker hearer option Agent B Deliberate option option comparison current proposal better current proposal reject reason rejection If rejecting option rejected t11 Accept option c Agent A Reject Agent B Store belief Agent A Open speaker hearer option 1 Agent B Mark discourse segment Agent A Close speaker hearer intention Agent B Close discourse speaker hearer belief segment matches option open intention These acts effects determine structure dialogue effect mental state converaants 33 Plati evaluation There components plan evaluation process different effects collaborative model evaluation applied planning Two features related task definition iii iii intended beliefs related degree belief coordination itztetztiotzs associated plan mutually intended acts mutually believed fault tolerance task determinacy fault tolerant satisfiable model specify optimized resource consumption minimized task solution performance evaluation planning Different theories collaborative required agents belief coordination require divide plan requiring agreement subcomponents coordination mutually reflect different views degree agents collaborative plan The minimal approach 35531 Rather agents establish mutual beliefs separately plan component planned At level belief plan level belief coordination intended acts collaborative 5179 125 1271 At highest subcomponents common require intended I7 This ih simpiitication form acceptance determines endorsement type mutual belief added beliefs database This represents agents committed option binding option specifies agent execute option h4A WalkerArtijcial Intelligence 85 1996 181243 199 agents mutually support plan In addition intended plan WARRANT possible intend intentions beliefs require actions satisfy mutually believed mutually believe beliefs provide reasons inferences adopting step goals In work assumption degree belief coordination experiments discussed experiments vary intentions required derived explicitly discussed level intended feature task The minimal intentions mutually WARRANTS inferred mutual Task determinacy intentions effect communicative fault tolerance directly planning plan If partial plan utility collaborative tolerable constructing measure quality final plan determined plan partial plans evaluated satisfiable partial plan related choice uncertainty making mistake utility step task I assume catastrophic For task determinacy With respect evaluating performance I assume agents working team team attempt dialogue minimize planning teams performance Clarks assumption purpose LEAST COLLABORATIVE approaches maximizes conversants 351 A final choice processes expected utility teams consumption dialogue attempt EFFORT 182122 agents participate communication collaborative optimize resources This follows achieve dialogue This approach contrasts degree collaborative effort consists A primary efficiency measure ASSUMPTION Since types IRUs 2 3 planning memory defined reference collaborative stored beliefs interpreting utterances required effort number utterances FEWEST UITERANCES work collaborative processes assumption assumption common 15471 violate agent architecture 1 retrieval processes necessary related communicative reasoning processes agents With respect communicative inferences filtering Collaborative processes combined processes access AWM plan access previously generating IRMA architecture operate beliefs stored memory communicated Fig 3 retrieval processes databases generation messages costs agents processes library beliefs intentions processes deliberation meansend modules effort includes perception reasoning COLLABORATIVE EFFORT total cost communication agents total cost inferences agents total cost retrievals agents Collaborative This definition process Given quality problem effort defined dialogue utterance basis specification plan evaluation difference measure assumptions definitions support performance solution COLLABORATIVB EFFORT 700 MA WalkerArtijcial lntelliqence 85 I 996 1X1243 PERFORMANCE QUALITY OF SOLUTION COLLABORATIVE EFFORT Since agents desires simply maximize utility quality solution measured utility resulting plan respect agents utility functions 4 DesignWorld 41 Methodological basis Design World DesignWorld testbed model collaborative theory collaborative planning use DesignWorld dialogue discussed developing testbed theory communication collaborative instance general method describes planning communication Section 3 In testing describes testbed parameters The method section stantiates order motivate feasible DesignWorld implementation characterized task communication steps Generate hypotheses features model collaborative planning dialogues statistical analysis humanhuman dialogue corpora ii Produce functional characterization model specifically affect task outcome claims including efficacy iii model testbed independently motivated modules parameters aspects parameters model Implement controlled testbed The hypotheses discussed resource bounds belief coordination effort increase The step C iv Test hypotheses resulting model different situations controlled parameter settings generated statistical analysis dialogue corpora Section 2 These hypotheses constraints roughly task inferential complexity communicative task fault tolerance task requirements choices include IRUs reduce collaborative plan quality solution collaborative produce functional characterization model features model collaborative partial planning choices resource claims motivated limits communicative In Section 3 I discussed formalization In interact agents autonomy work model final result research However leaves nonexperimental In formal model empirically model need characterizations simplifying assumptions clear results carry complex domains simplifying hold While model presented empirically based statistical analysis corpus naturally occurring dialogues hypotheses discussed provide weak models agents processing Corpus analysis related desirable support hypotheses Thus source empirical verification order develop wellspecified DesignWorld theory This motivation defeasible assumptions unverified testbed MA WalkerArtificial Intelligence 85 I 996 181243 201 consider parameters Next necessary affect outcome claims efficacy model implement model testbed parameters controlled The use independently motivated modules aspects testbed guarantees small testbed makes testbed actually case experimentation tests likely 1541 Parameters affect efficacious use IRUs discussed complexity requirements belief coordi resource bounds implemented independently limited agents task inferential resource bounds include nation The AWM model introduces parameter IRMA architecture resource motivated duces simulation wellknown utterance In addition research collaborative corpora 1217106113120127139143 7991 The AWM model independently motivated repro 76118 results human memory learning acts effects independently motivated planning dialogues statistical analysis dialogue related tasks testbed To introduce parameters agents form collaborative rooms tworoom house The task based cooperative design experiments available inferential errors usefulness partial solutions task plan arrange furniture tasks cooperative work corpus dialogues 1 2 degree belief coordination designed simple task varied 1421 However dimensions distributed complexity simple tolerance required 3 These task dimensions inferential task increasing agent communication dimensions tasks Section 42 introduce task variations enable generalize algorithms represent different complexity provides simple versus tasks For example varying performance complex information inferentially specific task DesignWorld tasks The realworld Standard version task Section 44 To introduce parameters related interaction communicative choice task complexity tion strategies tive choice parameters The experiments resource limits agents designed IRUs Section 45 vary communica communica include include experimental reported Section 5 examine limits 2 communicative strategies 3 testbed 1 resource iments implemented vide empirical verification hypotheses function particular communicative provided corpus analysis researchers strategies tion describes collaborative domain domain communicative strategies task variations intuitions This sec flaws model highlight potential 1 demonstrate implementation planning model functions 3 2 results presented Section 5 interaction factors task definition The exper model pro 42 Design World collaborative planning domain In DesignWorld artificial parameterizable design floor plan tworoom house agents converse order agree 133142 The DESIGNHOUSE plan 203 MA WdkerArtficrul Intellipxce 85 1996 IXI243 SJ 54 KEY F FUCHSIA C GREEN P PURPLE P El G PI G 53 ROOM I IDESIGN WORLD OLLABORATIVE PLAN 434 points Fi g 5 One tinal state DesignWorld Standard task represents collaborative plan achieved dialogue 434 points agents requires beginning simulation plan requires furniture negotiated simulated agree DESIGNROOM1 DESIGNROOMT At agents know structure DESIGNHOUSE room Each agent 12 items design plan final collaborative furniture items plan A potential shown dialogue Each furniture Fig 5 item value WARRANT support deliber basis calculating Section 3 The values items range furniture values test hypotheses ation utility act consideration QUALITY OF SOLUTION final plan discussed furniture items range 10 56 agents values Since beliefs function IRUs agents know values furniture dialogue DesignWorld ning algorithm furniture OPTIONSthese item furniture artificial language language agents negotiate collaborative discussed italics designing room This items design Meansend options content PROPOSALS agent illustrated dialogue agents communicate gloss automatically plan reasoning reasoning generates Section 3 Each agent carries meansend PUT items beginning collaborative plan following 12 generated room I includes 12 1 2 agentbill BILL First green rug it1 study Propose agentbill putact KIM Then lets green lamp itz study Propose agentkim putact agentkim option 10 green rug room 1 agentbill option33 green lamp rooml agentkim MA WalkerArtcial Intelligence 85 1996 181243 203 3 4 5 6 agentkim option45 green couch rooml lets purple couch study agentbill option56 purple couch room 1 BILL Then lets green couch study Propose agentbill putact agentbill KIM No instead Reject agentkim putact agentm BILL PUTTING IN THE GREEN COUCH IS WORTH 56 Say agentbill score option45 BILL Reject agentbill agentbill putact agentkim bel265 agentbill It better green couch study agentkim option56 green couch room 1 green couch rooml putact 56 agentkim dialogue At beginning score green rug 56 When receives Bills proposal shown accept reject evaluates evaluating score proposition memory Thus supporting deliberation decide retrieve scores furniture order attempt proposal proposal propositions memory stored proposition 121 As stored earlier items WARRANTS PRINCIPLE discussed ACCEPT REJECT 34135 Proposals As discussed Section 3 agents retain implicitly ACCEPTED want agree plan designing agent deliberates inferred follows ACCEPTED proposal mutual 1311 COLLABORATIVE explicitly implicitly intention contributes Agents REJECT proposal deliberation autonomy agents house Thus receiving proposal 1 2 139143 This content 101113 Section 3 If proposal final design plan rejected option better option based evaluating generated meansend 123 pursuing rejection counterproposal nicated PRINCIPLES 1391 When agent 125 126 125 agentbill agentkims reminds agentkim proposal reasoning For example option45 based observations proposes option56 leads 124 Kim rejects believe utility competing know options proposal instead The form commu PLANNING In value green couch rejecting reject agents support rejection proposal COLLABORATIVE rejection information intends naturally occurring dialogue codified agent includes additional 43 Agent architecture implementation Design World The agent architecture DesignWorld simulation ified IRMA architecture aspects architecture AWM implemented For experiments Fig 3 discussed shown specific DesignWorld way belief deliberation plan library implemented total size AWM set 16 memory retraces If path memory pointer overwriting wrap steps environment mod Section 3 7991 The way 204 MA WulkerArtijiciul lntellipnce X5 1996 IYl243 current memory simply added Thus memory capacity unbounded loci stored new item Since hypothesis A4 relates degree able compare Thus experiments comparisons ranges AWM performance settings agents attention AWM limited want limited strategies search radius parameter varies LOW communicative different AWM radius 3 4 lo MID AWM agents arc severely attention radius 6 7 HIGH AWM radius 01 limited agents wherease AWM 1 I 16 LOW AWM agent knows salient HIGH AWM agents The salient deliberation belief deliberation agent accept Landauers AWM model The limits AWM plays critical role determining bcr salierzt beliefs meansend proposal warrant agent knows option proposal However proposal assumption impact resource implementation agents performance Remem reasoning agent properly evaluate better Section 5 option limits performance For details 761351 present Thus agents belief deliberation purpose DesignWorld tied directly deleted modified Rather new beliefs added effectively compete process depends beliefs applying algorithm collecting set related beliefs contradictory determine agent believes emergent property belief state world supercedes old information retrieval mechanism stochastic aspect retrieval means believe decide outofdate world As casts outdated beliefs encountered Section 5 means greater frequency repeatedly agents access beliefs likely beliefs recently added likely retrieved However 39431 The fact new information believe date beliefs forget recent changes In model possible stored agent propositions memory memory decide stored The plan library contains domain plans discourse plans discussed discourse acts shown Section 45 11 Design World tasks Designhouse Fig 4 The discourse plans subgoals The DesignWorld task plan simple involves higher level goals shown contribute modified difficult testbed performance according general perform These modifications task affect degree evaluation Fig 6 However task features discussed applicable tasks different aspects task contribute linear planning subgoals task easily I5 It unclear mance However predict For example I previous evening prediction belief deliberation algorithm easy think examples humans making kind error I commonly believe falsely I eggs home refrigerator consistent human perfor model quiche MA WalkerArtijcial Intelligence RS 1996 181243 205 DESIGN HOUSE DESIGN ROOM 1 DESIGN ROOMZ Fig 6 Standard version task fault tolerant partial solutions acceptable There versions task test hypotheses Matchedpair simple fault tasks difficult tolerant requires task inferentially The Section 2 Standard Zerononmatchingbeliefs Standard coordination belief coordination beliefs Matchedpair inferential complexity The Zeroinvalids required magnify task fault intolerant effect mistakes The Zerononmatching tasks explore different aspects belief coordination introduced Zeroinvalids The low levels belief degree increase Standard task low The Standard levels belief coordination valid step plan task provides baseline inferentially fault tolerant requires QUALITY OF SOLLJTION particular dialogue consists sum furniture task defined partial pieces items room valid plan solutions items This choice task requiring determinacy makes different restrictions resource room furniture gradient effect performance possible Any number furniture The Standard In addition possible defined simple task In addition Standard task fault tolerant If agents mistake planning invalid steps collaborative plan subtracted score Thus making mistakes inserting point values invalid steps task agents Standard steps plans task insert plan simply heavily penalized actually executable The Standard meansend options acteffect relies premise premise option supports multiple premises processing inferentially reasoning inferences premise simple generate options committing agent item supports deliberation score item score inferring simultaneously effort Standard salient However task making inferences agents deliberation evaluate action Each inferences reasoning intend A B requires test hypotheses easier access inferential supports meansend premise possible effect option Thus processes MA WulkerArrQiciul Inlellixcr 8S 1996 181243 DESIGN ROOM I IESICiN ROOM2 I Fig 7 Tasks differ level tnutual beliet required Some tasks require W reason I mutually believed dont It possible test effect resource limits premises premises accessible perform optimally task The degree belief coordination Standard coordinate intentions intentions corresponding explicitly discussed task low agents putacts shown coordination required Fig 6 These achieved The Zerononnzatchitlghrlirj task The Zerononmatchingbeliefs task increases agents base deliberation adopting intention requiring WARRANTS shows structure beliefs In Zerononmatchingbeliefs mutually believed This generally agents A B mutually believe necessarily agents option consideration option order decide agreeing utility intentions task shown warrants underlying required warrants degree belief coordination process beliefs They order task Fig 7 goal intentions forming collaborative plan maximized utility general case utility need evaluate Designhouse Furthermore accept reject The Zerononmatchingbeliefs AS introduced perform task beliefs deliberation Section 2 increasing task provides basis testing hypotheses Al degree belief coordination required task models particular tasks agents agree reasons carrying particular types realworld The Zerononmatchingbeliefs necessary action For example company agreement An agreement pay possible companys plan different negotiation reached agreed party different union management reasons shorter work week supported union overtime want work supported management insurance premiums lower However reasons change agents agree beliefs MA WalkerArtijcial Intelligence 85 1996 181243 207 MATCHEDPAIR 2 KEY P PUTAFRT Fig 8 Making additional inferences Matchedpairtworoom task Each PUT intention contributes Designroom goal Matchedpair goal different conditions agents agree actions Under The stable longterm collaborative performed actions conditions agents task examines extreme belief revision revise intentions compatible way intention Zerononmatchingbeliefs deliberation intentions plans reasons likely simpler Thus coordination Matchedpair tasks number independent Another aspect belief coordination inferences There task definitions creasing working memory These 1 Matchedpairsameroom room Fig 8 shows PUT furniture ing matched pair goal A Matchedpair inference Matchedpair Matchedpairtworoom item room potentially increase furniture contribute premises coordinating inferential simultaneously complexity beliefs based available 2 Matchedpairtwo version task Each intention intention achiev items color The based minor premises shown 13 13 b c Intend A B Put agent item1 room1 Intend A B Put agent item2 room2 Color itemI Color item2 Equal demanding resource limited agents processing inference Standard Making needed plan available access tasks contribute accessed furthermore premise WAFZRANT task In Standard task order agents access belief furniture In order evaluate properly w ARRANT option option represented In contrast agree step item item furniture Matchedpair 13 items beliefs accessed furniture Matchedpair goal In addition version Matchedpair premises task requires additional Fig 9 In Zeroinvalids task invalid steps invalidate plan tasks Matchedpair rooms Matchedpairsameroom The difference different Equal room 1 room2 Matchedpairtworoom NOT Equal room1 room2 Because premise memory time proposal room starting salient additional premise agents complete necessary premise shown 13a likely requires 13a inferred stored matches additional premise Matchedpairsameroom requires accepted task As discussed Sections I 7 WC wish provide test hypothesis A2 examine affects coordination inference inference constraint discourse collaborative inference measure inferential draw inference Matchedpairsameroom room task increase planning Hypotheses A3 A5 interact agents ability complexity complexity inferential imply complexity stay coordinated inferences Since required premises number independent task Matchedpairtwo Evaluating QUALITY SOLUTION Matchedpair inferences inferences Matchedpair phasis coordinating agents Matchedpair task measures agents coordinated inferred intentions Matchedpair counted sum utilities furniture 50 points explicitly agreed Only intentions tasks reflects em order score points matched pairs The follow contribute tasks require intentions final solution utility intentions items plus utility Matchedpair Zeroitlvalids task The Zeroinvalids task fault intolerant task mistake invalids determinacy 8 items counted valid solutions valid solutions Zero feature task possible 8 step plans solutions task Fig 9 The assumption plan This Zeroinvalids Standard invalidates task MA WalkerArtificial Intelligence 85 1996 181243 209 This intolerance tasks mistake invalidate task example extreme fault invalid step adequate For example tolerant task depends interdependency solution For partial solutions furnishing mistake assume room building plan invalid executed furnished tower step depends successful In general fault different subparts problem tasks solution task like couch chair agents room task step step foundation block use chair end different usable On hand room desirable execution previous partially Note agent reject agents proposal based believing add invalid step plan shown rejection utterance act schema Section 32 Since agents agree step plan invalid step inserted plan plan hold agents failed preconditions remember 45 Varying communicative strategies types utterance acts discourse acts composed controls agents participate discourse act schema Section 3 discussed dialogue discussed Which utterance acts discourse act decomposes STRATEGIES codify different communicative discourse placing different expansions action Agents parameterized discourse plans Varying agents communicative strategies provides ses potential benefits IRUs Varying act basis communicative Closeconsequence 3 Explicitwarrant strategies hypothesized limits solution Figs assumptions depends COMMUNICATIVE choices particular strategies different communicative plan libraries strategies 4 Matchedpairinferenceexplicit basis testing hypothe degree explicitness discourse 2 All resource definition quality 1 Allimplicit tested mitigate agents attentional inferential architecture plan operator acts integration task lo13 Walker Rambow discourse Sidners theory discourse precisely defined collaborative Section 3 Each discourse act proposal represents CONTRIBUTOR achieving strategy These operators draw work 1381 use Moser Moores definitions Grosz plan operators planning model agent architecture discussed composed CORE act primary purpose act propose utterance act likelihood act warrant purpose intention core 92145146 The predicates increase 50899394 rhetorical structure theory RST Allimplicit strategy The Allimplicit strategy PROPOSAL decomposes plan operator trivially Fig 10 This strategy expansion discourse plan PROPOSAL act PROPOSE See 3 choice shown communicative communicative 210 MA WdkerArticrtd Intelligence 85 I 996 181243 NAME EFFECT CONSTRAINTS speaker hearer act ProposalAllimplicit desire hearer hearer act utilityact option act salient hearer utility act utilityact CORE propose speaker hearer act Fig IO The IJKOPOSAI plan operator tbr Allimplicit agent Section 1 provides baseline strategy CONSTRAINT The experiments compare Allimplicit discussed In dialogue 12 Section 41 DesignWorld strategy performance agents consistent REDUNDANCY performance agents proposal strategies agents communicate I 2 3 As proposals information strategy proposals shown utterances Allimplicit Fig IO shows Allimplicit leaving agent strategy retrieve Allimplicit includes additional memory 2 reasoning The constraints agents parameterized OPTION generated meansend hearer In experiments consistently hearer knows proposal deliberate hearer accept reject proposal depends options knows Clearly proposal specify proposal operators strategy I proposed act SALIENT utility use strategy hearer evaluate act However hearer options Thus effect action intended hearer This holds agent salient The effect proposal degree strategy assumes speaker predict hearer desires Allimplicit The Allimplicit strategy agents Section 44 agents capable making tasks inferences accessing left implicit strategy Other inferences drawn IO For example leaving infer intention makes match option discussed memory hearer proposal utterance act shown agent use Allimplicit agent currently consideration tither Matchedpair DesignWorld strategy Fig tasks 14 agent CLC uses Closeconsequence Closeconsequence In dialogue strategy statements segment A contributor makes inference explicit study longer green rug acteffect strategy The plan operator explicit CLOSING C I42 completion intention associated discourse CLCs CLOSING discourse act IRU 143 CLC green rug agreed putting I I The core strategy inference shown Fig 14 1 BILL Then lets greetz rug study Propose agentbill putact agentbill agentclc option30 green rug room I MA WalkerArcial lnrelligence 85 1996 181243 211 NAME EFFECT CONSTRAINTS CONTRIBUTOR CORE speakerheareract Closeconsequence effect act effect act salient hearer be1 hearer intend speaker hearer act opensegment closedsegment act speaker hearer close speaker hearer act effect act effect Fig Il The CLOSING plan operator Closeconsequence agent 2 CLC So weve agreed green rug study Close agentclc agentbill agentbill putact intended30 green rug room 1 3 CLC AND WE NO LONGER HAVE GREEN RUG agentbill Say agentclc agentbill bel48 green rug naturally The Closeconsequence models explicit located close discourse DesignWorld occurring tasks discussed strategy making example inferences Section 22 In cases inference explicit close segment follows said inference sequentially segment This strategy agents Section 44 explicit inferences The Closeconsequence agents phase plan strategy test hypothesis C2 potential Allimplicit contrasted 12 Section 42 infererategy explicit inferences strategy closing acts produced benefits making strategy closing acts produced Note dialogue leaving test hypothesis C2 potential benefits making contrasted Allimplicit 12 Note inference acceptance plan However Closeconsequence experiments difficult capability Section 42 agents phase See 1371 discussion experiments vary agents agent good test hypotheses agents acteffect dialogue leaving inferences inferences closing inferences Explicitwarrant The Explicitwarrant strategy varies proposal discourse proposal The plan operator 15 Remember RANT IRUs dialogue excerpt adopting utility proposal mutually believed outset dialogues 15 WARRANT WARRANTS score propositions act including WAR given Fig 12 exemplified reason intention In WARRANT IRU 151 contributes core act 152 proposal intention 15 1 IEI PUTTING Say agentiei score option2 IN THE GREEN RUG IS WORTH 56 agentiei2 bel2 putact agentiei green rug rooml 56 NAME EFFECT ProposalExplicitwarrant speaker hearer act desire hearer hearer act utilityact salient hearer utility act utilityact CONSTRAINTS option act CONTRIBUTOR CORE C notsalient hearer utility act utilityact speaker hearer utility act utilityact propose speaker hearer act Fig I The IKOPOSAI plan oprralor Explicitwarrant agent 2 IEI Thelen lets greet1 rug study Propose agentiei agentiei2 option2 putact agentiei green rug rooml Fig 12 specilies effect The plan operator utility proposal option Explicitwarrant deliberation involved determining facts relevant memory A constraint Explicitwarrant proposal act salient salient Since warrants agent processing utility strategy save agent deliberation retrieving plan operator plan natural dialogues shown naturally occurring example In experiments agents parameterized result agent Explicitwarrant salient maintain strategy occurs dialogue C 2 dynamic model salient hearer See 1641 experiments This strategy agents use strategy consistently warrant strategy assumes agent attempts agent The Explicitwarrant Section 44 The Explicitwarrant IRUs support produce Attention It related In Standard agents hood agents coordinate steps In Zerononmatching degree task predicted DesignWorld tasks discussed strategy provides test hypothesis Al agents beliefs intentions processes deliberating test hypothesis A4 agent choice resource produce Attention limited attentional beliefs beliefs improve performance task strategy resource increase warrants underlying IRU capacity limited likeli different plan The Matchedpairinferenceexplicit strateg The Matchedpairinferenceexplicit strategy expands acts See Fig 13 The contributor intended PROPOSAL discourse act proposal consists core propose utterance act communicative statement 166 followed 167 turn ih The names agents use Matchedpairinferenceexplicit strategy numbered version string IMI stands Implicit acceptance matched inference MA WalkerArcial Intelligence 85 1996 181243 213 NAME EFFECT CONSTRAINTS CONTRIBUTOR CORE speaker hearer act 1 hearer actl utilityact intend speaker hearer act2 Proposalmatchedpair desire hearer salient hearer option act 1 matchedpair salient hearer salient hearer intend speaker hearer acd speaker hearer intend speaker hearer acd propose speaker hearer act 1 utility act 1 utilityact act 1 acd Fig 13 The PROPOSAL plan operator Matchedpairinferenceexplicit agent 16 6 7 agentimi agentimi2 IM12 WE AGREED TO PUT THE PURPLE COUCH Say agentimi2 putact IM12 Then lets purple rug living room Propose agentimi2 putact agentimi optionSO purple rug room2 purple couch rooml intended5 1 agentimi2 IN THE STUDY The statement 166 IRU realizes information previously inferred IRU dialogue agents models variation discussed Matchedpair constraint As Fig 13 shows constraint inferred Matchedpair Section 1 choice 4 This strategy tasks way testing hypothesis A2 discourse intended inference plan speaking agent 11 Matchedpairinferenceexplicit option proposed Although strategy strategy specifically making premises test general inferentially ences For example clauses Generates complex require agents generalize strategy Matchedpair act 1 A acd act3 generates actl Note effect strategy pair inference A constraint agents parameterized hearer See 64 experiments model agents attentional effect premise strategy premise strategy assume state cases planrelated tied Matchedpair inferences inferences salient remain coordinated provides tasks infer inferences act2 replaced general 33971 Matched salient inference salient However salient premise agents attempt maintain dynamic hearer makes desired inferred relation 46 Plan evaluation Section 33 specified model collaborative plans evaluated terms QUALITY OF SOLUTION order able measure Section 44 defined quality solution examine performance tradeoffs COLLABORATIVE EFFORT DesignWorld quality solution collaborative constructed effort tasks We want DesignWorld strategy choices 214 MA WulkerArtrficrd lntellience 85 1996 181243 IRU effort Thus It obvious related tradeoffs versus total cost inference versus total cost communication retrieval agents collaborative simply add number retrievals makes inference Consequence discourse model However inference processing potential benefit Attention effort retrieval increasing communication beneficial This hypothesis benefit strategy Consequence extra utterance Consequence calculate collaborative relative contributions total cost effort inferences messages Consider inferred belief explicit ensures inference cost IRU A similar argument holds IRU reduces overall Attention effort degree IRU greater dependent effort general form IRUs Whenever given l HYPOTHI 1 Strategies solution beneficial reduce collaborative effort affecting quality 01 This hypothesis convenience Section 33 follows directly definition performance repeated PERFORMANCE QUALITY OF SOLIJTION COLLABORATIVE EFFORT We need processes implementation parameterized inference defined introduce parameters effort involved component strictly comparable dependent Thus agents 1 COMMCOST retrieval inference communicative cost sending message 3 RETCOST cost retrieval memory Collaborative modules costs 2 INFCOST cost effort COLLABORATIVE EFFORT COMMCOST x total messages agents INFCOST x total inferences agents RETCOST x total retrievals agents explore free 2 retrieval effort dominates processing extremes effort dominates processing We use cost parameters processing communication modeling varying plan library working memory implemented Varying communication models situations values parameters experimental cost retrieval models different assumptions absolute values instantiations outcomes planning agent architecture given utilities steps space 1 costs 3 support Fig 3 For example beliefs database costs The parameters costly The relation plan determines cost communication As example effect varying plots performance shown Figs 14 15 LOW MID HIGH AWM In figures plotted xaxis number simulations level distributions distributions performance given bars yaxis The performance increase QUALITY OF SOLUTION expect increases Fig 14 demonstrate AWM costs consider performance MA WalkerArtijcial Intelligence 85 1996 181243 Fig 14 Performance Allimplicit HIGH AWM agent agents processing dialogues LOW MID x n x distributions showing effect AWM parameterization free The performance distributions E P ADL It _ x 11 Fig 15 Performance dialogues agents AWM retcost 0001 distributions Allimplicit showing agents The performance effect increased retrieval cost AWM LOW MID HIGH range distributions 116 MA WulkerArrctal ntellience 85 1996 181243 costs I7 Fig 15 shows happens processing given processing free retrieval cost 0001 means memory access reduces quality solution utilities plan steps range 10 I 1000 point reasoning beliefs database 56 As Fig 15 shows similarly HIGH AWM agents perform MID AWM agents improve performance ability remember access 217 Summuc mupping naturully ocwrring data Design World experiments Section 2 proposed hypotheses function IRUs human human col dialogues Section 3 presented model collaborative Section 2 Section 4 described testbed model Sections 44 45 introduced number dialogues based observations laborative planning planning DesignWorld parameters testbed intended dialogues support naturally clarify basis experiments The testbed experimental dialogues model features humanhuman testing hypotheses Here I wish summarize occurring design testbed mapping order section parameters based following mapping examples communication naturally occurring mapping WARRANT tied agent architecture Third memory CAWM shown limits processes modeled extending relation act belief strategy collaborative planning dialogues testbed First planning aspects human processing modeled IRMA architecture IRMA architecture model processing relation modeled seen mapping assumes tween humanhuman deliberation resource model attentionworking limited critical set properties human processing Second dialogue act belief WARRANT Explicitwarrant arbitrary relation required tasks based assumption task difficulty 1 inferential com financial advice domain related abstract features 3 plexity measured number premise degree belief coordination plan 3 reasonable planning dia logues domain plan utility measure quality solution defining cost achieve natural dialogues contentbased Matchedpair making inferences inferences beliefs underlying inferences tasks Fifth mapping task determinacy evaluate performance agents solution collaborative fault tolerance Finally Section 45 Fourth discussed required intentions mapping assumes t I 1 mapped naturally occurring effort appropriately DesignWorld DesignWorld collaborative parameterized contentbased 9 example inferences required These distributions 200 runs guarantee equal S greater approximately 133 samples different strategies tested approximate Beta distributions stable results The Beta distribution largest variance I44 1 approximation determine parameters R I uniform distribution This largest variance distribution require I IS 144 1 An empirical evaluation adequacy sample size runs 100 differences showed alternate differences MA WalkerArtijicial Intelligence 85 1996 181243 217 The details mapping provides orative planning results excellent environment critical aspects humanhuman humanhuman testing specifies testbed implements basis extrapolating model collab testbed experimental dialogues modeled The testbed provides model captures extent hypotheses dialogues 5 Experimental results 51 Statistically evaluating performance resource interaction The experiments varies AWM task 200 dialogues tasks communication examine limits Every experiment AWM MID HIGH In order run experiment particular communicative particular AwM model parameter yields performance agents hypothesized agents collaborative setting shown resource MID dialogue simulation different strategies ranges LOW strategy result The AWM limited agents LOW resource unlimited agents AWM QUALITY OF SOLUTION range simulated Because HIGH Sample performance runs Allimplicit effort subtracted AwM probabilistic similar distributions distribution human agents Fig 14 To test hypotheses want compare performance task different asssumptions particular costs To effect communicative municative strategies limits processing range AWM settings run twoway analysis variance AWM factor communication 1 AWM nication strategy significant interaction factor predicting performance factor predicting performance communication strategy The anova strategy AWM significant anova tells 2 commu 3 different com resource strategy AWM Furthermore strategy aids hinders performance However anova enable determine particular Awh4 range communication hypothe ses benefits particular communication strategies specific resource limited agent effects value AWM negatively strategy seen anova Therefore conduct planned compar 701 isons strategies 25 TO I9 On AWM range setting BENEFICIAL basis comparisons strategy particular determine AWM range strategy affects task particular AWM range strategy affects performance value AwM modified Bonferroni test MB potential positively s The experimental performance distributions normal variance different samples anova robust violation assumptions conditions experiments 25701 I According modified Bonferroni test significant F values planned comparisons reported 388 p 005 506 p 0025 666 p 001 961 p 0002 21x A strategy A BENEFICIAL compared range significantly task situation cost settings mean B according greater modified Bonferroni mean A test strategy B particular AWM MB test The converse 01 BENEFICIAL DETRIMENAL A strategy A DETRIMENTAL IS compared range significantly MB test mean B according task situation cost settings modified Bonferroni mean A test strategy B LI particular AWM Strategies ference BENEFICIAL DETRIMENTAL strategies compared strategy beneficial detrimental riced tither BENEFICIAL DETRIMENTAL dif strategies Also definition given strategy range AWM LOW AWM agents HIGH AWM agents depending strategy 1 strategy 2 In comparisons A DIFFERENCE PLOT Fig 16 summarize strategies Closeconsequence 2 Allimplicit plotted yaxis AWM ranges xaxis Each point represents range These plots summarize comparison strategy 1 strategy strategies plot means 200 runs strategy particular AWM strategy DiJfemrzces performance means 1200 simulated dialogues Matchedpairinferenceexplicit O Explicitwarrant information difference 52 Standcud task DESIGNHOUSE plan constructed dialogue task defined QUALITY OF SOLUTION sum tolerant Standard Remember agents achieve utilities valid step plan The fault subtracted mistakes Furthermore required cases inferences premise deliberation point values Allimplicit agents fairly Standard score effect agents heavily penalized task low inferential complexity task multiple correct solutions invalid steps plan simply making inferences agents In access single minor meansend reasoning agents required processing free shown performance increase HIGH AWM agents dont retrieval effort retrieval collaborative costs expend HIGH AWM distribution HIGH AWM agents Fig 14 potential benefit task assumptions plot Fig 14 However retrieval free task Fig 15 Thus Standard strategies communication planning Compare In experiments Closeconsequence use strategy agent produce closing statement simulations constrained agent dialogue uses Closeconsequence strategy open See Fig 1 I Since dialogue segment agent given option dialogue segment MA WalkerArtificial Intelligence 85 1996 18243 219 total effort reduce task minimal deliberation agents task fault contribute Closeconsequence Below compare Closeconsequence tolerant strategy retrieval inferential Explicitwarrant nonoptimal complexity retrieval agents penalized easy access free In addition information strategy provides benefit LOW AWM decisions Furthermore making errors errors strategies task communication number errors beneficial performance Thus Standard reduce Allimplicit strategy Explicitwarrant strategy Explicitwarrant The Explicitwarrant strategy IRUs support test hypothesis beliefs It test hypothesis A4 choice produce Attention attentional capacity strategy result higher performance access free ensuring Al agents produce Attention intentions IRU related Thus prediction Explicitwarrant LOW AWM agents processing warrant use deliberation Standard processes deliberating degree agent resource limited task making better decisions performance means Explicitwarrant Fig 16 plots differences effect AWM Explicitwarrant strategy Allimplicit anova exploring shows AWM large effect performance main effect communicative interaction strategy LOW MID HIGH AWM agents A twoway task strategy Standard F 33663 p 0000001 There F 192 p 016 However choice F 113634 p 0000001 AWM communicative strategy By comparing performance particular AWM range strategy MB test modified Bonferonni interact communicative AWh4 settings beneficial implicit strategy MBHIGH 039 ns Note trend detrimental The hypothesis detrimental processing MID AWM based task Explicitwarrant All Standard free MBLOW 029 ns MBMID 279 ns strategy comparison Explicitwarrant strategy strategy The planned comparisons corpus analysis strategies include Further analysis result suggests hypothesis apparent IRUs However hypothesis LOW AWh4 agents limited resource working memory useful deliberation effect IRU cancelled IRUs displace information beneficial communicative benefit disconfirmed corpus analysis agents useful In case despite making options When agents resource important salient displaces warrant fact warrant information information limited making optimal decision generate able generate multiple options The Explicitwarrant reduce collaborative 11 strategies prediction proposal accessing memory processing providing Explicitwarrant cost strategy Standard task test hypothesis effort overall beneficial Thus proposal warrant deliberating strategy potential reduce resource consumption 220 MA WulkerArtiJiciul hellgre 85 I 996 181243 cost ieiiei2 billkim C 0 I 0 R 0 Fig 16 If processing I Explicitwarrant infcost 0 retcost 0 free Explicitwarrant beneficial detrimental AWM settings strategy agents strategy 7 Allimplicit agents task Standard commcost 0 cost ieiiei2 billkim C 1 I 1 R 001 Fig 17 Explicitwarrant costs strategy commcost I infcost I retcost 00 I 1 Explicitwarrant beneficial MID HIGH AWM agents retrieval dominates processing task Standard agents strategy 2 Ailimplicit agents AWM strategy LOW AWM agents Explicit 8643 p 0002 HIGH AWM MA WalkerArtificial Intelligence 85 1996 181243 221 Fig 17 plots differences Allimplicit strategy retrieval effort dominates Explicitwarrant processing 0000001 OOl interaction p 0000001 The planned shows There performance means strategy LOW MID HIGH AWM Explicitwarrant agents processing A twoway anova exploring strategy Standard AWM large effect performance main effect communicative effect AM task retrieval cost dominates F 33015 p F 574 p F 107764 AWM communicative strategy choice comparisons Standard MB test compare performance task comparison Allimplicit range Explicitwarrant strategy MBLOW warrant The Explicitwarrant agents MBHIGH beliefs necessary proposal As additional strategy 027 ns However hypothesis beneficial detrimental 11 confirmed beneficial MID AWM agents MBMID strategy tends improving performance 207 p 010 For higher AWM values deliberating proposal available trend current context agents dont search memory test hypothesis 11 final experiment strategy costs Fig 18 plots situation differences tests Explicitwarrant cost communica performance strategy Allimplicit agents communication effect AWM Explicitwarrant strategy LOW MID effort dominates processing A twoway Standard strategy AWM large main effect AWM effort dominates processing F 40952 p 0000001 There F 2812 p OOOOOOl interaction shows F 96024 p 0000001 Allimplicit processing Explicitwarrant strategy tion dominates means HIGH AWM anova exploring task communication effect performance communicative communicative The planned strategy choice comparisons strategy effort dominates 012 ns However MB test compare performance situation communication beneficial detrimental strategy AWM processing range MID AWM agents Explicitwarrant MBMID LOW HIGH AWM agents 3965 p 001 Since strategy includes extra utterance proposal provides clear benefits effort dominates Zerononmatchingbeliefs task low coordination situation task fact Standard requirements performance processing Below compare 769 p 001 MBHIGH task communication Explicitwarrant Standard detrimental detrimental MBLOW Closeconsequence The Closeconsequence strategy making task measure test hypothesis C4 Standard related task fault tolerant invalid step reduces Making explicit decreases inferences error important acteffect choice inference inferences produce explicit IRU Standard quality solution final plan kind likelihood making Consequence Even 22 MA WalkerArtcid Inrellience 85 1996 181243 IX Explicitwarrant Fig high strategy commcost IO infcost 0 retcost 0 detrimental I Explicitwarrant LOW HIGH AWM agents communication agents strategy Allimplicit agents task Standard effort cost clckim billkim C 0 I 0 R 0 Fig 19 Closeconsequence HIGH AWM agents Strategy 1 combination strategy 2 Allimplicit detrimental agents Standard task LOW AWM agents beneficial Allimplicit agent Closeconsequence agent task Standard commcost 0 infcost 0 retcost 0 MA WalkerArtcial Intelligence 85 1996 181243 223 Close task process The difference plot Fig 19 plots performance differences consequence strategy Allimplicit ing free A twoway anova exploring strategy situation shows AWM large effect performance p 0000001 interaction AWM communicative F 91927 p 0000001 strategy Standard effect AWM Closeconsequence F 24920 choice MBLOW Planned consequence agents performance utterances displacing difference comparisons strategy detrimental strategies AWM comparison Allimplicit 870 p 001 This inferences agents LOW AWM explicit Closeconsequence facts meansend range shows Close LOW AWM generating options contributes avoiding errors additional strategy effect generate options There reasoning However comparisons performance MID AWM agents strategies MBMID 0439 HIGH AWM agents shows ns strategy probability belief deliberation comparison Allimplicit agents choosing MBHIGH Closeconsequence beneficial algorithm 17171 p 0002 See Fig 19 This believe date beliefs HIGH AWM increases invalid steps state world The result likely reinforcing plans Thus Closeconsequence agents believe belief item This result predicted hypotheses furniture discussed Section 43 property belief deliberation mechanism intuitive appeal In case result provides data point benefit strategy making inferences inference explicit probability making error increases item makes beneficial furniture likely strategy 53 Zerononmatchingbeliefs task Remember lief coordination WARRANTS based inferences compare Explicitwarrant Zerononmatchingbeliefs task requires greater degree requiring agents 21 Thus increases agree beliefs underlying deliberation importance making particular deliberation test hypotheses Al A4 A5 Below performance agents strategy strategy Zerononmatchingbeliefs Allimplicit task Fig 20 plots mean performance differences Explicitwarrant Zerononmatchingbeliefs strategy Allimplicit effect AWM shows AWM large effect performance main effect communicative interaction AWM communicative communicative strategy strategy Zerononmatchingbeliefs F 47 142 p 0000001 strategy task A twoway anova exploring task There F 37974 p OOOOOOl F 66924 p 0000001 choice 2 Remember tasks agents agree WARRANTS know option proposal Thus agents limited AWM accept proposal having retrieved warrant situations order able decide need retrieve warrant accept match ieiiei2 billkim C 0 I 0 R z 0 LOW MID TTENTIONmORKING MEMORY J HlGH Exphcitwarrant beneficial Zerononmatchingbeliefs task LOW MID AWM agents task Zerononmatchingbeliefs strategy I Explicitwarrant agents strategy 7 Allimplicit agents commcost 0 infcost 0 retcost 0 match ieiiei2 billkim C 10 I 0 R 0 Fig 7 I Explicitwarrant beneficial Zerononmatchingbeliefs task LOW MID AWM agents communication cost dominates processing strategy I Explicitwarrant agents strategy Allimplicit agents task Zerononmatchingbeliefs commcost IO infcost 0 retcost 0 MA WalkerArtificial Intelligence 8S 1996 181243 225 Comparisons AWM range communicative strategies task strategy highly beneficial Explicitwarrant 2606 p 0002 MBMID HIGH AWM agents MBHIGH LOW MID AWM 1955 p 0002 The strategy 448 p 005 When agents strategy fail access warrant The Explicitwarrant agents access warrant option discussion shows agents MBLOW beneficial resource guarantees Thus agents higher values AWM benefit strategy task requires Hypothesis high degree belief coordination 11 tested task We ask limited inefficient benefits Explicitwarrant high strategy Allimplicit However drive total effort communication Explicitwarrant strategy reduced task strong LOW MID AWM agents communication 2464 p 0002 high 2427 p 0002 See Fig 21 In words extra agents Explicit MBMID WARRANT message 10 task warrant better Contrast Fig 21 Standard Fig 18 collaborative Zerononmatchingbeliefs effort 10 reduces performance task cost parameters increases resource MBLOW limited cost However communication cost high strategy detrimental possible choose HIGH AWM agents warrants increase offset high communication belief coordination cost MBHIGH 756 p 001 These agents usually afforded Explicitwarrant 54 Inferential tasks Matchedpair access strategy Section 44 1 increase degree belief coordination follow intentions Matchedpairtwo easier Matchedpairsameroom inferences The versions Matchedpair task tasks described increase 2 increase complexity agreed Both inferential tasks agents fairly making Matchedpair task requires inferential required requiring agents coordinated inferences explicitly small degree Allimplicit Matchedpairsameroom room task inferences inferential The Matchedpair A5 The Attention inferenceexplicit salient strategy beneficial predictions AWM agents HIGH AWM agents access necessary Attention stronger premises likely tasks provide environment test hypotheses strategy makes premises IRUs Furthermore predict agents making Matchedpair beneficial likelihood salient increasing strategy strategy task testing hypotheses A2 A3 A4 Matchedpair Matchedpair inferences inferences The MID inferential premises effect LOW possibly difficulty inferences The Matchedpairtworoom performance Fig 22 plots pairinferenceexplicit exploring large effect performance agents effect AWM communicative strategy F 32393 p 0000001 There differences Allimplicit Matchedpairsameroom agents Matched task A twoway anova task shows AWM main effect 7 1 0 I I 0 n I I 0 n I I 0 MA WalkerArtificial Intelligence 85 1996 181243 227 communicative communicative strategy choice F 003 ns interaction AWM F 110151 p 0000001 Comparisons AWM ranges agents Allimplicit strategy Matchedpairsameroom strategy agents Matchedpairinferenceexplicit task Fig 22 Matchedpairinferenceexplicit AWM agents HIGH AWM agents recently small restricted MBLOW 447 p 005 significantly In Matchedpairsameroom inferred likely salient resource limited agents strategy beneficial Low MID task content IRU relatively effect different beneficial In contrast Matchedpairtworoom task effect performance larger predicted Fig 23 plots Matchedpairinferenceexplicit agents strategy differences Matchedpairinferenceexplicit mean performance strategy Allimplicit achieve A twoway anova exploring shows AWM large effect performance main effect communicative AWM communicative levels mutual strategy choice effect AWM communicative strategy The Allimplicit inference Matchedpairinferenceexplicit strategy agents manage agents task F 17179 p 0000001 There F 5712 p 0001 interaction F 56734 p 0000001 Comparisons AWM ranges agents Allimplicit strategy Matchedpairinferenceexplicit agents task Fig 23 Matchedpairinferenceexplicit MID HIGH AWM agents MBLOW MBHIGH increasing inferences 3885 p 0002 ability LOW MID HIGH AWM agents Matchedpairtworoom In words task strategy Matchedpairtworoom beneficial strategy LOW 2194 p 001 MBMID 771 p 001 strategy highly effective Matchedpair beneficial LOW possibly MID AWM agents inferences effect hypothesized DISCOURSE INFERENCE HIGH AWM agents beneficial fact case higher AWh4 values We predicted strategy access This confirms gives agents access premises unable CONSTRAINT However expect This surprising Matchedpairinferenceexplicit proposing agent intended words agents HIGH AWM situation effect strategy keeps agents coordinated inference In divergent inferences multiple possible inferences making strategy Thus corpus analysis strategy controls inferential premises salient inferential processes improves agents inferential coordination way predicted based Hypothesis 11 tested effort communication drive Matchedpairinferenceexplicit task We ask high strategy Allimplicit inefficient possible choose Fig 24 plots communication strategy munication 1046 p 001 required coordinating cost mean performance cost high Comparisons AWM differences strategies LOW MID HIGH AWM agents high com 1910 p 001 MBMID 394 p 005 MBHIGH strategy beneficial This result task situation difficult range shows In words inference MBLOW beneficial 238 MA WtrlkrrArr1t2crul lmlliqmce X5 1996 IX213 mp imiimi2mpr billkimmpr C 10 I 0 R 0 Matchedpairtworoom I hcneficial LOW MID HIGH AWM Fig 24 The Matchedpairlnfcerenceexplicit tratrgy task communication cost IO Strategy I agents Matchedpairinferenceexplicit agents strategy 7 Allimplicit agents task Matchedpairtworoom commcost IO infcost 0 retcost 0 strong prevalence strategy support DISCOURSE INFEIENCB CONSTRAINT explain naturally occurring dialogues 30 109 1411 55 Zeroinvalids tusk Zeroinvalids Remember invalid environment explicit Closeconsequence invalidates intention testing hypotheses C2 C4 respect strategy plan Thus task fault intolerant version task task provides inferences Zeroinvalids Fig 25 plots mean performance agents differences Allimplicit strategy consequence task A twoway anova exploring task shows AWM large effect performance There interaction AWM communicative main effect communicative strategy agents Close strategy Zeroinvalids strategy F 22314 p 0000001 F 7581 p OOOl choice F 10338 p 0000001 effect AWM communicative The Closeconsequence strategy detrimental agents Comparisons AWM agents differences Zeroinvalids beneficial MBLOW MID HIGH AWM Closeconsequence performance task ranges agents Allimplicit strategy LOW AWM Zeroinvalids agents Standard task LOW AWM strategy task intolerant strategy 2662 p 0002 MBHIGH fault Closeconsequence agents MBMID 364 ns However MA WalkerArtiJicial Intelligence 85 1996 181243 229 inval clckim billkim C 0 I 0 R 0 w Fig 25 Closeconsequence combination agents task Zeroinvalids Allimplicit agent Closeconsequence commcost 0 infcost 0 retcost 0 beneficial Zeroinvalids task MID HIGH AWM agents Strategy 1 agent strategy 2 Allimplicit 26772 p 0002 In words robustness mistakes This direct result rehearsing unlikely strategy process decreasing planning attention highly beneficial increasing frequency agents inferences making acteffect limited agents forget important inferences 6 Discussion task In Section 3 I presented model collaborative action designed communicative context particular features col planning affect efficacy Section 5 I planning process Then testing hypotheses effects param development dialogues These results contribute This paper showed agents choice limits effect resource mitigate laborative planning dialogue discussed number parameters final plan efficiency collaborative presented results experiments eters collaborative model collaborative testbed implementation easily inter alia dialogue planning incorporated planning planning compatible current theories dialogue presented In addition results algorithms 17485 1537988127 A secondary goal paper argue particular methodology theory development The method specified introduced Section 4 Sections 44 45 described Section 41 The DesignWorld parameterizations dialogue testbed 230 MA WulkerArticrul Intellipence X5 1996 181233 testing support model strategies tested Standard 2 Zerononmatchingbeliefs Three situations varying processing 4 Matchedpairinferenceexplicit hypotheses Four parameters 1 Allimplicit C 2 Closeconsequence communicative 3 Explicitwarrant Four parameters C 3 Matchedpair tasks tested 1 MP 4 Zeroinvalids In section effort tested hypotheses I summarize Section 61 I discuss experimental situations implemented 65 consists concluding testbed Section 64 proposes remarks experimental results generalize results future work Section 6 I Suttwtuq results The hypotheses generated statistical analysis dialogue corpora repeated convenience Sections 2 46 l HYPOTHCl inference l HYPOTHC2 agents produce Consequence IRUs demonstrate explicit agents choose produce Consequence IRUs ensure agent access inferrable information l HYPOTHC3 choice measure hard inference produce Consequence produce Consequence IRU directly related IRU directly related l HYPOTHC4 choice measure important inference l HYPOTHC5 choice produce Consequence IRU directly related inferences degree task requires agents coordinated l HYPOTHAl agents produce Attention IRUs support processes deliber ating beliefs intentions DISCOURSE INFERENCE CONSTRAINT effect dialogue derived propositions currently discourse l HYPOTHA2 inferences salient working memory l HYPOTHA3 inferential taskrelated complexity inferences l HYPOTHA4 agent l HYPOTHAS choice resource choice choice produce Attention IRU related task measured number premises degree required produce Attention IRU related degree limited attentional capacity produce Attention IRU related degree task requires agents coordinated inferences l HYPOTHI 1 strategies solution beneficial Below I summarize hypotheses reduce collaborative effort affecting quality experimental results reported Section 5 respect Hypotheses C3 C4 tested comparing Closeconsequence Allimplicit explicit Consequence strategy Standard task In experimental setup IRU hard critical strategy inference MA WalkerArtcial Intelligence 85 1996 181243 231 inference The results formince Hypothesis C3 weakly Strategy detrimental information IRU hard working memory LOW AWM agents This tested experiments agents Fig 19 Closeconsequence IRUs displace useful inference explicit critical The Standard task provides weak test hypothesis C4 The fact making task fault inference At lower values AWM Standard tolerant means However errors result making probability high However HIGH AWM agents Standard inference forgetting errors Fig 19 probability error higher case belief deliberation HIGH AWM agents Closeconsequence results shown beneficial algorithm strategy task The Zeroinvalids test hypothesis C4 increasing task provides tance inference explicit Closeconsequence hypothesis C4 confirmed Closeconsequence LOW MID HIGH AWM agents In addition beneficial task strategy scores ensuring improve impor strategy Fig 25 shows strategy beneficial Standard reasons discussed potential HIGH AWM agents dont errors test hypothesis Cl agents The experiments actively monitor evidence designed Hypothesis C5 tested experiments rectify reject proposals preconditions detect discrepancy hold situation agents inferences beliefs acteffect testbed agents inferences Hypotheses Al A4 A5 tested experiments Explicitwarrant LOW AWM agents Fig 16 shows Explicitwarrant strategy compared Allimplicit disconfirmed beneficial detrimental processing resource free This counterintuitive limited LOW AWM agents Standard strategy Standard task Hypothesis Al strategy task result arises agents highly useful IRUs displace information strategy To test hypothesis free When communication 11 situation examined situations pro LOW HIGH AWM agents However Explicitwarrant MID AWM agents trend beneficial effect HIGH hypothesis 11 confirmed processing cessing Explicitwarrant retrieval beneficial AWM agents Thus situations effort major effect strategy processing processing cost dominates cost dominates detrimental beneficial strategy costs costs We tested hypotheses Al A4 A5 experiments Explicit task Figs 20 21 This warrant strategy compared Allimplicit beliefs deliberationbased order Explicitwarrant tion effort Thus inferences include Attention strategies strategy task agents requiring situations inferences task In situation saw large beneficial diminished agents required increasing coordinated communica IRUs important strategy Zerononmatching importance increases making coordinated inferences effect 137 MA WulkerArrjiciul lnfelligmce 85 1996 181243 Hypotheses A2 A3 A4 A5 tested experiments strategy Allimplicit shown Figs 22 23 provide strategy included unpredicted comparing Matched versions benefit Attention support agents performance tasks agents coordinate inferences Fig 23 improves Matched IRUs divergent strategy This explained fact Attention agents Same inference possible inferences Matchedpairinferenceexplicit tied provides test general strategy making premises complex require agents remain specifically strategy salient tasks inferentially results complex likelihood task The results pairinferenceexplicit Matchedpair hypotheses However IRUs inferentially shows MID HIGH AWM pairinferenceexplicit increase inferences multiple inferences Furthermore Matchedpair inferences coordinated inferences Thus ENCE CONSTRAINT clauses replaced general A act2 act3 generates To generalize strategy plan operator provides strong support DISCOURSE strategy cases planrelated refer Matchedpair specifically inference relation general Generates inferred 335197 INFER inferences inferences actl Hypothesis 11 tested examining extremes Standard effort hypothesis I8 shows high communication communication confirmed Fig strategy detrimental eliminate beliefs task Fig 24 shows high communication Matchedpairinferenceexplicit strategy making premises processing strategy inferences benefits Explicitwarrant effort cost ratios retrieval effort effects IRUs beneficial effort Explicitwarrant task Fig 21 shows high communication effort strategy Zerononmatching effort eliminate Matchedpairtworoom salient robust extremes benefits task Thus 62 Generalizability results This section addresses concerns raised 1541 simulation experimentation small Hanks writes 54 Section 5151 The ultimate valuearguably order experimenter demonstrate I resultsthe designer otllJ valueof relationships inform 2 specification tics world characteristicsextend problem studied solution problem area encountered problem area studied experimentation solves interesting problems constrain In things demonstrates agent characteris particular agent world isolation applicable larger complex world 3 relationship demonstrated experimentally actually constrains guides design larger realistic agent The list 1 3 different ways saying results generalize basic issue experi specifics experiment MA WalkerArtificial Intelligence 85 1996 181243 213 designed shown series multiple experiments mental work Typically generalizations modifying multiple variables For example task specifically generalize manipulated briefly discuss results presented potentially generalizable generalizations agent architectural Cohens ecological strategies tasks However ask extent variables abstract key properties real situations Below I I focus 2 3 agent behaviors These dimensions 1 task environmental test beneficial properties dimensions modifications simulation communicative properties triangle 241 planning tasks In addition Generalizations tasks The DesignWorld task selected simple planning test generalizability tasks examined complex variants task manipulating tion step The structure task isomorphic collaborative abstract inferential quired making taskrelated intentions fault tolerance plan These general features certainly applied tasks domains features applied complexity inference 2 degree belief coordination think task domain task requires negotia hypothesized benefits required task determinacy measured number premises beliefs underlying In fact difficult subcomponent plan 3 inferences features 1 Generalizations agent properties agents DesignWorld agents artificial designed deliberation resource IRMA architecture model attentionworking model resource aspects human pro limits processes limited qualities human agents The planning cessing modeled IRMA architecture modeled extending memory erties human processing The way agents process dialogue architecture AWM shown set prop tied agent model limited critical The experimental modeled size memory time access memory Artificial results extend dialogues artificial agents extent similar cognitive properties Here looked resource limit time agents testbed benefit strategies discussed subset agents artificial I predict plausible strategies For example In addition defining number premises simultaneously artificial processors computation inferences explicit communicating agent able inferential memory bears strong requires large complexity correlated memory similar communicative rapidly changing worlds agents exhibit bound access size directly limited benefit agents Phoenix simulation 241 In work artificial agents agents partial computations computations direct consequence resemblance working set 1221 The experimental results extend 2436130 problems agents DesignWorld agents designed dialogues humans artificial model humans However 334 MA WulkerArttjicictl lnfelligerlcr X5 1996 1X1243 change allow definition collaborative desirable interaction human Furthermore claims AWM model based limited set human working based memory properties architectures effort modeling humancomputer easy properties hold easy human SOAR 174771 cognitively handle processing handle processing strate Gerleraliations agent behaviors In work agent behaviors tested agent communication gies One reason believe based observed strategies planning dialogues Design corpora strategies general humanhuman different corpora natural collaborative types IRUs Trains Maptask discourse It possible 1298 128 1421 financial advice domain In addition generalizations empirical evidence reasons expect The communicative acts discourse acts DesignWorld agents similar strategies based acts 12 14 I 13 1201 Thus communicative implementable systems strategies based general results based strategies generalize The experimental situations underlying processes mapping WARRANT examples 9 modeled WARRANT lief DesignWorld use Explicitwarrant communication dialogue planning domain agents use warrants discourse relations utterance acts inference For example relation act belief naturally occurring relation act strategy The claims strategy generalize support deliberation supporting deliberation seen Explicitwarrant communication Similarly contentbased inferences natural dialogues 1 1 modeled contentbased Matchedpair DISCOURSE premises INFERENCE currently discussed inferences DesignWorld situation tasks This inferential CONSTRAINT inferences salient Both experimental evidence provided support discourse inference use Matchedpairinferenceexplicit constraint communication example relation required test designed dialogue restricted corpusbased The claims strategy based experimental agents premises agents required planning evidence inferences contentbased generalize available inferences strategy dialogue planning domain support deliberation The evaluation metrics applied strategies reasonable measure quality solution generalize dialogue domain plan utility task 63 Relation work The model collaborative previous work cooperative planning dialogue dialogues presented 10213037505 Section 3 draws 167859798141143 MA WalkerArtcial Intelligence 85 1996 181243 235 current research collaborative planning 17 results applicable 263248535687113127146 The agent architecture reasoning meansend model deliberation work based work 7341 Pollacks TileWorld simulation The use IRMA underlying model intention deliberation planning model proposed collaborative incorporated The architecture limited working memory claims recency frequency properties provided cognitively based architectures consistent assumed frameworks The relationship SOAR 74771 Since testbed architecture work 991 environment provide basis includes specific model model based discourse acts domainbased results generalizable options intentions experimental 13 I1331 48146 85861 similar stage planning agents based developed environment 1214127 belief work based Litmans model discourse plans approach process theory belief Automated Librarian project testbed reasoning mechanism multiagent The emphasis autonomy The DesignWorld revision DesignWorld simulation environments optimize reasoning rapidly changing 14384088 based methods TileWorld Phoenix agent single agent agent limits artificial TileWorld test theory effect resource robot worlds 245499 planning agent interacts environment uses similar methods behavior agents simulation attempts world DesignWorld communicative agent strategies DesignWorld based method Carlettas JAM simulation 12100 planning place recovery Edinburgh Maptask JAM based Maptask dialogue corpus goal task instructor reactive instruct agent instructee map JAM focuses efficient communicative error recovery strategies Given good error recovery strategies Carletta efficient strategies attempt way approach provides quantifying task definition determine combination strategies efficient Future work test Carlettas claims recovery strategies effective efficient limitations resource risk communicative In contrast error parameterizes agents according agents strategy quantify framework results high efficiency suggest argues extended To knowledge range variation measured communicative ability conversants rative planning earlier work considered communicative affect choice effects different choices choice affects construction collaborative plan stay coordinated Nor theories collabo ideas agent architecture tested specific factors explicit 22 1361 discusses model attentional 4950114 AWM model useful state differences AWMlike attentional model Grosz Sidners See 1071 discussion discourse phenomena stack 336 MA WulkerArinl Intelligence X5 I 996 181243 resource bounds municative argued determining choice conversational dialogue In addition earlier work cooperative utility basis agents com dialogue major factors taskoriented agents resource effective conversational limits task complexity collaboration strategies 64 Future work future work investigate beneficial In agents avenue suggest A promising experiments agents heterogeneous parameterized resource heterogeneous strategies agents effective Attention knew beginning homogeneous agent capabilities heterogeneous forgets agents limited IRU strategy ones For example strategies teams dialogue pairs agents limits Pilot studies dialogues homogeneous effective 1331 I tested limited agent exploit facts important information However agent agents tell options beneficial room This strategy planning IRUs displace useful helpful resource capable agent telling Another extension extend agent communication strategies test additional ones For example work proposes number strategies information strategies dialogue provides evidence selection ordering I 1 17 123 147 1 Support claims provided efficient efficacious DesignWorld agents strategies communicate experiments Future work modify DesignWorld like TileWorld making properties world task For example world possible change course task adding removing These results incorporated agents decide online strategy determine strategies effective presented information parison LOW MD algorithms Another promising avenue furniture decision input algorithms pursue investigate collaborative planning dialogues The results agent consider For example com shows design decision additional factors HIGH AWM agents agents decide expend additional effort past mistakes adapt strategies results incorporated Finally design multiagent agents capable remembering situation learning 3 systems systems solving teaching advice explanation example premised abilities learner apprentice humancomputer communication use particular problem strategies 65 Concluding remarks The goal paper agents choice algorithms resource limits In paper I motivate number hypotheses based statistical language behavior designed context particular features collaborative mitigate communicative action effect task analysis planning MA WalkerArtcial Intelligence 85 1996 181243 237 natural collaborative planning dialogues hypothesized testbed planning dialogues Then functional model collaborative developed based hypotheses including parameters affect generalizability model The model implemented parameters varied hypotheses tested research criteria based models judge initial process specifying The method contrasted work dialogue modeling Much previous work dialogue modeling carries process described completed Followon subjective model judged according model parameters testbed ways initial hypotheses refined model testing hypotheses suggests steps The models developed basis empirical model according elegant provides way check subjective evaluations model suggested corpus analysis criteria work carries additional test generalizability functional model subjective fits researchers test refine implementation Implementing intuitions evidence tested testbed conversational types independent parameters systems systemat hypothesized plan negotiated dialogue 1 agents resource The DesignWorld introduces testbed different efficacy collaborative ically affect efficiency dialogue process Experiments agents choice task difficulty tolerance particular assumptions corpus analysis Several unpredicted counterintuitive limits attentional 3 communication inferential complexity errors The results verified number hypotheses resource features communicative agents limits degree belief coordination possible testbed examined capacity inferential interaction 2 capacity tasks affect required depended test task property belief coordination Zerononmatchingbeliefs Matchedpair IRUs resource robust benefits results demonstrated ex combination resource tasks shown limits originally Second I predicted useful beliefs IRUs detrimental IRUs beneficial agents working memory Third LOW Awh4 effect HIGH AWM agents perform better LOW MID 1 cost 2 access multiple beliefs lead small shared corre humans explains agents access information However In case restricting inferential advantage processes This limit intuitively situations potential benefits limited working memory information divergent set natural way limit inferences agents periments First limits produce hypothesized agents displacing plausible AWM agents results showed accessing agents working sponds humans manage coordinate inferences conversation 496683 These results clearly demonstrate models taken account claims supported resource humanhuman dialogue experimental limited processing I shown account In addition factors previously considered dialogue cooperativity theory dialogue observed efficiency efficacy includes model language behavior results presented 238 Acknowledgements The work reported paper benefited Janet Cahn Jean Carletta discussions Steve Whittaker Joshi Ellen Prince Mark Liberman Max Mintz Bonnie Webber Scott We Aravind instein Candy Sidner Owen Rambow Beth Ann Hockey Karen Sparck Jones Julia Galliers Phil Stenton Megan Moser Johanna Moore Christine Nakatani Penni Sibun Ellen Germain Julia Hirschberg Alison Jerry Hobbs Pam Jordan Barbara Di Cawsey Rich Thomason Cynthia McLemorc I Eugenio Susan Brennan Rebecca Passonneau Rick Alterman providing early grateful belief revision mechanism Automated Librarian project Julia Hirschberg provided tapes financial advice anonymous reviewers provided useful suggestions talk Thanks Paul Cohen Julia Galliers Jon Oberlander implementation This research partially funded AR0 grants DAAG2984K0061 DAAL03 89COO3 1 PRI DARPA grants NO001 485KOOI 8 NOOOl490J 1863 NSF grants INT9 110856 1991 Summer MCS82 19 196 IRI 90 16592 Fellowship Science Engineering University Pennsylvania Japan Ben Franklin Grant 91S3078C1 HewlettPackard Laboratories Institute References 1 I 1 JF Allen Recognizing intentions natural language utterances M Brady RC Berwick eds Cortqtiontrl Models cfDiscmfrse I 1 JF Allen CR Perrault Analyzing 13 1 R Alterman R ZitoWolf T Carpenter Interaction comprehension instruction usage I Learn intention utterances Art Infell 15 1988 143178 MIT Press Cambridge MA 1983 Sci 1 1991 273318 11 1 JR Anderson GH Bower Htrrun Assocrutivr Memory Winston Sons 1973 A Baddeley Workins Memory Oxford University Press Oxford 1986 J Banvise The situation logicIV model theory common knowledge Tech Rept No 123 Center Study Language Information Ventura Hall Stanford University Stanford CA 1988 M Bratman D Israel M Pollack Plans resource bounded practical reasoning Cornput Intell 4 C 1988 349355 SE Brennan Seeking providing evidence mutual understanding PhD Thesis Psychology Department Stanford University Stanford CA C 1990 19 I SE Brennan EA Hulteen Bused Svstems 1995 1 Interaction feedback spoken language Knowledge 1 IO1 S Carberry Plan recognition use understanding dialogue A Kobsa W Wahlster eds User Models DiuloRue S_vsems Springer Berlin 1989 I33 162 1 11 I G Carenini J Moore Generating explanation context Proceedings International Workshop ori Intellijient User InteqCufore7 1993 I I3 JC Carletta Risk taking recovery taskoriented dialogue PhD Thesis Edinburgh University Edinburgh 1992 1 I 3 1 A Cawsey Generating interactive explanations Pmceedins AAAI91 Anaheim CA I99 I 869 I 1 14 1 A Cawsey J Galliers S Reece K Sparck Jones Automating librarian fundamental approach belief revision Tech Rept 243 Cambridge Computer Laboratory Cambridge MA 1992 1 15 1 A Chapanis 16 1 J ChuCarrel S Carberry A planbased model response generation collaborative taskoriented Interactive human communication Sci Amer 232 1975 3442 dialogue Pmeediqs AAAI94 Seattle WA C 1994 799805 MA WalkerArtificial Intelligence 85 1996 181243 239 I 17 I J ChuCarrel S Carberry Response generation collaborative negotiation Proceedings 33rd Annual Meeting Association Computational Linguistics 1995 I181 HH Clark SE Brennan Grounding communication LB Resnick J Levine SD Bahrend eds Perspectives Socially Shared Cognition APA 1990 reference mutual knowledge I191 HH Clark CR Marshall Definite AK Joshi BL Webber 198 I I Sag eds Elements ofDiscourse Vnderstanding Cambridge University Press Cambridge 1063 I201 HH Clark EF Schaefer Collaborating contributions conversations Lang Cognit Processes 2 1987 1941 211 HH Clark EF Schaefer Contributing 22 HH Clark D WilkesGibbs Referring collaborative process Cognition 22 1986 l39 1231 PR Cohen A survey Eighth National Conference Artifical discourse Cognit Sci 13 1989 259294 Intelligence pulling pulling apart AI Magazine 12 1 1991 1641 1241 PR Cohen M1 Greenburg DM Hart AE Howe Trial requirements agents complex environments AI Magazine 10 3 1989 3248 251 PR Cohen Empirical Methods Artificial Intelligence MIT Press Boston MA 1995 26 P Cohen H Levesque Teamwork Nous 25 1991 1 l24 I27 1 PR Cohen On knowing planning speech acts Tech Rept 118 Department Computer Science University Toronto Toronto Ont 1978 28 PR Cohen The pragmatics referring modality communication Comput Linguist 10 1984 97146 291 PR Cohen Reasoning Uncertainty An Artificial Intelligence Approach Pitman Boston MA 1985 30 I R Cohen Analyzing 13 11 AM Collins MR Quillian Retrieval structure argumentative discourse Comput Linguist 13 1987 1 l24 time semantic memory J Verbal Learn Verbal BehaL cognitive computational aspects PhD Thesis 8 1969 240247 1321 N Dahlback Representations Linkoping University Linkoping discourse 199 1 natural 1331 B Di Eugenio Understanding language clauses PhD Thesis University Pennsylvania instructions Philadelphia PA 1993 computational approach purpose 341 J Doyle Rationality I35 EH Durfee P Gmytrasiewics roles reasoning Comput Intell 18 3 1992 J Rosenschein The utility embedded communications 36 I37 138 protocols Proceedings AAAI Workshop Planning Interagent Communication Distributed Artificial Intelligence Morgan Kaufmann Los Altos CA 1987 emergence 1994 EH Durfee VR Lesser DD Corkill Cooperation solving network TW Finin AK Joshi BL Webber Natural IEEE 74 1986 921938 JR Galliers A theoretical acknowledging multi agent conflict Tech Rept 172 Computer Laboratory University Cambridge Cambridge 1989 models cooperative dialogue interactions artificial experts Proc distributed problem communication framework language 1391 JR Galliers Belief revision theory communication Tech Rept 193 Computer Laboratory University Cambridge Cambridge 1990 40 JR Galliers Autonomous belief revision communication P Gadenfors ed Belief Revision Cambridge University Press Cambridge I41 I JR Galliers Cooperative interaction 199 1 220246 strategic belief revision MS Deen ed Cooperating Knowledge Based Systems Springer Berlin 1991 148163 1421 P Giirdenfors Knowledge Flux Modeling Dynamics Epistemic States MIT Press Cambridge MA 1988 1431 P Gardenfors The dynamics belief systems foundations vs coherence theories Revue International De Philosophie 1990 441 G Gazdar Pragmatics Implicature Presupposition Logical Form Academic Press New York 1979 45 1 AI Goldman Epistemology Cognition Harvard University Press Cambridge MA 1986 HP Grice Willwn Jumes Lectures 1967 HP Grice Logic conversation Acts Academic Press New York 1975 1 4158 B Grosz S Kraus Collaborative plans 1993 representation BJ Gros7 The International Menlo Park CA I I977 BJ Gross CL Sidner Attentions 1986 175304 BJ Grosz CL Sidner Planh P Cole 1 Morgan eds Syntax und Semuntics IllSpeech group activities Proceedings IJCAI93 Chambery use focus iu dialogue understanding Tech Rept 151 SRI intentjon structure discourse Conplct Linguist 12 discourse PR Cohen J Morgan M Pollack eds Irltrntiozs Communrwion MIT Press Cambridge MA 1990 CI Guinn A computational model dialogue initiative collaborative discourse AA1 Tech Rept FS9305 1993 IS3 1 CI Guinn Metadialogue behaviors improving efficiency humanmachine dialogue PhD Thesis Duke University Durham NC I994 15l I S Hanks M Pollack P Cohen Benchmarks testbeds controlled experimentation design agent architectures Al Muytrzine 14 1993 I I 55 I B HayesRoth PW Thomdyke Integration knowledge text J Verbrtl Leum Verbal Behuv 18 1979 91108 I 5h PA Heeman G Hirst Collaborating referring expressions Conztf Liquist 21 1995 35 I 3x3 I57 1 S Hellyer Frequency stimulus presentation shortterm decrement recall J Exper Psych 64 1961 650 RA Block Repetition memory evidence multiple trace hypothesis J DL Hintzmann Exper Psych 88 I97 I 297306 J Hirschberg A University theory scalar mplicaturr Pennsylvania Philadelphia PA I985 1 PhD Thesis Computer Information Science JR Hobbs On coherence structure discourse Tech Rept CSLI8537 Center Ventura Hall Stanford University Stanford CA 1985 Language Information Study JR Hobbs Intention information structure discourse D Scott E Hovy eds Burnin Iww7 Diswtrrse I994 A Jameson Knowing know PhD Thesis University Nijmegen Nijmegen 1990 Lawrence Erlbaum Hillsdale NJ I99 I resource sensitive communication Proceedings AAAI FuII PN JohnsonLaird Deductirm P Jordan MA Walker Multiagent Workshop Rutionul Agency C 1995 1 equivalent Informationally AK Joshi Micwwuves CirGt Theory und Infirmtrtion Ttwr sentences Proceedings 1964 inference partial Infernutionul Cwrence AK Joshi Some extensions hystcm Injerence Swtenrs Academic Press New York 197X 24 I257 AK Joshi B Webber RM Weischedel Some aspects default reasoning information Pattern Dvected interactive discourse Tech Rept MSCIS8627 University Pennsylvania Philadelphia PA 1986 AK Joshi BL Webber RM Weischedel Preventing false inferences Proceedings Tenth Interrtutionul Corrence ot Conrputttiltl iquistics Palo Alto CA 1984 134l 38 L Karttunen S Peters Conventional I69 I 70 I G Keppel Dcsiqn und Anuiv A RPseczrcherr Hundhook implicature ntax Semanf 11 1979 PrenticeHall Englewood Cliffs NJ 2nd ed 1982 171 I A Kldd The consultative Computers Designing role expert P Johnson S Cook eds People und lnterjiuw Cambridge University Press Cambridge 1985 171 I K Konolige Belief incompleteness JR Hobbs RC Moore eds Formal Theories Commonsense World Ablex Norwood NJ 1985 359403 1 73 I K Konolige A Deduction Model Beliej Brown University Press Providence RI 1986 I 74 I JE Laird A Newell PS Rosenbloom SOAR architecture general intelligence Arrif Intell 33 1987 l64 175 I TK Landauer Reinforcement ac consolidation h Rev 16 1969 81196 15x1 11 I 60 I 161 I 1631 163 I64 I 65 I flfJ I67 1681 MA WalkerArtificial Intelligence 85 1996 181243 241 properties model random storage undirected 1761 TK Landauer Memory organization retrieval Cognit Psych 7 1975 495531 1771 JE Lehman RL Lewis A Newell Natural language comprehension soar Tech Rept CMU CS9 I 117 Carnegie Mellon University Pittsburgh PA 199 1 I78 I N Lenke Anticipating readers problmes automatic generation paraphrases Proceedings COLING94 Kyoto 1994 I791 HJ Levesque PR Cohen JHT Nunes On acting Proceedings AAAI90 Boston MA 1990 I 80 SC Levinson Activity I81 I SC Levinson Some preobservations types language Linguistics 17 1979 365399 modelling dialogue Discourse Processes 4 1981 93l 16 82 SC Levinson Pragmatics Cambridge University Press Cambridge I831 SC Levinson Whats special conversational I 84 I D Lewis Convention Harvard University Press Cambridge MA 1969 I 85 I D Litman Plan recognition discourse analysis integrated approach 1983 inference 1987 Linguistics Institute Packet 1985 understanding dialogues Tech Rept 170 University Rochester Rochester NY 1985 I861 D Litman J Allen Recognizing PR Cohen J Morgan M Pollack eds Intentions Communication MIT Press Cambridge MA 1990 intentions taskoriented relating discourse plans 87 I KE Lochbaum Using collaborative plans model intentional structure discourse PhD Thesis Harvard University Cambridge MA 1994 88 I B Logan S Reece K Sparck Jones Modelling retrieval agents belief revision Proceedings Seventh Annual International ACM SIGIR Conference Research Development Information Retrieval Springer London 1994 91100 information 891 WC Mann SA Thompson Rhetorical structure theory description construction structures 8396 G Kempen ed Natural Language Generation Martinus Nijhoff Dordrecht text 1987 I 90 I KR McKeown Paraphrasing 191 I GA Miller The magical number seven plus minus limits capacity questions given new information Comput Linguist 9 1983 processing information Psych Rev 3 1956 8197 1921 JD Moore CL Paris Planning text advisory dialogues capturing intentional rhetorical information Compui Linguist 19 4 1993 93 j MG Moser J Moore Proceedings ACL Workshop Intentionality Structure Discourse Relations 1993 94 MG Moser J Moore Investigating cue selection placement tutorial discourse Proceedings 33rd Annual Meeting Association Computational Linguistics 1995 951 DA Norman 1975 4446 DG Bobrow On datalimited resourcelimited processes Cognit Psych 7 96 R Perrault An application default logic speechact theory PR Cohen J Morgan M Pollack eds Intentions Communication MIT Press Cambridge MA 1990 I 97 1 M Pollack Inferring domain plans question answering Tech Rept 403 SRI International Artificial Intelligence Center University Pennsylvania Philadelphia PA 1986 I98 I M Pollack J Hirschberg B Webber User participation reasoning process expert systems Proceedings AAAI82 Pittsburgh PA 1982 99 M Pollack M Ringuette Introducing TileWorld experimentally evaluating agent architectures Proceedings AAAI90 Boston MA 1990 183189 1001 R Power A model conversation PhD Thesis University Edinburgh Edinburgh 1011 R Power Mutual 102 EE Prince Toward taxonomy New York 1981 223255 J Theory Social Behav 14 1984 givennew information intention Radical Pragmatics Academic Press 1974 1031 EE Prince The ZPG letter subjects definiteness information status S Thompson W Mann eds Discourse Description Diverse Analyses Fund Raising Text Benjamin New York 1992 295325 1041 R Reichman Getting Computers Talk Like You Me MIT Press Cambridge MA 1985 42 MA WulkerArrtl Intelligence X5 1996 181243 I I OS I K Reiter A logic IO6 I N Reithinger E Maier Utilizing default reasoning Art Intrll 13 1980 8 I 132 statistical speech act processing verbmobil Proceediqs 33rd Annunl Meeting Associution fir Compututionul Linguistics 1995 I 107 1 CP Rose B Di Eugenio L Levin C Van EssDykema Discourse processing dialogues multiple threads Proceedinp 33rri Annual Meeting offhe Associationfor Computufionul Linptistics 1995 1 108 1 JS Rosenschein Rational interactlon multi agent planning PhD Thesis Computer Science Department Stanford University Stanford CA 1985 JM Sadock On implicnture conversational Academic Press New York 1978 28 l297 Prqmutics testing I Cole rd Snrtr ccnd Semuntics 9 California Press Berkeley CA EA Schegloff Between micro macro contexts connections University P Sibun The Massachusetts Amherst MA 1991 C Sidner Plan parsing response recognition local organisation intended I987 1 incremental generation The MicrwMucro Link text PhD Thesis University discourse Cornjur Intel 1 1985 C Sidner An artificial discourse language collaborative negotiation Proceedings AAAI94 Seattle WA 1994 814820 theory delinite anaphora comprehension CL Sidner Toward computational AITR537 MIT Cambridge MA 1979 S Siegel Nonptrumetw Stutistics fhe Behurrrrul Sciences McGrawHill control level communication R Smith The contract net protocol high Eolver IEEE Trcln7 Conrpu 12 1980 R Smith DR Hipp AW Biermann A dialogue Proceedings Third Conference Nuturul Ltrnuue Processing Trento 1992 M Solomon Scientific human reasoning Philos Sci 59 3 C 1992 control algorithm rationality IlO4I I 13 English Tech Kept New York 1956 distributed problem performance II091 I J Ill1 I II21 11131 11151 I1161 Ill7i RC Stalnaker Assertion l Cole rd yfcr cnd Srmunficr 9 Prqmutics Academic Press New York 1978 3 I S332 I 1201 A Stein U Thiel A conversational model multimodal interaction Proceedings AAAI93 Washington DC I993 I I2 I I S Stemberg Highspeed scnnmng 11221 human memory Science 153 1967 652654 HS Stone High Perormunce Cornpurer Archifecfure AddisonWesley Reading MA 1987 II231 DD Suthers Sequencing explanations enhance communicative functionality Proceedinp f51h Annuul Conference ofrhe Cqnitive Scienw Swietv Boulder CO I993 1141 R Thomason Accommodation meaning implicature interdisciplinary foundations pragmatics PR Cohen J Morgan M Pollack eds Intentions Communicution MIT Press Cambridge MA 1990 II751 R Thomason Propagating cpistemic coordination mutual defaultsi R Parikh ed Third Conference Tfteoreriatl Asfwcfs Reusoning ubout Knoulede Pacific Grove 939 froceedirqg CA 1990 D Traum Mental state trains92 dialogue manager Reusoning ubouf Menn Stutes I993 D Traum A computational model grounding II261 II271 natural language conversation PhD Thesis llniversity Rochester Rochester NY I 1993 II281 DR Traum The discourse reasoner trains90 TRAINS Technical Note 9 IS Department Computer Science University Rochester Rochester NY 199 I I 129 I E Tulving The effects presentation recall material free recall learning J Verbul Lawn Verbal Beuv 6 1967 1 E Turner Selecting information I I30 communicate froceedings AAAI Workshop Plunning fijr fnterujient Communiculion I994 1 II31 MA Walker Redundancy collaborative dialogue Proceeding7 Fourteenth fnternutionul Conference Compufutionul Linquistics 1992 3453s I Il12 MA Walker Information deliberation discourse Proceedings ACL Workshop ON fntentionulitv und Sfructure Disxurse Rrutivrs 1993 Procredmgs AAAI Spring Symposium MA WalkerArticial Intelligence 85 1996 181243 243 I 133 1 MA Walker Informational Philadelphia redundancy PA 1993 I 1341 MA Walker Discourse deliberation Pennsylvania resource bounds dialogue PhD Thesis University testing collaborative strategy Proceedings COLINC94 Kyoto 1994 I 135 1 MA Walker Rejection implicature Proceedings 20th Meeting Berkeley Linguistics Saciet 1994 1361 MA Walker Limited attention discourse I 1371 MA Walker Testing collaborative structure Cornput Linguist appear strategies computational simulation cognitive task effects Knowledge Based Sysfems 1995 138 1 MA Walker 0 Rambow The role cognitive modeling achieving communicative intentions Proceedings 7th International Conference Natural Language Generation 1994 1 139 I MA Walker S Whittaker Mixed Proceedings 28th Annual Conference rhe Association far Computational discourse dialogue investigation initiative segmentation Linguistics Pittsburgh PA 1990 7079 I 140 I BL Webber A formal approach discourse anaphora PhD Thesis Harvard University Cambridge MA 1978 1 1411 BL Webber AK Joshi Taking initiative natural language database interaction justifying Proceedings COLING82 Prague 1982 413419 142 1 S Whittaker E Geelhoed E Robinson Shared workspaces work useful Int J ManMach Stud 39 1993 813842 I 1431 S Whittaker P Stenton Cues control expert client dialogues Proceedings 26th Annual Meeting fhe Associafion Compufafional Linguisfics Buffalo NY 1988 123130 I 1441 S Wilks Mafhematical Statistics Wiley New York 1962 1 1451 MR Young JD Moore Representation generation University Pittsburgh Pittsburgh PA 1994 discourse planning Tech Report I 1461 MR Young JD Moore ME Pollack Towards principled representation discourse plans Proceedings 16th Annual Conference Cognitive Science Society 1994 147 1 1 Zukerman R McConachy Generating concise discourses addresses users inferences Proceedings UCAI93 Chambery France 1993 J Pearl Comprehensiondriven generation metatechnical utterances math I 148 1 I Zukerman tutoring Proceedings AAAI86 Philadelphia PA 1986 606611