Artiﬁcial Intelligence 190 2012 131 Contents lists available SciVerse ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Generating diverse plans handle unknown partially known user preferences Tuan Anh Nguyen a1 Minh Do b2 Alfonso Emilio Gerevini c Ivan Serina d Biplav Srivastava e Subbarao Kambhampati School Computing Informatics Decision System Engineering Arizona State University Brickyard Suite 501 699 South Mill Avenue Tempe AZ 85281 USA b NASA Ames Research Center Mail Stop 2693 Moffett Field CA 940350001 USA c Dipartimento di Ingegneria dellInformazione Università degli Studi di Brescia Via Branze 38 I25123 Brescia Italy d Free University BozenBolzano Viale Ratisbona 16 I39042 Bressanone Italy e IBM India Research Laboratory New Delhi Bangalore India r t c l e n f o b s t r c t Article history Received 12 January 2011 Received revised form 16 May 2012 Accepted 16 May 2012 Available online 18 June 2012 Keywords Planning Partial preferences Diverse plans Heuristics Search 1 Introduction Current work planning preferences assumes user preferences completely speciﬁed aims search single solution plan satisfy In real world planning scenarios user provide knowledge best partial knowledge preferences respect desired plan In situations presenting single plan solution planner instead provide set plans containing plans similar user prefers In paper ﬁrst propose usage different measures capture quality plan sets These domainindependent distance measures based plan elements actions states causal links knowledge user preferences given Integrated Convex Preference ICP measure case incomplete knowledge preferences provided We investigate heuristic approaches generate sets plans accordance measures present empirical results demonstrate promise methods 2012 Elsevier BV All rights reserved In real world planning scenarios user preferences plans unknown best partially speciﬁed cf 33 In cases planners task changes ﬁnding single optimal plan ﬁnding set representative solutions options The user presented set hope ﬁnd constituent plans desirable accordance preferences Most work automated planning ignores reality assumes instead user preferences expressed provided terms completely speciﬁed objective function This work extension work presented Srivastava et al 2007 51 Nguyen et al 2009 42 Corresponding author Email addresses natuanasuedu TA Nguyen minhbdonasagov M Do gereviniingunibsit AE Gerevini ivanserinaunibzit I Serina sbiplavinibmcom B Srivastava raoasuedu S Kambhampati 1 Authors listed alphabetical order exception ﬁrst 2 Company aﬃliation Stinger Ghaffarian Technologies SGT Inc 00043702 matter 2012 Elsevier BV All rights reserved httpdxdoiorg101016jartint201205005 2 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 In article study problem generating set plans partial knowledge user preferences This set generated hope user ﬁnd desirable according preferences Speciﬁcally consider qualitatively distinct scenarios The planner aware user preferences solution plan provided knowledge preferences The planner provided incomplete knowledge user preferences form plan attributes duration cost ﬂight importance delivering priority packages time logistics problem Each plan attributes different unknown degree importance represented weights tradeoff values In general users ﬁnd hard indicate exact value tradeoff likely indicate attribute important For instance business executive consider duration ﬂight important factor cost Incompletely speciﬁed preferences modeled probability distribution weight values3 assumed input planner attributes In cases focus returning set plans In principle larger plan set implies user better chance ﬁnding plan desires problems computational comprehensional Plan synthesis single plan costly terms computational resources large set plans cost increases The comprehensional problem unclear user able completely inspect set plans order ﬁnd plan prefers What clearly needed ability generate set plans highest chance including users preferred plan sets bounded small number plans An immediate challenge direction formalizing means meaningful set plans words want deﬁne quality measure plan sets given incomplete preference speciﬁcation We propose different quality measures scenarios listed In extreme case user unable provide knowledge preferences deﬁne spectrum distance measures plans based syntactic features order deﬁne diversity measure plan sets These measures regardless user preferences maximizing diversity plan set increase chance set uniformly distributed unknown preference space This makes likely set contains plan close desired user The quality measure reﬁned knowledge user preferences provided We assume speciﬁed convex combination plan attributes mentioned incomplete sense distribution tradeoff weights exact values available The complete set best plans plans best value function pictured lower convex hull Pareto set attribute space To measure quality bounded set plans complete optimal set adapt idea Integrated Preference Function IPF 14 particular special case Integrated Convex Preference ICP This measure developed Operations Research OR community context multicriteria scheduling able associate robust measure representativeness set solution schedules 21 Armed quality measures formulate problem planning partial user preferences ﬁnd ing bounded set plans best quality value Our contribution investigate effective approaches quality measures search high quality plan set eﬃciently For ﬁrst scenario preference speciﬁcation provided representative planning approaches considered The ﬁrst GPCSP 19 typiﬁes issues involved generating diverse plans bounded horizon compilation approaches second LPG 27 typiﬁes issues involved modifying heuristic search planners Our investigations GPCSP allow compare relative diﬃculties enforcing diversity different distance measures deﬁned forthcoming sections With LPG ﬁnd proposed quality measure makes effective generating plan sets large problem instances For second case user preferences provided present spectrum approaches solve problem eﬃciently We implement approaches MetricLPG 28 Our empirical evaluation compares approaches methods gener ating diverse plans ignoring partial preference information results demonstrate promise proposed solutions The rest paper organized follows We start comprehensive discussion related work Section 2 Section 3 reviews fundamental concepts preferences introduces formal notations In Section 4 formalize proposed quality measures plan sets cases unknown partially known user preferences Sections 5 6 present experimentally evaluate heuristic approaches generating plan sets respect introduced quality measures Finally Section 7 characterizes limitations approaches Section 8 presents conclusions outlines future directions 3 If prior information probability distribution option initialize uniform distribution gradually improve based interaction user TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 3 2 Related work There currently research efforts planning literature explicitly consider incompletely speciﬁed user preferences planning The common approach handling multiple objectives assume speciﬁc way combining objectives available 4420 search optimal plan respect function In sense work considered assuming complete speciﬁcation user preferences Other relevant work includes 13 authors devise variant LAO algorithm search conditional plan multiple execution options observation branch options nondominated respect objectives like probability cost reach goal Our work seen complementing current research planning preferences Under umbrella planning preferences current work planning focuses synthesizing single solution plan assumption user preferences single best solution assuming complete knowledge preferences given planner We hand address problem synthesizing set plans knowledge user preferences completely unknown4 partially speciﬁed In context decisiontheoretic planning work considered Markov decision processes imprecise reward functions represent user preferences visited states execution These methods assume true reward function revealed execution policies setting incomplete knowledge user preferences resolved synthesis plans plan execution required effort user Many different notions optimality policies deﬁned respect incomplete reward function aim search optimal policy The minimax regret criterion 454655 deﬁned quality policies true reward function deterministic unknown given set functions This criterion seeks optimal policy minimizes loss terms expected discounted reward assuming presence adversary selects reward function possible ones maximize loss policy chosen Another criterion called maximin maximizes worstcase expected reward assuming adversary acting optimally agent 38 Incomplete knowledge user preferences resolved effort user plan generation This idea unfortunately considered previous work automated planning preferences work related areas decision theory preference elicitation In 17 user provided sequence queries time optimal strategy respect reﬁned preference model meets stopping criterion output user That work ignores users diﬃculty answering questions posted instead emphasizes construction best value information step This issue overcome Boutilier 6 takes account cost answering future elicitation questions order reduce users effort Boutilier et al 9 consider preference elicitation problem incompleteness user preferences speciﬁed set features utility function In systems implementing examplecritiquing interaction mechanism 5437 user critiques examples options presented information revise preference model The process continues user pick ﬁnal choice k examples presented There important difference methods outcomes conﬁgurations scenarios considered given upfront obtained low cost feasible solution planning domains computationally expensive synthesize As result interactive method sequence plans sets plans needs generated critiquing suitable applications Our approach presents set plans user select requires effort user time avoids presenting single optimal plan according pessimistic optimistic assumptions minimax regret maximin criteria The problem reasoning partially speciﬁed preferences long studied multiattribute utility theory work different ignoring computation cost alternatives Given prior preference statements user compares alternatives Hazen 31 considers additive multiplicative utility functions unknown scaling coeﬃcients represents user partial preferences proposes algorithms consis tency problem exists complete utility function consistent prior preferences dominance problem prior information implies alternative preferred potential optimality prob lem exists complete utility function consistent prior preferences particular alternative preference optimal Ha Haddawy 30 addressed problems multilinear utility functions known coeﬃcients These efforts similar user preferences partially represented However similar examplecritiquing work mentioned assume user able provide pairwise comparison alternatives constrain set complete utility functions representing user preferences Our approach generating diverse plan sets cope planning scenarios knowledge user preferences spirit 52 4041 different purposes Myers particular presents approach generate diverse plans context HTN planner requiring metatheory domain available bias metatheoretic elements control search 41 The metatheory domain deﬁned terms predeﬁned attributes possible values covering roles features measures Our work differs respects First 4 Note knowing users preferences different assuming user preferences 4 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 1 The planning problem unknown A partially known B user preferences reformulated problem synthesizing plansets complete preferences plansets C focus domainindependent distance measures Second consider computation diverse plans context domainindependent planners The problem ﬁnding multiple butsimilar plans considered context replanning 22 Our work focuses problem ﬁnding diverse plans variety measures user preferences exist completely unknown partially speciﬁed Outside planning literature closest connection ﬁrst work Gelain et al 25 consider soft constraint satisfaction problems CSPs incomplete preferences These problems quantitative values constraints represent preferences unspeciﬁed Given incomplete preferences authors interested ﬁnding single solution necessarily optimal possibly effort user assignment variables optimal possible ways currently unspeciﬁed preferences revealed In sense notion optimality similar maximin criterion seeking solution optimal worst selection unspeciﬁed preferences Hebrard et al 32 use model closer focuses problem ﬁnding similardissimilar solutions CSPs assuming domainspeciﬁc distance measure solutions deﬁned It instructive note unlike CSPs ﬁnite variable domains number potential solutions ﬁnite albeit exponential number distinct plans given problem inﬁnite Thus effective approaches generating good quality set plans critical The challenges ﬁnding set interrelated plans bear tangential similarities work search areas applications In information retrieval Zhang et al 56 return relevant novel nonredundant documents stream documents approach ﬁrst ﬁnd relevant docs ﬁnd non redundant ones In adaptive web services composition causal dependencies web services change execution time result web service engine wants set diverse planscompositions failure executing composition alternative likely failing simultaneously 15 However user helping selecting compositions planner ﬁrst asked set plans account users trust particular sources selects asked ﬁnd plans similar selected Another example use diverse plans 39 test cases graphical user interfaces GUIs generated set distinct plans corresponding sequence actions user perform given users unknown preferences interact GUI achieve goals The capability synthesizing multiple plans potential application casebased planning 48 important plan set satisfying case instance These plans different terms criteria resources makespan cost speciﬁed retrieval phase The primary focus paper scenarios end user interested single plans preferences single plan unknown partially known planner Our work shows effective technique handling scenarios generate set diverse plans present user select single plan interested While came sets plans intermediate step handling lack preference knowledge single plans applications end user fact interested sets plans aka plansets preferences plansets Techniques handling problem overlap techniques develop paper important remember distinct motivations Fig 1 makes distinctions clear considering orthogonal dimensions The Xaxis concerned end user interested single plans plansets The Yaxis concerned degree knowledge user preferences In space traditional planning preferences corresponds singleplan fullknowledge The problems considering paper singleplan noknowledge singleplan partialknowledge respectively A contribution work problems reformulated planset TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 5 fullknowledge quality plansets evaluated internal diversity measures develop There compelling motivations study planset fullknowledge problem right end user explicitly interested plansets This case example applications intrusion detection 5 objective come set plans inhibit breaches option generation mission planning commander wants set options immediately commit study tradeoffs The techniques develop paper related equivalent techniques inputs solving planset generation problem In particular end users interested plan sets preferences plansets single plans5 This means need language support expressing preferences plan sets work DDPREF language 18 ii planner input support wide variety planset preferences contrast current planset preference decided internally terms distance measures unknown single plan preference case terms IPF measure partially known preference cases6 3 Background notation cid3 cid3 cid3 cid3 cid3 cid3 cid3 cid3 Note ordering partial possible p cid4 p Given planning problem set solution plans S user preference model transitive reﬂexive relation cid3 means user prefers p cid3 cid4 p holds p cid3 cid4 p holds A plan p considered strictly cid3 cid4 p A plan A plan set P S considered preferred incomparable exists p P S S deﬁnes ordering plans p p p words incomparable total p cid4 p denoted p p preferred plan p p optimal preferred plan p cid4 p P cid3 S denoted P cid7 P cid3 cid3 P cid3 p p p cid3 cid2 p equally preferred p cid4 p S Intuitively p cid4 p p P p plan p incomparable p cid4 p p p cid3 P cid3 p p p The ordering cid4 implies partition S disjoint plan sets classes S0 S1 S0 S1 S Si S j plans set equally preferred set Si S j Si cid7 S j S j cid7 Si incomparable The partial ordering sets represented Hasse diagram 3 sets vertices upward edge S j Si Si cid7 S j Sk partition Si cid7 Sk cid7 S j We denote lSi layer set Si diagram assuming preferred sets placed layer 0 lS j lSi 1 edge S j Si A plan set layer smaller value general preferred incomparable ones layers higher values7 Fig 2 shows examples Hasse diagrams representing total partial preference ordering plans We use representation plan sets Section 4 justify design quality measures plan sets knowledge user preferences available cid3 cid3 cid3 cid3 The preference model user explicitly speciﬁed iterating set plans providing ordering case answering queries comparing plans ﬁnding preferred optimal plan easy task This practically infeasible synthesizing plan hard solution space planning problem inﬁnite Many preference languages proposed represent relation cid4 compact way serve starting points algorithms answer queries Most preference languages fall following categories cid3 V p cid2 V p Quantitative languages deﬁne value function V S R assigns real number plan precise cid3 Although function deﬁned differently languages high interpretation p cid4 p level combines user preferences aspects plan measured quantitatively For instance context decisiontheoretic planning 8 value function policy deﬁned expected rewards states visited policy executes In partial satisfaction oversubscription planning PSP 4953 quality plans deﬁned total rewards soft goals achieved minus total action costs In PDDL21 23 value function arithmetic function numerical ﬂuents plan makespans fuel PDDL3 26 enhanced individual preference speciﬁcations state trajectory constraints deﬁned formulae modal operators having semantics consistent modal operators linear temporal logic 43 modal temporal logics 5 This akin college having explicit preferences freshman classes student body diversity preferences individual students 6 As analogy partial order planning originally invented speed plan generation classical planning end solutions action sequences Of course technique partial order planning useful end user interested action sequences concurrent plans In case need preference language allows user express preferences concurrent plans relax speciﬁc simpliﬁcations normal partial order planners single contributor causal link semantics Another interesting analogy MDP discrete state space POMDPS context partial observability The POMDPS handled compiling MDPs continuous state spaces speciﬁcally MDPs space belief states It possible end user interested fully observable MDPs continuous state spaces While problem related problem solving POMDPs MDPs beliefspace important differences In particular reward function continuous MDP terms continuous states case POMDPs terms underlying discrete states Further eﬃciency tricks techniques POMDPs employ based fact value function convex beliefspace longer hold general continuous MDPs 7 If cid4 total ordering plans layer smaller value strictly preferred ones layer higher value 6 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 2 The Hasse diagrams layers plan sets implied preference models In S1 cid7 S2 cid7 S3 plans comparable In b hand S1 cid7 S2 cid7 S4 S1 cid7 S3 plan S3 incomparable plans S2 S4 Fig 3 The metamodel 11 The user preference model compactly represented preference language algorithms perform tasks answering queries Qualitative languages provide qualitative statements intuitive lay users specify A commonly language type CPnetworks 7 user specify preference statements values plan tributes possibly given speciﬁcation instance Among tickets prices I prefer airline A airline B Another example LPP 2 statements speciﬁed LTL formulae possibly aggregated different ways Fig 3 shows conceptual relation preference models languages algorithms We refer reader work Brafman Domshlak 11 detailed discussion metamodel Baier McIlraith 1 overview different preference languages planning preferences From modeling point view order design suitable language capturing user preference model modeler provided knowledge users affects way evaluates plans instance ﬂight duration ticket cost travel planning scenario Such knowledge cases completely speciﬁed Our purpose present bounded set plans user hope increase chance ﬁnd desired plan In section formalize quality measures plan sets situations knowledge user preferences given 4 Quality measures plan sets 41 Syntactic distance measures unknown preference cases We ﬁrst consider situation user preferences solution plans planner provided knowledge preferences It impossible planner assume particular form prefer ence language representing hidden preference model There issues need considered formalizing quality measure plan sets What elements plans involved quality measure How quality measure deﬁned elements For ﬁrst question observe users normally interested high level features plans relevant features considered functions base level elements plans For instance set actions plan determines makespan sequential plan sequence states plan executes gives total reward goals achieved We consider following types base level features plans deﬁning quality measure independently domain semantics TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 7 Table 1 The pros cons different base level elements plan Basis Actions States Causal links Pros Cons Does require problem information No problem information Not dependent speciﬁc plan representation Considers causal proximity state transitions action positional physical proximity Needs execution simulator identify states Requires domain theory Actions present plans deﬁne high level features plans makespan execution cost user preference model represented preference languages PSP PDDL21 Sequence states agent goes captures behaviors resulting execution plans In preference languages deﬁned high level features plans reward goals collected PSP state MDP temporal relation propositions occurring states PDDL3 PP 50 LPP 24 sequence states affect quality plan evaluated user The causal links representing actions contribute goals achieved measures causal structures plans8 These plan elements affect quality plans respect languages mentioned causal links capture actions appearing plan temporal relation actions variables A similar conceptual separation features considered recently context casebased planning Serina 48 planning problems assumed classiﬁed terms costs adapt plans problem solve unknown high level feature space The similarity problems space implicitly deﬁned kernel functions domainindependent graph representations In situation aim approximate quality plan sets space features user interested distance plans respect base level features mentioned Table 1 gives pros cons different base level elements plan We note actions plans deﬁning quality measure plan sets additional problem domain theory information needed If plan behaviors base level elements representation plans bring state transition irrelevant actual states execution plan considered Hence compare plans different representations plans ﬁrst deterministic plan second contingent plan hierarchical plan fourth policy encoding probabilistic behavior If causal links causal proximity actions considered physical proximity plan Given base level elements question deﬁne quality measure plan sets Recall knowledge user preferences way planner assume particular preference language motivation choice quality measure come hidden user preference model Given Hasse diagram induced user preference model kplan set presented user considered randomly selected diagram The probability having plan set classiﬁed class optimal layer Hasse diagram increase individual plans likely different layers chance turn increase likely equally preferred user9 On hand effect base level elements plan high level features relevant user suggests plans similar respect base level features likely close high level feature space determining user preference model In order deﬁne quality measure base level features plans proceed following assumption plans different respect base level features likely equally preferred user words likely different layers Hasse diagram With purpose increasing chance having plan user prefers propose quality measure plan sets diversity measure deﬁned distance S R plan plans set respect base level element More formally quality measure ζ 2 set P deﬁned minimal maximal average distance plans minimal distance ζminP min ppcid3P cid2 δ p p cid3 cid3 1 8 A causal link a1 p a2 records proposition p produced a1 consumed a2 9 To consider diagram S1 p1 p2 layer 0 S2 p3 S3 p4 layer 1 S4 p5 layer 2 Assuming randomly 2 However forced select set 2 plans If plans known layer chance having plan layer 0 1 different layers probability 3 4 8 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 maximal distance ζmaxP max ppcid3P cid2 δ p p cid3 cid3 average distance ζavgP cid4 P cid51 2 cid6 cid2 δ p p cid3 cid3 ppcid3P δ S S 0 1 distance measures plans 2 3 411 Distance measures plans There choices deﬁne distance measure δp p cid3 plans plan actions sequence states causal links way different impact diversity plan set Hasse diagram In following propose distance measures plan considered set actions causal links ii sequence states agent goes independently plan representation total order partial order plans Plan set actions causal links given plan p let Ap Cp set actions causal links p The deﬁned ratio number actions causal links distance plans p p appear plans total number actions causal links appearing cid3 cid2 δa p p cid3 cid3 1 cid2 δcl p p cid3 cid3 1 cid3 Ap Ap Ap Apcid3 cid3 Cp Cp Cp Cpcid3 4 5 cid3 Plan sequence states given sequences states s0 s1 sk s plans p p options deﬁning distance measure p p deﬁned average distances state pairs si s contribute maximally unit difference plans cid3 cid3 kcid3 resulting executing 0 s cid3 cid2 k Since sequences states different lengths consider options In ﬁrst cid3 state skcid31 sk considered cid3 0 cid2 cid2 k assume k cid3 1 s cid3 cid2 δs p p cid3 cid3 1 k cid2 cid4 si s cid3 cid3 cid8 k k cid3 cid7 cid3cid6 k i1 On hand assume agent continues stay goal state s executing p measure deﬁned follows cid3 cid2 δs p p cid3 cid3 1 k cid7 cid3cid6 k i1 cid2 cid4 si s cid3 cid3 kcid6 ikcid31 cid8 cid3 cid2 cid4 cid3 si s kcid3 cid3 states s s The distance measure cid4s s cid3 s s s scid3 1 s s cid4 cid3 cid2 cid3 cid3 measures deﬁned 6 cid3 kcid3 k k cid3 time steps 7 8 These distance metrics consider long plans distant short plans In absence information user preferences rule possibility unknown preference actually favor longer plans possible longer plan cheaper actions making attractive user In implementation computing diverse plans distance measures affect partial plan search space planner tends focus general length resulting plans especially depends search strategy planner tempts minimize In experiments use types planners employing exhaustive search local search respectively For second attempt minimize plan length introduce additional constraints search mechanism balancing differences generated diverse plans attempts control relative size resulting plans Example Fig 4 shows plans p1 p2 p3 planning problem initial state r1 goal propositions r3 r4 The speciﬁcation actions shown table The action sets ﬁrst plans a1 a2 a3 a1 a2 a4 similar δap1 p2 05 causal links involve a3 a2 r3 a3 a3 r4 aG TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 9 Fig 4 Example illustrating plans baselevel elements aI aG denote dummy actions producing initial state consuming goal propositions respectively text details a4 aI r1 a4 a4 r4 aG difference signiﬁcant respect causallink based distance δclp1 p2 4 7 Two plans p1 p3 hand different terms action sets sets causal links δap1 p3 1 closer term statebased distance 13 18 deﬁned Eq 6 05 deﬁned Eq 7 42 Integrated Preference Function IPF partial preference cases We discuss quality measure plan sets case user preference partially expressed In par ticular consider scenarios preference model represented quantitative language incompletely speciﬁed value function high level features As example quality plans PDDL21 23 PDDL3 26 represented metric function combining metric ﬂuents preference statements state trajectory pa rameters representing relative importance While providing convenient way represent preference models parameterized value functions present issue obtaining reasonable values relative importance features A common approach model type incomplete knowledge consider parameters vector random variables values assumed drawn distribution This representation follow To measure quality plan sets propose usage Integrated Preference Function IPF 14 measure quality solution set wide range multiobjective optimization problems The IPF measure assumes user preference model represented factors 1 probability distribution hα parameter cid9 αΛ hα dα 1 absence special information vector α domain denoted Λ distribution hα assumed uniform 2 value function V p α S Λ R combines different objective functions single realvalued quality measure plan p We assume objective functions represent aspects plans minimized makespan execution cost This incomplete speciﬁcation value function represents set candidate preference models user select different plan best value given plan set P S The IPF value solution set P deﬁned cid10 IPFP hαV pα α dα αΛ 9 pα argminpP V p α best solution P according V p α given α value Let p 1 α values p optimal solution according V p α V p α cid2 V p α p cid3 α α p 1 α range cid3 P p As pα piecewise constant IPFP value computed cid11 cid10 IPFP cid6 pP cid12 Let P p P p 1 α cid14 hαV p α dα αp 1 α 10 10 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 IPFP IPF cid3 cid2 P cid12 hαV p α dα cid11 cid10 cid6 pP αp 1 α 11 Since P set plans optimal speciﬁc parameter vector IPFP interpreted expected value user selecting best plan P Therefore set P solutions known lower convex hull P minimal IPF value likely contain desired solutions user wants essence good representative plan set P 1 The requirement IPFP exist function hαV p α needs integrable p α domains10 The α p P 1 complication computing IPFP value deriving partition Λ domain α ranges p computation integration ranges parameter vector As computational effort obtain IPFP negligible work objectives Although scope article refer readers Kim et al 35 calculation measure value function convex combination high number objectives Bozkurt et al 10 weighted Tchebycheff value function criteria In work order discussion generating plan sets concrete concentrate metric temporal planning action A duration da execution cost ca The planner needs ﬁnd plan p cid15a1 ancid16 sequence actions executable achieves goals The common plan quality measures makespan total execution time p plan cost total execution cost actions p Both high level features affected actions plan In realworld applications criteria compete shorter plans usually higher cost vice versa We use following assumptions The desired objective function involves minimizing components timep measures makespan plan p costp measures execution cost The quality plan p convex combination V p w w timep 1 w costp weight w 0 1 represents tradeoff competing objective functions The belief distribution w range 0 1 known If user provide information learned preference tradeoff time cost plan planner assume uniform distribution improve later techniques preference elicitation Given exact value w unknown purpose ﬁnd bounded representative set nondominated11 plans minimizing expected value V p w regard given distribution w 0 1 IPF metric temporal planning The user preference model target domain temporal planning represented convex combination time cost quality measures IPF measure called Integrated Convex Preference ICP Given set plans P let t p timep c p costp makespan total execution cost plan p P ICP value P regard objective function V p w w t p 1 w c p parameter vector α w 1 w w 0 1 deﬁned cid3 cid2 P ICP w icid10 kcid6 i1 w i1 cid2 hw w t pi 1 w c pi cid3 dw 12 w 0 0 wk 1 V pi w cid2 V p w p P pi w w i1 w In words divide 0 1 k nonoverlapping regions region w i1 w optimal solution pi P according value function We select IPFICP measure evaluate solution set following reasons From perspective decision theory presenting plan set P S user possible subsets S considered action possible outcomes p P occur selected user hα dα Since IPFP measures expected utility P presenting set plans probability optimal IPF value rational action consistent current knowledge user preferences cid9 αp 1 α If P1 dominates P2 set Pareto dominance sense IPFP1 cid2 IPFP2 type weight density function hα 14 property holds scaling objective values ICP measure 21 Intuitively means merge plan sets nondominated plans extracted resulting set P1 10 Although value function form satisfying axioms preferences user preferences realworld scenarios represented approximated additive value function 47 including setting application integrable parameter domain Since hα integrable product hαV p α situations 11 A plan p1 dominated p2 timep1 cid2 timep2 costp1 cid2 costp2 inequalities strict TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 11 Fig 5 Solid dots represent plans Pareto set p1 p2 p3 p5 p7 Connected dots represent plans lower convex hull p1 p3 p7 giving optimal ICP value distribution tradeoff cost time The value IPFP monotonically nonincreasing increasing sequences solution sets set plans optimal according utility function V p α eﬃcient frontier minimal IPF value 14 Thus measure indicator quality plan set search eﬃcient frontier Empirically extensive results scheduling problems 21 shown ICP measure evaluates solution quality approximation robustly similar visual comparison results alternative measures misjudge solution quality Example Fig 5 shows running example total 7 plans timep costp values follows p1 4 25 p2 6 22 p3 7 15 p4 8 20 p5 10 12 p6 11 14 p7 12 5 Among 7 plans 5 belong Pareto optimal set nondominated plans Pp p1 p2 p3 p5 p7 The plans dominated plans Pp p4 dominated p3 p6 dominated p5 Plans Pp depicted solid dots set plans P p1 p3 p7 optimal speciﬁc value w highlighted connected dots In particular p7 optimal w w 0 0 w 1 2 3 derived satisfaction 3 constraints V p7 w cid2 V p w p p1 p3 Similarly p3 p1 respectively optimal w w 1 2 13 w 3 1 Assuming hw uniform distribution value ICPP computed w w 2 10 follows w 1 2 3 w 2 10 13 cid3 cid2 P ICP 2 3cid10 0 2 3cid10 10 13cid10 hwV p7 w dw hwV p3 w dw 2 3 1cid10 10 13 hwV p1 w dw cid13 cid14 12w 51 w dw 10 13cid10 cid13 cid14 7w 151 w dw cid13 cid14 4w 251 w dw 1cid10 10 13 0 732 2 3 In Sections 5 6 investigate problem generating high quality plan sets cases men tioned knowledge user preferences given given input planner 5 Generating diverse plan set absence preference knowledge In section approaches searching set diverse plans respect measure deﬁned base level elements plans discussed previous section In particular consider quality measure plan set minimal pairwise distance plans generate set plans containing k plans quality predeﬁned threshold d As discussed earlier diversifying set plans space base level features likely plans set cover wide range space unknown high level features increasing possibility user select plan close prefers The problem formally deﬁned follows dDISTANTkSET Find P P S P k ζ P min pqP δp q cid3 d distance measure plans formalized Section 411 implement δp p cid3 12 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 6 An example portion planning graph At level propositions presenting previous noop actions omitted level k actions support goals shown simpliﬁcation We consider representative stateoftheart planning approaches generating diverse plan sets The ﬁrst GPCSP 19 representing constraintbased planning approaches second LPG 27 uses eﬃcient localsearch based approach We use GPCSP compare relation different distance measures diversifying plan sets On hand LPG stick actionbased distance measure shown experimentally diﬃcult measure enforce diversity investigate scalability heuristic approaches generating diverse plans 51 Finding diverse plan set GPCSP The GPCSP planner 19 converts planning graph Graphplan 4 CSP encoding solves standard CSP solver A planning graph data structure consisting alternating levels proposition set action set The set propositions present initial state proposition set zeroth level graph Given klevel planning graph actions preconditions present proposition set level k introduced level k 1 In addition noop action added proposition level k precondition effect action The set propositions level k 1 constructed taking union additive effects actions level This expansion process computes propagates set mutex mutually exclusive constraints pairs propositions actions level At ﬁrst level computation starts marking mutex actions statically interfering preconditions effects inconsistent The mutex constraints propagated follows level k propositions mutually exclusive action level k achieving mutually exclusive actions level supporting ii actions level k 1 mutex statically interfering precondition ﬁrst action mutually exclusive precondition second action The planning graph construction stops level T following conditions satisﬁed goal propositions present proposition set level T mutex constraints ii consec utive levels graph sets actions propositions mutex constraints In ﬁrst case Graphplan algorithm searches graph backward level T valid plan continuing planning graph expansion new search solution exists In second condition problem provably unsolvable Fig 6 taken Do Kambhampati 19 shows example levels planning graph The toplevel goals G 1 G 4 supported actions A1 A4 level k Each actions preconditions set P 1 P 6 appear ing level k 1 turn supported actions A5 A11 level The action pairs A5 A9 A7 A11 A6 A8 mutually exclusive mutex relations pair propositions level k 1 mutually exclusive The GPCSP planner replaces search algorithm Graphplan ﬁrst converting planning graph data structure constraint satisfaction problem invoking solver ﬁnd assignment encoding represents valid plan original planning problem In encoding CSP variables correspond predicates achieved different levels planning graph different planning steps possible values actions support predicates For CSP variable representing predicate p special values indicates predicate supported action false particular levelplanningstep ii noop indicates predicate true given level true previous level j action deletes p j Constraints encode relations predicates actions 1 mutual exclusion relations predicates actions 2 causal relationships actions preconditions Fig 7 shows CSP encoding corresponding portion planning graph Fig 6 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 13 Variables Domains G 1 G 4 P 1 P 6 G 1 A1 G 2 A2 G 3 A3 G 4 A4 P 1 A5 P 2 A6 A11 P 3 A7 P 4 A8 A9 P 5 A10 P 6 A10 Constraints Mutex Constraints Activity P 1 A5 P 4 cid14 A9 P 2 A6 P 4 cid14 A8 P 2 A11 P 3 cid14 A7 G 1 A1 P 1 cid14 P 2 cid14 P 3 cid14 G 2 A2 P 4 cid14 G 3 A3 P 5 cid14 G 4 A4 P 1 cid14 P 6 cid14 Initial state G 1 cid14 G 2 cid14 G 3 cid14 G 4 cid14 Fig 7 The CSP encoding example planning graph 511 Adapting GPCSP different distance metrics When planning encoding solved standard CSP solver return solution containing cid15var valuecid16 form cid15x1 y1cid16 cid15xn yncid16 The collection xi yi cid14 represents facts true different time steps plan trajectory basis statebased distance measure12 set yi cid14 yi cid14 noop represents set actions plan actionbased distance measure lastly assignments cid15xi yicid16 represent causal relations causalbased distance measure However technical diﬃculties need overcome speciﬁc distance measure plans computed First action represented different values domains different variables Consider simple example facts p q supported actions a1 a2 When setting CSP encoding assume CSP variables x1 x2 represent p q The domains x1 x2 v 11 v 12 v 21 v 22 representing actions a1 a2 order The assignments cid15x1 v 11cid16 cid15x2 v 21cid16 cid15x1 v 12cid16 cid15x2 v 22cid16 distance 2 traditional CSP different values assigned variable x1 x2 However represent action set a1 a2 lead plan distance 0 use actionbased distance plan comparison Therefore ﬁrst need translate set values assignments set action instances comparison actionbased distance The second complication arises causalbased distance A causal link a1 p a2 actions a1 a2 indicates a1 supports precondition p a2 However CSP assignment cid15p a1cid16 provides ﬁrst half causallink To complete causallink need look values CSP assignments identify action a2 occurs later level planning graph p precondition Note multiple valid sets causallinks plan implementation simply select causallinks based CSP assignments 512 Making GPCSP return set plans To GPCSP return set plans satisfying dDISTANTkSET constraint distance measures add global constraints original encoding enforce ddiversity pair solutions When global constraint called normal forward checking arcconsistency checking procedures inside default solver check distance plans predeﬁned value d ﬁrst map set assignments actual set actions actionbased predicates true different plansteps statebased causallinks causal based method discussed previous section This process mapping cid15var valuecid16 CSP assignments action sets planning graph outside CSP solver works closely general purpose CSP solver GPCSP The comparison implementation global constraint decide solutions diverse We investigate different ways use global constraints 1 The parallel strategy return set k plans In approach create encoding contains k identical copies original planning encoding created GPCSP planner The k copies connected kk 12 pairwise global constraints Each global constraint ith jth copies ensures plans represented solutions copies d distant If copy n variables constraint involves 2n variables 2 The greedy strategy return plans In approach k copies setup parallel upfront sequentially We add ith copy global constraint enforce solution ith copy ddiverse earlier 1 solutions The advantage greedy approach CSP encoding 12 We implement statebased distance plans deﬁned Eq 6 14 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Table 2 Average solving time seconds ﬁnd plan greedy ﬁrst 3 rows random row approaches δa δs δcl Random logeasy 0087 0077 0190 0327 rocketa 7648 9354 6542 15480 loga 1021 1845 1063 8982 logb 6144 6312 6314 88040 logc 8083 8667 8437 379182 logd 178633 232475 209287 6105510 Table 3 Comparison diversity plan sets returned random greedy approaches Cases random approach better greedy approach marked δa δs δcl logeasy 0041035 003504 015808 rocketa 0067065 00508 0136095 loga 0067025 009605 0256055 logb 013101 014704 0459015 logc 0126015 014005 034603 logd 012802 010105 0349045 signiﬁcantly smaller terms number variables n vs k n smaller terms number global constraints 1 vs kk 12 global constraint contains lesser number variables n vs 2 n13 Thus encoding greedy approach easier solve However solution depends previously solutions encoding unsolvable previously solutions comprise bad initial solution set 513 Empirical evaluation We implemented parallel greedy approaches discussed earlier distance measures tested benchmark set Logistics problems provided Blackbox planner 34 All experiments run Linux Pentium 4 3 GHz machine 512 MB RAM For problem test different d values ranging 001 1 095 9514 k increases 2 n n maximum value GPCSP ﬁnd solutions plan horizon The horizon parallel plan steps limit 30 We greedy approach outperformed parallel approach solved signiﬁcantly higher number prob lems Therefore focus greedy approach For combination d k given distance measure record solving time output averageminmax pairwise distances solution sets Baseline comparison As baseline comparison implemented randomized approach In approach use global constraints use random value ordering CSP solver generate k different solutions enforcing pairwise ddistance apart For distance d continue running random algorithm ﬁnd kmax solutions kmax maximum value k solve greedy approach particular d value In general want compare approach global constraint random approach effectively generate diverse set solutions looking 1 average time ﬁnd solution solution set 2 maximumaverage pairwise distances k cid3 2 randomly generated solutions Table 2 shows comparison average solving time ﬁnd solution greedy random approaches The results average random approach takes signiﬁcantly time ﬁnd single solution regardless distance measure greedy approach To assess diversity solution sets Table 3 shows comparison 1 average pairwise minimum distance solutions sets returned random approach 2 maximum d greedy approach ﬁnd set diverse plans The comparisons distance measures For example ﬁrst cell 0041035 Table 3 implies minimum pairwise distance averaged solvable k cid3 2 random approach d 0041 035 8 diverse greedy approach δa distance measure Except 3 cases global constraints enforce minimum pairwise distance solutions helps GPCSP return signiﬁcantly diverse set solutions On average greedy approach returns 425 731 279 diverse solutions random approach δa δs δcl respectively Analysis different distancebases Overall able solve 1264 d k combinations distance measures δa δs δcl greedy approach We particularly interested investigating following issues Q1 Computational eﬃciency Is easy diﬃcult ﬁnd set diverse solutions different distance measures Thus 1 d k values distance measure diﬃcult time consuming solve 2 given encoding horizon limit high value d k ﬁnd set solutions given problem different distance measures 13 However constraint complicated encodes 1 previously solutions 14 Increments 001 001 01 005 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 15 Table 4 For given d value cell shows largest solvable k distance measures δa δs δcl order The maximum values cells bold d 001 003 005 007 009 01 02 03 04 05 06 07 08 09 logeasy 11 5 28 6 3 24 5 3 18 2 3 14 2 3 14 2 3 10 2 3 5 2 2 3 1 2 3 1 1 3 1 1 2 1 1 2 1 1 2 rocketa 8 18 12 8 13 9 6 11 9 6 10 8 6 9 6 6 9 6 5 9 6 4 7 5 3 6 5 2 4 5 2 3 4 1 2 2 1 2 2 1 1 2 loga 9 818 7 7 12 5 7 10 47 6 36 6 36 6 26 6 1 4 4 1 3 3 1 2 2 logb 3 4 5 2 4 3 2 4 3 2 4 2 2 4 2 2 4 2 1 3 1 1 2 1 1 2 1 logc 4 6 8 46 6 46 5 46 5 36 4 26 4 1 5 2 1 3 2 1 2 1 1 2 1 logd 8 7 7 4 7 6 37 5 37 5 37 4 37 4 2 5 3 13 3 1 2 3 12 1 Table 5 Crossvalidation distance measures δa δs δcl δa δs δcl δa 0485 0461 δs 1262 0938 δcl 1985 0883 Q2 Solution diversity What correlationsensitivity different distance measures Thus comparative diversity solutions different distance measures Regarding Q1 Table 4 shows highest solvable k value distance d base δa δs δcl For given d k pair enforcing δa appears diﬃcult δs δcl easiest GPCSP able solve 237 462 565 combinations d k respectively δa δs δcl GPCSP solves dDISTANTkSET problems easily δs δcl δa fact solutions different action sets diverse regard δa likely cause different trajectories causal structures diverse regard δs δcl Between δs δcl δcl solves problems easier instances logeasy rocketa loga harder instances shown Table 4 We conjecture solutions actions bigger problems causal dependencies actions harder reorder actions create different causal structure For running time comparisons 216 combinations d k solved distance measures GP CSP takes time δa 84 combinations δs 70 combinations 62 δcl The ﬁrst lines Table 2 average time ﬁnd solution ddiverse kset problem δa δs δcl ta ts tc respectively In general ta smallest ts tc problems Thus harder enforce δa δs δcl indicated Table 4 encodings distances solved given d k δa takes time search plan diverse plan set tighter constraints pruning power global constraints simpler global constraint setting cid3 cid3cid3 d distance measured according δcid3cid3 To test Q2 Table 5 crosscomparison different distance measures δa δs δcl In table cid3 cid3cid3d cell cid15row columncid16 cid15δcid3 δcid3cid3cid16 indicates combinations d k solved distance δcid3 cid3 cid3 d For example cid15δs δacid16 0485 means δcid3 d 462 combinations d k solvable δs d average distance k solutions measured δa 0485 ds The results indicate enforce d δa likely ﬁnd diverse solution sets according δs 126 da δcl 198 da However enforce d δs δcl likely ﬁnd diverse set solutions measured distance measures Nevertheless enforcing d δcl likely comparable diverse degree d δs 094 dc vice versa We observe ds highly dependent difference parallel lengths plans set The distance ds smallest ds da dc k plans samesimilar number time steps This consistent fact δa δcl depend steps plan execution trajectory δs average value d respectively d 52 Finding diverse plan set LPG In section consider problem generating diverse sets plans planning approach particular LPG planner able scale bigger problems compared GPCSP We focus actionbased distance measure plans shown previous section diﬃcult enforce diversity LPG localsearchbased planner incrementally modiﬁes partial plan search plan contains ﬂaws 27 16 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 The behavior LPG controlled evaluation function select different plan candidates neighborhood generated local search At search step elements search neighborhood current partial plan π alternative possible plans repairing selected ﬂaw π The elements neighborhood evaluated according action evaluation function E 27 This function estimate cost adding removing action node partial plan p generated 521 Revised evaluation function diverse plans In order manage ddistancekset problems function E extended include additional evaluation term purpose penalizing insertion removal actions decrease distance current partial plan p adaptation reference plan p0 In general E consists weighted terms evaluating aspects quality current plan affected addition Eai removal Ear Eai αE Execution_costai αT Temporal_costai αS Search_costai αD Ear αE Execution_costar αT Temporal_costar αS Search_costar αD cid15 cid15p0 p pi cid15 cid15p0 p pr cid15 cid15 R cid15 cid15 R The ﬁrst terms forms E unchanged standard behavior LPG The fourth term computing diverse plans new term estimating proposed plan modiﬁcation affect distance reference plan p0 Each cost term E computed relaxed temporal plan p R 27 The p R plans computed algorithm called RelaxedPlan formally described illustrated 27 We slightly modiﬁed algorithm penalize selection actions decreasing plan distance reference plan The speciﬁc change RelaxedPlan computing diverse plans similar change described 22 concerns heuristic function selecting actions achieving subgoals relaxed plans In modiﬁed function RelaxedPlan extra 01 term penalizes action b p R addition decreases distance p p R p0 plan repair context investigated 22 b penalized addition increases distance p0 p pr R The term modiﬁed evaluation function E measure decrease plan distance caused adding removing p0 p pi R contains new action The αcoeﬃcients Eterms R weigh relative importance15 The values ﬁrst 3 terms automatically derived expression deﬁning plan metric problem 27 The coeﬃcient fourth new term E αD automatically set search value proportional dδap p0 p current partial plan construction The general idea dynamically increase value αD according number plans n generated far n higher k search process consists ﬁnding solutions diversiﬁcation importance Eterm increase pi 522 Making LPG return set plans In order compute set k ddistant plans solving ddistancekset problem run LPG multiple times problem solved following additional changes standard version LPG preprocessing phase computing mutex relations reachability information exploited relaxed plan construction runs ii maintain incremental set valid plans dynamically select reference plan p0 search Concerning ii let P p1 pn set n valid plans computed far CPlanspi subset P containing plans distance greater equal d reference plan pi P The reference plan p0 modiﬁed heuristic function E plan pmax P maximal set diverse cid16cid15 cid15 cid15CPlanspi cid15 cid17 13 plans P pmax argmax pi P The plan pmax incrementally computed time local search ﬁnds new solution In addition identify reference plan E pmax deﬁning initial state partial plan search process Speciﬁcally initialize search partial plan obtained randomly removing actions randomly selected plan set CPlanspmax pmax The process generating diverse plans starting dynamically chosen reference plan continues k plans ddistant produced The modiﬁed version LPG compute diverse plans called LPGd 523 Experimental analysis LPGd Recall distance function δa setdifference written sum terms δapi p j Api Ap j Api Ap j Ap j Api Api Ap j 14 15 These coeﬃcients normalized value 0 1 method described 27 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 17 Fig 8 Performance LPGd CPU time plan distance problem pﬁle20 DriverLogTime domain The ﬁrst term represents contribution actions pi plan difference second term indicates contribution p j δa We experimentally observed cases differences diverse plans computed δa concentrated δa components This asymmetry means plans actions imply quality plans worse quality plan In order avoid problem parametrize δa imposing extra constraints cid3 dγ δ B δ A δ B δ A ing diversity pi p j cid3 dγ ﬁrst second terms RHS Eq 14 respectively γ integer parameter balanc In section analyze performance LPGd different benchmark domains DriverLog Satellite Storage FloorTile 3rd 5th 7th IPCs16 The main goals experimental evaluation showing LPGd eﬃciently solve large set d kcombinations ii investigating impact δa γ constraints performance iii comparing LPGd standard LPG We tested LPGd default parametrized versions δa γ 2 γ 3 We detailed results γ 3 general evaluation γ 2 original δa We consider d varies 005 095 005 increment step k 2 5 6 8 10 12 14 16 20 24 28 32 overall total 266 d kcombinations Since LPGd stochastic planner use median CPU times seconds median average plan distances ﬁve runs The average plan distance set k plans solving speciﬁc d kcombination δav average plans distances pairs plans set The tests performed IntelR XeonTM CPU 300 GHz 3 GB RAM The CPUtime limit 300 seconds 16 We similar results domains Rovers IPC35 Pathways IPC5 Logistics IPC2 ZenoTravel IPC3 18 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 9 Performance LPGd CPU time plan distance problem pﬁle20 SatelliteStrips domain Fig 8 gives results largest problem IPC3 DriverLogTime domain fullyautomated track LPGd solves 161 d kcombinations including combinations d cid2 04 k 20 d 095 k 2 The average CPU time plots 15185 seconds The average δav plots 073 δav greater 057 With original δa function LPGd solves 168 d kcombinations average CPU time 1495 seconds average δav 073 γ 2 LPGd solves 139 combinations average CPU time 1442 seconds average δav 072 Fig 9 shows results largest problem IPC3 SatelliteStrips domain LPGd solves 242 k dcombinations 153 require 10 seconds The average CPU time 546 seconds average δav 069 We observed similar results original δa function parametrized δa γ 2 second case LPGd solves 230 problems average CPU time average δav nearly γ 3 Fig 10 shows results middlesize problem IPC5 StoragePropositional domain With γ 3 LPGd solves 252 k dcombinations 58 require 10 seconds 178 require 50 seconds The average CPU time 254 seconds average δav 091 With original δa LPGd solves 257 k dcombinations average CPU time 145 seconds average δav 09 γ 2 LPGd solves 201 combinations average CPU time 31 seconds average δav 093 Fig 11 gives results largest problem IPC7 FloorTileMetricTime domain LPGd solves 210 d k combinations 171 require 10 seconds The average CPU time 36 seconds average δav 07 We observed similar results original δa function parametrized δa γ 2 second case LPGd solves 191 problems average CPU time average δav nearly γ 3 The local search LPG randomized noise parameter automatically set updated search 27 This randomization techniques escaping local minima useful computing diverse plans run search multiple times search likely consider different portions search space lead different solutions It interesting compare LPGd method simply run standard LPG k ddiverse plans generated An experimental comparison approaches cases TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 19 Fig 10 Performance LPGd CPU time plan distance problem pﬁle15 StoragePropositional domain LPGd performs better In particular new evaluation function E especially useful planning problems easy solve standard LPG admit solutions In cases original E function produces valid plans diversiﬁcation This problem signiﬁcantly alleviated new term E An example domain observed behavior Logistics17 6 Generating plan sets partial preference knowledge In section consider problem generating plan sets user preferences partially expressed In particular focus metric temporal planning preference model assumed represented incomplete value function speciﬁed convex combination features plan makespan execution cost exact tradeoff value w drawn given distribution The quality value plan sets measured ICP value formalized Eq 12 Our objective ﬁnd set plans P S P cid2 k ICPP lowest Notice restrict size solution set returned comprehension issue discussed earlier important property ICP measure monotonically nonincreasing function solution set speciﬁcally given solution sets P1 P2 superset easy ICPP2 cid2 ICPP1 17 For example LPGd solved 176 instances log_a problem 47 1 CPU second 118 10 CPU seconds average CPU time 375 seconds average δav 047 While standard LPG 107 instances solved 27 1 CPU seconds 73 10 CPU seconds average CPU time 514 seconds average δav 033 20 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 11 Performance LPGd CPU time plan distance problem pﬁle20 FloorTileMetricTime domain 61 Sampling weight values Given distribution tradeoff value w known straightforward way ﬁnd set representative solutions ﬁrst sample set k values w w 1 w 2 wk based distribution hw For value w ﬁnd optimal plan pi minimizing value overall value function V p w w t p 1 w c p The ﬁnal set solutions P p1 p2 pk ﬁltered remove duplicates dominated solutions selecting plans making lower convex hull The ﬁnal set returned user While intuitive easy implement samplingbased approach potential ﬂaws limit quality resulting plan set First given k solution plans searched sequentially independently plan pi optimal ﬁnal solution set P p1 p2 pk optimal set k solutions w regard ICP measure More speciﬁcally given set solutions P tradeoff value w nondominated plans p q V p w V q w possible ICPP p ICPP q In running example Fig 5 let P p2 p5 w 08 V p1 w 08 4 02 25 82 V p7 w 08 12 02 5 106 Thus planner select p1 add P looks locally better given weight w 08 However ICPp1 p2 p5 1005 ICPp2 p5 p7 771 taking previous set consideration p7 better choice p1 Second values tradeoff parameter w sampled based given distribution independently particular planning problem solved As relation sampled w values solution space given planning problem sampling approach return distinct solutions sample large number weight values w In example w samples values w cid2 067 optimal solution returned p7 However know P p1 p3 p7 optimal set according ICP measure Indeed w cid2 0769 sampling approach ﬁnd set p7 p3 p7 able ﬁnd optimal set P TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 21 Algorithm 1 Incrementally ﬁnd solution set P 1 Input A planning problem solution space S maximum number plans required k number sampled tradeoff values k0 0 k0 k time bound t 2 Output A plan set P P cid3 k 3 begin 4 5 6 7 8 W sample k0 values w P ﬁnd good quality plans S w W P k search_time t Search p st ICPP p ICPP P P p 9 10 end Return P 11 end 62 ICP sequential approach Given potential drawbacks sampling approach outlined pursued alternative approach takes account ICP measure actively Speciﬁcally incrementally build solution set P ﬁnding solution p P p lowest ICP value We start solution set P step try ﬁnd new plan p P p lowest ICP value While approach directly takes ICP measure consideration step ﬁnding new plan avoids drawbacks samplingbased approach share potential ﬂaws Given set built incrementally earlier steps ﬁrst seed solutions important The closer seed solutions global lower convex hull better improvement ICP value In example Fig 5 ﬁrst plan p2 subsequent plans best extend p2 p5 ﬁnal set come close optimal set P p1 p3 p7 63 Hybrid approach In approach aim combine strengths sampling ICPsequential approaches Speciﬁcally use sampling ﬁnd plans optimizing different weights The plans seed subsequent ICPsequential runs By seeding hybrid approach good quality plan set scattered Pareto optimal set hope gradually expand initial set ﬁnal set better overall ICP value Algorithm 1 shows pseudo code hybrid approach We ﬁrst independently sample set k0 values k0 predetermined w given distribution w step 4 We run heuristic planner multiple times ﬁnd optimal good quality solution tradeoff value w step 5 We collect plans seed subsequent runs incrementally update initial plan set plans lower overall ICP value steps 68 The algorithm terminates returns latest plan set step 9 k plans time bound exceeds 64 Making LPG search sensitive ICP We use modiﬁed version MetricLPG planner 28 implementing algorithms introducing totalcost numerical ﬂuent domain represent plan cost interested in18 Not MetricLPG equipped ﬂexible localsearch framework extended handle objective functions search single multiple solutions Speciﬁcally samplingbased approach ﬁrst sample w values based given distribution For w value set metric function domain ﬁle w makespan 1 w totalcost run original LPG quality mode heuristically ﬁnd best solution time limit metric function The ﬁnal solution set ﬁltered remove duplicate solutions returned user For ICPsequential hybrid approach use original LPG implementation need modify neighborhood evaluation function LPG account ICP measure current plan set P For rest section explain procedure Background MetricLPG uses local search ﬁnd plans space numerical action graphs NAgraph This leveled graph consists sequence interleaved proposition action layers The proposition layers consist set proposi tional numerical nodes action layer consists action node number noop links An NAgraph G represents valid plan actions preconditions supported actions appearing earlier level G The search neighborhood localsearch step deﬁned set graph modiﬁcations ﬁx remaining 18 Although interested plan cost summation action costs implementation extended planning problems plan cost expression involving numerical ﬂuents 22 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Each local creates new NAgraph G cid3 Here SearchCostG inconsistencies unsupported preconditions p particular level l This inserting new action supporting p removing graph action p precondition introduce new inconsistencies cid3 cid3 search effort resolve inconsistencies newly introduced inserting ExecCostG removing action measured number actions relaxed plan R resolving inconsistencies The cid3 default function measure plan quality measured total action execution costs total cost ExecCostG actions R The weight adjustment values α β steer search ﬁnding solution quickly higher α value better solution quality higher β value MetricLPG selects local leading smallest EG evaluated weighted combination factors SearchCostG cid3 value cid3 cid3 cid3 ICPEstG cid3 new measure ICPEstG cid3 guides MetricLPGs search plan p generated G cid3 ﬁnding set plans low ICP measure To guide MetricLPG optimizing Adjusting evaluation function EG ICPsensitive objective function instead original minimizing cost objective function need replace default cid3 Speciﬁcally adjust function evaluating plan quality measure ExecCostG cid3 Given set new NAgraph generated local moves step combination SearchCostG plans P p1 p2 pn ICPEstG cid3 estimates expected total ICP resulting set P p minimum ICP value p argminp ICPP p Thus ICPEstG added current plan set P Like original MetricLPG p value best plan p expanding G estimated p R G caused inserting removing The cid3 ICPP p R ICP measure described Eq 12 ICPEstG Notice P set valid plans p R It invalid plan represented NAgraph containing unsupported preconditions However Eq 12 applicable long measure time cost dimensions p R To measure makespan p R estimate time points unsupported facts G supported p R G level We earliest time point facts level appear measure makespan p R For cost measure sum individual costs actions p R cid3 R R relaxed plan resolving inconsistencies G cid3 R propagate actions G cid3 given NAgraph G At step MetricLPGs local search framework combining measures ICPEstG cid3 gives evaluation function ﬁts right original MetricLPG framework prefers NAgraph G neighborhood G gives best tradeoff estimated effort repair estimated decrease quality resulting plan set cid3 SearchCostG cid3 calculated ICPEstG cid3 cid3 cid3 cid3 cid3 65 Experimental results We implemented approaches based algorithms discussed previous sections Sampling Sec tion 61 ICPsequential Section 62 Hybrid combines Section 63 uniform triangular distributions We consider types distributions probable weight plan makespan 02 08 w02 w08 distributions respectively Fig 12 shows distributions We test implementations set 20 problems benchmark temporal planning domains pre vious International Planning Competitions IPC ZenoTravel DriverLog Depots The modiﬁcation original benchmark set added action costs The descriptions domains IPC website ipcicaps conferenceorg The experiments conducted Intel Core2 Duo machine 316 GHz CPU 4 GB RAM For approaches search maximum k 10 plans 10minute time limit problem t 10 min utes resulting plan set compute ICP value In Sampling approach generate tradeoff values w makespan plan cost based distribution search plan p subject value function V p w w t p 1 w c p In Hybrid approach hand ﬁrst Sampling approach k0 3 generated tradeoff values ﬁnd initial plan set improved ICPsequential runs As MetricLPG stochastic local search planner run times problem average results In 77 70 60 problems tested domains Hybrid Sampling approaches respectively standard viation ICP values plan sets 5 average values This indicates ICP values plan set different runs stable As Hybrid approach improved version ICPsequential gives better results tested problems omit ICPsequential discussions We analyze results The utility partial knowledge users preferences To evaluate utility taking partial knowledge user pref erences account ﬁrst compare results naive approaches generate plan set explicitly taking account partial knowledge Speciﬁcally run default LPG planner different random seeds ﬁnd multiple nondominated plans The LPG planner run speed setting ﬁnds plans quickly diverse setting takes longer time ﬁnd better set diverse plans Fig 13 shows comparison quality plan sets returned Sampling naive approaches distribution tradeoff value w makespan plan cost assumed uniform Overall 20 tested problems ZenoTravel DriverLog De pots domains Sampling approach better LPGspeed 1920 2020 2020 better LPGd 1820 1820 2020 problems respectively We observed similar results comparing Hybrid approaches particular Hybrid approach better LPGspeed 60 problems better LPGd 1920 1820 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 23 Fig 12 The distributions uniform b w02 c w08 text Fig 13 Results ZenoTravel DriverLog Depots domains comparing Sampling baseline LPG approaches overall ICP value log scale uniform distribution 2020 problems respectively These results support intuition taking account partial knowledge user preferences available increases quality plan set Comparing Sampling Hybrid approaches We compare effectiveness Sampling Hybrid approaches terms quality returned plan sets uniform w02 w08 distributions ICP value We ﬁrst compare approaches terms ICP values plan sets returned indicating quality evaluated user Tables 6 7 8 results domains In general Hybrid tends better Sampling criterion domains distributions In particular ZenoTravel domain returns higher quality plan sets 1520 problems distribution uniform 1020 1320 problems w02 w08 respectively approaches return plan sets equal ICP values problems w02 distribution problem w08 distribution In DriverLog domain Hybrid returns better plan sets 1120 problems uniform distribution problems plan sets equal ICP values worse triangular distributions 820 2 equals 920 equals w02 w08 The improvement quality plan sets Hybrid contributes signiﬁcant Depots domain better Sampling 1120 problems uniform distribution equal 3 problems 1220 problems w02 w08 distributions w02 approaches return plan sets equal ICP values 4 problems 2 problems w08 In large problems ZenoTravel DriverLog domains Sampling performs better Hybrid notice ﬁrst phase Hybrid approach searches ﬁrst 3 initial plans normally takes allocated time time left second phase improve quality plan set We observe settings tradeoff distributions positive effect second phase Hybrid approach improve quality initial plan sets tends stable different domains uniform distribution triangular particular Sampling beats Hybrid DriverLog domain distribution w02 Perhaps triangular distributions chance LPG planner Sampling approach returns plans different tradeoff values increase especially probable value makespan happens wide range weights single plan optimal This result agrees intuition knowledge user preferences complete distribution tradeoff value peak Sampling approach smaller number generated weight values good assuming good planner optimizing complete value function available Since quality plan set depends features makespan plan cost optimized plans span space time cost compare Sampling Hybrid approaches terms criteria In particular compare plan sets returned approaches terms median values makespan cost represent close plan sets origin space makespan cost ii standard deviation makespan cost values indicate sets span feature axis 24 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Table 6 The ICP value plan sets ZenoTravel domain returned Sampling Hybrid approaches distributions uniform b w02 c w08 The problems Hybrid returns plan sets better quality Sampling marked Prob Sampling Hybrid Prob Sampling Hybrid Prob Sampling Hybrid 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 84000 266143 180784 348131 300797 344737 400638 454990 639732 759272 530704 728854 1020811 1193922 933468 1672421 2708557 2361071 2911430 3493927 83998 266125 180595 347749 274385 275525 379344 434470 587513 682660 505007 680728 995694 1373087 1354128 1394926 2682237 2508940 2927609 3716629 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 97200 306720 208391 405275 317186 428800 464440 506081 703787 906440 594668 795474 1184713 1447400 1612570 1938600 2955903 2852017 3422402 3944366 b 97200 306720 208383 402692 317173 318861 437740 504443 661430 747237 589176 758628 1141488 1573919 1614728 1984167 3217566 2902015 3649640 4279097 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 70800 2255792 153554 296084 278216 280200 354695 380260 546924 614268 457809 548319 851574 1161038 1174845 1450379 2135478 2010703 2372190 2817845 c 70800 2255788 153532 294766 232694 252418 323563 373390 504088 599745 440836 575689 847909 1136946 1141859 1512177 2229765 2172775 2522224 2896151 Table 7 The ICP value plan sets DriverLog domain returned Sampling Hybrid approaches distributions uniform b w02 c w08 The problems Hybrid returns plan sets better quality Sampling marked Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21200 36330 17600 28200 23683 22200 17650 33896 36918 17838 28904 71148 46950 45704 60681 443221 131083 180049 394108 222566 Hybrid 21200 34838 17600 27845 23633 22100 17650 31943 30172 17055 23265 72765 46099 51211 59141 449017 142770 176817 427867 239761 Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 23599 45007 20320 33601 27380 25480 22620 38753 42064 19644 33413 82417 51992 52456 69949 490234 163286 199232 461413 266400 b Hybrid 23600 39846 20320 32379 28851 25480 20380 39775 33905 19511 25309 80993 52105 56594 64372 632807 165946 218313 797800 279290 Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 18800 33320 14880 23820 20080 18747 14920 30054 31680 15818 24538 60586 38880 40902 55279 358032 106203 144836 386554 189228 c Hybrid 18800 29970 14880 23320 19952 18720 14920 32387 26392 14612 21160 58882 39767 41053 57495 429747 114668 154909 271208 193411 Table 9 summarizes domain distribution feature number problems approach Sampling Hybrid generates plan sets better median feature value makespan plan cost There 60 problems 3 different distributions total 180 cases feature Sampling Hybrid return plan sets better makespan 40 62 cases better plan cost 52 51 cases respectively indicates Hybrid slightly better Sampling optimizing makespan possibly worse optimizing plan cost In ZenoTravel domain distributions Hybrid likely returns better plan sets makespan Sampling Sampling better plan cost feature In DriverLog domain Sampling better makespan feature nonuniform distributions worse Hybrid uniform On plan cost feature Hybrid returns plan sets better median Sampling uniform w02 distributions approaches perform equally w08 distribution In Depots domain Sampling better Hybrid features uniform distribution better Hybrid makespan distribution w08 In terms spanning plan sets Hybrid performs better Sampling features domains shown Table 10 In particular 360 cases makespan plan cost features 10 cases Sampling produces plan sets better standard deviation Hybrid feature Hybrid hand generates plan sets better standard deviation makespan 91 cases 85 cases plan cost TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 25 Table 8 The ICP value plan sets Depots domain returned Sampling Hybrid approaches distributions uniform b w02 c w08 The problems Hybrid returns plan sets better quality Sampling marked Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2787 3922 5136 4300 8036 9940 3850 5908 9529 5204 10143 12309 5737 6275 11682 5077 3838 8828 8260 13713 Hybrid 2787 3922 5043 4300 8101 11111 3849 5841 10385 5000 10766 12934 5722 6233 11786 4936 3777 8555 8208 13347 Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2856 4112 5444 4600 8293 10258 4053 6215 10059 5240 11018 14467 6083 7032 11315 5498 4286 9453 9421 15080 b Hybrid 2856 4112 5282 4600 8445 11098 4040 6208 10600 5240 10807 13580 6072 6987 12428 5412 4150 9002 8928 13593 Prob Sampling 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 2850 3826 4949 4087 7596 9479 3704 5589 8793 4786 9756 12458 5466 6520 10109 4704 3756 7673 7473 12243 c Hybrid 2785 3826 4858 4000 7899 9840 3660 5467 9505 4760 9906 12801 5466 6202 12443 4635 3692 7529 7245 12031 Table 9 Number problems domain distribution feature Sampling Hybrid returns plan sets better smaller median feature value Hybrid Sampling denoted table S H H S respectively We mark bold numbers problems indicate outperformance corresponding approach Domain Distribution Median makespan S H H S Median cost S H H S ZenoTravel DriverLog Depots uniform w02 w08 uniform w02 w08 uniform w02 w08 3 6 6 6 10 10 9 7 11 17 12 13 11 8 7 8 9 7 16 14 13 7 8 9 9 5 7 4 4 6 11 10 9 7 9 11 Table 10 Number problems domain distribution feature Sampling Hybrid returns plan sets better larger standard deviation feature value Hybrid Sampling denoted table S H H S respectively We mark bold numbers problems indicate outperformance corresponding approach Domain Distribution SD makespan S H H S ZenoTravel DriverLog Depots uniform w02 w08 uniform w02 w08 uniform w02 w08 8 4 6 5 7 8 10 7 5 12 14 13 11 10 9 7 9 13 SD cost S H 6 7 8 6 7 10 7 5 7 H S 14 11 11 10 9 7 9 10 11 These experimental results support arguments Section 61 limits sampling idea Since single plan optimal wide range weight values search Sampling approach different tradeoff values focus looking plans region feature space speciﬁed particular value weight reduce chance having plans better value particular feature On opposite Hybrid 26 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Fig 14 The contribution common lower convex hull plan sets ZenoTravel domain different distributions Fig 15 The contribution common lower convex hull plan sets DriverLog domain different distributions approach tends better spanning plan sets larger region space set plans taken account search Contribution lower convex hull The comparison Sampling Hybrid considers features separately We examine relation plan sets returned approaches joint space features particular taking account dominance relation plans sets In words compare relative total number plans lower convex hull LCH approach Given set returned user select higher number tends better expected utility value To measure relative performance approaches respect criterion ﬁrst create set S combining plans returned We compute set Slch S plans lower convex hull plans S Finally measure percentages plans Slch actually returned tested approaches Figs 14 15 16 contribution LCH plan sets returned Sampling Hybrid ZenoTravel DriverLog Depots domains In general observe plan set returned Hybrid contributes LCH Sampling problems large problems distributions domains Speciﬁcally ZenoTravel domain Hybrid contributes plans LCH Sampling 1520 1320 2 equals 1320 2 equals problems uniform w02 w08 distributions respectively In DriverLog domain better Sampling 1020 6 equals 1020 4 equals 820 5 equals problems Hybrid better 1120 6 equals 1120 4 equals 1120 4 equals uniform w02 w08 distributions Depots domain Again similar ICP value Hybrid approach effective problems large size w08 distribution Depots domain search time ﬁnding initial plan sets We note plan set higher contribution LCH guaranteed better quality extreme case plan set contributes 100 completely dominates contributes 0 LCH For example consider problem 14 ZenoTravel domain plan sets returned Hybrid contribute Sampling distributions w08 better ICP value The reason ICP value depends range tradeoff value density plan LCH optimal LCH constructed simply comparing plans terms makespan cost separately dominance relation ignoring relative importance The sensitivity plan sets distributions All analysis having far compare effectiveness ap proaches respect particular distribution tradeoff value In examine sensitive plan sets respect different distributions TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 27 Fig 16 The contribution common lower convex hull plan sets Depots domain different distributions Table 11 Number problems approach domain feature plan sets returned w02 w08 distribution better smaller median feature value w08 w02 denoted table w02 w08 w08 w02 respectively For approach mark bold numbers domains problems plan sets returned w08 w02 better makespan plan cost median w02 w08 respectively Approach Domain Median makespan w02 w08 w08 w02 Median cost w02 w08 w08 w02 Sampling Hybrid ZenoTravel DriverLog Depots ZenoTravel DriverLog Depots 5 6 6 5 4 8 13 10 12 10 10 10 11 13 10 10 6 4 8 5 7 4 9 11 Optimizing highpriority feature We ﬁrst consider plan sets optimized feature makespan plan cost approach respect nonuniform distributions w02 w08 Those distributions representing scenarios users different priority features plan sets biased optimizing feature higher priority larger value weight In particular plans generated w08 distribution better smaller makespan values w02 distribution makespan higher priority w08 w02 hand plan set returned w02 better values plan cost w08 Table 11 summarizes domain approach feature number problems plan sets returned distribution w02 w08 better median value We observe features Sampling approach likely push plan sets regions space makespan cost better value interested feature On hand Hybrid approach tends sensitive distributions features ZenoTravel domain sensitive makespan feature DriverLog Depots domains Those results generally approaches bias search optimizing features desired user Spanning plan sets individual features Next examine plan sets span feature depending degree incompleteness distributions Speciﬁcally compare standard deviation plan sets returned uniform distribution generated w02 w08 distributions Intuitively expect plan sets returned uniform distribution higher standard deviation distributions w02 w08 Table 12 shows approach domain feature number problems generated uniform distribution better standard deviation feature distribution w02 We observe makespan feature approaches return plan sets spanned makespan Depots domain ZenoTravel DriverLog With plan cost feature Hybrid shows positive impact domains Sampling shows ZenoTravel Depots domains Similarly Table 13 shows results comparing uniform w08 distributions This time Sampling returns plan sets better standard deviation features ZenoTravel Depots domains DriverLog Hybrid shows ZenoTravel domain remaining domains tends return plan sets expected standard deviation plan cost feature From results observe uniform distribution approaches likely generate plan sets span better nonuniform distributions especially plan cost feature In summary experimental results section support following hypotheses Instead ignoring user preferences partially speciﬁed account synthe sizing plans plan sets returned better quality 28 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 Table 12 Number problems approach domain feature plan sets returned uniform w02 distribution better higher standard deviation feature value w02 uniform denoted table U w02 w02 U respectively For approach feature mark bold numbers domains problems plan sets returned uniform distribution better standard deviation value feature w02 distribution Approach Domain SD makespan U w02 w02 U SD cost U w02 w02 U Sampling Hybrid ZenoTravel DriverLog Depots ZenoTravel DriverLog Depots 9 6 9 9 6 8 10 8 6 10 9 6 10 7 8 12 8 9 7 8 7 7 7 4 Table 13 Number problems approach domain feature plan sets returned uniform w08 distribution better higher standard deviation feature value w08 uniform denoted table U w08 w08 U respectively For approach feature mark bold numbers domains problems plan sets returned uniform distribution better standard deviation value feature w08 distribution Approach Domain SD makespan U w08 w08 U SD cost U w08 w08 U Sampling Hybrid ZenoTravel DriverLog Depots ZenoTravel DriverLog Depots 11 5 12 10 7 5 8 10 7 9 7 8 15 5 12 15 8 11 4 9 6 4 6 4 In generating plan sets sequentially cope partial user preferences Sampling approach searches plans separately independently solution space tends return worse quality plan sets Hybrid approach The resulting plan sets returned Hybrid approach tend sensitive user preferences Sampling approach 7 Discussion To best knowledge work ﬁrst step domainindependent planning preferences user preferences completely speciﬁed spirit modellite planning 33 Our language represent partial preference model assumes complete set attributes parameterized value function unknown parameter values Although work unknown values restricted continuous range rep resented set possible discrete values These representations parameters incompleteness ways imprecise parameters modeled boundedparameter MDPs 29 MDPs imprecise reward functions 454655 Boutilier et al 9 consider preference elicitation problem general framework set tributes utility function incomplete Our current representation plan synthesis approach limitations The representation underlying complete preference model setting convex combination metric quantities subset preference language deﬁned PDDL3 26 commonly represent preferences planning domains In PDDL3 preferences constraints state trajectory plans penalty values weights violated plan preferable lower total penalty value While model partially speciﬁed penalty preferences PDDL3 distribution continuous range set discrete values unclear represent incompleteness constructs language Similarly interesting question incompleteness extended conditional preferences 7 Using convex combination attributes utility function setting assumes criteria mutual preferential independence attribute important affect way user trades attributes 47 This property violated instance want extend setting include preference statements PDDL3 attributes In travel domain example passenger willing accept expensive ticket nonstop ﬂight ﬂy night weight importance cost smaller Our current implementation ignores fact changing scale objectives hours minutes makespan plans change bias distribution Pareto set plans objective axis In TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 29 words set look uniform objective space scale different scale 12 Although ICP value agrees set Pareto dominance relation regardless scaling mechanism 21 effect introduce wrong evaluation distribution entire Pareto set plans objective space user observing representative set plans biased region axis scaling mechanism Given IPF nonlinear function challenge modify MetricLPG planner eﬃciently search set plans optimizing quality measure We believe current modiﬁcation MetricLPG experiments improved designing new speciﬁc heuristics effective optimizing measure In addition observed Kim et al 35 computation time IPF measure increases roughly exponentially number objectives challenging effectively incorporate measure search planning problems high number criteria 8 Conclusion future work In paper consider planning problem partial user preferences scenarios knowledge preferences completely unknown given We propose general approach problem set plans presented user select For type preference incompleteness deﬁne different quality measure plan sets investigate approaches generating plan sets respect quality measure In ﬁrst scenario user known preferences plans details completely unknown deﬁne quality plan sets diversity value speciﬁed syntactic features plans action set sequence states set causal links We consider generating diverse sets plans stateoftheart planners GPCSP LPG The approaches developed supporting generation diverse plans GPCSP broadly applicable planners based bounded horizon compilation approaches planning Similarly techniques developed LPG biasing relaxed plan heuristics terms distance measures applied heuristic planners The experimental results GPCSP explicate relative diﬃculty enforcing distance measures correlation individual distance measures assessed terms sets plans ﬁnd The experiments LPG demonstrate potential planning heuristic local search producing large sets highly diverse plans When user preferences given particular set features user interested distribution weights representing relative importance propose use Integrated Preference Function special case Integrated Convex Preference function measure quality plan sets propose heuristic approaches based MetricLPG planner 28 ﬁnd good plan set respect measure We empirically taking partial knowledge user preferences account improve quality plan set returned user proposed approaches sensitive degree preference incompleteness represented distribution While planning agent start partial knowledge user preference model long run like agent able improve repeated interactions user In context beginning degree incompleteness high learning involve improving estimate hα based feedback speciﬁc plan user selects set returned This learning phase principle connected Bayesian parameter estimation approach sense distribution parameter vector hα updated receiving feedback user taking account current distribution models starting prior instance uniform distribution Although interactive learning framework discussed previously 16 set users decisions work assumed given planning scenarios cost plan synthesis incorporated interactive framework problem presenting plan sets user needs considered Recent work Li et al 36 considered learning user preferences planning restricting preference models represented hierarchical task networks Acknowledgements We thank Menkes van den Briel drawing attention ICP measure initially Kambhampatis research sup ported IBM Faculty Award NSF grant IIS2013308139 ONR grants N000140910017 N000140711049 N000140610058 Lockheed Martin subcontract TT0687680 ASU DARPA Integrated Learning pro gram Tuan Nguyen supported Science Foundation Arizona fellowship References 1 J Baier S McIlraith Planning preferences AI Magazine 29 4 2009 25 2 M Bienvenu C Fritz S McIlraith Planning qualitative temporal preferences Proceedings 10th International Conference Knowledge Representation Reasoning KR 2006 pp 134144 3 G Birkhoff Lattice Theory 2nd revised edition American Mathematical Society Colloquium Publications vol XXV American Mathematical Society New York 1948 4 A Blum M Furst Fast planning planning graph analysis Artiﬁcial Intelligence 90 12 1997 281300 5 M Boddy J Gohde T Haigh S Harp Course action generation cyber security classical planning International Conference Automated Planning Scheduling ICAPS 2005 pp 1221 30 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 6 C Boutilier A POMDP formulation preference elicitation problems Proceedings National Conference Artiﬁcial Intelligence AAAI 2002 pp 239246 7 C Boutilier R Brafman C Domshlak H Hoos D Poole CPnets A tool representing reasoning conditional ceteris paribus preference statements Journal Artiﬁcial Intelligence Research 21 1 2004 135191 8 C Boutilier T Dean S Hanks Decisiontheoretic planning Structural assumptions computational leverage Journal Artiﬁcial Intelligence Re search 11 1 1999 94 9 C Boutilier K Regan P Viappiani Simultaneous elicitation preference features utility Proceedings National Conference Artiﬁcial Intelligence AAAI 2010 pp 11601197 10 B Bozkurt J Fowler E Gel B Kim M Köksalan J Wallenius Quantitative comparison approximate solution sets multicriteria optimization problems weighted Tchebycheff preference function Operations Research 58 3 2010 650659 11 R Brafman C Domshlak Preference handlingAn introductory tutorial AI Magazine 30 1 2009 5886 12 J Branke Consideration partial user preferences evolutionary multiobjective optimization Multiobjective Optimization 5252 2008 157178 13 D Bryce W Cushing S Kambhampati Modellite planning Diverse multioption plans dynamic objective functions ICAPS 2007 Workshop Planning Plan Execution Real World Systems 2007 14 WM Carlyle JW Fowler ES Gel B Kim Quantitative comparison approximate solution sets bicriteria optimization problems Decision Sci ences 34 1 2003 6382 15 G Chaﬂe K Dasgupta A Kumar S Mittal B Srivastava Adaptation Web Service Composition Execution International Conference Web Services ICWS06 2006 pp 549557 16 U Chajewska D Koller D Ormoneit Learning agents utility function observing behavior Proceedings Eighteenth International Con ference Machine Learning ICML 2001 pp 3542 17 U Chajewska D Koller R Parr Making rational decisions adaptive utility elicitation Proceedings National Conference Artiﬁcial Intelligence AAAI 2000 pp 363369 18 M desJardins K Wagstaff Ddpref A language expressing preferences sets Proceedings National Conference Artiﬁcial Intelligence 2005 19 M Do S Kambhampati Planning constraint satisfaction Solving planning graph compiling CSP Artiﬁcial Intelligence 132 2 2001 151182 20 M Do S Kambhampati Sapa A multiobjective metric temporal planner Journal Artiﬁcial Intelligence Research 20 1 2003 155194 21 J Fowler B Kim W Carlyle E Gel S Horng Evaluating solution sets posteriori solution techniques bicriteria combinatorial optimization problems Journal Scheduling 8 1 2005 7596 22 M Fox A Gerevini D Long I Serina Plan stability Replanning versus plan repair Proc ICAPS AAAI Press 2006 pp 212221 23 M Fox D Long PDDL21 An extension PDDL expressing temporal planning domains Journal Artiﬁcial Intelligence Research 20 1 2003 61124 24 C Fritz S McIlraith Decisiontheoretic golog qualitative preferences Proceedings 10th International Conference Principles Knowl edge Representation Reasoning Lake District UK June 2006 25 M Gelain M Pini F Rossi K Venable T Walsh Elicitation strategies soft constraint problems missing preferences Properties algorithms experimental studies Artiﬁcial Intelligence 174 34 2010 270294 26 A Gerevini P Haslum D Long A Saetti Y Dimopoulos Deterministic planning ﬁfth international planning competition PDDL3 experi mental evaluation planners Artiﬁcial Intelligence 173 56 2009 619668 27 A Gerevini A Saetti I Serina Planning stochastic local search temporal action graphs LPG Journal Artiﬁcial Intelligence Re search 20 1 2003 239290 28 A Gerevini A Saetti I Serina An approach eﬃcient planning numerical ﬂuents multicriteria plan quality Artiﬁcial Intelligence 172 89 2008 899944 29 R Givan S Leach T Dean Boundedparameter Markov decision processes Artiﬁcial Intelligence 122 12 2000 71109 30 V Ha P Haddawy A hybrid approach reasoning partially elicited preference models Proceedings Fifteenth Annual Conference Uncertainty Artiﬁcial Intelligence 1999 pp 263270 31 G Hazen Partial information dominance potential optimality multiattribute utility theory Operations Research 1986 296310 32 E Hebrard B Hnich B OSullivan T Walsh Finding diverse similar solutions constraint programming Proceedings 20th National Conference Artiﬁcial Intelligence AAAI 2005 p 372 33 S Kambhampati Modellite planning web age masses The challenges planning incomplete evolving domain theories Proceed ings National Conference Artiﬁcial Intelligence AAAI 2007 p 1601 34 H Kautz B Selman BLACKBOX A new approach application theorem proving problem solving AIPS98 Workshop Planning Combinatorial Search 1998 35 B Kim E Gel J Fowler W Carlyle J Wallenius Evaluation nondominated solution sets kobjective optimization problems An exact method approximations European Journal Operational Research 173 2 2006 565582 36 N Li S Kambhampati S Yoon Learning probabilistic hierarchical task networks capture user preferences Proceedings 21st International Joint Conference Artiﬁcial Intelligence Pasadena CA USA 2009 37 G Linden S Hanks N Lesh Interactive assessment user preference models The automated travel assistant Courses LecturesInternational Centre Mechanical Sciences 1997 pp 6778 38 H McMahan G Gordon A Blum Planning presence cost functions controlled adversary Proceedings Twentieth International Conference Machine Learning ICML 2003 p 536 39 A Memon M Pollack M Soffa Hierarchical GUI test case generation automated planning IEEE Transactions Software Engineering 27 2 2001 144155 40 K Myers Metatheoretic plan summarization comparison International Conference Automated Planning Scheduling ICAPS06 2006 41 K Myers T Lee Generating qualitatively different plans metatheoretic biases Proceedings National Conference Artiﬁcial Intelli gence 1999 pp 570576 42 T Nguyen M Do S Kambhampati B Srivastava Planning partial preference models Proceedings 21st International Joint Conference Artiﬁcial Intelligence IJCAI Morgan Kaufmann Publishers 2009 pp 17721777 43 A Pnueli The temporal logic programs 18th Annual Symposium Foundations Computer Science IEEE 1977 pp 4657 44 I Refanidis I Vlahavas Multiobjective heuristic statespace planning Artiﬁcial Intelligence 145 12 2003 132 45 K Regan C Boutilier Regretbased reward elicitation Markov decision processes Proceedings TwentyFifth Conference Uncertainty Artiﬁcial Intelligence AUAI Press 2009 pp 444451 46 K Regan C Boutilier Robust policy computation rewarduncertain MDPs nondominated policies Proceedings 24th AAAI Conference Artiﬁcial Intelligence 2010 pp 11271133 47 S Russell P Norvig Artiﬁcial Intelligence A Modern Approach Prentice Hall 2010 TA Nguyen et al Artiﬁcial Intelligence 190 2012 131 31 48 I Serina Kernel functions casebased planning Artiﬁcial Intelligence 174 2010 1617 49 D Smith Choosing objectives oversubscription planning Proceedings Fourteenth International Conference Automated Planning Scheduling 2004 pp 393401 50 T Son E Pontelli Planning preferences logic programming Theory Practice Logic Programming 6 5 2006 559607 51 B Srivastava S Kambhampati T Nguyen M Do A Gerevini I Serina Domainindependent approaches ﬁnding diverse plans IJCAI 2007 pp 20162022 52 A Tate J Dalton J Levine Generation multiple qualitatively different plan options Technical Report University Edinburgh 1998 53 M Van Den Briel R Sanchez M Do S Kambhampati Effective approaches partial satisfaction oversubscription planning Proceedings National Conference Artiﬁcial Intelligence 2004 pp 562569 54 P Viappiani B Faltings P Pu Preferencebased search examplecritiquing suggestions Journal Artiﬁcial Intelligence Research 27 1 2006 465503 55 H Xu S Mannor Parametric regret uncertain Markov decision processes Proceedings 48th IEEE Conference Decision Control held jointly 2009 28th Chinese Control Conference CDCCCC 2009 IEEE 2009 pp 36063613 56 Y Zhang J Callan T Minka Novelty redundancy detection adaptive ﬁltering Proceedings 25th Annual International ACM SIGIR Conference Research Development Information Retrieval ACM 2002 pp 8188