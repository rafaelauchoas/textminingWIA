Artiﬁcial Intelligence 228 2015 4565 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Bigoal evolution manyobjective optimization problems Miqing Li Shengxiang Yang b Department Computer Science Brunel University London UB8 3PH UK b Centre Computational Intelligence CCI School Computer Science Informatics De Montfort University Leicester LE1 9BH UK Xiaohui Liu r t c l e n f o b s t r c t Article history Received 22 August 2014 Received revised form 14 June 2015 Accepted 20 June 2015 Available online 3 July 2015 Keywords Evolutionary multiobjective optimization Manyobjective optimization Proximity Diversity Bigoal evolution This paper presents metaobjective optimization approach called BiGoal Evolution BiGE deal multiobjective optimization problems objectives In multi objective optimization generally observed 1 conﬂict proximity diversity requirements aggravated increase number objectives 2 Pareto dominance loses effectiveness highdimensional space works lowdimensional space Inspired observations BiGE converts given multiobjective optimization problem bigoal objective optimization problem proximity diversity handles Pareto dominance relation bigoal domain Implemented estimation methods individuals performance classic Pareto nondominated sorting procedure BiGE divides individuals different nondominated layers attempts wellconverged welldistributed individuals ﬁrst layers From series extensive experiments groups welldeﬁned continuous combinatorial optimization problems 5 10 15 objectives BiGE competitive ﬁve stateoftheart algorithms balancing proximity diversity The proposed approach ﬁrst step new way addressing manyobjective problems indicating important issues future development type algorithms 2015 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 1 Introduction Realworld problems commonly involve multiple objectivescriteria required optimized simultaneously For example individual like maximize chance healthy wealthy having fun time family friends A software engineer interested ﬁnding cheapest test suite achieving coverage statement coverage branch coverage decision coverage When prescribing radiotherapy cancer patient doctor balance attack tumor potential impact healthy organs overall condition patient These multiobjective optimization problems MOPs seen ﬁelds including engineering science medicine logistics They share issue pursuing objectives time long regarded substantial challenge artiﬁcial intelligence AI 7325 There variety approaches MOPs including traditional mathematical programming methods local search techniques evolutionary algorithms EAs Inspired biological evolution mechanisms EAs demon strated successful diverse AI applications 7310 For example EAbased AI planner Divide Evolutionary Corresponding author Email address syangdmuacuk S Yang httpdxdoiorg101016jartint201506007 00043702 2015 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 46 M Li et al Artiﬁcial Intelligence 228 2015 4565 DaE 8 won Deterministic Temporal Satisﬁcing track International Planning Competition IPC7 21st International Conference Automated Planning Scheduling ICAPS 20111 Recently DaE successfully applied multiobjective AI planning called MODaE 58 MODaE working wellknown multiobjective EA indicatorbased EA IBEA 99 shown clear advantage metricbased approach LPG metric sensitive planner 58 A key strength EAs MOPs populationbased feature allows individuals simultaneously approximate different parts Pareto single execution 1997 Intuitively search process EA basic goals minimizing distance population Pareto proximity maximizing distribution population Pareto diversity Since optimal outcome MOP set Pareto optimal solutions Pareto dominance relation naturally criterion distinguish solutions Given solutions p q MOP p said Pareto dominate q p better q objective worse The Pareto dominance reﬂects weakest assumption preferred structure decisionmaker As primary selection criterion evolutionary multiobjective optimization EMO area Pareto dominance commonly evaluate proximity solutions When Pareto dominance fails interested solutions non dominated EMO algorithms introduce densitybased criterion maintain diversity population For example nondominated sorting genetic algorithm II NSGAII 23 separates individuals population dif ferent layers ranks Pareto dominance relation prefers 1 individuals lower layers 2 individuals lower crowding degrees measured crowding distance 23 located layer An MOP objectives called manyobjective optimization problem Manyobjective optimization important challenging topic increasing use EAs tackle manyobjective optimization problems 14162635 Although Paretobased algorithms popular approaches scale poorly number objectives 184875 When dealing MOP objectives Pareto dominance loses effectiveness differentiate individuals 57 makes individuals population incomparable terms proximity NSGAII individuals fall ﬁrst layer Consequently densitybased selection criterion play decisive role determining survival individuals evolutionary process leading individuals ﬁnal population distributed widely objective space far desired Pareto 85 A straightforward way handle problem ineffectiveness Paretobased algorithms manyobjective opti mization modify Pareto dominance relation Some interesting attempts include loosening dominance condition controlling dominance angle cid2dominance 22366184 αdominance 43 cid2box dominance 60 dom inance area control 78 By relaxing area individual dominating dominance relations able provide suﬃcient selection pressure Pareto However set proper value parameters determine relaxation degree crucial issue methods needing studies 626979 On hand way comparing individuals according quantitative difference objectives effective converging Pareto Many recent EMO algorithms originate motivation introducing variety new criteria distinguish individuals average ranking 5270 fuzzy Pareto optimality 3739 subspace partition 251 preferenceinspired rank 8887 gridbased rank 7092 distancebased rank 327191 density adjustment strategies 166 These methods provide ample alternatives deal manyobjective optimiza tion problems despite having risk leading population concentrate subareas Pareto 50678165 Recently signiﬁcant use selection criteria involve proximity diversity solve MOPs Some criteria like decompositionbased 94 indicatorbased 99 criteria shown promising manyobjective optimization 1520414485 The uses idea singleobjective aggregated optimization decomposing MOP number scalar subproblems optimizing simultaneously The deﬁnes optimization criterion regard speciﬁed performance indicator uses criterion guide search population The indicator hypervolume popular indicatorbased criteria good theoretical empirical properties 7132942101 Whereas superpolynomial time complexity required calculation hypervolume indicator P N P 11 lots effort reduce computational cost terms exact computation 61290 approximate estimation 41449 Nevertheless balancing proximity diversity single criterion easy task 76386968 especially manyobjective optimization problem conﬂict objectives generally MOP objectives 751 In fact evolving population optimum diversifying individuals Pareto manyobjective optimization multiobjective problem The advance aspect usually comes degradation 3375 1 http wwwsigevo org wiki tikiread _article php articleId 1 M Li et al Artiﬁcial Intelligence 228 2015 4565 47 Fig 1 Evolutionary trajectories average convergence metric CM 30 runs original NSGAII denoted A modiﬁed NSGAII diversity maintenance mechanism denoted A DTLZ2 This paper presents metaobjective optimization approach called BiGoal Evolution BiGE deal manyobjective optimization problems Inspired observations 1 conﬂict proximity diversity requirements aggravated increase number objectives 2 Pareto dominance loses effectiveness high dimensional space works lowdimensional space BiGE converts given manyobjective optimization problem bigoal objective optimization problem individuals proximity crowding degree handles Pareto dominance bigoal domain The bigoal evolution implemented speciﬁc methods estimating individuals performance proximity crowding degree simple individual comparison strategies mating environmental selection In implementation crowding degree estimation pragmatic approach developed prevent adjacent individuals assigned similar ﬁtness bigoal domain In environmental selection BiGE Pareto nondominated sorting proximity crowding degree attempts wellconverged welldistributed individuals ﬁrst layers chosen ﬁrst It worth mentioning metaobjective optimization uncommon approach multiobjective opti mization ﬁeld For example Jones Jimenez introduced metaobjectives number unmet goals closeness pairwise comparisons extended goal programming framework 56 Wang Cai considered constraint violation metaobjective solve singleobjective constrained optimization problems 89 Toffolo Benini viewed diversity additional objective turned mobjective MOP m 1objective MOP 82 Ishibuchi et al considered hypervolume maximization solution set m reference points m metaobjectives optimize number solution sets 46 An interesting difference BiGE metaobjective approaches lies metaobjective approaches typically introduce objectives original optimization problem BiGE deals objectives converting manyobjective problem biobjective problem metaobjectives The rest paper organized follows In Section 2 motivation BiGE described Section 3 devoted presentation BiGEs framework implementation Section 4 introduces experimental design Empirical results BiGE comparison ﬁve peer algorithms shown Section 5 Further investigation proposed algorithm discussions given Sections 6 7 respectively Section 8 provides concluding remarks pertinent observations 2 Motivation An EMO algorithm pursues basic conﬂicting goals proximity diversity Such conﬂict detrimen tal impact algorithms optimization process aggravated manyobjective optimization Fig 1 gives comparison trajectories proximity results original NSGAII involving proximity diversity main tenance mechanisms modiﬁed version diversity maintenance mechanism removed 2 5 10objective DTLZ2 24 These results evaluated convergence metric CM 21 calculates average normalized Euclidean distance solution set Pareto As seen Fig 1 interval CM trajectories algorithms visible increase number objectives This divergence behavior ﬁrst reported 75 For 2objective prob lem algorithms perform CM trajectories virtually overlapping For 5objective problem NSGAII diversity maintenance mechanism achieves better CM results original NSGAII evo lutionary process means diversity maintenance unfavorable impact proximity algorithm For 10objective problem diversity maintenance mechanism NSGAII makes evolving population gradu ally away Pareto great interval trajectories Fig 1 indicates conﬂict proximity diversity obtained 48 M Li et al Artiﬁcial Intelligence 228 2015 4565 Fig 2 An illustration conversion actual objective space bigoal space proximity crowding degree biobjective minimization problem Algorithm 1 Bigoal evolution BiGE Require P population N population size 1 P initializeP 2 termination criterion fulﬁlled 3 4 5 6 7 8 end 9 return P proximityEstimationP crowdingDegreeEstimationP cid4 matingSelectionP P cid4cid4 variationP P P environmentalSelectionP cid4cid4 cid2 cid4 P On hand Pareto dominance popular effective distinguish individuals 2 3objective MOPs fails manyobjective optimization In fact portion individuals comparable mdimensional objective space η 12m1 For 2 3dimensional space η equal 05 025 respectively m reaches 6 η low 003125 Such exponential decrease portion leads dramatic decline Pareto dominances effectiveness number objectives Given viable use Pareto dominance optimize goals objectives proximity diversity cope objectives MOP This way suﬃcient selection pressure provided highdimensional space Bearing mind propose bigoal evolution approach BiGE tackle manyobjective optimization problems 3 Bigoal evolution BiGE BiGE treats MOP objectives bigoal optimization problem minimizing proximity individuals optimal direction minimizing crowding degree individuals population Fig 2 gives biobjective scenario illustrate conversion actual objective space bigoal space As seen Fig 2 conversion nondominated individuals AG objective space comparable In bigoal space individuals C A E Pareto nondominated best individuals population given C A perform best terms proximity crowding degree respectively performance E regarded tradeoff C A In contrast individual F performs poorly proximity crowding degree dominated individuals population Below introduce main procedure BiGE speciﬁc implementations 31 Basic procedure bigoal evolution The aim BiGE deal ineffectiveness Pareto dominance relation highdimensional objective space BiGE considers individuals incomparable basis Pareto dominance selection process Algorithm 1 gives basic procedure BiGE Firstly N individuals randomly generated form initial population P Then proximity crowding degree individuals current population estimated Next mating selection performed select promising solutions bigoal space variation Finally environmental selection procedure implemented record N best solutions respect goals survival M Li et al Artiﬁcial Intelligence 228 2015 4565 49 32 Proximity estimation Conversion MOP number objectives bigoal problem involves integration objectives In order integration feasible able deal MOP noncommensurable objective functions BiGE objective individuals normalized respect minimum maximum values current population estimating proximity crowding degree For convenience description proposed algorithm objective value individuals refers normalized objective value range 0 1 BiGE estimates proximity denoted f pr individual p population summing value objec tive f prp mcid3 k1 f kp 1 f kp denotes objective value individual p kth objective m number objectives This estimation function determined factors number objectives performance objective An individual good performance majority objectives likely obtain lower better f pr value It worth pointing proximity information individual m objectives mdimensional vector completely reﬂected represented scalar value f pr The accuracy estimation inﬂuenced shape MOPs Pareto For example individuals knee Pareto better estimation result far away knee nondominated To solve issue introduce goal minimizing crowding degree individuals population We consider Pareto dominance relation goals preferring individuals good tradeoff 33 Crowding degree estimation Niching techniques kind popular density estimation methods EA ﬁeld Bearing idea sharing resource mind niching techniques effectively measure crowding degree individual population Here consider following sharing function individuals p q cid4 shp q 1 dpq 0 r 2 dp q r 2 dp q denotes Euclidean distance individuals p q objective space r radius niche determined population size N number objectives m given MOP r 1 m N 3 Note considered individuals normalized according range current population Thus niche radius actually adaptive varying evolutionary population Using sharing function Eq 2 crowding degree denoted f cd individual p population P deﬁned follows cid3 f cdp shp q12 4 qP qcid7p Up performance individual population reﬂected f pr f cd However problem arise applying estimation functions conversion actual objective space bigoal space Since performance estimation individual depends position comparison individuals population individuals located closely objective space similar behaviors proximity crowding degree situated closely bigoal space For example similar nondominated individuals A B Fig 3a conversion located closely nondominated shown Fig 3b In case likely individuals preserved eliminated simultaneously result congestion regions vacancy regions To overcome problem modiﬁcation sharing function Eq 2 order distinguish similar individuals Two individuals assigned different sharing function values according performance com parison terms proximity Speciﬁcally introduce weight parameter called sharing discriminator sharing function shp q r 051 dpq 151 dpq rand 0 r 2 2 dp q r f prp f prq dp q r f prp f prq dp q r f prp f prq 5 50 M Li et al Artiﬁcial Intelligence 228 2015 4565 Fig 3 An illustration case similar individuals objective space located closely nondominated bigoal space remedy The actual objective space b The bigoal space respect proximity original crowding degree c The bigoal space respect proximity modiﬁed crowding degree The numerical values individuals spaces given Table 1 Table 1 Individual values spaces example Fig 3 Objective No 1 objective No 2 Proximity original crowding degree Proximity modiﬁed crowding degree A B C D E F G 000 100 005 089 033 072 059 064 070 037 094 015 102 000 100 068031 094 070114 105 029965 123 033658 107 026737 109 056741 102 055022 100 102047 094 034663 105 024422 123 054256 107 013369 109 085112 102 027511 function rand means assign shp q 051 dpq 151 dpq 2 shq p 051 dpq 2 randomly r r r 2 shq p 151 dpq r 2 shp q The sharing function contributes differently crowding degree individuals niche An individual better proximity neighbors obtain lower crowding degree For individuals sole neighbor population crowding degree better individual terms proximity half original crowding degree worse half original crowding degree In general modiﬁcation enables adjacent individuals located distantly More importantly lead similar individuals comparable basis Pareto dominance criterion proximity diversity goals suited BiGE Fig 3c gives illustration explain effect modiﬁcation As shown individual A dominated B evaluated modiﬁed crowding degree Table 1 shows values individuals spaces example Fig 3 34 Mating selection Mating selection aims good preparation exchanging information individuals picks promis ing solutions current population form mating pool BiGE uses type binary tournament selection strategy based Pareto dominance bigoal domain given Algorithm 2 For candidates Paretocomparable goal functions f prp f prq f cdp f cdq better selected tie split randomly Note variation operations crossover mutation ﬁxed BiGE freely chosen users Here use simulated binary crossover SBX polynomial mutation continuous MOPs uniform crossover bitﬂip mutation combinatorial MOPs 35 Environmental selection Environmental selection aims obtain wellapproximated welldistributed new population chooses best solutions previous population newly created individuals BiGE implements environmental selection according individuals Pareto dominance relation bigoal domain Here adopt popular Paretobased rank strategy area nondominated sorting 34 Nondominated sorting effective method rank individuals lowdimensional space First nondominated individuals population identiﬁed ﬁrst layer Then remaining individuals regarded current population nondominated individuals selected form second layer This process continued entire population classiﬁed different layers M Li et al Artiﬁcial Intelligence 228 2015 4565 51 return p Algorithm 2 Tournament selection Require individuals p q 1 p q bigoal domain 2 3 q p bigoal domain 4 5 random0 1 05 6 7 8 9 end return p return q return q Algorithm 3 environmentalSelectionQ Require N population size 1 Generate population P 2 proximityEstimationQ Compute proximity individual Q Eq 1 3 crowdingDegreeEstimationQ Compute crowding degree individual Q Eqs 4 5 4 L1 L2 Li nondominatedSortingQ critical layer Li 0 N L1 L2 Li1 Li Partition Q different layers L1 L2 Li Pareto nondominated sorting proximity crowding degree ﬁnd 5 P L1 L2 Li1 6 P N 7 randomSelectionP Li N P 8 end 9 return P Select N P individuals Li P random Fig 4 The average number solutions nondominated layers bigoal Pareto nondominated sorting b original Pareto nondominated sorting population size 100 number runs 30 test instance DTLZ2 Algorithm 3 gives environmental selection procedure BiGE First individuals performance proximity crowding degree estimated Steps 2 3 Then candidate set Q divided different layers nondominated sorting procedure respect goals ﬁrst 1 layers moved population P L1 L2 Li1 N L1 L2 Li1 Li N Steps 4 5 Finally slots P ﬁlled randomly individuals Li Steps 68 Note BiGE employs randomlyselected mode layer Li densitybased selection mode This density individuals bigoal space reﬂect performance An individual high density bigoal space mean worse individuals low density individuals having similar proximity crowding degree population cf individual C example Fig 3 Therefore randomly select individuals located layer In order investigate effectiveness bigoal nondominated sorting providing selection pressure Fig 4 demonstrates average number solutions nondominated layers 2 3 5 10 15objective DTLZ2 contrast average number solutions nondominated layers obtained nondominated sorting actual objectives shown As seen Fig 4b number individuals placed ﬁrst layer L1 increases rapidly number objectives approximating 80 population size number 52 M Li et al Artiﬁcial Intelligence 228 2015 4565 Table 2 Properties test problems comparative studies Problem WFG1 WFG2 WFG3 WFG4 WFG5 WFG6 WFG7 WFG8 WFG9 Knapsack TSP Water Number objectives m 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 Number variables n 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 2 m 1 20 500 30 3 Properties Mixed ﬂat biased Convex disconnected nonseparable Linear degenerate nonseparable Concave multimodal Concave deceptive Concave nonseparable Concave parameter dependant biased Concave nonseparable parameter dependant biased Concave nonseparable deceptive parameter dependant biased Convex constraint Convex zero correlation Convex degenerate constraint objectives reaches 5 In contrast individuals Fig 4a located different layers distributed similar pattern For example L1 small 6 individuals In instances number individuals Li increases total number individuals L1 Li reaches half population size This means bigoal nondominated sorting effectively distinguish individuals largely independent number objectives 4 Experimental design BiGE focuses comparison individuals nondominated objective space For individuals differentiated Pareto dominance existing comparison strategy EMO area nondominated sorting 34 nondominated ranking 28 strength 100 Here nondominated sorting strategy chosen cooperate BiGE simplicity popularity 23 In section introduce test problems performance indicators peer algorithms general parameter setting experimental studies 41 Test problems Three wellknown continuous combinatorial benchmark suites walking ﬁsh group WFG toolkit 40 multi objective 01 knapsack problem 100 multiobjective traveling salesman problem TSP 18 included objective number m 5 10 15 Also realworld constraint problem water problem 72 considered Their characteristics summarized Table 2 WFG continuous problem suite scaled number objectives decision variables Comprised problems characteristics having linear convex concave multimodal disconnected biased degenerated Pareto fronts WFG suite challenge varying capabilities EMO algorithm According suggestion 40 parameters k l WFG set 2 m 1 20 respectively m denotes number objectives The multiobjective 01 knapsack problem standard combinatorial problems multiobjective optimization Given set n items set m knapsacks multiobjective knapsack problem deﬁned follows Maximize f ix ncid3 j1 pi j x j 1 m ncid3 Subject w j x j ci 1 m j1 x x1 xnT 0 1n 6 pi j 0 proﬁt item j knapsack w j 0 weight item j knapsack ci capacity knapsack x j 1 means item j selected knapsacks Following study 100 pi j w j random integers interval 10 100 knapsack capacity set half total weight corresponding knapsack Also greedy repair method infeasible solutions presented 100 order items removed knapsacks determined maximum proﬁtweight ratio adopted experimental studies The multiobjective TSP typical combinatorial optimization problem stated follows 18 given network L V C V v 1 v 2 vn set n nodes C ck k 1 2 m set m cost matrices nodes ck V V need determine Pareto optimal set Hamiltonian cycles minimize M Li et al Artiﬁcial Intelligence 228 2015 4565 53 m cost objectives In study m matrices uncorrelated generated assigning distinct pair nodes random number range 0 1 According 18 number nodes set 30 The water problem 7277 threevariable ﬁveobjective sevenconstraint optimization problem relates optimal planning storm drainage urban area It frequently area challenge EMO algorithms dealing problem objectives constraints 19818053 A detailed description problem 72 42 Hypervolume indicator Hypervolume HV 100 popular quality indicator good theoretical properties 1329101 Calculating volume objective space obtained solution set reference point HV set compre hensive assessment terms proximity diversity For clarity provide normalized HV value algorithm respect proportion optimal HV result achieved This normalization makes obtained results reside range 0 1 1 representing optimal value For test problems WFG4WFG9 optimal HV value obtained calculation optimal value suggested 36 approximately estimated HV result nondominated set respect mixed population consisting obtained solutions given problem In calculation HV crucial issues scaling search space 30 choice reference point 331 Since objectives WFG water problems different ranges values standardize ob jective value obtained solutions according range problems Pareto Following recommendation 45 reference point set 11 times upper bound Pareto r 11m emphasize balance proximity diversity obtained solution set For combinatorial optimization problems range Pareto unknown set reference point slightly worse boundary values nondom inated set respect mixed population consisting obtained solutions points 13000 22 objective r 13000m r 22m ﬁxed knapsack TSP problems respectively In addition exact calculation HV indicator generally infeasible solution set 10 objectives approximately estimate HV result solution set Monte Carlo sampling method 4 Here 10000000 sampling points ensure accuracy 4 43 Stateoftheart algorithms comparison We compare proposed BiGE following algorithms MultiObjective Evolutionary Algorithm based Decomposition MOEAD2 94 Decomposing MOP set scalar optimization subproblems optimizing collaborative manner MOEAD popular EMO algorithms developed recently The high search ability MOEAD multi manyobjective problems demonstrated literature 476369 Here Tchebycheff scalarizing function3 MOEAD experiments Nondominated Sorting Genetic Algorithm III NSGAIII4 20 NSGAIII recent manyobjective algorithm framework based NSGAII signiﬁcant changes selection mechanism Instead crowding distance NSGAIII uses decompositionbased niching technique maintain diversity NSGAIII shown outperform popular decompositionbased algorithms classical generative method manyobjective optimization 2053 Hypervolume Estimation Algorithm HypE5 4 HypE indicatorbased algorithm manyobjective optimization HypE adopts Monte Carlo simulation approximate hypervolume value signiﬁcantly reducing algorithms time cost enabling hypervolumebased search easily applied manyobjective optimization num ber objectives reaches 50 4 HypE demonstrated competitive WFG problem suite objectives 6988 Fuzzy Dominancebased NSGAII FDNSGAII6 39 To deal failure Pareto dominance manyobjective optimization fuzzy dominancebased ﬁtness evaluation mechanism developed 39 continuously dif ferentiate individuals different degrees optimality The concept fuzzy logic adopted deﬁne fuzzy Pareto dominance relation Speciﬁcally fuzzy set based Gaussian function applied quantify degrees domi nance dominating dominated degrees dominance objective Incorporated NSGAII proposed fuzzy concept promising manyobjective optimization 3839 2 The code MOEAD http dces essex ac uk staff zhang webofmoead htm 3 In order obtain uniform solutions Tchebycheff scalarizing function multiplying weight vector w original MOEAD 94 replaced dividing w suggested practiced recent studies 2064 4 The code NSGAIII http web ntnu edu tw tcchiang publications nsga3cpp nsga3cpp htm 5 The code HypE http wwwtikee ethz ch pisa 6 The code FDNSGAII provided authors 54 M Li et al Artiﬁcial Intelligence 228 2015 4565 ApproximationGuided Evolutionary Algorithm II AGEII7 84 Recently approximationguided EA AGE proposed 15 allows incorporate formal notion approximation EA Using best knowledge obtained far evolutionary process AGE improves approximation quality current population AGE shown outperform stateoftheart EMO algorithms particularly dealing manyobjective prob lems 1583 Despite good performance AGE suffer heavy computational cost new incomparable solutions unconditionally insert AGEs archive To tackle issue fast effective AGE called AGEII developed 84 AGEII introduces adaptive cid2dominance approach balance convergence speed runtime Also mating selection strategy elaborately designed emphasize diversity solution set 44 General experimental setting All results presented paper obtained executing 30 independent runs algorithm problem Following practice 3385 population size set 100 termination criterion run 30000 evaluations 300 generations WFG TSP water problems For knapsack problem evaluations required generation algorithm repair method deals infeasible solutions set 100000 evaluations termination criterion Note size population MOEAD NSGAIII number weight vectors impossible algorithms generate uniformly distributed weight vectors arbitrary number Here uniformly generate set 5000 weight vectors select 100 welldistributed weight vectors set method 95 Parameters need set peer algorithms According study MOEAD 94 neighborhood size speciﬁed 10 population size For HypE number sampling points HypE set 10000 Following practice 88 reference point calculating hypervolume contribution HypE set 2i 1 WFG problems number objectives problems reference point set HV indicator In FDNSGAII parameter σ determines spread Gaussian function set 05 suggested 39 In AGEII parameter cid2grid determines size archive set 01 provide good tradeoff performance runtime manyobjective problems 84 A crossover probability pc 10 mutation probability pm 1n n denotes number decision variables For continuous problems operators crossover mutation SBX crossover polynomial mutation distribution indexes set 20 494 As combinatorial problems following studies 1844 uniform crossover bitﬂip mutation knapsack instance order crossover inversion mutation TSP instance 5 Experimental results In section verify performance BiGE according experimental design described previous sec tion The HV results tables mean standard deviation SD 30 independent runs best second best mean values algorithms problem instance shown dark light gray background respectively Moreover order statistically sound conclusions adopt Wilcoxons rank sum test 98 005 signiﬁcance level examine signiﬁcance difference results obtained BiGE competitors The Wilcoxon test nonparametric alternative twosample ttest advantages 1 valid data nonnormal distribution 2 sensitive outliers 51 WFG problems Table 3 gives comparative results algorithms WFG problems 5 10 15 objectives As shown BiGE HypE perform best having clear advantage 4 algorithms test instances Speciﬁcally BiGE obtains best second best HV results 14 10 27 instances respectively HypE 10 15 respectively NSGAIII performs best 5objective WFG3 WFG9 generally outperforms algorithms AGEII MOEAD typically work fairly 5objective WFG struggle 10 15objective instances FDNSGAII fails maintain diversity individuals population worst HV results WFG problem suite Concerning statistical results observed difference BiGE peer algorithms sig niﬁcant test instances Speciﬁcally proportion test instances BiGE outperforms MOEAD NSGAIII HypE FDNSGAII AGEII statistical signiﬁcance 2627 2127 1127 2727 2527 respectively Con versely proportion instances BiGE performs worse MOEAD NSGAIII HypE FDNSGAII AGEII statistical signiﬁcance 127 227 927 027 027 respectively For visual understanding solutions distribution Fig 5 plots ﬁnal solutions run respect 10objective WFG9 parallel coordinates This particular run associated result closest mean 7 The code AGEII provided authors M Li et al Artiﬁcial Intelligence 228 2015 4565 55 Table 3 Normalized HV results mean SD algorithms WFG problem The best second mean algorithms problem instance shown dark light gray background respectively Problem Obj MOEAD NSGAIII HypE FDNSGAII AGEII BiGE WFG1 WFG2 WFG3 WFG4 WFG5 WFG6 WFG7 WFG8 WFG9 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 6892E1 36E2 6421E1 32E2 5913E1 22E2 7999E1 90E2 7576E1 84E2 6454E1 77E2 6450E1 20E2 4553E1 32E2 2431E1 23E2 5899E1 29E2 4359E1 44E2 3000E1 38E2 6418E1 18E2 4911E1 34E2 3170E1 64E2 5753E1 26E2 5158E1 43E2 2845E1 45E2 6413E1 43E2 5852E1 43E2 2057E1 58E2 3536E1 27E2 3756E1 31E2 2479E1 63E2 4727E1 35E2 3675E1 53E2 2044E1 53E2 6773E1 63E2 7710E1 54E2 7208E1 31E2 8881E1 15E1 8647E1 75E2 8834E1 81E2 9139E1 17E2 7949E1 66E2 8136E1 77E2 7269E1 65E2 4223E1 76E2 5332E1 48E2 7607E1 58E3 5235E1 65E2 6250E1 54E2 7718E1 39E2 5389E1 51E2 6528E1 45E2 7878E1 37E2 5637E1 67E2 6919E1 52E2 5609E1 97E2 4944E1 70E2 6112E1 88E1 7253E1 16E2 6127E1 36E2 5570E1 42E2 7827E1 16E2 8324E1 23E2 8138E1 31E2 8819E1 86E2 8864E1 80E2 9247E1 83E2 9137E1 74E3 9149E1 12E2 8964E1 18E2 8171E1 76E3 8049E1 29E2 7831E1 25E2 7701E1 85E3 8142E1 17E2 7628E1 19E2 7750E1 12E2 8352E1 11E2 8139E1 23E2 8262E1 87E3 8808E1 12E2 8305E1 24E2 6893E1 77E3 7628E1 12E2 7872E1 24E2 6971E1 32E2 6727E1 24E2 6677E1 12E2 2194E1 72E2 4294E1 69E2 4775E1 78E2 2977E1 74E2 2698E1 14E1 2841E1 12E1 1330E1 19E3 1242E1 18E3 1213E1 24E3 2770E1 82E2 2207E1 98E2 1223E1 52E2 8776E2 20E4 7930E2 26E4 7892E2 28E4 1040E1 35E2 8434E2 13E3 8367E2 12E3 1011E1 37E5 1140E1 53E2 9381E2 17E2 1529E1 86E2 1279E1 59E2 1116E1 52E2 8059E2 46E5 7417E2 23E3 7435E2 33E3 5219E1 24E2 6092E1 28E2 5735E1 22E2 9180E1 72E2 9168E1 71E2 8535E1 71E2 8139E1 25E2 6673E1 34E2 4713E1 26E2 6381E1 19E2 3248E1 23E2 2336E1 23E2 6301E1 15E2 4040E1 35E2 2735E1 65E2 6577E1 18E2 3897E1 30E2 3402E1 71E2 6770E1 20E2 3869E1 56E2 1160E1 25E2 5587E1 28E2 2976E1 71E2 1215E1 45E2 5963E1 29E2 4273E1 51E2 3408E1 52E2 6151E1 39E2 7786E1 47E2 7612E1 34E2 9014E1 82E2 9475E1 53E2 9402E1 61E2 9092E1 11E2 8705E1 18E2 8545E1 26E2 8117E1 84E3 8313E1 11E2 8073E1 19E2 7709E1 62E3 7990E1 19E2 7715E1 14E2 7728E1 89E3 8270E1 13E2 8339E1 14E2 8356E1 55E3 8827E1 12E2 8787E1 13E2 6822E1 91E3 7722E1 61E3 8179E1 10E2 6903E1 14E2 6824E1 13E2 6893E1 31E2 indicates result peer algorithm signiﬁcantly different BiGE 005 level Wilcoxons rank sum test Fig 5 The ﬁnal solution set algorithms tenobjective WFG9 shown parallel coordinates 56 M Li et al Artiﬁcial Intelligence 228 2015 4565 Table 4 Normalized HV results mean SD algorithms Knapsack problem The best second mean algorithms problem instance shown dark light gray background respectively Obj MOEAD NSGAIII HypE FDNSGAII AGEII BiGE 5 10 15 5412E1 32E2 1385E1 36E2 1396E1 29E2 5467E1 21E2 2529E2 32E2 2100E1 30E2 indicates result peer algorithm signiﬁcantly different BiGE 005 level Wilcoxons rank sum test 5436E1 24E2 3171E1 40E2 2183E1 28E2 5319E1 27E2 3224E1 54E2 2299E1 33E2 4657E1 16E2 1017E1 26E2 4793E2 14E2 5738E1 21E2 3507E1 53E2 2268E1 37E2 Table 5 Normalized HV results mean SD algorithms TSP problem The best second mean algorithms problem instance shown dark light gray background respectively Obj MOEAD NSGAIII HypE FDNSGAII AGEII BiGE 5 10 15 6004E1 31E2 2246E1 39E2 4201E2 17E2 5037E1 21E2 3000E1 18E2 2144E1 41E2 indicates result peer algorithm signiﬁcantly different BiGE 005 level Wilcoxons rank sum test 5636E1 38E2 4125E1 88E2 2446E1 63E2 6345E1 25E2 3477E1 28E2 1467E1 27E2 4173E1 39E2 2295E2 11E2 8876E3 64E3 6186E1 21E2 4523E1 30E2 2860E1 47E2 HV value Although considered solution sets appear converge optimal upper lower bounds objective WFGs Pareto 0 2 respectively algorithms perform differently terms diversity maintenance The solutions obtained FDNSGAII converge point Pareto solutions MOEAD concentrate boundaries optimal The solutions AGEII NSGAIII good uniformity fail reach regions Pareto HypE BiGE perform similarly The difference solutions HypE struggle cover problems boundary objectives solutions BiGE appear good coverage Pareto 52 The knapsack problem Table 4 gives results algorithms 01 knapsack problem As seen table BiGE generally outperforms ﬁve peer algorithms Speciﬁcally 5 10objective instances BiGE best HV value difference BiGE competitors statistically signiﬁcant For 15objective instance BiGE ranks second outperformed FDNSGAII In addition interesting note FDNSGAII performs worst WFG problems works knapsack problem TSP problem shown Table 5 later This indicates different characteristics continuous combinatorial optimization problems Some EMO algorithms better behavior combinatorial optimization problems ﬁtness assignment strategy particularly suitable structure integral code problems 53 The TSP problem The normalized HV results algorithms TSP test instances shown Table 5 It observed BiGE performs better problem larger number objectives For 5objective TSP AGEII highest HV value BiGE outperforms algorithms statistical signiﬁcance For 10 15objective instances BiGE FDNSGAII like knapsack problem perform better algorithms A difference results knapsack problem BiGE obtains higher HV value FDNSGAII instances It worth mentioning HypE NSGAIII competitive WFG problems perform constantly worse BiGE 6 knapsack TSP instances To facilitate visual comparison Fig 6 plots ﬁnal solutions single run algorithms dimensional objective space f 1 f 2 15objective TSP Similar plots obtained objectives problem As shown solutions BiGE good balance proximity diversity In contrast ﬁve peer algorithms struggle terms proximity solutions generally distributed topright region ﬁgures 54 The water problem The water problem threevariable ﬁveobjective sevenconstraint realworld problem 7277 designed optimize planning storm drainage urban area Table 6 gives HV results algorithms problem As shown BiGE outperforms ﬁve peer algorithms statistical signiﬁcance This indicates effec tiveness proposed bigoal evolution dealing problem objectives constraints M Li et al Artiﬁcial Intelligence 228 2015 4565 57 Fig 6 Result comparison BiGE ﬁve algorithms 15objective TSP The ﬁnal solutions algorithms shown twodimensional objective space f 1 f 2 Table 6 Normalized HV results mean SD algorithms water problem The best second mean algorithms problem instance shown dark light gray background respectively MOEAD NSGAIII HypE FDNSGAII AGEII BiGE 8589E1 91E3 9176E1 29E3 9133E1 38E3 1982E1 18E3 8960E1 15E3 9273E1 41E3 indicates result peer algorithm signiﬁcantly different BiGE 005 level Wilcoxons rank sum test 55 Result summary To sum BiGE generally outperforms ﬁve stateoftheart algorithms best second best HV results 19 12 34 test instances respectively The ﬁve peer algorithms perform differently problems distinct properties HypE NSGAIII perform continuous MOPs FDNSGAII competitive combinatorial ones AGEII MOEAD work fairly 5objective instances perform poorly higherdimensional objective space Similar observations reported recent studies 88699686 In addition behavior difference BiGE peer algorithms seen simple artiﬁcial example Table 1 In example BiGE effectively distinguish seven Pareto nondominated solutions B G C E clearly outperforming remaining ones cf Fig 3c In contrast ﬁve peer algorithms fail pick solutions The individual selection MOEAD NSGAIII HypE AGEII largely depends references associated algorithm MOEAD NSGAIII predeﬁned reference directions basis distribution weight vectors HypE reference point hypervolume calculation AGEII distribution solutions archive For FDNSGAII fuzzybased dominance relation prefers wellconverged individuals B A G C assigned better ﬁtness values lead loss population diversity 6 Further investigations BiGE The experimental results previous section shown effectiveness BiGE diverse problems Next examine BiGE investigating effect parameter setting algorithm performance comparing algorithms similar components proposed algorithm 58 M Li et al Artiﬁcial Intelligence 228 2015 4565 Fig 7 Normalized HV algorithms different settings population size 10objective WFG9 Fig 8 Normalized HV algorithms different settings number objectives WFG9 61 Effect population size objective dimensionality In BiGE parameters population size number objectives play important role They determine niche radius crowding degree estimation algorithm In section investigate effect parameters algorithms performance Here experimental results WFG9 challenging test problems inferred HV values Table 3 Similar results observed problems First consider effect population size performance algorithms The population size previous studies ﬁxed 100 In study wide range population size 50 1000 test performance algorithm varies Other parameters kept unchanged study function evaluations changed accordingly order number generations 300 ﬁxed Fig 7 shows HV results 10objective WFG9 Clearly FDNSGAII HV result algorithms increases population size means larger population size generally leads better performance This shown evidently AGEII NSGAIII MOEAD On hand HypE BiGE outperform algorithms seven settings population size More speciﬁcally HypE best HV population size 50 BiGE performs best remaining cases Overall results indicate insensitiveness proposed algorithm population size BiGE work sizes evolutionary population Next consider effect objective dimensionality performance algorithms In previous studies algorithms tested 5 10 15 objectives Here extend range number objectives investigate algorithms work lower higherdimensional space Fig 8 shows HV results algorithms 3 4 5 7 10 15 20objective WFG9 As shown NSGAIII HypE BiGE outperform algorithms seven settings number objectives Taking closer comparison algorithms NSGAIII HypE perform best problem 3 5 objectives BiGE shows advantage number objectives reaches 10 In addition interesting difference BiGE algorithms HV value remains steady degrades increase number objectives This occurrence attributed fact bigoal evolution provide good balance proximity diversity largely independent problems objective dimensionality 62 Effect sharing discriminator sharing function A feature BiGE sharing discriminator introduced differentiate individuals niche When calculating sharing function neighboring individuals better proximity encouraged multiplying 05 discouraged multiplying 15 denote sharing discriminator sde sdd This adjustment lead individual better proximity lower crowding degree individual worse proximity M Li et al Artiﬁcial Intelligence 228 2015 4565 59 Table 7 Normalized HV BiGE different set tings sharing discriminator 10objective WFG9 sde sdd 000 200 025 175 050 150 075 175 100 100 Normalized HV 6211E1 15E2 6822E1 14E2 6824E1 13E2 6806E1 13E2 5650E1 15E2 Table 8 Normalized HV BiGE settings sharing discriminator discourage individual worse proximity 10objective WFG9 sd1 sd2 100 125 100 150 100 175 100 200 050 150 Normalized HV 6720E1 13E2 6773E1 12E2 6758E1 13E2 6732E1 12E2 6824E1 13E2 higher Now straightforward question sde sdd affects performance algorithm In addition ask discourage individual worse proximity remaining unchanged sde sdd set 10 15 In case neighboring individuals differentiated In section investigate effect sharing discriminator attempt answer questions Due space limitation results 10objective WFG9 Similar results obtained problems Here consider representative settings discriminator 00 20 025 175 075 125 10 10 The setting 00 20 extreme individual better proximity assigned zero sharing function value 10 10 extreme individuals sharing function value changed The settings 025 175 075 125 middle values extremes setting 05 15 paper Table 7 gives HV results BiGE settings 05 15 10objective WFG9 As shown algorithm settings 025 175 05 15 075 125 performs similarly signiﬁcantly outperform algorithm extreme settings 00 20 10 10 This indicates insensitiveness algorithm discriminator parameter certain range BiGE work different discriminator values provided away extremes Next consider case individual worse proximity discouraged sharing function That sde set 10 sdd larger 10 Here consider settings discriminator 10 125 10 15 10 175 10 20 The HV results BiGE given Table 8 result algorithm 05 15 repeated comparison As seen table algorithm individual better prox imity encouraged performs slightly worse original algorithm This occurrence attributed following reason In general group individuals niche ideal select representative individual best proximity population However discriminator setting discourages dividuals worse proximity individuals niche high crowding degree comparison having neighbor niche This lead individuals niche surviving population Thus encouragement individual better proximity niche beneﬁcial diversity population differentiates similar individuals enables representative preserved evolutionary process 63 Comparison average ranking AR methods In BiGE proximity individual estimated sum normalized values objectives This estimation viewed slightly ﬁnegrained version wellknown AR method 5 AR estimates proximity individual summing ranks population objectives The difference estimations AR considers individuals rank population objective proposed proximity estimation considers quantitative difference individuals objective As individual comparison criterion AR popular manyobjective optimization Corne Knowles demon strated AR provide suﬃcient selection pressure optimal highdimensional objective space 18 However lack diversity maintenance scheme AR lead evolutionary population verge subarea Pareto 52 Recently methods proposed enhance diversity AR For 60 M Li et al Artiﬁcial Intelligence 228 2015 4565 Table 9 Normalized HV results mean SD algorithms 34 test instances The best second mean algorithms problem instance shown dark light gray background respectively Problem WFG1 WFG2 WFG3 WFG4 WFG5 WFG6 WFG7 WFG8 WFG9 Knapsack TSP Water Obj AR 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 10 15 5 1553E2 69E2 1577E1 14E1 4961E1 29E1 1714E1 76E2 2276E1 90E2 2442E1 99E2 2274E1 29E2 2001E1 28E2 1868E1 39E2 1351E1 17E2 1114E1 13E2 1053E1 11E2 1210E1 21E2 9355E2 11E2 9344E2 10E2 1196E1 23E2 9997E2 24E2 1019E1 26E2 2239E1 74E2 2166E1 60E2 1734E1 51E2 1832E1 30E2 1581E1 25E2 1449E1 30E2 1218E1 44E2 9933E2 37E2 1131E1 57E2 4199E1 32E2 1409E1 36E2 7471E2 19E2 2850E1 30E2 1251E1 24E2 5187E2 27E2 7904E1 77E3 ARsharing 5001E1 14E2 4842E1 29E2 4716E1 31E2 9663E1 82E3 9717E1 14E2 9587E1 19E2 7470E1 37E2 7486E1 55E2 7559E1 47E2 6745E1 15E2 6455E1 23E2 5448E1 36E2 6634E1 14E2 6754E1 18E2 6224E1 24E2 6283E1 19E2 6607E1 24E2 6673E1 30E2 6876E1 15E2 7303E1 21E2 6858E1 35E2 5064E1 14E2 5769E1 27E2 6427E1 28E2 6078E1 14E2 6314E1 19E2 6122E1 26E2 4538E1 29E2 2879E1 13E2 1403E1 39E2 3295E1 32E2 1837E1 24E2 1013E1 55E2 8668E1 56E3 BiGEAR 5530E1 28E2 5998E1 39E2 6001E1 37E2 9255E1 84E2 9715E1 52E2 9541E1 63E2 8975E1 14E2 8609E1 21E2 8349E1 23E2 8340E1 65E3 8304E1 11E2 7829E1 27E2 7778E1 74E3 7909E1 11E2 7870E1 13E2 7891E1 93E3 8190E1 10E2 8120E1 18E2 8426E1 68E3 8489E1 12E2 8182E1 19E2 6833E1 89E3 7478E1 86E3 7843E1 14E2 6910E1 87E3 6742E1 21E2 6616E1 35E2 5652E1 21E2 3126E1 39E2 2096E1 33E2 5788E1 29E2 4094E1 33E2 2367E1 48E2 9213E1 80E3 BiGE 6151E1 39E2 7786E1 47E2 7612E1 34E2 9014E1 82E2 9475E1 53E2 9402E1 61E2 9092E1 11E2 8705E1 18E2 8545E1 26E2 8117E1 84E3 8313E1 11E2 8073E1 19E2 7709E1 62E3 7990E1 19E2 7715E1 14E2 7728E1 89E3 8270E1 13E2 8339E1 14E2 8356E1 55E3 8827E1 12E2 8787E1 13E2 6822E1 91E3 7722E1 61E3 8179E1 10E2 6903E1 14E2 6824E1 13E2 6893E1 31E2 5738E1 21E2 3507E1 53E2 2268E1 37E2 6186E1 21E2 4523E1 30E2 2860E1 47E2 9273E1 41E3 indicates result peer algorithm signiﬁcantly different BiGE 005 level Wilcoxons rank sum test example Purshouse et al modiﬁcation ARbased ﬁtness combining sharing scheme based Epanechnikov kernel 76 Li et al imposed punishment individuals neighbors bestAR individual prohibit postpone entry population 70 Kong et al repeatedly initialized population chaotic method generations order enhance diversity individuals decision space 59 Instead consider ing objectives original AR Yuan et al summed aggregation function values based uniformlydistributed weight vectors 93 A clear difference BiGE ARbased algorithms BiGE uses idea Pareto dominance deal proximity diversity This suited manyobjective optimization conﬂict proximity diversity goals bi triobjective optimization Considering dominance relation goals provide good balance lead algorithm affected increase objective dimensionality Next empirically investigate difference BiGE ARbased algorithms Speciﬁcally consider peer algorithms 1 original AR 5 2 AR combined ﬁtness sharing scheme called ARsharing 76 3 new version BiGE AR proximity estimation method denoted BiGEAR In 76 AR competitive combined sharing scheme based Epanechnikov kernel 27 From initial experiments replacing Epanechnikov kernel proposed niching method algorithm obtain similar results Therefore proposed niching method ARsharing order investigate difference algorithm framework That ARsharing BiGEAR proximity crowding degree estimation methods difference algorithm framework In addition worth noting BiGEAR BiGE algorithm framework difference proximity estimation Table 9 gives HV results algorithms 34 test instances comparison results BiGE included table As shown diversity mechanism dramatically improves HV results ARsharing BiGEAR BiGE outperforming original AR 34 test instances This suggests importance diversity maintenance manyobjective optimization M Li et al Artiﬁcial Intelligence 228 2015 4565 61 Regarding algorithms having proximity crowding degree estimators BiGEAR performs better ARsharing 31 34 instances This clearly indicates advantage bigoal evolution framework objective problems In ARsharing proximity diversity information individual population integrated scalar value One think ARsharing work second negatively correlated helper objective explicitly related diversity promotion This type structure presented multiobjectivization literature solve singleobjective problems 55 However ARsharing structure struggle balance proximity diversity manyobjective problems explicit diversity maintenance mechanism algorithm guide search different promising areas In addition note ARsharing best HV result WFG2 instances disconnected Pareto This ARsharing ﬁnd optimal regions Pareto 30 runs BiGEAR BiGE half 30 runs Finally considering comparison versions bigoal evolution algorithm BiGEAR outperforms BiGE 10 test instances including seven 5objective instances BiGE better HV result remaining 24 stances An interesting observation ﬁnegrained algorithm BiGEAR generally performs better 5objective instances One possible explanation BiGEAR prefer boundary individuals population These boundary solutions perform poorly objective best nearly best objectives play important role extending search range Due having consideration quantitative difference individ uals BiGEAR favor solutions Nevertheless worth pointing ﬁnegrained estimation individual proximity important highdimensional space needed clearly differentiate individuals 7 Discussions In BiGE diversity goal estimated nichebased crowding degree In estimation radius niche depends factors population size number objectives A large population size low objective dimen sionality lead small radius The previous experiments Section 61 shown effectiveness BiGE settings population size number objectives This indicates BiGE works setting niche radius It worth pointing niche radius paper rough setting estimate A ﬁnely tuned setting based characteristics given MOP varying Pareto fronts shape lead better performance algorithm Nevertheless algorithm radius setting shown high competitiveness ﬁve stateoftheart algorithms diverse MOPs considered Also setting beneﬁt applicability algorithm realworld problems hard impossible know problems characteristics The major purpose EMO algorithm assist decisionmaker select single solution solutions ﬁts hisher preferences 1795474 However EMO algorithm usually supply decisionmaker ap proximation Pareto diﬃcult decisionmaker choose hisher preferred ones especially manyobjective optimization In spite obtaining Pareto approximation set welldistributed wellconverged solutions greatly useful learn characteristics optimization problem For example decisionmaker learn nature tradeoffs objectives discontinuousness convexity degeneration knees discover inconsistencies model regard real optimization problem 51 This help decisionmaker specify preferences eﬃciently lead search eventually ﬁnd satisﬁed solution On hand diﬃculties representing Pareto choosing satisﬁed solution highdimensional space appealing EMO algorithm work collaboratively decisionmaker preferences This lead search region decisionmaker Intuitively ways implementing incorporation decisionmaker preferences proposed bigoal evolution framework 1 incorporating preference information proximity goal 2 incorporating preference information diversity goal 3 incorporating preference information proximity diversity goals However ﬁrst ways lead evolutionary population hard rid individuals far away region decisionmaker individuals perform goal goal including preference information nondominated population basis goals Therefore better alternative proximity diversity goals implicate preference information considering individuals distance relative position reference point supplied decisionmaker This help population evolve gradually region decisionmaker relative balance proximity diversity highdimensional objective space 8 Conclusions Manyobjective optimization poses great challenges EAs The ineffectiveness Pareto dominance relation highdimensional space suggests need new methodologies This paper presents metaobjective optimization approach called BiGE deal manyobjective problems Converting objectives given problem 62 M Li et al Artiﬁcial Intelligence 228 2015 4565 objectives proximity crowding degree BiGE creates optimization problem objectives goals search process Systematic experiments carried providing extensive comparative studies BiGE ﬁve state oftheart algorithms groups welldeﬁned continuous combinatorial benchmark suites 5 10 15 objectives Unlike peer algorithms work fraction test problems AGEII MOEAD 5objective instances HypE NSGAIII continuous instances FDNSGAII combinatorial stances BiGE achieve good balance solutions proximity diversity test problems different properties In addition effect parameters algorithm investigated Experimental results dicated insensitiveness BiGE population size objective dimensionality effectiveness BiGE different settings sharing discriminator certain range Finally comparison ARbased al gorithms shown advantage proposed framework proximity estimation dealing manyobjective problems Bigoal evolution proximity diversity new concept evolutionary multiobjective optimization It performs key decision process mating environmental selection twolay process lower level sort recursive multiobjective optimization This twolayer decision structure open possibilities hy bridizations future example instantiated different comparison strategies selection process Despite high competitiveness BiGE shown ﬁrst attempt work needed investigate beneﬁts limitations future In regard applying BiGE realworld problems developing introducing proximity crowding degree estimation methods focuses subsequent study Acknowledgements The authors like thank Dr Markus Wagner School Computer Science University Adelaide Prof Gary G Yen School Electrical Computer Engineering Oklahoma State University help carrying exper iments This work supported Engineering Physical Sciences Research Council EPSRC UK Grant EPK0013101 National Natural Science Foundation China Grant 71110107026 EU FP7Health Grant 242193 References 1 SF Adra PJ Fleming Diversity management evolutionary manyobjective optimization IEEE Trans Evol Comput 15 2011 183195 2 H Aguirre K Tanaka Space partitioning adaptive cid2ranking substitute distance assignments comparative study manyobjective MNK landscapes Proceedings 11th Annual Conference Genetic Evolutionary Computation GECCO 2009 pp 547554 3 A Auger J Bader D Brockhoff E Zitzler Theory hypervolume indicator optimal μdistributions choice reference point Proceedings 10th ACM SIGEVO Workshop Foundations Genetic Algorithms FOGA 2009 pp 87102 4 J Bader E Zitzler HypE algorithm fast hypervolumebased manyobjective optimization Evol Comput 19 2011 4576 5 PJ Bentley JP Wakeﬁeld Finding acceptable solutions Paretooptimal range multiobjective genetic algorithms Soft Computing Engineering Design Manufacturing 1997 pp 231240 chapter 5 6 N Beume Smetric calculation considering dominated hypervolume Klees measure problem Evol Comput 17 2009 477492 7 N Beume B Naujoks M Emmerich SMSEMOA multiobjective selection based dominated hypervolume Eur J Oper Res 181 2007 16531669 8 J Bibaı P Savéant M Schoenauer V Vidal An evolutionary metaheuristic based state decomposition domainindependent satisﬁcing planning Proc 20th International Conference Automated Planning Scheduling ICAPS 2010 pp 1825 9 J Branke K Deb K Miettinen R Slowinski Eds Multiobjective Optimization Interactive Evolutionary Approaches SpringerVerlag Berlin 10 AH Brie P Morignot Genetic planning variable length chromosomes Proc 20th International Conference Automated Planning 11 K Bringmann T Friedrich Approximating volume unions intersections highdimensional geometric objects Comput Geom 43 2010 Heidelberg 2008 Scheduling ICAPS 2005 pp 320329 601610 12 K Bringmann T Friedrich An eﬃcient algorithm computing hypervolume contributions Evol Comput 18 2010 383402 13 K Bringmann T Friedrich Approximation quality hypervolume indicator Artif Intell 195 2013 265290 14 K Bringmann T Friedrich C Igel T Voß Speeding manyobjective optimization Monte Carlo approximations Artif Intell 204 2013 2229 15 K Bringmann T Friedrich F Neumann M Wagner Approximationguided evolutionary multiobjective optimization Proceedings 22nd International Joint Conference Artiﬁcial Intelligence IJCAI 2011 pp 11981203 16 D Brockhoff T Friedrich N Hebbinghaus C Klein F Neumann E Zitzler On effects adding objectives plateau functions IEEE Trans Evol Comput 13 2009 591603 putation CEC 2000 pp 3037 17 CA Coello Coello Handling preferences evolutionary multiobjective optimization survey Proceedings Congress Evolutionary Com 18 DW Corne JD Knowles Techniques highly multiobjective optimisation nondominated points better Proceedings 9th Annual Conference Genetic Evolutionary Computation GECCO 2007 pp 773780 19 K Deb MultiObjective Optimization Using Evolutionary Algorithms John Wiley New York 2001 20 K Deb H Jain An evolutionary manyobjective optimization algorithm referencepointbased nondominated sorting approach I solving problems box constraints IEEE Trans Evol Comput 18 2014 577601 21 K Deb S Jain Running performance metrics evolutionary multiobjective optimization Technical Report 2002004 KanGAL Indian Institute Technology 2002 M Li et al Artiﬁcial Intelligence 228 2015 4565 63 22 K Deb M Mohan S Mishra Evaluating cid2domination based multiobjective evolutionary algorithm quick computation Paretooptimal solutions Evol Comput 13 2005 501525 23 K Deb A Pratap S Agarwal T Meyarivan A fast elitist multiobjective genetic algorithm NSGAII IEEE Trans Evol Comput 6 2002 182197 24 K Deb L Thiele M Laumanns E Zitzler Scalable test problems evolutionary multiobjective optimization A Abraham L Jain R Goldberg Eds Evolutionary Multiobjective Optimization Theoretical Advances Applications Springer Berlin Germany 2005 pp 105145 25 M Ehrgott Multiobjective optimization AI Mag 29 2009 4757 26 P Fleming R Purshouse R Lygoe Manyobjective optimization engineering design perspective Proceedings 3rd International Conference Evolutionary MultiCriterion Optimization EMO 2005 pp 1432 27 C Fonseca P Fleming Multiobjective genetic algorithms easy selection sharing mating restriction Proceedings First International Conference Genetic Algorithms Engineering Systems Innovations Applications 1995 pp 4252 28 CM Fonseca PJ Fleming An overview evolutionary algorithms multiobjective optimization Evol Comput 3 1995 116 29 T Friedrich K Bringmann T Voß C Igel The logarithmic hypervolume indicator Proceedings 11th ACM SIGEVO Workshop Foundations Genetic Algorithms FOGA 2011 pp 8192 30 T Friedrich C Horoba F Neumann Multiplicative approximations hypervolume indicator Proceedings 11th Annual Conference Genetic Evolutionary Computation GECCO 2009 pp 571578 31 T Friedrich F Neumann C Thyssen Multiplicative approximations optimal hypervolume distributions choice reference point Evol Comput 2014 press Evolutionary Computation CEC 2010 pp 18 32 M GarzaFabre G ToscanoPulido CAC Coello Two novel approaches manyobjective optimization Proceedings IEEE Congress 33 M GarzaFabre G ToscanoPulido CCA Coello E RodriguezTello Effective ranking speciation manyobjective optimization Proceedings IEEE Congress Evolutionary Computation CEC 2011 pp 21152122 34 D Goldberg Genetic Algorithms Search Optimization Machine Learning AddisonWesley 1989 35 D Hadka P Reed Diagnostic assessment search controls failure modes manyobjective evolutionary optimization Evol Comput 20 2012 423452 36 D Hadka P Reed Borg autoadaptive manyobjective evolutionary computing framework Evol Comput 21 2013 231259 37 Z He GG Yen A new ﬁtness evaluation method based fuzzy logic multiobjective evolutionary algorithms Proceedings IEEE Congress 38 Z He GG Yen Ranking manyobjective evolutionary algorithms performance metrics ensemble Proceedings IEEE Congress Evolutionary Computation CEC 2012 pp 18 Evolutionary Computation CEC 2013 pp 24802487 39 Z He GG Yen J Zhang Fuzzybased Pareto optimality manyobjective evolutionary algorithms IEEE Trans Evol Comput 18 2014 269285 40 S Huband P Hingston L Barone L While A review multiobjective test problems scalable test problem toolkit IEEE Trans Evol Comput 10 2006 477506 tion GECCO 2011 pp 761768 41 EJ Hughes Manyobjective directed evolutionary line search Proceedings 13th Annual Conference Genetic Evolutionary Computa 42 C Igel N Hansen S Roth Covariance matrix adaptation multiobjective optimization Evol Comput 15 2007 128 43 K Ikeda H Kita S Kobayashi Failure Paretobased MOEAs nondominated mean near optimal Proceedings IEEE Congress 44 H Ishibuchi N Akedo Y Nojima Behavior multiobjective evolutionary algorithms manyobjective knapsack problems IEEE Trans Evol Comput Evolutionary Computation CEC 2001 pp 957962 2014 press 45 H Ishibuchi Y Hitotsuyanagi N Tsukamoto Y Nojima Manyobjective test problems visually examine behavior multiobjective evolution decision space Proceedings International Conference Parallel Problem Solving Nature PPSN 2010 pp 91100 46 H Ishibuchi H Masuda Y Nojima Metalevel multiobjective formulations set optimization multiobjective optimization problems multi reference point approach hypervolume maximization Proceedings 2014 Conference Companion Genetic Evolutionary Computa tion GECCO 2014 pp 8990 47 H Ishibuchi Y Sakane N Tsukamoto Y Nojima Evolutionary manyobjective optimization NSGAII MOEAD large populations Proceedings IEEE Conference Systems Man Cybernetics 2009 pp 17581763 48 H Ishibuchi N Tsukamoto Y Nojima Evolutionary manyobjective optimization short review Proceedings IEEE Congress Evolutionary Computation CEC 2008 pp 24192426 49 H Ishibuchi N Tsukamoto Y Sakane Y Nojima Indicatorbased evolutionary algorithm hypervolume approximation achievement scalarizing functions Proceedings 12th Annual Conference Genetic Evolutionary Computation GECCO ACM 2010 pp 527534 50 AL Jaimes CA Coello Coello Study preference relations manyobjective optimization Proceedings 11th Annual Conference Genetic Evolutionary Computation GECCO 2009 pp 611618 51 AL Jaimes CA Coello Coello H Aguirre K Tanaka Adaptive objective space partitioning conﬂict information manyobjective optimization Proceedings 6th International Conference Evolutionary MultiCriterion Optimization EMO 2011 pp 151165 52 AL Jaimes LVS Quintero CA Coello Coello Ranking methods manyobjective evolutionary algorithms R Chiong Ed NatureInspired Algo rithms Optimisation Springer Berlin Germany 2009 pp 413434 53 H Jain K Deb An evolutionary manyobjective optimization algorithm referencepoint based nondominated sorting approach II handling constraints extending adaptive approach IEEE Trans Evol Comput 18 2014 602622 54 A Jaszkiewicz J Branke Interactive multiobjective evolutionary algorithms Multiobjective Optimization Springer 2008 pp 179193 55 MT Jensen Helperobjectives multiobjective evolutionary algorithms singleobjective optimisation J Math Model Algorithms 3 2004 56 D Jones M Jimenez Incorporating additional metaobjectives extended lexicographic goal programming framework Eur J Oper Res 227 323347 2013 343349 57 R Joshi B Deshpande Scalability populationbased search heuristics manyobjective optimization Proceedings 16th European Con 58 M Khouadjia M Schoenauer V Vidal J Dréo P Savéant Paretobased multiobjective AI planning Proceedings TwentyThird International ference Applications Evolutionary Computation 2013 pp 479488 Joint Conference Artiﬁcial Intelligence IJCAI 2013 pp 23212327 64 M Li et al Artiﬁcial Intelligence 228 2015 4565 59 W Kong J Ding T Chai J Sun Largedimensional multiobjective evolutionary algorithms based improved average ranking 49th IEEE Confer ence Decision Control CDC 2010 pp 502507 60 N Kowatari A Oyama HE Aguirre K Tanaka A study large population MOEA adaptive εbox dominance neighborhood recombination manyobjective optimization Proceedings 6th Learning Intelligent Optimization Conference LION 2012 pp 86100 61 M Laumanns L Thiele K Deb E Zitzler Combining convergence diversity evolutionary multiobjective optimization Evol Comput 10 2002 263282 62 M Laumanns R Zenklusen Stochastic convergence random search methods ﬁxed size Pareto approximations Eur J Oper Res 213 2011 414421 63 H Li Q Zhang Multiobjective optimization problems complicated Pareto sets MOEAD NSGAII IEEE Trans Evol Comput 13 2009 284302 64 K Li Q Zhang S Kwong M Li R Wang Stable matching based selection evolutionary multiobjective optimization IEEE Trans Evol Comput 18 65 M Li S Yang X Liu Diversity comparison Pareto approximations manyobjective optimization IEEE Trans Cybern 44 2014 25682584 66 M Li S Yang X Liu Shiftbased density estimation Paretobased algorithms manyobjective optimization IEEE Trans Evol Comput 18 2014 2014 909923 348365 67 M Li S Yang X Liu A test problem visual investigation highdimensional multiobjective search Proceedings IEEE Congress Evolutionary Computation CEC 2014 pp 21402147 68 M Li S Yang X Liu A performance comparison indicator Pareto approximations manyobjective optimization Proceedings 17th Annual Conference Genetic Evolutionary Computation GECCO 2015 pp 703710 69 M Li S Yang X Liu R Shen A comparative study evolutionary algorithms manyobjective optimization Proceedings 7th Interna tional Conference Evolutionary MultiCriterion Optimization EMO 2013 pp 261275 70 M Li J Zheng K Li Q Yuan R Shen Enhancing diversity average ranking method evolutionary manyobjective optimization Proceedings International Conference Parallel Problem Solving Nature PPSN 2010 pp 647656 71 S Mostaghim H Schmeck Distance based ranking manyobjective particle swarm optimization Proceedings International Conference Parallel Problem Solving Nature PPSN 2008 pp 753762 72 K Musselman J Talavage A tradeoff cut approach multiple objective optimization Oper Res 28 1980 14241435 73 M Negnevitsky Artiﬁcial Intelligence A Guide Intelligent Systems Pearson Education 2005 74 RC Purshouse K Deb MM Mansor S Mostaghim R Wang A review hybrid evolutionary multiple criteria decision making methods IEEE Congress Evolutionary Computation CEC 2014 pp 11471154 75 RC Purshouse PJ Fleming On evolutionary optimization conﬂicting objectives IEEE Trans Evol Comput 11 2007 770784 76 RC Purshouse C Jalba PJ Fleming Preferencedriven coevolutionary algorithms promise manyobjective optimisation Proceedings 6th International Conference Evolutionary MultiCriterion Optimization EMO 2011 pp 136150 77 T Ray K Tai KC Seow Multiobjective design optimization evolutionary algorithm Eng Optim 33 2001 399424 78 H Sato H Aguirre K Tanaka Controlling dominance area solutions impact performance MOEAs Proceedings 4th International Conference Evolutionary MultiCriterion Optimization EMO 2007 pp 520 79 H Sato HE Aguirre K Tanaka Selfcontrolling dominance area solutions evolutionary manyobjective optimization Proceedings 8th International Conference Simulated Evolution Learning SEAL 2010 pp 455465 80 DK Saxena JA Duro A Tiwari K Deb Q Zhang Objective reduction manyobjective optimization linear nonlinear algorithms IEEE Trans Evol Comput 17 2013 7799 IEEE Trans Evol Comput 15 2011 539556 81 HK Singh A Isaacs T Ray A Pareto corner search evolutionary algorithm dimensionality reduction manyobjective optimization problems 82 A Toffolo E Benini Genetic diversity objective multiobjective evolutionary algorithms Evol Comput 11 2003 151167 83 M Wagner T Friedrich Eﬃcient parent selection approximationguided evolutionary multiobjective optimization Proceedings IEEE 84 M Wagner F Neumann A fast approximationguided evolutionary multiobjective algorithm Proceedings 15th Annual Conference Congress Evolutionary Computation CEC 2013 pp 18461853 Genetic Evolutionary Computation GECCO 2013 pp 687694 85 T Wagner N Beume B Naujoks Pareto aggregation indicatorbased methods manyobjective optimization Proceedings 4th International Conference Evolutionary MultiCriterion Optimization EMO 2007 pp 742756 86 H Wang L Jiao X Yao An improved twoarchive algorithm manyobjective optimization IEEE Trans Evol Comput 2014 press 87 R Wang RC Purshouse PJ Fleming On ﬁnding wellspread Pareto optimal solutions preferenceinspired coevolutionary algorithm Proceed ings 15th Annual Conference Genetic Evolutionary Computation GECCO 2013 pp 695702 88 R Wang RC Purshouse PJ Fleming Preferenceinspired coevolutionary algorithms manyobjective optimisation IEEE Trans Evol Comput 17 2013 474494 Comput 16 2012 117134 89 Y Wang Z Cai Combining multiobjective optimization differential evolution solve constrained optimization problems IEEE Trans Evol 90 L While L Bradstreet L Barone A fast way calculating exact hypervolumes IEEE Trans Evol Comput 16 2012 8695 91 UK Wickramasinghe X Li Using distance metric guide PSO algorithms manyobjective optimization Proceedings 11th Annual Conference Genetic Evolutionary Computation GECCO 2009 pp 667674 92 S Yang M Li X Liu J Zheng A gridbased evolutionary algorithm manyobjective optimization IEEE Trans Evol Comput 17 2013 721736 93 Y Yuan H Xu B Wang Evolutionary manyobjective optimization ensemble ﬁtness ranking Proceedings 16th Annual Conference Genetic Evolutionary Computation GECCO 2014 pp 669676 94 Q Zhang H Li MOEAD multiobjective evolutionary algorithm based decomposition IEEE Trans Evol Comput 11 2007 712731 95 Q Zhang W Liu H Li The performance new version MOEAD CEC09 unconstrained MOP test instances Proceedings IEEE Congress Evolutionary Computation CEC 2009 pp 203208 96 X Zhang Y Tian Y Jin A knee point driven evolutionary algorithm manyobjective optimization IEEE Trans Evol Comput 2014 press 97 A Zhou B Qu H Li S Zhao P Suganthan Q Zhang Multiobjective evolutionary algorithms survey state art Swarm Evol Comput 1 2011 3249 M Li et al Artiﬁcial Intelligence 228 2015 4565 65 98 E Zitzler J Knowles L Thiele Quality assessment Pareto set approximations J Branke K Deb K Miettinen R Slowinski Eds Multiobjective Optimization vol 5252 Springer Berlin Heidelberg 2008 pp 373404 99 E Zitzler S Künzli Indicatorbased selection multiobjective search Proceedings International Conference Parallel Problem Solving 100 E Zitzler L Thiele Multiobjective evolutionary algorithms comparative case study strength Pareto approach IEEE Trans Evol Comput 3 101 E Zitzler L Thiele M Laumanns CM Fonseca VG da Fonseca Performance assessment multiobjective optimizers analysis review IEEE Nature PPSN 2004 pp 832842 1999 257271 Trans Evol Comput 7 2003 117132