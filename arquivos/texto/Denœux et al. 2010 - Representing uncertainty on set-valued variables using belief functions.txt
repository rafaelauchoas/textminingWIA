Artiﬁcial Intelligence 174 2010 479499 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Representing uncertainty setvalued variables belief functions Thierry Denœux Zoulﬁcar Younes Fahed Abdallah HEUDIASYC UTC CNRS Centre Recherche Royallieu BP 20529 F60205 Compiègne France r t c l e n f o b s t r c t Article history Received 20 April 2009 Received revised form 2 February 2010 Accepted 3 February 2010 Available online 6 February 2010 Keywords DempsterShafer theory Evidence theory Conjunctive knowledge Lattice Uncertain reasoning Multilabel classiﬁcation 1 Introduction A formalism proposed representing uncertain information setvalued variables formalism belief functions A setvalued variable X domain Ω variable taking zero values Ω While deﬁning mass functions frame 22Ω usually feasible doubleexponential complexity involved propose approach based deﬁnition restricted family subsets 2Ω closed intersection lattice structure Using recent results belief functions lattices notions DempsterShafer theory transposed particular lattice making possible express rich knowledge X limited additional complexity compared singlevalued case An application multilabel classiﬁcation learning instance belong classes simultaneously demonstrated 2010 Elsevier BV All rights reserved An important concept knowledge representation variable Usually associate variable X domain frame discernment Ω assume X takes value Ω For instance conventional classiﬁcation problems X denotes class object object assumed belong class set Ω classes There cases convenient consider variable X taking zero values domain Ω In cases X called setvalued conjunctive variable 833 For instance diagnosis problems Ω denote set faults possibly occur X faults actually occurring given time In text classiﬁcation Ω denote set topics X list topics dealt given text A straightforward approach problem course consider setvalued variable X Ω single valued variable power set Θ 2Ω However approach implies working space high cardinality If paper assume Ω ﬁnite size K size Θ 2K If want express imprecise information X manipulate subsets Θ As 22K subsets approach rapidly intractable K increases In paper consider problem representing partial knowledge setvalued variable X domain Ω DempsterShafer theory belief functions 2630 Our approach based simple representation class CΩ subsets Θ 2Ω endowed set inclusion lattice structure Using recent results belief functions lattices 14 able generalize concepts DempsterShafer theory including canonical decompositions cautious rule 5 setting This formalism shown allow expression wide range knowledge setvalued variables moderate increase complexity 2K 3K compared usual singlevalued case Corresponding author Fax 33 03 44 23 44 77 Email address tdenoeuxhdsutcfr T Denœux 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201002002 480 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 The rest paper organized follows Background notions belief functions classical setting general lattices ﬁrst recalled Sections 2 3 respectively Our approach introduced Section 4 relationships previous work outlined Section 5 An application multilabel classiﬁcation presented Section 6 Section 7 conclude paper 2 Belief functions The basic concepts DempsterShafer theory belief functions introduced 26 ﬁrst summarized Section 21 The canonical decomposition cautious rule recalled Section 22 21 Basic deﬁnitions Let Ω ﬁnite set A mass function Ω function m 2Ω 0 1 cid2 m A 1 AΩ The subsets A Ω m A 0 called focal elements m The set focal elements m denoted F m m said normal focal element dogmatic Ω focal element A mass function m model agents beliefs variable X taking single illknown value ω0 Ω 30 The quantity m A interpreted measure belief committed exactly hypothesis ω0 A Full certainty corresponds case mωk 1 ωk Ω total ignorance modeled vacuous mass function verifying mΩ 1 Probabilistic uncertainty corresponds case focal elements singletons case m equivalent probability distribution Ω To mass function m associated implicability function b belief function bel deﬁned follows cid2 b A B A bel A mB cid2 mB b A m 1 2 B ABcid2 A These functions equal m normal However need distinguished considering nonnormal mass functions Function bel easier interpretation bel A corresponds degree belief proposition The true value ω0 X belongs A However function b simpler mathematical properties For instance m recovered b m A 1 AB bB 3 cid2 B A denotes cardinality Function m said Möbius transform b For function f f Ω 1 following conditions known equivalent 26 2Ω 0 1 1 The Möbius transform m f positive veriﬁes cid3 AΩ m A 1 2 f totally monotone k cid2 2 family A1 Ak 2Ω cid6 cid2 Ai cid4 f kcid5 i1 cid2 1 I1 f cid7I1k cid7 cid8 cid9 Ai iI Hence b bel totally monotone Other functions related m plausibility function deﬁned cid2 pl A mB B Acid7 1 b A commonality function coMöbius transform b deﬁned q A cid2 mB B A m recovered q following relation m A 1 B A qB cid2 B A 4 5 6 7 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 481 Functions m bel b pl q onetoone correspondence regarded different facets information A special case focal elements m nested m said consonant In case pl A B max cid10 cid11 pl A plB A B Ω The plausibility function possibility measure corresponding possibility distribution deﬁned π x plx x Ω Conversely possibility distribution corresponds unique consonant mass function 26 Let assume receive mass functions m1 m2 distinct sources information assumed reliable Then m1 m2 combined conjunctive sum unnormalized Dempsters rule combination deﬁned follows m1 cid12 m2 A cid2 m1Bm2C BC A 8 This rule commutative associative admits vacuous mass function neutral element It conjunctive product m1B m2C transferred intersection B C The quantity m1 cid12 m2 referred degree conﬂict m1 m2 Let q1 cid12 2 denote commonality function corresponding m1 cid12 m2 It computed q1 q2 common The normalized Dempsters rule 26 deﬁned conjunctive sum followed normalization step ality functions associated m1 m2 follows q1 cid12 2 A q1 A q2 A A Ω cid12 0 m1 m2 A m1 cid12 m2 A 1m1 cid12 m2 It clear m1 m2 deﬁned long m1 cid12 m2 1 A choice union operator results disjunctive sum 28 m1 cid12 m2 A It shown cid2 m1Bm2C BC A b1 cid12 2 A b1 A b2 A A Ω Alternatives conjunctive sum constructed replacing binary set operation 8 For instance 9 10 11 12 counterpart 9 Dubois Prade 10 proposed hybrid rule intermediate junctive disjunctive sums product m1Bm2C assigned B C B C cid7 B C This rule associative usually provides good summary partially conﬂicting items evidence In 30 Smets proposed twolevel model items evidence quantiﬁed mass functions combined credal level decisions pignistic level Latin pignus meaning bet Once decision mass function m transformed pignistic probability distribution p The pignistic transformation consists normalizing m assuming m 1 distributing normalized mass m A1 m equally atoms ωk A cid2 pωk AΩωk A m A 1 m A ωk Ω 13 Other authors suggested socalled plausibility transformation transforming mass function probabil ity distribution normalizing plausibilities singletons 3 In decision making context approach results selecting plausible single hypothesis 22 Canonical decompositions idempotent rules According Shafer 26 mass function said simple following form m A 1 w0 mΩ w0 A Ω w 0 0 1 Let denote mass function A w0 The vacuous mass function noted A1 A Ω It clear A w 0 cid12 A w cid15 0 A w 0 w cid15 0 482 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 A mass function called separable obtained result conjunctive sum simple mass functions It written m cid12 14 AΩ A w A w A 0 1 A Ω Smets 29 showed nondogmatic mass function m uniquely expressed 14 weights w A 0 This referred conjunctive canonical decomposition mass function Note w A 1 A w A longer mass function conjunctive sum extended generalized mass functions obvious way Function w called conjunctive weight function associated m 5 It new equivalent representation non dogmatic mass function computed directly q follows w A qB1B A1 A Ω taking logarithms ln w A 1 B A ln qB A Ω cid13 B A cid2 B A 15 16 In 29 5 w A deﬁned strict subsets A Ω However function w extended 2Ω 15 A Ω We wΩ 1 qΩ 1 mΩ cid13 AΩ w A 1 cid7 cid13 cid91 w A AΩ 17 With convention 16 extended A Ω We notice 16 exactly form 7 formula computing ln w ln q computing m q Conversely ln q computed ln w formula similar 6 cid2 ln q A ln wB A Ω B A We note function w simple property respect conjunctive sum Let w 1 w 2 weight functions let w 1 cid12 2 denote result cid12 combination Then following relation holds w 1 cid12 2 A w 1 Aw 2 A A Ω 18 In 5 Denœux introduced cautious rule noted cid12 obtained replacing product minimum 18 A Ω cid10 w 1 cid12 2 A min cid11 w 1 A w 2 A 19 The value w 1 cid12 2Ω determined satisfy normalization condition 17 This rule obviously com mutative associative idempotent As shown 5 suitable combining conjunctively nonindependent items evidence As conjunctive sum cautious rule normalized version deﬁned cid12 cid10 m1 cid12 m2 cid11 A 0 m1 cid12 m2 A 1m1 cid12 m2 A 20 As shown 5 conjunctive canonical decomposition disjunctive counterpart Any mass function m m 0 decomposed disjunctively follows m cid12 A A v A 21 A v A generalized mass function assigning mass v A 0 possibly greater 1 1 v A A A Ω A cid7 This deﬁnes new function v called disjunctive weight function computed b follows v A bB1 AB1 A Ω A cid7 22 cid13 B A T Denœux et al Artiﬁcial Intelligence 174 2010 479499 ln v A cid2 B A 1 AB ln bB A Ω A cid7 As equations extended A leads cid7 cid13 cid91 v A Acid7 v 1 b 1 m cid13 AΩ v A 1 The disjunctive rule 11 simple expression function disjunctive weights v 1 cid12 2 A v 1 Av 2 A A Ω 483 23 24 25 By replacing product minimum equation deﬁne new rule denoted cid12 called bold rule 5 v 1 cid12 2 A min cid10 cid11 v 1 A v 2 A cid14 26 Acid7 v 1 cid12 2 A1 This rule obviously commutative associative idempotent suitable com A Ω A cid7 v 1 cid12 2 bining disjunctively nonindependent items evidence 3 Extension general lattices As shown Grabisch 14 theory belief function extended Boolean lattice 2Ω lattice necessarily Boolean We ﬁrst recall basic deﬁnitions lattices Section 31 Grabischs results work summarized Section 32 31 Lattices A review lattice theory 21 The following presentation follows 14 Let L ﬁnite set cid3 partial ordering reﬂexive antisymmetric transitive relation L The structure L cid3 called poset We L cid3 lattice x y L unique greatest lower bound denoted x y unique upper bound denoted x y Operations called meet join operations respectively For ﬁnite lattices greatest element denote cid20 element denoted exist We x covers y x y z x z y An element x L atom covers element element It coatom covered single element element cid20 cid15 isomorphic exists bijective mapping f L L x cid3 y f x cid3 f y For poset L cid3 deﬁne dual L cid2 inverting order relation A lattice autodual isomorphic dual Two lattices L L A lattice distributive x y z x z y z holds x y z L For x L x cid15 cid20 L said complemented element cid15 x x complement L exists x complement Boolean lattices distributive complemented lattices Every Boolean lattice isomorphic 2Ω set Ω For lattice 2Ω cid20 Ω cid15 L x x cid15 A closure C set Θ family subsets Θ satisfying following properties 1 Θ C 2 C1 C2 C C1 C2 C As shown 21 closure C lattice following meet join operations C1 C2 C1 C2 C1 C2 cid8 C C C1 C2 C 32 Belief functions lattices 27 28 Let L cid3 ﬁnite poset having element let f function L R The Möbius transform f function m L R deﬁned unique solution equation f x m y x L 29 cid2 ycid2x 484 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 Function m expressed cid2 mx μ y x f y ycid2x μx y L2 R Möbius function deﬁned inductively μx y cid3 1 0 xcid2t y μx t x y x y The coMöbius transform f cid2 qx m y ycid3x deﬁned m recovered q cid2 mx μx yq y ycid3x 30 31 32 33 Let assume L cid3 lattice Following Grabisch 14 function b L 0 1 called implicability function L bcid20 1 Möbius transform nonnegative The corresponding belief function bel deﬁned belx bx m x L Note Grabisch 14 considered normal belief functions case b bel As shown 14 implicability function L cid3 totally monotone k cid2 2 family x1 xk L cid4 cid6 b cid2 xi kcid18 i1 cid2 1 I1b cid7I1k cid7 cid19 cid9 xi iI Note converse hold general totally monotone function nonnegative Möbius transform As shown 14 results DempsterShafer theory transposed general setting lattices For instance conjunctive sum 8 cid2 m1 cid12 m2x m1 ym2z x L 34 yzx following relation commonality functions holds q1 cid12 2x q1x q2x x L 35 The normalized Dempsters rule deﬁned classical case dividing number m1 cid12 m2x x cid7 1 m1 cid12 m2 provided m1 cid12 m2 1 Using similar line reasoning followed 14 extend disjunctive rule 11 m1 cid12 m2x m1 ym2z x L cid2 yzx 12 b1 cid12 2x b1x b2x x L cid13 wx q y μx y x L x cid7 cid20 ycid3x generalizes 15 Obviously w 1 cid12 2x w 1xw 2x x L x cid7 cid20 Grabisch 14 extended conjunctive canonical decomposition belief functions general lattice setting He showed mass function m L mcid20 0 decomposed m cid12 xcid20xwx 38 xwx simple mass function assigning 1 wx x wx cid20 wx 0 Clearly 38 general izes 14 As classical case function w L cid20 0 computed q following equation 36 37 39 40 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 The existence w function allows deﬁne cautious rule general lattice setting cid10 w 1 cid12 2x min cid11 w 1x w 2x x L x cid7 cid20 485 41 The normalized cautious rule cid12 provided w 1 cid12 2 1 deﬁned classical case dividing w 1 cid12 2x x cid7 1 w 1 cid12 2 Although Grabisch consider disjunctive canonical decomposition extended general lattice setting The proof parallels given 14 conjunctive case We state main result Let xvx mass function L assigning 1 vx x vx vx 0 Any mass function m L m 0 decomposed m cid12 xxvx The function v L 0 computed b following equation cid13 vx b y μ yx x L x cid7 ycid2x generalizes 22 We v 1 cid12 2x v 1xv 2x x L x cid7 existence v function allows deﬁne bold rule cid11 v 1x v 2x cid10 v 1 cid12 2x min x L x cid7 42 43 44 45 The extension notions classical DempsterShafer theory require additional assumptions L cid3 For instance deﬁnition plausibility function pl dual b 5 extended autodual lattices 14 The deﬁnition pl 4 remains possible cases relationship pl b bel lost Also probability measures deﬁned arbitrary lattices Consequently pignistic probability 13 extended restricted settings Remark 1 Although approach relies essentially Grabischs work note existence line research aims extending results Probability Theory classes residuated lattices general Boolean algebra In particular developments probability measures MValgebra called states 2161722 Gödel algebras 1 In course revising paper aware recent work deﬁning belief functions MValgebras 181 4 Belief functions setvalued variables In section main concepts DempsterShafer theory recalled Section 2 extended case want uncertainty setvalued variable X ﬁnite domain Ω The key extension deﬁnition closure CΩ Θ 2Ω set subsets Θ closed intersection Each element CΩ shown simple description pair disjoint subsets Ω Belief functions associated notions deﬁned lattice CΩ resulting simple framework uncertain reasoning setvalued variables 41 The lattice CΩ In rest paper X denotes setvalued variable ﬁnite domain Ω variable taking values Θ 2Ω Let A0 Ω denote unknown true value X We want partial knowledge value belief function framework As explained introduction formalism recalled Section 2 applied modiﬁcation case deﬁning mass function mΘ Θ However brute force approach require storage Θ 22 numbers mass function Basic operations conjunctive disjunctive sums 2 doubleexponential complexity making approach inapplicable sets Ω small cardinality Ω As alternative propose deﬁne mass functions associated functions subset 2Θ forms lattice equipped inclusion relation The intuitive idea underlying approach fact expressing knowledge setvalued variable X convenient specify sets values certainly taken X sets values certainly taken X This illustrated following example 1 We indebted anonymous referees bringing work attention 486 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 Fig 1 Two subsets Ω broken lines containing A intersecting B The set subsets denoted ϕ A B Example 1 Let X denote languages spoken John deﬁned large set Ω existing languages If know sure John speak English French brought US stayed France long time speak Japanese Chinese traveled Asia subsets Ω containing A English French intersecting B Japanese Chinese possible values X As shown example families subsets Ω equivalently subsets Θ 2Ω conveniently described subsets A B Ω A B Fig 1 More generally let QΩ A B 2Ω 2Ω A B Ω set ordered pairs disjoint subsets Ω Ω denotes set Ω For A B QΩ let ϕ A B denote following subset Θ 2Ω ϕ A B C Ω C A C B Ω 46 ϕ A B subset Θ composed subsets Ω including A intersecting B Equivalently set subsets Ω include A included B ϕ A B C Ω A C B 47 It interval A B lattice Ω Let CΩ denote set subsets Θ form ϕ A B completed set Θ noted Θ Θ ϕ A B A Ω B Ω A B Ω CΩ cid20 cid21 CΩ subset 2Θ For reason evident later use ϕΩ Ω alternative notation Θ Function ϕ bijective mapping QΩ QΩ Ω Ω CΩ The following proposition states CΩ closure consequently lattice structure Proposition 1 CΩ closure Θ cid15 B B cid22 cid11 cid10 ϕ A B ϕ cid15 A cid15 B ϕ A A Θ cid15 QΩ A B A cid15 B cid15 cid15 B B A A cid15 Ω Proof It obvious Θ ϕΩ Ω CΩ Now cid11 cid20 cid10 ϕ A B ϕ cid15 A B cid15 cid20 C Ω C A C A cid11 cid15 C Ω C cid10 cid15 cid10 cid15 Ω C B Ω C B cid21 cid15 Ω C cid15 equal ϕ A A B B cid11 A A cid15 B cid15 Ω ϕ A B ϕ A cid21 If A A include A A cid15 B B cid15 intersection B B consequently ϕ A B ϕ A cid15 cid15 B cid15 Θ cid2 cid15 B B cid15 Otherwise subset C Ω As recalled Section 31 closure endowed inclusion relation lattice structure deﬁned 28 Here inclusion relation following simple expression ϕ A B representation ϕ A B ϕ cid15 A B cid15 cid10 cid11 A A cid15 B B cid15 48 The element ϕΩ Ω Θ We note 48 remains valid A B Ω explains notation ϕΩ Ω Θ The greatest element cid20 ϕΩ Ω Θ The atoms form ϕ A A A Ω coatoms form ϕx Ω ϕΩ x x Ω We number atoms equal number coatoms shows C autodual This lattice complemented consequently Boolean T Denœux et al Artiﬁcial Intelligence 174 2010 479499 487 As consequence 48 easy meet operation following operation denoted cid24 cid10 cid11 cid10 ϕ A B cid24 ϕ cid15 A B cid15 ϕ A A cid15 B B cid15 cid11 It noted cid24 identical set union The following proposition states relation operators Proposition 2 For A B A cid10 ϕ A B ϕ cid15 A B cid15 cid11 cid15 B ϕ A B cid24 ϕ cid15 QΩ cid11 cid10 cid15 cid15 B A Proof For C ϕ A B ϕ A C A C A cid15 B cid15 C A A cid15 cid15 C B Ω C B cid15 cid2 cid15 B B C ϕ A A cid15 Ω C cid10 B B cid11 cid15 Ω 49 50 One notice implications 49 50 strict Consequently ϕ A B ϕ A cid15 usually strict cid15 As lattices CΩ 2Θ join operator CΩ cid15 B cid15 B subset ϕ A B cid24 ϕ A sublattice 2Θ subposet As noticed 15 ordered pair A B disjoint subsets Ω ω1 ωK represented vector u1 u K 1 0 1K ui ωi A 1 1 ωi B 0 Consequently ϕ A B CΩ A B cid7 Ω Ω represented way For ϕΩ Ω Θ special representation adopted This encoding makes possible implement cid24 operations simple way generalized truth tables It makes clear cardinality CΩ equal 3K 1 42 Belief functions CΩ The general theory recalled Section 32 applied directly lattice CΩ Let m CΩ 0 1 mass function CΩ The notation mϕ A B simpliﬁed m A B For reason m called twoplace mass function We assume cid2 ABQΩ m A B 1 The implicability belief commonality functions computed m following formula cid2 cid2 b A B mC D ϕCDϕ AB bel A B b A B mΩ Ω cid2 q A B mC D C ADB cid2 ϕCDϕ AB C ADB mC D mC D 51 52 53 pairs A B C D understood belong QΩ convention adopted paper The conjunctive sum operation CΩ deﬁned follows cid2 m1 cid12 m2 A B m1C Dm2E F ϕCDϕEF ϕ AB cid12 cid3 cid3 CE ADF B m1C Dm2E F CEDF cid7Ω m1C Dm2E F It computed commonality functions q1 cid12 2 A B q1 A B q2 A B A B Q Ω Similarly disjunctive sum computed A B Ω A B Ω 54 55 56 488 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 m1 cid12 m2 A B cid2 m1C Dm2E F ϕCDcid24ϕEF ϕ AB cid2 m1C Dm2E F CE ADF B implicability functions b1 cid12 2 A B b1 A B b2 A B A B Q Ω 57 58 It possible deﬁne rule expressing consensus items evidence spirit DuboisPrade rule recalled Section 21 Assume learn sources value X ϕC D ϕE F ϕC D ϕE F Θ C E D F cid7 Ω pieces information conﬂict It safe C E D F positive information D F C E negative information Denoting cid25 following operation CΩ ϕC D cid25 ϕE F ϕ cid10 cid11 C E D F D F C E deﬁne new combination rule cid2 m1 cid4 m2 A B ϕCDcid25ϕEF ϕ AB m1C Dm2E F 59 This rule referred consensus rule We note operations cid25 cid4 associative However quasiassociative possible deﬁne nary version cid25 ϕC1 D1 cid25 cid25 ϕCn Dn ϕ cid4 ncid5 cid23 ncid5 cid23 ncid5 cid23 ncid5 Ci D D Ci i1 i1 i1 i1 cid6 To compute functions m w v q b 30 33 39 43 need expression Möbius function μ It given following proposition Proposition 3 The Möbius function CΩ given A B A cid15 1 A A 0 ϕ A B ϕ A ϕ A B ϕ cid15BB cid10 μ cid15 B B cid11cid11 cid22 A cid10 cid15 cid15 cid15 cid15 B cid15 QΩ Proof The proof similar Theorem 2 15 simple adaptations similarity twoplace belief functions CΩ bicapacities Remark 2 cid2 This result allows compute m b m A B q m A B 1 C ADB bC D 1 ACBD qC D cid2 C ADB cid2 C ADB cid13 The conjunctive disjunctive weight functions computed respectively w A B qC D1 ACBD1 A B cid7 Ω Ω C ADB v A B cid13 C ADB bC D1C ADB1 A B cid7 Ω Ω makes possible use cautious bold rules context 60 61 62 63 Example 2 Let X denote set languages spoken Bernard Assume 100 sure Bernard speaks language Dutch d English e French f restrict domain X Ω d e f Suppose following items evidence T Denœux et al Artiﬁcial Intelligence 174 2010 479499 489 Table 1 Computation conjunctive sum m1 m2 Example 2 The columns lines correspond focal elements m1 m2 respectively Each cell contains intersection focal element m1 focal element m2 The mass focal element indicated e 07 f 015 015 d f 027 d e f 07 027 Θ 015 027 d f 015 027 f d 029 e f d 07 029 f d 015 029 f d 015 029 f d 034 e f d 07 034 f d 015 034 f d 015 034 01 e 07 01 f 015 01 015 01 1 Bernard Belgian Approximately 60 Belgians Dutchspeaking 40 Belgians Frenchspeaking neglect small Germanspeaking community simplicity According recent survey approximately 20 Frenchspeaking Belgians declare good knowledge Dutch 50 members Dutch speaking community claim good knowledge French 2 Bernard studied years Canada universities Englishspeaking French speaking Based available evidence 07 degree belief Bernard studied Englishspeaking university 015 degree belief studied Frenchspeaking Each items evidence represented mass function CΩ According ﬁrst item evidence approximately 06 05 100 30 Belgians speak Dutch French approximately 04 08 100 32 speak French Dutch rest speak languages Knowing Bernard belongs population assuming ﬁgures accurate lead following mass function 032 f d 038 d f f d 03 cid11 cid11 cid11 cid10 cid10 cid10 m1 m1 m1 To account inaccuracy ﬁgures discount mass function 26 transferring fraction mass 10 greatest element CΩ ϕ We cid10 cid10 m1 m1 cid11 d f f d 03 09 027 cid11 038 09 034 cid10 m1 cid11 f d 032 09 029 m1 01 The second item evidence represented mass function m2 deﬁned cid10 cid11 cid10 cid11 m2 e 07 m2 015 Assuming items evidence distinct combined conjunctive sum operation cid12 This achieved ways 015 f m2 1 We compute intersection focal element m1 focal element m2 apply mula 54 The computations presented Table 1 2 Alternatively compute commonality functions q1 q2 53 multiply convert result mass function 61 The intermediate ﬁnal results shown Table 2 We check approaches yield result In particular set Θ receives mass equal 015 027 00405 interpreted degree conﬂict m1 m2 Using consensus rule cid4 59 mass 015 027 transferred cid11 cid11 cid10 cid11 ϕ f cid25 ϕ cid10 d f cid10 d ϕ resulting normal conﬂictfree mass function Table 2 shows normal mass function computed normalized Dempsters rule Table 3 displays intermediate steps ﬁnal results computing combinations m1 m2 unnormalized normalized cautious rules Remark 2 We remark concept twoplace mass belief functions deﬁned bears similarity bicapacities introduced Grabisch Labreuche 15 A bicapacity deﬁned 15 increasing function deﬁned lattice QΩ cid27 cid27 partial ordering QΩ deﬁned A B cid27 C D A B C D In 15 Grabisch Labreuche introduce concepts related bicapacities application cooperative game theory In 19 introduce concept bibelief function deﬁned totally monotone bicapacity QΩ 0 1 They suggest interpretation terms bipolar representation uncertainty case singlevalued variable Bibelief functions twoplace belief functions introduced distinct classes belief functions built different lattices different interpretations 490 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 Table 2 Computation m1 cid12 m2 m1 m2 Example 2 A f f f e e e f f f e e e f d d df d d df f B f f df d d df d d e f e e f f e f e e f f m1 0 0 0 0 0 0 029 0 0 0 0 0 0 0 01 0 0 0 0 0 0 0 027 0 034 0 0 0 q1 1 01 01 039 01 01 039 01 01 039 01 01 01 01 01 01 01 01 01 037 01 044 037 01 044 037 01 044 Table 3 Computation m1 cid12 m2 m1 cid12 m2 Example 2 A f f f e e e f f f e e e f d d df d d df f B f f df d d df d d e f e e f f e f e e f f m1 0 0 0 0 0 0 029 0 0 0 0 0 0 0 01 0 0 0 0 0 0 0 027 0 034 0 0 0 w 1 6349 1 1 1 1 1 0256 1 1 1 1 1 1 1 10 1 1 1 1 1 1 1 0270 1 0227 1 1 1 m2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 015 015 0 07 0 0 0 0 0 0 0 0 0 0 m2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 015 015 0 07 0 0 0 0 0 0 0 0 0 0 q2 1 015 015 03 015 015 03 085 085 1 015 015 03 015 015 03 085 085 1 015 015 03 015 015 03 085 085 1 w 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 667 05 1 0176 17 1 1 1 1 1 1 1 1 1 q1 cid12 2 1 0015 0015 0117 0015 0015 0117 0085 0085 039 0015 0015 003 0015 0015 003 0085 0085 01 00555 0015 0132 00555 0015 0132 03145 0085 044 w 12 1 1 1 1 1 1 0256 1 1 1 1 1 1 1 7196 05 1 0176 1 1 1 1 0270 1 0227 1 1 1 m1 cid12 m2 00405 0 0 0 0 0 0087 0 0 0203 0 0 0 0 0015 0015 0 007 0 0 0 0 00405 0 0102 0189 0 0238 m1 cid12 m2 0864 0 0 0 0 0 000806 0 0 00376 0 0 0 0 000139 000139 0 000649 000649 0 0 0 000375 0 000945 00175 0 00441 m1 m2 0 0 0 0 0 0 0091 0 0 0212 0 0 0 0 0016 0016 0 007 0 0 0 0 00422 0 0106 0197 0 0248 m2 m1 cid12 0 0 0 0 0 0 00591 0 0 0276 0 0 0 0 00102 00102 0 00477 00477 0 0 0 00275 0 00694 0129 0 0324 Remark 3 Another remark concerns decision making As noted previous section lattice CΩ Boolean notion pignistic probability deﬁned lattice In classical setting common alternative rule maximum pignistic probability decision making maximum plausibility consists selecting element Ω greatest plausibility equivalent greatest commonality functions coincide singletons In CΩ propose reasonable decision rule select atom ϕ A A highest T Denœux et al Artiﬁcial Intelligence 174 2010 479499 491 Table 4 Commonalities atoms according m1 m2 m1 cid4 m2 m1 cid12 m2 Example 2 A A f f e df e f d d e f df e f f q12 A A 00156 0122 00889 0406 00578 0138 0328 0459 q1cid22 A A 0015 0117 0085 039 0096 0173 0355 0481 q1 2 A A 00102 00796 00578 0451 00377 00898 0214 0509 commonality Table 4 shows commonalities atoms computing m1 m2 m1 cid4m2 m1 cid12 m2 Example 2 In particular case rules lead conclusion Bernard speaks languages The second likely hypothesis Bernard speaks English French Dutch However clear different combination rules general result different decisions The following section devoted review previous work uncertainty representation setvalued variables 5 Relation previous work This section discusses relation notions introduced related concepts formalisms proposed handling setvalued variables 51 Disjunctive vs conjunctive bodies evidence Yager 3233 ﬁrst authors emphasize fundamental difference singlevalued setvalues variables develop speciﬁc formalisms reasoning In 33 distinction disjunctive conjunctive information setbased representations Given variable X taking single value Ω statement X A A Ω means X takes value A know In contrast X multiple valued statement understood mean X takes values A possibly values outside A The corresponding piece information called disjunctive case conjunctive Yager proceeds observing kind duality disjunctive conjunctive knowledge For instance statement P 1 X A implies P 2 X B B A disjunctive case P 2 deduced P 1 B A conjunctive case If know P 1 P 2 hold deduce X A B disjunctive case X A B conjunctive case Viewing mass functions generalized sets Dubois Prade 8 remarked distinction holds belief function framework They pointed mass function m represents body evidence pertaining set valued variable referred conjunctive body evidence commonality function q appropriate b representing degrees belief disjunctive sum 11 combining information conjunctively The formalism developed Section 4 sheds new light duality conjunctive disjunctive knowledge The conjunctive statement X A corresponds proposition ϕ A Let m mass function CΩ focal cid15 A m A A Using 51 elements form ϕB B Ω We note m A Ω b A cid2 B A mB cid2 B A cid15 m B q cid15 A q cid15 commonality function corresponding m cid2 cid2 q A mB cid15 B b cid15 A B A m B A cid15 Conversely As consequence let m1 m2 mass functions CΩ focal elements form described assume want combine conjunctively 56 We q1 cid12 2 A q1 A q2 A b cid15 1 Ab cid15 2 A b cid15 1 cid12 2 A A Ω explains disjunctive sum combining conjunctive bodies evidence conjunctive manner 492 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 52 Random sets Random sets deﬁned random elements taking values subsets space 2023 In ﬁnite case random AΩ m A 1 mathematically equivalent set deﬁned probability function m 2Ω DempsterShafer mass function Ω 24 However noted Smets 27 semantics random sets standard belief functions different random sets model random experiments setvalued outcomes standard belief functions quantify beliefs variable taking single unknown value cid3 In contrast random sets recovered special class belief functions setvalued variables introduced paper Let m mass function CΩ assume focal elements m atoms CΩ cid15 A m A A A Ω random set 2Ω 0 1 m form A A In case function m Random sets equivalent mass functions CΩ atomic focal elements probability distributions Ω equivalent mass functions 2Ω singleton focal elements cid15 53 Veristic variables In 3435 Yager develops theory veristic variables deﬁned fuzzy setvalued variables Let X denote fuzzy setvalued variable domain Ω variable taking single value set I Ω fuzzy subsets Ω For x Ω A I Ω denote Ax degree membership x A Let A0 I Ω denote unknown true value X Yager considers ways associating variable X fuzzy set A I Ω following statements 1 X isv A meaning A A0 denotes standard fuzzy set inclusion Ax cid3 A0x x Ω 2 X isvn A meaning A0 A A denotes complement A membership function Ax 1 Ax x Ω 3 X isvc A meaning A0 A 4 X isvc n A meaning A0 A In expressions copula isv parameters c closed exclusive n negative We observe statement X isvc n A equivalent X isvc A Consequently need consider ﬁrst cases As remarked Yager basic types statements interpreted specifying set W fuzzy subsets Ω crisp subset I Ω W contains possible values variable X It deﬁned follows types statements cid20 W X isv A X isvn A W X isvc A W A cid20 F I Ω F x cid2 Ax x Ω F I Ω F x cid3 Ax x Ω cid21 cid21 Yager associated W functions Ω 0 1 called verity rebuff distributions deﬁned follows F x Verx min F W Rebuffx 1 max F W F x min F W 1 F x min F W F x Verx minimal degree membership x possible value X interpreted minimal support x values taken X In contrast Rebuffx interpreted minimal support x values taken X These distributions following expressions basic types statements Verx Ax Rebuffx 0 X isv A X isvn A Verx 0 X isvc A Verx Ax Rebuffx 1 Ax Rebuffx Ax Clearly major difference Yagers approach fact Yager represents piece knowledge X set fuzzy subsets Ω use set crisp subsets Ω However kinds statements considered Yager associated verity rebuff distributions close representations approach To begin let provisionally assume A crisp subset Ω Then types statements expressed categorical mass functions CΩ follows m A 1 X isv A X isvn A m A 1 X isvc A m A A 1 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 It easy cases cid11 cid11 cid10 x cid10 x b b Verx Rebuffx 493 64 65 x Ω The verity x belief x values taken X rebuff x belief x value taken X This interpretation shown remain true A fuzzy subset Ω In case function x Ax seen possibility distribution known equivalent consonant mass function m cid10 Ω focal elements A1 An The corresponding plausibility function pl cid11 veriﬁes cid2 cid15 cid15 cid15 pl x cid15 m Ai cid28x Ai Ax x Ω For instance let consider statement X isv A let translate following twoplace mass function m Ai m cid15 Ai 1 n We cid10 x b cid11 cid2 Ai cid28x m Ai cid2 Ai cid28x cid11 cid10 x b 0 Rebuffx cid15 m Ai Ax Verx By handling cases similarly veriﬁed Eqs 64 65 hold cases We conclude based slightly different interpretation Yagers framework easily trans lated formalism twoplace belief functions general However true static level long combine different pieces information For instance shown Yager conjunctive com bination statements X isv A X isv B veristic framework results new statement X isv A B denotes fuzzy set union This consistent approach long A B crisp sets If A B fuzzy translating statements twoplace mass functions combining conjunctive sum cautious rule general yield consonant mass function corresponding veristic constraint X The formalisms differ combining statements involving fuzzy subsets 54 Twofold fuzzy sets To complete review previous work uncertainty representation setvalued variables need mention representation incomplete conjunctive information pair fuzzy sets introduced 9 In work Dubois Prade proposed represent partial knowledge setvalued variable possibility distribution π 2Ω This equivalent deﬁning fuzzy set crisp subsets Ω contrasts Yagers approach deﬁnes crisp set W fuzzy subsets Ω To representation easily tractable Dubois Prade follows Let Ai I family subsets Ω A proposed approximate π pair fuzzy sets A π Ai 0 Let x 1 sup x Ai π Ai A A x sup x Ai π Ai x The degree membership x A referred twofold fuzzy set constitutes corresponds possibility ﬁnding Ai containing x The pair A approximation π sense simpler incomplete representation possibility distributions π correspond twofold fuzzy set However Dubois Prade showed speciﬁc possibility distribution π extent impossible ﬁnd Ai containing x A expressed π 1 sup A π Ω inf A A A induced twofold fuzzy set A cid24 B min π cid10 cid11cid25 1 A B 2Ω Ω A x inf xB To twofold fuzzy set A x inf x B associated fuzzy subset A 2Ω membership function equal π We note approach similarity based representation subset 2Ω crisp corresponding crisp subset A 2Ω exactly equal A However general case twofold fuzzy set representation based pair possibility distributions pair subsets Ω Actually A ϕ A consonant belief functions Ω approach based single twoplace belief function CΩ A A 494 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 B A A B What seen limitation twofold fuzzy set approach arises combining information B representing knowledge setvalued variables X Y Dubois sources Given pairs A knowledge X Y B A Prade showed knowledge X Y represented A Applications kind reasoning database query evaluation discussed 9 represented A However different maybe common problem uncertain reasoning situation items evidence single setvalued variable X want combine items evidence If A correspond respectively fuzzy subsets A B 2Ω result combination ideally correspond B A B A B depending choice conjunctive disjunctive combination mechanism However fuzzy subsets 2Ω generally admits twofold fuzzy set representation restricts use formalism reasoning setvalued variables B B A B We shown formalism twoplace belief functions introduced paper compare favorably terms expressive power existing formalisms representing reasoning uncertain conjunctive information In section demonstrate usefulness formalism certain category classiﬁcation problems 6 Application multilabel classiﬁcation In section present application framework developed paper multilabel classiﬁcation2 In kind problems object belong simultaneously classes contrary standard singlelabel problems objects belong class 13381236 Multilabel classiﬁcation tasks arise realworld problems For instance image retrieval image belong semantic classes beach urban In text categoriza tion document belong topics In problems learning task consists predicting value class variable new instance based training set As class variable setvalued framework developed paper In order construct multilabel classiﬁer generally assume existence labeled training set composed n examples xi Y xi feature vector describing instance Y label set instance deﬁned subset set Ω classes In practice gathering high quality information feasible reasonable cost In problems ground truth assigning unambiguously label set instance opinions experts elicited Typically expert express lack conﬁdence assigning exactly label set If experts consulted conﬂict inevitably arise introduce uncertainty labeling process The formalism developed paper easily handle situations In general setting opinions experts set classes pertain particular instance modeled mass function mi CΩ A general arguably workable option restrict mi categorical single focal element ϕ Ai B Ai B Ω Ai B The set Ai set classes certainly apply example B set classes certainly apply In multiple expert setting Ai represent set classes indicated experts relevant instance B set classes mentioned experts The usual situation precise labeling recovered special case B Ai For instance assume instances songs classes emotions generated songs emotion dataset Section 63 Upon hearing song expert decide song certainly evokes happiness certainly evoke sadness undecided emotions quietness anger surprise In case song assigned single label set associate set label sets containing happiness containing sadness form suggested In 439 introduced singlelabel knearest neighbor NN classiﬁer based DempsterShafer theory This method brieﬂy recalled Section 61 extended multilabel classiﬁcation tasks Section 62 An experimental comparison multilabel k nearest neighbor MLkNN method introduced 38 realworld data presented Section 63 61 Singlelabel evidential kNN classiﬁcation The evidential kNN method introduced 4 singlelabel classiﬁcation problems summarized follows Let L x1 A1 xn An learning set n instances xi pdimensional attribute vector describing instance Ai Ω ω1 ωK set possible classes instance We emphasize fact context considered instance actually belongs class class known lie Ai Let x denote feature vector new object unknown class y We want guess value y based evidence provided learning set L For purpose consider set Φkx k nearest neighbors x according distance measure d usually Euclidean Each learning instance xi Ai xi Φkx 2 A preliminary version application described section presented 37 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 495 regarded piece evidence unknown value y represented following simple mass function Ω mi Ai α exp miΩ 1 α exp cid10 cid11 γ dx xi cid10 cid11 γ dx xi 66 67 0 α 1 γ 0 Parameter α usually ﬁxed value close 1 α 095 γ depend scaling distances ﬁxed heuristically optimized 39 The evidence k NNs pooled conjunctive sum m cid12 xi Φxmi 68 class highest plausibility pignistic probability selected As remarked 7 6 method easily extended case learning instance L labeled general mass function Ω 62 Multilabel evidential kNN classiﬁcation Let come multilabel classiﬁcation problem objects belong simultaneously classes Let L x1 A1 B1 xn An Bn learning set Ai Ω ω1 ωK denotes set classes surely apply instance B Ω set classes surely apply instance If Y Ω denotes true label set instance know Y ϕ Ai B As let Φkx denote set k nearest neighbors new instance described feature vector x xi element set label Ai B This item evidence described following simple twovalued mass function mi Ai B α exp mi 1 α exp cid10 cid11 γ dx xi cid10 cid11 γ dx xi 69 70 0 α 1 γ 0 These k mass functions combined conjunctive sum 68 singlelabel case For decision making different procedures The following simple computationally eﬃcient rule implemented Let cid26Y predicted label set instance x To decide include class ω Ω compute degree belief belω true label set Y contains ω degree belief bel ω contain ω We deﬁne cid26Y cid26Y cid20 ω Ω bel cid10 ω cid11 cid10 cid2 bel ω cid11cid21 63 Experiments To study procedure experimentally real datasets3 The emotion dataset presented 31 consist 593 songs annotated experts according emotions gen erate The emotions amazedsurprise happypleased relaxingcalm quietstill sadlonely angryfearful Each emotion corresponds class There 6 classes song labeled belonging classes The average size label set song 187 067 Each song described 8 rhythmic fea tures 64 timbre features resulting total 72 features The data split training set 391 examples test set 202 examples The yeast dataset contains data gene functional classes yeast Saccharomyces cerevisiae 1125 It describes 2417 genes represented 103 features There 14 possible classes average size label set gene 424 157 The data split learning set 1500 examples test set 917 examples The scene dataset consists 2407 natural scene images label set manually assigned image There 6 classes 294 attributes The average cardinality 1074 026 735 observations labeled class The data split training set 1211 examples test set 1196 examples Each datasets constructed way instance assigned single set labels Y As explained choice questioned emotion scene datasets ground truth data labeled subjectively pool experts To assess performances approach learning data imprecise labels postulated Section 62 randomly simulated imperfect labeling process proceeding follows 3 These datasets downloaded httpmlkdcsdauthgrmultilabelhtml 496 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 Fig 2 Mean accuracy plus minus standard deviation 5 trials function k emotions dataset following methods EMLkNN imprecise labels Ai B EMLkNN noisy labels MLkNN noisy labels Let yi yi1 yi K vector 1 1K yik 1 ωk Y yik 1 For instance class ωk generated probability error pik 0 05 drawing random number beta distribution parameters b 05 bimodal distribution modes 0 1 dividing We cid15 changed yik yik probability pik resulting noisy label vector y The imprecise label vector ﬁnally deﬁned y cid15cid15 y cid22 cid15 ik y 0 cid15cid15 K cid15cid15 i1 y pik 02 cid15cid15 ik y cid15cid15 ik cid15cid15 ik As remarked Section 41 vector 1 0 1K encodes ordered pair Ai B disjoint subsets Ω Ai ωk Ω y 1 B ωk Ω y 1 The intuition model described follows Each number pik represents probability membership instance class ωk wrongly assessed expert This number turned degree conﬁdence ci transformation cik 1 2pik We assume numbers provided expert allows label instance pair sets Ai B The set Ai contains classes ωk deﬁnitely assigned instance high degree conﬁdence cik cid2 06 B set classes deﬁnitely assigned instance The remaining set Ω Ai B contains classes expert undecided cik 06 cid15 imprecise labels Ai B The features normalized zero mean unit variance Parameters α γ ﬁxed 095 05 respectively datasets We note γ easily determined automatically crossvalidation However results sensitive value γ parameter ﬁxed manually Our method referred EMLkNN applied datasets noisy labels y As reference method MLkNN method introduced 38 shown 38 good formances compared existing multilabel classiﬁcation algorithms It closest method methods based nearest neighbors The MLkNN algorithm applied noisy labels clear imprecise labels handled method For evaluation accuracy performance measure deﬁned Accuracy 1 n ncid2 i1 Y cid26Y Y cid26Y n number test examples Y true label set examples cid26Y predicted label set example This measure takes values 0 1 higher values corresponding better performance Figs 2 4 mean accuracy plus minus standard deviation ﬁve generations noisy imprecise labels datasets following methods EMLkNN imprecise labels Ai B EMLkNN noisy labels MLkNN noisy labels The results consistent datasets EMLkNN method noisy labels outperforms MLkNN trained data EMLkNN algorithm imprecise labels clearly yields best performances problems T Denœux et al Artiﬁcial Intelligence 174 2010 479499 497 Fig 3 Mean accuracy plus minus standard deviation 5 trials function k yeast dataset following methods EMLkNN imprecise labels Ai B EMLkNN noisy labels MLkNN noisy labels Fig 4 Mean accuracy plus minus standard deviation 5 trials function k scene dataset following methods EMLkNN imprecise labels Ai B EMLkNN noisy labels MLkNN noisy labels These preliminary results demonstrate ability approach handle imprecise labels multilabel classiﬁcation tasks More generally illustrate practical situation mass functions lattice CΩ natural model expert knowledge successfully exploited uncertain reasoning setvalued variables It noted encouraging results ﬁrst step comprehensive assessment approach multilabel classiﬁcation tasks A complete study require extensive comparisons wider range algorithms datasets sophisticated schemes tuning hyperparameters Such study goes scope present paper left future work 7 Conclusion We presented formalism quantifying uncertainty setvalued variable X deﬁned domain Ω belief function framework This approach relies deﬁnition family CΩ subsets 2Ω closed intersection lattice structure Each element C family indexed subsets A B deﬁned 498 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 set subsets Ω containing A intersecting B The number elements including set 2Ω equal 3K 1 K size Ω smaller size 22Ω rich express evidence X realistic situations Using recent results belief functions general lattices reported 14 shown notions DempsterShafer theory deﬁned CΩ moderate increase complexity compared single valued case contrasts doubleexponential complexity encountered working 22Ω This formalism shown general previous attempts apply DempsterShafer framework problem It shown somewhat similar arguably general ﬂexible approaches introduced possibilistic framework Finally formalism applied multilabel classiﬁcation imprecise labels extension singlelabel evidential k nearest neighbor rule Preliminary experimental results real data simulated uncertain labeling suggest proposed approach allows development powerful classiﬁcation procedures applied solve complex realworld problems Further investigations belief function approach multilabel classiﬁcation including extensive comparison methods currently way reported future publications References 1 S Aguzzoli B Gerla V Marra De Finettis noDutchbook criterion Gödel logic Studia Logica 90 1 2008 2 RLO Cignoli IML DOttaviano D Mundici Algebraic Foundations ManyValued Reasoning Trends Logic Studia Logica Library vol 7 Kluwer Academic Publishers Dordrecht 2000 3 BR Cobb PP Shenoy On plausibility transformation method translating belief function models probability models International Journal Approximate Reasoning 41 3 2006 314330 4 T Denœux A knearest neighbor classiﬁcation rule based DempsterShafer theory IEEE Transactions Systems Man Cybernetics 25 05 1995 804813 5 T Denœux Conjunctive disjunctive combination belief functions induced nondistinct bodies evidence Artiﬁcial Intelligence 172 2008 234264 6 T Denœux P Smets Classiﬁcation belief functions relationship casebased modelbased approaches IEEE Transactions Systems Man Cybernetics B 36 6 2006 13951406 7 T Denœux LM Zouhal Handling possibilistic labels pattern classiﬁcation evidential reasoning Fuzzy Sets Systems 122 3 2001 4762 8 D Dubois H Prade A settheoretic view belief functions logical operations approximations fuzzy sets International Journal General Systems 12 3 1986 193226 9 D Dubois H Prade On incomplete conjunctive information Computers Mathematics Applications 15 10 1988 797810 10 D Dubois H Prade Representation combination uncertainty belief functions possibility measures Computational Intelligence 4 1988 244264 11 A Elisseeff J Weston A kernel method multilabelled classiﬁcation TG Dietterich S Becker Z Ghahramani Eds Advances Neural Infor mation Processing Systems vol 14 MIT Press 2002 pp 681687 12 J Fürnkranz E Hüllermeier EL Mencia K Brinker Multilabel classiﬁcation calibrated label ranking Machine Learning 73 2 2008 133153 13 S Godbole S Sarawagi Discriminative methods multilabeled classiﬁcation Proceedings 8th PaciﬁcAsia Conference Knowledge Discovery Data Mining PAKDD 2004 Sidney Australia 2004 pp 2230 14 M Grabisch Belief functions lattices International Journal Intelligent Systems 24 2009 7695 15 M Grabisch C Labreuche Bicapacities I deﬁnition Möbius transform interaction Fuzzy Sets Systems 151 2005 211236 16 T Kroupa Conditional probability MValgebras Fuzzy Sets Systems 149 2 2005 369381 17 T Kroupa Representation extension states MValgebras Archive Mathematical Logic 45 4 2006 381392 18 T Kroupa Belief functions formulas Lukasiewicz logic T Kroupa J Vejnarová Eds 8th Workshop Uncertainty Processing WUPES 09 Liblice Czech Republic 2009 19 C Labreuche M Grabisch Modeling positive negative pieces evidence uncertainty TD Nielsen NL Zhang Eds Symbolic Quanti tative Approaches Reasoning Uncertainty Proceedings ECSQARU 03 Aalborg Denmark Springer 2003 pp 279290 20 G Matheron Random Sets Integral Geometry Wiley New York 1975 21 B Monjardet The presence lattice theory discrete problems mathematical social sciences Why Mathematical Social Sciences 46 2 2003 103144 22 D Mundici Averaging truthvalue Lukasiewicz logic Studia Logica 55 1 1995 113127 23 H Nguyen An Introduction Random Sets Chapman HallCRC Press Boca Raton Florida 2006 24 HT Nguyen On random sets belief functions Journal Mathematical Analysis Applications 65 1978 531542 25 P Pavlidis J Weston J Cai WN Grundy Combining microarray expression data phylogenetic proﬁles learn functional categories support vector machines Proceedings Fifth Annual International Conference Computational Biology 2001 pp 242248 26 G Shafer A Mathematical Theory Evidence Princeton University Press Princeton NJ 1976 27 P Smets The Transferable Belief Model random sets International Journal Intelligent Systems 7 1992 3746 28 P Smets Belief functions disjunctive rule combination generalized Bayesian theorem International Journal Approximate Reasoning 9 1993 135 29 P Smets The canonical decomposition weighted belief Int Joint Conf Artiﬁcial Intelligence Morgan Kaufman San Mateo CA 1995 pp 18961901 30 P Smets R Kennes The transferable belief model Artiﬁcial Intelligence 66 1994 191243 31 K Trohidis G Tsoumakas G Kalliris I Vlahavas Multilabel classiﬁcation music emotions Proc 9th International Conference Music Information Retrieval ISMIR 2008 Philadephia PA USA 2008 32 RR Yager On different classes linguistic variables deﬁned fuzzy subsets Kybernetes 13 1984 103110 33 RR Yager Setbased representations conjunctive disjunctive knowledge Information Sciences 41 1987 122 34 RR Yager Reasoning conjunctive knowledge Fuzzy Sets Systems 28 1988 6983 35 RR Yager Veristic variables IEEE Transactions Systems Man Cybernetics B 30 1 2000 7184 36 Z Younes F Abdallah T Denœux Multilabel classiﬁcation algorithm derived knearest neighbor rule label dependencies 6th European Signal Processing Conference EUSIPCO 08 Lausanne Switzerland 2008 T Denœux et al Artiﬁcial Intelligence 174 2010 479499 499 37 Z Younes F Abdallah T Denœux An evidencetheoretic knearest neighbor rule multilabel classiﬁcation Proceedings 3rd International Conference Scalable Uncertainty Management SUM 2009 Washington DC USA LNAI vol 5785 SpringerVerlag 2009 pp 297308 38 ML Zhang ZH Zhou MLKNN lazy learning approach multilabel learning Pattern Recognition 40 7 2007 20382048 39 LM Zouhal T Denœux An evidencetheoretic kNN rule parameter optimization IEEE Transactions Systems Man Cybernetics C 28 2 1998 263271