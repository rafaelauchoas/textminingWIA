Artiﬁcial Intelligence 174 2010 585596 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Information loss knowledge compilation A comparison Boolean envelopes Peter Schachte Harald Søndergaard Leigh Whiting Kevin Henshall Department Computer Science Software Engineering The University Melbourne Victoria 3010 Australia r t c l e n f o b s t r c t Article history Received 18 March 2009 Received revised form 14 March 2010 Accepted 27 March 2010 Available online 1 April 2010 Keywords Boolean approximation Coclones Knowledge bases Tractable inference Since Selman Kautzs seminal work use Horn approximation speed querying knowledge bases great Boolean approximation AI applications There Boolean classes desirable computational properties similar Horn class The class aﬃne Boolean functions example proposed interesting alternative Horn knowledge compilation To investigate tradeoffs precision eﬃciency knowledge compilation compare analytically empirically wellknown Boolean classes combinations ability preserve information We note traditional evaluation explores unitclause consequences random hard 3CNF formulas tell story complement evaluation experiments based variety assumptions queries underlying knowledge base 2010 Elsevier BV All rights reserved 1 Introduction Boolean approximation The problem eﬃcient inference propositional knowledge fundamental importance symbolic reasoning example circuit veriﬁcation Knowledge compilation introduced Selman Kautz 16 particular technique uses approximations knowledge base speed querying expense completeness As case powerful ideas approach simple Let knowledge base ϕ given let ϕ logical consequence upper approximation ϕ ϕ belonging class Horn example Boolean functions question logical consequence tractable For query α positive answer question ϕ cid4 α aﬃrms ϕ cid4 α A negative answer help However lower approximation ϕ available assumed Selman Kautz framework negative answer question ϕ cid4 α similarly answer ϕ cid4 α negative Otherwise fall standard expensive method resolving ϕ cid4 α answer dont know We shall follow Kavvadias et al 8 refer unique best upper approximation envelope dual concept corealthough need cores welldeﬁned classes discussed paper Three factors determine effectiveness knowledge compilation 1 time required compute approxima tions amortised queries knowledge base 2 time saved evaluating queries approxima tions 3 proportion queries approximate knowledge base yields deﬁnite answer The second factor determined choice Boolean function class tractable inference ﬁrst availability eﬃcient algorithm calculating approximations class Both aspects received considerable attention Corresponding author Tel 61 3 8344 1342 fax 61 3 9348 1184 Email addresses schachteunimelbeduau P Schachte haraldunimelbeduau H Søndergaard leighwhitinggmailcom L Whiting kevinhenshallgmailcom K Henshall 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201003003 586 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 including indepth study 10 Del Val 6 shown Selman Kautzs Horn envelope algorithm carries Boolean function classes closed subsumption He proposed improved algorithm applicable addition ally complement class closed resolution Moreover del Val discussed case ﬁrstorder predicate logic showing original concepts extended direction 6 While computational questions received attention said information loss knowledge compilation In study Selman Kautz 16 analysed generated approximations preserve information They applied method large number hard propositional formulas 3CNF analytically derived estimate queries forms x x y x y z answered successfully based approximations The results encouraging particularly expressive class conjunctive unit Horn functions substituted Horn class simplify analysis One aim note extend complement SelmanKautz analysis empirical analysis ﬁdelity Horn approximations upper Krom contradual Horn aﬃne approximations A second aim understand ﬁdelity varies underlying assumptions knowledge bases queries Selman Kautzs analysis random hard 3CNF knowledge bases These strong Boolean functions close half unsatisﬁable lead unsatisﬁable approximations rest typically relatively models Each application knowledge compilation different expected applications involve somewhat weaker Boolean functions inconsistent knowledge bases repaired How approximation different classes preserve information setting Here empirically measure information loss approximation different classes combinations different test sources 1 random Boolean functions 2 random 3 CNF including random hard 3CNF SelmanKautz analytical investigation 3 structured functions arising encodings combinatorial problems We measure information loss different ways counting number models added envelopes calculating fraction random queries entailed original function approximation Results different experiments given Sections 57 A aim investigate extent combinations Boolean classes improve success rate accelerated queryanswering This question presents naturally owing observation Proposition 2 For query α expressed 3CNF knowledge base ϕ entails α decided completely ϕs Horn contra dual Horn envelopes An interesting corollary given assumptions Selman Kautzs analysis 16 obtain better results envelopes perfect ones100 accuracy achieved need lower approximations Related conclusions drawn Section 8 2 Boolean coclones Let B 0 1 let V countably enumerable set variables A valuation μ V B assignment truth values variables V Let I V B denote set V valuations A Boolean function V function ϕ I B We let B denote set Boolean functions V The ordering B usual x cid2 y iff x 0 y 1 B ordered pointwise ordering relation corresponds exactly classical entailment cid4 A valuation μ model ϕ denoted μ cid4 ϕ ϕμ 1 We use usual connectives including exclusive We let cid8x y zcid9 denote median1 operation cid8x y zcid9 x y x z y z These connectives applied valuations obvious intention pointwise application In study concerned Schaefer classes 1 Krom K ϕ Krom iff valuations μ μcid11 cid8μ μcid11 μcid11cid11cid9 cid4 ϕ μ cid4 ϕ μcid11 cid4 ϕ μcid11cid11 cid4 ϕ Syntacti cally K set functions written conjunctive normal form literals clause members referred 2CNF bijunctive μcid11cid11 Horn H ϕ Horn iff valuations μ μcid11 written conjunctive normal form clause μ μcid11 cid4 ϕ μ cid4 ϕ μcid11 cid4 ϕ H set functions cid41 cid4k k cid3 0 positive literal cid4 cid2 Contradual Horn N ϕ contradual2 Horn iff valuations μ μcid11 These functions written conjunctive normal form negative literal cid4 clause Aﬃne A ϕ aﬃne iff valuations μ μcid11 μcid11cid11 μ μcid11 μcid11cid11 cid4 ϕ μ cid4 ϕ μcid11 cid4 ϕ μcid11cid11 cid4 ϕ 15 A Boolean function aﬃne iff written conjunction terms c0 c1x1 c2x2 ckxk ci 0 1 xi V 0 k3 μ μcid11 cid4 ϕ μ cid4 ϕ μcid11 cid4 ϕ cid41 cid4k k cid3 0 cid2 There classes including kHorn 4 kquasiHorn envelopes welldeﬁned Some wellstudied classes including class unate functions class renamable Horn functions 1 Or majority operation prefer terminology notation suggested Knuth 9 2 We follow Halmos 7 term 3 In cryptographycoding community aﬃne Post 12 called alternating function function written c0 c1x1 c2x2 ck xk k cid2 0 The class alternating functions closed conjunction P Schachte et al Artiﬁcial Intelligence 174 2010 585596 587 Fig 1 Lattice coclonestop provide unique best upper approximations4 It inconvenient question Does ψ follow approximation ϕ answered nondeterministically insist relation Boolean function envelope proper function5 This corresponds technical requirement Boolean function class coclone 11roughly Boolean function collection characterised model closure set connectives classes It known coclone contains 1 closed conjunction existential quantiﬁcation Hence coclone C Cenvelope Boolean function ϕ deﬁned simply ψ C ϕ cid4 ψ cid2 Recall clone family functions containing projection functions closed composition The Boolean clones form lattice subset ordering lattice subset Posts wellknown lattice 12 easily reads Posts famous functional completeness result propositional logic The relations clones lattice coclones classes identiﬁed Schaefer dichotomy result generalised satisﬁability 15 explained Böhler et al 1 Fig 1 shows end lattice coclones including K H N A B The classes II0 II1 Schaefers 0valid 1valid classes respectively6 That ϕ II0 iff λv0 cid4 ϕ ϕ II1 iff λv1 cid4 ϕ The class IN2 set Boolean functions ϕ satisfying modelclosure constraint μ cid4 ϕ μ cid4 ϕ The class IN intersection II0 II1 IN2 expression equivalently leave ﬁrst For K H N wellknown lineartime algorithms deciding satisﬁability SAT formulas CNF A satisﬁability decidable polynomial time assuming usual matrix form representation aﬃne functions modulo2 arithmetic Simple reductions SAT entailment similarly decided polynomial time classes Let C K H N A The entailment ϕ cid4 γ1 γn holds exactly γi logical consequence ϕ suﬃces consider entailment conjunct separately But ϕ cid4 γ amounts satisﬁability ϕ γ formula translated conjunction C constraints linear time Moreover ϕ γ belongs C ϕ The proposition communicates sense Schaefer classes appropriate study We argued focus Boolean coclones envelopes unique Proposition 1 says assuming CNF presentation classes contained Schaefer classes allow eﬃcient entailment tests P coNP To precise let EC entailment problem class C instance form ϕ ψ ϕ C ϕ ψ presented CNF The decision problem posed EC Does ϕ cid4 ψ hold Proposition 1 For coclone C contained K H N A EC coNP complete Proof The complement EC obvious polynomial time veriﬁer For instance ϕ ψ veriﬁer uses certiﬁcate interpretation satisﬁes ϕ ψ Inspection Fig 1 fact omitted coclones subsets K H N A makes clear need EIN coNP hard We providing sequence hcid4 EIN UNSATC unsatisﬁability problem polynomialtime mapping reductions UNSATB class C fcid4 UNSATIN2 For ﬁrst reduction consider f deﬁned f ϕ ϕ ϕ dual function Note ϕ ϕ computed polynomial time note f ϕ ϕs contradual negation ϕs equisatisﬁable f ϕ IN2 satisﬁable iff ϕ To formula f obtained simply changing γ η γ ϕ η ϕ ϕ ϕ gcid4 EIN2 cid2 4 For example x y x y unate x y unate envelope welldeﬁned 5 Where unique best upper approximation minimal upper approximations suffer exponentially different information loss Section 3 discusses phenomenon dualfor maximal lower approximations Without insistence classes unique best approximations need discuss actual approximation algorithms probability producing better worse minimal upper approximation 6 Here use nomenclature Böhler et al 1 588 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 sign literal ϕ The second reduction performed g deﬁned gϕ ϕ 0clearly polynomialtime reduction For reduction consider function h deﬁned cid3 hϕ ψ ϕ ψ IIϕ IIψ ϕ 0valid 1valid II yields 0valid 1valid envelope Note IIϕ obtained polynomial time replacing ϕclause γ u v γ u v occur ϕ cid2 cid2 3 Lower upper approximations A class closed disjunction offers unique weakest implicant coredual concept envelope How classes consider closed disjunction In absence unique best lower approximations common use maximal lower approximations given class7 Selman Kautz 16 derive maximal lower Horn approximation repeated use socalled Horn strengthening removal k 1 positive literals clause k 1 positive literals There task ﬁnding maximal lower approximations particular Horn approximations 2 However different maximal approximations staggeringly different information content treated great care Zanuttini 17 elegantly makes point K H A single example He considers Boolean nplace function 2n3 2 models m100 m 0 1n3 00 010 00 001 Maximal lower Horn approximations include 00 010 exponentially larger m100 m 0 1n3 Maximal lower Krom approx imations include 00 010 00 001 exponentially larger m100 m 0 1n3 00 010 Maximal lower aﬃne approximations 00 010 00 001 exponentially larger m100 m 0 1n3 Upperapproximation classes avoids kind divergence Nevertheless class C studied loss information involved C upperapproximation considerable number models added function exponential number variables Below examples nplace Boolean functions produce vacuous envelope 1 They Cenvelope worst case incur great loss information 1 With n cid3 3 function cid2 xi x j xk 1 cid2 j k cid2 n N nn 12 1 models Its K envelope 2n models 2 With n cid3 2 function cid2 A envelope 2n models cid2 3 With n cid3 2 function A envelope 2n models xi x j 1 cid2 j cid2 n H K n 1 models Its N envelope xi x j 1 cid2 j cid2 n N K n 1 models Its H envelope Notably Horn envelope combined contradual Horn envelope achieves complete coverage queries presented 3CNF Proposition 2 Let ϕ Boolean function let ϕcid11 3CNF Then ϕ cid4 ψ iff clause C ψ ϕcid11 cid4 C ϕcid11cid11 cid4 C ϕcid11cid11 Horn contradual Horn envelopes Let ψ Boolean formula Proof The immediate ϕ cid4 ϕcid11 clause ψ logical consequence ϕ ψ For assume ϕ cid4 ψ let C arbitrary clause ψ Then ϕ cid4 C C H C N C logical consequence ϕcid11 cid2 ϕ cid4 ϕcid11cid11 ϕcid11cid11 Proposition 2 strengthened Using results del Val 5 propositions assertion holds 3CNF contradual Horn envelope Of course 3CNF Horn envelope ϕcid11cid11 assume ϕcid11 queries 3CNF presentation Boolean functions expressed 4 Experimental method Our aim empirically evaluate loss information incurred approximation knowledge bases classes guarantee unique best approximation tractable entailment checking Only subclasses Schaefer classes satisfy requirements As subclasses correspond greater information loss consider We stress single representation ideal classes CNF works K H N suitable A A modulo2 arithmetic matrix form ideal A unsuitable K H N Hence use neutral Reduced Ordered Binary Decision Diagrams ROBDDs 3 associated envelope algorithms 1314 From eﬃciency point view representation adequate classes ideal But focus measuring information loss 7 We avoid commonly term GLB maximal lower approximation different use lattice theory P Schachte et al Artiﬁcial Intelligence 174 2010 585596 589 Fig 2 Information lost models gained envelopes random functions Fig 3 3CNF queries dropped percentages envelopes random functions concerned eﬃcient representation given class ROBDDs provide uniform base experiments allow generate Boolean functions truly random sense valuation equal probability model 5 First experiment randomly generated Boolean functions We ﬁrst explore information loss approximation random Boolean functions To end generate Boolean functions 24 variables valuation probability p model varying p 1 215 1 224 For random Boolean function evaluate information loss taking K H N A envelopes different ways Firstly compute number models original function envelopes consider model envelope model original function information lost approximation We calculate percentage loss follows Let m number models original function n number models envelope The percentage information loss 100 n m224 n The results calculation envelope functions varying strengths presented Fig 2 The number models original function 590 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 Fig 4 6CNF queries dropped percentages envelopes random functions Fig 5 Information lost vs function size random functions presented logarithmically X axis strongest functions left Y axis shows percentage information loss Note approximations lie imperceptibly X axis A K slightly worse H N functions 16 models H N indistinguishable Our second appraisal information loss counts proportion random queries correctly answered approximation A query dropped entailed original function envelope We follow tradition literature single clause 3CNF queries disjunctions literals We consider 6CNF queries weaker queries different results We consider queries consisting conjunctions clauses handled separately checking clause entailed Each query formed generating 3 6 literals random ensuring literals involve variable envelope tested 1000 3CNF 1000 6CNF queries considering queries entailed original function All repeated 100 random original formulas averages calculated We results fewer 1 random queries 1000 queries overall entailed original function One wonder queries answered approximation handled successfully This selecting effective approximation use separate types P Schachte et al Artiﬁcial Intelligence 174 2010 585596 591 Fig 6 3CNF queries dropped vs function size random functions Fig 7 6CNF queries dropped vs function size random functions approximation successfully answer query able answer Although requires computing approximations knowledge base worthwhile applications knowledge base change However wasteful approximations tend fail queries Thus additionally present results pair approximation domains consider pair answer query successfully course Figs 3 4 results 3CNF 6CNF queries respectively We conﬁrmed results hold formulas different numbers variables ranging 10 90 similar strengths Fig 5 shows percentage information loss computed plotted number variables randomly generated function In case function n variables set probability valuation model approximately n models These results little information loss number variables rises 20 30 Figs 6 7 showing percentage 3CNF 6CNF queries dropped approximation refute conclusion Here ﬁx probability valuation model approximately n 2n As cases 100 random Boolean functions 592 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 Fig 8 Information lost models gained envelopes 3CNF functions Fig 9 3CNF queries dropped percentages envelopes 3CNF functions 1000 3CNF 1000 6CNF random test queries approximation The charts fairly consistent degree information loss measured queries dropped regardless number variables8 6 Second experiment random 3CNF including hard 3CNF The second experiment like ﬁrst arbitrary random functions replaced random functions expressible 3CNF formulas This provides baseline comparison related work exclusively considered hard 3CNF case In ﬁrst experiment generated formulas variety modelprobability dis tributions Here instead generate formulas variety clausetovariable ratios Each formula translated ROBDD form approximations produced In cases formulas denote 24place Boolean functions explore range numbers clauses 8 148 including 103 yields hard 3CNF func tions 8 The ﬂuctuations graphs random variation fact approximated n2n model probability 1 2ncid1805log2ncid19 The systematic error caused rounding tend raise values 50 30 60 70 variables lower 90 relative P Schachte et al Artiﬁcial Intelligence 174 2010 585596 593 Fig 10 6CNF queries dropped percentages envelopes 3CNF functions Fig 11 Information lost vs function size 3CNF functions As ﬁrst experiment measure information loss terms models added envelope For given number clauses test 100 random functions time 3CNF The result shown Fig 8 The point corre sponding 103 clauses hard 3CNF case falls 2 models X axis Although readily discernible ﬁgures hard 3CNF point average K approximation adds 1 model possible 224 H N add 4 A adds 211 Similarly proportions 3CNF 6CNF queries dropped approximations 1000 tests presented Figs 9 10 including results pairs envelopes At hard 3CNF point 3 6CNF queries K performs best A worst dropping 1 queries Again veriﬁed results fairly insensitive size functions involved Fig 11 shows information lost percentage models gained approximation hard 3CNF formulas sizes ranging 10 90 variables 43387 clauses Figs 12 13 information loss measured dropped queries hard 3CNF formulas size range Once despite approximations gaining small percentage models proportion queries dropped negligible fairly independent size Note A approximation loses information K combination H N answers 3CNF 6CNF queries correctly 594 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 Fig 12 3CNF queries dropped vs function size 3CNF functions Fig 13 6CNF queries dropped vs function size 3CNF functions 7 Third experiment structured Boolean functions Randomly generated Boolean functions arguably unrepresentative real world knowledge bases structure experiment investigates information loss structured Boolean functions sourced SATbased problemsolving Table 1 gives size sample problems shows additional models created envelopes Note numbers large case percent possible models added To better understanding means typical queryanswering Table 2 shows percentage 3CNF queries dropped envelopes pairwise combinations Table 3 6CNF queries Each formula satisﬁable queried 1000 random 3CNF queries 1000 random 6CNF queries The formulas ais6cnf allintervalseries instance SATLIB colourcnf 4colouring map 7 westernmost contiguous US states queensncnf solving nqueens problem sudokuncnf solving 4 4 sudoku instance unary encoding n squares ﬁlled sud1_ncnf solving 9 9 sudoku instance binary encoding n squares ﬁlled sud2_ncnf similar different instance sv4cnf disproving software veriﬁcation assertion Note varying n queensncnf tests involve varying numbers variables P Schachte et al Artiﬁcial Intelligence 174 2010 585596 595 Table 1 Information lost number models gained envelopes structured functions Ais6 Colour Queens5 Queens6 Sudoku1 Sudoku2 Sudoku3 Sudoku4 Sud1_22 Sud1_23 Sud1_24 Sud2_26 Sv4 Variables 61 28 26 37 64 64 64 64 324 324 324 324 58 Clauses 581 97 276 497 241 242 243 244 15883 15887 15891 15899 150 K 43890 10425 276 1 915128 2282 376 16 418750 64 1 431 896 Table 2 3CNF queries dropped percentages envelopes structured functions Ais6 Colour Queens5 Queens6 Sudoku1 Sudoku2 Sudoku3 Sudoku4 Sud1_22 Sud1_23 Sud1_24 Sud2_26 Sv4 K 53 00 84 00 28 16 15 05 01 00 00 01 03 H 85 00 42 00 09 12 14 06 04 02 03 08 05 N 777 1000 816 182 255 116 89 28 18 03 05 11 08 A 877 1000 858 182 281 169 142 46 47 09 05 24 00 Table 3 6CNF queries dropped percentages envelopes structured functions Ais6 Colour Queens5 Queens6 Sudoku1 Sudoku2 Sudoku3 Sudoku4 Sud1_22 Sud1_23 Sud1_24 Sud2_26 Sv4 K 86 65 97 03 84 25 16 04 03 00 00 02 03 H 20 23 49 03 24 19 18 11 06 02 01 08 03 N 641 1000 644 88 360 125 81 25 11 04 03 04 03 A 870 998 841 74 432 212 147 30 35 10 02 18 00 KH 05 00 42 00 06 06 06 01 00 00 00 00 01 KH 20 23 49 03 22 09 09 04 01 00 00 00 02 H 178 2913 26 1 1968 152 58 13 8945 55 3 229 901 KN 48 00 42 00 22 10 09 04 01 00 00 01 02 KN 54 65 14 00 63 13 04 00 01 00 00 02 01 N 672555 5688357 951 11 15132387 5991 775 33 241026 270 4 239 247 A 1048552 2096912 246 4 131000 1006 244 10 16777170 119 1 244 0 KA 53 00 84 00 28 16 15 05 01 00 00 01 00 KA 85 65 86 00 83 25 16 04 03 00 00 01 00 HN 00 00 00 00 00 00 00 00 00 00 00 00 00 HN 03 23 00 00 09 00 00 00 00 00 00 00 00 HA 05 00 42 00 06 09 08 01 02 01 01 05 00 HA 19 23 40 00 21 13 10 04 05 02 00 05 00 NA 777 1000 816 182 253 110 80 22 17 02 01 07 00 NA 641 998 628 74 352 116 72 14 08 03 01 02 00 similar numbers models group Sudoku tests involve number variables considerable differences numbers models Again results HN strongest giving perfect results Also considering Sudokun Sud1_n results stronger Boolean functions larger n suffer loss information dropped queries These tests bias exhibited earlier tests approximation loses information drops fewer queries depending idiosyncrasies knowledge bases queries involved Consider example Table 3 queens5 K improve H approximation improves N surpass KH combination Also contrary earlier results A approximation performs better N cases 8 Conclusions We considered classes Boolean functions use knowledge compilation standpoint infor mation consequence preservation showed maximally precise classes guaranteeing unique 596 P Schachte et al Artiﬁcial Intelligence 174 2010 585596 best approximation polynomial time entailment checking Empirical evaluation approximations leads interesting observations On knowledge compilation works strong knowledge bases Querying pairs domains beneﬁcialfor right combinations domains In particular HN combination Horn contradual uniformly gives best results This combination answers 3CNF queries precisely need lower approximation As shown Fig 10 Table 3 HN drops 6CNF queries 3CNF knowledge bases Aﬃne approximation A generally performs worst domains considered domains beneﬁt combination A In structured test cases A outperformed N nature knowledge base particular Sv4 test case happens aﬃne For random knowledge bases A performs worst note test queries disjunctive aﬃne It diﬃcult recommend aﬃne approximation knowledge compilation cases knowledge base queries expected nearly aﬃne Krom approximation K appear useful For 3CNF knowledge bases K approximations answer 3CNF queries correctly approximations For strong knowledge bases3CNF functions clausevariable ratio 26 Boolean functions 64 modelsthe phenomenon extends 6CNF queries Remarkably true despite fact H N generally stronger approximations K It interesting precision KH KN combinations signiﬁcantly better single domain surpassed HN Whether test random 3CNF knowledge bases H N rarely diverge This surprising domains contraduals average unbiased tests tend behave similarly H N approximation However striking H N behave differently structured tests probably owing natural human tendency favour implications single consequent implications single antecedent As shown Figs 6 7 12 13 queryanswering performance approximation combination inde pendent number variables knowledge base However queryanswering performance sensitive strength knowledge base shown Figs 3 4 9 10 The structured tests involved strong knowledge bases range 26 324 variables conﬁrm Tables 2 3 Conclusions drawn hard 3CNF case Of 100 random hard 3CNF functions experiments 75 fewer 3 models Those deﬁnition Krom aﬃne classes The points suggest success knowledge compilation sensitive nature knowledge base queries Where queries fall class tractable inference approximation knowledge base class lose information drop queries Considering case 3CNF queries approximations hard 3CNF knowledge bases adequately predict behaviour shapes knowledge bases queries Acknowledgements We thank reviewers provided detailed helpful advice In particular comments Proposition 2 reviewers References 1 E Böhler N Creignou S Reith H Vollmer Playing Boolean blocks II Constraint satisfaction problems ACM SIGACT News 35 1 2004 2235 2 Y Boufkhad Algorithms propositional KB approximation Proc 15th Nat Conf Artiﬁcial Intelligence AAAI PressMIT Press 1998 pp 280285 3 R Bryant Graphbased algorithms Boolean function manipulation IEEE Transactions Computers C 35 8 1986 677691 4 R Dechter J Pearl Structure identiﬁcation relational data Artiﬁcial Intelligence 58 1992 237270 5 A del Val An analysis approximate knowledge compilation Proc IJCAI95 vol 2 1995 pp 830836 6 A del Val First order LUB approximations Characterization algorithms Artiﬁcial Intelligence 162 2005 748 7 PR Halmos Lectures Boolean Algebras SpringerVerlag 1963 8 D Kavvadias C Papadimitriou M Sideri On Horn envelopes hypergraph transversals K Ng P Raghavan N Balasubramanian F Chin Eds Proc Fourth Int Symp Algorithms Computation Lecture Notes Computer Science vol 762 SpringerVerlag 1993 pp 399405 9 DE Knuth Introduction Combinatorial Algorithms Boolean Functions The Art Computer Programming vol 4 AddisonWesley 2008 10 P Liberatore Compilation Intractable Problems Its Application Artiﬁcial Intelligence PhD thesis University Rome La Sapienza Italy 1998 11 N Pippenger Theories Computability Cambridge University Press 1997 12 EL Post The TwoValued Iterative Systems Mathematical Logic Princeton University Press 1941 Reprinted M Davis Solvability Provability Deﬁnability The Collected Works Emil L Post Birkhäuser 1994 pp 249374 13 P Schachte H Søndergaard Boolean approximation revisited I Miguel W Ruml Eds Proc SARA 2007 Lecture Notes Artiﬁcial Intelligence vol 4612 SpringerVerlag 2007 pp 329343 14 P Schachte H Søndergaard L Whiting K Henshall An algorithm aﬃne approximation binary decision diagrams Chicago Journal Theoretical Computer Science press 15 TJ Schaefer The complexity satisﬁability problems Proc Tenth Ann ACM Symp Theory Computing 1978 pp 216226 16 B Selman H Kautz Knowledge compilation theory approximation Journal ACM 43 2 1996 193224 17 B Zanuttini Approximation relations propositional formulas Complexity semantics S Koenig R Holte Eds Proc SARA 2002 Lecture Notes Artiﬁcial Intelligence vol 2371 SpringerVerlag 2002 pp 242255