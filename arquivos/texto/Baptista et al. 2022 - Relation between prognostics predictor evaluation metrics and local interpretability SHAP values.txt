Artiﬁcial Intelligence 306 2022 103667 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Relation prognostics predictor evaluation metrics local interpretability SHAP values Marcia L Baptista Delft University Technology TU Delft Mekelweg 5 2628 CD Delft Netherlands b Luleå University Technology 971 87 Luleå Sweden c Palo Alto Research Center PARC Palo Alto CA 94304 USA d University Lisbon Instituto Superior Tecnico IST Av Rovisco Pais nº1 1049001 Lisbon Portugal Kai Goebel bc Elsa MP Henriques d r t c l e n f o b s t r c t Article history Received 6 October 2020 Received revised form 24 December 2021 Accepted 20 January 2022 Available online 15 February 2022 Keywords Local interpretability Modelagnostic interpretability SHAP values Monotonicity Trendability Prognosability Maintenance decisions domains aeronautics increasingly depen dent able predict failure components systems When datadriven techniques prognostic task face headwinds ceived lack interpretability To address issue paper examines features datadriven prognostic approach correlate established metrics monotonicity trendability prognosability In particular use SHAP model SHapley Additive exPlanations ﬁeld eXplainable Artiﬁcial Intelligence XAI analyze come increasingly complex algorithms Linear Regression MultiLayer Perceptron Echo State Network Our goal test hypothesis prognostics metrics correlate SHAP models explanations SHAP values We use baseline data standard data set contains runtofailure trajectories jet engines The results indicate SHAP values track closely metrics differences observed models support assertion model complexity signiﬁcant factor consider explainability consideration prognostics 2022 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 1 Introduction Over decades developments storage acquisition technologies permitted access large volumes data The continual growth computing power followed corresponding decrease costs come meet requirements advanced decisionmaking systems These systems started revolutionize way think data modeling brought additional challenges especially interpretability level Decision systems based machine learning wellknown promising results 79 complexity lack transparency 14276 An accuracyinterpretability tradeoff 42 true machine learning methods For example deep learning networks advanced form machine learning typically combine activities thousands neurons Despite neural units relative simplicity networks structure intricate fully understood designer Mostly reason neural network systems tend seen blackboxes user typically aware inputoutput relationships underlying reasoning Corresponding author Email addresses mlbaptistatudelftnl ML Baptista kgoebelparccom K Goebel elsahistutlpt EMP Henriques httpsdoiorg101016jartint2022103667 00043702 2022 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Machine learning algorithms revolutionized ﬁelds image recognition natural language processing 103 However obstacles hinder adoption ﬁelds In highly regulated environments strict requirements audit veriﬁability decisions limited acceptance For example aerospace certiﬁcation regulatory bodies requires applicant demonstrate meets minimal safety criteria Accountability trust essential properties applications As noted Wilkinson et al 135 Federal Aviation Administration FAA National Aero Space Agency NASA understanding mechanisms essential understanding impact software assurance The General Data Protection Regulation GDPR approved European Parliament 2016 imposed restrictions automated decisionmaking establishing human right obtain explanations logic involved algorithmic decisions inﬂuence lives 47132 Recognizing importance interpretability accelerate machine learning progress Artiﬁcial Intelligence AI search community started pay increasing attention explainability topic Researchers different backgrounds experiences started produce signiﬁcant body research explanations intelligibility A project note eXplainable AI XAI initiative 52 led Defense Advanced Research Projects Agency DARPA United States The XAI initiative aims creating machines operate environments providing explanations behavior Researchers different ﬁelds researched interpretability given complexity subject agreement single deﬁnition taxonomy As noted Lipton 84 concept interpretability monolithic reﬂects distinct ideas trust transparency Given lack formal technical meaning 84 important establish deﬁnition interpretability Here adopt deﬁnition Biran Cotton 19 level observer understand cause decision Following work Miller 92 simplicity equate interpretability explainability As described work Arrieta et al 8 approaches interpretability One approach SHAP model SHapley Additive exPlanations 85 This kind XAI model uses Shapley values game theory characterize input variables relative importance The approach modelagnostic 107 requires knowing blackbox models output neighbor instances input sample When SHAP observed value feature gets SHAP value The focus explaining model locally depends instead learning mapping In words goal achieve local interpretability 43 The technique local interpretability contrasts global interpretability Global interpretability consists tech niques able explain structure model macro perspective This type approach simpler methods complexity models increases gradually diﬃcult understand 93 Global interpretability methods typically examine blackbox models inputoutput relationships infer equivalent logical structure simulate blackbox models behavior In words goal build surrogate model transparent 60 Local interpretability concerns provision independent explanations individual model responses Models SHAP focus calculating importance different features speciﬁc prediction The goal isolate single instance build surrogate model neighborhood locally instance explain model processes Because typically explicit concern maintaining correlation diverse independent local models work aims understand better SHAP local models relate In work interested understanding SHAP beneﬁt Remaining Useful Life RUL estimation aero nautics To end study increasingly complex prognostics models Linear Regression LR MultiLayer Perceptron MLP recent algorithm Echo State Network ESN 6437 The ESN recurrent neural network connections output computed regression instead gradientbased methods simpliﬁes accelerates training process These networks additional capability learning multidimensional temporal patterns As ESN fed input signals past signals inﬂuence new ones networks feedback loops This kind memory enables ESN capture temporal dimension data explicitly There archi tectures memory LongShort Term Memory Network LSTM 59 Gated Recurrent Unit GRU 29 The ESN simple eﬃcient alternative shown promising results prognostics 10195110114109 This paper discusses need XAI prognostics providing comprehensive literature review investigating SHAP model according classical metrics PHM monotonicity trendability prognosability proposed 32 It advantageous trajectories explanatory values produced SHAP exhibit properties Monotonic SHAP values imply weight associated given feature changing monotonically units lifecycle Monotonicity desirable means sensor features exhibit increasing decreasing importance time Having ﬂuctuating SHAP values likely mean SHAP model unstable probably appropriate model analyze importance prognostics feature time Trendability relevant trendable SHAP values imply SHAP trajectories SHAP sequences different units follow trend line In prognostics importance feature consistent different units This consistency facilitates prognostics interpretation results Prognosable SHAP values imply weight associated speciﬁc feature end life slight variation considering different units Prognosability desirable characteristic means explainability different end life points consistent units This works main contribution SHAP values exhibit desirable properties monotonicity trendability prognosability A secondary contribution showing model complexity inﬂuences interpretability 2 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 The remainder article organized follows Section 2 reviews related work ﬁeld Prognostics Health Management PHM eXplainable Artiﬁcial Intelligence XAI Section 3 describes approach Section 4 focuses case study methodology The results experiments presented discussed Section 5 Section 6 concludes article 2 Background related work In section ﬁeld Prognostics Health Management PHM review work interpretability techniques discuss contributions PHM interpretability domain 21 Prognostics health management Prognostics Health Management PHM engineering discipline studies improve lifecycle based current health status future condition 102 PHM seeks prevent unexpected failure based realtime monitoring technologies improve control maintenance operations use condition monitoring data promote better design Within PHM prognostics focuses predicting future health state failure modes equipment based condition monitoring historical trends anticipated usage proﬁles 44 The ﬁelds signiﬁcance comes potential enable reliable operations enhance understanding aging factors safety margins Some beneﬁts prognostics unscheduled maintenance optimized lifecycle management increased availability engineered systems infrastructure These goals particularly encouraged aerospace engineering 63 issues performance reliability safety concern Zio 149 makes distinction approaches prognostics ﬁrst principles modelbased reliability model based datadriven approaches In approach ﬁrst principles modelbased prediction algorithm bases estimates mathematical model derived ﬁrst principles engineering behavior Mostly promising results ﬁeld 25357494 established notion methods superior performance remaining prognostics approaches This notion premises possible derive rigorous model degradation process In practice deﬁning complete physical model easy possible Most complex systems subject multiple nonlinear stochastic processes degradation In cases possible partially actual physics underlying phenomena represented blackbox simpliﬁcation Modeling errors minimized optimizing model parameters given experimental ﬁeld data However design faulty based inadequate testbenches Reliability modelbased approaches depend classical reliability theory bathtub curve product failure behav ior estimate time failure equipment In approach failure repair time distributions described statistical properties estimated failure repair records The Weibull distribution preferred choice analysis Generally models include environmental weather conditions operational parameters temperature pressure vibration load Several authors Peng Huang 100 Rocchetta et al 111 Alvehag Soder 5 Naseri et al 97 worked limitation techniques accelerated life models proportional hazard models Nevertheless advanced methods simple capture range systems change complicated effect deterioration Compared previous methods datadriven methods rely explicit domain knowledge There reliance reliability theory explicit physical representation aging processes There misconception underlying mathematical model kind approach 71 p 244 This claim entirely valid Datadriven models build mathematical model observed relationships input data target variables The way models built depends utilized artiﬁcial intelligence technique For example simple terms decision trees exploit causality neural networks optimize function composition support vector techniques kernelbased estimation methods The target output analytical measurable model relates input output variables irrespective procedure applied datadriven approach Even kind model easily obtainable physical meaning datadriven modeling produces abstract useful physical phenomena representations The generalization capabilities models bring provide solutions signiﬁcant issues prognostics For example help cluster data address complex numerical problems capture nonlinear relationships automatically 112 In prognostics noted Zio Maio 150 skepticism datadriven methods Deep learning complex class datadriven methods come raise questions 144 Fields video games vision natural language processing hastened adopt deep learning seen techniques sur pass classical methods performance expectations 79 The trend observed prognostics manner Two substantial differences prognostics ﬁelds explain discrepancy The ﬁrst lack failure data prognostics particularly highlyreliable assets new equipment This issue critical 45 options exist address unsupervised anomaly detection 126 data simulation 55 The second difference major cause mistrust deep learning critical systems 151 relates general lack interpretability models 3 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Due factors prognostics technologies low Technology Readiness Level TRL PHM considered emerging ﬁeld 116 Over decades great deal effort invested improving accurate prediction Remaining Useful Life RUL different systems components The focus accuracy certiﬁcation However increased concerns trust accountability auditing diverse ﬁelds nuclear energy 11 pp 151152 aerospace 63135 bringing increased attention area Recent works 1418761366980 started apply methods eXplainable Artiﬁcial Intelligence XAI PHM Before latest developments explainable prognostics authors 1503813382 fuzzy set theory Zadeh 139 promote interpretability PHM This form multivalued logic particularly successful diagnostics applications review 133 showing possible capture nonlinear complexity maintaining degree transparency However Mencar 91 notes fuzzy logic guarantee interpretability There open questions ﬁeld diﬃculty deﬁne exact fuzzy rules membership functions optimize fuzzy systems As noted Chimatapu et al 28 fuzzy systems perceived XAI technique However interesting observe original motivation 1088 fuzzy control systems came artiﬁcial intelligence Regardless classiﬁcation contribution fuzzy techniques advance ﬁeld XAI explainable prognostics notice In subsections review important contributions ﬁeld interpretability 22 Premodel interpretability Some authors Carvalho et al 23 consider existence premodel data interpretability This kind interpretability consists applying independent techniques understand data train build model Such approaches depend data modelagnostic Principal Component Analysis PCA Dis tributed Stochastic Neighbor Embedding tSNE clustering methods examples exploratory data analysis methods 53 classiﬁed premodel interpretability These techniques high interpretability power considered authors 238131 XAI ﬁeld This follows techniques able promote better comprehension model able aid experts understand gain insights prognostics process They work combination advanced techniques provide holistic overview model In prognostics premodel interpretability subject extensive study For example PCA preferred choice authors prognostics Zhang et al 146 Benkedjouh et al 17 Mosallam et al 96 Lasheras et al 78 Yongxiang et al 138 reduce data dimensionality A relevant study Lall Thomas 77 compared utility PCA Indendepent Component Analysis ICA capturing damage evolution electronic assemblies The authors reported ICA help discriminate failure clearly indicate damage progression The PCA helped distinguish healthy failure stage variance principal components instantaneous frequency strain signals allowed follow failure progression Another data exploration technique tSNE technique proposed Maaten Hinton 86 allows visualizing highdimensional data threedimensional map The technique typically PHM 2756 help separate different failure modes For example Chen et al 27 apply dimension reduction methods tSNE PCA Locality Preserving Projections LPP PHM dataset related bearings tSNE achieving best accuracy methods The authors trained classiﬁers features derived different visualization techniques outcome possible estimate accuracy 23 Inmodel interpretability The ﬁeld inmodel interpretability 23 focuses intrinsically interpretable models These transparent 84 models naturally design provide degree interpretability Lipton 84 classiﬁes transparency dimensions simulatability decomposability algorithmic transparency Simulatability relates ability understand entire model Lipton 84 notes simulatability direct consequence use particular model For example models linear regression rulebased systems decision trees typically easier interpret 8 cases compact neural network transparent alternatives Note simple methods linear regression challenging number predictors increases In expert systems based ifthen rules possible grasp rules interactions Seemingly decision trees deep broad graphical visualization comprehension Lipton 84s second notion transparency decomposability deﬁnes degree user understand model components input data parameters calculation rules The notion Lipton 84 algorithmic transparency relates ability understand inferential process It important consider notions designing transparent machine learning models We review approaches proposed achieve inmodel transparency In work Fellous et al 39 identiﬁes classes approaches achieve inmodel interpretability 1 hybrid models 2 architecturally explainable models 3 explainable convolutional networks 4 models regularization Arrieta et al 8 review hybridization XAI Hybrid models XAI combine simple interpretable models complex models One modeling trend popular propose deep formulations classical machine learning models A work mention Deep kNearest Neighbours DkNN Papernot McDaniel 99 hybrid classiﬁer 4 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 runs KNearest Neighbors KNN algorithm data learned layer DNN In DkNN neighbor instances humaninterpretable explanations prediction Another hybrid model Deep Weighted Averaging Classiﬁer DWAC Card et al 22 The DWAC bases expla nations predictions examples prototypes 70 presenting user training samples similar given input instance Deep models combined probabilistic graphical models Deep Kalman ﬁlters DKFs Krishnan et al 72 conditional random ﬁelds RNNs Zheng et al 147 Deep Variational Bayes Filters DVBFs Karl et al 68 Structural Variational Autoencoders SVAE Johnson et al 67 Other approaches hybridization use transparency mechanisms inside blackbox models Bennetot et al 18 use instance knowledgebase enhance neural network Ensemble techniques authors Zhou et al 148 create hybrid models integrate transparent blackbox models Probabilistic graphical models choice given interpretability advantages learned graphical structures reveal relevance independence causal relationships A survey techniques enrich neural networks transparency techniques extract symbolic rules neural networks utilize ANNs deﬁne rulebased systems provided Andrews et al 7 Other examples hybrid models include SelfExplaining Neural Networks SENN Melis Jaakkola 90 Contextual Explanation Networks CEN AlShedivat et al 3 BagNets Brendel Bethge 20 Architecturally explainable models display architecture adjustments enhance interpretability For example interpretable convolutional network proposed Zhang et al 145 included class The proposed architecture differs conventional convolutional architecture loss function added ﬁlter convolutional layer results meaningful representations Another contribution note Alain Bengio 4 propose linear classiﬁer probes extract information intermediate layers neural network The general idea use layers information ﬁt linear classiﬁer function observe function predict output classes Joint predictionexplanation models machine learning models explicitly trained explain predictions An example approach Teaching Explanations Decisions TED framework proposed Hind et al 58 TEDs underlying idea augment training dataset include rationale outcome explanation provided explicitly algorithm Under model transparency regularization techniques Note difference architectural change regularization techniques Regularization techniques 73 speciﬁc architectural schemes reduce overﬁtting weight decay dropout data augmentation Architectural modiﬁcations typically entail complexity change network altering models structural components As Zhang et al 143 note regularization signiﬁ cance architectural changes hold increased interpretability potential 24 Postmodel interpretability In addition premodel inmodel interpretability postmodel interpretability 23 Postmodel techniques analyze model creation posthoc devised independent methods interpret ﬁnal cisions There approaches modelspeciﬁc modelagnostic 8 Posthoc modelspeciﬁc interpretability consists methods speciﬁcally designed given machine learning algorithm In contrast posthoc modelagnostic interpretability agnostic analyzed machine learning model Several modelspeciﬁc studies substitute original model simpliﬁed version For example authors Barakat Diederich 14 Martens et al 89 Barakat Bradley 15 proposed Support Vector Machines SVM rule extraction techniques enhance comprehensibility model Assche Blockeel 9 proposed method learn single decision tree ensemble decision trees Aside model simpliﬁcation research directions modelspeciﬁc interpretability For example DeepLIFT method proposed Shrikumar et al 123 tries compute internal neuron importance The method inspects deep learning models comparing activation neuron reference activation assigns score neuron contribution accordingly The reference activation corresponds default input selected designer Another posthoc modelspeciﬁc technique Layerwise Relevance Propagation LRP proposed Bach et al 12 The method produces heatmap highlighting pixels responsible predicted class image classiﬁcation task In addition LRP modelspeciﬁc visualization techniques received considerable attention For example use Saliency Maps SM 124 based parameters gradients neural networks common Saliency maps heatmaps help visualize importance different regions visual input Examples works techniques Springenberg et al 127 Shrikumar et al 123 Selvaraju et al 119 Sundararajan et al 129 Gu et al 51 Gu Tresp 5049 A popular posthoc modelagnostic interpretability approach consists generating neighborhood instance By observing blackbox models behavior neighborhood possible characterize relative importance input variables Typically ﬁtting interpretable surrogate model linear regression new instances This kind approach modelagnostic 107 requires knowing blackbox models output neighbor instances The focus explaining model locally depends instead learning mapping Examples models follow modelagnostic approach include Local Interpretable ModelAgnostic Explanations LIME 108 variants The variants LIME attempt address limitations For example NormLime proposed 5 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Ahern et al 2 tackles issue deriving global interpretability local explanations LIMEAleph Rabold et al 105 combines Inductive Logic Programming Aleph LIME provide enriched visual verbal explanations GraphLime Huang et al 62 modelspeciﬁc note vast majority LIME approaches modelagnostic LIME approach tailored graph neural networks Some LIME alternatives address topic neighborhood generation By neighborhood generation mean creat ing set synthetic instances instance explain These instances serve train interpretable local model extract explanation The synthetic instances classiﬁed training process utilizing original blackbox model A variant uses clustering techniques address neighborhood generation KLIME Hall et al 54 This variant LIME partitions training set K clusters ﬁts local models cluster Zafar Khan 140 proposed alternative neighborhood generation scheme LIME called Deterministic Local Interpretable ModelAgnostic Explanations DLIME In DLIME instead random perturbation clustering algorithm combined KNearest Neigh bors discover instances relevant cluster This methods advantage provides stable explanations quality clusters local predictions accuracy depends number samples training dataset Shankaranarayana Runje 120 proposed autoencoderbased local interpretability model ALIME The authors use autoencoder data generator weighting function Instead computing Euclidean distance generated data instance explained ALIME uses distance latent vector space Another popular posthoc interpretability model SHAP SHapley Additive exPlanations 85 SHAP works assigning SHAP value 121 predictor indicate contribution ﬁnal outcome Lundberg Lee 85 SHAP provides guarantees accuracy stability LIME actually subset SHAP lacking properties SHAP consistent approaches posthoc interpretability 85 method subject investigation paper In section review important contributions ﬁeld interpretability prognostics 25 Interpretability prognostics In prognostics interpretability methods starting extensively Some authors proposed model transparent methods prognostics Xie et al 136 explain hard disk failure predictions performing series feature replacement tests determine failure causes Keneni et al 69 propose explainable model decisions Unmanned Aerial Vehicle UAV The explainable model based Sugenotype fuzzy inference Other authors Amruthnath Gupta 6 perform fault diagnosis factor analysis classical techniques In work Amruthnath Gupta 6 Gaussian mixture clustering partition data signiﬁcant groups spectrum analysis diagnose cluster speciﬁc state machine The signiﬁcant features identiﬁed random forest classiﬁcation scheme Recently Lee et al 80 proposed explainable deep learning approach estimate remaining useful lives ro tating machinery The model ﬁrst learns highlevel features autoencoder The features input feedforward neural network estimate remaining useful life Octaveband ﬁltering simpliﬁes model improves interpretability Regarding posthoc XAI modeling prognostics important contributions For example work Zeldam 141 authors work sensor data extracted 24L diesel engine LIME identify critical sensors concerning anomaly detection Seemingly LIME utilized Madhikermi et al 87 explain fault detection heat recovery air handling unit A comparative study interpretability techniques prognostics includes SHAP LIME Jalali et al 65 This work differs compare different interpretability methods XAI instead compare SHAP performance classical preinterpretability methods prognostics More speciﬁcally aim investigate relationship SHAP values metrics monotonicity trendability prognosability 32 Despite importance contributions considerable work ﬁeld eXplainable prognostics XAI help answer pressing industrial questions datadriven prognostics models model giving prediction sensor triggering failure importantly given model prediction trusted With work aim analyze SHAP modeling approach motivate researchers investigate previously reviewed methods apply blackbox models PHM 3 Approach In paper correlate popular prognostics metrics predictor importance SHAP values We start describing utilized prognostics metrics We brieﬂy review SHAP XAI method work We denoising solution datadriven models studied paper 31 Prognostics feature selection metrics Metrics monotonicity trendability prognosability Prognostics Health Management PHM applications 81 compare potential predictors Nevertheless different authors use distinct methods com pute evaluation indicators 81 In work adopt deﬁnitions formalization proposed Coble 6 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Hines 32 Extensive work PHM 32313398109 based concepts proposed authors We explain metric Monotonicity characterizes increasing decreasing trend predictor Formally monotonicity predictor feature deﬁned monotonicity 1 M cid3 cid3 cid3 cid3 cid3 Mcid2 j1 N j 1cid2 cid4 cid5 x jk 1 x jk sgn k1 N j 1 cid3 cid3 cid3 cid3 cid3 1 number units number measurements feature unit j vector measurements feature unit j M N j x j x jk 1 measurement feature unit j time k 1 x jk sgn measurement feature unit j time k sign function With metric measure degree monotonicity signal In PHM predictor shows obvious increasing decreasing trend time accurate Remaining Useful Life RUL prediction results expected The monotonicity range 0 1 A monotonicity 1 means feature strictly monotonic monotonicity zero means feature possible monotonicity usually nondesirable predictor PHM applications Trendability measures extent predictor displays shape group units It measure similarity damage trajectories population units The metric trendability devised runto failure data Formally trendability predictor feature deﬁned cid3 cid3 cid3corrx j xk cid3 j k 1 M 2 trendability min jk M x j xk corr number units vector measurements feature unit j vector measurements feature unit k Pearson correlation function When x j x j different lengths linearly interpolate smallest vector match length longer vector The linear interpolation points x0 y0 x1 y1 given formula y y0 x x0 y1 y0 x1 x0 y0x1 x y1x x0 x1 x0 3 The trendability metric range 0 1 monotonicity metric positively correlated importance predictor This metric measures signals different units resemble Prognosability measures variance predictor End Life EoL set units Formally prognosability predictor feature deﬁned cid6 cid7 prognosability exp std jx jN j mean jx j1 x jN j 4 number units index unit j 1 M number measurements feature unit j vector measurements feature unit j M j N j x j mean j average function units std j standard deviation function units 7 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Prognosability measures degree failure occurs measurement level population units It measures dispersion fault critical level predictor Prognosability range 0 1 When close 1 failure measurements EoL similar close zero indicates failure measurements different The performance predictor expected higher prognosability close 1 Monotonicity trendability metrics widely PHM literature For example Javed et al 66 apply trigono metric functions cumulative transformation vibration signals decomposed Discrete wavelet transform enhance monotonic trendable traits The ﬁnal features selected based monotonicity trendability scores In work Saidi et al 113 monotonicity trendability evaluate performance timedomain predictors derived spectral Kurtosis applied bearing degradation health data She Jia 122 use monotonicity trend ability evaluate wear indicators Other works use monotonicity trendability assess predictors health indexes ﬁtness Ref 61217513026 Prognosability popular important metric authors use PHM For example He et al 57 com pare distinct timedomain health indexes performance indicators monotonicity trendability prognosability Baraldi et al 16 optimize health indicator based properties monotonicity trendability prognosability The indicators monotonicity trendability prognosability Qiu et al 104 assess performance bearing health index 32 SHAP model Machine learning help establish complex occasionally counterintuitive patterns observed tween predictor variables residual life engineering equipment However lack deep understanding machine learning models prevents widespread use Prognostics Health Management PHM community This paper studies recently proposed method eXplainable Artiﬁcial Intelligence XAI SHapley Additive exPlanations SHAP approach evaluating quality produced explanatory trajectories classical prognostics metrics described Section 31 SHAP 85 modelagnostic approach XAI draws foundations game theory 128 The goal SHAP explain prediction f x instance x computing relative contribution feature value speciﬁc cid3 0 1N N number features outcome The explanation function g receives input coalition vector z original instance vector x The coalition vector represents presence absence feature binary format entry 1 means corresponding feature contributes explanation entry 0 means feature considered contribution We explanation function gz cid3 decomposed follows cid3 gz φ0 Ncid2 i1 φi z cid3 φi R N g cid3 z φi number input features x instance vector explanation model coalition vector z decomposition factor cid3 0 1N 5 Several methods match deﬁnition Equation 5 LIME 108 DeepLIFT 123 Layerwise Relevance Propa gation LRP 12 These additive feature attribution methods SHAP attribute effect importance φi cid3 approximates output f x original model As ex predictor feature sum effects gz ample consider Fig 1 The picture displays relationship input vector corresponding prediction Here feature values xi lead prediction f x SHAP referred models work assigning decomposition factor φi feature value aims reﬂect importance feature particular prediction Assuming axioms eﬃciency symmetry dummy additivity previous decomposition shown 85 unique solution known Shapley value proposed Lloyd Shapley 121 cooperative game theory cid8 cid9 cid10 SN S 1 cid11 f S xi f S 6 φi f x 1 N cid2 SP xi x N instance vector number input features x 8 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Fig 1 Overview relationship input instance vector corresponding prediction prognostics model black box machine learning algorithm The inputs lead prediction explicit causal relationships The SHAP model able output decomposition factors SHAP values facilitating understanding importance feature value prediction f φi P S S original prediction model decomposition factor Shapley value set feature values model subset features model include feature value xi number nonzero entries S The Shapley value feature characterizes gain adding feature weighted summed possible feature value combinations feature present Note difference feature value Shapley value The feature value numerical categorical value feature instance Shapley value feature contribution prediction The formula rewritten understood cid11 cid10 marginal contribution coalition weight cid2 7 1 φi f x number coalitions coalitions excluding In simple terms correct interpretation Shapley value contribution feature value difference actual prediction mean prediction Unfortunately calculation Shapley values time consuming approximate solution feasible cases An approximation Equation 6 proposed Štrumbelj Kononenko 128 obtained MonteCarlo sampling The SHAP model assigns feature local prediction approximate Shapley value SHAP value represents change expected model prediction calculating effect observing observing feature Features large absolute SHAP values important The range SHAP values bounded prediction range Note previous description Shapley values account interdependence features However methods calculate approximations Shapley values SHAP values produce imprecise explanations Only recently authors 1 started address kind problematic The utility work provide means measure quality individual SHAP values assuming SHAP method provides reasonably good estimations 33 Denoising generative adversarial network Sensor data typically contaminated noise nonnormally distributed outliers Such signal corrup tion makes problem computing residual life engineering equipment challenging task 125 To ﬁlter data mitigate noise outliers use Generative Adversarial Network GAN Deep generative adversarial neural networks shown outperform methods noise removal especially vision review Ref 48 recently 1dimensional signal processing works Creswell Bharath 34 Casas et al 24 In work adopt standard GAN architecture denoising model We provide brief introduction topic refer readers follow Ref 46 details In broad terms GAN consists neural networks compete reach learning solution In case training GAN takes input pair synthetic sensor signals synthetic signal subject noise signal artifacts The generator network learns reduce noise minimizing difference recovered signal noisefree signal The loss function generator function measures difference signals discriminator neural network After training phase GAN generator receive new set nonsynthetic signals denoise A challenge work generate synthetic pairs signals noise GANs training phase In work train GAN generate synthetic sensor data according methodology Baptista et al 13 We refer reader work details The result synthetic data generation process col lection synthetic trajectories These synthetic data sole purpose training GAN The important training hyperparameters GAN outlined Table 1 9 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 1 Principal hyperparameters Denoising Generative Adversarial Network Parameter 2D representation width 2D representation height 2D number channels Base number ﬁlters Kernel size Strides Dropout rate Learning rate Max epochs Regularization L1 lambda Value 20 20 1 64 3 3 2 2 05 2e4 2000 100 Fig 2 Overview interpretability process prognostics model SHAP approach It important note sensor data differ image data Each sensor trajectory unit 1dimensional timeseries data In contrast images 2dimensional representations given point time For reasons use traditional convolutional GAN signals transformed 2D representations fed network architecture A simple reshape operation accomplishes transformation This operation transforms 1D vector representation original signal 2D image representation It expected conﬁguration operation setting image width height inﬂuences results signiﬁcantly Other works followed representation choice dealing onedimensional time series 3683 34 Remaining useful life estimation The objective prognostic model estimate predict Remaining Useful Life RUL engineering equipment accurately possible The models focus typically causality explanation interpretability accuracy estimation How prognostics models developed different explanatory methods SHAP SHAP investigates causal relationships prognostic models input output Fig 2 depicts ﬂow obtain local explanation prediction The SHAP model receives input observation instance resulting prediction This model tries establish reasonable connection input output simpliﬁed way transparent complex original prognostics algorithm The RUL outcome prognostics model corresponding explanation outcome SHAP model In work study prognostics approaches increasing level complexity Linear Regression LR MultiLayer Perceptron MLP Echo State Network ESN We brieﬂy techniques Linear regression LR straightforward machine learning algorithm MultiLayer Perceptron MLP Feed Forward Neural Network FFNN classical neural network An MLP composed layers In work simplicity use single layer network A complex neural network Echo State Network ESN 64 This network Recurrent Neural Network feedback loops It Reservoir Computing technique 64 particularity reservoir sparsely connected The ESN shown ﬁtted time series forecasting 30137 It promising approach prognostics dynamic properties generalization training speed Some works PHM approach positive results For example Morando et al 95 apply ESN Remaining Useful Life RUL estimation industrial fuel cells Fink et al 40 combine ESN Conditional Restricted Boltzmann Machines predict railway speed restrictions Wang et al 134 estimate health state lithium ion batteries ESN Rigamonti et al 110 use single ESN Rigamonti et al 109 ensemble optimized ESNs RUL estimation The models optimized training process The ESN optimized Differential Evolution DE work Rigamonti et al 110 Further details ESN conﬁguration previous work 13 10 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 2 Nonﬂat predictors features CMAPSS data Predictor Description T24 T30 T50 P30 Nf Nc Ps30 phi NRf NRc BPR htBleed W31 W32 Total temperature LPC outlet Total temperature HPC outlet Total temperature LPT outlet Total pressure HPC outlet Physical fan speed Physical core speed Static pressure HPC outlet Ratio fuel ﬂow Ps30 Corrected fan speed Corrected core speed Bypass Ratio Bleed Enthalpy HPT coolant bleed LPT coolant bleed Units R R R psia rpm rpm psia ppspsi rpm rpm lbms lbms 4 Methodology This section explains case study hypotheses paper metrics assess We refer indicators evaluate performance Remaining Useful Life RUL estimation 41 Case study The data case study Commercial Modular AeroPropulsion System Simulation CMAPSS veloped NASA Glenn Research Center 41 CMAPSS simulator mimics operation large highbypass ratio turbofan engine similar GE90 The CMAPSS data consists collection measurements taken cruise Each degrada tion trajectory characterized series predictors features including sensor operational variables changing time nominal condition failure The data described Saxena et al 117 This paper studies CMAPSS training dataset 1 comprises simulated data 100 jet engines The recorded useful life ranged 128 362 cycles We selected dataset simplest including operating regime fault mode In CMAPSS engine unit characterized 21 prognostics sensors additional indicators Altitude Mach Number Throttle Resolver Angle From 21 available features selected 14 features steady state signals features nonconstant value Table 2 describes selected feature 42 Metrics hypotheses We advance hypotheses test CMAPSS data The ﬁrst hypothesis concerns SHAP values change time unit H1 SHAP values tend exhibit monotonic behavior We use monotonicity metric Equation 1 assess hypothesis The second hypothesis concerns SHAP values change time population units H2 SHAP values tend exhibit trendability behavior We use trendability metric Equation 2 assess hypothesis We investigate prognosability We use prognosability metric Equation 4 assess following hypothesis H3 SHAP values tend exhibit prognosability behavior We accept hypotheses instances behavior perfectly monotonic trendable prognos able It accepted expected features exhibit traits Therefore aiming prove general SHAP trajectories tend exhibit properties In order investigate hypotheses apply following methodology Preprocessing The data preprocessed denoising Generative Adversarial Network GAN Prediction A set randomly selected units 40 total units train different models LR MLP ESN The remaining units conﬁguration validation testing 10 10 40 units Interpretability A SHAP model built prognostics models LR MLP ESN A set SHAP values feature predictor generated input instance 11 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 3 RUL estimation performance CMAPSS ﬁrst dataset Linear Regression MultiLayer Perceptron EchoState Network PHM08 Score 205525103 1207723104 829479607 Accuracy 248118 338525 267232 FPR 369748 373387 368179 FNR 382137 288263 364873 MAE 304914 263717 29729 RMSE 395332 359228 385442 MAPE 823659 464156 6558169 Validation The monotonicity trendability prognosability SHAP values evaluated according Equations 1 2 4 respectively We rerun experience times K10 retrieve appropriate statistics results We interested correlating features predictors dimensions monotonicity trendability prog nosability SHAP values To effect advance hypotheses H4 The monotonicity SHAP values predictor correlated predictors monotonicity H5 The trendability SHAP values predictor correlated predictors trendability H6 The prognosability SHAP values predictor correlated predictors prognosability Correlation measured Spearman rank correlation coeﬃcient Spearmans rank correlation coeﬃcient Spear mans ρ statistical measure nonparametric requirement normality correlation It aims evaluating relationship variables described monotonic function Several attempts translate Spearmans correlation coeﬃcient descriptive labels weak moderate strong relationship actually formal consensus 118 Nevertheless correlation 050 authors consider moderate relationship We use correlation cutoff value discuss previous hypotheses We stating H4 H6 quality SHAP trajectories directly related feature quality For example feature changes behavior nonmonotonic way expected marginal contribution feature prognostics ﬂuctuate Put differently feature quality explanations related feature expected trusted quality low These hypotheses imply SHAP values combined classical prognostics metrics evaluate predictors signiﬁcance importance 43 Evaluation RUL estimation performance We compute Remaining Useful Life RUL Linear Regression LR MultiLayer Perceptron MLP Echo State Network ESN The following metrics evaluate model performance Scoring function PHM Challenge 2008 S Accuracy A False Positive Rate FPR False Negative Rate FNR Mean Average Error MAE Root Mean Squared Error RMSE Mean Absolute Percentage Error MAPE Saxena et al 115 Ramasso Saxena 106 provide metrics 5 Results In section present discuss results experiments We discuss obtained scores monotonicity trendability prognosability SHAP values We examine rankings predictor importance produced scores 51 Remaining useful life performance evaluation The results evaluating increasingly complex prognostics models presented Table 3 We average results runs crossvalidation method corresponding standard deviation As shown clear winning model different approaches ranked differently according utilized evaluation metric The best performing model regards averaging metrics MAE RMSE MAPE MultiLayer Perceptron MLP The MAE RMSE MAPE results MLP lowest tested models In regards PHM08 metric MLP model worse performance follows tendency model overestimate instead underestimate Since metric penalizes late predictions late predictions failure MLP scores low respect Importantly model scored best PHM08 Score EchoState Network This metric selected original CMAPSS competition evaluate quality prognostics exercise The interesting trait metric penalizes late predictions early predictions 52 Monotonicity SHAP values The evolution SHAP values time different features predictors shown Figs 4 5 6 Each Figure corresponds model Regression LR Fig 4 MultiLayer Perceptron MLP Fig 5 EchoState Network 12 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Fig 3 Monotonicity trendability prognosability trajectories formed SHAP values different predictors different models Linear Regression LR MultiLayer Perceptron MLP Echo State Network ESN ESN Fig 6 Each plot represents SHAP values feature engine We selected presented features T24 P30 Nc Nf features correspond representative cases different trajectories formed SHAP values The aim shapes SHAP trajectories depend feature model Interestingly time goes observe monotonic trends signiﬁcant number predictors studied models LR MLP ESN The performance models Remaining Useful Life RUL estimation presented Table 3 A quantitative analysis trajectories formed SHAP values resulted Fig 3 Each plot Fig 3 shows monotonicity trend ability prognosability scores yaxis SHAP value trajectories different predictors xaxis considered models LR MLP ESN As depicted Fig 3a predictors showed marked tendency score high 50 monotonicity mod els Only 4 42 predictors 952 scores 50 This property SHAP values important prognostics means SHAP values provide consistent information equipments life Had values ﬂuctuated clear trend sign explanations coherentconnected time It desirable signiﬁcance contribution predictor changes time slow manner equipments end life Comparing monotonicity shown SHAP values different models Fig 3a Linear Regression LR consistently presents highest scores This result examined plots Fig 4 illustrate SHAP values LR exhibit monotonic trends time In LR Nf predictor signals increasingdecreasing time functions SHAP assigns Nf zero contribution LR model time This nonsigniﬁcance attributed SHAP Nf predictor LR model explained low monotonicity trendability original features 13 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Fig 4 Evolution SHAP values time different predictors unit Linear Regression LR Fig 5 Evolution SHAP values time different predictors unit MultiLayer Perceptron MLP Table 4 From predictors Nf feature lowest trendability Seemingly analyzing LR model T24 Nc NRc experience low SHAP monotonicity Fig 3a scoring low original predictor trendability Table 4 The MultiLayer Perceptron MLP complex model Linear Regression LR signals predictors Nf T24 Nc NRc SHAP monotonic As shown Figs 5 3a monotonicity MLP SHAP values high LR case Note SHAP values represent impact feature outcome Since SHAP values different predictors interfere predictors SHAP values change direction time This 14 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 4 Monotonicity trendability prognosability selected predictors features CMAPSS data Scores average standard deviation shown percentages Predictor T24 T30 T50 P30 Nf Nc Ps30 phi NRf NRc BPR htBleed W31 W32 Monotonicity 814816 795411 881811 809805 734232 50629 692214 953409 800518 681631 816207 850908 924308 940915 Trendability 681125 971104 964111 96651 30177 583107 887515 974702 77367 733148 984404 95707 962305 94731 Prognosability 926407 914706 94405 881309 68432 32693 929405 888706 693314 305425 941503 913206 949605 943805 Fig 6 Evolution SHAP values time different predictors unit Echo State Network ESN lack trendability necessarily alarming desirable understandable strictly monotonic SHAP values The complex model examined Echo State Network ESN The SHAP values ESN monotonicity scores comparable MultiLayer Perceptron MLP Fig 3a Nevertheless observing SHAP values trajectories Fig 6 seen fewer changes direction This lack changes direction explained fact ESN Recurrent Neural Network RNN predictions linked time The ESN model produces noise SHAP trajectories compared MLP The increased level noise ESNs SHAP values probably increased complexity model For example linear regression model weighted sum variables Given simplicity linear regression output likely ﬂuctuate neural network As result computed SHAP values contributions output oscillatory simpler models linear regression Given SHAP monotonicity models high reinforces notion H1 H1 SHAP values tend exhibit monotonic behavior We interested testing SHAP monotonic ranking predictors different models similar To effect compared predictor rankings Spearman rank correlation coeﬃcient ρ Table 5 shows 15 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 5 Spearman rank correlation analysis monotonicity scores obtained SHAP values different models Linear Regression LR MultiLayer Percep tron MLP Echo State Network ESN Monotonicity Model LR MLP ESN LR 070 089 MLP 070 080 ESN 089 080 Monotonicity Table 6 Spearman rank correlation analysis trendability scores obtained SHAP values different models Linear Regression LR MultiLayer Percep tron MLP Echo State Network ESN Trendability Model LR MLP ESN LR 060 078 MLP 060 069 ESN 078 069 Trendability rankings based SHAP monotonicity correlated different models As presented models correlated ρ 070 pvalue1 001 In particular LR model ESN showed highest correlation These results important indicate rankings signiﬁcant features according SHAP monotonicity similar regardless model To certain extent outcome attests integrity monotonicity rankings produced SHAP 53 Trendability SHAP values Comparing trendability Fig 3b shown trajectories SHAP values MLP lower scores ESN LR The model seven predictors 50 trendability score In contrast ESN ﬁve predictors LR predictors 50 trendability score The desirable outcome high trendability score High SHAP trendability means SHAP values tend functional form different units Traditionally trendability expected good features This result suggests SHAP values reﬂect damage degradation equipments life They perform prediction SHAP values calculated forecasting expose damage progression equipment elicit better understanding equipments actual health state moment In general seen 14 predictors 50 mark majority predictors 28 67 predictors score 50 threshold high trendability scores 80 Given SHAP trendability models high reinforces notion H2 H2 SHAP values tend exhibit trendability behavior As case SHAP monotonicity interested analyzing different models SHAP trendability rankings correlated To end compared predictor rankings Spearman Rank correlation coeﬃcient ρ Table 6 shows rankings based SHAP trendability correlated different models Even correlations high SHAP monotonicity models correlated reasonably ρ 060 pvalue 001 These results important indicate rankings signiﬁcant features according SHAP trendability similar different models This result attests integrity rankings generated SHAP prognostics 54 Prognosability SHAP values Concerning prognosability SHAP values Fig 3c predictors exhibited high prognosability models This result means variance SHAP values end life low population engine units This outcome expected result dealing CMAPSS dataset 1 concerns failure mode A predictors impact end life likely different units It interesting check 1 In null hypothesis signiﬁcance testing pvalue likelihood obtaining results conﬁrming null hypothesis 16 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Table 7 Spearman rank correlation analysis prognosability scores obtained SHAP values different models Linear Regression LR MultiLayer Percep tron MLP Echo State Network ESN Prognosability Model LR MLP ESN LR 056 078 MLP 056 069 ESN 078 069 Prognosability Table 8 Spearman Rank correlation analysis relationship monotonicity Mon trendability Tren prognosability Prog rankings SHAP values classical monotonicity trendability prognosability rankings ρMon ρTrend ρProg Linear Regression LR MultiLayer Perceptron MLP Echo State Network ESN 093 058 071 083 052 065 098 058 094 results change CMAPSS datasets failure modes With results conﬁrm H3 notion H3 SHAP values tend exhibit prognosability behavior We note predictors low SHAP prognosability LR MLP ESN These predictors T24 Nf Nc NRc This low SHAP prognosability linked original predictors low trendability scores Table 4 As SHAP monotonicity SHAP trendability studied SHAP importance rankings produced prognosability indicator correlated We compared rankings Spearman rank correlation coeﬃcient ρ Table 7 shows rankings based SHAP prognosability correlated different models ρ 056 pvalue 001 This result implies SHAP ranks features according SHAP prognosability similar way considered models LR MLP ESN This ﬁnding validates utility generality importance rankings derived SHAP prognostics 55 Measuring predictor importance SHAP To investigate hypothesis H4 H5 H6 Spearman rank correlation analysis Fisher transformation average results experiments The analysis similar Tables 5 6 7 case correlate importance rankings produced originals predictors importance rankings produced SHAP values The goal check different models similar SHAP rankings analyze signiﬁcance assigned predictor classical metrics SHAP similar signiﬁcance computed classical metrics original predictors Results summarized Table 8 As seen Table 8 applying classical metrics SHAP values linear regression LR Echo State Network ESN produced rankings correlated applying metrics directly predictors The MultiLayer Perceptron MLP slightly worse results respect trendability metric monotonicity prognosability indicators acceptable correlation scores These results reinforce notions H4 The monotonicity SHAP values predictor correlated predictors monotonicity H5 The trendability SHAP values predictor correlated predictors trendability H6 The prognosability SHAP values predictor correlated predictors prognosability These results important indicate compute classical metrics monotonicity trendability prognosability SHAP values certainty indicate best features available predictor set 6 Conclusion Prognostics approaches based machine learning typically perceived blackbox models severely depen dent quality training data The application interpretability methods prognostics algorithms way engage complex questions transparency safety ethics Discussion debate explainability 17 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 Prognostics Health Management PHM models bring additional information different engineering ﬁelds aerospace energy bringing tacit knowledge different sensor features contribute estimations life cycle different equipment Acquiring knowledge essential step moving interpretability explainability engineering Monotonicity trendability prognosability 32 important metrics evaluate health monitoring trajec tories In work applied metrics evaluate quality SHAP values In prognostics SHAP values form explanatory trajectories engineering unit If explainable trajectory monotonic means associated sensor signal provides increasingly important information start end life equipment If explain able trajectory trendable means importance sensor feature consistent lifetimes different engineering units If explainable trajectory prognosable importance sensor feature end life equipment different units All qualities desirable SHAP values trajectories prognostics applications The goal work measure effectiveness quality interpretability temporal prognostics sequence resorting metrics In paper investigate explanations produced SHapley Additive exPlanations SHAP eXplainable Artiﬁcial Intelligence XAI posthoc method classiﬁed according monotonicity trendability prognosability This exercise carried models increasing complexity Linear Regression LR MultiLayer perceptron MLP Echo State Network ESN The results study indicate SHAP values form monotonic trajectories exhibit trendability prognos ability traits These ﬁndings important outcomes mean trust SHAP values The SHAP variables added value bringing additional information prognostics exercise explored future A close examination SHAP values help answer questions RUL estimation changed instant important factor given RUL forecast given time We studied models study increasing complexity We showed complex models best performance Remaining Useful Life RUL estimation Concretely Linear Regression LR worse performance MultiLayer Perceptron MLP Echo State Network ESN However Linear Regression LR best SHAP monotonicity scores This ﬁnding raises question suﬃcient use simple model combination SHAP identify best predictors prognostics application It relevance study inﬂuence preprocessing steps prognostics denoising monotonicity constraints feature selection health stage classiﬁcation interpretability result SHAP XAI method Theoretically apply SHAP understand physicsbased models SHAP posthoc method applied kind RUL forecasting method It interesting know results observed physicsbased approaches future work It interesting study metrics literature 81 understand applied SHAP values Another direction future work develop new indicators SHAP context prognostics For example interesting explore indicators feature importance instead analyzing features independently consider prognostics features interrelated Also feature importance change life equipment Deriving indicators capable measuring feature importance time topic fully explored Declaration competing The authors declare known competing ﬁnancial interests personal relationships appeared inﬂuence work reported paper References 1 K Aas M Jullum A Løland Explaining individual predictions features dependent accurate approximations Shapley values Artif Intell 298 2021 103502 httpsdoi org 10 1016 j artint 2021103502 2 I Ahern A Noack L GuzmanNateras D Dou B Li J Huan Normlime new feature importance metric explaining deep neural networks preprint arXiv1909 04200 2019 3 M AlShedivat A Dubey EP Xing Contextual explanation networks preprint arXiv1705 10301 2017 4 G Alain Y Bengio Understanding intermediate layers linear classiﬁer probes preprint arXiv1610 01644 2016 5 K Alvehag L Soder A reliability model distribution systems incorporating seasonal variations severe weather IEEE Trans Power Deliv 26 2011 910919 httpsdoi org 10 1109 tpwrd 2010 2090363 6 N Amruthnath T Gupta Factor analysis fault diagnostics random forest preprint arXiv1904 13366 2019 7 R Andrews J Diederich AB Tickle Survey critique techniques extracting rules trained artiﬁcial neural networks KnowlBased Syst 8 1995 373389 8 AB Arrieta N DíazRodríguez JD Ser A Bennetot S Tabik A Barbado S Garcia S GilLopez D Molina R Benjamins R Chatila F Herrera Explainable artiﬁcial intelligence XAI concepts taxonomies opportunities challenges responsible AI Inf Fusion 58 2020 82115 httpsdoi org 10 1016 j inffus 2019 12 012 9 AV Assche H Blockeel Seeing forest trees Learning comprehensible model ensemble Machine Learning ECML 2007 Springer Berlin Heidelberg 2007 pp 418429 10 S Assilian Artiﬁcial intelligence control real dynamic systems PhD thesis 1974 11 T Aven E Zio Eds Knowledge Risk Assessment Management John Wiley Sons Ltd 2018 12 S Bach A Binder G Montavon F Klauschen KR Müller W Samek On pixelwise explanations nonlinear classiﬁer decisions layerwise relevance propagation PLoS ONE 10 2015 e0130140 httpsdoi org 10 1371 journal pone 0130140 18 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 13 ML Baptista EM Henriques K Goebel More effective prognostics elbow point detection deep learning Mech Syst Signal Process 146 2021 106987 httpsdoi org 10 1016 j ymssp 2020 106987 14 N Barakat J Diederich Eclectic ruleextraction support vector machines Int J Comput Intell 2 2005 5962 15 NH Barakat AP Bradley Rule extraction support vector machines sequential covering approach IEEE Trans Knowl Data Eng 19 2007 16 P Baraldi G Bonfanti E Zio Differential evolutionbased multiobjective optimization deﬁnition health indicator fault diagnostics 17 T Benkedjouh K Medjaher N Zerhouni S Rechak Fault prognostic bearings support vector data description 2012 IEEE Conference 729741 httpsdoi org 10 1109 tkde 2007190610 prognostics Mech Syst Signal Process 102 2018 382400 Prognostics Health Management IEEE 2012 18 A Bennetot JL Laurent R Chatila N DíazRodríguez Towards explainable neuralsymbolic visual reasoning NeSy Workshop IJCAI 2019 19 O Biran C Cotton Explanation justiﬁcation machine learning survey IJCAI17 Workshop Explainable AI XAI 2017 20 W Brendel M Bethge Approximating CNNs bagoflocalfeatures models works surprisingly imagenet preprint arXiv1904 00760 2019 21 F Cannarile P Baraldi M Compare D Borghi L Capelli M Cocconcelli A Lahrache E Zio An unsupervised clustering method assessing degradation state cutting tools packaging industry Safety Reliability Theory Applications CRC Press 2017 22 D Card M Zhang NA Smith Deep weighted averaging classiﬁers Proceedings Conference Fairness Accountability Transparency 23 DV Carvalho EM Pereira JS Cardoso Machine learning interpretability survey methods metrics Electronics 8 2019 832 httpsdoi org FAT19 ACM Press 2019 10 3390 electronics8080832 24 L Casas A Klimmek N Navab V Belagiannis Adversarial signal denoising encoderdecoder networks preprint arXiv1812 08555 2018 25 C Chen M Pecht Prognostics lithiumion batteries modelbased datadriven methods Proceedings IEEE 2012 Prognostics System Health Management Conference PHM2012 Beijing IEEE 2012 26 C Chen T Xu G Wang B Li Railway turnout RUL prediction based feature fusion genetic programming Measurement 151 2020 27 J Chen D Zhou C Lyu C Lu An approach fault diagnosis rotating machinery based feature reconstruction LCD tSNE 28 R Chimatapu H Hagras A Starkey G Owusu Explainable AI fuzzy logic systems Theory Practice Natural Computing Springer 107162 httpsdoi org 10 1016 j measurement 2019 107162 Vibroengineering PROCEDIA vol 11 2017 pp 4045 International Publishing 2018 pp 320 29 K Cho B van Merrienboer D Bahdanau Y Bengio On properties neural machine translation encoderdecoder approaches Proceedings SSST8 Eighth Workshop Syntax Semantics Structure Statistical Translation Association Computational Linguistics 2014 30 N Chouikhi B Ammar N Rokbani AM Alimi PSObased analysis echo state network parameters time series forecasting Appl Soft Comput 31 J Coble An Automated Approach Fusing Data Sources Identify Optimal Prognostic Parameters PhD thesis Dissertation University Tennessee 32 J Coble JW Hines Identifying optimal prognostic parameters data genetic algorithms approach Annual Conference Prognostics 33 J Coble JW Hines Identifying suitable degradation parameters individualbased prognostics Diagnostics Prognostics Engineering 55 2017 211225 Knoxville TN 2010 Health Management Society 2009 Systems IGI Global 2013 pp 135150 34 A Creswell AA Bharath Denoising adversarial autoencoders IEEE Trans Neural Netw Learn Syst 30 2018 968984 35 M Daigle B Saha K Goebel A comparison ﬁlterbased approaches modelbased prognostics 2012 IEEE Aerospace Conference IEEE 2012 36 J Debayle N Hatami Y Gavet Classiﬁcation timeseries images deep convolutional neural networks J Zhou P Radeva D Nikolaev A Verikas Eds Tenth International Conference Machine Vision ICMV 2017 SPIE 2018 37 H Dinsdag H Jaeger A tutorial training recurrent neural networks covering BPTT RTRL EKF echo state network Technical Report German National Research Center Information Technology 2001 38 M ElKoujok R Gouriveau N Zerhouni A neurofuzzy self built prognostics way ensure good prediction accuracy balancing complexity generalization 2010 Prognostics System Health Management Conference IEEE 2010 39 JM Fellous G Sapiro A Rossi H Mayberg M Ferrante Explainable artiﬁcial intelligence neuroscience behavioral neurostimulation Front Neurosci 13 2019 httpsdoi org 10 3389 fnins 2019 01346 40 O Fink E Zio U Weidmann Predicting time series railway speed restrictions timedependent machine learning techniques Expert Syst Appl 40 2013 60336040 41 DK Frederick JA DeCastro JS Litt Users Guide Commercial Modular AeroPropulsion System Simulation CMAPSS Technical Report 2007 42 AA Freitas Comprehensible classiﬁcation models ACM SIGKDD Explor Newsl 15 2014 110 httpsdoi org 10 1145 2594473 2594475 43 SA Friedler CD Roy C Scheidegger D Slack Assessing local interpretability machine learning models preprint arXiv1902 03501 2019 44 K Goebel MJ Daigle A Saxena I Roychoudhury S Sankararaman JR Celaya Prognostics science making predictions 2017 45 K Goebel B Saha A Saxena A comparison datadriven techniques prognostics 62nd Meeting Society Machinery Failure 46 I Goodfellow J PougetAbadie M Mirza B Xu D WardeFarley S Ozair A Courville Y Bengio Generative adversarial nets Advances Neural Prevention Technology MFPT 2008 pp 119131 Information Processing Systems 2014 pp 26722680 doi org 10 1609 aimag v38i3 2741 httpsdoi org 10 1016 j inffus 2019 09 003 47 B Goodman S Flaxman European union regulations algorithmic decisionmaking right explanation AI Mag 38 2017 5057 https 48 B Goyal A Dogra S Agrawal B Sohi A Sharma Image denoising review classical stateoftheart approaches Inf Fusion 55 2020 220244 49 J Gu V Tresp Saliency methods explaining adversarial attacks preprint arXiv1908 08413 2019 50 J Gu V Tresp Semantics global local interpretation deep neural networks preprint arXiv1910 09085 2019 51 J Gu Y Yang V Tresp Understanding individual decisions CNNs contrastive backpropagation Computer Vision ACCV 2018 Springer International Publishing 2019 pp 119134 52 D Gunning D Aha DARPAs explainable artiﬁcial intelligence XAI program AI Mag 40 2019 4458 httpsdoi org 10 1609 aimag v40i2 2850 53 BD Haig Exploratory Data Analysis Oxford University Press 2018 54 P Hall N Gill M Kurka W Phan Machine learning interpretability H2O driverless AI H2Oai httpdocs h2o ai driverless ai latest stable docs 55 D He N Hu M Wang Study realtime fault injection simulation mechanicelectronichydraulic control based AMESim LabVIEW 2014 Prognostics System Health Management Conference PHM2014 Hunan IEEE 2014 56 W He Y He B Li C Zhang Analog circuit fault diagnosis joint crosswavelet singular entropy parametric tSNE Entropy 20 2018 604 booklets MLIBooklet pdf 2017 httpsdoi org 10 3390 e20080604 57 W He Q Miao M Azarian M Pecht Health monitoring cooling fan bearings based wavelet ﬁlter Mech Syst Signal Process 64 2015 149161 19 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 58 M Hind D Wei M Campbell NCF Codella A Dhurandhar A Mojsilovi c KN Ramamurthy KR Varshney TED teaching AI explain decisions Proceedings 2019 AAAIACM Conference AI Ethics Society ACM 2019 59 S Hochreiter J Schmidhuber Long shortterm memory Neural Comput 9 1997 17351780 httpsdoi org 10 1162 neco 19979 8 1735 60 SR Hong J Hullman E Bertini Human factors model interpretability industry practices challenges needs Proceedings ACM 61 Y Hu T Palmé O Fink Deep health indicator extraction method based autoencoders extreme learning machines PHM 2016 Denver 62 Q Huang M Yamada Y Tian D Singh D Yin Y Chang Graphlime local interpretable model explanations graph neural networks preprint HumanComputer Interaction vol 4 2020 pp 126 USA 36 October 2016 PMH Society 2016 pp 446452 arXiv200106216 2020 63 S Jacklin J Schumann P Gupta M Richard K Guenther F Soares Development advanced veriﬁcation validation procedures tools certiﬁcation learning systems aerospace applications InfotechAerospace American Institute Aeronautics Astronautics 2005 64 H Jaeger The Echo State Approach Analyzing Training Recurrent Networks Technical Report German National Research Center Information 65 A Jalali A Schindler B Haslhofer A Rauber Machine learning interpretability techniques outage prediction comparative study PHM Society Technology 2001 European Conference 2020 p 10 66 K Javed R Gouriveau N Zerhouni P Nectoux Enabling health monitoring approach based vibration data accurate prognostics IEEE Trans Ind Electron 62 2015 647656 httpsdoi org 10 1109 tie 2014 2327917 67 MJ Johnson DK Duvenaud A Wiltschko RP Adams SR Datta Composing graphical models neural networks structured representations fast inference Advances Neural Information Processing Systems 2016 pp 29462954 68 M Karl M Soelch J Bayer P Van der Smagt Deep variational Bayes ﬁlters unsupervised learning state space models raw data preprint arXiv1605 06432 2016 69 BM Keneni D Kaur AA Bataineh VK Devabhaktuni AY Javaid JD Zaientz RP Marinier Evolving rulebased explainable artiﬁcial intelligence unmanned aerial vehicles IEEE Access 7 2019 1700117016 httpsdoi org 10 1109 access 2019 2893141 70 B Kim C Rudin JA Shah The Bayesian case model generative approach casebased reasoning prototype classiﬁcation Advances 71 NH Kim D An JH Choi Study attributes prognostics models Prognostics Health Management Engineering Systems An Introduction Neural Information Processing Systems 2014 pp 19521960 Springer International Publishing 2016 pp 243280 72 RG Krishnan U Shalit D Sontag Deep Kalman ﬁlters preprint arXiv151105121 2015 73 J Kukaˇcka V Golkov D Cremers Regularization deep learning taxonomy preprint arXiv1710 10686 2017 74 CS Kulkarni M Daigle GS Gorospe K Goebel Application modelbased prognostics framework pneumatic valves cryogenic testbed AIAA Infotech Aerospace American Institute Aeronautics Astronautics 2015 75 P Kundu AK Darpe MS Kulkarni A correlation coeﬃcient based vibration indicator detecting natural pitting progression spur gears Mech Syst Signal Process 129 2019 741763 httpsdoi org 10 1016 j ymssp 2019 04 058 76 H Kuwajima M Tanaka M Okutomi Improving transparency deep neural inference process Prog Artif Intell 8 2019 273285 httpsdoi org 10 1007 s13748 019 00179 x 77 P Lall T Thomas PCA ICA based prognostic health monitoring electronic assemblies subjected simultaneous temperaturevibration loads ASME 2017 International Technical Conference Exhibition Packaging Integration Electronic Photonic Microsystems American Society Mechanical Engineers 2017 78 F Lasheras P Nieto F Cos Juez R Bayón V Suárez A hybrid PCACARTMARSbased prognostic approach remaining useful life aircraft engines Sensors 15 2015 70627083 httpsdoi org 10 3390 s150307062 79 Y LeCun Y Bengio G Hinton Deep learning Nature 521 2015 436444 httpsdoi org 10 1038 nature14539 80 N Lee MH Azarian MG Pecht An explainable deep learningbased prognostic model rotating machinery preprint arXiv2004 13608 2020 81 Y Lei N Li L Guo N Li T Yan J Lin Machinery health prognostics systematic review data acquisition RUL prediction Mech Syst Signal Process 104 2018 799834 httpsdoi org 10 1016 j ymssp 201711016 82 X Li Remaining useful life prediction bearings fuzzy multimodal extreme learning regression 2017 International Conference Sensing Diagnostics Prognostics Control SDPC IEEE 2017 111 httpsdoi org 10 1016 j ress 201711021 83 X Li Q Ding JQ Sun Remaining useful life estimation prognostics deep convolution neural networks Reliab Eng Syst Saf 172 2018 84 ZC Lipton The mythos model interpretability Commun ACM 61 2018 3643 httpsdoi org 10 1145 3233231 85 SM Lundberg SI Lee A uniﬁed approach interpreting model predictions I Guyon UV Luxburg S Bengio H Wallach R Fergus S Vish wanathan R Garnett Eds Advances Neural Information Processing Systems vol 30 Curran Associates Inc 2017 pp 47654774 http papers nips cc paper 7062 uniﬁed approach interpreting model predictions pdf 86 Lvd Maaten G Hinton Visualizing data tSNE J Mach Learn Res 9 2008 25792605 87 M Madhikermi AK Malhi K Främling Explainable artiﬁcial intelligence based heat recycler fault detection air handling unit Lecture Notes Computer Science Springer International Publishing 2019 pp 110125 88 E Mamdani S Assilian An experiment linguistic synthesis fuzzy logic controller Int J ManMach Stud 7 1975 113 httpsdoi org 10 89 D Martens B Baesens TV Gestel J Vanthienen Comprehensible credit scoring models rule extraction support vector machines SSRN 90 DA Melis T Jaakkola Towards robust interpretability selfexplaining neural networks Advances Neural Information Processing Systems 1016 s0020 737375 80002 2 Electron J 2006 httpsdoi org 10 2139 ssrn 878283 2018 pp 77757784 007 doi org 10 1109 tvcg 2018 2864812 2018 2535 httpsdoi org 10 1016 j ress 201711020 IEEE Industrial Electronics Society IEEE 2013 91 C Mencar Interpretability fuzzy systems Fuzzy Logic Applications Springer International Publishing 2013 pp 2235 92 T Miller Explanation artiﬁcial intelligence insights social sciences Artif Intell 267 2019 138 httpsdoi org 10 1016 j artint 2018 07 93 Y Ming H Qu E Bertini RuleMatrix visualizing understanding classiﬁers rules IEEE Trans Vis Comput Graph 25 2019 342352 https 94 M Mishra J Martinsson M Rantatalo K Goebel Bayesian hierarchical modelbased prognostics lithiumion batteries Reliab Eng Syst Saf 172 95 S Morando S Jemei R Gouriveau N Zerhouni D Hissel Fuel Cells prognostics echo state network IECON 2013 39th Annual Conference 96 A Mosallam K Medjaher N Zerhouni Nonparametric time series modelling industrial prognostics health management Int J Adv Manuf Technol 69 2013 16851699 httpsdoi org 10 1007 s00170 013 5065 z 97 M Naseri P Baraldi M Compare E Zio Availability assessment oil gas processing plants operating dynamic arctic weather conditions Reliab Eng Syst Saf 152 2016 6682 httpsdoi org 10 1016 j ress 2016 03 004 20 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 98 SA Niknam J Kobza JW Hines Techniques trend analysis degradationbased prognostics Int J Adv Manuf Technol 88 2016 24292441 httpsdoi org 10 1007 s00170 016 8909 5 99 N Papernot P McDaniel Deep knearest neighbors conﬁdent interpretable robust deep learning preprint arXiv1803 04765 2018 100 L Peng Y Huang Survival analysis temporal covariate effects Biometrika 94 2007 719733 httpsdoi org 10 1093 biomet asm058 101 Y Peng H Wang J Wang D Liu X Peng A modiﬁed echo state network based remaining useful life estimation approach 2012 IEEE Conference Prognostics Health Management IEEE 2012 102 A Popov W Fink A Hess PHM astronauts new application Annual Conference Prognostics Health Management Society 2013 103 S Pouyanfar S Sadiq Y Yan H Tian Y Tao MP Reyes ML Shyu SC Chen SS Iyengar A survey deep learning ACM Comput Surv 51 2019 pp 566572 136 httpsdoi org 10 1145 3234150 104 G Qiu Y Gu J Chen Selective health indicator bearings ensemble remaining useful life prediction genetic algorithm Weibull propor tional hazards model Measurement 150 2020 107097 105 J Rabold H Deininger M Siebers U Schmid Enriching visual verbal explanations relational concepts combining LIME aleph Machine Learning Knowledge Discovery Databases Springer International Publishing 2020 pp 180192 106 E Ramasso A Saxena Performance benchmarking analysis prognostic methods cmapss datasets 2014 107 MT Ribeiro S Singh C Guestrin Modelagnostic interpretability machine learning preprint arXiv1606 05386 2016 9195 108 MT Ribeiro S Singh C Guestrin Why I trust explaining predictions classiﬁer Proceedings 22nd ACM SIGKDD International Conference Knowledge Discovery Data Mining ACM 2016 109 M Rigamonti P Baraldi E Zio I Roychoudhury K Goebel S Poll Ensemble optimized echo state networks remaining useful life prediction Neurocomputing 281 2018 121138 httpsdoi org 10 1016 j neucom 201711062 110 M Rigamonti P Baraldi E Zio et al Echo state network remaining useful life prediction turbofan engine European Conference Prognostics Health Management Society PHME 2016 pp 255270 111 R Rocchetta Y Li E Zio Risk assessment riskcost optimization distributed power generation systems considering extreme weather conditions Reliab Eng Syst Saf 136 2015 4761 httpsdoi org 10 1016 j ress 2014 11013 112 SH Rudy SL Brunton JL Proctor JN Kutz Datadriven discovery partial differential equations Sci Adv 3 2017 e1602614 httpsdoi org 10 113 L Saidi JB Ali E Bechhoefer M Benbouzid Wind turbine highspeed shaft bearings health prognosis spectral kurtosisderived indices 1126 sciadv1602614 SVR Appl Acoust 120 2017 18 114 SB Salah I Fliss M Tagina Echo state network particle swarm optimization prognostics complex 2017 IEEEACS 14th International Conference Computer Systems Applications AICCSA IEEE 2017 115 A Saxena J Celaya E Balaban K Goebel B Saha S Saha M Schwabacher Metrics evaluating performance prognostic techniques Interna tional Conference Prognostics Health Management IEEE 2008 pp 117 116 A Saxena J Celaya B Saha S Saha K Goebel Metrics oﬄine evaluation prognostic performance Intern J Prog Health Manag 1 2010 423 117 A Saxena K Goebel D Simon N Eklund Damage propagation modeling aircraft engine runtofailure simulation International Conference Prognostics Health Management IEEE 2008 pp 19 118 P Schober C Boer LA Schwarte Correlation coeﬃcients Anesth Analg 126 2018 17631768 httpsdoi org 10 1213 ane 0000000000002864 119 RR Selvaraju M Cogswell A Das R Vedantam D Parikh D Batra GradCAM visual explanations deep networks gradientbased localiza tion 2017 IEEE International Conference Computer Vision ICCV IEEE 2017 120 SM Shankaranarayana D Runje ALIME autoencoder based approach local interpretability Intelligent Data Engineering Automated Learn ing IDEAL 2019 Springer International Publishing 2019 pp 454463 121 LS Shapley A value nperson games Contrib Theory Games 2 1953 307317 122 D She M Jia Wear indicator construction rolling bearings based multichannel deep convolutional neural network exponentially decaying learning rate Measurement 135 2019 368375 httpsdoi org 10 1016 j measurement 2018 11040 123 A Shrikumar P Greenside A Kundaje Learning important features propagating activation differences 34th International Conference 124 K Simonyan A Vedaldi A Zisserman Deep inside convolutional networks visualising image classiﬁcation models saliency maps preprint 125 M Soleimani F Campean D Neagu Diagnostics prognostics complex systems review methods challenges Qual Reliab Eng Int 126 W Song L Wen L Gao X Li Unsupervised fault diagnosis method based iterative multimanifold spectral clustering IET Collaborative 127 JT Springenberg A Dosovitskiy T Brox M Riedmiller Striving simplicity convolutional net preprint arXiv1412 6806 2014 128 E Štrumbelj I Kononenko Explaining prediction models individual predictions feature contributions Knowl Inf Syst 41 2013 647665 129 M Sundararajan A Taly Q Yan Axiomatic attribution deep networks Proceedings 34th International Conference Machine Learning Machine Learning 2017 pp 31453153 JMLRorg arXiv1312 6034 2013 2021 httpsdoi org 10 1002 qre 2947 Intelligent Manufacturing vol 1 2019 pp 4855 httpsdoi org 10 1007 s10115 013 0679 x vol 70 2017 pp 33193328 JMLRorg 130 DD Susilo A Widodo T Prahasto M Nizam Remaining useful life estimation motor shaft based feature importance statespace model Proceedings 6th International Conference Exhibition Sustainable Energy Advanced Materials Springer Singapore 2020 pp 675688 131 E Tjoa C Guan A survey explainable artiﬁcial intelligence XAI medical XAI IEEE Trans Neural Netw Learn Syst 2020 121 https doi org 10 1109 tnnls 2020 3027314 132 E Union Date subjects rights EU General Data Protection Regulation GDPR edition IT Governance Publishing 2019 pp 6277 133 Z Viharos K Kis Survey neurofuzzy systems applications technical diagnostics measurement Measurement 67 2015 126136 134 J Wang Z Li X Li Y Zhao A novel SOH prediction framework lithiumion battery echo state network International Conference httpsdoi org 10 1016 j measurement 2015 02 001 Neural Information Processing Springer 2014 pp 438445 135 C Wilkinson J Lynch R Bharadwaj K Woodham Veriﬁcation adaptive systems Federal Aviation Administration DOTFAATC164 2016 136 Y Xie D Feng F Wang X Tang J Han X Zhang DFPE explaining predictive models disk failure prediction 2019 35th Symposium Mass Storage Systems Technologies MSST IEEE 2019 137 C Yang J Qiao Z Ahmad K Nie L Wang Online sequential echo state network sparse RLS algorithm time series prediction Neural Netw 2019 138 L Yongxiang S Jianming W Gong L Xiaodong A datadriven prognostics approach RUL based principle component instance learning 2016 IEEE International Conference Prognostics Health Management ICPHM IEEE 2016 139 L Zadeh Fuzzy sets Inf Control 8 1965 338353 httpsdoi org 10 1016 s0019 995865 90241 x 21 ML Baptista K Goebel EMP Henriques Artiﬁcial Intelligence 306 2022 103667 140 MR Zafar NM Khan DLIME deterministic local interpretable modelagnostic explanations approach computeraided diagnosis systems 141 S Zeldam Automated failure diagnosis aviation maintenance explainable artiﬁcial intelligence XAI Masters thesis University Twente preprint arXiv1906 10263 2019 2018 142 J Zerilli A Knott J Maclaurin C Gavaghan Transparency algorithmic human decisionmaking double standard Philos Technol 32 2018 661683 httpsdoi org 10 1007 s13347 018 0330 6 143 C Zhang S Bengio M Hardt B Recht O Vinyals Understanding deep learning requires rethinking generalization preprint arXiv161103530 2016 144 L Zhang J Lin B Liu Z Zhang X Yan M Wei A review deep learning applications prognostics health management IEEE Access 7 2019 162415162438 httpsdoi org 10 1109 access 2019 2950985 145 Q Zhang YN Wu SC Zhu Interpretable convolutional neural networks 2018 IEEECVF Conference Computer Vision Pattern Recognition IEEE 2018 American Control Conference IEEE 2005 146 X Zhang R Xu C Kwan S Liang Q Xie L Haynes An integrated approach bearing fault diagnostics prognostics Proceedings 2005 147 S Zheng S Jayasumana B RomeraParedes V Vineet Z Su D Du C Huang PH Torr Conditional random ﬁelds recurrent neural networks IEEE international Conference Computer Vision 2015 pp 15291537 148 ZH Zhou Y Jiang SF Chen Extracting symbolic rules trained neural network ensembles AI Commun 16 2003 315 149 E Zio Prognostics health management industrial equipment Diagnostics Prognostics Engineering Systems IGI Global 2013 pp 333356 150 E Zio FD Maio A datadriven fuzzy approach predicting remaining useful life dynamic failure scenarios nuclear Reliab Eng Syst Saf 95 2010 4957 httpsdoi org 10 1016 j ress 2009 08 001 151 E Zio FD Maio M Stasi A datadriven approach predicting failure scenarios nuclear systems Ann Nucl Energy 37 2010 482491 https doi org 10 1016 j anucene 2010 01017 22