selforganizing neural network architecture learning humanobject interaction luiza mici german parisi stefan wermter knowledge technology department informatics university hamburg germany 8 1 0 2 r m 2 e n s c 2 v 6 1 9 1 0 0 1 7 1 v x r abstract visual recognition transitive action comprising humanobject interaction key component artiﬁcial system operating natural environment challenging task requires jointly recognition articulated body action extraction semantic element scene identity manipulated object paper present selforganizing neural network recognition humanobject interaction rgbd video model consists hierarchy grow whenrequired gwr network learn prototypical representation body motion pattern object accounting development actionobject mapping unsupervised fashion report experimental result dataset daily activity collected purpose study publicly available benchmark dataset line neurophysiological study selforganizing architecture exhibit higher neural activation congruent actionobject pair learned training session respect synthetically created incongruent one unsupervised model show competitive classiﬁcation result benchmark dataset respect strictly supervised approach keywords selforganization hierarchical learning action recognition object recognition humanobject interaction 1 introduction recognition transitive action action volve interaction object represents key function human visual goal inference social commu nication study transitive action grasping holding focus research neuroscience psychology 1 2 task remained open challenge computational model action recognition ability computational approach reliably recog nize humanobject interaction establish eﬀective coop eration assistive system people realworld sce narios promoting learning demonstration robotic sys tems 3 4 given outstanding capability human infer goal action interaction object biolog ical visual represents source inspiration devel oping computational model computational perspec tive important question arises potential link representation body posture manipulated object particular representation inter act integrated visual information body pose object processed separately reside distinct subcorti cal area 5 6 7 neuroscientist widely studied object action perception focus vi sual cortex construct invariant object representation 8 corresponding author email address miciinformatikunihamburgde luiza mici parisiinformatikunihamburgde german parisi wermterinformatikunihamburgde stefan wermter neuron superior temporal sulcus sts area encode action term pattern body posture motion 9 10 shown identity object play cru cial role complete understanding humanobject teractions 11 modulates response speciﬁc action selective neuron 12 13 14 little known exact neural mechanism underlying integration action object paper present selforganizing neural architec ture learns recognize humanobject interaction rgbd video design proposed architecture relies following assumption visual feature body pose manmade object represented distinct area brain 6 7 5 ii inputdriven selforganization deﬁnes topological structure speciﬁc visual area brain 15 iii representation object concept based pro totypical example 16 iv identity object crucial understanding action performed dividuals 11 12 develop hierarchical architecture use grow ing selforganizing network growwhenrequired gwr network 17 learn prototypical representation action object resulting actionobject mapping unsupervised fashion growing selforganizing network eﬀective model clustering human motion pat tern term multidimensional ﬂow vector 18 19 learning object representation supervision 20 generative property topology network particularly suitable task considering po sible generalization unseen actionobject pair preprint submitted elsevier march 5 2018 proposed architecture consists network stream processing separately feature representation body posture manipulated object second layer stream integrated combine information development actionobject mapping selforganized manner ba si previously reported result mici et al 21 work contributes improve architecture design provides indepth analysis extended number experiment unlike previous work use gwr network lay er including object recognition module em ployed selforganizing map som 22 reason considerable impact predeﬁned topological struc ture 23 especially having input highdimensional complex data distribution like perceptual representation object previous model additional network learn prototype temporal activation trajectory body pose integration phase impact overall classiﬁcation accuracy network marginal introduces computational complexity evaluate architecture dataset rgbd video containing daily action acquired purpose study publicly available action benchmark dataset cad120 24 present discus result datasets particular look role object iden tity contextual information unambiguously distinguish ing diﬀerent activity classiﬁcation performance architecture term recognition humanobject teraction activity response network fed congruent incongruent actionobject pair 2 related work important goal human activity recognition ma chine learning vision automatically detect analyze human activity information acquired visual sensing device rgb camera range sensor literature suggests conceptual categorization human activity diﬀerent level depending complexity gesture action interaction group activi tie 25 26 27 gesture elementary movement son body atomic component describing meaningful motion person stretching arm rais ing leg action singleperson activity com posed multiple gesture walking waving inter action human activity involve person object instance person making phone humanobject interaction finally group activity ac tivities performed group composed multiple person object group having meeting understanding humanobject interaction requires tegration complex relationship feature human body action object identity computational perspec tive clear link architecture specialized object recognition motion recognition bind diﬀer ent type object handarm movement recently fleis cher et al 1 proposed physiologically inspired model recognition transitive handactions grasping plac ing holding model work visual data acquired constrained environment video ing hand grasping ball diﬀerent size uniform ground role identity object transitive action recognition unclear similar model tested robotics accomplishing recognition grip aper tures aﬀordances hand action classiﬁcation 3 4 number technique applied recognition humanobject interaction typical approach explicitly model interplay object recognition body pose estimation 28 29 30 typically ﬁrst object recognized activity involving subsequently recognized analyzing object motion tra jectories 31 yang et al 32 proposed method learn ing action comprising object manipulation demonstrat ing video model able distinguish diﬀerent power precision grasp recognize object ing deep neural network architecture hu man action simply inferred action maximum loglikelihood ratio computed possible trigram ob ject1 action object2 extracted sentence en glish gigaword corpus pieropan et al 33 proposed includ ing actionrelated audio cue addition spatial relation object order learn object manipulation purpose robot learning imitation important scriptive visual feature like body motion ﬁnegrained cue like hand pose manipulation considered probabilistic approach extensively rea soning relationship dependency object mo tion human activity gupta et al 34 35 proposed bayesian network model integrating appearance ma nipulated object human motion reaction object estimate reach manipulation motion hand trajecto ries hidden markov model hmms bayesian network integrates information make ﬁnal cision recognize object human activity following similar probabilistic integration approach ryoo aggar wal 36 proposed framework recognition highlevel activity introduced additional semantic layer provid ing feedback module object identiﬁcation mo tion estimation leading improvement object recognition rate better motion estimation subject articulated body pose considered input data leading application restricted taskspeciﬁc domain air port video surveillance research study modeled mutual context object human pose graphical model conditional random field crf 37 24 38 type model suﬀer high computational complexity require ﬁnegrained segmentation ac tion sequence motivated fact visual recognition complex human pose identiﬁcation object realistic scene extremely hard task additional method rely extracting novel lowlevel visual feature yao feifei 39 proposed set sophisticated visual feature called grouplet cap tures spatial organization image patch encoded 2 sift descriptor 40 method able distinguish tween interaction cooccurrences human ob jects image application video data reported aksoy et al 41 proposed semantic event chain sec matrix entry represent spatial relation tween extracted image segment video frame action classiﬁcation obtained unsupervised way maxi mal similarity method suitable teaching object manipulation command robot representation vi sual stimulus allow reasoning semantic aspect congruence action performed cer tain object early attempt apply neural network problem understanding humanobject interaction visual percep tion yielded promising result shimozaki kuniyoshi 42 proposed sombased hierarchical architecture capable tegrating object category spatial relation movement shown perform simple 2d scene ball han dling action literature suggests compared static image domain limited work understand ing humanobject relationship video data sequence neural network architecture 43 44 system estimation articulated human body pose 2d image sequence struggle great number challenge change ambient illumination occlusion body part enduring problem segmentation combination rgb depth information provided low cost depth sensing device microsoft kinect asus xtion camera shown computational eﬃciency sensory data processing boosted number visionbased ap plication 45 sensor technology provides depth mea surements obtain reliable estimation 3d human body pose tracking body limb cluttered en vironments application type technology led successful classiﬁcation fullbody action recog nition hand gesture 27 limitation skeletal feature lack information surrounding object wang et al 46 proposed new 3d appearance feature called local occupancy pattern lop describing depth appearance neighborhood 3d joint capturing rela tions human body part hand envi ronmental object person interacting method produce stateoftheart result identity object completely ignored discriminative power feature unclear object manipulated small partially occluded 3 methodology proposed architecture consists main network stream processing separately visual representation body posture manipulated object information stream combined developing actionobject mapping building block architecture gwr network 17 growing extension selforganizing network competitive learning overview archi tecture depicted fig 1 3 body pose cue processed assumption actionselective neuron sensitive temporal order prototypical pattern output body pose processing stream computed concatenating consecutively activated neuron gwrb sliding time window tech nique object appearance cue processed order topological arrangement gwro diﬀerent 2d view 3d object diﬀerent instance object category mapped proximal neuron prototype main advantage having topological arrangement consists mapping unseen view known object corresponding view learned training capabil ity resembles extent biological mechanism learn ing threedimensional object human brain 47 48 7 prototypebased learning approach supported psychological study claiming semantic category brain represented set typical example category 16 evaluating architecture term classiﬁcation humanobject interaction activity semantic label assigned prototype neuron gwra extending gwr algorithm labeling strategy 31 learning gwr algorithm inputdriven selforganization unsupervised mecha nism learns input probability distribution ﬁ nite set prototype vector unlike traditional vector quanti zation vq method selforganizing neural network som 22 neural gas ng 49 grow ing extension growing neural gas gng 50 gwr algorithm 17 associate prototype vector neuron adaptively form topology preserving map input space unsupervised fashion similar input mapped neuron near map process topology preservation motivated similar neural mechanism multiple cortical area brainx 15 growing selforganizing network learn incrementally add remove neuron according diﬀerent criterion like gng algorithm neural growth gwr al gorithm constant depends overall net work activation respect input lead faster convergence make gwr algorithm suitable learning representation nonstationary datasets susceptible noise gwr network composed set neuron associ ated weight vector set edge link neuron forming neighborhood relationship network start set neuron randomly initialized learning iteration neuron edge created updated removed given input data sample xt index b bestmatching unit bmu given b arg min jw xt w j 1 w j weight vector neuron j w set neuron activity network computed function euclidean distance bmu wb figure 1 overview proposed architecture processing body posture set local feature encode posture upper body limb extracted fed gwrb network b input object recognition module rgb image manipulated object region automatically extracted pointcloudbased tabletop segmentation object represented compact feature vector fed gwro network classiﬁes object c network gwra learns combination body posture object involved action d action label associated neuron gwra network order evaluate architecture action classiﬁcation performance input data sample xt time step t expxt wb 2 new neuron added activity bmu lower insertion threshold parameter modulates generalization largest discrepancy incoming stimulus bmu edge created neuron smallest distance input data sam ple ﬁrst second bmus rarely activated edge amax iteration neuron edge moved ﬁring rate mechanism measure neuron activated input lead suf ﬁcient training new neuron created ﬁring rate initially set zero decrease time neuron neighbor activated following way hi τi κ 1 hi τi 3 τi κ constant controlling behaviour decreasing function curve ﬁring counter typically τ constant set higher bmu τb topo logical neighbor τi given input data sample xt new neuron added weight winner neuron neighbor updated follows wi cid15i hi xt wi 4 cid15i hi constant learning rate ﬁring counter variable learning gwr algorithm stop given criterion met maximum network size maximum number learning epoch 32 hierarchical learning adopt hierarchical gwr learning 18 data pro cessing subsequent actionobject integration hierarchical figure 2 schematic description hierarchical learning associa tion action label neuron connection shown time step t input data sample xt represented weight w winner neuron concatenated previous winner neuron weight previous neuron example category label object li o order compute winner neuron gwra gwra neuron asso ciated histogram action category frequently matched class recognized action training carried layerwise oﬄine manner batch learning ﬁrst extract body pose object fea tures o training image sequence t section 34 obtained data processed training ﬁrst layer proposed architecture gwrb trained body pose data gwro object fig 1 training com pleted gwrb network created set neuron tuned prototype body pose conﬁgurations gwro network learned classify object appearing action sequence step generate new dataset t gwra network integrates information coming stream fig 2 order encode spatiotemporal dependency body pose prototype space compute trajectory gwrb bestmatching unit having input training action 4 xtxt1xt2xt3wwwwwwwygwrogwrbgwraaction label sequence body pose frame xi bestmatching unit calculated eq 1 corresponding neuron weight concatenated following temporal sliding window technique follows ψxi bxi bxi1 bxiq1 q m 5 denotes concatenation operation m total number training frame q width time win dow refer computed ψxi action segment object data y o extracted action sequence provided input gwro network bestmatching unit calculated eq 1 object extracted beginning action sequence object representation learned contain temporal infor mation computation neural activation trajectory reported eq 5 performed label gwro bestmatching unit represented form onehot encod ing vectorial representation element zero one index corresponding rec ognized object category object appears action sequence object data processing classi ﬁcation gwro repeated time number additional object resulting onehotencoded label merged ﬁxed dimension vector following inte gration step finally new dataset t computed concatenating action segment ψxi label corresponding object loy follows t φuxi ψxi loy xi y o u q m q 6 pair φu refer actionobject seg ment encodes temporallyordered body pose sequence identity object manipulated ac tion sequence gwra network trained newly computed dataset t learning provided action object pair resulting representative vector body pose high dimension increase concate nating temporal window technique meth od based euclidean distance metric case shown performance degradation data lie highdimensional space 51 apply prin cipal component analysis pca dimensionality reduction tech nique neural weight gwrb number principal component chosen tradeoﬀ accounting greatest variance set weight having smaller di mensional discrepancy object label new basis project weight activated neuron gwrb concatenation activation trajectory subsequent integration step 33 classiﬁcation extend gwr algorithm labeling strategy classiﬁcation task keeping learning process unsuper vised use simple method based majority vote strat egy 52 neuron ni store information 5 category data point matched train ing phase neuron associated histogram histc ni counting case seeing sequence signed speciﬁc label c additionally histogram malized scaling bin corresponding inverse class frequency fc inverse neuron activation frequency fani way class label appear training penalized vote neuron weighed equally regardless ﬁred training phase complete neuron ﬁred training bmus associated histogram hi 1 fc fani histc ni 7 recognition time given test action sequence length k bestmatching unit computed frame action label l given l arg max c kcid88 i1 hbi 8 classiﬁcation nontemporal data object classiﬁca tion gwro network performed applying majority vote histogram associated bestmatching unit hbmu special case eq 8 considering k 1 nontemporal data case action sequence composed smaller action object segment described section 32 majority vote labeling technique described far applied follows let assume set activity label la training data instance drinking eating actionobject segment φ t assigned label action sequence following form φ φ1 l j φk l j l j la 9 l j activity label k number action object segment included sequence training gwra network action sequence φ label la j added histogram neuron activated composing segment φ training complete action sequence φ classiﬁed according majority vote strategy fig 2 noted associa tion neuron symbolic label aﬀect forma tion topological arrangement network approach classiﬁcation object action remains unsupervised 34 feature extraction 341 body pose feature visual identiﬁcation segmentation body pose rgb video challenging spatial transformation compromising appearance translation dif ference point view change ambient illumination occlusion reason use depth sensor technolo gy asus xtion camera provide reliable estimation threedimensional articulated body pose motion realworld environment dimensional skeletal representation straightfor ward way achieving invariance subject appearance body size consider position upper body joint shoulder elbow hand center torso neck head given carry signiﬁcant information instance foot knee joint humanobject interaction focus paper number considered joint dimensionality input data limit application architecture recognition humanobject interaction extract skeletal quad feature 53 variant respect location viewpoint body orientation feature built concept geo metric hashing shown promising result recog nition action hand gesture given quadruple body joint j1 j2 j3 j4 ji r3 local coordinate built making j1 origin mapping j2 vector 1 1 1t position joint j3 j4 cal culated respect local coordinate catenated 6dimensional vector ˆj31 ˆj32 ˆj33 ˆj41 ˆj42 ˆj43 compact representation body joint position empirically select quadruple joint center torso neck left hand left elbow center torso neck right hand right elbow mean position hand elbow encoded respect torso center neck choose neck instead head posi tion noisy tracking head caused occlusion action eating drinking composing holistic body pose vector concatena tions joint position convenient employing gwr network learning case missing joint data frame example noise body occlusion bestmatching unit input vector computed omit ting missing part body pose vector self organizing network som gwr network grow ing extension able operate robustly case missing value 54 342 object feature natural variation rgb image variation size rotation lighting condition usually wide object compared simply based image pixel intensity reason extract visual fea tures object image following way extract dense sift feature sift descrip tor 40 computed crossing point ﬁxed grid superim posed object image1 sift feature success fully applied problem unsupervised object classiﬁca tion 55 learning approach based selforganization 56 sift descriptor known extent robust change illumination image distortion multiple descriptor diﬀerent window size com puted image order account scale invariance 1dense sift vlfeat library httpwwwvlfeatorg figure 3 illustration step encoding object image vlad encoding method image orientation descriptor ﬁxed relaxes descriptor invariance respect object rotation kind representation train gwro network obtain neuron tuned diﬀerent object view invariant translation scale perform quantization followed image encoding step order ﬁxeddimensional vectorial represen tation object image necessary training gwro network object compared vectorial metric euclidean distance apply vector locally aggregated descrip tor vlad 57 encoding method fig 3 shown higher discriminative power extensively bag visual feature bof 58 59 bof method simply com putes histogram local descriptor hard assignment dictionary visual word vlad method com putes trace diﬀerences local descriptor assigned visual word 35 training table 1 report parameter training proposed neural architecture experiment pre sented section 4 selection range parameter empirically considering gwr algorithm learning factor parameter ﬁx layer constant controlling decrease function ﬁring rate variable τb τi κ learning rate weight update function cid15b cid15i threshold maximum age edge amax set higher insertion threshold pa rameter data processing layer gwrb gwro integration layer gwra higher value chosen gwrb gwro network lead greater number neuron created better representation input data result slightly lower value gwra seek generate set neuron tolerate discrepancy input generalize relatively insertion threshold parameter close close 1 impact imperceptible given input data normalized value interval 0 1 train network 300 epoch dataset order ensure convergence response network input show little signiﬁcant modiﬁcations 6 imagedensekeypointssiftvocabularyvisual wordsvladyimage vector table 1 training parameter gwrb gwro gwra network architecture classiﬁcation humanobject interaction parameter insertion threshold firing threshold learning rate firing rate behavior maximum edge age training epoch value 098 098 09 ft 01 cid15b 01 cid15i 001 τb 03 τi 01 κ 105 amax 100 300 addition aforementioned parameter sliding window mechanism applied processed body pose data impact growth gwra network wider win dows lead creation neuron albeit slightly lower number data sample understandable sequence fact temporal frame included time window higher variance resulting data prototype neuron created consequence parameter set empirically according experimental training data distribution report time window width parameter set experiment following section 4 experimental result evaluated proposed neural architecture transitive action dataset fig 4 acquired purpose study publicly available action benchmark dataset provided cornell university cad 120 24 section provide detail datasets classiﬁcation performance obtained datasets quantitative evaluation integration module case incongruent actionobject pair comparative evaluation cad120 41 experiment transitive action dataset 411 data collection collected dataset following daily activity pick ing object drinking container like mug eating object like cookie talking phone fig 4 action performed 6 participant given explicit indication purpose study instruction perform action dataset collected asus xtion depth sensor provides syn chronized rgb depth frame frame rate 30 fps distance participant sensor ﬁxed maintained maximum range proper function ing depth sensor tracking skeleton joint provided openni framework2 attenuate noise computed median value body joint 3 frame resulting 10 joint position vector second added mirrored version action sample obtain invariance figure 4 example sequence skeleton joint object taken transitive action dataset object category label mug biscuit box phone action performed right left hand action label manually annotated manipulated object segmented video pointcloudbased tabletop segmentation algorithm3 extract possible cluster plane surface table false positive obtained automatic segmentation manually deleted finally obtained image training data object recognition module architecture 412 classiﬁcation result ass performance proposed neural ar chitecture classiﬁcation action described sec tion 411 particular want evaluate importance identity manipulated object disambiguating activity subject performs purpose conducted separate experiment process body pose cue combination recognized object exclude possible bias particular sub ject followed leaveonesubjectout strategy diﬀerent trial designed video sequence ﬁrst ﬁve subject training remaining sub ject testing phase type crossvalidation challenging diﬀerent subject perform action diﬀerent manner diﬀerent velocity trained gwr network learning parame ters reported section 35 dataset composed short temporal sequence time window ﬁve frame chosen concatenation processed body cue led actionobject segment 05 second considering 10 2openninite httpwwwopenniorgsoftware 3point cloud library httpwwwpointcloudsorg 7 picking updrinkingeatingtalking phone figure 5 neural weight gwro network having trained object transitive action dataset ﬁrst principal compo nents chosen visualization dimension frame second training architecture complete number neuron reached input taining 6500 video frame 170 neuron gwrb network 182 gwro gwra network number varied 90 120 diﬀerent trial plot showing neural weight gwro network depicted fig 5 given neural weight high dimensionality dimensionality vlad descrip tor illustration purpose performed principal compo nent analysis pca ﬁrst principal compo nents seen plot neuron topolog ically organized cluster composed diﬀerent 2d view object diﬀerent instance object category advantageous architecture allows generalization unseen object view extent unseen object instance overlap tween mug cluster suggests visual appear ance object category similar compared consequence confused aﬀect action classiﬁcation performance object involved activity drinking report precision recall f1score 60 class activity averaged trial fig 6 obtained value equal 100 object identity informa tion lower percentage value body pose expected increase classiﬁcation performance signiﬁcant case body pose introduces ambiguity drinking eating talking phone picking activity hand diﬀerence clas siﬁcation performance marginal fact ac tion performed object identity speciﬁc object play decisive role 413 experiment incongruent actionobject pair addition classiﬁcation experiment carried qualitative evaluation integration module given input test data sequence incongruent actionobject pair 8 figure 6 classiﬁcation result transitive action dataset illustrated precision recall f1score averaged 6 trial crossvalidation body pose information manipulated object identity given object recognition module gwro obtained value 100 reported classiﬁcation performance measure consider incongruent pair unusual functionally irrel evant combination action object drinking telephone eating interestingly fmri study human brain region aﬀected object action congruence 14 neural response area greater action performed appropriate object opposed unusual action performed object ex periment artiﬁcially created test dataset placed image object manipulated video sequence image incongruent object extracted diﬀerent action video analyzed activation value gwra bmus eq 2 original action sequence manipulated example obtained neural activation illustrated fig 7 observed activation typically rela tively low incongruent sample explained fact gwra prototype represent joint distri bution action segment congruent object taken congruent set activation network expected lower input taken diﬀerent data distri bution model learned ﬁt incongru ent sample yield higher discrepancy respect pro totype neuron leading lower network activation noticed exception incongru ent pair talking phone depicted fig 7c case observe network activation higher incongruent input certain point se quence certain actionobject segment decreased network activation congruent input indicates network high quantization error particular actionobject segment noted small quantization error gwr network requirement good performance action classiﬁcation task described section 33 classiﬁcation action sequence performed consider ing label histogram associated activated neuron notice case network activation incongruent input signiﬁcantly low beginning sequence slightly higher case eating phone fig 7b reason similar motion hand holding object head precede eating talking phone activity ex phonebiscuit boxcanmugpc1pc2 figure 7 comparison gwra network activation having input action sequence combined incongruent object red com bined congruent blue y axis represents activation value 1 highest x axis represents number frame illustrated data sequence number frame vary diﬀer ent action action eating typically shorter talking phone drinking changing object biscuit box phone initial action segment little impact network response 42 experiment cad120 evaluated classiﬁcation performance archi tecture publicly available benchmark dataset cad120 fig 8 dataset consists 120 rgbd video 10 long daily activity arranging object cleaning object having meal making cereal microwaving food picking object stack ing object taking food taking medicine unstacking ob jects activity performed diﬀerent subject male female lefthanded peating action time video annotated human skeleton track position manipu lated object frame computed skeletal quad feature described section 32 encoding pose upper body based threedimensional position skeletal joint provided dataset additionally extracted rgb image manipulated object frame encoded vlad en coding technique described section 32 concate nation processed body pose cue time window frame chosen downsample activity video frame rate 10 fps lead actionobject segment having temporal duration 09 second training architecture input data 18000 frame number neuron reached gwr network 460 gwrb 410 gwro gwra number varied 3200 3700 diﬀerent trial crossvalidation 9 figure 8 example highlevel activity cad120 dataset 24 dered row microwaving food taking food stacking object unstacking object arranging object picking object cleaning object taking medicine fig 9 confusion matrix 10 high level activity dataset inspected activity interchanged model one including category object similar body motion stacking ob jects unstacking object microwaving food taking food activity picking object confused ar ranging object fact body pose segment ﬁrst similar one preceding activity arranging object table 2 comparison result state art cad120 dataset accuracy pre cision recall evaluation metric obtained 79 accuracy 805 precision 785 recall reported approach use ground truth temporal segmentation activity smaller atomic action subactivities 61 62 result comparable rybok et al 63 similar work method siders object appearance contextual information concatenated body motion feature represented bag word best result obtained koppula et al 64 reporting 831 accuracy 87 precision 827 recall work spatiotemporal dependency tween action object modelled conditional ran dom field crf combine learns relationship number diﬀerent feature coordinate object centroid total displacement total dis tance moved object centroid temporal segment diﬀerence x y z coordinate object skeleton joint location distance generation sample purpose classiﬁcation extended gwr labeling technique based majority vote evaluation approach shown good result dataset humanobject interaction collected speciﬁcally study importance identity object analysis neural response integration layer showed overall lower network activation given incongruent actionobject pair compared congruent pair classiﬁcation accuracy unsupervised architec ture publicly available action benchmark dataset compet itive respect supervised stateoftheart approach 52 selforganizing neural learning analogy neuro science generative approach based selforganization learn probability distribution ﬁnite set reference vec tor associated neuron resemble topo logical relationship input space neuron organization growing selforganizing approach gng 50 gwr network 17 characterized dynamic topological structure able adapt input data space mechanism competitive hebbian learning 66 unlike gng network grows constant rate gwr algorithm equipped learning mechanism creates new neuron current input represented prototype neuron extended gwr algorithm process input data vector spatial domain processing tempo ral data mechanism temporal sliding window 19 temporally ordered neural activation obtained technique resemble motion pattern encoding snapshot neuron sts area brain 10 computational perspective sliding window technique al low extrapolation spatiotemporal dependency data sequence use prototypebased representation object motivated psychological study nature human categorization 16 according exemplarbased theory category object concept typically learned set prototypical example similarity called family resemblance class association finally use gwr integrating information action object produced behavior resembling actionselective neural circuit sensitivity congruence action performed object 14 53 future work work focused twopathway hierarchy learning humanobject interaction represented combina tion upper body pose conﬁgurations object category label order reduce computational com plexity architecture excluded important com ponent motion information result approach recognition humanobject interaction learning object aﬀordances 38 24 shown tracking ob jects position spatial relationship respect body help better interpretation type interaction figure 9 confusion matrix 10 highlevel activity cad120 dataset algorithm koppula et al64 crf svm koppula et al24 crf svm approach gwr rybok et al63 svm tayyub et al65 svm u o rec o tr acc prec rec cid88 cid88 cid88 cid88 cid88 cid88 831 870 827 806 818 800 790 805 785 782 758 779 754 table 2 result cad120 dataset recognition 10 highlevel activity reported accuracy precision recall percentage averaged 4fold crossvalidation experiment comparison included reported method unsupervised u performs object recogni tion classiﬁcation activity orec relies object tracking otr graph model spatiotemporal relation use sup port vector machine svm classifying action sequence unlike work perform object classiﬁcation rely manually annotated label assume tracking object position scene object distance subject hand provides additional information improve classi ﬁcation result considered future work 5 discussion 51 summary paper presented selforganizing neural net work architecture learns recognize action comprising humanobject interaction rgbd video architec ture consists pathway gwr network processing spectively body pose object appearance identity subsequent integration layer learning actionobject mapping prototypebased learning mechanism gwr allows attenuate input noise generalize unseen data 10 evidence neuroscience observation ing tool activates area lateral temporal cortex hu man brain engaged perceiving storing informa tion motion 5 neural mechanism processing human body motion believed contribute action discrimination general 10 possible step extend model including motion information additional future work direction introduction recurrent connection gwr network purpose temporal sequence processing recurrence selforganizing network extensively investigated applied tem poral data classiﬁcation 52 67 current implementa tion temporal dependency encoded learned hard assignment time window concatenation perceptual feature vector lead highdimensional space method based euclidean distance metric known perform worse 51 current work depth information ef ﬁcient extraction threedimensional skeleton model dealing complex activity human object interaction type depth representation subject number issue highly noisy skele ton body selfocclusions manipulating object future work address limitation hand crafted feature extraction neural architecture able ex tract visual feature raw image use deep neural network selforganization 67 finally result reported paper motivate future work integration learning robotic platform evaluation realworld scenario learn ing imitation task humanrobot assistance natural en vironments acknowledgment author gratefully acknowledge partial support eu city hamburgfunded program proexzellenzia 40 german research foundation dfg project cml trr 169 hamburg landesforschungsforderungsprojekt reference reference 1 f fleischer v caggiano p thier m giese physiologically inspired model visual recognition transitive hand action journal neuroscience 33 15 2013 65636580 doi101523jneurosci 4129122013 2 k nelissen w vanduﬀel g orban charting lower superior temporal region new motionsensitive region monkey superior tem poral sulcus journal neuroscience 26 22 2006 59295947 doi101523jneurosci0824062006 3 r prevete g tessitore m santoro e catanzariti connectionist architecture viewindependent gripaperture computation brain search 1225 2008 133145 doi101016jbrainres200804 076 4 g tessitore r prevete e catanzariti g tamburrini mo tor sensory processing mirror neuron computational modelling biological cybernetics 103 6 2010 471485 doi101007 s0042201004155 11 5 m s beauchamp k e lee j v haxby martin parallel visual mo tion processing stream manipulable object human movement neuron 34 1 2002 149159 doi101016s0896627302 006426 6 p e downing m v peelen role occipitotemporal bodyselective region person perception cognitive neuroscience 2 34 2011 186 203 doi101080175889282011582945 7 k grillspector representation object oxford handbook cognitive neuroscience volume 2 cutting edge 2 8 d h hubel t wiesel receptive ﬁelds binocular interaction func tional architecture cat visual cortex journal physiology 160 1 1962 106154 9 e d grossman r blake brain area active visual perception biological motion neuron 35 6 2002 11671175 doi101016 s0896627302008978 10 m giese t poggio neural mechanism recognition bio logical movement nature review neuroscience 4 3 2003 179192 doi101038nrn1057 11 r saxe s carey n kanwisher understanding mind linking developmental psychology functional neuroimaging annual review psychology 55 2004 87124 doi101146annurevpsych55 090902142044 12 v gallese l fadiga l fogassi g rizzolatti action recognition premotor cortex brain 119 2 1996 593609 doi101093brain 1192593 13 k nelissen g luppino w vanduﬀel g rizzolatti g orban ob serving multiple action representation frontal lobe science 310 5746 2005 332336 doi101126science1115593 14 e y yoon g w humphreys s kumar p rotshtein neural se lection integration action object fmri study journal cognitive neuroscience 24 11 2012 22682279 doi101162 jocn_a_00256 15 r miikkulainen j bednar y choe j sirosh computational map visual cortex springer science business medium 2006 16 e rosch c b mervis family resemblance study internal structure category cognitive psychology 7 4 1975 573605 doi 1010160010028575900249 17 s marsland j shapiro u nehmzow selforganising network grows required neural network 15 8 2002 10411058 doi 101016s0893608002000783 18 g parisi c weber s wermter selforganizing neural integration posemotion feature human action recognition frontier neuro robotics 9 doi103389fnbot201500003 19 g parisi c weber s wermter human action recognition hi erarchical growing neural gas learning international conference artiﬁcial neural network icann springer 2014 pp 8996 doi 1010079783319111797_12 20 g s donatti o lomp r p wurtz evolutionary optimization grow ing neural gas parameter object categorization recognition international joint conference neural network ijcnn ieee 2010 pp 18 doi101109ijcnn20105596682 21 l mici g parisi s wermter recognition transitive action hierarchical neural network learning artiﬁcial neural network machine learning icann springer international publishing 2016 pp 472479 doi1010079783319447810_56 22 t kohonen essential selforganizing map neural network 37 2013 5265 doi101016jneunet201209018 23 b fritzke kohonen feature map growing cell structuresa perfor mance comparison advance neural information processing sys tems 5 nip morgan kaufmann 1993 pp 123130 24 h s koppula r gupta saxena learning human activity object aﬀordances rgbd video international journal robotics research 32 8 2013 951970 doi1011770278364913478446 25 j k aggarwal m s ryoo human activity analysis review acm computing survey csur 43 3 doi10114519226491922653 26 m ziaeefard r bergevin semantic human activity recognition lit erature review pattern recognition 48 8 2015 23292345 doi 101016jpatcog201503006 27 j k aggarwal l xia human activity recognition 3d data review pattern recognition letter 48 2014 7080 doi101016j patrec201404011 28 e cippitelli s gasparrini e gambi s spinsante human activ ity recognition skeleton data rgbd sensor com putational intelligence neuroscience 2016 doi1011552016 4351435 29 x yang y tian eﬀective 3d action recognition eigenjoints jour nal visual communication image representation 25 1 2014 211 doi101016jjvcir201303001 30 j sung c ponce b selman saxena unstructured human activity tection rgbd image international conference robotics automation icra ieee 2012 pp 842849 doi101109icra 20126224591 31 j wu osuntogun t choudhury m philipose j m rehg scalable approach activity recognition based object use international conference vision iccv ieee 2007 pp 18 32 y yang y li c fermuller y aloimonos robot learning manipu lation action plan watching unconstrained video world wide web association advancement artiﬁcial intelligence aaai 2015 pp 36863693 33 pieropan g salvi k pauwels h kjellstrom audiovisual classiﬁca tion detection human manipulation action ieee international conference intelligent robot system iros ieee 2014 pp 30453052 34 gupta l s davis object action approach combining ac tion understanding object perception vision pat tern recognition cvpr ieee 2007 pp 18 doi101109cvpr 2007383331 35 gupta kembhavi l s davis observing humanobject interac tions spatial functional compatibility recognition ieee transaction pattern analysis machine intelligence 31 10 2009 17751789 doi101109tpami200983 36 m s ryoo j aggarwal hierarchical recognition human activity interacting object vision pattern recognition cvpr ieee 2007 pp 18 doi101109cvpr2007383487 37 b yao l feifei recognizing humanobject interaction im age modeling mutual context object human pose ieee transaction pattern analysis machine intelligence 34 9 2012 16911703 doi101109tpami201267 38 h kjellstrom j romero d kragic visual objectaction recognition inferring object aﬀordances human demonstration vi sion image understanding 115 1 2011 8190 doi101016j cviu201008002 39 b yao l feifei grouplet structured image representation rec ognizing human object interaction vision pat tern recognition cvpr ieee 2010 pp 916 doi101109cvpr 20105540234 40 d g lowe distinctive image feature scaleinvariant keypoints international journal vision 60 2 2004 91110 doi 101023bvisi00000296649961594 41 e e aksoy abramov j dorr k ning b dellen f worgotter learning semantics objectaction relation observation international journal robotics research 2011 12291249doi10 11770278364911410459 42 m shimozaki y kuniyoshi integration spatial temporal context action recognition self organizing neural network ieee inter national conference intelligent robot system iros vol 3 ieee 2003 pp 23852391 43 c lea reiter r vidal g d hager segmental spatiotemporal cnns ﬁnegrained action segmentation european conference com puter vision eccv springer 2016 pp 3652 44 cy ma kadav melvin z kira g alregib h p graf attend interact higherorder object interaction video understanding arxiv preprint arxiv171106330arxiv171106330 45 j han l shao d xu j shotton enhanced vision mi crosoft kinect sensor review ieee transaction cybernetics 43 5 2013 13181334 doi101109tcyb20132265378 46 j wang z liu y wu learning actionlet ensemble 3d human ac tion recognition human action recognition depth camera springer international publishing 2014 pp 1140 doi101109 tpami2013198 47 t poggio s edelman network learns recognize dimensional object nature 343 6255 1990 263266 doi101038 12 343263a0 48 d perrett viewdependent coding ventral stream conse quences recognition vision movement mechanism cere bral cortex 1996 14251 49 t martinetz k schulten neuralgas network learns topology artiﬁcial neural network elsevier science publisher bv 1991 pp 397402 50 b fritzke growing neural gas network learns topology advance neural information processing system 7 1995 625632 51 c c aggarwal hinneburg d keim surprising havior distance metric high dimensional space international conference database theory icdt springer 2001 pp 420434 doi101007354044503x_27 52 m strickert b hammer merge som temporal data neurocomputing 64 2005 3971 doi101016jneucom200411014 53 g evangelidis g singh r horaud skeletal quad human action recognition joint quadruple international conference pat tern recognition icpr 2014 pp 45134518 doi101109icpr 2014772 54 t vatanen m osmala t raiko k lagus m sysiaho m oreˇsiˇc t honkela h lahdesmaki selforganization missing value som gtm neurocomputing 147 2015 6070 55 t tuytelaars c h lampert m b blaschko w buntine unsupervised object discovery comparison international journal vi sion 88 2 2010 284302 doi101007s1126300902718 56 t kinnunen jk kamarainen l lensu h kalviainen unsupervised object discovery selforganisation pattern recognition letter 33 16 2012 21022112 doi101016jpatrec201207013 57 h jegou f perronnin m douze j sanchez p perez c schmid ag gregating local image descriptor compact code ieee transaction pattern analysis machine intelligence 34 9 2012 17041716 doi101109tpami2011235 58 m everingham l van gool c k williams j winn zisser man pascal visual object class voc challenge international journal vision 88 2 2010 303338 doi101007 s1126300902754 59 r szeliski vision algorithm application springer sci ence business medium 2010 60 m sokolova g lapalme systematic analysis performance mea sures classiﬁcation task information processing management 45 4 2009 427437 doi101016jipm200903002 61 n hu g englebienne z lou b krose learning latent structure activity recognition robotics automation icra 2014 ieee international conference ieee 2014 pp 10481053 62 taha h h zayed m khalifa e m elhorbaty skeletonbased human activity recognition video surveillance international journal scientiﬁc engineering research 6 1 2015 9931004 63 l rybok b schauerte z alhalah r stiefelhagen important stuﬀ activity recognition salient protoobjects context winter conference application vision wacv ieee 2014 pp 646651 doi101109wacv20146836041 64 h s koppula saxena learning spatiotemporal structure rgb d video human activity detection anticipation international conference machine learning icml 2013 pp 792800 65 tayyub jawadtavanai y gatsoulis g cohn d c hogg qual itative quantitative spatiotemporal relation daily living activity recognition vision accv 2014 springer international publishing cham 2015 pp 115130 66 t martinetz competitive hebbian learning rule form perfectly topol ogy preserving map international conference artiﬁcial nerual network icann springer 1993 pp 427434 doi101007 9781447120636_104 67 g parisi j tani c weber s wermter lifelong learning human action deep neural network selforganization neural network 96 2017 137149 