Artiﬁcial Intelligence 165 2005 135 wwwelseviercomlocateartint Egeneralization grammars Jochen Burghardt Institute Computer Architecture Software Technology Berlin Germany Received 11 January 2003 Available online 14 March 2005 Abstract We extend notion antiuniﬁcation cover equational theories present method based regular tree grammars compute ﬁnite representation Egeneralization sets We present framework combine Inductive Logic Programming Egeneralization includes ex tension Plotkins lgg theorem equational case We demonstrate potential power Egeneralization example applications computation suggestions auxiliary lemmas equational inductive proofs computation construction laws given term sequences learning screen editor command sequences 2005 Elsevier BV All rights reserved Keywords Equational theory Generalization Inductive logic programming 1 Introduction Many learning techniques ﬁeld symbolic Artiﬁcial Intelligence based adopting features common given examples called selective induction classiﬁcation 14 example Syntactical antiuniﬁcation reﬂects abstraction techniques theoretically elegant domain term algebras In article propose extension called Eantiuniﬁcation Egeneralization provides way coping wellknown problem representation change 1229 It allows perform abstraction modeling equivalent represen tations appropriate equations terms This means equivalent repre sentations considered simultaneously abstraction process Abstraction insensitive representation changes 00043702 matter 2005 Elsevier BV All rights reserved doi101016jartint200501008 2 J Burghardt Artiﬁcial Intelligence 165 2005 135 In 1970 Plotkin Reynolds 303133 introduced notion syntactical anti uniﬁcation terms dual operation uniﬁcation computes general common specialization given terms exists computes special generalization exists unique renaming For example usual 0s representation natural numbers abbreviating ss0 s20 terms 0 0 s20 s20 antiunify x x retaining common function symbol equality arguments While extensions uniﬁcation equational theories classes investigated 172036 antiuniﬁcation long neglected respect theory associativity commutativity 32 socalled commutative theories 1 For arbitrary equational theory E set Egeneralizations given terms usually inﬁnite Heinz 222 presented specially tailored algorithm uses regular tree grammars compute ﬁnite representation set provided E leads regular congru ence classes However work internationally published In paper try neglect giving improved presentation standard gram mar algorithms adding new theoretical results applications Sections 4 53 In general Eantiuniﬁcation provides means ﬁnd correspondences detectable equational theory background knowledge By way simple ex ample consider terms 0 s40 Antiunifying purely syntactically considering equational theory obtain term y indicates common structure If consider usual deﬁning equations Fig 1 left terms rewritten nondeterministically shown Fig 1 right syntactically antiuniﬁed x x possible result In words recognized terms quadratic numbers Expressed predicate logic means learn deﬁnition px x ex amples p0 ps40 Other possible results ps40 x meaningfully px y z The closed representation generalization sets grammars allows ﬁlter generalizations certain properties undesirable given application context After formal deﬁnitions Section 2 introduce method Egeneralization based regular tree grammars Section 3 brieﬂy discuss extensions phisticated grammar formalisms As ﬁrst step integrating Egeneralization Inductive Logic Programming ILP provide Section 4 theorems learning terminate nondeterminate predicate deﬁnitions atoms clauses In Section 5 present applications determinate atom learning different areas including induc 1 2 3 4 x 0 x x sy sx y x 0 0 0 E 0 0 s40 E s20 s20 syn antiun syn antiun x sy x y x y x x Fig 1 Equations deﬁning left Egeneralization 0 s40 right J Burghardt Artiﬁcial Intelligence 165 2005 135 3 tive equational theoremproving learning seriesconstruction laws user support learning advanced screeneditor commands Section 6 draws conclusions 2 Deﬁnitions We assume familiarity classical deﬁnitions terms substitutions 13 Horn clauses 24 The cardinality ﬁnite set S denoted S A signature Σ set function symbols f ﬁxed arity f nullary constant Let V inﬁnite set variables TV denotes set terms Σ given V V For term t vart denotes set variables occurring t t ground term We term linear variable occurs By x1 cid3 t1 xn cid3 tn xi cid3 ti 1 cid1 cid1 n denote substitution maps variable xi term ti We ground ti ground We use postﬁx notation tσ application σ t σ τ composition σ applied ﬁrst τ second The domain σ denoted dom σ A term t called instance term t cid5 t t cid5σ substitution σ In case t special t cid5 t cid5 general t We t renaming t cid5 σ V V bijection A term t called syntactical generalization terms t1 t2 exist substitu tions σ1 σ2 tσ1 t1 tσ2 t2 In case t called speciﬁc syntactical generalization t1 t2 syntactical generalization t cid5 t1 t2 exists substitution σ cid5 t t cid5σ cid5 The speciﬁc syntactical generalization terms unique renaming syntactical antiuniﬁer 30 An equational theory E ﬁnite set equations terms E denotes t cid5 T smallest congruence relation contains equations E Deﬁne t E t cid5 E t congruence class t algebra ground terms The congruence class term usually inﬁnite example equational theory Fig 1 t cid5 Tdom σ t cid5σ E t denote set 0 E terms congruent t σ 0 0 s0 0 0 0 Let tσ E cid1 A congruence relation 1 said reﬁnement congruence relation 2 t t cid5 TV t 1 t cid5 t 2 t cid5 In Section 51 need deﬁnition t1 E t2 t1σ E t2σ ground substitutions σ vart1 vart2 dom σ equivalent equality t1 t2 inductively provable 13 Section 32 We nary function symbol f constructor n functions π f t E ti t E f t1 tn The π f 1 π f n exist t t1 tn called selectors associated f As usual assume additionally f s1 sn cid12E gt1 tm cid12E x constructors f cid12 g variable x arbitrary terms si tj On assump tion constants called constructors No selector constructor If f constructor f t1 tn E E tn f t1 i1 π f A term t called constructor term built constructors variables Let t t cid5 constructor terms If tσ1 E tσ2 x vart xσ1 E xσ2 If tσ E t cid5 tσ cid5 t cid5 σ cid5 xσ cid5 constructor term xσ cid5 E xσ x V A nondeterministic regular tree grammar 1037 triple G cid13Σ N Rcid14 Σ signature N ﬁnite set nonterminal symbols R ﬁnite set rules E n 4 J Burghardt Artiﬁcial Intelligence 165 2005 135 form N f1N11 N1n1 fmNm1 Nmnm abbreviated N m i1 fiNi1 Nini Each fiNi1 Nini called alternative rule We sume nonterminal N N exactly deﬁning rule R N lefthand Given grammar G nonterminal N N language LGN produced N deﬁned usual way set ground terms derivable N start symbol We omit index G clear context We denote total number alternatives G G In Section 4 use following predicate logic deﬁnitions To simplify tation assume predicate symbols unary An nary predicate pcid5 simulated unary p nary tupling constructor symbol deﬁning pcid13t1 tncid14 pcid5t1 tn An nary predicate p called determinate wrt ground theory B k wlog arguments k 1 n possible binding given bindings arguments 1 k 25 Sec tion 561 The background theory B deﬁne p ps determinacy depends B Similar write pt1 tn binary pred icate pcid13t1 tkcid14 cid13tk1 tncid14 reﬂect classes arguments For binary determinate predicate p relation cid13s tcid14 s t T B ps t corresponds function g We assume g deﬁned equations given E B ps t gs E t A literal form pt pt p predicate symbol t term We consider negation predicate symbol We literals L1 L2 ﬁt predicate symbol including negation We extend E literals deﬁning pt1 E pt2 t1 E t2 For example dividescid131 1 5cid14 E dividescid132 5cid14 1 1 E 2 A clause ﬁnite set C L1 Ln literals meaning C L1 Ln We consider nonredundant clauses clauses contain congruent liter als For example px 0 px redundant x 0 E x We write C1 E C2 L1 C1 L2 C2 L1 E L2 C2 nonredundant L2 uniquely determined L1 We C1 Esubsumes C2 C1σ E C2 σ In case conjunction E C1 implies C2 cases E C1 C2 C1 Esubsume C2 For example px pf x implies subsume px pf f x E A Horn clause clause p0t0 p1t1 pntn exactly positive lit eral It written p0t0 p1t1 pntn We p0t0 head literal piti body literal 1 n Like 25 Section 21 Horn clause constrained vart0 vart1 tn We Horn clause p0s0 t0 m i1 qiti semideterminate wrt background theory B pi determinate wrt B variables xi dis tinct occur s0 varsi vars0 x1 xi1 vart1 tm vars0 x1 xn Semideterminacy clauses slight extension determinacy ﬁned 25 Section 561 additionally permits arbitrary predicates qi On hand 25 permits xi xj cid12 j pisi xi pj sj xi equivalently transformed pisi xi pj sj xj xi E xj cid1 n i1 pisi xi cid1 J Burghardt Artiﬁcial Intelligence 165 2005 135 5 3 Egeneralization We treat problem Egeneralization ground terms standard algorithms regular tree grammars Here rational reconstruction original approach 22 provided monolithic specially tailored algorithms Eantiuniﬁcation We conﬁne Egeneralization terms All methods work similarly simultaneous Egeneralization n terms 31 The core method Deﬁnition 1 Egeneralization For equational theory E term t called E generalization Eantiuniﬁer terms t1 t2 exist substitutions σ1 σ2 tσ1 E t1 tσ2 E t2 In Fig 1 right t1 0 t2 s40 t x x σ1 x cid3 0 σ2 x cid3 s20 As uniﬁcation special Egeneralization arbitrary terms normally exist A set G TV called set Egeneralizations t1 t2 member Egeneralization t1 t2 Such G called complete Egeneralization t t1 t2 G contains instance t As ﬁrst step computing Egeneralization sets let weaken Deﬁnition 1 ﬁxing substitutions σ1 σ2 We Sections 4 5 weakened deﬁnition important applications right Deﬁnition 2 Constrained Egeneralization Given terms t1 t2 variable set V substitutions σ1 σ2 dom σ1 dom σ2 V equational theory E deﬁne set Egeneralizations t1 t2 wrt σ1 σ2 t TV tσ1 E t1 tσ2 E t2 This set equals t1σ1 E t2σ2 E If represent congruence class t1 E regular tree language LG1N1 LG2N2 respectively immediately compute set constrained Egeneralizations t1σ1 E The set regular tree languages closed wrt union E intersection complement inverse tree homomorphisms cover E t2 t2σ2 t1 t2 cid5 cid1cid1cid2 cid3cid3cid4 cid5 E t1 E t2 E σ1 cid2 cid4 σ2 cid3cid3cid4 cid5 cid5 cid1cid1cid2 t1σ1 E t2σ2 E cid3cid3cid4 cid1cid1cid2 t1σ1 E t2σ2 E cid5 t Constrained Egeneralization Unconstrained Egeneralization σ1 σ2 externally prescribed σ1 σ2 computed t1 E t2 E Fig 2 Egeneralization tree grammars 6 J Burghardt Artiﬁcial Intelligence 165 2005 135 substitution application special case Fig 2 gives overview method com puting constrained set Egeneralizations t1 t2 wrt σ1 σ2 according Deﬁnition 2 From ti E obtain grammar congruence class ti E exists discussion issue postponed Section 32 Apply inverse substitution σi grammar ti E grammar tiσi E standard algorithm 10 Theorem 7 Section 14 This algorithm takes time ON sizeσi inverse substitution application sizeσi sizexσi total number function symbols occurring σi E productautomaton Compute grammar intersection t1σ1 E t2σ2 xdom σi construction 10 Section 13 takes time ON1 N2 Each member t resulting tree language actual Egeneralization t1 cid2 t2 The question enumerating language discussed later Based result compute set unconstrained Egeneralizations t1 t2 according Deﬁnition 1 σi given It sufﬁcient compute ﬁxed universal substitutions τ1 τ2 grammars t1 E let play role σ1 σ2 method cf dotted vectors Fig 2 Intuitively introduce variable pair congruence classes map kind normalform member ﬁrst second class τ1 τ2 respectively E t2 We general construction accounts auxiliary nonterminals representing congruence class state universality τ1 τ2 formal way For E share grammar G sake technical simplicity assume t1 easily achieved disjoint union grammars t1 E E t2 E t2 Deﬁnition 3 Normal form Let arbitrary tree grammar G cid13Σ N Rcid14 given A nonempty set nonterminals N N called maximal LN cid12 cid3 cid5 cid1 N Deﬁne Nmax N N N cid12 N maximal Choose N Ncid5 LN N N N cid3 arbitrary ﬁxed maximal Nt N N t LN t maximal Nt t TV ground term tN N N LN LN N Nmax cid4 cid3 N N cid4 N N LN The mappings N t effectively computed G We abbreviate t tNt kind normalform t Each term LN particular nonground term mapped arbitrary ground term choice matter For substitution σ x1 cid3 t1 xn cid3 tn deﬁne σ x1 cid3 t1 xn cid3 tn We xσ xσ Lemma 4 Substitution normalization For N N t TV σ 1 t LN t LN 2 tσ LN tσ LN J Burghardt Artiﬁcial Intelligence 165 2005 135 7 Proof From deﬁnition N t t LN N Nt N N tN LN respectively 1 Hence t LN N Nt t LN 2 Induction structure t If t x V xσ LN xσ xσ LN 1 Assuming N f N11 N1n f Nm1 Nmn f t1 tn σ LN cid1 m j cid1 n tj σ LNij cid1 m j cid1 n tj σ LNij f t1 tn σ LN Deﬁnition L Induction Hypothesis cid1 Deﬁnition L Lemma 5 Universal substitutions For grammar G effectively compute substitutions τ1 τ2 universal G following sense For substitu tions σ1 σ2 substitution σ exists 1 2 t Tdom σ1 dom σ2 N N tσi LN tσ τi LN Proof Let vN1 N2 new distinct variable N1 N2 Nmax Deﬁne τi vN1 N2 cid3 tNi N1 N2 Nmax let σ x cid3 vNxσ1 Nxσ2 x dom σ1 dom σ2 Then σ τi σi coincide vart tσi LN tσ τi LN Lemma 42 cid1 1 2 Given σ1 σ2 Example 6 We apply Lemma 5 grammar G consisting topmost rules Fig 3 The result Example 8 compute set Egeneralizations We Nmax N0 Nt N1 Nt 0 LN0 LNt s0 LN1 LNt LN0 LN1 We choose cid5 Nt tN0 Nt 0 tN1 Nt s0 We abbreviate vN0 Nt N1 Nt v01 This way obtain t LN0 N0 Nt N1 Nt cid7 cid6 v00 cid3 0 v01 cid3 0 v10 cid3 s0 v11 cid3 s0 cid7 cid6 v00 cid3 0 v01 cid3 s0 v10 cid3 0 v11 cid3 s0 τ1 τ2 Given t x y σ1 x cid3 0 0 y cid3 0 σ2 x cid3 s0 y cid3 s0 s0 example obtain proper instance v01 v01 t τ1 τ2 LN0 cid22 00 0 LN0 cid22 0 0 σ1 x y τ1 v01 v01 σ2 s0 s0s0 LN1 τ2 s0 s0 LN1 The computation universal substitutions expensive involves com puting treelanguage intersections determine mappings N t Assume N Nc No Nc comprises nc nonterminals representing congruence classes No comprises ones A maximal set N contain nonterminal 8 J Burghardt Artiﬁcial Intelligence 165 2005 135 cid9 cid8 Nc arbitrary subset No maximal N proper sub set By combinatorics nc 1 upper bound Nmax Hence cardinality dom τi bounded square number In experience usually small In applications exceed 1 resulting dom τi cid1 nc 12 Computing τi requires 1 grammar intersections worst case viz No Nc Nc Nc maximal In case dom τi small Since time testing emptiness dominated intersection compu o cid1 Gno1 time upper bound tation time nc 1 OGno1 computing τi cid1 nc 1 nno2 no2 no2 cid9 cid8 If grammar deterministic nonterminal produces distinct congruence class 26 Section 2 need compute intersection obtain τ1 τ2 We dom τi N 2 In case N t v computed linear time G However general nondeterministic grammar smaller size deterministic counterpart Theorem 7 Unconstrained Egeneralization Let equational theory E ground terms t1 t2 given Let G cid13Σ N Rcid14 tree grammar N1 N2 N LGNi ti E complete set Egeneralizations t1 t2 A regular tree grammar computed G time OG2 Gno1 E 1 2 Let τ1 τ2 Lemma 5 Then t1τ1 t2τ2 E t2τ2 Proof If t t1τ1 E tτ1 E t1 tτ2 E t2 t Egeneralization t1 E t2 To completeness let t arbitrary Egeneralization t1 t2 t2τ2 tσi E ti σi Obtain σ Lemma 5 tσ τi ti E contains instance tσ t cid1 E Then t1τ1 E Since set Egeneralizations resulting method given regular tree grammar necessary enumerate terms corresponding tree language order actually obtain results Usually notion simplicity weight depending application Egeneralization desirable enumerate simplest terms weight ﬁrst The minimal weight term language nonterminal computed time OG log G 6 After easy enumerate nonterminals language order increasing weight time linear output size simple PROLOG program Example 8 To simple example generalize 0 s0 wrt equational theory Fig 1 Fig 3 shows grammars appear computation For assume grammar G deﬁning congruence classes 0 E given topmost rules Fig 3 In Example 10 discuss obtained E Nevertheless rules G intuitively understandable rule N0 topmost line reads A term value 0 built constant 0 sum terms value 0 product term value 0 term vice versa Similarly LN1 s0 E LNt T In Example 6 computed universal substitutions τ1 τ2 G E s0 J Burghardt Artiﬁcial Intelligence 165 2005 135 9 0 v10 v10v11 N0 Nt N0 N0 sN0 N0 N1 N1 N0 0 sNt Nt Nt N0 N0 0 sN0N0 N1N1 N0 N0 N1 Nt N0v00v01 N1 Nt v00v01v10v110sNt Nt Nt N0 N0 N0v00 N1 sN0N0 N1N1 N0 v11 Nt v00v01v10v110sNt Nt Nt N00v00 N01 v01 N0t v00v01 Nt0 v00 Nt1 v11 Ntt v00v01v10v110 sNtt Ntt Ntt Nt N0 N1 N1 Nt Nt N0 NtNt N0 N1 N1 Nt Nt N0 Nt Nt N0 N1 N1 Nt Nt N00 N00 N00 Ntt N0t Nt0Nt0 N0t Ntt N00 N01 Nt1Nt1 N01 N00 N01N01 N00 N0t Ntt Ntt N0t N0t N0t Nt0 Ntt Ntt Nt0 Nt0 Nt0 Nt1 Nt1 sNt0 Nt0 Nt1 Nt1 Nt0 Ntt Ntt v10 0 0 v01 v01 0 0 Fig 3 Grammars G Gτ1 Gτ2 G12 Examples 8 10 Fig 3 shows grammars Gτ1 Gτ2 resulting inverse substitution application deﬁning nonterminals N0 N1 Nt N0 N1 Nt respectively For example LGτ1 N0 0τ1 E rule N0 obtained N0 simply including variables mapped member LGN0 τ1 They appear new constants ΣGτ1 ΣGτ2 ΣG v00 v11 For t LGτ1 N0 tτ1 E 0 The bottommost 6 rules Fig 3 intersection grammar G12 obtained kind productautomaton construction deﬁning N00 Ntt We LG12Nij LGτ1 Ni LGτ2 Nj j 0 1 t By Theorem 7 LG12 N01 complete set E generalizations 0 s0 wrt E We N01 N01 Nt1 v01 v01 showing 0 s0 quadratic numbers v01 v01τ1 0 0 E 0 v01 v01τ2 s0 s0 E s0 By repeated application rules N01 N01 Nt1 Nt1 Nt1 Nt1 obtain generalization form v01 v01 arbitrary paranthesation By way intuitive example v01 sv10 v10 LG12N01 32 Setting grammars congruence classes t1 E deferred Section 31 It discussed The question obtain grammar representation initial congruence classes E t2 Procedures help compute grammar representing congruence class ground term given 26 Section 3 This paper provides criterion equational theory inducing regular tree languages congruence classes Theorem 9 Ground equations 26 An equational theory induces regular congruence classes iff deductive closure ﬁnitely ground equations E Proof To prove direction start grammar consisting rule Nf t1tn f Nt1 Ntn subterm f t1 tn occurring E For equation 10 J Burghardt Artiﬁcial Intelligence 165 2005 135 t1 E t2 E fuse nonterminals Nt1 Nt2 grammar Then suc cessively fuse pair nonterminals rules righthand sides The result deterministic grammar G t1 E t2 iff t1 t2 LGN N In addition nonoptimal intuitive algorithm McAllester gives On log n algo rithm based congruence closure 15 n written length E The proof direction need sketched cid1 In order compute complete set Egeneralizations given ground terms t1 t2 need congruence classes regular sufﬁcient t1 t2 More precisely sufﬁcient E reﬁnement congruence relation G ﬁnitely classes ti E tiG 1 2 E sn0 Example 10 Let Σ 0 s let E equational theory Fig 1 To illustrate application Theorem 9 obtain grammar deﬁning 0 E arbitrary n N Obviously E inﬁnitely congru ence classes However order consider terms 0 sn0 relation G cid4 si0 E C E sn0 deﬁned classes 0 E sufﬁcient This rela cid4 n tion fact congruence wrt 0 s term t E member i0 tc C occur subterm form 0 tc similar equals 0 regardless choice tc For n 1 choose representative term 0 s0 c classes 0 E s0 E C respectively We instantiate equation Fig 1 possi ble combinations representative terms resulting 3 32 3 32 ground equations After adding equation c ss0 apply Theorem 9 obtain determin istic grammar Gd LGd N0 0 E LGd Nc C The equations ground instances Gd built automatically The grammar Gd equivalent G Fig 3 Example 8 The nondetermin istic sake brevity It describes 0 E N0 N1 respectively LNt 0 E E LGd Ns0 s0 E s0 s0 E si0 C In 2 Corollary 16 sufﬁcient criterion given Intuitively allows construct grammar equational theory describes operators building larger values normal forms smaller ones Theorem 11 Constructive operators Let E given ground conﬂuent Noetherian termrewriting For term t T let nf t denote unique normal form let NF set normal forms Let wellfounded partial ordering NF ﬁnite branching degree let cid24 reﬂexive closure If ti cid24 nf f t1 tn f Σ t1 tn NF 1 n t T congruence class t E regular tree language Proof Deﬁne nonterminal Nt normalform term t NF Whenever t E f t1 tn t1 tn NF include alternative f Nt1 Ntn righthand rule Nt Since ti cid24 t ﬁnitely alternatives This results ﬁnite grammar G LGNnf t t E J Burghardt Artiﬁcial Intelligence 165 2005 135 11 terms t Let ai denote number iary function symbols Σ m denote maxi m i0 ai NFi normalform computations build G mal arity Σ Then need total alternatives NF rules Its computation takes OG time cid1 cid2 By way example consider theory E consisting equations 1 2 Fig 1 E known groundconﬂuent Noetherian lead NF sn0 n N Deﬁning si0 sj 0 j observe si0 cid24 sij 0 nf si0 sj 0 similarly sj 0 cid24 nf si0 sj 0 si0 cid24 nf ssi 0 Hence E leads regular congruence classes Theorem 11 For example ﬁve ways obtain term value s30 normalform terms s Accordingly N3 sN2 N3 N0 N2 N1 N1 N2 N0 N3 deﬁnes s30 E If respective preconditions met Theorems 9 11 allow automatically compute grammar describing congruence classes wrt given theory E In practice Theorem 9 problem E rarely given ground equations Theorem 11 requires properties sufﬁcient necessary For example theory Fig 1 ordering si0 cid24 0 nf si0 0 0 cid24 si0 nf 0 si0 So far best set grammar scheme given E manually For exam ple E Fig 1 easy write program reads n N computes grammar describing congruence classes 0 E The grammar consists rules N0 Nt Fig 3 rule Ni sNi1 j 0Nj Nij j kiNj Nk 1 n Similarly grammar schemes theory list operators like append reverse theories implemented E sn0 The lack single algorithm computes grammar E sufﬁciently large class equational theories restricts applicability Egeneralization method problems E changed Using grammar schemes restriction relaxed somewhat The grammarscheme approach applicable theories given conditional equations formulas long lead regular congruence classes schemes computable A problem equational theories lead regular congruence classes Consider example subtraction natural numbers We 0 E si0 si0 N Assume E reﬁnement G ﬁnitely classes si0 G sj 0 cid12 j If G congruence relation 0 G si0 si0 G 0G impossible Thus si0 sj 0 0 cid12E si0 sj 0 Hence 0 E operator like deﬁned E Egeneralize method However compute approximation Egeneralization set cases artiﬁcially cutting grammar rules maximum number alternatives This result set contains correct Egeneralizations usually incomplete For example starting grammar rules N0 0 N1 N2 N0 N0 N1 N1 N2 N2 sN0 N1 N0 N2 N1 sN1 N2 N0 12 J Burghardt Artiﬁcial Intelligence 165 2005 135 obtain Egeneralization terms t evaluation exceeds value 2 subterms instance Depending choice cutoff point resulting E generalization set sufﬁce given application To overcome limited expressiveness pure regular tree grammars sirable extend results Section 31 automata equality tests However automata equality tests siblings 410 equivalently shallow systems sort constraints 38 problem language class closed inverse substitution application 4 Section 52 For reduction automata 910 gener alized reduction automata 8 unknown closed inverse substitution application Moreover approach universal substitutions τ1 τ2 n j 1 tj LNij f t1 tn LN strongly depends fact needed proof Lemma 42 In words rule N f Ni1 Nin allowed additional constraints For reasons approach remains lim ited ordinary regular tree grammars equality constraints The following lemma shows ﬁnd sophisticated grammar formalism handle equational theories cid1 Lemma 12 General uncomputability Egeneralization There equational theories E undecidable set constrained Egeneralizations certain t1 t2 σ1 σ2 Such set represented grammar formalism closed wrt language intersection allows testing emptiness Proof We encode version Posts correspondence problem Egeneralization problem certain E Let set cid13a1 b1cid14 cid13an bncid14 pairs nonempty strings ﬁnite alphabet A given It known undecidable exists sequence 1 i2 im m cid2 1 a1 ai2 bim 35 Section 27 aim denotes string concatenation Let Σ A 1 n f b let E consist following equations b1 bi2 x y z x y z f x y ai f x y f b x y bi f b x y 1 n 1 n x y z variables Then congruence class f 1 a1 E f b 1 b1 E equals set admitted Post sequences ai bi respectively Let σ1 x cid3 σ2 x cid3 b f b 1 b1σ2 set constrained Egeneralizations f 1 a1σ1 E E nonempty iff given correspondence problem solution cid1 4 Learning predicate deﬁnitions In section relate Egeneralization Inductive Logic Programming ILP closest approach machine learning We argue favor outsourcing equational tasks Horn program induction algorithms similar long common practice area deduction From theoretical point J Burghardt Artiﬁcial Intelligence 165 2005 135 13 B cid12 F Necessity B h F Sufﬁciency B h cid12 false Weak Consistency Strong Consistency B h F cid12 false Fig 4 Requirements hypothesis generation according Muggleton 28 view generalpurpose theoremproving algorithm complete wrt equational formulas necessary instances congruence axioms s E t f s E f t s E t ps pt supplied However practice proved ef ﬁcient handle equality predicate E separately specially tailored methods like Euniﬁcation ﬁxed paramodulation varying E Similarly integrating Eantiuniﬁcation ILP algorithm helps restrict hypotheseslanguage bias search space In particular learning determinate clauses reduced learning atoms generalization wrt E deﬁning function determinate predicate We investigate learning deﬁnition new predicate symbol p different settings In cases given conjunction F F F positive negative ground facts background theory B describing equational theory E In section assume E leads regular congruence classes We generate hypothesis h explain F B From Inductive Logic Programming require ments hypothesis known 28 Section 21 They listed Fig 4 More precisely Necessity requirement impose restriction h forbids generation positive hypothesis provided positive facts explainable Muggleton remarks requirement checked conventional theorem prover calling hypothesis generation The Weak Strong Consistency requirements incide negative facts entailed In 16 Section 524 Sufﬁciency called Completeness Strong Consistency required We circumstances Egeneralization generate hypothesis satis fying Sufﬁciency Consistency requirements The meaningful equational setting require E nontrivial x y x E y Without formula false derived equational theory nonsen sical Given E require logical background theory B entail reﬂexivity symmetry transitivity axiom E congruence axiom E wrt function f Σ predicate p occurring B universal closure equation E nontriviality axiom E As stringent alternative Necessity require ment assume B contradictory predicate symbol p deﬁnition learned occur B ps congruence axiom To begin investigate learning deﬁnition unary predicate p pti For sets T T i1 pti F atom h pt Let F ground terms arbitrary term t deﬁne m in1 cid1 n cid1 h h t T t T t t cid5 T cid5 T χ tχ E t χ tχ cid12E t cid5 cid5 14 J Burghardt Artiﬁcial Intelligence 165 2005 135 We substitutions χ instead σ order identify given h proofs h Lemma 13 Requirements Let ti t cid5 arbitrary term Let F n T tn1 tm Then cid1 ground terms 1 m let t pti Let T t1 tn i1 pti F m in1 cid1 1 pt cid5 1 B pt pt cid5 2 B pt F iff h t T 3 B pt F cid12 false iff h ncid5 iff tσ E t cid5 t T σ Proof 1 The direction trivial To prove direction observe B Herbrand model containing instances p If add set pt cid5cid5 σ ground tσ E t cid5cid5 model Herbrand model B pt In model pt cid5 1 pt cid5 ncid5 holds pt cid5 holds ground This implies turn pt cid5 pt cid5cid5 tσ E t cid5 ground substitution σ 1 pt cid5 ncid5 paraphrasing Strong Consistency 2 Follows 1 ncid5 1 3 Follows 1 F pt cid5 B pt cid12 F cid1 The following Lemma 14 Lemma 20 determinate case work horses section They apply Egeneralization obtain hypotheses term set given positive negative example term sets In theorems based lemmas need enclose hypotheses terms arguments appropriate predicates Lemma 14 Hypotheses For ﬁnite set T T ground terms compute regular set H H14T T t TV t H h σ tσ H h t T t T h h t T t T Proof Let T t1 tn let G grammar deﬁning t1 E Obtain universal substitutions τ1 τn G Lemma 5 All τi domain Using notations Deﬁnition 3 let E tn The set S ﬁnite large N N n cid4 cid7 σ dom σ dom τ1 x dom σ N Nmax xσ tN cid3 n i1 E H E Deﬁne H H H sets regular tree languages elements Deﬁne H tiτi t cid5σ t cid5T S σS max cid4 max cid6 computed standard grammar algorithms For t H trivially h t T hold t T Assume h tσ E t cid5 σ t cid5 T Since vart dom τ1 construction 15 J Burghardt Artiﬁcial Intelligence 165 2005 135 If h t t cid5σ assume wlog dom σ dom τ1 σ S From Lemma 42 tσ t cid5 E tσ t cid5 E t T h t T tχi E ti χi 1 n Using Lemma 5 E E tσ H If tσ t cid5σ cid5 σ tσ tiτi t cid5 T σ cid5 S tσ σ cid5 E t cid5 contradicting h E contradicting t H t T cid1 Theorem 15 Atomic deﬁnitions Let t1 tm ground terms Let F F n i1 pti pti given We compute regular set H H15F F m in1 cid1 cid1 pt H hypothesis satisfying Sufﬁciency Strong Consistency hypothesis satisfying requirements having form pt requirement wrt F F ptσ H σ Proof Deﬁne T ti 1 n T ti n1 m By Lemma 132 3 pt hypothesis satisfying Sufﬁciency Strong Consistency t T respectively By Lemma 14 choose quirement iff h H pt t H14T T regular tree language cid1 t T h The time requirement computation Theorem 15 grows quickly neg ative examples given Even deterministic grammars m n N N n inverse substitution applications needed requiring renamed copy original gram mar If positive examples given time complexity OGn Gno1 allows nontrivial practical applications LGN0 s0 E By way example consider equational theory E Fig 1 Let F 0 cid1 0 0 cid1 s0 F true given In Example 8 computed grammar G describing 0 LGN1 Fig 3 The congruence E class cid130 0cid14 deﬁned additional grammar rule Ncid1300cid14 cid13N0 N0cid14 Instead rule add N0cid10 N0 cid1 N0 grammar anticipating cid13t1 t2cid14 H14 transformed t1 cid1 t2 H15 Theorem 15 Similarly add rule N0cid11 N0 cid1 N1 The universal substitutions obtain following construction Lemma 14 simply τ1 τ2 Example 8 We extend include variables like vN0cid10 N0cid11 v0cid100cid11 domain v0cid100cid11 H15 vcid1300cid14cid1301cid14 H14 sense From formal point view retaining τi Example 8 restricts H15 H14 predicates terms form t1 cid1 t2 cid13t1 t2cid14 respectively After lifting extended G wrt τ1 τ2 obtain grammar G12 Fig 3 extended rules like N0cid100cid11 N00 cid1 N01 By Theorem 15 element H15F F LG12N0cid100cid11 hypothesis satisfying Sufﬁciency Strong Consistency requirement Using variable naming convention Example 8 members H15 1 v00 cid1 v01 2 v00 cid1 v01 v01 3 v00 v00 cid1 v01 4 v00 v01 cid1 v11 v01 5 0 cid1 v01 6 v00 cid1 v00 v01 16 J Burghardt Artiﬁcial Intelligence 165 2005 135 Hypothesis 1 intuitively means cid1 relates possible pair terms Hypotheses 2 3 indicate F chosen speciﬁcally viz examples quadratic numbers right left argument cid1 Similarly hypothesis 5 reﬂects fact left arguments actually zero While 0 cid1 x valid law x cid1 y x E 0 valid deﬁnition Similarly variant x cid1 x H15 cover second example F Hypothesis 6 acceptable deﬁnition cid1 relation natural numbers corresponds x cid1 y z N y E x z If F F s0 cid12cid1 0 S set 24 substitutions domain v00 v11 range 0 s0 The resulting grammar H15 large shown H15 contains hypotheses 5 6 longer 1 4 We demonstrate Egeneralization incorporated existing Induc tive Logic Programming method learn clauses To concrete chose method relative general generalization rlgg originates 30 forms basis GOLEM 27 We extend deal given equational background theory E Theorem 16 Clausal deﬁnitions Let ground clauses C1 C2 given We compute regular set H lggEC1 C2 C H clause Esubsumes C1 C2 clause Esubsuming C1 C2 subsumes element H h If p1t1 pmtm H Proof Let M cid13L1 L2cid14 L1 C1 L2 C2 L1 ﬁts L2 Assuming M cid13pit1i pit2icid14 1 m let T cid13t11 t1mcid14 cid13t21 t2mcid14 T Let H piti 1 m cid13t1 tmcid14 H14T T H regular tree language regular H14T T image H tree homomor phism maps p1x1 pmxm cid13x1 xmcid14 cf 10 Theorem 7 Section 14 p1t1χi pmtmχi E Ci 1 2 χi substitutions deﬁnition Conversely let clause C Esubsume C1 C2 We assume wlog h C p1t1 pntn tj σi E tij σi 1 2 j 1 n By Lemma 5 σ exists tj σ τi E tij Choosing t cid5 tj σ j 1 n j t cid5 vNt1j Nt2j j n 1 m obtain t cid5 j τi E tij j 1 m Hence j cid13t cid5 h cid14 T T holds Cσ p1t cid5 cid13t1 tmcid14 T T To compute H grammar deﬁning tij E extended deﬁne E Since nonterminals congruence classes added additional cid13ti1 timcid14 language intersections necessary compute extended τi cid1 1 pmt cid5 1 t cid5 m H m For E lggEC1 C2 lggC1 C2 Theorem 16 implies Plotkins lgg theorem 30 Theorem 3 special case In terminology Fig 4 F C1 C2 F true The Consistency requirement satisﬁed predicate symbol p different E occurs C1 C2 B ps congruence axiom In case hypothesis h form p B h contradictory The set lggEC1 C2 subset equal set hypothesis clauses satisfying Sufﬁciency Usually clauses J Burghardt Artiﬁcial Intelligence 165 2005 135 17 imply C1 C2 Esubsume The limitation applies Plotkins syntactical lgg Theorems 16 15 share special case lggEpt1 pt2 Theorem 16 equals H15pt1 pt2 true Theorem 15 In case Theorem 15 stronger ensures result set contains sufﬁcient hypotheses On hand Theorem 16 allows general form hypotheses examples To illustrate Theorem 16 consider wellknown example learning family lations We use abbreviations ddaughter pparent ffemale eeve ggeorge hhelen mmary nnancy ttom Let background knowledge K ph m ph t pg m pt e pn e f h f m f n f e positive ex amples F1 dm h F2 t given By generalizing relative K computing lggF1 K F2 K eliminating body literals containing variable occurring head literal clausal deﬁnition daughter relation dvme vht pvht vme f vme K results In addition abbreviation sspouse let equations E sg h sh g sn t st n given The congruence classes g h described Ng g sNh Nh h sNg We obtain Theorem 16 clauses form dvme tht pt cid5 ht vme ptgn vme f vme tht t cid5 E tgn gτ1 E In order obtain constrained clause ﬁrst choose E tht head literal choose t cid5 Tvartht gτ1 Tvartht respectively We use standard intersection algorithm tree E grammars mentioned Section 31 ﬁltering case requires linear time nτ2 grammar size hτ1 E Choosing smallest solutions tht E t cid5 ht tgn obtain dvme vht pvht vme psvht vme f vme reﬂects fact background knowledge concubinages ht tgn ﬁltered sets hτ1 E gτ1 hτ1 E nτ2 E tτ2 E nτ2 tτ2 tτ2 ht E E 1 t cid5 1 pscid5 Below prove learning theorem similar Theorem 15 yields atomic hypotheses ps t deﬁne determinate predicate p Formally looking ps t satisfy scid5 pscid5 2 B t cid5 2 In cases hypothesis ps t determinate Determinacy hypothesis essentially semantic property 25 Sec tion 561 undecidable certain background theories In order compute set determinate hypotheses little detour deﬁning notion weak determinacy equivalent simple syntactic criterion Lemma 18 2 B ps t scid5 E scid5 2 E t cid5 1 scid5 2 t cid5 1 t cid5 1 t cid5 1 1 Since B imply p congruence property sume B Bcid5cid5 x y xcid5 ycid5 x E xcid5 y E ycid5 px y pxcid5 ycid5 p occur Bcid5cid5 We replace congruence axiom p partial Bcid5 Bcid5cid5 x y ycid5 y E ycid5 px y px ycid5 We hypothesis ps t weakly deter minate scid5 t cid5 2 For example E Fig 1 px y x y weakly ordinarily determinate hypothesis We deﬁne sets T T groundterm pairs arbitrary terms s t 2 Bcid5 ps t pscid5 t cid5 2 Bcid5 t cid5 1 pscid5 t cid5 E t cid5 1 t cid5 1 h h s t T s t T cid13s cid13s cid5 cid5 cid5cid14 T cid5cid14 T t t σ sσ s σ sσ cid12 s cid5 tσ E t cid5 tσ cid12E t cid5 cid5 We lemma similar Lemma 13 similar proof omitted 18 J Burghardt Artiﬁcial Intelligence 165 2005 135 Lemma 17 Weak requirements Let si ti scid5 t cid5 Let F m in1 T cid13sn1 tn1cid14 cid13sm tmcid14 Then i1 psi ti F cid1 n cid1 ground terms s t arbitrary terms psi ti Let T cid13s1 t1cid14 cid13sn tncid14 1 Bcid5 ps t pscid5 1 t cid5 2 Bcid5 ps t F iff h 3 Bcid5 ps t F cid12 false iff h 1 pscid5 s t T ncid5 t cid5 s t T ncid5 iff sσ scid5 tσ E t cid5 σ Lemma 18 Syntactic criterion 1 If vart vars hypothesis ps t weakly determinate 2 Each weakly determinate hypothesis ps t weakly determinate instance psσ tσ vartσ varsσ Bcid5 ps t psσ tσ Proof 1 pscid5 t cid5 1 If Bcid5 ps t pscid5 t cid5 tσ2 E t cid5 2 Lemma 172 Hence σ1 σ2 coincide vars vart t cid5 E 1 tσ1 tσ2 E t cid5 2 2 sσ1 scid5 sσ2 tσ1 E t cid5 2 Deﬁne σ x cid3 x vart vars arbitrary constant Then vartσ varsσ construction Since Bcid5 ps t psσ tσ sit uation psσ tσ weakly determinate Since sσ s Bcid5 ps t ps t ps tσ Since ps t weakly determinate implies t E tσ Since Bcid5 ensures p Ecompatible right argument Bcid5 psσ tσ ps t cid1 1 Lemma 19 Equivalence constructor terms Let s constructor term 1 ps t weakly determinate hypothesis iff determinate 2 B ps t pscid5 t cid5 iff Bcid5 ps t pscid5 t cid5 scid5 instance s 3 B ps t pscid5 t cid5 iff Bcid5 ps t pscid5 t cid5 scid5 constructor term Proof All directions follow B Bcid5 1 Obtain σ Lemma 182 psσ tσ weakly determi nate varsσ vartσ Bcid5 ps t psσ tσ From B ps t psσ tσ 1 pscid5 Hence B ps t scid5 E 1 scid5 2 σ1 σ2 Lemma 132 Since s 2 constructor term xσ σ1 E xσ σ2 x varsσ vartσ Hence t cid5 1 E scid5 pscid5 1 t cid5 2 tσ σ2 E t cid5 E sσ σ2 tσ σ1 E t cid5 1 2 holds sσ σ1 E scid5 E tσ σ1 E tσ σ2 E t cid5 2 2 Obtain sχ E scid5 tχ E t cid5 χ Lemma 132 deﬁnition h Since sσ cid5 scid5 σ cid5 sσ cid5 E sχ Since s constructor term xσ cid5 E xχ x vars vart Hence tσ cid5 E tχ E t cid5 By Lemma 172 implies Bcid5 ps t pscid5 t cid5 2 t cid5 1 J Burghardt Artiﬁcial Intelligence 165 2005 135 19 3 Follows 2 sχ E scid5 implies scid5 instance s cid1 Lemma 19 ends little detour It ensures weak ordinary determinacy coincide supply constructor terms input argument hypothesis p On hand restriction learn hypothesis like px x x deﬁnes partial function realizing integer square root On hand desirable hypothesis correspond explicit deﬁnition applied like rewrite rule term s purely syntactical pattern matching Tuples built operator cid13 cid14 frequently occurring special cases constructor terms For example hypothesis pcid13x ycid14 x 2 y preferred pcid132 x ycid14 2 x y explicit implies wrt E Fig 1 Lemma 192 allows instantiate cid13x ycid14 hypothesis arbitrarily nonconstructor terms like cid132 1 z1 z2cid14 The following lemma corresponds Lemma 14 leads reduced time complex ity It need compute universal substitutions uses constrained E generalization Deﬁnition 2 It permits negative examples handling efﬁciently Lemma 14 They sense determinate predicates learned allow exclude certain undesirable hypotheses committing ﬁxed function behavior Lemma 20 Weakly determinate hypotheses For ﬁnite set ground term pairs T T compute regular set H H20T T s t TV cid13s tcid14 H h σ cid13sσ tσ cid14 H h s t T s t T h h s t T s t T vars vart vars vart Proof Assume T cid13si ticid14 1 n T cid13si ticid14 n1 m For 1 n I 1 m let sI speciﬁc syntactical generalization si I sI σIi si I Such I called maximal 1 n I cid5 1 m sI sI cid5 I cid5 I denotes term equality renaming For example T cid13a tacid14 T cid13b b tbcid14 cid13b c tccid14 1 2 1 2 3 maximal 1 3 Since s12 x x instantiated b b merely ensure t12x cid3 cid12E ta t12x cid3 b cid12E tb order s12 t12 T However s13 x y sufﬁcient ensure obtain h t13x cid3 y cid3 cid12E ta t13x cid3 b y cid3 c cid12E tc Since s13 happens s13 t13 T violated t13x cid3 b y cid3 b instantiable bb h E tb Therefore generalizations sI maximal I considered iIin E Each E tm set TI computed t1 E standard tree grammar algorithms Given grammar TI easy compute grammar tagged union H cid13sI tI cid14 I I tI TI To prove properties H ﬁrst observe following Let I set maximal I For I I let TI cid3 n i1 tiσIi E tiσIi cid4 1 We vartI dom σI1 varsI The ﬁrst inclusion follows tI TI t1σI1 E second deﬁnition σI1 20 J Burghardt Artiﬁcial Intelligence 165 2005 135 2 If I maximal sI σ si 1 m σ I Since sI σIj sj j I sI σ si term sI common generalization set sj j I si Hence special generalization viz sI instance sI Conversely sI trivially common generalization sj j I sI instance sI Therefore sI sI implies I I maximal If s t given h If I I tI TI trivially sI σIi si tI σIi E ti cid1 n Assume sI σ si tI σ E ti σ n By 2 I fore sI σIi si Hence σIi σ coincide varsI vartI 1 We tI σIi tI σ E ti contradicts tI tiσIi E s t T hold let I 1 n s t T h si Then s common generalization si I n cid1 m σ cid5 sσ sI σ We I I Let I cid5 sI cid5 sI let I cid5 sσ σI cid5i sI σI cid5i sI cid5σI cid5i si I Since arbitrary I cid5 I I maximal For cid1 n sσ σIi sI σIi si sσi In words σ σIi σi ob s t T coincide vars vart Hence tσ σIi tσi E ti tained h tσ tiσIi E For n I sσ σIi si Hence tσ member tiσIi E Therefore cid13sσ tσ cid14 H cid1 sσ cid5 Theorem 21 Atomic determinate deﬁnitions Let F cid1 i1 psi ti F psi ti given ti ground si ground constructor m in1 term Then compute regular set H H21F F cid1 n ps t H determinate hypothesis satisfying Sufﬁciency Strong Consistency requirement wrt F F determinate hypothesis satisfying requirements having form ps t s constructor term psσ tσ H σ Proof Let T cid13si ticid14 1 n T cid13si ticid14 n 1 m Deﬁne H ps t cid13s tcid14 H20T T regular tree language If ps t H cid13s tcid14 H20T T h s t T vars vart hold By Lemma 181 ps t weakly determinate Lemma 172 3 satisﬁes requirements wrt Bcid5 By construction Lemma 20 s constructor term Hence Lemma 191 3 ps t determinate satisﬁes require ments wrt B respectively s t T h Let ps t determinate hypothesis satisfying requirements wrt B s constructor term By Lemma 191 3 weakly determinate satisﬁes requirements wrt Bcid5 respectively Obtain σ Lemma 182 psσ tσ additionally satisﬁes vartσ varsσ By Lemma 172 3 sσ tσ T respectively By Lemma 20 h cid13sσ σ cid5 tσ σ cid5cid14 H20T T σ cid5 psσ σ cid5 tσ σ cid5 H sσ tσ T h J Burghardt Artiﬁcial Intelligence 165 2005 135 21 To compute H union m n 2mn intersection n difference grammars needed No additional grammar intersection necessary compute universal substitution cid1 Examples application Theorem 21 given Section 5 We learning semideterminate clause lgg simulated learn ing equivalent constrained clause Egeneralization By analogy obtain background theory Bcid5 B replacing congruence axiom p0 partial Lemma 22 shows semideterminate clause C transformed equivalent constrained clause dlrC Theorem 23 simulates lgglearning C lggc Elearning dlrC cid1 Lemma 22 Determinate literal removal Let semideterminate clause C p0s0 t0 cid1 n m i1 qiti given pisi xi gisi E xi Let σ i1 pisi xi m i1 qitiσ xn cid3 gnsn x1 cid3 g1s1 Then dlrC p0s0σ t0σ strained clause deﬁnes relation p0 wrt Bcid5 wrt B cid1 Proof From properties semideterminacy s0σ s0 Since p0 occur Bcid5 outside partial congruence axiom use following property SLD resolution 11 Bcid5 p0s0 t0 C p0s t iff s0σ cid5 s t0σ cid5 E t Bcid5 Cσ cid5 σ cid5 A similar property holds dlrC The proofs directions based establishing xiσ σ cid5 E xiσ cid5 This property follows pisiσ cid5 xiσ cid5 deﬁnitions gi σ Bcid5 C p0s t Bcid5 dlrC p0s t proved When converse direction shown established extending σ cid5 vardlrC x1 xn deﬁning xiσ cid5 xiσ σ cid5 cid1 Theorem 23 Clausal determinate deﬁnitions We use abbreviation D pis t s t T pi determinate Bcid5 pis t Let ground Horn clauses C1 C2 given body literal Ci entailed Bcid5 element D We compute regular tree language H lggc EC1 C2 member C H constrained clause Esubsumes C1 C2 2 Ccid5 semideterminate clause C lggC1 Ccid5 1 C2 Ccid5 1 Ccid5 2 D dlrC subsumes member H Proof For 1 2 let p0s0i t0i head literal Ci Let M set pairs cid13L1 L2cid14 body literals L1 C1 L2 C2 L1 ﬁts L2 Assuming M cid13qj tj 1 qj tj 2cid14 j 1 k deﬁne T cid13s01 cid13t01 t11 tk1cid14cid14 cid13s02 cid13t02 t12 tk2cid14cid14 T Deﬁne H p0s0 t0 q1t1 qktk cid13s0 cid13t0 t1 tkcid14cid14 H20T T H regular tree language H20T T image H der tree homomorphism maps term p0x0 y0 q1y1 qkyk cid13x0 cid13y0 y1 ykcid14cid14 Since T set H20T T contains element cid13s0 cid13t cid5 cid14cid14 left component element H20T T s0 0 t cid5 1 t cid5 k 22 J Burghardt Artiﬁcial Intelligence 165 2005 135 For clause p0s0 t0 q1t1 qktk H vars0 s0 cid13t0 t1 tkcid14 T T Theorem 20 Hence vart0 t1 tk h p0s0 t0 q1t1 qktkχi E Ci Assume cid8 cid9 p0s0 t0 p1s1 x1 pnsn xn q1t1 qmtm lggC1 C cid5 1 C2 C cid5 2 semideterminate clause Then qj tj σi Ci σi assume wlog tj σi E tj Moreover pj sj σi xj σi member Ccid5 D implying entailed Bcid5 σ denotes substitu xj σi E gj sj σi xj σ σi tion dlrC computation Lemma 22 Since dom σ x1 xn xσ σi E xσi variables x Therefore tj σ σi E tj σi E tj s0σ σi s0σi s0i vars0 disjoint domain σ Hence ex tend clause dlrC p0s0σ t0σ q1t1σ qmtmσ superset p0s0σ t0σ q1t1σ qmtmσ qm1t cid5 k satisﬁes h vars0σ vartj σ vart cid5 m1 qkt cid5 j cid5 member H To compute lggc ﬁne cid13s0i cid13t0i t1i tkicid14cid14 needed universal substitution needs computed cid1 E extended rules E One intersection extended grammars E grammar deﬁning tj The form Theorem 23 differs Theorem 16 C dlrC need Esubsume To establish similarity second assertion theorems note subsumed clause deﬁning predicate leads speciﬁc deﬁnition subsuming clause Let Ccid5 subsume C1 C2 contain nontrivial head literal p0 Then Ccid5 subsumes C lggC1 C2 By Theorem 23 dlrC sub sumes member lggc EC1 C2 That member leads speciﬁc deﬁnition p0 Ccid5 In order duplicate ﬂexible lgg approach Theorem 23 allows literal pre postselection strategy applied lgg computation respectively Both serve eliminate undesirable body literals lgg result clause Preselection modeled Ci Ccid5 postselection enabled choosing C cid2 lggC1 Ccid5 2 In cases Theorem 23 provides corresponding constrained clause lggc EC1 C2 sufﬁcient wrt F C1 C2 F true Each C consistent predicate symbol q occurs C1 C2 B congruence axiom EC1 C2 equivalent speciﬁc C Similar Theorem 16 C lggc 1 C2 Ccid5 Again similar nondeterminate case H21p0s01 t01 p0s02 t02 true equals Ep0s01 t01 p0s02 t02 Theorem 23 In common special case Theo lggc rem 21 Theorem 23 ensures result set contains sufﬁcient hypotheses On hand Theorem 23 ensures purely determinate clause clause nondeterminate qi body lggc EC1 C2 contains clause leading equivalent speciﬁc deﬁnition p0 In words lgglearning purely determinate clauses simulated lggc Elearning atoms J Burghardt Artiﬁcial Intelligence 165 2005 135 23 p0b bbb p0ε b aε y y aax y z ax ay z ax ε x qε d qb d qc e qbb d qbc e qbcb e F P aε y y av x y v z ax y z Kq Ka aε ε ε aε b b aε bb bb ab b bb aε bbb bbb ab bb bbb ab ε b lgg p0vbε vbbbb avbε vbε vbbε avbbε b vbbbb qvbbε d E G lggc E Nε ε aNε Nε Nb b aNε Nb aNb Nε aNb Nb Nbb aNε Nbb Nbbb aNε Nbbb aNb Nbb p0vbε aavbε vbε b qavbε vbε d Fig 5 Comparison ILP lgg lggc E Let compare ILP methods lgg lggc E example Assume background knowledge describes lists associative append operator neutral element ε nil Lines 23 Fig 5 Horn program P equational theory E formalizes knowledge v x y z denote variables denotes append b c d e denote constants Moreover let conjunction Kq facts predicate q given shown fourth line Fig 5 We abbreviated qb c b e qbcb e Let F p0b bbb p0ε b given Let assume preselection strategy chose K cid5 q qε d qbb d E use ﬁrst background knowledge directly Most ILP systems including GOLEM restrict background theories sets ground literals Hence directly use equality background knowledge require formulas like p0x y eqy ycid5 p0x ycid5 background theory While Plotkins lgg deﬁned nonground clauses deﬁned clause sets like P Moreover F contains ground literals relevant arguments body literals ground obtain necessary variable bindings generalized clause Thus derive conjunction Ka ground facts implied P relevant respect Neither lgg lggc On hand E transformed grammar G order com E We Theorem 11 lexicographic path ordering pute lggc commonly prove termination rewrite associated E 13 Section 53 Alternatively instantiate predeﬁned grammar scheme like i0 aNx1xi Nxi1xn At rack Nx1xn brains question terms relevantit sufﬁcient deﬁne congruence classes terms occurring F K cid5 q n0 ε n1 x1 n Lines 58 Fig 5 preprocessed form Ka G P E respectively Observe ground literal t u left column corresponds grammar alter native Nu aNs Nt right It plausible assume literals Ka alternatives G Next compute cid5 q p0ε b Ka K cid8 p0b bbb Ka K cid9 cid5 q lgg 24 J Burghardt Artiﬁcial Intelligence 165 2005 135 cid8 p0b bbb K lggc E cid5 q p0ε b K cid9 cid5 q E E E E apply literal postselection strategy A sample result shown E results set terms p0vbε tbbbb qtbbε d Fig 5 More precisely lggc tbbbb bbbvbεcid3b bvbεcid3ε The choice tbbbb tbbε righthand Fig 5 corresponds choice body literals left sides equivalent deﬁnitions p0 If postselection strategy chooses avbε b vbbb avbbb vbε vbbbb avbε vbε vbbε left need choose tbbbb aavbε b vbε right duplicate result However preselection chooses different literals q K cid5 qbc e qc e q E c recompute grammar G include deﬁnitions bc tbbε bbvbεcid3b εvbεcid3ε E result clause constrained lgg yields determinate clause The reason function calls simulated predicate calls requiring extra variables intermediate results The deeper term lggc E clause nested longer extra variable chains corresponding lgg clause If K cid5 q true chosen lggc When lggc E approach hypotheses search space split Literal pre postselection strategies need handle nondeterminate predicates The preselected literals K cid5 q control size form grammar G Choices tbbbb LGNbbbb independently pre postselection choice leading condensed equivalent semideterminate clause E yields atom proper clause The lggc E Filtering LGNbbbb allows ensure additional properties result clause expressed regular tree languages For example orienting equation E Fig 5 left right generates canonical termrewriting R Since terms E linear grammar GNF set normal forms wrt R obtained automatically E Choosing tbbbb LGNbbbb LGNF NNF ensures redundant clause like p0vbε avbε avbε b qavbε vbε d result In classical ILP corresponding ﬁltering method similar simplicity 5 Applications In section apply Egeneralization different areas In cases use paradigm learning determinate atomic deﬁnition positive examples As indicated Section 4 restrictive paradigm allows efﬁcient algorithms We intend demonstrate notion Egeneralization help solve comparatively ambitious tasks Artiﬁcial Intelligence ﬁrst attempt We claim develop single application maturity Instead cover variety different areas order illustrate ﬂexibility Egeneralization 51 Candidate lemmas inductive proofs Auxiliary lemmas play important role automated theorem proving Even pure ﬁrstorder logic lemmas strictly necessary 18 proofs expo nentially longer consequently harder ﬁnd In induction proofs J Burghardt Artiﬁcial Intelligence 165 2005 135 25 exceed ﬁrstorder logic owing induction axioms lemmas avoidable demonstrate certain theorem By way simple example consider induction proof multiplicative asso ciativity law equational theory Fig 1 In inductive case applying equation 4 Fig 1 induction hypothesis distributivity law needed lemma order continue proof While obvious mathematically expe rienced reader automated prover know law stuck point require user interaction actual term rewritten In simple example lemma required crossfertilization technique 3 sufﬁce generate automatically However technique generally fails lemmas needed cid1 n In cases try simulate mathematical intuition Egeneralization order ﬁnd useful lemma allow prover continue increase level automa tion We consider term t1 obtained proof far x y zcid5 x y example try ﬁnd new lemma applied prover We look ing lemma form t1 E t2 t2 σ ground t1σ E t2σ holds Using Theorem 21 able compute set terms t2 t1σ E t2σ holds ﬁnitely given σ We choose ground substitutions σ1 σn vart1 x y zcid5 domain let F i1 pcid13xσi yσi zcid5σicid14 t1σi We apply Theorem 21 F F true See Fig 6 partial congruence property p simplify examples F Using notation Lemma 20 I I viz I 1 n supply negative examples Therefore compute TI The speciﬁc syntactical generalization sI cid13x y zcid5cid14σ1 cid13x y zcid5cid14σn need cid13x y zcid5cid14 However cid13x y zcid5cid14σ cid5 sI σ cid5 If sufﬁciently different ensure σ cid5 inverse This choose σi case Fig 6 σ cid5 x cid3 v021 y cid3 v310 zcid5 cid3 v201 By Theorem 21 Bcid5 pcid13x y zcid5cid14 tI σ cid51 implies pcid13x y zcid5cid14σi t1σi tI TI 1 n Since trivially implies pcid13x y zcid5cid14σi tI σ cid51σi obtain t1σi E tI σ cid51σi determinacy t1σiσi E cid3 n i1 Therefore deﬁning t2 tI σ cid51 ensures t1 t2 value sample substitution σi This necessary condition t1 E t2 sufﬁcient Before lemma suggestion t1 E t2 continue original proof checked t1 x y zcid5 x y pcid13 xσi yσi zcid5σi cid14 x y zcid5 x y σi F pcid13 0 s30s20cid14 pcid13s20 s0 0 cid14 pcid13 s0 0 s0 cid14 0 s20 0 H cid22 t2 pcid13 v021 v310 v201 cid14 v021v310v201 v310 x y zcid5 y Fig 6 Generation lemma candidates Theorem 21 26 J Burghardt Artiﬁcial Intelligence 165 2005 135 validity recursive induction prover Two simple restrictions help eliminate unsuccessful hypotheses Usually equations t1 E t2 desired satisfy vart2 vart1 For example obvious x y zcid5 x y E x v123 universally valid This restriction result set built Theorem 21 Any lemma contradicting restriction appear grammar language However instances satisfy restriction appear Moreover E given groundconvergent termrewriting R 13 Sec tion 24 makes sense require t2 normal form wrt R For example x y zcid5 x y E x 0 y zcid5 y s0 valid lemma redundant compared x y zcid5 x y E x y zcid5 y The closed representation set TI regular tree language allows easily eliminate undesired terms t2 For leftlinear termrewriting systems 13 Section 23 set normalform terms representable regular tree language terms nonnormal form eliminated intersection For rewriting systems leftlinear ﬁlter subset nonnormalform terms If desired appli cation TI restricted terms tI satisfy V cid5 vartI V arbitrarily given variable sets V cid5 V The sample instances enumerated lemma candidates valid However method lead learnability limit 19 normally result language contain invalid equationsregardless number sample substitutions It lead PAClearnability 39 currently way compute number sample substitutions depending required δ cid8 accuracies In associativity law example equations lemma suggestion x y zcid5 x y E x y zcid5 y allows prover continue successfully This suggestion appears ﬁrst TI enumerated increasing term size Most earlier terms variants wrt commutativity like x y zcid5 x y E y y zcid5 x Fig 7 shows examples lemma candidates generated prototypical im plementation Section 54 The column Theory shows equational theory We distinguish truncating integer division true division For ex ample 7 3 E 2 73 deﬁned The grammar rules realize partial functions like N2 N6 N3 N7 N3 N6N3 The integer mainder denoted We embedded twoelement Boolean algebra 0 1 natural numbers 1 corresponding true This allows model relations like logical connectives The functions compute maximum minimum numbers respectively The function dp doubles natural number 0s representation ap concatenates lists consnil representation rv reverses list ln computes length natural number The cube theory formalizes possible threedimensional 90degree rotations cube viz left right clockwise counterclockwise shown Fig 8 right The column Lemma shows corresponding lemma righthand having supplied lefthand generated method Note example differ J Burghardt Artiﬁcial Intelligence 165 2005 135 27 Lemma Theory x y z x y z x y z x y x z x y y x x y z x y z x y z x y z xz yz x yz x zy z z x y z x y y x x y x x y y dp dp dp aprv aprv aprv aprv dpx x x x dpy dpx y x y y x x y x y x y x z y z x y x z y z x y x x y x x x y aprvx rvy rvapy x apx apy z apapx y z dpx dpy dpx y x y x y x y x rvrvx rvrvx x aprvln aprvln cube cube lnapx y lnx lny lnconsx apy z slny lnz lf ccx uplf x lf ccx ccupx Fig 7 Generated lemma candidates Rhs 113 022 00 002 0024 513 011 603 213 011 011 011 303 515 24 04 00 1110 1110 222 332 02 02 12 23 11 11 No 6 10 3 31 3 2 1 1 4 3 20 6 7 2 2 4 13 1 6 1 1 4 1 4 10 1 2 Time 21 17 0 7 22 263324 19206 17304 17014 174958 174958 47128 45678 42670 6 1 1 308 308 89 296 1 1 4 21 18 18 ence lemmas x rvrvx rvrvx x The column Rhs indicates size t1σi 1 n measure size grammars intersected For arithmetic list theories value number t1σi length list t1σi given respectively The column No shows place lemmas righthand appeared enumeration sequence column Time shows required run time milliseconds compiled PROLOG 933 MHz PC Both depend strongly number size example ground instances The dependence No seen lines 4 5 The runtime depends grammar connectivity In grammar includes nonterminal reached grammar considering nonterminals smaller values Nt reached If grammar deﬁnes Nt N0 N6 computing 0σ1 E leads E 8 8 8 intersection nonterminals case compared 2 3 3 For 1σ2 E 1σ3 28 J Burghardt Artiﬁcial Intelligence 165 2005 135 Fig 8 Law computation Theorem 21 left Cube rotations right reason runtimes essentially independent Rhs sizes 2nd 4th theory The exception line 6 larger input grammar 52 Construction laws series A second application Egeneralization consists computation construction laws term series ordinary intelligence tests The method based Theo rem 21 explained For technical reasons write series reverse order consnil list inﬁx reversed cons enhance readability We consider sufﬁxes list append number denoting length We use binary predicate pls n denote sufﬁx s length l leads n series element We apply Theorem 21 k leads relations obtained given series Fig 8 left k given user Each result form pls n corresponds rewrite rule ls cid2 n computes term series sufﬁx length By construction rewrite rule guaranteed compute input terms correctly A notion correctness formally deﬁned later terms Fig 9 shows computed construction laws Its ﬁrst line exactly corresponds example Fig 8 left The column Theory indicates equational theory The ternary function realizes deﬁning equations sx y z y 0 y z z unary function ev returns s0 0 odd natural numbers Using ev series interleaved cf line 5 The column Series shows given term series sn0 abbreviated n The num ber k sufﬁxes supplied procedure corresponds number series terms right semicolon Any computed hypothesis explain series terms earlier ones The column Law shows computed hypothesis The place series denoted vp ﬁrst term having place 0 second place 1 The previous series term denoted v1 v2 respectively The column No shows place law appeared enumeration sequence In line 5 formally smaller wrt height terms enumerated term shown Fig 9 equivalent The column Time shows required runtime milliseconds 933 MHz machine strongly depending k size series terms The strength approach lie ﬁnding plausible continuation given series building precisely limited set operators nonrecursive J Burghardt Artiﬁcial Intelligence 165 2005 135 29 Fig 9 Computed construction laws algorithm computing series terms Human superiority area demonstrated line 9 construction law The strength approach area clear series 0 0 1 0 0 1 shown line 7 We expected construction law exist series period relative prime 2 trivial solution v3 eliminated choice k construction law compute ﬁrst 1 preceding 0s It decidable result language H21 ﬁnite cases pre cise propositions construction laws expressed given signature equational theory For example line 9 conclude construction law built given operators 53 Generalizing screen editor commands By way application employed Egeneralization learning complex cursormovement commands screenoriented editor like UNIX vi For j N let pij distinct constant denoting position given ﬁle column line j let P pij j N For sake simplicity assume screen large display entire contents ﬁle deal scrolling commands present Assuming ﬁle contents given cursormovement commands modeled partial functions P For example dpij pij 1 j 1 cid1 li undeﬁned models command li denotes number lines ﬁle The constant H p11 models home command Commands depend ﬁle contents For example cid6 W pij min cid7 cid5 cid1 coj chpicid51j SP chpicid5j SP cid5 30 J Burghardt Artiﬁcial Intelligence 165 2005 135 b c d e f g h j k l m n o p q r s t u v w 1 CURSOR MOTIO N COMMANDS 2 l left 3 r right 4 u 5 d H h ome m m atching W n ext word B p rev word b2 lc2 ra2 ub3 db1 c2 ld2 rb2 uc3 dc1 Wa2Wb2 Bd2Bk2 k2 ll2 rj2 uk3 dk1 Bl2 Bm2 Wc2Wj2 Fig 10 Example ﬁle contents left Corresponding grammar excerpt right minimum deﬁned models word command coj chp SP denote number columns line j character position p set space characters respectively From given ﬁle contents easy compute regular tree grammar G describes congruence classes positions time linear ﬁle size number movement commands Fig 10 gives example For sake brevity columns numbered lowercase letters Lb2 pb2 E Note ﬁle contents happen explain movement commands Using Egeneralization cursor movements easily generalized obtain common scheme Given start end positions s1 sn e1 en apply Theorem 21 F ps1 e1 psn en rule form px t t Tx term describing command sequence achieves ments For n 1 compute simplest term transforms given starting position given end position This useful advise novice user advanced cursor movement commands Imagine example user typed commands l l l l l l l l l position pk2 pb2 The term height obtained Theo rem 21 viz px lBx indicates movement achieved simply typing commands B l Each command assigned degree simplicity reﬂecting example number modiﬁer keys like shift involved distinguishing simple advanced commands In case simplest term minimized overall numbers keys pressed No grammar intersection needed n 1 Moreover lifting G constant time case In example sufﬁcient include alternative x righthand rule k2 Therefore simplest term computed overall time OG log G Changes ﬁle content require recomputation grammar minimum term sizes In cases example parenthesis changed local content changes require local grammar changes It worthwhile investigate incremental approach cover weight recomputation For n 1 smallest terms result language implement intelligent approach repeat n movement command sequences For example simplest scheme common movements ppm2 po2 ppn4 pv4 wrt ﬁle content Fig 10 computed px dW ux Since computation time grows exponentially n small J Burghardt Artiﬁcial Intelligence 165 2005 135 31 In prototypical implementation considered vi commands h j k l H M L w b e W B E 0 f F renamed suggestive identiﬁers We allow search single characters In order consider nontrivial string search commands approach combined string grammar inference 2334 learn regular search expressions Moreover com mands change ﬁle content included learning mechanism And satisfactory user interface learning features desirable allowing deﬁne command macros examples 54 Prototypical implementation We built prototypical implementation realizing Egeneralization method Section 31 applications Section 5 It comprises 4000 lines PRO LOG code Fig 11 shows architecture arrow meaning source function uses destination function The application module allows learn series laws candidate lemmas editor cursor commands edt cmds The antiuniﬁcation module contains algorithms syntactic synt au constrained cs eau unconstrained uc eau E antiuniﬁcation The grammargeneration module compute grammars given ﬁle content edt grm set t T V vart W var grm set mal forms wrt E nf grm The grammar algorithms module allows test LN ﬁniteness emptiness given member t compute intersection complement languages simplify grammar generate Nmax Lemma 5 max nt s grammar T nt For sake clarity omitted dashed lines pre postprocessing module The merely contains code choose exm instances lemma generation The term evaluation normal form enumeration minimal weight computation LN The prototype uses monolithic specially tailored algorithms Eantiuniﬁcation originally given 22 com bination standard grammar algorithms described Section 31 For reason function intersect uses cs eau special case viz σi vice versa However Fig 11 Prototype architecture 32 J Burghardt Artiﬁcial Intelligence 165 2005 135 uses relations remain unchanged implementation strictly based paper All runtime ﬁgures given paper taken prototype Currently efﬁciencyoriented reimplementation C planned Moreover use available memory efﬁciently allowing run larger examples PRO LOG The PROLOG prototypical implementation future C implementation downloaded web page httpswtcstuberlindejocheneau 6 Conclusions future work We presented method computing ﬁnite representation set E generalizations given terms showed applications Egeneralization able cope representation change abstraction making promising approach old satisfactorily solved problem Artiﬁcial Intelligence Our approach based standard algorithms regular tree grammars It allows add ﬁltering compo nents modular fashion needed surrounding application software The closed form Egeneralization set grammar simple mathematical characteriza tion easy prove formal quality properties needed application Using standard grammar language enumeration algorithm closed form converted succession form Our method handle equational theory E To use analogy E deduction method corresponds Euniﬁcation concerned particular E case paramodulation concerned class canonical E On hand partial functions conditional equations basically prevent method applicable In order demonstrate Egeneralization integrated ILP learning meth ods proved ways combining lggbased ILP Egeneralization Predicate deﬁnitions atoms clauses learned If desired hypotheses space restricted determinate hypotheses resulting faster algorithms Learning purely terminate clauses reduced learning atoms Egeneralization An lgglearner constrained clauses builtin Egeneralization learn proper superclass called semideterminate predicates We provide completeness properties hypothe ses sets Using Egeneralization search space split parts concerned se lection nondeterminate literals selection argument terms While ﬁrst best handled elaborate strategy classical ILP second left grammar language enumeration strategy For example OG log G al gorithm ﬁnd term minimal complexity tree language apparently corresponding selection algorithm determinate literals classical ILP Separating search space parts allows modularize strategy algorithms use best ﬁts needs surrounding application Experiments prototypical implementation showed comparatively ambi tious AI tasks solvable ﬁrst attempt Egeneralization We focus sketch ing applications number different areas perfectly elaborating single J Burghardt Artiﬁcial Intelligence 165 2005 135 33 application By seek demonstrate ﬂexibility Egeneralization necessary feature approach related intelligence In 2 Section 8 applications sketched including divergence handling KnuthBendix completion guessing Hoare invariants reengineering functional programs strengthening induction hypotheses The method given 5 compute ﬁnite representation complete equational theory describing given set ﬁnite algebras essentially based Egeneralization It shown complete theory implement fast specialpurpose theorem provers particular theories Based experience venture suggest Egeneralization able sim ulate important aspect human intelligence worth investigating In particular restrictions regular tree grammars impose background equational theory E relaxed In paper brieﬂy looked wellknown represen tation formalisms expressive regular tree grammars negative results It remains seen expressive formalisms Egeneralization The attempt combine higher order antiuniﬁcation 2140 Such combination expected allow recursive functions learned examples As indicated applications Egeneralization certainly improved Lemma generation integrated real induction prover particular test behavior combination rippling method 7 While rippling suggests checking homomorphic laws like f gt1 gtn E gcid5f t1 tn validity Egeneralization able suggest lemmas arbitrary forms Empirical studies series based intelligence tests geometrical theories mirror shift rotate look saturation effect Is single reasonable equational background theory solve sufﬁciently large number common tests And reasonable intelligence quotient achieved theory Currently investigating use Egeneralization analogical reasoning 12 new application ﬁt schemas described Section 4 The aim allow problems intelligence tests stated ways mere linear series solve A B C X A B C given terms X term result applying rule C time transforms A B Acknowledgements Ute Schmid Holger Schlingloff Ulrich Geske provided valuable advice presen tation References 1 F Baader Uniﬁcation weak uniﬁcation upper bound lower bound generalization problems Proc 4th Conf Rewriting Techniques Applications Lecture Notes Comput Sci vol 488 Springer Berlin 1991 pp 8691 2 J Burghardt B Heinz Implementing antiuniﬁcation modulo equational theory Arbeitspapier 1006 GMD June 1996 34 J Burghardt Artiﬁcial Intelligence 165 2005 135 3 RS Boyer JS Moore A Computational Logic Academic Press New York 1979 4 B Bogaert S Tison Equality disequality constraints direct subterms tree automata Proc STACS 9 Lecture Notes Comput Sci vol 577 Springer Berlin 1992 pp 161172 5 J Burghardt Axiomatization ﬁnite algebras Proc KI2002 Lecture Notes Artiﬁcial Intelligence vol 2479 Springer Berlin 2002 pp 222234 6 J Burghardt Weight computation regular tree languages Technical Report 001 FIRST December 2003 7 A Bundy F van Harmelen A Smaill A Ireland Extensions ripplingout tactic guiding inductive proofs Proc 10th CADE Lecture Notes Artiﬁcial Intelligence vol 449 Springer Berlin 1990 pp 132146 8 AC Caron H Comon JL Coquidé M Dauchet F Jacquemard Pumping cleaning symbolic straints solving Proc ICALP Lecture Notes Comput Sci vol 820 1994 pp 436449 9 AC Caron JL Coquidé M Dauchet Automata reduction properties solving J Symbolic Com 20 2 1995 215233 10 H Comon M Dauchet R Gilleron F Jacquemard D Lugiez S Tison M Tommasi Tree automata techniques applications Available httpwwwgrappaunivlille3frtata October 2001 11 KL Clark Predicate logic computational formalism Research Report Imperial College 1979 12 M Dastani B Indurkhya R Scha An Algebraic Method Solving Proportional Analogy Problems Dublin City University Dublin 1997 13 N Dershowitz JP Jouannaud Rewrite systems Handbook Theoretical Computer Science vol B Elsevier Amsterdam 1990 pp 243320 14 TG Dietterich RS Michalski A Comparative Review Selected Methods Learning Examples Springer Berlin 1984 pp 4182 15 PJ Downey R Sethi RE Tarjan Variations common subexpression problem J ACM 27 4 1980 758771 16 S Džeroski Inductive Logic Programming Knowledge Discovery Databases MIT Press Cambridge MA 1996 pp 117152 17 M Fay Firstorder uniﬁcation equational theory Proc 4th Workshop Automated Deduction 1979 18 G Gentzen Untersuchungen über das logische Schließen 1932 19 EM Gold Language identiﬁcation limit Inform Control 10 1967 447474 20 JH Gallier W Snyder Complete sets transformations general Euniﬁcation Theoret Comput Sci 67 1989 203260 21 RW Hasker The replay program derivations PhD thesis Univ Illinois UrbanaChampaign 1995 22 B Heinz AntiUniﬁkation modulo Gleichungstheorie und deren Anwendung zur Lemmagenerierung Doc toral dissertation TU Berlin December 1995 23 V Honavar R Parekh Grammar Inference Automata Induction Language Acquisition Marcel Dekker New York 1999 24 R Kowalski Predicate logic programming language Memo 70 Dept Comp Logic School Artif Intell Univ Edinburgh 1973 25 N Lavrac S Džeroski Inductive Logic Programming Techniques Applications Ellis Horwood New York 1994 26 D McAllester Grammar rewriting Proc CADE11 Lecture Notes Artiﬁcial Intelligence vol 607 Springer Berlin 1992 27 S Muggleton C Feng Efﬁcient induction logic programs Proc 1st Conf Algorithmic Learning Theory Tokyo Omsha 1990 pp 368381 28 S Muggleton Inductive logic programming Issues results challenge learning language logic Artiﬁcial Intelligence 114 1999 283296 29 S OHara A model redescription process context geometric proportional analogy problems Proc AII 92 Dagstuhl Germany Lecture Notes Artiﬁcial Intelligence vol 642 Springer Berlin 1992 pp 268293 30 GD Plotkin A note inductive generalization B Meltzer D Michie Eds Machine Intelligence vol 5 Edinburgh Univ Press 1970 pp 153163 31 GD Plotkin A note inductive generalization B Meltzer D Michie Eds Machine Intelli gence vol 6 Edinburgh Univ Press 1971 pp 101124 J Burghardt Artiﬁcial Intelligence 165 2005 135 35 32 L Pottier Generalisation termes en theorie equationelle Cas associatifcommutatif Report 1056 INRIA 1989 33 JC Reynolds Transformational systems algebraic structure atomic formulas B Meltzer D Michie Eds Machine Intelligence vol 5 Edinburgh Univ Press 1970 pp 135151 34 Y Sakakibara Recent advances grammatical inference Theoret Comput Sci 185 1997 1545 35 U Schöning Theoretische Informatikkurzgefaßt SpektrumHochschultaschenbuch Heidelberg 1997 36 JH Siekmann Universal Uniﬁcation Univ Kaiserslautern 1985 37 JW Thatcher JB Wright Generalized ﬁnite automata theory application decision problem secondorder logic Math Syst Theory 2 1 1968 38 TE Uribe Sorted uniﬁcation set constraints Proc CADE11 Lecture Notes Comput Sci vol 607 1992 pp 163177 39 LG Valiant A theory learnable Comm ACM 27 1984 11341142 40 U Wagner Combinatorically restricted higher order antiuniﬁcation Masters thesis TU Berlin April 2002