Artiﬁcial Intelligence 174 2010 726748 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Analysis probabilistic model redundancy unsupervised information extraction Doug Downey Oren Etzioni b Stephen Soderland b Northwestern University 2133 Sheridan Road Evanston IL 60208 United States b University Washington Box 352350 Seattle WA 98195 United States r t c l e n f o b s t r c t Article history Received 7 July 2009 Received revised form 14 April 2010 Accepted 26 April 2010 Available online 29 April 2010 Keywords Information extraction Unsupervised World Wide Web Unsupervised Information Extraction UIE task extracting knowledge text use handlabeled training examples Because UIE systems require human intervention recursively discover new relations attributes instances scalable manner When applied massive corpora Web UIE systems present approach primary challenge artiﬁcial intelligence automatic accumulation massive bodies knowledge A fundamental problem UIE assessing probability extracted information correct In massive corpora Web extraction repeatedly different documents How redundancy impact probability correctness We present combinatorial ballsandurns model called Urns computes impact sample size redundancy corroboration multiple distinct extraction rules probability extraction correct We methods estimating Urnss parameters practice demonstrate experimentally UIE models log likelihoods 15 times better average obtained methods previous work We illustrate generality redundancy model detailing multiple applications UIE Urns effective We provide theoretical foundation Urnss performance including theorem showing PAC Learnability Urns guaranteed handlabeled data certain assumptions 2010 Elsevier BV All rights reserved 1 Introduction Automatically extracting knowledge text task Information Extraction IE When applied Web IE promises radically improve Web search engines allowing answer complicated questions synthesizing infor mation multiple Web pages Further extraction Web presents new approach fundamental challenge artiﬁcial intelligence automatic accumulation massive bodies knowledge IE Web particularly challenging variety different concepts expressed The strategy employed previous smallcorpus IE handlabel examples target concept uses examples train extractor 19 38792927 On Web handlabeling examples concept intractablethe number concepts simply far large IE handlabeled examples referred Unsupervised Information Extraction UIE UIE Corresponding author Email addresses ddowneyeecsnorthwesternedu D Downey etzionicswashingtonedu O Etzioni soderlancswashingtonedu S Soderland URLs httpwwwcsnorthwesterneduddowney D Downey httpwwwcswashingtoneduhomesetzioni O Etzioni httpwwwcswashingtoneduhomessoderlan S Soderland 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201004024 D Downey et al Artiﬁcial Intelligence 174 2010 726748 727 systems KnowItAll 1618 TextRunner 34 demonstrated Web scale automaticallygenerated textual patterns perform UIE millions diverse facts As simple example occurrence phrase C x suggests string x member class C phrase ﬁlms Star Wars 221 However extraction techniques errors key problem IE determining probability extracted information correct Speciﬁcally given corpus set extractions XC class C wish estimate P x Ccorpus x XC In UIE handlabeled examples unavailable task particularly challenging How automatically assign probabilities correctness extractions arbitrary target concepts hand labeled examples This paper presents solution question applies broad spectrum UIE systems techniques It relies KnowItAll hypothesis states extractions occur frequently distinct sentences corpus likely correct KnowItAll hypothesis Extractions drawn frequently distinct sentences corpus likely correct The KnowItAll hypothesis holds Web Intuitively expect KnowItAll hypothesis hold extraction errors occur KnowItAll erroneously extracts California City phrase states taining large cities California errors occurring distinct sentences tend different2 Thus typically given erroneous extraction repeated limited number times Further Web contain misinformation example statement Elvis killed JFK appears 200 times Web according major search engine tends exception correct statement Oswald killed JFK occurs 3000 times At Webscale KnowItAll hypothesis identify correct extractions redundancy individual facts repeated times different ways For example consider TextRunner Web information extraction extracts relational statements pairs entities phrase Edison invented light bulb TextRunner extracts relational statement InventedEdison light bulb In experiment set 500 million Web pages ignoring extractions occurring tend errors TextRunner extracted 829 million total statements 218 million unique average 38 repetitions statement Wellknown facts repeated times According major search engine Web contains 10000 statements Thomas Edison invented light bulb fact expressed dozens different ways Edison invented light bulb The light bulb invented Thomas Edison Thomas Edison thousand trials invented workable light bulb Although KnowItAll hypothesis simply stated leveraging assess extractions nontrivial For example 10000th frequently extracted Film dramatically likely correct 10000th frequently ex tracted US President relative sizes target sets In UIE distinction identiﬁed handlabeled data This paper shows probabilistic model KnowItAll hypothesis coupled redundancy Web power UIE arbitrary target concepts The primary contributions discussed 11 The urns model redundancy text The KnowItAll hypothesis states probability extraction correct increases repetition But How precisely quantify conﬁdence extraction given available textual evidence We present answer questions form Urns modelan instance classic ballsandurns model combinatorics In Urns extractions represented draws urn ball urn labeled correct extraction errorand different labels repeated different numbers balls Given frequency distribution urn labels target set error set compute probability observed label target element based times drawn A key insight Urns frequency distributions predictable structure example textual corpora distributions tend Zipﬁan estimated handlabeled data We prove frequency label urn drawn mixture Zipﬁan distributions target class errors parameters Urns learned handlabeled data When data exhibits certain separability criterion PAC learnability guaranteed We demonstrate Urns effective practice In experiments UIE Web probabilities produced model shown 15 times better average compared techniques previous work 14 1 Here term class refer relations multiple strings ordered pair Chicago Illinois member Locate dIn class 2 Two sentences distinct comprised exactly word sequence We stipulate sentences distinct avoid placing undue credence content simply duplicated different pages common occurrence Web 728 D Downey et al Artiﬁcial Intelligence 174 2010 726748 12 Paper outline The paper proceeds follows We Urns model Section 2 experimentally demonstrate effectiveness UIE applications UIE model employed The theoretical results characterizing Urns model presented Section 3 We discuss future work Section 4 conclude 2 The URNS model In section Urns model assigning probabilities correctness extractions We begin formally introducing model implementation set experiments establishing models effectiveness UIE The Urns model takes form classic ballsandurns model combinatorics We ﬁrst consider single urn case simplicity generalize multiple Urns Model experiments We think IE abstractly generative process maps text extractions Extractions repeat distinct sentences yield extraction For example sentence containing Scenic towns Yakima sentence containing Washington towns Yakima lead believe Yakima correct extraction relation Cityx Each potential extraction modeled labeled ball urn A label represents instance target relation error The information extraction process modeled repeated draws urn replacement Thus example balls drawn urn label Yakima The labels instances relation Cityx Each label appear different number balls urn Finally balls urn error labels California representing cases extraction process generated label member target relation Formally parameters characterize urn C set unique target labels C number unique target labels urn E set unique error labels E number unique error labels urn numb function giving number balls labeled b b C E numB multiset giving number balls label b B Of course extraction systems access parameters directly The goal extraction discern labels extracts fact elements C based number repetitions label Thus central question investigating given particular label x extracted k times set n draws urn probability x C In deriving probability formally assume access multisets numC numE giving number times labels C E appear balls urn In experiments provide methods estimate multisets unsupervised supervised settings We derive probability element extracted k n times target class follows First P x appears k times n drawsx C cid2 rnumC cid4 k cid3 cid4cid3 cid3 n k r s 1 r s cid4 nk cid5 P numx rx C cid6 s total number balls urn sum taken possible repetition rates r Then express desired quantity Bayes Rule P x Cx appears k times n draws P x appears k times n drawsx CP x C P x appears k times n draws 1 Note expressions include prior information label xfor example P x C prior probability string x target label P numx rx C represents probability target label x repeated r balls urn In general integrating prior information valuable extraction systems analysis experiments follow simplifying assumption uniform priors yielding following simpliﬁed form Proposition 1 P x Cx appears k times n draws cid7 cid7 rnumC r rcid5numCE rcid5 s k1 r s k1 rcid5 s nk s nk D Downey et al Artiﬁcial Intelligence 174 2010 726748 729 Fig 1 Schematic illustration number distinct labels C E sets repetition rate r The confusion region shaded 201 The uniform special case For illustration consider simple case labels C repeated number balls That numci R C ci C assume numei R E ei E While assumptions unrealistic fact use Zipf distribution numb experiments reasonable approximation majority labels lie ﬂat tail Zipf curve Deﬁne p precision extraction process probability given draw comes target class In uniform case CR C ER E CR C p The probability particular element C appears given draw pC pC similarly p E 1 pE s nk We use Poisson model approximate binomial Proposition 1 That approximate r cid5 λ n k s Using approximation algebra cid6 k λ rn s k1 r λke P USCx Cx appears k times n draws 1 kenpC p E 1 E C p E pC 2 In general expect extraction process noisy informative pC p E Notice true Eq 2 shows odds x C increase exponentially number times k x extracted decrease exponentially sample size n A numerical examples illustrate behavior equation The examples assume precision p 09 Let C E 2000 This means R C 9 R E target balls times common urn error balls Now k 3 n 10000 P x C 930 Thus small number repetitions yield high conﬁdence extracted label However sample size increases n 20000 parameters unchanged P x C drops 196 On hand C balls repeat frequently E balls R C 90 R E E set 20000 p remains unchanged P x C rises 999 The examples enable illustrate advantages Urns noisyor model previous IE work 251 The noisyor model IE assumes extraction independent assertion correct fraction p time extracted label correct The noisyor model assigns following probability extracted labels P noisyorx Cx appears k times 1 1 pk Therefore noisyor model assign probability999in examples Yet explained 999 correct case n 10000 R C 90 R E As examples different sample sizes repetition rates noisyor model highly inaccurate This surprising given noisyor model ignores sample size repetition rates Section 22 quantiﬁes improvements noisyor obtained Urns practice 202 Applicability Urns model Under conditions redundancy model provide accurate probability estimates We address question formally Section 3 informally primary criteria hold First labels target set C repeated balls urn labels E set Fig 1 The shaded region Fig 1 represents confusion regionif classify labels based solely extraction count half labels region classiﬁed incorrectly ideal classiﬁer inﬁnite data examples simply isnt information decide belong C E Thus model effective confusion region relatively small Secondly small confusion region sample size n large approximate distributions shown Fig 1 probabilities output model inaccurate 730 D Downey et al Artiﬁcial Intelligence 174 2010 726748 203 Multiple urns We generalize model encompass multiple urns When multiple extraction mechanisms target class simply sum extraction counts example apply singleurn model described previous section However approach forfeits differences extraction mechanisms informative classiﬁcation For example IE employ patterns extracting city names cities including x x towns It case different patterns different modes failure labels extracted multiple patterns generally likely correct appearing single pattern Previous work cotraining shown leveraging distinct uncorrelated views data valuable 5 We model situation introducing multiple urns urn represents different pattern3 Instead n total extractions multiurn case sample size nm urn m M label example x appearing times Let Ax k1 n1 nm denote event Further let Amx k n event label x appears k times n draws urn m assuming draws urn independent Proposition 2 cid5 P x C cid5 cid8 cid8 A x k1 n1 nm cid6cid6 cid7 cid9 cid7 ci C xCE mM P Amci nm cid9 mM P Amx nm With multiple urns distributions labels balls urns represented multisets nummC nummE Expressing correlation nummx nummcid5 x important modeling decision Multiple urns especially beneﬁcial repetition rates elements C strongly correlated different urns elements Ethat nummx nummcid5 x proportionally similar x C x E Fortunately turns case practice IE We method modeling multiurn correlation Section 211 21 Implementation Urns This section describes implement Urns UIE supervised IE identiﬁes assumptions case In order compute probabilities extracted labels need method estimating numC numE For purpose estimating sets labeled unlabeled data assume numC numE Zipf distributed zC We char meaning ci ith frequently repeated label C numci proportional acterize numC numE sets ﬁve parameters set sizes C E shape parameters zC zE extraction precision p 211 Multiple urns To model multiple urns consider different precisions pm urn simplifying assumption size shape parameters urns As mentioned expect repetition rate correlation urns higher elements C set E set We model correlation follows ﬁrst elements C set assumed come location Zipf curve urns relative frequencies perfectly correlated Some elements E set similar relative frequency urnswe refer global errors However rest E set local errors meaning appear kind mechanism example Eastman Kodak extracted instance Film phrases involving word ﬁlm involving word movie Formally local errors labels present urns Each type local error makes fraction E set fractions parameters correlation model Assuming simple correlation model identical size shape parameters urns restrictive generaldifferences mechanisms complex However assumptions allow compute probabilities eﬃciently described dont appear hurt performance signiﬁcantly practice compared ideal model Section 221 With correlation model label x element C global error present urns In terms Proposition 2 probability label x appears times nm draws m cid5 cid6 Amx nm P cid5 cid6 fmx cid5 cid6 nmkm 1 fmx 3 cid3 cid4 nm fmx frequency label x That zC fmci pm Q C fmei 1 pmQ E ci C zE ei E 3 We lump patterns single urn tend behave similarly D Downey et al Artiﬁcial Intelligence 174 2010 726748 731 In expressions frequency rank label assumed urns Q C Q E normalizing constants cid2 cid2 zC Q C zE 1 Q E ci C ei E For local error x present urn m P Amx nm 1 0 0 Substituting expressions P Amx nm Proposition 2 gives ﬁnal form Urns model 212 Eﬃcient computation A feature implementation allows eﬃcient computation probabilities In general computing sum Proposition 2 potentially large C E sets require signiﬁcant computation label However given ﬁxed number urns numC numE Zipf distributed integral approximation sum Proposition 2 Poisson place binomial Eq 3 solved closed form terms incomplete Gamma functions The details approximation solution singleurn case given Section 34 The closed form expression evaluated quickly probabilities labels obtained eﬃciently This solution leverages assumptions size shape parameters identical urns relative frequencies perfectly correlated Finding eﬃcient techniques computing probabilities stringent assumptions item future work 213 Supervised parameter estimation In event large sample handlabeled training examples available target class directly estimate parameters Urns In experiments use Differential Evolution identify parameter settings approximately maximize conditional log likelihood training data 405 Differential Evolution populationbased stochastic optimization technique appropriate optimizing nonconvex likelihood function Urns Once parameters set model yields probability extracted label given number times appears urn number draws nm urn 214 Unsupervised parameter estimation Estimating model parameters unsupervised setting requires making number assumptions tailored spe ciﬁc task Below assumptions employed Urns UIE It important note assumptions speciﬁc UIE speciﬁc particular target class As argued 17 UIE systems rely class informationin form assumptions handlabeled training examplesif scale extracting information arbitrary classes speciﬁed advance Implementing Urns UIE requires solution challenging problem estimating numC numE untagged data Let U multiset consisting number times unique label extracted given corpus U number unique labels encountered sample size n cid7 rU r In order learn numC numE handlabeled data following assumptions Because number different possible errors nearly unbounded assume error set large6 We assume numC numE Zipf distributed zE parameter set 1 In experience KnowItAll different extraction rules differing precision rules precision stable different classes 17 For example precision extractor cities x insects y similar Urns takes precision input To demonstrate Urns overly sensitive parameter chose ﬁxed value 09 precision pm urns experiments7 Section 225 provides evidence observed p value tends relatively stable different target classes We use Expectation Maximization EM U order arrive appropriate values C zC quantities uniquely determine numC given assumptions Our EM algorithm proceeds follows 1 Initialize C zC starting values 2 Repeat convergence Estep Assign probabilities element U Proposition 1 b Mstep Set C zC U probabilities assigned Estep details 4 For multiurn solution obtained symbolic integration package complicated refer reader Java implementation solution available downloadsee 12 Appendix A 5 Speciﬁcally use Differential Evolution routine built Mathematica 50 6 In experiments set E 106 A sensitivity analysis showed changing E order magnitude direction resulted small changes results 7 A sensitivity analysis showed choosing substantially higher 095 lower 080 value pm resulted Urns outperforming noisyor model factor 8 PMI factor 10 experiments described Section 221 732 D Downey et al Artiﬁcial Intelligence 174 2010 726748 We obtain C zC Mstep ﬁrst estimating rankfrequency distribution labels C untagged data U From U probabilities Estep obtain E C k expected number labels C extracted k times k cid2 1 k 0 case detailed We round fractional expected counts discrete rankfrequency distribution number elements equal expected total number labels C k E C k We obtain zC ﬁtting Zipf curve rankfrequency distribution linear regression untagged data loglog scale8 cid7 Lastly set C k E C k unseen estimate number unseen labels C set k 0 GoodTuring estimation 20 GoodTuring estimation provides estimate probability mass unseen labels speciﬁcally estimate equal expected fraction draws C extracted labels seen To convert probability number unseen labels simply assume unseen label probability equal frequent seen label A potentially accurate method choose unseen actual number unique labels observed equal expected model measured sampling Such methods item future work cid7 This unsupervised learning strategy proved effective target classes different sizes example Urns learned pa rameters number elements Country relation nonnegligible extraction probability orders magnitude smaller Film City classes approximately agrees actual relative sizes sets 22 Urns Experimental results How accurate Urns assigning probabilities correctness extracted labels In section answer ques tion comparing accuracy Urnss probabilities methods previous work This section begins describing experimental results IE settings unsupervised supervised We ﬁrst unsupervised methods previous work noisyor model PMI We compare Urns methods experimentally lastly compare Urns baseline methods supervised setting We evaluated algorithms extraction sets classes Cityx Filmx Countryx Mayo rOfxy taken experiments KnowItAll performed 17 The sample size n 64605 City 135213 Film 51390 Country 46858 MayorOf The extraction patterns partitioned urns based employed target relation country nation lefthanded countries including x righthanded x countries We chose partition results extraction mechanisms relatively uncorrelated errors assumed multipleurns model For example phrase Toronto Canada cities mislead righthanded pattern extracting Canada City candi date lefthanded pattern far prone error Each combination relation handedness treated separate urn resulting urns Cityx Filmx Countryx urns MayorOfx y910 For relation tagged random sample 1000 extracted labels external knowledge bases Tipster Gazetteer cities Internet Movie Database ﬁlms manually tagging instances knowl edge base For Country MayorOf manually veriﬁed correctness extracted labels Web Countries marked correct provided correct including abbreviations current country mayors marked correct person mayor city point time In UIE experiments evaluate algorithms 1000 examples supervised IE experiments perform 10fold cross validation 221 UIE experiments We compare Urns methods unsupervised information extraction First noisyor model mM 1 pmkm pm previous work extracted label appearing times urn assigned probability 1 extraction precision urn m We second method cid9 Our previous work KnowItAll Pointwise Mutual Information PMI obtain probability estimates extracted labels 17 Speciﬁcally PMI extracted label set automatically generated discriminator phrases movies x computed Web search engine hit counts These PMI scores features Naive Bayes Classiﬁer NBC produce probability estimate label The NBC trained set automatically bootstrapped seed instances The positive seed instances taken having highest PMI discriminator phrases 8 To help ensure probability estimates increasing k zC falls 1 adjust zE zC 9 Draws Urns intended represent independent evidence Because sentence duplicated multiple different Web documents experiments consider unique sentence containing extraction draw Urns In experiments possibilities including counting number unique documents producing label simply counting extraction label UIE performance differences approaches small compared differences Urns methods 10 In unsupervised setting assumed fraction errors urns local 01 errors appearing left righthanded patterns equally prevalent appearing label The exception City class target class union class names city town intersection ﬁlm movie assumed local errors appeared Altering settings simply single urnsee Section 224 negligible impact results Fig 2 D Downey et al Artiﬁcial Intelligence 174 2010 726748 733 Fig 2 Deviation average log likelihood ideal relations lower better On average Urns outperforms noisyor factor 15 PMI factor 20 Table 1 Improved eﬃciency Urns The row reports number search engine queries KnowItAll PMI divided number queries KnowItAll Urns The row shows PMIs queries increase kthe average number distinct labels relation Thus speedup tends vary inversely average number times label drawn Speedup Average k City 173 37 Film 95 40 MayorOf 19 207 Country 31 233 bootstrapping process negative seeds taken positive seeds relations work 25 Although PMI shown 17 rank extracted labels fairly signiﬁcant shortcomings First obtaining hit counts needed compute PMI scores expensive requires large number queries public Web search engine alternatively expensive construction local Webscale inverted index Second seeds produced bootstrapping process noisy representative overall distribution extractions 39 This combined probability polarization introduced NBC tends inaccurate probability estimates 222 Discussion UIE results The results unsupervised experiments shown Fig 2 We plot deviation ideal log likelihooddeﬁned maximum achievable log likelihood given feature set Speciﬁcally class C deﬁne ideal model P idealx equal fraction test set labels extraction counts x correct We deﬁne ideal log likelihood ideal log likelihood log P idealx 4 cid2 xC cid2 log xE cid5 cid6 1 P idealx Our experimental results demonstrate Urns overcomes weaknesses PMI First Urnss probabilities far accurate PMIs achieving log likelihood factor 20 closer ideal average Fig 2 Second Urns substantially eﬃcient shown Table 1 This eﬃciency gain requires explanation These experiments performed KnowItAll relies queries Web search engines identify Web pages containing potential extractions The number queries KnowItAll issue daily limited querying Web far KnowItAlls expensive operation Thus number search engine queries eﬃciency metric Let d number discriminator phrases PMI explained The PMI method requires O d search engine queries compute PMI extracted label search engine hit counts In contrast Urns computes probabilities directly set extractionsrequiring additional queries cuts KnowItAlls queries factors ranging 19 17 As explained Section 201 noisyor model ignores target set size sample size leads assign prob abilities far high Country MayorOf relations average number times label extracted high row Table 1 This illustrated Country relation Fig 3 The noisyor model assigns appropriate probabilities low sample sizes case extracted labels fact correct predicted noisyor model However sample size increases fraction correct labels decreasesand noisyor estimate worsens On hand Urns avoids problem accounting interaction target set size sample size adjusting probability estimates sample size increases Given suﬃcient sample size Urns forms close ideal log likelihood improving slightly samples estimates obtained EM process 734 D Downey et al Artiﬁcial Intelligence 174 2010 726748 Fig 3 Deviation average log likelihood ideal sample size varies Country relation lower better Urns performs close ideal given suﬃcient sample size noisyor accurate sample size increases accurate Overall Urns assigns far accurate probabilities noisyor model log likelihood factor 15 closer ideal average The large differences Urns noisyor model PMI suggest performance Urns degrades domains likely outperform PMI noisyor model Our computation loglikelihood contains numerical potentially inﬂuence results To avoid possibility likelihood zero restrict probabilities generated Urns methods lie range 000001 099999 Widening range tended improve Urnss performance relative methods increases penalty erroneously assigning extreme probabilitiesa problem prevalent PMI noisyor Urns If narrow range digits precision 0001 0999 Urns outperforms PMI factor 15 noisyor factor 13 Thus comfortable differences observed artifact design decision Lastly focus evaluation quality methods probability estimates terms likelihood advantage Urns reﬂected metrics classiﬁcation accuracy When convert methods probability estimate classiﬁcation positive label iff probability estimate greater 05 ﬁnd Urns average accuracy approximately 81 compared PMI 63 noisyor 47 Thus Urns decreases classiﬁcation error previous methods factor 19 28 Urns ranks majority extracted labels manner similar noisyor model ranks overall frequency Thus Urns offers comparable performance noisyor terms area precisionrecall curve 6 However correlations captured multiple urns improve ranking suﬃciently frequent labels detailed Section 224 223 Supervised IE experiments We compare Urns supervised methods All methods utilize feature set Urns extrac tion counts noisyor Has parameter urn making set M parameters h1 hM assigns probability equal cid10 1 1 hmkm mM logistic regression Has M 1 parameters b1 b2 bM assigns probability equal 1 cid7 mM kmbm 1 ea SVM Consists SVM classiﬁer Gaussian kernel To transform output classiﬁer probability use probability estimation builtin LIBSVM 8 based logistic regression SVM decision values Parameters maximizing conditional likelihood training data noisyor logistic regression models Differential Evolution11 For models Urns performed 20 iterations Differential Evolution 11 For logistic regression different convex optimization methods applicable experiments Differential Evolution routine appeared converge optimum believe choice optimization method impacted logistic regression results D Downey et al Artiﬁcial Intelligence 174 2010 726748 735 Table 2 Supervised IE experiments Deviation ideal log likelihood method relation lower better The overall performance differences small Urns 19 closer ideal noisyor average 10 closer logistic regression The overall performance SVM close Urns noisyor logistic regression SVM Urns City 00439 00466 00444 00418 Film 01256 00893 00865 00764 Mayor 00857 00655 00659 00721 Country Average 00795 01020 00769 00823 00837 00759 00684 00681 Table 3 Labelprecision K highestranked extracted labels varying values K 10 200 Across ﬁve K values shown Urns reduces error singleurn model average 29 Number highestranked extracted labels Singleurn 10 20 50 100 200 1 09875 0925 08375 07075 Urns 1 1 0955 0845 071 400 distinct search points In SVM case performed grid search ﬁnd kernel parameters giving best likelihood performance training setthis grid search required acceptable performance SVM task The results supervised learning experiments shown Table 2 Urns expressive able outperform noisyor logistic regression models In terms deviation ideal log likelihood ﬁnd average Urns outperforms noisyor model 19 logistic regression 10 SVM 04 224 Beneﬁt multiple urns The previous results use multiurn model How Urnss large performance advantage UIE multiple urns In terms likelihood measured Fig 2 impact multiple urns negligible This primarily majority extracted labels occur handful times cases multipleurn model lacks data estimate correlation counts urns Multiple urns offer performance beneﬁt commonly extracted labels We evaluated effect multiple urns UIE relations shown Fig 2 computing average labelprecision K equal fraction K highestprobability labels correct The results singleurn Urns model shown Table 3 varying K The Urns model performs singleurn model provides higher precision In fact multiple urns reduces error 29 average ﬁve K values shown table 225 Is p universal constant Our UIE experiments employed extraction precision parameter p 09 While Urns massively outperforms previous methods value adjusted 08 095 accuracy Urnss probabilities degrade p altered away 09 In section attempt measure consistent observed p value varying classes This experiment differs somewhat presented In order test wide variety classes moved KnowItAll experiments 17 TextRunner provide instances classes 3 To choose classes investigate randomly selected 12 nouns WordNet 100 extractions necessarily unique TextRunner We excluded nouns overly general nearly extraction correct class Example nouns rarely concrete instances class Purchases The results section compiled querying TextRunner 100 sentences containing extractions class12 While TextRunner provides greater coverage KnowItAll precision general lower One inaccuracies TextRunner fails delimit boundaries extractions properly extracts phrase alkanes cycloalkanes instance Solvents class We improve precision TextRunner 20 average postprocessing extractions breaking conjunctions punctuation previous example simply alkanes Our results employ heuristic The results experiment shown Table 4 For class p Observed gives fraction 100 extractions tagged correct manual inspection The average p value observed classes 084 lower value 09 12 The list excluded nouns labeled extractions selected class available download 12 Appendix A 736 D Downey et al Artiﬁcial Intelligence 174 2010 726748 Table 4 Average p values classes measured 100 handtagged examples class Three 12 classes p values bold indicating statistically signiﬁcantly difference mean 084 signiﬁcance level 001 Fisher Exact Test However adjust estimate p class according frequently occurs pattern factor hclass text resulting p hclass values signiﬁcantly different mean Class solvents devices thinkers relaxants mushrooms mechanisms resorts flies tones wounds machines cultures p Observed Hitsclass Hitsclass p Observed hclass 098 093 093 092 086 085 085 084 077 077 069 067 0201 0022 0013 0010 0001 0017 0002 00004 0001 0002 0002 0002 085 087 089 089 090 080 088 093 083 080 071 070 use previous experiments reﬂects relatively lower precision TextRunner increased diﬃculty extracting common nouns versus proper noun extractions previously The results substantial regularity observed p values values perfectly consistent In fact classes p Observed values bold differ signiﬁcantly average observed p value signiﬁcance level 001 Fisher Exact Test Given observe variability p values classes important question correct p value given class pclass predicted We observed empirically precision extractions class increases relatively frequently class extraction patterns As example phrase cultures x appears infrequently relative word cultures shown Table 4 terms Web hit counts obtained search engine In turn class Cultures exhibits relatively low p value Intuitively result makes senseclass names natural naming instances appear frequently extraction patterns provide precise extractions We exploit intuition adjusting estimate extraction precision class factor hclass For illustration based values Table 4 devised following adjustment factor hclass 008 cid3 236 log10 cid4 Hitsclass Hitsclass 5 The adjustment factor accurate estimate precision given class pclass p hclass Obviously expression hclass heuristic reﬁned additional experiments Nonetheless ad justing factor allow obtain better precision estimates classes The quantity p Observed hclass 57 variance original p Observed mean construction Further ob served differences p Observed hclass statistically signiﬁcantly different original mean signiﬁcance test employed previously Lastly mention adjustment factor variance p value classes substan tially greater employed sensitivity analysis Section 22 Thus expect performance advantages Urns noisyor PMI models extend classes 23 Urns Other applications Urns general model For classiﬁcation task features represents count observations following mixture Zipf distributions assumed Urns model employed In section highlight examples Urns model applied tasks assigning probabilities correctness extractions 231 Estimating UIE precision recall An attractive feature Urns enables estimate expected recall precision function sample size If distributions Fig 1 cross dotted line shown given suﬃciently large sample size n expected recall fraction area C curve lying right dotted line For given sample size n deﬁne τn number appearances k extracted label likely C set E set given distributions Fig 1 τn computed Proposition 1 Then ETruePositives C cid2 τn1cid2 cid4cid3 cid3 n cid4 k cid3 cid4 nk r s 1 r s rnumC k0 k D Downey et al Artiﬁcial Intelligence 174 2010 726748 737 Table 5 Estimating precision recall UIE Listed Urns model estimate precision recall actual measured quantities classes The major differences classesthat MayorOf Country classes roughly orders magnitude lower recall City Film classesis qualitatively reﬂected model City Country Film MayorOf n 64605 51390 135213 46858 ERecall Actual recall EPrecision Actual precision 12900 37 25900 58 14300 176 23400 158 078 063 079 062 084 077 068 079 deﬁne true positives number extracted labels ci C model assigns probability P ci C 05 The expected number false positives similarly cid4 k cid4cid3 τn1cid2 cid2 cid3 n r EFalsePositives E rnumE k0 k s cid3 1 r s cid4 nk The expected precision approximated EPrecision ETruePositives EFalsePositives ETruePositives To illustrate potential beneﬁt calculations evaluate accuracy computed expected recall precision particular numC numE learned unsupervised setting experiments Section 22 The results appear Table 5 The recall estimates 11 actual recall estimated number correct examples set extracted labels based handtagged test set City Film classes Further estimates reﬂect important qualitative difference large City Film classes compared smaller MayorOf Country classes Were increase sample size n Film class Country class 1000000 model predicts increase Film recall 81 versus 4 Country Thus equations allow informa tion extraction dynamically choose allocate resources match given precision recall goals absence handlabeled data 232 Estimating functionality relations Knowledge relations knowledge base functional valuable variety different tasks Previous work shown knowledge functional relations automatically detect contradictions text 1134 automatically identify extractor errors IE 1 For example know Headquartered relation functional document asserting Intel headquartered Santa Clara asserting headquartered Phoenix determine documents contradict error extraction In section illustrate Urns automatically compute probability phrase denotes functional relation The discussion section based set extracted tuples An extracted tuple takes form Rx y roughly x subject sentence y object R phrase denoting relationship If relation denoted R functional typically object y function subject x Thus discussion focuses possibility analysis easily extended symmetric case The main evidence relation Rx y functional comes distribution y values given x value If R denotes function x unambiguous expect extractions predominantly single y value outliers noise Example A Fig 4 strong evidence functional relation 66 70 extractions was_born_in Mozart PLACE y value An ambiguous x argument functional relation appear nonfunctional Example B refers multiple realworld individuals named John Adams distribution y values appears functional example C nonfunctional relation Logically relation R functional variable x maps unique variable y x y1 y2 Rx y1 Rx y2 y1 y2 Thus given large random sample ground instances R detect high conﬁdence R functional In text situation far complex ambiguity polysemy synonymy linguistic phenomena To decide R functional x x ﬁrst consider detect R locally functional particular value x We later combine local functionality probabilities estimate global functionality relation13 Local functionality given x modeled terms global functionality R ambiguity x 13 We compute global functionality average local scores weighted probability x unambiguous 738 D Downey et al Artiﬁcial Intelligence 174 2010 726748 Fig 4 Functional relations example A different distribution y values nonfunctional relations C Ambiguous x argument B functional relation appear nonfunctional We later outline EMstyle algorithm alternately estimates probability R functional probability x ambiguous Let θ f R probability Rx locally functional random x let Θ f vector parameters x represents probability x locally unambiguous random R Θ u vector relations R Likewise θ u x We wish determine maximum posteriori MAP functionality ambiguity parameters given observed data D arg maxΘ f Θ u P Θ f Θ uD By Bayes Rule cid6 cid5 cid5 cid6 cid6 cid5 P Θ f Θ uD P DΘ f Θ u P Θ f Θ u 6 We outline generative model data P DΘ f Θ u Let R x indicate event relation R locally func tional argument x x locally unambiguous R Also let D indicate set observed tuples deﬁne D Rx multiset containing frequencies extractions form Rx Let assume event R x assume given parameters local ambiguity local functionality conditionally independent We obtain following expression probability R x depends θ f R θ u x given parameters θ f Θ f Θ u R P cid6 cid5 x R θ u x We assume set data D Rx generated independently data parameters given R cid5 DΘ f Θ u P cid6 cid10 cid5 cid5 P D RxR cid6 x θ f R θ u x P cid5 D RxR x cid6cid5 Rx 1 θ f R θ u x cid6cid6 x From 7 R These independence assumptions allow express P DΘ f Θ u terms distributions D Rx given x holds We use singleurn model estimate probabilities based binomial distributions cid7 Let k max D Rx let n D Rx approximate distribution D Rx terms k n In singleurn model Rx locally functional unambiguous k binomial distribution parameters n p p precision extraction process If Rx locally functional unambiguous expect k typically smaller values Empirically ﬁnd underlying frequency frequent element R x case tends follow Beta distribution Under model probability evidence given R x cid5 P D RxR cid6 x cid5 k nR cid6 x P pk1 pnk cid4 cid3 n k And probability evidence given R x cid5 P D RxR cid6 x cid5 k nR cid6 x P cid4 1cid11 cid3 n k 0 cid5kα f 11 p cid5nβ f 1k p Bα f β f cid5 dp cid6 cid5 Γ n k β f Γ α f k n k Bα f β f Γ α f β f n n sum D Rx Γ Gamma function B Beta function α f β f parameters Beta distribution R x case practice estimated empirically Substituting Eq 9 Eq 7 applying appropriate prior gives probability parameters Θ f Θ u given observed data D However Eq 7 contains large product sumswith independent vectors coeﬃcients Θ f Θ u making diﬃcult optimize analytically If knew arguments ambiguous ignore computing functionality relation Like wise knew relations nonfunctional ignore computing ambiguity argument Instead initialize Θ f Θ u arrays randomly execute EMstyle algorithm arrive highprobability setting parameters Note Θ u ﬁxed compute expected fraction locally unambiguous arguments x R locally functional D Rxcid5 Eq 9 Likewise ﬁxed Θ f given x compute expected fraction locally functional relations R locally unambiguous x 8 9 D Downey et al Artiﬁcial Intelligence 174 2010 726748 739 Speciﬁcally repeat convergence 1 Set θ f R 2 Set θ u x 1 sR 1 sx cid7 cid7 x P R R P R x x D Rxθ u D Rxθ f x R R x cid7 In steps sums taken x R D Rx nonempty Also normalizer sR x likewise sx cid7 x θ u R θ f R By iteratively setting parameters expectations steps 1 2 arrive good setting parameters The algorithm experimentally investigated 34 showing technique effectively identiﬁes functional relations power effective contradiction detection 233 Synonym resolution The application Urns discuss resolving strings refer objects relations In text object referred multiple distinct namesUS United States refer country example Likewise relationships objects expressed multiple distinct paraphrases x capital y x capital y The Resolver performs Synonym Resolutiontaking input set extracted tuples discussed Is CapitalOfDC United States returning set clusters cluster contains coreferential object strings relationship strings 42 Here provide highlevel description Resolver employs Urnslike model deferring 42 details Consider task determining strings s1 s2 refer object based set tuples including s1 s2 argument Resolver speciﬁes urnbased generative process observed tuples set potential tuples si modeled labels balls urn actual observed tuples involving si modeled draws urn Resolver assumes s1 s2 refer object urn contents s1 maximally similar s2 urns differ greater lesser degree With assumption Resolver computes probability s1 s2 corefer based frequently participate similar tuples This method shown effective resolving synonymous strings practice 24 Related work In contrast bulk previous IE work focus unsupervised IE UIE Urns substantially outperforms previous methods Fig 2 In addition noisyor models compare experiments IE literature contains variety heuris tics repetition indication veracity extracted information For example Riloff Jones 33 rank extractions number distinct patterns generating plus factor reliability patterns Our work intended formalize heuristic techniques unlike noisyor models explicitly model distribution target error sets numC numE shown important good performance Section 221 The accuracy probability estimates produced heuristic noisyor methods rarely evaluated explicitly IE literature systems implicit use estimates For example bootstraplearning systems start set seed instances given relation identify extraction patterns relation patterns turn extract instances 3325130 As process iterates random extraction errors result overly general extraction patterns leading extract erroneous instances The accurate estimates extraction probabilities produced Urns help prevent concept drift Skounakis Craven 37 develop probabilistic model combining evidence multiple extractions super vised setting Their problem formulation differs classify occurrence extraction use binomial model false positive true positive rates classiﬁer obtain probability occurrence true positive Similar approaches explicitly account sample size n model distribution target error extractions Culotta McCallum 10 provide model assessing conﬁdence extracted information conditional ran dom ﬁelds CRFs Their work focuses assigning accurate conﬁdence values individual occurrences extracted ﬁeld based textual features This complementary focus combining conﬁdence estimates multiple occurrences extracted label In fact possible feature vector processed CRF 10 thought virtual urn m Urns The conﬁdence output Culotta McCallums model provide precision pm urn Our UIE task related previous work automatically devising logical statements text 2436 unsupervised semantic role labeling 412132 UIE distinct target output knowledge base factual relations interpretation text terms logic labeled semantic roles Because UIE approach operates large corpus attempt identify semantic assertions text corpus Instead focus factual assertions identiﬁed automatically relatively high precision extraction patterns present methods combining evidence Webscale 740 D Downey et al Artiﬁcial Intelligence 174 2010 726748 Our work similar spirit BLOG language specifying probability distributions sets unknown objects 28 As work BLOG models express observations draws unknown set balls urn Whereas BLOG intended general modeling framework probabilistic ﬁrstorder logic varying sets objects work directed modeling redundancy IE We provide supervised unsupervised learning methods model effective data sets containing thousands examples experiments demonstrating eﬃcacy practice One problems EMbased algorithm learning Urns parameters solve estimating parameter C size target set This problem commonalities classic capturerecapture problem ecology goal estimate size animal population capturing marking sample population resampling later time 31 There number signiﬁcant differences capturerecapture problem estimating Urns parameters First Urns attempts learn parameter C observations mingled samples confounding error distribution Second Urns characterize frequencies target set vary terms Zipﬁan shape parameter zC In order overcome additional parameter estimation diﬃculties Urns exploits problem structures textual domains fact extraction frequencies tend Zipf distributed 3 URNS Theoretical results The Urns model shown previous section effective practice UIE applications In section analyze Urns model theoretically To better understand behavior Urns like able characterize class probability increases extraction count Further like guarantee Urnss accuracy given suﬃcient unlabeled data How accuracy increase sample size Can parameters model learned unlabeled data general Speciﬁcally investigate following questions context singleurn model 1 In model rate probability extracted label target class increase number extractions k 2 What suﬃcient conditions accurate classiﬁcation given parameters model What sample size n suﬃcient achieve given level classiﬁcation accuracy 3 Can parameters model learned unlabeled data 4 Can Urns model provide accurate classiﬁcations extractions PAClearnability guaranteed We begin considering ﬁrst questions uniform special case previously introduced Section 201 The uniform case fully realistic provides qualitatively interpretable results useful illustration We address questions realistic Zipﬁan model experiments In notational convenience utilize place multiset numC multiset F C containing f 1 element C relative fraction balls labeled element We deﬁne F E similarly Then following expression adapted Eq 1 speciﬁes probability x element C given observed values k n f F C F E cid7 P x Ck n cid7 cid7 f k1 f nk f F C f F C F E f k1 f nk We refer classiﬁer output Urns function extracted labels binary value indicating Urnss probability greater 05 positive 05 negative 31 Theoretical results Known parameters This section presents theoretical results parameters Urns known In following examine Urns sets assumptions Uniform Special Case USC Zipﬁan Case ZC deﬁned Theorems 3 5 address question 1 model describing class probability increases number times k label extracted Speciﬁcally provide expressions increase odds ratio oddsk n P x Ck n1 P x Ck n terms k Theorems 4 7 address question 2 Let cknown indicate classiﬁer output Urns parameters known provide upper bounds expected error Eerrorcknown terms sample size n model parameters 32 Analyzing uniform special case The Uniform Special Case USC Urns model ﬁrst introduced Section 201 characterized following assumptions D Downey et al Artiﬁcial Intelligence 174 2010 726748 741 USC1 Each target label probability pC selected single draw error label corre sponding probability p E USC2 Each label C repeated balls urn label E pC p E USC3 Frequency observations k Poisson distributed Eq 2 321 Theoretical results USC The following theorem states odds ratio oddsk n increases k USC Theorem 3 In USC cid3 oddsk1 n oddsk2 n cid4k1k2 pC p E Proof Follows posterior probability USC Eq 2 P x Ck n 1 kenpC p E cid2 1 E C p E pC 10 11 Along assumption USC2 Theorem 3 illustrates USC odds element member target class increase exponentially repetition The increase hastened target error classes confusable pC increases relative p E How accurately classify extracted labels given parameters model sample size Let cknown indicate Urns classiﬁer parameters known The following theorem provides upper bound error cknown USC terms sample size n separability pC p E C E sets Theorem 4 In USC expected error Eerrorcknown cid9 sample size n satisﬁes n cid2 12pC ln 1cid9 pC p E 2 12 Proof Deﬁne model m threshold τ pC p E Pmx Ck n cid2 05 k cid2 nτ Pmx Ck n 05 Since calculate optimal threshold parameters known Eerrorcknown worse expected error model m utilizes potentially suboptimal threshold We express expected error model m set C E summing expected contribution label equal probability label appears number times resulting misclassiﬁcation cid7 cid7 cid7 cid7 2 cid12 cid13 errorcknown E xE kcid2nτ P kx E n xC knτ P kx C n C E 13 Employing Chernoff bounds bound probability given label deviates expected frequency misclassiﬁed The Chernoff bounds employ state random variable X Xi equal sum independent Bernoulli random variables Xi probability X exceeds expectation μ factor 1 δ δ 0 bounded cid7 cid5 cid6 X 1 δμ P e μδ23 Likewise probability X suﬃciently expectation bounded cid5 cid6 X 1 δμ P μδ22 e 14 15 δ 0 Let d pC p E Then cid2 cid2 P kx E n P kx E n kcid2nτ kcid2np E d2 cid5 k cid2 np E d2x E cid5 k npC d2x E nd212pC cid6 cid6 P cid3 P e inequality uses Chernoff bound Eq 14 μ npC δ d2pC Similarly bound Eq 15 742 D Downey et al Artiﬁcial Intelligence 174 2010 726748 cid2 knτ P kx C n cid2 P kx C n knpC d2 cid5 k npC d2x C nd28pC cid6 P e e nd212pC Algebra gives ﬁnal result cid2 Theorem 4 yields following corollary states assumptions USC weakly indicative extractor pC p E slightly greater zero provide arbitrarily accurate classiﬁer given suﬃciently large n This statement akin similar results boosting algorithms machine learning 35 Corollary 1 In USC cid9 0 extractor pC p E 0 achieve accuracy 1 cid9 given suﬃcient sample size n 33 Analyzing Zipﬁan singleurn case The USC reasonable approximation labels ﬂat tail Zipf curve clearly oversimpliﬁcation labels The following theorems analogous presented USC employ realistic Zipﬁan singleurn assumptions In particular assume target error sets governed known Zipf distributions described sizes C E shape parameters zC zE Further assume draws generated mixture Zipf distributions governed known mixing parameter p giving probability single draw comes C cid2 p f f F C 16 As experiments ﬁnd mathematically convenient work continuous representation commonly discrete Zipﬁan distribution Integrating continuous representation allow arrive closedform expressions class probability terms gamma functions Theorem 5 In discrete Zipﬁan case assumed ith frequent element C frequency αC izC αC normalization constant In continuous representation frequency element C random variable drawn choosing uniform x range 1 C 1 mapping x curve f C x αC xzC obtain frequency The normalization constant αC αC p cid14 C1 1 1 xzC dx 17 The normalization constant chosen draw C frequencies labels C set expected sum frequencies p desired The frequency element E deﬁned analogously We refer functions f C f E frequency curves As USC label ZC underlying frequency f assume observed count k Poisson distributed expected value nf Thus likelihood observing example set S denote C E sets total k times n draws P Z C kx S n 1 S S1cid11 1 nαS x enαS x zS k zS k dx 18 The solution equation terms incomplete gamma functions given Theorem 5 Eq 19 We state assumptions ZC follows ZC1 The distributions labels C E Zipﬁan deﬁned mixing parameter p That likelihood data governed Eq 18 ZC2 Conﬁdence increases repetition P x Ck increases monotonically k ZC3 The error label frequency curve positive probability mass minimum target label frequency αE izE αC C 1zE known E 1 ZC4 Analogously target label frequency curve positive probability mass maximum error label frequency αC izC αE known 1 ZC5 Both target error set nonzero probability mass urn p 1 p M known lower bound M 0 D Downey et al Artiﬁcial Intelligence 174 2010 726748 743 Assumptions ZC3 ZC4 encode assumption given suﬃcient number distinct labels urn high probability frequent labels target labels frequent error labels These assumptions allow establish PAC learnability unlabeled data To lend justiﬁcation assumptions note expect hold approximately Unsupervised Information Extraction applications The Zipﬁan nature extractions monotonicity ZC1 ZC2 known hold approximately practice Further assumption ZC3 certainly empirically true considers simple example target set element exist multiple lessfrequent misspellings error set Assumption ZC4 tends approximately true practice frequently extracted labels tend instances target class Assumption ZC5 nearly trivially true practice expect target error sets probability mass nonzero minimum value 331 Theoretical results ZC We start explicitly expressing odds element member target class increases number repetitions Theorem 5 In ZC odds ratio oddsk 1 n oddsk n k 1zC gk zC np C 1 αC hk 1zC k 1zE gk zE n1 p E 1 αE hk 1zE np C1zC αC n1p E1zE αE cid5 k cid5 h n cid6 cid5 n cid5 cid5k cid5 en P kx C n np αC 1zC gk zC np C 1 αC cid5 k cid5 g cid5 cid5 cid5 αcid5 s n z cid6 cid3 Γ cid5 1z cid5 k cid5 n scid5zcid5αcid5 cid4 cid3 Γ cid5 1z cid5 k cid4 cid5 n αcid5 assuming zC zE exactly equal 1 19 Proof Given C E k cid2 1 zC zE cid11 1 result obtained symbolic integration Mathematica algebra14 cid2 Theorem 5 utilize assumptions Zipﬁan mixture ZC1 Eq 19 closedform likelihood expression perform eﬃcient inference experiments Of course odds ratio given complex An illustration class probability varies k shown Fig 5 In order provide qualitative insights odds ratio simpliﬁed interpretable bound item future work We wish bound classiﬁcation error Urns ZC The following theorem provides bound relative error optimal classiﬁer utilizes Urns parameters precise frequencies label simply observed counts As optimal classiﬁer exhibits best classiﬁcation performance achieved extraction count Deﬁnition 6 The optimal classiﬁer classiﬁes label optimally given knowledge urn parameters precise frequency urn label Deﬁne τ classiﬁcation threshold optimal classiﬁer given n equal nτ From assumption ZC2 know single τ exists Then following theorem illustrates sample size increases expected error falls nearly linearly optimal classiﬁer Theorem 7 In ZC given δ 0 expected error urns bounded cid12 cid13 errorcknown E cid3 β K C δ K E δ C En1δ K C δ K E δ constants respect n deﬁned β expected error optimal classiﬁer 14 For reference speciﬁc Mathematica commands involved proof available online httpwwwcsnorthwesterneduddowneydata urnsIntegrationhtml 744 D Downey et al Artiﬁcial Intelligence 174 2010 726748 Fig 5 Probabilities assigned Urns model Uniform Special Case USC Zipﬁan Case ZC Zipﬁan shape parameters vary For ﬂat Zipf curves zC 045 zE 04 ZC similar USC ZC differs USC shape parameters increase diverge A zE value 11 implies errors high extraction frequency meaning k increases class probability ZC converges slowly USC In E 20000 C 500 p 09 n 10000 The constants K C K E deﬁned follows S denoting C E cid15 K S δ max 3δ 1 cid16 1 αS xzS xτ S 2 dx xτ 1cid11 S 1 20 xτ S deﬁned unique value f S xτ S τ αS normalization constant Eq 17 Proof Following proof Theorem 4 aggregate probabilities elements misclassiﬁed We present analysis expected error elements C set E set analogous When parameters known Urns makes errors optimal classiﬁer true frequency target label x greater threshold τ observed count nτ We bound probability element true frequency zC τ appears fewer nτ times n draws Chebyshevs inequality Chebyshevs inequality bounds αC x probability random variable Y expectation μ variance σ 2 appears suﬃciently far expectation cid5 P Y μ rσ cid6 cid3 1 r2 For Poisson random variable expected value p pression bounds probability deviation exceeds r misclassiﬁcation nαC x expected error C set zC nxτ n ex n equal smallest deviation resulting C integrating frequency curve f C following bound n Setting r n 0 p cid5 1 σ bounded cid5 cid12 cid13 errorC cknown E xτ Ccid11 cid3 cid3 βC min 1 1 1 nαC xzC xτ C 2 cid4 dx 21 βC fraction expected error optimal classiﬁer elements C probability mass elements C frequency τ Deﬁne γn 1 n xτ 1ncid11 C 1 1 nαC xzC xτ C 2 xτ Ccid11 cid3 dx cid2 min 1 1 1 nαC xzC xτ C 2 cid4 dx We claim γn cid3 K C δn1δ given theorem follows The proof claim proceeds induction First note n 1 case γ1 cid3 K C δ holds construction K C δthe second term max function Eq 20 equal γ1 Then assuming γn cid3 K C δn1δ consider n 1 case γn1 nγn n 1 xτ C 1n1 cid11 xτ C 1n 1 nαC xzC xτ C 2 dx cid3 K C δnδ n 1 1 n2 K C δ n 11δ cid3 nδ n 1δ n 11δ K C δn2 cid4 It remains cid3 nδ n 1δ n 11δ K C δn2 D Downey et al Artiﬁcial Intelligence 174 2010 726748 cid4 cid3 1 745 22 With algebra equivalent statement K C δn2n 1δ nδ cid2 n 1 From generalized binomial theorem n 1δ large nδ δnδ1 δ1 δnδ22 With algebra cid5 K C δn2 n 1δ nδ cid6 cid2 K C δδn1δ cid2 3n1δ 2 2 cid2 n 1 desired fact K C δ cid2 3δ cid2 34 Theoretical results unknown parameters In unsupervised classiﬁcation general given Urns parameters advance learn unlabeled data In section provide theorems bounding error unsupervised classiﬁcation parameter values unknown The following theorem shows high probability parameter values Urns estimated accurately unlabeled data total number distinct labels urn u C E increases n ﬁxed Theorem 8 In ZC δ cid9 0 given suﬃciently large u C E ﬁxed n obtain estimate parameters f C f E probability 1 δ estimate lies cid9 true parameter value Proof The frequency curves f C f E converted functions gC λ g E λ giving probability density particular frequency λ labels C resp E set These functions power law distributions For example error set case cid17 g E λ L E λ1zE zE 0 aE cid3 x cid3 b E x aE x b E 23 suitable constant L E zE indicates exponent original frequency curve The distribution error labels model completely characterized parameters L E zE minimal frequency aE maximal frequency b E The probability particular label appears k times n extractions written follows P kn ncid11 cid5 0 gC λ g E λ cid6 e λλk k dλ 24 Let gx gC x g E x When written form Eq 24 distribution k instance compound Poisson process existence effective estimators gx wellknown In particular Theorem 1 26 states x n obtain sequence estimates ˆgux gx E ˆgux gx2 o1 u Thus given δcid5 cid9cid5 0 probability 1 δcid5 u suﬃciently large It remains convert estimator gx estimators Urns parameters In rewritten model Eq 23 employ total parameters characterizing mixture components gC g E We present construction parameters g E gC case analogous ˆgux gx cid9cid5 Consider estimates ˆgux0 ˆgurx0 x0 rx0 αC C 1 That x0 rx0 suﬃciently small gC x0 gC rx0 zero assumption ZC3 By algebra region 1 zE zE ln gx0 ln grx0ln r zE continuous bounded function gx0 grx0 domain This implies estimate zE cid9 probability 1 δ given estimator ˆgu u suitably large Likewise L E continuous bounded function gx zE estimate L E effectively cid52 Thus minimal xi ˆgux M It remains obtain estimator limits support aE b E We begin minimal limit aE We construct 0 n uniform lattice estimates ˆguxi cid9 apart By assumption ZC5 g E x M x aE aE cid9 cid5 given cid9 suﬃciently small By taking u suitably large ensure probability 1 δ known constant M cid52 x j cid2 aE falling interval aE aE cid9 estimate ˆgux j xi aE ˆguxi gxi ˆguxi M cid52 probability 1 δ estimate cid9 aE Estimating M maximal limit support b E similar The procedure employed gC b E nonzero instead identify successive estimates ˆguxk ˆguxk1 differ suﬃciently large margin xk greater estimate aE By taking u suﬃciently large cid9 suﬃciently small probability 1 δ value xk cid9 b E cid2 cid5 746 D Downey et al Artiﬁcial Intelligence 174 2010 726748 341 PAC learnability Urns In section suﬃciently informative extractor follows Urns model PAC learn unlabeled data Here assume additional features label extraction counts example features include cooccurrence counts label textual contexts extractors 15 Our result expressed terms given ﬁxed concept class binary classiﬁers mapping input features 0 1 denoted Cas typical PAClearning setting assume target function having zero error C Our result requires separability criterion holds concept class C This criterion states distinct concepts C agree large fraction instance space Deﬁnition 9 A concept class Ccid5 cx c cid5x 1 cid9 cid9separable distinct concepts c c cid5 Ccid5 fraction examples x X We require extractor suﬃciently informative We state criteria terms minimal expected classiﬁcation error achieved extraction counts limit u n large This equivalent area confusion region Fig 1 deﬁne formally Deﬁnition 10 The area confusion region extractor cid18 τcid11 min τ 0 cid11 cid19 gC λ dλ g E λ dλ τ 25 Given deﬁnition state following result shows Urns able PAC learn unlabeled data Proposition 11 If C cid9separable given extractor follows ZC confusion region area 1 cid92 C PAClearnable unlabeled data Proof By Theorem 8 high probability obtain parameters Urns error cid9cid5 cid9cid5 0 Because optimal classiﬁcation threshold τ continuous bounded function Urns parameters Eq 25 Urns achieve accuracy arbitrarily close confusion region size Thus error Urns 1 cid92 given n u suﬃciently large meaning assigns classiﬁcations different target classiﬁer fewer 1 cid92 examples By separability criterion target concept hypothesis differs output Urns examples Thus algorithm returns concept c C similar output Urns return target concept cid2 35 Related work Joachims provides theoretical results supervised textual classiﬁcation use Zipﬁan structure text arrive error bounds Support Vector Machine classiﬁers textual data 23 The strong performance SVMs super vised experiments corroborate Joachimss claim classiﬁers effective textual data However contrast Joachimss work theoretical results experiments focused unsupervised case We Zipﬁan structure holds unsupervised learning possible certain assumptions Our result showing PAC Learnability guaranteed Urns model Proposition 11 extends previous result showing single monotonic feature suﬃcient PAClearn certain assumptions monotonic feature like extraction counts consider value increases monotonically class probability 13 The primary advantage result require extraction counts conditionally independent features given class strong assumption shown problematic practice 12 Our result avoids assumption exploiting problem structure inherent extraction expressed Urns model 4 Future work The techniques described paper leave open potential areas future work One important direction developing probabilistic model multiple extractors ﬂexible multiple urns The correlation model multiple urns limited handle small predeﬁned set distinct mechanisms Language modeling techniques UIE recent work leverage contextual information assessing extractions relying select set extraction patterns 152 However currently techniques rank extracted labels output probabilities classiﬁcations A model produces probabilities correctness labeled data like Urns leverages available contextual information important target future work D Downey et al Artiﬁcial Intelligence 174 2010 726748 747 When utilizing Urns UIE practice EMbased algorithm employ learn Urns parameters unlabeled data improved number ways The algorithm requires sample size hundreds thousands unlabeled observations class order effective illustrated Fig 3 For classes data plentiful relations extracted TextRunner parameter learning algorithm effective We expect Urns modiﬁed learn accurate parameters smaller data sets use priors robust likelihoodmaximization techniques Urns requires reasonable estimate precision extraction process known We demonstrated requirement prohibitive extracting instances classes drawn WordNet generic extraction patterns extraction frequency assumed adjusted unlabeled text way probabilities pro duced Urns offer large improvements previous techniques However Open IE systems TextRunner discover target relations text situation complex 3 In TextRunner extraction precision vary greatly discovered relations probabilities output Urns case accurate Automatically estimating extraction precision relations Open IE systems area future work 5 Conclusions This paper described methods identifying correct extractions UIE use handlabeled training data The Urns model estimates probability extraction correct based sample size redundancy corroboration multiple distinct extraction rules We described supervised unsupervised methods estimating parameters model data reported experiments showing Urns massively outperforms previous methods unsupervised case slightly better baseline methods supervised case We detailed applications general Urns model redundancy effective Our theoretical results accuracy Urns improves sample size parameters Urns estimated handlabeled data Urns guarantees PAClearnability unlabeled data given certain conditions Acknowledgements This research supported NSF grants IIS0535284 IIS0312988 DARPA contract NBCHD030010 ONR grants N000140210324 N000140810431 gifts Google carried University Washingtons Turing Center The ﬁrst author supported Microsoft Research Graduate Fellowship sponsored Microsoft Live Labs Google generously allowed issue large number queries XML API facilitate experiments We thank Pedro Domingos Anna Karlin Marina Meila Dan Weld helpful discussions Jeff Bigham comments previous drafts Also thanks Alex Yates suggesting consider problem References 1 E Agichtein L Gravano Snowball Extracting relations large plaintext collections Proc Fifth ACM International Conference Digital Libraries 2000 2 A Ahuja D Downey Improved extraction assessment better language models Human Language Technologies Annual Conference North American Chapter Association Computational Linguistics NAACL HLT 2010 3 M Banko M Cafarella S Soderland M Broadhead O Etzioni Open information extraction Web Proc IJCAI 2007 4 M Banko O Etzioni The tradeoffs traditional open relation extraction Proceedings ACL 2008 5 A Blum T Mitchell Combining labeled unlabeled data cotraining COLT Proceedings Workshop Computational Learning Theory Morgan Kaufmann Publishers 1998 pp 92100 6 M Cafarella D Downey S Soderland O Etzioni Knowitnow Fast scalable information extraction Web Proc EMNLP 2005 7 M Califf R Mooney Relational learning patternmatch rules information extraction Working Notes AAAI Spring Symposium Applying Machine Learning Discourse Processing AAAI Press Menlo Park CA 1998 pp 611 8 C Chang C Lin LIBSVM library support vector machines 2001 9 F Ciravegna Adaptive information extraction text rule induction generalisation Proc 17th International Joint Conference Artiﬁcial Intelligence IJCAI 2001 Seattle Washington 2001 pp 12511256 10 A Culotta A McCallum Conﬁdence estimation information extraction HLTNAACL 2004 11 MC Marneffe A Rafferty CD Manning Finding contradictions text ACL 2008 2008 12 D Downey Redundancy Webscale information extraction probabilistic model experimental results PhD thesis University Washington 2008 13 D Downey O Etzioni Look ma hands Analyzing monotonic feature abstraction text classiﬁcation Advances Neural Information Processing Systems NIPS 21 2008 January 2009 14 D Downey O Etzioni S Soderland A probabilistic model redundancy information extraction Proc IJCAI 2005 15 D Downey S Schoenmackers O Etzioni Sparse information extraction Unsupervised language models rescue Proc ACL 2007 16 O Etzioni M Cafarella D Downey S Kok A Popescu T Shaked S Soderland D Weld A Yates Webscale information extraction KnowItAll WWW New York City New York 2004 pp 100110 17 O Etzioni M Cafarella D Downey S Kok A Popescu T Shaked S Soderland D Weld A Yates Unsupervised namedentity extraction Web An experimental study Artiﬁcial Intelligence 165 1 2005 91134 18 O Etzioni M Cafarella D Downey A Popescu T Shaked S Soderland D Weld A Yates Methods domainindependent information extraction Web An experimental comparison Proc 19th National Conference Artiﬁcial Intelligence AAAI04 San Jose California 2004 pp 391398 19 D Freitag A McCallum Information extraction HMMs shrinkage Proceedings AAAI99 Workshop Machine Learning Infor mation Extraction Orlando Florida 1999 20 WA Gale G Sampson GoodTuring frequency estimation tears J Quantitative Linguistics 2 3 1995 217237 748 D Downey et al Artiﬁcial Intelligence 174 2010 726748 21 T Grenager CD Manning Unsupervised discovery statistical verb lexicon Conference Empirical Methods Natural Language Processing 22 M Hearst Automatic acquisition hyponyms large text corpora Proc 14th International Conference Computational Linguistics Nantes France 1992 pp 539545 23 T Joachims Learning Classify Text Using Support Vector Machines Methods Theory Algorithms Kluwer Academic Publishers Norwell MA USA 2002 24 M Liakata S Pulman From trees predicateargument structures Proceedings 19th International Conference Computational Linguistics Association Computational Linguistics Morristown NJ USA 2002 pp 17 25 W Lin R Yangarber R Grishman Bootstrapped learning semantic classes positive negative examples Proc ICML2003 Workshop The Continuum Labeled Unlabeled Data Washington DC 2003 pp 103111 26 WL Loh Estimating mixing density mixture power series distributions SS Gupta JO Berger Eds Statist Decision Theory Related Topics V Springer New York 1993 pp 8798 27 A McCallum Eﬃciently inducing features conditional random fields Proceedings Nineteenth Conference Uncertainty Artiﬁcial Intelligence Acapulco Mexico 2003 pp 403410 28 B Milch B Marthi S Russell D Sontag DL Ong A Kolobov Blog Probabilistic models unknown objects LD Raedt T Dietterich L Getoor SH Muggleton Eds Probabilistic Logical Relational Learning Towards Synthesis Dagstuhl Seminar Proceedings vol 05051 Internationales Begegnungs und Forschungszentrum für Informatik IBFI Schloss Dagstuhl Germany 2006 httpdropsdagstuhldeopusvolltexte2006416 date citation 20060101 29 K Nigam J Lafferty A McCallum Using maximum entropy text classiﬁcation Proc IJCAI99 Workshop Machine Learning Information Filtering Stockholm Sweden 1999 pp 6167 30 M Pasca D Lin J Bigham A Lifchits A Jain Organizing searching world wide web facts step The onemillion fact extraction challenge AAAI 2006 AAAI Press 2006 31 KH Pollock JD Nichols C Brownie JE Hines Statistical Inference CaptureRecapture Experiments Wildlife Society Monogr vol 107 1990 32 SD Richardson WB Dolan L Vanderwende Mindnet acquiring structuring semantic information text Proceedings 17th Interna tional Conference Computational Linguistics Association Computational Linguistics Morristown NJ USA 1998 pp 10981102 33 E Riloff R Jones Learning dictionaries information extraction multilevel bootstrapping AAAIIAAI 1999 34 A Ritter S Soderland D Downey O Etzioni Its contradiction A case study functional relations EMNLP 2008 35 RE Schapire The strength weak learnability Mach Learn 5 2 1990 197227 36 L Schubert Can derive general world knowledge texts Proceedings Second International Conference Human Language Tech nology Research Morgan Kaufmann Publishers Inc San Francisco CA USA 2002 pp 9497 37 M Skounakis M Craven Evidence combination biomedical naturallanguage processing BIOKDD 2003 38 S Soderland Learning information extraction rules semistructured free text Mach Learn 34 13 1999 233272 39 S Soderland O Etzioni T Shaked D Weld The use Webbased statistics validate information extraction AAAI04 Workshop Adaptive Text Extraction Mining 2004 pp 2126 40 R Storn K Price Differential evolution simple eﬃcient heuristic global optimization continuous spaces J Global Optim 11 4 1997 341359 41 RS Swier S Stevenson Unsupervised semantic role labelling Proceedings EMNLP 2004 pp 95102 42 A Yates O Etzioni Unsupervised resolution objects relations Web Proc HLT 2007