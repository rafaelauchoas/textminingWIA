Artiﬁcial Intelligence 244 2017 7094 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Constrained clustering constraint programming ThiBichHanh Dao KhanhChuong Duong Christel Vrain Univ Orléans INSA Centre Val Loire LIFO EA 4022 F45067 Orléans France r t c l e n f o b s t r c t Article history Received revised form 12 May 2015 Accepted 23 May 2015 Available online 29 May 2015 Keywords Constrained clustering Bicriterion clustering Constraint programming Modeling Global optimization constraint Filtering algorithm Constrained Clustering allows clustering task accurate integrating user constraints instancelevel clusterlevel constraints Few works consider integration different kinds constraints usually based declarative frameworks exact methods enumerate solutions satisfying user constraints ﬁnd global optimum optimization criterion speciﬁed In previous work proposed model Constrained Clustering based Constraint Programming framework It declarative allowing user integrate user constraints choose optimization criterion ones In article present new substantially improved model Constrained Clustering based Constraint Programming framework It differs earlier model way partitions represented means variables constraints It ﬂexible number clusters need set lower upper bound number clusters provided In order modelbased approach eﬃcient propose new global optimization constraints dedicated ﬁltering algorithms We framework easily embedded general process illustrate problem ﬁnding optimal Pareto bicriterion constrained clustering task We compare approach existing exact approaches based branchandbound approach graph coloring datasets Experiments model outperforms exact approaches cases 2015 Elsevier BV All rights reserved 1 Introduction Constrained Clustering received attention decade It allows clustering task accurate integrating user constraints Several kinds constraints considered First constraints limit size diameter clusters second enforce expert knowledge instances cluster mustlink cannotlink constraints Much work focused instancebased constraints adapted classi cal clustering methods handle mustlink cannotlink constraints A small number earlier studies considered integration different kinds constraints These studies based declarative frameworks offer exact methods enumerate solutions satisfying user constraints ﬁnd global optimum optimization criterion given For instance 1 SAT based framework constrained clustering proposed integrating kinds user constraints limited clustering tasks clusters A framework conceptual clustering based Integer Linear Programming proposed 2 In 3 presented model based Constraint Programming Corresponding author Email addresses thibichhanhdaounivorleansfr TBH Dao khanhchuongduongunivorleansfr KC Duong christelvrainunivorleansfr C Vrain httpdxdoiorg101016jartint201505006 00043702 2015 Elsevier BV All rights reserved TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 71 constrained clustering This model allows choose different optimization criteria integrate kinds user constraints As far know approach propose able handle different optimization crite ria popular constraints number clusters It based Constraint Programming CP paradigm constraint optimization problem constraint satisfaction problem modeled deﬁning variables domains expressing constraints variables Solving CP problem relies operations constraint propagation reduces domain variables removing inconsistent values branching divides problem subprob lems taking unassigned variable splitting domain parts It important notice modeling task Constraint Programming implies choices high impact eﬃciency approach choice variables choice constraints model development ﬁltering algorithms dedicated task use adapted search strategies solving model A point favor CP requirement getting exact solution relaxed metaheuristics local search methods For time fully investigated exact methods push eﬃciency framework far possible Approximate search strategies integrated future In paper propose new model Constrained Clustering based Constraint Programming signiﬁ cantly improved compared previous model 3 In previous model sets variables introduced variable cluster identifying cluster points variable point expressing assignment cluster The number clusters set The new model present contains variable point giving index cluster point belongs As result constraints enforcing solution partition breaking symmetries entirely different The new model lighter terms number variables It enables remove restriction number clusters bounds number clusters required Moreover order model eﬃcient developed dedicated global constraints optimization criteria minimizing maximal diameter maximizing split clusters minimizing withincluster sum dissimilarities The approach propose easily embedded general process task Constrained Clustering Consider ing Data Mining iterative interactive process composed classical steps task formulation data preparation application tool requiring set parameters validation results user specify task hand including constraints decide change settings according results Heshe decide change constraints removing relaxing constraints adding hardening constraints The modularity declara tivity model allow easily In paper illustrate integration model complex process considering bicriterion clustering problem ﬁnding Pareto minimizing maximal diameter maximizing minimal split To achieve framework integrated algorithm alternatively calls model minimize maximal diameter maximize split clusters adapted constraints Our contributions follows We propose new model based Constraint Programming allowing ﬁnd optimal solution clustering constraints given optimization criterion This new model improves substantially previous modular criterion implemented global constraint eﬃcient We framework easily embedded general process illustrate problem ﬁnding optimal Pareto bicriterion constrained clustering task As far know ﬁrst approach handle bicriterion clustering presence userconstraints We propose new global optimization constraints dedicated ﬁltering algorithms allowing model eﬃcient We compare model existing exact approaches based branchandbound approach 4 graph coloring 5 datasets Experiments model propose generally eﬃcient Moreover compare models based CP developed different changes search strategy development global constraints allow improve model The paper organized follows Section 2 dedicated preliminaries Constrained Clustering Constraint Programming Related work presented Section 3 Section 4 devoted presentation CP models ﬁrst presented 3 new The ﬁltering algorithms optimization criteria presented Section 5 We Section 6 framework easily integrated solving bicriterion constrained clustering task Experiments presented Section 7 showing performance ﬂexibility approach 2 Preliminaries 21 Constrained clustering Cluster analysis Data Mining task aims partitioning given set objects homogeneous andor separated subsets called classes clusters It formulated search partition objects inside cluster similar different objects belonging clusters These requirements usually expressed optimization criterion clustering task usually deﬁned ﬁnding partition objects 72 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 optimizes given criterion In remainder paper consider dataset n objects O o1 dissimilarity measure doi o j objects oi o j O A partition cid2 objects k clusters C1 Ck 1 c 1 k1 Cc cid4 2 c Cc O 3 c cid4 c Cc Cccid7 The optimization criterion cid7 Minimizing maximal diameter clusters maximal diameter partition cid2 largest dissimilarity objects cluster Dcid2 max c1koi o j Cc doi o j A clustering task minimizes criterion called nonhierarchical completelink clustering Maximizing minimal split clusters minimal split clusters partition cid2 smallest dissimilarity objects different clusters Scid2 min cccid71koi Cco j Cc cid7 doi o j A clustering task maximizes criterion called singlelink clustering Minimizing withincluster sum dissimilarities WCSD sum partition cid2 deﬁned WCSDcid2 cid2 c1k 1 2 cid2 oi o j Cc doi o j For criterion dissimilarity doi o j usually measured squared Euclidean distance oi o j Minimizing withincluster sum squares WCSS Euclidean space withincluster sum squares sum squared Euclidean distances object oi centroid mc cluster containing oi cid2 cid2 WCSScid2 oi mc2 c1k oi Cc Let notice squared Euclidean distance measuring dissimilarities WCSS criterion mathematically equivalent WCSD criterion standardized division size cluster WCSScid2 cid2 c1k 1 2Cc cid2 oi o j Cc doi o j Most clustering algorithms rely optimization criterion All criteria NPHard split crite rion In consequence algorithms search local optimum For instance kmeans algorithm ﬁnds local optimum WCSS criterion FPF Furthest Point First 6 diameter criterion Several optima exist closer expected user In order model task better hope reducing complexity user speciﬁed constraints added leading Constrained Clustering aims ﬁnding clusters satisfy user constraints User constraints classiﬁed clusterlevel constraints specifying requirements clusters instancelevel constraints specifying requirements pairs objects Most attention instancelevel constraints ﬁrst introduced 7 Commonly kinds constraints mustlink cannotlink A mustlink constraint objects oi o j expresses cluster c 1 k oi Cc o j Cc A link constraint objects oi o j expresses cluster c 1 k oi Cc o j Cc Clusterlevel constraints impose requirements clusters The minimum capacity constraint requires cluster number objects greater given threshold α c 1 k Cc α maximum capacity constraint requires cluster number objects inferior predeﬁned threshold β c 1 k Cc β The maximum diameter constraint speciﬁes upper bound γ diameter clusters c 1 k oi o j Cc doi o j γ The minimum split constraint called δconstraint 8 requires distance cid7 cid4 c oi Cc o j Cccid7 doi o j δ points different clusters superior equal given threshold δ c 1 k c As observed 8 maximum diameter constraint represented conjunction cannotlink constraints minimum split constraint represented conjunction mustlink constraints The cid7constraint introduced 8 requires point oi neighborhood radius cid7 point belonging cluster c 1 k oi Cc o j Cc o j cid4 oi doi o j cid7 This constraint tries capture notion density introduced DBSCAN 9 We extended proposing densitybased constraint stronger cid7constraint requires point oi neighborhood radius cid7 contains m points belonging cluster oi 1 For discrete variable 1 k denotes set integers 1 k TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 73 Fig 1 Effect different criteria A intuitive groups B complete link C single link D WCSS In years works extend classical algorithms handling mustlink link constraints This achieved modifying dissimilarity measure objective function search strategy Recently works investigated declarative approaches constrained clustering aim extending traditional algorithms different types user constraints A presentation works given Section 3 22 Bicriterion constrained clustering Clustering criterion minimizing maximal diameter aims ﬁnding homogeneous clusters suffers dissection effect 10 similar objects classiﬁed different clusters order diameters small On hand clustering criterion maximizing minimal split aims ﬁnding separated clusters suffers chain effect 11 chain closed objects lead group different objects cluster The popular WCSS criterion minimizes sum squared distances points center cluster suffers undesirable effects Considering criterion objects large group classiﬁed different clusters order sum small Fig 1 gives illustration effects Image A shows groups easily identiﬁed Image B shows obtained solution diameter criterion number clusters set 3 In partition points close classiﬁed different groups The partition obtained considering split criterion shown Image C Because chain effect largest group contains points far The optimal solution WCSS criterion shown Image D In partition points close grouped different clusters A good partition homogeneous wellseparated clusters minimal diameter maximal split Unfortunately partition general exist criteria conﬂicting This problem modeled considering bicriterion maximizing minimal split clusters minimizing maximal diameter introduced 5 Considering criteria natural allows capture homogeneity separation requirements good clustering A general approach handling optimization criteria ﬁnd Pareto optimal solutions A Pareto optimal solution solution possible improve value criterion degrading value A partition cid2cid7 dominates partition cid2 cid7 cid7 Dcid2 Dcid2 Dcid2 Scid2 cid7 Scid2 Dcid2 Scid2 cid7 Scid2 A partition cid2 Pareto optimal partition cid2cid7 dominates cid2 Two Pareto optimal solutions cid21 cid22 equivalent Dcid21 Dcid22 Scid21 Scid22 A set P Pareto optimal solutions complete Pareto optimal solution P equivalent element P The set P minimal partitions P equivalent The Pareto projection Pareto optimal solutions criterion space set pairs Dcid2 Scid2 cid2 Pareto optimal solution If P complete minimal set Pareto optimal solutions set Dcid2 Scid2 cid2 P equal Pareto Fig 2 gives illustration Pareto A point Pareto correspond partitions If user speciﬁes function criteria optimize example maxSD minα D 1 αS 0 α 1 optimal solution Pareto optima Let consider instance example given Fig 1 When number classes set 3 complete minimal set Pareto solutions given Fig 3 If ratio SD minimized optimal solution solution 5 74 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Fig 2 Pareto Fig 3 Pareto optimal solutions ﬁts best intuitive groups The user specify conditions desired solutions If instance speciﬁed points 5 14 cluster solutions 5 6 If condition added requiring size group 2 solution 5 A bicriterion clustering algorithm ﬁnding complete minimal set Pareto solutions different values number k clusters proposed 5 When k 2 exact polynomial algorithm proposed 1213 However best knowledge algorithm dealing bicriterion supporting kinds user constraints 23 Constraint programming Constraint Programming CP powerful paradigm solve combinatorial problems based Artiﬁcial Intelligence Operational Research methods A Constraint Satisfaction Problem CSP triple cid15 X Dom Ccid16 X cid15x1 x2 xncid16 ntuple variables Dom cid15Domx1 Domx2 Domxncid16 corresponding ntuple domains xi Domxi C cid15C1 C2 Ctcid16 ttuple constraints constraint Ci expresses condition subset X A solution CSP complete assignment values Domxi variable xi satisﬁes constraints C A Constraint Optimization Problem COP CSP objective function optimized An optimal solution COP solution CSP optimizes objective function In general solving CSP NPHard Nevertheless methods TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 75 Fig 4 Value graph alldifferentx1 x2 x3 Domxi 1 2 solvers enable eﬃciently solve large number real applications They rely constraint propagation search strategies Constraint propagation constraint c reduces domain variables c removing inconsistent values values solution c A set propagators associated constraint depends kind consistency required constraint If arc consistency required propagators remove inconsistent values domain If bound consistency required propagators modify bounds domains The type consistency chosen programmer constraint deﬁned Different kinds constraints available programmer elementary constraints expressing arithmetic logic relations global constraints expressing meaningful nary relations One best known global constraints constraint alldifferentx1 xn imposes variables xi pairwise different Global constraints beneﬁt eﬃcient propagation performed ﬁltering algo rithm exploiting results domains instance graph theory From logical point view global constraint equivalent conjunction elementary constraints constraint alldifferentx1 x2 x3 equivalent junction binary constraints x1 cid4 x2 x1 cid4 x3 x2 cid4 x3 The interesting point global constraint ﬁltering algorithm powerful propagation set propagators elementary constraints Different global constraints developed aims exploiting eﬃciently nary relation Filtering algorithms global constraints use operational research techniques graph theory achieve generalized arc consistency bound consistency low complexity A catalog global constraints 400 inventoried global constraints maintained 14 Example 21 Let X x1 x2 x3 Domxi 1 2 Let P 1 CSP deﬁned X constraints x1 cid4 x2 x1 cid4 x3 x2 cid4 x3 The arc consistency individual constraint xi cid4 x j remove value domains Domxi Domx j value solution xi 1 x j 2 xi 2 x j 1 The CSP P 1 inconsistent solution satisﬁes constraints propagation individual constraints detect Let P 2 CSP deﬁned X single constraint alldifferentx1 x2 x3 The ﬁltering algorithm constraint 15 maintains bipartite graph G V E V x1 x2 x3 1 2 E xi v v Domxi This bipartite graph called value graph X given Fig 4 A matching M E set disjoint edges edges M share vertex Two important observations relationship constraint alldifferentx1 xn matching introduced 15 There matching cardinality n constraint alldifferentx1 xn satisﬁable An edge xi v belongs matching cardinality n value v consistent constraint From observations ﬁltering algorithm detect inconsistencies remove inconsistent values In example bipartite graph G matching cardinality 3 The constraint alldifferentx1 x2 x3 inconsistent In CP solver steps constraint propagation branching repeated solution Constraints propagated stable state domains variables reduced possible If domains variables reduced singletons solution If domain variable exists solution current partial assignment solver backtracks In cases solver chooses variable domain reduced singleton splits domain different parts leading new branches search tree The solver explores branch activating constraint propagation domain variable modiﬁed The search strategy determined programmer If depthﬁrst strategy solver orders branches following order given programmer explores depth branch For constraint optimization problem branchandbound strategy integrated depthﬁrst search time solution complete assignment variables satisfying constraints value objective function solution computed new 76 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Fig 5 Search trees variable choice S E N D M O T Y left S T Y N D E M O right constraint added expressing new solution better Assume objective function represented variable y minimized When solution problem corresponding objective value f added This implies ﬁrst best solution returned solver The solver performs complete search pruning branches lead solution ﬁnds optimal solution The choice variables values branching important drastically reduce search space computation time computed constraint y f In context constraint optimization problems optimization constraint global constraint linked objective function Each solution induces cost global constraint exploits cost ﬁlter variable represents objective function decision variables inside constraint The ﬁrst ﬁltering algorithm kind global constraints proposed 16 A wellknown example extension global constraints optimization constraints constraint cost_gcc 17 extends Global Cardinality Constraint cost For details global constraints search generally CP refer reader 18 Example 22 Let illustrate simple COP ﬁnd assignment letters digits SEND MOST MONEY maximizing MONEY This problem modeled COP variables S E N D M O T Y having domain set digits 0 9 variable V domain integer represents objective function maximized Constraints problem ﬁrst digits different 0 S cid4 0 M cid4 0 values letters pairwise different alldifferentS E N D M O T Y 1000S 100E 10N D 1000M 100O 10S T 10 000M 1000O 100N 10E Y V 10 000M 1000O 100N 10E Y The initial constraint propagation leads stable state domains D S 9 D E 2 3 4 5 6 7 D M 1 D O 0 D N 3 4 5 6 7 8 D D D T D Y 2 3 4 5 6 7 8 Since domains reduced sin gletons branching performed At end search optimal solution assignment S 9 E 7 N 8 D 2 M 1 O 0 T 4 Y 6 leading MONEY 10 876 Strategies specifying way branching performed important When variables chosen order S E N D M O T Y values chosen following increasing order search tree composed 29 nodes 7 intermediary solutions solutions satisfying constraints better previous ones optimal When variables chosen order S T Y N D E M O search tree 13 nodes 2 intermediary lutions Fig 5 presents corresponding search trees generated Gist environment Gecode solver 19 In search trees blue circle represents stable state solution red square fail state solution green diamond intermediary solution orange diamond diamond optimal solution 3 Related work Due hardness clustering problem exact algorithms literature algorithms heuristic metaheuristic approximation algorithms Finding partition maximizing split clusters polynomial problem 5 NPHard user constraints cannotlink constraints 20 Concerning minimization maximal diameter problem polynomial k 2 NPHard k 3 21 An exact algorithm based graph coloring proposed 21 Graph coloring check distance objects maximal diameter Another exact approach uses branchandbound search 4 The algorithm uses hierarchical algorithm ﬁnd good bound reordering point strategy reduce search space For criterion minimizing withincluster sum dissimilarities repetitive branchandbound algorithm presented 4 To knowledge exact algorithm supports user constraints criteria k 2 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 77 For splitdiameter bicriterion optimization user constraints algorithm ﬁnding complete minimal set Pareto optimal solutions partitions kmax clusters proposed 5 It proved n points regardless number clusters k regardless partition split value edges minimum weight spanning tree constructed matrix dissimilarities objects These values ordered decreasingly split s value order On hand diameter value dissimilarities objects All dissimilarities ordered decreasingly diameter d value order Each couple s d considered case conﬂict induce graph Graph coloring induced graph helps ﬁnd partition minimum number clusters number chromatic number induced graph The algorithm ﬁnds complete minimal set Pareto optimal solutions Each solution partition kmax clusters In case bipartition k 2 exact polynomial algorithm ﬁnd Pareto optimal solutions proposed 1213 For k 2 13 offers 2approximation algorithm These algorithms 1213 based principle 5 spanning tree built ﬁnd possible values split graph coloring tests verify dissimilarity maximal diameter However bicriterion cluster analysis approaches support kind user constraints Most attention constrained clustering instancelevel constraints mustlink link constraints 22 They ﬁrst introduced Wagstaff 7 Subsequently works extend classical algorithms handling mustlink cannotlink constraints instance extension COBWEB 7 k means 2324 hierarchical nonsupervised clustering 25 spectral clustering 2627 When constraints tight algorithms ﬁnd solution satisﬁes constraints solution exists In recent years realized problems Data Mining including constrained clustering solved generic optimization tools Recent works investigate generic frameworks Constraint Programming SAT Integer Linear Programming In 28 L De Raedt et al present framework Constraint Programming kpattern set mining applied conceptual clustering In conceptual clustering intentional deﬁnition represented pattern associated cluster The objective ﬁnd pairs composed clusters patterns elements cluster satisfy pattern Constraints imposed patterns clusters In order ﬁnd interesting solutions optimization criteria introduced JP Métivier et al present 29 constraintbased language expressing queries discover patterns Data Mining Conceptual clustering tasks expressed queries kinds user constraints The language elements translated SAT clauses solved SAT solver Davidson et al propose SAT framework 1 constrained clustering problems k 2 Several kinds constraints considered mustlink cannotlink diameter split constraints The algorithm allows obtain global optimum criterion diameter split Mueller et al propose 2 approach constrained clustering based Integer Linear Programming This approach takes set candidate clusters input builds clustering selecting suitable subset It allows different kinds constraints clusters set clusters constraint individual objects It integrates different objective functions based quality clusters composing clustering The framework guarantees ﬁnd global optimum requires set candidate clusters This condition makes framework applicable clustering general ﬁnding good set candidate clusters diﬃcult task number candidate clusters exponential compared number objects This approach experimented conceptual clustering candidate clusters generated frequent patterns Recently Babaki et al present 30 exact approach constrained clustering criterion minimizing withincluster sum squares based Integer Linear Programming This approach extends exact algorithm uses column generation 31 It allows mustlink cannotlink constraints antimonotone User constraints handled branchandbound search generating new columns This approach experimented 30 small datasets containing 200 objects For clustering task maximizes intercluster distances Kotthoff et al present talk 32 Constraint Programming approach assert ﬂexibility opportunities provided CP formulation Other tasks clustering based similarity graph objects Spectral clustering clustering task aims minimizing ratio cut criterion2 33 Wang et al present 2734 ﬂexible framework spectral clustering The framework integrates different kinds constraints allows specify threshold setting lower bound given constraints satisﬁed Zhi et al present 35 framework spectral clustering integrates logical combinations constraints Logical combinations constraints expressed linear equalities inequalities incorporated mathematical programming formulations clustering Multiview spectral clustering extension spectral clustering multiview datasets Instead combining different views single objective function Davidson et al propose 36 natural formulation treats problem multiobjective problem solve Pareto optimization 2 Based similarity measure soi o j objects ratio cut criterion deﬁned 12 cid3 cid3 c1k1Cc oi Cc o j Cc soi o j 78 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Table 1 Comparison models Variables Partition User constraints Optimization Criterion First model I I1 Ik DomIc 1 n G G 1 Gn DomG 1 n Second model G G 1 Gn DomG 1 kmax D diameter S split V WCSD precedeG 1 kmax atleast1 G kmin cid7 1 k Ic Iccid7 c 1 k elementG Ic Ic 1 n exactly1 I G 1 n G c c I1 1 Minimal size α clusters 1 n atleastα G G Maximal size β clusters c 1 kmax atmostβ G c Minimal split δ S δ G G j j st di j δ Maximal diameter γ D γ G cid4 G j j st di j γ Density constraint 1 n atleastm Nicid7 G Mustlink constraint G G j D di j Cannotlink constraint G cid4 G j S di j j 1 n di j D G cid4 G j diameterG D d WCSD criterion wcsdG V d Diameter criterion j 1 n di j S G G j splitG S d Split criterion The clustering tasks interested aim ﬁnding partition objects Another clustering approach hierarchical clustering aims ﬁnding hierarchy partitions sequence nested partitions The result tree diagram called dendrogram A framework formalizing hierarchical clustering Integer Linear Programming problem recently proposed Gilpin et al 37 Gilpin et al propose 38 framework based SAT hierarchical constrained clustering different types user constraints Another clustering setting correlation clustering based similarity graph objects aims ﬁnding partition agrees possible similarities Berg et al present 39 MaxSAT framework constrained correlation clustering In framework hard clauses ensure welldeﬁned clustering soft clauses encode cost function In paper investigate use Constraint Programming constrained clustering Constraint Programming shown promising approach Data Mining tasks itemset mining 4044 skypattern mining 45 decision tree construction 46 4 New CP model constrained clustering We given collection n points dissimilarity measure pairs points j denoted di j Without loss generality let suppose points indexed named index 1 represents ﬁrst point The model aims ﬁnding partition k clusters satisfying set user constraints optimizing given criterion The model propose composed set CP constraints They model partition requirements optimization criterion different kinds user constraints Thus separated groups CP constraints expressing result partition CP constraints expressing user constraints CP constraints expressing criterion optimized Please note optimization criterion given CP solver searches partitions satisfying constraints In previous work 3 presented CP model task This model based twolevel representation set variables assignment representative cluster set variables assignment representative point Choosing representation requires number clusters k ﬁxed representative modeled CP variable In paper introduce new CP model based set variables assignment number index cluster point As result number clusters k bounded kmin kmax kmin kmax given user In following present models ease comparison In models CP constraints expressing user constraints similar express partition requirements optimization criteria different All optimization criteria new model expressed new global constraints ﬁltering algorithm The differences models signiﬁcant new model variables constraints eﬃcient previous model Table 1 summarizes differences models TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 79 41 Variables In ﬁrst model cluster c 1 k point smallest index considered representative point cluster3 An integer variable Ic introduced value index representative point cluster c domain Ic set integers 1 n Let I array I1 Ik Assigning point cluster assigning point representative cluster Therefore point 1 n integer variable G 1 n introduced G representative point cluster contains point Example 41 Assume 7 points o1 o7 2 clusters ﬁrst composed o1 o2 o4 second composed remaining points The points denoted index o1 denoted 1 o2 2 Then I1 1 I2 3 1 smallest index 1 2 4 3 smallest index 3 5 6 7 G 1 G 2 G 4 1 1 representative ﬁrst cluster G 3 G 5 G 6 G 7 3 3 representative second cluster In new model clusters identiﬁed index varies 1 k partition k clusters To represent assignment points clusters use integer variables G 1 Gn domain set integers 1 kmax An assignment G c means point cluster number c The domains variables G models different meaning variables identical represent assignment points clusters Let G denote array G 1 Gn To represent optimization criterion models ﬂoat value variable introduced It named D diameter criterion S split criterion V WCSD criterion Their domains DomD mini jdi j DomS maxi jdi j DomV 0 42 Partition constraints 421 First model To express result partition following constraints Each representative belongs cluster c 1 k G Ic Ic This constraint represented CP constraint elementG Ic Ic The constraint element A B C A array variables B C variables sets relation AB C Each point assigned representative 1 n need c1kG Ic This relation expressed c Ic G 1 represented CP constraint exactly1 I G This constraint sets relation requiring value G appear exactly array I The representative cluster point minimal index cluster words index cid4 point greater equal index representative given G 1 n G A set clusters differently represented depending order clusters For instance Example 41 chosen I1 3 I2 1 leading representation set clusters To avoid symmetry following constraints added The representatives sorted increasing order c c The representative ﬁrst cluster ﬁrst point I1 1 cid7 1 k Ic Iccid7 422 Second model In model clusters identiﬁed number index variable G gives index cluster contains point A complete assignment variables G represents partition However partition represented different complete assignments G For instance given complete assignment G permutation variables G value c1 value c2 time variables G j having value c2 value c1 new assignment G represents partition terms clusters As second example variables G value c1 receive value c3 assignment variables G leads new assignment representing symmetric solution Such situation appears building clusters new created cluster receive value remaining cluster numbers To break kind symmetries clusters numbered number 1 index ﬁrst created cluster new number c c 1 number c 1 A straightforward way express condition constraint G 1 1 constraints G max j1i1G j 1 2 n However order better interactions propagations relations better way sum relations global constraint good ﬁltering algorithm The constraint precede 47 helps achieve 3 It allows single representation cluster It confused notion representative medoid approach 80 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 precedeG 1 kmax This constraint imposes G 1 1 G c 1 c kmax exist index j G j c 1 The requirement kmin clusters means numbers 1 kmin assignment variables G When constraint precede needs require variable G equal kmin This expressed relation G kmin 1 represented CP constraint atleast1 G kmin Since domain variable G 1 kmax kmax clusters If user needs exactly k clusters heshe set kmin kmax k 43 User constraints All popular userdeﬁned constraints straightforwardly integrated They expressed way models rely use variables G represent assignment points clusters Minimal size α clusters means point cluster α points including For 1 n assigned value variable G appear α times array G j G j G α Therefore 1 n constraint atleastα G G This constraint helps set bound number possible clusters Indeed number clusters exceed cid20nαcid21 In second model expressed G cid20nαcid21 1 n Maximal size β clusters number c 1 kmax appear array G β times true unused value c kmin 1 kmax appears 0 time G c β Therefore c 1 kmax constraint atmostβ G c Minimal split δ δconstraint requires split clusters δ Therefore couple j 1 n di j δ constraint G G j The constraint S δ Maximal diameter γ diameter constraint requires diameter cluster γ The constraint D γ couple j 1 n di j γ G cid4 G j Density constraint density constraint expresses point neighborhood radius cid7 m points belonging cluster So 1 n set variables corresponding points cid7neighborhood computed Nicid7 G j di j cid7 constraint atleastm Nicid7 G Mustlink constraint mustlink constraint points j expressed G G j D di j Cannotlink constraint cannotlink constraint j expressed G cid4 G j S di j 44 Optimization criteria In ﬁrst model proposed model optimization criterion reiﬁed CP constraints When minimizing maximal diameter D represents maximal diameter points distance greater D different clusters j 1 n di j D G cid4 G j Since D variable value unknown relations expressed reiﬁed constraints4 When maximizing minimal split clusters points distance minimal split S cluster j 1 n di j S G G j Since S variable relations expressed reiﬁed constraints When minimizing WithinCluster Sum Dissimilarities WCSD cid2 V G G jdi j j1n For relation developed global constraint wcsdG V d ﬁltering algorithm 4 A reiﬁed constraint logical constraint form A B A B A B constraints The reiﬁed constraint A B means constraint B satisﬁed A satisﬁed A satisﬁed B satisﬁed TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 81 When minimizing diameter 3 use heuristics provided algorithm FPF 6 lower upper bound diameter user constraints upper bound presence user constraints Such bounds allow reduce number reiﬁed constraints model In new model diameter split criteria instead reiﬁed constraints develop global straints diameterG D d splitG S d exploit measure d operate array G variable D S The ﬁltering algorithms constraints diameterG D d splitG S d wcsdG V d presented Section 5 If user speciﬁes optimization criterion objective function model minimize D case minimizing maximal diameter maximize S case maximizing minimal split minimize V case minimizing WCSD When optimization criterion speciﬁed exist solutions satisfy constraints solver ﬁnds global optimal solution If user specify optimization criterion solver ﬁnds solutions satisfying constraints exist 45 Search strategy cid7 Symmetry breaking partition constraints models based indices points constraints ﬁrst model constraint precedeG 1 kmax second model The way points Ic Iccid7 c c indexed important Points reordered reindexed points far small index In order achieve rely Furthest Point First algorithm 6 This algorithm starts choosing point marks ﬁrst head links points iterates points marked At iteration chooses point furthest head marks new head links points closer head The search strategy ﬁrst model based instantiating variables I variables G This means cluster representatives identiﬁed assigning points clusters Variables I chosen I1 Ik Since representative point minimal index cluster values instantiating Ic chosen increasing order The choice variables values G depends criterion For diameter split criteria variable G smallest remaining domain chosen Recall value j DomG index cluster representative All values DomG examined value j corresponds smallest value di j chosen alternatives created G j G cid4 j In new model search strategy based choice variables values G depends criterion For diameter split criteria branching point variable G smallest remaining domain chosen Recall value c DomG number cluster All values DomG examined number closest cluster chosen The distance point cluster number c deﬁned maximal distance di j G j instantiated c If cluster number c point j G j c distance cluster c set zero This means assignment point new cluster favored unused cluster numbers Moreover smallest remaining number chosen The closest cluster c point chosen alternatives created G c G cid4 c Concerning WCSD criterion mixed strategy models In order good upper bound variable V greedy search quickly ﬁnd solution At step chosen variable G value c assignment G c increases V little possible The ﬁrst solution good general After ﬁnding ﬁrst solution strategy changes ﬁrstfail tends detect failures quickly In strategy value sic point cluster c deﬁned sum dissimilarities points j assigned cluster c At branching point points G uninstantiated minimal value si mincDomG sic computed The variable G largest value si chosen value c arg min sic chosen 5 Filtering algorithms optimization criteria For optimization criterion developed ﬁltering algorithm global constraint links variables G representing partition variable representing objective function D S V This kind global constraints called optimization constraint 18 When solution corresponding objective value com puted constraint expressing new solutions better value added This constraint sets new upper bound D V minimized new lower bound S maximized By reasoning globally objective variable variables representing partition interactions domains variables captured search subspaces pruned instantiating vari ables 82 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Algorithm 1 Filtering constraint diameterG D d 1 stack 2 Dub changed 3 4 1 n G instantiated stack stack 5 6 7 foreach G instantiated stack stack 8 foreach stack j 1 n 9 10 11 di j Dub delete valG DomG j G j instantiated valG valG j Dlb maxDlb di j 51 Diameter split criteria To represent relations points diameter split develop ﬁltering algorithms global constraints diameterG D d splitG S d exploit dissimilarity measure d points operate array G variable D S The constraint diameterG D d ensures D maximal diameter clusters formed variables G 1 Gn This constraint ensures j 1 n D di j G cid4 G j 1 This kind relation realized reiﬁed constraints previous model 3 However reiﬁed constraint needed couple j implies number reiﬁed constraints quadratic respect number points By developing constraint diameterG D d maintain relations constraint The ﬁltering algorithm presented Algorithm 1 In algorithm DomD represented Dlb Dub Dlb lower bound initially minimal dissimilarity points Dub upper bound value D previous solution The bound Dub strict branchandbound search solution D value strictly smaller previous The relation 1 useful following cases happen The upper bound Dub changed new solution diameter constraint In case couple j Dub di j conclude D di j 1 infer G cid4 G j However relation G cid4 G j useful ﬁlter domain G domain G j variable G j G resp instantiated Therefore Algorithm 1 uses stack remember variables G instantiated lines 14 exploits ﬁlter line 10 The lower bound Dlb possibly revised line 11 Some variables G instantiated In case couple j G G j instantiated value infer D di j revise Dlb The stack remembers variables G instantiated lines 67 This lead revision lower bound Dlb line 11 Let notice soon domain variable failure case detected solver The worst case complexity O n2 This algorithm awaken upper bound D modiﬁed variable G instantiated However complexity scheduled effective constraints propagators lower complexity instance constraints representing mustlink cannotlink constraints The constraint splitG S d hand maintains S minimal split clusters formed variables G 1 Gn It ensures j 1 n S di j G G j 2 The ﬁltering algorithm presented Algorithm 2 DomS Slb Sub The lower bound Slb value S previous solution S maximized In manner constraint diameterG D d algorithm invoked lower bound Slb changed variables G instantiated In algorithm Slb changed couple j Slb di j 2 infer G G j propagated enforcing DomG DomG j Otherwise variables G instantiated G cid4 G j 2 infer S di j upper bound S changed The worst case complexity O n2 52 Withincluster sum dissimilarities criterion We developed ﬁltering algorithm new global optimization constraint wcsdG V d links vari able V array variables G exploits dissimilarity measure d This constraint ensures relation TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 83 Algorithm 2 Filtering constraint splitG S d 1 stack 2 Slb changed stack 1 n 3 4 5 foreach DomG changed stack stack 6 foreach stack j 1 n 7 8 9 10 di j Slb DomG DomG DomG j DomG j DomG 11 G G j instantiated valG cid4 valG j Sub minSub di j cid2 V 1i jn G G jdi j 3 G G j 1 G G j value 0 The ﬁltering algorithm ﬁrst model motivations proofs experiments presented 48 However 48 algorithm designed clustering task exactly k clusters case considered ﬁrst model We present revision algorithm clustering tasks number clusters bounded considered second model Let assume partial assignment variables G Let K 1 n G assigned U 1 n G unassigned We use computation lower bound proposed 49 takes account unassigned variables The sum deﬁning V split parts V V 1 V 2 V 3 V 1 sum dissimilarities assigned points V 1 G G jdi j V 2 sum dissimilarities unassigned points assigned points V 2 G G jdi j V 3 sum dissimilarities unassigned points V 3 G G jdi j cid2 jK j cid2 iU jK cid2 jU j Since set K known exact value V 1 computed Since points U assigned cluster value V 2 unknown However lower bound V 2 denoted V 2lb computed sum minimal contribution unassigned points For unassigned point U value c DomG represents index cluster point assigned If point assigned cluster number c contribute cluster sum dissimilarities point assigned points cluster c sum dissimilarities di j j K G j c The minimal contribution v 2i point minimal added considering values DomG respect assigned points cid2 v 2i min cDomG di j jK G j c A lower bound V 2lb V 2 computed sum v 2i U V 2lb cid2 v 2i iU The exact value V 3 unknown use heuristic compute lower bound V 3 We recall V 3 sum di j j U j cluster Let p cardinality U let k cardinality union iU DomG Each value iU DomG index possible cluster points U assigned The number k maximal number clusters points U assigned We minimal number terms di j sum V 3 minimal number withincluster pairwise connections considering partitions p points k clusters Let m quotient division p k m cid7 km2 It proved 48 total number withincluster pairwise connections clusters greater equal f p k The equality remainder Let f p k km2 2mm cid7 84 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Fig 6 Example V lb V 1 V 2lb V 3lb cid7 reached m clusters m elements Therefore set U unassigned points order increasingly constants di j j U lower bound V 3 denoted V 3lb computed sum f p k ﬁrst constants order clusters m 1 elements k m cid7 Example 51 Let consider case given Fig 6 14 points grouped 2 clusters Assume 7 points grouped 7 The exact value V 1 computed sum solid black lines The lower bound V 2lb sum dash lines unassigned points With 7 unassigned points p 7 k 2 m 3 cid7 1 minimal number connections f 7 2 9 The lower bound V 3lb sum dotted lines Theses lines m 9 smallest lines connect unassigned points The lower bound V 3lb heuristic lines correspond case 7 unassigned points grouped 2 groups Assume domain variable V V lb V ub V lb lower bound initially 0 V ub upper bound value V previous solution The upper bound V ub strict branchandbound search solution better previous solution Given partial assignment variables G new lower bound variable V computed V lb maxV lb V 1 V 2lb V 3lb We use lower bound ﬁltering algorithm wcsdG V d The algorithm presented Algorithm 3 The lower bound V lb purposes Detecting failure branchandbound search A failure happens V lb V ub means domain V Filtering inconsistent values unassigned variables For unassigned variable G value c DomG assumption G c propose revise lower bound constant time If revised value greater equal upper bound V ub c inconsistent removed DomG Since constants di j j U j ordered increasingly computation V 3lb ordered array ord time arrays px py constructed For value pos ordpos gives value di j order position pos pxpos pypos gives index j respectively constant The arrays ord px py given input Algorithm 3 This algorithm computes arrays add m addi c added assigned cluster number c addi c jK G j c di j mi minimal added considering possible assignments mi mincDomG addi c Lines 1 26 computes lower bound V based partial assignment variables G Lines 27 29 ﬁlter domain uninstantiated variables G follows For uninstantiated variable G value c DomG cid7 3lb case assignment cluster number c new lower bound V lb revised V cid7 2lb V cid7lb V V cid3 cid7 1 cid7 1 cid7 2 V V 1 addi c point supposed assigned cluster c sum dissimilarities instanti ated points increased addi c V V 2lb mi point unassigned contribution point computation V 2lb V removed cid7 3lb sum ﬁrst f U k elements related U increasingly ordered array ord cid7 3lb Here V 4 sum ﬁrst In order revise bound constant time actually use V 4 instead V f U 1 k f p 1 k elements ord These elements related U possible cid7 3lb V 4 The value V 4 computed independently c related It evidence V line 24 The revised lower bound case assignment point cluster c TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 85 Algorithm 3 Filtering algorithm wcsdG V d input U set unassigned variables G ord array dissimilarities di j j U j ordered increasingly px py arrays giving index j wrt ord output compute new lower bound V ﬁlter unassigned variables G 1 V 1 0 V 2lb 0 V 3lb 0 V 4 0 2 1 n G unassigned 3 4 5 c DomG addi c 0 addi c c 1 kmax 6 1 n G assigned 7 8 9 10 c valG j 1 n G j assigned valG j c j V 1 V 1 di j G j unassigned c DomG j add j c add j c di j 11 1 n G unassigned 12 13 14 mi foreach value c DomG mi addi c mi addi c V 2lb V 2lb mi 15 16 p cardU 17 k cardiU DomG 18 cpt 0 pos 1 19 cpt f p k 20 21 22 23 24 pxpos j pypos G unassigned G j unassigned cpt cpt 1 V 3lb V 3lb ordpos cpt f p 1 k V 4 V 4 ordpos pos pos 1 25 26 V lb maxV lb V 1 V 2lb V 3lb 27 1 n G unassigned foreach value c DomG 28 29 V lb addi c mi V 3lb V 4 V ub delete c DomG V 1 addi c V 2lb mi V cid7 3lb greater equal V lb addi c mi V 3lb V 4 So value greater equal actual upper bound V point assigned cluster c The value c inconsistent removed DomG The complexity algorithm O n2 nk O n2 nkmax domain G size kmax Since kmax n complexity O n2 6 Bicriterion splitdiameter constrained clustering Our CP model represents general declarative framework constrained clustering user choose different optimization criteria integrate different kinds user constraints This ﬂexibility offers different ways framework We section applied handle bicriterion constrained clustering tasks Let consider constrained clustering task set C user constraints possibly We aim com puting Pareto constrained clustering task bicriterion min D max S One approach achieve described Algorithm 4 comparable cid7constraint approach presented 50 In algorithm optimiza tion steps single criterion iterated time condition value criterion The function Maximize_SplitC Minimize_DiameterC means use model optimization criterion maximizing split minimizing diameter respectively set constraints C It returns optimal solution satis ﬁes constraints C exists NULL We prove algorithm computes complete minimal set Pareto optimal solutions Proposition 61 Let cid2D 1 cid2S 1 cid2D m cid2S m partitions visited Algorithm 4 We 1 partition cid2 satisfying C Dcid2 Dcid2D 1 86 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Algorithm 4 Algorithm computing complete minimal set P cid2S 1 cid2S m Pareto optimal solutions input C set user constraints output P complete minimal set Pareto optimal solutions 1 P 2 1 3 cid2D 4 cid2D 5 cid2S P P cid2S 1 cid2D 6 7 8 9 Return P Minimize_DiameterC cid4 NULL Maximize_SplitC D Dcid2D Minimize_DiameterC S Scid2S i1 cid4 NULL cid2S cid4 NULL 2 cid2D 3 2 m Scid2S Scid2S i1 4 1 m Dcid2S Dcid2D 5 2 m Dcid2D Dcid2D i1 6 1 m partition cid2 satisfying C Scid2 Scid2S 7 1 m partition cid2 satisfying C Scid2 Scid2S Dcid2 Dcid2D i1 Dcid2 Dcid2S Proof 1 Since cid2D 1 partition minimizes diameter partitions satisfying user constraints C line 3 exists partition cid2 satisfying C Dcid2 Dcid2D 1 2 If cid2D cid4 NULL cid2D Moreover set ﬁnite set partitions ﬁnite There exists partition satisfying constraints maximizing split satisﬁes set C condition D Dcid2D set partitions satisfying C D Dcid2D partitions satisfying C S Scid2S i1 line 8 Scid2D partitions satisfying C D Dcid2D cid2S Scid2S i1 Since cid2D satisﬁes maximizes split 3 Since cid2D C D Dcid2D line 5 Scid2S Scid2D Therefore Scid2S Scid2S i1 1 minimal diameter partitions satisfying userconstraints C 4 To prove distinguish cases 1 satisﬁes C Dcid2D 1 Dcid2D 1 cid2S Case 1 cid2S Dcid2S Case 2 Since cid2S precedent item Scid2S diameter ones satisfying C S Scid2S 5 For 2 set partitions satisfying C S Scid2S partition satisfying set C D Dcid2D satisﬁes C S Scid2S i1 cid2S Scid2S 1 belongs partitions satisfying D Dcid2D i1 line 8 Dcid2S 1 Dcid2D 1 Dcid2D 1 So Dcid2S line 5 Dcid2S i1 Since cid2D As proven partition minimizes Dcid2D 1 subset set partitions satisfying C Therefore i1 subset set partitions satisfying i1 partitions minimize diameter Therefore Dcid2S Dcid2D 1 For 3 set partitions satisfying C S Scid2S i2 Scid2S 2 Dcid2D Dcid2D C S Scid2S ones respective sets Dcid2D In cases 2 m Dcid2D constraints entail set partitions maximal split contradicts Scid2S Therefore Dcid2D i1 Dcid2D i1 Scid2S i2 Since cid2D i1 If Dcid2D Dcid2D i1 Scid2S Dcid2D Scid2S cid2D Dcid2D i1 6 Assume exists partition cid2 satisﬁes C Scid2 Scid2S Dcid2 Dcid2D Scid2S cid2D Dcid2 Dcid2D i1 partition minimizes diameter satisfying condition S Scid2S i1 This contradicts fact Dcid2 Dcid2D i1 7 Assume exists partition cid2 satisfying C Scid2 Scid2S cid2 satisﬁes C D Dcid2D By line 5 cid2S Dcid2D C D Dcid2D Scid2 Scid2S This contradicts fact Scid2 Scid2S cid2 By point 4 Dcid2 Dcid2 Dcid2S partition maximizes split satisfying i1 line 5 i1 Scid2S i1 Since Scid2 Fig 7 illustrates positions solutions Algorithm 4 according Proposition 61 The left image presents 1 By point 7 2 1 By point 6 2 ﬁrst steps By point 1 partition dark zone line D Dcid2D 1 line D Dcid2D partition segment S Scid2S dotted line partitions white zone dotted line dominated cid2S partition grey zone line D Dcid2D 2 By point 7 partition segment S Scid2S 1 By point 5 line 8 Algorithm 4 partition cid2D TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 87 Fig 7 The solutions Algorithm 4 left ﬁrst steps right algorithm line D Dcid2D zone A solution white zone dominated solution cid2S 2 The right image presents positions algorithm There exists partition grey P Proposition 62 The set P cid2S 1 cid2S m computed Algorithm 4 complete minimal 1 m Pareto optimal solution 1 cid2S 2 Pareto optimal solutions cid2 satisfying C exists 1 m Dcid2 Dcid2S Scid2 Scid2S The set Dcid2 Scid2 cid2 P Pareto Proof Algorithm 4 terminates according Proposition 61 Scid2S maximal dissimilarity pairs points Scid2S i1 values discrete limited Dcid2 Dcid2S Scid2 Scid2S Scid2 Scid2S 1 We prove 1 m exists partition cid2 satisfying C dominates cid2S Dcid2S Dcid2 Dcid2D Dcid2 Dcid2D partition maximizes split satisfying condition D Dcid2D cid2 exist according point 1 Proposition 61 If 1 Scid2S satisfy Dcid2 Dcid2D partition cid2S Dcid2 partition cid2 satisfy For second case 1 i1 partition cid2 i1 This impossible according point 6 Proposition 61 Therefore The ﬁrst case impossible cid2S Scid2 Scid2S Scid2 Scid2S Scid2 Scid2S Since Dcid2S Pareto optimal Dcid2D Scid2S 1 exists 1 m 1 Scid2S 2 Let cid2 Pareto optimal solution cid2 dominated satisfying C m cid2D m Therefore Scid2 Scid2S We Scid2 Scid2S satisfying C Scid2 Scid2S Scid2S Considering case Scid2 Scid2S Dcid2S dominated Dcid2 Dcid2S In case exists 1 m 1 Scid2S Dcid2 Dcid2D Dcid2 Scid2 Dcid2S Dcid2 Dcid2S i1 point 4 Dcid2 Dcid2S i1 cid2S 1 Dcid2 We Dcid2 Scid2 Dcid2S m Since Scid2S i1 1 Scid2 Scid2S 1 Scid2 Scid2S 1 Dcid2S i1 Scid2S i1 Scid2 Scid2S i1 cid2 m1 null Algorithm 4 terminates exists partitions strictly increasing Scid2 1 By point 1 Proposition 61 Dcid2D 1 Dcid2 point 4 Dcid2D 1 1 dominates cid2 Since cid2 1 cid2S 1 Scid2S Scid2 Scid2S i1 By point 6 Proposition 61 i1 Dcid2 i1 Scid2 Dcid2S i1 We Scid2S dominates cid2 Since cid2 dominated Minimize_Diameter resp Maximize_Split searches partition minimizing diameter resp maximizing split partitions satisfying set constraints given argument Let recall exist partitions optimizing criterion model returns ﬁrst Nevertheless later possible apply model optimization criterion constraint diameter partitions optimum algorithm enumerate partitions satisfying constraint In way given element D S Pareto model optimization criterion constraints C D D S S enumerate partitions cid2 satisfy C Dcid2 D Scid2 S Multiobjective optimization Constraint Programming phase search proposed 51 The idea implement global constraint ParetoObj1 Objm A keeps set nondominated solutions far computed A operates variables representing objective functions Obji This constraint reduces domain variable Obji domains variables enter dominated zone solution A A detailed description constraint extension Large Neighborhood Search proposed 52 This constraint Pareto introduced model Nevertheless approach moment eﬃcient Algorithm 4 deeper studies instance study search strategy needed order improve eﬃciency 88 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Table 2 Properties datasets Dataset Objects Classes Iris Wine Glass Ionosphere User Knowledge Breast Cancer Synthetic Control Vehicle Yeast Multiple Features Image Segmentation Waveform 150 178 214 351 403 569 600 846 1484 2000 2000 5000 3 3 7 2 4 2 6 4 10 10 7 3 Table 3 Performance measured seconds criterion minimizing maximal diame ter Dataset Dopt BaB GC CP1 CP2 18 23 420 06 37 18 258 45813 497 86 117 237796 10936 26483 067 Iris 14 Wine 20 Glass 81 IonoSphere User Knowledge Breast Cancer Synthetic Control Vehicle Yeast Multi Features Image Segmentation Waveform There error 3 giving 86 s instead 04 s solving dataset Iono Sphere 01 03 09 04a 750 07 561 143 23899 01 01 02 03 02 05 16 09 52 104 57 501 12 5055 4364 156 5892 7 Experiments Our model implemented Gecode solver version 4215 Gecode 19 open source Constraint Programming library C current stateoftheart CP solvers Twelve databases taken repository UCI 53 experiments They vary size number clusters Table 2 summarizes information datasets presented increasing order number objects Since problem address ﬁnding exact solution distancebased clustering important factors number objects n number clusters k For experiments chosen wide range datasets different values n k The experiments performed 34 GHz Intel Core i5 processor 8G Ram running Ubuntu All programs available httpcp4clusteringcom 71 Constrained clustering single criterion 711 Minimizing maximal diameter clusters Performance test We compare performance previous model denoted CP1 new model denoted CP2 relying Gecode solver branchandbound approach 4 denoted BaB algorithm based graph coloring 5 denoted GC The program BaB obtained authors website6 Since implementation algorithm GC available coded C wellknown available graph coloring program 54 We consider clustering user constraints algorithms handle knowledge exact algorithm handling user constraints criterion In experiments timeout set 1 hour Euclidean distance compute dissimilarity objects The value k set ground truth number clusters given Table 2 new model kmin kmax k Table 3 shows results experiments For dataset present value Dopt optimal diameter second column runtime seconds The symbol complete search 1 hour symbol mark runs memory ﬁnish search All algorithms exact ﬁnd value optimum diameter 5 http wwwgecode org 6 httpmailerfsuedumbrusco TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 89 Fig 8 Comparison nodes search tree different search strategies Table 4 Performance measured seconds CP2 modelings diameter criterion Reiﬁed constraints Dedicated ﬁltering algorithm Iris Wine Glass IonoSphere User Knowledge Breast Cancer Synthetic Control Vehicle Yeast Multi Features Image Segmentation Waveform 01 01 04 03 154 07 236 119 5742 2267 01 01 02 03 02 05 16 09 52 104 57 501 It clear datasets new model CP2 eﬃcient cases All datasets solved CP2 minute Among programs BaB algorithm eﬃcient It able solve datasets 300 objects The performance GC better BaB decreases rapidly number n objects 500 BaB algorithm based bounds maximal diameter detect failures search GC algorithm considers available distances decreasing order ﬁnd optimum diameter Our models exploits beneﬁts Constraint Programming constraint propagation appropriate search strategies eﬃcient Analysis search strategy Although models based Constraint Programming framework main reasons explain signiﬁcant difference performance models search strategy dedicated ﬁltering algorithm For analyzing inﬂuence search strategy use new model CP2 different search strategies strategy previous model CP1 new model CP2 Fig 8 presents number nodes search trees strategies datasets given Table 2 It clear new strategy better search trees smaller The new search strategy ﬁnds quickly ﬁrst solution maximal diameter close optimal diameter As result solver remove unfruitful branches number nodes search tree Analysis dedicated ﬁltering algorithm In CP1 modeling diameter criterion number reiﬁed constraints square number points n Although dedicated global constraint complexity worst case O n2 considers necessary variables CP1 node reiﬁed constraint checked time In order study eﬃciency ﬁltering algorithm test new model CP2 reiﬁed constraints CP1 express diameter criterion Table 4 presents performances obtained reiﬁed constraints dedicated ﬁltering algorithm We reiﬁed constraints solver ﬁnd optimal solution datasets Wave Form Multi Features The reason reiﬁed constraints runs memory Table 4 shows ﬁltering algorithm boosts performance signiﬁcant larger datasets Analysis bounds number clusters new model We evaluate inﬂuence bounds number clusters k kmin kmax performance CP2 In ﬁrst experiment kmax set 10 kmin varies 2 10 The diameter criterion favors high number clusters higher number clusters smaller value optimal diameter Without userconstraints optimal solution diameter criterion number clusters equal kmax For datasets total time search tree constant kmin changes It shows 90 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Fig 9 Analysis bounds kmin 2 kmax 2 3 10 Table 5 Maximizing minimal split clusters diameter constraint Dataset Iris Wine Glass Ionosphere User Knowledge Modeling Breast Cancer Synthetic Control Vehicle Yeast Multi Features Image Segmentation Waveform Sopt 053 5333 178 529 032 42199 4516 2706 015 110707 22870 ksol kreal Total time 3 3 7 2 4 2 5 4 10 10 7 3 3 7 2 4 2 6 4 10 10 7 01 01 17 24 115 07 174 295 6398 2679 513 propagation constraint modeling diameter criterion effective After ﬁnding proving optimal solution kmax clusters solver conclude exist better solution kmax clusters In second experiment kmin set 2 kmax varies 2 10 Fig 9 presents results obtained datasets Vehicle Yeast Multi Features Image Segmentation For dataset report number nodes search tree bound kmax varies In general kmax increases partitions considered However interesting trend Fig 9 number nodes search tree increase kmax increases Indeed kmax higher optimal maximum diameter smaller propagation diameter constraint effective It explains cases computation time decreases kmax increases 712 Maximizing minimal split clusters Finding partition maximizing split clusters polynomial problem However user constraints problem NPHard To knowledge exact algorithm criterion supports kind user constraints general value k 3 When optimizing split user constraints number k clusters set kmin k kmax optimal solution number clusters equal kmin However longer true user constraints instance diameter constraint We experimented point new model adding diameter constraint In order set results given Table 3 set upper bound diameter cluster 15Dopt The number clusters k set bounded kmin 2 kmax equal actual number clusters given Table 2 The results given Table 5 For dataset present optimal split Sopt number clusters solution ksol actual number clusters kreal total execution time seconds Our model able solve datasets exception dataset Waveform largest dataset 713 Minimizing withincluster sum dissimilarities WCSD Finding exact solution minimizing WCSD diﬃcult compare performance new model Gecode solver Repetitive BranchandBound Algorithm RBBA 4 The program RBBA obtained authors website httpmailerfsuedumbrusco To knowledge best exact algorithm WCSD criterion The dissimilarity objects measured squared Euclidean distance Without user constraints model RBBA approach ﬁnd optimal solution Iris dataset Our model needs 4125 s complete search RBBA takes 3249 s RBBA solves problem repetitively solving subproblems ﬁnding optimal solution k 1 k 2 n objects Relying optimal value WCSD computed subproblems better lower bound WCSD computed enabling RBBA better performance However extending algorithm integrate user constraints diﬃcult TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 91 Fig 10 WCSD user constraints Iris left computation time right Adjusted Rand Index Our model handle different kinds user constraints appropriate combinations user constraints boost performance A set 120 instancelevel constraints generated dataset Iris The constraints generated following method described 7 points chosen randomly dataset belong cluster ground truth partition mustlink constraint generated cannotlink constraint generated The ﬁrst test user constraints second considers ﬁrst 30 constraints takes account ﬁrst 60 constraints Fig 10 left reports total time needed solve dataset user constraints When 30 constraints solver takes computation time The reason user constraints optimal value WCSD higher propagation WCSD constraint weaker However user constraints integrated propagation mustlink cannotlink constraints stronger enables quickly instantiate variables G As result solver takes 94 s solving problem 60 constraints 10 s 90 constraints We evaluated quality partitions For measuring quality partition consider Adjusted Rand Index ARI It measures similarity partitions case ground truth partition P dataset partition P model It deﬁned cid7 ARI 2ab cd dd b cc b b number pairs points number pairs points cluster P P c number pairs points cluster P different different clusters P P clusters P The results experiment reported Fig 10 right Since constraints generated ground truth partition dataset ARI value optimal partition improved constraints considered d number pairs points different clusters P cluster P cid7 cid7 cid7 cid7 72 Clustering bicriterion splitdiameter 721 Performance test For splitdiameter bicriterion compare new model CP2 bicriterion clustering algorithm based graph coloring 5 denoted bGC Since implementation algorithm available coded C To knowledge exact algorithm k kmin kmax The datasets given Table 2 experiments timeout set 1 hour The number clusters k varies 2 ground truth number clusters Table 6 gives results experiments The second column Sol gives number Pareto optimal solutions equivalently number elements complete Pareto The following columns run time approach seconds The programs exact ﬁnd Pareto It clear model eﬃcient cases It takes advantage eﬃcient constraint propagation mechanism reduce search space As case GC algorithm bGC limited datasets 500 points 722 Bicriterion clustering userconstraints We generated set 80 instancelevel constraints dataset Iris described Section 713 applied Algorithm 4 CP2 solving task bicriterion constrained clustering The ﬁrst test user constraints second ﬁrst 20 user constraints ﬁrst 40 constraints Fig 11 presents Pareto ﬁve cases 0 80 user constraints As user constraints added number feasible solutions decreases result criterion space changes signiﬁcantly Since generated user constraints ground truth partition obvious point Dr Sr corresponding partition region delimited Pareto including 80 constraints We user constraints points Pareto far Dr Sr For reason useful enable user constraints task bicriterion clustering Moreover given element D S Pareto model enumerate Pareto optimal solutions maximum diameter D minimum split S For example considering Pareto case 80 instancelevel constraints composed points correspond respectively 8704 4352 partitions 92 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 Table 6 Comparison performance measured seconds bi criterion SplitDiameter Dataset Sol Iris Wine Glass Ionosphere User Knowledge Breast Cancer Synthetic Control Vehicle Yeast Multi Features Image Segmentation Waveform 8 8 9 6 16 7 6 13 15 8 bGC 42 09 215 18 236 1675 CP2 01 01 04 26 128 11 67 55 2291 413 8 Conclusion Fig 11 Bicriterion constrained clustering dataset Iris We presented new Constraint Programming model Constrained Clustering This model signiﬁcantly im proved version previous model Constraint Programming framework 3 It based different choice variables constraints This model modular sense dedicated global constraints developed different optimization criteria It ﬂexible number clusters need speciﬁed suﬃcient provide bounds number clusters It declarative general allows choose different optimization cri teria integrate kinds user constraints We thanks properties directly integrated general processes instance handling bicriterion constrained clustering Experiments classical datasets model outperforms existing exact approaches cases We believe working search strategies constraint propagation enables improve substantially eﬃciency approach We continue studying aspects model able deal larger datasets We investigate use approximate search strategies local search methods The use model bicriterion splitdiameter constrained clustering generalized bicriterion prob lems requirement single criterion integrated inside model From Data Mining point view consider integrating optimization criteria instance withincluster sum squares Acknowledgement We gratefully thank anonymous referees helpful comments improve article This work supported Doctoral grant French Ministry National Education Higher Education Research References 1 I Davidson SS Ravi L Shamis A SATbased framework eﬃcient constrained clustering Proceedings 10th SIAM International Conference 2 M Mueller S Kramer Integer linear programming models constrained clustering Proceedings 13th International Conference Discovery Data Mining 2010 pp 94105 Science 2010 pp 159173 3 TBH Dao KC Duong C Vrain A declarative framework constrained clustering Proceedings European Conference Machine Learning Principles Practice Knowledge Discovery Databases 2013 pp 419434 4 M Brusco S Stahl BranchandBound Applications Combinatorial Data Analysis Statistics Computing 1st edition Springer 2005 5 M Delattre P Hansen Bicriterion cluster analysis IEEE Trans Pattern Anal Mach Intell 4 1980 277291 6 T Gonzalez Clustering minimize maximum intercluster distance Theor Comput Sci 38 1985 293306 7 K Wagstaff C Cardie Clustering instancelevel constraints Proceedings 17th International Conference Machine Learning 2000 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 93 8 I Davidson SS Ravi Clustering constraints feasibility issues kmeans algorithm Proceedings 5th SIAM International Conference pp 11031110 Data Mining 2005 pp 138149 9 M Ester HP Kriegel J Sander X Xu A densitybased algorithm discovering clusters large spatial databases noise Proceedings 2nd International Conference Knowledge Discovery Data Mining 1996 pp 226231 10 R Cormack A review classiﬁcation J R Stat Soc A 134 3 1971 321367 11 S Johnson Hierarchical clustering schemes Psychometrika 32 3 1967 241254 12 Y Wang H Yan C Sriskandarajah The weighted sum split diameter clustering J Classif 13 2 1996 231248 13 J Wang J Chen Clustering maximize ratio split diameter Proceedings 29th International Conference Machine Learning 2012 14 N Beldiceanu M Carlsson JX Rampon Global constraint catalog SICS EMN technical report httpsofdemgithubiogccat 15 JC Régin A ﬁltering algorithm constraints difference CSPs Proceedings 12th National Conference Artiﬁcial Intelligence Vol 1 16 F Focacci A Lodi M Milano Costbased domain ﬁltering Proceedings 5th International Conference Principles Practice Constraint 17 JC Régin Arc consistency global cardinality constraints costs Proceedings 5th International Conference Principles Practice 18 F Rossi P van Beek T Walsh Eds Handbook Constraint Programming Foundations Artiﬁcial Intelligence Elsevier BV Amsterdam Netherlands 2006 19 Gecode Team httpwwwgecodeorg 20 I Davidson SS Ravi The complexity nonhierarchical clustering instance cluster level constraints Data Min Knowl Discov 14 1 2007 2561 21 P Hansen M Delattre Completelink cluster analysis graph coloring J Am Stat Assoc 73 362 1978 397403 22 S Basu I Davidson K Wagstaff Constrained Clustering Advances Algorithms Theory Applications 1st edition Chapman HallCRC 2008 23 K Wagstaff C Cardie S Rogers S Schrödl Constrained kmeans clustering background knowledge Proceedings 18th International Conference Machine Learning 2001 pp 577584 Conference Machine Learning 2004 pp 1118 24 M Bilenko S Basu RJ Mooney Integrating constraints metric learning semisupervised clustering Proceedings 21st International 25 I Davidson SS Ravi Agglomerative hierarchical clustering constraints theoretical empirical results Proceedings 9th European Conference Principles Practice Knowledge Discovery Databases 2005 pp 5970 26 Z Lu MA CarreiraPerpinan Constrained spectral clustering aﬃnity propagation Proceedings 2008 IEEE Conference Computer 1994 pp 362367 Programming 1999 pp 189203 Constraint Programming 1999 pp 390404 27 X Wang I Davidson Flexible constrained spectral clustering Proceedings 16th ACM SIGKDD International Conference Knowledge Discov Vision Pattern Recognition 2008 pp 18 ery Data Mining 2010 pp 563572 28 T Guns S Nijssen L De Raedt kPattern set mining constraints IEEE Trans Knowl Data Eng 25 2 2013 402418 29 JP Métivier P Boizumault B Crémilleux M Khiari S Loudni Constrained clustering SAT Proceedings 11th International Symposium Advances Intelligent Data Analysis 2012 pp 207218 30 B Babaki T Guns S Nijssen Constrained clustering column generation Proceedings 11th International Conference Integration AI oR Techniques Constraint Programming Combinatorial Optimization Problems 2014 pp 438454 31 D Aloise P Hansen L Liberti An improved column generation algorithm minimum sumofsquares clustering Math Program 131 12 2012 195220 32 L Kotthoff B OSullivan Constraintbased clustering Proceedings 10th International Conference Integration Artiﬁcial Intelligence AI Operations Research OR Techniques Constraint Programming 2013 presentationonly abstract 33 U Luxburg A tutorial spectral clustering Stat Comput 17 4 2007 395416 34 X Wang B Qian I Davidson On constrained spectral clustering applications Data Min Knowl Discov 28 1 2014 130 35 W Zhi X Wang B Qian P Butler N Ramakrishnan I Davidson Clustering complex constraints algorithms applications Proceedings 27th AAAI Conference Artiﬁcial Intelligence 2013 tional Conference Data Mining 2013 pp 234242 Artiﬁcial Intelligence 2013 pp 372378 36 I Davidson B Qian X Wang J Ye Multiobjective multiview spectral clustering Pareto optimization Proceedings 13th SIAM Interna 2013 pp 750757 Intelligence 2010 Intelligence 2010 pp 11091110 37 S Gilpin S Nijssen IN Davidson Formalizing hierarchical clustering integer linear programming Proceedings 27th AAAI Conference 38 S Gilpin IN Davidson Incorporating SAT solvers hierarchical clustering algorithms eﬃcient ﬂexible approach Proceedings 17th ACM SIGKDD International Conference Knowledge Discovery Data Mining 2011 pp 11361144 39 J Berg M Jarvisalo Optimal correlation clustering MaxSAT Proceedings 13th IEEE International Conference Data Mining Workshops 40 L De Raedt T Guns S Nijssen Constraint programming itemset mining Proceedings 14th ACM SIGKDD International Conference Knowledge Discovery Data Mining 2008 pp 204212 41 L De Raedt T Guns S Nijssen Constraint programming data mining machine learning Proc 24th AAAI Conference Artiﬁcial 42 H Cambazard T Hadzic B OSullivan Knowledge compilation itemset mining Proceedings 19th European Conference Artiﬁcial 43 T Guns S Nijssen L De Raedt Itemset mining constraint programming perspective Artif Intell 175 2011 19511983 44 S Jabbour L Sais Y Salhi The topk frequent closed itemset mining topk SAT problem Proceedings European Conference Machine Learning Knowledge Discovery Databases 2013 pp 403418 45 WU Rojas P Boizumault S Loudni B Crémilleux A Lepailleur Mining soft skypatterns dynamic CSP Proceedings 11th International Conference Integration AI OR Techniques Constraint Programming 2014 pp 7187 46 C Bessiere E Hebrard B OSullivan Minimising decision tree size combinatorial optimisation Proceedings 15th International Conference 47 YC Law JHM Lee Global constraints integer set value precedence M Wallace Ed Proceedings 10th International Conference Principles Practice Constraint Programming 2009 pp 173187 Principles Practice Constraint Programming 2004 pp 362376 48 TBH Dao KC Duong C Vrain A ﬁltering algorithm constrained clustering withincluster sum dissimilarities criterion Proceedings 25th International Conference Tools Artiﬁcial Intelligence 2013 pp 10601067 49 G Klein JE Aronson Optimal clustering model method Nav Res Logist 38 3 1991 447461 50 V Tkindt JC Billaut Multicriteria Scheduling Theory Models Algorithms 2nd edition Springer 2006 94 TBH Dao et al Artiﬁcial Intelligence 244 2017 7094 51 M Gavanelli An algorithm multicriteria optimization CSPs F van Harmelen Ed Proceedings 15th European Conference Artiﬁcial 52 P Schaus R Hartert Multiobjective large neighborhood search Proceedings 19th International Conference Principles Practice Intelligence 2002 pp 136140 Constraint Programming 2013 pp 611627 53 K Bache M Lichman UCI machine learning repository httparchiveicsucieduml 54 A Mehrotra MA Trick A column generation approach graph coloring INFORMS J Comput 8 1995 344354