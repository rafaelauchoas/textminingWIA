Artiﬁcial Intelligence 302 2022 103579 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Probabilistic modelling general noisy multimanifold data sets M Canducci School Computer Science University Birmingham Edgbaston Birmingham B15 2TT UK b Ghent University Krijgslaan 281 S9 B9000 Gent Belgium P Tiño M Mastropietro b r t c l e n f o b s t r c t Article history Received 6 March 2021 Received revised form 19 June 2021 Accepted 9 August 2021 Available online 31 August 2021 Keywords Latent variable models Dimensionality estimation Multimanifold Learning Riemannian manifolds Generative topographic mapping Density estimation Probabilistic modelling The intrinsic nature noisy complex data sets concealed lowdimensional structures embedded higher dimensional space Number methodologies developed extract represent structures form manifolds geometric structures locally resemble continuously deformable intervals R j 1 Usually priori knowledge manifolds intrinsic dimensionality required Additionally performance hampered presence signiﬁcant highdimensional noise aligned lowdimensional core manifold In realworld applications data contain lowdimensional structures different dimensionalities We propose framework dimensionality estimation reconstruction multiple noisy manifolds embedded noisy environment To best knowledge work represents ﬁrst attempt detection modelling set coexisting general noisy manifolds uniting aspects multimanifold learning recovery approximation core noiseless manifolds construction probabilistic models The easyto understand hyperparameters manipulated obtain emerging picture multimanifold structure data We demonstrate workings framework synthetic data sets presenting challenging features stateoftheart techniques MultiManifold learning The ﬁrst data set consists multiple sampled noisy manifolds different intrinsic dimensionalities Möbius strip toroid spiral arm The second topologically complex set interlocked toroids Given absence uniﬁed methodologies literature comparison existing techniques organized separate aspects approach mentioned manifold approximation probabilistic modelling The framework applied complex data set containing simulated gas volume particles particle simulation dwarf galaxy interacting host galaxy cluster Detailed analysis recovered 1D 2D manifolds help understand nature Star Formation complex systems 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 Corresponding author continuous inverse Email addresses MCanduccibhamacuk M Canducci PTinocsbhamacuk P Tiño MicheleMastropietrougentbe M Mastropietro j manifold dimensionality Mathematically continuous deformation corresponds homehomorphism onetoone continuous mapping 1 httpsdoiorg101016jartint2021103579 00043702 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 1 Introduction Dimensionality reduction Density Estimation raw data commonly tools extract information com plex noisy data sets Due dependencies measured attributes real world data data distributed lowdimensional structures higher dimensional measurement space This realisation driven development variety Manifold Learning algorithms Principal Component Analysis PCA 1 understood widely linear dimensionality reduction scheme However design PCA appropriately capture nonlinear lowdimensional structures This lack ﬂexibility addressed nonlinear dimensionality reduction algorithms Isomap 2 Locally Linear Embedding LLE 3 manifold approximated neighbourhood graph neigh bouring preserving map respectively Both methods advantage deﬁnition manifold locally linear low dimensional structure dimension j Many Manifold Learning algorithms aiming provide suitable approximations lowdimensional data manifold proposed Examples include Laplacian eigenmaps 4 Hessian eigenmaps 5 Local Space Tangent Alignment LSTA 6 CIsomap 7 extension Isomap conformal embeddings NMDS non metric formulation Multidimensional Scaling MDS 8 9 10 Riemannian Manifold Learning RML 11 In 12 bibliographic references different angle based computational geometry proposed order extract lowdimensional manifolds data samples Here simplicial complexes Delaunay triangulations αcomplexes ﬁltrations manifold reconstruction With techniques possible infer geometrical topological properties data points uniformly sample single manifold embedded higher dimensional space While techniques potentially powerful theoretically grounded capability naturally handle high dimensional noise aligned lowdimensional manifolds limited Besides sensitivity noise issues required intrinsic data dimensionality known priori Generative Topographic Mapping GTM 13 proposed probabilistic formulation SelfOrganizing Map 14 Its main advantage instead treating noisy manifold core lowdimensional manifold discovered plus noise needs dealt formulates consistent manifoldaligned density model form constrained mixture Gaussians2 The original GTM formulation trained maximum likelihood framework EM algorithm 15 Because sensitivity initialization suitable initialization required PCA assuming latent space topology known priori 16 Bayesian formulations GTM proposed 17 Other global density estimators nonparametric Parzen windows 18 extensions Mani fold Parzen Windows 19 FastParzen Windows 20 semiparametric Inﬁnite Gaussian Mixture model 21 designed extract representation embedded lowdimensional structures They computationally expensive train andor evaluate To deal complex data sets manifolds different dimensionalities coexist generalizations previous methods developed MultiManifold Discriminant Analysis MMDA 22 SparseManifold Clustering Embedding SMCE 42 MultiManifold Isomap MISOMAP 23 Multimanifold Proximity Embedding MPE 24 MultiManifold LLE MMLLE 25 SIsomap 26 Hierarchical GTM 27 However based assumptions predecessors methods need informed dimensionalities different manifolds struggle dealing topologically complex noisy structures The works proposed 28 29 particularly relevant terms dimensionality estimation clustering The ﬁrst methodology relies construction Translation Poisson Mixture Models TPMM estimating dimensionality local neighbourhoods data However design prone separate unique manifold local density points changes manifold The second methodology Hidalgo Bayesian extension TWONN3 30 The dimensionality individual points obtained maximization posterior distribution models parameters Despite appealing formulation estimated complexity ON 2 N number points data set suited applications considered study N generally large We propose framework automated dimensionality estimation reconstruction multiple noisy manifolds em bedded noisy environment We generalize GTM model densities aligned arbitrary manifolds nonorientable ones Möbius strip captured This achieved replacing simple Euclidean latent space generally parametrized discretized interval R j abstract graph reﬂecting topology data manifold embedded data space provides manifold skeleton noise models ganized This work inspired 31 extends generalizes threefold 1 proposes new robust dimensionality index estimation data points 2 dedicated manifold crawling mechanism allows completely abstract manifold representations GTM latent space instead regular grid 3 Gaussian noise components nat urally aligned manifold unlike spherical noise models original GTM 31 Manifold aligned noise models GTM considered 32 assumption simple latent space structure form jdimensional interval The key idea impose larger smaller variances directions locally parallel perpen dicular respectively manifold Since latent space discrete structure abstract graph representing skeleton 2 Location parameters means Gaussian components constrained lie smooth manifold commonly smooth image data space twodimensional interval latent space 3 The methodology based distances nearest neighbours point 2 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 given manifold formulate local noise models kernel based estimates local covariance matrix data trainable scale parameter allow optimized overlapping neighbouring Gaussian components Our work presents radical reformulation GTM capture model lowdimensional general noisy manifolds dedicated abstract graphstructured latent space reﬂecting core manifold structure speciﬁc noisy manifold Bacciu et al 33 present radical generalization GTM reverse direction time keeping original simple latent space structure allowing abstract structure data space space trees The paper following organization section 2 set scene explain broad outline methodology introduce synthetic data set different steps methodology demonstrated Section 3 introduces core model methodology Abstract GTM AGTM representing density aligned single manifold We explain abstract latent space graph representing topology data manifold extracted manifold crawling graph embedded data space suitable set noise models We calculate local curvature edges embedded graph taking advantage smooth manifold description provided AGTM Section 4 deﬁnes notion Dimensionality index individual points extends framework section 3 multimanifold case We offer computationally eﬃcient alternative MultiManifold Crawling The price pay gains eﬃciency weaker detection stability low dimensional manifold entities buried data Section 5 presents experimental comparison synthetic data sets methodology alternative multi manifold learning probabilistic modelling methods Even methodology aims provide density models multiple lowdimensional manifolds buried data organise comparative experiments separately multi manifold capture probabilistic modelling aspects work This best knowledge method exists simultaneously recover low dimensional representations unknown number manifolds building probabilistic models Our main contributions summarized follows Formulation new dimensionality index assigned individual points based point cloud partitioned background points sets representing cloud points organised noisy lowdimensional manifold structures Development recursive crawling algorithm extraction multiple lowdimensional noisy manifolds embed ded higher dimensional space MultiManifold crawling Extension GTMs applicability broad class manifolds nonorientable closed manifolds reformulating latent space abstract graph introducing manifoldaligned noise attached embedded nodes latent graph Abstract GTM The abstract latent space embedding allows understand important global structural features underlying manifolds important aspect methodology bringing manifold learning umbrella Artiﬁcial Intelligence The methodology4 applied section 6 astrophysical data set resulting mixed NbodySmoothed Particle Hydrodynamics numerical simulation dwarf galaxy falling gaseous halo galaxy cluster The point cloud generated simulation presents non linear noisy low dimensional structures providing ideal test bed methodology We extract model signiﬁcant manifolds suggesting possible scenario formation new stars disrupted dwarf galaxy Section 8 summarizes main achievements concludes paper 2 Methodology overview Consider point cloud Q t1 t2 tL ti Rd containing points sampled unknown number noisy lower dimensional manifolds embedded noisy environment points generated broad ddimensional distribution As example Fig 2 shows data set R3 obtained collection noisy twodimensional central panel dimensional left panel red points manifolds All underlying true manifolds shown Fig 1 onedimensional ones Figs 1a 1b parabolic arm spiral twodimensional manifolds Figs 1c1f cap hyperbolic sur face 2toroid Sshape surface Möbius strip The noisy manifolds embedded uniform noise Fig 2 rightmost panel We included uniformly sampled 3dimensional ball Fig 2 left panel green points Characteristics manifolds Table 1 details parametric forms sampling presented Appendix A Note total number manifold points 33 data set meaning 67 points ideally discarded initial ﬁltering process In following brief outline methodology robustly detect manifolds build cor responding manifoldaligned density models We ﬁrst apply physicsbased diffusion method structureAware Filtering Technique SAF 34 collapses points close vicinity dense structures resulting diffused data set Q t1 t2 tL ti Rd The SAF method moves points high density regions enabling points vicinity noisy manifold migrate spine mean surface Fig 3 shows noisy manifolds described previously Figs 3a3f corresponding recovered mean manifolds SAF Figs 3g3l Despite imperfections 4 A MATLAB implementation methodology data sets generation httpsgithub com MarcoCanducci general noisy multi manifold learning git 3 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 1 Plots showing groundtruth manifold dataset For interpretation colours ﬁgures reader referred web version article Fig 2 Data sets containing manifolds different dimensionalities sampled uniform distribution Merging adding uniform background noise creates ﬁnal dataset testing phase Fig 3 Top row noisy manifolds Bottom row Diffused manifolds SAF technique Table 1 Manifolds intrinsic dimensionality underlying distribution number points Manifold ID Dim Distribution 1 2 3 4 5 6 7 1 1 2 2 2 2 3 Spiral Arm Parabolic arm Hyperbolic surface toroidal surface S surface Möbius strip Uniformly sampled 3d ball Summed manifolds Background noise Dataset total points 689 424 2297 18959 8307 2338 1958 34972 70463 105435 4 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 compared groundtruths deformation spiral second ring method generally reduces transverse noise manifolds Assuming data structures modelled densely sampled noisy environment ﬁrst ﬁlter data sets Q Q removing point couples ti ti sparse neighbourhood Q Q In particular ti Q ti Q construct hyperball Bti r Bti r respectively Rd radius r 0 In case point ti Q lies apart manifold Bti r Bti r sparsely populated Hence Bti r Bti r contain points Q Q respectively prespeciﬁed threshold τ 0 points ti ti removed corresponding data sets Following ﬁrst task capturing multimanifold structure Q estimate local dimensionality cloud point ti form dimensionality index δi section 41 Using dimensionality indices partition data subsets Q j Q j according local dimensionalities j 1 2 d Since Q j Q j contain sev eral distinct sampled manifolds dimensionality j use dedicated manifold crawling procedure operating Q separate individual manifolds section 42 Moreover crawling produces manifold graph structure embedded Rd representing piecewise linear skeleton approximation spine noisy manifold section 32 For manifold associated graph function abstract latent space generalized form Genera tive Topographic Mapping GTM 13 Abstract GTM AGTM Using points Q generalized GTM produces manifold aligned density models section 31 Finally single summary model required density models detected manifolds AGTMs grouped hierarchical mixture model 27 representing concise manner global density lowdimensional structures dataset Q 3 Density model single noisy manifold In section deal construction manifoldaligned density model single manifold For sake presentation clarity slightly abusing mathematical notation use D t1 t2 tN denote subset points Q belonging manifold The set D t1 t2 tN contains corresponding diffused points Q Section 32 presents recursive algorithm Manifold Crawling capable recovering latent graph abstract form embedded graph data space 31 Abstract GTM Let consider jdimensional manifold M embedded higher dimensional space Rd j d In following assume dimensionality j manifold M known We later section 41 provide methodology estimation intrinsic dimensionality points lying lowdimensional manifolds We consider D t1 t2 tN data sample M obtained noisy manifold sample D SAF section 2 The original GTM 13 assumes manifold M image jdimensional interval 1 1 j latent space smooth embedding y 1 1 j Rd To add noise M latent space 1 1 j covered regular grid xiK i1 K points images yxi y form skeleton M data space A spherical Gaussian noise model positioned skeleton node yxi representing noisy manifold mixture K Gaussians centred yxi Fig 4a The latent space grid structure represented abstract undirected graph G V E grid point xi corresponds vertex v V edges ei j E connecting vertices corresponding neighbouring grid points xi x j The structure G directly reﬂected latent grid shown Fig 4b We generalize GTM model manifold skeleton obtained direct embedding latent graph G data space parametrized mapping f Individual Gaussian noise models centred images vi fv Rd nodes G The manifold skeleton formed embedded graph G V E V vi vK ei j E ei j E This enable naturally represent density models noisy manifolds intricate structure smoothly embedded low dimensional interval For example sample noisy Möbius strip shown Fig 4b right panel captured Gaussian mixture centres ﬁxed skeleton points Fig 4b central panel The skeleton points images f vertices v V Fig 4b left panel The abstract graph G presented usual topological convention identiﬁcation opposite sides rectangular grid inversion direction The additional edges resulting identiﬁcation shown red Motivated original GTM model formulate embedding f V Rd nonlinear model linear parame ters In particular use set M basis functions φm V R m 1 2 M operating abstract latent space G The image vertex v V cid6 φ1 φM cid5 obtained v fv W Wcid6v 1 W d M matrix weights To formulate basis functions φm construct regular cid7net graph G 12 M nodes The nodes cm V cid7net form centres corresponding basis functions φmv exp cid2 D2v cm γ 2 cid3 5 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 4 Panel shows classic GTM setup leftmost panel representation latent space discretized grid points xi The jdimensional interval 1 1 j mapped parametrized function yX W data space spherical Gaussian centred point assumed noise The noise model aims describing true distribution points data space rightmost panel Panel b sketch AGTM The latent space substituted abstract graph shown Möbius strip topological representation arrows pointing opposite directions shortest edges graph Function f V W maps graph data space manifoldaligned noise models estimated graphs node v The true noisy distribution displayed rightmost panel Dv cm shortest distance G vertices v cm Analogously original GTM ensure smoothness embedding f scale parameter set5 2cid7 The manifold aligned probabilistic model ﬂat mixture model ptW ζ 1 K Kcid4 i1 ptv ζicid10i W 2 mixture components locally manifoldaligned multivariate Gaussians centred embedded vertices vi V cid6 cid5 ptv ζicid10i W 1 2π ζidcid10i 1 2 exp cid12t 1 cid12t cid5cid10 2ζi 3 cid12t fv W t Unlike 32 model local manifoldaligned covariance matrix scaled version scaled ζi 0 local covariance matrix estimated cid10i cid7 1 a1 κvi ta cid14i N Ncid4 n1 cid5 κvi tn cid14itn vitn vi Gaussian smoothing kernel cid8 κvi tn cid14i exp cid9 cid6vi tncid62 3cid142 determined average distances embedded vertex vi The kernel scale parameter cid14i neighbouring vertices G embedded Rd cid4 cid14i 1 N v aN v cid6vi acid6 N v G set neighbours v graph G 5 Alternatively value γ set according suitable criterion crossvalidation 6 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 As latent variable model AGTM trained maximize loglikelihood LW ζ Ncid4 cid5 ln n1 1 K Kcid4 i1 cid6 ptnv ζicid10i W 4 EM algorithm In Estep original GTM model fact mixture model n calculated posterior distribution nodes v V given data points tn D 13 The M responsibilities R step updates parameters W ζ obtained differentiating expected value complete data loglikelihood cid8LW ζ cid9 equation 4 wrt corresponding parameters setting zero Wcid8LW ζ cid9 0 ζ cid8LW ζ cid9 0 cid8LW ζ cid9 Ncid4 Kcid4 n1 i1 In particular nWold ζ old lnptnv ζicid10i W R Wcid8LW ζ cid9 Ncid4 Kcid4 n1 Ncid4 i1 Kcid4 n1 i1 R n W 1 2ζi Wcid6i tncid5 cid10 1 Wcid6i tn R n ζi cid10 1 Wcid6i tncid6 cid5 0 We rewrite equality matrix notation Kcid4 i1 CiWcid15i Kcid4 i1 1 cid10 ζi TRicid6 cid5 5 6 7 8 Ri N 1 column vector containing responsibilities point tn wrt centre v T D N matrix having tns column vectors cid6i cid6v M 1 cid15i cid6icid6cid5 cid10 cid7 cid10 cid11 Ci 1 ζi N n1 R n We solve equation 8 taking advantage properties Kronecker product vec operator 35 sections 51 102 obtaining vecWne w cid10 Kcid4 i1 cid111 cid10 Kcid4 vec cid15 cid5 Ci i1 cid11 cid5 TRicid6 1 cid10 ζi We turn attention equation 6 We ζi cid8LW ζ cid9 Ncid4 n1 Ncid4 n1 ζi cid12 R n cid12 D 2 ln ζi 1 Wcid6i tncid5cid10 2ζi D ζi 1 tn vicid5cid10 ζ 2 tn vi cid13 Wcid6i tn 0 cid13 Solving ζi scale parameters ζ local covariance matrices updated ζ ne w cid7 1 N n1 Rn d Ncid4 n1 n D2 R M tn vi D2 M tn vi squared Mahalanobis distance tn vi Wcid6i cid5 M tn v tn vi tn vi cid10 1 D2 9 10 11 This intuitive interpretation scale parameter ζi ith Gaussian mixture component obtained effective squared mean Mahalanobis distance points component centre vi dimension As example consider noisy sample Möbius strip shown Fig 4b right panel Fig 5a presents embedded abstract graph Fig 5b isosurface density model given AGTM model trained sample 7 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 5 Left panel Embedded graph Möbius strip initialization AGTM Right panel Probabilistic model obtained 2 iterations AGTM initialised graphs G G manifold aligned noise 32 Manifold crawling The previous section speciﬁed obtain probabilistic models noisy manifolds AGTM In following recursive algorithm enables recover abstract graph embedding function f given data set D We refer procedure Manifold Crawling simply Crawling Recall manifold dimensionality j d Initialization Initially single seed t0 D randomly chosen Principal Component Analysis PCA 36 applied neigh bourhood Bt0 r D We assume unit length eigenvectors obtained PCA ordered descending order corresponding eigenvalues The ﬁrst j eigenvectors u1 u j span tangent space manifold M t0 T t0 eigenvector ul l 1 j new points computed distance η r t0 directions ul M spanu1 u j For z l cid5 t0 η r u l 12 0 η 1 stepsize parameter In order crawling adherent diffused sample D closest neighbour z l t l argmin t D t z l We start construction embedded graph G initializing set nodes edges V v0 v1 v2 j1 v2 j E v0 v1 v0 v2 v0 v2 j1 v0 v2 j v0 t0 v1 t 1 v2 t 1 v2 j1 t j v2 j t j 13 14 15 At time initialize construction abstract graph G imposing node vl V corre sponds node vl V abstract counterpart G G The node vl considered image vl unknown embedding function f V Rd vl fvl We deﬁne pullback edges abstract graph G E v 0 v 1 v 0 v 2 v 0 v 2 j We compute degree node graph G analogously G The gree degvi node vi G number edges incident node We select vertices having edge V V E v degv 1 After initialization phase successive iteration split phases expansion contraction The phases 1 blue dots Fig 6 having edge6 connecting parent alternated newly discovered node vi V E node vp 1 6 Note newly discovered nodes necessarily degree 1 8 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 6 Visual representation Expansion Contraction phases Crawling algorithm Starting initial 1edge nodes blue points ﬁrst set node candidates green points panel directions represented black dashed lines For candidate tc construct Btc β r V red circles left panel If ball non element takes place tc added graph right panel red point Fig 7 Projection tangent space spanned blue arrows new nodes estimate red arrows Expansion phase Given node vi leading eigenvectors g1 g j To preserve crawling directions eigenvectors parents node u projected tangent space vi T vi M spang1 g2 g j renormalized unit length 1 eigendecomposition neighbourhood Bvi r D performed yielding ﬁrst j j p 2 u V E p 1 u p ui 1 Pu Pu p 1 j p Here P VV orthogonal projection operator T vi pseudoinverse Fig 7 As initialization step new points computed equation 12 closest data set D stored candidate nodes added V The result expansion phase given neighbours t l iteration shown Fig 6 The green points new candidates dashed black lines represent principal crawling directions Construction set new candidate nodes Cvi t l l 1 j vi terminates Expansion phase M V matrix containing gl columns V 16 Contraction phase In contraction phase check candidate nodes V collapsed smaller set nodes For new candidate tc Cvi Expansion phase check lands small tolerance neighbour hood Bve β r existing node ve G Here 0 β η 1 tolerance scale parameter If case ve vi r candidate tc identiﬁed ve nodes ve vi connected edge ve vi added E red point lower right plot Fig 6 Otherwise tc conﬁrmed new node constraint tc vi r added V edge tc vi added E yellow points lower right plot Fig 6 This marks end contraction phase The iteration concluded expansion contraction performed vi singleedge node set V E 1 previous iteration After expansion contraction phases singleedge node set V E 1 updated new iteration expansion contraction steps started Manifold crawling stops number nodes V longer increases consecutive iterations The application Manifold crawling point cloud obtained diffusion sampled noisy Möbius strip presented Fig 8 Iteration 1 Fig 8a algorithm initialization recovers principal crawling directions The crawling propagated tangent bundle manifold building series growing abstract embedded latent graphs representing manifolds structure Figs 8b8j Initialization latent graph embedding fv W The node sets V V initialize embedding fv W equation 1 abstract latent space G data space Rd setting weight matrix W linear regression fv W vi corresponding 9 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 8 Consecutive iterations Crawling algorithm shown Möbius strip At end ﬁrst iteration initialization panel main directions crawling identiﬁed ﬁrst version graph formed The following iterations spread graph manifold crawling local tangent spaces completion bj couples v V vi V While G V E unweighted edges G weighted distance connected nodes If needed regularize parameters W applying ridge regression instead linear regression minimization cost function Vcid4 vi fv i2 F i1 Mcid4 j1 χ jw2 j solving equations cid5 cid6 X ˆW cid6 cid5V cid6 17 18 Here X diagonal matrix having diagonal elements regularization parameters χ jM equation 18 normal equation 37 j1 The solution ˆW cid6 cid5 cid6 X 1cid6 cid5V 19 In order recover smooth mapping function small optimal weights ˆW tests chose χ j χ 1e 5 j 1 M 321 Local curvatures As outlined 27 having obtained smooth embedding latent space estimate local curvatures edges abstract graph Consider node v 0 V edge e01 connecting node v 1 Since G unweighted graph assume loss generality weight edge e01 w 01 1 We like estimate effect small perturbation 0 h 1 position node v 0 edge e01 relative basis functions centres cm m 1 M We consider e01 segment unit length estimate change tangent vectors embedded image e01 It crucial tangent vectors normalised length case unit vectors remove effects parameterisation speed The tangent vectors estimated ﬁnite differences To end insert ﬁve new nodes x1 x5 edge e01 connect chain node v 0 node v 1 edges eii1 respective weights wv 0 x1 wx1 x2 wx4 x5 h wx5 v 1 1 5h mentioned h 0 small perturbation parameter study h 001 The chain newly deﬁned nodes connecting v 0 v 1 replaces edge e01 acts discretization continuous segment small neighbourhood node v 0 We deﬁne discretized lifted line ωxi fxi W given mapping f new nodes xi 1 5 Given discretization approximate unit tangent vectors ωx2 ωx4 central differences 10 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 9 Curvature computed recovered graphs concentric circles data sets The radii circles 1 2 4 respectively The curvature values corresponding circles shown colormap Note relation inverse radius ϑx2 ωx3 ωx1 cid6ωx3 ωx1cid6 ϑx4 ωx5 ωx3 cid6ωx5 ωx3cid6 20 21 The curvature ωx3 evaluated difference unit tangent vectors ωx2 ωx4 relative geodesic distance ωx2 ωx4 approximated cid6ωx3 ωx2cid6 cid6ωx4 ωx3cid6 ϒx3 ϑx4 ϑx2 cid6ωx3 ωx2cid6 cid6ωx4 ωx3cid6 written ϒx3 cid6ωx3ωx1cid6 ωx5ωx3 ωx3ωx1 cid6ωx5ωx3cid6 cid6ωx3 ωx2cid6 cid6ωx4 ωx3cid6 22 This perturbation based estimation regularised observing suﬃciently small h distances embedded neighbouring nodes cid6ωx2 ωx1cid6 cid6ωx3 ωx2cid6 cid6ωx4 ωx3cid6 cid6ωx5 ωx4cid6 approximately equal represented h cid6ωx3 ωx1cid6 ωx5 ωx3cid6 2h We ϒx3 ωx5 2ωx3 ωx1 4h2 23 In practice calculate mean length cid14 edges abstract latent graph embedded data space set h h cid14 The norm cid6ϒx3cid6 quantiﬁes directional curvature f vicinity node v 0 edge e01 To demonstrate workings local curvature estimation ﬁrst performed set controlled experiments concentric circles known radii We expect estimated curvatures approximate inverse radius7 After generating points circles radii r0 1 2 4 performed crawling latent graph construction circle mani fold We evaluated curvatures edges embedded graphs The results presented Fig 9 As expected relation curvatures circles radii 1 2 4 approximately 1 05 curvatures closely follow r 025 respectively 1 0 As illustrative example consider case 2dimensional manifold M sphere bump em bedded R3 shown Fig 10 left panel Manifold M expressed terms spherical peak components respectively CS CP The component CS sampled uniform distribution U θ φ angular components spherical coordinate θ φ Iθ Iφ 0 2π π 2 π 2 ﬁxed radius r 1 The peak component additive term coordinate r generated Gaussian distribution N μP CP μP θP φP π 2 π 4 7 We thankful anonymous reviewer suggestion 11 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 10 Data set left panel extracted graph central panel planar representation right panel manifold Mx y z onedge curvature distribution covariance matrix CP diagπ 90 π 180 In words deﬁne varying radius angular component coordinates rM 1 15 N μP CP 24 Sample M obtained converting spherical coordinate Cartesian coordinates x y z x r sin θ cos φ y r sin θ sin φ z r cos θ By applying manifold crawling AGTM sample recover smooth manifold basis functions formu lation compute edge abstract latent graph value curvature deﬁned equation 23 Fig 10 central panel presents extracted graph edges colourcoded curvature curvature portion graph containing peak adjacent spherical structure The visualization Fig 10 right panel presents portion graph central unfolded plane Here central region captures extreme curvature culminating peak The curvature decreases minimum Gaussian peak smoothly approaches spheres surface steadily converges constant curvature spherical surface outer edges planar representation This behaviour veriﬁed central panel expected construction data set 4 Multi manifold learning Until considered single noisy manifold embedded Rd We extend method multiple manifolds possibly different dimensionalities embedded noisy background We use illustrative example data set Q described section 2 shown Fig 2 The data processed removing lowdensity background noise producing pair corresponding data sets Q Q outlined section 2 Recall Q contains samples noisy manifolds diffused core spine Q collects original samples distributed mani folds In order build initial skeleton model individual manifolds Manifold Crawling section 32 subsequent density modelling Abstract GTM section 31 missing piece information intrinsic dimensionality manifold given characteristic scale r 41 Local dimensionality estimation Around ti Q perform local Principal Component Analysis PCA points Bti r Q obtaining eigenspectrum λi1 λi2 λid The dimensionality index ti Q 31 limited 3dimensional data derived 38 obtained δ O argmax j S j 25 S i1 λi1 λi2 S i2 2λi2 λi3 S i3 3λi3 Here suggest general method computing dimensionality index points distributed spaces arbitrary ﬁnite dimension d based renormalized eigenvalues λi j λi jcid7 d k1 λik 12 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 viewed likelihoods different dimensionalities j cloud points ti Note cid25i λi1 λi2 λid lies d 1dimensional simplex S0 vertices s1 1 0 0 0 s2 12 12 0 0 s3 13 13 13 0 sd 1d 1d 1d The simplex S0 subset standard simplex S vertices equal standard basis e1 1 0 0 0 e2 0 1 0 0 ed 0 0 1 Considering S simplex multinomial distributions appropriate Riemannian geodesic distance Fisher distance 39 In particular cid25k cid25l S d J cid25k cid25l 2 arccos cid16 λki λli cid14 cid15 dcid4 i1 26 Note vertex s j S0 corresponds ideal normalized eigenspectrum jdimensional neighbourhood Hence quantify degree neighbourhood ti resembles jdimensional hyperplane Rd closeness cid25i s j terms geodesic distance 26 δG argmin j d J cid25i s j 27 We propose soft spatially smoothed version dimensionality index This positioning isotropic kernel K α e j exp cid12 cid13 d J α e j2 2κ 2 α S vertex e j S kernel scale κ set geodesic distance equidistant point sd S vertex S centre S κ d J e j sd j As explained imposed eigenvalue order normalized eigenspectra cid25i live subsimplex S0 standard simplex S To transform S0 S calculate barycentric coordinates 40 αi αi1 αi2 αid cid25i solving cid25i dcid4 j1 αi js j αi j 0 dcid4 j1 αi j 1 The eigenspectrum cid25i mapped point S barycentric coordinates αi This leads soft kernelbased dimensionality distribution K αi e j cid7 k1 K αi ek d P j It happen normalized index distribution P abruptly changing neighbouring points low sample density manifold edges We spatially smooth P Gaussian ﬁlter8 ci l exp cid6ti tlcid622r2 The smoothed normalized index distribution reads j P S 1cid7 tlBti r ci l cid4 tlBtir ci l Pl j 28 sum taken diffused points tl spherical neighbourhood ti radius r The smoothed dimensionality index ti δ S argmax j P S j 29 Fig 11 shows results obtained dimensionality indices δG row δ S row Each column presents results indices toy data set The ﬁrst column shows 1 red 2 blue 3dimensional green eigenvaluerelated distributions simplices S0 S δG respectively points data set removing lowdensity background noise Central column shows points Q dimensionality index equal 1 red 3 green Points dimensionality index 2 blue shown column The central column clearly shows beneﬁcial effect spatial smoothing dimensionality index In columns small ball radius r 01 value r characteristic scale local manifold linearisations employed dimensionality index calculations manifold crawling data set δ S 8 r radius local PCA estimation 13 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 11 Eigenvalue distribution simplex dataset labelled dimensionality index δG upper row δ S lower row Fig 12 Confusion matrices dimensionality indices δ O left δG centre δ S right The superior performance δ S conﬁrmed Fig 11 Knowing apriori true dimensionality point provide qualitative analysis different dimensionality index formulations form confusion tables shown Fig 12 The confusion tables present percentages correctly incorrectly classiﬁed points depending true dimensionality corresponding dimensionality indices We included Noise class containing points generated lower density background noise supposed ﬁltered initial preprocessing step outlined section 2 Left middle right panels confusion matrices indices δ O reformulation dimensionality index proximity renormalized eigenspectrum ideal eigenspectrum dimensionality 1 j d index δG stabilizes estimation The index stabilized spatial smoothing soft version δG respectively Compared δ O provided index δ S δ S δG 42 Multi manifold crawling Having obtained dimensionality index δ S point ti Q corresponding point ti Q j Q j j For given 1 j d data sets Q j Q j contain noisy crisp samples respectively perform partition data sets according dimensionality indices Q j ti Q δ S ti Q δ S manifolds intrinsic dimension j While Manifold Crawling algorithm section 32 crawl assist model building single manifold method extended crawl isolate multiple manifolds given dimensionality j We initialize processed data set R Q j Then Manifold Crawling algorithm run R scale parameter r This results graphs G1 G1 forming skeletons individual manifolds dimensionality j Here assume separation manifolds Q greater r cid17 l For node vl G1 Ol subtracted R At time computing Ol Bvl r Q j vl V 1 cid17 l compute neighbourhood R Ol Bvl r R The neighbourhoods nodes G 1 recover noisy Ol aligned 1st manifold dimensionality j data set A1 14 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 13 Both panels probabilistic model manifold data set D recovered AGTM highlighted isosurface respective Probability Density Function The black skeletons panel embedded graphs obtained MultiManifold Crawling training AGTM The manifolds sampled Q j separated larger distances previous crawling run reached Therefore R cid18 seed picked random R new crawling procedure initiated This produces graphs G2 G2 accompanied corresponding manifoldaligned data A2 After reduction R described R cid18 process repeated Finally assuming processing Q j took H runs procedure results collection H extracted jdimensional The individ associated manifold speciﬁc data sets cid18 Gcid14 Gcid14 Acid14 cid6 cid5 cid19 cid18 cid19 H H cid141 Gcid14 data sets Acid14 AGTM algorithm section 31 construct manifoldaligned manifolds represented graphs ual graphs Gcid14 density models manifolds intrinsic dimensionality j cid141 H cid141 To guarantee smoothness AGTM density estimates conservatively set cid7net parameter basis function positioning abstract graphs section 31 cid7 1 Due relatively modest curvature lowdimensional structures crawling step size parameter η section 32 set η 075 The tolerance scale parameter contraction phase crawling procedure set β 04 As mentioned earlier r 01 characteristic scale parameter Fig 13 shows embedded graphs Gcid14 black lines overlaid AGTMs red blue pdf isosurfaces manifolds example data set described section 2 plotted intrinsic dimensionality corresponding manifolds j 1 left j 2 right The results insensitive small variations parameters r η β Larger values η cause overshooting highly curved local manifold structures smaller values η harmless modulo increased computational complexity Likewise larger values β result neglecting important details manifold structure smaller values harmless lead mixture components ﬁnal probabilistic model The important parameter characteristic scale r governing local manifold linearisations determination dimensionality indices manifold crawling This set based prior knowledge inspection data set Alternatively multimanifold learning method semiautomatic exploratory tool domain experts focus characteristic scale r structures mined varied continuously starting capturing coarse structures data larger r proceeding detailed analysis potentially lowdimensional manifolds start appear decreasing r 43 An eﬃcient alternative multimanifold crawling One approximate results Multimanifold crawling constructing cid7neighbourhood graph speciﬁc sam ples data set Q j cid7 set r radius local PCA crawling algorithm We ﬁrst cover Q j L hyperballs Btk c k 1 2 L radius c r2 centred tk Q j located recursive algorithm 20 Hence Q j L Sk Sk Btk c Q j For set Sk deﬁne centre sk sample mean obtaining set centres S s1 sL By design minimum Euclidean distance pair centres sm sn S m cid18 n k1 r 2 min mcid18n dE sm sn r We compute distance centres obtaining square symmetric matrix Dmn dE sm sn m cid18 n m n 1 L recover initial estimate adjacency matrix A graph G The adjacency matrix nonzero elements elements D smaller r cid8 Amn 1 Dmn r 0 Otherwise 15 30 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 14 Data set D2 interlocked noisy toroids right panel diffused ﬁltered counterpart D2 left panel This initial adjacency matrix A tends overly connected consideration alignment tangent spaces neighbouring partition centres In order include geometrical information A set Sk compute eigendecomposition approximate local tangent space unknown manifold Mcid14 centre sk ﬁrst j eigenvectors u1 u j collected matrix Uk u1 u j For pair connected points corresponding entry initial adjacency matrix 1 compute angle corresponding tangent spaces mUn R j j We retain existing edge angle cid5 41 cid26mn arccos det Mmn Mmn U connected points cid26mn π 3 Alternatively deﬁne additional hyperparameter 0 T θ 1 smaller larger angles tolerated construction graph The condition ﬁnal adjacency matrix cid8 Amn 1 Dmn r cid26mn T θ π 2 0 Otherwise 31 In case simply imposed T θ 2 3 Having constructed adjacency matrix A set Q j split graph G corresponding A maximal connected components Kc V c E c c 1 NG Here V c E c sets centres nodes edges respectively component Kc For component deﬁne corresponding abstract graph Kc Vc Ec previous section We use NG extracted pairs embedded abstract graphs initialization AGTM alternative Multimanifold crawling initialization presented section 5 Experimental comparison existing methods While multimanifold AGTM covers multimanifold learning probabilistic modelling simultaneously methodologies literature focus aspect capturing spatial structures point clouds We split evaluation AGTM comparative experiments lines 1 recovery collection smooth manifolds possibly different dimensionalities 2 probabilistic modelling data distribution We use main data sets The ﬁrst data set D1 Q presented section 2 composed sampled manifolds different dimensionali ties embedded R3 We recall presence nonlinear 1dimensional curved spiral hyperbolic arm 2dimensional manifolds toroid Möbius strip parabolic cap Sshape The second data set D2 consists interlocked noisy toroids Fig 14 Both data sets embedded uniformly distributed noise domain All methods comparison applied data sets initial ﬁltering methodology section 2 obtaining diffused Di noisy Di version data set 51 Multimanifold learning In section compare manifold crawling alternative eﬃcient graph construction presented sec tion 43 main algorithms literature codes publicly available Sparse Manifold Clustering Embedding SMCE 42 Low Rank Neighbourhood Embedding LNRE 43 We test method ologies data sets D1 D2 order verify ability deal multiple manifolds different dimensionalities topologies Both SMCE LRNE designed cluster mixture lowdimensional manifolds embedded higher dimensional space recovering lowdimensional embedding manifold In methods number manifolds data set provided user In contrast Multimanifold crawling alternative graph construction recover number manifolds data set automatically characteristic size manifolds 16 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 15 Comparison embeddings obtained data set D2 LRNE second column MultiManifold Crawling rightmost column cid7mesh alternative column The clusters shown leftmost column equally recovered methods panel Panel b shows number components row computational time row MultiManifold Crawling black boxplots cid7mesh alternative blue boxplots identiﬁed label NG evaluated 30 samplings synthetic data set D2 provided Fig 15a presents qualitative comparison9 embeddings recovered LRNE second column eﬃ cient alternative Manifold Crawling column Manifold Crawling fourth column data sets D2 While clustering performance similar methods ﬁrst row embeddings recovered LRNE explicitly display properties toroids The graphs recovered Manifold Crawling alternative graph construction provide insight topological structures underlying sampled noisy manifolds We tested stability Multimanifold crawling cid7graph alternative respect hyperparameter settings To end evaluated number recovered manifolds range hyperparameter values Fig 15b upper row The blue box plots statistics number manifolds recovered cid7graph construction 30 different samplings data set D2 given radius The black compact boxplots10 measure 30 iterations MultiManifold crawling data set radius different values parameter β Not surprisingly Multimanifold crawling displays higher stability alternative range values parameter r little change 9 Parameters method tuned optimize performance D2 10 For visualization purposes black compact boxplots shown hollow dots means black vertical lines variances plus smaller black dots outliers present 17 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 16 Same Fig 15a data set D1 parameter β given radius While methods converge correct number manifolds case starting r 01 eﬃcient cid7graph method vastly overestimates number manifolds radius small The computational times shown Fig 15b lower row This discrepancy quality results stems imposition alternative methodology crawling hard angular threshold controls variability angles neighbouring tangent spaces Even slight deviation threshold prevent nodes belonging manifold connected The eﬃcient alternative critically relies angle relations local PCA subspaces The subspace decompositions increasingly unreliable decreasing radius reliance subspace angles needed crawling procedure The comparison shown Figs 16 17 data set D1 For Crawling approximation clusters obtained applying procedure outlined section 42 43 respectively While case data set D2 LRNE able successfully recover manifolds set carefully tuned parameter conﬁgurations results proved unsatisfactory applied data set D1 In particular parameter setting able distinguish Möbius strip parabolic arm shown Fig 16 right panel red points All resulting embeddings Fig 16 rightmost column exception hyperbolic surface cyan points panel spiral panel blue points fail capturing lowdimensional structure corresponding manifold The ﬁrst columns Fig 16 illustrate performance Multimanifold crawling cid7graph alternative D1 Although representation 2dimensional manifolds coherent methodologies cid7graph tends break prematurely 1dimensional structures smaller segments This behaviour conﬁrmed values radius shown Fig 17 row Here contrast data set D2 convergence correct number 18 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 17 Same Fig 15b data set D1 Fig 18 Top row shows results obtained SMCE data set described 42 row shows results obtained MultiManifold Crawling From left right obtained clusters embedding graph ﬁrst cluster embedding graph second cluster Table 2 Parameters Manifold Learning methods analysis data sets D1 D2 Methods cid7graph Crawling LRNE SMCE Parameters r 008 009 017 r 008 009 017 k 25 30 50 k 30 35 40 45 50 β 03 035 05 lL R N E 1e 3 5e 3 1e 2 10 l S MC E 1e 3 1e 2 1e2 manifolds achieved MultiManifold Crawling eﬃcient cid7graph alternative consistently overestimates measure This clearly demonstrates enhanced accuracy stability Multimanifold crawling course price higher computational time Fig 17 row The application SMCE set parameters Table 2 proven unsuccessful data sets D1 D2 In order perform qualitative comparison methodology applied manifold crawling data set described 42 The data set consists noiseless 3foiled interlocked knots The application methods presented data set proved equally satisfying parameter settings However introducing small noise manifold performance SMCE greatly deteriorates terms clustering accuracy quality embedding Fig 18a row The results improve data set diffused ﬁltered 19 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 parameter setting In contrast Manifold crawling recovers underlying ground truth building 1dimensional closed graphs clustering noisy data set accordingly Fig 18b 52 Probabilistic modelling In subsection evaluated construction embedded latent space AGTM model manifold tection approximation method speciﬁcally designed handle general lowdimensional manifolds embedded ﬁnite dimensional Euclidean spaces In section treat AGTM section 3 generative probabilistic model data aligned noisy manifolds As explained needed split model evaluation distinct strands best knowledge ﬁnd competitor naturally span general manifold learning probabilistic modelling We compare AGTM initialized Manifold crawling eﬃcient cid7graph alternative probabilistic modelling techniques Fast Parzen Window FPW 20 unsupervised algorithm learning ﬁnite mixture models multivariate data 44 For data sets D1 D2 apply 5fold crossvalidation scheme Each method initialization Multimanifold crawling applied thirty times training folds given parameter setting average loglikelihood point generated model evaluated corresponding holdout fold The Multi manifold crawling initialization repeated ﬁve times training set run different β parameter The results data sets multiple manifolds different dimensionalities D1 interlocked toroids D2 presented Figs 19b 19a respectively Top row plot shows average loglikelihood different parameters boxplot initialization repetitions Bottom row shows computational time required training model The performance FPW generally higher faster methods natural consequence eﬃcient unconstrained probabilistic modelling algorithm The manifold structure lost set mixture components However data sets AGTM initialized MultiManifold crawling comparable FPW outperforms alternative initialization algorithm proposed 44 terms average loglikelihood It worth noting computational time AGTM comparable lower ﬁnite mixture method 44 In conclusion AGTM provides faithful probabilistic model data providing clear interpretation lowdimensional general manifold structures data organized 6 Experiments jellyﬁsh galaxy We demonstrate methodology analysis formation curious astronomical object jellyﬁsh galaxy detailed astrophysical simulation formation The term jellyﬁsh galaxy refers observed galaxy showing signs gas stripping 45 signatures dense head mainly gas stars elongated gaseous star forming tail These galaxies usually observed falling large clusters galaxies hot ionized gas ﬁlling cluster able strip away tentacles relatively cold gas galactic body The technique described valuable tool investigate behaviour physical quantities head gaseous tail We focus study identifying star formation regions head tail galaxy main reasons presence new stars born head important indicator galactic gas affected stripping pressure ii stars created dense cold regions gas presence lack thereof stars formed gaseous tail carries information galaxy gas mixed hot gas surrounding environment To quantify star formation measure intensity C ii emission line Recent observations Herschel Space Observatory showed tight correlation intensity C ii known tracers Star Formation Rate SFR 4647 The study provide useful insights formation scenario galaxies infalling cluster 48 As example dwarf galaxy NGC 1427A Fornax cluster provides interesting case unclear formation scenario generally accepted common interpretation lacking 4951 Starting existing suite simulations dwarf galaxies evolving Fornaxlike cluster environment 51 chose single simulated snapshot representing irregular gas rich galaxy exposing elongated star forming gaseous tail intense ram pressure stripping The simulation performed modiﬁed version mixed NbodySmoothed Particle Hydrodynamics SPH code GADGET2 5253 In order simulate evolution galaxy high resolution reduce computational cost simulating galaxy cluster advantage moving box technique 54 In formulation follow closely evolution galaxy immersing cubic volume box enveloping galaxy gravitational potential galaxy cluster The gravitational potential modelled spherically symmetric static NavarroFrenkWhite proﬁle NFW 55 The box position orientation updated timestep xaxis tangential orbit galaxy moment Also timestep new gas particles injected simulation box open 20 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 19 Panels b present average loglikelihood point probabilistic models generated methodologies different parameter settings row computational time required train models row data sets D2 D1 respectively face existing ones removed close opposite box11 This injectionejection technique simulate motion galaxy clusters gas crucial studying processes gas stripping The density temperature injected particles change according position box cluster following radial proﬁles described 56 assuming hydrostatic equilibrium gas This setup allows study evolution galaxy high consistent characteristics ambient space physical properties galaxy cluster comparatively lower computational cost The computation model SPH simulations based particle formulation hydrodynamics particle samples physical properties mass temperature density volume radius rN radius sphere containing N neighbouring particles smoothing length A continuous distribution physical variables domain obtained spatial smoothing Gaussian kernels centred particle 57 Associated gas particle representing corresponding volume values physical quantities density temperature pressure 11 The particles falling box 21 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 20 Gas particles simulated dwarf galaxy falling halo Fornax Galaxy Cluster An estimate C ii emission kind simulations obtained evolved quantities gas metallicity density temperature inputs chemical evolution models radiating gas taking account ionization equilibrium ion level occupation model 5853 Here focus state galaxy 25 Gyrs evolution injection galaxy cluster The data set consists 135530 gas particles observations having 11 ob served variables12 dimensions rN smoothing length x y zcoordinates representing position moving box v x v y v z velocities axis box m ρ T C ii mass density temperature C ii emission volume gas sampled particle Since particles construction SPH methodology ﬁll volume moving box ﬁrst apply 3 atomcm3 This lower limit density physically motivated ﬁltering removing particles density ρ 10 particles able emit radio band observed galaxy After initial ﬁltering remaining data set consists 83772 particles Their distribution boxs volume shown Fig 20 Several low dimensional structures clearly visible example long 1dimensional manifold departing head elongating xaxis simulation box Visually inspecting data set chose radius r 1 kpc characteristic scale parameter manifolds shown small sphere Fig 20 The chosen radius agreement spatial resolution recent observations galaxies distant NGC 1427A This parameter ﬁxed preprocessing diffusion ﬁltering section 2 local dimensionality estimation section 41 manifold crawling sections 32 42 The parameters set synthetic data experiments section 42 cid7 1 η 075 β 04 As mentioned earlier main body data set visually divided head tail parts However topological standpoint justiﬁcation clear segregation 1D manifolds tail 2D manifolds head Dimensionality index estimation clearly identiﬁed 1D structures tail elongated stream particles starting head However points head predominantly identiﬁed as13 1D complicated intertwined ﬁlamentary structure On hand distribution 2D points localized main body tail 61 A multi manifold analysis dwarf jellyﬁsh galaxy We evaluate performance AGTM initializations compare probabilistic modelling methods introduced 5fold crossvalidation scheme 1 2dimensional gas particles The average outofsample loglikelihood point computational times reported Fig 22 methods parameter settings From probabilistic modelling standpoint methods perform similarly FPW providing best score Both initializations AGTM comparable results obtained method described 44 lower compu tational effort Initialization crawling shows high stability results compared alternative initialization competing methodology The cid7graph initialization despite larger sensitivity randomness sampling process reaches higher values average loglikelihood initialization obtained crawling This behaviour explained tendency break manifolds substructures Having structures cover spatial region leads better performance probabilistic modelling algorithm However infor mation lowdimensional structures retained substructures gradually deteriorates phenomenon occurs frequently The limiting case information loss represented FPW distribution data set globally captured high eﬃciency additional information lowdimensional local structures inferred Having obtained multimanifold probabilistic proﬁle gas particles tail jellyﬁsh galaxy possible perform kinds detailed analysis physical properties vary manifolds Here centrate curvature Fig 23 deﬁned section 321 star formation potential analysing behaviour emission line C ii 1D 2D structures jellyﬁsh tail shown black dots Fig 21 left right 12 The number observed variables larger presented We decided focus ones relevant analysis 13 We use loose terminology referring points dimensionality index j jD points 22 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 21 1D left 2D right distributions diffused particles tail jellyﬁsh structure Highlighted black points belonging distinct 1D 2D structures discussed section 61 Fig 22 Average loglikelihood row log computational time probabilistic modelling techniques described section 52 applied jellyﬁsh data set respectively gaseous stream gas particles departing head reaching half way tail predominant 2D structure tail Fig 23 left panel shows regions high curvature 2dimensional manifold presented Fig 21 right panel The far right region intense curvature located end tail gas motion chaotic motion galaxy halo galaxy cluster However spherical region left manifold presenting coherent curvature elongation circle Fig 23 left panel suggests possible cause formation isotropic expansion typical Supernova remnants Taking advantage probabilistic nature AGTM model Fig 24a embedded vertices v j particles ti graph G stream model intensity modulated weighted mean C ii values I C ii manifold weights posterior probabilities node v j given particles ti cid7 I C ii j i1 pv jti ζ jcid10 j W j IC ii NM cid7 k1 pv jtk ζ jcid10 j W j Analogous ﬁgure 2D structure presented Fig 24b NM 32 In 1D case manifold located outskirts jellyﬁsh Fig 20 left panel meaning exposed evolution surrounding gas galaxy cluster This implies manifold subject higher ram pressure tail leading higher density lower temperature gas necessary conditions formation new stars These conditions reﬂected increase C ii emission line middle section manifold 3 x 6 informing enhanced Star Formation Rate compared rest manifold The 23 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 23 Embedded graph left panel planar representation right panel 2dimensional manifold extracted jellyﬁsh data set onedge curvature distribution Fig 24 1D 2D manifolds extracted data set Fig 20 The graphs nodes coloured based value C ii surrounding particles lying 1 kpc local tangent space manifold weighted nodes responsibilities 2D structure shows overall constant C ii intensity region 5 x 9 presents sharply higher values The shape region particularly interesting It fact hole spherical section This structure detected AGTM Manifold Crawling potent C ii emission boundary remnant supernova explosion This process modelled simulation injection 1051 erg energy short time transfer metallic elements case simulation model tracks iron magnesium 53 neighbouring gas particles The metalenriched gas particles like surrounding supernova explosion able cool eﬃciently strong C ii emission line Our methodology provides strong tool extracting information morphology gas particles effectively calibrate feedback models14 simulations Such detailed analysis low dimensional structures remnants galaxy interactions currently possible tools routinely calibrate analyse astrophysical simulations galaxy evolution As mentioned section 42 technique presented paper semiautomatic exploratory tool domain experts focus characteristic scale structures mined varied continuously analysis physical properties necessary computations performed studied ﬂy 7 Detecting manifolds higher dimensions We performed additional experiment 3dimensional torus embedded dimensions The torus parametrized angle space θ φ ψ 0 2π 0 2π 0 2π 14 A feedback mechanisms process allows exchange energy matter andor momentum galaxy components 24 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 Fig 25 Results crawling sampled 3torus row comparison ground truth graph left crawled regularly sampled 3torus right rθ φ ψ 3 cosφ cosθ 3 cosφ sinθ 3 sinφ cosψ 3 sinφ sinψ 33 The 3torus covered sampling angle parameters large number uniformly distributed values We applied procedure producing sample noisy manifold previous synthetic data exper iments After preprocessing noisy data set SAF ﬁltering proceed estimating dimensionality index remaining point ﬁnding able retain structure 3dimensional points We apply Crawling algorithm constructing abstractembedded pair graphs The embedded latent space shown Fig 25a projected different triplets dimensions The global structure clearly recovered crawling However given abstract latent space induced diffused sample points regularly covering 3 25 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 torus internal structure manifold easily identiﬁable To demonstrate clearly ability crawling algorithm recover underlying 3dimensional manifold structure let crawling operate data set created regular grid points lying 3torus This way directly compare groundtruth embedded latent space graph obtained connecting neighbouring grid points 3torus topology shown subsampled version Fig 25b left panel recovered crawling Fig 25b right panel The embedded graphs shown projection corresponding Fig 25a left panel clearly sample manifold structure As shown example methodology principle applied higher dimensional manifolds embedded higher dimensional space This true ambient dimension increases provided manifold sampled local neighbourhoods populated perform PCA However computation time crawling algorithm bound increase expansion phase 2 j new children node estimates created parent node 8 Conclusion We presented novel semiautomated framework denoising dimensionality estimation multimanifold extraction manifold aligned density estimation complex data sets containing samples noisy manifolds diverse di mensionalities embedded noisy environment The framework uses easytounderstand hyperparameters characteristic scale manipulated obtain emerging picture multimanifold structure data We illustrated workings methodology synthetic data sets containing number manifolds including toroid Möbius strip embedded extremely noisy environment For manifold able estimate intrinsic dimensionality Abstract GTM extract embedded abstract graphs Man ifold Crawling constructing probabilistic model describing density We provided eﬃcient alternative Crawling algorithm computationally intensive While competitive manifold learning algorithms alternative Crawling proved accurate slower stable graph construction method We showed possible compute local curvature recovered manifolds taking advantage smooth mapping func tion formulation AGTM We performed detailed comparison MultiManifold learning Probabilistic modelling algorithms widely literature The MultiManifold learning alternatives proved sensitive noise impractical dealing multiple manifolds different dimensionalities The probabilistic modelling techniques al capable representing globally data sets designed explicitly capture general noisy lowdimensional structures data organized AGTM proved equally capable modelling global distribution data sets carrying meaningful information underlying lowdimensional manifolds The methodology applied complex data set containing simulated gas volume particles numerical simulation dwarf galaxy interacting host galaxy cluster We shown extracted 1D 2D manifolds help understand nature star formation inside disrupted dwarf galaxies Besides possible applications methodology offers new exciting ways analysing details emerging astrophysical simulations possible current tools commonly astronomy Declaration competing The authors declare known competing ﬁnancial interests personal relationships appeared inﬂuence work reported paper Acknowledgements This project received ﬁnancial support European Unions Horizon 2020 research innovation program Marie SklodowskaCurie grant agreement No 721463 SUNDIAL ITN Network PT MC supported Alan Turing Institute Fellowship 96102 Appendix A Manifolds equations data sets generation All synthetic data sets documented main body work generated ﬁrst deﬁning parametric functions Ground Truth manifolds adding noise manifolds rearranging aﬃne operators scaling rotation shift adding background noise In following parametric equations structure shown noise addition process described The functional forms presented following order Parabolic arm M1 1D Spiral M2 1D Sshape M3 2D Hyperbolic surface M4 2D Toroid M5 2D Möbius strip M6 2D 3ball M7 3D 3Toroid M8 3D embedded 4D M1 x 0 1 y 2x2 2x 1 z 02 M2θ1 r 2 r cosθ1 1 01 2 r sinθ1 1 04 x 1 y 1 z 01 1 26 A1 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 θ1 2π 10π r 01 1 In order obtain spiral data set variables θ1 r reordered ascending order variable z descending order M3 x sinθ21 y 1 3 z sgnθ2cosθ21 5 1 3 Here θ2 5 3π 5 M4 x R sinθ3 05 y R cosθ3 05 z 04 06 r 0 05 R r2 025 θ3 0 2π variables r θ3 z sorted ascending order M5 x R r cosv cosu y R r cosv sinu z r sinv Here set R 05 r 015 u v 0 2π 0 2π The Móbius strip obtained equations x y z t cid30 cid31 1 t cosu 2 cos u 2 cid30 cid31 1 t sinu 2 cos u 2 2 sin u 2 M6 A2 A3 A4 A5 t 1 1 Manifold M7 3ball radius r 1 The 3torus embedded 4 dimensions discussed section 7 parame terised M8 x 3 coscid6 cosθ y 3 coscid6 sinθ z 3 sincid6 coscid15 cid14 3 sincid6 sincid15 θ cid6 cid15 0 2π 0 2π 0 2π To generate data set D1 rotation operators needed T1 T2 T1 1 0 0 0 0 1 0 0 1 T2 0 1 0 1 0 0 1 0 0 A6 A7 Furthermore set shifting scaling operators designed manifold order obtain presented conﬁgu ration ˆM1 M1 01 01 0 ˆM2 04 M2 01 04 09 ˆM3 T1M3 0 0 05 ˆM4 12 M4 04 13 03 ˆM5 12 M5 02 068 05 ˆM6 025 T2M6 04 15 02 ˆM7 02 M7 02 05 0 The construction data set D2 simpler relies speciﬁc rotations shifts manifold M5 In particular ˆM9 M5 095 0 0 ˆM10 14 T1M5 0 0 012 ˆM11 M5 19 0 0 27 A8 A9 A10 A11 A12 A13 A14 A15 A16 A17 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 For manifold ˆMi 1 9 ﬁrst sample large number NG T 1e4 points ground truth Mi densely covering structure Around sample point manifold position hyperball ﬁxed radius rG T 004 Let denote union hyperballs BG T To generate sample noisy manifold ﬁrst envelope ground truth manifold cuboid ambient space The cuboid covered large number NC ub 1e6 points sampled uniform distribution collected SC ub The sample noisy manifold SC ub BG T After extensive testing hyperparameters SAF technique best results achieved r 005 μ 1e 3 Niter 5 References 1 K Pearson LIII On lines planes closest ﬁt systems points space Lond Edinb Dublin Philos Mag J Sci 2 11 1901 559572 https 2 JB Tenenbaum Vd Silva JC Langford A global geometric framework nonlinear dimensionality reduction Science 290 5500 2000 23192323 3 ST Roweis LK Saul Nonlinear dimensionality reduction locally linear embedding Science 290 2000 23232326 4 M Belkin P Niyogi Laplacian Eigenmaps Spectral Techniques Embedding Clustering Advances Neural Information Processing Systems 5 DL Donoho C Grimes Hessian eigenmaps locally linear embedding techniques highdimensional data Proc Natl Acad Sci 100 10 2003 doi org 10 1080 14786440109462720 pCA beginnings httpsdoi org 10 1126 science 290 5500 2319 vol 14 MIT Press 2001 pp 585591 55915596 httpsdoi org 10 1073 pnas 1031596100 6 Z Zhang H Zha Principal manifolds nonlinear dimension reduction local tangent space alignment SIAM J Sci Comput 26 2002 313338 7 Vd Silva JB Tenenbaum Global versus local methods nonlinear dimensionality reduction Proceedings 15th International Conference Neural Information Processing Systems NIPS02 MIT Press Cambridge MA USA 2002 pp 721728 httpdl acm org citation cfm id 2968618 2968708 8 WS Torgerson Warren S Torgerson Theory methods scaling New York John Wiley Sons Inc 1958 Pp 460 Behav Sci 4 3 1958 245247 httpsdoi org 10 1002 bs 3830040308 9 MAA Cox TF Cox Multidimensional Scaling Springer Berlin Heidelberg Berlin Heidelberg 2008 pp 315347 10 JB Kruskal Nonmetric multidimensional scaling numerical method Psychometrika 29 2 1964 115129 httpsdoi org 10 1007 BF02289694 11 T Lin H Zha Riemannian manifold learning IEEE Trans Pattern Anal Mach Intell 30 5 2008 796809 httpsdoi org 10 1109 TPAMI 200770735 12 JD Boissonnat F Chazal M Yvinec Geometric Topological Inference Cambridge Texts Applied Mathematics Cambridge University Press 2018 httpshal inria fr hal 01615863 wwwjstororg stable 2984875 13 CM Bishop M Svensén CKI Williams GTM generative topographic mapping Neural Comput 10 1998 215234 14 T Kohonen Selforganized formation topologically correct feature maps Biol Cybern 43 1 1982 5969 15 AP Dempster NM Laird DB Rubin Maximum likelihood incomplete data em algorithm J R Stat Soc B 39 1 1977 138 http httpsdoi org 10 1016 j patcog 201101019 Mining 2012 pp 241250 httpsdoi org 10 1016 j ins 2016 01069 patcog 2015 04 003 16 A Taghribi M Canducci M Mastropietro S De Rijcke K Bunte P Ti ˇno ASAP subsampling approach preserving topological structures modeled geodesic topographic mapping Neurocomputing 2021 httpsdoi org 10 1016 j neucom 202105 108 17 I Olier A Vellido Variational Bayesian generative topographic mapping J Math Model Algorithms 7 2008 371387 18 E Parzen On estimation probability density function mode Ann Math Stat 33 3 1962 10651076 19 P Vincent Y Bengio Manifold Parzen windows S Becker S Thrun K Obermayer Eds Advances Neural Information Processing Systems vol 15 MIT Press 2003 pp 849856 httppapers nips cc paper 2203 manifold parzen windows pdf 20 X Wang P Tino MA Fardal S Raychaudhury A Babul Fast Parzen window density estimator 2009 International Joint Conference Neural 21 CE Rasmussen The inﬁnite Gaussian mixture model Proceedings 12th International Conference Neural Information Processing Systems Networks 2009 pp 32673274 NIPS99 MIT Press Cambridge MA USA 1999 pp 554560 22 W Yang C Sun L Zhang A multimanifold discriminant analysis method image feature extraction Pattern Recognit 44 8 2011 16491657 23 M Fan H Qiao B Zhang X Zhang Isometric multimanifold learning feature extraction 2012 IEEE 12th International Conference Data 24 M Fan X Zhang H Qiao B Zhang Eﬃcient isometric multimanifold learning based selforganizing method Inf Sci 345 C 2016 325339 25 R Hettiarachchi J Peters Multimanifold LLE learning pattern recognition Pattern Recognit 48 9 2015 29472960 httpsdoi org 10 1016 j 26 S Mahapatra V Chandola SIsomap multi manifold learning streaming data arXiv1710 06462 Oct 2017 27 P Tino I Nabney Hierarchical GTM constructing localized nonlinear projection manifolds principled way IEEE Trans Pattern Anal Mach Intell 24 5 2002 639656 httpsdoi org 10 1109 34 1000238 28 G Haro G Randal G Sapiro G Haro G Randall G Sapiro Translated Poisson mixture model stratiﬁcation learning Int J Comput Vis 2000 29 M Allegra E Facco F Denti A Laio A Mira Data segmentation based local intrinsic dimension Sci Rep 10 2020 16449 httpsdoi org 10 1038 s41598 020 72222 0 arXiv1902 10459 30 E Facco M dErrico A Rodriguez A Laio Estimating intrinsic dimension datasets minimal neighborhood information Sci Rep 7 2017 31 X Wang P Tiño MA Fardal Multiple manifolds learning framework based hierarchical mixture density model W Daelemans B Goethals K Morik Eds Machine Learning Knowledge Discovery Databases Springer Berlin Heidelberg Berlin Heidelberg 2008 pp 566581 32 CM Bishop M Svensén CKI Williams Developments generative topographic mapping Neurocomputing 21 1998 203224 33 D Bacciu A Micheli A Sperduti Compositional generative mapping treestructured datapart II topographic projection model IEEE Trans Neural 34 S Wu P Bertholet H Huang D CohenOr M Gong M Zwicker Structureaware data consolidation IEEE Trans Pattern Anal Mach Intell 40 10 Netw Learn Syst 24 2 2013 231247 2018 25292537 httpsdoi org 10 1109 TPAMI 20172754254 35 KB Petersen MS Pedersen The Matrix Cookbook Technical University Denmark 2012 version 20121115 httplocalhost pubdb p php 3274 36 H Hotelling Analysis complex statistical variables principal components J Educ Psychol 24 1933 417441 37 JO Rawlings SG Pantula DA Dickey Applied Regression Analysis A Research Tool Springer Science Business Media 2001 38 P Mordohai G Medioni Unsupervised dimensionality estimation manifold learning highdimensional spaces tensor voting Proceedings 19th International Joint Conference Artiﬁcial Intelligence IJCAI05 Morgan Kaufmann Publishers Inc San Francisco CA USA 2005 pp 798803 httpdl acm org citation cfm id 1642293 1642421 28 M Canducci P Tiño M Mastropietro Artiﬁcial Intelligence 302 2022 103579 39 G Lebanon Riemannian geometry statistical machine learning PhD thesis Carnegie Mellon University Pittsburgh PA USA 2005 aAI3159986 40 AF Möbius Der barycentrische Calcul ein neues Hülfsmittel zur analytischen Behandlung der Geometrie Barth 1827 41 H Gunawan O Neswan WS Budhi A formula angles subspaces inner product spaces Beitr Algebra Geom 46 01 2005 42 E Elhamifar R Vidal Sparse manifold clustering embedding J ShaweTaylor R Zemel P Bartlett F Pereira KQ Weinberger Eds Ad vances Neural Information Processing Systems vol 24 Curran Associates Inc 2011 pp 5563 httpsproceedings neurips cc paper 2011 ﬁle fc490ca45c00b1249bbe3554a4fdf6fb Paperpdf 43 AM Saranathan M Parente On clustering embedding mixture manifolds low rank neighborhood approach IEEE Trans Geosci Remote Sens 57 6 2019 38903903 httpsdoi org 10 1109 TGRS 2018 2888983 44 MAT Figueiredo AK Jain Unsupervised learning ﬁnite mixture models IEEE Trans Pattern Anal Mach Intell 24 3 2002 381396 https doi org 10 1109 34 990138 45 BM Poggianti A Moretti M Gullieuszik J Fritz Y Jaffé D Bettoni G Fasano C Bellhouse G Hau B Vulcani et al GASP I Gas stripping phenomena galaxies MUSE Astrophys J 844 1 2017 48 httpsdoi org 10 3847 1538 4357 aa78ed 46 I De Looze M Baes GJ Bendo L Cortese J Fritz The reliability C II indicator star formation rate Mon Not R Astron Soc 416 4 2011 27122724 httpsdoi org 10 1111 j 1365 2966 201119223 x arXiv1106 1643 47 R HerreraCamus AD Bolatto MG Wolﬁre JD Smith KV Croxall RC Kennicutt D Calzetti G Helou F Walter AK Leroy et al C ii 158 μm emission star formation tracer Astrophys J 800 1 2015 1 httpsdoi org 10 1088 0004 637x 800 1 1 48 H Ebeling LN Stephenson AC Edge Jellyﬁsh evidence extreme rampressure stripping massive galaxy clusters Astrophys J 781 2 2014 49 MD Mora J Chanamé TH Puzia A starburst core galaxy cluster dwarf irregular NGC 1427A Fornax Astron J 150 3 2015 93 L40 httpsdoi org 10 1088 2041 8205 781 2 l40 httpsdoi org 10 1088 0004 6256 150 3 93 arXiv14117314 50 K LeeWaddell P Serra B Koribalski A Venhola E Iodice B Catinella L Cortese R Peletier A Popping O Keenan M Capaccioli Tidal origin NGC 1427A Fornax cluster Mon Not R Astron Soc 474 1 2017 11081115 httpsdoi org 10 1093 mnras stx2808 51 M Mastropietro S De Rijcke RF Peletier A tale tails insights simulations formation peculiar dwarf galaxy NGC 1427A Mon Not R Astron Soc 504 3 2021 33873398 httpsdoi org 10 1093 mnras stab1091 arXiv2104 07671 52 V Springel The cosmological simulation code GADGET2 Mon Not R Astron Soc 364 4 2005 11051134 httpsdoi org 10 1111 j 1365 2966 53 S De Rijcke J Schroyen B Vandenbroucke N Jachowicz J Decroos A CloetOsselaer M Koleva New compositiondependent cooling heating curves galaxy evolution simulations Mon Not R Astron Soc 433 4 2013 30053016 httpsdoi org 10 1093 mnras stt942 arXiv1306 4860 54 M Nichols Y Revaz P Jablonka The postinfall evolution satellite galaxy Astron Astrophys 582 2015 A23 httpsdoi org 10 1051 0004 6361 55 JF Navarro CS Frenk SDM White The structure cold dark matter halos Astrophys J 462 1996 563 httpsdoi org 10 1086 177173 arXiv 56 M Paolillo G Fabbiano G Peres DW Kim Deep ROSAT HRI observations NGC 1399NGC 1404 region morphology structure Xray halo Astrophys J 565 2 2002 883907 httpsdoi org 10 1086 337919 57 R Gingold J Monaghan Smoothed particle hydrodynamics theory application nonspherical stars Mon Not R Astron Soc 181 1977 58 U Maio K Dolag B Ciardi L Tornatore Metal molecule cooling simulations structure formation Mon Not R Astron Soc 379 3 2007 375389 httpsdoi org 10 1093 mnras 1813 375 963973 httpsdoi org 10 1111 j 1365 2966 200712016 x 2005 09655 x 201526113 arXiv1503 05190 astro ph 9508025 29