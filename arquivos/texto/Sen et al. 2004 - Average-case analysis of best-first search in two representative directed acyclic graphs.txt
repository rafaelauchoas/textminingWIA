Available online wwwsciencedirectcom R Artiﬁcial Intelligence 155 2004 183206 wwwelseviercomlocateartint Averagecase analysis bestﬁrst search representative directed acyclic graphs Anup K Sen Amitava Bagchi Weixiong Zhang b Indian Institute Management Calcutta Joka D H Road Calcutta 700 104 India b Department Computer Science Engineering Washington University Saint Louis St Louis MO 63130 USA Received 5 May 2003 Abstract Many problems arise real world search spaces graphs trees Understanding properties search algorithms analyzing performance major objectives research AI But published work analysis search algorithms focused tree search comparatively little reported graph search One major obstacles analyzing averagecase complexity graph search single graph serve suitable representative graph search problems In paper propose possible approach analyzing graph search We problem domains search graphs directed acyclic graphs similar structure determine average case performance graphs The ﬁrst domain relates onemachine job bestﬁrst search algorithm A sequencing problems set jobs sequenced machine way penalty function minimized The second domain concerns Traveling Salesman Problem Our mathematical formulation extends technique previously analyzing tree search We demonstrate existence gap computational cost classes problem instances One class exponential complexity polynomial complexity For job sequencing domain provide supporting experimental evidence showing problems exhibit huge difference computational cost different conditions For Traveling Salesman Problem theoretical results reﬂect longstanding debate expected complexity branchandbound algorithms solving problem indicating complexity polynomial exponential depending accuracy heuristic function 2004 Elsevier BV All rights reserved Keywords Graph search Averagecase complexity A Job sequencing Traveling salesman Corresponding author Email addresses seniimcalacin AK Sen bagchiiimcalacin A Bagchi zhangcsewustledu W Zhang 00043702 matter 2004 Elsevier BV All rights reserved doi101016jartint200401001 184 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 1 Introduction overview In realworld applications graph search shown efﬁcient tree search Sometimes tree search simply feasible Consider sequence alignment important issue computational biology formulated shortestpath problem grid It solved help graph search 51217 Problems arise singlemachine minimumpenalty job sequencing solved help graph search tree search case graph search outperforms tree search terms running time evaluation function nonorderpreserving 26 In addition determination winner combinatorial auction 25 solution obtained principle enumerating exhaustive partitions items search space form graph These examples demonstrate graph search possible applications Moreover graph search usually needs memory bestﬁrst tree search making larger problems solvable current machines 27 Although graph search plays important role understanding characterizing solving difﬁcult combinatorial optimization problems averagecase performance graph search algorithms hardly analyzed In sharp contrast large literature devoted analysis performance tree search algorithms 2671116 202231 One objective paper extends work reported 28 try redress balance A major consideration hamstrung research performance analysis graph search algorithms single graph claim representative graph search spaces arise realworld applications Therefore general results performance graph search reach One way dilemma separate independent analysis individual problem makes generalization difﬁcult Here middle road Our analysis perfectly general conﬁned individual case We choose study representative model set related problems hope shed light individual problems lead generalization help achieve deeper understanding graph search Here look classes problems The ﬁrst class consists onemachine job sequencing problems second consists Traveling Salesman Problem TSP Job scheduling job sequencing problems arise frequently manufacturing production systems information processing environments 23 We consider class problems N given jobs sequenced machine way speciﬁed function job completion times minimized The function different forms involve minimization measures mean job lateness andor earliness weighted sum quadratic functions completion times Our analytical model job sequencing problem form graph deﬁnes partial ordering subsets set N elements jobs set inclusion property N determines problem size The graph 2N nodes directed acyclic graph DAG root node goal node multiple solution paths The set N elements forms root node level 0 set goal node level N To analysis feasible assumed following 22 normalized errors heuristic estimates nongoal nodes independent identically distributed iid AK Sen et al Artiﬁcial Intelligence 155 2004 183206 185 random variables Using abstract model analyze complexity bestﬁrst graph search algorithm A The measure complexity expected number node expansions We choose A preference search algorithms optimal terms number node expansions algorithms use heuristic information 8 There main theoretical results First shown certain weak conditions expected number distinct nodes expanded A increases exponentially number N jobs large N This consistent previous experimental results onemachine job sequencing problem 27 Second special cases identiﬁed expected number node expansions A polynomial N large N The results indicate expected complexity A graph search job sequencing problems distinct phases exponential polynomial demonstrating existence huge gap similar phenomenon phase transition Experimental results support theoretical analysis We summarize previous results exponential case provide new test results polynomial case A similar identical search graph arises solution procedure Traveling Salesman Problem TSP In essence known algorithms solving TSP exactly implicit enumeration methods based branchandbound procedure progressively construct complete tours 91018 One difference algorithms relates branching rules determine search space tree graph 3 Even best TSP algorithms use tree search space 30 remains determined search space tree graph efﬁcient It likely search space use depend application hand In addition graph search space originally proposed TSP 22 benchmark domain computational experiments 24 Therefore worthwhile examine graph search spaces context TSP It interesting note theoretical results derived job sequencing domain counterparts TSP domain means A run exponential nonexponential polynomial time number N cities We state prove corresponding theorems These results shed light longstanding debate expected complexity speciﬁc branchand bound algorithms solving TSP 4 It argued branchandbound algorithm ﬁnd optimal solution TSP time polynomial N certain conditions 4 time exponential N conditions hard satisfy 1519 When run graphs A viewed special type branchandbound algorithm uses bestﬁrst search strategy exits soon solution Therefore results paper indicate expected complexity branchandbound algorithm TSP polynomial nonexponential exponential depending deﬁnition intercity cost function accuracy heuristic function The paper organized follows The application domains representative search graphs introduced Section 2 Basic concepts relating graph search framework analysis presented Section 3 In Section 4 examine job sequencing problem greater derive expected complexity A 186 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 present supporting experimental results Section 5 concerned TSP Section 6 concludes paper Proofs theorems supplied Appendix A 2 Application problem domains representative graphs 21 Onemachine job sequencing problems We representative graphs model search spaces application problem domains mentioned Consider graph deﬁnes partial ordering subsets set N elements set inclusion property Let SN set 1 2 N The subsets SN partial ordering relation induced set inclusion form directed acyclic graph Gjs 2N nodes In graph SN root node level 0 set goal node level N The immediate successors node n subsets SN obtained n removing element Thus node corresponding subset k elements k immediate successors Gjs N 4 shown Fig 1 Such graph following characteristics 1 A node elements level N 2 There distinct paths node level 3 There CN nodes level 4 The total number paths starting root going level CN This graph arises solution certain onemachine job sequencing problems exhibits topdown leftright symmetry Graphs similar symmetries arise graph search formulations Traveling Salesman Problem 22 winner determination problem combinatorial auctions 25 Fig 1 Analytical model Gjs N 4 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 187 cid1 In job sequencing problem jobs Ji processing times Ai 0 1 cid1 cid1 N submitted machine job shop time 0 The jobs assumed setup times processed given machine time Let processing job Ji completed time Ti Penalty functions Hi supplied penalty associated completing job Ji time Ti HiTi 0 Hi nondecreasing argument general nonlinear The jobs sequenced machine N way total penalty F i1 HiTi minimized Nodes search graph Gjs correspond subsets jobs remain processed The root node corresponds set N jobs goal node set jobs completion jobs Arc costs assigned follows Suppose arc node n1 node n2 suppose job Ji present subset jobs associated n1 absent subset jobs n2 Then cn1 n2 HiTi Here Ti time processing job Ji completed value depend order jobs prior job Ji processed Since setup times ignored model arc costs order preserving 22 Such graphs searched past A TCBB 13 Here restrict A algorithm optimal terms node expansions 8 22 Traveling Salesman Problem TSP A graphsearch solution procedure TSP gives rise similar search graph Let N cities numbered 1 2 N Each node network identiﬁed pair set cities visited current city The trip assumed begin city 1 start node 1 represents set The goal node 1 2 N 1 A expands start node generates N 1 successor nodes 1 2 1 3 1 N The cost arc 1 successor 1 J 2 cid1 J cid1 N equals cost going city 1 current city predecessor node city J current city successor node The complete network Gtsp N 4 shown Fig 2 For speciﬁc cost matrix tour minimum cost running A search graph The heuristic estimate nongoal node computed minimum spanning tree heuristic 10 The network Gtsp following characteristics 1 The start node level 0 goal node level N A node level corresponds partial tour cities visited 1th city reached 2 A node level 1 incoming arcs 1 cid1 N incoming arcs 0 1 Similarly node level N 1 outgoing arcs 0 cid1 N 1 N outgoing arcs N 1 N cid2 3 The total number nodes level 1 cid1 N 0 N CN 1 1 cid2 4 The total number paths entering node level 1 cid1 cid1 N 0 1 0 188 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Fig 2 Analytical model Gtsp N 4 3 Basic concepts A search graph network G ﬁnite directed graph nodes n ncid9 n1 n2 The search begins start root node s ends goal node r Each directed arc n1 n2 G ﬁnite arc cost cn1 n2 0 A path sequence directed arcs A solution path path begins start node s ends goal node r The cost cP path P sum costs arcs path The objective search algorithm like A ﬁnd solution path minimum cost G To ﬁnd solution path A uses nonnegative heuristic estimate hn associated nongoal node n G hn viewed estimate hn cost path cost n goal node Let gn cost path cost start node node n let f n gn hn Then f n cost solution path cost constrained pass node n During execution A use gn represent cost path cost currently known s n So gn viewed current estimate gn f n gn hn current estimate f n As customary f r denotes cost minimum cost solution path G Our networks directed acyclic graphs In graphs introducing goal node add generality multiple paths root node goal node case When A run network node reenter OPEN CLOSED result node expanded Let Zd Zt denote respectively number distinct nodes expanded A total number node expansions A run given network G Zt Zd referred total number reopenings nodes Our primary goal determine expected values EZd EZt In order assign probability distribution heuristic estimates nongoal nodes G meaningful way adopt notion normalizing function 22 p 184 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 189 A normalizing function Φ total function set nonnegative real numbers domain set real numbers greater equal 1 range It following properties 1 Φ0 1 2 Φx nondecreasing x 3 Φx unbounded range Φ ﬁnite upper bound We allow Φ functional forms viz identity lessthanlinear logarithmic Φx max1 x Φx max1 xδ δ 0 δ 1 Φx max1 lnx identity lessthanlinear logarithmic The normalized error nongoal node n χn hn hnΦhn We assume nongoal nodes G normalized errors iid random variables The normalizing function Φ determines accuracy heuristic estimate function When Φ identity function magnitude error hn hn proportional hn The purpose allowing functions logarithmic ones example enable study consequences limiting error hn hn lower order values implying greater accuracy heuristic estimates We use χ place χn χns identically distributed Let Fχ x pχ cid1 x cumulative probability distribution function χ Then Fχ x nondecreasing x We allow Fχ x discontinuities These leftdiscontinuities Fχ x deﬁnition right continuous We assume speciﬁc functional form Fχ x A heuristic function h admissible nongoal node n network G hn cid1 hn Otherwise h inadmissible If Fχ x 1 x cid2 0 nongoal nodes admissible heuristic estimates probability 1 Let a1 lubx Fχ x 0 a2 glbx Fχ x 1 For x a1 Fχ x identically 0 x cid2 a2 Fχ x identically 1 The heuristic estimate function admissible a2 cid1 0 purely inadmissible a1 0 When Φx identity function a1 cid2 1 Even heuristic estimate function admissible a2 0 long a1 0 node n expanded A f n f r immediate predecessors n expanded Note deﬁnition a1 a2 case 1 hn cid2 hn a1Φhn probability 1 2 hn cid1 hn a2Φhn probability 1 A heuristic estimate function consistent 22 nongoal node n network G immediate successor ncid9 n case hn cid1 cn ncid9 hncid9 From onwards normalizing function discussion assume corresponding a1 a2 ﬁnite 190 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 4 Analysis onemachine minimumpenalty job sequencing problems 41 Exponential complexity We begin assigning probability distribution heuristic estimates nodes Gjs To compute number nodes expanded impose restrictions job processing times penalty functions We ﬁrst suppose processing times Ai integers satisfy condition 1 cid1 Ai cid1 k 1 cid1 cid1 N constant k 1 This imposes ﬁxed upper bound processing times jobs We assume positive integer constant β penalty Hix integer order oxβ 1 cid1 cid1 N This means penalty functions polynomial argument highest power polynomial β We assume arc costs greater equal 1 These reasonable assumptions processing jobs single machine job sequencing problems Similar assumptions 27 To test assumptions carried experiments penalty function job proportional square completion time All jobs submitted time t 0 The jobs processing times setup times The objective sequence jobs minimize sum penalties 29 Penalty coefﬁcients proportionality constants random integers uniformly distributed range 1 9 Processing times random integers uniformly distributed range 1 99 For given number jobs 100 random problem instances generated solved A results averaged 100 runs The heuristic estimate node computed suggested 29 This heuristic consistent accurate know exact accuracy level normalizing function linear lessthanlinear logarithmic The average numbers nodes generated expanded A problems different sizes shown Table 1 The number nodes generated exceeds N Zt N number jobs No node expanded heuristic consistent The results reported 27 similar slightly better additional pruning rule applied In Table 1 number nodes generated number nodes expanded increase fairly rapidly number jobs Let try offer partial theoretical justiﬁcation observations Let function Ψ N N varies exponentially N large N exists real constants γ δ ε 0 lim N Ψ N δ expγ N ε 1 Let Ψ N varies polynomially N large N exists real constant ε 0 lim N Ψ N N ε 0 We prove normalizing function identity function a1 0 expected number distinct nodes expanded exponential N large N provided ﬁxed upper bound processing times jobs AK Sen et al Artiﬁcial Intelligence 155 2004 183206 191 Table 1 Performance A consistent heuristics No jobs Nodes generated Nodes expanded Mean Std Dev Mean Std Dev 18 20 22 24 26 28 30 129937 232702 420779 706399 1260269 2204605 3719994 83737 152312 319339 525522 927302 1691290 3257806 11970 19152 31313 47735 78799 126868 200012 8613 13797 26738 38968 63892 104452 189312 Theorem 41 Suppose 1 cid1 cid1 N Hix oxβ β positive integer constant 1 cid1 Ai cid1 k constant k 1 If Φ identity function a1 0 EZd expected number distinct nodes Gjs expanded exponential N large N Proof See Appendix A This theorem general covers wide variety situations arise minimumpenalty job sequencing 26 In particular theorem assume heuristic admissible merely a1 0 Some constraints relaxed explained 1 There need assume constant upper bound job processing times We assume exists positive integer constant ε Ai oN ε 1 cid1 cid1 N 2 The proof remains valid normalizing functions lessthanlinear We curious ﬁnd observation happens heuristic estimates admissible necessarily consistent So carried set experiments making assumptions minor change This time node n took hn hn nhn n uniformly distributed random number open interval 0 1 determined independently n The results shown Table 2 Since heuristic estimates inconsistent node expanded paths lower cost As result number nodes expanded exceeded number nodes generated These experiments conﬁrm earlier observation normalizing function Φ identity function performance A tends deteriorate fast N increases We interested ﬁnd happens heuristic estimates purely admissible a1 0 a2 0 We carried experiments heuristic estimates h nodes underestimated overestimated formula h h h uniformly distributed random number open interval 05 05 determined independently node The results obtained summarized follows 192 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Table 2 Performance A linear error inconsistent h No jobs 6 8 10 12 14 16 Nodes generated Nodes expanded Mean Std Dev Mean Std Dev 6122 24924 100167 402992 1615633 6475236 469 2227 9665 40012 162379 652943 6055 31728 160649 790696 3934997 18599106 1831 8712 44389 188663 1028872 4074379 1 Due inadmissibility heuristic estimate number nodes generated expanded reduced typical values averaged 100 runs 16 jobs 36 03407 17 60036 respectively Algorithm A ran faster admissible case 2 The number node expansions increased factor 40 problem size increased 10 12 jobs The factor increased 42 46 number jobs increased 14 16 jobs respectively Thus trend indicates performance A deteriorated faster problem size expected 3 The solutions obtained optimal heuristic estimates inadmissible We restricted experiments smaller problems instance needed ﬁnd h nodes search graph ﬁrst store computing heuristic estimates What happens normalizing function logarithmic Unfortunately speciﬁc said Example 41 Let arcs Gjs unit cost This happen example penalty functions Hi constant value 1 arguments 1 Suppose heuristic estimate function h perfect h h nodes Then Zd linear exponential N depending ties resolved 2 Now consider general case heuristic estimates necessarily perfect Let a1 0 This means probability p 0 hn hn probability p Hence f n N probability p Then search graph Gjs EZd cid2 1 p CN 1 p2 CN 2 pN 1 pN exponential N large N This true normalizing function logarithmic Instead imposing constant upper bound arc costs try ensure majority outgoing arcs nongoal node low cost Deﬁnition 41 Let θ 1 2 N R given increasing total function positive integers domain positive real numbers range θ 1 1 Let C cost function deﬁned arcs Gjs Then Gjs C superregular respect AK Sen et al Artiﬁcial Intelligence 155 2004 183206 193 θ nongoal node n Gjs integer y 0 node n minN cid13θ ycid14 outgoing arcs cost cid1 y level node n Gjs When Gjs C superregular arcs costs said θ relaxed Thus superregular graphs large number outgoing arcs node arc costs lying given upper bound constant upper bound cost arc In case exponential number nodes expanded functions θ Φ positive fractional powers arguments Theorem 42 Let θ y yβ y 0 0 β cid1 1 let Gjs C superregular respect θ θ relaxed If Φx max1 xδ 0 δ cid1 1 a1 0 EZd exponential N large N Proof See Appendix A 42 Polynomial complexity To polynomial bounds number nodes expanded Φx max1 lnx need impose upper bound number arcs emanating node costs lying speciﬁed limit This brings notion subregular graph deﬁnition similar superregular graph instead large number outgoing arcs bounded cost small number arcs Deﬁnition 42 Let θ 1 2 N R given increasing total function positive integers domain positive real numbers range θ 1 1 Let C cost function deﬁned arcs Gjs Then Gjs C subregular respect θ nongoal node n Gjs following conditions satisﬁed 1 For integer y 0 minN cid13θ ycid14 outgoing arcs node n cost cid1 y level node n Gjs 2 Node n outgoing arc unit cost When Gjs C subregular arcs costs said θ restricted An additional assumption arc costs required Consider set SN root Gjs consisting jobs sequenced We view elements SN totally ordered linear ordering For example suppose jobs SN distinct processing times Then jobs viewed ordered increasing order processing times At node n outgoing arcs corresponding jobs processed ordered left right order processing times jobs We impose condition costs outgoing arcs node n increasing left right outgoing arc corresponding job smallest processing time lowest cost 194 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Deﬁnition 43 A graph Gjs C said Cordered jobs distinct processing times ii nongoal node processing time Ai job Ji processing time Ak job Jk cost outgoing arc corresponding job Ji cost outgoing arc corresponding job Jk In 27 graphs Cordered processing times jobs distinct penalty coefﬁcients identical Cordering imposes additional structure graph enables prove following result normalizing function logarithmic Theorem 43 Let θ y yβ y 0 0 β cid1 1 let Gjs C θ restricted Cordered If Φ logarithmic EZt polynomial N large N Proof See Appendix A Our experimental results case given Table 3 Here jobs distinct processing times penalty coefﬁcients identical Moreover node k arcs having arc cost 10 100k2 Thus graphs Cordered θ restricted outgoing arc unit cost nongoal node Heuristic estimates nodes admissible generated formula h h logh deﬁned experiments corresponding Table 2 In set experiments set h h logκh κ large constant forcing logarithmic error larger experiments Table 3 The results obtained similar shown Table 4 κ 1025 When error logarithmic numbers nodes generated expanded reduce dramatically Since error relatively small heuristic estimate node close perfect As result arc costs node distinct penalty coefﬁcients identical A generates expands small number nodes The following theorem speciﬁes sufﬁcient condition ensures θ restricted graphs total number nodes expanded A polynomial N large N The required condition imposes upper bound maximum possible value θ y attain turn restricts number outgoing arcs bounded cost node Table 3 Performance A logarithmic error No Nodes generated Nodes expanded jobs Mean Std Dev 6 8 10 12 14 16 2100 3600 5500 7800 10500 13600 000 000 000 000 000 000 Mean 500 700 900 1100 1300 1500 Std Dev 000 000 000 000 000 000 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 195 Table 4 Performance A logarithmic error κ 1025 No Nodes generated Nodes expanded jobs Mean Std Dev Mean Std Dev 6 8 10 12 14 16 2104 3606 5516 7810 10524 13655 040 060 113 100 169 271 501 702 902 1101 1302 1504 010 020 014 010 014 020 Theorem 44 Let y0 given positive integer independent N Let β 0 integer constant Suppose cid6 θ y yβ yβ 0 y cid1 y0 y y0 Let Gjs C θ restricted Cordered Then regardless Φ linear thanlinear logarithmic EZt polynomial N large N Proof See Appendix A We end section following general result Here unlike previous theorem allow θ y large value arguments cid2 y0 In θ restricted case permits remaining arcs node cost y0 Theorem 45 Let y0 given positive integer independent N Let β 0 constant Suppose cid2 yβ y y0 N y cid2 y0 θ y Then 1 If Gjs C superregular respect θ Φx max1 xδ 0 δ cid1 1 a1 0 EZd exponential N large N 2 If Gjs C subregular respect θ Gjs Cordered Φ logarithmic EZt polynomial N large N Proof See Appendix A 5 Analysis Traveling Salesman Problem TSP We consider expected complexity N city Traveling Salesman Problem TSP assuming TSP solved means A graph search Gtsp Let cost N N matrix positive nonzero integer entries specify cost distance 196 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 travel costI J cost going directly city I city J In symmetric version TSP cost symmetric matrix We costJ J 1 cid1 J cid1 N inﬁnite large positive integer We given cost matrix satisﬁes triangle inequality costI J costJ K cid2 costI K triple I J K 1 cid1 I J K cid1 N This intuitively appealing notion usual distance metric twodimensional Euclidean space satisﬁes triangle inequality 51 Exponential complexity We heuristic admissible normalizing function identity function cost matrix symmetric satisﬁes triangle inequality expected number EZd distinct nodes expanded exponential N large N This general result Theorem 51 Consider symmetric N city Traveling Salesman Problem cost matrix satisﬁes triangle inequality Let Φ identity function suppose a1 0 Then EZd exponential N large N Proof See Appendix A As seen heuristic need admissible weaker condition sufﬁces The theorem generalizes readily normalizing functions lessthanlinear The additional requirement cost best tour large In theorem require cost tour ON condition relaxed For example δ 05 sufﬁces cost best tour lower order N 2 Theorem 52 Consider symmetric N city Traveling Salesman Problem cost matrix satisﬁes triangle inequality condition Let Φx max1 xδ δ 0 δ 1 let a1 0 Then EZd exponential N large N cost minimum cost solution path ON Proof See Appendix A A similar result proved cost matrix asymmetric provided costI J large compared costJ I Theorem 53 Consider N city asymmetric Traveling Salesman Problem cost matrix satisﬁes triangle inequality condition Let Φ identity function let a1 0 Suppose exists constant ε 0 ε 1 costI J cid1 N ε costJ I 1 cid1 I J cid1 N I cid16 J Then EZd exponential N large N AK Sen et al Artiﬁcial Intelligence 155 2004 183206 197 Proof See Appendix A It possible relax constraints The cost matrix need satisfy triangle inequality condition strict way We triangle inequality condition holds αweakly cost matrix satisﬁes following condition real number α 1 cid7 cid8 α costI J costJ K cid2 costI K triples I J K 1 cid1 I J K cid1 N Theorem 51 remains valid triangle inequality condition holds αweakly provided α oN ε ε 1 Similar conditions derived Theorems 52 53 In Traveling Salesman Problem pairs cities connected directly arcs costI J inﬁnite In cases matrix entries fail satisfy triangle inequality condition deﬁned But version Theorem 51 holds provided following technical condition satisﬁed There subsequence cities 1 2 N ε 1 lying minimum cost tour 0 ε 1 cost portion minimum cost tour lying subsequence N ε cost matrix restricted cities subsequence symmetric satisﬁes triangle inequality What said normalizing function Φx logarithmic x Unfortu nately deﬁnite said case following examples The expected number node expansions linear exponential N depending cost matrix Example 51 Suppose costI J 1 I J 1 cid1 I J cid1 N I cid16 J This cost matrix symmetric satisﬁes triangle inequality Let a1 0 suppose heuristic estimates nodes nonzero probability admissible Then nongoal node n f n N probability p 0 EZd EZt cid2 1 p CN 1 1 2 p2 CN 1 2 N 1 pN1 1 p N 1 1 pN2 exponential N large N This holds normalizing function logarithmic When heuristic perfect EZt linear exponential N depending ties resolved However cases polynomial complexity certain restrictive types cost matrix described 52 Polynomial nonexponential complexity We try determine kind restriction placed cost function achieve polynomial complexity error logarithmic Theorem 54 Consider symmetric N city Traveling Salesman Problem having following cost matrix cid2 costI J I J 1 I 1 J N J 1 I N b ln N 198 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 b constants 0 Suppose Φx logarithmic x Then expected number node expansions EZt polynomial N large N Proof See Appendix A The conditions Theorem 54 restrictive When cities I J adjacent city numbering scheme costI J constant cost increases logarithmically N One way relax conditions given case result weaker Theorem 55 Consider symmetric N city Traveling Salesman Problem having following cost matrix cid2 costI J I J 1 I 1 J N J 1 I N b b constants b 0 Suppose Φx logarithmic x Then expected number node expansions EZt exponential N large N Proof See Appendix A A similar result obtained costI J varies I J rate linear Theorem 56 Let Ψ z b zr 0 b 0 r cid1 1 Consider symmetric N city Traveling Salesman Problem city I 1 cid1 I cid1 N costI J Ψ K 1 J I 1 K mod N 1 K positive integer Suppose Φ logarithmic x Then total number node expansions EZt exponential N large N Proof See Appendix A The results section expected complexity A algorithm TSP polynomial exponential number cities depending cost function accuracy heuristic function Since A graphs viewed special type bestﬁrst branchandbound algorithm results shed light expected complexity bestﬁrst branchandbound algorithms TSP 6 Conclusion This paper presented general technique extending analysis average case performance A search spaces trees search spaces directed acyclic graphs The topic importance practical problems solved efﬁciently search spaces graphs trees We derived expressions expected number nodes generated A expected number node expansions A run general types directed AK Sen et al Artiﬁcial Intelligence 155 2004 183206 199 acyclic graphs Such search graphs typical arise certain types machine job sequencing problems Similar graphs arise solution procedures Traveling Salesman Problem TSP Our analytical results expected complexity problems domains change exponential polynomial heuristic estimates nodes accurate restrictions placed cost matrix We provided supporting experimental evidence onemachine job sequencing problem We expect analytical approach proposed generalized extended number directions One possible way making use incremental random tree model described 14202131 Experimentally try compare expected number nodes generated andor expanded graph search tree search different types problems This tell saving realized computational cost practice use search space directed acyclic graph help choose graph tree search spaces implementing search algorithms different application domains Acknowledgements Anup K Sen funded CMDS grant AIT2117 Indian Institute Management Calcutta W Zhang funded NSF grants IIS0196057 ITREIA0113618 DARPA Cooperative Agreements F306020020531 F3361501C1897 Thanks anonymous reviewers constructive comments Appendix A Proofs Theorem 41 Suppose 1 cid1 cid1 N Hix oxβ β positive integer constant 1 cid1 Ai cid1 k constant k 1 If Φ identity function a1 0 EZd expected number distinct nodes Gjs expanded exponential N large N Proof The basic idea initial segment minimal cost solution path Gjs consider set S jobs processed segment Each subset S corresponds node Gjs The length segment chosen number elements S fractional power N number subsets S exponential N We node gets expanded nonzero probability deduce expected number nodes expanded exponential N We renumber jobs needed assume minimal cost solution path G cost M cid2 N root goal jobs scheduled set 1 2 N sequence 1 2 N Choose 0 δ 1β 1 consider nongoal nodes Gjs missing jobs corresponding jobs completed belong set 1 2 V V N δ There 2V 1 nodes excluding root node n gn V V kβ hn M V V kβ 200 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Let ncid9 node missing elements exactly 1 2 V Since ncid9 lies minimum cost solution path hncid9 M Moreover cost path ncid9 predecessor n ncid9 exceed V V kβ It follows M V V kβ hn M V V kβ Let acid9 a12 0 p Fχ acid9 0 Then hn cid1 hn acid9 Φhn probability p f n M probability p provided gn hn M acid9 Φhn As acid9 0 Φ identity function sufﬁces M 2 V V kβ M acid9 M acid9 V V kβ holds large N V β1 smaller order N M The conditions true ncid9 ancestor ncid9 Thus node n level gets expanded probability pi Therefore EZd cid2 1 p V p2 CV 2 pV 1 pV exponential N large N Theorem 42 Let θ y yβ y 0 0 β cid1 1 let Gjs C super regular respect θ If Φx max1 xδ 0 δ cid1 1 a1 0 EZd exponential N large N Proof Here use fact superregular graph outgoing arcs node arc costs lying given bound Since θ 1 1 Gjs C superregular follows nongoal node Gjs outgoing arc unit cost So minimal cost solution path Gjs cost N Let n node level Then hn N Let a1 acid9 0 p Fχ acid9 0 Then f n N probability p gn hn N acid9 Φhn gn acid9 N iδ Let conﬁne attention outgoing arcs having costs cid2 1 k 1 acid9 N iδ 1i All paths root node n composed arcs gn values speciﬁed limit Let P path let m predecessor n level icid9 Then gm icid9 icid9 acid9 N iδi cid1 icid9 acid9 N icid9δ gm satisﬁes similar condition Thus node n expanded probability cid2 pi We choose N ρ 0 ρ δ ββ 1 Since paths root node level cid13θ kiicid14 nodes gvalue cid1 N ρ acid9 N iδ level Hence EZd cid2 j 0 pj cid13θ kj j cid14 But righthand sum smaller expN ρ exponential N large N Theorem 43 Let θ y yβ y 0 0 β cid1 1 let Gjs C θ restricted Cordered If Φ logarithmic EZt polynomial N large N Proof We ﬁrst ﬁnd total number nodes n gn hn cid1 f r a2 lnf r include nodes possibly expanded But case hn cid2 hn a1 lnhn Suppose node n level Then nongoal node outgoing arc unit cost f r N hn N So condition gn k0 lnk N k k0 positive constants Since Gjs θ restricted outgoing arcs node costs bounded 1 cid1321βcid14 cid1331βcid14 β cid1 1 1β cid2 1 implying cid1321βcid14 cid2 2 cid1331βcid14 cid2 3 In computing upper bounds number expanded nodes lower bounds viewed exact costs outgoing arcs We ﬁnd nodes level gvalues summing cid1 k0 lnk N AK Sen et al Artiﬁcial Intelligence 155 2004 183206 201 Since Gjs Cordered consider subset jobs processed node n level Let J1 J2 Ji jobs subset SN missing node n Suppose J1 J2 Ji There ways scheduling jobs leading paths node n root The scheduling jobs sequence J1 J2 Ji determine path cost root node n Moreover completion times jobs increasing order Gjs Cordered arc costs path form increasing ordered sequence integers jobs processed increasing order job number penalty function nondecreasing argument The ordered sequences arc costs corresponding minimal cost paths different nodes level identical Thus need count number increasing integer sequences length sum k0 lnk N To upper bound number sequences help HardyRamanujan asymptotic formula 1 pp 70 97 number unrestricted partitions integer q form Aq expB q 12 A B constants The number partitions obtained polynomial N We need determine total number partitions integers cid1 q number polynomial N As explained conﬁned partitions 1 parts parts increasing order values This shows polynomial number nodes expanded level 1 cid1 cid1 N Although node n expanded multiple times gn integer N a2 ln N distinct values node gets expanded N a2 ln N times It follows EZt polynomial N large N Theorem 44 Let y0 given positive integer independent N Let β 0 integer constant Suppose θ y cid6 yβ yβ 0 y cid1 y0 y y0 Let Gjs C θ restricted Cordered Then regardless Φ linear thanlinear logarithmic EZt polynomial N large N Proof Let k0 yβ 0 Then k0 constant Every node level 1 cid1 cid1 N mink0 N outgoing arcs arc costs cid1 y y cid2 y0 leftmost arcs node Other outgoing arcs viewed having inﬁnite cost Because Cordering jobs processed moving level 0 level 1 job numbers cid1 k0 jobs processed moving level 1 level 2 job numbers cid1 k0 1 Thus number nodes level ﬁnite gvalue cid1 Ck0 1 So total number nodes graph ﬁnite gvalue cid1 N i1 Ck0 1 1 cid1 Ck0 N N polynomial N large N A node n expanded gn cid1 f r 1 a2 N 1 a2 As Theorem 43 gn integer N 1 a2 distinct values node gets expanded N 1 a2 times It follows EZt polynomial N 202 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Theorem 45 Let y0 given positive integer independent N Let β 0 constant Suppose cid2 yβ y y0 N y cid2 y0 θ y Then 1 If Gjs C superregular respect θ Φx max1 xδ 0 δ cid1 1 a1 0 EZd exponential N large N 2 If Gjs C subregular respect θ Gjs Cordered Φ logarithmic EZt polynomial N large N Proof 1 Follows proof Theorem 42 nongoal node graph outgoing arcs cost cid1 y0 2 Here graph θ restricted nongoal node level minN θ y arcs cost cid1 y y y0 N arcs cost cid1 y y cid2 y0 Since graph Cordered costs outgoing arcs integers increasing order values left right nongoal node y outgoing arcs cost cid1 y Thus y cid2 y0 Gjs C θ restricted θ y y It sense β 1 case We relax given conditions assume θ y y y increase expected number nodes expanded We β 1 proof Theorem 43 applies Theorem 51 Consider symmetric N city Traveling Salesman Problem cost matrix satisﬁes triangle inequality Let Φ identity function suppose a1 0 Then EZd exponential N large N Proof Let M cost minimum cost tour Without loss generality renumber cities necessary 1 2 N 1 minimum cost tour subsequence cities 1 2 N β N β 1 β 0 β 1 cost portion tour city 1 city N β 1 cid1 N β MN Let k cid2 2 integer consider level N β k Gtsp Let S set nodes level current city N β 1 visited cities belonging set 1 2 N β Then node n S corresponds situation apart city 1 N β k 1 cities visited cities numbered 2 N β The number nodes S CN β 1 N β k 1 exponential N large N Since 0 a1 cid2 1 acid9 a12 0 Then acid9 a1 p Fχ acid9 0 We node n S enter OPEN satisfy gn hn M probability pi We similar condition hold predecessor n Since minimum cost tour cost M implies node n S expanded probability pi For node n S hn cid1 cost traveling city N β 1 unvisited city lowest number cost visiting unvisited cities numbers set 2 3 N β increasing order city number cost visiting remaining cities tour returning city 1 Since cost matrix AK Sen et al Artiﬁcial Intelligence 155 2004 183206 203 symmetric satisﬁes triangle inequality ﬁrst second terms cid1 N β MN term M hn M 2 N β MN But g n cid1 N β MN triangle inequality Hence gn hn M 1 3 N β N On hand h n cid2 M g n cid2 M1 N β N Thus gn hn cid1 gn hn acid9 hn probability p M acid9 M 3 acid9 M N β N probability p acid9 0 M probability p term ignored low order compared acid9 M For predecessor ncid9 n level smaller Gtsp hn bounds arguments remain valid current city instead N β 1 city 2 3 N β The bound remains gncid9 gncid9 hncid9 M probability p We conclude node S level gets expanded probability pi expected number distinct nodes expanded level pi CN β 1 N β k 1 given value easily shown help Stirlings approximation exponential N large N k chosen greater 1p Theorem 52 Consider symmetric N city Traveling Salesman Problem cost matrix satisﬁes triangle inequality condition Let Φx max1 xδ δ 0 δ 1 let a1 0 Then EZd exponential N large N cost minimum cost solution path ON Proof Similar proof Theorem 51 Here g n hn M 3 M N β N cid9 M δ 1 N β Nδ probability p M ON The parameter β chosen small like particular smaller δ given condition M second term ignored respect term giving gn M Indeed weaker condition M sufﬁces shown theorem holds M oN ε ε 1 β1 δ 204 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 Theorem 53 Consider N city asymmetric Traveling Salesman Problem cost matrix satisﬁes triangle inequality condition Let Φ identity function let a1 0 Suppose exists constant ε 0 ε 1 costI J cid1 N ε costJ I 1 cid1 I J cid1 N I cid16 J Then EZd exponential N large N Proof Similar proof Theorem 51 Here h n M 1 N β N N βεN inequalities remaining probability p g n hn M 1 2 N β N N βεN The theorem holds provided choose β β ε 1 cid9 M 1 N β N Theorem 54 Consider symmetric N city Traveling Salesman Problem having following cost matrix cid6 I J 1 I 1 J N J 1 I N costI J b ln N b constants 0 Suppose Φx logarithmic x Then expected number node expansions EZt polynomial N large N Proof Here cost matrix symmetric triangle inequality condition satisﬁed We ﬁrst ﬁnd upper bound expected number EZd distinct node expansions The cost going city city numbering scheme constant f r N A node n level expanded gn hn cid1 N a2 lna N gn hn cid1 N a2 lna N a1 lnhn Since hn cid2 N required condition node expansion written gn acid9 ln N bcid9 acid9 bcid9 constants To ﬁnd upper bound EZd count nodes n level having gn acid9 ln N bcid9 Consider path starting root nodes expanded examine order cities visited reached There exist positive constant q independent successive cities numbers adjacent city numbering scheme maximum q positions required condition gvalue satisﬁed Whenever successive cities adjacent N possible choices city Therefore total number distinct paths root nodes level node expansions q j 0 N j Ci j q 1 N q Ci q large total number possible i0 Ci q q 1N q1 CN q N expansions nodes graph q 1N q This polynomial N q constant cid1 cid1 Theorem 55 Consider symmetric N city Traveling Salesman Problem having following cost matrix cid6 costI J I J 1 I 1 J N J 1 I N b AK Sen et al Artiﬁcial Intelligence 155 2004 183206 205 b constants b 0 Suppose Φx logarithmic x Then expected number node expansions EZt exponential N large N Proof We proceed proof Theorem 54 Here cost matrix symmetric satisﬁes triangle inequality condition For expanded node n level upper bound gn Theorem 54 As consider path starting root nodes expanded examine order cities visited reached This time Oln N positions successive cities adjacent city numbering scheme Thus expected number EZt node expansions bounded expression form N ln N1 CN ln N This bound polynomial N exponential N Theorem 56 Let Ψ z b zr 0 b 0 r cid1 1 Consider symmetric N city Traveling Salesman Problem city I 1 cid1 I cid1 N costI J Ψ K 1 J I 1 K mod N 1 K positive integer Suppose Φ logarithmic x Then total number node expansions EZt exponential N large N Proof We proceed proof Theorem 54 Here cost matrix symmetric satisﬁes triangle inequality condition For expanded node n level upper bound gn Theorem 54 This time expanded node examine set visited cities current city added exist positive global constant w set cities arranged increasing order city number w places gap successive cities proportional ln N But addition exist positive global constant u Oln N places gap successive cities 1 cid1 u The gap successive cities value constant ln N long sum gaps Oln N Thus upper bound number tours nodes expanded suppose Oln N gaps Oln N different values Thus EZt bounded expression form N ln Nln N CN ln N This bound polynomial N exponential N References 1 GE Andrews The Theory Partitions GG Rota Ed Encyclopedia Mathematics Its Applications vol 2 AddisonWesley Reading MA 1976 2 A Bagchi AK Sen Average case analysis heuristic search treelike networks Search Artiﬁcial Intelligence SpringerVerlag BerlinNew York 1988 pp 131165 3 E Balas P Toth Branch bound methods The Traveling Salesman Problem Wiley Essex UK 1985 pp 361401 4 M Bellmore JC Malone Pathology travelingsalesman subtourelimination algorithms Operations Research 19 1971 278307 5 H Carrillo D Lipman The multiple sequence alignment problem biology SIAM J Appl Math 48 1988 10731082 6 SV Chenoweth HW Davis High performance A 91 Sydney Australia 1991 pp 198203 search rapidly growing heuristics Proc IJCAI 206 AK Sen et al Artiﬁcial Intelligence 155 2004 183206 7 HW Davis Cost error relationships A tree searching J ACM 37 1990 195199 8 R Dechter J Pearl Generalized bestﬁrst search strategies optimality A J ACM 32 1985 505536 9 G Gutin AP Punnen Eds The Traveling Salesman Problem Its Variations Kluwer Academic DordrechtNorwell MA 2002 10 M Held RM Karp The traveling salesman problem minimum spanning trees Part II Mathematical Programming 1 1971 625 11 N Huyn R Dechter J Pearl Probabilistic analysis complexity A Artiﬁcial Intelligence 15 1980 241254 12 T Ikeda H Imai Enhanced A algorithms multiple alignments Optimal alignments sequences kopt approximate alignments large cases Theoretical Computer Science 210 1999 341374 13 H Kaindl G Kainz A Leeb H Smetana How use limited memory heuristic search Proc IJCAI 95 Montreal Quebec 1995 pp 236242 14 RM Karp J Pearl Searching optimal path tree random costs Artiﬁcial Intelligence 21 1983 99117 15 RM Karp JM Steele Probabilistic analysis heuristics The Traveling Salesman Problem Wiley Essex UK 1985 pp 181205 16 RE Korf M Reid S Edelkamp Time complexity iterativedeepeningA Artiﬁcial Intelligence 129 2001 199218 17 RE Korf W Zhang Divideandconquer frontier search applied optimal sequence alignment Proc AAAI00 Austin TX 2000 pp 910916 18 EL Lawler JK Lenstra AHG Rinnooy Kan DB Shmoys Eds The Traveling Salesman Problem Wiley Essex UK 1985 19 JK Lenstra AHG Rinnooy Kan On expected performance branchandbound algorithms Operations Research 26 1978 347349 20 CJH McDiarmid Probabilistic analysis tree search GR Gummett DJA Welsh Eds Disorder Physical Systems Oxford Science 1990 pp 249260 21 CJH McDiarmid GMA Provan An expectedcost analysis backtracking nonbacktracking algorithms Proc IJCAI91 Sydney Australia 1991 pp 172177 22 J Pearl Heuristics Intelligent Search Strategies Computer Problem Solving AddisonWesley Reading MA 1984 23 M Pinedo Scheduling Theory Algorithms Systems Prentice Hall New York 1995 24 A Reinefeld TA Marsland Enhanced iterative deepening search IEEE Trans Pattern Analysis Machine Intelligence 16 1994 701710 25 T Sandholm Algorithm optimal winner determination combinatorial auctions Artiﬁcial Intelli gence 135 2002 154 26 AK Sen A Bagchi Graph search methods nonorderpreserving evaluation functions Applications job sequencing problems Artiﬁcial Intelligence 86 1996 4373 27 AK Sen A Bagchi R Ramaswamy Searching graphs A Trans Syst Man Cybern A 26 1996 168173 Applications job sequencing IEEE 28 AK Sen A Bagchi W Zhang An averagecase analysis graph search Proc AAAI02 Edmonton Alberta 2002 pp 757762 29 W Townsend The single machine problem quadratic penalty function completion times A branch bound solution Management Science 24 1978 530534 30 W Zhang Depthﬁrst branchandbound versus local search A case study Proc AAAI00 Austin TX 2000 pp 930936 31 W Zhang RE Korf Performance linearspace search algorithms Artiﬁcial Intelligence 79 1995 241 292