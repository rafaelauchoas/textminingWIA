Artificial Intelligence 94 1997 756 Artificial Intelligence The independent choice logic modelling multiple agents uncertainty David Poole Department Computer Science University British Columbia 2366 Main Mall Vancouver BC Canada V6T I24 Abstract Inspired game theory representations Bayesian networks influence diagrams structured Markov decision process models logic programming work dynamical systems inde pendent choice logic ICL semantic framework allows independent choices agents including nature logic program gives consequence choices This representation specification agents act world observa tions world memory modelling tool dynamic environments uncertainty The rules specify consequences action sensed utility outcomes This paper presents possibleworlds semantics ICL shows embed fluence diagrams structured Markov decision processes strategic normal form extensive gametree form games ICL It argued ICL provides natural concise representation multiagent decisionmaking uncertainty allows representation structured probability tables dynamic construction networks use logical variables way handle uncertainty decisions logical representation 1997 Elsevier Science BV 1 Introduction This paper presents Independent Choice Logic ICL agents uncertainty 7351 representations multiple networks tured agent madelling dynamical change influence diagrams Bayesian 274550 It inspired game theory logic modelling 173253 Bayesian networks 22231 probabilistic Horn abduction 361 struc 578 29485 1571 logical modelling action Markov decision processes systems Email poolecsubcca 00043702971700 1997 Elsevier Science BV All rights reserved PZI s0004370297000271 8 D PooleArtijcial Intelligence 94 1997 756 First motivate ICL number different perspectives Section knowledge 13 representation paradigms foundations fits subsections present theory Section build paper presents examples use logic including diagrams Markov decision processes represented diagrams representation influence formal definition Section ICL based agents 14 logic strategic extensive In separate 12 game 15 We Section Section 2 The majority 11 Section showing influence forms games tests rulebased framework parents represented probabilities representation exponentially independence variables given conditional probability network The conditional tables specified compactly rule representation agents knowledge base expressed compactly 351 provide useful representation representation reasoning Bayesian belief networks uncertainty Bayesian networks random variables The Bayesian network model constrain variable depends variable parents specify representation given parents typically trees terms trees 71 rules 361 Rules compact trees sense shared structure redundant functions larger tree representation converse hold Rules added advantage extension 361 firstorder failure fewer restriction rules paper extends probabilistic multiple rules agents policies expressed rules primary natural firstorder case 361 This paper builds probabilistic Horn abduction Bayesian networks allowing negation probabilistic Horn abduction This decisions include utilities AI This specify It want argued scheme rich firstorder predicate calculus One problems order predicate calculus blunt reasoning uncertainty Rather calculus theory uncertainty In ICL start logic instead disjunction include uncertainty theory entails exactly p propositions p Agents alternatives sets owns propositions An agent gets choose value alternative Nature special agent alternatives owned nature probability distribution The logic gives firstorder predicate probabilistic computed representation representation way 42 entail having disjunctive choices nature definitive propositions way handles uncertainty use probability justice 33 general adding uncertainty subtleties handle uncertainty This involved focus knowledge paper proposes Logic available consequences meaning disjunction decision independently 3192024 compute symbols provides instrument way As allow negation failure roles rules seen DNF definition concept Clarks completion converted leaf decision 111 It known DNF formulae decision trees 461 Decision tree body corresponds trees converted path leaf entail exponential blow size mles role simply D PooleArtificial Intelligence 94 1997 756 9 agents This allows advantages logic symbols denotations specifications lets use normative agent valid consequences tools decisiongame theory notions firstorder representations given determine systems 29441 referring functions state state space terms Bayesian Models dynamical 121 concisely terms matrices terms propositions terms propositions The state transition networks described traditionally treating state spaces terms vectors states It convenient transition function stated 81 loga local size state space The effects actions typically poten variables This provides propositional In terms rules One advantage rules cal dynamic program terms state spaces example state transition function cisely rules 11401 rithmic value variable depending tial ICL specify state closer 3 1 culus stage situation helps clarify ming advantage compactness functions transition traditional AI representations 401 The firstorder nature rules explicit rules perspicuous The rule based representation state The number variables situation close relationship regression planning explicit representation reference trees 11 Knowledge representation representation There axe different views knowledge l The knowledge representation let users state knowl view appropriate specify piece knowl follows facts common sense manner An example conclude logically represen let state facts world logics knowledge tradition representation edge reasonably natural way Under designer knowledge edge encoded Reasoning stated facts missing view use firstorder predicate calculus tation It rich primitive means developed 21 4 Missing maximum user add able appropriate l The second view knowledge entropy random worlds assumptions handle uncertainty Within handle uncertainty facts inferred default reasoning 41 What inferences language like knowledge base representation multiple agents making decisions 31519 301 making important language representation symlbolic modelling view knowledge guide users choices specified An example tool representing specify random variables independence representation makes things easier provide highlevel It think domain specify model domain prescribes information state Under needs Bayesian networks 351 provide modelling random variables The user needs variables values 10 D PooleArtificial Intelligence 94 1997 756 dependency variables Once specified Bayesian network model prescribes probabilities need specified It important confuse judging knowledge representation inappropriate criteria lead unfair judgment The knowledge representation paper seen instance second We expect people able throw knowledge For example missing rules particular meaning want assert ignorance specific ways 12 Agents An agent acts world An agent example person robot worm wind gravity lamp Purposive agents act order prefer states world statesand preferencesthey try achieve worlds prefer The nonpurposive agents grouped called nature Whether agent purposive modelling assumption appropriate For example applications appropriate model dog purposive suffice model dog nonpurposive Agents sensors possibly limited memory computational capabilities effecters Agents reason act time An agent react world condition actions received sensors These sensors reflect true world2 sensors noisy unreliable broken sensors reliable ambiguity world sensors readings An agent condition actions knows weak sensor appears outputting value u Similarly actuators noisy unreliable slow broken What agent control message command sends actuators An agent seen implementation transduction 39474857 function input sensor readings history outputs action attempts actuator settings time point These causal sense output depend current inputs previous inputs outputs conditional future inputs outputs A policy strategy specification agent contin gencies That representation transduction A plan policy includes time stage contingencies conditioned Our aim provide representation define perception actions preferences agents This define policy notion agents preferences policy better according appropriate notion optimal policy agent Once defined optimal policy use exact approximation algorithms build policies agents Of course correlation sensor reading tells true world preferences agent depend true world usually ignore sensor D PooleArticial Intelligence 94 1997 756 11 We want model agents environments language The lan guage provide decision theoretic game theoretic agent framework build agents shown optimal 481 specification expected utility agent A planner framework program generates possibly stochastic transduction agent execute The output planner suitable actually controlling agent It sequence steps output traditional planners Here consider reactive agents internal state This paper consider problem building planner Even singleagent propositional case problem finding optimal policy computationally prohibitive 25 property problem representation By having rich representation discuss complexity restrictions build approximation algorithms Under view beliefs desires intentions commitments 51 essential agenthood It case agents beliefs desires intentions commitments example communicate way speech acts 5 11 perform better measure We want define agenthood exclude possibility formulating testing empirical claim In paper provide representation model world agents including available sensors actuators goals terms agents utilities different situations allow design optimal approximately optimal agents 13 Game theory Game theory 173253 theory multiagent reasoning uncertainty The general idea set players agents moves actions based observe The agents try maximize utility Game theory designed general theory economic behaviour 53 generalization decision theory The use term game richer typically studied AI text books parlour games chess These described deterministic chance moves nature perfect information plalyer knows previous moves players zerosum player win making player lose twoperson games Each assumptions lifted 531 A game sequence moves taken sequentially concurrently finite set agents Nature usually treated special agent There main essentially equivalent power 171 representations games extensive form normalized 531 strategic 17321 form game The extensive form game specified terms tree node belongs agent arcs node correspond possible moves actions agent A branch root leaf corresponds possible play game Information availability represented terms information sets sets nodes agent distinguish The aim agent choose information sets 12 D PooleArtificial Intelligence 94 1997 756 kicker left right goalie left 09Ol 0208 right 0 I 09 09Ol Fig 1 Expected payoff matrix game Example 1 Payoff 1 2 indicates kicker expected payoff UI goal worth block worth zero kicker goalie expected payoff u2 goal worth zero block worth goalie In strategic form game player adopts strategy strategy specifies choices plan 53 p 791 This represented agent possible situation agents information available function The initial framework developed seen representation form game possible world corresponding normalized game In ICL add logic program This allows use logical representation presents representation closer extensive form game based complete play play world agents Section 55 consequences Where ized strategy probability In cases distribution agents competing interests best strategy agent decides randomly random choose actions based problem prevent designing example jumping soccer playing robots soccer games Suppose left kicker kicks goal The goalie commit tied end regulation In particular decide agents kicker trying problem penalty kick Penalty kicks Example 1 Consider want consider winner kick trying know let know direction goalie jumps goal Similarly kicker kicks left goalie jumps kicker kicks right goalie jumps happen goalie The goalie reason right For kicker think kick left This ending game theory choice Similarly example goalie time In penalty score goal goalie left right kicker kick right left course want left 90 chance right 90 chance goal If right 10 chance goal If left 20 chance goal example jump kick right The goalie left In case kicker regress Such problems studied randomize goalie choice In 815 best realizing kicker kick right I jump right handed See Fig 1 payoff matrix 531 It turns best strategy sense deviate I better I jump kick right probability best kicker right probability right I best strategy randomize kicker jump 715 D PooleArtificial Intelligence 94 1997 756 13 randomized strategy exploit deviation higher chance scoring goal stopping goal Example 22 derivation numbers 14 Injutrnce diagrams Influence diagrams 1231 papers 341 graphical representation decision problems extend Bayesian networks include decision nodes value nodes Infuence diagrams provide perspicuous representation decision problems making explicit probabilistic dependencies information available decision 22 The propositional version logic presented seen representation influence diagrams Section 31 use rules specify conditional probabilities 361 rules specify utility policies agents specified logic programs imply agent based observations The ICL allows specification influence diagram logic lets axiomatise dynamics world derive implicit information explicit knowledge formal natural semantics The independent choice logic ICL preserves reprentation clarity influence diagrams extends ways The advance representation structured probability tables The use rules allows compact representation probability tables similar use decision trees specifying probability utility tables 552 For example variable d depend variables b c depend b value c value This asymmetric dependency easily expressed rules forming compact representation traditional tables The rule structure exploited efficiency 53841 The rulebased representation express policies The use logical variables allows form firstorder influence diagrams These form method dynamic construction influence diagrams 9361 The use rule base means specify step variable depends parents use arbitrary computation For example axiomatise dynamics domain use iomatisation specify position time depends position previous time compact way This features exploited examples The ICL handle multiple agents making decisions permitting form multipleagent influence diagrams We importing representational advantages influence diagrams gametheory representations Note extending representation logical variables multiple agents increases worst case computational complexity deriving optimal plans3 problems represented complex It problem representation se 3 The use variables makes undecidable variables multiagent reasoning exponentially harder modelling singte noforgetting agent 1251 14 D PooleArticial Intelligence 94 1997 756 15 Logic Our aim define logic uncertainty resolved decisiongame theory uncertainty uncertainty probability disjunction encode uncertainty We start logic definitive value proposition We chosen agents alternatives modelled distribution The logic tells consequences choices We treating logic modelling object 561 logic metalevel describing 281 constraint nets representation structure world causal structure agents terms propositions 4 language world Rather level logic represent language having GOLOG object level There causal defined apart logic We use logic axiomatise disjunction use probability Rather want normative uncertainty decision game theory arguments handle uncertainty decision handle use probability theory reasoning 491 The aim logic predicate calculus uncertainty There utilities handle uncertainty 274550 Starting logic uncertainty potentially situation calculus actions lets sidestep traditional prob frame 311 solved case complete knowledge nonde 6 This lems adopt simple solutions For example problem deterministic terministic paper takes different view proposals resolve nondeterminism uncertainty gets resolve uncertainty We consider actions deterministic probabilities variables chosen different agents This powerful arguably natural way model nondeterministic incomplete knowledge problems Section 54 401 hidden variables resolved considering actions action 2 Independent choice logic In section formalize independent abstract definition independent logic In order programs stable model semantics base logic paper examples concrete adopt acyclic choice choice logic constructed logic We general base logic An independent tion We assume construction choosing propositions determine choice logic ICL given base logic conforms logic built specific semantic construc restrictions The specifies build possible worlds Possible worlds built choice alternatives The base logic sets independent truth possible worlds 4 All logical statements paper arc object level domain axiomatised axioms formalism This order reduce confusion need statements problems quoting language All melevel languages different given English normal mathematical notation D PooleArtcial Intelligence 94 1997 756 15 The base logic defined languages language CF facts language relation k elements Z elements infix notation We languages share atomic definition semantic construction discuss properties relation LF x LQ It usually written languages 13 LQ logical k LQ qtreries consequence CQ That assume formulae After want CF LQ Definition 2 A base logic triple b consequence relation LF k CQ LF LQ languages Definition 3 An independent choice logic theory base LF b CQ pair C F l C called choice space set sets ground atomic formulae language LF x1 E C x2 E C x1 x2 x1 n x2 An element called atomic choice C called alternative An element alternative l 3 called facts rule base set formulae logic CF The base logic omitted understood context The semantics ICL defined world selection element consequence world relation terms possible worlds There possible alternative The atoms follow atoms 3 true possible Definition 4 Given mapping 7 written Rr called total choice independent choice logic theory C F selector function r C IJ C rx E x x E C The range selector function function 1 x E C The range selector set rx The basic semantic construction want ICL selector function possible world element range selector IS true The facts 3 specify true possible world corresponds function First define restrictions base logic ensure semantic construction gives defined semantics Definition 5 Base logic selector function 7 LF k CQ ICL theory C F dejkitive l la negation language CQ 5 ground atom CQ FURT 3 U RT k FUR 7 b case FURr b f TZ l o atomic choice 3 U RT j Y cr E Rr 5 If LQ contain negation property need set atomic formulae example FUR T completely determines formulae follow FURT F U RT b V b FURT n F U RT b b follow This means 16 D PooleArtificial Intelligence 94 1997 756 Definition 6 Suppose given definitive base logic C 3 For selector language Co w possible world write w kc3 function k Co ICL theory f read f true world r possible world w If f formula w based CF omitted subscript k iff F U Rr b f When understood context C J The fact proposition true false possible world follows definitiveness base logic Note alternative x E C world w7 exactly w LY E true w In particular w b element x rx x rx 21 The languages LF LQ Languages LF LQ logical languages share propositions The want impose restrictions reason appropriate different task For rest paper assume corresponding logic atoms set ground atoms CF In paper LQ propositional relating variables LQ We allow arbitrary logical connectives disjunction use independent negation choice LQ framework property choose logic gives language LF plus consequence unique model total choice This means relation k things propositions ignore issues conjunction If want l Each selection element logic allow selection choices restrictions logic integrity constraints choices alternative impose alternatives This example disallows arbitrary predicate calculus Horn clauses consistent This means alternatives 271 l Each total choice extended excludes having explicit disjunctions example tics cluding tion extending semantics valued models logic programs possible world This seman stable model7 We ex stable model It means logic6 logic programs 43 consideration way useful open ques 6 Disjunction seen form uncertainty choice space uncertainty relegated choices This contrasted approaches end simpler alternatives Whether currently study The program good computationally 1 stable models language handle uncertainty considering different agents getting logic leaving In sense pursuing idea 31 allow sorts uncertainty We choose idea empirical question consequences ergonomically lb b ya stable models true b true The program D PooleArtificial Inrelligence 94 1997 756 17 22 Acyclic logic programs In order use ICL commit language 13 consist logic programs unique stable model truth stable model consequence q true unique stable model P One way ensure model base logic In paper consider 181 181 That logic program P t q unique stable acyclic programs restrict relation 2 In section language semantics acyclic logic programs The language follows Prologs conventions Definition 7 A variable upper case letter alphanumeric string possibly including _ starting A constant function symbol predicate symbol letter starting uppercase alphanumeric string A term variable constant form f tl t f function symbol tl t terms An atom predicate symbol form p tl t p predicate symbol tl tm terms A literal atom form lcr atom conjunction A body literal conjunction bodies PI written PI A A cZause atom form Y p LY atom called head clause p body The form called rule A program A groltnd set clauses term atom clause instance clause c clause obtained uniformly variables c contain variables A ground terms replacing ground Definition 8 The Herbrand base program P set ground atoms formed function constant P contain constants symbols constants predicates instances new P inventing integer Definition 9 2 A logic program P acyclic positive ground instances clauses atom head rule greater appears element Herbrand base P P set atom rule P number assigned number assigned assignment body P Acyclic programs surprisingly It means recursive definitions general 21 Note acyclicity preclude definitions founded Definition 10 An interpretation Herbrand base Interpretation M ground atom h h true M assignment true false member stable model 181 logic program P h P rule h b 18 D PdeArtijicial Intelligence 94 1997 756 P b true M Conjunction M A negation Ta true M true M A b true M b true Note negation socalled negationasfailure 111 We use negationasfailure necessarily knowledge 371 hold base standard procedural intuition Theorem 11 21 An acyclic logic program unique stable model Acyclicity agent Section 55 important condition physical realization game theory strategies going depends value In sense possible world w stable model 3 U RT assign exactly truth values propositions Example 12 Suppose ICL theory C ui 2 Q bl bz 3 c al A bl c a3 A b2 d al d la2 A bl e c e Td There 6 truth assignments possible worlds following WI bl ai t al wuzb Wa3b t Tal Wbz I al la2 Ta3 bl Tb c d Ta3 61 Tb2 TC d e e la2 a3 bl Tb2 c d Te a2 la3 lb b2 lc d Te Wazrbz I la1 Wasbz I la1 Ta2 ag a2 Tas Tbl b2 c d lb b c Td e e c d e The atomic choices Note sorts atoms atomic choices atoms function selector derived atoms bl b2 derived alaza3 true world given selector range worlds truth defined rules range selector function The function world function world selector subscripted 23 The multiagent independent choice logic The independent model multiagent different agents choice logic ICL specifies way build possible worlds In order In particular need situations need structure able control different choices Definition 13 A multiagent controller PO independent choice logic theory tuple C3 A l C choice space Definition 3 3 facts acyclic logic program atomic choice unifies head rule A finite set agents There distinguished agent 0 called nature D PooleArtiial Intelligence 94 1997 756 19 C A If controller set alternatives agent said controlled Note C UaEA C suchthatVxECoPoal Thatisfor controlled nature Pa probability measure atomic function controller control alternative x If E A agent C x EC 1 controllerx Pa function UC0 Ol alternative choices Often theory simply independent alternative context clear refer choice logic theory multiagent independent choice logic The idea agent gets choose element controlled nature probability distribution alternatives controls The facts consequences The alternatives choices agents 231 Rules utility Game theory decision theory based notion utility cardinal value worth agent outcome possible world9 Higher utilities utility Finding optimal agents competing objectives representing reflect preferred worlds Agents act increase strategies idea agent multiple maximise trickier trying expected utility remains function agent world Different different utilities possible worlds Note nature agents different agent 0 Utility preferences utility The logic program rules utiZity u utiZity u true possible world u utility agent 0 world Definition 14 ICL theory l utility consistent C 3 A controller PO agent E A 0 possible world w w I utiZitya 1 A utilitya 242 implies ui 2 The theory utility consistent utility consistent agent 0 agents l utility complete agent E A 0 possible world w utility complete unique number u w k utiZity u The theory utility complete agent 0 agents Thus ICL theory utility consistent function possible world complete means utility relation We assume theories utility consistent complete 8 When x discrete need use integration paper sets discrete finite summation To avoid measurability framework integrability necessarily issues assume restricted g The existence utility case function intuitive axioms rational preferences Like decision game represent use derive optimal actions utilities acquired papers 341 existence probability agents distribution implied try maximise expected utilities set 4953 theory practitioners notion utility want large body literature agents There 20 D PooleArtificial Intelligence 94 1997 756 Example 15 Continuing Example 12 suppose rules utility utilizy agent 5 t Te utilityagent 0 e A c utilityagent 9 e A lc utility agent2 7 d utiZity agent2 2 d Note complete rules utility ICL utility consistent agent1 agent2 independently choice space rules The values possible worlds omitting false atomic choices Wb a1 h c d e utility agent 0 utiZity ugent2 7 Wah k a2 h TC d e utility agent 9 utility agent2 2 WUjb I a3 h TC d le utilityagentI 5 utilityagent2 7 Wabz k b2 yC d le utilityagentl 5 utilityagent2 7 Wazbz k a2 b C WaSb2 k a3 b2 C ld ld e utility agent 9 utilityagent2 2 e utility agent 0 utility agent2 2 232 Strategies Given ICL singleagent chooses alternatives stochastic agent adopts probability trols theory agents adopt strategies These called policies agent strategy specify atomic choices alternatives agent case These In general distribution controlled strategies Definition 16 strategy agent function P UC 0 1 If C 3 A controller PO ICL theory E A f 0 VXECn CPal aEx In words alternative atomic choices alternative controlled agent P probability measure Definition 17 A pure strategy agent strategy agent range 0 1 In words P selects member element C P probability 0 A pure strategy agent probability corresponds selector function C 1 members Definition 18 A strategy proZe function strategies nature If strategy profile E A 0 aa agents agents D PooleArlijcial Intelligence 94 1997 756 21 strategy agent We write aa alternatives controlled agent We define P PO P emphasize CT induces probability Thus strategy profile specifies agent sense specifying probability distribution alternatives Given probability distribution alternatives derive expected utility weighted sum tbe utilities worlds worlds weighted probability 19 If ICL theory C 3 A controller PO utility consistent complete Definition CT strategy profile expected utility agent 0 strategy profile v summing selector functions r defined theory utility consistent complete probability world T strategy profile g u T utility cT T world w agent Note expected utility undefined probability distribution alternative In particular multiagent case thing expected utility agent strategy agent utility agent depends strategies agents Each agent wants choose strategy maximise expected utility For singleagent finite choice finite number finite alternatives case definition strglitforwd Each finite number strategies expected utility choose strategy maximal expected utility For multiple agent case agent consider agents choose choice depends agents choice How choose strategies studied game theory 173253 We mirror definitions game theory example define Nash uilibrium Pareto optimal reduce maximum expected utility singleagent case follows 20 Given utility consistent complete ICL theory C 3 d controller Definitim PO strategy profile Nash Equilibrium agent increase utility unilaterally deviating cr Formally CT Nash equilibrium agents f A sa cr strategy profile aa rra 44 22 D PooleArtijicial Intelligence 94 I 997 756 In words strategy profile crO strategy profile cr agents better U That better unilaterally deviating One fundamental results game theory Nash equilibrium equilibrium equilibrium exist For single agent optimal decision theoretic strategy 17321 In general need nonpure finite game strategies randomised Nash environment uncertain Definition 21 Given utility consistent PO strategy profile u Pareto optimal agent better agents worse Formally CT Pareto optimal exists agent E A EU u EU exists agent u E A strategies complete theory C 3 A controller ICL game game theory Other definitions What adding provide environment way probabilistic Horn abduction assumptions Bayesian networks theory given use logic program express way 36 represent logic paper agents model independence independence Example 22 Here represent Example 1 In facts axiomatise utility kicker goalie complete axiomatisation utility consistent utility kicker 1 goal utility kicker 0 goal utilitygoulie 1 goal utility goalie 0 ygoul In facts axiomatise goal scored lo goal c kicksD A jumps D A goulifsamedir goal kicks left A jumps right A goul_z_kl_jr goal kicks right A jumps left A goulifkrjl owned goalie Gjumps right jumps left In C alternative owned kicker alternative tives owned nature nogoulifkl_jr PO goulifkljr goalifkr_jl nogoulifkrjl 01 PO goulif_kr_jl 02 goulifsamedir kicksright kickslef alterna goalifAl_jr nogoalsame_dir Pogoalifsume_dir 09 lo The atoms goal_if_samedir goal_kl_jr goaljfkrjl introduced normal logical rules independent alternatives independent causal hypotheses 361 These D PooleArtificial Intelligence 94 1997 756 23 Suppose goalie choose strategy ps Pgonump kicker choose strategy m Pkicker kick g In setup cases goal true cases exclusive sum probabilities Thus right Xd pkpgo9f1 pkl pgo9 lpkpgolpkl pgo2 agent The problem utility So kicker choose pk maximise goalie choose ps minimize probability choose In Nash equilibrium agent improve probability maximise probability expected goal goal expected utility unilaterally strategy payoffs pure kicker values pure strategy higher value linear combination In randomized strategies Take kickers point view If randomised pure strategies strategy changing randomised strategies improve equilibrium kicking pk 0 These equal payoff kicking utility choosing right formula pk 1 payoff kicking right kicking left equal The payoff left formula po9 1 psO2 1 pO9psOl pg derive pg 715 Thus mixed strategy goalie jumps time right probability randomis kicker 7f15 Us equilibm reasoning It easy pk S15 unique Nash equilibrium pg 715 pk 815 Under pure strategy equilibria equi kicker slight jumps slightly worse probability goal 79150 052666 expected goalie Solving consider ing similar goalie There librium advantage left 3 Embedding formalisms ICL In section influence diagrams Markov decision problems MDPs ICL We strategic direct embeddings form games represented formalisms Another embedding 361 restriction ICL resirictions embedding rules influence diagrams noted probabilistic Horn abduction failure 361 The choices nature negation represent Bayesian networks directly based embedding 31 Representing influence diagrams An influence diagram decision network 23 graphical representation decision problem singleagent See Section 14 We translate influence diagram policies ICL theory isomorphism 24 D PooleArtcial Intelligence 94 1997 756 diagram influence utilities equal We consider influence diagram mapped representation strategies ICL corresponding expected influence diagrams single value node Definition 23 An influence diagram tuple N A 0 P U l N finite set nodes partitioned decision nodes singleton set V containing nodes drawn ovals decision nodes rectangles diamond set R random nodes set D value node Random value node l A c N x N set arcs N A forms acyclic directed graph If ni nj E A ni said parent nj nj child ni set parents node n DAG Define rn m 1 m n E A That rn We assume l 0 function value node children RU D sets variable values On called frame variable associated node n We node n set values extend 0 cover sets nodes Ona n fno x x f2n l P probability function random nodes given parents That x E R P x u 1 nx w nonnegative number VW c PxJ OX 1 TX w 1 The probability w E r x derived context written simply Px 1 nx values u E Ox l U LTT V Iw U utility function gives utility different values parents V The parents random node represent probabilistic dependence Bayesian 351 The parents value node represent network utility depends values parents value node The parents decision node represent node known decision available value parent decision dependence information functional If di E D decision function di function Si fl r di Odi If 8k Si decision decision nodes dl dk policy tuple St function di Policy S induces conditional probability Pa decision variables defined Psdi I411 1 sirdi di Suppose R U D XI x The joint distribution given policy 6 PSXl9 Xn n PXi I rXi X n PSXj 1 TXj XR XED meant Pa clear context D PooleArtcial Intelligence 94 1997 756 25 ta d Fig 2 An influence diagram The expected utility policy 8 given XX XR XjED summing values variables XI xn ta d Example 24 Fig 2 shows influence diagram decision nodes randlom nodes b bs value node utility The intuition diagram decision d depends b bs noisy sensor b sensor controlled ta Associated influence diagram conditional probability shown diagram frame table random variable given tables random nodes major source complexity number parents node variable parents These probability size exponential Suppose frames follows 26 D PooleArtijicial Intelligence 94 1997 756 fl tu high low f2 low medium high Oas PO neg Qb PO neg iI pas neg dldzd3 There probability assignment bs values distributions assigned tu Pus pos 1 low A ta high b The mapping influence diagram l Random variable xi value vi represented l Random variable Xi ki parents xi xi4 represented singleagent ICL theory follows l1 proposition xi ui l2 rule expo nentially ki alternatives There rule XiK XiXl AAxiKkl ACiXtK9Q For assignment x fl Xi alternative controlled nature values Xij Ui uik E L Xi1 x Ciuluig uitCiuuilui nxi ut u The probability atomic choice value corresponding probability conditional POCilv uil T UitiPXilll Xi UisXik Uiz righthand probabilities diagram Note rows probability The conditional influence alternatives provided probabilities In cases probability occurs parents irrelevant variables 71 mapping provided number tables Xi number represented compactly context values In particular l Value node parents Xi Xiti represented rule form UtiktyUgent U t Xi LJ A A XitiUik chance nodes compactly Oil eU E flXi X x f2Xiki u UUi cases value function AS represented Toi The mapping Horn abduction We standard probabilistic different equality random nodes 361 terms denote object representation Bayesian networks probabilistic notation xi U logicians usually mean D PooleArtcial Intelligence 94 1997 756 21 l Decision variable xi ki parents xi xiii represented rule expnentily ki alternatives There rule XiF XiQ AnxiKi ACitiKvl For ui 9 Uix agent E fJXiL x x Lxj alternative controlled CiUlUilt uikCiuTuilui Lxi 1 u Just influence diagram policy choose value value parents choose value alternative There mapping alternatives values parents node Example 25 Continuing Example 24 influence diagram Fig 2 variable tu parents value chosen This represented having tz hi ta low E Ct There 8 independent choices d assignment values parents This represented rule dDV ta7V A asAV A bsBV A desDABV d7esdtAYBVdesdzAYBVddesdsAYBV E Cl value TV AV BV Theorem 26 Given influence diagram ID corresponding ZCL theory dejined matpping correspondence policies injuence diagram pure strategies ICL theory The corresponding policies strategies expected tii Proof A policy influence diagram specifies decision function decision node Each decision function function values parent values nodes A decision function S corresponds selection corresponding alternative It easy different policies correspond different selections different selections correspond different policies The expected utility influence diagram policy S eS x xtx n riER PXi 1 d1 x n pSxj IQdXjl X u4V XjED x n pOCiXivXi X r fCjXj71xj x uVr xx xiER TjED ciXi V Xi obvious mining policy This expected utility PHA theory policy Pt probability induced 28 D PooleArtificial Inrelligence 94 1997 756 32 Markov decision processes Markov decision processes 44 models singleagent decision problems notion state conveys information history stochastic sequential past A Markov decision process defined function Psl 1 specifies terms set S states set A actions s1 probability carrying action state s reward function R q reward obtained action carried resulting state transition state resulting specifies state 1 A stationary policy selection action state agent time depends state We represent choice function agent assuming want stationary policies A S true agent action A state S A al set available actions The agent gets choose state If want nonstationary policy depends time stage add time parameter policy We axiomatise state transition function specifies states transform actions state S sT state S T A A S A st_trans S A S state S T true true action A transforms state S state S This stochastic transition state S time T st_trans S A S VSVA st_transSAsgst_transSAsECo SO s set states Note alternatives nature PO st_trans S A S probability action A state S controlled state S result carrying A reward function defined terms rules form reward ri T c statesi T state Si number ri We typically want write Markov decision processes explicitly size probabilistic states instead want divide state propositions 121 This reduce reduced distributions gain Boutilier computational iomatisation use rules concisely This concise et al 5 exploit gain MDPs The ICL representation logic defined semantics rule allows express structured probability computational specification exploited tree structure probability allows concise ax dynamics tables assessment necessary This referring random variables D PooleArtcial Intelligence 94 1997 756 29 Kanazawa 24 incorporates particular claim useful similar This probability independence structured MDP example Boutilier logic Essentially convert rules action exactly trees et al 5 rules frame prob Example 27 Let axiomatise choice independent need separate lem 31 In example office opposed umbrellaiT robot coffee uhcT robot state propositions Zoc_ofsT location robot wet caf6 time T wetT carrying umbrella raining cT ruiningT robot user coffee There actions goT opposite location buyC T buy coffee delC T deliver coffee getUT coffee We specify dynamics logic example following clauses define wet hcu wetT 1 t wetT wetT 1 goT A ruiningT A umbreZZuT hcuT 1 hT hcu T 1 c deZC T A 4cu T A loc_o T A hcr T A deECsucceeds T VT deZCsucceedsT delCfuiZs T E Co VT PodelCsucceedsT We define reward function rules 08 rewurd 10 T t KUT A lwetT rewurd09 T t KUT A wetT rewurd01 T c zcuT A TwetT rewurdOO T cuT A wetT For finite horizon problems value specified terms rules For example vulueto R U T 1 rewurd R T A vulueto U T vuzutrto 0O vulueto VT true V sum rewards time T For infiinite horizon problems simple You imagine writing discounted reward function 441 vuluc R U x y T reward R T A vulueU T 1 y discount terminate specifcation specification atic factor However rules problematic It probably better define value external value traditionally function separate MDPs recursion logic Having parts problem problem 30 D PooleArtQ5cial Intelligence 94 1997 756 33 The strategic form game The direct connection ICL strategic form game Section 55 comparison extensive form game The strategic form game 17321 tuple A X U l A nonempty set players agents 0 2 function agents nonempty sets pure strategies Thus _Z set pure strategies agent 0 u function A G2A2a lR Suppose A 1 E A ua function given ntuple strategies agent A returns utility agent strategy profile Thus 24 CT gai E X ai von NeumannMorgenstern utility agent player ai chooses strategy ohi The general idea player chooses strategy specifies contingencies Following complete play specified players strategy player receives utility Note different forms treat One nature agent payoffs expectations averaging natures choices The second nature player probability distribution strategies called Bayesian form game 171 players partial information natures choice The private information natures called players type The Bayesian form game assumes player chooses strategy learns type Such distinction scope paper consider strategies computed example computed online offline The ICL seen particular representation strategic Bayesian form game The set agents We divide space strategies players independent choices allow structure strategy space use logic program axiomatise u function There direct mapping strategic Bayesian form game ICL theory strategic game A z U mapped multiagent ICL theory C F d controller PO A set C set ffoaiai 1 ani strategy aj 1 ad E A ai ohi atom says agent ai adopting strategy need strategy controller function ai I ai PO probability distribution types Bayesian model game 3 set rules form utiZitya util cio oh A A CT util ua D PooleArtcial Intelligence 94 1997 756 31 This mapping trivialised fact lot hidden structure strategies We assumed strategies follows For simple games able realistic situations want able specify choices lower level able control selection components strategies The consequence number different agents choosing strategies involve reasoning building blocks strategies circumstances reasoning dynamics domain determine consequences actions 4 The dynamic ICL The ICI presented far good representing problems decision problem statically expressed problem solved involves dynamics change Like strategic form game building blocks strategies constructed ahead time For example influence diagram mapping create alternative corresponding assignment values parents creating appropriate rules defining policy fly There number problems l What agent attempt buried representation The alternatives lower level choices faced agent specify agent contingency While represent dynamic structure structure reasoning acting foalism presented far gives help l We create alternative independent choice agent priori divide information states decision The problem priori division needs finest level For available example alough decision d infoation decision influence diagram d parents specification agent require distinctions information state There concise encoding policy Just rules concise specification probability distributions like express policy agent rules o We want create alternatives fly options available agent information knows depend context economical create alternatives needed having anticipate strategy l We want reason program agent compute action action 48 We want build representation natural specification dynamic systems We extend ICL dynamic ICL logic slightly complicated arguably natural We model dynamics world structure choices The dynamic ICL like representation extensive form game representation strategic form game tell construct 32 D PooleArtificial Intelligence 94 1997 756 appropriate gamedecision advantages networks variables ability ICL represent tree Section 55 This embedding structured decision independence tables losing Bayesian use logical We build theory general model agents environment places ICL wider theoretical context introduces interacting This important notions traces transductions state sensing 41 Dynamical systems 13291 common areas science Modelling dynamical engineering systems economics mechanical ecology We assume time structure 7 totally ordered metric intervals time framework A trace paper consider discrete development continuous discrete time 7 continuous See function 7 39 domain A A transduction function output time sense output time t depend agent specification transduction Transductions dynamic adequately handle case nondeterministic agents dynamic agents l3 general systems input traces output traces causal inputs times t t t function input history time An form general abstraction 394757 The state agent needs information function state current remembered order inputs At extreme state entire history agent At extreme agent output contain state react current inputs 42 Agent structure So far modelled agents naming specifying choices makes agents It helps want provide structure control easy model actual agents Not logic program set assignments choices sense Agents input outputs access internal values access values We model agents logic program specifies outputs entailed 391 This logic program use internal values sense values agent access sense certain inputs use values determine l3 With deterministic nondeterministic memory agent inputs composition step agents input history inhabit environment needed Nondeterministic need able recall implement agents competing inputs choice commitments For example bcd I nondeterministic agents agents need limited choice sequential time chose second time step agent able recall D PooleArttjMd Intelligence 94 1997 756 33 In modelling agents careful number things What inputs outputs When havenoisy sensors actuators slop failure condition values world sensors tell We able model agent observe relates world agent controls relates agent actually We sure agent actually carry policy specified agent An executable policy depend events agent observe agents control The logic programs models agents They agents We want able model different sorts agents natural artificial We want able model agents implements simple language example We want logic circuits traditional programing use language model agents design agents agent encounter environment We want able model long agent execute action including time execute program choose action 483 This mean run specification agent different agent example forward chain axioms backward chain axioms different timing properties We distinguish controller plant agent 131 See Fig 3 The controEZer optimize receives digital signals observa tions outputs digital controls actuator commands The plant body physical embodiment agent includes input devices cameras micro phones radio receivers wheels limbs transmitters The plant receives percepts environment sound light radio signals sends observa tions controller The observations usually correlated percepts received typically identical sensors noisy The plant receives controls controller makes actions environment actually moving sending messages Multiple agents interact environment way agents communicate environment I4 a11 act environment Fig 3 There agents carry actions environment receive percepts environment As far as8 outside world including agents concerned agent receives percepts messages light sounds performs actions moving limbs sending messages Thus agents tend group controller plant agent robot physical implementations As far controller concerned group plant environment It receives observations outputs controls The distinction plant environment essentially arbitrary usually distinction build controllers particular plants general environments While I4 If form direct communition This makes modelling uniform allows model noise failure channel modelbd environment communication 34 D PooleArtificial Intelligence 94 1997 756 agent I act uat oTTlervat ions 14 IA agent2 agent3 Fig 3 An agent acting environment distinction outside observer building order construct controller 1 1055 controller plant agent commit arbitrary particular division plants Typically want hierarchy controllers scope paper controllers rest paper receives definitive observations For plant The plant controller modelled observations observations reflect true environment modelled terms rules depend percepts natures choices point view assume environment In particular uncertainty issue controls 43 Agent specification module The agent specification module inputs outputs controls The agent able condition need choose values controls takes controllers point view observations observations specification modules allow modularise Agent science common modular program design We generalise use agent specification modules decision problems like information techniques knowledge use hiding abstract data types ICL representation allow concise ICL dynamic D PooleArtificial Intelligence 94 1997 756 35 Definition 28 An agent specication module agent 0 written ASM C 0 T tuple l C set alternatives ator commands commands agent element C controlled This set possible actu actuator agent attempt l c3 observables called observation alternatives elements observation atomic observations set sets ground atomic formulae Elements 0 called alternatives l T observable function agent decides element alternative x E C choose atomic observation rx 1 rx diagram function T C 20a The idea observed Elements agent choose element influence available parents decision node x information corresponds observation alternative rx The following definition mirrors analogous definition game theory Definition 29 Agent pelfect previous observations C totally ordered XI E C x2 E C x1 2 XI E 74x2 element recall noforgetting actions Formally remembers previous means TXI c rTTx2 A dynamic ICL theory consists agent specification module logic program plus stochastic choices choices axiomatise follows agent agents Definition 30 A dynamic PO ASM independent choice logic theory tuple A 30 l A finite set agents containing l CO natures choice space choice space alternatives l controlled nature logic program atomic choice unifies agent 0 called nature distinguished natures facts head rule 0 PO function UC0 0 l Vy E CO CcrEX Pocr 1 l ASM function A 0 ASM agent specification module agent VO E ry Va E 0 acyclic ordering That ordering actions corresponding acyclic acyclic ordering Vu E A Vx E C Vcz E x acyclic observables Note CO PO correspond strategy nature Definition 37 It specification choices nature This specifies stochastic dynamics particular stochastic We sure observables agent cover possibilities alternatives 36 D PooleArtcial Intelligence 94 1997 756 ICL theory dCoFo PoASM set r ground nonexclusive exists choice function 1 LYE Rr UFii b a1 A 2 Otherwise choice function r UaEA C r lJaEA C exists exclusive cx E r r Definition 31 Given dynamic mulae E r cry2 E r r covering R7 u t_ cy For example choice alternative exclusive covering A trivial example exclusive covering Every set form given C b c d la e f F g c h c b A c c b A d g h exclusive covering set If g c e added F g h longer exclusive Definition 32 A dynamic element 0 ICL theory ing ICL theory exclusive respect observation consistent E A ICL theory A dynamic cover dynamic observation complete E A element 0 require theory The definitions sure treat elements 0 random variables Unlike elements C exclusive covering definition We consistent negation failure complete extra unnamed element element 0 Note observation consistency exploit severe restriction 0 set singleton structure observations 371 require observation observation logic theory sets suppose high medium low observation allow choices agents strategy specified function entail high set Example 33 For example alternative We want theory medium This means actuator settings medium lmedium exclusive covering cross product actuator settings cover case Thigh A Tmedium A 4ow low llow If values exclusive sets high digh observation mean strategy function If high medium low covering alternatives defining strategy The general idea agent observe element member observa 7r x choosing element x The acyclicity tion completeness possible temporal ordering consistency ensure requirements restrictions In paper assume theories observation consistent complete 44 Pure strategies A pure strategy represented specification agent based observes logic logic program There restrictions values condition ensure agent This strategy program access D PooleArticial Intelligence 94 1997 756 31 Definition 34 pure strategy agent logic program 30 If C O 7r0 agent specification module agent E A function observed decision rrcX rx logic program specifies agent Y E x true unique stable model 3a U R 7 That 30 acyclic acyclic ordering x E C element element rrO x element x That agent observe making For x E C selection unique The heads rules 30 unify local atoms unify atoms agent specification module agent 30 members choice alternatives x0 Thus 3Q imply alternatives owned agent local atoms intermediaries For x E C formulae prove element x elements members VX definition built compute agent observe compute appear bodies rules 3a local atoms atoms formulae While want restrict complexity programs choice element x choice depend values depend choices agents Thus strategy agent program specify agent based information receives Definition 35 Given dynamic pure program J F UaEA 30 specifies agent attempt selection strategy agent nature Thus strategy profile logic ICL theory pure strategy profile alternative There equivalent ways define semantics One possible world selection element controlled nature 3 specify true world In case probability world strategy strategy profile specifies true world independent possible world selection element The second In case true world depend strategy profile alternative world The second possible worlds chosen probability zero probability method scenario We define created formally Definition 36 pure trategy profile If dynamic ICL theory A Co 30 PoASM utility complete 3 expected utility strategy profile 3 agent eu93 Cp7 x U7U3 summing selector functions r Cc u76r3 u R7 U3kutilityau defined theory utility complete 38 D PdeArtcial Intelligence 94 1997 756 P7 JJ Podx xeo 7 3 probability utility world w agent strategy profile world 7 7 p7 45 Stochastic strategies As goal kick example desirable agents strategies random strategy In section define random stochastic strategies The general probability distribution pure strategies adopt random idea If C Oa TV agent specification module agent E A Definition 37 strategy agent tuple 3 CL Pa CL choice space stochastic atomic choices appear outside strategy P probability distribution element CL dx E CA Va E x 0 6 Pa 1 CaEX Pa l F pure strategy element R ra local atoms strategy logic program selector functions r CA F U R 7 qdown r Example 38 Suppose left highmedium agent That left act know high medium low left high medium low T agent specification module strategy facts true One stochastic low high A uh high A dh left t high A Zh t medium A urn medium A dm left t low choice space CA uh dh Zh umdm 02 PZh Ol POum 06 Pmh 04 P given Puh 07 Pdh strategy If u strategy profile Fz component Cz second component Definition 39 A strategy profile agent E A aa define P component ca assignment stochastic stochastic strategy It remains define expected value strategy profile A Definition 40 complete u stochastic strategy profile expected utility agent utility consistent Fa PoASM If dynamic theory ICL cag CP 7gl x 47a D PooleArtcial Intelligence 94 1997 756 39 summing selector functions T Co U lJaEA C 7CZG u ifR7U3ffVtilityau 3 UaEA 3 u defined theory utility consistent complete u 7 3 probability world 7 strategy profile 7 utility world w agent strategy profile 3 p T 5 Discwon In section discuss modelling issues dynamic ICL We discuss model informationproducing actions model noisy sensors actuators means execute stochastic strategy finally relationship extensive form game Section 6 presents detailed examples 51 Passive sensors information seeking actions The observations represent passive sensors time receive values environment value observation alteative We distinguish informationproducing actions actions change world type action The nature module specify consequences action We model informationproducing actions having actions effect sensor value correlates value world For example information producing action look affect sensed eyes agent look sense value look certain direction sense direction Of course look action unreliable lights arbitrary time achieve effect medical test What important agent condition sense values values derived The agent condition access true state world Similarly agent control message sent actuators actually different Section 61 gives detailed example discussion modelling passive sensors infoation seeking actions 52 Noisq sensors actuators There straightforward way model noisy sensors actuators This follows distinction plant environment depicted Fig 3 The general idea axiomatise observations function percepts plus noise Similarly 40 D PooleArtQicial Intelligence 94 1997 756 axiomatise actions agent function controls plus noise slop errors slippage We divide noise sensor systematic errors broken makes error intermittent noise independent reading checking continuum road speeds highway For example consider 161 actually error sensor Example 41 In example axiomatise noisy sensor break normal error The sensor true reading produces reading random independent If sensor actual velocity working If working working sense_velocity V DYT velocitysensor_OKT A velocity YT A normal_error DYT sense_velocity EYT velocitysensor_OKT A error_reading DVT We need errors discrete probability lOkmh distribution normal errors For example steps specify like dT normahror DYT 1 DV E 30 20 10 0 102030 E Co PonormaZ_error 30T 001 Pa normal_error 20 T 003 Po normal_error 10 T 006 PO normaZ_error 0 T 08 Ponormalerror 10T 006 Po normalerror 30 T 003 Po normal_error 30 T 001 Similarly define error_reuding provides error readings There distribution mathematics sets speeds speed normal prevents having nondiscrete distribution errors We presented complicated need consider measurable probability distribution principle Gaussian Whether sensor working time working time We need axiomatise need specify time suppose distribution time The sensor break working dynamics sensor failure 2 chance breaking time probability independent D PooleArtijkinl Intelligence 94 1997 756 41 5 chance fixed broken axiomatise complicated dynics sensor fixed main point verocitysensor_OK axiomatised velocitysensor_OK T f 1 velocitysensor_OK T A velociesora T velocitysensor_OK T 1 melocitysensor_OK T A veociensor_ed T VT velocity_sensor_breaks T velocitysensor_remains_OK T f Co VT velocitysensorjixed T velocitysensor_remainsbroken T E CO 005 In PO velociensorreu addition need define initial value veociensor_OK example member alternative controlled nature T 002 PO veociensorbed 53 Executing strategy What mean agent execute sategy If strategy agent pure tell agent based sensor values The agent unambiguous actions entailed If strategy agent pure number things agent attempt based inputs To follow strategy pick actions randomly according disibution specified strategy Picking strategies random mean random number generator robot access random quantum phenomenon For example soccer playing robots compile randomness choosing offline right left according random strategy If hide design opponent designer replace robot single penalty kick An alternative nonrandom robots choose random penalty kick These robots choosing mechanism seen randomizing agent The important property agent able predict agent It silly think agent cheating choosing random distribution This particularly case consider agent gets choose whichever strategy wants Cheating strategy choosing different strategy We consider strategy agent carrying This mean agent lie strategy carrying What agent says action agent wants 42 D PooleArtijcial Intelligence 94 1997 756 54 Nondeterministic actions frame problem There work logical specifications actions change The speci solves frame problem fication actions case complete knowledge axiomatisation change acyclic programs 274550 change See 2 understood These axiomatisations detailed description deterministic closure assume axiomatising What added work way handle nondeterministic complete knowledge idea determinism knowledge The central negation failure occurs world We distribution When uncertainty value Often axiomatiser random agent What require ambiguity useful consider resolves question chooses actions partial assumed worlds Example 42 We axiomatise heads 50 time tails 50 time state heads tails coin toss coin tossed tossed remains lands headsCT I t tossed C T A heads_tums_up C T headsCT 1 t ossed C T A heads C T taiZs C T lheads C T headsC T true time T heads turn coin C tossed time T It defined true coin C heads time T heads_tumsapC T VC VT headxtumsup C T tailsfurnsup C T E Co VC VT Po headsturnsup C T 05 Many papers use situation calculus time model See 40 description situation calculus combined independent frame problem discrete present solution change representing 2274550 choice logic 55 The extensive form game The extensive form game 173253 representation game terms game tree generalisation node having decision information tree include different agents making decisions sets nodes agents distinguish D PooleArtificial Intelligence 94 1997 756 43 following form game contains The extensive 1 set players order moves moves 2 3 players payoffs function moves 4 players choices 5 player knows makes choices 6 probability distribution exogenous events information 17 p 771 There direct mapping dynamic actions game d set players The logic program specifies moves The v function probability provides random variables specifies player knows function exogenous players The set C specifies CO events represented ICL extensive form payoffs function players choices Pa makes independent The order moves defined acyclicity knowledge base The moves If 1 x2 xi 2 choice ordered information acyclicity ordering acyclicity ordering x2 xi order choices information depend choice matter available available decision While ple semantic games acyclicity rule base chosen framework 36 justified order appealing allow sim structure 6 Examples In section present information strates socalled second prlesents decisiontheoretic imperfect information representation formalism seeking actions different examples ICL The demon noisy sensors actuators The example The defines twoplayer details planning tictattoe There intended game blind chosen elegant examples 61 Information seeking actions noisy sensors In section ideald single agent environment example showing model l Information following producing robotics asking question plans l Comlitional l How passive sensor model active sensor l How noisy sensors actuators modelled conditioning Section 614 looks user modelling sense values situation actions tests diagnosis positioning camera 44 D PooleArcial htdigence 94 1997 756 _r_______ z j isTrue j Fig 4 Influence diagram idealised example 61 I Informution producing actions The look decision Fig 4 seen information information isTrue available action producing action It lets It cost associated The agents action look dontlook The action modelled having look dontlook E C agent controlling alternative In rule base model actions agent truths world affect case sense values agent Here idealised example noise agent Section 614 considers noise Suppose sense pos neg For case noise environment model following following looking axioms 3 sensepos look A istrue sense neg look A true sense dentlook Thus looK provides information is_true doit 612 Conditioning sense values The agent sense world decide based sense values Continuing agent possible actions doit dontdoit example suppose sense values There independent doit contingencies choices agent Within ICL modelled having axioms D PooleAriciuf Intelkgence 94 1997 756 45 doit sensepos A doifgos dont_doit c sensepos A dontifpos doit sense neg A doijlneg dent_doit sense neg A dontifneg doit c sense A doifnothing dent_doit sensefnothing A dontnothing having following alternatives C controlled agent do_ifpos dont_ifqos do_ifneg dontifneg donothing dontif_nothing Within ithe dynamic ICL specify doit dontdoit E Ct 0 ngenr sensepos sense neg sensenoting T doit dontdoit sensepos sense neg sense The rules need provided defining ICL created agents strategy dynamic ICL 613 Utility model Finally utility model environment model specifies utility varies depending true agent Here example axiomatisation given agent agent tiagent Fnie K tesr_cost TC A prize Prize test_ctst 5 look testcostO c dentlook prize 10 c doit A istrue prize 0 c dont_doit A istrue prize 8 c dontdoit A true prize 1 doit A true 614 Noisy actuators sensors In Section 611 assume noise actuator settings sense values We model actuator noise example looking actuator like 46 D PooleArtificial Intelligence 94 1997 756 look A lookingworks t dontlook A not_looking_doesnt_work following C controlled nature lookingworks lookingdoesntwork notlookingworks notlookingdoesntwork Polooking_works Pu notlookingdoesntwork look probability agent succeeds seeing probability agent sees looks Noisy sensors modelled similarly Assume alternatives controlled nature agent sees noise respect value sensed depends seeing There Gfalsepositive truenegative Gfalsenegative truepositive following facts sensepos A istrue A truepositive sense A isfrue A falsenegative sense A Gtrue A truenegative sensepos c A s_true A falsegositive sense c 7see Pofalsepositive value falsenegative sensor reports negative value world true probability falsepositive sensor reports positive true PoCfalsenegative probability world 62 Shipping widgets In section present example Draper et al 141 The example process widget Its goal widget painted processed flawed Processing widget robot notify widgets shipping untlawed widgets The robot inspect blemished usually widget painted removes blemishes correlates widget flawed Painting consists rejecting supervisor widget initially results Agent module We represent blemishes time T senseblemishedT robot The robot sensor widget true robot senses detecting blemished The robot 6 actions exactly possible time reject ship notify paint inspect robot action A time T widget doAT true D PooleArtcial Intelligence 94 1997 756 47 The robot specification module robot tuple Crobot Orobor r C robor reject T ship T donotify T dopaint T inspect T donothing T 1 T time 0 robt lsense blemished T sense blemished T 1 T time T reject T doship T donotify T dopaint T inspect T donothing T lsense blemished T sense blemished T 1 T T In words time robot gets choose actions When past carries knows sensed blemishes decision making Nature module The remaining nature This specifies actions affect world world affects senses robot dynamics world We axiomatise define rules alternatives thing controlled robots The widget painted persists widget result widget painted painting works depend time second painting widget likely painted Painting works shipped rejected Once painted widget remains painted world Painting 095 We assume probability paintedT 1 dopaint T A paintworks A vhipped T A vejected T paintedT 1 paintedT Painting succeeds 95 time pai8t_workspaintfils E Co P0paint_works 095 Popaintfails 005 Note parametrized paintworks time This lets model fact repainting help painting world paintfails false painting results time In possible widget painted true painting results widget painted failed The widget blemished flawed painted 48 D PooleArtificial Intelligence 94 1997 756 btemished T uwedT A lpuinted T Note use logic programs assuming stable model semantics entails rules mean way Clarks completion 111 Whether widget flawed persists Jlawed T 1 wed T The widget processed rejected flawed shipped flawed processedT rejectedT A wed 1 processedT hipped T A uwed T The widget shipped robot ships shipped persists sipped T dofship T shipped T 1 shippedT The widget rejected robot rejects rejected persists rejectedT c reject T rejected T 1 EjectedT We axiomatise robot senses affected robots actions world sease blemished T 1 da inspect T A blemishedT A zlsepos T The sensor gives false positive probability 01 Unlike punting succeeds suppose probability sensor giving false positive time independent happens times Gfulsepos T notuZsepos T E Co PO ue T 01 PonotfuZse_posT 09 D PooleArtijicial Intelligence 94 1997 756 49 30 widgets initially flawed cfzawed 0 ffe 0 E Co Pe jawerl 0 03 PO ufzJEawed 0 07 Finally specify utility dependent world actions robot The utility widget painted processed time robot notifies zero utility robot 1 dc notify T A zotiedefore T I paintedT A processedT tility robot 0 tii robot 1 notifed_before T c TI T A notify TI One pure policy robot logic program inspect 0 dopaint 1 reject 2 t sense blemished 1 ship 2 t lsense blemished 1 notify 3 This expected utility 0925 Note problem formulation need paint blemished widgets This policy optimal Policy inspect 0 inspect 1 dopzint 2 reject 3 c sense blemished I doreject 3 senseblemished 2 ship 3 c vense blemished 1 A lsense blemished 2 donotify4 expected utility 094715 There optimal policy example finite game Nashs theorem apply add inspects raising expected utility 50 D PooleArtijicial Intelligence 94 1997 756 The best policy expected utility 0665 inspecting Quint 0 doship 1 donotify 2 Of course define utility robot penalized taking time defining utility utility robot 1 T 10 rewardedT utility robot 0 vvwarded_atsome_time rewarded_atsometime rewardedT rewardedT c notify T A lnotiedbefore T A paintedT A processed T policy single inspect optimal revised utility Under expected utility 0625 63 Blind tictattoe Koller Pfeffer 26 present game description tictattoe We represent example enable compare representation language Gala In language game ICL represent game blind order present parlourgame Gala Blind tictattoe imperfect information version standard tictattoe tictattoe players As regular turns placing marks squares How turn player choose mark x o reveals makes opponent mark type square goal complete line squares makes As usual mark 26 The basic idea defining game axiomatise dynamics game logic The rules imply consequences state game In game choices agents First need representation row wins We represent order important player places state game list player Who b X Y The element list moves marker form X Y Who What means What o x position element placed The rule defines The second rule state progression defines subsequent moves sture X KAgent What 1 s 0 startsAgent A choosesAgentplace X E What 0 D PooleArtcial Intelligence 94 1997 756 51 stutc putX ZAgent What putXp Yp Ap Wp Rest sT c stat4 putXp Yp AP Wp IRest T A nished Xp Yp Ap Wp IRest A opponentAp Agent A choosesAgentplaceX I What T We define auxiliary game finished relations starts moves alternate stana opponent b opponent b nished S drawS jinisized S wins A S drawS c length S 9 We axiomatise particular utility functions Note relying fact set choices agents win state draw state utiZiy 1 t wins S utiliy 0 wirzs b S utiliv 05 c dmw S utiu b 1 t wirzs b S utiZity b 0 c wins u S utiZiQ 05 c dmw S 52 D PooleArtcial Intelligence 94 1997 756 We axiomatise choices agents t5 chooses Agent place X I What T chooseXAgent X T A chooseYAgent X T A chooseWhatAgent What T The agents choose X position Y position mark ThUS VT chooseXAgent 1 T chooseXAgent 2 T chooseXAgent 3 T E Cr VT chooseYAgent 1 T chooseYAgent 2 T chooseYAgent 3 T E Cenr VT chooseWhatAgent o T chooseWhatAgent x T E Cent Now decide agent gets observe making decision choices We assume state consists list poswho X I Who squares pos_what X I What occupy agent gets observe filtered version square list senseAgent Pas_WhoList Pas_WhatList T stute S T A extractpos_whoZist S Pos_Who_List A extractpos_what_listAgent S Pas_WhatList extruct_pos_who_list extructposwho_list X XAgent What IS11 pos_who X x Who IP 11 t extract_pos_who_list Sl P 1 Similarly extruct_pos_whatlist The observable function given l6 z chooseXAgent 1 T chooseXAgent 2 T chooseXAgent 3 T senseAgent Pos_WhoList Pos_WhatList T 1 Pos_WhoList PosWhatList appropriate lists The choices similar agent knows X chose choosing Y sets include information previous decisions space presumably I5 This simple way occupied method list element I6 We presented syntax present object set notation gets general level rules idea agent derive list free spaces sensed information axiomatise choices It means penalized losing agents choose choose occupied place mark spot Another choose r syntax order present choices This wanted It hoped different formalisms logical D PlieArciai Intelligence 94 1997 756 53 For like read declarative logical formulae best way understand rules think building game tree forward chaining rules starts choice X position Y position mark making This forms lway split game tree 18 different Ichoices available Then state evolves b making There 9 different information states b choose 18 choices I6 alternative iomatisation And building game tree It envisioned representation build game tree Gala 261 use efficient algorithms The representation proposed paper declarative declarative possible worlds semantics framework logical rules interpreted statements domain general tuned specifically 2person alternating games In fact ICL tuned particular application built predicates syntax logic This mean Gala natural games designed believe general language useful general specification decision problems uncertainty 7 Conclusion This paper presented logic allows arguably natural specification multiagent decision problems There simple semantic framework terms possible worlds semantics It lets use logic specify dynamics world retaining elegance generality game theory What adding game theory objectlevel representation domain We axiomatise actions moves affect world utility derived simpler components sensors work All axioms interpreted simple logic It allows represent probabilistic dependencies domain way influence diagrams provide intuitive representation problems decision trees 22231 We allow form parametrized rules use logical variables allow construct large game trees smaller components We adding influence diagrams ability represent multiple agents ability represent I7 structured probability decision tables way dynamic construction influence diagrams similar motivation Breese 91 having logic programs objectlevel statements world metalevel Breese We allow designer axiomatise dynamics sydem instead having summarize single step probability distribution We adding logic new way handle think nondeterminism uncertainty Rather disjunction subtle range forms uncertainty need handle provide mechanism I7 In papers structure exploited computational gain 38411 54 D PooleArticial Intelligence 94 1997 756 different logical formalism choices independence handle uncertainty We argue considering right way think uncertainty terms independent agents making choices The ICL weaker mixes logic decision 192024 added probability general cope different disjunction choices agents The goals paper different investigating way viewing uncertainty representations question agents We looking world simpler Whether succeeded state independence forms uncertainty modelling decisions assumptions assumptions different ways open theory modelling agents 3 rich logic They Conspicuous absence paper discussion In 1 building situated agent embodies computation harder 2 simulating propositional mean things policy environment authors web page l8 It noted second finds expected utilities strategies context computation strategy Prolog implementation finding Nash equilibria case exponentially dynamic programming problem representation representation There easier decision problem 53841 structure There problems algorithms computational singleagent perfect 3 finding optimal strategy A available complexity recall work forgetful agent 541 This It clear solve presented makes solving rules work exact approximate represented representation influence diagram formalism makes problems difficult evidence influence diagram earlier decisions exploit problems difficult decision independently ICL Intuitively solve solve 25 Acknowledgements Thanks Craig Boutilier This work supported Institute Natural Sciences OGP0044 12 1 Holger Hoos detailed comments paper Robotics Intelligent Systems Project IC7 Engineering Research Council Canada Operating Grant References l JS Albus Brains Behavior Robotics BYTE Publications Peterborough NH 1981 2 KR Apt M Berem Acyclic programs New Generafion Comput 9 1991 335363 3 E Bacchus Representing Reasoning Uncertain Knowledge MIT Press Cambridge MA 1990 4 F Bacchus AJ Grove JY Halpem D Keller From statistical knowledge bases degrees belief ArtiJcial InteZZigence 87 1996 75143 ftplogosuwaterloocapubbacchus 51 C Boutilier R Dearden M Goldszmidt Exploiting structure policy construction Proceedings IJCAI95 Montreal Que 1995 1104l 111 lx httpwwwcsubccaspiderpoole D PooleArtificial Intelligence 94 1997 756 55 6 C Boutilier N Friedman Nondeterministic Working Notes AAAI Theories Actions Formal Theory Practical Applications actions frame problem Spring Symposium 1995Extending 199 71 C Boutilier N Friedman M Goldszmidt D Keller Contextspecific independence Bayesian E Horvitz E Jensen eds Proceedings 12th Conference Uncertainty Articial networks Intelligence CIAI96 Portland OR 1996 115123 81 C Boutilier D Poole Computing optimal policies partially observable decision processes compact representations 9 JS Bmese Construction lo RA Brooks A robust layered control mobile robot IEEE I Robotics Automation 2 1986 Proceedings AAAI96 Portland OR 1996 1168l 174 belief decision networks Comput Intell 8 1992 624647 1423 111 KL Clark Negation failure New York 1978 293322 H Gallaire J Minker eds Logic Databases Plenum Press 121 TL Dean K Kanazawa A model reasoning persistence causation Comput Intell 5 198 142150 131 TL Dean MI Wellman Planning Control Morgan Kaufmann San Mateo CA 1991 141 D Draper S Hanks DS Weld Probabilistic contingent Proceedings 2nd International Conference AI Planning Systems Menlo Park CA planning information gathering execution 1994 3136 15 RY Fagin JY Halpem Y Moses MY Vardi Reasoning Knowledge MIT Press Cambridge MA 1994 161 J Forbes T Huang K Kanazawa S Russell The BATmobile PFoceedings IJCAI95 Montreal Que 1995 18781885 Bayesian automated taxi 171 D Fudenbetg 181 M Gelfond V Lifschitz The stable model semantics J Tiiole Game Theory MIT Press Cambridge MA 1992 logic programming R Kowalski K Bowen eds Proceedings 5th Logic Programming Symposium Cambridge MA 1988 10701080 191 P Haddawy Representing Plans Uncertainty A Logic Time Chance Action Lecture Notes Artificial Intelligence Vol 770 Springer Berlin 1994 20 JY Halpem An analysis firstorder 1211 JY Halpem MR Tuttle Knowledge probability 22 RA Howard From influence relevance knowledge logics probability Artificial Intelligence 46 1990 31 l350 adversaries J ACM 40 1993 917962 RM Oliver JQ Smith eds Influence Diagrams Belief Nets Decision Analysis Wiley New York 1990 Chapter 1 323 Influence diagrams JE Matheson RA Howard J Matheson 23 RA Howard eds The Principles Applications Decision Analysis Strategic Decisions Group CA 198 1 720762 241 K Kanazawa A logic time nets probabilistic inference Proceedings AAAI91 Anaheim CA 1991 360365 251 D Koller N Megiddo The complexity Economic Behavior 4 1992 528552 twoperson zerosum games extensive form Games 261 D Koller AJ Pfeffer Generating solving imperfect information games Proceedings IJCAI 95 Montreal Que 1995 1185l 192 27 R Kowalski Logicfor Problem Solving Artificial 28 HJ Levesque R Reiter Y Lesperance E Lin RB Scherl GOLOG logic programming Intelligence Series NorthHolland New York 1979 language Action Change J Logic Programming Special Issue Reasoning dynamic domains 1996 291 DG Luenberger Introduction Dynamic Systems Theory Models Applications Wiley New York 1979 301 J McCarthy Applications circumscription formalizing commonsense knowledge Art1 Intelligence 28 1986 89l 16 3 11 J McCarthy PJ Hayes Some philosophical intelligence B Meltzer D Michie eds Machine Intelligence Vol 4 Edinburgh University Press Edinburgh 1969 463502 standpoint artificial problems 321 RB Myerson Game Theory Analysis Conflict Harvard University Press Cambridge MA 1991 331 NJ Nilsson Logic artificial intelligence Artificial Intelligence 47 1991 3 l56 56 D PooieArtcial Intelligence 94 1991 7X 341 RM Oliver JQ Smith eds Influence Diagrams Belief Nets Decision Analysis Series Probability Mathematical Statistics Wiley Chichester 1990 35 J Pearl Probabilistic Reasoning Inielligent Systems Networks Plausible Inference Morgan Kaufmann San Mateo CA 1988 1361 D Poole probabilistic Horn abduction Bayesian networks Arricial rnrelligence 64 1993 81129 37 D Poole Abducing negation failure stable models independent choice logic Tech Rem Department Computer Science University British Columbia Vancouver BC 1997 ftpftpcsubccaftplocalpoolepaperslabnafpsgz 138 J D Poole Exploiting rule structure decision making independent choice logic P Besnard S Hanks eds Proceedings 11th Conference Uncertainty Artificial Intelligence IAI95 Montreal Que 1995 454463 1391 D Poole Logic programming robot control Proceedings IJCAI95 Montreal Que 1995 150157 40 D Poole A framework decisiontheotic pIanning 1 combining situation calculus conditional plans probility utility E Horvitz I Jensen eds Proceedings 12th Conference Uncertainty Artijiciul Intelligence UAI96 Portland OR 1996 436445 41 D Poole Probabilistic partial evaluation exploiting rule structure probabilistic inference Proceedings IJCAI97 Nagoya Japan 1997 ftpftpcsubccaftplocalpoolepapepapsgz 1421 D Poole AK Mackworth RG Goebel Computational Intelligence A Logical Approach Oxford University Press New York 1997 43 TC Przymusinski Threevalued nonmonotonic formalisms semantics logic programs Articiul lnrelljgence 49 1991 309343 44 ML Puterman Markov decision nrocesses DP Hevman MJ Sobel eds ffndboo Operations Research tenement Science Vol 2 NighHolland Amsterdam 1990 Chapter 8 331434 R Reiter The frame problem situation calculus simple solution completeness result goal regression V Lifschitz ed Artijcial Intelligence Mathematical Theory Computation Papers Honor John McCarthy Academic Press San Diego CA 1991 359380 RL Rivest Learning decision lists Machine Learning 2 1987 229246 SJ Rosenschein LP Kaelbhng A situated view representation control Artificial Intelligence 73 1995 149173 SJ Russell D Subranian Provably boundedoptimal agents J Art Zntelf Res 2 1995 5X609 LJ Savage The Foundon Statistics Dover New York 2nd ed 19720 LK Schubert Monotonic solutions frame problem situation caJculus efficient method worlds fully specified actions HE Kyburg RP Loui GN Carlson eds Knowledge Representation Defeasible Reasoning Kluwer Academic Press Boston MA 1990 2367 Y Shoham Agentoriented programming Artijicial Intelligence 60 1993 5192 JE Smith S Holtzman JE Matheson Structuring conditional relationships influence diagrams Oper Res 41 1993 280297 J von Neumann 0 Morgenstem ieory Games Economic Behavior Princeton University Press Princeton NJ 3rd ed 1953 L Zhang R Qi D Poole A computational theory decision networks International J Approximate Reasoning 11 1994 83158 Y Zhang A foundation design analysis robotic systems behaviours PhD Thesis Department Computer Science University British Columbia Vancouver BC 1994 Y Zhang AK Mackworth Will robot right thing Proceedings 10th Biennial Conference Canadian Society Computfltionf Studies fnteliigence Banff Aha 1994 255262 Y Zhang AK Mackworth Constraint nets semantic model hybrid dynamic systems Theoret Comput Sci 138 1995 211239 1451 1461 1471 481 t491 l501 l511 f521 t531 I541 1551 L561 1571