Artificial Intelligence 105 1998 209261 Artificial Intelligence Multiple perspective dynamic decision making Tze Yun Leong Medical Computing Laboratory Department Computer Science School qf Computing National University Singapore Lower Kent Ridge Road Singapore 119260 Singapore Received 15 September 1997 received revised form 17 April 1998 Abstract Decision making involves deliberations acquisition discourse This work presents general paradigm views support knowledge inference decision making time uncertainty Baaed unifying vocabulary model transparency solution efficiency relevant decision problems current decision frameworks representation new paradigm balances multiple perspective task definition common tradeoff different perspectives Distinct perspectives types stages suitable different language design DynaMoL support modeling The new paradigm motivates modeling solving dynamic decision problems The DynaMoL inferential representational Dynamic decision Modeling Language frame general task solution work differentiates computation task The dynamic decision grammar defines extensible decision ontology supports complex problem specification multiple interfaces The graphical presentation conven tion governs parameter visualization formal model analysis admits multiple solution meth semiMarkov decision process facilitates ods A set general translation devised manage different perspectives rep resentations decision parameters constraints DynaMoL evaluated prototype implementation comprehensive case studies medicine The results demonstrate practical promise framework 0 1998 Elsevier Science BV All rights reserved multiple perspectives The mathematical representation techniques Keywords Decision making Knowledge representation Multiple perspective reasoning Probabilistic reasoning Temporal reasoning SemiMarkov decision processes 1 Introduction Dynamic decision making concerns problems explicitly considered For example common medical decision time uncertainty choose optimal Email leongtycompnusedusg 0004370298 matter 0 1998 Elsevier Science BV All rights reserved PII SOOO4370298000824 210 7 K Leong Artijicial Intelligence 105 1998 209261 course treatment common investment decision fluctuating market factors time financial patient physical determine conditions vary time optimal portfolio respect Reasoning dynamic decision problems information different perspectives viewpoints For instance stage problem delibera states patient tion essential stage illuminating uncertain effects treatment lead different physiological possible physiological consider estimate integrating involves states intelligence solving support different Research control theory operations research decision analysis artificial techniques formulating led AI disciplines analyzing dynamic decision problems They adopt different assumptions ontologies different strengths weaknesses One major difficulty dynamic decision making simple parameterized models Many assumptions resulting models The limited decision vocabulary contributes obscures model transparency Moreover current perspective presentation influence diagrams 37 decision decision problem The respective strengths different different stages decision addressed integrates supports different representational factors fit complex decision implicit solution efficiency support single frameworks fixed vocabulary graphical instance analysis In decision frameworks best suited In AI efforts solution analysis levels abstraction None frameworks decision models conform framework trees 60 provide alternate perspectives issues reasoning multiple specific constraints formulation convention reasoning views 11 Research objectives approaches introduces reason general addressing new paradigm dynamic decision making We present methodology extension Multiple This work uniform way common vocabulary supports multiple perspective perspective different ways facilitates effective modeling analysis dynamic decision problems Incremental use translators gradually expanded class dynamic problems We language allows scope dynamic decision problems addressed reasoning allows modeler visualize examine language extension provides framework customized information decision problems incremental reasoning The proposed methodology motivates language design called DynaMoL tradeoff model transparency Dynamic modeling decision Modeling Language To balance solution efficiency requirements The relevant support modeling correspondences relevant support action wellformed model relationships solution We evaluate DynaMoL prototype studies medicineWe demonstrate DynaMoL design differentiates task solution computation representational inferential task facilitates specification decision parameters computation task accelerates task derivation constraints optimal course implementation comprehensive expressive case handle class DynaMoL I E hong ArtiJicial Intelligence 105 1998 209261 211 reallife dynamic decision problems We claim proposed methodology general effective techniques The exercise illuminates proposed methodology motivates new generation dynamic decision making tools techniques practical use existing 12 Guide paper This paper organized follows Section 2 describes class dynamic decision multiple decision dynamic reasoning addressed main concepts desiderata multiple perspective decision problems design DynaMoL work Section 3 introduces language Section 4 presents domain background framework Section 5 case study Based examines syntax semantics language Section 7 discusses problems perspective modeling sketches case study Section 6 describes decision model formulation DynaMoL translated consistency different perspectives solution maintained process Sections 8 9 briefly examine design methods analyses supported language Section 10 illustrates prototype applying documents different dynamic decision problems compares It examines research Finally Section 12 summarizes methodology related work proposes ideas future research general AI decision making experiences practical domains Section 11 limitations work methodology translation achievements implications DynaMoL DynaMoL 2 Dynamic decision making uncertainty overview 2 I The dynamic decision problem The general dynamic decision problem environment The main distinguishing objectives problem action decision points objective measures specified respect time horizon Fig 1 depicts factors involved static explicit reference dynamic decision problem time The environment satisfies feature dynamic decision description select course action This work addresses dynamic decision problems following properties l The time horizon l The environment defined set discrete time points comprises discrete phenomena A patient sick day treated robot grasp halffull finite set discrete reasonably assumed l There finite set discrete actions These actions contextdependent varying preconditions A patient carried patients physical conditions permit usually respect environment time open heart surgeries surgery l Each action finite set discrete reasonably discrete effects moving current position robot gets closer target position The patient previously After treatment forward assumed sick 212 T E hong Artificial Zntelligence 105 1998 209261 t Objective measure t6 j 4 Objective measure t t Objective measure t6 Fig 1 A dynamic decision problem nature effects uncertain A treatment cures disease leads undesirable time effects occur uncertain A patient cured peptic ulcer relapse sooner patient sideeffects Moreover l The effects action measurable desirability Such measure multi dimensional hospital versus staying staying home sick time separable total desirability calculated summing functions time desirability desirability Given initial environment optimizes stages stages vary duration expected desirability problem solved choosing course action potential effects The decisions 22 Current approaches The major approaches addressing class dynamic decision problems described include following 221 Markov semiMav decision processes Markov decision processes MDPs mathematical models sequential optimization 64 Bellman state structure In 1950s research MDPs Howard decision processes MDPs Much progress occurred 3 formalization semiMarkov results formulation problems stochastic began ideas Shapley 34 Jewel1 39 extended SMDPs general extending 59 The small simple vocabulary assumptions formidable constraints directly formulate basic mathematical definitions improving involved algorithms methodology necessitates optimization implicitly incorporated complex dynamic decision problems renders practice 2 Y Leong Artcial Intelligence 105 1998 209261 213 instance Markov semiMarkov In medicine survival prognosis analyses MDPs SMDPs seldom applied directly decision making processes clinical 38 222 Dynamic decision analysis Emerging 1960s operations theory normative analytical optimal course action gain constructing research game theory 60 decision analysis technique risk uncertainty Based probability useful decision making framework helps decision theory utility complex maker determine analyzing graphical decision model decision situation systematically 36 In recent years new decision analytic deal dynamic decision problems These include dynamic influence diagrams 70 Markov trees 32 based structural semantical cycEe trees 233 stochastic extensions conventional trees mathematical decision models influence diagrams decision definitions stochastic processes formalisms devised insights Dynamic decision analysis widely real world applications For instance common difficult intensive graphical structures tool clinical decision making apply In particular model formulation 40545657 Nevertheless knowledgeintensive restrict admissible solution methods methodology labor 44 223 Planning artijicial intelligence theorem proving AI planning Motivated studies human problem emerged 26 Early research logical et al 51 Fikes Nilsson reasoning complete deterministic imperfect planexecution planning gaining attention extends algorithms frameworks information 122547 52 operations solving research 1960s works Newell area focuses representing introduces information Recent progress planning ontology improves 69 Analytical studies theoretical terms expressiveness plangeneration complexity foundations planning algorithms applied AI planners 75 OPlan 13 difficult 48 While generalpurpose fixed planning vocabularies As compared The AI planning works modest impact realistic applications systems specialpurpose practice use SIPE partly complexity problems 20 The impracticality planning problems encode domaindependent addressed partly difficulty MDP heuristics solution algorithms operate directly fully specified set actions states AI planner allows flexible expressive probabilistic action problem descriptions instance effects relevant partial plans hierarchical 20 Such expressiveness constraints facilitates complicate search control optimal solutions representation represented syntactic abbreviations formulation highly complex problems task network HTN planning significantly actions In hierarchical relationships 214 TY Leong Artificial Intelligence IO5 1998 209261 planning 224 Recent development decisiontheoretic planning In late 1980s research efforts decisiontheoretic different approaches described stochastic domain techniques involves planning works DTP based semantic computational The major focus DTP research solutions approximation evaluate potential plans achieving goals 2343 restricting state space allowing existing MDPs solution reduced problems 221 action space 3 1 reduce search space optimal plans DTP began integrate The general DTP problem action effects uncertain Most framework MDPs 16 speeding computation optimal include probabilities search local regions applied 11967 abstraction aggregation state space 717 techniques Relevant approaches techniques DTP frameworks usually employ compact structured representations common MDPs For instance problem components action effects adopted frameworks 43 More general expressive definitions state space 30 utility functions adopted goal descriptions 63074 involved The expressive frameworks mainly aim support search control optimal solutions planning problems usually secondary concern probabilistic STRIPSlike operators representations facilitate representation uncertain formulation 23 A uniform task dejinition The major tasks problem dynamic decision making uncertainty solution analysis These tasks iterated times given formulation problem 231 Problem formulation involved Formulating constraints dynamic decision problem begins specifying type problems different decision parameters In optimization problems actions strategies compared optimal course action include alternative actions strategies possible state transitions uncertain events constitute relevant probability distributions respect time Examples state transitions decision constraints conditions actions validity conditions states logical relationships determined Examples decision parameters states uncertain events terms effectiveness include applicability In discriminatory problem The formulation task guided decision ontology vocabulary following constraints decision ontology defines accurately specify situation defining characteristics l Expressiveness parameters organization decision ontology include actions states basic concepts temporal basic relations include uncertain events dependences probabilistic decision ontology represent actions dependences individual concepts support reasoning classes actions types decision factors interrelationships relevant For example determines Similarly TY Leong Artificial Intelligence 105 1998 209261 215 decision ontology determines l Succinctness parameters decision states dynamic decision problem explicitly enumerated state descriptions situation For example constraints factored relevant conditions attributes easily specify SMDPs AI planning information decision ontology involved l Transparency comprehend necessarily needed specify small piece knowledge easily information An ontology simple syntax semantics imply transparent succinct expressions reflects efficiently draw inferences decision situation 232 Problem solution The solution conditional wellformed objectives A closedloop dynamic decision problem solution solves problem respect possible initial points SMDP An openloop solution solves problem respect initial point specific end point plan generated classical AI computational model wellformed model need know optimizes decision situation possible end points policy determined employ specific planner manipulates information organization starting state goal state A solution method course action observation arises place decision information feedback situation 233 Problem analysis Both formulation solution dynamic decision problem require ensure accuracy sensitivity involved analysis sensitivity Structural clarity Sensitivity sensitivity analysis decision parameters constraints relevance numerical qualitative relevant alternatives sensitivity includes affect choice value decision divided reflected problem threshold analysis stochastic analysis ensures uncertain involved objectives adjustments reflected information sensitivity quantitative structural adjustments framed correctly events specified properly Numerical reveal uncertain information involved events 24 The application domain test therapy planning work general tests treatments combinations issues address diagnostic involve domain application While medicine The relevant dynamic decision examine risk adverse events continue vary time problems uncertain The relevant actions events recur timing recurrences comprises diagnostic include physical conditions physiological lead states For instance patient state stroke cerebral hemorrhage caused stroke Some events effects actions The decision objectives usually life expectancy include prolonging maximizing states patient observable unobservable patient class patients These conditions The environment costeffectiveness actions patients events 216 T Y Leong Artid Intelligence 105 1998 209261 3 Multiple perspective reasoning Decision making involves deliberations tives views support knowledge acquisition representation stages inference support visualizing spectives Different ways frameworks display decision parameters constraints discourse Many decision making different perspectives Distinct perspec suitable different types frameworks provide specific graphical different information 31 Advantages disadvantages different perspectives To illustrate tives consider strengths weaknesses visualizing following example different graphical perspec Example A patient states WELL SICK DEAD A doctor decide treatments A B different effect patient WELL SICK state The patient stick course treatment repeated initial success rate treating treatment fails improve patients condition fixed period treatment decision Treatment B hand cause complication C sick patient disease patient die immediately times Treatment A higher Fig 2 illustrates structural representations transition diagram MDP b dynamic c Markov cycle perspective perspective explicates different point view Problem conducted respect chosen perspective tree Each representation solution problem Markov state influence diagram finite time period specific problem projects level problem structure different analysis framework 3 I 1 State transition diagram In state transition diagram associated function transition functions denote defined state diagram nodes denote possible states arcs transitions given action A value As shown Fig 2a state transition diagram explicitly transitions given au action The diagram reflect complication C treatment B occur state transitions shows possible state events uncertain 312 Dynamic In dynamic injuence diagram influence diagram squares represent circles value nodes The number end chance nodes diamonds considered The arcs node indicates arcs leading leading chance node value node list possible values outcomes node chance value nodes indicate probabilistic decision nodes dependences dependences Embedded decision stage decisioneventvalue decision nodes informational indicate T Y Leong Artijicial Intelligence 105 I 998 2OS261 217 State transition diagram Treatment A State transition diagram Treatment EI Keys q Decision node tevdaaode n Complications 0 Chance node __ Pmbablllstk lnftuence 0 v wdttlonal dependence Vaue node Markov cycle tree Treatment A Markov cycle tree Treatment 8 Keys Markov node Branches emanating states 1 State node 0 Chance node Probabilistic conditional dependence Fig 2 Representation influence diagram c Markov cycle trees simple decision problem Markov state transition diagrams b dynamic conditional probabilistic predecessors Well Sick Dead S Complication CT No complication C C table probabilities decision node list alternate predecessors shows sequential structure decision problem capture varying uncertain events inbetween particular relations state transitions But possible patterns state transitions general kept chance outcomes andor decision alternatives treatments list informational influence diagram explicitly Fig 2b dynamic As shown embedded 218 ZYS Leong Artijicial Intelligence 105 1998 209261 table entries embedded reflect treatment B lead complication C nodes For instance structure diagram 313 Markov cycle tree In Markov cycle tree branches emanating stage given action The intermediate possible outcomes probabilistic represent states beginning root node called Markov end nodes chance nodes events happen root leaves cycle tree dependencies uncertain associated branch tree A value function node leaf nodes respectively decision arcs indicate nodes All possible combinations state transitions represented A conditional defined state diagram probability As shown Fig 2c Markov cycle tree explicitly shows possible state transitions depicts given action reflects uncertain events inbetween asymmetric relations chance outcomes decision alternatives For instance complication C occur sick patient treatment B prescribed The uncertain events tree extremely complex vary time represent mixture sequential actions effectively state transitions state transitions 32 Desiderata integrated decision language Based observations postulate decision making provide representational tasks involved balancing efficiency In particular language satisfy following desiderata tradeoff model transparency effective inferential language dynamic support different solution l The decision ontology address wide range issues typical dynamic decision expressive organization components problems The language succinct transparent l The language formal theoretical basis simple rigorous syntax formal semantics These qualities facilitate examining properties problems solutions analyzing l The language support multiple user deal mainly relevant ontological mathematical definitions reasoning levels abstraction concepts instead specific l The language support graphical multiple perspectives constraints Visualization viewing making providing perspective natural multiple perspectives It analogous decision visualization different reflects common pattern parameters levels abstraction human decision world different pairs lenses particular task incrementally additional l The language incorporating constraints Adaptation constructs l The language A practical necessarily support language implementations modular comprehensive language constructs involves changes extensible adaptable Extensions involve new types decision parameters language organization affect expressiveness language practical use explicit lYK L_eong Artificial Intelligence 105 1998 209261 219 4 DynaMoL language The DynaMoL design motivated indepth analysis existing frameworks 44 previous section In section explain features Detailed definitions design language based desiderata outlined design approach summarize presented Sections 69 4 I Design approach To address transparencyefficiency tradeoff representation problems highlevel inference support modeling It incorporates general language modeling idea programming object language execution DynaMoL design aims separate solving dynamic decision translating language design The language comprises components graphical presentation mathematical extensible decision ontology supports complex problem interfaces multiple perspectives analysis admits multiple devised manage different perspectives representations constraints dynamic decision grammar defines specification multiple formal model techniques convention governs parameter representation SMDP facilitates translation decision parameters solution methods set general visualization language defined convention The semantics dynamic decision grammar bridges grammar defined mathematical presentation SMDP translations The syntax graphical presentation representation mathematical In DynaMoL representation formulate examine dynamic decision model terms solution highlevel decision grammar different graphical visualization high level model translated analysis formal mathematical representation perspectives 42 Basic decision ontology We adopt knowledge formalization approach similar 27 In DynaMoL conceptualization relevant decision parameters interrelationships define expressions FOPC presented includes conceptualization components basic concepts variable conceptsfunctions DynaMoL firstorder predicate calculus decision situation Based terms following relations constraints 421 Basic concepts A basic concept partial description decision situation single point time l An event describes property phenomenon There types basic concepts events actions states It corresponds proposition t In clinical context presence form Pr unary predicate P constant complication C absence complication C number stroke patient suffered 2 I number stroke patient suffered examples events expressed propositions 220 lYE Leong Artcial Intelligence 105 1998 209261 ComplicationCPresent ComplicationCAbsent Numberofstrokel Numberofstroke2 respectively An action externally include different events controlled phenomenon involves tests treatments single relevant conjunction actions Test A Treatment B Test X followed Treatment Y The effects action terms events sideeffect prescribing Treatment B event expressed c These actions effects expressed presence complication propositions conjunctive propositional actor In clinical combinations It corresponds sentences context TestA TreatmentB TestXTreatmentY ComplicationCPresent respectively l A state describes phenomenon properties relevant overall decision ob jectives brought performing certain actions It corresponds special events called state attributes For instance clinical decision problem expressed conjunctive propositional conjunction state WELL typical sentence VitalstatusAliveDiseaseXAbsent DiseaseYAbsent Every state associated utility value indicating state desirability 422 Variable concepts A variable concept represents uncertainty partial description decision function form probability situation single point time It corresponds Px unary predicate P variable x FOPC random variable theory There types variable concepts chance variables action variables We consider discrete variables propositional An instantiation work chance variable FOPC outcome event state defined earlier Each outcome occurs chance A chance variable chance node decision model There types chance interpretation interpretation probabilistic possible corresponds variables instantiation Event variable The possible events For instance instantiations number stroke patient suffered outcomes event variable Z Y Leong Artificial Intelligence 105 1998 209261 221 denoted atomic sentence Numberof Numberofstrokel event variable strokex possible instantiations Numberof stroke 2 random variable Numberofstroke possible outcomes x 1 2 x ii A state attribute variable special kind event variables represents states The possible characteristic property directly relevant describing instantiations outcomes state attribute variable state attributes special events Given set variables state usually defined terms Cartesian product outcomes Some heuristics reduce number resulting states For instance state patient described WELL SICK DEAD defined terms vital status alive dead disease X present state attribute variables absent disease Y present absent state WELL canbeexpressedas theconjunctionofthe al state attributesVit statusAliveDiseaseXAbsentDiseaseYAbsent uncertainty state space SMDP influence diagram time point possible outcomes state variable clinical decision problem reachable single point time It corresponds state variable node dynamic All outcomes state variable states For example instantiations states patient WELL SICK DEAD In particular mentioned actual state iii A state variubZe represents action variable interpretation b An action variable denotes decision choice point single point time An FOPC interpretation alternative action defined earlier An action variable action space SMDP decision node instantiation probabilistic corresponds decision model For example action variable denoted atomic sentence Treatment possible A Treatment variable Treatment x possible outcomes x A B clinical decision problem possible alternatives B random instantiations Treatment x 423 Functions There types basicfunctions A probabilityfunction function events andor transition characteristics probability mass function CDF The probability functions express PMF cumulative conditional states defined basic variable concepts distribution probabilities given action b A valuefunction measures desirability state decision situation cost life expectancy It different dimensions clinical context usually conditional action monetary 424 Relations There types basic relations defined basic variable concepts domain relation constants descriptions distinguished basic concepts Section 421 222 L E bong Artificial Intelligence 105 1998 209261 A probabilistic dependence notion conditionally ditional dependence concept rection probabilistic dependence conditional dependence complication C probabilistically state patient SICK relation probability theory Such relation dependent given decision situation The di concepts corresponds indicates relation reflects definition underlying temporal implication For example presence dependent action Treatment B b A temporal dependence relation concepts indicates precedes causal implication For example t temporally dependent state variable time t 1 temporally state variable time 425 Constraints A constraint metalevel concepts quantification assumed quantification sentence applicable sentence relations functions descriptive prescriptive imposed logical actions E A states s E S time points t E T expressed defined It correspond constraint FOPC For instance condition VaVsVt Applicablea s t 43 Dynamic decision grammar DynaMoL The dynamic decision grammar defines structure dynamic decision model terms components components support multiple defining appropriate abstract grammar The grammar structures recursively defined similar manner The abstract grammar grammar extended implementations Moreover new constructs translators interface The complete dynamic decision grammar DynaMoL documented 45 contains following components l A finite set names constructs l A finite set productions associated construct defines construct model An example production follows Model Identifier contexts Contextlist de3nitions Dejinitionlist constraints Constraintlist solution Optimalitypolicy Each construct describes structure set objects called specimens construct The construct appearing righthand productions productions choice productions syntactic type specimens The constructstypes definition similarly defined different The structure construct terms aggregate constructs specimens comprising fixed number components specified list productions 7 E Lmng Artificial Intelligence 105 1998 209261 223 44 Graphical presentation The presentation convention constraints visualized graphical representations grammar displayed DynaMoL prescribes decision parameters determines information multiple perspectives The current convention includes established 441 Transition view The transition view given action depicts Markov state transition diagram corresponds Fig 3 node represents state condition associated utility value function Conditional action arc represents possible onestep defined arc govern transition characteristics state origin transition transition function possible state transition patterns It MDP framework As shown 442 Influence view An influence view given action shows nature uncertainties network specific decision factored Bayesian probabilistic state transitions state attribute variables corresponds conditional alternative slice dynamic state descriptions It corresponds involved relevant stage allows influence diagram stage represented DiseaseX disease X present NoX As shown Fig 4 node denotes event variable possible outcomes disease state variable state stage n stage n 1 states DiseaseY state definitions outcomes x X absent The state space decision The possible outcomes state variable states corresponding space outcomes state variable node S state decision nextstate variable node I event variables DiseaseX depicted Fig 3 In example state attribute variables following contribute WELL NoX NoY DISCOMFORT NoX Y SICK X DEAD Each arc dependence A conditional probability figure indicates conditional probabilistic distribution table associated node The diagram interpreted follows given action taken state origin decision stage n state patient decision stage n 1 conditionally dependent presence absence disease X presence absence disease Y characterized underlying conditional probability distributions state decision Fig 3 A transition view action 224 k Leong ArtQicial Intelligence 105 1998 209261 Fig 4 An influence view action Sick _ No X 07 Discomfort 1 o Dead NoY Well 03 10 B 4 Fig 5 A tree view action 443 Tree view The tree view given action decision tree expansion influence view It Markov cycle tree specific action It explicitly inbetween possible state transitions chronological manner shows uncertain depicts corresponds events asymmetric relations chance outcomes As shown Fig 5 nodes correspond event variables influence views arcs capture possible outcomes event variables probabilistic dependences root node S leaf nodes l In particular represent state I k Leong Artificial Intelligence 105 1998 209261 225 branches nodes variables decision denote possible associated outcome branch event variable conditional given action states andor events left event variable stages n n 1 respectively states corresponding stages A probability decision entry 45 Mathematical representation The central basis theoretical basis dynamic decision model SMDP idea supporting multiple perspective different views aspects decision reasoning establish common In DynaMoL situation Briefly SMDP mathematical model sequential decision process An SMDP time index set T action space A state space S following basic components set onestep transitionfunctions probability mass functions PMFs qm t functions CDFs Qm cumulative distribution j E S E A t E T m O 123 reflected duration m transition governed onestep MDP SMDP constant destination intertransition A solution SMDP optimal policy state j transition time lapsed functions An transition times time unit m 1 guideline choosing optimal possible evolutions states maximize t set valuefunctions vm The stochastic nature transitions actions decision horizon expected value reward Many solution methods available SMDPs 46 Translation convention Two types translation involved coordinating multiple perspective reasoning model interlevel interlevel translation DynaMoL translation interperspective translation dynamic SMDP The model involve constructs rules employed In translated SMDP A set translators correspondence correspondence The general idea map construct set constructs entity relation Interperspective hand establishes mathematical representation translation specified decision grammar defining proper establish grammar translation representational formats Since different perspective constructs different perspectives For example view corresponds corresponds state space transition view root node branches defined terms covering correspondence information involved inter set representation state variable influence tree view 47 Dynamic decision making DynaMoL Dynamic decision making DynaMoL iterative process involves repeating problem l The dynamic decision problem formulation problem solution problem analysis formulated dynamic decision model The model specifies relevant decision parameters constraints preferences involved including uncertainties interleaving tasks 226 TZ Leong Artificial Intelligence 105 1998 209261 l The dynamic decision model solved respect evaluation optimal criterion derive optimal policy course action l The model solution analyzed ensure correctness formulation robustness results In sections discuss modeling solution analysis processes DynaMoL framework case study medicine 5 A case study Atrial fibrillation major undesirable formation blood clots AF occur Both frequency fibrillation develops eventually AF kind cardiac arrhythmia abnormal heartbeat It sudden periodic episodes length AF episodes increase time constant embolization paroxysms hemodynamic deterioration sideeffects AF management involves antrhythmic restore normal sinus rhythm Because risk embolization warfarin aspirin prevent blood clot formation treatments corresponding antiarrhythmic cause excessive bleeding turn lead strokes death control heart rates atria The In particular common risk sudden death anticoagulant agent Quinidine anticoagulants sideeffects undesirable increases agents The case question based actual clinical consult TuftsNew England Medical Center Boston Massachusetts The patient history paroxysmal AF He warfarin Quinidine The clinical decision problems follows 52year old white male Question 1 Quinidine decreases decreased risk embolic complications proportion time patient spends AF Does justify increased risk sudden death Question 2 What optimal course treatment account treatment relative risk bleeding varying warfarin respect years taking duration theoretical capabilities illuminate practical DynaMoL The case study aims modeled solved handle actual dynamic decision problem framework The original clinical consult addresses Markov cycle tree clinical exact qualitative quantitative parameters model existing frameworks adopted important For ease exposition formulate dynamic terms single dynamic decision model sets slightly limitations clinical question framework To DynaMoL medicine adhere closely question reusing appropriate To DynaMoL offers additional focus illustrating second clinical question problem decision problems different numerical parameters clinical significance data assumptions original clinical consult computational features involved ontological addressing addressing flexibility We assess effectiveness DynaMoL problem respect criteria First demonstrate modeling solving dynamic decision relevant decision ZI Leong Artial Intelligence 105 1998 209261 227 solutions constraints expressed parameters compare domain experts Third conduct behavior parameters ensure interpretation analysis reasonable case study documented analysis solutions sensitivity involved The detailed discussion 45 data results actual clinical consult clinical judgment DynaMoL ontology Second 6 Model formulation DynaMoL Model formulation I Specify problem 2 Define alternative actions states involved 3 Conditional typically comprises action type duration optimality evaluation criteria following tasks identify possible progression patterns significant states final outcomes values achievable values difficult transitions 4 When states directly assessed uncertain relations effects actions specifying possible event variables constitute transitions identify 5 Identify special assumptions actions effects states impose relevant constraints decision parameters appropriate performing There strict order definitions change modeling In DynaMoL formulate dynamic decision model interfaces multiple perspective visualization dynamic decision grammar provide adequate direct support changes modeling process A major challenge involved The specifications implement tasks language 6 I Definition dynamic decision model A dynamic decision model DynaMoL wellformed complete model corresponds directly correspond The default optimality criterion wellformed SMDP optimality criterion Some model constructs underlying mathematical definitions need translated discounted total expected value finitehorizon Definition 1 Dynamic decision mode A dynamic decision model M DynaMoL lotuple criterion evaluation optima T A S E QE Z q K r l The decision horizon time index set T 0 123 denotes time frame decision problem l The action space A al a2 aAI denotes set alternative actions considered l The state space S SI 2 slsl denotes set states conditions affect value functions actions place l For action E A actionspecific event variable space E el e2 eE I effects The event vari set event chance variables constitute denotes able space E UucA E denotes set event variables actions 228 I Y hong Articial Intelligence 105 1998 209261 l Each event variable e associated event outcome space L WI O_Q Wk k 1 denotes set possible outcomes e The actionspeczic event space DE overall event space DE Simihrly defined l Conditional action set possible transitions 8 ta j t 1 j E S E A t E T defined states A transition action E A time t E T denotes nature accessibility relation 6 A x S x S x T states j E S given j given t The PMF characterized onestep transitionfinction accessibility q CDF Q defined SMDP action set probabiEistic l Conditional influences x y t 1 E influence A x y E Ear t E T defined event variables A probabilistic variables X y E Ea given action E A time t E T reflects dependences variables time t action conditional probabilistic outcomes event relation q G A x E x E x T event l Conditional action respect evaluation criterion set vaEue functions vm 1 E S E A m 0 12 defined states A value function u A x S x K IR determines E S state time duration m E K conditional action E A objective value achievable l The components subjected set general domainspecific sentence wellformed constraints K K 1 K C S U fiE U 3 U P U 0 n b 2 A constraint logical quantification formula K corresponds wff FOPC set translators l f set correspondence rules functions establish equivalence relations language constructs 62 Basic problem specication The basic characteristics dynamic decision problem determined follows 621 Problem type Both optimization An optimization problem problems discrimination solved constructing problems supported DynaMoL optimal policy puf S A t E T optimizing space A time t respect time index set T function state space S action An optimization problem compares independent effects actions stage best alternative problem action solution answers question decision Contrarily discrimination problem solved choosing best policy 75 na l E Leong Artcial intelligence 105 1998 209261 229 predetermined set singleaction involve single action entire decision horizon stationary policies n policies na aJLaaa kLn S E A function state space S optimizing action The main type discrimination problems delineates strategies combinations effects This formulation strategy incorporates embedded actions actions dependent controlled actions called explicit enumeration combinations question designates single action externally application pattern relevant state descriptions To solve problem action possible solution answers entire decision horizon best alternative strategy necessary The problem policies associating embedded controlled actions The dynamic decision problem case study formulated discrimination problem Four strategies discriminated 1 start drug warfarin administered 2 start warfarin stopped necessary 3 start Quinidine warfarm administered 4 start Quinidine The second dynamic decision problem warfarin warfarin stopped necessary case study formulated optimization stopped necessary stopped necessary problem The problem warfarin Quinidine strategic implications determine course optimal initial action start defined decision modeling problems support frameworks different extents Dynamic optimization Other dynamic support discrimination problems Without augmenting direct formulation optimization solution computational methods Markov cycle trees support direct formulation discrimination problems They support direct formulation optimization problems allow decisions values alternatives entire decision horizon formulation influence diagrams final stage comparing stages decision flags assumptions discrimination bindings structures 622 Decision horizon The decision horizon finite infinite A finite horizon long duration small time units approximated infinite horizon In case study decision horizon T 600 months 50 years dynamic decision problem 60 months 5 years second 623 Evaluation criterion The evaluation cost costbenefit evaluation additive The evaluation criterion QAW criterion unit life expectancy monetary ratio defined sets value functions More linear life expectancy case study qualityadjusted criterion involved The value functions assumed 230 I I Leong ArtQicial Intelligence 105 1998 209261 63 Structure specication DynaMoL currently remain unchanged behavior activities entire decision horizon An action assumes static action space static state space indicates single unit drugs The constituent involve activity administer action assumed simultaneous controlled In case study action space A NoDrug Quinidine actions constant decision stage consists involved The effects warfarm states state attribute variables vital status indicates indicates heartbeat pattern cerebral vascular strategies externally modeled embedded actions state descriptions The state space S includes defined patient accident indicates history obstruction blood flow brain result stroke temporary weakness warfarin eligibility affects applicability action warfarin warfarin status reflects status embedded action warfarin alive dead sinus rhythm terms following Conditional controlled action set value functions C defined states QALE achievable A value function v indicates given action chance In dynamic nodes directly strict Cartesian product outcomes chance nodes In Markov cycle trees state attribute variables captured frameworks involves influence diagrams influencing value nodes implicit state descriptions state attribute variables represented state time duration relevant bindings state space definition logical combinations bindings case study atria1 631 Modeling transition view Based state attribute variables total 20 states defined For instance relevant state AFSTRWNE indicates fibrillation AF history stroke STR eligible warfarin WNE patient Conditional controlled action set possible states Each transition C associated onestep transitions transition 8 defined function PMF qa CDF Q governing transition destination transition time remaining functions Transition transitions including state attributes Fig 6 transition view A simplified action specified directly links representing transition view action Quinidine action warfarin embedded related shown The transition view expresses following facts patient Quinidine l If patient determined l If patient determined warfarin warfarin ineligible warfarin later warfarin warfarin later ineligible l Once patient determined treatment warfarin ineligible warfarin considered ZI kong Artificial Intelligence 105 1998 209261 231 WAARlNOPF 6 WARfAR1NQN Fig 6 Transition view action Quinidine 632 Modeling influence view In transition view states assumed expressed specified directly At times fully observable terms state attributes specify difficult action effects partially observable interact complex manner Such effects modeled event variables effects fully observable functions transition transition functions directly especially unobservable probabilistic If action influences In case study event variable space E includes event variables indicating cerebral hemorrhage gastrointestinal presence absence thromboembolization bleeding patient survives action events probabilistically influence eligibility cerebral vascular accident turn define physiological patient Conditional event variables variables events occur Conditional state attribute variables warfarin states action set probabilistic absence probabilistic relation event influence defined directly event variable influence view Fig 7 shows influence case study The outcomes state variables nodes connected probabilistic view action Quinidine represented nodes named staten statenl different states defined model The state attribute variables represented nodes directly state variable node statenl While influence view incorporation probabilistic dependencies independence Given action conditional probabilities influences event variables state attribute variables specifications facilities separate independent given decision context need explicitly ly defined indicates conditional represented influencing injuences 633 Modeling tree view Operating set event variables probabilistic tree view imposes chronological relations Conditional probabilities outcomes event variables probabilistic view action asymmetric representing Fig 8 shows simplified version tree view action Quinidine showing simplified branches terminating Sri All subtrees grouped brackets attached states subtree branch triangles assumed lead directly case study In figure DEAD state branches influences influence defined directly tree branches dependences order explicit display 232 Z K hong Artificial Intelligence 105 1998 2OS261 Fig 7 Influence view action Quinidine WartarinOFF AFib WON TIA WarfOK Fig 8 Tree view action Quinidine directly preceding group subtrees order Asymmetries tree reflected subtrees attached selected groups preceding branches branches PDieTE 1 NoTe 0 zero conditional probabilities imposed ordering event variable nodes tree view obscure manipulate DynaMoL complex expansion The strictly actual relations render incorporates particular predecessor nodes filling influence view conditional partial tree view supports partial expansion focused specification event variable node expansion influence view In words partial involves distribution table corresponding chosen node tree view facilitates event variable node Z E Leong Artificial Intelligence 105 1998 20926I 233 Conditional distribution DieTE event variable distribution dieteNoDrug DistributionTable G721 Type DISCRETE Matrix G721 Pclr PEWSTR TRANSSTR TIA NOTE DIETE PDIEPERMSTR PDIETRANSSTR 000000 000000 NOTDIETE 1 PDIEPERWSTR 1 PDIETRANSSTR 100000 100000 Fig 9 Asymmetric relations represented influence view PermSTR DieTE PDIEPERMSTR TransSTR TIA NoTE NotDieTE 1 PDIEPERMSTR DieTE PDIETRANSSTR 1 PDIETRANSSTR NotDieTE 10 NotDieTE 10 Fig 10 A partial tree view event variable DieTE action NoDrug Consider piece knowledge patient chance thromboembolization stroke transient ischemic attack stroke permanent transient chance die stroke Fig 9 shows partial embedded influence view represents conditional distribution knowledge The asymmetry table involved tree structure The tree structure reflects logical flow represented The piece knowledge expressed relevant event variables shown Fig 10 In partial obvious knowledge directly Numerical functional probabilities terminating terminating partial tree view branches Only probabilities partial tree view expands tree view asymmetry specified branches relevant 234 I Y Leong Artcial Intelligence 105 1998 209261 64 Numerical parameters assessment The numbers value functions probability distributions associated variables relations usually assessed structure model place 641 Value function dejinitions vm The value function defined terms associated transition value functions vm possible transition state given action A transition value function vjim determines state j time duration m conditional action It components objective value achievable transition state yieZd rate yl entering transition independent absolute time t bonus b The yield rate indicates state time interval I I 1 bonus value achievable time 1 onetime value achievable takes place state 35 The value functions assumed Formally vm C qg m tvtm j E A j E S lm 3 0 Cqf j IJ m t 1 I yl b iJ j bleeding actions states transitions associated transitions bonuses currently specified respect transitions In case study adopt special case value function states absorbing shortterm morbidities yield rates bonus constant In words vm vij m myi bij E A j E S m 0 The yields specified states zero Bonuses negative individual case indicating adverse events occur presence stroke cerebral hemorrhage gastrointestinal instead In DynaMoL influence diagrams Markov cycle constituent value influence diagrams trees allow detailed bonus specifications bonuses functions usually contain yield rates fixed time intervals links relevant chance nodes value nodes incorporated adding influence associated Similarly outcome chance node indicating positive chance nodes A toll binding life months negative value associated outcome 025 qualityadjusted stroke Tolls added subtracted branches tree structure traversed This feature feasible forward induction based solution algorithms total expected value accumulated Markov cycle trees allow bonuses event variables Both dynamic toll structures In dynamic 642 Transition functions andprobabilistic specifying Some guidelines directly inuences onestep transition view DynaMoL corresponding estimation onestep influence views andor constituent event variables transition functions tree views instead functions transition documented SMDP 45 When direct parameters specified difficult terms conditional distributions ZY Lung Artificial Intelligence IO5 1998 209261 235 For distribution Markov case influence table matrix C associated event variable view entry Cx y conditional POJ I x tl subject c PIY I x tl 1 1 2 event variable y y E Sz column combination outcome events probabilistic x row index representing outcome predecessors y E A t E T The entry usually function probability event y decision stage given event x occurs action taken decision stage time t ft time indicates index representing Similarly tree view 1 2 hold conditional probability associated lie left branch outcome y E QY event variable y x index representing combination leading outcome events probabilistic y tree structure given E A t E T predecessors For semiMarkov terms constituent case ways assess onestep event variables Consider specifying transition functions PMFs onestep transition functions qzrl t The PMFs onestep transition functions defined terms transition probabilities pt holding time PMFs hm t lJ t PPthjm J lJ t aEA ijES tET m30 3 conditional transition probabilities pm t waiting time PMFs wfm t qpm J t pm J twpm I t E A 1 j E S t E T m j 0 t H 4 The approach corresponding 3 assess probabilities transition times respect transitions transition probability decide holding probability given 1 function In destinations ft time case interpret eventual probability event y outcomes y given event x occurs action taken decision stage time t The collection conditional distributions eventual influence view constitute Ft j E S E A t E T underlying SMDP transition probabilities In We estimate transition destination patient clinical context time duration spent current state depending destination probability 03 patient making undergone patient 02 month surgery 05 second month develop 03 month transition For instance surgery A develop complication B probability determines estimates mg time PMFs directly corresponding ho1 d approach complication transitions The second approach corresponding 4 decide waiting assess probabilities transition destinations respect waiting times times 236 Z K Leong Artzl Intelligence IO5 1998 209261 waiting probability given l function time PMFs state s E S We In case directly estimate f m t duration interpret time conditional probability event y outcomes y given event x occurs action taken waiting time m decision stage time t The collection conditional distributions transition probability influence conditional transition probabilities view constitute E A t E T m 3 0 underlying SMDP In clinical context estimates depending duration determines probability patient undergone month surgery 05 months 03 months probability second month 03 month time duration patient spends current state making transition transition destination For instance surgery A remain 02 patient develop complication B 06 month surgery 05 p m t j E S approach Validity established DynaMoL ontology future adequacy techniques appropriate Such techniques numeric relevance parameters determined incorporated In case study distributions derived statistical event usually reported terms yearly monthly following equation convert constant involved estimated medical tables life tables Since relevant data occurrence rates instead probabilities rate r probability literature t unit rate respect time unit decision horizon derive monthly probability rate t 1 12 yearly rate t 1 monthly In case study dynamic decision problem formulated Markov decision second semiMarkov decision problem Most numerical parameters problems For second problem assume relative rate warfarin varies duration m entering state s according problem identical bleeding function form A BepCm 6 A B C E I With respect distributions conditional We assume waiting bleeding This means patient warfarin sooner later corresponding transition probabilities relative warfarin functions duration m form indicated varying event variables conditional time PMFs states affected varying risk 6 likely transition state risk assess 65 Constraint declaration Definitions model components constraints K Many constraints domainspecific DynaMoL For instance conditional action E A absorbing zero value function example relevance particular set event variables outgoing inherent transitions definitions set general supported state E S states j E S A similar describing state transition described subjected l Y Leong Artificial Intelligence 105 1998 209261 237 conditional effects explicitly encoded dynamic decision model action These constraints imposed model construction definitions structural numerical parameters There constraints effects need explicitly inter interpreted disjunctive definition translations A major example specifying Bayesian networks Canonical models default strategies Bayesian network level interperspective partial ORgate event combinations The partial ORgate analogous model specifying detailed elicit complex reduce interaction noisyORgate interactions determined precisely probabilities 55 A common canonical need assessed canonical form disjunctive conditional distributions chance variables variables unavailable number conditional numerous devised facilitate conditional distribution specifications constraint general form The partial ORgate event variables Formally et Ve2VVeke elez constraint specification The constraining event outcome x ek constraining events e read et e2 ek e The constraint interpretation conditional distribution consequent event The imposed table event variable x events outcomes probabilistic predecessors x consequent With respect generalized noisy OR model developed Srinivas 65 55 special case partial ORgate different binary noisy ORgate described following manners First DynaMoL vocabulary function event variable space E function event space DE Second combination constraint combination subset predecessors partial imposed event variable predecessors constraint imposed event variable In DynaMoL user explicitly specify partial ORgate constraints terms set logical statements different event variables conditional distribution created The numerical instance want express patient stroke dies cerebral hemorrhage dies gastrointestinal This expressed partial ORgate constraint tables correct dimensions involved For dead dies natural causes dies bleeding labels automatically specified accordingly parameters shown The If Die DieTE DieCHM DieGIB DeadA event DeadA consequent status constraining status influence view shown Fig 7 restriction Numerical outcome state attribute variable vital events outcomes probabilistic predecessors vital restriction order expressed terms extra state attribute variables Additional grammar constructs actions currently translators similarly manage constraints incorporated directly corresponding DynaMoL 238 TZ Leong Artificial Intelligence 105 1998 209261 7 Model translation DynaMoL employs set translators extension Structural language automatically incremental perspective modeler work convenient modeling process translated numerical support multiple perspective effective perspective view stage parameters perspectives reasoning specified updated 71 Translating transition view SMDP consistently When completely correspond directly case Details model usually easily specified directly transition views interperspective translations constructs transition views definitions SMDP Hence special translators needed views transition views involved components translating specified Once translated transition view reversed translation influence view information structural numerical transition functions tree view supported This influence view tree view compiled aggregated transition view If transition recovered respect original functions subsequently changed loss information influence view tree view 72 Translating injbence view transition view The mathematical probabilities The conditional influences transitions states translated definitions SMDP include event variables influences corresponding characterizing event variables functions onestep transition captured The injuence translator view analogous probabilities 62 Given random variables x y z conditional y means variable e x E algorithm based expectation chance node reduction algorithm conditional influence diagrams expectation z given x respect y E J2 z E 52 Q2 outcome space event Fig 4 overall idea algorithm With reference variable nodes direct influence state space conditional event state variable nodes final diagram contains static action space static table associated nextstate variable state variables Assuming reduce intermediate distribution Fig 11 Final influence view reduction k Leong Artial Intelligence IO5 1998 209261 239 set PMFs CDFs onestep transition functions right contains components conditional action influence view translator In essence identifies event variable node reduced updates conditional distributions event variables affected removes The main algorithm follows iteratively INFLUENCEVIEWTRANSLATOR ID 0 ID sequence eventvariablenodes x t FINDREMOVABLEEVENTVARIABLE x ID ID t ABSORBEVENTVARIABLE ID x x t FINDREMOVABLEEVENTVARIABLE ID return ID An event variable node A simple heuristic distribution distribution dimensions tables updated small possible This heuristic employed removable single probabilistic successor remove event variable nodes smaller conditional size conditional helps FINDREMOVABLEEVENTVARIABLE ID 0 ID sequence eventvariablenodes Elist t 0 x E ID x statevariable x nextstatevariable 1 lengthsuccessorsx Elist t Elist U x 0 Sort elements Elist according increasing return firstElist size lone successor increasing number predecessors nodes To remove event variable node X lone successor y inherit conditional distribution y updated accordingly Consequently x longer successor predecessors predecessors ABSORBEVENTVARIABLE ID X x eventvariablenode 0 Assume x successor firstsuccessorsx 0 ID sequence eventvariablenodes D t distributiontablex y t D t distributiontabley predecessorsy distributiony t newdistribution UPDATEDISTRIBUTIONTABLE p E predecessorsx successorsp t successorsp U yx return IDx t predecessorsx U predecessorsy distributiontablex Dx DY 240 Z Y Leong ArtiJicial Intelligence 105 1998 209261 Conditional distribution table b PCIT n A NOTA Bl 070 030 B2 020 050 83 010 020 Conditional distribution table c Pclr Ir A Bl NOTA al A 82 NOTA BZ A B3 NOTA B3 C 070 060 045 010 020 030 NOTC 030 040 055 090 080 070 Updated conditional distribution table c b removed Pclr A NOTA C 060 029 NOTC 040 071 Calculation methods PCIA 070070 045020 OZOOlO 060 PNOTCIA 1 PCIA 030070 055020 080 010 040 PCINClA 060 030 010050 030 020 029 PNOTCINOTA 1 PClNOTA 040030 090 050 070020 071 Fig 12 An example conditional distribution table updating Updating conditional distribution table successor event variable begins conditioning row column events respect indices conditional events event sequence constituting conditioning new predecessors distribution table events appropriately The 7 Fig 12 shows simple outcome predecessor event variable The conditioning removed filtered combination proper combination default Recall conjunctions index event variable conditional probability example calculations entries updated according involved Assuming event variable average number conditional distribution involved m outcomes n predecessors table entries updated Om 73 Translating tree view transition view tree view transition view based expectation Translation conditional probabilities reduce intermediate final diagram contains direct probabilistic dependences variable nodes shown Fig 13 Assuming conditional idea state variable nodes state static action space static state space entries associated state variable outcomes right event variable nodes 7 With reference Fig 5 main distribution shown Z E Leong Artificial Intelligence 105 1998 209261 241 Well d I 012 Discomfort 028 0 nl Sick 048 Sick Dead Fig 13 Final tree view reduction PMFs CDFs onestep transition functions components indicate conditional action tree view The calculating corresponding translator updates entries conditional expected conditional nextstate variable outcomes concerned The path outcomes depthfirst leading simply propagated event variable nodes breadthfirst manner The final path probabilities traversing branches probabilities downstream summed established nextstate variable node The main algorithm conditional distributions distribution probabilities outcomes states forward multiplication follows liXeVIEWTRANSLATOR TD 0 TD sequence eventvariablenodes x E TD slist t successorsx x slist PROPAGATE 0 Assume SUMPATHS olist t outcomesstatevariable o E olist sums final path probabilities ns E nextstatevariableo SUMPATHS ns return TD 242 Z Z Lang Artificial Intelligence 105 1998 209261 The propagation procedure simply multiplies conditional probability outcome event variable successors PROPAGATE x Elist 0 x event variable node Elist sequence eventvariablenodes olist t outcomesx 0 olist sequence ordered pairs 1 prob 1 label outcome prob conditional probability o E olist associated outcome e E Elist solist t outcomese s E solist probs probsprobo Assuming event variable average number conditional distribution involved m outcomes n predecessors entries updated Om 731 Translating injuence view tree view The influence view regarded special form influence diagram tree view special form decision tree Both influence view tree view contain decision nodes values associated outcomes special chance nodes nextstate variable nodes Moreover influence view tree view oriented state variable node source influence diagram state variable node sink Many theoretical decision influence view tree view tree applied directly simplified manner results concerning representations The main idea direct translation event variable nodes influence view tree view shown Fig 14 The number entries conditional distribution tree view generalized Section 633 relations captured similarly proper zerovalued entries reflected asymmetric conditional influence view proper omission branches tables influence view number branches event variables As mentioned tree view nonbinary distribution tables Influence view Tree view gzy Y NotY 085 Fig 14 Direct translation influence view tree view action 7 K Leong Artcial Intelligence IO5 1998 209261 243 In translating influence view tree view event variable nodes influence view ordered state variable node source nextstate variable node sink end list These nodes respective outcomes associated conditional probabilities follows expanded terms maximal distances nodes branches tree The main algorithm connected INFLUENCEVIEWTOTREEVIEWTRANSLATOR ID 0 ID sequence eventvariablenodes ID t ORDER ID TDtIzr 0 Assume EXPAND properly attaches node outcomes corresponding tree e E ID conditional probabilities leaves branches EXPAND e TD return TD functions The ordering procedure performs maximum distances event variable nodes source node second sorts event variable nodes increasing order respect maximum distances nodes equal maximum distances respect minimum distances source This heuristic ensures predecessors event variable node positioned left node resulting determines minimum tree ORDER Elist 0 Elist sequence eventvariablenodes 0 dise event variable node e ordered pair tmin max min minimum distance max maximum distance statevariable node e E Elist dise t e E Elist tOO e statevariable slist t s E slist successorse mindiss 0 mindiss maxdise 1 maxdiss MAXmaxdiss maxdise 1 maxdiss MAXmaxdiss maxdise 1 0 Assume DISSORT properly sorts marked eventvariable distances statevariable node DISSORT return Elist Elist nodes according The complexity marking ordering algorithm set event variables p set probabilistic influences 0 1 E I 1 ly I E influence view 244 ZK Leong Arhjicial Intelligence 105 1998 209261 sorting 0 1 E I2 I 0 1 E 1 log I E I average quicksort algorithm In translating tree view influence view event variable nodes tree view event variable aligned nodes representing depth tree state variable node root These nodes respective outcomes branches associated conditional probabilities nodes tables influence view The main algorithm extracted follows TREEVIEWTOINFLUENCEVIEWTRANSLATOR TD 0 TD sequence eventvariablenodes TD t ALIGN TD ID t 0 0 Assume EXTRACT collects information pertaining eventvariable corresponding x E TD EXTRACT conditional probabilities x ID influence view single particular depth tree view updates outcomes return ID The aligning procedure simply assigns depth number tree view The asymmetric cases automatically nodes tree The event variable nodes sorted according root node tree view event variable nodes taken care relative positions depths ALIGN Elist 0 Elist sequence eventvariablenodes 0 depthe event variable node e distance root node e E Elist depthe e E Eli t 0 e statevariable slist t successorse s E slist depths depthe 1 properly sorts marked eventvariable nodes depths statevariable node 0 Assume DEPTHSORT according DEPTHSORT return Elist Elist The complexity marking aligning algorithm 0 I E In E set event variables m average number outcomes sorting O E 12 O E Jm log I E I average quicksort algorithm The inherent exponential nature tree representation algorithms complexity reflected T Z Leong Articial Intelligence 105 1998 209261 245 The translations l Translating described complicated following situations influence view tree view loses information conditional independence event variables l Translating tree view influence view loses information chronological ordering event variables The current memorize specifications conditional framework translators relevant information DynaMoL framework view prompt technique chronological interface heuristics user required automated detection conversion ordering incorporated employ necessary A general independence near future 78 74 Handling constraints translations Most constraints direct correspondence instance corresponds variable SMDP No explicit translator currently defined influence view It encoded special version update distribution algorithm described earlier Each state time decision stage constraints The explicit partial ORgate constraint table translators DynaMoL statespace particular SMDP representation translator devised In translating influence view transition view new algorithm update conditional distribution lone successor y contain conditional distribution constraints The algorithm simply propagates successor event variable removed entries event variable x removed tables partial ORgate disjunctive outcome labels properly influenceviewtranslator In translating influence view tree view disjunctive outcome table partial ORgate constraint properly conditional distribution corresponding asymmetric branches The number table entries branches tree view updated order lnl m average number outcomes n average Om number predecessors event variable For influence view case study state variable nextstate variable 18 19 outcomes event average number predecessors variables average number 3 outcomes event variable influence view number order 8700 addition table entries predecessor order 26000 The smaller dimensions conditional distribution intermediate tables rendered partial ORgate drastically cuts sizes tables practice 3 To reduce event variable need calculated conditional distribution labels interpreted 75 Maintaining consistency Decision modeling view render constructs time Modifying view obsolete There types consistency management involves working different graphical views DynaMoL information involved numerical DynaMoL parameters add 1 number l Zntraview consistency ensures structural particular view specified correctly probabilities 246 T k Leong Artificial Intelligence IO5 1998 209261 l interfaces simple checking mechanisms states displayed accordance statespace Such consistency maintained incorporating Interview consistency ensures updated information views translators invoked For unidirectional event variables influences transition transition target view updated new transition functions transition information translation origin obsolete target modified view influence directly updating A consistency invoked modeling session flag signalled functions sure arcs associated onestep convention view Under transition table track translations reflected relevant translators translating target information displayed modified translating function relevant updating parameters direct correspondence reflected inconvenience model changes reflected saved confirmed For bidirectional translations different views modifications minimized requiring interfaces 8 Model solution Once dynamic decision model model solved solution methods SMDPs A variety solution methods available dynamic decision problem concerned choose efficient solution method available The major solution methods current version DynaMoL based value iteration SMDPs Based characteristics SMDP translated formulated incorporated 81 Value iteration A dynamic decision problem expressed dynamic programming Bellman optimality equation SMDP The main idea solving equation solving approach working backward pruning suboptimal branches way equation divide conquer final outcomes end decision horizon stage optimizing decision subproblems In specialized case MDP state transitions state E S occur unit time interval duration 1 For decision horizon n stages discount factor 0 j3 1 optimal value achievable state E S VT given initial value Vi 0 current time t E T Vi B t maxa vlBCtVln1Btl nO ijES UEA teT d 1 8 Pi t transition probability state j conditional action time t VP 1 value achievable time state conditional action unit In general case SMDP state transitions state E S occur state For decision horizon n stages time durations entering different T Z Leong Artijicial Intelligence 105 I 998 209261 241 factor 0 1 dynamic programming optimal state E S Vi given initial value Vi 0 current time t E T calculating equation discount value achievable consists parts l The indicates transition state occurs duration n values achievable decision horizon ignored expected value achievable l The second indicates duration state values achievable account IZ values achievable expected value achievable transition occurs transitions state taken state duration The equation incorporates addend second second addend follows 35 maxa C C qcmt CyfZjVjO n1 lO 1 j mnl 1 03 j ml I0 yymt B1glzBhiHvnmtm II nO ijcS atzA tcT 9 sm transition value function t onestep transition function vTm cr yial bl vm qliaolpm forallijESaEAtETandmO The value iteration solution method solve optimality equation shown 8 9 The solution equation optimal policy jr CL CL 1 I j3 0 optimal expected value S A t E T maximizes VizN reward initial state duration N time t 0 Recall n N I remaining duration decision horizon For decision horizon duration N complexity value iteration algorithm SMDP 0 N2 1 A 1 1 S 1 2 decision stage generally need consider time points t t 6 t t n The complexity corresponding IA 1 S12 case onetoone MDP ON correspondence duration n current time t n N t algorithm All default solution methods existing dynamic decision modeling inference frameworks techniques employed based value iteration While probabilistic solving dynamic directly influence diagrams Markov value iteration Cohort analysis Monte Carlo simulation 63 graph reduction algorithm 70 corresponds Markov 248 Z E Leong Artcial Intelligence 105 1998 209261 cycle complexity algorithms memorized optimal substructures The clinical question trees based conditional OS IAl ISlN use forward manner expectation inherent case study times The solution produced Markov value iteration assessed strategies considered numerical parameters holding corresponding achievable patient probability thromboembolism results longterm decision horizon 50 years 600 months administering possible warfarin dynamic programming techniques problem posed discrimination accordance MDP constant set policies expected value stages We assume history decision horizon The preferred strategy policy includes starting states possible decision 025 atria1 fibrillation warfarin beginning indicate initially assessed The second clinical question case study posed optimization problem accordance SMDP The solution produced numerical parameters optimal policy possible starting states semiMarkov value iteration possible decision stages We adopt assumptions condition patient mentioned For shortterm decision horizon 5 years 60 months results indicate administering months preferred preferred strategy 8 months After 8 condition administering patient remains drug initially warfarin initially 82 Other methods reported Solution methods matrix solution policy directly applicable stationary policies constant discount MDPs SMDPs literature fundamental iteration 34 adaptive aggregation 4 linearprogramming certain assumptions conditions met These conditions include factors homogeneous transition functions As mentioned Section 224 recent research MDPs 171719222329314367 methods solution optimality domains Some required formats specific framework computation DTP led new solution tradeoff These methods address decision special cost complex timecritical MDPs formulated Besides solution methods MDPs SMDPs solution methods advantage highlevel DynaMoL ontology employed 83 Separating modeling solution support In stunmary separating modeling task supported decision grammar task supported mathematical solution graphical presentation large collection solution methods employed new solution method involve change solution methods Similarly extending adapting affect solution methods applicable methods use additional constructs reference highlevel modeling representation DynaMoL Moreover employing language model admit solution representation decision grammar graphical presentation mathematical T Z Leong Artijicial intelligence 105 1998 209261 249 9 Model analysis Model analysis analysis techniques clarity ensure correctness performed dynamic decision model solution Many sensitivity test 36 risk profiles In DynaMoL event variables model robustness decision analysis way analyses directly applicable removing adding changing transition value functions methods The influence view supports structural parameter manipulation numerical parameters explicitly displaying information structural organizationThe numerical parameters For instance warfarm ineligible tornado diagrams multi usually analysis solution analysis allowing direct level specified structural state transition view helps detect improperly transition event variables The tree view supports careful examination parameter SMDP invoking structural parameter analysis warfarin administered numerical The quality model assessed terms requisiteness turn reflects decision clarity A model accurate sufficiently information contains relevant terms accuracy conciseness interpreted wellformed situation A model concise contains redundant contains meaningful meaningful formulation indicate easily problem analysis answers Therefore quality metrics practice information easily accessed inference process information A model clear produce theoretically model debugged problem include determining Some relevant metrics decision compares assessing model accuracy relevant chance events 58 value information class analysis confidence measure recommended subjective probabilities objective While metrics applicable implementations metrics types For instance equivalence dynamic renders updating difficult specific model types mind structural controllability diagrams equivalence decision fidelity 5076 relative dynamic decision model type actual ease use vary different model updating usually employed structural complexity treebased decision models metrics designed influence decision class analysis influence diagrams observability In addition frequencies model state attributes formal canonical forms domainspecific formulating analyzing SMDP combinatorially state space relevant state space description state attribute variable One explicitly manipulate increasing dimension way ensure conciseness combinations heuristics Another way develop quantities smaller dimension information effective guidelines solution developing problem The quality solution statistics called suficient original state space summarize essential 4 Currently general decision model analysis techniques usually determined dynamic knowledge standard statistical domainspecific respect oneway SMDP facilitates analysis solution nature Much insights gained solution analysis The mathematical twoway representation techniques sensitivity 111 The main difficulty 250 Z E Leong Atcial Intelligence 105 1998 209261 Graphical Interface Fig 15 The DYNAMO architecture value iteration The accuracy SMDP assessed nature state space action space decision parameters absorbing wellformed terms proved existence convergence facilitate proofs certainty equivalence SMDP convergence states present examining For instance guaranteed mathematical properties optimal policies Some methods principle contraction mapping principle techniques difficult apply understand discrimination For longterm controllability problem observability 4 Due advanced mathematical definitions monotonicity conditions case study practice indicate administering strategy reasonable optimization preferred strategy shifts reasonable manner drug depending desirable undesirable warfarin Quinidine ranges numerical parameters results demonstrate sensitivity problem sensitivity results patient dominant involved For shortterm decision horizon initially administering warfarin effects warfarin 10 The DYNAMO The architecture prototype Fig 15 The implemented shown graphics package indicate specification The baselanguage correspondence implements information 49 In figure blocks inflows The graphical defines solution methods SMDPs implementation DynaMoL called DYNAMO Common Lisp GARNET arrows interactive model model components The translator contains SMDP The solver indicate components user interface allows rules model components 101 System implementation All preceding components described DynaMoL current version DYNAMO implemented dynamic decision ontology described transition view influence view corresponding version tree view partial influence view transition view 2 The solution methods value tree view corresponding solving discrimination In particular problems iteration optimization Section 4 complete graphical presentation functioning translators translators implemented fromto include problems policy sections supports The current version implemented algorithms preliminary evaluation results tree views translators documented 78 Y Lmng Artcial Intelligence 105 1998 209261 251 iteration adaptive aggregation semiMarkov interfaces decision parameters constraints data visualizing analysis linear programming3 set practical cases A sophisticated support tools developed Figs 6 7 actual screen snapshots DYNAMO Markov editors tools sensitivity tools including copy software restricted The commercialized use available request licensing negotiations release noncommercial 102 System evaluation The DYNAMO DynaMoL framework evaluated practical domains follows 1021 Atria1 fibrillation management rate reasoning multiple As illustrated demonstrated different The effectiveness shown actions specify transition support transition value iterations Numerical functions directly corresponding include Markov semiMarkov significant parameters rate embolism Section 6 conducted comprehensive Fig 7 created include case study based atria1 fibrillation management graphical actual clinical decision analysis consult views influence views The dynamic translation decision problems involve 4 different strategies 20 states 10 event variables time horizons 600 months 50 years 60 months 5 years The solution methods employed sensitivity analyses clinically cerebral hemorrhage ensure robustness optimal policies derived perspective 20 states transition views modeling process Modeling begins specifying influence Since difficult In case study influence views set event variables different views structurally different Although numerical parameters general event variables performed underlying numerical parameters facilitated partial tree views support influence views corresponding tree views shown Fig 8 order event variables illuminate specified Visualizing numerical parameters explicitly structure model original tree views allow compare model influence views transition views simplified version translated specified verified making shown sure transition administered If discrepancies tables influence views tree views partial tree views examined links correctly defined states warfarin ineligible warfarin distribution reachable contribution relations shown Fig 10 Translations specification asymmetric exercise deliberations help rectify errors Fig 6 numerical corresponding Markov cycle tree format When relationships fully specified chronological parameters detected parameters showing 3 The implemented programming methods algorithms included evaluation DYNAMO solver documented 53 results policy iteration adaptive aggregation linear 252 TE Leong Aicial Intelligence IO5 1998 209261 As compared original solutions expert judgment terms expressiveness correct answers according capabilities problem For instance DynaMoL bleeding dependent allows direct accounting warfarin respect duration treatment expression duration factors difficult existing decision modeling frameworks clinical consult framework achieves sensitivity analyses provides extra efficiency modeling solving decision risk varying relative 1022 Colorectal cancerfollowup We conducted comprehensive case study deciding optimal followup surgery The decision context Singapore General test treatment spreading optimal course diagnostic cancer recurrence metastasis schedule colorectal cancer patients undergone based group Dukes Stage 3 colorectal cancer patients Hospital The objective determine early detection management cancer recurrence metastasis The dynamic decision model constructed graphical translation tree views In case tree views partial modeling process described earlier The chronological metastasis recurrence metastasis solution method employed implemented produced reasonable judged clinical experts 78 support transition views influence views facilitate order cancer recurrence tree views The results algorithms work correctly optimal policies Markov value iteration Preliminary explicitly captured tree views directly translation evaluation 1023 Dynamic decision problems domains Finally evaluated implemented test suite 53 The test suite includes benchmark problems space state space range problems considered discounting general domains automobile problem solution methods DYNAMO examples decision randomized 34 The sizes action 5 25 Both finitehorizon infinitehorizon correctness implemented suitable problem characteristics linear programming solution infinite problems large state space andor action space adaptive state aggregation preferred On hand finite applying sensitivity different analyses stationary policies solution methods algorithms facilitates involving The exercise demonstrated illuminated methods For instance horizon problems policyiteration horizon problems strategies decision optimization problems timedependent suitable method case applied stages appropriate transition functions value iteration heterogeneous 11 Discussion 111 Related work The DynaMoL framework dynamic decision making Section 22 mainly motivated ideas approaches SMDPs dynamic decision analysis DTP described TE Leong ArtiJicial Intelligence 105 1998 209261 253 Egar Musen 24 examined specifying decision model variables graphical level abstraction grammar extended structure influence modeling diagrams grammar higherlevel constraints This grammar captures prototypical language approach based patterns high clinical decision problems The tradeoffs dilemmas handle dynamic decision models Graphical representation continuoustime Berzuini et al 5 Dean et al 21 Similarly models Dagum et al 1415 captures general frameworks networks These Bayesian presentation relevant decision probabilistic influence diagrams semiMarkov processes explored recent work dynamic network techniques focus single perspective variables Bayesian networks timeseries analysis dynamic techniques integrating automatically On developed data underlying SMDPs employ algorithms influence decision dynamic explicitly decision stage decision models SMDPs Provan et al 5758 evaluating dynamic overall structure corresponds SMDP Tailoring parameters influence diagram representation state attribute variables Bayesian network stage represented In framework influence diagrams construct dynamic diagrams involved Magni Bellazzi 46 recently adopted influence view representation naMoL develop DTPlanner environment fluence view supports parsimonious representing specification MDP interactive Dy solving MDPs The framework 112 Future work extension Besides addressing features capabilities general practical applications On theoretical transparency tradeoff model solution efficiency adapted allow model solve larger class propose research extended discuss DynaMoL issues language developed language enhancement problems On practical effective convenient use 1121 Supporting language extension adaptation Incremental language enhancement supported DynaMoL introducing set new grammar constructs presentation formats devising set translators Static versus dynamic spaces The DynaMoL decision grammar extended action space New productions dynamic state action The graphical presentation constructs state space dynamic written incorporate corresponding duration unchanged valid entities displayed decisions stages Solution methods readily available SMDPs incorporate valid convention time remains particular time points general classes b Automatic state augmentation State augmentation incorpo rating extra information SMDPs Most declaratory strategic constraints instance represented state attribute variables additional dimensions basic technique 254 TZ Leong Artijcial Intelligence 105 1998 209261 automatically indicates convenient state attribute variable separately set translators state space Many constraints affect original state space For example patient stroke constraint number stroke affects states specify constraints volve stroke Therefore associated parameters information This involves working abstract state space corporate eventually translated state space solution analysis This approach allow incrementally directly dealing resulting This idea modeling idea execution solution idea adopted aggregation methods AI 4142616668 methods Automatic state augmentation grammar translating needed facilitate modeling multiple directly opposite abstract state space efficiency The control theory 4 HTN planning DynaMoL adding set set translators separately large complex state space DTP 71722 achieved form larger state space Another abstract state space transparency impose constraints levels abstraction set reversed constraints specifying translators constructs important dynamic decision problem For example c Limited memory In semiMarkov process limited memory time entry state In cases memory previous states patient second heart attack semiMarkov Markov duration actions heart attack susceptible surgery Such limited memory incorporated process state augmentation lead explosion state Repeated applications state augmentation space size To avoid explosion relegate track limited memory Only forward induction based solution methods In approach new counter binding called memory history applicable track relevant states process visited introduced model parameters Calculations conditional history accumulated A set history constructs limited memory set translators specification needed The solution methods operate SMDP history constructs d Numerical DynaMoL conditional parametric far introduced expected value respect track solution methods types numerical usually ordering constraints There event state numerical specify constraints constraints ordering number events states lead specific consequence constraints assumed dead strokes Action numerical number times action applied Action ordering constraints action follow action The method augment decision solution methods needed incorporate state space factors The second method dynamic decision model track number order introduce set counters let care constraints Again new constructs translators To facilitate proper constraints constraints patient incorporate translations certain restrict specify Y Lmng Artijcial Intelligence 105 1998 209261 25s nature constraints external knowledge based employed examining domain specific constraints canonical models introduced similar manner described earlier choose right translators solution methods Other general DynaMoL definition partialOR constraint event combination e Presentation convention In addition DynaMoL useful presentation perspectives parametric conventions evolution translators incorporated graphical presentation perspectives 2D 3D visualization new presentation introducing 1122 Supporting automated dynamic decision making The DynaMoL decision making analysis relevant problems effectively framework serve anchor new paradigm dynamic solution integrates automatic interactive formulation Automatic derivation numerical parameters One daunting task issues processing numerical parameters estimate specify assumptions derivations support decision modeling errors dynamic decision modeling In general given statespace size 1 S 1 actionspace size 1 A I involved assessed decision horizon duration n number probabilistic parameters expert physicians order 0 IA 11 S12n Subjective assessments cases When decision situations complex decision adequate limited large practicality modeling approach dimensions lack realistic estimations On hand given large set data objective probabilities easily calculated recording measurement formats associated data complicate We wish investigate transition feasibility task supporting dynamic decision modeling limiting illuminate learned contribute decision modeler database builder This turn encourage advancement techniques facilities provided fields By incorporating mented parameter butions DynaMoL 93 We reported encouraging sults experimenting large medical databases dependent diabetes mellitus surgery patients learning methods imple construct probability distri influence views transition views dynamic decision model insights insulin 77 followup management colorectal cancer onestep It lessons dynamic integration databases This exercise provide preliminary management constraints bridging set statistical Bayesian available databases The expectation gap automatic construction automatically functions involved inherent learning insights 910 b Supporting knowledge based model construction Knowledgebased sys tems employing knowledgebased model construction KBMC ALTERID 8 decision FRAIL 28 SUDOPLANNER 72 DYNASTY 56 advocate models different problems constructed demand knowledge base 73 Currently KBMC synthesizes type decision mod els influence diagrams In dynamic decision models timedependent decision 256 ZZ hong Artificial Intelligence IO5 1998 209261 project translated substructures impossible numbers equations complicated specific decision models subsequent models 71 explore high straints usually hardwired difficult level decision ontology In ongoing facilitate KBMC DynaMoL provides expressive explicit DynaMoL knowledge language base representation restricted graphical structure target model The resulting models support detailed analysis efficient solution methods argued formulating dynamic decision problems This relieves retrieval constraints organization c Automated knowledge acquisition tasks essential sources imprecision multiple knowledge possible disagreements biomedical knowledge electronic address sources Automating effective dynamic decision making delivery information issues wide variety model formulation With rapid advances model building support available information different sources In ongoing project investigate acquire integrate information different sources domain experts knowledge bases electronic medical test treatment protocols Internet The records online different sources major research model formulation support model model formulation incompleteness experts groups experts including dealing issues integrated facilitating organizing analysis issues include selecting knowledge possible disagreements structural inconsistency collaborative representing information information refinement registries relevant 12 Conclusions We conclude paper summarizing achievements limitations work 121 A unifying view The analysis major approaches similarities differences dynamic decision making uncertainty strengths weaknesses representational task definition role dynamic decision making uncertainty inferential dynamic decision making uncertainty SMDPs support involved We propose firstorder representation Recently Dean 161 FOPC deterministic knowledge come idea regard MDPs basis DTP We illustrated motivation proposal devising new methodology highlighted Based uniform explicated regarded predicate calculus independently based idea 122 A general paradigm Building methodology common new general dynamic decision making uncertainty We propose novel language basis SMDPs introduced 7 Z Leong Artijcial Intelligence 105 1998 20261 251 integrates desirable design new paradigm multiple perspective perspective languages We established methods ontology This contrast features current techniques By introducing mold single existing graphical dynamic decision modeling language design breaks systematically existing techniques fixed vocabularies reasoning supported reasoning extend influence Model specification DynaMoL terms higherlevel language languages presentation frameworks declaratory structure model strategic constraints In frameworks dynamic existing dynamic decision modeling diagrams Markov cycle trees model parameters need explicitly explicitly In particular graphical explicitly encoded time slice period considered The dynamic decision grammar DynaMoL hand supports abstract statements decision situation related These statements events states logically abstract statements macro constructs languages By focusing decision problem ontology components DynaMoL provides concise transparent platform supporting model construction conventional instead decision model specified incorporated temporal parameters probabilistic analogous programming The advantages graphical nature existing dynamic decision modeling extended preserved convention model components different presentation perspectives visualized The ease clarity Theoretically SMDPs approximate stochastic processes state augmentation potentially visualization contribute DynaMoL By extending constraints graphical mechanisms The resulting manipulation general stochastic models By distinguishing underlying mathematical model DynaMoL preserves model structure time admits spectrum solution methods direct visualization On hand efficient solution methods exist specification grammar clarity expressiveness state space complex While illuminate different perspectives information occur information Unless perspective difficult Therefore overhead Moreover translation SMDP framework inherent time information kept extra burden information model different ways loss stored normal form SMDPs later retrieval information limitations Explosion state storage There space size unavoidable introduce problem attributes constraints Choosing appropriate daunting task We proposed ideas issues addressed solution method adapting handle constraints 123 A prototype To evaluate feasibility effectiveness new paradigm developed prototype handle general class dynamic decision problems We conducted implementation gave confidence problems results produced methodology works large class dynamic decision practical domains Besides providing superior modeling support variety detailed case studies evaluate DynaMoL design DYNAMO involved solution The modeling experiences 258 ZE hong Artificial Intelligence 105 1998 209261 performance solution methods par existing programs The model reallife decision problems clinical pharmaceutical domains planned decision analysis Applications DYNAMO We interested putting documented lessons illuminated experiences performing practical use Towards end detailed case studies complex domains relevant research issues required support tools Acknowledgements National This paper reports work partly MIT Laboratory Computer Science Institutes supported Cambridge MA USA This research Health Grant No 5 ROl LM04493 National Library Medicine USA It National Science supported Strategic Research Grant No RP960351 Technology Board Ministry Education Singapore like thank case study Drs Charles E Ellis Stephen G Pauker guidance I like thank Peter Szolovits Alvin Drake atria1 fibrillation management useful discussions David Harmanec Eric Horvits Cungen Cao Jianye Zheng comments version tree views functioning DYNAMO architecture Mun Cheong Ng analyzed translators David Harmanec Suman Sundaresh implemented non commercial use Jianye Zheng worked release version DYNAMO Jianye Zheng incorporated solution methods conducting I References l AG Barto SJ Bradtke SP Singh Learning act realtime dynamic programming Artificial Intelligence 72 l2 1995 81138 2 JR Beck SG Pauker The Markov process medical prognosis Medical Decision Making 3 1983 419458 3 RA Bellman Dynamic Programming 4 DP Bertsekas Dynamic Programming Deterministic Princeton University Press Princeton NJ 1957 Stochastic Models PrenticeHall Englewood Cliffs NJ 1987 5 C Berzuini R Bellazzi S Quaglini Temporal reasoning probabilities Uncertainty 1421 Artificial Intelligence Association Uncertainty Proceedings 5th Workshop 1989 pp Intelligence Artificial 6 C Boutilier RI Brafman C Geib Prioritized goal decomposition Markov decision processes synthesis classical decision Intelligence Artificial IJCAI97 Nagoya Japan 1997 theoretic planning Proceedings 15th International Joint Conference 7 C Boutilier R Dearden M Goldszmidt Exploiting International 1111 Joint Conference Artificial Intelligence structure policy construction 14th IJCAI95 Montreal Quebec 1995 pp 1104 Proceedings 81 JS Breese Construction belief decision networks Computational 9 C Cao TY Leong Learning probabilities conditional influence views Intelligence 8 1992 624647 Working Notes IJCAI Workshop Intelligent Data Analysis IDAMAP97 lo C Cao TY Leong A Peng Kiong Leong F Choen Seow Dynamic decision analysis Medicine Pharmacology 1997 pp 1119 medicine data driven approach Intemat J Medical Informatics appear Z I Leong Artid Intelligence 105 1998 209261 259 l l BY Chan RD Shachter Structural controllability observability influence diagrams MP Wellman BD DAmbrosio P Smets Eds Proccedmgs 8th Conference Uncertainty Intelligence Morgan Kaufmann San Mateo CA 1992 pp 2532 D Dubois Artificial 12 D Chapman Planning 131 K Currie A Tate OPlan 141 P Dagum A Galper Forecasting Eds Proceedings A Mamdami Kaufmann San Mateo CA 1993 pp 6471 conjunctive goals Artificial Intelligence 32 1987 333377 open planning architecture Artificial Intelligence 5 1 1 1991 4986 sleep apnea dynamic 9th Conference Uncertainty network models Artificial D Heckerman Intelligence Morgan 15J P Dagum A Galper E Horvitz Dynamic network models forecasting BD DAmbrosio P Smets Eds Proceedings Morgan Kaufmann San Mateo CA 1992 pp 4148 8th Conference Uncertainty D Dubois MP Wellman Intelligence Artificial 161 T Dean Decisiontheoretic Institute Probability Artificial Intelligence Corvalis OR 1994 planning Markov decision processes Tutorial presented Summer 17 T Dean R Givan S Leach Model reduction Proceedings Markov decision processes Morgan Kaufmann San Mateo CA 1997 pp 124131 techniques computing approximately 13th Conference Uncertainty Artificial optimal solutions Intelligence lS T Dean LP Kaelbling J Kirman A Nicholson Deliberation scheduling timecritical sequential decision making Artificial D Heckerman A Mamdami Eds Proceedings 9th Conference Uncertainty m Intelligence Morgan Kaufmann San Mateo CA 1993 pp 309316 19 T Dean LP Kaelbling J Kirman A Nicholson Planning deadlines Proceedings pp 574579 1 lth National Conference Artificial Intelligence AAAI93 Washington DC 1993 stochastic domains 20 T Dean S Kambhampati Planning scheduling AB Tucker Ed The Computer Science Engineering Handbook CRC Press Rockville MD 1997 pp 614636 21 T Dean JKriman K Kanazawa Probabilistic network representations processes applications Planning Systems 1992 planning control Proceedings continuoustime 1st International Conference stochastic AI 22 R Dearden C Boutilier Abstraction approximate decisiontheoretic planning Artificial Intelligence 89 l2 1997 219283 23 M Drummond J Bresina Ayntime synthetic projection maximizing probability goal satisfaction Proceedings 8th National Conference Artificial Intelligence AAAI90 Boston MA 1990 1388144 24 JW Egar MA Musen Graphgrammar assistance automated generation influence diagrams D Heckerman A Mamdami Morgan Kaufmann San Mateo CA 1993 pp 235242 Eds Proceedings 9th Conference Uncertainty Artificial Intelligence 25 K Erol J Hendler DS Nau HTN planning complexity expressitivity Proceedings 12th National Conference Artificial Intelligence AAAI94 Seattle WA 1994 26 RE Fikes NJ Nilsson STRIPS new approach application theorem proving problem solving Artificial Intelligence 2 1971 189208 1271 MR Genesereth NJ Nilsson Logical Foundations Mateo CA 1987 Artificial Intelligence Morgan Kaufmann San 28 RP Goldman E Chamiak Dynamic construction belief networks Proceedings 6th Conference Uncertainty Artificial Intelligence 1990 pp 997 129 V Ha P Haddawy Theoretical Conference Uncertainty 298 foundations abstractionbaaed 12th probabilistic planning Intelligence Morgan Kaufmann San Mateo CA 1996 pp 29 I Proceedings Artificial 30 P Haddawy AH Doan R Goodwin Efficient decisiontheoretic planning analysis Intelligence 1995 pp 229236 P Besnard S Hanks Eds Proceedings 11th Conference 3 11 M Hauskrecht N Meuleau C Boutilier LP Kaelbling T Dean Hierarchical techniques Uncertainty empirical Artificial 14th Conference Uncertainty solution markov decision Intelligence Artificial processes macroactions Morgan Kaufmann San Mateo CA 1998 Proceedings 32 GB Hazen Stochastic trees new technique temporal medical decision modeling Medical Decision Making 12 1992 163178 260 ZK Leong ArtiJicial Intelligence IO5 1998 209261 33 JP Hollenberg Markov cycle trees new representation complex Markov processes Medical Decision Making 4 4 1984 Abstract 34 RA Howard Dynamic Programming 35 RA Howard Dynamic Probabilistic Systems Vol 1 2 Wiley New York 1971 36 RA Howard Decision analysis practice promise Management Science 34 1988 679695 37 RA Howard JE Matheson 6th Annual Meeting Society Medical Decision Making Markov Processes MIT Press Cambridge MA 1960 RA Howard JE Matheson Influence diagrams Eds The Principles Applications Decision Analysis Vol 2 Strategic Decisions Group Menlo Park CA 1984 pp 719762 38 J Janssen Ed SemiMarkov Models Theory Applications Plenum Press New York 1986 39 WS Jewell Markov renewal programming finite return models II infinite return models I formulations example Operations Research 11 1963 938971 40 JP Kassirer AJ Moskowitz Medicine 106 1987 275291 J Lau SG Pauker Decision analysis progress report Annals Internal 41 CA Knoblock Search reduction Artificial Intelligence hierarchical problem solving AAAI91 Anaheim CA 199 1 pp 68669 1 Proceedings 9th National Conference 42 RE Korf Planning search quantitative approach Artificial Intelligence 33 1987 6588 43 N Kushmerick Proceedings 1078 12th National Conference Artificial S Hanks D Weld An algorithm AAAI94 Seattle WA 1994 pp 1073 leastcommitment probabilistic Intelligence planning 44 TY Leong Dynamic decision modeling medicine critique existing formalisms Proceedings 17th Annual Symposium Computer Applications Medical Care IEEE November 1993 pp 478484 45 TY Leong An integrated approach dynamic decision making uncertainty Technical Report TR 63 1 MIT Laboratory Computer Science Cambridge MA 1994 46 P Magni R Bellazzi DTPlanner environment managing dynamic decision problems Computer Methods Programs Biomedicine 54 1997 183200 47 D McAllester D Roseblitt Systematic nonlinear planning Proceedings 9th National Conference Artificial 48 D McDermott Intelligence AAAI91 Anaheim CA 1991 pp 634639 J Hendler Planning What What An introduction Special Issue Planning Scheduling Artificial Intelligence 76 l2 1995 116 49 BA Myers DA Giuse B Vander Zanden Dannenberg DS Kosbie E Pervin A Mickish P Marchal IEEE Computer 23 11 graphical highlyinteractive user interfaces support Garnet comprehensive 1990 7185 50 RE Neapolitan Computing medical decision obtained influence diagram Artificial 51 A Newell Intelligence confidence Medicine 5 1993 341363 JC Shaw HA Simon Report general problemsolving program Proceedings International Conference Information Processing UNESCO 1960 pp 256264 52 A Newell HA Simon Human Problem Solving PrenticeHall Englewood Cliffs NJ 1972 53 MC Ng A solution suite dynamic decision modeling National University Singapore Department Information Systems Computer Science Honours Year Project Report 1997 54 SG Pauker JP Kassirer Medical progress decision analysis New England Journal Medicine 316 1987 250258 55 J Pearl Probabilistic Reasoning Kaufmann San Mateo CA 1988 Intelhgent Systems Networks Plausible Inference Morgan 56 GM Provan Modeling Report MISCS9269 Philadelphia PA 1992 evolution acute abdominal pain temporal University Pennsylvania Department Computer influence diagrams Technical Information Science 57 GM Provan JR Clarke Dynamic network construction updating techniques diagnosis acute abdominal pain lEEE Trans Pattern Analysis Machine Intelligence 15 3 1993 299307 58 GM Provan D Poole A utilitybased analysis consistencybased diagnosis J Allen R Fikes E Sandewall Conference Eds Principles Knowledge Representation Reasoning Proceedings 2nd International KR91 Morgan Kaufmann San Mateo CA 1991 pp 461472 59 ML Puterman Markov decision processes DP Heyman MJ Sobel Eds Handbooks Operations Research Management Science Vol 2 Elsevier NorthHolland Amsterdam 1990 pp 331434 60 H Raiffa Decision Analysis Introductory Lectures Choices Under Uncertainty AddisonWesley Reading MA 1968 T I Leong Artijicial Intelligence 105 1998 209261 261 61 ED Sacerdoti Planning 62 RD Shachter Evaluating 63 RD Shachter MA Peot Decision making probabilistic hierarchy abstraction spaces Artificial influence diagrams Operations Research 34 1986 871882 inference methods Intelligence 5 1974 115135 MP Wellman BD DAmbrosio P Smets Eds Proceedings 8th Conference Uncertainty Intelligence Morgan Kaufmann San Mateo CA 1992 pp 276283 D Dubois Artificial 64 LS Shapley Stochastic games Proceedings National Academy Science 39 1953 1095I 100 65 S Srinivas Generalizing nary variables Technical Memorandum noisy model 79 Rockwell International Science Center Palo Alto Laboratory Palo Alto CA April 1992 66 M Stefik Planning constraints 67 J Tash S Russell Control strategies Intelligence 1681 A Tate Generating Artificial MOLGEN Part l Artificial Intelligence 16 1981 11 l139 stochastic planner Proceedings 12th National Conference AAAI94 Seattle WA 1994 pp 10791085 project networks Proceedings 5th International Joint Conference Artificial Intelligence IJCAI77 Cambridge MA 1977 pp 888893 69 A Tate J Hendler M Drummond A review ai planning techniques J Allen J Hendler A Tate Eds Readings Planning Morgan Kaufmann San Mateo CA 1990 pp 249 70 JA Tatman RD Shachter Dynamic programming influence diagrams IEEE Trans Systems Man Cybcmet 20 2 1990 365379 71 C Wang Knowledgebased formulation dynamic decision models medicine MSc Thesis National University Singapore Department Information Systems Computer Science 72 MP Wellman Formulation Tradeoffs Planning Uncertainty Pitman LondonMorgan Kaufmann San Mateo CA 1990 73 MP Wellman JS Breese RP Goldman From knowledge bases decision models The Knowledge Engineering Review 7 1 1992 3553 74 MP Wellman J Doyle Modular utility representation decisiontheoretic planning Proceedings 1st International Conference Al Planning Systems 1992 75 DE Wilkins Practical Planning Extending Classical Planning Paradigm Morgan Kaufmann San Mateo CA 1988 76 KE Willard GC Critchfield Probabilistic analysis decision trees symbolic algebra Medical Decision Making 6 1986 77 SS Yeh TY Leong Automatic generation transition probabilities dynamic decision modeling case study Proceedings AAAl Spring Symposium Artificial 1781 J Zheng Consistency management multipleperspective Intelligence Medicine 1994 dynamic decision modeling MSc Thesis National University Singapore Department Information Systems Computer Science