Available online wwwsciencedirectcom R Artiﬁcial Intelligence 155 2004 139 wwwelseviercomlocateartint A framework linguistic modelling Jonathan Lawry Department Engineering Mathematics University Bristol Bristol BS8 1TR UK Received 13 November 2001 received revised form 7 November 2003 Abstract A new framework linguistic reasoning proposed based random set model degree appropriateness label Labels assumed chosen ﬁnite predeﬁned set labels set appropriate labels value deﬁned random setvalued function population individuals set subsets labels Appropriateness degrees evaluated relative distribution random set appropriateness degree label corresponds probability contained set appropriate labels This interpretation referred label semantics A natural calculus appropriateness degrees described weakly functional taking account logical structure expressions Given framework shown bayesian approach adopted order infer probability distributions underlying variable given constraints form linguistic expressions mass assignments In addition conditional measures introduced evaluating appropriateness linguistic expression given linguistic information 2003 Elsevier BV All rights reserved Keywords Random sets Linguistic constraints Fuzzy labels Label semantics Bayesian inference 1 Introduction The limitations classical modelling techniques effectively capture behaviour complex systems increasingly clear recent years This motivated research new alternative modelling paradigms artiﬁcial intelligence community fuzzy reasoning possibility theory Bayesian modelling default reasoning 48 112830 All approaches share emphasis high level qualitative descriptions opposed traditional low level framework The advantage higherlevel knowledge representation allows fusion expert background knowl Email address jlawrybrisacuk J Lawry 00043702 matter 2003 Elsevier BV All rights reserved doi101016jartint200310001 2 J Lawry Artiﬁcial Intelligence 155 2004 139 edge knowledge derived data Furthermore tends provide clearer insight underlying nature obtained transparent lower level models Another feature shared new approaches provide methodology reasoning presence uncertainty This coincidence fact uncertainty imprecision inherent complex modelling problems This uncertainty lack precision errors mea sured features present model available features sufﬁcient provide complete model To illustrate point consider important area river basin modelling ﬂood forecasting For problem necessary model river levels particular time point purely terms rainfall river levels earlier times However reality complex features inﬂuence runoff difﬁcult identify important practically impossible measure For instance likelihood given rainfall event produce ﬂood dramatically affected factors size drainage basin topography basin urban use basin While development analytical models impractical complex sys tems data available implicitly describing behaviour For example large companies supermarkets high street stores banks collect stream data relating behaviour customers Such data analysed provide ﬂexible models customer behaviour aid wide variety decisionmaking processes Hence higher level modelling approach truly effective provide natural knowledge representation framework inductive learn ing As important allows modelling uncertainty imprecision vagueness semantically clear manner Indeed emphasise necessity clear underlying semantics higherlevel modelling paradigm fun damental reasons high level approach provide transparent models understood practitioners relevant ﬁelds This achieved validity underlying concepts inference processes obscured doubt In sequel outline new methodology linguistic modelling applied inductive learning context The approach centre modelling linguistic constraints variables proposed Zadeh 37 underlying semantics different The phrase computing words introduced Zadeh 42 capture idea computation based numerical values natural language terms expressions As general idea clearly relevance type modelling described shall propose different interpretation given 3840 The general methodology computing words proposed Zadeh fuzzy set theory fuzzy logic particular based idea linguistic variables 38 40 A linguistic variable deﬁned variable takes natural language terms large small tall medium values meaning words given fuzzy sets underlying domain discourse Hence particular expression form Bill tall taken expressing fact linguistic variable describing Bills height value tall statement partial truthvalue corresponding membership degree Bills actual height fuzzy set representing meaning tall The truthvalue compound expressions Bill tall medium J Lawry Artiﬁcial Intelligence 155 2004 139 3 evaluated according fuzzy set calculus based choice tnorm tconorm 18 exposition In view principal problem approach semantics underlying standard fuzzy logic notion membership function obscure The difﬁculty revealed consideration fundamental question asked models linguistic constraints What information conveyed underlying variable For instance asserts Bill tall exactly information Bills height conveyed assertion In case fuzzy set theory according Zadeh 41 provides ﬂexible constraint variable representing Bills height More speciﬁcally tells possibility distribution Bills height corresponds membership function fuzzy set tall However association possibility distributions support assumption fully truthfunctional calculus membership degrees fuzzy set theory 26 Indeed provide insight behaviour compound fuzzy sets One possible solution difﬁculty accept possibility distributions fuzzy memberships sufﬁciently intuitive treated primitive notions attempt provide lowerlevel model If going adopt fuzzy logic methodology semantics intuitive consistent fully truthfunctional calculus based particular choice tnorm tconorm A number different models investigated reviewed 627 One promising ideas view fuzzy memberships ﬁxed point coverage functions random sets representing uncertainty variation underlying crisp deﬁnition concept 12 For instance population different individuals proposing set heights qualify description tall The associated random set function set individ uals set subsets heights membership particular height h fuzzy set tall correspond probability encountering individual included h crisp set deﬁnition This essence voting model fuzzy sets proposed originally Black 3 later Gaines 10 Clearly interpretation implicitly probabilistic nature surprising ﬁt inference framework fuzzy logic One problem onetoone correspondence fuzzy sets random sets The fuzzy set generated potentially inﬁnite family random sets Goodman 12 In possibility theory problem overcome making assumption random set consonant set sets nonzero mass constitutes nested hierarchy Lawry 20 justiﬁes introducing idea optimism parameter according optimistic voter likely include h extension concept tall It difﬁcult consolidate assumption fully truthfunctional calculus case voter high optimism parameter required opti mistic concept negation Lawry 20 suggests weaker notion negation overcome difﬁculty nonetheless treatment negation remains problematic In sequel outline new random set based approach ran dom sets relate sets appropriate labels value We formal framework approach overcomes problems highlighted This new calculus fully truthfunctional functional 4 J Lawry Artiﬁcial Intelligence 155 2004 139 weaker sufﬁcient sense The work described Sections 2 3 extension presented earlier paper 22 This work clearly related random set se mantics fuzzy sets proposed Goodman 12 Nguyen 25 However deﬁnes random sets underlying attribute universe proposed framework deﬁne random sets labels In view focus labels provides interesting new perspective 2 Label semantics The fundamental notion underlying label semantics individuals assertions kind described essentially providing information labels appropriate value underlying variable For simplicity assume given context ﬁnite set words available This somewhat controversial assumption claimed recursively applying hedges easily generate inﬁnite set labels initially ﬁnite set words In words tall possible label Bills height tall tall tall This claim problematic number reasons For instance appear use hedges natural language somewhat restricted One use expressions tall tall tall tall Also practice limit number times hedges applied label nonsensical This point suggest practice ﬁnite number labels available natural language Another related difﬁculty use hedges determining relationship meaning word meaning new word generated application hedge In Zadeh 3840 suggested relationships simple functional form For example meaning tall deﬁned fuzzy set membership function µtall Zadeh proposes meaning tall fuzzy set membership µ2 tall The choice particular function relatively arbitrary fundamentally far apparent simple functional relationship meaning word new word generated application hedge In words claim hedges simple syntactic device generating new labels equally simple semantic device generating associated new meanings Now let return problem interpreting natural language statements Bills height represented variable H Let suppose ﬁxed ﬁnite set possible labels H denoted LA labels known completely identical individual interpret statement Bills height Given assumptions interpret statement Bill tall asserted particular individual I We claim natural interpretation merely conveys information according I tall appropriate label value H In order clarify idea suppose I knows H h given information heshe able identify subset LA consisting words appropriate labels value h This set denoted DI h stands description h given I If allow I vary population individuals V naturally J Lawry Artiﬁcial Intelligence 155 2004 139 5 obtain random set Dh V power set LA DhI DI h Given obtain higher level information degree applicability label value deﬁning case µtallh PrI V tall DI prob h ability calculated basis underlying prior distribution V Now clearly function Ω 0 1 technically viewed fuzzy set However shall use term appropriateness degree partly accurately reﬂects underlying semantics partly highlight distinct calculus functions introduced sequel Similarly determine probability distribution mass assignment random set Dh deﬁning S LA mhS S Now suppose I know value H alternatively PrI V DI h know value assigned H I naturally deﬁne H h DI H universe H power set LA DI random set DI h The distribution random set clearly depend prior information available distribution H Hence assertion I Bill tall text interpreted tall DI H Finally case information I deﬁne random set DH cross product V universe H power set LA DH I h DI h interpret statement tall DH In order clarify ideas consider following example objective provide linguistic labels outcome single throw dice Example 1 Suppose variable SCORE universe 1 2 3 4 5 6 gives outcome single throw particular dice Let LA low medium high V I1 I2 I3 possible deﬁnition DSCORE follows low DI1 2 low medium DI2 2 low DI3 2 low DI1 1 DI1 3 DI1 4 DI1 5 DI1 6 DI2 DI3 1 1 medium DI2 3 medium high DI2 4 high DI2 5 DI2 high 6 DI3 6 medium DI3 3 medium DI2 4 high medium high DI3 5 medium low medium The value appropriateness measure depend underlying distribution V I1 I2 I3 representing weight importance associated views individual For instance assume uniform distribution V degree appropriateness low label 3 given I V low DI 3 V I3 V Overall appropriateness degrees word given 1 3 µlow1 µlow2 1 µlow3 1 3 µmedium2 1 3 µhigh4 1 µhigh5 1 µhigh6 1 3 µmedium3 1 µmedium4 1 µmedium5 1 3 6 J Lawry Artiﬁcial Intelligence 155 2004 139 Similarly assuming uniform prior V determine mass assignments DSCORE SCORE 1 6 For example SCORE 2 low medium V cid1 low medium I V DI 2 I1 V 1 3 m2 cid2 The mass assignments value x given m1 low 1 m2 low medium 1 3 m3 medium 2 3 m4 medium high 1 3 medium high 1 m5 high 2 3 3 low medium 1 3 medium 2 3 low 2 3 m6 high 1 In order determine overall mass assignment m SCORE varies need know distribution universe 1 6 Assuming uniform distribution gives example cid1 low medium cid2 m 6cid3 x1 cid1 low medium cid2 Prx mx 1 3 1 3 6 1 9 Overall m low 5 18 low medium 1 9 medium 2 9 medium high 1 9 high 5 18 We consider problem interpret expressions involving compound labels built set logical connectives For scope paper consider main connectives Firstly let consider case negation How interpret expressions form Bill tall We view negation express nonsuitability label In words statement means tall appropriate label H tall DH Conjunction disjunction taken having obvious meanings Bill tall medium interpreted saying tall medium appropriate labels H tall medium DH Bill tall medium interpreted saying tall appropriate label H medium appropriate label H tall DH medium DH In case implication tall implies tall mean tall appropriate label H tall tall DH implies tall DH It clearly desirable measure appropriateness degree compound expressions particular values underlying variable For instance given scenario outlined Example 1 want know appropriateness degree expression medium low value 3 Now expression identiﬁes set subsets LA contains low medium low medium J Lawry Artiﬁcial Intelligence 155 2004 139 7 low medium low high medium high low medium high Hence natural deﬁne appropriateness degree medium low 3 sum values m3 set m3low m3medium m3low medium m3low high m3medium high m3low medium high 2 1 In following section 3 formalise ideas logical framework 1 3 3 A formal framework label semantics In paper adopt logical formalisation label semantics label expres sions represented propositional logic sentences Consider formal language consist ing set labels LA L1 Ln connectives Within language represent compound linguistic descriptions generated recursively application connectives Deﬁnition 2 Label expressions The set label expressions LE deﬁned recursively follows Li LE 1 n ii If θ ϕ LE θ θ ϕ θ ϕ θ ϕ LE Recall discussion previous section label expression identiﬁes set subsets LA capture meaning We formal deﬁnition subset general label expression Deﬁnition 3 Appropriate label sets Every θ LE associated set subsets LA element 22LA denoted λθ deﬁned recursively follows λLi S LA Li S ii λθ ϕ λθ λϕ iii λθ ϕ λθ λϕ iv λθ ϕ λθ λϕ v λθ λθ Intuitively λθ corresponds subsets LA identiﬁed candidates set appropriate labels x possible values Dx expression θ In sense imprecise linguistic restriction x θ x corresponds strict constraint Dx λθ Dx Hence linguistic description Dx provide alternative linguistic variables Zadeh 3840 means formally representing linguistic constraints Example 4 Let LA small medium large λsmall medium λsmall medium cid4 small medium small medium large cid4 small medium small medium small large medium large small medium large cid5 cid5 8 J Lawry Artiﬁcial Intelligence 155 2004 139 λsmall medium cid4 small medium small medium large medium large cid5 medium large λsmall cid5 cid4 medium large medium large The following results illustrate clear relationship appropriate label sets logical structure expressions identify Initially introduce basic notation Let Val denote set valuations allocations truth values L1 Ln For v Val vLi true taken meaning Li appropriate label current context Let LE0 L1 Ln LEn1 LEn θ θ ϕ θ ϕ θ ϕ θ ϕ LEn Clearly LE n LEn valuation v LE0 truthvalue vθ θ LE determined recursively usual way application truth tables connectives cid6 Deﬁnition 5 Let τ Val 2LA v Val τ v Li vLi true Notice τ clearly bijection Also note v Val τ v associated Herbrand interpretation language LE 24 Lemma 6 θ LE τ v v Val vθ true λθ Proof We prove induction complexity θ Suppose θ LE0 θ Li 1 n Now v ranges valuations Li true τ v ranges subsets LA contain Li Hence τ v v Val vLi true S LA Li S λLi required Now suppose θ LEn τ v v Val vθ true λθ consider expression θ LEn1 θ LEn case result follows trivially following hold θ φ ϕ φ ϕ LEn In case cid4 cid5 v Val vφ ϕ true cid4 v Val vφ true cid5 cid4 v Val vϕ true cid5 Therefore cid4 cid5 τ v v Val vφ ϕ true cid5 cid4 τ v v Val vφ true λφ λϕ λφ ϕ inductive hypothesis Deﬁnition 3 cid4 τ v v Val vϕ true cid5 ii θ φ ϕ φ ϕ LEn In case cid4 v Val vφ ϕ true cid4 cid5 v Val vφ true cid5 cid4 v Val vϕ true cid5 J Lawry Artiﬁcial Intelligence 155 2004 139 9 Therefore cid4 cid5 τ v v Val vφ ϕ true cid5 cid4 τ v v Val vφ true λφ λϕ λφ ϕ inductive hypothesis Deﬁnition 3 cid4 τ v v Val vϕ true cid5 iii θ φ ϕ φ ϕ LEn In case cid4 cid5 cid4 v Val vφ ϕ true v Val vφ false cid5 cid4 v Val vφ true cid5 cid4 v Val vϕ true cid5 cid4 v Val vϕ true cid5 cid4 τ v v Val vϕ true cid5 inductive hypothesis Therefore cid4 cid5 τ v v Val vφ ϕ true cid5 cid4 τ v v Val vφ true λφ λϕ λφ ϕ iv θ φ φ LEn In case cid5 τ v v Val vφ true cid4 Deﬁnition 3 cid5 cid4 τ v v Val vφ true λφ λφ inductive hypothesis Deﬁnition 3 Proposition 7 For θ ϕ LE θ ϕ iff λθ λϕ Proof cid4 θ ϕ λθ λϕ cid5 v Val vθ true τ v v Val vθ true Lemma 6 cid4 cid4 v Val vϕ true cid5 cid5 cid5 cid4 τ v v Val vϕ true Suppose λθ λϕ Then λθ τ v v Val vθ true λϕ τ v v Val vϕ true Lemma 6 Therefore cid4 τ v v Val vθ true cid5 v Val vθ true cid4 cid5 cid4 τ v v Val vϕ true cid4 v Val vϕ true cid5 cid5 τ bijection A trivial corollary proposition Corollary 8 For θ ϕ LE θ ϕ iff λθ λϕ 10 J Lawry Artiﬁcial Intelligence 155 2004 139 Proposition 9 If ϕ LE inconsistent λϕ Proof If ϕ LE inconsistent ϕ θ θ Corollary 8 λϕ λθ θ λθ λθ λθ λθ Deﬁnition 3 In order introduce higher level measures appropriateness discussed earlier sections need consider logical structure label expressions conjunction set individuals probability distribution set probability distribution domain Ω To allow introduce notions frame extended frame Deﬁnition 10 Frame extended frame A frame tuple cid22V PV cid23 V set individuals PV probability distribution V ii An extended frame tuple cid22V PV Ω PΩ cid23 cid22V PV cid23 frame PΩ distribution underlying domain Ω Deﬁnition 11 Mass assignments label appropriateness degrees Given frame Γ cid22V PV cid23 deﬁne mass assignment Dx cid1cid4 S LA mΓ x S PV I V DI x S cid5cid2 In case V ﬁnite PV uniform distribution corresponds S LA mΓ x S I V DI x V S From mass assignment deﬁne appropriateness measure degree µΓ θ LE x Ω µΓ θ x mΓ x S cid3 Sλθ ii Given extended frame Γ cid22V PV Ω PΩ cid23 mass assignment Dx x varies Ω given S LA mΓ S PV PΩ cid1cid4 cid22I xcid23 DI x cid5cid2 S From mass assignment deﬁne general appropriateness degree θ LE µΓ θ cid3 mΓ S Sλθ In cases frame extended frame ﬁxed shall drop superscripts Γ Γ deﬁnitions Notice requirement Deﬁnition 11 zero mass allocated x corresponds probability frame set In label semantics mΓ J Lawry Artiﬁcial Intelligence 155 2004 139 11 Γ labels appropriate x appropriateness degrees allocating nonzero value mΓ maxµΓ L1 x µΓ Ln x 1 Dx In terms x consequence Trivially Proposition 7 θ ϕ frame Γ x Ω ϕ x extended frame Γ µΓ θ x cid1 µΓ µΓ ϕ Similarly Corollary 8 θ ϕ frame Γ x Ω µΓ ϕ x extended frame Γ µΓ cid1 µΓ θ x µΓ θ µΓ ϕ θ Proposition 12 For frame Γ θ LE x Ω µΓ θ x 1 µΓ θ x Proof µΓ θ x cid3 Sλθ mΓ x S cid3 Sλθ mΓ x S 1 cid3 Sλθ mΓ x S 1 µΓ θ x In order investigate behaviour appropriateness measure conjunctions disjunctions implications need introduce notion consonant mass assignments More speciﬁcally consider frames Γ mΓ x consonant x Ω Here consonance standard random set meaning 13 S Scid26 LA mΓ x Scid26 0 S Scid26 Scid26 S x S 0 mΓ Consonance label sets implies individuals V differ labels appropriate value terms generality speciﬁcity This justiﬁed idea individuals share common ordering appropriateness labels value composition DI x consistent ordering I More formally supposing element x Ω population V shares common total ordering cid27x Li Lj LA Li cid27x Lj means Lj appropriate label x Li In case deciding set appropriate labels individual I expected consistent cid27x Li DI x Lj DI x labels Lj Li cid27x Lj Clearly case vary individuals V values DI x occurring form nested hierarchy For instance case dice problem described Example 1 possible appropriateness orderings values SCORE 1 6 follows high cid271 medium cid271 low high cid272 medium cid272 low high cid273 low cid273 medium low cid274 high cid274 medium low cid275 medium cid275 high low cid276 medium cid276 high Hence individual I I decides low appropriate label 3 low DI 3 consistent ordering cid273 decide medium appropriate label 3 medium DI 3 medium appropriate low label 3 Notice consonance assumption random sets labels sense weaker corresponding assumption random sets universe Ω requires individuals maintain level speciﬁcity values Ω To clearly recall Example 1 observe mx consonant x 1 6 Now 12 J Lawry Artiﬁcial Intelligence 155 2004 139 member I V extension associated subset Ω medium given x Ω medium DI Hence obtain 2 3 4 3 4 5 3 4 I1 I2 I3 x respectively Clearly form nested hierarchy Proposition 13 If x Ω mΓ x Ω µΓ Li Lj x minµΓ Li x µΓ Lj x x consonant mass assignment Li Lj LA Proof Notice λLi Lj λLi λLj cid4 S LA Li S S LA Li Lj S cid5 cid4 cid5 cid4 S LA Lj S cid5 Hence x Ω µΓ Li Lj x cid3 mΓ x S S Li Lj S For x mΓ x consonant mass assignment form M0 m0 Mk mk Mt Mt 1 t 0 k 1 Now suppose wlog x Li Mt iff Li Lj Mt t 0 k Therefore mΓ x µΓ Li x cid1 µΓ Lj µΓ Li Lj x cid3 S Li S mΓ x S µΓ Li cid1 x min µΓ Li x µΓ Lj x cid2 Proposition 14 If x Ω mΓ x Ω µΓ Li Lj x maxµΓ Li x µΓ Lj x x consonant mass assignment Li Lj LA In order compare contrast label semantics manyvalued logic approach fuzzy reasoning ﬁrst formal deﬁnition meant calculus strongly functional Deﬁnition 15 Let w LE Ω 0 1 w said strongly functional iff exist functions f 0 1 0 1 f 0 12 0 1 f 0 12 0 1 f 0 12 0 1 θ ϕ LE x Ω wθ x fwθ x wθϕx fwθ x wϕx wθϕx fwθ x wϕx wθϕx fwθ x wϕx wθ x shorthand wθ x This contrasted condition calculus weakly functional deﬁned Deﬁnition 16 w LE Ω 0 1 said weakly functional iff θ LE exists function fθ 0 1n 0 1 wθ x fθ wL1x wLnx Clearly weak functionality strictly weaker condition strong functionality Strong functionality implies value w conjunction expressions depends value w conjuncts logic structure Weak J Lawry Artiﬁcial Intelligence 155 2004 139 13 functionality allows logical structure taken account It noted weak functionality sufﬁcient insure values w determined values LA information needed stored order n order exponential n higher case nonfunctional calculi 26 In view argue weak functionality adequate ensure computational feasibility real world applications In literature especially approximate reasoning case type functionality considered strong functionality However clearly calculi exist weakly strongly functional typical example standard probabilistic calculus basic events assumed independent This failure distinguish clearly levels functionality lead misunderstandings For example consider triviality results proved Dubois Prade 4 later Elkan 9 nonbinary functional calculus satisfy laws Boolean algebra For example binary functional calculi satisfy idempotence laws excluded middle noncontradiction 5 It important realise case type functionality referred strong functionality Weakly functional calculi restricted manner instance probabilistic calculi independence assumption satisfy standard boolean laws maintaining weak functionality To appropriateness measure strongly functional notice despite θ x µΓ ϕ x x From Deﬁni Propositions 13 14 hold θ ϕ LE µΓ µΓ θ x µΓ tion 3 λLi Lj λLi λLj θϕx minµΓ Li Lj ϕ x For instance consider µΓ θϕx maxµΓ cid3 µΓ Li Lj x mΓ x S S Li S Lj S Given consonance assumption know mΓ x Mt 1 t 0 k 1 Now suppose µΓ x cid1 µΓ Lj Li Li Mt Lj Mt µΓ M0 m0 Mk mk Mt x t 0 k x cid2 µΓ x Lj x 0 Alternatively µΓ Li Li Lj µΓ Li Lj x cid3 cid3 cid3 mΓ x S mΓ x S mΓ x S S Li S S Lj S x µΓ Li x max0 µΓ This summarised expression µΓ Li Lj Li x 1 µΓ general minµΓ x given strongly Lj Li functional calculus consistent Propositions 1214 fa b mina b fa b maxa b fa 1 As aside note result gives insight behaviour implication label semantics level individual labels For instance Li Lj logically equivalent Li Lj µΓ x LiLj min1 1 µΓ x This corresponds Lukasiewicz implication 14 Li 18 applies label level complex expressions x 1 max0 µΓ Li x 1 µΓ x µΓ Lj x µΓ Lj x µΓ Lj x Li Lj S Li S Lj S x µΓ Lj 14 J Lawry Artiﬁcial Intelligence 155 2004 139 µL1 x µLn x cid29 mx cid29 µθ x fθ µL1 x µLn x cid7 Sλθ mx S Fig 1 Weak functionality label semantics To appropriateness degrees weakly functional recall elementary random set theory consonant mass assignment 13 uniquely deﬁned ﬁxed point coverage This means mΓ x completely determined values L x 0 ordered L x L LA µΓ µΓ L1 yt yt 1 t 1 k 1 x follows Let y1 yk µΓ x µΓ Ln mΓ x Mt yt yt 1 t 1 k 1 Mk yk M0 1 y1 x µΓ Ln θ x uniquely determined λθ mΓ θ x µΓ L1 L x cid2 yt t 1 k Hence M0 Mt L LA µΓ Deﬁnition 11 µΓ x clearly functional relationship µΓ x Fig 1 In words linguistic expression θ function fθ 0 1n 0 1 µθ x fθ µL1x µLnx fθ evaluated consonance assumption infer mass assignment label sets summing masses sets contained λθ It noted appropriateness degree satisﬁes laws excluded middle noncontradiction sense frame Γ x Ω θ LE θθ x 0 follows immediately Propositions 9 12 θθ x 1 µΓ µΓ Thus consonance assumption applied label sets results functional calculus coincides standard fuzzy logic connectives basic label level preserving laws excluded middle noncontradiction This contrasted consonance assumption applied random sets attribute universe sufﬁcient generate functional calculus number fuzzy concepts The weak functionality label semantics brings considerable practical advantages longer need knowledge underlying population individuals V distribution PV frame order determine mx Rather reasoning label semantics practice need deﬁne appropriateness degrees µL L LA corresponding imprecise deﬁnition label cid8 cid9 One possible method calculating µΓ θ x general θ LE x Ω follows By disjunctive normal form theorem θ logically equivalent α αθ α atom conjunction literals disjunction atoms Li Now easily seen Lemma 6 atom form α form λα singleton consisting subset LA labels appearing positively α Also Deﬁnition 3 Corollary 8 λθ α αθ λα µΓ x λα NB We abusing notation slightly taking λα correspond single element 2LA associated α set containing element Alternatively convenient determine λθ recursively according Deﬁnition 3 α αθ mΓ θ x cid7 cid6 In speciﬁc context particular frame able inferences label expressions generally hold Furthermore frame effectively deﬁnes meaning relationship members LA identiﬁes subset 2LA sets appropriate labels actually occur This restriction J Lawry Artiﬁcial Intelligence 155 2004 139 15 calculation appropriateness degrees complex provided basic labels overlap semantically For instance given LA small medium large ﬁnd frame Γ small overlaps medium medium overlaps small large large overlaps medium This means following occur sets possible labels small small medium medium medium large large We formalise observation deﬁning set focal elements frame follows Deﬁnition 17 Set focal elements The set focal elements frame Γ FΓ S LA x Ω mΓ x S 0 In words focal sets correspond sets appropriate labels consistent deﬁnition labels frame Γ Given concept deﬁne following natural semantic relations LE Deﬁnition 18 Follows frame Γ For θ ϕ LE ϕ follows θ frame Γ denoted θ Γ ϕ iff λθ FΓ λϕ FΓ ii Equivalent frame Γ For θ ϕ LE ϕ equivalent θ frame Γ denoted ϕ Γ θ iff λθ FΓ λϕ FΓ iii For θ LE θ universally true frame Γ denoted Γ θ iff λθ FΓ FΓ The frame Γ provides interpretation label LA apparent respective appropriateness degrees taken account subsequent reasoning So instance generally case value small large certainly true frame appropriateness degrees small large overlap The operators Γ Γ incorporate additional information meaning labels logical notions follows equivalent These operators deﬁned terms standard propositional logic deduction following result shows Deﬁnition 19 S LA αS cid10 cid11 cid10 cid11 cid12 Li cid12 Li Li S Li S Lemma 20 λ cid8 SFΓ αS FΓ Proof λ cid8 SFΓ αS cid6 SFΓ λαS Deﬁnition 3 Now 16 J Lawry Artiﬁcial Intelligence 155 2004 139 cid10cid10 cid11 λαS λ cid10 cid11 cid12 Li Li cid12cid12 cid13 Li S λLi cid13 Li S λLi Li S cid13 Li S cid4 T LA Li T cid5 Deﬁnition 19 cid13 cid4 T LA Li T cid5 Deﬁnition 3 Li S cid4 T LA S T cid8 cid5 cid6 Li S cid4 cid5 T LA S T S Therefore λ SFΓ S FΓ required SFΓ αS cid8 Proposition 21 θ Γ ϕ iff SFΓ αS θ ϕ Proof θ Γ ϕ λθ FΓ λϕ FΓ cid10 cid14 cid12 Deﬁnition 18 cid12 cid10 cid14 λθ λ αS λϕ λ λϕ Lemma 20 αS SFΓ αS λϕ Deﬁnition 3 SFΓ cid12 cid14 cid10 λ θ cid15 SFΓ cid10 τ v v Val v θ cid4 cid15 τ v v Val vϕ true cid10 v Val v θ cid14 αS SFΓ θ cid4 cid5 v Val vϕ true cid14 αS ϕ required cid12 cid16 αS true cid14 SFΓ cid5 cid12 Lemma 6 cid16 true τ bijection SFΓ cid14 SFΓ θ cid15 αS ϕ cid10 v Val v θ cid15 cid14 SFΓ cid10 v Val v θ cid15 cid10 τ v v Val v θ cid12 cid16 αS true cid4 v Val vϕ true cid5 cid12 cid16 cid15 cid10 αS cid12 true v Val v ϕ cid16 true cid14 SFΓ cid14 αS SFΓ cid12 cid16 αS true cid14 SFΓ J Lawry Artiﬁcial Intelligence 155 2004 139 17 cid15 cid10 τ v v Val v ϕ cid14 cid12 cid16 αS true τ bijection cid10 λ θ cid14 SFΓ cid14 cid12 cid10 αS λ ϕ cid12 αS Lemma 6 SFΓ cid10 cid14 λϕ λ cid12 αS Deﬁnition 3 SFΓ cid10 cid14 λθ λ cid12 αS SFΓ λθ FΓ λϕ FΓ θ Γ ϕ required SFΓ Lemma 20 Proposition 21 tells information meaning labels LA contained particular focal set S completely represented logical expression αS In sense expected set S αS provides logical description S stating exactly labels contained S The corollary follows trivially Proposition 21 Corollary 22 θ Γ ϕ iff cid14 cid14 αS θ αS ϕ SFΓ SFΓ x µΓ Ln We observe mΓ x completely determined µΓ L1 x set focal elements Γ determined given values Therefore strong sense meaning labels LA captured appropriateness degrees A common example Deﬁnition 18 certain label conceptually implied label For instance described tall described tall In fuzzy set theory captured taking fuzzy set tall fuzzy subset fuzzy set tall In label semantics expect frame Γ tall deemed appropriate label tall In words tall Γ tall alternatively Γ tall tall In case easy x Ω µΓ tallx instance fuzzy set theory label semantics coincide In general frame Γ θ Γ ϕ x Ω θ x cid1 µΓ µΓ tallx cid1 µΓ ϕ x Example 23 Let LA small medium large Ω 0 10 Γ frame small µΓ µΓ large trapezoidal functions Fig 2 deﬁned medium µΓ µΓ smallx cid17 1 2 x 2 0 x 0 2 x 2 4 x 4 µΓ mediumx 1 0 x 2 1 4 x 2 0 x 2 x 2 4 x 4 6 x 6 8 x 8 18 J Lawry Artiﬁcial Intelligence 155 2004 139 Fig 2 Appropriateness degrees left right small medium large µΓ largex cid17 0 x 2 1 3 x 6 x 6 8 x 8 Allowing x vary 0 10 obtain following deﬁnition mΓ x follows Fig 3 cid1 small cid2 mΓ x cid17 1 3 x 0 x 0 2 x 2 3 x 3 cid1 small medium cid2 mΓ x 0 x 1 2 2 x 2 0 x 2 x 2 3 x 3 4 x 4 cid1 medium cid2 mΓ x 0 x 3 1 7 x 0 x 3 x 3 4 x 4 6 x 6 7 x 7 cid1 medium large cid2 mΓ x 0 x 2 4 x 2 0 x 6 3 x 6 7 x 7 8 x 8 J Lawry Artiﬁcial Intelligence 155 2004 139 19 Fig 3 Mass assignments varying x shown left mΓ x medium large mΓ equal mΓ x medium large x 6 8 zero x medium mΓ x large mΓ right mΓ x equal mΓ x small mΓ x small medium x small medium x 2 4 cid17 cid1 large cid2 mΓ x 0 x 7 1 x 7 x 7 8 x 8 mΓ x 0 x 1 2 2 x 2 0 x 3 2 4 x 2 0 x 2 x 2 3 x 3 4 x 4 6 x 6 7 x 7 8 x 8 This gives set focal elements FΓ small small medium medium medium large large example follows µΓ mediumlargex cid1 mΓ x small medium cid2 cid1 mΓ x medium cid2 0 x 2 1 7 x 0 x 2 1 x 2 4 x 4 6 x 6 7 x 7 smallmediumlargex mΓ µΓ x cid1 medium cid2 x 3 0 x 3 x 3 4 4 6 1 x 6 7 7 x x 7 0 20 J Lawry Artiﬁcial Intelligence 155 2004 139 Fig 4 Appropriateness degree µΓ dashed line mediumlargex solid line minµΓ mediumx 1µΓ largex µΓ mediumx smallmediumx mΓ µΓ x cid1 cid2 large mΓ x 0 x 2 2 x 2 0 x 2 1 x 2 1 x 2 3 x 3 4 x 4 6 3 x 6 8 x 8 Fig 3 shows values mass assignment mx focal element x ranges Ω From mass associated set values ranges 2 4 6 8 In label semantics suggest individuals V terms LA appropriate labels values ranges One observe phenomena occurs frequently natural language especially labelling perceptions generated continuum For example occasionally en counter colours available colour descriptors appropriate Fig 4 clearly illustrates difference label semantics fuzzy logic evaluating compound expressions case medium large It interesting note strongly functional fuzzy logic based min conjunction function statements x medium x medium large provide exactly informa tion memberships In words extra information x large tells This highly counter intuitive On hand label semantics µmediumlarge zero values greater seven values sets appropriate labels nonzero mass containing medium contain large 4 Multidimensional label semantics Most modelling problems involve multiple attributes variables Therefore label semantics provide effective knowledge representation framework linguistic J Lawry Artiﬁcial Intelligence 155 2004 139 21 modelling generalised multidimensional case In words need provide means interpreting evaluating linguistic expressions involving variable Speciﬁcally consider modelling problem k variables attributes x1 xk associated universes Ω1 Ωk For variable deﬁne set labels LAj L1j Lnj j j 1 k In case ask individuals V provide set appropriate labels attribute value Hence individual I provide cid23 attribute vector cid22a1 akcid23 In vector label descriptions cid22DI a1 context extend deﬁnitions mass assignment appropriateness degree given Section 3 multidimensional case Initially formally deﬁne kdimensional linguistic expressions DI ak Let LEj set label expression variable xj generated recursive application connectives labels LAj We deﬁne set multi dimensional label expression describing linguistic relationships variables follows Deﬁnition 24 Multidimensional label expressions MLEk set multi dimensional label expressions generated label expression LEj j 1 k deﬁned recursively If θ LEj j 1 k θ MLEk ii If θ ϕ MLEk θ θ ϕ θ ϕ θ ϕ MLEk Any kdimensional label expression θ identiﬁes subset 2LA1 2LAk denoted λkθ constraining cross product label descriptions Dx1 Dxk In way imprecise constraint θ x1 xk interpreted precise constraint Dx1 Dxk λkθ Deﬁnition 25 Multidimensional appropriate label sets θ MLEk λkθ 2LA1 2LAk θ LEj λkθ 1λθ ij 2LAi θ ϕ MLEk λkθ ϕ λkθ λkϕ λkθ ϕ λkθ λkϕ λkθ ϕ λkθ λkϕ λkθ λkθ Note context particular frame Γ convenient evaluate set focal elements LAj given frame Γ Γ F j F j j 1 Γ λkθ k Deﬁnition 17 1 λθ LAj refers dimensional appropriate label set given Deﬁnition 3 22 J Lawry Artiﬁcial Intelligence 155 2004 139 Example 26 Consider modelling problem variables x1 x2 LA1 small medium large LA2 low moderate high Also suppose given frame Γ focal elements LA1 LA2 respectively cid4 cid4 F 1 Γ F 2 Γ small small medium medium medium large large cid5 low low moderate moderate moderate high high cid5 Now according Deﬁnition 25 cid1 cid2 medium small low λ2 λ2medium small λ2low λmedium small λlow Now λmedium small F 1 Γ cid4 medium medium large cid5 λlow F 2 Γ cid4 moderate moderate high high cid5 Hence cid2 F 2 Γ cid1 λ2 cid1 F 1 Γ cid2 medium small low cid4 cid22medium moderatecid23 cid22medium moderate highcid23 cid22medium highcid23 cid22medium large moderatecid23 cid22medium large moderate highcid23 cid5 cid22medium large highcid23 Deﬁnition 27 Joint mass assignment xj Ωj Sj LAj j 1 k mcid22x1xkcid23S1 Sk kcid22 j 1 mxj Sj Now mcid22x1xkcid23S1 Sk PV cid1 I V Dx1 S1 Dxk Sk cid2 provided following conditional independence assumption It assumed individual I choice appropriate labels variable xj dependent value xj known independent value variables This actually weak assumption prior imply independence variables J Lawry Artiﬁcial Intelligence 155 2004 139 23 Deﬁnition 28 Multidimensional appropriateness degrees θ MLEk xj Ωj j 1 k µk θ x1 xk cid3 mcid22x1xkcid23S1 Sk cid22S1Skcid23λkθ cid3 kcid22 cid22S1Skcid23λkθ j 1 mxj Sj Proposition 29 If θ MLEc c k xj Ωj j 1 k µk θ x1 xk µc θ x1 xc Proof By Deﬁnition 25 λkθ λcθ k j c12LAj µk θ x1 xk cid3 cid3 mcid22 j 1 mxj Sj cid3 kcid22 cid22S1Sccid23λcθ cid3 cid22Sc1Skcid232LAc1 2LAk ccid22 cid3 mxj Sj mxj Sj cid22S1Sccid23λcθ cid3 j 1 ccid22 Sc1LAc1 cid23 kcid22 cid3 SkLAk j c1 cid24 cid22S1Sccid23λcθ cid3 j 1 ccid22 cid22S1Sccid23λcθ j 1 mxj Sj mxj Sj j c1 Sj LAj mxj Sj µc θ x1 xc required Proposition 30 Let θj LEj j 1 k appropriateness degree conditional k1 j 1 θj θk given cid9 µk cid9 k1 j1 θj θk x1 xk 1 k1cid22 j 1 µθj xj kcid22 j 1 µθj xj Proof By Deﬁnition 25 cid25 cid25cid25 cid26 cid26 λk θj θk λk k1cid11 j 1 cid26 θj λkθk λk cid26 θj λkθk cid25 k1cid11 j 1 k1cid11 j 1 Now Deﬁnition 25 follows cid25 cid26 k1cid11 j 1 λk θj λkθk λθ1 λθk1 λθk 24 J Lawry Artiﬁcial Intelligence 155 2004 139 Therefore µk cid9 x1 xk k1 j1 θj θk cid23 k1cid22 cid3 j 1 Sj λθj k1cid22 j 1 µθj xj 1 cid23 1 required cid24 mxj Sj cid27 cid3 cid28 mxk Sk cid24 cid29 Skλθk cid30 1 µθk xk 1 k1cid22 j 1 µθj xj kcid22 j 1 µθj xj It interesting note corresponds use Reichenbach implication operator surprisingly generated product tconorm Example 31 Consider modelling problem variables x1 x2 universe 0 10 deﬁned label sets LA1 small1s1 medium1m1 large1l1 LA2 small2s2 medium2m2 large2l2 For variables appropriateness degrees small medium large deﬁned Example 23 Now suppose learn If x1 medium large x2 medium according Proposition 30 appropriateness degree medium1 large1 medium2 given µ2 medium1large1 1 µmedium1large1x1 µmedium1large1x1µmedium2x2 medium2 x1 x2 Assuming appropriateness degrees small medium large given Example 23 resulting function shown Fig 5 Clearly function provides information relationship x1 medium2 For instance Fig 5 x2 assuming constraint medium1 large1 Fig 5 Plot appropriateness degree medium1 large1 medium2 J Lawry Artiﬁcial Intelligence 155 2004 139 25 x1 5 unlikely 8 cid1 x2 cid1 10 The problem output predictions x2 given input values x1 considered sequel Now suppose learn If x1 large x2 small In case want evaluate appropriateness degrees expression medium1 large1 cid1 small2 For expression medium2 large1 cid2 λ2 m1 l1 m2 l1 s2 cid2 cid1 λ2m1 l1 λ2m2 cid1 λ2m1 l1 λ2m2 cid1 cid1 λm1 l1 λm2 cid2 cid2 cid1 cid1 λ2l1 λ2s2 λ2l1 λ2s2 cid2 λl1 λs2 cid2 cid2 Now cid1 λm1 l1 λm2 cid5 cid4 s1 m1 m1 cid2 F 2 F 1 Γ cid5 cid4 m2 m2 l2 l2 Γ λl1 λs2 cid5 cid4 m2 m2 l2 l2 Hence sets 2LA1 2LA2 mutually exclusive follows cid4 l1 m1 l1 cid1 F 1 Γ F 2 cid5 cid2 Γ x1 Ω1 x2 Ω2 µ2 cid10 cid3 cid3 m1l1m2l1s2x1 x2 mx1S1mx2S2 cid3 cid3 cid12 mx1S1mx2S2 1 cid1 1 S1λm1l1 µm1l1x1 S2λm2 cid1 1 µm2x2 cid2 S1λl1 cid1 S2λs2 1 µs2x2 µl1x1 cid2cid2 Again assuming appropriateness degrees small medium large given Example 23 resulting function shown Fig 6 Fig 6 Plot appropriateness degree medium1 large1 medium2 large1 small2 26 J Lawry Artiﬁcial Intelligence 155 2004 139 The semantics proposed section based idea meaning vague linguistic expressions determined use population individuals This close theory vagueness proposed Black 3 An alternative viewpoint fuzzy concepts inherently vague independent actual use In principle possible provide operational semantics membership functions consistent interpretation little foundational work kind undertaken For example possible semantics kind based idea membership values measure similarity set prototypical exemplars concept 3133 However alternative approach problem vague concepts scope paper instead focus entirely random set interpretation 5 Conditional information linguistic constraints To understand information content linguistic expressions consider nature constraints expression place underlying variable If know Bill tall exactly tell Bills height For example determine exact value distribution values family distributions In 37 proposed constraints specify possibility distribution underlying variable given membership degree associated fuzzy set This suggest resulting family probability distributions characterised corresponding possibility dual necessity measure However applications fuzzy sets particular fuzzy control socalled defuzziﬁcation techniques treat possibility distribution probability distribution order estimate precise value variable In case Bills height called centre mass defuzziﬁcation method 30 evaluate cid31 Ω xµtallx dx cid31 Ω µtallx dx Clearly obvious semantic justiﬁcation fuzzy set theory In addition association membership values fuzzy sets discussed 37 nature primitive deﬁnition consequence lower level semantics membership possibility In section introduce label semantics based approach linguistic constraints argue order inferences underlying variable based linguistic expression knowledge frame associated extended frame Since appropriateness degrees analogue fuzzy memberships label semantics determined frame clearly claiming information inadequate draw general conclusions linguistic expressions For simplicity assume sequel extended frame Γ PΩ discrete associated density function pΩ Now consider knowledge base consisting single label expression θ meaning Dx λθ Then according Bayes theorem infer following posterior distribution Ω J Lawry Artiﬁcial Intelligence 155 2004 139 27 Continuous case Ω paθ Prθ x apΩ cid31 Ω Prθ xpΩ x dx Discrete case Ω Prx aθ cid7 Prθ x aPΩ x xΩ PΩ x0 Prθ xPΩ x Now according label semantics Prθ x Pr cid1 Dx λθ x cid2 cid1 Da λθ cid2 Pr cid3 Sλθ maS µθ Therefore obtain continuous case x Ω px θ cid31 µθ xpΩ x Ω µθ xpΩ x dx discrete case x Ω Prx θ cid7 µθ xPΩ x xΩ PΩ x0 µθ xPΩ x From appropriateness degrees viewed likelihood measure µθ x interpreted likelihood θ appropriate label x This surprising Dubois Prade 6 comment likelihood random set semantics fuzzy concepts strongly linked A number authors independently investigated likelihood semantics possibility fuzzy sets outside random set framework including Hisdal 17 Dubois Moral Prade 7 Also Thomas 32 investigated relationship Bayesian reasoning fuzzy sets The likelihood interpretation important consequences level condition information obtain knowledge x constrained θ Clearly given appropriateness degrees deﬁned LA sufﬁcient knowledge frame knowledge posterior distribution depends entirely knowledge prior PΩ associated extended frame For example know PΩ P set distributions P able determine upper lower bounds posterior describing inferred family posterior distributions In discrete case upper lower probabilities deﬁned follows x Ω Pr x θ sup PΩ P cid7 µθ xPΩ x xΩ µθ xPΩ x x Ω Prx θ inf PΩ P cid7 µθ xPΩ x xΩ µθ xPΩ x This essentially corresponds special case imprecise Bayesian inference proposed Walley 34 However noted practice surprisingly little information inferred knowledge For example consider scenario 28 J Lawry Artiﬁcial Intelligence 155 2004 139 described Example 1 prior knowledge score dice 2 3 P PΩ PΩ 2 PΩ 3 1 Furthermore suppose informed SCORE low Now appropriateness degree low 2 1 3 1 3 expect safely infer PrSCORE 2 low cid2 PrSCORE 3 low A little trivial mathematics reveals case prior PΩ 2 1 ﬁnd PrSCORE 2 low 1 PrSCORE 3 low 0 prior PΩ 3 1 obtain PrSCORE 3 low 1 PrSCORE 2 low 0 Obviously terms upper lower bounds infer PrSCORE 2 low PrSCORE 3 low 0 1 PrSCORE 1 2 low 1 We presence relatively speciﬁc linguistic constraints information infer value underlying variable strongly dependent prior assumptions distribution For instance inequality PrSCORE 2 low cid2 PrSCORE 3 low suggested holds 1 4 µlow3 µlow2 µlow3 PΩ 2 cid2 See 35 alternative semantics linguistic concepts based upper lower probabilities A common problematic 36 discussion assumption Bayesian analysis assume uniform prior Ω In case obtain Pr2 low µlow2 µlow2 µlow3 3 4 Pr3 low µlow3 µlow2 µlow3 1 4 Generally assumption uniform prior Ω gives Prxθ proportional µθ x px θ µθ x cid31 Ω µθ x dx continuous case Prx θ cid7 µθ x xΩ µθ x discrete case Now required estimate precise value x basis linguistic constraint θ natural approach current context simply determine expected value Prx θ Clearly uniform prior Ω assumed gives expression appropriateness degrees equivalent centre mass defuzziﬁcation method described J Lawry Artiﬁcial Intelligence 155 2004 139 29 We illustrate conditioning evaluate output values given speciﬁc input values relationships input output variables described terms linguistic expressions Initially observe conditional distributions deﬁned easily extended multi dimensional case θ MLEk xj Ωj j 1 k px1 xk θ cid31 px1 xk prior distribution Ω1 Ωk µk θ x1 xkpx1 xk dx Ω1 Ωk µk cid31 θ x1 xkpx1 xk Example 32 Recall problem described Example 31 knowledge relationship variables x1 x2 corresponds medium2 large1 Assuming uniform prior distribution 0 102 posterior distribution x1 x2 given K medium1 large1 small2 x1 Ω1 x2 Ω2 px1 x2 K µ2 m1l1m2l1s2x1 x2 cid31 0 µ2 m1l1m2l1s2x1 x2 dx1 dx2 10 cid31 10 0 Now suppose given value x1 want calculate probability different values x2 given information In case need evaluate following conditional distribution px2 K x1 px1 x2 K px1 K µ2 m1l1m2l1s2x1 x2 cid31 0 µ2 m1l1m2l1s2x1 x2 dx2 10 A plot distribution x1 x2 vary given Fig 7 In case x1 65 conditional density px2 K 65 shown Fig 8 Fig 7 Plot conditional density px2 K x1 30 J Lawry Artiﬁcial Intelligence 155 2004 139 Fig 8 Plot conditional density px2 K 65 Therefore order obtain estimate output x2 given input x1 65 evaluate expected value distribution 10 ˆx1 x2px2 K 65 dx2 45079 0 In situations conditional information form linguistic expression distribution linguistic expressions In label semantics information provides constraints distribution mass assignment Dx x varies Here consider simplest case sufﬁcient constraints available specify unique mass assignment Dx To illustrate speciﬁc knowledge obtained let return height problem extended frame Γ cid22V PV Ω PΩ cid23 PΩ prior based known distribution heights European males Furthermore suppose database DB heights ﬁnite number British males x Ω PDBx corresponds probability male height x chosen random DB Given evaluate mass assignment Dx conditional information x height British male follows S LA mDBS cid3 PDBxmxS xΩ PDBx0 Now given posterior mass assignment mDB Dx information infer underlying variable x According theorem total probability pa PrDx Spa Dx S cid3 SLA Hence know S LA PrDx S mDBS condition knowledge follows cid3 pa mDB mDBSpa Dx S SLA Now according Bayes theorem J Lawry Artiﬁcial Intelligence 155 2004 139 31 Fig 9 Appropriateness degrees labels diastolic blood pressure Ω pa Dx S PrDx S x apΩa cid31 Ω PrDx S x apΩ da maSpΩ cid31 Ω maSpΩ da Let Ω maSpΩ da pmS prior mass assignment Dx generated prior distribution PΩ Ω x Ω px mDB cid3 SLA mDBS mx SpΩ x pmS pΩ x cid3 SLA mDBS pmS mxS Notice case S LA mDBS pmS words posterior knowledge Dx matches prior knowledge px mDB pΩ x intuitively expect Example 33 This example relates database stored machine learning repository University California Irvine It essentially classiﬁcation problem serves illustrate use label semantics determine underlying distributions data The database contains details 768 females population Pima Indians living near Phoenix Arizona USA The diagnostic binary valued variable investigated patient shows signs diabetes according World Health Organisation criteria There measured variables include number times pregnant plasma glucose concentration diastolic blood pressure triceps skin fold thickness 2hour serum insulin body mass index diabetes pedigree function age A label semantics approach 21 29 conjunction Bayesian classiﬁer shall simply use example posterior mass assignment infer posterior density underlying variable 32 J Lawry Artiﬁcial Intelligence 155 2004 139 Fig 10 Mass assignment labels diastolic blood pressure diabetics diastolic blood pressure In case LA small small medium large large appropriateness degrees shown Fig 9 These functions deﬁned percentile based approach ensure label covers approximately number data elements Clearly set focal elements frame given cid4 FΓ small small small small small medium medium medium large large large large large cid5 The extended frame assumed Ω 0 122 PΩ uniform distribution interval The posterior mass assignments Fig 10 generated subdatabase DIAB diabetic individuals given mDIAB small 00805969 small small 0110448 small 0101492 small medium 0117911 medium 007462 medium large 0084223 large 0106608 large large 0222976 large 0101119 The prior mass assignment domain based uniform prior PΩ pm small 0368 small small 01434 small 004099 small medium 003074 medium 002049 medium large 002459 large 002869 large large 009631 large 02459 Now instance 68 m68 small 04 small medium 06 J Lawry Artiﬁcial Intelligence 155 2004 139 33 Fig 11 Posterior density diastolic blood pressure diabetics cid27 cid1 small cid2 mDIABsmall p68 mDIAB 1 m68 pmsmall 122 mDIABsmall medium pmsmall medium cid27 0101492 004099 1 122 04 011791 003074 cid1 small medium m68 cid28 cid2 cid28 06 00269822 The posterior density obtained shown Fig 11 Another interesting issue relating conditional inference linguistic expressions conditional matching expressions For example suppose told Bill tall level certainty infer Bill tall In section propose approaches matching framework label semantics probabilistic nature 6 Matching linguistic expressions Suppose known variable x constrained linguistic expression ϕ In case degree expression θ appropriately x This important question takes special signiﬁcance area fuzzy possibilistic logic programming 128 In context mechanism required evaluate semantic match uniﬁcation expression θ forming query given expression ϕ knowledge base A number authors investigate problem relevance current framework work Baldwin et al 2 introduces measure semantic uniﬁcation based 34 J Lawry Artiﬁcial Intelligence 155 2004 139 conditional probability fuzzy events This measure based random sets deﬁned attribute universe label level In section present measures matching expressions discuss respective properties The ﬁrst approach follows If know linguistic expression ϕ holds corresponds event Dx λϕ according Bayesian inference update prior mass assignment m obtain posterior mass assignment mϕ follows S LA mϕS cid17 pmS Sλϕ pmS cid7 0 S λϕ Interestingly mϕ consistency deﬁnition conditional distribution given linguistic expression conditional distribution given mass assignment highlighted following proposition NB In following proofs assumed PΩ density pΩ The ﬁnite case proved similar way Proposition 34 x Ω pxmϕ px ϕ Proof x Ω px mϕ pΩ x deﬁnition mϕ cid3 SLA mϕS pmS mxS pΩ x cid3 Sλϕ mϕS pmS mxS pΩ x cid3 Sλϕ cid7 mxS Sλϕ pmS pΩ x cid7 cid7 Sλϕ mxS Sλϕ pmS cid7 Now Sλϕ mxS µϕx Deﬁnition 11 cid3 cid3 pmS mxSpΩ x dx cid10 cid3 cid12 mx S pΩ x dx Sλϕ Sλϕ Ω Sλϕ Ω µϕxpΩx dx Ω Therefore px mϕ cid31 pΩ xµϕx Ω pΩ xµϕx dx px ϕ Given mϕ evaluate likelihood linguistic expression θ according following deﬁnition Deﬁnition 35 Matching type I θ ϕ LE µΓ θϕ cid3 mϕS Sλθ J Lawry Artiﬁcial Intelligence 155 2004 139 35 It easily seen deﬁnition match expressed terms conditional probabilities Dx follows Proposition 36 θ ϕ LE µΓ θϕ PrDx λθ Dx λϕ Proof cid1 Pr Dx λθ Dx λϕ cid2 PrDx λθ λϕ PrDx λϕ PrDx λθ ϕ PrDx λϕ Deﬁnition 3 Bayes theorem cid31 Ω PrDx λθ ϕ x apΩ da cid31 Ω PrDx λϕ x apΩ da cid31 cid7 Ω maSpΩ da Sλθϕ cid31 Ω maSpΩ da Sλϕ cid7 cid7 cid3 Sλθϕ cid7 pmS Sλϕ pmS cid3 Sλθ Sλθϕ pmS cid7 Sλϕ pmS mϕS cid7 cid31 Ω cid31 Ω Sλθϕ maSpΩ da cid7 Sλϕ maSpΩ da Given easily seen µΓ θϕ cid31 Ω µθϕxpΩ x dx cid31 Ω µϕxpΩ x dx 1 µΓ ϕϕ Interestingly θ ϕ LA corresponds degree subsethood measure proposed Kosko 19 compound expressions case Also proposition shows µΓ θϕ truly conditional extension general appropriateness measure deﬁned Section 3 notation suggests Furthermore notice trivially µΓ 0 case deﬁnitions ϕϕ conditional match proposed literature example 2 However label semantics alternative deﬁnition match satisfy properties deﬁned follows Suppose know ϕ asserted individual V likelihood θ hold true individual randomly chosen V To evaluate observe given ϕ determine distribution underlying variable x px ϕ value x know probability θ deemed appropriate label expression µθ x From obtain following deﬁnition match θ given ϕ Deﬁnition 37 Matching type II θ ϕ LE π Γ θϕ µθ xpx ϕ dx Ω Given deﬁnition pxϕ rewritten π Γ θϕ cid31 Ω µθ xµϕxpΩ x dx cid31 Ω µϕxpΩ x da 36 J Lawry Artiﬁcial Intelligence 155 2004 139 Fig 12 Matching types I II large given medium The dark grey area corresponds numerator π Γ largemedium assuming uniform prior sum dark light grey areas corresponds numerator µΓ largemedium Interestingly taking µ analogous fuzzy memberships corresponds deﬁnition conditional probability fuzzy events proposed 37 Obviously case π Γ ϕϕ 0 However intuitive given prevailing interpretation π fact particular individual deems ϕ appropriate label expression guarantee individuals ϕϕ necessarily equal 1 π Γ Example 38 Consider extended frame Ω 0 1 PΩ uniform distribution 0 1 x025 025 075x 025 0 x 025 05 x 05 075 µlarge x05 025 1x 025 0 x 05 075 x 075 1 µmedium µΓ largemedium cid31 1 0 µlargemediumx dx cid31 1 0 µmediumx dx cid31 1 0 minµmediumx µlargex dx cid31 1 0 µmediumx dx 00625 025 025 Alternatively π Γ largemedium cid31 1 0 µlargexµmediumx dx cid31 1 0 µmediumx dx 00416667 025 0166667 075 cid31 025 x05 05 075x 025 025 dx J Lawry Artiﬁcial Intelligence 155 2004 139 37 Fig 13 Matching type II medium given medium The dark grey area represents numerator π Γ mediummedium Now stated µΓ mediummedium cid31 1 0 µ2 mediumx dx cid31 1 0 µmediumx dx π Γ mediummedium 1 hand cid31 05 025 x025 025 2 dx 025 0166667 025 0666667 7 Conclusions A new framework linguistic modelling referred label semantics presented based random set interpretation measure appropriateness label value A natural weakly functional calculus appropriateness degree described satisﬁes law excluded middle general takes account logical structure compound expressions evaluating This calculus combined bayesian framework provide means inferring distributions underlying variable given linguistic expressions mass assignments Furthermore given linguistic expression presented methods evaluating likely applicability linguistic expressions based measures conditional match types I II Overall claim label semantics potential act effective high level knowledge representation framework modelling problems At present applications centred use data mining machine learning number new methods developed based ideas proposed Section 4 Lawry 21 Randon 29 In context label semantics offers prospect combining numerical linguistic reasoning discussed Lawry 23 Furthermore provides mechanism conditioning prior background linguistic information infer probability distributions conjunction models derived data In different context method estimating distributions data described Section 4 evaluate imprecise probabilities failure 38 J Lawry Artiﬁcial Intelligence 155 2004 139 risk analysis environmental engineering 15 16 More generally framework outlined paper gives coherent calculus linguistic reasoning variety decisionsupport problems Certainly context notions appropriateness degree conditional match central role play Acknowledgements Many thanks Tru Cao John Shepherdson helpful discussions I like thank anonymous referees patience insightful comments This work partially funded grant Nufﬁeld Foundation References 1 T Alsinet L Godo A complete calculus possibilistic logic programming fuzzy propositional variable Proceedings Uncertainty AI 2000 Stanford CA 2000 2 JF Baldwin TP Martin BW Pilsworth FrilFuzzy Evidential Reasoning AI Wiley New York 1995 3 M Black Vagueness An exercise logical analysis Philos Sci 4 1937 427455 4 D Dubois H Prade An introduction possibility fuzzy logics P Smets et al Eds NonStandard Logics Automated Reasoning Academic Press New York 1988 pp 742755 5 D Dubois H Prade Can enforce compositionality uncertainty calculi Proc AAAI94 Seattle WA 1994 pp 149154 6 D Dubois H Prade The semantics fuzzy sets Fuzzy Sets Systems 90 1997 141150 7 D Dubois S Moral H Prade A semantics possibility theory based likelihoods J Math Anal Appl 205 1997 359380 8 D Dubois H Prade Possibility theory Qualitative quantitative aspects DM Gabbay P Smets Eds Handbook Defeasible Reasoning Uncertainty Management Systems vol 1 Kluwer Dordrecht 1998 pp 169226 9 C Elkan The paradoxical success fuzzy logic Proc AAAI93 Washington DC MIT Press Cambridge MA 1993 pp 698703 10 BR Gaines Fuzzy probability uncertainty logics J Inform Control 38 1978 154169 11 H Geffner Default Reasoning Causal Conditional Theories MIT Press Cambridge MA 1992 12 IR Goodman Fuzzy sets equivalence classes random sets R Rager Ed Fuzzy Set Possibility Theory 1982 pp 327342 13 IR Goodman HT Nguyen Uncertainty Models Knowledge Based Systems NorthHolland Amster dam 1985 14 P Hajek Fuzzy logic logical point view M Bartosek et al Eds SOFSEM 95 Theory Practice Informatics Lecture Notes Computer Science vol 1012 1995 pp 3149 15 J Hall J Lawry Imprecise probabilities engineering failure random fuzzy set reliability analysis Proceedings Second International Symposium Imprecise Probabilities Their Applications New York 2001 16 J Hall J Lawry Fuzzy label methods constructing imprecise limit state functions Structural Safety 28 2003 317341 17 E Hisdal Are grades membership probabilities Fuzzy Sets Systems 25 1988 325348 18 GJ Klir B Yuan Fuzzy Sets Fuzzy Logic PrenticeHall Englewood Cliffs NJ 1995 19 B Kosko Neural Networks Fuzzy Systems A Dynamical Systems Approach Machine Intelligence PrenticeHall Englewood Cliffs NJ 1992 20 J Lawry A voting mechanism fuzzy logic Internat J Approx Reason 19 1998 315333 J Lawry Artiﬁcial Intelligence 155 2004 139 39 21 J Lawry Label prototypes modelling words Proceedings The North American Fuzzy Information Processing Society 2001 Conference 2001 22 J Lawry Label semantics A formal framework modelling words S Benferhat P Besnard Eds Proceedings Sixth European Conference Symbolic Quantitative Approaches Reasoning Uncertainty Lecture Notes Artiﬁcial Intelligence vol 2143 Springer Berlin 2001 pp 374384 23 J Lawry Query evaluation linguistic prototypes Proceedings FUZZIEEE 2001 Workshop Modelling Words Melbourne Australia 2001 pp 3942 24 JW Lloyd Foundations Logic Programming Second Edition Springer Berlin 1987 25 HT Nguyen On modeling linguistic information random sets Inform Sci 34 1984 265274 26 JB Paris The Uncertain Reasoners Companion A Mathematical Perspective Cambridge University Press Cambridge 1994 27 JB Paris Semantics fuzzy logic supporting truth functionality V Novak I Perﬁlieva Eds Discovering World Fuzzy Logic Springer Berlin 2000 28 J Pearl Probabilistic Reasoning Intelligent Systems Morgan Kaufmann San Mateo CA 1988 29 NJ Randon J Lawry A transparent framework data mining modelling words Proceedings 2001 UK Workshop Computational Intelligence 2001 30 EH Ruspini PP Bonnisone W Pedtycz Eds Handbook Fuzzy Computation Institute Physics Publishing 1998 31 EH Ruspini On semantics fuzzy logic Internat J Approx Reason 5 1991 4588 32 SF Thomas Fuzziness Probability ACG Press Kansas 1995 33 E Trillas L Valverde An enquiry indistinguishability operators HJ Skala S Termini E Trillas Eds Aspects Vagueness Kluwer Academic Publishers Dordrecht 1984 pp 231256 34 P Walley Statistical Inference Imprecise Probabilities Chapman Hall London 1991 35 P Walley G Cooman A behavioural model linguistic uncertainty Inform Sci 34 1999 137 36 SL Zabell Symmetry discontents Causation Chance Credence Vol 1 Kluwer Academic Dordrecht 1988 pp 155190 37 LA Zadeh Probability measures fuzzy events J Math Anal Appl 23 1968 421427 38 LA Zadeh The concept linguistic variable application approximate reasoning Part 1 Inform Sci 8 1975 199249 39 LA Zadeh The concept linguistic variable application approximate reasoning Part 2 Inform Sci 8 1975 301357 40 LA Zadeh The concept linguistic variable application approximate reasoning Part 3 Inform Sci 9 1976 4380 41 LA Zadeh Fuzzy sets basis theory possibility Fuzzy Sets Systems 1 1978 328 42 LA Zadeh Fuzzy logic computing words IEEE Trans Fuzzy Systems 2 1996 103111