ELSEVIER Artificial Intelligence 100 1998 275322 Artificial Intelligence Pragmatic navigation reactivity heuristics search Susan L Epstein Deprrttnent Computer Science Hunter College und The Graduate School The City University f New York 695 Park Avenue New York NY 10021 USA Received I7 April 1997 revised 15 October 1997 Abstract techniques architecture Right Reasons set solution methods opportunity learning problem solving serial testing known triggered incomplete overlapping represents inte address complex problems facet domain expertise vary reliability FORR For grates possibly Each method speed The principal contribution paper extension FORR include situationbased behavior reactivity heuristic based addresses problem reasoner activates set reactive If fail produce response rationales All components experiments strate component plays important paper include FORRbased pragmatic cognitively plausible approach learned heuristic Empirical evidence demonstrates guidelines problem solving domain reasoning FORR categorizes methods reactive heuristic situation solving category methods time A hierarchical reasoner tailored specific situations heuristic In series shown effective efficient Ablation experiments demon role problem solving Additional contributions navigation territory travel experience interact effective efficient domains provided 1998 Elsevier Science BV search procedures resorts learned reasoner reference knowledge careful study situationbased collaboration experience react correctly If ready reaction behavior reactivity heuristics resultant triggers timelimited generalization architecture twodimensional approximations computed Keywords AI architectures Heuristic search Machine solving Satisficing Situationbased search Spatial representation learning Multistrategy learning Navigation Problem Email epsteinrozhuntercunyedu 00043702981900 PIf SOOO437029700083O 1998 Elsevier Science BV All rights reserved 216 SL EpteinArtijiciul Intelligence 100 1998 275322 Naive geographic reasoning probably common basic form human intelligenceEgenhofer Mark 1995 rational behavior applied world reasoning principles serial testing known trigger action conscious domain The principal contribution search space people employ variety devices automatic certain reasoning AI researchers automaticity reactive systems Other portions behavior combination limitedly When confronted intractable hope expert decisions Some behavior perceptions modeled heuristic There Situationbased solving For integrates complex problem FORR heuristic expertise vary reliability speed Additional contributions pragmatic situationbased evidence important mechanism people use kind restricted search problem paper extension FORR reasoning To solve set facet domain paper include navigation FORR careful study empirical possibly solution methods Each method architecture behavior reactivity structures reactivity heuristics effective efficient Right Reasons situationbased incomplete represents resultant overlapping heuristic problem learning cognitively techniques behavior approach triggered plausible solving interact Consider example situationbased reactivity decision constitutes behavior heuristics behave In grid world studied robot knows goal Other kinds grid worlds treated line visible robot situationbased separately pathfinding coordinates similarly The robot map orthogonal directions location Fig 1 shows goal 96 legal moves behavior heuristics encounter difficulties Without experience cyclic behaviors Without relevant decisionmaking err resorting And efficient decision making heavy search costs record recent learn purely reactive mired local rule purely heuristic random choice search heuristic applicable incur straight locations reactivity RI striped Unilateral nearest obstruction possible ability situationbased application purely kY obstl q legal G goal uction moves Rl R 1 R2 R3 robot locations Fig I Robot R seeks goal G SL EpweinArticiul Intelligence IOa 1998 275322 277 In contrast FORR strikes economical balance reactivity situationbased responds gives priority correct reactions behavior heuristics Rather exhaustively deliberate complete model variety efficient ways partial featurebased model world FORR As threetiered situation architecture model learned based behaviors finally inexpensive way problem solving Reactivity right obvious decisions costly situationbased computational limited manner Heuristics right decision partial model relies triggers justify cycles search relies restricted search resort applied restricted search heuristics reference priority given appropriate expenditure routines avoid wrong obvious ones Although obvious problem solver albeit frequent behavior justify 75 correct reaction eliminate Consider FORR deal robot locations RI contemplated deadend consideration Now consider robot R2 immediate little progress task recognized intervening circumnavigate goal 99 path Fig 1 If robot If aligned goal robot obstruction FORR activate timelimited If search algorithm able realign remembered search algorithm obstruction reactions 636 697 77 798 878 839 939 goal Happily performance executed particular implemented twodimensional situation Aligning way addressing entire path proposed situation Finally consider robot R3 immediate recognized recognize generally good heuristic 66 good choice Then robot having difficulty trip trying location helpful Of course good choices Since longstep heuristic value highly Achieving consensus nontrivial Pragmatic navigation visited 48 65 88 choices general direction goal large steps speed travel 3 S 63 reactions robot dilemma R3 resolved FORR aspires space performance origin destination learns way new territory pragmatic navigator resilient particular series trips competent time expertise territory differ Just person detailed description pragmatic navigator detailed map pragmatic navigation territory pragmatic navigator learns features territory performance As envisioned accurate travels efficiently trip remember trips origins destinations campus retain tree rock location ignores travel history topographical details Instead travel room extended wall In new initially performs competent novice traveling improve uses knowledge absolutely features heuristic territory travel experience useful approximations support efficient relies features difficult door provide improves Instead preengineered heuristics Section 4 robust territory changes 278 SL Epstch Artjicid lmlligence 100 1998 275322 1 2 3 4 5 6 7 6 9 1011121314 1 2 3 4 5 6 7 9 10 11 12 13 14 Fig 2 A problem solution maze Such representation storage retrieval computation deliberately sacrifices exchange efficient travel learned appropriately unmapped tasks perceptuallylimited context cognitively situationbased features This approach works It thesis work expert navigation territory behavior care territory allocates control plausible way The section paper unknown agent difficult pro balances search reactivity decision making navigation principles learned demonstrate responsible including guidelines ideas domains The final sections address related future achieved integration correct reactions fully balanced heuristics reference responds frames navigation set travel territory explains traditional AI search algorithms poses pragmatic navigation learning problem solving underlying architecture heuristics Section 3 identifies territory learned Section 4 summarizes offers examples FORR coordinates knowledge Section 5 formulates reports series experiments strengths pragmatic navigation performance Section 6 provides discussion results applying work Algorithmic alternative The second section describes FORR features navigation principles pragmatic navigation FORR components details reserved Appendix identify 1 The task approach task suggested problem challenge 251 The robots world maze discrete rectangular The pragmatic navigation power search algorithms grid external walls internal obstructions obstructed experiments r c maze position array A problem 30 runs A lacufion rth row cth column addressed travel initial robot location R goal location G examples substantially paper taken actual Fig 2 All like 14 x 14 maze larger mazes SL Eptein Artificial Intelligence 100 1998 275322 219 coordinates travel 9s coordinates goal dimensions necessarily optimal path goal sequence legal moves 1 14 In state robot senses In Fig 2 problem maze goal The distance north south east west nearest obstruction robot sense moving The robot remembers useful knowledge similar privethedge mazes grown royalty Hampton Court game Maze Wars The robot knows current problem given construct explicit detailed map maze Section 3 As problem like Fig 2 Rather level increases path far traversed maze This domain trips previous acquired Intuitively legal passes number unobstructed vertical horizontal robot r c rc true line More formally legal transition learns features map described task map nontrivial locations state exactly foilowing l rrccandunobstructedrcIrc l rrcCandunobstructedrclrc l ccrrandunobstructedrIcrc l cc rrandunobstructed r The robot exists path Fig 2 1 I legal moves north 78 88 east 99 9 14 south 108 west 96 97 A problem solvable lcrc R lock nzovel loq locii nzove lot loc_i movep lot G Iiove legal Ioci solvable problem minimum level difficulty problem right turns Manhattan distance Manhattan distance 16 indicated minimum value p solution number legal moves robot reach goal Effectively loci 1 p The level ofdifficulzj robot reach goal Note different R G Fig 2 level6 problem sixmove solution number left minimum 98 913 413 412 2712 2314 I 14 Interchanging heading task subset north east south west describes R G The heading task Fig 2 northeast robot goal produces problem level The direction expected maze Lowerlevel problems perform quickly Speed measured elapsed computation traveled The robot task performance This problems expected number decisions path length expected locations expected important distinction performance criteria The robot solve multiple easier solve The robot time measured number distinct robot number decisions number moves As improve experience path Finally perform efficiently Efficiency visited percentage repeated Manhattan learn distance locations There 280 S L Eptein Artijicial Intelligettce 100 1998 275322 described solution consumes decision solution step search resources Thus appears taken problem problem solution path solving appears exhaustive backtracking amenable search requires search visits visits high proportion nodes As Section 5 demonstrates task formulated substantial nodes hard problems search large structure requires knowledge search sensible easily misled deceptive problems proximity AI techniques Depthfirst repetitive Breadthfirst approaches space maintains inapplicable backwards Bestfirst distance goal valid robot away goal reach eventually For example placing robot 94 For large maze explicit search extremely With FORR pragmatic navigation offers alternative The goal hidden long wall open paths Meansends traditional paths long search analysis reason Euclidean level6 problem intractable Fig 2 produces deceptive vicinity goal goal 85 indicator progress inefficient evaluation function 2 The underlying architecture FORR furnished intended models transition problemsolving learning architecture experience sequence moves specific expertise capitalizes methods people use lo solving sequence reasonable decisions A tusk reach desired R G Fig 2 A problem class set related rooms mazes simulate office suites set related problem classes gridworld mazes A FORRbased general expertise FORR approaches problem problemsolving state robot moving tasks mazes simulate A domain begins domain domainspecific knowledge gradually acquires useful knowledge problemclassspecific probably enhance program data potentially useful particular maze problemclassindependent FORRbased avoid deadends With task experience deadends Although useful knowledge useful knowledge items pragmatic navigation FORRbased broadly tailored FORR provides learns default Those applicable relevant number moves Total learning experiences Openings paper terms recent x indicate parameters user A listing parameter values experiments appears number tasks attempted stored tree x moves recorded task Throughout preset described correct This useful knowledge task Average specific domain Appendix performance calculated task length FORRs threetier hierarchical model reasoning process domainspecific problemclassindependent decisionmaking shown Fig 3 An rationale implemented destination Each Advisor right reason procedure Input Advisor current state world Advisor closer timelimited 281 Tier 7 Reaction perfect knowledge Tier 2 Search inference triggered situatian recognition Tier 3 Heuristic reactions Fig 3 How FORR makes decisions actions current permissible state learned useful knowledge current problem class Each Advisor outputs number comments support actian commented discourage permissible strength integer direction Advisors opposition Although procedures world respond rapid computation constraints nature commentgenerating FORRbased sense current state support 5 5 construed actians A comment lists Advisor search current state world know avoid extensive Tierl Advisors sense measures intensity inrended 0 lo Strengths opinion decision fixed order Each Advisor authority problem class predetermined eliminate reactive reference correct useful knowledge An important FORRbased decision legal action consideration Tierl Advisors navigator goal directly ahead Only fast correct They consulted tierl Advisor 282 S L Epstein Artl lftelligence 100 I 998 275322 actions Tier3 Advisors reactive tier FORRbased tier Tier 1 like sensecomputeexecute perfectly accurate Tier3 Advisors contrast necessarily reactive fails decision control default loop carefully constructed specialized view reality correct context state reasoning process useful knowledge tier 3 tier3 relegated The decision choice In FORRbased goal Although tier3 rule expert term evaluation important differences First tier state change navigator incorrect irrelevant heuristic comment correct Once control rely guaranteed space Each embodies plausible argument far trustworthy Advisors opportunity arrive action highest good tier3 Advisor minimize reminiscent Advisor search algorithm function 3 Advisor rely useful knowledge experience Second tier3 Advisor inappropriate perspective learn refuse allocate computational control decision making example As results Sections 4 5 Section 5 indicate total strength distance heuristic reactions resources particular problem class FORR learn disregard As result appropriate tier 3 obvious trivial Further details appear rescue rescue reliably search emergency situationbased commander necessary FORR quickly timelimited based psychologists reports human experts team called sign jumping semiconscious During debriefing 231 For example suicide person dangles limited person tiers 1 3 solve difficult implements problems searches Advisors tier 2 Situationbased certain resourcelimited behavior scene situations highway attempted overpass Time secured successful lift safety He semiconscious womans arms legs needed mentally tested devices team lifted device time When device failed mental simulation ran times simulation apparent When flaw began predominance evidence judges key features procedural nuclear power plant operators situation responses tested parallel real world Klein Calderwood fourth scenario execute team describes immediately cite additional deliberation Its triggers set purposes discussion studies army commanders hold responses solutions setting bail highway situationbased 32 incidents business executives ran instantiated engineers retrieved behavior juries 23 Each tier2 Advisor reactive highlyconstrained set possible solution tier2 Advisor sequence decisions sensecomputeexecute method directly robot Advisor paths circumnavigate aligned goal instantiates related trigger procedure generates tests fragments A solution emerges single reactive digression recognizes triggers fragment loop A tier2 Advisor current situation example intervening wall Execution tier2 example like tier 1 lacks tests possible intervening wall Tier 2 prioritized fragments solution SL EpsteinAmid lntellipm 100 1998 275322 283 guarantee tier2 Advisor fragment Once executed control outcome robot fragment Advisor sequence recommended FORR implemented returned correctness Until produces solution ceded control given limited triggers tier2 Advisor constructs solution time subject override fragment time develop solution tier 1 regardless sequence fragment tier 1 Decisions search charged step recommended triggers produces result search If tier2 Advisor steps tier 3 decision Common Lisp To apply FORR domain specifies useful knowledge procedures problem classes implemented domain navigation King Minos Crete told Theseus way protected great treasure The sections Ariadnes useful knowledge set features principles learn Pragmatic Ariadne daughter labyrinth space sketch Ariadnes Advisors navigation FORRbased twodimensional path finding Ariudne 3 Learning represent territory These Instead map pragmatic navigation support efficient travel cfacilitutors features constitute Ariadnes useful knowledge territory obsrructors specific problem class experience Although knowledge expected described program prespecified designer learning This section describes Ariadne time limit learnin 0 schedule preceding relies kinds features difficult learned useful items FORRbased learning algorithm decision task set tasks approximate enhance performance Other default learns learns section kind useful knowledge FORR including 3 I Facilitators Ariadne identifies kinds facilitators gates bases corners A gate large segment space A choice successful paths A corner offers theory ability base repeatedly appears counterintuitive possibility provide transition new direction dimensions knows tests offers transition quadrant changed maze Ariadne calculate quadrants A gate quadrant maze After moved Since location Ariadne gate If robots current previous A gate helpful quadrants 3 4 Fig 4 offers access gate stored exterzf rectangular reached extent 8 10 Fig 4 example learns 9 S 65 Ariadne current quadrant 8 10 gate little quadrant 3 Each hash table key sorted pair quadrant numbers The 9 lo Fig 4 rectangle vertices gates visits learned gate locations approximation example locations location 6 lo 284 S L Ewcirr Artificitrl Irxtellience 100 1998 275322 Quadrant 2 1 2 3 4 5 6 7 6 9 1011121314 Quadrant 1 m q obstruction ETJ gate Quadrant 3 Quadrant 4 Fig 4 After IO tasks gates learned simple maze 1 2 3 4 5 6 7 8 9 1011171114 1 2 3 z 6 7 0 9 10 11 12 13 14 1 2 3 4 5 6 7 6 9 1011121314 m obstruction path 0 R G derived base robot goal base frequent plan 1 2 3 4 5 6 7 6 9 10 11 12 13 14 Fig S A solution path bases bases arise b A plan task formulated learned I definition satisfy trip robot moved 14 10 quadrant 3 14 IO gate Although learned gate That position kind facilitator The subdivision quadrants deliberate Specifying manage fewer areas provide gate learned marked For example learned identified II areas produces CZ gate categories information little transition gate experienced areas maze 149 A base location maze appears town people regularly directions beginning key successful First path In authors home Claremont Diner Although Diner burned 15 years ago served memorable cheesecake particularly Claremont significant SL EpstcinArtciuI Intelligence IW 1998 275322 285 I 2 3 4 5 6 7 6 9 1011121314 3 obstruction deadend hallway Fig 6 After IO tasks corridors learned simple maze What significant corrects necessarily replaced affords ready path eliminate shortest path access car dealership location IOmile radius A base location Bases learned successful algorithm base location base deadend G solution circumvent walls contribute extreme positions opposite headings Bases stored hash table theirfrequency circled bases diner locations task digressions A R G A fragments constructed tier2 Advisors original number times solution path corners corrected path heading identified Fig 5a heading north easternmost different problems The bases learned loops unnecessary Bases facilitate Ariadne primitive highlevel planning sequence Ariadnes decision making ba bi 62 b_l b bl 6 bl bo A plan location bI goal b base 1 n bi aligned robots current vertically horizontally bl b_l closer bo b bil closer G b Plans constructed search aligned bases bases higher frequency obstructions A plan preference prevents fails formulated b An example plan Ariadne tasks maze indicated Fig 5 b bases learned 20 level6 frequency values In Fig 5b keys route eastern western portions maze Others 7 13 99 obstruction task shown intersections passageway width single exit deadend bi intervening bases 145 like Claremont Diner bidirectional lie important A corridor 149 robot straight hallway In Fig 6 hallway lie row hallway A yiye column pipe 14 10 14 1 I Some pipes offer view space far end For example ends pipe Fig 6 robot 1412 Other pipes offer view space far end pipe deadend 149 14 1 I endpoints promises 135 14B 14lO 286 S L Epstein Artcid Inteiigencr 100 I 998 275322 4 10 Fig 6 robot turn direction For example promises turn ends length pipe 4 13 far end pipe called corner A corner far end Such turnpromising robot actually helpful orthogonal Fig 6 goal seeks travel If example south moving east known corner 4 13 promises travel north south A corridor learned current state robot moves The endpoints corridor serve keys hash table indicates deadend Corridors enlarged merged Ariadne experiences learned necessary Like gates corridors robot located 4lO direction ability 32 Obstructors Ariadne narrow spaces linear approximation kinds obstructors bottles circumscribing identifies corridors Chambers stricted contiguous barrier obstruct movement deadend noncorner pipe In case movement locations reason traveling east efficiently internal afford access rectangular chambers bottles barriers certain corridor exits A obstructed positions A corridor 29 Fig 6 necessitates extra decision approximations pause 14 IO 1411 For example pipe pause 149 Learning obstructor space There measures confinement robot hampered triggered Fig 6 goal lies ability termed recently constrained l The area territory covered x moves y total maze area l All legal moves visited l The x moves y possible maze locations l 2 recent moves visited A chamber irregularly shaped space access point approximate rectangle chamber bounding robot moved affords view outside compact heuristic approximation access point reachable direction chamber The access point location need border shows chamber extent 1 north 13 east 5 south 9 west south constitute limited task location legal moves locations visited task location result tier2 fragment dimensions extent The extent furthest extent Fig 7a When In principle single roomlike The learning underway current goal remote current The chamber algorithm current sensing tries location chamber appears locations large chamber robot recently constrained chambers 4 13 saw triggered learns initial position chamber estimates Ariadne robots extent according algorithm learning time S L Epwitl ArtiJiciul Intelligence 100 1998 275322 287 1 2 3 4 5 6 7 8 9 1011 121314 1 2 3 4 5 6 7 8 9 1011 121314 Kev q obstruction fl extent A access point N bottleneck 4 Fig 7 A learned chamber extent access point b A learned bottle neck extent identifies legal locations current location offering robot scans horizontally location largest view scans vertically higher wider From scanned horizontallyadjacent procedure extent chambers extent access point list The scan chamber 4 12 A new chamber subsume old case replaces list Otherwise access point If If enlarge Fig 7 began chambers merged overlap vertical scan performed access points sequence locations previously unvisited task records A bottle contiguous spots corridorlike directions learned deliberately visited repeatedly useful knowledge description constrained path immediately neighboring ultimately similar subspace chamber Chambers search bottles learned search analysis entire path task completed A potential bottle begins location extended includes x area maze Once bottle neck necessarily entry andor stored hash table extent neck Fig 7b north 6 east 14 south 1 west neck 62 linear approximation IO tasks learned positions encompass identified extent computed identified Bottles shows bottle extent 12 A barrier barriers I I 13 example approximation corner maze Barriers learned different ways depending context clearly prioritized circumnavigate goal treat deadends fragments wall obstructs movement Fig 8 shows right search arise There tier2 Advisors search paths preferences intervening obstructions All searches solution In case simple maze The barrier irregular wall Two attempt shift space Whether Advisors produce direction obstruction follows contiguous barriers detected opposite searches lower obstructed attempts exit point paths followed 13 10 288 XL ErteirArtijicitrl Intelligence 100 1998 275322 1 2 3 4 5 6 7 8 9 1011121314 Kev obstruction barrier Fig 8 After IO tasks barriers computed simple maze learning algorithm search path Experience encountered vertical wall program encountered object endpoints recourse Ariadnes rationale function preferences tier 2 determine barriers irregular eastern western portions maze Fig 8 difficulty required slope intercept length Each retained barrier produced avoid learned barriers 4 Pragmatic navigation action rationale general An Advisor Ariadne Advisor narrow decisionmaking characterized tier resides particular maze As described designed maze navigation Section 2 Advisor reactive Advisors tier I situationbased Advisors dimensions maze input Advisor location robot location goal legal moves robot trip history features maze Although Advisor access entire store apply items useful knowledge domain tier 2 heuristic Advisors tier 3 Recall Table 1 lists Ariadnes 32 Advisors useful knowledge Section 6 Advisors Advisors appears order Full descriptions appear experiments perfectly correct situationbased sequence moves origin Advisors discussion 2 appear prioritized parameter values Advisors 2 Advisors produce trigger identified solution tier2 Advisor tested serially The 20 tier3 Advisors reactive heuristics reactive procedures procedures oppose number legal moves mandate Each signals fragments embody pathfinding situation The solution search method timelimited search applicability attempts commonsense recommend address reference A tiers 1 behavior Appendix The tierl decide quickly The tier search attempt tier2 Advisor compute fragments generated timelimited maze Each S L Epsrcitl Artciul lntellienence ICQ I 998 275322 289 Table I Ariadnes Advisors tiers I 2 prioritized order Tier Advisor Rationale Useful knowledge I I I I 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 Victory Can Do No Way Pipeline Roundabout Outta Here Probe Patchwork Other Side If goal reachable legal Move adjacent goal Avoid deadends Avoid internal locations straight corridors Corridors Corridors Circumnavigate intervening obstructions Barriers corridors Exit chamber deadend containing goal Chambers corridors Determine current extent try leave Repair plans Bases Move robot opposite goal Super Quadro Search entry goals quadrant Gates new quadrant Wander Move far Lshaped path Barriers average task steps bases corridors Humpty Dumpty Seek barriers Adventure Move far unvisited locations preferably Barriers goal Been There Discourage returning location visited task Chamberlain Move chamber contains goal avoid Chambers Contract Take large steps far goal small chamber Cork Corner Crook steps close Move bottle contains goal avoid Bottles bottle Move end pipe promises turn Move end crooked corridor Corridors Corridors Cycle Breaker Stop repeated visits spots Detour Done That Move away barriers obstruct goal Barriers Discourage moving direction fore previouslyvisited location Giant Step If recently confined long step preferably Goal Column Align robot vertically goal goal Goal Row Align robot horizontally goal Home Run Move bases Bases Hurry Take big steps early small steps late Average task steps Leap Frog Execute opportunistic plans Bases Mr Rogers Move neighborhood goal Opening Plod Quadro Begin previously successful path Openings Take oneunit step preferably goal Move goals quadrant new Gates quadrant 290 XL fsfeizArtciul Itrrelligence 100 1998 275322 Move Comments Advisor strength Score 38 4X 538 63 64 Giant Step 8 Adventure 6 Giant Step 8 Adventure 6 Adventure 6 Plod 6 Home Run IO Giant Step 10 Home Run 8 Mr Rogers 6 Giant Step 10 Adventure 8 635 Home Run 8 Mr Rogers 7 636 67 78 88 Giant Step 10 Adventure 8 Home Run 8 Mr Rogers 8 Giant Step 10 Adventure 8 Goal Column 10 Mr Rogers 7 Adventure 8 Plod 8 Mr Rogers 9 Been There 4 Plod 8 Mr Rogers IO Giant Step 10 Been There 4 4 4 2 10 12 13 19 8 6 9 Kev q obstruction G goal R robot Fig 9 A state midst problem solving tier 3 votes The strengths converted 0 10 I 1 S S I summed produce scores No Way Although eliminated navigation simple run time level 10 problems trusted support ideas tier3 Advisor captures reasonable rationale decide All vote rapid computation Given 10 seconds Pragmatic navigation Advisors Table decision mandated tier fragment tier 2 topranked selected vote tier 3 achieved execution FORRs Fig 3 decision process tier turn A single executed I solution delegated I Control submitted The nature voting process chose comment The best supported clearly 66 R3 Fig 1 state middle fourth tier 3 best explained example Fig 9 trip Ariadne particular maze The program time useful knowl tier3 Advisors list state produced territory forwards position key previous problem recaps dilemma edge IO legal moves Fig 9 shows 30 tier3 comments seven tier3 Advisors variety reasons closer goal legal moves Mr Rogers moves Giant Step task Adventure way goal Ariadne task Roundabout 99 triggered drove Fig 9 demonstrates thesis good decisions Thus Ariadne seek construct explanation circumnavigates right decisions satisticing ones robot FORRs tier2 Advisor repositioned reasons Home Run larger step current 66 intervening problem quickly obstruction solved combine logical flawless aligns robot goal Goal Column Although visited robot For problem Fig IO Table 2 demonstrates matic navigation surprising satisficing nature prag results Table 2 annotated version SL EsteilArtficiul hltellience 100 1998 275322 291 1 2 3 4 5 6 7 8 9 1011121314 uction obstrl q legal R robot G goal Fig IO A levelb problem Table 2 Three solutions problem Fig IO Generators path Second Ariadne solution First Ariadne solution 8 decisions 26 path length IO decisions 22 path length 14 14 13 14 13 12 14 14 1314 13 12 identical 12 12 Patchwork generator fragment 14 12 lZl2 42 decisions 58 path length 1414 1314 IO 12 l312 IO 12 1412 good indecisive choice IO 13 713 Wander tries help l49 99 92 42 44 IO 12 shortcut IO 13 IO 13 713 7 13 797 Patchwork forces perfect plan 67 634 434 3 13 overshooting 713 77 637 64 44 3 12 partial correction 412 alignment 48 far goal Other Sides fragment 53 interrupted Victory 64 44 Fig 10s level8 problem The column solutions tion column solution 10 different In Ariadnes somewhat baroque plan bases learned try second column tasks including soon robot moved problem generators solu Ariadnes maze 1314 initial learning second solution formulated Ariadnes level8 1314 13121 12121 125 95913 7913 77 67 64 44 292 XL Epstein Amid lnteiligpm 100 1998 275322 original 10 12 12 12 Ariadne executed 12 12 125 ordinary decisionmaking triggered 13 12 allotted search 12 12 Ariadne resumed Ariadne recognized 713 task The resultin g solution entailed decisions produced The problem generators In contrast Ariadnes fragment helped step plan Patchwork The movement illegal Patchwork time patch plan forced fragment moved forged ahead completed shorter path length solution solution began bit indecisively Wanders primitive alignment shifted plan fully executable led robot premature alignment goal 313 knowledge helped avoid second number turns path length problem generators 1013 Patchwork newlyaccessible optimal tier3 Advisors time triggered solution process 5 Empirical design results The data described produced Ariadne generated maze tested different performance results 10 runs 10 randomlygenerated mazes averaged experiment Throughout 95 confidence section cited differences statistically reasoning agents Because FORR nondeterministic produce significant Experiments performed level stated problems II generated selecting fixed random unoccupied level difficulty II A R location level algorithm extends robots legal Each newly marked problem location marking locations On iteration location element reachable single iterations element fringe extended removed thefringe On subsequent fringe remains marked new fringe fails robot location R discarded process begins anew After n iterations G selected random element fringe locations The marked The problem generators number locations estimated maze problem generated visited breadthfirst total number locations marked sequence marked search algorithm If iteration possible formed location solution 51 The ablation experiments ability demonstrates Ariadnes The set experiments explores components experienced problems gram necessary random mazes 20 x 20 mazes 4 6 8 IO Dimensions possible problems specified mazes sqme fixed percentage obstruction routines designed hard problems Fig 10 example irregular wall running solve pro achieve performance These experiments performed levels provide generation square formulate lengthy deceptive nature distance 30 obstructed problem offers ample challenges Note level difficulty Although frequency selected obstruction 69 learning l4 SL EpsteinArtl Intelligence 100 1998 275322 293 complexities 74 version Ariadne given 20 learning problems 83 In maze pairs fixed level difficulty Then 10 newlygenerated maze level difficulty offered agents learning After learning l Ariadne l The Reactive agent ablated version Ariadne problem generator exploits nicely R G turned following agents tested tierl Advisors reactive decision making If legal simulate correct left tier 1 agent randomlyselected testing problems l The ReactiveSearclz agent ablated version Ariadne tier 1 tier2 Advisors behavior heuristic agent randomlyselected simulate reasoning reactive decision making situationbased If decision tier 2 agent ablated version Ariadne simulate correct heuristic reactive decision making applied Advisors useful l The ReactiveHeuristic tier 1 tier3 Advisors situationbased behavior l The NoLearn agent algorithm available l The NoPlan agent algorithm knowledge Advisors Patchwork involved planning applied useful knowledge Leap Frog Home Run experiments Separate equivalent Euclidean distance blind search tested random agent bestfirst agent selected bestfirst random legal moves search goal evaluation function The learning problems established useful knowledge base Advisors reached decision agent reached reasoning included exploration depend All agents Advisors equal access learned knowledge goal A problem kind terminated tier2 step limit limit set 200 level 4 300 level 6 400 level 8 On search This solve problem level IO set 1000 agents ample opportunity The IOOOdecision Ariadne acquired additional useful knowledge In preliminary limit permitted experience support better comments testing IO random mazes efficacy random trips maze IOOOdecision cutoff agent Ariadne permitted 20 learning Ariadne random agent tested 10 trips maze 200 decision cutoff Although Ariadne solved 99 level4 10 randomlygenerated Ariadnes 27 I 86 entailed The random agent eliminated mazes solved problems significantly random agent able solve 36 In addition 1753 opposed random agents ablation experiment 23 IO instead 16606 testing problems fewer decisions determine solutions shorter Table 3 reports results experiment Manhattan 10 runs Distance difficulty ablated agents Ariadne averaged In Table 3 location distance grid square distinct goal Since step locations path length varies problems tier2 search solution taken path Decisions number steps 294 Table 3 I ElreirAitcitrl lntellipnce 100 1998 275322 The performance Ariadne ablated versions learning particular 20 x 20 milze Ariadnes world Results averaged runs IO mazes Agent Distance Decisions Moves Locations Triggers Time Solved 4step problems generator path length 1247 Reactive ReactiveSearch ReactiveHeuristic NoLearn NoPlan Ariadne 12432 3 I 99 471s 2510 1695 1638 7578 5 I 07 1866 5398 2514 2390 464 I 1638 1682 1301 IO49 1002 2469 1538 939 99 I 982 936 6step problems generator path length 1919 ReactiveSearch ReactiveHeuristic NoLearn NoPlan Ariadne 5306 6263 Sl34 3014 2636 10260 3748 I 1946 4798 3904 289 I 2400 2856 2698 1871 IS87 1310 1781 1705 1458 gstep problems generator path length 2562 ReactiveHeuristic I IS37 NoPlan Ariadne 4374 413s 9914 7359 8389 4164 2672 2598 1942 2447 23 I2 IOstep problems generator path length 3 I 23 464 318 165 144 878 729 261 220 556 459 I58 81 0 05 1 96 0 I I2 078 043 044 099 397 I 59 09s 091 99 0 91 0 98 0 98 51 88 0 95 0 86 0 99 0 97 38 1800 84 0 222 220 95 0 93 14 NoPlan Ariadne 963 I 7248 7968 6044 393 I 3513 24 I4 2370 1494 1395 888 595 98 0 97 19 moves reported locations tier2 Advisor executed Distance moves locations number steps solution The number distinct moves locations actually visited reliance tier 2 number passes Fig 3 computed look somewhat better solved problems time execution actually testing problem solved Ariadne listed number problem generators parentheses solution Time seconds The percentage testing problems solved better ablated agents easier problems This Triggers measures solve tends testing subsequent decisionstep levels solved fewer limit given level On level 4 An ablated agent eliminated 90 problems Reactive agent solved surprising 8 1 testing problems solutions Ariadnes required significantly typically large portions far execution randomlygenerated way upper right corner Reactive agents behavior likely maze unreachable Fig 1 In maze substantial random component effective Mazes Pipeline longer entailed decisions time The Reactive agent succeeded robots starting point S L Epstein Artirrl Intelligence 100 1998 275322 295 Table 4 Percentage maw visited Ariadne breadthfirst search Level Breadthfirst Ariadne 4 6 8 IO 4026 6462 8625 9563 356 558 883 919 able veto choices supported agent Nonetheless Reactive agent eliminated level 4 substitutes agent produced agent NoLearn On level 6 ReactiveSearch significantly Note increased number triggers longer paths required decisions level NoLearn 6 Despite able solve 95 level6 problems level 8 inadequacy clear There paths far longer solution greater On level 10 Ariadne clearly solves failed solve problem NoPlan succeeded search knowledge Both eliminated agent retained long paths ReactivefHeuristic shorter paths problems time substantially NoPlan faster overall produces There In reality important benefit planning As discussed generator produces problem difficulty path length turns Ariadne solution level 8 19 level solutions distance Section 4 problem predicated number steps shorter solution ablated agents In contrast Ariadne half time level 4 38 time level 6 14 rest Ariadnes outlier driving average near optimal occasional problem generators frequently Observe possible good better IO Inspection indicates robot search heuristic search evaluation goal Table 4 compares efficacy Ariadnes problem solving compare breadthfirst standard equal fraction search In robot starting position visited breadthfirst To measure AI techniques Euclidean distance locations accessible visited Ariadne Ariadne visits small fraction locations contrast breadthfirst large fraction maze This somewhat understates breadthfirst learned 20 problems best separate experiment function search able solve 26 level 10 1000 steps averaged path lengths 8765 solved problems versus Ariadnes 6299 path length 93 success rate Bestfirst search averaged 16448 seconds problem Ariadne 423 seconds problems exploring increasingly executed search repetitive subpaths uncounted By comparison goal evaluation 10 runs Ariadne cost physically Euclidean distance search solved In summary problems difficult Tables 3 4 search reaches increasing percentage accessible things happen breadthfirst unobstructed trigger frequently searchoriented tier2 Advisors locations 296 S L Ewin Artficitr Intelligence 100 1998 275322 Fig I I Some nonrandom environments warehouse b clarity furnished room c office Grids omitted b solve ablated agents tier 2 offers measure reliability ability FORR lack Although successful paths ablated agents extremely place Ariadne gets robot way fewer alternatives inferior versions solutions tiers goal quickly considers suboptimal long With FORRs work predicated acceptability markedly achievement problems 52 Peqormance nonrandom environments Although random mazes present ments random To test Ariadnes intended furnished large produce somewhat challenging face environ real navigators classes mazes model realistic worlds constructed These maze classes represent rooms warehouses office suites 40 x 40 grid The nonrandom mazes challenges robustness interesting problems The warehouse maze models single room like typical basement garage specify rectangular The furnished warehouse maze places objects room maze models room obstructions attic storeroom The generator size number obstructions objects minimum distance object outer wall grid Objects overlap contiguous parameters permit An example warehouse maze appears random grid Parameters space Fig 11 objects rows desks require particular model room furniture size objects Like warehouse maze parameters space perimeter center section Although precise touching perimeter placed sequentially locations chosen random measure balance Objects perimeter allowed overlap As result sectional couch An example furnished objects resemble pieces furniture regularity Thus classroom regular television encompassed room maze passes Objects placed objects Fig 11 b furnished room appears surrounding specify S L Epstein Artjicitrl lntellipmce 100 1998 275322 297 The ofice jnaze models single floor office building Such environment ofices layouts possible good use space subspaces outer rectangle offices gular hallway The space framed hallway Parameters determine door hallway As real world corner offices somewhat oftices adjacent hallway inner core slightly Office mazes example office maze appears accessible Al generator produces mazes windows bordered rectan inner core connected offices size hallway number offices wall larger model private spaces accessible adjacent offices Offices larger outer rectangle doors room An include objects placed office furnished corner office open corner office Fig 11 c problems mazes program Ariadne developed learned 20 different problems warehouse furnished random mazes Without changes edge Advisors tested problem class run new maze generated Ariadne 10 previouslyunseen offices warehouses problems higher perimeter furniture provides mazes 4 times mained 1000 Ariadne solved furnished better problem generators problems useful knowl like Fig 11 In room maze tested maze Level8 problems run room new limit room problems easily 49 time It solved warehouse ready access locations Although decisionstep readily 4 1 better problem generator larger earlier experiments level 4 presumably required gap difficult furnished solution 1000 decisionstep problem generators The office mazes presented greater challenge Only 5 Ariadnes solutions cases Ariadne limit In contrast Ariadne devoted furnished warehouse cases solution near hand search One obvious linked chambers access point offices grid worlds good better solve test problem average 4283 decisions problems indicated Inspection corner offices sufficiently deceptive solution create representation chamber appropriate Other Ariadnes knowledge satisficing approach scales extent Although add Ariadne readily programmable facilitate solutions twodimensional demand additional testing room problems evidence nonrandom representation environments adequate 8479 appears 6 Discussion 61 Why FORK work FORR works react search guess priate allocates control appropriately Control appro foolish errors guarantees easy right reaction intelligently When quick obvious tier I responds correctly Tier 1 prevents 298 S L Eprein Artijicitr Irztelligence 100 I 998 275322 needs addressed particular search answers When preidentified tier 2 Tier 2 provides appropriate thoughtful costly routine arise tier responses Rather tier2 1 monitors neces tier 1 prevented obvious mistakes search option sary When tier 3 formulates In way search minimized egregious errors committed safeguards tier execution decisions timely wellfounded reproduce fragments tier2 Advisor guess compromise I reasonable heuristics interrupt FORR works responds context appropriately Context domain reasons tiers A FORRbased knows Advisors assignment knows affects decides A FORRbased right reasons relate knows worth learning apply acquired FORRbased general prespecified principles information ways applied knows exactly Decisions acquired useful knowledge sequence Advisors Useful knowledge represented ways That flexibility brings learn ways bear based experience needs things note It important Advisors Table 1 useful knowledge Section 3 developed random mazes The problem classes recent changes kind adjust Domain knowledge tool Of course useful knowledge Advisors learning methods architecture entirely validate The interested onedomain demonstration twoperson referred reader play 910 To date Hoyle learned perfect play 18 information different games better best human opposition The games Hoyle simple search space larger billion plays relatively ways play states People games challenging tiers 1 3 set tier2 Advisors 361 Although Hoyles Advisors reactive currently development Hoyle FORRbased games powerful learning finiteboard like Hoyle program location planners How Ariadne extend pathfinding domains Path finding printed reason backward robot This suggests additional goals forward direct robots approach facilitators obstructors map work correct knowledge provide opportunity Advisors place tier2 bidirectional legal steps goal Path finding process longdistance like currently performed One local search join R chosen highway goal location G The longdistance algorithms FORRbased facilitate knowledge target positions known require 3 large scale space probably travel network highways plus local searches location route segment rely standard graph search structured solution require additional useful travel FORRbased highway Since highway network second join chosen highway Advisors interchanges longdistance starting exploit route robot XL EpsteinArtijiciul Intelligence IO0 1998 275322 299 Ariadne imposes approach computation reference deliberately fundamental random domain navigate Because readily augmented learn descriptions central distribution learns instances descriptions spatial descriptions experience random grids applies impoverished point station consistent R descriptions general Ariadne landmarks learn In words richer domain task easier realistic ones The program instances landmarks tasks reflect regularity docking One need add category useful knowledge method Advisors invalidate If unlimited domains readily accessible application opti mality essential FORRs approach appropriate The right reasons FORRs useful knowledge systems facilitates modularity currently signs course use host tier3like heuris work day Human experts task observed Initial tics believe version promising The second constructs results preliminary formula Here Advisors fewer threedimensional complex weight described important development The transportation model protein learning tier2 Advisors substantial development Two substantial FORRbased pick deliver 1000 loads Section 67 particularly failure intolerable time available resource scheduling trucks drivers contribution 63 How search space engenders FORRbased It possible In sense Ariadnes visible space provides metaphor search blind like ablated version edge geography state space search Unintelligent goal Ariadnes simulated evaluation tive problems subtleties proximity rowed work genetic algorithms section exploit knowledge reason traversal search space complete knowl sought intelligence measures proximity goal Decep function overlooks evaluation obvious deceptive defined term deceptive bor address similar difficulties The purpose suggest additional ways think search space limited vision function foil approach Recall problem valid indicator progress In AI artifacts FORRbased Indeed space ideas Ariadne The kind knowledge available domain tier To instantiate inspire Advisor typically determines domain reader consider learned observed cost cost best exploited The experiments rooms search The surprise Ariadne warehouses robot little point distance way behave way usually behaves begin set good reasons situation Brooks rarely necessary tier2 hillclimbing Advisor nonrandom plan described took great care monitor reach goal For example behavior The reader encouraged goal location 141 leaven recommendations like furnished environments learning 300 S L Epdt Arfficid Intelligence 100 1998 275322 based search Save search ameliorating clearly defined situations efficient algorithms testing construct Advisors FORRbased tier3 Advisors gradually remembering difficult problems Begin tierl tier3 Advisors add tierl frequency If decide suite increasingly Advisors need arises Monitor require Monitor comment Advisor problem dependent rationale need partition overlap premise simple This minimizes Advisors effectively Advisor poor choice broadly applicable Although Irrelevant Advisors quickly dropped Take pains particular maze valid tier3 Advisors try minimize repetitive possibility vote strongly rationales domain good decision making example designed unnecessary relatively resources comment inexpensive reasons ability automate solving FORRbased Individual Advisors encapsulate people consider commonsense Mr Rogers closer Giant Steps long steps The kinds mistakes suggest problem development rationale existing ones It possible new Advisors corrections discovery tier3 Advisors gradually phase domains decision making Patternoriented learned 141 These visual cues Advisors based limited vocabulary extensive play experience generalized Extendibility vocabulary learn Advisors begin crucial constrained vocabulary postulate Advisors useful ways Such program learn manage corner oflice suites sequence connected components tier3 Advisors 13 1 shown improve performance terminology combine domain connect game playing issue In pathfinding instantiated shapes spatial typically terms principles Ariadne FORR For attempting remainder apply extend appli section categorizes Ariadnes Advisors kind state space maze world Full maneuver individual Advisors appear Appendix tier purpose cations knowledge details Ariadnes section reader note actually search restricted search Many Advisors maze world characterize approach intelligent 631 Correct conditions good shallow search A correct condition generate choices generate good single actions instead searching examine legal actions Advisor predicated correct Rather condition example test action goal Most domains intrinsic version makes single reaches immediately wins game Ariadnes Can Do Victory decision second example goal setting Victory decision Some domains version Can Do example actual win occurs king captured Victory look possible states robot reaches location vertically horizontally legal moves Ariadnes Victory chess Can Do checkmate problem description forces adjacent S L Epwin Arrijiciul Intelligence 100 1998 275322 301 interprets visibility legal options Similarly Can Do interprets goal Can Do look moves away search space Instead Victory seeks goalachieving accessibility seeks onefromthegoal exploits execute properly Advisor condition access correctly chosen operator correctly exploits tier 1 offers quick easy search assumes agent aspect environment prevent purported postcondition An Advisor good shallow search belongs legal options An Advisor good shallow nearby solutions nearaccessibility achieving condition adjacency constrained subspace set states 632 Constrained subspaces hindrances subspace A constrained domains primarily little access bottle corridor constrained exclusively formally access world chamber visuallyoriented neighbors states players shuttle No intelligent believed subspace More goal state lay instead formally An example constrained agent deliberately search repetitive state space curtail unnecessarily In afford ready portions space In maze In represent constrained subspace set states search cycle set game piece small set locations domain subspaces subspace search constrained subspace seek operator left constrained let S denote state space let S set states lie S A subspace S constrained set immediate neighbors s E S accessible single operation s Let exit S state s E S SY S f 0 state relatively neighbors exits proportional subspaces exit exit deadend access point chamber Bear mind concept constrained Learning visible space Ariadne subspaces occur domain extent constrained SI By definition Ariadnes constrained tier2 searchbased Advisor called Probe delineates perceives chamber constrained triggered appropriately terminated exit identified Confinement territory It possible search Thus Ariadne subspace exit access point Such search search space Ariadne little recently critique path bottles search space This essence learning algorithm robot distinct agent senses confinement measured locations space postsolution useful metaphor subspace requires induce confined Once constrained subspace exits identified Advisor exploit refusal goal state deadend pipe increase locations exit constrained In Ariadne pause pipe believed example subspace agent reason goal Unless intelligent enter goal pipe provide new option treats pipe set contain contain number steps solution This Ariadne locations avoided Advisors prune search knowledge constrained 302 S L Epstein Arrd Intellipme 100 I 998 275322 appear Pipeline keeps pausing stumble subspace heuristically subspaces deadend constrained subspace example searching Chamberlain bottles respectively tier In tier 1 No Way keeps robot entering pipe Since agent begin Advisors leave constrained contain goal state necessary This Outta Here tier 2 exit chamber deadend knowledge chambers Cork tier 3 reactions location hindrance domain prunes search Yet kind knowledge state In maze world presence barrier hindrance An example hindrance set states goal robot particular playing piece particular place game board search visit states hindrances solving example agent address particular search current seeking Ariadnes Detour Roundabout Patchwork respectively Because knowledge state space share property presence guarantees achieved goal constitutes inability chess In domain kings close goal elimination productive Since hindrances predictable set subgoals problem know barriers hindrances state situationbased hindrances Humpty Dumpty hindrances tier 3 examples approaches likely arise reactively situationbased search plan revision deliberately initial state intelligent agent merely decompose arise problem particular hindrance heuristic Advisors rely reside nonhindrance conditions Ariadne avoiding lie An intelligent tier 2 633 Transition regions Although accustomed imagining state space vast somewhat transition permits movement search space quadrants suggests formless graph shape suggests solutions A transition region set locations represents Fig 12 identifies Fig separately single decision E 63 F quadrant 4 step Q denotes region portion space Ariadne maze regions shown quadrant 3 robot east region transition respectively A location robot quadrant For example I For clarity Figs 12a 12b horizontal vertical pairs transition regions A N portion quadrant regions transition quadrants transition region 65 64 The summary graph Fig 12c clear example common single decision shuttle graph makes travel reduce powerful planning state space Instead single representative region D quadrant Because number nodes tool Its construction N rest fourth quadrant links transition regions robot location The summary travel regions B N limited value Qd require movement summary graph substantially requires exhaustive search transition region expedite movement search space 64 17 case S L Epwh Artcicd Intelligence 100 I 998 2 75322 12 3 4 5 67 8 910 1234 5 6 7 8 910 D K L Ql M r4 E F Q4 H G 03 Fig 12 The horizontal vertical b pairs transition regions c The summary graph maze state space Ariadnes gates heuristic approximation learning graph relationship overlap extent Ql Q Thus way approach problem summary gate Fig 12 maze For example regions C D F reach 57 57 304 XL Epvei ArtiJicicd Intelligence 100 I 998 275322 maze world search intervening precede movement movement implemented N Quadro transition region reactive version A tier2 planning Advisor way Qt idea sequence quadrants reasonable 634 Other classifications search space relationship set conditions It possible classify If search productive state space according states visited characterize goal state state classification Other Side monitors remained tier2 Ariadne Advisor classification moving mechanism based notion moving away small set states Advisors like use knowledge derived costly search procedures triggered far search example tier2 Advisor called goal If robot consistently north goal Wander south goal Other Side devote resources different robots position constructive space respect In Ariadne search likelihood success assigned superficially arc primarily heuristic tier 2 right When decisions describing states Therefore like FORR general classifications past useful Advisors historical perspective repeatedly draw agent nonproductive approach cided typically counterparts That discourages Advisor suggests states entirely new current applied domains Been There discourages repeating tier 3 Ariadnes Been There Done That Cycle Breaker Adventure state Done tier3 current context Adventure task A similar exploratory heuristic transition state Cycle Breaker suggest alternatives different revisiting reasons satisficing agent Advisor Ariadnes Opening supports counterpart Run Leap Frog dependent bases historically useful generalizations states goal historical perspective set tasks successful path It game playing Home location reuse beginning previously domains obviously A base generalization space openings ignores Still classilications actions select extremes Ariadnes Giant Step Plod example advocate extreme step size large steps small ones A similar heuristic employed AM Eurisko compare alternative 29301 635 The role reactivity Reactivity important component Ariadne FORR Inexpensive reasoning actually combine solve difficult problems efficiently ing simplistic fast wise decisions Although tant component Advisors heuristics concern alignment goal Mr Rogers Contract goal Corner Crook react visible tier 3 Advisors favor simple environment sens produce remarkable number prove impor reactive Ariadne Goal Row Goal Column sensors typically react distance ablation experiment proved Go 32 It possible 64 Cognitive plausildity 305 There claim Ariadne cognitive model human navigator plausible Several Advisors recognize Plods 8 readily curiosity Hurrys anxiety In addition cognitive scientists 181 rationales reveals tests human search rationale naive geographic features cognitively reasoning model principles tentativeness Adventures empirical evidence Advisors 20 A literature subjects problems difficult heuristics Contracts reactivity integration The search situationbased 23 There people behavior increasing detection approaches based evidence human problem psychologists decisions inconsistent architecture rationales accomplish The use learning FORR Ariadnes underlying solving architecture In variety domains report people integrate multiple parallel possibly conflicting captures aspects game playing strategies 2637 During problem solving people multiple possibly single goal 361 The brain appears use modular circuit design accurately relevant integration information architecture 7461 prespecified supported people evolve superior performance Human expertise develops experience set problem solving classes For example unfamiliar applicable problem l1733 This expertise expert path finder immediately wonder deadends domain knowledge color ob source fo rely foundation provide baseline ignorance total methods level competence Thus architecture reasonable provide specialize example learning general feature evidence repeated related territory structions Experts cus direction need begin main knowledge instances represent inferences form Ariadnes facilitators representations cognitive map visual world representations based abstract general obstructors world These features consistent ways humans use constructed representations 44 These 45 They integrated kinds information human user require multiple representations geographers use levels people gauge distance There ways tolerance tell like naive geography number turns way 381 view Ariadnes degree problem difficulty distort visual perception task resourcelimited inconsistent systematically complete consistent Ariadnes incorrect representation space People space perception recall reliance information facilitate form model people rely 81 Even supported results If CPU time agent makes fewest passes Fig 3 best If travelin g time fuel scarce resource scarce resource structure constructs synergy variety routes campus explained distance 181 turns FORRs decision agent FORR agent achieves lack The behavior human subjects asked traverse time number shortest paths best On metrics ablated versions problem level 306 SL EpsteinArtijicid ltztellience 100 1998 275322 65 Situationbased behavior compromise search forget philosophy The initial tier 2 easy Tier 2 Advisors computing ways First FORR allocates Advisor impulse reactive programming avoid search instead search local space restricted tier reactive Advisors tier 1 search long intended fragments identified decisions local time unconfirmed current perception When augments 3 minimization tier limited construct arise Second address particular subgoals These routines generate test solution proposed partial solutions trigger preserving combinatoric search effective saves tier2 Advisor Appendix Roundabouts deep severely curtailed knowledge tier2 Advisors handcoded resources This constraint explosion For example highly constrained routines kept time Solution situation detailed address fragments applied procedure proposed kind solution deemed appropriate Section 2 tier2 Advisors intended decision making tailored particular category situation simulate behavior observed 23 The decision makers Ariadne type Ariadne situation category reasoning indexed relevant cases retrieved attempt behavior In CBR experiences casebased situation situationbased common current problem 24 Although current state behavior retrieve specific solutions generate solution situationbased solution generation CBR knowledge fragments Situationbased searching inherent study CBR human experts This claim likely resources behavior emphasize problem solving reminding studying timelimited interpretation As discussed psychologists described recognized trigger search In FORRs CBR stored Later potentially modify solutions behavior index modified procedures behavior old solutions situationbased procedures Klein Calderwood perceive parallel limited triggered abstraction CBR situationbased CBR constrain people solve intended Situationbased intended behavior planning set ac reach specific goal 43 The Advisors tier 2 planners recom eventually Lshaped paths second step chooses A plan actually behavior execute For example Wander investigate step direction plus possible tions mend longest execute Rather planners seize control FORRbased time elapses sequence actions execution like Pengi maker world held explicit decision standard steps situationbased Advisors programs 11 The principal difference resources situationbased Advisor returns control requires Tier 3 constitutes procedures reactively fixed period time When tier 3 returns reactive decision living 1000 decision Pengis problem like solved XL EpwinArtificiol lntellipnce 100 1998 275322 307 Situationbased behavior resourcegrabbing fragment production duce solution tier2 Advisor condition production tors response action A macrooperator successful procedure situationbased Advisor situation kinds behavior appropriate generalization complex particularly rule macrooperator Although intended heuristic digression pro trigger rule comment genera overridden tier 1 variables entailed procedural generalization situationbased Finally reactivity resentation moves aligned lies domain representation component reactive learner behavior sheds light ongoing debate rep includes 30 22 Ariadnes conceptual knowledge maze wall essential 5 locations robot goal This paper demonstrates conceptual context knowledge 66 The interaction reactivity heuristics search reactive ReactiveHeuristic Ablation shows interdependence reactivity heuristics situationbased determined tier 2 FORR intervening wall augmented needs maneuvers goal reach circumnavigation trigger significantly ReactivetSearch repertoire behaviors The situationbased Advisors learned useful agent simply regions Giant Step ex like Wanders Lshaped path It regularly needs closer The situationbased Advisors behaviors Without knowledge The results good This agent regularly gets stuck tricate gets close Roundabouts tier 2 clear contribution combined tier 1 ReactivetSearch limited sufficient They Ariadne tively device example Wander wall Subgoals programmer There inherent situationbased Advisors Goal Column robot Roundabout based Advisors tier 2 set heuristic puts robot comments Another useful knowledge sets tier 2 trigger For example Goal Row trigger In turn situation tier 3 For example Wander newly constructive robot experiences ReactivefSearch subgoals The subgoal tries Roundabout detected program nature lack recent progress Tier 2 effec opposite trigger tries predetermined tiers Tier 1 offers task Tier 3 tries avoid search effectively tier3 Advisors likely sideeffect search complex problemsolving tier 2 acquisition tier benefit Advisors commonsense triggers measure relationship execute important reasoners 67 The role qf learning pragmatic navigation As limited data indicate learning essential resources The ablated NoLearn agent agent failed facing hard problems solve hardest 308 S Id Epwirr A1 Intelligence 100 1998 275322 version perform 20 learning problems Even level 6 NoLearn slower solve problems meander nraze knowledge forced Ariadne trials lack Table 1 indicates One hallmark Ariadnes pragmatic navigation variety flexible use applied seven different experience useful knowledge Corridors demonstrate procedures knowledge data Advisors Barriers demonstrate different Advisors provides apparently single representation flexible acquisition knowledge fodder learning danger learning useful knowledge static map maze efficient Nor detailed 20 x 20 random Ariadnes mazes average 325 barriers 805 bases 16 bottles 39 chambers 493 corridors 180 gates As graph maze 280 nodes approximately features After 20 level8 problems learned heuristic representation example 1485 edges Perhaps interesting Even randomlygenerated goal walllike compares triggers programs overall performance program FORR uses learn weights formulated model expertise learner Although initial paths autonomy domain challenge balancing Advisors comments mazes different kinds Some conceal structures place end tortuous path When Table 3 number decisions solve problem number clear Ariadnes decisions tier 3 improved The key believe apply voting learn value tier3 Advisors appropriately AWL algorithm tier 3 111 AWL game playing learner necessarily access autonomous weights trained problem generators improve performance currently adapting AWL retain Ariadnes opposition As described Ariadne testing indicated 68 The role plunnirg pragmatic navigation level10 distinct effective Ariadne tool Although surprisingly inexpensive The simple planning naive sors Home Run Leapfrog Patchwork problem computation necessarily 770 available bases Because bases strengthened reidentification different Advisors use time Ariadne develops habitual way people It uncommon Ariadne This means fortuitous choice occurs develop shortcuts taught plans generate The planrelated Advi average 015 17 seconds 1458 average routes stage entirety unlikely testing On average Ariadne constructs plans level 10 problem testing late learning plan fairly early execute program reasonable formulate testing Because plan Ariadne goal plan instead reaction knowledge reactive sequence positions location fact currently applicable plan robots current sense 1391 Ariadnes planning construct The preference attempt Schoppers bases SL EpsteinArtificiul Intellipnce 100 1998 275322 309 orthogonal moves readily patched circumnavigation bases instead considering strategic approach locations 40 Ariadnes plans deliberately planning similar legal travel routine Using bases plan makes overly optimistic assumptions travel experience routes correct robot adequate maze This generally efficient time invested replan plan construction Ariadnes correction possible choices support structured The component ripe development Ariadne barriers gates corridors facilitate efficiently useful knowledge long appropriately wary heuristic nature information corner offices office mazes An Advisor items significant plan construction links chambers bottles planning No Advisor considers reasoned contribution travel 69 The real world Although Ariadne require adaptation direct realworld territory distant navigation dangerous deep sea terrain roboticists embodies principles planet correct complete maps unavailable pragmatic When warehouse practical The nature maze permits sections edges Fig 1 territory mazes unreachable For real world fineness grid determined Given heuristic nature useful knowledge inaccuracies measuring devices robotic controls want fine grid approximations pragmatic navigation feature orientation irregularlyshaped tolerable tolerated dynamic robot consider issue The primary allow margin error Continuous adaptation sensors Their inaccuracies discrete sensing require modifications robot sense travel orthogonal costly Permitting equipment robots far human directions limiting 191 The equidistant placement sensors judged appropriate proclivities task forward motion productive lateral backward movement A generous number sensors directions better revision algorithms Finally drift attempt avoidance maneuvers Standard AI search methods provision No real difficulty G unit randomly chosen direction nice fit opportunistic Ariadnes moves The instability G goal completely necessitate increased computation realworld problems foreseen stationary planner require 7 Related work This work clear counterparts Korfs analysis heuristic tile puzzles 25 His minimin search strategy commitment search shared 310 XL EpsreinArtijiciul Intelligence 100 1998 275322 lengthens Euclidean necessity loop prevention number steps distance heuristic tile puzzles disappointing better ways reach goal Korfs permission solution For Ariadnes Plod correct unobstructed I 1 1 IO plodding example 9 moves immediate 1 10 legal Ariadnes way Korf tried heuristic Mr Rogers uses results Once node ordering close domain backtrack Roundabout Ariadne foolproof Done That discourage Korf indicates limited far robot ahead ReactiveHeuristic solve problems expected performance general mazetraveling level difficulty uncertainty solver loop prevention Been There Cycle Breaker tree search space If search horizon agent sees step ahead That agents better useful knowledge particular maze remains ability problem loops In Ariadnes graph locally optimal Ariadnes problems tile puzzles decision making level difficulty expect tier3 Advisors solutions impacts attributable It possible analogous knowledge dictate different definition recent machine learnin g important note programs I single problem Although Ariadnes maze problems reminiscent learning task fun 3 1421 Such programs seek convergence In contrast Ariadne mechanism satisticing paths set problems applying knowledge attempt instead problemsolving work reinforcement damental approach significantly Sec optimal path repeated solution according tion guarantee optimality quickly settle route cases Ariadne constructs attempt problem problem The complexity maze problem learners function goal strength number stateaction pairs number The complexity reachable locations directed onestep movements problem Ariadne size maze strength goal Memory use different learns abstractions value onestep attempted Ariadne hand number turns required reinforcement reinforcement state refine estimates independent learners learned recently A second learning set abstraction suggested grid world operated abstracted solution paths adnes warehouses present deadends narrownecked effective barriers easy approach casebased planning method spaces stored detailed 31 These mazes somewhat simpler versions Ari chambers bottles large regions Once Ariadne relatively One way characterize approach learning navigation robot degree engineered area ranges robots abilities preprogrammed thoroughly 34 5 Although Ariadnes rum approach tabula initial knowledge certainly engineered conflicts knowledgebased tier 3 tier3 Advisor deliberately learn left principles outweigh formulated Work prescribed learn voting SL EsteilAtcicll Intelligence 100 I 998 275322 311 particularly approach learning navigation general cognition A second way characterize survey map global limited shortterm memory integrates path finding landmarks human sensory orientation position robot reflects known human perception behavior PLAN 5 PLAN route map place sequences information All maps strong 180 necessary maps based In contrast gate base Although developed gateways Ariadnes bottles chambers PLAN regional maps PLANs maps scale level difficulty far traverses ease authors offer statistics degree connectionist model learns topological map experienced directions based visual scene aerial view The resultant biases intelligent experience experience Ariadne reasoning independently similar makes global overview explicit plans hierarchically expertise appears Ariadne efficiency effectiveness sequence PLANs features similar record pure1 y visual rote experience Ariadnes gates regions similar robot navigation The authors claim represents momentary retains knowledge experiences refusal Ariadnes experience robot approach representations characterize quadrants connectors rigorous approach boundaries learning navigation 2 11 He envisions world Hayes constructed reasoning space pieces like Ariadnes like Ariadnes access points gates There implemented version sensorily distinctive Ariadnes A way representation space bottles chambers bottlenecks 271 Qualnav TOUR landmarks As grid world originally theories substitute Ariadne useful completed problems TOUR PLAN topological network routes systems Ariadnes places plans naively global overview graph opportunistically Ariadnes gates bases reactive approach described preferred computational 281 landmarks postulated Korf provide useful knowledge simple travel Ariadne store routes route fragments learns learn routefragment efficiency limited storage gates bases predicated implicit Although manipulated path Unlike SSH Spatial Semantic Hierarchy realworld spatial knowledge topological level learned places chambers Kuipers envisions pathfinding robots fourlevel ontological features 26 I Ariadnes gates bases level representation hierarchy lie primarily regions provide SSHs bottles exploration work complementary There work learning heuristics problems Ariadne transformations affords access risko sought approach tractive path available approach best content concepts Eurisko addressed Prieditis Absolver existing heuristics interesting transformations Since representation linked concepts problem solving Lenats Eu new useful ones 301 Such syntactic process semantic 29 domains way reflects transformation II sought abstraction problem AM 312 XL Epreh Artijicid Intelligence 100 1998 275322 representation The heuristics transformations 35 Absolver admissible number rooms robot visited problem description good problem heuristic variety grammatical sped tails required prune search time One problems Absolver dressed Rooms World problem mized analogous Chamberlain prespecihed solving Although classes ence II removed intended II ad mini task This relies rely gathered problem problem experi entering Outta Here In contrast Ariadnes heuristics heuristic course box moving Ariadne variety problems induced chambers necessary makes vulnerable incorrect generalizations learned applicable information computed makes Finally optimum paths space variety welldocumented algo IZ points 411 eventually face 0 n2 complexity cost The 24 Advisors search 0n2 comes underlying experience people formulate space If Ariadne construct rithms map based graph heuristic knowledge kind spatial descriptions tiers 1 3 react finite set subvert 2r1 1 legal moves available useful knowledge u fixed time t The tier 2 spend finite time t search For problem 8 Advisors 1 8t time Ariadne spends 1242n solution step limit 1 means search solution The key control U cost referenc ing useful knowledge sublinear The result occasionally optimal usually good performance Instead Ariadne employs satisficing approach obstructors facilitators 8 Conclusion tailored reasoning navigation particular closer Human navigators implemented better search mode react quickly correctly goal I pragmatic learning clearly productive unhelpful oppor tunities theres goal deadend They entertain variety far away long straight step heuristics situation They digress example obstacle epitomizes Ariadne naive geographic town Ariadne knowledge difficult problems Compared problems quickly measured path length It performs efficiently measured number distinct visited percentage repeated applies previous experience variety realistic world models Ariadne primitive planning controls kind way new campus uses fewer steps fewer resources solves time number decisions locations learns hitherto unseen problems random mazes learns variety features new environment solve multiple It solves travel easier ones allocation search resources elapsed problemsolving solves multiple problems path And Ariadne acquire knowledge search techniques Ariadne traditional locations territory tasks SL ElsteirlArtcicll Intelligence 100 I 99U 275322 313 Pragmatic navigation detailed shaped underlying architecture features longrange learning methods FORR robust adaptive detailed map pragmatic correct possibly useful executing journey representation mandate path selection Despite decision making tasks Ariadne Ariadnes plan pragmatic clear ability time empirical integration reactivity heuristics navigation represents search Instead Instead uniform acquire learning territoryspecific probably world collection technique feature instances Instead selects reasonable navigation pragmatic navigation opportunistically Instead planning heavy search costs finegrained constructs naive plans suggest heuristic nature Ariadnes knowledge learning relatively results demonstrate able solve novel difficult problems quickly outperform timelimited ablated versions demonstrates subset FORRs reasoning methods suffices domain Reactivity heuristics ing planning good performance advocates pragmatic navigation proach robust applicable learn essential appropriate manner This paper ap cognitively plausible developmental viable efficient path finding Ariadne demonstrates broad range environments search based situation approach FORR connects satislicing recognition Acknowledgments David Sullivans preliminary work Tonka convinced FORRbased version far primitive version Ariadne insight furnished Barry Schiffman provided generators represent suggestions mazes 121 Since Ariadne success An earlier reported constructive rooms offices warehouses Thanks compare Ariadne bestfirst Hayes Ben Kuipers Barbara Tversky search Mike Pazzani Jack Gelfand Alice Greenwood Pat suggestion shared wisdom Appendix A Ariadnes Advisors tier AI Tier I Advisors appear Victory absolute order consulted authority goal reachable legal Victory makes Curz Do forces adjacent On decision cycle Victory turn goal reach location vertically horizontally goal No Way vetoes unnecessary moves resides extent Recall No Way eliminates robot extent deadend deadend This Advisor checks legal goal If Advisor conservative contain approach bounding consideration rectangle deadend needs 314 S L EpsteinArtjid Intellimce 100 1998 275322 1 2 3 4 5 6 7 8 9 1011121314 Kev obstruction q deadend path R robot G goal Fig A I Roundabout circumnavigates obstruction Pipeline vetoes opposite exit view goal For example 14 IO 14 1 I pause location pipe aligned Fig 6 p 285 149 Pipeline veto moves pipe traveling east efficiently robot pipe location location A2 Tier 2 faced attempts algorithm robot robot situation attempts obstruction circumnavigate obstruction When goal When order consulted It triggers intervening tier2 Advisor goal traditional wallfollowing goal secondary direction obstruction row column aligned took robot Fig A Roundabout horizontal obstruction stopping 2 10 goal primary primary In Fig A 1 primary direction Advisors discussed Roundabout robot goal Roundabout example Ariadne intervening sight Roundabout direction barrier north secondary direction east Avoiding known deadends 49 58 direction possible goal view backup directions exceed original alignment search fails produce solution secondary direction circumnavigate attempt succeeds Roundabout search fail circumnavigate started actually bringing Roundabouts Fig A I search repeatedly moves goal primary secondary direction opposites secondary permitted algorithm shift robot laterally large shifts Its goal goal sight All learning opposite secondary direction iterates increasingly starch paths successful serve input barrier Although timelimited robot goal like tier2 Advisor getting closer coordinates While primary obstruction time permits heuristic establishes orthogonal fragment opposite 59 S L Epstei Artficid Intelligence 100 I 998 275322 315 Kev q obstruction plan patch R robot G goal Fig A2 Patchwork repairs plan small attempts triggers cover relatively Outta Here tier2 Advisor learn chamber sideeffect chamber Outta Here scans If Outta Here trigger Fig 7a goal Outta Here locations recent robot deadend chamber containing leave chamber deadend task underway fraction total area deadend Outta Here marches sequence steps way exit If robot routine access point p 287 robot path 4 12 4 13 10 13 Outta Here contain robots maze Ariadne believes goal If robot lead chamberlearning returns sequence steps robot chamber 2 12 generate guaranteed visited tier2 Advisor leave space Its trigger learning condition described Probe attempts Probe scans current chamber orthogonally recent experience Probe actually generated path chamber shown Probe chambers view tries robot access point leave chamber Chambers learned Fig 7a depending scans sideeffect search From 412 access point return current determines extent robots confinement robot location learn chamber guaranteed learned improve task triggered attempts tier2 Advisor routine Roundabout naively disregards repair current plan plan fails obstruction Patchwork circumnavigation Fig A2 shows typical Patchwork plan 5 10 When Patchwork fragment 41 7 10 Patchwork number solutions simpler approaches suffice When Patchwork succeeds step plan result contains Patchwork need correction circumnavigation I 4 12 512 4 IO triggers valid current plans 30 expected overly elaborate repairing task location new executes initial steps plan sequence patch set steps exhausted This prevents premature indicated plan inserting Fig A2 repaired obstruction fragment decisions 713 forces 613 513 316 S L ElsteirzArticirrl Intelligence 100 1998 275322 1 2 3 4 5 6 7 8 9 1011121314 Kev obstruction path R robot G goal Fig A3 Other Side shifts robots orientation goal need correction goal In way Patchwork moved robot Fig A2 directly state Other Side goal task robot cycles Other Side costly trigger describes result justexecuted attempts Other Side tier2 Advisor In decision location location fairly desperate goal appropriate current plans current right goal Other Side right Other Side path appears The robot began running northsouth 119 directional goal 42 I 12 contribution goal comes attempt fragment late attempts triggers edges maze robot shift robot left goal An example task maze learning irregular barrier penetrate robot If example 122 constructive robot triggered instead view 122 instead Other Sides path gone left respectively Fig A3 early right goal Other Side abandon halted I I 1 left goal reach goal When Other Side finally task 9 12 kept trying Super Quaw tier2 Advisor attempts change robots quadrant It current quadrant scans It goals quadrant time SuperQuadro extent gate change task underway robot triggers current quadrant tries sequence orthogonal goal quadrant preferably taken early learning 24 Super Quadro generated goals quadrant right solution Super Quadro heuristics require search solution constructive recently From task Ariadne path 56 different steps location quadrant 55 Fig A4 way goal This takes robot eventually like preferring gate lead goal Ariadne robots quadrant fragments 5ll S L Epstein Artciul Intelligence 100 1998 275322 317 1 2 3 4 5 6 7 6 9 1011 121314 Kev q obstruction El gate path R robot G goal Fig A4 Super Quadro responds trigger 1 2 3 4 5 6 7 6 9 1011 121314 Kev obstruction Wanders path Fig AS A situation triggered Wander Wander tier2 Advisor attempts new location far robots current location bases identified result solution robots behavior judged constrained location possible Wander Lshaped path leads triggers current likely fragment Wandering repetitive trigger stochastic probability I bases 0 I unobstructed maze locations Wander orthogonal directions As sideeffect Wander L On second solution recommend tests Lshaped paths pairs longest possible steps learns deadends leg robot align task goal Wander produces It prefers farthest direction goal ends location leg L pass location fragments like tier2 Advisor robot visited barrier recommend location goal 318 XL EpsteitrArtiial htellience 100 1998 275322 1234 567 8910 Kev obstruction path barrier R robot Fig A 6 Part Humpty Dumpty path barrier learned location rarely visited visited recently When little progress reliable tier2 Fig A5 robot begun 82 145 Wander triggered robots current Wander Now Wander Advisors makes dramatic Humpty Dumpty tier2 Advisor forced path 105 available vicinity The fragment Humpty Dumpty avoided judicious selection locations current barriers immediate data sors A Humpty Dumpty path fragment Fig A6 area contiguous tier 2 obstructions collects serves important impact sorely needed goes search barriers hindrances It triggers robot legal moves known algorithm Advi It goaldirected traverses barrier extracted appear returns input A3 Tier 3 Advisors tier 3 consulted simultaneously Their order presentation facilitate discussion align align Goal Row Goal Column attempt favors moves Row favors moves horizontally Giant Step Plod advocate steps respectively Late task Hurry proportionately longest steps When Step encourages single unit moves strongly goal robot close G robot goal Goal Column robot vertically goal Goal large small moves small area Giant strengths Plod advocates strength longest moves proportionate higher comment robot recently confined encourages Mr Rogers Contract address shortest distances supports strengths proportional produce advocates large steps robot close Closeness possible distance Both Advisors goal Contract uses proximity steps draw robot closet goal measured robot Euclidean goal Mr Rogers result moves goals neighborhood distance far relative goal Contract hand goal small steps mazes diagonal maximum address proximity Mr Rogers seeks close step size determine S L Epsteirl Artijiciul lntellience 100 1998 275322 319 visited returning strength representation lower comment locations With careful current task Been There discourages task discouragement Been There Done That Cycle Breaker Adventure address prior behavior location visited respond example direction previously robot repeatedly visits spots recent contrast encourages frequently reactive One way Been There reactive note locations Done That discourages moving visited location When moves Cycle Breaker attempts necessarily innovation Adverlture task greater strengths Czunzberuin discourages direction goal extent chamber intervene suggesting current context Adventure task array sense far unvisited recommends moves visited Advisors current new novel alternative locations goal If robot encourages moves powerful Probe goal Chamberlain exit Chamberlain encourages chamber support subsequent search recommend bottles Any bottle When bottle extent neck bottle bottle goal When location robot outside robot inside indicates single Cork tier3 version Chamberlain bottles neck seen provides exit goal encourages moves contain bottle Chamberlain contain discourages moves extent bottle Cork reverses indicates advice goal access point Detour avoids moving goal Jf barrier barriers intervenes Detour encourages moves avoid lie directly location known gates goals quadrant moves Quadra simpler version Super Quadro It encourages decreasing strengths extent known gate moves goals quadrant moves extent known gate quadrant known gates quadrant moves Home Run Leap Frog use bases Home Run encourages moves bases locations bases Leap Frog advocates lesser strengths moves legal location closest end current plan Corner advocates pipe direction goal opposite goal Crook advocates near exit corridor deadend strongly corridor far exit corridor far exit pipe turns strongly direction straight direction goal direction goal opposite Opening encourages reuse previously moves odd goal different cable Although heuristic works old path successful area offered good access parts maze successful path beginnings appli began moving location A4 Parameters Advisor applicabilit One common component triggers tier2 Advisors relative available resources Each task FORRbased measure lateness terminated 320 XL Epstein Artckd Intelligence 100 1998 275322 limit decision Depending partial solution far exhausted average described trigger met computation time allocated exhausted lateness measured number actual moves moves ratio actual moves limit computation problem time percentage decision resulted task length The following parameters applied experiments l Giant Step The recent 30 history confined 10 maze area l Humpty Dumpty The recent 30 history includes 80 fewer 3 known walls robots vicinity 50 legal actions decision limit exhausted l Opening The 15 moves constitute l Other Side 60 decision l Outta Here The recent 30 history limit exhausted opening confined 10 maze area l Wander The recent 30 history confined 10 maze area References 1 I 1 PE Agre D Chapman What plans Robotics Autonomous Systems 6 1990 2 1 G Biswas S Goldman D Fisher B Bhuva G Glewwe Assessing design activity 1734 complex CMOS Eds Cognitively Diagnostic Assessment circuit design Lawrence Erlbaum Hillsdale NJ 1995 13 LK Branting DW Aha Stratified casebased P Nichols S Chipman R Brennan Proceedings Morgan Kaufmann San Mateo CA 1995 pp 384390 14th International Joint Conference Artificial reasoning Reusing hierarchical problem solving episodes IJCAI95 Montreal Que Intelligence 41 RA Brooks 5 I E Chown S Kaplan D Kortenkamp Prototypes Location Associative Networks representation Artificial Intelligence 47 1991 Intelligence 139160 PLAN unified theory cognitive mapping Cognitive Science 19 1995 151 16 I K Crowley RS Sieglrr Flexible strategy use young childrens tictattoe Cognitive Science 17 4 1993 SRIS6l 171 E DeYoe D Van Essen Concurrent processing streams monkey visual cortex Trends Neuroscience I I 1988 219226 181 MJ Egenhofer DM Mark Naive Geography Technical Report 958 National Center Geographic Information Analysis 1995 191 SL Epstein Prior knowledge strengthens J Intelligent Systems 7 1992 547586 learning control search weak theory domains Internat 101 SL Epstein For Right Reasons FORR architecture learning skill domain Cognitive Science I8 3 1994 47951 I I I I I SL Epstein Collaboration interdependence limitedly rational agents Proceedings AAAI FaII Symposium Rational Agency AAAI Press Cambridge MA 1995 1 121 SL Epstein On heuristic Conference Artifcial 1995 pp 45446 I reasoning Intelligence reactivity Joint Proceedings IJCAI95 Montreal Que Morgan Kaufmann San Mateo CA 14th International search I I3 1 SL Epstein J Gelfand J Lesniak Patternbased decisionmaking multiagent expert Computational learning spatiallyoriented concept formation Intelligence 12 1 1996 199221 1 141 SLEpstein appear J Gelfand ET Lock Learning gamespecific spatiallyoriented heuristics Constraints XL EpsteinArtijiiciul Intelligence 100 1998 275322 321 I IS I KA Ericsson N Charness Expert performance Its structure acquisition American Psychologist 49 8 1994 725747 1 16 1 KA Ericsson RT Krampe C TcschRiimer The role deliberate practice acquisition expert performance Psychological Revirw 100 3 1993 363406 1171 KA Ericsson J Smith Toward General Theory ExpertiseProspects Limits Cambridge University Press Cambridge UK 1991 I8 1 RG Golledge Path selection route preference human navigation progress report ditineraires Proceedings 95 Semmerling cognitive des descriptions en Sciences Cognitives La Motte dAveillans France 1994 Proceedings 2nd International Conference Spatial Information Theory COSIT Austria Lecture Notes Computer Science Springer Berlin 1995 pp 207222 A Gryl Analyse Chercheurs A Cry Analyse et modelisation des processus discursifs mis en oeuvre dans la description ditindraires PhD Thesis Universite Paris Xl Orsay 1995 PJ Hayes The second naive physics manifesto JR Hobbs RC Moore Commonsense World Ablex Publishing Norwood NJ 1988 pp l36 PJ Hayes KM Ford N Agnew On babies bathwater 1994 GS Klein R Calderwood Decision models lessons field IEEE Trans Systems Man Cybernet 21 5 JL Kolodner Issue CaseBased Reasoning Machine Learning 1991 Introduction Eds Formal Theories tale AI Magazine Premier Colloque Special cautionary 10181026 I5 4 IO 3 Jeunes 1526 1191 1201 1211 1221 1231 1241 1251 1261 1271 1281 1291 1301 131 I 1321 1331 341 1351 L36l 1371 1381 1391 1401 141 I l5 I3 I 1993 1988 learning learning 129153 103130 approach sweeping intelligence Intelligence discovery reinforcement largescale mapping initial results PhD Thesis mathematics Intelligence 2The game Go space AI Magazine 9 2 learning data time spatial knowledge Cognitive Science 2 1978 learns new heuristics domain concepts Artificial Intelligence 42 1990 18921 I robot J Connell Eds Robot Learning Kluwer Academic Publishers Boston MA 1993 pp 141170 1993 R Korf Realtime heuristic search Artificial B Kuipers R Froom WY Lee D Pierce The semantic hierarchy S Mahadevan BJ Kuipers Modeling BJ Kuipers TS Levitt Navigation 2543 DB Lenat AM artificial Department Computer Science Stanford University 1976 DB Lenat EURISKO program 26 1983 6198 AW Moore CG Atkeson Prioritized Machine Learning B Pell Exploratory Heuristic Programming Artificial Chichester UK 1991 pp 137152 J Piaget B Inhelder The Childs Conception Space WW Norton New York 1967 D Pierce BJ Kuipers Learning Artiticial 1271 AE Prieditis Effective admissible heuristics Machine Learning 12 l3 MJ Ratterman SL Epstein Skilled like person comparison human game playing Proceedings 17th Annual Conference Cognitive Science Society Lawrence Erlbaum Pittsburgh PA 1995 pp 709714 MJ Ratterman SL Epstein Gameplaying EK Sadalla SG Magel The perception traversed distance Environment 6579 MJ Schoppers SJJ Smith DS Nau TA Throop Totalorder multiagent Proceedings 13th National Conference Press Cambridge MA 1996 pp IOS I 13 E Stefanakis M Kavouras On determination International Conference Notes Computer Science Springer Berlin 1995 pp 241257 DNL Levy DF Beal Eds Second Computer Olympiad Ellis Horwood 12th National Conference Press Cambridge MA 1994 pp l264 2nd 95 Semmerling Austria Lecture In defense reaction plans caches Al Magazine 10 4 explore build maps Proceedings contract bridge Portland OR MIT optimum path space Behavior 12 1980 Seattle WA AAAIMlT Information Theory young children preparation Proceedings 1989 5160 Artificial tasknetwork AAAI94 AAAI96 Intelligence Intelligence Spatial expertise planning I17141 COSIT 1993 322 XL EpsreiArtfificicrl intelligence 100 1998 275322 I42 1 RS Sutton programming Integrated architectures learning planning reacting based approximating dynamic Proceedings 7th International Conference Machine Learning Austin TX Morgan Kaufmann San Mateo CA 1990 pp 216224 1431 A Tate J Hendler M Drummond A review AI planning techniques J Allen J Hendler A Tate Eds Readings Planning Morgan Kaufmann San Mateo CA 1990 pp 2649 144 1 B Tversky Spatial mental models The Psychology Learning Motivation 145 1 B Tversky Distortions 131138 1461 L Ungerleider M Mishkin Two cortical visual systems cognitive maps Geoforum 23 2 1992 Analysis Visual Behavior MIT Press Cambridge MA 1982 pp 548586 D Ingle M Goodale R Mansfield Eds 27 1991 109145