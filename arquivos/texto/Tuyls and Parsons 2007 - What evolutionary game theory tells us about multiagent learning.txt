Artiﬁcial Intelligence 171 2007 406416 wwwelseviercomlocateartint What evolutionary game theory tells multiagent learning Karl Tuyls Simon Parsons b Institute Knowledge Agent Technology Maastricht University The Netherlands b Department Computer Information Science Brooklyn College City University New York 2900 Bedford Avenue Brooklyn 11210 NY USA Received 1 May 2006 received revised form 8 January 2007 accepted 9 January 2007 Available online 26 January 2007 Abstract This paper discusses If multiagent learning answer question Y Shoham R Powers T Grenager If multi agent learning answer question Artiﬁcial Intelligence 171 7 2007 365377 issue perspective evolutionary game theory We brieﬂy discuss concepts evolutionary game theory examine main conclusions Y Shoham R Powers T Grenager If multiagent learning answer question Artiﬁcial Intelligence 171 7 2007 365377 issue respect previous work Overall ﬁnd agree concluding central concerns multiagent learning narrow compared broad variety work identiﬁed Y Shoham R Powers T Grenager If multiagent learning answer question Artiﬁcial Inteligence 171 7 2007 365377 issue 2007 Elsevier BV All rights reserved Keywords Evolutionary game theory Replicator dynamics Multiagent learning 1 Introduction In If multiagent learning answer question Shoham Powers Grenager 20 authors valiant effort analyse state ﬁeld multiagent learning summarise results achieved ﬁeld discern major research directions followed issue arms In short Shoham et al conclude work multiagent learning placed ﬁve buckets associated distinct research agenda descriptions taken directly caricatures Section 5 20 1 Computational learning algorithms way compute properties game 2 Descriptive learning algorithms natural agents learn context learners 3 Normative learning algorithms means determine sets learning rules equilibrium 4 Prescriptive cooperative learning algorithms agents learn order achieve distributed control dynamic systems 5 Prescriptive noncooperative learning algorithms agents act obtain high rewards Corresponding author Email addresses ktuylsmiccunimaasnl K Tuyls parsonsscibrooklyncunyedu S Parsons 00043702 matter 2007 Elsevier BV All rights reserved doi101016jartint200701004 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 407 In addition 20 Not work ﬁeld falls buckets This means need buckets work needs revisited reconstructed wellgrounded The authors point research multiagent learning unclear agendas pursuingand contrast needs clear ones aimsthat ﬁeld progress deﬁning arbitrary learning strategies analysing resulting dynamics converge certain cases Nash equilibrium solution concept ﬁeld needs evaluation seriously especially set standard problems We basically agree points quoted expand feel background leaves best qualiﬁed discuss However major point disagreement views expressed 20 The point disagree idea overall taxonomy research agendas work slotted This explicitly statedall Shoham et al quoted ﬁve distinct agendas additional ones need addedbut existence underlying taxonomy additional categories slotted implied Our objection neatly summarised following passage McWhorters The Power Babel A natural history language 15 author tries express original language spoken common ancestors thousands languages descended He starts saying I implied speech varieties developed like bush starting single sprout branching directions branch developing subbranches going explain interrelationships languages constant process adoption terms language formation dialects creoles intertwined languages means 15 page 94 analogy stewing good spring lamb stew juice juice messes analogy Clearly distinguish lamb peas potatoes carrots leeks rosemary leaves Yet ingredients good stew suffused juice ﬂavor items Every encounter piece covered liquid cooked original shape consistency work ﬁgure original identity Overall stew tastes looks like dumped pot boiling water It multiagent learning stew helpful identify ingredientsespecially stretch metaphor better taken potto concentrate constituents misses essence It places agendas stew meld new things things taxonomy mixture ﬁnd interesting work1 That said reiterate largely agreement agendas identiﬁed 20 section amplify agreement examining ﬁve agendas lens evolutionary game theory EGT area multiagent learning working discussed 20 Following exploration return point interplay agendas illustrating discussion recent work 2 The ﬁve research agendas perspective evolutionary game theory In section use EGT illustrate reaction analysis multiagent learning presented 20 To ﬁrst consider ﬁve research agendas means terms EGT taking order best ﬁts argument order presented Shoham et al 1 Though especially careful clear junctures 408 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 21 Normative descriptive agendas Our view EGT represents away normative agenda terms 20 descriptive agenda In particular summarised 6 recent years seen important shift game theory away classical solution concepts Nash equilibrium EGT solution concepts evolutionary stable strategy2 ESS replicator equations The obvious reasons Nash equilibrium hard compute best way behave terms optimality stability able deal highly dynamic situations EGT 8101319 suffers problems opinion descriptive approach embodies matches overall goals multiagent learning better normative approach preserve traditional game theory GT In subsequent sections explain basis beliefs 211 From game theory evolutionary game theory When John MaynardSmith applied game theory biology 1314 invented evolutionary game theory relaxed premises GT Classical GT normative theory sense expects players agents perfectly rational behave accordingly 242729 In classical game theory interactions rational agents modelled games players choose set strategies corresponding preferences Game theory mathematical study interactive decision making sense agents involved decisions account choices Choices determined stable preferences concerning outcomes possible decisions strategic interaction agents account relation choices decisions agents Players classical setting perfect knowledge environment payoff tables try maximise individual payoff However biological circumstances considered MaynardSmith impossible judge choices rational Instead ﬁguring priori optimise actions question facing player learn optimise behaviour maximise return based local knowledge process trial error This learning process matches concept evolution biology forms basis EGT In contrast classical GT EGT descriptive theory describing process learning need assumption complete knowledge perfect rationality As result evolutionary game theory steadily gained acceptance economic game theory 67 given close connection game theory work multiagent learning believe important foundation descriptive agenda Evolutionary models agents decisions complex environments interact agents In words evolutionary models expressly designed work exactly kinds environment exist real world 212 On relation solution concepts GT EGT To understand importance EGT multiagent learning helpful summarise relationship solution concepts GT EGT GT assumes players compute Nash equilibria choose play strategy EGT assumes players gradually adjust strategy time response repeated observations payoffs The replicator dynamics RD control learning specifying frequency different pure strategies played depending mix strategies played remainder population agents playing game Strategies gain aboveaverage payoff likely played RD models process agents switch strategies appear successful Carrying analysis number mixed strategies gives picture gameat point space mixed strategies possible determine agent switch current strategy possible plot direction ﬁeld indicates movement strategy space switches lead As example consider Prisoners Dilemma PD game In Fig 2 plot direction ﬁeld replicator equations applied PD The direction ﬁeld presented consists grid arrows tangential solution curves It graphical illustration vector ﬁeld indicating direction movement point grid state space The xaxis represents probability ﬁrst player play defect 2 A strategy evolutionary stable robust evolutionary pressure strategy appears In context strategic game strategy simply pure mixed strategies available agent K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 409 Fig 1 The strategic form Prisoners dilemma row player A column player B D Defect C Cooperate Fig 2 Direction ﬁeld plot Prisoners dilemma game yaxis represents probability second player play defect We plot probability players play second strategy cooperate The stationary points direction ﬁeld given game clearly points groups agents evolve time Every Nash equilibrium game stationary point opposite hold Thus notion rest point RD interpretation Nash equilibrium context As result introduce criterion asymptotic stability gives kind local test dynamic robustnesslocal sense minimal perturbations The following intuitive deﬁnition asymptotic stability equilibrium asymptotically stable following conditions hold Any solution path RD starts sufﬁciently close equilibrium remains arbitrarily close This condition called Liapunov stability Any solution path starts close equilibrium converges equilibrium For formal deﬁnition asymptotic stability refer 9 Now equilibrium RD asymptotically stableit robust local perturbationsthen Nash equilibrium 24 This means solution asymptotically stable Nash equilibrium asymp totic stability weak reﬁnement Nash concept It natural ask ESS asymptotic stability strongest reﬁnement Hofbauer Sigmund Schuster provided answer question 10 proving strategy s ESS population state represents stable terms RD This result gives way reﬁne asymptotically stable rest points RD provides way selecting equilibria RD dynamic robustness convincing solutions Nash equilibria precisely stability Turning example Fig 2 Nash equilibrium ESS lie coordinates 1 1 All movement goes equilibrium 410 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 Fig 3 Battle sexes Overall believe EGT Nash equilibria continue relevant relevant Shoham et al maybe credit Since equilibria RD natural points groups agents end imagine interesting ones ESSs ones agents stay points Nash equilibria EGT tells Nash equilibria reasonable focus attention For detailed technical discussion refer reader 22 213 On multiagent learning Building models agents learn requires insight type form agents interactions environment agents including humans In work multiagent learning modelling similar standard game theoretical modelplayers assumed complete knowledge environment hyperrational optimise individual payoff disregarding means utility fairness entire population In contrast basic properties multiagent systems MAS correspond EGT main reasons First MAS consists actions interactions independent agents try accomplish certain possibly cooperative conﬂicting goal No agent general completely informed agents intentions goals general completely informed complete state environment EGT provides mechanism behaviour analysed Second MAS dynamic agents change behaviour time response behaviour agents EGT offers solid basis understand dynamic iterative situations context strategic interactions shown ﬁts dynamic nature typical MAS3 Not fundamental assumptions EGT MAS ﬁt formal relationship replicator equations EGT reinforcement learning RL 22123 As illustration provide example relation Qlearning popular forms RL EGT More precisely present battle sexes game Fig 3 direction ﬁeld Qlearning trace agents Figs 4 5 As ﬁgures dynamics revealed trace precisely direction ﬁeld More technical details 22 22 The computational agenda The computational research agenda described Shoham et al concerned computing properties game As seen clear evolutionary game theory considered contribution work agenda What obvious use evolutionary game theory compute useful properties 3 We argue MAS reﬂection way people behave real worldsince agents typically act behalf peopleand Gintis points 8 Far norm people selfinterested common parlance called sociopaths That odd build systems selfinterested agents use classical game theory analyse MAS However argue adequate construction agents utility function maximise utility act way obviously selfinterested game theory perfectly adequate tool analysing MAS K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 411 Fig 4 Direction ﬁeld plot battle sexes game Fig 5 Qlearning trace battle sexes game As example consider work presented 16 EGT analyse differences complex games played set players The games analysed 16 forms double auction4 continuous double auction CDA matches buyers sellers occur time makes offer clearing house CH buyers sellers matched predetermined time point The approach borrowed heuristic strategy analysis HSA Walsh et al 28 assumes complex games boundedly rational buyers sellers choose handful wellestablished bidding strategies inventing new approach Given assumption reasonable model participants choosing replicator dynamics subset handful strategies In particular 16 considered computing properties double auction variants assumption traders choose bidding strategy suggested Preist van Tol 17 proposed Roth Erev 4 mimics human behaviour The point analysis able predict human automated traders interact The results analysis given Figs 6 75 The ﬁrst set results suggested Shoham et al equilibrium results As described interpret stationary points replicator dynamics ﬁeld equilibria agents end given initial mixture strategies adopted agents playing game These results example suggest CH initially half agents humanthat use RothErev RE strategyand half automatedthat 4 A double auction like stock market multiple buyers sellers See 5 double auctions 5 Note passing true multiplayer games As 16 28 results vary greatly number agents change 412 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 Fig 6 Replicator dynamics direction ﬁeld CH 10 agents Fig 7 Replicator dynamics direction ﬁeld CDA 10 agents use Preist van Tol strategy PVTthen reach equilibrium traders automated In contrast CDA initial conditions lead agents RE strategy6 However argued 16 If assume starting point priori equally likely use size basin attraction given equilibriumthat set points replicator dynamics suggest agents equilibriumas measure likely given equilibrium Combining payoff strategy obtains equilibrium establish expected payoff agents game 16 assuming initial points distribution strategies agents equally likely factor probability distribution strategy distributions wanted Of course validity particular results obtained 16 hinge underlying assumptions heuristic strategy analysis course disputed What disputable point view computational perspective EGT offers way compute equilibrium behaviour equilibrium properties games use information provide comparisons games7 When working mechanism design perspective interested picking games satisfy certain criteria kind analysis helpful To summarise thoughts computational agenda EGT perspective agenda fundamental EGT primarily computing properties games Equally EGT analysis contribution computational agenda Furthermore computation focus identiﬁcation equilibria payoffs obtained agents establish properties interaction agents 6 The pure strategy Figs 6 7 truth telling TT strategy trader honestly bids true value good question 7 Though discussed section equilibrium behaviour set boundedly rational perfectly rational agents K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 413 23 The prescriptive agendas The ﬁnal agendas identiﬁed 20 view multiagent learning mechanism identifying agents behave different classes problemcases agents cooperate provide distributed control share overall team rewards cases agents compete look achieve high personal payoffs Again view slightly different way Shoham et al 231 Our view prescriptive agendas Our view stems background researchers interested constructing multiagent systems That concern essentially engineering concernhow construct systems work The kinds interested consider orthodox multiagent systems statement means essence writings 30 They systems multiple threads controltypically thread control associated independent entity goals control resources deployed achieve goalsand resource constrainedso resources available entities sufﬁcient achieve goals The dependencies resources goals mean entities best cooperating fact entities independently controlled means essentially competition From perspective key issue ﬁnd right way entities represented software agents act order cooperate agents makes sense deﬁned fashion cooperate best welldeﬁned sense maximise position This consider coop erative noncooperative agendas headingin general agent operating setting cooperative noncooperative work agenda considering Though course considering perfectly valid given size task understand best We paramount need agents trying engineer able adapt8 They need adapt environments change time inherently sum total agents inﬂuences environment environment exists bubble interactions agents general considerable effect best point time In short focus obtain distributed control adapts For multiagent learning question multiagent learning help answer Furthermore believe research agendas identiﬁed Shoham et al contribute ﬁnding answers question 232 Where disagree Shoham et al We considering completely orthodox views multiagent systems imagine systems build composed agents cooperative respect peers noncooperative respect peers Furthermore peers given agent cooperates typically change time goals held resources available agent change time9 This overall goal establish mechanisms adaptive distributed control believe prescriptive agendas ultimately merge In contrast Shoham et al consider fourth ﬁve agendashow prescribe agent behaviour cooperative domainsis concerned adaptive distributed control form control naturally modelled team game Further suggest 20 rarely role equilibrium analysis agents freedom deviate prescribed algorithm 8 Thus agree completely Shoham et al interesting aspect adaptation learning agree arguing point distraction main message 9 The fact agents wholly cooperative taken factor distinguishes multiagent research narrower ﬁeld research distributed artiﬁcial intelligence 414 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 We disagree Rather believe adaptive distributed control arise perfectly naturally noncooperative domains domains noncooperative sense understand 20 domains closely align human society domains agent behaviour prescribed10 An example provided Rosenschein Zlotkin classic work negotiation 18 example school run Although parent suburban neighbourhood derives purely individual payoff ensuring children school completing delivery quickly possibleand preprogrammed cooperative subject team rewardthese parents end cooperating reallocating delivery children order minimise journeys Even joint wards considering payoffs individual agents case solutions involve measure cooperation albeit cooperation individually beneﬁts agent emerge This course taken lesson overtly noncooperative domains Iterated Prisoners Dilemma 1 Fur thermore right perspective sufﬁcient distance naked selfinterest agents visible selforganisation kind recognisable pattern delivery children school time looks like form distributed control adaptively manages resources parental time car capacity Finally taking EGT perspective clear equilibrium analysis important examples like In EGT establishing equilibria replicator dynamics tells states given settle time intermediate states In words equilibrium analysis tool predicting adapt equilibrium state There thing note passing The example Rosenschein Zlotkin classical example kind problem vogue early days multiagent systems The designers multiagent systems presumed given problem statement idea good allocation resources expected come strategies agents use enable agents range properties reach good solutions This implicitly assumes designers access internals agents insert necessary algorithms A modern view design mechanism design usual economic meaning term 11 In kind setting designers given harder task coming rules interactions agents matter algorithm agents use decisions good solutions good deﬁned terms individual beneﬁts group beneﬁt wants arise This change affect argument 3 Research agendas intermingle As discussion ﬁve research agendas indicated believe perspective EGT clear agendas distinct suggested Shoham et al We example consider EGT means computing properties games mechanism describing agents act game Thus application EGT contribution agendas emphasis varying applications Thus example auction analysis described mainly contributes ﬁrst second agendas load balancing work 2526 contributes ﬁrst fourth ﬁfth agendas More generally EGT thought work computational agenda work focuses primarily payoffs individual agents largely descriptive Furthermore view research multiagent learning concerned build systems adaptive distributed control prescriptive agenda subsume In way position ampliﬁes importance following Shoham et als advice researchers multiagent learning need clear exactly agendas contributing While view piece research multiagent learning way contributing understanding create systems adaptive distributed control vital burgeoning ﬁeld able easily understand piece research making contribution The need clarity increases time use EGT ﬁnd making contributions agendas Indeed better thinking work tributions new agendas arise intermingling ﬁve agendas 20 As new agendas multiply possibilities picked order identiﬁcation 10 Noting staple intelligent agent literature notion notsodistant future agents handle mundane human tasks 312 agent societies reasonably assumed mirror human societies K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 415 agendas intermingle easier mistake work mingled agenda return stew analogy borrowed start paper harder distinguish lamb onion carrot stew cooks longer 4 Summary In paper taken EGT perspective ﬁve research agendas identiﬁed Shoham et al 20 In summary agree existence agendas need greater clarity work multiagent learning respect relates agendas contributes overall goals ﬁeld However feel examples evolutionary game theory work falls boundaries agendas contributing way wrong We believe crossagenda work expected encouraged Looking individual agendas believe work normative agenda tribute overall goals multiagent learning ultimately concerned computationally limited agents descriptive agenda It help build systems real agents people interact Because agents people motivated level selfinterest payoff individual agents important role play equilibrium analysis certain classes equilibria equilibria replicator dynamics informative Putting view core activity multiagent learning area Shoham et als ﬁrst second ﬁfth agendas overlap In overlap concerned computing properties agenda 1 systems real idealised agents agenda 2 decisions motivated largely individual payoffs agenda 5 It believe multiagent learning effective answering question construct systems makes interested ﬁeld Acknowledgements We like express gratitude colleagues cooperated years work multiagent learning Furthermore wish thank reviewers editors Michael Wellman Rakesh Vohra providing valuable feedback documentwe believe feedback improved considerably The work described paper partially funded National Science Foundation grant NSF IIS0329037 References 1 R Axelrod The Evolution Cooperation Basic Books New York 1984 2 T Borgers R Sarin Learning reinforcement replicator dynamics Journal Economic Theory 77 1997 3 A Clark NaturalBorn Cyborgs Minds Technologies Future Human Intelligence Oxford University Press Oxford 2003 4 I Erev AE Roth Predicting people play games unique mixedstrategy equilibria American Economic Review 88 1998 848881 5 D Friedman The double auction institution A survey D Friedman J Rust Eds The Double Auction Market Institutions Theories Evidence Santa Fe Institute Studies Sciences Complexity Perseus Publishing Cambridge MA 1993 pp 325 Chapter 1 6 D Friedman Evolutionary economics goes mainstream A review The Theory Learning Games Journal Evolutionary Eco nomics 8 4 December 1998 423432 7 D Fundeberg DK Levine The Theory Learning Games MIT Press Cambridge MA 1998 8 H Gintis Game Theory Evolving A ProblemCentered Introduction Modeling Strategic Interaction Princeton University Press 2001 9 MW Hirsch S Smale Differential Equations Dynamical Systems Linear Algebra Academic Press Inc 1974 10 J Hofbauer K Sigmund Evolutionary Games Population Dynamics Cambridge University Press Cambridge 1998 11 MO Jackson Mechanism theory U Devigs Ed Optimization Operations Research The Encyclopedia Life Support Science EOLSS Publishers Oxford UK 2003 The working paper version article includes comprehensive bibliography bibliographic notes 12 P Maes Agents reduce work information overload Communications ACM 37 7 July 1994 3040 13 J MaynardSmith Evolution Theory Games Cambridge University Press Cambridge 1982 14 J MaynardSmith J Price The logic animal conﬂict Nature 146 1973 1518 15 J McWhorter The Power Babel A Natural History Language HarperCollins New York 2003 16 S Phelps S Parsons P McBurney Automated trading agents versus virtual humans evolutionary gametheoretic comparison doubleauction market designs Proceedings 6th Workshop AgentMediated Electronic Commerce New York 2004 416 K Tuyls S Parsons Artiﬁcial Intelligence 171 2007 406416 17 C Preist M van Tol Adaptative agents persistent shout double auction Proceedings 1st International Conference Internet Computing Economics ACM Press 1998 pp 1118 18 JS Rosenschein G Zlotkin Rules Encounter MIT Press Cambridge MA 1994 19 L Samuelson Evolutionary Games Equilibrium Selection MIT Press Cambridge MA 1997 20 Y Shoham R Powers T Grenager If multiagent learning answer question Artiﬁcial Intelligence 171 7 2007 365377 issue 21 PJ t Hoen K Tuyls Engineering multiagent reinforcement learning evolutionary dynamics Proceedings 15th European Conference Machine Learning 2004 22 K Tuyls PJ t Hoen B Vanschoenwinkel An evolutionary dynamical analysis multiagent learning iterated games The Journal Autonomous Agents MultiAgent Systems 12 2006 115153 23 K Tuyls K Verbeeck T Lenaerts A selectionmutation model Qlearning multiagent systems The Second International Joint Conference Autonomous Agents MultiAgent Systems ACM Press Melbourne Australia 2003 24 F VegaRedondo Economics Theory Games Cambridge University Press Cambridge 2003 25 K Verbeeck Coordinated exploration multiagent reinforcement learning PhD dissertation Vrije Universiteit Brussel Brussels Belgium 2004 26 K Verbeeck A Nowe K Tuyls Coordinated exploration multiagent reinforcement learning An application loadbalancing Pro ceedings Fifth Joint Conference Autonomous Agents MultiAgent Systems Utrecht The Netherlands 2005 27 J von Neumann O Morgenstern Theory Games Economic Behaviour Princeton University Press 1944 28 WE Walsh R Das G Tesauro JO Kephart Analyzing complex strategic interactions multiagent systems P Gymtrasiwicz S Parsons Eds Proceedings 4th Workshop Game Theoretic Decision Theoretic Agents 2001 29 JW Weibull Evolutionary Game Theory MIT Press Cambridge MA 1996 30 M Wooldridge An Introduction Multiagent Systems John Wiley Sons Ltd Chichester England 2002