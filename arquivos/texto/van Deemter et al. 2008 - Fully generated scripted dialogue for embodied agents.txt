Artiﬁcial Intelligence 172 2008 12191244 wwwelseviercomlocateartint Fully generated scripted dialogue embodied agents Kees van Deemter Brigitte Krenn b Paul Piwek c Martin Klesen d Marc Schröder d Stefan Baumann e Computing Science Department University Aberdeen Scotland UK b Austrian Research Centre Artiﬁcial Intelligence OEFAI University Vienna Austria c Centre Research Computing The Open University UK d German Research Centre Artiﬁcial Intelligence DFKI Saarbruecken Germany e IfL Phonetik University Cologne Germany Received 13 March 2007 received revised form 29 January 2008 accepted 14 February 2008 Available online 29 February 2008 Abstract This paper presents NECA approach generation dialogues Embodied Conversational Agents ECAs This approach consist automated construction abstract script entire dialogue cast terms dialogue acts incrementally enhanced series modules ﬁnally performed means text speech body language cast ECAs The approach makes possible automatically produce large variety highly expressive dialogues essential properties control user The paper discusses advantages disadvantages NECAs approach Fully Generated Scripted Dialogue FGSD explains main techniques demonstrators built The paper read survey issues techniques construction ECAs focusing generation behaviour focusing information presentation interpretation 2008 Published Elsevier BV Keywords Embodied conversational agents Fully generated scripted dialogue Multimodal interfaces Emotion modelling Affective reasoning Natural language generation Speech synthesis Body language 1 Introduction A number scientiﬁc disciplines started decade join forces build Embodied Conver sational Agents ECAs software agents humanlike synthetic voice computeranimated body engage conversation natural language Although techniques area shared ECAs paper focuses particular family ECAs behaviour determined automatically generated scripted dialogue autonomous agents decisions Let start explaining scripted dialogue Corresponding author Email address kvdeemterabdnacuk K van Deemter 00043702 matter 2008 Published Elsevier BV doi101016jartint200802002 1220 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Scripted dialogues follow master plan Perhaps basic example scripted dialogue stage dialogue actors behave according script written playwright Two actors playing Romeo Juliet example want necessarily Shakespeare adapting work wants The communication actors arguably fake real ﬂow information goes script writer audience The true dialogues people TV commercial real communication manufacturer customer This paper describes approach computational production scripted dialogues arisen NECA1 project henceforth called NECA approach scripted dialogue In NECA approach generation dialogue behaviour centralised heart NECA automated script writing engine This engine produces script performed ECAs The ECAs comparable actors like human counterparts carrying script written ECAs appear entered world scripted dialogue number systems described 2 Initially scripts mapped words gestures fairly direct manner fully canned text In paper approach powerful combined techniques Natural Language Generation NLG speak fully generated scripted dialogue FGSD NLG programs able express wellformed input information language English German example NLG makes possible express content different ways This makes possible create endless variety different actors acts role given following single set rules govern manner speaking moving This especially importantand especially challenging different ECAs distinct personalities expressive power starts include expression emotion case Henceforth speak expressive dialogues mean multimodal dialogues able express factual information affective state characters Although research ECAs different work games instructive compare en deavours Games programmers create characters display sophisticated behaviours able engage dialogue However creation games time consuming involves great deal handcrafting Even variation displayed characters tends limited number differ ent dialogues typically small performed way minor variations Games arguably interesting enjoyable useful characters displayed richly varied behaviour cf 23 ECAs Taking notion game point departure goal work ECAs viewed making easier cheaper create large variety appealing effective dialogues controlled way The Holy Grail workwhich applied games applications alikeis create tools allow semiautomatic construction dialogues believable highly ex pressive characters NECA aims Holy Grail It reason variation generated dialoguesat levels involving modalitiesis central design constraint NECA motivates aspects approach including choice fully generated dialogues Generating scripted dialogues involves speciﬁc set tasks different ones involved construction autonomous agents In scripted dialogue need recognise understand verbal input example The challenge generate dialogues agents behave understood reacted believable ways Believable implies course content form dialogues appropriate ECA systems based autonomous agents 13437281 interact real people ECAs This comes naturally ECA systems based scripted dialogue contrast ﬁnd interaction people difﬁcult possible interactions built script However certain advantages particularly terms alignment modalities terms ability ensure generated dialogues fulﬁl constraints example total length style internal coher ence 68 This paper presents NECAs approach creation varied expressive dialogues respect different levels modalities synchronisation Section 2 sketches different applications 1 NECA stands Net Environment Embodied Emotional Conversational Agents wwwofaiatresearchnluNECA We speak NECA approach refer ideas underlying demonstrators developed project K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1221 Fig 1 eShowroom selection actor personality explored order test generality methods Section 3 discusses architectural issues Section 4 scribes initial dialogue scripts produced Section 5 explains scripts subsequently treated Multimodal Natural Language Generation module Sections 6 7 focus speech gestures respec tively In course paper explain NECA differs alternatives proposed literature allowing paper read review state art construction ECAs introduction Fully Generated Scripted Dialogue The wideranging character paper allows important issues emerge tradeoff quality ﬂexibility advantages incremental architecture These issues highlighted Conclusion Section 8 2 Two NECA applications Each NECA demonstrators takes existing demonstrator point departure The eShowroom demonstrator inspired work collaborating presentation agents 1 Socialite extension Sysis NetLife platform communitybuilding tool users represented avatars 48 In cases stuck names demonstrators predecessors known Both systems substantially enhanced terms generality architecture terms variety quality dialogues produced In eShowroom scenario car sales dialogue seller buyer simulated The purpose application entertain site visitor educate cars User interaction restricted users set parameters inﬂuence dialogue content script played animated characters After user speciﬁed herhis preferences cars saying ﬁnd road safety particularly important personality acting characters role buyer seller played given agent dialogue generated takes settings account Fig 1 shows interface selecting characters personality For virtual actor Ritchie characteristics good humoured impolite selected user Fig 2 illustrates interface determining users preferences value dimensions speciﬁed product Fig 3 shows typical scene eShowroom agents seller buyer located selection cars screenshot Socialite system2 Socialite designed multiuser Web community derSpittelbergat users create personal avatar endow personality traits preferences send virtual environment order meet avatars The overall goal avatar accepted community reach certain degree popularity The community metaphor involves ﬂatsharing students live area Vienna named Spit telberg community derSpittelberg Socialite scenes strongly inﬂuenced evolving 2 The screenshot taken demonstrator international audience text animation window English translation German spoken dialogue In online version German text displayed 1222 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Fig 2 eShowroom selection value dimensions Fig 3 eShowroom typical scene Fig 4 Screenshot Socialite K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1223 social relations user involved When user logged represented avatar ongoing electronic life community The avataragent reports time user logs Animated di alogues simulate encounters users avatar avatars Fig 4 To diminish likelihood problems stemming limited speech quality text dialogue displayed animation The frame lefthand screen depicts calendar functionalities including overview previous encoun ters Dialogues eShowroom based straightforward model world cars customers focus conveying information correct relevant customer Socialite contrast accommodate colloquial conversational style emphasising personality social background speaker It important challenge project tackle kinds dialogues essentially approach Scripted Dialogue The fact eShowroom English Socialite German different languages added complication Evaluation Several speciﬁc aspects NECA approach evaluated later sections meth ods suitable technology discussion Even systemlevel evaluation focus paper worth summarising main ﬁndings pair ﬁeld studies demonstrators 33 Beta versions available general public months accompanied minimum advertisement In case Socialite led 1488 logins 66 different users showing encouraging return behaviour Approximately half 66 participants visited avatars 5 times 20 50 times In eShowroom user registration animated presentation self contained logged 241 presentations played evaluation period Each user systems asked complete questionnaire assessing impression animated dialogues In crucial questions subjects asked express agreement disagreement ﬁvepoint scale As usual questionnaires associated ﬁeld studies fraction participants com pleted questionnaires resulting 17 completed questionnaires Socialite 11 eShowroom In cases clear majority subjects classiﬁed having considerable expertise information technology As 64 eShowroom users 88 Socialite users characterised animated char acters regular basis The results indicate demonstrators seen enjoyable In Socialite example 47 subjects application enjoyable ticking 4 5 agreement scale follow ing statement I dialogue enjoyable 24 gave negative opinion 1 2 scale 29 neutral midpoint 3 scale Participants questionnaire judged body movements fa cial expressions match spoken words Socialite 48 positive 40 neutral 12 negative quality speech rated lower Socialite 82 negative 12 neutral 5 positive Section 6 discussion In eShowroom issue particular importance characters dialogue judged matching parameters user set cf Figs 1 2 A puzzling ﬁnding female participants critical aspects demonstrators Similar ﬁnd ings reported 21 All ﬁgures need taken grain salt given paucity respondents absolute terms percentage users familiarity animated characters unusual 3 Architecture representation language scripted multimodal dialogue Each different modalities text speech body language employed dialogue involve ex pressive choices example concerning words gestures intonation patterns All choices properly synchronised For example particular concept new important pitch ac cent appear words convey concept additionally mouth eyebrows right moment In order meet challenges NECA uses specially designed architecture representa tion language processing model These key aspects NECA approach introduced chap ter We start focusing architecture processing model discussing representation lan guage 1224 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Fig 5 Architecture realising scripted multimodal dialogue component 31 An architecture generating multimodal dialogue Fig 5 offers overview NECA architecture The Scene Generator uses Affective Reasoner called Emotion Engine produce Scene Description takes role playwright planning dialogue generating script In Scene Description dialogue presentation acts speciﬁed rough temporal coordination The dialogue generated left right turn time conventional interactive The Scene Description speciﬁes semantic content type temporal order associated emotion communicative acts characters perform All information encoded XML document incrementally reﬁned course processing Since Scene Generator constructs outlines dialogues module speciﬁc Scripted Dialogue All later modules use techniques equally produce dialogues autonomous agents agents behaviour speciﬁed right format The Scene Description handed Multimodal Natural Language Generator Section 5 transforms formal speciﬁcation communicative acts text This component partially responsible selection gestures The Multimodal Output XMLbased script specifying set sentences gestures temporal ordering The task Speech Synthesis Section 6 convey adequate speech intended meaning text emotion uttered3 It provides information exact timing utterances syllables phonemes indispensable Gesture Assignment Module Section 7 The module responsible exact timing gestures relative speech Its output script animation directives control sequence comprising synchronised verbal nonverbal behaviour characters scene In step control sequence converted data stream processed animation player While scene generation dialogue planning textual surface realisation largely application speciﬁc important parts mechanisms reused later components entirely domain independent The key feature NECA processing model incrementality module Rendering module adds information script throwing information away This allows module use information added previous stage compromising pipeline See Conclusion section Architecture Processing Model The following section explains incremental process works 3 This module called TextConcepttoSpeech synthesis input text abstract conceptual structures K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1225 32 The rich representation language RRL The modules Fig 5 presuppose representation language expressive represent formation modules produce PlayerSpeciﬁc Rendering end pipeline information consume Scene Generator start A variety structures usually XML com pliant designed allow speciﬁcation multimodal information unable ﬁnd expressive represent Discourse Representation Theorybased 40 semantic information words speech body language To NECAs representation language context compare brieﬂy languages associated ECAs Markup languages typically deﬁne sets markups allow nonexpert user web designer annotate text highlevel expert information See instance VoiceXML httpwwwvoicexmlorg creating voice enabled web applications VHML httpwwwvhmlorg Virtual Human Markup Language creating interactive multimodal applications Talking Heads bodied ECAs Other examples markup languages text annotated highlevel concepts APML 22 MPML 78 Languages kind built represent detailed syntactic semantic pragmatic information Representation languages sense unlike markup languages systeminternal HumanComputer Interfacing function Existing languages kind limited function interface components 15444686 Our representation language general extending combining different aspects existing representation languages designed called Rich Representation Language RRL RRL 63 combines information levels semantic level content utterance speciﬁed equally textual string words utterance information speech body language4 NECAs RRL5 specifying multimodal dialogue stages generation added dialogue script At end pipeline RRL script contains sufﬁcient information mapped chain lowlevel animation directives We start describing structure abstract script dialogue Scene Description contains 1 representation initial common ground 2 repre sentation participants dialogue 3 representation dialogue acts 4 temporal ordering dialogue acts This information available Affective Scene Generation In following explain elements RRL script A speciﬁcation RRL XML Schema wwwofaiatresearchnluNECARRLindexhtml 1 Common Ground The initial common ground captures information shared interlocutors start conversation It identiﬁes referents speciﬁes properties terms nary predicates The information common ground MNLG module generation referring expressions All semantic information dialogue formalised making use Discourse Representation Theory 33 2 Participants Each dialogue participant provided person data gender appearance graphics design voice pitch range Each character equipped information sonality role scenario In eShowroom scenario instance roles interlocutors seller buyer 3 Dialogue Acts A dialogue represented means individual acts verbal nonverbal Each di alogue act represented xml element number subelements including characterisation acts communicative function encoded domainSpeciﬁcAttr cf Fig 7 semantic content Discourse Rep resentation Structure 33 prevalent emotion expressed cf Fig 7 emotionExpressed computed Affective Reasoner 4 Temporal Ordering Dialogue Acts The temporal ordering individual acts dialogue speciﬁed temporalOrdering element Usually verbal dialogue acts follow sequence speaker contributions Nonverbal acts backchannelling typically occur parallel dialogue acts speaker Ac 4 Languages XSTEP 37 ABL 55 incorporate declarative procedural knowledge They function programming languages behaviour generation behaviour markup representation 5 A speciﬁcation RRL XML Schema wwwofaiatresearchnluNECARRLindexhtml 1226 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 cordingly temporalOrdering subelements seq par dialogue acts sub elements To generate text interleaved gestural information Multimodal Natural Language Generation Section 5 pro cesses communicative function emotion semantic content adding sentence gesture elements dialogue act See example In eShowroom gesture small animated clip 3D Charamel imation combines handarm gesture posture facial expression In Socialite facial expression handarm gesture encoded separate gesture elements 2D Flash animations The information encoded sentence sent Speech Synthesis Synthesis produces sound ﬁle RRL script sentence encodes address sound ﬁle SAMPAencoded wwwphonuclacukhome sampahomehtm phonetic transcription text including syllable structure TOBIencoded accentuation prosodic boundaries 6 See example The output Gesture Assignment Module RRL speciﬁcation animation stream subset SMIL Synchronised Multimedia Integration Language httpwwww3orgTRsmil20 All linguistic information dialogueAct replaced audio element holds duration speech sound ﬁle The alignment gestures languagerelated entities sentences words syllables precise The result K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1227 encoded animationSpec input style sheets transform RRL representation playerspeciﬁc 4 Affective scene generation We aim produce large variety believable dialogues Each dialogue match personality participants speciﬁed user Fig 1 Moreover dialogues match interests user reﬂected choice value dimensions Fig 2 characters display types emotions ﬁt situation The module produces skeletal dialogues factors account What follows description planbased approach affective scene generation employed NECAs eS howroom scenario6 The approach extension previous work generation dialogue scenes animated presentation teams 2 integrating models personality emotions lifelike characters 3 In NECA combine dialogue act generation car sales domain mechanisms emotion elicitation computation The result sequence dialogue acts specify semantic content utterance affective state speaker 41 Domain modelling Domain modelling essential prerequisite automatic dialogue generation In eShowroom scenario domain model consists parts The ﬁrst factual description different cars comprises kind information typically ﬁnds car sales brochure In model car characterised following attributes price horsepower maximum speed fuel consumption spaciousness interior spaciousness luggage compartment proportion recyclable materials manufacturing availability optional features antilock brakes airbags broad tires power windows leather seats catalytic converter This information stored knowledge base accessed dialogue planner inform selection dialogue strategies specify propositional content individual dialogue acts explained section The second domain model relates attributes set value dimensions users select express preferences operational costs safety sportiness comfort prestige family environmental friendli 6 In Socialite emotions computed runtime essentially hardwired templates MNLG module cf Section 5 1228 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 ness Fig 2 The dimensions adopted study German car market particularly relevant people purchasing car The domain model characterises attribute ways First relevant certain value dimension low medium high For example fuel consumption attributes relevance value dimension operational costs high Second valence attributes value determined evaluation function positive negative For example consumption 10 litters 100 kilometres rated negative operational costs dimension The value 230 HP rated positive dimension sportiness negative safety 42 Dialogue act generation The domain model determines large extent virtual characters talk nearly questions answers car sales dialogues refer cars attributes However factual description information presented This knowledge contained dialogue model speciﬁes global local structure conversation terms dialogue strategies Our sales dialogues start greeting phase followed customers request information speciﬁc car Subsequently questionanswer game customer sales person develops features cars discussed Finally customer communicates purchase decision closing phase dialogue ends In eShowroom scenario dialogue planner generates initial version Scripted Dialogue sequence dialogue acts A dialogue act represents abstract communicative function requesting information requestIf answering question afﬁrmative giving feedback agreeing Such communicative functions realised different ways depending example personality actor Dialogue acts usually follow typical order For example question availability feature followed positive negative answer discussed dialogue participants In dialogue model combinations dialogue acts frequently observed genre hand represented dialogue strategies Following planbased approach dialogue strategies encoded plans selected executed dialogue planner Fig 6 example plan dialogue strategy QuestionAnswerBoolean introduced previous example The customer requests information Boolean attribute attribute car airbags The dialogue planner retrieves information domain model depending attributes value sales person conﬁrm disconﬁrm availability Finally new dialogue strategy triggered actors discuss new piece information Plans referenced Their applicability given dialogue context deﬁned goal expres sion precondition Both sections contain instantiated uninstantiated variables example denoted strings preceded dollar sign Uninstantiated variables bindings plans selected instantiated The precondition speciﬁes initial conditions fulﬁlled plan scheduled execution As shown Fig 6 typically requires facts established retrieving dialogue plan ners knowledge base Goal expressions matched set goals currently pursued dialogue planner To increase variation dialogues multiple plans goal expression optionally different pre conditions speciﬁed To inform selection dialogue strategies utility plans reﬂecting goodness ﬁt particular situation speciﬁed integer value The dialogue planner constantly checks plans applicable matching goal expressions speciﬁed plans current set goals Plans match preconditions fulﬁlled added set applicable plans The dialogue planner chooses plan highest utility value If choice ambiguous applicable plans utility value randomly chosen executed By providing multiple plans utility given situation nondeterminism introduced dialogue act generation process different dialogue act sequences generated time dialogue planner invoked During plan execution actions body section plan executed The plan body procedural speciﬁcation deﬁnes plans goal achieved typically spawning subgoals trigger new dialogue strategies In way plan tree incrementally built dialogue planner nodes represent dialogue strategies leaves represent individual dialogue acts performed interlocutors Plans interrupted suspended time new plan higher utility applicable This mechanism example adapt dialogue generation process affective state virtual characters explained section K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1229 Fig 6 Plan dialogue strategy requesting information Fig 7 RRL representation dialogue act structure A single dialogue contribution encapsulated DialogueMove plan The plan creates abstract dialogue act structure containing information speaker speakers dominant emotion dialogue act type propositional content needed temporal alignment previously generated dialogue acts Fig 7 shows RRL representation dialogue act structure As described Section 2 users assign roles personalities actors select value dimensions These parameters precondition plans inﬂuence course style ensuing conversation constraining selection available dialogue strategies For example depending mood actors display different degrees criticism enthusiasm discussing cars properties 43 Affect computation Affect computation eShowroom scenario performed Affective ReasonerEmotion Engine based cognitive model emotions developed Ortony Clore Collins 61 The OCC model deﬁnes emotions positive negative reactions events actions objects Events evaluated terms desirability actions terms praiseworthiness objects terms appeal The subjective appraisal current situation based agents goals standards attitudes The result appraisal process set Emotion Eliciting Conditions EECs example degree event desirable likelihood future event The Emotion Engine maps EECs emotion categories intensity An event undesirable disliked agent example triggers emotion category gloating event elicited pity person liked The intensity generated emotions depends EEC variables degree blameworthiness personality traits speciﬁed agent A decay function models fact emotions diminish time 29 Although criticised limitations 1230 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Fig 8 Plan dialogue strategy break discussion psychological theory OCC model time established reference model emotion synthesis cognitively modelled embodied agents For generating affective dialogues combine dialogue generation process described previous section mechanism emotion elicitation computation This concept Current Discourse State CDS set appraisal rules The CDS includes previouslygenerated sequence dialogue acts object focus particular car current goals standards attitudes agents When new dialogue act generated appraisal rules applied CDS For example suppose sales person answer customers question This appraised sales person undesirable event endangers hisher goal come competent The degree undesirable depends relevant information value dimensions representing customers The generated EEC undesirable mapped emotion category distress certain intensity The customer appraise action blameworthy believes sales person hiding unfavourable information This time EEC somewhat blameworthy mapped emotion category reproach The inferred emotions updating characters affective state In end emotion highest intensity assigned dialogue act representation When dialogue planner determines dialogue takes new affective states account evaluating preconditions dialogue strategies selecting best matches affective states characters For instance sales person repeatedly says I dont know customer frustrated If intensity elicited distress emotion exceeds certain threshold questionanswer game interrupted closing phase initiated The plan dialogue strategy shown Fig 8 higher utility value currently executing plan goal PERFORM Discuss car interrupted suspended dialogue planner In order avoid interruption middle dialogue act generation process result corrupted dialogue act structure additional check included end precondition sure dialogue act ﬁnished The ﬁrst action body BreakOffDiscussion plan removes suspended goal set goals pursued dialogue planner actions subsequent dialogue moves customer salesperson performed Emotions affect sequence dialogue acts generated dialogue planner way processed subsequent modules In particular speakers dominant emotion additional parameter text generation gesture alignment speech synthesis For emotions generated Emotion Engine mapped model emotion thought better suited speech Section 62 The Emotion Engine affect computation eShowroom scenario forms basis Gebhards A Layered Model Affect ALMA 30 This model integrates emotions moods personality covering short medium longterm affect respectively The plausibility generated emotions moods demonstrated empirical evaluation involving textual dialogues characters Subjects asked assess plausibility computergenerated emotions moods character based dialogues The results K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1231 indicated ALMA provides authentic believable emotions moods 31 Since NECA uses basically functions ALMA computing emotion types intensities results interpreted support principles NECAs Emotion Engine 5 Multimodal natural language generation The aim Multimodal Natural Language MNLG module express Scene Description Fig 5 natural language gestures appropriate situation This implies particular emotion personality speaker factual information dialogue act taken account Here sketch design philosophy MLNG module For details 64 67 Since MNLG module differs existing NLG systems task architecture worth examining MNLG sits Scene Generator TextConcept Speech Synthesis The Scene Generator provides MNLG speciﬁcation content semantic pragmatic emotional structure dialogue The MNLG maps speciﬁcation representation verbal nonverbal behaviours stitute fullyﬂedged dialogue The result multimodal output representation describes combination words grammatical constructions gestures dialogue Phonetic prosodic realisation detailed timing left subsequent modules The output MNLG intended human consumption instead consists machinereadable description dialogue team animated agents expected act Before delving details MNLG let brieﬂy highlight respects differs natural language generators The generator described 60 resembles MNLGs approach semantics Both generators operate unordered sets statements highly structured inputs required offtheshelf surface realisers fufsurge 27 The generator 60 unimodal unable cope pragmatic constraints example personality emotions speaker The MNLGs functionality resembles microplanner NLG 71 Most microplanners designed sentence generation multimodal dialogue act generation 1156 Some like SPUD generator 79 adapted multimodal generation 15 But like systems speciﬁcally signed ECAs 415370 SPUD uses algorithm based integrated planning advocate highly modular Fig 9 order support fast generation Integrated approaches motivated psycholinguistic plausibility 42 We psycholinguistic claims approach advocated like point widely cited psycholinguistic models speaking modular essentially pipelined 52 51 Requirements MNLG NECAs MNLG module built following requirements mind 1 Integration heterogeneous generation resources One main determinants dialogue act semantic content The semantic content Scene Generator provide dialogue act depends content underlying database For dialogue acts greetings Hello Ritchie impos sible generate ﬁrst principles starting semantic content MNLG needs capability combine generation templates created human writers 2 Integration different factors emotion personality The realisation dialogue script depends semantic content To obtain believable presentations factors personality speaker gender emotional state play role Therefore require MNLG variety factors account choosing given message words 3 Variation expression People different things different occasions circumstances aforementioned factors identical This means MNLG needs capable non deterministic generation 4 Performance Long delays decrease appreciation endusers For reason MNLG able produce output instantaneously 1232 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Fig 9 Schematic representation MNLG architecture 5 Reuse The MNLG intended application independent It easy port new applications saving developers applications time effort The section explain requirements met 52 Outline MNLG module Like overall NECA MNLG module pipelined architecture Fig 9 The module dialogue ActGen generates individual dialogue acts It turn calls referringExpressionGen referring expressions need incorporated realisation dialogue act K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1233 Requirement 3 variation output addressed having number nondeterministic steps generation process deep structure generation dialogue acts referring expressions contain consist overgeneration followed random selection Gesture selection operates random selection gesture set appropriate alternatives In order facilitate maintenance reuse MNLG divided Sicstus Prolog modules Requirement 5 Applicationspeciﬁc data separated generic generation algorithms development new applications requires modiﬁcation data ﬁles The highly modular setup combination pipeline architecture contributes high performance terms generation times section evaluation Requirement 4 One main tasks MNLG generation deep structures dialogue acts pairings content verbal nonverbal realisations satisfy given set syntactic semantic pragmatic constraints These constraints constitute input MNLG dictated Scene Generator Formally collection input constraints represented typed feature structure The typing structures facilitates reuse maintenance explicit representation data structures kept separately The structures manipulated Prologs fast builtin uniﬁcation algorithm Proﬁt library 28 The linguistic resources represented trees nodes typed feature structures Together trees MNLGs tree repository Generation consists matching input feature structure root nodes trees repository Matching trees incomplete daughter nodes daughters fully realised These recur sively expanded matched trees repository daughters complete Daughter nodes semantics rise referring expressions dealt referringExpressionsGen module Fig 9 67 The formalism trees repository able represent linguistic resources wide variety including lexical entries spans canned text templates fullﬂedged grammar rules For given input resources allow construction multiple deep structure trees selected random Emotion personality stored attribute currentAct inﬂuence selection words phrases gestures sets alternatives express semantic content Requirement 2 Fig 10 shows example tree representing template The usual angledbrackets notation feature structures types italics attributes small capitals Sharing values represented coindexing When template called value Speaker uniﬁed speaker current dialogue act ends realisation template Note template provides syntactic structure sentence generated blurring distinction real templatebased generation line current thinking Natural Language Generation 83 Note meaning sentence computed composition Fig 10 Template I NP 1234 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 Fig 11 Socialite templates Mir gehts I feel beschissen fucked ally meaning parts Grammar rules compositional semantics useful input generator consists complex semantic representations ﬁrst place For example eShowroom holds description cars underlying database allows derive complex semantic input representations The example Fig 11 derives Socialite application guess colourful use language It provides example linguistically fully speciﬁed template adjp This template combines indicated dotted line sentence template semantics radically underspeciﬁed value linguistically underspeciﬁed constituent node labelled fragment 53 Evaluation MNLG module The MNLG goes long way meeting requirements introduced earlier section We seen requirements 1 4 addressed speciﬁc design decisions Requirement 5 involving performance evaluated running tests measure average generation times range examples 64 These tests provided satisfactory results generation taking 1100 4100 second dialogue act based tree repository consisting 138 generation trees Pentium III 1200 MHz processor Require ment 6 reuse MNLG evaluated porting MNLG reused Socialite demonstrator outside NECA project epoch iGuide Virtual Tour Guide 26 Most Socialite generation templates Fig 11 originally written professional script writers format different MNLG The tree formalism proved ﬂexible accommodate pre existing templates Perl scripts written automatically transforming MNLG trees resulting tree base 1170 trees The experience implementing epoch iGuide Virtual Tour Guide systems generation component MNLG similarly encouraging We investigated effect different MNLG settings focusing NECAs eShowroom demonstrator comparing dialogues gestures 65 Neither subjective user experience measured questionnaire scores retention test differed signiﬁcantly conditions subjects N 28 However users withgestures condition complained signiﬁcantly quality speech gestures detracted onscreen speech bubbles accompanied speech Furthermore evaluate exten sion eShowroom backchannelling gestures hearer compared dialogues hearers gestures keeping speakers gestures constant subjects N 12 9 67 We subjects withhearer gestures condition signiﬁcantly worse retention test possibly hearer gestures intrusive This consistent 87 presence highly expressive talking head ar gued diminish task performance cases distract attention A possible alternative explanation ﬁndings rendering feedback gestures good For purpose particular study Microsoft Agents technology render simultaneous gestures multiple agents adequately gestures bit abrupt example K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1235 Finally study N 40 67 small effect result varying algorithm gener ation referring expressions A egocentric algorithm agent ignoring contributions interlocutor caused agent appear friendly 6 Speech The generation speech performed texttospeech TTS MARY 77 While existing TTS technology sufﬁcient quality intelligible room improvement particularly personality emotion taken account NECA makes contributions longterm goal linguistically appropriate prosody dialogue emotional expressivity 61 Prosody reﬂecting information structure The term prosody covers suprasegmental aspects speech utterance pitch duration loudness Prosody convey information affective state speaker linguistic structure utterance example accenting new important words inserting pauses Despite work ex ample 355769 36 existing TTS technology usually effects account Systems based NLG placed better This particularly true NECA incremental processing model Section 3 guarantees semantic syntactic pragmatic information available Speech Synthesis module This makes easy example look given object represents given new information having parse interpret text Information structure realised interplay linguistic means strategies These means syntactic word order speciﬁc constructions like clefts passives parallelism morphosyntactic spe ciﬁc particles prosodic deaccentuation intonational phrasing nature employed different languages different degrees 85 In English intonation predominant linguistic marker information structure holds German word order plays important role NECAs treatment prosody based heavily RRL incremental processing model empiri cally informed extensive perception tests Here summarise main results German 578 Broadly speaking results conﬁrmed familiar idea new information carry accent textually given information deaccented 84 We type accent taken ac count necessary distinguish ﬁnely usually taking type information account called accessible 1850 Such information totally new totally given inferable situational textual context For textually inferable referents nature semantic rela tion antecedent determines item accented type accent carry For example synonyms elevatorlift anaphors partwhole relations pagebook tend behave similarly given information usually deaccented anaphor wholepart relation reverse order inclusion relation bookpage similar new information accented The type accent subordinate expression different accent marking new information It shown early peak accent transcribed HL terms oftenused GToBI categorisation 32 appropriate marking type accessibility medial peak accent symbolised H best marking new information Semanticpragmatic properties referring expression including degree type givenness provided NLG component This information assign tags given accessible applicable respective items RRL script Furthermore contrastive usage referring expression explicitly ﬂagged These markers referring expressions information status communicated MARY prosody module affect accent placement form Tokens marked given ignored accent assignment deaccented tokens marked accessible assigned HL accent contrast kens receive rising accent LH particularly high pitch range The default nuclear accent type assigned new adjectives nouns H These rules enable generate contextually appropriate intonation patterns 1236 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 62 Emotionally expressive speech We argued crucial dialogues produced Scripted Dialogue expressive terms emotional state speaker Two types generating emotionally expressive speech distinguished playback model approaches The ﬁrst approach 1038 treats emotions holistically creating speech synthesis voices recordings spoken certain expressive styles angry voice friendly voice While approach likely lead highly natural emotion expression suffers lack ﬂexibility Only emotional states recorded played Clearly NECAs goal creating dialogues highly varied makes ﬂexibility key issue alternative record store prohibitively large amounts speech The second approach 58 models emotions terms acoustic synthesis parameters corresponding emotions This approach requires high degree control acoustic parameters Rulebased formant syn thesis enables modelling wide array acoustic parameters technology choice number emotional speech synthesis undertakings lack naturalness nearly disap peared landscape commercial speech synthesis systems Promising new approaches datadriven formant synthesis 13 early development phase Unit selection yields highest degree naturalness speech speaking style usually neutral provide ﬁnegrained control prosodic pa rameters Indeed unit selection synthesis draws naturalness interfering recorded speech signal rarely allows explicit modelling prosody This limitation currently makes unit selection synthesis unsuitable modelbased approaches emotional speech synthesis A compromise degree ﬂexibilitycontrol naturalsounding synthesis diphone synthesis allows ﬁnegrained prosody modelling limited degree distortion It based concatenation small recordings human speech socalled diphones ranging middle phone segment middle following phone segment followed signal processing step generate desired prosody Unfortunately voice quality inherent diphones appears inappropriate certain emotions 58 The current work pursues modelbased approach synthesis based explicit model vocal correlates emotions realised diphone synthesis enhanced limited control voice quality 78 We start decision represent emotional states 19 Consistent state art speech research chosen use emotion dimensions 2074 continuous framework representation essential properties emotional states The emotion dimensions emerged important large number studies evaluation called valence pleasure activation called arousal These complemented dimension called power dominance The main task building model ﬁnd mapping point emotion dimension space corresponding acoustic correlates We constructed mapping based database analysis literature sur vey 7578 We Belfast Naturalistic Emotion Database contains recordings 124 English speakers exhibiting relatively spontaneous emotion 24 This database largest collections natural emotional speech available labelled according emotion dimensions The emotion dimension coordinates clip database correlated number acoustic measures semiautomatically extracted database Robust correlations especially activation dimension alsoif lesser extentfor evaluation power dimensions These correlations accompanied quantiﬁed linear prediction coefﬁ cients allowing relatively simple deduction rules synthesis As second source information literature survey conducted The assorted evidence dozen publications brought studied English speech 66 details While articles gave qualitative trends correlations emotion dimensions acoustic parameters provided solid baseline expected conveyed acoustic voice parameters Essentially strong trends activation dimension All evidence consolidated model predicts prosodic voice quality changes point emotion dimension space The evidence conﬁrmed emotion dimension best conveyed speech activation arousal degree excitation vs passivity According model increased activation conveyed voice prosodic effects increased pitch speaking rate voice quality particularly increased vocal effort caused higher muscle tension The importance voice quality modelling expressing emotions synthetic speech matter bate 78 In essence frequent presence voice quality effects human expressions emotion desirable K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1237 Fig 12 Effort ratings male diphone voice Ger man listeners 76 Fig 13 Effort ratings female diphone voice interpolated versions German French Turkish listeners 82 model voice quality synthetic speech Since instruments modelling voice quality diphone synthesis spite promising developments 4380 recorded separate diphone databases lev els vocal effort male female speaker Both voices publicly available noncommercial use httptctsfpmsacbesynthesismbrolahtml MBROLA 25 diphone databases de6 male de7 female We tested perceptual adequacy male voice perception tests 76 A ﬁrst test carried test hypothesis diphone sets sufﬁciently similar recognised belonging person We prepared pairs sentences ﬁrst second sentence synthesised voice different different pitch levels Subjects asked stimuli pair produced speaker Results showed effect vocal effort perceived speaker identity relatively small 799 sentences differing vocal effort perceived speaker However strong effect pitch level A modiﬁcation pitch slightly range typically nonemotional synthesis moderate view emotional speech caused speaker identity ratings drop chance level Next tested hypothesis effort intended recording perceived synthesised material Stimuli differing intended vocal effort overall pitch level played subjects rated stimuli continuous scale effort great effort Since stimuli amplitudenormalised subjects instructed base ratings sound voice loudness Results conﬁrmed effort perceived intended Fig 12 While able select levels vocal effort step forward clearly limited control A step ﬂexibility afforded use voice interpolation From original recordings female voice databases created new databases intermediate levels vocal effort simple spectral interpolation algorithm 82 A listening test performed evaluate intended vocal effort original female databases interpolated ones The results interpolation algorithm create intended intermediate levels vocal effort given original databases This effect largely independent language background subjects Fig 13 7 Generating dialogueaccompanying gestures We arrived step facial expressions handarm gestures postures chosen aligned speech Since able build established techniques procedures area description NECA approach comparatively brief Dialogueaccompanying gestures facial expression handarm gestures body postures typically generated phases planning phase realisation phase 46 proposal SAIBA framework We discuss phases turn 1238 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 71 Multimodal behaviour planning During Multimodal Natural Language Generation MNLG gestures planned basis semantic pragmatic content utterances aligned respective nodes MNLG tree See example dialogueAct Section 32 The actual point time start gesture unknown stage processing When Gesture Assignment module starts information body behaviour underspeciﬁed This ﬁrstly information relative alignment verbal nonverbal behaviour available ALIGNTO ALIGNTYPE features example dialogueAct MNLG Section 32 secondly choice gestures restricted features IDENTIFIER MODALITY example gestures involving body hips suitable The idea intertwining gestural syntactic structure proposed 16 They mecha nism applying SPUD natural language generator 79 Lexicalized Tree Adjoining Grammar LTAG formalism 3973 multimodal generation Integration gestures syntax particularly suitable gestures express semantic content present alternative linguistic expression content The MNLG allows second type gesture generation tightly integrated syntax This second type gesture generation concerns gestures expressing discourse function question assertion Such gestures grammar added separate gesture generation module associates gestures body postures particular types dialogue acts 72 Temporal ﬁnetuning behaviours At later planning stage Gesture Assignment relative alignment utterances gestures resulting behaviour planning stage MNLG transformed absolute alignment according time constraints imposed speech synthesis This approach typical ECA systems 44 More generally accessibility prosodic temporal information produced speech synthesis crucial ﬁnegrained alignment verbal nonverbal communication systems In NECA speech synthesis component provides sound ﬁle utterance RRL ﬁle contain ing phonetic transcription utterance7 See Section 32 Speciﬁcation sentence Speech Synthe sis This information constraints coming MNLG metalevel description available gestures Gesticon subsection Gesture Assignment module producing playerindependent multimodal animation directives The animation directives encoded animationSpec element RRL transformed playerspeciﬁc formats For example animationSpec Section 32 73 Gesture representationThe gesticon Information gestures stored RRLcompliant repository behaviour descriptions Gesticon Analogous Lexicon natural language Gesticon central behaviour repository relating form meaning function connecting abstract information concrete playerspeciﬁc animations When deﬁning Gesticon NECA applications eShowroom Socialite started descriptions comprising minimal information meaning function gesture deictic greeting facial expression happy sad disgusted highlevel description form features body parts involved relative duration gestures gesture phases 49 Duration information speciﬁes extent gesture elongated shrunk changing meaning For handarm gestures relative wrist position beginning end gesture stored 47 This information estimate time required end gesture beginning following gesture The need representations body behaviours independent animation player technology arisen wish develop planning components independent individual animation player technologies 7 For overview TOBI httpwwwlingohiostateedutobi K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1239 The Gesticon functions central behaviour repository relating form meaning function connecting abstract information concrete playerspeciﬁc animations The eShowroom animation library consists 160 animation videos Charamels CharActor format deﬁne small sequences overall body behaviour including handarm gestures male female character The behaviours built basic graphical building blocks face shapes eye mouth shapes hand shapes upper arms lower arms For facial display emotions anger fear animation directives formulated terms degree eyebrow lip corner raise lip stretch In Socialite character animation restricted facial animation handarm gestures Its animation library collection Flashencoded handarm gestures 53 base gestures snapshots facial expressions 19 male female character Facial expressions Socialite based Ekmans basic emotions happiness sadness anger fear disgust surprise plus faginstyle additional labels like false laugh reproach The approach animation pursued NECA comparable majority current work ECAs haviours realised selecting set prefabricated animations instance REA 15 NICE project 5 FearNot 30 These differ approaches behaviours generated instance 62 generating facial expressions speech Tepper et al 2004 generating directiongiving gestures seman tic representations 45 driving virtual character means form descriptions derived motion capture 8 Conclusion The NECA approach Fully generated Scripted Dialogue FGSD embodied eShowroom Socialite demonstrators developed NECA project build predecessors described 14 represents 1240 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 signiﬁcant step forward construction systems involving ECAs able engage large variety highly expressive dialogues In summarising highlights useful distinguish issues 1 overall paradigm Scripted Dialogue 2 architecture NECA produce scripted dialogue 3 individual components NECA 1 The paradigm scripted dialogue ECAs widely thought potentially beneﬁcial effect motivation task performance user application Lester et al example presence lifelike character interactive learning environmenteven expressivecan strong positive effect students perception learning experience calling Persona Effect 51 23 We argued Fully Generated Scripted Dialogue FGSD promising framework purpose potential beneﬁts We believe wealth applications ranging edutainment VirtualConstructor 59 advertising edrama witness Carmens Bright IDEAS 47 FearNot 434 Façade 55 useful generate dialogue Similarly FGSD increase variety dialogues produced story generation systems 12 particularly multimodal 17 55 Computergenerated animations mainstream cinematography witnessed ﬁlms Finding Nemo Monsters Inc Polar Express automated creation ﬁlm content speciﬁcally dialogue content lags possibilities currently explored graphics We hope FGSD paradigm advocated paper contribute closing gap The fact NECAs dialogues fully generated makes possible generate huge variety dialogues wording speech body language accordance interests personalities affective states agents The degree control enhanced revision strategy applied takes output Scene Generator ﬁrst approximation optimised later operations 6668 Consider eShowroom scenario instance If yesno questions car similar structure eliciting response questionanswer pairs merged aggregated questionanswer pair Does car power windows leather seats Sure 2 Architecture processing model Scripted dialogues generated different ways A distinctive feature NECA fact based processing model starts scene generated Scene Generator incrementally decorated information linguistic phonetic graphical nature The backbone incrementallyenhanced representation NECAs Rich Representation Language RRL based XML Perhaps best defence incremental processing model lies experimental multidisciplinary nature work ECAs Partly young research area difﬁcult predict aspects given level representation needed later modules This difﬁculty exacerbated fact researchersprogrammers limited understanding goes later modules By keeping generation process incremental monotonically increasing guarantee information produced given module available later modules Consider example information status referents domain It obvious working MNLG novelty givenness roughly absence presence Common Ground object importance later modules importance example information Speech Synthesis deciding particular kind pitch accent Noun Phrase referring object Section 61 Our incremental processing model ensures information fact available Undeniably processing model lead XML structures large As remedy implemented streaming model Scene Generation individual communication acts processed parallel As soon player generator ﬁnished processing act result streamed user immediately subsequent acts processed This leads drastic reduction response times ensures realtime behaviour 3 Individual components When different scientiﬁc disciplines join forces construct ECAbased sys tem interesting compare respective contributions Comparisons modalities example asking basic concepts information structure focus expressed different modali ties text speech body language Another interesting question emotions modelled differently Affective Reasoning uses OCC model 61 Speech Schlosbergs emotion dimensions thought appropriate facial expressions Ekmans basic emotions hold sway For reasons space shall focus comparison particularly important given NECAs emphasis generic K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1241 technologies hold promise longer term tradeoff quality ﬂexibility featured strongly discussions Natural Language Generation Speech Synthesis The issues quality ﬂexibility likened problem construction real estate Suppose architect wants restore old stone building grand style Ideally want harvest natural stone colours shapes restoration work requires But difﬁcult ﬁnd exactly right piece case natural piece exactly right piece artiﬁcial reconstituted stone custom The tradeoffs facing language generation speech synthesis gesture assignment similar In case Nat ural Language Generation NECA combination canned text cf natural stone fully compositional generation cf artiﬁcial stone case speech synthesis NECA combination diphone synthesis comparable grinding natural stone pulp moulded desired shape limited control voice quality In order create suitable animations NECA employed libraries playerspeciﬁc prefabricated animations cf giving architects choice different rooms facades metainformation concerning dimensions scalability approach graphics comparable parameterised unit selection Speech Synthesis highly ﬂexible kind templatebased Natural Language Generation advocated 83 Closing remarks The word dialogue taken imply interaction agent person In paper examined alternative perspective dialogue way let Embodied Conversational Agents present information cars eShowroom tell story students Socialite NECAs version Scripted Dialogue happens allow sophisticated interactions user The interface Fig 1 Section 2 example allows user choose different personalities 256 different combinations value dimensions simple menu We believe ample space similarly direct applications fullygenerated scripted dialogue FGSD technology example place noninteractive radio ﬁlm television Perhaps importantly substantial future role hybrid systems combine FGSD extended facilities letting user inﬂuence behaviour exist interactive drama example 43454558 References 1 E André T Rist Presenting performing On use lifelike characters knowledgebased presentation systems Proceedings IUI 2000 International Conference Intelligent User Interfaces 2000 2 E André T Rist S van Mulken M Klesen S Baldes The automated design believable dialogues animated presentation teams J Cassell J Sullivan S Prevost E Churchill Eds Embodied Conversational Agents MIT Press Cambridge 2000 3 E André M Klesen P Gebhard S Allen T Rist Integrating models personality emotions lifelike characters A Paiva Ed Affective Interactions Towards New Generation Computer Interfaces Lecture Notes Computer Science vol 1814 Springer Berlin 2000 4 RS Aylett R Figuieredo S Louchart J Dias A Paiva Making alongimprovising stories pedagogical purposes J Gratch M Young R Aylett D Ballin P Olivier Eds 6th International Conference IVA 2006 LNAI vol 4133 Springer Berlin 2006 pp 307315 5 S Baumann M Grice The intonation accessibility Journal Pragmatics 38 10 2006 16361657 6 S Baumann M Grice S Steindamm Prosodic marking focus domainscategorical gradient Proceedings SpeechProsody 2006 Dresden Germany 2006 pp 301304 7 S Baumann M Grice Accenting accessible information Proceedings Speech Prosody 2004 Nara Japan 2004 pp 2124 8 S Baumann K Hadelich On perception intonationally marked givenness auditory visual priming Proceedings AAI Workshop Prosodic Interfaces Nantes France 2003 pp 2126 9 M Bergenstråhle Feedback gesture generation embodied conversational agents Technical Report ITRI0322 ITRI University Brighton UK 2003 10 M Bulut SS Narayanan AK Syrdal Expressive speech synthesis concatenative synthesiser Proceedings 7th International Conference Spoken Language Processing Denver Colorado USA 2002 11 S Busemann H Horacek A ﬂexible shallow approach text generation Proceedings 9th International Workshop Natural Language Generation Canada 1998 pp 238247 12 ChB Callaway JC Lester Narrative prose generation Artiﬁcial Intelligence 139 2 2002 213252 13 R Carlson T Sigvardson A Sjölander Datadriven formant synthesis Progress Report No 44 KTH Stockholm Sweden 2002 14 J Cassell J Sullivan S Prevost E Churchill Eds Embodied Conversational Agents MIT Press Cambridge MA 2000 8 Carmens Bright IDEAS FearNot apply interactive drama education IDEAS designed help mothers young cancer patients FearNot trains school children cope bullying Façade interactive game user inﬂuences outcome game 1242 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 15 J Cassell M Stone H Yan Coordination contextdependence generation embodied conversation Proceedings First Interna tional Natural Language Generation Conference INLG2000 Mitzpe Ramon Israel 2000 pp 1216 16 J Cassell H Vilhjálmsson T Bickmore BEAT The behavior expression animation toolkit Proceedings ACM SIGGRAPH 2001 Los Angeles USA 2001 pp 477486 17 M Cavazza M Charles Dialogue generation characterbased interactive storytelling Proceedings AIIDE 2005 18 W Chafe Discourse Consciousness Time University Chicago Press ChicagoLondon 1994 19 R Cowie RR Cornelius Describing emotional states expressed speech Speech Communication 40 12 2003 532 Special Issue Speech Emotion 20 R Cowie E DouglasCowie N Tsapatsoulis G Votsis S Kollias W Fellenz J Taylor Emotion recognition humancomputer interaction IEEE Signal Processing Magazine 18 1 2001 3280 21 A De Angeli N BianchiBerthouze Eds Proceedings AVI 2006 Workshop Gender Interaction Real Virtual Women Male World Venice Italy 2006 22 B De Carolis C Pelachaud I Poggi M Steedman APML markup language believable behavior generation H Prendinger Ed LifeLike Characters Tools Affective Functions Applications Springer Berlin 2004 23 DM Dehn S Van Mulken The impact animated interface agents A review empirical research Journal HumanComputer Stud ies 52 1 2000 122 24 E DouglasCowie N Campbell R Cowie P Roach Emotional speech Towards new generation databases Speech Communica tion 40 12 2003 3360 Special Issue Speech Emotion 25 T Dutoit V Pagel N Pierret F Bataille OV Vrecken The mbrola project Towards set high quality speech synthesisers free use noncommercial purposes Proceedings 4th International Conference Spoken Language Processing Philadelphia USA pp 13931396 26 KR Echavarria M Généreux D Arnold A Day J Glauert Multilingual virtual city guides Proceedings Graphicon Novosibirsk Russia 2005 27 M Elhadad FUFSURGE Homepage Available httpwwwcsbguacilsurge 19 September 2006 28 G Erbach Proﬁt 154 users guide University Saarland December 3 1995 29 P Gebhard M Kipp M Klesen T Rist Adding emotional dimension scripting character dialogues Proceedings 4th International Working Conference Intelligent Virtual Agents IVA03 30 P Gebhard ALMAa layered model affect Proceedings 4th International Joint Conference Autonomous Agents Multiagent Systems AAMAS05 Utrecht Netherlands 2005 pp 2936 31 P Gebhard KH Kipp Are computergenerated emotions moods plausible humans Proceedings 6th International Conference Intelligent Virtual Agents IVA06 Marina Del Rey USA 2006 32 M Grice S Baumann R Benzmüller German intonation autosegmentalmetrical phonology A Jun Ed Prosodic Typology The Phonology Intonation Phrasing Oxford University Press Oxford 2005 pp 5583 33 E Gstrein C Schmotzer B Krenn Report demonstrator evaluation results NECA IST report D9e July 2004 downloadable httpwwwofaiatresearchnluNECApublicationspublication_docsd9epdf 34 L Hall M Vala M Hall M Webster S Woods A Gordon R Aylett FearNots appearance Reﬂecting childrens expectations perspec tives J Gratch M Young R Aylett D Ballin P Olivier Eds Proceedings 6th International Conference IVA 2006 LNAI vol 4133 Springer Berlin 2006 pp 407419 35 J Hirschberg Pitch accent context Predicting intonational prominence text Artiﬁcial Intelligence 63 1993 305340 36 L Hiyakumoto S Prevost J Cassell Semantic discourse information texttospeech intonation ACL Workshop Conceptto Speech Technology 1997 37 Z Huang A Eliens C Visser XSTEP A markup language embodied agents Proceedings 16th International Conference Computer Animation Social Agents CASA2003 IEEE Press 2003 38 A Iida N Campbell S Iga F Higuchi MA Yasumura Speech synthesis emotion assisting communication Proceedings ISCA Workshop Speech Emotion Northern Ireland 2000 pp 167172 39 AK Joshi L Levy M Takahashi Tree adjunct grammars Journal Computer System Sciences 10 1975 136163 40 H Kamp U Reyle From Discourse Logic Kluwer Dordrecht 1993 41 M Kantrowitz GLINDA Natural language text generation oz interactive ﬁction project Technical Report CMUCS90158 School Computer Science Carnegie Mellon University Pittsburgh PA 1990 42 M Kantrowitz J Bates Integrated natural language generation systems Aspects Automated Natural Language Generation D Roes ner O Stock Eds NAI vol 587 Springer Berlin 1992 43 H Kasuya K Maekawa S Kiritani Joint estimation voice source vocal tract parameters applied study voice source dynamics Proceedings 14th International Conference Phonetic Sciences San Francisco USA pp 25052512 44 S Kopp I Wachsmuth Synthesizing multimodal utterances conversational agents Computer Animation Virtual Worlds 15 1 2004 3952 45 S Kopp T Sowa I Wachsmuth Imitation games artiﬁcial agent From mimicking understanding shaperelated iconic gestures X Camurri X Volpe Eds GestureBased Communication HumanComputer Interaction LNAI vol 2915 Springer Berlin 2004 pp 436447 httpwwwtechfakunibielefeldde7Eskoppdownloadgesture_imitation_GW03pdf 46 S Kopp B Krenn S Marsella A Marshall C Pelachaud H Pirker K Thorisson H Vilhjalmsson Towards common framework multimodal generation ECAs The behavior markup language J Gratch et al Eds Intelligent Virtual Agents 2006 LNAI vol 4133 Springer Berlin 2006 pp 205217 47 A Kranstedt S Kopp I Wachsmuth MURML A multimodal utterance representation markup language conversational agents Proceedings AAMAS02 Workshop Embodied conversational agentslets specify evaluate Bologna Italy 2002 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 1243 48 B Krenn B Neumayr E Gstrein M Grice Lifelike agents Internet A crosscultural case study S Payr R Trappl Eds Agent Culture HumanAgent Interaction Multicultural World Lawrence Erlbaum Associates NJ 2004 pp 197229 49 B Krenn H Pirker Deﬁning gesticon Language gesture coordination interacting embodied agents Proceedings AISB2004 Symposium Language Speech Gesture Expressive Characters University Leeds UK 2004 pp 107115 50 K Lambrecht Information Structure Sentence Form Cambridge University Press Cambridge 1994 51 JC Lester SA Converse SE Kahler ST Barlow BA Stone RS Bhoga The persona effect Affective impact animated pedagogical agents Proceedings CHI Conference Atlanta Georgia 1997 52 W Levelt Speaking From Intention Articulation MIT Press Cambridge MA 1989 53 A Loyall Believable agents Building interactive personalities PhD thesis CMU Technical Report CMUCS97123 54 S Marsella WL Johnson C LaBore Interactive pedagogical drama health interventions AIED 2003 11th International Conference Artiﬁcial Intelligence Education Australia 2003 55 M Mateas A Stern Facade An experiment building fullyrealized interactive drama Game Developers Conference Game Design Track San Jose California 2003 56 S McRoy S Channarukul S Ali An augmented templatebased approach text realization Natural Language Engineering 9 4 2003 381420 57 A Monaghan Intonation texttospeech conversion PhD thesis University Edinburgh 1991 58 JM Montero J GutiérrezArriola J Colás E Enríquez JM Pardo Analysis modelling emotional speech Spanish Proceedings 14th International Conference Phonetic Sciences San Francisco USA 1999 pp 957960 59 A Ndiaye P Gebhard M Kipp M Klesen M Schneider W Wahlster Ambient intelligence edutainment Tangible interaction lifelike exhibit guides Proceedings Conference INtelligent TEchnologies interactive entertainment INTETAIN05 Madonna di Campiglio Italy 2005 60 N Nicolov C Mellish G Ritchie Approximate generation nonhierarchical representations Proceedings 8th International Workshop Natural Language Generation Herstmonceux Castle UK 1996 61 A Ortony GL Clore A Collins The Cognitive Structure Emotions Cambridge University Press Cambridge MA 1988 62 C Pelachaud NI Badler M Steedman Generating facial expressions speech Cognitive Science 20 1 1996 146 63 P Piwek B Krenn M Schröder M Grice S Baumann H Pirker RRL A rich representation language description agent behaviour NECA Proceedings AAMAS Workshop Embodied Conversational AgentsLets Specify Evaluate Them Bologna Italy 2002 64 P Piwek A ﬂexible pragmaticsdriven language generator animated agents Proceedings EACL Research Notes Budapest Hun gary 2003 65 P Piwek The effect gestures perception dialogue embodied conversational agents pilot study Technical Report ITRI0309 ITRI University Brighton UK 2003 66 P Piwek K van Deemter Dialogue discourse Controlling global properties scripted dialogue Proceedings AAAI Spring Symposium Natural Language Generation Spoken Written Dialogue Stanford California 2003 67 P Piwek J Masthoff M Bergenstrahle Reference gestures dialogue generation Three studies embodied conversational agents Proceedings AISB05 Joint Symposium Virtual Social Agents Symposium University Herfordshire UK 2005 pp 5360 68 P Piwek K Van Deemter Generating global constraints The case scripted dialogue Journal Research Language Compu tation 5 2 2007 237263 69 S Prevost M Steedman Specifying intonation context speech synthesis Speech Communication 15 1994 139153 70 W Reilly Believable social emotional agents PhD thesis Carnegie Mellon University Pittsburgh 1996 71 E Reiter R Dale Building Natural Language Generation Systems Cambridge University Press Cambridge 2000 72 J Rickel WL Johnson Animated agents procedural training virtual reality Perception cognition motor control Applied Artiﬁcial Intelligence 13 1999 343382 73 Y Schabes Mathematical computational aspects lexicalized grammars PhD thesis Computer Science Department University Pennsylvania 1990 74 H Schlosberg A scale judgement facial expressions Journal Experimental Psychology 29 1941 497510 75 M Schröder Speech emotion research An overview research frameworks dimensional approach emotional speech synthesis PhD thesis Institute Phonetics Saarland University Phonus 7 2004 76 M Schröder M Grice Expressing vocal effort concatenative synthesis Proceedings 15th International Conference Phonetic Sciences Barcelona Spain 2003 77 M Schröder J Trouvain The German texttospeech synthesis MARY A tool research development teaching International Journal Speech Technology 6 2003 365377 78 M Schröder Expressing degree activation synthetic speech IEEE Transactions Audio Speech Language Processing 14 4 2006 11281136 79 M Stone T Bleam C Doran M Palmer Lexicalized grammar description motion events TAG Workshop TreeAdjoining Grammar Related Formalisms 2000 80 A Tassa JS Liénard A new approach evaluation vocal effort psola method WEBSLS The European Student Journal Language Speech 2000 81 D Traum J Bos R Cooper S Larsson I Lewin C Matheson M Poesio A model dialogue moves information state revision Trindi Project Deliverable D21 1999 82 O Turk M Schröder B Bozkurt LM Arslan Voice quality interpolation emotional texttospeech synthesis Proceedings Interspeech Lisbon Portugal 2005 pp 797800 83 K van Deemter E Krahmer M Theune Real versus templatebased natural language generation A false opposition Computational Lin guistics 31 1 2005 1524 1244 K van Deemter et al Artiﬁcial Intelligence 172 2008 12191244 84 K van Deemter Whats New A semantic perspective sentence accent Journal Semantics 11 1994 131 85 E Vallduví E Engdahl The linguistic realisation information packaging Linguistics 34 1996 459519 86 H Vilhjalmsson Animating conversation online games M Rauterberg Ed Entertainment Computing ICEC Lecture Notes Computer Science vol 3166 Springer Berlin 2004 pp 139150 87 M White ME Foster J Oberlander A Brown Using facial feedback enhance turntaking multimodal dialogue Proceed ings HCI International 2005