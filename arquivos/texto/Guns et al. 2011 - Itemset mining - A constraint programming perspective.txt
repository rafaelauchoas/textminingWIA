Artiﬁcial Intelligence 175 2011 19511983 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Itemset mining A constraint programming perspective Tias Guns Siegfried Nijssen Luc De Raedt Katholieke Universiteit Leuven Celestijnenlaan 200A 3001 Leuven Belgium r t c l e n f o b s t r c t Article history Received 31 May 2010 Received revised form 5 May 2011 Accepted 6 May 2011 Available online 11 May 2011 Keywords Data mining Itemset mining Constraint programming The ﬁeld data mining accustomed specifying constraints patterns A large number systems techniques developed solving constraintbased mining problems especially mining itemsets The approach taken ﬁeld data mining contrasts constraint programming principles developed artiﬁcial intelligence community While data mining research focuses algorithmic issues aims developing highly optimized scalable implementations tailored speciﬁc tasks constraint programming employs declarative approach The emphasis lies developing highlevel modeling languages general solvers specify problem outlining solution computed powerful wide variety applications application domains This paper contributes declarative constraint programming approach data mining More speciﬁcally possible employ offtheshelf constraint program ming techniques modeling solving wide variety constraintbased itemset mining tasks frequent closed discriminative costbased itemset mining In particular develop basic constraint programming model specifying frequent itemsets model easily extended realize settings This contrasts typical procedural data mining systems underlying procedures need modiﬁed order accommodate new types constraint novel combinations thereof Even performance stateoftheart data mining systems outperforms constraint programming approach standard tasks exist problems constraint programming approach leads signiﬁcant performance improvements stateoftheart methods data mining new insights underlying data mining problems Many insights obtained relating underlying search algorithms data mining constraint programming systems We discuss number interesting new research questions challenges raised declarative constraint programming approach data mining 2011 Elsevier BV All rights reserved 1 Introduction Itemset mining probably best studied problem data mining literature Originally applied supermarket setting involved ﬁnding frequent itemsets sets items frequently bought transactions customers 1 The introduction wide variety constraints range algorithms solving constraint based itemset mining problems 33541421131509 enabled application itemset mining numerous Corresponding author Tel 32 16 32 75 67 fax 32 16 32 79 96 Email address tiasgunscskuleuvenbe T Guns 00043702 matter 2011 Elsevier BV All rights reserved doi101016jartint201105002 1952 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 problems ranging web mining bioinformatics 31 instance early itemset mining algorithms focused ﬁnding itemsets unsupervised sparse data nowadays closed itemset mining algorithms enable application itemset mining dense data 4043 discriminative itemset mining algorithms allow application su pervised data 3513 This progress resulted effective scalable itemset mining systems algorithms usually optimized speciﬁc tasks constraints This procedural algorithmic focus nontrivial extend systems accommodate new constraints combinations thereof The need allow userspeciﬁed combinations constraints recognized data mining community witnessed development theoretical framework based antimonotonicity 334111 systems ConQueSt 9 MusicDFS 50 Molfea 18 These systems support predeﬁned number antimonotonicity based constraints making suited number typical data mining tasks These approaches contrast constraint programming Constraint programming general declarative methodology solving constraint satisfaction problems meaning constraint programs specify problem outline solution computed focus particular application Constraint program ming systems provide declarative modeling languages types constraints expressed combined support wider range constraints specialized systems satisﬁability SAT integer linear programming ILP solvers 10 To realize model separated possible solver In past decades constraint programming developed expressive highlevel modeling languages solvers powerful wide variety applications domains scheduling planning 45 The question arises context constraint programming principles applied itemset mining As compared traditional constraintbased mining approach approach specify data mining models general declarative constraint satisfaction primitives instead specialized primitives easy incorporate new constraints combinations thereof principle model needs extended specify problem general purpose solvers computing solutions The contribution article answer question positively showing general offtheshelf constraint programming methodology applied speciﬁc problems constraintbased itemset mining1 We wide variety itemset mining problems frequent closed costbased modeled constraint programming language general purpose outofthebox constraint programming systems effectively deal problems While frequent closed costbased itemset mining ideal cases existing constraint programming modeling language suﬃces tackle problems expected cases Indeed formulation discriminative itemset mining introduce novel primitive means global constraint This common practice constraint programming identiﬁcation study global constraints effectively solve speciﬁc subproblems branch research 6 Here exploited ability constraint programming serve integration platform allowing free combination new primitives existing ones This property allows ﬁnd closed discriminative itemsets effectively discriminative patterns adhering constraints Furthermore casting problem constraint programming setting provides new insights solve discriminative pattern mining problems lead important performance improvements stateoftheart discriminative data mining systems A ﬁnal contribution compare resulting declarative constraint programming framework wellknown stateoftheart algorithms data mining It realized comparison diﬃcult perform holds comparing different data mining resp constraint programming systems In com parison focus highlevel concepts speciﬁc implementation issues Nevertheless demonstrate feasibility approach CP4IM implementation employs stateoftheart constraint programming li brary Gecode 47 developed solving general constraint satisfaction problems While analysis reveals weaknesses applying particular library itemset mining problem reveals Gecode outperform stateoftheart data mining systems tasks Although outside scope present paper interesting topic ongoing research 37 optimize constraint programming systems use data mining The article organized follows Section 2 provides introduction main principles constraint programming Section 3 introduces basic problem frequent itemset mining discusses problem addressed ing constraint programming techniques The following sections alternative itemset mining constraints problems dealt constraint programming Section 4 studies closed itemset mining Section 5 considers discriminative itemset mining Section 6 shows typical monotonicitybased problems studied literature addressed constraint programming framework We study sections search constraint programming approach compares specialized approaches The CP4IM approach evalu ated Section 7 provides overview choices modeling frequent itemset mining concrete constraint programming compares performance constraint programming specialized data mining systems Finally Section 8 concludes 1 We studied problem conference papers 1638 brought attention AI community 17 This article extends earlier papers proofs experiments comprehensive comparisons related work literature T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1953 2 Constraint programming In section provide brief summary common approach constraint programming More details text books 453 focus highlevel principles omit implementation issues Constraint programming CP declarative programming paradigm user speciﬁes problem terms straints responsible ﬁnding solutions adhere constraints The class problems constraint programming systems focus constraint satisfaction problems Deﬁnition 1 Constraint Satisfaction Problem CSP A CSP P V D C speciﬁed ﬁnite set variables V initial domain D maps variable v V set possible values Dv ﬁnite set constraints C cid5 A variable x V called ﬁxed Dx 1 domain D ﬁxed variables ﬁxed x V Dx 1 A domain D cid5x Dx x V domain false exists x V Dx called stronger domain D D A constraint Cx1 xk C arbitrary boolean function variables x1 xk V A solution CSP ﬁxed domain D stronger initial domain D satisﬁes constraints Abusing notation cid5 ﬁxed domain Cx1 xk C CD cid5x1 D cid5xk true A distinguishing feature CP focus speciﬁc set constraint types Instead provides general principles solving problems type variable constraint This sets apart satisﬁability SAT solving focuses mainly boolean formulas integer linear programming ILP focuses linear constraints integer variables Example 1 Assume people want allocate oﬃces person list people want share oﬃce Furthermore person identiﬁed rooms want occupy We represent instance problem variables represent persons inequality constraints encode roomsharing constraints Dx1 Dx2 Dx3 Dx4 1 2 C x1 cid8 2 x1 cid8 x2 x3 cid8 x4 The simplest algorithm solve CSPs enumerates possible ﬁxed domains evaluates constraints domains clearly approach ineﬃcient Most CP systems perform intelligent type depthﬁrst search given Algorithm 1 4745 return Algorithm 1 ConstraintSearchD 1 D propagateD 2 D false domain 3 4 end 5 x V Dx 1 6 7 8 9 10 11 12 end x arg minxVDx1 f x d Dx Output solution end ConstraintSearchD x cid11 d Other search strategies investigated 5344 restrict common case In node search tree algorithm branches restricting domain variables ﬁxed line 7 Algorithm 1 It backtracks violation constraint line 2 The search optimized carefully choosing variable ﬁxed line 6 function f x ranks variables instance determining variable involved highest number constraints The main concept speed search constraint propagation line 1 Propagation reduces domains variables domain remains locally consistent One deﬁne types local consistencies node consistency arc consistency path consistency 45 In general locally consistent domain value d cid5x d The main occur domain variable x determined solution D D cid5 1954 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 motivation maintaining local consistencies ensure backtracking search unnecessarily branch values signiﬁcantly speeding search To maintain local consistencies propagators propagation rules Each constraint implemented propaga tor Such propagator activated domain variables constraint changes A propagator takes domain input outputs failed domain case constraint longer satisﬁed exists cid3 xk stronger D C x1 D true ﬁxed D 1 D cid2 cid5 cid5 cid5 When possible propagator remove values domain satisfy constraint giving output stronger locally consistent domain More formally value c removed domain variable x cid5 ﬁxed D stronger D D cid5 x c C cid2 cid5 D x1 D cid5 cid3 xk true 2 This referred propagation propagation ensures domain consistency The repeated application propagators lead increasingly stronger domains Propagators repeatedly applied ﬁxed point reached domain change Consider constraint x1 cid8 x2 corresponding propagator given Algorithm 2 Dx2 Dx2 Dx1 Algorithm 2 Conceptual propagator x1 cid8 x2 1 Dx1 1 2 3 end 4 Dx2 1 5 6 end Dx1 Dx1 Dx2 The propagator propagate x1 x2 ﬁxed lines 1 4 If value removed domain variable lines 2 5 In propagator need explicitly check constraint violated violation results false domain line 2 Example 2 Example 1 continued The initial domain problem consistent constraint x1 cid8 2 satisﬁed Dx1 2 value 2 removed domain x1 Subsequently propagator constraint x1 cid8 x2 activated removes value 1 Dx2 At point obtain ﬁxed point Dx1 1 Dx2 2 Dx3 Dx4 1 2 Persons 1 2 allocated oﬃce rooms possible persons 3 4 The search branches x3 branch constraint x3 cid8 x4 propagated ﬁxed point reached variable ﬁxed solution In example variable entire domain Dx maintained In constraint programming types consistency algorithms maintaining consistency studied A popular type consistency bound sistency In case variable lower upperbound values domain maintained A propagator try narrow domain variable range values believes solution maintain consistency individual values To formulate itemset mining problems constraint programming models use variables binary domains Dx 0 1 x V For variables difference bound domain consistency Furthermore extensive use types constraints boolean variables summation constraint Eq 3 reiﬁed summation constraint Eq 6 introduced 21 Summation constraint Given set variables V V weights w x variable x V general form summation constraint cid4 xV w xx cid2 θ 3 The ﬁrst task propagator discover early possible constraint violated To aim propagator needs determine upperbound sum required threshold ﬁlling constraint Eq 1 means need check cid5cid4 cid6 4 max ﬁxed Dcid5 stronger D w x D xV cid5 x cid2 θ T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1955 cid5cid4 cid6 A intelligent method evaluate property works follows We denote maximum value variable x xmax maxdDx d minimum value xmin mindDx d Denoting set variables positive respectively x V w x cid2 0 V negative weight V cid6 x V w x 0 bounds sum deﬁned cid4 cid5cid4 cid5cid4 cid4 cid4 cid4 cid6 max w xx w xxmax w xxmin xV xV xV min w xx xV cid7 w xxmin w xxmax xV xV xV w xx cid2 θ satisﬁed These bounds allow determine inequality constraint The second task propagator maintain bounds variables constraint case variables V In general variable x V need update xmin lowest value c exists domain D cid5 cid5 ﬁxed D stronger D D cid5 x c w x D cid5 x cid2 θ 5 xV Also computed eﬃciently essentially binary variables x V update domains follows Dx Dx 0 w x V Dx Dx 1 w x V θ cid3 max θ cid3 max cid7 cid7 xV w xx θ w x xV w xx θ w x Example 3 Let illustrate propagation summation constraint Given Dx1 1 2 x1 4 x2 8 x3 cid2 3 Dx2 Dx3 0 1 know x2 x3 value 1 conclude variables certainly zero The propagator change domains On hand given Dx1 1 2 x1 4 x2 8 x3 cid2 7 Dx2 Dx3 0 1 propagator determines constraint satisﬁed x3 false Dx3 1 22 Reiﬁed summation constraint The second type constraints use extensively reiﬁed summation constraint Reiﬁed constraints common construct constraint programming 5254 Essentially reiﬁed constraint binds truth value constraint C binary variable b cid5 b C cid5 cid5 In principle C reiﬁed summation constraint boolean constraint In article C usually constraint sum In case speak b cid4 xV w xx cid2 θ 6 This constraint states b true weighted sum variables V higher θ The important constraint propagation occurs constraint updates domain variable b Essentially domain variable updated follows Db Db 1 max Db Db 0 min xV w xx θ xV w xx cid2 θ cid7 cid7 In addition constraint programming systems constraint propagators simplify constraints In case Db 1 reiﬁed constraint simpliﬁed constraint xV w xx cid2 θ Db 0 simpliﬁed constraint cid7 cid7 xV w xx θ Many different constraint programming systems exist They differ types variables support constraints implement way backtracking handled data structures store constraints propagators Furthermore systems constraints speciﬁed logic instance constraint logic programming ECLiPSe 3 declarative primitives embedded imperative programming language An example Gecode 47 use experimental section article 1956 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Tid T 1 T 2 T 3 T 4 T 5 T 6 T 7 T 8 T 9 T 10 Itemset B E AC AE BC DE CDE ABC ABE ABCE Tid 1 2 3 4 5 6 7 8 9 10 A 0 0 1 1 0 0 0 1 1 1 B 1 0 0 0 1 0 0 1 1 1 C 0 0 1 0 1 0 1 1 0 1 D 0 0 0 0 0 1 1 0 0 0 E 0 1 0 1 0 1 1 0 1 1 Fig 1 A small example itemset database multiset notation left binary matrix notation right 3 Frequent itemset mining Now introduced key concepts underlying constraint programming CP study itemset mining problems framework We start frequent itemset mining present section discuss closed discriminative costbased itemset mining following sections For problem provide formal deﬁnition introduce constraint programming model shows itemset mining problem formalized CP problem compare search strategy obtained constraint programming approach existing itemset mining algorithms We start problem frequent itemset mining formulate CP models case The difference initial model improved later uses notion reiﬁed constraints yields better propagation shown analysis resulting search strategies 31 Problem deﬁnition The problem frequent itemset mining proposed 1993 Agrawal et al 1 Given database set transactions2 Let I 1 m set items A 1 n set transaction identiﬁers An itemset database D binary matrix size n m Dti 0 1 equivalently multiset itemsets I I cid8 Dcid5 t I cid9 cid9 t A I I I Dti 1 cid10 A small example itemset database given Fig 1 convenience item represented letter There databases converted itemset database The traditional example supermarket database transaction corresponds customer item transaction product bought customer Attributevalue tables converted itemset database For categorical data attribute value pair corresponds item row converted transaction The coverage ϕDI itemset I consists transactions itemset occurs ϕDI t A I Dti 1 The support itemset I denoted supportDI size coverage supportDI cid9 cid9 cid9 cid9ϕDI In example database ϕDD E T 6 T 7 supportDD E T 6 T 7 2 Deﬁnition 2 Frequent itemset mining Given itemset database D threshold θ frequent itemset mining problem consists computing set cid8 I cid9 cid9 I I supportDI cid2 θ cid10 The threshold θ called minimum support threshold An itemset supportDI cid2 θ called frequent itemset Note interested ﬁnding itemsets satisfying frequency constraint The subset relation itemsets deﬁnes partial order This illustrated Fig 2 example database Fig 1 frequent itemsets visualized Hasse diagram line drawn itemsets I1 I2 iff I1 I2 I2 I1 1 By changing support threshold analyst inﬂuence number patterns returned data mining lower support threshold larger number frequent patterns 2 Itemset mining ﬁrst applied supermarket setting terminology reﬂects T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1957 Fig 2 A visualization search space database Fig 1 frequent itemsets θ 2 highlighted Frequent closed itemsets highlighted black nonclosed frequent itemsets grey 32 Initial constraint programming model Our model frequent itemset mining problem constraint programming based observation formalize frequent itemset mining problem ﬁnding set cid8 I T cid9 cid9 I I T A T ϕDI T cid2 θ cid10 Here set transactions T ϕDI explicit This yields solutions original problem set transactions T completely determined itemset I We refer T ϕDI coverage constraint T cid2 θ expresses support constraint To model formalization CP need represent set items I set transactions T In model use boolean variable I individual item furthermore use boolean variable Tt transaction t An itemset I represented setting I 1 I I 0 I The variables Tt represent transactions covered itemset T ϕI Tt 1 iff t ϕI One assignment values I Tt corresponds itemset corresponding transaction set We coverage constraint formulated follows Property 1 Coverage constraint Given database D itemset I transaction set T cid5 cid6 T ϕDI t A Tt 1 I i1 Dti 0 cid4 iI equivalently cid5 T ϕDI t A Tt 1 cid6 Dti 1 I 0 cid11 iI I Tt 0 1 I 1 iff I Tt 1 iff t T 7 8 Proof Essentially constraint states transaction t items included transaction Dti 1 included itemset I 0 T ϕDI t A I Dti 1 t A t A Tt 1 I Dti 1 Tt 1 I 1 Dti 0 1958 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 t A Tt 1 cid4 iI I i1 Dti 0 The representation clause Eq 8 follows cid2 It common constraint programming encounter different ways model problem conceptual constraint How propagation implemented constraints change solver solver For example watched literals clause constraint leading different runtime memory characteristics compared setting watched literals We defer study characteristics Section 7 Under coverage constraint transaction variable true corresponding transaction covers itemset Counting frequency itemset achieved counting number transactions Tt 1 Property 2 Frequency constraint Given database D transaction set T threshold θ T cid2 θ cid4 tA Tt cid2 θ Tt 0 1 Tt 1 iff t T 9 We model frequent itemset mining problem combination coverage constraint 7 fre quency constraint 9 To illustrate provide example model Essence language Algorithm 3 Algorithm 3 Fim_cps frequent itemset mining model Essence 1 given NrT NrI int 2 given TDB matrix indexed int1NrTint1NrI int01 3 given Freq int 4 ﬁnd Items matrix indexed int1NrI bool 5 ﬁnd Trans matrix indexed int1NrT bool 6 7 Coverage Constraint Eq 7 8 forall t int1NrT 9 Transt sum int1NrI 1TDBtiItemsi 0 10 Frequency Constraint Eq 9 11 sum t int1NrT Transt Freq Essence solverindependent modeling language developed support intuitive modeling abstracting away underlying solver technology 22 We study constraint programming solver search solutions given model A ﬁrst observation set transactions completely determined itemset need search item variables When item variable set DI 1 search constraints contain item activated In words frequency constraint activated coverage constraint contains item A coverage constraint reiﬁed summation constraint propagator explained Section 2 In summary item variable set following propagation possible coverage constraint t t cid7 cid7 iI 1 Dti I min iI 1 Dti I max 0 remove 1 DTt 0 remove 0 DTt Once domain variable Tt changed support constraint activated The support constraint summation constraint check cid4 tA T max t cid2 θ If constraint fails need branch backtrack Example 4 Fig 3a shows search tree small example minimum frequency threshold 2 Essentially search ﬁrst tries add item itemset backtracking consider itemsets including After search step indicated green propagators activated The coverage propagators set transactions 0 1 frequency constraint cause failure desired frequency longer obtained indicated red cross leftmost branches T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1959 Fig 3 Searchpropagation interaction nonreiﬁed frequent itemset model left reiﬁed frequent itemset model right A propagation step colored blue search step green For interpretation references color ﬁgure legend reader referred web version article 1960 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Observe example branched item 2 ﬁrst This follows generic constrained variable order heuristic branches variable contained constraints ﬁrst remember coverage constraints posted items 0 matrix If item 1 branched ﬁrst search tree larger branches determine separately I2 1 result frequent itemset An experimental investigation different branching heuristics Section 7 33 Improved model Inspired observations traditional itemset mining algorithms propose alternative model substantially reduces size search tree introducing ﬁnegrained constraints The main observation formulate frequency constraint item individually Property 3 Reiﬁed frequency constraint Given database D itemset I cid8 transaction set T T ϕDI T cid2 θ I Ii 1 cid4 tA Tt Dti cid2 θ I Tt 0 1 I 1 iff I Tt 1 iff t T Proof We observe rewrite ϕDI follows ϕDI t A I Dti 1 cid2 cid3 ϕD cid12 iI 10 Using observation follows cid9 cid9 cid9 cid9 cid9 T cid2 θ cid9 cid9 cid3 cid9 cid9 cid9 cid2 θ j ϕD cid12 cid2 jI I I cid9 cid9 cid9 cid9 cid9ϕD cid9 cid9ϕD cid2 cid2 cid3 cid3 cid12 cid2 j ϕD cid9 cid9 cid3 cid9 cid9 cid9 cid2 θ jI cid9 cid9 cid2 θ T cid4 I Ii 1 Tt Dti cid2 θ cid2 tA The improved model consists coverage constraint Eq 7 newly introduced reiﬁed frequency constraint Eq 10 This model equivalent original model ﬁnds frequent itemsets The reiﬁed frequency constraint posted item separately resulting ﬁnegrained searchpropagation interactions Essentially reiﬁed frequency constraint performs kind lookahead item propagator check item frequent given current itemset If removed consideration inclusion itemset infrequent In summary main additional propagation allowed reiﬁed constraint following cid7 tA Dti T max t θ remove 1 DI I 0 Example 5 Fig 3 shows search trees original nonreiﬁed model improved model reiﬁed frequency constraint In original model Fig 3a search branches I2 1 propagation detects makes itemset infrequent fails leftmost branch In reiﬁed model Fig 3b reiﬁed frequency propagator I2 detects item infrequent When evaluating sum 0 T max easy maximum 1 2 leading I2 0 second level The situation occurs I3 near ﬁgure This time propagator takes account point T 3 0 T max 1 T max 0 T max 0 1 2 3 3 The reiﬁed propagations avoid creating branches fail In fact reiﬁed model search failurefree branch lead solution frequent itemset This comes cost larger number propagations In Section 7 experimentally investigate difference eﬃciency formulations T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1961 34 Comparison Let study proposed CPbased approach compares traditional itemset mining algorithms In order understand relationship let ﬁrst provide short introduction traditional algorithms The important property exploited traditional algorithms antimonotonicity Deﬁnition 3 Antimonotonic constraints Assume given itemsets I1 I2 predicate pI D expressing straint itemset I satisfy database D Then constraint antimonotonic iff I1 I2 pI2 D cid20 pI1 D Indeed itemset I2 frequent itemset I1 I2 frequent included transactions I2 This property allows develop search algorithms need consider possible itemsets Essentially itemset I2 I1 needs considered I1 infrequent Starting search itemset ways traverse search space important ones breadthﬁrst search depthﬁrst search Initial algorithms itemset mining breadth ﬁrst search algorithms Apriori algorithm main representative 2 However recent algorithms use depthﬁrst search Given CP systems perform depthﬁrst search similarities CP depthﬁrst itemset mining algorithms larger CP breadthﬁrst mining algorithms An outline general depthﬁrst frequent itemset mining algorithm given Algorithm 4 The main observations following item infrequent database remove corresponding column database itemset contain item column redundant item added itemset transactions containing item irrelevant search tree itemset remove corresponding row database The resulting database contains smaller number transactions having smaller number items called projected database Hence time add item itemset determine items transactions irrelevant continue search resulting database contains frequent items transactions covered current itemset Important beneﬁts search procedure try add items infrequent transactions longer relevant similarly ignored Please note following projected database include items strictly higher order highest item currently itemset The reason wish avoid itemset multiple times instance wish ﬁnd itemset 1 2 child itemset 1 child itemset 2 Algorithm 4 DepthFirstSearch Itemset I Database D 1 F I 2 determine total order R items D 3 items occurring D 4 5 6 7 F F DepthFirstSearchI Di 8 end 9 return F create D projected database Di containing transactions D contain items Di frequent higher chosen order R An important choice general algorithm projected databases stored A large number strate gies explored tidlists FPtrees 30 Tidlists relevant compare best strategies chosen CP systems Given item tidlist database D ϕDi We store list list integers 56 binary vector variations runlength encoding 49 The projected database given itemset I set cid8cid2 cid2 I cid3cid3 cid9 cid9 cid2 cid9 cid9ϕD cid10 cid3cid9 cid9 cid2 θ I ϕD The interesting property tidlists easily updated incrementally wish obtain tidlist item j projected database itemset obtained computing ϕDi ϕD j D original database instance case bit vectors binary AND operation CPUs evaluate eﬃciently The wellknown algorithm approach Eclat algorithm 56 An example depthﬁrst search tree given Fig 4 database Fig 3 represent projected database tidlists The order items assumed usual order integers In initial projected database item 2 occur frequent Each child root corresponds itemset item 1962 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Fig 4 The search tree depthﬁrst frequent itemset miners example Fig 3 items ordered natural order integers Each itemset corresponding projected database containing frequent items higher items chosen far For instance projected database itemset 4 items 1 3 lower 4 database 1 contain item i3 1 3 fre quent 341 Comparison search CP model We compare descriptions itemset mining algorithms constraint programming systems Necessarily need restrict discussion comparison highlevel principles detailed comparison approaches possible studying data structures speciﬁc constraint programming systems consider scope article 37 ﬁrst attempt direction We ﬁrst consider differences search trees CP model compared traditional mining algo rithms These differences understood comparing trees Figs 3 4 In depthﬁrst itemset mining node search tree corresponds itemset Search proceeds adding items nodes search tree arbitrary number children In CP node search tree corresponds domain model represents choice possible values items transactions Search proceeds restricting domain variable The resulting search tree binary item represented boolean variable true false include exclude item We identify following relationship nodes search tree CP nodes search tree itemset miners Denoting DI domain item variable I state CP map state itemset follows cid9 cid9 DI 1 I cid10 cid8 Essentially CP branches search tree correspond assignment DI 0 item item removed consideration All nodes path branches collapsed node search tree itemset miner turning binary tree nary tree Even different perception search tree leads higher memory use CP systems necessarily case If search tree traversed order indicated Fig 3b assigned value DI1 0 generated corresponding child node longer need store original domain D DI1 0 1 The reason children generate original node search tree search returns node immediately backtrack parent Hence additional memory needs consumed branches corresponding DI 1 assignments This implies practice eﬃciency depends implementation CP depend theoretically different shape search tree In possible domains variables representing items search CP DI 0 1 represents item added itemset currently included traditional itemset mining algorithms items included projected database DI 0 represents item added itemset In case traditional itemset mining algorithms items projected database current itemset DI 1 represents item itemsets deeper search tree case traditional algorithms item itemset represented search tree node T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1963 Similarly transaction variables DTt 0 1 represents transaction covered current itemset 1 domain removed coverage later traditional algorithms transaction projected database DTt 0 represents transaction covered current itemset traditional algorithms transaction projected database DTt 1 represents transaction covered current itemset covered itemsets deeper search tree transaction contains items added itemset traditional itemset mining algorithms transaction projected database A second difference information available transactions search In CP formalization distinguish transactions domain DTt 0 1 DTt 1 Frequent itemset mining algorithms distinction This difference allows determine transactions unavoidable A transaction unavoidable DTt 1 remaining items 1 DI included propagation detect occurs branches items removed consideration Such branches present itemset mining algorithms avoiding propagation important development new constraint programming systems Thirdly evaluate constraints CP systems store constraints propagators search Essentially node search tree state associated reﬂects active constraints propagators variables Such state corre sponds concept projected database itemset mining algorithms The data structures storing maintaining propagators CP systems itemset mining algorithms different For example itemset min ing eﬃcient data representations tidlists fptrees developed CP systems use data structures storing propagators constraints redundant problem setting For instance depthﬁrst itemset mining popular approach store tidlist integer array CP systems use array store indexes variables constraint use array store list constraints watching variable Resolving differences requires closer study particular constraint programming systems outside scope paper Overall comparison shows highlevel similarities itemset mining constraint pro gramming systems cases expect lowerlevel differences Our experiments lowlevel differences signiﬁcant practical impact interesting direction future research bridge gap systems 4 Closed itemset mining Even frequency constraint limit number patterns constraint restrictive ﬁnd useful patterns A high support threshold usually effect wellknown itemsets low threshold number patterns large To alleviate problem additional types constraints introduced In following sections study representative types constraints formalized constraint programming problems Closed itemset mining aims avoiding redundant itemsets dis criminative itemset mining wants ﬁnd itemsets discriminate classes transactions costbased constraints representative fairly general class constraints monotonicity framework 41 Problem deﬁnition Condensed representations aim avoiding redundant itemsets itemsets necessary presence solution set derived itemsets algorithm The closedness constraint typical constraint ﬁnd condensed representation 40 We introduce closedness constraint formally One way interpret itemsets seeing rectangles ones binary matrix For instance example database Fig 1 page 1956 itemset D corresponding transactions T 6 T 7 The itemset D transaction set T 6 T 7 select submatrix seen rectangle matrix Observe way calculate set transactions set items add transaction set transactions including zero element rectangle However case columns In case ϕD ϕD E T 6 T 7 add item E obtain rectangle containing ones Closed itemset mining seen problem ﬁnding maximal rectangles ones matrix An essential property maximal rectangles consider transactions derive corresponding set items largest itemset shared transactions deﬁne columns included rectangle This leads following deﬁnition closed itemset mining Deﬁnition 4 Frequent closed itemset mining Given database D let ψDT deﬁned ψDT I t T Dti 1 1964 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Given threshold θ frequent closed itemsets itemsets cid8 I cid9 cid9 I I supportDI cid2 θ ψD cid2 cid3 ϕDI cid10 I Given itemset I itemset ψDϕDI called closure I Closed itemsets equal closure If itemset equal closure means add item itemset changing support Closed itemsets example database highlighted black Fig 2 The idea closed itemsets studied communities closed itemset mining particular closely related problem ﬁnding formal concepts formal contexts 24 Essentially formal concepts thought closed itemsets applying support threshold In formal concept analysis operators ϕ ψ called Galois operators These operators deﬁne Galois connection partial orders itemsets transaction sets respectively 42 Constraint programming model Compared frequent itemset mining additional constraint need express closedness constraint We deal constraint similar way coverage constraint Assuming T represents set transactions covered itemset I constraint need check following ψDT I 11 case ψDϕDI I This leads following constraint CP model posted constraints Eqs 7 10 Property 4 Closure constraint Given database D itemset I transaction set T cid5 cid6 I ψDT I I 1 Tt1 Dti 0 12 cid4 tA I Tt 0 1 I 1 iff I Tt 1 iff t T The proof similar proof coverage constraint 43 Comparison Several classes algorithms proposed closed itemset mining extension breadth ﬁrst algorithm Apriori depthﬁrst algorithm operating tidlists fptrees We limit depthﬁrst mining algorithms Initial algorithms mining closed itemsets based repository closed itemsets stored The search performed depthﬁrst frequent itemset miner modiﬁed follows transactions projected database contain item item immediately added itemset itemset closed itemset I1 way checked repository itemset I2 I1 earlier support itemset stored repository search continues closed supersets starting I2 earlier children I2 branch search tree pruned The ﬁrst modiﬁcation checks items projected database construction items maxI higher lexicographic order The repository needed check superset additional item maxI second modiﬁcation With appropriate search order closed itemsets stored 43 This procedure works number closed sets small database large When number closed itemsets large storing itemsets searching costly The LCM algorithm addresses problem 51 In algorithm items maxI checked data closure depthﬁrst search procedure recurse items 431 Constraint propagation The additional constraint 12 closed itemset mining similar coverage constraint propagation similar When remaining transactions 1 DTt contain certain item propagator change domain item DI 1 1 DI fail 1 DI T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1965 Tid T 1 T 2 T 3 T 4 T 5 T 6 T 7 T 8 T 9 T 10 Itemset B E A C A E B C D E C D E A B C A B E A B C E Class Fig 5 A small example classlabeled itemset database multiset notation Hence case failurefree search closure constraint requires inclusion item closure included search backtrack Overall behavior similar LCM algorithm essentially performing backtracking search storing solutions items closure immediately added branches pruned fail satisfy order constraint The main difference LCM CP previous section data structures search tree differently organized 5 Discriminative itemset mining Itemset mining initially motivated need ﬁnd rules association rules However problem settings discussed till rules instead conditions consequents In section study discovery rules special type transactional data data transaction labeled binary class label The task ﬁnd itemsets allow discriminate transactions belonging class belonging class As turns integrating constraint eﬃciently constraint programming requires addition new primitive constraint programming till On hand shows limits declarative approach presented till hand results demonstrate feasibility adding new data mining primitives global constraints Furthermore application CP principles development new constraint propagator turns crucial improving performance existing mining systems 51 Problem deﬁnition To illustrate problem discriminative itemset mining consider database given Fig 5 We interested ﬁnding itemsets discriminate transactions different classes In example database instance itemset B C occurs positive examples thought discriminate positive transac tions negative ones leading rule B C Whereas refer mining problem problem discriminative itemset mining 351321 known names correlated itemset mining 4839 interesting itemset mining 5 contrast set mining 4 emerging itemset mining 20 subgroup discovery 553228 The problem highly related rule learning machine learning 23 The key difference rule learning machine learning usually uses heuristic techniques itemset mining typically exhaustive techniques ﬁnd global optimum target attribute negative D Even general case target attribute multiple values restrict case target attribute values positive negative We refer database target attribute positive D The set transactions identiﬁers appearing corresponding parts indicated A We deﬁne stamp point itemset I σ I supportD I supportD I Hence stamp point itemset vector p n p frequency itemset D Given numbers compute discrimination score f p n For itemsets stamp point σ I p n calculate score f σ I written f I short Examples include χ 2 information gain Gini index Fisher score For example χ 2 discrimination measures f known measure correlation statistics n frequency itemset D A χ 2p n p pn D pn D D2 D D p Dpn D Dpn D D n pn D pn D D2 D2 D D n Dpn Dpn D D D D2 13 assumed 00 0 An illustration measure given Fig 6 The domain stamp points 0 D 0 D called PNspace 1966 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Fig 6 Left Plot χ 2 measure threshold χ 2 20 Right isometric threshold PN space Essentially interested ﬁnding itemsets close possible maxima opposite corners χ 2 measure scores higher closer maxima A discrimination measure constraint ways We limit following cases Deﬁnition 5 Discriminative itemset mining Given database D discrimination measure f parameter θ dis criminative itemset mining problem ﬁnding itemsets cid8 I cid9 cid9 I I f I cid2 θ cid10 Deﬁnition 6 Topk discriminative itemset mining Given database D discrimination measure f value k topk discriminative itemset mining problem problem ﬁnding ﬁrst k elements list I1 I2 In consisting itemsets I I downward sorted f I values In words set k patterns score highest according discrimination measure For k 1 corre sponds ﬁnding arg maxII f I 52 Constraint programming model The discrimination constraint expressed straightforward way In addition variables Tt I introduce new variables p n calculated follows cid4 cid4 p Tt tA n Tt 14 tA represent set transaction identiﬁers positive database D A negative database Remember A D respectively The discrimination constraint expressed follows Property 5 Discrimination constraint Given database D transaction set T discrimination measure f threshold θ itemset discriminative iff f p n cid2 θ p n deﬁned described Eq 14 Such constraint readily expressed CP systems essentially discrimination measure χ 2 composed large number mathematical operations variables p n A A By carefully decomposing measure simple operations intermediate variables CP systems able maintain bound consistency This approach cumbersome instance case χ 2 function need rewrite formula care division zero guaranteed rewriting formula leads eﬃcient computation strategy discrimination measures Hence propose robust approach requires addition new constraint CP enable maintenance tighter bounds discrimination measures nice properties Adding specialized global T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1967 Fig 7 Illustration rectangle stamp points PN space rectangle p1 p2 n1 n2 ZDC measure reaches highest value highlighted stamp points constraints common practice CP 45 supported systems Gecode The main observation use case discrimination measures χ 2 zero diagonal convex ZDC Deﬁnition 7 A scoring function f zero diagonal convex ZDC following properties function reaches minimum stamp points diagonal PNspace 0 cid3 α cid3 1 f cid9 cid9 α function convex pair stamp points σ cid8 σ cid5 cid2 cid9 cid9A cid9 cid9A 0 cid2 α cid9 cid3 cid9 cid3 0 cid3 α cid3 1 f cid2 ασ 1 ασ cid5 cid3 α f σ 1 α f holds cid3 σ cid5 Theorem 1 Fisher score information gain Gini index χ 2 ZDC measures Deﬁnitions independent alternative proofs theorem 133435 The plot χ 2 Fig 6 illustrates properties function zero diagonal convex For ZDC measure following proved Theorem 2 Maximum ZDC measures Let f ZDC measure 0 cid3 p1 cid3 p2 0 cid3 n1 cid3 n2 Then max σ1σ2p1p2n1n2 f σ1 σ2 max cid8 cid10 f p1 n2 f p2 n1 Proof The proof similar 35 First observe function convex Hence know maximum space p1 p2 n1 n2 reached points p1 n1 p1 n2 p2 n1 p2 n2 Next need ignore corners p1 n1 p2 n2 Observing minimum reached diagonal distinguish cases If n1A p1A point p1 n1 diagonal We know point A A n1 n1 diagonal f A A n1 n1 0 Due convexity know f A A n1 n1 0 cid3 f p1 n1 cid3 f p2 n1 Similarly p1 n1 diagonal f p1 n1 cid3 f p1 n2 f p2 n2 cid3 f p2 n1 p2 n2 diagonal f p2 n2 cid3 f p1 n2 p2 n2 diagonal cid2 The bound states ﬁnd highest possible score rectangle points suﬃces check corners rectangle This illustrated Fig 7 rectangle p1 p2 n1 n2 highlighted maximum ZDC measure reached corners p2 n1 p1 n2 This property implement propagator discrimination constraint Similar model standard frequent itemset mining improve model posting discrimination constraint item individually leading reiﬁed discrimination constraint cid4 cid5 cid4 cid6 I I 1 f Tt Dti Tt Dti cid2 θ 15 tA tA Our CP model discriminative itemset mining combination constraint coverage constraint Eq 7 The propagator constraint obtained applying Theorem 2 Algorithm 5 To understand propagator consider example Fig 7 marked curve f p n θ particular value θ Due convexity function f stamp points f p n cid2 θ 1968 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 cid7 tA Tt Dti cid7 tA Tt Dti cid2 θ cid7 cid7 tA Tt Dti post constraint f cid7 Algorithm 5 Conceptual propagator Ii 1 f 1 DIi 1 2 3 4 5 6 7 8 9 end Dti tA T max cid7 t tA T min f t DIi DIi 1 upper max f upper θ end cid7 tA Tt Dti cid2 θ Dti tA T min cid7 t Dti tA T max t Dti Fig 8 Stamp points p2 0 0 n2 upper bounds itemset I p2 n2 σ I cid7 lowerright upperleft corner None stamp points p n p1 p2 n1 n2 p1 cid7 p2 checked propagator determining f p1 n2 θ f p2 n1 θ Dti Dti satisﬁes f p n cid2 θ ﬁgure easily Dti n2 tA T max tA T max tA T min tA T min Dti n1 cid7 t t t t cid7 53 Comparison Traditional discriminative itemset mining algorithms essentially proceed updating frequent itemset mining algorithms different antimonotonic constraint search This constraint based derivation upperbound discrimination measure 35 Deﬁnition 8 Upperbound Given function f p n function gp n upperbound f iff p n f p n cid3 gp n In case itemsets said upperbound antimonotonic constraint gI cid2 θ antimonotonic The following upperbound presented Morishita Sese ZDC measures 35 Theorem 3 Upperbound ZDC measures Let f p n ZDC measure gp n max f p 0 f 0 n upperbound f p n gI cid2 θ antimonotonic constraint Proof The fact function upperbound follows Theorem 2 p1 n1 0 p2 σ1I n2 σ2I The antimonotonicity follows fact f p 0 f 0 n monotonically increasing functions D p n respectively p n represent support itemset positive negative databases D respectively antimonotonic cid2 The bound illustrated Fig 8 Given threshold θ ﬁgure itemset I stamp point p n σ I pruned f p 0 f 0 n discrimination score exceeds threshold θ This bound updated frequent itemset miner main differences need able compute support classes data separately This achieved tidlist fptrees prune items projected database instead support constraint constraint upperbound discrimination score subtree search tree pruned iff gI θ θ threshold score score kth best itemset far topk mining In case wish ﬁnd discriminative patterns score θ instead topk patterns highest discriminative score branchandbound search strategy employed In 1 branchandbound search bound discrimination score f p n increased patterns higher score For k branchand bound search bound set kth pattern T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1969 Fig 9 Illustration possible propagation discriminative itemset mining propagation loop studied specialized itemset mining algorithms In step 1 itemset 2 ﬁnd itemset 2 6 reach desired score item 6 excluded consideration As result transactions unavoidable Consequently itemset 2 4 known reach threshold item 4 excluded consideration 531 Constraint propagation Intuitively compare Figs 7 8 search continue itemset Fig 8 maximum reachable score measured points p2 0 0 n2 score threshold θ On hand search stop Fig 7 maximum itemset reach measured p2 n1 p1 n2 score threshold The difference Fig 7 p1 n1 taken account number unavoidable transactions As outlined page 1963 unavoidable transactions transactions min DTt 1 So instead having use upperbound Theorem 3 unavoidable transactions account use Theorem 2 offers tighter bound especially case unavoidable transactions Using reiﬁed discrimination constraint leads ﬁnegrained interaction search propagation similar reiﬁed frequency constraint Section 33 Excluding item itemset reducing domain DI 0 lead following propagation loop 1 Some transactions unavoidable changed DTt 1 2 DTt having changed reiﬁed discrimination constraints checked possibly constraint detects item longer included itemset items domain reduced DI 0 3 Return step 1 This propagation loop illustrated Fig 9 It absent traditional discriminative itemset miners use simple bound gI We experimentally verify beneﬁcial perform additional proposed propagation Section 7 6 Itemset mining costs In cases mining process yields large set patterns additional constraints reduce number patterns Several papers studied alternative constraints support constraint lead concepts monotonic antimonotonic convertible antimonotonic constraints The prime example concepts illustrated theory practice constraints cost weight associated item In section review constraints handled constraint programming approach 61 Problem deﬁnition Essentially item associated weight ci called cost3 item Let deﬁne total cost itemset cI cid4 ci iI Then interested ﬁnding itemsets high total cost 42119 Deﬁnition 9 Frequent itemset mining minimum total cost Given database D parameters θ γ frequent itemset mining problem minimum cost constraint problem ﬁnding itemsets cid8 I cid9 cid9 I I supportDI cid2 θ cI cid2 γ cid10 3 This terminology supermarket setting cost item price proﬁt 1970 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Similarly maximum cost constraints average cost constraints Deﬁnition 10 Frequent itemset mining maximum total cost Given database D parameters θ γ frequent itemset mining problem maximum cost constraint problem ﬁnding itemsets cid8 I cid9 cid9 I I supportDI cid2 θ cI cid3 γ cid10 Deﬁnition 11 Frequent itemset mining minimum average cost Given database D parameters θ γ frequent itemset mining problem minimum average cost constraint problem ﬁnding itemsets cid8 I cid9 cid9 I I supportDI cid2 θ cII cid2 γ cid10 Please note special case costbased itemset mining achieved ci 1 These constraints usually referred size constraints A minimum size constraint similar minimum support constraint deﬁned items transactions 62 Constraint programming model In analogy support constraint cost constraints expressed ways nonreiﬁed reiﬁed added usual support coverage constraints CP model Property 6 Nonreiﬁed minimum maximum total cost constraint Given database D itemset I threshold γ cI γ cid6 I ici γ cid5cid4 iI cid3 cid2 I 0 1 I 1 iff I 16 Property 7 Reiﬁed minimum maximum total cost constraint Given database D itemset I threshold γ supportDI cid2 1 cid5 cI γ Tt 1 cid6 I Dtici γ cid4 iI cid3 cid2 I 0 1 I 1 iff I Tt 1 iff t T 17 Proof This follows assumption coverage constraint hold Tt 1 know I 1 Dti 1 Because supportDI cid2 1 know transaction Tt 1 cid2 Average cost constraints expressed allowing negative coeﬃcients Property 8 Nonreiﬁed minimum maximum average cost constraint Given database D itemset I transaction set T cII γ cid5cid4 cid2 ci γ cid3 I cid6 0 iI cid3 cid8 cid2 I 0 1 I 1 iff I Proof This follows following observation cII γ cI γ I cid3 cid2 cI γ I 0 cid2 The reiﬁed average cost constraints obtained similar way reiﬁed total cost constraints 18 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1971 63 Comparison All specialized algorithms mining cost constraints exploit constraints properties similar antimonotonicity Deﬁnition 12 Monotonic constraints Assume given itemsets I1 I2 predicate pI D expressing constraint Then constraint monotonic iff I1 I2 pI1 D cid20 pI2 D Examples maximum support minimum cost constraints Different approaches proposed dealing monotonic constraints literature We discuss approaches separately time pointing relation models CP 631 Minimum total cost constraint simple approach The simplest depthﬁrst algorithms developed data mining community dealing monotonic constraints based observation supersets itemsets satisfying constraint satisfy constraint Hence depthﬁrst search procedure need check monotonic constraint children itemsets satisfying monotonic constraint 41 To emulate behavior CP check satisﬁability monotone constraint refrain possibly propagating variables This result branches search tree cut longer satisfy constraint constraint disabled longer violated 632 Minimum total cost constraint DualMinernonreiﬁed More advanced specialized DualMiner algorithm 11 DualMiner associates triplet Iin Icheck Iout node depthﬁrst search tree itemset miner Element Iin represents itemset node search tree corresponds Icheck Iout provide additional information search node Items Icheck currently included itemset added itemsets deeper search tree items projected database For items Iout clear longer added itemset deeper search tree Adding item Icheck Iin leads branch search tree An iterative procedure applied determine ﬁnal triplet Iin Icheck Iout new search node determine recursion continue checked set Iin satisﬁes antimonotonic constraints If stop checked individual items Icheck added Iin satisfy antimonotonic constraints Only satisfy constraints kept Icheck moved Iout checked set Iin Icheck satisﬁes monotonic constraints If stop Every item Icheck itemset Iin Ichecki satisfy monotonic constraints added Iin For instance total cost low certain item include item itemset Finally procedure iterated determine Iin satisﬁes antimonotonic constraints If loop reaches ﬁxed point items left Icheck search continues appears Iin Icheck satisﬁes antimonotonic constraints Iin satisﬁes monotonic constraints case sets Icheck I Iin Icheck immediately listed A similar search procedure obtained cost constraints formulated nonreiﬁed way CP As pointed earlier nonreiﬁed minimum maximum cost constraint takes following form cid4 I icI γ Propagation constraint following kind according current domains constraint satisﬁed CP includes minimum cost constraint excludes maximum cost constraint item corresponds moving item Iin Iout set DualMiner according current domains constraint longer satisﬁed backtrack according current domains constraint satisﬁed constraint removed constraint store Hence overall search strategy nonreiﬁed constraint similar DualMiner There differ ences DualMiner aim ﬁnding transaction set itemset If ﬁnds Iin satisﬁes monotonic constraint Iin Icheck satisﬁes antimonotonic constraint continue searching outputs corre sponding range itemsets explicitly implicitly The CP continue enumerating itemsets range order ﬁnd corresponding transaction sets explicitly 1972 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 633 Minimum total cost constraint FPBonsaireiﬁed In FPBonsai algorithm 8 idea iteration till ﬁxed point reached extended monotonic constraints The main observation algorithm based transaction satisfy minimum cost straints contain itemset satisﬁes minimum cost constraint Hence remove transactions consideration This reduce support items projected database result removal items database The reduction size transactions trigger new step propagation If consider reiﬁed minimum cost constraint Tt 1 cid4 I icIDti cid2 γ observe similar propagation Propagation essentially removes transaction consideration constraint longer satisﬁed transaction The removal transaction affect support items requiring propagators support constraints reevaluated Note reiﬁed constraint useful maximum total cost constraint cI cid3 γ Essentially trans action items included itemset considered If sum items large transaction removed consideration This happen transactions separately leading failed branch Overall propagation expensive evaluate needs transaction effective nonreiﬁed propagator prune items consideration instead failing Thus reiﬁed nonreiﬁed form complementary We obtain types propagation posting constraints types CP 634 Minimum maximum average cost constraints Average cost constraints monotonic antimonotonic Still property related monotonic antimonotonic constraints Deﬁnition 13 Convertible antimonotonic constraints Assume given itemsets I1 I2 predicate pI D express ing constraint order items Then constraint convertible antimonotonic order iff I1 I2 minI2 I1 cid2 maxI1 pI2 D cid20 pI1 D For example items ordered according increasing cost cI adding items expensive current items average cost increase For decreasing order item cost minimum average cost constraint convertible antimonotonic Different orderings result antimonotonic behavior adding expensive items item low cost added average cost Note conjunction maximum minimum cost constraints convertible antimonotonic need opposing orders constraints Essentially formalization CP average cost constraints similar total cost constraints main difference negative costs allowed Consequently depending constraint minimum maximum weight positive negative maximum value domain minimum value domain propagator In nonreiﬁed form obtain propagation items reiﬁed form transac tions This search strategy fundamentally different search strategy specialized mining systems property average cost constraint convertible antimonotonic Whereas specialized systems combi nation multiple convertible constraints poses problems CPbased approach combination straightforward 635 Conclusions Interestingly comparing models CP algorithms proposed data mining community similarities approaches The different approaches distinguished based represent reiﬁed nonreiﬁed constraint The main advantage constraint programming approach approaches easily combined This advantage evident combining convertible constraints specialized algorithms optimize constraint time 7 Experiments In previous sections concentrated conceptual differences traditional algorithms itemset mining constraint programming showed itemset mining modeled constraint programming In present section ﬁrst consider choices implementing itemset mining constraint program ming framework evaluate inﬂuence performance mining process More speciﬁcally answer following questions choices T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1973 Table 1 Properties datasets Dataset 1 Soybean 2 Splice1 3 Anneal 4 Mushroom transactions items Density 10 freq solutions 10 freq 630 3190 812 8124 59 290 41 119 025 021 043 019 63 319 81 812 12 754 1963 1 891 712 574 514 QA What difference performance reiﬁed versus nonreiﬁed constraints itemset mining QB What effect different variable orderings performance itemset mining Further technical dependent choices implementation explained Appendix A com pleteness reproducibility All implementations available website httpdtaicskuleuvenbeCP4IM We use best approach resulting experiments experimentally compare constraint program ming framework CP4IM stateoftheart itemset mining systems More speciﬁcally comparative experiments focus answering following questions Q1 What difference performance CP4IM frequent itemset mining traditional algorithms Q2 What difference performance CP4IM closed itemset mining traditional algorithms Q3 Is additional propagation CP4IM discriminative itemset mining beneﬁcial If Q4 Is alternative approach dealing convertible constraints CP4IM beneﬁcial If We ran experiments PCs Intel Core 2 Duo E6600 processors 4 GB RAM running Ubuntu Linux The experiments conducted Gecode constraint programming 25 Gecode4 open source constraint programming representative current stateoftheart eﬃcient constraint programming The starting point experiments Gecode version 220 In course experiments tried formulations implemented alternative propagators explained Appendix A included Gecode default 71 Data sets In experiments data UCI Machine Learning repository5 To deal missing values prepro cessed dataset way 16 ﬁrst eliminated attributes having 10 missing values removed examples transactions remaining attributes missing values Numerical attributes binarized unsupervised discretization 4 equalfrequency bins item attribute corresponds threshold bins These preprocessed datasets downloaded website6 The datasets basic properties Table 1 The density relative ones matrix In itemset problems higher density indicates dataset diﬃcult 72 Alternative itemset miners We following stateoftheart specialized algorithms implementations freely available basis comparative evaluation LCM LCM 51 specialized frequent closed itemset mining algorithm based tidlists Eclat Eclat 56 specialized depthﬁrst frequent itemset mining based tidlists Patternist Patternist 9 specialized breadthﬁrst algorithm mining monotonic antimonotonic constraints DDPMine DDPMine 13 specialized depthﬁrst closed discriminative itemset mining algorithm based fptrees repository closed itemsets uses tight bound bound summarized Section 5 38 Note experiments algorithms discussed previous sections The reason preferred use algorithms comparable implementations original authors freely available executable Linux machine Table 2 provides overview different tasks data mining systems support The LCM Eclat algorithms upgraded original authors support respectively frequent itemset mining closed itemset mining Patternist constraintbased mining algorithm carefully designed maximal use monotone 4 httpwwwgecodeorg 5 httparchiveicsucieduml 6 httpdtaicskuleuvenbeCP4IM 1974 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Table 2 Comparing mining tasks different miners support Frequent itemsets Closed itemsets Correlated itemsets Monotone constraints Convertible constraints Combinations CP4IM X X X X X X LCM X X Eclat X X Patternist DDPMine X X X X X X Not originally designed task X Combinations constraints supports multiple convertible constraints Table 3 Comparing reiﬁed versus nonreiﬁed formulation frequency constraint 2 datasets different frequencies The reiﬁed formulation failed branches Dataset Freq Nonreiﬁed frequency Reiﬁed frequency Mem Props Failures Time s Mem Props Time s Anneal Anneal Anneal Mushroom Mushroom Mushroom 5 10 15 5 10 15 2694 2438 2309 17 862 17 862 17 862 235 462 221 054 200 442 7 737 116 4 184 940 2 680 479 170 248 298 10 383 3376 1909 463 193 84 2695 742 408 2950 2501 2373 20 486 20 229 19 973 236 382 224 555 203 759 5 980 478 2 853 248 1 589 289 447 189 83 2398 434 105 Faster 104 102 101 112 171 389 convertible constraints search Our CP4IM supports constraints combinations constraints Furthermore thanks use declarative constraint programming easily extended types constraints This regard major advantage straint programming methodology It interesting contrast approach taken alternative procedural systems typically designed cope single constraint family later upgraded deal ones This upgrade usually involves changing algorithm dramatically hardcoding new constraint In contrast CP need add new propagator discrimination constraint corresponding constraint freely combined current future constraint This essentially difference declarative procedural approach On hand generality ﬂexibility price terms performance Therefore expect CP4IM perform task hope performance competitive averaging number tasks 73 QA nonreiﬁed vs reiﬁed In Section 33 argued reiﬁed frequency constraints standard frequent itemset mining problem lead propagation Table 3 shows comparison running CP model nonreiﬁed reiﬁed frequency constraints Two datasets different frequency thresholds For reasonably small anneal dataset noted nonreiﬁed version needs bit memory propagation cost failed branches search tree This leads small increase run time For bigger mushroom dataset difference larger For higher minimum frequency thresholds reiﬁed pruning stronger nonreiﬁed formulation cost failed branch increases leading larger difference runtime In general observed reiﬁed frequency constraints leads better performance especially larger datasets 74 QB variable ordering In constraint programming known order variables searched large impact size search tree eﬃciency search This received lot attention itemset mining community algorithms like fpgrowth good ordering needed fptree size We consider possible variable ordering strategies standard frequent itemset mining problem input order variables arbitrary minimum degree maximum degree variable occurring smallest number propagators variable occurring largest number propagators The comparison variable orderings Table 4 The experiments choosing variable maximum degree leads large reduction number propagations runtime The maximum degree heuris T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1975 Table 4 Comparison peak memory number propagations time seconds different variable ordering heuristics 4 datasets listed Table 1 Arbitrary Mem 1860 124 431 2116 31 236 1 2 3 4 Minimum degree Maximum degree Props 799 791 3 188 139 121 495 848 344 377 153 Time 05 49 73 365 Mem 1540 126 927 2116 30 148 Props 3 861 055 3 772 591 472 448 674 997 905 725 Time 31 60 374 1504 Mem 1860 122 511 1796 26 244 Props 137 666 2 602 069 577 719 6 232 932 Time 02 41 18 48 Fig 10 Standard itemset mining different datasets For interpretation references color ﬁgure reader referred web version article Fig 11 Closed itemset mining different datasets tic corresponds choosing item lowest frequency item occurs coverage constraint Eq 7 transactions In words eﬃcient variable ordering strategy failﬁrst strategy explores unlikely branches search tree ﬁrst Such conclusion surprising constraint programming commu nity 75 Q1 frequent itemset mining A comparison specialized frequent itemset miners CP4IM provided Fig 10 representative number datasets In ﬁgure run times different support thresholds previously differences systems highly depend constraint 27 The run time systems correlated number patterns red line Our CP4IM model implemented Gecode indicated FIM_CP signiﬁcantly slower depthﬁrst miners shows similar behavior This indicates search strategy similar use alternative data structures overhead straint programming introduces lot overhead standard frequent itemset mining It remarkable CP4IM compares breadthﬁrst Patternist use concept projected databases pervasively systems compact representations developed specialized itemset miners projected databases explain performance difference 1976 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Table 5 Statistics UCI datasets runtimes seconds CP models systems Name Anneal Australiancr Breastwisc Diabetes Germancr Heartclevel Hypothyroid Ionosphere krvskp Letter Mushroom Pendigits Primarytum Segment Soybean Splice1 Vehicle Yeast Dense 045 041 050 050 034 047 049 050 049 050 018 050 048 050 032 021 050 049 Trans 812 653 683 768 1000 296 3247 351 3196 20 000 8124 7494 336 2310 630 3190 846 1484 76 Q2 closed itemset mining Item CP4IM4 CP4IM2 ddpmine 14 lcm 51 93 125 120 112 112 95 88 445 73 224 119 216 31 235 50 287 252 89 022 030 028 245 239 019 071 144 092 5266 1411 368 003 145 005 3041 085 567 2409 063 1366 12804 6679 215 1091 4620 1348 013 007 3111 78163 2246 340 9675 949 12560 009 026 005 186 792 122 2749 69712 3084 287 2562 003 008 002 002 18528 In Fig 11 runtime mining algorithms shown problem closed itemset mining Again run time correlated number patterns The difference CP4IM miners smaller exper iment We argued previous section CP behaves similar LCM Indeed experiments mushroom letter data set case case outperforming Eclat originally developed closed itemset mining It noted sparse data mushroom difference performance Gecode specialized systems larger dense data letter data This explained ineﬃcient representation sparse data Gecode dense data compared Eclat ineﬃcient representation compensated effective propagation 77 Q3 discriminative closed itemset mining In experiment compare approaches ﬁnding discriminative itemset given labeled data Results shown Table 5 As setting determine threshold parameter perform experiments larger number datasets The missing values datasets preprocessed way previous experiments However numerical attributes binarized unsupervised discretization 7 binary split points 8 equalfrequency bins This enforces language bias patterns closer rule learning subgroup discovery systems 28 In case nonbinary class label largest class labeled positive negative The properties datasets summarized Table 5 note higher density datasets previous experiments resulting discretization procedure We report types experiments CP4IM propagator introduced Section 52 CP4IM4 propagator mimics propagation occurring specialized discriminative itemset miner introduced 35 CP4IM2 Furthermore apply LCM algorithm 38 shown wellchosen support thresholds resulting set frequent itemsets guaranteed contain itemsets exceeding correlation threshold We use correlation threshold best pattern algorithm compute support threshold according method run LCM support threshold Note providing LCM knowledge best pattern comparison unfair advantage LCM For experiments marked table solution 900 seconds In experiments marked repository closed itemsets runs memory The experiment shows CP4IM4 consistently outperforms exist ing data mining systems cases increased performance attributed improved propagation revealed CP4IM4 It noted dataset mushroom dataset new propagator takes slightly time Our hypothesis related low density data 4bound pruning effective structure data lead unavoidable transactions To test hypothesis performed additional exper iments gradually sparsiﬁed dense datasets given Fig 12 The sparsiﬁcation performed randomly removing items uniformly transaction database predeﬁned sparsity threshold reached Averaging run times 10 different samples setting ran CP4IM different propagators CP4IM4 CP4IM2 explained CP4IM1 uses simple frequency based propagator 14 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1977 Fig 12 Correlated itemset mining sparsifying data Fig 13 Runtimes itemset miners Segment data constraints In left ﬁgure suﬃx _m25 _m30 indicates minimum size threshold In right ﬁgure suﬃx _1 represent minimum support threshold The experiments density decreased sampling removes structure data advantage advanced pruning method simple ones disappears However CP framework 4bound method better worse equivalent 2 1bound pruning 78 Q4 costbased itemset mining In experiment determine CP4IM compares systems additional cost constraints em ployed Results settings given Fig 13 indicated FIM_CP In ﬁrst experiment employed monotonic minimum size constraint addition minimum frequency constraint second vertible maximum average cost constraint The results positive small minimum size constraints brute force mining algorithms LCM outperform CP4IM CP4IM search effectively constraint selects small number large itemsets 30 items extreme cases CP4IM ﬁnishes seconds algorithms ﬁnish cutoff time 30 minutes Patternist breadthﬁrst algorithm unable ﬁnish experiments memory problems This indicates CP4IM competitive constraints require discovery small number large itemsets The results convertible constraints particularly promising optimize item order experiments usually dealing convertible constraints 8 Conclusions We started paper raising question constraint programming solving itemset mining problems declarative way Our results answer question positive use constraint programming offers advantages new insights Perhaps important advantage constraint programming systems general purpose systems supporting different types constraints In regard showed possible incorporate wellknown constraints cost constraints closedness discriminative measures deﬁned combinations constraint programming The advantage resulting declarative approach data mining easy extend change order accommodate new constraints constraints automatically combined Furthermore detailed analysis solution strategy constraint programming systems showed similarities systems specialized itemset mining systems Therefore constraint programming arguably generalizes systems 1978 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 theoretical perspective practical This conﬁrmed experiments problems frequent closed itemset mining fast implementation contests organized specialized systems usually outperform CP4IM runtime behavior constraint programming approach similar specialized systems The potential CP approach performance perspective demonstrated problem discriminative itemset mining We showed rigorously principles constraint programming effective propagation obtained alternative stateoftheart data mining algorithms This conﬁrms useful itemset mining context propagation guiding principle In regard interesting investigate use alternative search strategies developed constraint programming community 5344 Continuing research currently studying application approach problems arising bioinformatics For instance itemset mining commonly applied analysis microarray data hope constraint programming offer general ﬂexible approach analyze data Whereas work restricted discovery patterns binary data use constraint programming pattern mining related problems promising direction future research A problem closely related pattern mining pattern set mining 19 impose constraints individual patterns overall set patterns constituting solution 29 Constraints imposed include instance requirement patterns overlap cover complete set transactions Another related problem ﬁnding patterns continuous data This requirement particular relevant deal problems bioinformatics Likewise approaches mining structured data sequences trees graphs It interesting open question possible represent problems constraint programming One challenges structured data longer represented ﬁxed number features variables In addition pattern mining areas machine learning data mining proﬁt closer study constraint programming techniques One area statistical machine learning problems typically formulated mathematical programming Recently results use types solvers obtained certain probabilistic models 1215 In approaches Integer Linear Programming ILP satisﬁability SAT solvers CP solvers address general class problems ILP SAT solvers generality comes computational cost Current developments CP aim combining ILP SAT CP help addressing machine learning problems Other topics constraintbased clustering constraintbased classiﬁer induction In constraintbased clus tering challenge cluster examples additional knowledge available examples instance prohibiting certain examples clustered socalled cannotlink constraints Similarly constraintbased classiﬁer induction wish ﬁnd decision tree satisﬁes size costconstraints A ﬁrst study applica tion CP problem recently performed Bessiere Hebrard OSullivan 7 In data mining relationship itemset mining constraintbased decision tree learning studied 36 It open question relation exploited constraint programming setting Whereas previous cases study data mining proﬁt constraint programming opposite direction topic constraint programming systems extended techniques data mining For example constraint programming systems data typically spread constraints possibly multiple times different ways In contrast data mining data typically centrally accessed allowing use different matrix representations To summarize believe integration machine learning data mining constraint programming beneﬁcial areas Acknowledgements This work supported Postdoc project grant Research FoundationFlanders project Principles Patternset Mining grant Institute Promotion Innovation Science Technology Flanders IWTVlaanderen Appendix A Improved solving continued In Section 7 empirically studied effect nonreiﬁed versus reiﬁed formulations different variable ordering heuristics In appendix include additional ﬁndings experienced making right lowlevel decisions necessary competitive highly optimized itemset mining implementations We start studying differences boolean variables integers domain 0 1 We continue studying imple mentation alternatives essential constraint shared models coverage constraint We end comparison different value ordering heuristics explain improve results provide additional details Gecode Apart Gecode speciﬁc remarks applicable solvers copying cloning results pre sented appendix valid applicable solvers In fact parts work studied default aforementioned Gecode T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1979 Table A6 Comparison propagations peak memory time seconds boolean variables respective constraints versus integer variables constraints Dataset Original boolean Peak mem props 1 Soybean 2 Splice1 3 Anneal 4 Mushroom 2820 147 280 3140 45 636 5 909 592 23 708 807 1 121 904 924 2 989 128 466 Time 14 129 279 1447 Integers Peak mem props 2436 142 032 2564 39 940 1 839 932 9 072 323 273 248 618 862 480 847 Time 08 57 136 508 Gain 17 23 21 29 Table A7 Comparison propagations peak memory time seconds channeled integer formulation base model boolean formulation dedicated propagator Dataset Integers Peak mem props 1 Soybean 2 Splice1 3 Anneal 4 Mushroom 2436 142 032 2564 39 940 1 839 932 9 072 323 273 248 618 862 480 847 Time 08 57 136 508 Dedicated boolean Peak mem props 1796 123 279 2500 30 852 1 058 238 6 098 820 121 495 848 520 928 196 Time 05 68 74 387 Gain 16 08 18 13 A1 Booleans vs integers Finite domain integer solvers choose represent boolean integer domain 0 1 implement speciﬁc boolean variable An essential constraint models reiﬁed summation constraint Such sum expressed boolean integer variables reiﬁcation variable boolean domain Using boolean variables equally eﬃcient integer variables especially model integer variables need channeled boolean variables use reiﬁcation However experiments Table A6 model booleans slower integers The reason given reiﬁed summation constraint booleans B boolean variable C cid4 B cid2 v C cid7 decomposed constraints S B S cid2 v C S additional integer variable separate prop agators constraints For integers hand single propagator available Our experiments decomposing reiﬁed sum constraints booleans sum booleans reifying integer variable beneﬁcial We implemented dedicated propagator reiﬁed sum boolean variables constraint includes optimization inspired SAT solvers 26 A propagator said watch variables depends A propagator activated domain watched variables changes To improve eﬃciency number watched variables i1 B cid2 v C B C boolean variables larger necessary Assume sum suﬃcient watch maxv n v 1 arbitrary variables B ﬁxed propagator succeed v variables true fail n v 1 variables false assigning watched variables In Table A7 compare formulation basic frequent itemset mining problem integers channeling boolean variables new dedicated propagator The peak memory needed booleans naturally lower The propagations decreased signiﬁcantly leading lower runtimes dataset Hence overall recommended use boolean variables dedicated propagators cid7 n A2 Coverage constraint propagators versus advisers When variables domain changes propagators watch variable called different amounts information To adopt terminology Gecode differentiate classic propagators advisers propagators domain variable changes entire propagator activated reevaluated advisers domain variable changes adviser activated informed new domain variable When adviser detects propagation happen activate propagator Both techniques advantages disadvantages classic propagators conceptually simpler need iterate variables activated advisers ﬁnegrained require bookkeeping We implemented coverage constraint techniques compare Table A8 Using advisers requires memory reduces overall propagations runtimes decrease 1980 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 Table A8 Comparison propagations peak memory time seconds formulating coverage constraints new reiﬁed sum constraint advisor version new reiﬁed sum constraint clause constraint Boolean sum Boolean sum advisers Clause advisers Mem 1796 123 279 2500 30 852 props 1 058 238 6 098 820 121 495 848 520 928 196 1 2 3 4 Time 05 68 74 387 Mem 2500 237 071 2500 47 172 props 799 791 3 188 139 121 495 848 344 377 153 Time 05 54 73 372 Mem 1860 124 431 2116 31 236 props 799 791 3 188 139 121 495 848 344 377 153 Time 05 49 73 365 Table A9 Comparison peak memory propagations time seconds minimum maximum value ordering heuristics frequent itemset mining problem Dataset 1 Soybean 2 Splice1 3 Anneal 4 Mushroom Minimum value Maximum value Mem 1860 122 511 1796 26 244 Props 137 666 2 602 069 577 719 6 232 932 Time 02 41 18 48 Mem 899 16 328 1412 20 229 Props 217 802 4 961 137 726 308 9 989 882 Time 03 109 18 63 Fig A14 Search tree ﬁrst 35 variables mushroom dataset Every blue circle branchpoint item green diamond solution A branch left assigned 0 item branchpoint branch right assigned 1 For interpretation references color ﬁgure legend reader referred web version article A3 Coverage constraint clauses vs sums As pointed Property 1 Eqs 7 8 page 1957 coverage constraint expressed equivalent ways reiﬁed sums reiﬁed clauses Both options evaluated Table A8 Overall ﬁnd formulation clauses performs best A4 Value ordering For boolean decision variables value ordering heuristics meaningful selecting minimum value 0 select ing maximum value 1 ﬁrst A comparison Table A9 maximum degree variable ordering The results surprising maximum value heuristic leads propagation longer run times This counterintuitive search tree equally large cases complete tree searched total propagation identical The explanation Gecode stores intermediate states search Gecode uses technique called copying recomputation 46 In technique nodes necessarily nodes depthﬁrst search tree copied stored To backtrack retrieves latest copied node recomputes propagations assignments leading desired node This save memory consumption runtime large problems 46 The copyingrecomputation set copy distance parameter In Gecode default 8 meaning new copy 8 nodes When consider search tree minimum value ﬁrst heuristic models Fig A14 variables set zero ﬁrst creating long branch The copied nodes branch reused rest search When maximum value heuristic propagation possible shorter branches explored ﬁrst Consequently nodes copied lot recomputation needs short branches In experiments results increased overhead Table A10 compares values copy distance parameter inﬂuences value ordering heuristic With distance 0 node search tree copied This results smaller propagation compared distance 8 independent value ordering heuristic Interestingly runtime decreased compared larger copy distance Using maximum value ﬁrst heuristic fast minimum value heuristic T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1981 Table A10 Comparison peak memory propagations time seconds minimum maximum value ordering heuristics The copy distance default cd 8 zero cd 0 Minimum cd 8 Minimum cd 0 Maximum cd 0 Mem 1860 122 511 1796 26 244 Props 137 666 2 602 069 577 719 6 232 932 1 2 3 4 Time 02 41 18 48 Mem 7626 911 863 4231 148 173 Props 64 823 1 822 064 224 555 2 853 248 Time 02 24 19 43 Mem 1796 16 328 2501 20 229 Props 64 823 1 822 064 224 555 2 853 248 Time 02 23 19 43 Fig A15 Relative improvements applying heuristics needs signiﬁcantly memory For application faster memory intensive clone node search tree choose maximum value ﬁrst A5 Summary An overview relative improvements step Fig A15 Overall initial model reiﬁed constraints speciﬁed straightforwardly scalability approach highly depended making right lowlevel decisions discussed section Only modeling process CPbased approach competitive current specialized systems constraintbased itemset mining References 1 Rakesh Agrawal Tomasz Imielinski Arun N Swami Mining association rules sets items large databases Proceedings ACM SIGMOD International Conference Management Data ACM Press 1993 pp 207216 2 Rakesh Agrawal Hiekki Mannila Ramakrishnan Srikant Hannu Toivonen A Inkeri Verkamo Fast discovery association rules Advances Knowl edge Discovery Data Mining AAAI Press 1996 pp 307328 3 Krzysztof R Apt Mark Wallace Constraint Logic Programming Using Eclipse Cambridge University Press New York NY USA 2007 4 Stephen D Bay Michael J Pazzani Detecting change categorical data mining contrast sets Proceedings Fifth International Conference Knowledge Discovery Data Mining ACM Press 1999 pp 302306 5 Roberto J Bayardo Jr Rakesh Agrawal Dimitrios Gunopulos Constraintbased rule mining large dense databases Data Mining Knowledge Discovery 4 23 2000 217240 6 Nicolas Beldiceanu Mats Carlsson Sophie Demassey Thierry Petit Global constraint catalogue past present future Constraints 12 March 2007 2162 7 Christian Bessiere Emmanuel Hebrard Barry OSullivan Minimising decision tree size combinatorial optimisation Principles Practice Constraint Programming Lecture Notes Computer Science vol 5732 Springer 2009 pp 173187 8 Francesco Bonchi Bart Goethals FPbonsai art growing pruning small fptrees Advances Knowledge Discovery Data Mining Lecture Notes Computer Science vol 3056 Springer 2004 pp 155160 9 Francesco Bonchi Claudio Lucchese Extending stateoftheart constraintbased pattern discovery Data Knowledge Engineering 60 2 2007 377399 10 Sally C Brailsford Chris N Potts Barbara M Smith Constraint satisfaction problems algorithms applications European Journal Operational Research 119 3 1999 557581 11 Cristian Bucila Johannes Gehrke Daniel Kifer Walker M White DualMiner dualpruning algorithm itemsets constraints Data Mining Knowledge Discovery 7 3 2003 241272 12 MingWei Chang LevArie Ratinov Nicholas Rizzolo Dan Roth Learning inference constraints Proceedings TwentyThird AAAI Conference Artiﬁcial Intelligence AAAI Press 2008 pp 15131518 13 Hong Cheng Yan Xifeng Jiawei Han ChihWei Hsu Discriminative frequent pattern analysis effective classiﬁcation Proceedings 23rd International Conference Data Engineering IEEE 2007 pp 716725 14 Hong Cheng Yan Xifeng Jiawei Han PS Yu Direct discriminative pattern mining effective classiﬁcation Proceedings 24th International Conference Data Engineering IEEE 2008 pp 169178 15 James Cussens Bayesian network learning compiling weighted maxsat Proceedings 24th Conference Uncertainty Artiﬁcial Intelligence AUAI Press 2008 pp 105112 1982 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 16 Luc De Raedt Tias Guns Siegfried Nijssen Constraint programming itemset mining Proceeding 14th ACM SIGKDD International Confer ence Knowledge Discovery Data Mining ACM 2008 pp 204212 17 Luc De Raedt Tias Guns Siegfried Nijssen Constraint programming data mining machine learning Proceedings TwentyFourth AAAI Conference Artiﬁcial Intelligence AAAI Press 2010 pp 15131518 18 Luc De Raedt Stefan Kramer The levelwise version space algorithm application molecular fragment ﬁnding Proceedings Seven teenth International Joint Conference Artiﬁcial Intelligence Morgan Kaufmann 2001 pp 853862 19 Luc De Raedt Albrecht Zimmermann Constraintbased pattern set mining Proceedings Seventh SIAM International Conference Data Mining SIAM 2007 pp 112 20 Guozhu Dong Jinyan Li Eﬃcient mining emerging patterns discovering trends differences Proceedings Fifth International Conference Knowledge Discovery Data Mining ACM Press 1999 pp 4352 21 Wei Fan Kun Zhang Hong Cheng Jing Gao Yan Xifeng Jiawei Han Philip S Yu Olivier Verscheure Direct mining discriminative essential frequent patterns modelbased search tree Proceedings 14th ACM SIGKDD International Conference Knowledge Discovery Data Mining ACM 2008 pp 230238 22 Alan M Frisch Matthew Grum Christopher Jefferson Bernadette Martínez Hernández Ian Miguel The design essence constraint language specifying combinatorial problems Proceedings 20th International Joint Conference Artiﬁcial Intelligence Morgan Kaufmann 2007 pp 8087 23 Johannes Fürnkranz Peter A Flach ROC n rule learning better understanding covering algorithms Machine Learning 58 1 2005 3977 24 Bernhard Ganter Gerd Stumme Rudolf Wille Eds Formal Concept Analysis Foundations Applications Lecture Notes Computer Science vol 3626 Springer 2005 25 Gecode Team httpwwwgecodeorg 26 Ian P Gent Christopher Jefferson Ian Miguel MINION fast scalable constraint solver Proceeding 17th European Conference Artiﬁcial Intelligence IOS Press 2006 pp 98102 27 Bart Goethals Mohammed J Zaki Advances frequent itemset mining implementations report FIMI03 SIGKDD Explorations Newsletter vol 6 2004 pp 109117 28 Henrik Grosskreutz Stefan Rüping Stefan Wrobel Tight optimistic estimates fast subgroup discovery Machine Learning Knowledge Discov ery Databases Lecture Notes Computer Science vol 5211 Springer 2008 pp 440456 29 Tias Guns Siegfried Nijssen Luc De Raedt kPattern set mining constraints CW Reports CW596 Department Computer Science KU Leuven October 2010 30 J Han J Pei Y Yin Mining frequent patterns candidate generation Proceedings ACM SIGMOD International Conference Manage ment Data ACM Press 2000 pp 112 31 Jiawei Han Hong Cheng Dong Xin Xifeng Yan Frequent pattern mining current status future directions Data Mining Knowledge Discov ery 15 1 2007 5586 32 Branko Kavsek Nada Lavrac Viktor Jovanoski APRIORISD adapting association rule learning subgroup discovery Advances Intelligent Data Analysis Lecture Notes Computer Science vol 2810 Springer 2003 pp 230241 33 Heikki Mannila Hannu Toivonen Levelwise search borders theories knowledge discovery Data Mining Knowledge Discovery 1 3 1997 241258 34 Yasuhiko Morimoto Takeshi Fukuda Hirofumi Matsuzawa Takeshi Tokuyama Kunikazu Yoda Algorithms mining association rules binary segmentations huge categorical databases Proceedings 24rd International Conference Very Large Data Bases Morgan Kaufmann 1998 pp 380391 35 Shinichi Morishita Jun Sese Traversing itemset lattice statistical metric pruning Proceedings Nineteenth ACM SIGMODSIGACTSIGART Symposium Principles Database Systems ACM 2000 pp 226236 36 Siegfried Nijssen Élisa Fromont Optimal constraintbased decision tree induction itemset lattices Data Mining Knowledge Discovery 21 1 2010 951 37 Siegfried Nijssen Tias Guns Integrating constraint programming itemset mining Machine Learning Knowledge Discovery Databases Lecture Notes Computer Science vol 6322 Springer 2010 pp 467482 38 Siegfried Nijssen Tias Guns Luc De Raedt Correlated itemset mining ROC space constraint programming approach Proceedings 15th ACM SIGKDD International Conference Knowledge Discovery Data Mining ACM 2009 pp 647656 39 Siegfried Nijssen Joost N Kok Multiclass correlated pattern mining Knowledge Discovery Inductive Databases Lecture Notes Computer Science vol 3933 Springer 2005 pp 165187 40 Nicolas Pasquier Yves Bastide Raﬁk Taouil Lotﬁ Lakhal Discovering frequent closed itemsets association rules Database Theory Lecture Notes Computer Science vol 1540 Springer 1999 pp 398416 41 Jian Pei Jiawei Han Can push constraints frequent pattern mining Proceedings sixth ACM SIGKDD International Conference Knowledge Discovery Data Mining ACM 2000 pp 350354 42 Jian Pei Jiawei Han Laks VS Lakshmanan Mining frequent item sets convertible constraints Proceedings IEEE International Conference Data Engineering IEEE 2001 pp 433442 43 Jian Pei Jiawei Han Runying Mao Closet eﬃcient algorithm mining frequent closed itemsets ACM SIGMOD Workshop Research Issues Data Mining Knowledge Discovery ACM 2000 pp 2130 44 Laurent Perron Search procedures parallelism constraint programming Principles Practice Constraint Programming Lecture Notes Computer Science vol 1713 Springer 1999 pp 346360 45 Francesca Rossi Peter van Beek Toby Walsh Handbook Constraint Programming Foundations Artiﬁcial Intelligence Elsevier Science Inc 2006 46 Christian Schulte Programming Constraint Services HighLevel Programming Standard New Constraint Services Lecture Notes Computer Science vol 2302 Springer 2002 47 Christian Schulte Peter J Stuckey Eﬃcient constraint propagation engines Transactions Programming Languages Systems 31 1 2008 143 48 Jun Sese Shinichi Morishita Answering correlated n association rules eﬃciently Principles Data Mining Knowledge Discovery Lecture Notes Computer Science vol 2431 Springer 2002 pp 410422 49 Pradeep Shenoy Jayant R Haritsa S Sudarshan Gaurav Bhalotia Mayank Bawa Shah Devavrat Turbocharging vertical mining large databases Proceedings 2000 ACM SIGMOD International Conference Management Data ACM 2000 pp 2233 50 Arnaud Soulet Bruno Crømilleux An eﬃcient framework mining ﬂexible constraints Advances Knowledge Discovery Data Mining Lecture Notes Computer Science vol 3518 Springer 2005 pp 4364 51 Takeaki Uno Masashi Kiyomi Hiroki Arimura LCM ver3 collaboration array bitmap preﬁx tree frequent itemset mining Proceedings 1st International Workshop Open Source Data Mining ACM 2005 pp 7786 52 Pascal Van Hentenryck Yves Deville The Cardinality Operator A New Logical Connective Constraint Logic Programming MIT Press Cambridge MA USA 1993 pp 383403 T Guns et al Artiﬁcial Intelligence 175 2011 19511983 1983 53 Pascal Van Hentenryck Laurent Perron JeanFrancois Puget Search strategies OPL ACM Transations Computational Logic 1 2 2000 285320 54 Pascal Van Hentenryck Vijay A Saraswat Yves Deville Design implementation evaluation constraint language ccFD Journal Logic Programming 37 13 1998 139164 55 Stefan Wrobel An algorithm multirelational discovery subgroups Principles Data Mining Knowledge Discovery Lecture Notes Computer Science vol 1263 Springer 1997 pp 7887 56 Mohammed Javeed Zaki Karam Gouda Fast vertical mining diffsets Proceedings Ninth ACM SIGKDD International Conference Knowledge Discovery Data Mining ACM 2003 pp 326335