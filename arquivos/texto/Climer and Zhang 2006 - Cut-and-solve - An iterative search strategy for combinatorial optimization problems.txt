Artiﬁcial Intelligence 170 2006 714738 wwwelseviercomlocateartint Cutandsolve An iterative search strategy combinatorial optimization problems Sharlee Climer Weixiong Zhang Department Computer Science Engineering Washington University One Brookings Drive St Louis MO 631304899 USA Received 26 August 2005 received revised form 13 February 2006 accepted 23 February 2006 Available online 17 April 2006 Abstract Branchandbound branchandcut use search trees identify optimal solutions combinatorial optimization problems In paper introduce iterative search strategy refer cutandsolve prove optimality termination method This search different traditional tree search branching At node search path relaxed problem sparse problem solved constraint added relaxed problem The sparse problems provide incumbent solutions When constraining relaxed problem tight solution value better incumbent solution value At point incumbent solution declared optimal This strategy easily adapted anytime algorithm incumbent solution root node continuously updated search Cutandsolve enjoys favorable properties Since branching wrong subtrees search lost Furthermore memory requirement negligible For reasons potential problems difﬁcult solve depthﬁrst bestﬁrst search tree methods In paper demonstrate cutandsolve strategy implementing generic version Asymmetric Traveling Salesman Problem ATSP Our unoptimized implementation outperformed stateoftheart solvers ﬁve seven realworld problem classes ATSP For classes cutandsolve able solve larger substantially larger problems Our code available websites 2006 Published Elsevier BV Keywords Search strategies Branchandbound Branchandcut Anytime algorithms Linear programming Traveling Salesman Problem 1 Introduction Life optimization problems We constantly searching ways minimize cost time energy valuable resource maximize performance proﬁt production desirable goal satisfying constraints imposed Optimization problems interesting frequently large number feasible solutions satisfy constraints challenge lies searching vast solution space identifying optimal solution When number solutions large explicitly look search strategies branchandbound 4 branchandcut 28 exceptionally useful Corresponding author Email addresses sharleeclimerus S Climer zhangcsewustledu W Zhang 00043702 matter 2006 Published Elsevier BV doi101016jartint200602005 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 715 Branchandbound uses search tree pinpoint optimal solution Note optimal solution If entire tree generated feasible solution represented leaf node The search tree traversed relaxed variation original problem solved node When solution relaxed subproblem feasible solution original problem incumbent solution As solutions type incumbent updated needed retain best feasible solution far When search tree exhausted current incumbent returned optimal solution If number solutions large allow explicitly looking search tree large completely explored The power branchandbound comes pruning rules allow pruning entire subtrees guaranteeing optimality If search tree pruned adequately small size problem solved optimality Branchandcut improves branchandbound increasing probability pruning At nodes cutting planes 28 added tighten relaxed subproblem These cutting planes remove set solutions relaxed subproblem However order ensure optimality cutting planes designed exclude feasible solutions current unrelaxed subproblem While adding cutting planes substantially increase time spent node cuts dramatically reduce size search tree solve great number problems previously insoluble Branchandbound branchandcut typically implemented depthﬁrst fashion linear space requirement favorable features 49 However depthﬁrst search suffer problem exploring subtrees optimal solution resulting large search cost A wrong choice subtree explore early stage depthﬁrst search usually difﬁcult rectify The Artiﬁcial Intelligence community invested great deal effort addressing issue Branching techniques 4 heuristics investigations 42 search techniques limited discrepancy 24 randomization restarts 19 developed effort combat persistent problem In paper introduce iterative search strategy overcomes problem making wrong choices depthﬁrst branchandbound keeping memory requirements nominal We refer search strategy cutandsolve demonstrate integer linear programs Being iterative strategy search tree search path directly traversed In words child node need choose child traverse At node search path relatively easy subproblems solved First relaxed solution Then sparse problem solved Instead searching optimal solution vast solution space containing feasible solution sparse solution space searched An incumbent solution ﬁrst node updated needed subsequent nodes When search terminates current incumbent solution guaranteed optimal solution In paper prove optimality termination cutandsolve strategy The paper organized follows In section branchandbound branchandcut discussed greater In following section cutandsolve strategy described compared prevalent techniques Next illustrate strategy applying simple linear programming problem Then generic procedure cutandsolve presented This generic procedure demonstrated implementing algorithm Asymmetric Traveling Salesman Problem ATSP The ATSP NPhard problem ﬁnding minimum cost Hamiltonian cycle set cities cost city city j necessarily equal cost city j city We tested preliminary unoptimized implementation algorithm compared branchandbound branchandcut solvers Our tests cutandsolve fast stateoftheart solvers relatively simple problem instances However faster solvers largest instances ﬁve seven realworld problem classes solves larger substantially larger instances classes This paper concluded discussion technique related work A preliminary version paper appeared 11 2 Background In section deﬁne terms branchandbound branchandcut greater Asymmetric Traveling Salesman Problem ATSP example 716 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Branchandbound branchandcut solve variety optimization problems The method present paper applied problem However discussion concrete narrow focus integer linear programs IPs An IP optimization problem subject set linear constraints IPs model wide variety problems including Traveling Salesman Problems TSP 2236 Constraint Satisfaction Problems CSP 15 network optimization problems 45 Moreover wealth problems cast general problems TSP applications include vast number scheduling routing planning problems nowait ﬂowshop stacker crane tilted drilling machine disk read head robotic motion pay phone coin collection problems 30 Furthermore TSP model surprisingly diverse problems shortest common superstring problem genetics research CSPs model conﬁguration design diagnosis spatiotemporal reasoning resource allocation graphical interfaces scheduling problems 15 Finally examples network optimization problems include delaytolerant network routing cellular radio network base station locations minimumenergy multicast problem wireless ad hoc networks There exist interesting research problems cast IPs virtually ﬁeld science Furthermore staggering number commercial applications cast IPs A general IP written following form Z min max cid2 cixi subject set linear constraints xi I 1 2 3 ci values instancespeciﬁc constants set xi represents decision variables Constraints 2 linear equalities inequalities composed constants decision variables possibly auxiliary variables Constraints 3 enforce integrality decision variables A feasible solution satisﬁes constraints 2 3 The set feasible solutions solution space SS problem The solution space deﬁned given problem In contrast search space deﬁned algorithm solve problem An optimal solution feasible solution greatest value deﬁned objective function 1 Linear programs LPs similar IPs allow real numbers decision variables A general LP form general IP given omission constraints 3 LPs solved polynomial time ellipsoid method 33 However practice simplex method 13 commonly despite exponential worstcase running time 31 The simplex algorithm moves edges polyhedron deﬁned constraints direction improves solution Usually approach effective In contrast IPs solved polynomial time worst case For example ATSP NPhard problem deﬁned following IP cid3cid2 cid2 cid4 ATSPG min cij xij iV j V subject cid2 xij 1 j V iV cid2 xij 1 V j V cid2 cid2 xij cid2 W 1 W V W cid6 4 5 6 7 iW j W xij 0 1 j V 8 directed graph G V A vertex set V 1 n n number cities arc set A j j 1 n cost matrix cnn cij cid3 0 cii j V Each decision variable xij corresponds arc j graph Constraints 8 require arc j traversed xij equal 1 traversed xij equal 0 Constraints 5 6 require city entered exactly departed exactly Constraints 7 called subtour elimination constraints SECs require S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 717 cycle exist solution Note exponential number SECs It common practice initially omit constraints add necessary problem solved Finally objective function 4 requires sum costs traversed arcs minimized In problem solution space set permutations cities contains n 1 distinct solutions 21 Using bounds Without loss generality discuss minimization problems remainder paper An IP relaxed relaxing constraints This relaxation lowerbounding modiﬁcation optimal solution relaxation exceed optimal solution original problem Furthermore solution space relaxed problem SSr contains entire solution space original problem SSo converse necessarily true An IP tightened tightening constraints adding additional constraints This tightening upperbounding modiﬁcation optimal solution tightened problem smaller value optimal solution original problem Furthermore solution space original problem SSo contains solution space tightened problem SSt converse necessarily true In summary SSt SSo SSr For example ATSP relaxed completely omitting constraints 7 This relaxation allows number subtours exist solution This relaxed problem simply Assignment Problem AP 39 The AP problem ﬁnding minimumcost matching bipartite graph constructed including arcs nodes city node tail outgoing arcs head incoming arcs Fig 1 depicts solution AP relaxation 49city symmetric TSP STSP STSPs special class cost city city j equal cost city j city cities j Another relaxation realized relaxing integrality requirement constraints 8 This accom plished replacing constraints 8 following constraints 0 cid2 xij cid2 1 j V 9 This relaxation transforms IP LP referred HeldKarp relaxation 2526 Fig 2 depicts solution HeldKarp relaxation 49city STSP At ﬁrst glance appears subtour elimination constraints violated However constraints 7 violated fact xij variables values One way ATSP tightened adding constraints set values selected decision variables For example adding xij 1 forces arc j included solutions Fig 1 AP relaxation 49city TSP Two subtours occurred solution 718 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 2 HeldKarp relaxation 49city TSP The values shown arcs corresponding xij values This example appeared 14 22 Branchandbound search In 1958 papers appeared branchandbound search 5121643 This method organizes search space tree structure At level tree branching rules generate child nodes The children tightened versions parents constraints added set values decision variables Each node inherits tightening constraints added ancestors These tightened problems represent subproblems parent problem tightening reduce size individual solution spaces At node relaxation original problem solved This relaxation enlarge size nodes solution space Thus root node relaxation problem solved At node doublymodiﬁed problem solved simultaneously tightened relaxed The solution space doubly modiﬁed problems contain extra solutions solution space original problem missing solutions original problem illustrated following example Consider Carpaneto DellAmico Toth CDT implementation branchandbound search ATSP 7 depicted Fig 3 For algorithm AP relaxation allowing number subtours solution The branching rule dictates forced inclusions exclusions arcs Arcs forced way referred free arcs The branching rule selects subtour AP solution fewest free arcs child node forces exclusion free arcs Furthermore child node ﬁrst forces inclusion arcs excluded elder siblings More formally given parent node let E denote set excluded arcs I denote set included arcs a1 free arcs selected subtour In case t children generated kth child having Ek E ak Ik I a1 ak1 Thus child k tightened adding constraints decision variables arcs E equal zero arcs I equal When child k processed AP solved additional constraints The solution space doublymodiﬁed problem missing tours containing arc Ek tours arc Ik absent However enlarged addition AP solutions single cycle contain arc Ek contain arcs Ik The CDT algorithm experimentally compared cutandsolve Results section paper 23 Gomory cuts In late ﬁfties Gomory proposed iterative search strategy cutting planes systematically derived applied relaxed problem 20 An example cutting plane follows Assume given binary decision variables x1 x2 x3 constraint 10x1 16x2 12x3 cid2 20 integrality relaxation 0 cid2 xi cid2 1 substituted binary constraints It observed following cut added problem x1 x2 x3 cid2 1 removing solutions original problem However solutions removed relaxed problem x1 05 x2 025 x3 05 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 719 Fig 3 An example ﬁrst nodes CDT search tree ATSP The cycles shown subtours fewest free arcs AP solutions corresponding nodes Arcs forced excluded sets E arcs forced included sets I Gomory cuts tighten relaxed problem removing solution space These cuts tighten original unrelaxed problem solutions original problem removed However removal relaxed solutions tends increase likelihood relaxed solution solution unrelaxed problem Such solutions establish update incumbent solution Cuts added relaxations solved iteratively tightening relaxed problem constrictive solution equal current incumbent At point search terminated incumbent solution declared optimal 24 Branchandcut search Branchandcut search essentially branchandbound search addition application cutting planes nodes These cutting planes tighten relaxed problem increase pruning potential ways First value solution subproblem increased decreased tightening If increase causes value greater equal incumbent solution value entire subtree pruned Second forcing set relaxed solutions increase possibility feasible solution unrelaxed problem If feasible solution value current incumbent solution replace incumbent increase future pruning potential The number nodes cutting planes applied algorithmspeciﬁc Some algorithms apply cuts root node apply cuts nodes Concorde 12 awardwinning branchandcut algorithm designed solving symmetric TSP STSP This code solve large STSP instances including 24978city instance corresponding cities Sweden 2 This success possible design number clever cutting planes custom tailored problem 25 Branchandbound branchandcut design considerations When designing algorithm branchandbound branchandcut number policies determined These include determining relaxation algorithm solving relaxation branching rules search method determines order nodes explored Since relaxed problem solved node substantially easier solve original problem However desirable use tightest relaxation possible order increase pruning capability Branching rules determine structure search tree They determine depth breadth tree Since branching rules tighten subproblem strong rules increase pruning potential 720 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Finally search method selected Bestﬁrst search selects node best heuristic value explored ﬁrst A search bestﬁrst strategy uses sum cost path given node estimate cost node goal node heuristic value 23 This strategy ensures number nodes explored given search tree heuristic Unfortunately identifying best current node requires storing active nodes todays vast memory capabilities quickly exhausted For reason depth ﬁrst search commonly employed While strategy solves memory problem asymptotically optimal 49 introduces substantial new problem Heuristics guide search lead wrong direction resulting large subtrees fruitlessly explored Unfortunately combination policies ﬁnetuned best results problem instances remain insoluble This usually inadequate pruning On occasion difﬁculty computational demands solving relaxed problem ﬁnding cutting planes For instance simplex method commonly solving relaxation IPs despite fact exponential worstcase performance 3 Cutandsolve search strategy 31 Basic algorithm Unlike cutting planes branchandcut search cutandsolve uses cuts intentionally cut solutions original solution space We use term piercing cut refer cut removes feasible solution original unrelaxed problem solution space The cutandsolve algorithm presented Fig 41 In algorithm iteration corresponds node search path First piercing cut selected Let SSsparse set feasible solutions solution space removed cut Then best solution SSsparse This problem tends relatively easy solve sparse solution space opposed vast solution space original problem searched best solution At root node solution referred incumbent best solution If later iterations ﬁnd solution better best best replaced new solution In step piercing cut added IP This piercing cut excludes solutions SSsparse IP Thus piercing cut tightens IP reduces size solution space The lower bound tightened IP If lower bound greater equal best search terminated best optimal solution At subsequent nodes process repeated The incumbent solution updated needed The piercing cuts accumulate iteration When tightening piercing cuts constrictive solution doublymodiﬁed problem greater equal incumbent solution value When occurs incumbent solution returned optimal Theorem 1 When cutandsolve algorithm terminates current incumbent solution optimal solution Proof The current incumbent optimal solution solution spaces cut away piercing cuts The solution space ﬁnal doublymodiﬁed problem contains solutions original problem algorithm cut_and_solve IP select cut optimal feasible solution space removed cut update best necessary add cut problem lower bound lower bound best return best repeat Fig 4 Cutandsolve algorithm 1 We thank anonymous reviewer suggesting pseudo code S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 721 Fig 5 Cutandsolve depicted binary search tree At Ai nodes optimal solution small chunk solution space cut away corresponding piercing cut At Bi nodes relaxation solved remaining solution space cut away piercing cuts If relaxation reduced solution space value greater equal incumbent value reduced solution space contain solution better incumbent cid2 Termination algorithm summarized following theorem Theorem 2 If solution space original problem SSo ﬁnite relaxation algorithm algorithm selecting solving sparse problem guaranteed terminate cutandsolve algorithm guaranteed terminate Proof The number nodes search path ﬁnite nonzero number solutions removed SSo node Therefore ﬁnite number problems solved guaranteed terminate cid2 Cutandsolve cast binary search tree highly disproportionate children shown Fig 5 At node relaxation solved cut chosen This cut branching rule The left childs solution space small contains solutions cut away piercing cut The right child huge solution space remaining removing left childs solutions The left childs solution space easily explored produces potential incumbent solutions It immediately solved right child subdivided set disproportionate children When relaxed solution right child greater equal current incumbent pruned search ﬁnished Thus ﬁnal conﬁguration search tree single path far right single branch left level This search strategy essentially linear consistently solving easy problems immediately redividing 32 Using cutandsolve complete anytime algorithm The cutandsolve algorithm easily adapted anytime algorithm 6 Anytime algorithms allow ter mination execution time return best approximate solution far Many anytime algorithms based local search solutions This type anytime algorithm guarantee optimal solution eventually determine current solution optimal Complete time algorithms 354647 overcome restrictions These algorithms ﬁnd optimal solution given adequate time optimality guaranteed Cutandsolve ﬁnds incumbent solution root node approximate solution available time root node solved This solution improves optimum execution terminated making complete anytime algorithm Cutandsolve offers favorable beneﬁt anytime solver Many approximation algorithms unable provide bound quality solution This especially problematic result analysis estimated error needs propagated Upon termination cutandsolve value recently solved doublymodiﬁed problem lower bound optimal solution yielding desired information Furthermore rate decrease gap incumbent doublymodiﬁed problem solutions monitored determine terminate anytime solver 722 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 33 Parallel processing Cutandsolve computed parallel processing Each sparse problems solved independently different processors It necessary sparse problem runs completion Whenever sparse problem solved determined iteration smallest lower bound greater equal solution sparse problem It necessary sparse problems prior iteration run completion ensure optimality Consider search depicted Fig 5 The solutions Bi nodes nondecreasing increases Suppose A4 completes ﬁrst solution x Suppose B1 solution x B2 solution equal x In case B2s solution greater x lower bound solution space contains solution A4 Only A1 A2 need run completion search A3 terminated contain solution better x More generally let y equal cost solution node Ap Let Bq node smallest cost greater equal y All searches nodes Ai q terminated 4 A simple example In section present simple example problem step search process cutandsolve Consider following IP min Z y 4 5 x subject x cid3 0 y cid2 3 y 3 5 y 13 6 y 5 13 x I y I x cid3 6 5 x cid2 9 x cid3 1 14 10 11 12 13 14 15 16 17 This IP decision variables allowing representation 2D graph shown Fig 6 Every x y pair feasible obey constraints Each ﬁrst ﬁve linear constraints 11 15 corresponds edge polygon Fig 6 All feasible solutions lie inside edge polygon Constraints 16 17 require decision variables assume integral values Therefore feasible solutions IP shown dots located inside edge polygon The terms objective function 10 rearranged slopeintercept form follows y 4 5 x Z Therefore objective function IP represents inﬁnite number parallel lines slope 4 5 In example value Z equal corresponding yintercept For general 2D IPs yintercept equal constant times Z Fig 6b shows lines family The feasible solution point x value zero y value 3 yielding Z value 3 Clearly optimal solution By considering lines slope 4 5 apparent line smallest yintercept value intersects feasible solution identify optimal Z value This line inspection shown Fig 6d The optimal solution x 2 y 1 yielding Z 06 For IP solution space original problem SSo contains points lie polygon Each points feasible solutions satisfy constraints To apply cutand solve relaxation chosen In example relax constraints 16 17 The solution space S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 723 Fig 6 Graphical solution example IP The feasible solution space Dots polygon represent feasible solutions b One lines representing objective function Z 3 It intersects feasible solution x 0 y 3 c Lines representing objective function values Z Arrows direction Z decreases d The optimal solution x 2 y 1 Z 06 relaxed problem SSr contains point real values x y inside polygonan inﬁnite number solutions Fig 7 shows steps taken solving IP cutandsolve First relaxed solution The solution relaxation shown Fig 7a The value x 35 y 14 solution value relaxed subproblem equal 14 This lower bound optimal solution value Next piercing cut selected shown Fig 7b The shaded region contains solution relaxed problem feasible solution original problem It contains inﬁnite number feasible solutions relaxed problem This sparse problem solved ﬁnd best integral solution There integral solution sparse problem best Thus incumbent solution set x 3 y 2 objective function value 04 Best set 04 The line cuts away shaded region polygon Fig 7b represented linear constraint y 17 3 x cid3 14 This constraint added IP Now feasible region IP reduced current solution space contains points shown Fig 7c The relaxation current IP shown Fig 7d The value relaxed solution 11 Notice lower bound best search continues second iteration At second node search select piercing cut shown Fig 7e The sparse problem represented shaded area Fig 7e solved yielding value 06 This value current incumbent solution new incumbent best set 06 The linear constraint corresponding current piercing cut added IP resulting reduced feasible solution space shown Fig 7f The relaxed problem solved current IP shown Fig 7g The new lower bound 02 This value greater best 06 search ﬁnished The current incumbent optimal solution The incumbent best solution union solution spaces sparse problems solved 02 lower bound best possible solution remaining solution space Since greater incumbent solution space better incumbent Therefore optimality ensured 724 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 7 Solving example IP cutandsolve The relaxed solution original problem b The ﬁrst piercing cut c The solution space IP piercing cut added d The solution doublymodiﬁed problem e The second piercing cut f The solution space IP piercing cuts added g The solution doublymodiﬁed problem resulting value worse current incumbent The example problem presented section easily solved inspection However problems contain thousands decision variables yielding solution spaces deﬁned convex polyhedrons correspondingly highdimensional space For example 100city ATSP 9900 decision variables The piercing cuts chosen example problem section customized particular instance In section generic procedure deriving piercing cuts presented 5 A generic cutandsolve procedure The cutandsolve algorithm requires selections A relaxation chosen method deriving piercing cuts devised technique solving sparse problem selected For best results choices determined careful evaluation particular problem addressed For S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 725 problems relaxation techniques algorithms solving sparse instances previously researched However derivation piercing cuts previously explored In section summarize favorable characteristics piercing cuts present generic procedure deriving Then present generic cutandsolve algorithm selections speciﬁed This general procedure IP While customized approach yield better results generic approach implementation ATSP good results Every IP cast binary IP BIP 27 decision variables restricted values 0 1 For given BIP decision variables partitioned sets small set S large set L The sparse problem solved small set S This essentially setting values variables L zero After sparse problem solved constraint set variables L zero removed Then following piercing cut added BIP cid2 xi L xi cid3 1 18 Using cut partitions solution space Either sum variables L equal zero greater equal The solutions corresponding ﬁrst case precisely solutions sparse problem All solutions solution space contained original problem addition piercing cut 18 The question remains partition variables sets S L producing effective piercing cuts The answer question believed problem dependent We offer guidelines Following desirable properties piercing cuts 1 Each piercing cut remove solution current relaxed problem prevent solution subsequent iterations 2 The space removed piercing cut adequately sparse optimal solution relatively easily 3 The piercing cuts attempt capture optimal solution original problem The algorithm terminate optimal solution cut away consequently incumbent 4 In order guarantee termination piercing cut contain feasible solution original unrelaxed problem Sensitivity analysis extensively studied Operations Research 44 We borrow tool domain devise totally generic approach partitioning decision variables sets S L follows First integrality constraints relaxed BIP solved LP An LP solution deﬁnes set values referred reduced costs Each decision variable xi reduced cost value lower bound increase LP solution cost value variable increased unit Each decision variables nonzero values LP solution reduced cost zero If decision variable xi reduced cost zero possible increase value xi increasing cost LP solution On hand xi large reduced cost equally large larger increase LP solution cost occur unit increase value xi We use concept generic algorithm Set S composed decision variables reduced costs parameter α α 0 α set small resulting sparse problem relatively easy solvesatisfying property 2 On hand set large possible increase likelihood set S contains decision variables necessary optimal solution original problem Property 1 satisﬁed LP solution included sparse solution space decision variables nonzero values LP solution reduced costs zero Intuitively decision variables small reduced costs likely appear optimal solution Thus property 3 addressed reduced costs guide selecting variables set S making α large practical If guaranteed termination required property 4 satisﬁed setting α adequately large value adding variables S guarantee feasible solution original problem Having determined method partitioning decision variables present completely generic cutand solve program BIP consequently IP outlined Fig 8 The relaxation 726 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 algorithm generic_cut_and_solve BIP relax integrality solve LP LP solution best return best let S variables reduced costs alpha optimal feasible solution S update best necessary LP solution best return best add sum variables S 1 BIP repeat Fig 8 A generic cutandsolve algorithm omission integrality constraints The sparse problem solved BIP IP solver The piercing cut added BIP cid5 xi S xi cid3 1 Notice performance generic approach improved customizing problem hand Tighter lower bounds effective piercing cuts andor use solver designed solve sparse instances problem yield dramatic increases performance Yet sections simple implementation generic approach produce impressive results 6 Cutting traveling salesmen size We implemented cutandsolve algorithm solving realworld instances ATSP The ATSP model host planning routing scheduling problems addition number diverse applications noted Section 1 Many realworld applications difﬁcult solve conventional methods good candidates alternative search strategy Seven realworld problem classes ATSP studied 8 Instance generators seven prob lem classes available David Johnsons webpage httpwwwresearchattcomdsjchtspatsphtml A brief description seven problems follows The ﬁrst class approximate shortest common superstring super This problem pertains genome reconstruction given set strings combined form shortest pos sible superstring The second class tilted drilling machine additive norm rtilt This class corresponds problem scheduling drilling holes tilted surface The class stilt corresponds problem different norm The fourth class random Euclidean stacker crane crane pertains planning operation crane moves number items different locations The class disk drive disk This class represents problem scheduling disk read head reads number ﬁles The sixth class pay phone collection coin corresponding problem collecting coins pay phones The phones located grid twoway streets perimeter grid consisting oneway streets Finally nowait ﬂow shop shop class represents scheduling jobs require use multiple machines In problem delay job machines In generic algorithm lower bounds relaxing integrality For ATSP HeldKarp lower bound Then arcs reduced costs α selected set S sparse graph composed arcs solved The best tour sparse graph ﬁrst incumbent solution The original problem tightened adding constraint sum decision variables arcs S equal n 1 n equal number cities This effect piercing cut presented generic algorithm cid5 xi S xi cid3 1 n arcs optimal solution ATSP If arcs needed optimal solution present selected set arcs solution incumbent Otherwise arc set required optimal tour This constraint represented piercing cut The process solving HeldKarp lower bound solving sparse problem adding piercing cut problem repeats HeldKarp value deeplycut problem greater equal incumbent solution At point incumbent optimal tour The worstcase complexities solving HeldKarp lower bound simplex method solving sparse problem exponential However practice problems usually relatively easy solve Fur thermore ﬁrst iteration incumbent solution upper bound sparse problem solver potentially improving performance S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 727 Selection appropriate value α dependent distribution reduced cost values In current implementation simply select number arcs mcut initial cut At root node arcs sorted reduced costs mcut lowest arcs selected α set equal maximum reduced cost set At subsequent nodes α determine selected arcs The choice value mcut dependent problem class number cities We believe determining α directly distribution reduced costs enhance implementation priori knowledge problem class necessary α custom tailored suit variations instances class problems If cut contain single feasible solution enlarged However experiments check apparent beneﬁt The problems solved iterations guaranteeing termination practical importance We LP IP solver Cplex 29 solve relaxation sparse problem All parameters solver set default modes warm starts For larger instances generic solver bogged solving sparse problem Performance improved substi tution algorithm designed speciﬁcally solving sparse ATSPs We unable ﬁnd code available We investigating possible implementations task 1 adapting Hamiltonian circuit enumerative algo rithm exploit ATSP properties 2 enhancing Cplex implementation adding effective improvements Padberg Rinaldi shrinking procedures external pricing cutting planes customized sparse ATSPs heuris tics node selection heuristics determining advanced bases 3 implementing hybrid algorithm integrates constraint programming linear programming However despite crudeness implementation sufﬁces demonstrate potential cutandsolve method We compare solver branchandbound branchandcut implementations section 7 Computational results ATSP In section compare cutandsolve branchandbound branchandcut solvers We seven realworld problem generators 8 discussed Section 6 conduct large scale experiments For problem class size ran 500 trials revealing great insight expected behavior solver problem class We started n 25 incremented 25 cities time solver unable solve instances average time minutes allowing 5000 minutes trial With exception super problem generator generators use parameter effect number signiﬁcant digits arc costs We set parameter 100000 The crane class uses second parameter increased larger numbers cities 8 We set parameter 10 n cid2 100 13 n 125 15 n 150 We compare cutandsolve CZ branchandbound algorithm introduced Carpaneto DellAmico Toth CDT 7 discussed Section 2 We comparisons branchandcut solvers Concorde 12 Cplex 29 Concorde introduced Section 2 It solving symmetric TSPs STSPs ATSP instances transformed STSP instances 2node transformation 32 David Johnson publiclyavailable code 2node transformation httpwwwresearchattcomdsjchtspatsphtml When 2node transforma tion number arcs increased 4n2 2n However number arcs zero essentially inﬁnite cost n2 n original problem Concorde allows adjustment chunk size This parameter controls degree projectandlift cuts 3 utilized Projectandlift cuts dynamically produced suit particular instance solved If chunk size set zero projectandlift cuts generated Concorde behaves pure STSP solver It shown 17 default chunk size 16 produced best results realworld ATSP instances We default value trials The publically available branchandcut code speciﬁcally solving TSPs ﬁnd Concorde However Cplex robust branchandcut solver general IPs included comparisons This solver dynamically determines search strategies cuts instance For instance variables chosen branching direction search customized given instance Furthermore Cplex uses different classes cutting planes Gomory cuts comprise classes automatically determines frequency class cuts use Finally Cplex uses heuristics ﬁnd integer feasible solutions traversing search tree 728 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 9 Average normalized computation times 95 conﬁdence interval shown super problem class Generally speaking CZ generic Cplex implementation Both algorithms identify subtours add appropriate subtour elimination constraints Other algorithms generic IP solvers Our code run Cplex version 81 We Athlon 19 MHz dual processors gigabytes shared memory tests use parallel processing In order identify subtours relaxed problem Matthew Levines implementation Nagamochi Ibaraki minimum cut code 37 available 38 Our code available 10 In experiments presented search path short Typically sparse problems relaxed problems solved This result indicates set arcs small reduced costs likely contain optimal solution The average normalized computation times 95 conﬁdence intervals realworld problem classes shown Figs 9 15 One interested typical time required solvers median times trials given Figs 16 22 Table 1 lists largest problem instance size solved algorithm execution time limit Concorde outperformed solvers super class shown Figs 9 16 It able solve instances n 625 CZ solved 600 cities Cplex solved 275 cities CDT solved 250 cities Concorde outperformed solvers rtilt problem class shown Figs 10 17 It solved 125city instances CZ solved 100 cities Cplex solved 75 cities CDT solved 25 cities We solved super rtilt instances solutions optimal solutions For ﬁve problem classes CZ outperformed solvers For crane class CZ Concorde Cplex able solve 125 cities shown Figs 12 19 CZ fastest number cities followed Concorde For problem classes CZ able solve larger instances solvers For stilt CZ solved 100 cities allotted time Concorde Cplex solved 75 cities shown Figs 11 18 For disk CZ solved 775 cities Cplex followed far 325 cities shown Figs 13 20 CZ solved 100city coin instances Cplex solved 75 cities shown Figs 14 21 Finally CZ able solve 550city shop instances CDT following 350 cities shown Figs 15 22 CDT performed moderately super shop However able solve 50 cities crane 25 cities problem classes We let computations run past time limit S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 729 Fig 10 Average normalized computation times 95 conﬁdence interval shown rtilt problem class Fig 11 Average normalized computation times 95 conﬁdence interval shown stilt problem class trials required substantial amounts time The worst case 50city disk class ﬁnally killed 25900 minutes In summary problem instances tested CDT robust Cplex robust moderate performance general Concorde fastest problem classes large number optimal solutions CZ robust best performance ﬁve classes 730 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 12 Average normalized computation times 95 conﬁdence interval shown crane problem class Fig 13 Average normalized computation times 95 conﬁdence interval shown disk problem class 8 Discussion related work Many optimization problems difﬁcult solve optimality approximations employed Sacri ﬁcing optimality costly situations Approximations problematic solution important progress research biological applications Approximations costly solution ex S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 731 Fig 14 Average normalized computation times 95 conﬁdence interval shown coin problem class Fig 15 Average normalized computation times 95 conﬁdence interval shown shop problem class pensive procedure routing spacecraft solution reused number times manufacturing applications Moreover deleterious use approximation application approximation poor Cutandsolve offers alternative branchandbound branchandcut optimality desired In experiments observed performance cutandsolve diminished problems large numbers optimal solutions We monitored trials noticed cutandsolve optimal solution early 732 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 16 Median computation times super problem class Fig 17 Median computation times rtilt problem class search required substantial computation time prove optimality We suspect optimal solutions remained doublymodiﬁed problem making difﬁcult relaxation equal optimal solution value It optimal solutions cut away computation complete One concern viability cutandsolve choosing poor cut similar choosing wrong path depthﬁrst search tree These actions different When choosing wrong child depth S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 733 Fig 18 Median computation times stilt problem class Fig 19 Median computation times crane problem class ﬁrst search decision permanent descendants subtree For example variable appears optimal solution backbone variable 4048 setting value zero calamitous Conversely forcing inclusion variable doesnt appear feasible solution fat variable 9 results similar dire situation Every node subtree doomed On hand poor cut chosen cutandsolve consequence time spent exploring single node relatively ineffective It wasnt completely 734 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 Fig 20 Median computation times disk problem class Fig 21 Median computation times coin problem class wasted poor cut helps tighten problem degree cut repeated future iterations Moreover subsequent nodes locked choice current cut Search tree methods branchandbound branchandcut choose memory problems risk fruitlessly searching subtrees containing optimal solutions Cutandsolve free difﬁculties Its memory requirement insigniﬁcant current incumbent solution current doublymodiﬁed problem S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 735 Fig 22 Median computation times shop problem class Table 1 Largest problem size solved allotted time algorithm problem class CDT Concorde Cplex super rtilt stilt crane disk coin shop 250 25 25 50 25 25 350 625 125 75 125 100 25 275 75 75 125 325 75 250 CZ 600 100 100 125 775 100 550 Concorde terminated errors coin class need saved search path traversed Furthermore iterative search subtrees lost A great number techniques devised effort overcome problem depthﬁrst search Among iterative deepening 34 limited discrepancy 24 randomization restarts 19 Another interesting comparison branchandbound branchandcut compute relaxed solution feasible original problem optimal original problem In contrast cutandsolve required ﬁnd relaxed solution optimal feasible original problem Consider example generic cutandsolve Each righthand children Fig 5 non integral solutions Yet search terminated soon value relaxation greater equal incumbent value We discuss algorithms similar cutandsolve Cutandsolve similar Gomorys algorithm cuts constrain problem linear path searched Gomorys algorithm referred solving problem root node essentially behavior comparing branchand cut However cutting planes applied relaxed problems solved iterative manner search terminated suggesting iterative progression search Cutandsolve thought extension Gomorys method Like Gomorys technique cuts applied time optimal solution 736 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 The major difference methods Gomorys cuts piercing cuts cut away feasible solutions original problem Piercing cuts deeper Gomory cuts required trim feasible solutions unrelaxed problem Cutting deeply yields beneﬁts First provides set solutions best chosen potential incumbent Second piercing cuts tighten relaxed problem aggressive manner consequently tend increase solution doublymodiﬁed problem expeditiously Cutandsolve similar algorithm solving Orienteering Problem OP presented 18 In work conditional cuts remove feasible solutions original problem These cuts conjunction traditional cuts tighten problem When conditional cut applied enumeration feasible solutions cut attempted If enumeration solved short time limit cut referred branch cover cut sparse graph associated stored This algorithm attempts solve OP iterative fashion branching occurs ﬁve branch cover cuts applied After branchandcut tree solved second branchandcut tree solved union graphs stored branch cover cuts Cutandsolve differs OP algorithm ways First incumbent solutions forced early cutandsolve search These incumbents provide useful upper bounds improve anytime performance Second approach 18 stores sparse problems combines solves single larger problem initial branchandcut tree explored Finally OP algorithm truly iterative branching allowed In broad sense cutandsolve similar divideandconquer 41 techniques identify small subproblems original problem solve While divideandconquer solves subproblems cut andsolve solves small percentage When comparing techniques cutandsolve thought divideandconquer powerful pruning rules We conclude section note generality piercing cuts Piercing cuts iterative fashion cutandsolve applied search strategies branchandcut As long sparse problem deﬁned cut solved piercing cuts added IP For example Fischetti Toths branchandcut algorithm 17 solves number sparse problems node search tree order improve upper bound Piercing cuts corresponding sparse problems added IP loss optimality These piercing cuts tighten problem greater degree tightening traditional cuts reduce time required solve instance 9 Conclusions In paper presented search strategy referred cutandsolve We showed optimality termination guaranteed despite fact branching Being iterative strategy technique immune pitfalls plague search tree methods branchandbound branchandcut Memory requirements negligible incumbent solution current tightened problem need saved search path traversed Furthermore need use techniques reduce risks fruitlessly searching subtrees void optimal solution We demonstrated cutandsolve integer programs implemented strategy solving ATSP In general generic implementation robust outperforms stateoftheart solvers difﬁcult realworld instances dont optimal solutions For ﬁve seven problem classes cutandsolve outperformed solvers The remaining classes optimal solutions In future plan improve implementation designing custom solver sparse ATSPs As general cutandsolve search strategy looking dynamically determining α customized particular instance Finally investigating use cutandsolve IPs We currently implementing biological problem haplotype inferencing 21 Life optimization problems Many problems arise ﬁeld Artiﬁcial Intelligence number search strategies emerged tackle Yet problems stubbornly defy resolution current methods It hope unique characteristics cutandsolve prove useful addressing interesting problems S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 737 Acknowledgements This research supported NDSEG Olin Fellowships NSF grants IIS0196057 ITREIA 0113618 IIS0535257 DARPA Cooperative Agreement F306020020531 We grateful anonymous reviewers paper preliminary conference paper provided number valuable insights We thank Matthew Levine use minimum cut code David Applegate Robert Bixby Vašek Chvátal William Cook use Concorde We extend thanks Matteo Fischetti generously shared expertise discussions References 1 D Applegate R Bixby V Chvátal W Cook TSP cuts conform template paradigm M Junger D Naddef Eds Computational Combinatorial Optimization Springer New York 2001 pp 261304 2 D Applegate R Bixby V Chvátal W Cook ConcordeA code solving Traveling Salesman Problems 151299 Release httpwwwtspgatecheduconcordehtml web 3 D Applegate R Bixby V Chvátal W Cook On solution Traveling Salesman Problems Documenta Mathematica Extra volume ICM III 1998 pp 645656 4 E Balas P Toth Branch bound methods The Traveling Salesman Problem John Wiley Sons Essex England 1985 pp 361401 5 F Bock An algorithm solving travelingsalesman related network optimization problems Technical report Armour Research Foun dation 1958 Presented Operations Research Society America 14th National Meeting St Louis October 1958 6 M Boddy T Dean Solving timedependent planning problems Proceedings IJCAI89 Detroit MI 1989 pp 979984 7 G Carpaneto M DellAmico P Toth Exact solution largescale asymmetric Traveling Salesman Problems ACM Transactions Math ematical Software 21 1995 394409 8 J Cirasella DS Johnson L McGeoch W Zhang The asymmetric traveling salesman problem Algorithms instance generators tests Proc 3rd Workshop Algorithm Engineering Experiments 2001 9 S Climer W Zhang Searching backbones fat A limitcrossing approach applications Proceedings 18th National Conference Artiﬁcial Intelligence AAAI02 Edmonton Alberta July 2002 pp 707712 10 S Climer W Zhang Cutandsolve code ATSP httpwwwclimerus httpwwwcsewustleduzhangprojectstspcutsolve 2004 11 S Climer W Zhang A linear search strategy bounds Proc 14th International Conference Automated Planning Scheduling ICAPS04 Whistler Canada June 2004 pp 132141 12 GA Croes A method solving travelingsalesman problems Operations Research 6 1958 791812 13 G Dantzig Maximization linear function variables subject linear inequalities TC Koopmans Ed Activity Analysis Produc tion Allocation Wiley New York 1951 14 GB Dantzig DR Fulkerson SM Johnson Solution largescale travelingsalesman problem Operations Research 2 1954 393410 15 R Dechter F Rossi Constraint satisfaction Encyclopedia Cognitive Science March 2000 16 WL Eastman Linear programming pattern constraints PhD thesis Harvard University Cambridge MA 1958 17 M Fischetti A Lodi P Toth Exact methods Asymmetric Traveling Salesman Problem G Gutin A Punnen Eds The Traveling Salesman Problem Variations Kluwer Academic Norwell MA 2002 18 M Fischetti JJ Salazar P Toth The generalized traveling salesman orienteering problems G Gutin A Punnen Eds The Traveling Salesman Problem Variations Kluwer Academic Norwell MA 2002 pp 609662 19 CP Gomes B Selman H Kautz Boosting combinatorial search randomization Proceedings 15th National Conference Artiﬁcial Intelligence AAAI98 New Providence RI 1998 pp 431438 20 RE Gomory Outline algorithm integer solutions linear programs Bulletin American Mathematical Society 64 1958 275278 21 D Gusﬁeld SH Orzack Haplotype inference S Aluru Ed Handbook Bioinformatics CRC 2005 press 22 G Gutin AP Punnen The Traveling Salesman Problem Variations Kluwer Academic Norwell MA 2002 23 TP Hart NJ Nilsson B Raphael A formal basis heuristic determination minimum cost paths IEEE Transactions Systems Science Cybernetics 4 1968 100107 24 WD Harvey ML Ginsberg Limited discrepancy search Proceedings 14th International Joint Conference Artiﬁcial Intelligence IJCAI95 vol 1 Montreal Canada August 1995 25 M Held RM Karp The traveling salesman problem minimum spanning trees Operations Research 18 1970 11381162 26 M Held RM Karp The traveling salesman problem minimum spanning trees Part ii Mathematical Programming 1 1971 625 27 F Hillier G Lieberman Introduction Operations Research sixth ed McGrawHill Boston 2001 28 KL Hoffman M Padberg Improving LPrepresentations zeroone linear programs branchandcut ORSA Journal Computing 3 1991 121134 29 Ilog httpwwwcplexcom web 30 DS Johnson G Gutin LA McGeoch A Yeo W Zhang A Zverovich Experimental analysis heuristics ATSP G Gutin A Punnen Eds The Traveling Salesman Problem Variations Kluwer Academic Norwell MA 2002 31 DS Johnson LA McGeoch EE Roghberg Asymptotic experimental analysis HeldKarp Traveling Salesman bound Proceed ings 7th Annual ACMSIAM Symposium Discrete Algorithms 1996 pp 341350 738 S Climer W Zhang Artiﬁcial Intelligence 170 2006 714738 32 R Jonker T Volgenant Transforming asymmetric symmetric traveling salesman problems Operations Research Letters 2 1983 161 163 33 LG Khaciyan A polynomial algorithm linear programming Doklady Akademii Nauk SSSR 244 1979 10931096 34 RE Korf Depthﬁrst iterativedeepening An optimal admissible tree search Artiﬁcial Intelligence 27 1985 97109 35 RE Korf A complete anytime algorithm number partitioning Artiﬁcial Intelligence 105 1998 133155 36 EL Lawler JK Lenstra AHG Rinnooy Kan DB Shmoys The Traveling Salesman Problem John Wiley Sons Essex England 1985 37 MS Levine Experimental study minimum cut algorithms PhD thesis Computer Science Dept Massachusetts Institute Technology Massachusetts May 1997 38 MS Levine Minimum cut code httptheorylcsmitedumslevinemincutindexhtml web 39 S Martello P Toth Linear assignment problems Annals Discrete Mathematics 31 1987 259282 40 R Monasson R Zecchina S Kirkpatrick B Selman L Troyansky Determining computational complexity characteristic phase tran sitions Nature 400 1999 133137 41 ZG Mou P Hudak An algebraic model divideandconquer parallelism Journal Supercomputing 2 1988 257278 42 J Pearl Heuristics Intelligent Search Strategies Computer Problem Solving AddisonWesley Reading MA 1984 43 MJ Rossman RJ Twery A solution travelling salesman problem Operations Research 6 1958 687 Abstract E313 44 A Saltelli S Tarantola F Campolongo M Ratto Sensitivity Analysis Practice A Guide Assessing Scientiﬁc Models John Wiley Sons Ltd West Sussex England 2004 45 HP Williams Model Building Mathematical Programming second ed John Wiley Sons Chichester 1985 46 W Zhang Complete anytime beam search Proceedings 15th National Conference Artiﬁcial Intelligence AAAI98 Madison WI July 1998 pp 425430 47 W Zhang Depthﬁrst branchandbound vs local search A case study Proceedings 17th National Conference Artiﬁcial Intelli gence AAAI2000 Austin TX July 2000 pp 930935 48 W Zhang Phase transitions backbones asymmetric Traveling Salesman Journal Artiﬁcial Intelligence Research 20 2004 471497 49 W Zhang RE Korf Performance linearspace search algorithms Artiﬁcial Intelligence 79 1995 241292